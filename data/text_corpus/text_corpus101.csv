index,text
505,in this contribution a three dimensional sediment scour model based on the two phase flow eulerian eulerian solver sedfoam is developed within the framework of the open source platform openfoam the adoption of the eulerian approach for both fluid and sediment makes the model suitable for simulating scour process around structures with arbitrary geometry the model is first validated with unidirectional sediment transport configurations without structures to ensure that it can capture both flow and sediment transport processes the validation cases show that the model can accurately simulate the sediment transport rate and bedload layer thickness as a function of the shields number over a wide range of flow condition and sediment properties then the model is applied to simulate the live bed scour process around a vertical pile due to unidirectional current it is a first attempt to use a two phase model for simulating such case and its success serves as a proof of concept for future development simulated results of flow sediment transport and scour processes are compared with experiments and good agreement is observed a new methodology to determine the bed shear stress in complex flow configurations is proposed the mixture shear stress computed at the elevation of the iso concentration ϕ 0 0 08 corresponding to top of the bedload layer is used to define the local shields number within the scour hole a competition between fluid bed shear stress driven and gravity driven sediment transport occurs at bed angles up to β 23 this is lower than the repose angle β r 32 the relationship between the sediment flux and the bed slope is linear below β 23 above this angle the sediment flux increases nonlinearly with the bed slope while the shields number tends to 0 this shows that in the part of the scour hole close to the vertical cylinder the sediment flux only result from the action of gravity avalanching is the dominant transport mechanism and conventional power law become ineffective even with slope correction in the lee side of the cylinder suspended load dominant and the power law assuming a local equilibrium between bottom shear stress and transport flux is no longer valid further discussion is made on the computational cost of the proposed model and future research directions keywords two phase flow scour numerical modeling 1 introduction numerical simulation of scour is a very difficult task due to several scientific and technical obstacles first sediment transport is an extremely complex phenomena involving many physical processes e g particle particle fluid particle and turbulence particle interactions for which existing models exhibit limited predictive capability an factor two error in sediment fluxes is often considered reasonable for steady and uniform flow conditions gomez and church 1989 when the fluid flow is three dimensional unsteady and non uniform such as in the scour configuration existing models for sediment fluxes are questionable because they assume a local equilibrium between the bottom shear stress ans the sediment transport flux second when scour occurs the fluid flow is almost always turbulent and the flow dynamics is complex with turbulent structures such as the horse shoe vortex hsv system upstream or vortex shedding downstream of an obstacle even though turbulence modeling has made significant progress over the last decades this remains one of the major unsolved problems in fluid dynamics from a technical point of view scour is a rather large scale problem for high resolution numerical simulation the domain size has to be large enough to capture the vortex shedding correctly and the erosion process takes place at long time scale which makes the simulations very challenging the third technical difficulty is that the scour process involves a dynamically changing interface i e the bed and its interaction with the stationary structure for structures with complex geometry the dynamic intersection of the bed surface and the structure is extremely difficult to capture there are several techniques to deal with the problem for example the arbitrary lagrangian eulerian approach ale also termed the moving mesh method the eulerian approach and the immersed boundary method the method introduced in this paper belongs to the eulerian approach where water and sediment are treated with a two phase flow model the development and application of scour models have also been hindered by the excessive computational resources required for such simulations in the literature most of the scour models use what is denoted here as the classical approach where they couple the hydrodynamics solving the navier stokes equations and the bed morphodynamics solving the exner s equation exner 1920 1925 such coupling approach can be best demonstrated by the work of roulund et al 2005 in their model the bottom stress was first calculated based on the simulated flow field then the bottom shear was used to calculate the sediment transport rate which was consequently used in the exner equation for updating the new bed position with this approach roulund et al 2005 show that the agreement between the numerical predictions and the experimental observations is good in both transient and equilibrium states the numerical simulations presented in roulund et al 2005 are often considered as a reference case in many posterior studies stahlmann et al 2013 baykal et al 2015 these cases are also considered in this work the classical approach for scour modeling used in roulund et al 2005 or baykal et al 2015 is based on empirical sediment transport formulas developed for steady and uniform flow conditions meyer peter and müller 1948 engelund and fredsøe 1976 in the presence of an obstacle such as a bridge pier the flow is highly unsteady non uniform and the bed slope can reach values near the angle of repose as a result most formulas are used beyond their validity range when applied to three dimensional scour around structures furthermore to avoid the slope angle in scour hole to be greater than the angle of repose ad hoc avalanche models are always applied which essentially redistribute sediment mass by a smoothing scheme most of these avalanche models have very little physical bases and more studies are warranted in the simple configuration of a single pile the performance of classical models are satisfactory roulund et al 2005 stahlmann et al 2013 baykal et al 2015 however to design civil engineering structures the conventional sediment transport models are not comprehensive enough therefore engineers are still mainly relying on small scale physical models to overcome the limitations of classical models for scour two phase flow models have been developed over the last decade amoudry et al 2008 cheng et al 2017 mathieu et al 2019 in this new framework the sediment phase can be either modeled as discrete particles termed the eulerian lagrangian approach or as a continuous phase termed the eulerian eulerian approach in both approaches the fluid phase is always seen as a continuum in the lagrangian approach a dynamical equation is solved for each individual particle and its interactions with neighboring particles e g escauriaza and sotiropoulos 2011 the computational resources required by this approach are too expensive at present for engineering applications nevertheless some aspects of scour can be studied using the lagrangian approach for example link et al 2012 used the model of escauriaza and sotiropoulos 2011 with 10 000 particles to investigate the sediment transport capacity by the horseshoe vortex in a non erodible scour hole in their approach the particles were considered as point particles and the fluid flow around them was not explicitly solved in the eulerian approach for the sediment phase sediment is treated as a complex fluid with a peculiar rheology interacting with water through buoyancy and drag forces such model has been applied with some success to various configurations ranging from sheet flow jenkins and hanes 1998 hsu et al 2004 cheng et al 2017 chauchat 2018 to 2d scour configurations downstream of an apron amoudry and liu 2009 cheng et al 2017 chauchat et al 2017 and scour under a pipeline lee et al 2016 mathieu et al 2019 in this paper we present the first three dimensional eulerian eulerian two phase flow simulation of the 3d scour around a vertical cylinder the first objective of the present work is to provide the proof of concept that the two phase flow approach can be used for modeling the scour phenomenon the main advantage of such approach is that it can intrisically deal with complex structures and does not rely on any empirical sediment transport formula or avalanching model the second objective is to evaluate the assumption of a local correlation between the sediment transport flux and the fluid bed shear stress in order to evaluate the main assumptions routinely used by conventional scour models the paper is organized as follows in section 2 the mathematical formulation of the eulerian eulerian two phase flow model is presented in section 3 the model is calibrated first with a steady uniform and unidirectional sediment transport configuration with medium sand in section appendix a the hydrodynamic validation of the flow around a vertical cylinder mounted on a flat non erodible bed is undertaken in section 4 the results of the three dimensional scour simulation are presented with a validation against experimental data an in depth discussion on the sediment transport around the pile is provided in section 6 at the end a summary of findings is given and some future directions are discussed 2 mathematical model the mathematical formulation of the eulerian eulerian two phase flow model has been detailed in chauchat et al 2017 the model is obtained by averaging the local and instantaneous mass and momentum conservation equations over fluid and dispersed particles e g hsu et al 2004 the resulting system of governing equations can be considered as the fundamental equations for two phase flow system similar to the navier stokes equations for single phase clear fluid system when applying these equations to turbulent flow additional turbulence averaging or filtering has to be used in the present model the turbulence averaged eulerian two phase flow equations described in chauchat et al 2017 are used and a new closure is developed 2 1 two phase flow model equations for incompressible fluid the mass conservation equations for the particle phase and fluid phase are written as 1 ϕ t ϕ u i s x i 0 2 1 ϕ t 1 ϕ u i f x i 0 where ϕ and 1 ϕ are the particle and fluid volume fractions u i s u i f are the sediment and fluid phase velocities and i 1 2 3 represents streamwise spanwise and vertical component respectively following chauchat et al 2017 the momentum equations for fluid and particle phases can be written as 3 ρ s ϕ u i s t ρ s ϕ u i s u j s x j ϕ p x i ϕ f i p s x i τ i j s x j ϕ ρ s g i ϕ 1 ϕ k u i f u i s 1 s c 1 ϕ k ν t f ϕ x i 4 ρ f 1 ϕ u i f t ρ f 1 ϕ u i f u j f x j 1 ϕ p x i 1 ϕ f i τ i j f x j 1 ϕ ρ f g i ϕ 1 ϕ k u i f u i s 1 s c 1 ϕ k ν t f ϕ x i where ρs ρf are the particle and the fluid density respectively gi is the gravitational acceleration and p is the fluid pressure fi is the external force that drives the flow the fluid stress τ i j f includes fluid grain scale viscous stress and fluid reynolds stresses p s τ i j s are particle normal stress and shear stress the last two terms on the right hand side rhs of eqs 3 and 4 are momentum coupling between the fluid phase and particle phase through drag force where k is the drag parameter the second to the last term represents averaged drag force due to mean relative velocity between fluid and particle phases while the last term represents the fluid turbulent suspension term also called drift velocity deutsch and simonin 1991 finally ν t f is the turbulent viscosity that has to be calculated using a turbulence closure and sc is the schmidt number the drag parameter k is modeled following schiller and naumann 1933 5 k 0 75 c d ρ f d u f u s 1 ϕ h e x p where d is the particle diameter and uk the velocity vector of the phase k the hindrance function 1 ϕ h e x p represents the drag increase when the particle volume fraction increases h e x p 2 65 is the hindrance exponent that depends on the particulate reynolds number here following chauchat et al 2017 its value is constant the drag coefficient cd is calculated as 6 c d 24 r e p 1 0 15 r e p 0 687 r e p 1000 0 44 r e p 1000 in which the particulate reynolds number rep is defined as r e p 1 ϕ u f u s d ν f where νf represents the fluid kinematic viscosity 2 2 fluid phase shear stress due to the fact that the present model equations are obtained by averaging over turbulence the fluid stresses consist in a fluid phase component r i j f i e fluid phase reynolds stress and a grain scale stress r i j f including the viscous stress and an additional effect due to fluid particle interaction at the grain scale the total fluid stress is written as 7 τ i j f r i j f r i j f 8 r i j f ρ f 1 ϕ 2 ν t f s i j f 2 3 k δ i j 9 r i j f 2 ρ f 1 ϕ ν m i x s i j f where ν t f is the eddy viscosity k is the turbulent kinetic energy and νmix is the mixture viscosity defined as a function of the solid volume fraction as proposed by boyer et al 2011 see chauchat et al 2017 for more details s i j f is the deviatoric part of the fluid phase strain rate tensor and is defined as 10 s i j f 1 2 u i f x j u j f x i 1 3 u k f x k δ i j 2 3 turbulence modeling the two phase flow turbulence averaged formulation requires a closure for the eddy viscosity several turbulence models are available in sedfoam including a two phase version of the k ε turbulence model cheng et al 2017 and a two phase version of the k ω turbulence model chauchat et al 2017 however it is known that these turbulence models are not accurate in the case of boundary layer flows with a strong adverse pressure gradient such as the flow around a vertical cylinder and the use of the k ω sst developed by menter 1993 is recommended in roulund et al 2005 it was proven difficult if not impossible to adapt the k ω sst model to two phase flows indeed in this turbulence model blending functions are introduced for some of the model coefficients these blending functions depend on the distance to solid boundaries that is not clearly defined in the presence of a mobile sediment bed recently a reformulated version of the standard k ω has been developed see wilcox 2006 wilcox 2008 and successfully applied to the scour around a cylindrical pile case by baykal et al 2015 this revisited model formulation incorporates a cross diffusion term and a built in stress limiter modification to behave as the sst model its adaptation to a two phase flow version can be done similarly to what is presented in chauchat et al 2017 for the standard k ω turbulence model this new model will be denoted as the two phase k ω 2006 in the present paper first the turbulent kinetic energy tke k is computed from the solution of eq 11 appropriate for sand particles in water hsu et al 2004 yu et al 2010 11 k t u j f k x j r i j f u i f x j c μ k ω x j ν f σ k ν t f k x j 2 k 1 t m f ϕ k ρ f 1 s c 1 ϕ ν t f ϕ x j ρ s ρ f 1 g j the above k equation is similar to the clear fluid k ω 2006 closure the first three terms on the rhs describe respectively production dissipation and diffusion of tke the last two terms on the rhs of eq 11 describe the modification of the classical k transport equation induced by the presence of particules the fifth term on rhs accounts for the sediment damping effect on the carrier flow turbulence through density stratification it can be seen as the buoyancy production dissipation due to sediment induced density stratification kranenburg et al 2014 the fourth term on rhs is a damping term modeling the drag effect of sediment particles on the carrier flow turbulence indeed if their inertia is important enough particles cannot completely follow the turbulent fluid velocity fluctuations in this drag induced damping term the parameter tmf is introduced to characterize the degree of correlation between particles and fluid velocity fluctuations following kranenburg et al 2014 its value varies between 0 and 1 t m f 1 denotes particles following instantaneously the turbulent velocity fluctuations in that case the turbulence damping of the carrier fluid vanishes conversely when t m f 0 the particles velocity fluctuations are uncorrelated to the fluid turbulence and the turbulence damping term is at maximum this situation corresponds to high stokes numbers i e the particle inertia is much higher than the fluid danon et al 1977 and chen and wood 1985 proposed an exponential function for tmf which is also used in cheng et al 2017 12 t m f e b s t where b is an empirical coefficient the degree of correlation between particles and fluid velocity fluctuations can be quantified by the stokes number st benavides and van wachem 2008 13 s t t p t l where t p ρ s 1 ϕ k is the particle response time t l k 6 ε is the characteristic time scale of energetic eddies in the present paper the k ω 2006 and the k ε are used between both models the transport equation for the turbulent energy dissipation rate together as the expression of the turbulent viscosity differ 2 3 1 k ω 2006 model the fluid specific rate of turbulent energy dissipation ω equation reads 14 ω t u j f ω x j c 1 ω ν t f r i j f u i f x j c 2 ω ω 2 x j ν f σ ω ν t f ω x j c d k ω c 3 ω 2 k 1 t m f ϕ ω ρ f c 4 ω 1 s c ω k 1 ϕ ν t f ϕ x j ρ s ρ f 1 g j the different coefficient values can be found in table 1 the coefficients associated with the present two equations closure are adopted from their clear fluid counterpart wilcox 2008 the last two terms on the rhs of eq 14 account for the sediment damping effect on the fluid carrier flow turbulence through drag and density stratification respectively according to the numerical experiments described in chauchat et al 2017 for the two phase k ω turbulence model the coefficient c 3ω is chosen to be 0 35 the coefficient associated with the buoyancy term c 4 ω 0 is used in stably stratified condition while it is set to 1 for unstably stratified condition b is left as the only free model calibration parameter from our experience b can be tuned in the range of 0 1 2 for instance increasing b from 0 25 to 1 25 leads to an increase of the associated sediment flux of approximatively 20 on a simple sheet flow case nagel 2018 all the simulations presented in this paper have been undertaken with the default value b 0 25 the fourth term on the rhs of eq 14 denoted as cdkω is a cross diffusion term 15 c d k ω a σ d ω k x j ω x j where the a coefficient is a smoothing term and σd a coefficient that reads 16 σ d h k x j ω x j σ d 0 where σ d 0 1 8 wilcox 2008 h is the heaviside step function which has a value of unity if the argument is zero or positive and a value of zero if the argument is negative the role of this cross diffusion term is to increase the dissipation of tke in the free shear flow by enhancing the production of specific dissipation ω in that region this will reduce the free shear flow spreading rates sensitivity to the free stream boundary conditions wilcox 2008 however it is important to suppress the cross diffusion term near a solid boundary wilcox 2006 when approaching the wall k and ω are respectively decreasing and increasing in the viscous sublayer the argument of the heaviside step function becomes negative and the cross diffusion term is suppressed the a coefficient is a smoother imposing a gradual transition between the regions where the cross diffusion term is activated or not a is only present in the two phase flow version of the model and allows to avoid instabilities 17 a 1 2 1 tanh 40 ϕ 0 1 the coefficient involved in the dissipation of dissipation term second term on the rhs of eq 14 follows the generalization of the pope correction pope 1988 given by wilcox 2008 18 c 2 ω c 2 ω 0 f c 2 ω where 19 c 2 ω 0 0 0708 f c 2 ω 1 85 χ ω 1 100 χ ω and 20 χ ω ω i j ω j k s k i f c μ ω 3 ω i j 1 2 u i f x j u j f x i the idea of pope 1988 is to introduce the χω parameter to describe the vortex stretching the latter is considered as the main mechanism for energy transfer from large to small eddies note that the pope correction must be turned off for 1d or 2d configurations finally the turbulent eddy viscosity ν t f involved in k equation and ω equation is calculated incorporating a stress limiting term 21 ν t f k ω k m a x ω c l i m 2 s i j f s i j f c μ where c l i m 7 8 wilcox 2008 2 3 2 k ε model for the k ε model the turbulent viscosity ν t f is calculated as 22 ν t f c μ k 2 ε the dissipation rate ε can be expressed in term of the specific dissipation rate ω as ε c μ k ω therefore for the k ε turbulence model the tke equation is similar to eq 11 with the second term on the rhs replaced by ε the transport equation for the dissipation rate ε reads 23 ε t u j f ε x j c 1 ε ε k r i j f ρ f u i f x j x j ν f σ ε ν t f ε x j c 2 ε ε 2 k c 3 ε ε k 2 k 1 t m f ϕ k ρ f c 4 ε 1 s c ε k 1 ϕ ν t f ϕ x j ρ s ρ f 1 g j the values of the empirical coefficients σ ε c 1ε c 2ε c 3ε c 4ε cμ are listed in table 2 the detailled description of the two phase k ε turbulence model can be found in hsu et al 2004 cheng et al 2017 chauchat et al 2017 2 3 3 schmidt number the fluid turbulence also affect the drag force acting on the sediment particles in the model description of chauchat et al 2017 the schmidt number sc present in the two phase flow momentum and turbulent equations eqs 3 4 11 and 14 is a constant however van rijn 1984 based on coleman 1970 experimental data proposed a relationship between the schmidt number and the ratio of the fall velocity w fall0 to the bed friction velocity u the so called suspension number sumer et al 1996 in the present work an original local schmidt number definition for the two phase flow model inspired from jha and bombardelli 2009 is used 24 s c min 1 2 w fall0 u u small 2 1 1 3 where u small 10 10 m s 1 is a regularization parameter that is introduced to avoid singularity 2 4 granular stresses the particle phase stress tensor can be split into the normal and off diagonal components corresponding to the particle pressure p s and the particle shear stress τ i j s respectively as established by johnson and jackson 1987 the particle normal stresses or pressure can be generally classified into two contributions a shear induced or collisional component super script s and a permanent contact component super script ff 25 p s p f f p s where the permanent contact component pff is calculated as 26 p f f 0 ϕ ϕ min f r i c f r ϕ ϕ min f r i c η 0 ϕ max ϕ η 1 ϕ ϕ min f r i c with ϕ min f r i c 0 57 ϕ max 0 635 for spheres fr η 0 and η 1 are empirical coefficients following cheng et al 2017 the values are set to f r 0 05 η 0 3 and η 1 5 the permanent contact component is due to enduring contact in highly concentrated region that are often close to quasi static immobile bed this normal pressure increases rapidly when the sediment concentration is close to maximum packing limit and prevents unphysical sediment concentration in the sediment bed the second term in eq 25 accounts for the shear induced particle normal stress the approach chosen for shear induced particle normal stress and shear stress modelling is the dense granular flow rheology or the so called μ i rheology gdrmidi 2004 forterre and pouliquen 2008 this approach is phenomenological and based on dimensional analysis it has successfully been used by revil baudard and chauchat 2013 and chauchat 2018 to model turbulent sheet flows for instance the total particle phase shear stress reads 27 τ i j s r i j s r i j s in which r i j s represents a reynolds stress like contribution for the solid phase and r i j s is the granular stress contribution coming from particle particle interactions the reynolds stress contribution is modeled according to rusche 2003 using the ct model ct is defined as the ratio of particle rms velocity fluctuations to the fluid rms velocity fluctuations this leads to the following reynolds stress contribution for the particle phase 28 r i j s ρ s ϕ c t 2 ν t f s i j s 2 3 c t 2 k δ i j according to rusche 2003 ct depends on the local value of the particle concentration and varies between 1 and 3 in the present model a value of 1 has been chosen based on comparison with sheet flow cases not shown here but see nagel 2018 the reynolds stress like contribution to the particle phase momentum balance seems to be needed to better predict the suspended load the granular contribution is written as 29 r i j s ν f r s s i j s where s i j s is the deviatoric part of sediment phase strain rate tensor 30 s i j s 1 2 u i s x j u j s x i 2 3 u k s x k δ i j in eq 29 the frictional viscosity ν f r s is defined following chauchat and médale 2014 31 ν f r s min μ i p s ρ s s s 2 d s m a l l 2 1 2 ν max in which ν max is the maximum solid phase viscosity ss is the norm of the shear rate tensor and d s m a l l 10 6 s 1 is a regularization parameter that is introduced to avoid singularity in addition to the viscosity regularization ν f r s is also clipped by ν max for numerical stability the frictional shear viscosity ν f r s allows to relate the total particle phase shear stress to the total particle pressure p s by a dynamic friction coefficient μ jop et al 2006 depending on the dimensionless number i in the present study the regime of the granular flow rheology is in the free fall or grain inertia regime in this regime the friction coefficient depends on the inertial number i u s d ρ s p s according to 32 μ i μ s μ 2 μ s i 0 i 1 with μs the static friction coefficient μ 2 an empirical dynamical coefficient and i 0 an empirical constant of the rheology the shear induced contribution to the particle pressure can be obtained from the dilatancy law ϕ i as proposed by boyer et al 2011 for the viscous regime of the granular flow rheology the adaptation to the inertial regime leads to the expression suggested by maurin et al 2016 33 ϕ i ϕ max 1 b ϕ i where b ϕ 2 3 chauchat 2018 inverting eq 33 and substituting the definition of the inertial number i gives the following expression for the shear induced pressure 34 p s b ϕ ϕ ϕ max ϕ 2 ρ s d s s 2 finally the total particle pressure p s can be calculated by eq 25 2 5 numerical implementation the numerical implementation of the present version of the eulerian two phase flow sediment transport model sedfoam is based on the open source finite volume cfd library called openfoam the numerical implementation is similar that the one described in chauchat et al 2017 the only difference lies in the pressure solver used in the present numerical implementation the pressure solver iterate on the reduced pressure p 35 p p ρ f g h where p is the total pressure and ρfgh is the hydrostatic pressure this way of solving the pressure system is similar to what is done in other validated openfoam solvers such as inter foam deshpande et al 2012 it has also been found that this solver is more stable compared to the one described in chauchat et al 2017 allowing to increase the cfl condition and reducing the computational time 3 unidirectional sediment transport simulations before considering the 3d scour problem the first step is to evaluate the capability of the two phase flow model to reproduce a unidirectional sediment transport the objective of these simulations is to i evaluate the sensitivity of the results to the numerical parameter ν max ii provide a general definition of the fluid bed shear stress valid for complex geometries and iii verify the capability of the two phase flow model to reproduce sediment transport rate formulas and establish a reference for the sediment transport law in undisturbed flow conditions i e far from any obstacle this reference will be used for the evaluation of the sediment transport law modification induced by the presence of the obstacle in section 6 of the paper the cases are two dimensional the flow being restricted to a vertical plane with a dominating streamwise velocity in order to drive the flow an external body force or a stream wise pressure gradient is imposed the water depth h f 0 2 m and the initial sediment layer thickness h s 0 1 m are fixed following the live bed configuration of roulund et al 2005 the sediments are made of medium sand with density ρ s 2650 kg m 3 and mean grain size diameter d 0 26 mm the corresponding fall velocity of an individual grain in quiescent water is w f a l l 0 3 4 cm s the fluid is water with density ρ f 1000 kg m 3 and kinematic viscosity ν f 10 6 m2 s 1 the mean fluid flow velocity is u 0 46 m s 1 the initial concentration profile is imposed using a hyperbolic tangent profile the stream wise pressure gradient is computed from the bed friction velocity of u 2 8 cm s estimated from the experiments by roulund et al 2005 36 f p x ρ f u 2 h f the shields parameter at the inlet is the same as is in roulund et al 2005 θ 0 19 it can be seen as the ratio between the destabilizing fluid shear stress τb and stabilizing forces grains weight acting on a particle 37 θ τ b ρ s ρ f g d the water column is discretized using 64 vertical levels with a geometric common ratio r f 1 075 from the initial interface to the top in the sediment bed 50 vertical levels with a geometric common ratio rs 1 086 from the initial interface to the bottom are used the vertical profiles of this configuration will be used as inlet boundary conditions in the 3d simulation presented in section 4 the granular rheology parameters are set up as follows the static friction coefficient is set to μ s 0 63 corresponding to the tangent of the angle of repose for sand in water the dynamical friction coefficient is fixed to μ 2 1 13 and i 0 0 6 these values have been obtained for bed load transport with spheres using the discrete element method maurin et al 2016 in order to account for the particle shape the coefficients μs and μ 2 have been increased by a constant value so that μs matches the tangent of the repose angle for real sand particles β r 32 a sensitivity analysis to the solid phase maximum viscosity νmax has been performed in nagel 2018 the model shows a strong sensitivity at low values of νmax but converges to a constant value when νmax increases the error associated with νmax is called the creeping flow if the maximum viscosity is too low a non negligible velocity gradient will be predicted in the static sediment bed that can give rise to a non negligible spurious sediment transport flux the creeping flux decays exponentially as νmax increases it has been shown that a value of ν m a x 100 m2 s should be used to guarantee a negligible creeping flow by varying the pressure gradient we will investigate the sediment transport flux as a function of the shields parameter the dimensionless depth integrated sediment flux q and the dimensionless transport layer thickness δ are computed from the numerical solutions and plotted against the shields parameter θ in fig 1 the dimensionless depth integrated sediment flux is calculated as the total sediment transport rate including the contribution of the bed load and the suspended load 38 q u s ϕ d z s 1 g d 3 the dimensionless transport layer thickness is computed as the bed normal distance between the iso surfaces ϕ 0 57 and ϕ 0 08 made dimensionless by the particle diameter d 39 δ δ d s where ϕ 0 57 is a proxy for the immobile bed position and ϕ 0 08 corresponds to a an inter particle distance of one particle diameter which is taken as the transition between bedload and suspended load layers bagnold 1956 dohmen janssen et al 2001 in addition to roulund et al 2005 unidirectional bedload case q and δ are also calculated from simulation undertaken with revil baudard et al 2015 and sumer et al 1996 unidirectional sheet flow configurations described in chauchat et al 2017 these three configurations cover a wide range of shields number θ 0 1 2 5 for different particle sizes and densities see table 3 in the left panel of fig 1 the dimensionless sediment transport rate is plotted against the shields number for the three configurations investigated the numerical results are within the scatter of the experimental data namely meyer peter and müller 1948 for θ 0 5 and wilson 1966 for θ 0 5 in the right panel of fig 1 the dimensionless sediment transport layer thickness is plotted against the shields number for revil baudard et al 2015 and roulund et al 2005 configurations the results exactly match wilson 1987 semi empirical model δ 10 θ the results for sumer et al 1996 case does not exactly follow that law but the trend is similar and the numerical results are in the scatter of sumer et al 1996 experiments the definition of the bed shear stress used to evaluate the shields number is also a matter of debate in chauchat 2018 the maximum value of the fluid bed shear stress is used 40 τ b max r x z f this definition corresponds to the red empty circles plotted in the left panel of fig 1 in a unidirectional case computing the bed shear stress as the maximum of the fluid shear stress lead to a very good agreement with literature data see figure a4 of chauchat 2018 however when dealing with complex 3d flow configurations this definition may lead to an inconsistency as the fluid shear stress profile does not necessarily present a monotonous increase toward the bed we propose an alternative consisting of the use of the mixture shear stress computed at the elevation of the iso concentration ϕ 0 0 08 to compute the shields number 41 τ b τ x z f ϕ ϕ 0 τ x z s ϕ ϕ 0 a sensitivity analysis to ϕ 0 0 08 0 45 0 57 has been performed and the shields number estimation is only marginally affected not shown here see nagel 2018 for details for clarity only the results obtained using ϕ 0 0 08 are plotted with the dark empty triangles in the left panel of fig 1 a sensible choice for the bed shear stress definition would be to consider the actual shear stress exerted by the mixture of grains and fluid at the fixed bed interface this corresponds to the latest definition using ϕ 0 0 57 and works well for unidirectional steady uniform flows however when the flow is non uniform with steep bed slopes it is more complex to relate the shields number to the actual shear stress exerted on the immobile bed as other granular processes are involved it should be noted here that the shields number characterizes the fluid drag force exerted by the flow on the particles in the near bed region in the perspective of upscaling the two phase flow results in single phase sediment transport models it is important to use a resolved quantity in the single phase flow model to compute the shields number the shear stress in the dilute region of the flow is solved by the single phase flow model however the shear stress exerted by the grain fluid mixture on the immobile bed is not in order to establish the undisturbed reference solution against which a 3d simulation can be compared the one dimensional results for medium sand in the range of shields parameter between 0 1 to 2 5 can be fitted using a power law of the excess shields number 42 q m o d a θ θ c b where θ c 0 047 is the critical shields number the a and b coefficients obtained from the best fit are summarized in table 4 first of all the values obtained are consistent between the different methods for the bed shear stress estimation the exponent of the power law b is less sensitive and in better agreement with classical empirical formula of meyer peter and müller 1948 or wong and parker 2006 the prefactor a is more sensitive with values ranging between 25 and 32 which is quite far from the empirical values of 3 97 and 8 it should be noted that all the different cases have different suspension numbers according to sumer et al 1996 the suspension number can be written as s u w f a l l 0 u for su 1 corresponding here to θ 0 3 the suspension becomes important in the total sediment flux for the sand case su varies between 1 6 for θ 0 1 and 0 56 for θ 1 therefore a non negligible suspended load components to the total sediment flux is expected in these conditions it is not surprising that the coefficients a and b are different from the values of meyer peter and müller 1948 nevertheless the model is able to recover a power law with a reasonable exponent it is worth mentioning that an exponent b 2 has been obtained in all former studies using two phase flow models hsu et al 2004 revil baudard and chauchat 2013 chauchat 2018 interestingly when using the mixture stress at sediment concentration higher than 0 08 the exponent b tends toward 1 5 consistently with meyer peter and müller 1948 or wong and parker 2006 it is therefore kept as the definition of the fluid bed shear stress to analyze the 3d scour configuration 4 3d scour simulation when an obstacle such as a bridge pier or a river restoration structure is built in a stream its presence can strongly modify the flow field and induce scour for example around a cylindrical pier the flow separation creates a strong adverse pressure gradient as a result the flow plunges toward the bed and if the bottom boundary layer contains a sufficient amount of vorticity a horseshoe vortex hsv is generated at the bed structure junction along the sides of a structure streamline contraction leads to flow acceleration and amplify the bed shear stress at the downstream side of the structure the boundary layer can separate and lead to vortex shedding in the wake in combination the wake vortices and the hsv lead to a local increase of bed shear stress sediment transport rate and bed erosion scour hole development if not correctly predicted and treated may significantly undermine the structure and cause its failure with potentially disastrous consequences breusers et al 1977 dargahi 1990 breusers and raudkivi 1991 melville and coleman 2000 roulund et al 2005 in the previous section it has been demonstrated that the two phase flow model presented in section 2 is able to accurately predict unidirectional sediment transport for medium sand the range of shields number investigated corresponds to the expected range in the 3d scour configuration of roulund et al 2005 furthermore the detailed study of the hydrodynamics around a vertical cylinder in a steady current without sediments is presented in appendix a it ensure that sedfoam is able to accurately reproduce the flow key structures i e the hsv and the lee wake vortices for the scour phenomenon in the present section the two phase flow model will be used to investigate the more complex configuration of the scour around a cylindrical pile 4 1 numerical configuration the numerical domain can be divided into two parts the initial water domain and the initial sediment domain grey part in fig 2 the initial water domain is a three dimensional box with a stream wise length lx 13d a span wise length ly 8d and a height h 2d where d 10 cm is the pile diameter as in roulund et al 2005 at the bottom a thin sediments layer 0 25d extends below the entire water domain except in a region around the pile where a deeper circular pit of height h s d and radius r p i t 2 d has been setup to reduce the grid cells number the sediments properties are the same as in the unidirectional case see section 3 the shields parameter at the inlet and the reynolds number are the same as is in roulund et al 2005 θ 0 19 and r e d 4 6 10 4 respectively the computational domain is discretized using a unstructured mesh see table 5 the mesh is refined around the cylinder and at the initial interface position the mesh refinement area around the cylinder is axisymmetric as for the unidirectional case the water column is discretized using 64 vertical levels with a geometric common ratio r f 1 075 from the initial interface to the top for the sand layer outside the scour pit the mesh is composed of 100 vertical levels having a geometric distribution with a common ratio r s 1 025 in the pit an additional 100 grid points are used with a geometric common ratio r p i t 1 010 the boundary conditions are imposed as follows i at the inlet vertical profiles obtained from the unidirectional simulation are imposed for us uf k ω ϕ zero transverse velocity is prescribed ii at the outlet zero gradient conditions neumann conditions n 0 are specified for all quantities except for the reduced pressure for which a homogeneous dirichlet boundary condition is imposed p 0 for the velocities a homogeneous neumann boundary condition is used when the velocity vector points outside of the domain at the outlet and a homogeneous dirichlet boundary condition u k 0 is used otherwise iii at the top boundary neumann boudary conditions are applied for k ω and uk iv at the walls including the cylinder zero velocity no slip is imposed for the three components and a small value is imposed for the tke the boundary condition for ω is specified using the classical wall function from openfoam at the cylinder and a constant value is imposed at the rigid bottom v at the side cyclic conditions are used for the initial condition the unidirectional solution used for the inlet is imposed over the entire numerical domain finally the granular rheology parameters used are the same as for the unidirectional sediment transport case the scheme used for the divergence operators of the different quantities is a blend between a pure centered second order scheme and a first order upwind scheme in the regions of rapidly changing gradient limitedlinear 1 the laplacian scheme for all quantities is a linear interpolation with non orthogonality correction gauss linear corrected as for the unidirectional configuration the bed shear stress is computed as the mixture shear stress at the concentration ϕ 0 0 08 43 τ b τ x z f ϕ ϕ 0 2 τ y z f ϕ ϕ 0 2 τ x z s ϕ ϕ 0 2 τ y z s ϕ ϕ 0 2 because the scour is deforming the initial flat sediment bed the resulting interface can be inclined and these variations have to be accounted for in the bed shear stress calculation which is taken as the magnitude of the tangential shear stress with respect to the sediment bed surface the bed interface is first interpolated from the original unstructured grid to a cartesian one on each cell of the cartesian grid the normal n and the tangential t x and t y vectors are calculated using the bed interface elevation horizontal gradient the projection of the mixture bed shear stress magnitude on the plane tangential to the local bed surface reads 44 τ b t f t x 2 t f t y 2 t s t x 2 t s t y 2 where tk is the stress vector applied on the sediments bed surface of the phase k it is obtained from the product between the phase shear stress tensor τk and the vector normal to the isosurface ϕ 0 0 08 n 45 t k τ k n for more details about the specific methodology for the bed shear stress determination in a non uniform three dimensional case the interested reader is referred to nagel 2018 in the following the results of the three dimensional two phase flow simulations are presented the reference two phase flow simulation was run for 600 s of real time this computation took approximately 480 h 20 days on 224 processors intel xeon e5 2690 v4 the computational time is approximatively of 108 000 cpu hours which would correspond roughly to 12 years on a single processor 4 2 erosion pattern and maximum erosion depth in order to qualitatively illustrate the model results snapshots of dimensionless bed elevation s d and fluid velocity streamlines are shown at different times t 10 s 60 s 150 s and 600 s in fig 3 the bed interface is defined as the surface of iso concentration ϕ 0 57 these results can be qualitatively compared with figure 33 from roulund et al 2005 it is noted that the vortex shedding and the suspension load are not resolved in roulund et al 2005 s steady state flow simulations despite these differences both models exhibit the following bathymetric features i a semi circular shaped scour mark is predicted at the upstream side of the pile ii sediments eroded from the scour mark first accumulate downstream the pile see fig 3a iii at later stages a scour mark is predicted at the downstream side see figures 3b c and d this comparison supports at least qualitatively the relevance of the two phase flow approach for modeling scour around hydraulic structures the velocity streamlines show that the scour hole erosion modify the hsv but also that vortex shedding is taking place at the downstream side of the pile more quantitatively fig 4 shows the time evolution of the maximum dimensionless scour depth s d at the upstream side top panel and at the downstream side bottom panel of the pile the results of two different two phase flow turbulence models the k ω 2006 blue line and the k ε yellow lline are shown they are compared with experimental data red dots and single phase flow model results from roulund et al 2005 green dashed line and stahlmann et al 2013 magenta dashed line the k ω 2006 simulation has been performed up to 600 s of dynamics the good agreement between this two phase flow simulation and the experiments at the upstream side of the pile shows that the two phase flow model is able to accurately reproduce the upstream scour depth evolution up to 300 s from 300 to 600 s the maximum dimensionless scour depth is underestimated compared with the experimental data as a result at t 600 s the two phase flow results give s d 0 63 whereas roulund et al 2005 measured results show s d 0 8 the k ε simulation has been run for 350 s the results in terms of upstream scour are almost identical to the k ω 2006 up to 150 s beyond that time the results follow a logarithmic growth and are closer to the ones from roulund et al 2005 using a classical sediment transport model the two phase flow simulation results are sensitive to the turbulence model this confirms the simulation results of mathieu et al 2019 for the scour around a pipeline using k ε model leads to an overestimation whereas using k ω 2006 model leads to an underestimation of the scour depth however it is important to notice that both the experimental results of roulund et al 2005 and their best numerical prediction using a classical model stahlmann et al 2013 are within the range of the solutions given by the two phase flow model at the downstream side bottom panel of fig 4 the maximum erosion depth predicted by the k ω 2006 model exhibits temporal fluctuations whereas the k ε model results exhibit a smooth curve unlike the upstream side the position of the maximum scour depth downstream of the cylinder is located away from the structure at about 1 to 2 cylinder diameter downstream the fluctuations which are not present in roulund et al 2005 steady state numerical results are most probably due to the eddies shed downstream of the pile this result indicates that the downstream scour is highly influenced by the vortex shedding a result that has already been pointed out in former studies using classical sediments transport models e g zhao et al 2010 stahlmann et al 2013 baykal et al 2015 however if the maximum erosion depth predicted by the k ω 2006 model follow a tendency similar to the experimental results from roulund et al 2005 the erosion rate is underestimated by the two phase flow model this leads to an underestimation of the erosion depth downstream of the pile as for the upstream side the k ε scour depth results are very similar to roulund et al 2005 classical model results no fluctuations are observed meaning that the two phase k ε model fails to reproduce the vortex shedding 4 3 choice of the granular stress and turbulence model the first point that needs to be discussed is the choice of the granular stress model one could argue that the kinetic theory of granular flows jenkins and savage 1983 ding and gidaspow 1990 jenkins and hanes 1998 shall be preferred to predict sediment transport in scour configuration indeed it describes better the intermediate concentration region 0 08 ϕ 0 3 where collisional interactions dominates however the μ i rheology reproduces more accurately the dense granular flow regime 0 3 ϕ 0 6 where frictional interactions dominates for an unidirectional sheet flows case chauchat et al 2017 have demonstrated that the vertical structure of the flow as well as the repartition of the sediment flux is only slightly affected by the choice of the granular stress model furthermore mathieu et al 2019 recently performed a sensitivity analysis to the choice of the granular stress model using the same numerical model for the scour below a pipeline configuration the authors observed almost no sensitivity to the choice of the granular stress model on the erosion depth due to the very high computational cost of the 3d scour simulations this sensitivity analysis is not performed herein unlike classical sediment transport models two phase flow models are process based models and as such shall not be fine tuned on each configuration for the μ i rheology the parameters have been calibrated on unidirectional sediment transport configurations in section 3 the unicity and accuracy of this calibration could be questionned however for sake of consistency it has been decided not to modify these paremeters in the 3d simulations in classical sediment transport models the sediment transport fluxes are based on emprirical formula obtained under the assumptions of unidirectional steady and uniform flows applying these parametrizations to non uniform and unsteady flow conditions raises potential inconsistencies and a sensitivity analysis to some of the empirical constant is usually needed to improve the model predictions e g stahlmann et al 2013 as already pointed out by mathieu et al 2019 for the scour around the pipeline the near bed erosion is probably better described by the k ε model and the lee wake erosion is better predicted by the k ω 2006 model as a matter of fact in the vertical cylinder configuration the k ω 2006 turbulence model is the only one able to reproduce the vortex shedding downstream of the cylinder and to account for the adverse pressure gradient upstream of it roulund et al 2005 therefore in the following all the results presented are obtained with the k ω 2006 turbulence model 5 analysis of the sediment fluxes 5 1 upstream and around the pile in the case of a flow around a structure the assumption of uniform flow condition is not verified it has been shown in section 3 that the two phase flow model predicts a power law for the relationship between the sediments transport flux and the shields parameter under uniform and steady flow conditions in section 4 2 it has been further demonstrated that the two phase flow model is able to predict reasonably well the bed morphological evolution at the early stages of the scour process in this section the numerical results are further analyzed to investigate the perturbation induced by the pile on sediment transport and how much it differs from the results obtained under steady and uniform flow conditions fig 5a shows the local slope angle β at t 10 s it is determined from the magnitude of the horizontal gradient of the bed elevation 46 β arctan h z b e d where h z b e d z b e d x 2 z b e d y 2 and z b e d z ϕ 0 57 far from the obstacle the bed is almost flat but closer to the cylinder there is a semi circular area where the slope is gently increasing toward the cylinder the upstream distance to the center of the cylinder is defined as ru it is equal to x on the x axis at the upstream side of the cylinder ru d 0 7 an important variation of the bed slope angle is visible β varies between β 30 and β 45 exceeding the angle of repose β r 32 in this region avalanches occur and the sediment flux is predominately driven by gravitational acceleration closer to the cylinder 0 6 ru d 0 5 the slope angle is decreasing and the sediment bed is nearly flat just downstream of the cylinder up to x d 1 the bed slope angle is more noisy and it is hard to distinguish any slope tendency further downstream x d 1 the bed variations are very small and β remains below 10 fig 5c shows the instantaneous dimensionless depth integrated sediment flux calculated by the two dimensional extension of eq 38 the sediment flux starts to increase where the bed slope angle is increasing and it peaks around ru d 0 7 closer to the cylinder where the scour hole is the deepest and the bed is almost flat the sediment flux becomes very small the maximum of the sediment flux is located in the two hsv legs around the cylinder this result indicates that there is an important transverse flux driven by the hsv legs around the cylinder this is in agreement with the description of link et al 2012 the maximum dimensionless sediments flux within these two legs is q max 7 9 downstream of the cylinder the sediment flux is weak probably because the vortex shedding is not fully developed at this early stage t 10 s the patch of sediment flux appears to be due to a vortex shed from the cylinder passing by fig 5b shows the spatial distribution of the shields number its magnitude is slightly increasing with the slope in the scour hole and reaches its maximum at the sides of the cylinder where the shields number values correspond to sheet flow regime θ 0 3 i e for γ 65 120 γ is the angle measured with respect to the upstream x axis downstream of the pile a high shields number area is located around x d 1 and y d 0 25 exactly where an increase of sediments transport was observed in fig 5c here the local bed shear stress has a swirl structure confirming that it is generated by a vortex shed from the cylinder fig 5d shows the dimensionless sediments flux estimated using the power law deduced from unidirectional simulations presented in section 3 47 q a θ θ c s b with a 26 14 and b 2 09 i e using bottom shear stress evaluated at vertical elevation where ϕ 0 0 08 the critical shields number θcs is defined as a function of the local bed slope and orientation the formulation used in the present work is same as in roulund et al 2005 the flow velocity at the particle position and the steepest slope orientation with respect to the flow are used to adjust the critical shields number 48 θ c s θ c cos β 1 sin 2 α tan 2 β μ s 2 cos α sin β μ s where θ c 0 047 is the critical shields number for a flat bed β m i n β β r and α is the angle between the near bed velocity and the direction of maximum slope 49 α arccos h z bed u s ϕ 0 h z bed u s ϕ 0 in which us ϕ is the sediment velocity at the iso concentration ϕ 0 08 this concentration being the best compromise in term of bed shear stress estimation nagel 2018 eq 48 has been slightly modified from roulund et al 2005 definition the original definition provides non physical values for slope angles above the angle of repose β r 32 in classical sediment transport models an avalanche module is required to prevent the bed slope to exceed the angle of repose in the two phase flow model the bed slope is free to exceed that critical value while the solution of the momentum balance will predict a physical description for the avalanching process e g bagnold profile for dry granular flows andreotti et al 2013 the dimensionless sediment flux obtained using eq 47 is locally correlated to the bed shear stress or the shields number as expected the dimensionless sediment flux shown in fig 5d and the shields number shown in fig 5b present the same spatial patterns they increase in the upstream part of the scour hole reach a maximum value for γ 65 120 but are low for γ 0 45 and close to the cylinder due to vortex shedding the instantaneous flow pattern shown in fig 5 is asymmetric the spatial correlation between depth integrated sediments flux as predicted by the two phase flow model fig 5c and by the empirical classical power law given by eq 47 fig 5d is rather poor indeed for γ 0 65 and more particularly around the steep slope upstream the cylinder the important sediment flux observed in fig 5c is not observed in fig 5d this result suggests that in this region sediment transport is not driven by the local fluid bed shear stress but rather by the bed slope the second and third columns of fig 5 show the same quantities for t 60 s and t 150 s respectively the bed slope variations are very similar between t 60 and t 150 s in fig 5e and i the slope angle increases toward the cylinder exceeding the angle of repose between ru d 0 7 and ru d 0 6 the slope starts to be important further upstream at t 150 s this is in good agreement with the upstream extension of the scour hole as time increases between ru d 0 7 and the pile for γ 0 45 the shields number fig 5f and j is below its undisturbed value of 0 19 this is due to the presence of the cylinder which generates the down flow this leads to a reduction of the shields number in front of the cylinder the maximum shields number is located downstream of the cylinder and at the cylinder sides for γ 65 145 where it is decreasing in time downstream of the pile due to the vortex shedding the shields number is important in a narrow channel approximatively aligned with the x axis at t 60 s and t 150 s the depth integrated dimensionless sediments flux obtained directly from the velocity and concentration fields see fig 5g and k have similarities to the one at t 10 s far upstream of the cylinder the sediment flux increases slightly with the increasing bed slope angle around the main slope variation ru d 0 7 the flux drastically increases and remains at a high level q 4 5 where the bed angle exceeds the angle of repose excluding the area just downstream of the cylinder the maximum of the sediment flux is located in the two legs around the cylinder however compared with t 10 s the hsv legs are wider and the maximum sediment flux is slightly decreasing in time q max 7 1 at t 60 s and q max 6 6 at t 150 s the transverse flux driven by the hsv legs around the cylinder seems thus to decrease in time this result is coherent with the fact that the erosion rate is higher at the beginning of the scour process see fig 4 as for t 10 s important differences are observed between the two phase flow sediment flux and the empirical formula fig 5h and i a better understanding of the sediment transport in the cylinder vicinity can be obtained by investigating the vertical structure of the flow fig 6 shows the vertical profiles of the mixture velocity u the sediments concentration ϕ and the dimensionless sediments flux π ϕ u s 2 v s 2 w s 2 s 1 g d 3 for t 10 s in blue t 60 s in magenta and t 150 s in red the location of each profile is given in fig 5c at the upstream slope of the scour hole white circle and in the hsv legs squared symbol the horizontal dotted lines represent the vertical elevation where the sediments concentration is ϕ 0 08 allowing to distinguish between bedload and suspended load the vertical profile upstream of the pile is located where the bed slope angle is approximatively of 25 at t 10 s and above the critical angle β 32 for t 60 s and t 150 s the profiles have a similar shape the velocity is positive i e downstream oriented just above the bed this results in a strong downstream oriented bedload sediment flux above this dense transport layer the mixture velocity becomes negative over more than 5 mm in height for t 10 s and 1cm for t 60 and t 150 s the concentration in that region is lower than 0 08 meaning that sediments are transported upstream as suspension further away from the bed the mixture velocity is positive again but the sediments concentration is so low that the associated sediment flux is negligible in the hsv legs bottom panels of fig 6 the mixture velocity is positive over the entire water depth and the concentration profile is smoother at the bed interface as a result there is a positive sediments flux at that location the peak of sediment flux is located below the vertical position of concentration ϕ 0 08 meaning that bedload dominates nonetheless an important positive contribution from suspended load is also observed at all times in order to better explain the observations obtained from the vertical profiles fig 7 shows a vertical plan view in the plane of symmetry upstream of the pile the velocity vectors and the dimensionless sediments flux π are presented at the same instants 10 s 60 s and 150 s the sediment iso concentration contours ϕ 0 57 and ϕ 0 08 are also plotted in all figures to represent the bedload layer the angle of repose β r 32 is materialized as the red dashed line the vertical magenta dashed line represents the position x d 0 7 of the upstream vertical profile shown in fig 6 by examining the bed evolution and the velocity field it can be concluded that the downward flow in front of the pile acts as a vertical jet impinging the sediment bed this downflow will ultimately be involved in the generation an hsv and both features will lead to sediment erosion as the scour hole deepens in time the bed slope upstream the pile increases and reaches values higher than the angle of repose β 32 a competition between the local bed shear stress resulting from the fluid flow above the sediments bed and the downslope gravitational acceleration is taking place in the scour hole at the upstream part of the scour hole the slope is mild and the velocity vectors are aligned with the sediments flux fig 7 up to x d 1 closer to the cylinder in the suspended load layer sediments are transported upstream by the hsv while in the bedload layer sediments are transported downstream by gravity this result could be corroborated to experimental observation from link 2018 who measured intermittent avalanches in the scour hole link et al 2008 2012 further observed several slope breaks in their experiments that are probably related to the existence of multiple vortices in the hsv as mentioned by dargahi 1990 in the present simulation the velocity vectors allows to identify a single vortex in the hsv its position does not evolve in time and corresponds to the point at which the slope becomes steeper than the angle of repose in the region between the hsv and the pile the slope is steeper than the angle of repose meanwhile the velocity vectors and therefore the fluid bed shear stress are in the opposite direction the downslope gravity flow and the bed shear stress are counteracting each other but as the angle of repose is exceeded the downslope gravity flow dominates and the net sediment flux is positive downslope the observations presented in the plane of symmetry upstream of the pile are in good agreement with the two dimensional depth integrated results showed previously the importance of both the slope and the avalanche phenomenon on the sediments transport is confirmed 5 2 downstream of the pile downstream of the cylinder and for t 60 s the sediment flux predicted by the two phase flow model are very significant see fig 5g and fig 5k the strongest fluxes are located up to 1 5 diameter downstream of the pile fig 8 shows the same quantities as fig 6 but at two locations downstream of the pile the first profile is located in the recirculation cell x d 0 75 y d 0 star symbol just downstream of the pile the mixture velocity shows negative values of up to u 0 35m s 1 for the entire vertical profile shown and the concentration is non negligible ϕ 10 3 in the water column as a consequence there is a negative suspended sediment flux at all times although this upstream flux is small at early stage t 10 s it increase significantly at later stages t 60 s and 150 s as sediment concentration increases further downstream x d 1 75 y d 0 diamond symbol the observations are different for t 10 s the velocity are negative and the flux is much larger than that closer to the cylinder due to higher suspended sediment concentration it generates a more important suspended sediments flux toward the cylinder for t 60 and 150 s the velocity are positive and the sediments are transported downstream by the vortices as bedload and suspended load the present results illustrate the complexity of the instantaneous sediment transport downstream of the pile the sediment concentration profiles at the back of the cylinder drops rapidly away from the bed and suspended load generally dominates bedload this was already pointed out by baykal et al 2015 6 discussion in section 5 the role of the local bed slope on sediment transport in the scour hole has been clearly identified in classical models the downslope contribution is accounted for as a modification of the critical shields number in the bed load flux formula see eq 25 of roulund et al 2005 for instance this correction is only valid at very low bed slopes and it does not represent the avalanching process when the bed slope exceeds the angle of repose an iterative algorithm based on the sediment mass conservation is used to instantaneously limit the bed slope at the angle of repose this model neglects the avalanche dynamics and the associated relaxation time scale in the present two phase flow model the avalanche dynamics is implicitly accounted for by using the dense granular flow rheology for the sediment phase interestingly the numerical solution shows that the bed slope can locally exceed the angle of repose in the scour hole very near the pile this is due to the competition between the fluid bed shear stress associated with the up slope flow generated by the hsv and the downslope sediment flow this can not be predicted by classical single phase flow sediment transport models and illustrates the need for a new modeling approach for this phenomenon in engineering models it is possible to use the present two phase flow model results to infer the local relationship between the sediment fluxes the local fluid bed shear stress and the local bed slope in the scour configuration fig 9 a shows the computed depth integrated dimensionless sediment flux q as a function of the shields parameter along the plane of symmetry γ 0 the local sediment flux and shields parameter are averaged over 10 s of dynamics around time t 60 s the results are compared with the fit given by eq 42 obtained with the same two phase flow model under unidirectional and uniform flow conditions red line see section 3 the two red dashed line represents 100 error with respect to the best fit such confidence interval is considered as reasonable for steady and uniform flow conditions gomez and church 1989 the dimensionless sediment flux values are colored by their spatial distance from the inlet the empty black symbols represent reference points to facilitate the interpretation at the inlet dark blue dots cross symbol where the flow is not influenced by the presence of the pile the value of the local shields number and the dimensionless sediment flux are very close to the uniform flow case θ 0 19 moving downstream x d 2 5 upward triangle symbol both the dimensionless sediment flux and the shields parameter are decreasing due to the adverse pressure gradient generated by the presence of the cylinder despite the fact that the values present a small scatter they remain within a factor two confidence intervals with respect to the uniform and steady flow best fit when getting closer to the cylinder x d 1 5 downward triangle symbol the sediment flux and the shields number slightly increase and are very close to the unidirectional steady flow case this can probably be explained by the increase of the local bed slope see fig 7 and will be discussed later very close to the cylinder x d 1 5 0 7 circle symbol the sediment flux increases drastically by one order of magnitude while the shields number drops to almost zero this is the region where the avalanching occurs the dimensionless sediment flux strongly deviates from the uniform and steady solution the sediment flux is not related to the fluid bed shear stress most probably because of the strong downslope gravitational effect and of the avalanching downstream of the pile x d 0 5 1 75 star and losange symbols the dimensionless sediment flux slowly decreases from 10 to 5 while the shields number oscillates between 0 15 to 0 5 in this region the lee wake vortices dominate the hydrodynamics and the sediment flux is not related to the local fluid bed shear stress instead the sediment flux is dominated by the suspended load see fig 8 either due to local pick up of sediments from the bed or to sediments advected from upstream this explains the poor correlation between the sediment flux and the local shields number as well as the deviation from the best fit further downstream x d 3 from orange to red dots hexagonal symbol the dimensionless sediment flux and the shields parameter decrease due to the weakening of the lee wake vortices the sediment flux become closer to the best fit factor 2 error only and the sediment flux correlates again with the local shields number the overestimation of the sediment flux can be explained by the enhanced suspended load observed in fig 8 to summarize at the downstream side of the pile the dimensionless sediment flux deviation from the uniform and steady state case can be explained by the influence of the lee wake vortices and the enhanced suspended load upstream of the pile the deviation from the uniform and steady state case is probably due to the downslope gravitational effect and the avalanching process in order to infer the dependency of the local sediment flux to the bed slope the dimensionless sediment flux along the plane of symmetry is plotted in fig 9b as a function of the local bed slope angle β at t 60 s the results are only presented between x d 2 and the upstream edge of the pile and are colored with the same colobar as the one used in fig 9a the two phase flow model results exhibit a linear dependency on the bed slope for β 23 as highlighted by the magenta line a simple linear function of the bed slope angle reproduces fairly well the numerical results q β for β 5 25 the good collapse of the sediment flux with the bed slope and the poor correlation of the sediment flux with the bed shear stress fig 9a demonstrate that the sediment flux in the region just upstream of the pile is dominated by the gravity rather than by the bed shear stress for β 23 the sediment flux predicted by the two phase flow model non linearly increases with the bed slope angle before reaching a maximum value at β 35 the local bed slope is on the order or higher than the static friction angle of the μ i rheology meaning that avalanches is taking place this numerical result is supported by experimental observation from link 2018 and further confirms that the μ i rheology is probably the best choice for the granular stress model as it is more accurate to predict avalanches above this angle the sediment flux decreases drastically with the bed slope angle up to β 45 in this region avalanches occurs but sediments are also transported perpendicular to the symmetry plane by the hsv very close to the pile both the sediment flux and the bed slope angle tend toward zero the results presented above show that a competition between fluid bed shear stress driven and gravity driven sediment transport occurs at bed angles lower than the angle of repose β 23 the relationship between the sediment flux and the bed slope is linear below this value above this angle the sediment flux increases nonlinearly with the bed slope while the shields number vanishes showing that the sediment flux only result from the action of gravity this changes the vision of the problem and opens new perspectives on modeling the avalanching effect in sediment transport models 7 summary and conclusion in this paper the first three dimensional eulerian eulerian two phase flow simulation of scour around a cylinder has been presented the model has been firstly validated against existing experimental data for the hydrodynamics and the morphodynamics the relationship between the dimensionless sediment transport flux and the shields number for uniform and steady flow configuration using the two phase flow approach has been established to serve as a reference to analyze the 3d effects in the scour simulation the best fit of a power law of the excess shields number results shows very good agreement with the literature for shields numbers as low as 0 1 these results further demonstrate the capabilities of the two phase flow approach to deal with sediment transport over a wide range of sediment transport regimes from bed load to sheet flows a new methodology to determine the bed shear stress in complex flow configurations is proposed the mixture shear stress computed at the elevation of the iso concentration ϕ 0 0 08 corresponding to top of the bedload layer is used to define the local shields number in non uniform unsteady flow configurations concerning the three dimensional scour simulation the good agreement obtained between the numerical results and the available measurements demonstrates the applicability of two phase flow models to complex sediment transport problems such as scour the temporal evolution of both bed morphology and erosion depth is almost quantitatively reproduced this allows us to further analyze the numerical results in terms of local correlation between sediment flux local bed shear stress and local bed slope upstream of the pile the dimensionless flux deviation from the transport law under uniform and steady flows is within a factor two except in the scour hole where it deviates by almost one order of magnitude in this region the sediment flux results from a competition between the fluid bed shear stress and the downslope gravity effect close to the cylinder the sediment flux is fully correlated with the local bed slope demonstrating that avalanching is dominating according to our numerical results in the major part the scour hole the sediment flux is not correlated with the bed shear stress only the empirical laws on which the classical sediment transport models are build are therefore not accurate the numerical simulation shows that the downslope gravitational effect becomes very significant at a rather low bed slope angle with a linear dependency of the sediment flux to the bed slope angle below β 23 and a nonlinear dependency above this value these results change the vision of the problem and provides new perspectives on modeling the effect of the bed slope and the avalanching process further work is needed to propose new parameterizations that reproduce more accurately the influence of the bed slope concerning the downstream side of the pile the two phase flow results suggests that suspended load is dominant in both the hsv legs and the lee wake vortices this result is consistent with previous work on this topic using single phase flow model stahlmann et al 2013 baykal et al 2015 the main limitation of the two phase flow model for scour modeling stand probably within the urans approach the present k ω 2006 turbulence model could be improved following mathieu et al 2019 recommendations in order to more accurately predict the erosion and the morphodynamics where the interactions between the fluid vortices and the sediment bed are important improving the particle presence feedback on the turbulence in the near bed region seems to be the key to improve results however this is a very fundamental problem in fluid mechanics and in multiphase flows that even in the simplest configurations i e homogeneous isotropic turbulence is not fully understood the present work illustrates the capability and limits of the state of the art parametrization for eulerian eulerian model this point clearly deserves future investigation but we strongly believe that the 3d scour configuration is not the most appropriate partly due to the complexity of the flow hydrodynamics and partly due to the lack of experimental data moreover the urans approach is unable to accurately reproduce the actual dynamics of the hsv such as the bimodal oscillation or the existence of multiple vortices in the lee wake the urans approach is certainly not perfect to predict accurately the vortex shedding and the interaction between these vortices and the sediment dynamics the natural extension of the present work would be to perform two phase flow large eddy simulation les of this problem this approach has been recently applied to unidirectional sheet flows by cheng et al 2018 and the application to 3d scour will be carried out in future work credit authorship contribution statement tim nagel methodology software validation writing original draft writing review editing julien chauchat methodology software validation funding acquisition project administration supervision writing original draft writing review editing cyrille bonamy methodology software validation writing original draft writing review editing xiaofeng liu writing original draft writing review editing zhen cheng writing original draft writing review editing tian jian hsu writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment we would like to thank oscar link for the helpful discussions this work was supported by the french national programme ec2co lefe modsed the authors would also like to acknowledge the financial support from the région rhône alpes through the cmira coopera project and the explorapro grant of j chauchat this research was partially funded by the anr segsed project anr 16 ce01 0005 03 most of the computations presented in this paper were performed using the froggy platform of the ciment infrastructure https ciment ujf grenoble fr which is supported by the rhône alpes region grant cper07 13 cira and the equip meso project reference anr 10 eqpx 29 01 of the programme investissements d avenir supervised by the agence nationale pour la recherche and the genci infrastructure under the allocations dari x2015012153 x2016017567 a0020107567 a0040107567 and a0060107567 z cheng and t j hsu are supported by nsf of usa oce 1635151 we are grateful to the developers involved in openfoam who are the foundation of the model presented in this paper appendix a hydrodynamic validation of the flow around a vertical cylinder mounted on a flat bed hydrodynamic setup computational mesh boundary conditions the numerical domain used for the hydrodynamic validation is a three dimensional box with a stream wise length lx 12d a span wise length ly 8d and a height h d where d 53 6cm is the pile diameter this is the same configuration than the rigid bed rb case presented in roulund et al 2005 the reynolds number based on the pile diameter is r e d u d ν f 1 7 105 where the mean flow velocity is u 0 326 m s 1 the computational domain is discretized using a unstructured mesh refined around the cylinder and at the bottom boundary the mesh refinement area around the cylinder is axisymmetric the mesh characteristics are given in table 6 the boundary conditions are identical to the ones used by roulund et al 2005 i at the inlet profiles obtained from a unidirectional vertical simulation driven by a pressure gradient are imposed for uf k and ω whereas zero transverse velocities are prescribed ii at the outlet zero gradient conditions neumann conditions n 0 are specified for all quantities except for the reduced pressure for which a homogeneous dirichlet boundary condition is imposed p 0 for the velocities a homogeneous neumann boundary condition is used when the velocity vector points outside of the domain at the outlet and a homogeneous dirichlet boundary condition u f 0 is used otherwise iii at the top surface of the computational domain neumann conditions are applied for k and ω and for the three components of the velocity as in roulund et al 2005 work the model does not have a free surface iv on the sides cyclic conditions are used v at the walls bottom and cylinder zero velocity no slip is imposed for the three components consistently with the small non dimensional distance to the wall z z u ν f 5 a very small turbulent kinetic energy is specified for k o 10 6 m2 s 2 the conditions for ω are specified using a wall function in order to account for the flume bottom roughness a roughness height of ks 2 68 10 3 m is imposed at the bottom wall thanks to the tuned ω wall function described in roulund et al 2005 for the cylinder the classical wall function from openfoam is used omegawallfunction for the initial condition the unidirectional vertical solution used for the inlet is imposed over the entire numerical domain results fig 10 shows a comparison of the rb hydrodynamic results with roulund et al 2005 s experimental and numerical results for longitudinal profiles of stream wise fig 10 left panel and wall normal fig 10 right panel velocities in the plane of symmetry at different elevations from the bed 0 5 cm 1 cm 5 cm and 20 cm the results have been averaged over 10 vortex shedding periods corresponding to approximatively 60 s of dynamics the flow upstream of the pile is in good agreement with roulund et al 2005 experimental data the hsv defined as the area in front of the cylinder where the longitudinal velocities are negative is very well captured see fig 10 left panel at 0 5 and 1 cm height downstream the pile the change of sign in the velocities shows that there is a counterclockwise recirculation cell this cell has the correct size compared with experimental data the counterclockwise recirculation cell was not reproduced by roulund et al 2005 steady numerical simulations see fig 10 right panel which confirms the importance of unsteady flow simulations for this configuration stahlmann et al 2013 baykal et al 2015 it must be pointed out that a shift is observed for the wall normal velocities downstream of the pile at 20 cm in the water layer compared with roulund et al 2005 experimental results this is probably due to rigid lid effects and accounting for the free surface could improve the accuracy of the results as shown in zhou 2017 horseshoe vortex fig 11 shows a comparison between the bed shear stress amplification τb τ 0 along the longitudinal axis in the plane of symmetry predicted by the model blue line and roulund et al 2005 experimental and numerical results the bed shear stress amplification is computed as the ratio between the local bed shear stress and its value at the inlet where the flow is undisturbed by the cylinder presence the local bed shear stress τb is computed as 50 τ b τ x z f 2 τ y z f 2 s i g n τ x z f where τ x z f and τ y z f are the components of the fluid shear stress tensor τf at the bottom in fig 11 the zero crossing of the bed shear stress amplification in front of the pile between x d 1 and x d 0 5 shows the location of the hsv the two phase flow model results are in very good agreement with roulund et al 2005 results outside of the hsv region x d 1 however inside the hsv region the negative bed shear stress amplification is underestimated the difference with amplification found in roulund et al 2005 experimental work is about 25 this is slightly improved compared with the findings of roulund et al 2005 and baykal et al 2015 s numerical work were the difference was more than 30 as mentioned in roulund et al 2005 and baykal et al 2015 no clear explanation can be provided for these discrepancies between experimental observations and numerical predictions lee wake vortices the regime of the lee wake vortices generated downstream of a vertical cylinder in a unidirectional flow depends on the pile reynolds number of the flow here red 1 7 105 the flow is in the so called subcritical regime the wake flow is expected to be completely turbulent with vortices shed alternatively at each side of the pile sumer et al 2006 fig 12 shows the bed shear stress vectors and the contour lines of the magnitude of the bed shear stress amplification over one period of vortex shedding at the bottom of the rb case the magnitude of the bed shear stress is calculated as τ τ x z f 2 τ y z f 2 the position of the maximum bed shear stress in the cylinder vicinity can be found around γ 65 where γ is the angle measured with respect to the upstream x axis in roulund et al 2005 and baykal et al 2015 the magnitude of the bed shear stress amplification is compared with the experiments of hjorth 1975 where the pile reynolds number is r e d 1 5 10 4 i e one order of magnitude lower than the present configuration despite the diffence in term of reynolds number it is shown in figure 17 of roulund et al 2005 and in fig 3 of baykal et al 2015 that their numerical simulations also predict the maximum bed shear stress around γ 65 the discrepancies between the numerical prediction and the experimental observation of hjorth 1975 where γ 45 remain unexplained by roulund et al 2005 and baykal et al 2015 again because of the diffence in term of reynolds number between the configurations no definitive comparison can be provided in term of bed shear stress amplification but the order of magnitude found with sedfoam is similar to what is reported in hjorth 1975 configuration max τ τ 0 9 fig 12 also shows the unsteady behavior of the flow downstream of the cylinder in the four panels snapshots during a vortex shedding period t are shown the generation of two vortices at the opposite sides of the pile one at t 0 t fig 12 top left panel and the other at t t t 2 is clearly visible here the vortex shedding period is approximatively 6 s although higher than the theoretical strouhal value str 0 2 the present strouhal number str 0 27 is in good agreement with the one reported in baykal et al 2015 discussion on rigid bed hydrodynamics the detailed study of the hydrodynamics around the cylinder such as the hsv and the lee wake vortices demonstrates the good behavior of the proposed model to reproduce the flow around a vertical cylinder in a unidirectional current without sediments the rigid lid assumption might be questionable as all experiments have been carried out in open channels indeed constraining the domain height could be an over simplification of the problem it is usually accepted that when the froude number is lower than about 0 2 the free surface deformation near the structure is negligible roulund et al 2005 even in this limit the rigid lid treatment is only an approximation in the results presented above the shift of the wall normal velocities downstream of the pile near the free surface compared with roulund et al 2005 experimental data can be attributed to the fact that the free surface deformation is not accounted for this has been shown by zhou 2017 who performed rigid lid and free surface computations of roulund et al 2005 configuration however at the upstream side of the pile in the region where the hsv is generated and the scour occurs the rigid lid approximation has almost no influence on the numerical results it is therefore reasonable to use this approximation to perform 3d scour simulation using the two phase flow model 
505,in this contribution a three dimensional sediment scour model based on the two phase flow eulerian eulerian solver sedfoam is developed within the framework of the open source platform openfoam the adoption of the eulerian approach for both fluid and sediment makes the model suitable for simulating scour process around structures with arbitrary geometry the model is first validated with unidirectional sediment transport configurations without structures to ensure that it can capture both flow and sediment transport processes the validation cases show that the model can accurately simulate the sediment transport rate and bedload layer thickness as a function of the shields number over a wide range of flow condition and sediment properties then the model is applied to simulate the live bed scour process around a vertical pile due to unidirectional current it is a first attempt to use a two phase model for simulating such case and its success serves as a proof of concept for future development simulated results of flow sediment transport and scour processes are compared with experiments and good agreement is observed a new methodology to determine the bed shear stress in complex flow configurations is proposed the mixture shear stress computed at the elevation of the iso concentration ϕ 0 0 08 corresponding to top of the bedload layer is used to define the local shields number within the scour hole a competition between fluid bed shear stress driven and gravity driven sediment transport occurs at bed angles up to β 23 this is lower than the repose angle β r 32 the relationship between the sediment flux and the bed slope is linear below β 23 above this angle the sediment flux increases nonlinearly with the bed slope while the shields number tends to 0 this shows that in the part of the scour hole close to the vertical cylinder the sediment flux only result from the action of gravity avalanching is the dominant transport mechanism and conventional power law become ineffective even with slope correction in the lee side of the cylinder suspended load dominant and the power law assuming a local equilibrium between bottom shear stress and transport flux is no longer valid further discussion is made on the computational cost of the proposed model and future research directions keywords two phase flow scour numerical modeling 1 introduction numerical simulation of scour is a very difficult task due to several scientific and technical obstacles first sediment transport is an extremely complex phenomena involving many physical processes e g particle particle fluid particle and turbulence particle interactions for which existing models exhibit limited predictive capability an factor two error in sediment fluxes is often considered reasonable for steady and uniform flow conditions gomez and church 1989 when the fluid flow is three dimensional unsteady and non uniform such as in the scour configuration existing models for sediment fluxes are questionable because they assume a local equilibrium between the bottom shear stress ans the sediment transport flux second when scour occurs the fluid flow is almost always turbulent and the flow dynamics is complex with turbulent structures such as the horse shoe vortex hsv system upstream or vortex shedding downstream of an obstacle even though turbulence modeling has made significant progress over the last decades this remains one of the major unsolved problems in fluid dynamics from a technical point of view scour is a rather large scale problem for high resolution numerical simulation the domain size has to be large enough to capture the vortex shedding correctly and the erosion process takes place at long time scale which makes the simulations very challenging the third technical difficulty is that the scour process involves a dynamically changing interface i e the bed and its interaction with the stationary structure for structures with complex geometry the dynamic intersection of the bed surface and the structure is extremely difficult to capture there are several techniques to deal with the problem for example the arbitrary lagrangian eulerian approach ale also termed the moving mesh method the eulerian approach and the immersed boundary method the method introduced in this paper belongs to the eulerian approach where water and sediment are treated with a two phase flow model the development and application of scour models have also been hindered by the excessive computational resources required for such simulations in the literature most of the scour models use what is denoted here as the classical approach where they couple the hydrodynamics solving the navier stokes equations and the bed morphodynamics solving the exner s equation exner 1920 1925 such coupling approach can be best demonstrated by the work of roulund et al 2005 in their model the bottom stress was first calculated based on the simulated flow field then the bottom shear was used to calculate the sediment transport rate which was consequently used in the exner equation for updating the new bed position with this approach roulund et al 2005 show that the agreement between the numerical predictions and the experimental observations is good in both transient and equilibrium states the numerical simulations presented in roulund et al 2005 are often considered as a reference case in many posterior studies stahlmann et al 2013 baykal et al 2015 these cases are also considered in this work the classical approach for scour modeling used in roulund et al 2005 or baykal et al 2015 is based on empirical sediment transport formulas developed for steady and uniform flow conditions meyer peter and müller 1948 engelund and fredsøe 1976 in the presence of an obstacle such as a bridge pier the flow is highly unsteady non uniform and the bed slope can reach values near the angle of repose as a result most formulas are used beyond their validity range when applied to three dimensional scour around structures furthermore to avoid the slope angle in scour hole to be greater than the angle of repose ad hoc avalanche models are always applied which essentially redistribute sediment mass by a smoothing scheme most of these avalanche models have very little physical bases and more studies are warranted in the simple configuration of a single pile the performance of classical models are satisfactory roulund et al 2005 stahlmann et al 2013 baykal et al 2015 however to design civil engineering structures the conventional sediment transport models are not comprehensive enough therefore engineers are still mainly relying on small scale physical models to overcome the limitations of classical models for scour two phase flow models have been developed over the last decade amoudry et al 2008 cheng et al 2017 mathieu et al 2019 in this new framework the sediment phase can be either modeled as discrete particles termed the eulerian lagrangian approach or as a continuous phase termed the eulerian eulerian approach in both approaches the fluid phase is always seen as a continuum in the lagrangian approach a dynamical equation is solved for each individual particle and its interactions with neighboring particles e g escauriaza and sotiropoulos 2011 the computational resources required by this approach are too expensive at present for engineering applications nevertheless some aspects of scour can be studied using the lagrangian approach for example link et al 2012 used the model of escauriaza and sotiropoulos 2011 with 10 000 particles to investigate the sediment transport capacity by the horseshoe vortex in a non erodible scour hole in their approach the particles were considered as point particles and the fluid flow around them was not explicitly solved in the eulerian approach for the sediment phase sediment is treated as a complex fluid with a peculiar rheology interacting with water through buoyancy and drag forces such model has been applied with some success to various configurations ranging from sheet flow jenkins and hanes 1998 hsu et al 2004 cheng et al 2017 chauchat 2018 to 2d scour configurations downstream of an apron amoudry and liu 2009 cheng et al 2017 chauchat et al 2017 and scour under a pipeline lee et al 2016 mathieu et al 2019 in this paper we present the first three dimensional eulerian eulerian two phase flow simulation of the 3d scour around a vertical cylinder the first objective of the present work is to provide the proof of concept that the two phase flow approach can be used for modeling the scour phenomenon the main advantage of such approach is that it can intrisically deal with complex structures and does not rely on any empirical sediment transport formula or avalanching model the second objective is to evaluate the assumption of a local correlation between the sediment transport flux and the fluid bed shear stress in order to evaluate the main assumptions routinely used by conventional scour models the paper is organized as follows in section 2 the mathematical formulation of the eulerian eulerian two phase flow model is presented in section 3 the model is calibrated first with a steady uniform and unidirectional sediment transport configuration with medium sand in section appendix a the hydrodynamic validation of the flow around a vertical cylinder mounted on a flat non erodible bed is undertaken in section 4 the results of the three dimensional scour simulation are presented with a validation against experimental data an in depth discussion on the sediment transport around the pile is provided in section 6 at the end a summary of findings is given and some future directions are discussed 2 mathematical model the mathematical formulation of the eulerian eulerian two phase flow model has been detailed in chauchat et al 2017 the model is obtained by averaging the local and instantaneous mass and momentum conservation equations over fluid and dispersed particles e g hsu et al 2004 the resulting system of governing equations can be considered as the fundamental equations for two phase flow system similar to the navier stokes equations for single phase clear fluid system when applying these equations to turbulent flow additional turbulence averaging or filtering has to be used in the present model the turbulence averaged eulerian two phase flow equations described in chauchat et al 2017 are used and a new closure is developed 2 1 two phase flow model equations for incompressible fluid the mass conservation equations for the particle phase and fluid phase are written as 1 ϕ t ϕ u i s x i 0 2 1 ϕ t 1 ϕ u i f x i 0 where ϕ and 1 ϕ are the particle and fluid volume fractions u i s u i f are the sediment and fluid phase velocities and i 1 2 3 represents streamwise spanwise and vertical component respectively following chauchat et al 2017 the momentum equations for fluid and particle phases can be written as 3 ρ s ϕ u i s t ρ s ϕ u i s u j s x j ϕ p x i ϕ f i p s x i τ i j s x j ϕ ρ s g i ϕ 1 ϕ k u i f u i s 1 s c 1 ϕ k ν t f ϕ x i 4 ρ f 1 ϕ u i f t ρ f 1 ϕ u i f u j f x j 1 ϕ p x i 1 ϕ f i τ i j f x j 1 ϕ ρ f g i ϕ 1 ϕ k u i f u i s 1 s c 1 ϕ k ν t f ϕ x i where ρs ρf are the particle and the fluid density respectively gi is the gravitational acceleration and p is the fluid pressure fi is the external force that drives the flow the fluid stress τ i j f includes fluid grain scale viscous stress and fluid reynolds stresses p s τ i j s are particle normal stress and shear stress the last two terms on the right hand side rhs of eqs 3 and 4 are momentum coupling between the fluid phase and particle phase through drag force where k is the drag parameter the second to the last term represents averaged drag force due to mean relative velocity between fluid and particle phases while the last term represents the fluid turbulent suspension term also called drift velocity deutsch and simonin 1991 finally ν t f is the turbulent viscosity that has to be calculated using a turbulence closure and sc is the schmidt number the drag parameter k is modeled following schiller and naumann 1933 5 k 0 75 c d ρ f d u f u s 1 ϕ h e x p where d is the particle diameter and uk the velocity vector of the phase k the hindrance function 1 ϕ h e x p represents the drag increase when the particle volume fraction increases h e x p 2 65 is the hindrance exponent that depends on the particulate reynolds number here following chauchat et al 2017 its value is constant the drag coefficient cd is calculated as 6 c d 24 r e p 1 0 15 r e p 0 687 r e p 1000 0 44 r e p 1000 in which the particulate reynolds number rep is defined as r e p 1 ϕ u f u s d ν f where νf represents the fluid kinematic viscosity 2 2 fluid phase shear stress due to the fact that the present model equations are obtained by averaging over turbulence the fluid stresses consist in a fluid phase component r i j f i e fluid phase reynolds stress and a grain scale stress r i j f including the viscous stress and an additional effect due to fluid particle interaction at the grain scale the total fluid stress is written as 7 τ i j f r i j f r i j f 8 r i j f ρ f 1 ϕ 2 ν t f s i j f 2 3 k δ i j 9 r i j f 2 ρ f 1 ϕ ν m i x s i j f where ν t f is the eddy viscosity k is the turbulent kinetic energy and νmix is the mixture viscosity defined as a function of the solid volume fraction as proposed by boyer et al 2011 see chauchat et al 2017 for more details s i j f is the deviatoric part of the fluid phase strain rate tensor and is defined as 10 s i j f 1 2 u i f x j u j f x i 1 3 u k f x k δ i j 2 3 turbulence modeling the two phase flow turbulence averaged formulation requires a closure for the eddy viscosity several turbulence models are available in sedfoam including a two phase version of the k ε turbulence model cheng et al 2017 and a two phase version of the k ω turbulence model chauchat et al 2017 however it is known that these turbulence models are not accurate in the case of boundary layer flows with a strong adverse pressure gradient such as the flow around a vertical cylinder and the use of the k ω sst developed by menter 1993 is recommended in roulund et al 2005 it was proven difficult if not impossible to adapt the k ω sst model to two phase flows indeed in this turbulence model blending functions are introduced for some of the model coefficients these blending functions depend on the distance to solid boundaries that is not clearly defined in the presence of a mobile sediment bed recently a reformulated version of the standard k ω has been developed see wilcox 2006 wilcox 2008 and successfully applied to the scour around a cylindrical pile case by baykal et al 2015 this revisited model formulation incorporates a cross diffusion term and a built in stress limiter modification to behave as the sst model its adaptation to a two phase flow version can be done similarly to what is presented in chauchat et al 2017 for the standard k ω turbulence model this new model will be denoted as the two phase k ω 2006 in the present paper first the turbulent kinetic energy tke k is computed from the solution of eq 11 appropriate for sand particles in water hsu et al 2004 yu et al 2010 11 k t u j f k x j r i j f u i f x j c μ k ω x j ν f σ k ν t f k x j 2 k 1 t m f ϕ k ρ f 1 s c 1 ϕ ν t f ϕ x j ρ s ρ f 1 g j the above k equation is similar to the clear fluid k ω 2006 closure the first three terms on the rhs describe respectively production dissipation and diffusion of tke the last two terms on the rhs of eq 11 describe the modification of the classical k transport equation induced by the presence of particules the fifth term on rhs accounts for the sediment damping effect on the carrier flow turbulence through density stratification it can be seen as the buoyancy production dissipation due to sediment induced density stratification kranenburg et al 2014 the fourth term on rhs is a damping term modeling the drag effect of sediment particles on the carrier flow turbulence indeed if their inertia is important enough particles cannot completely follow the turbulent fluid velocity fluctuations in this drag induced damping term the parameter tmf is introduced to characterize the degree of correlation between particles and fluid velocity fluctuations following kranenburg et al 2014 its value varies between 0 and 1 t m f 1 denotes particles following instantaneously the turbulent velocity fluctuations in that case the turbulence damping of the carrier fluid vanishes conversely when t m f 0 the particles velocity fluctuations are uncorrelated to the fluid turbulence and the turbulence damping term is at maximum this situation corresponds to high stokes numbers i e the particle inertia is much higher than the fluid danon et al 1977 and chen and wood 1985 proposed an exponential function for tmf which is also used in cheng et al 2017 12 t m f e b s t where b is an empirical coefficient the degree of correlation between particles and fluid velocity fluctuations can be quantified by the stokes number st benavides and van wachem 2008 13 s t t p t l where t p ρ s 1 ϕ k is the particle response time t l k 6 ε is the characteristic time scale of energetic eddies in the present paper the k ω 2006 and the k ε are used between both models the transport equation for the turbulent energy dissipation rate together as the expression of the turbulent viscosity differ 2 3 1 k ω 2006 model the fluid specific rate of turbulent energy dissipation ω equation reads 14 ω t u j f ω x j c 1 ω ν t f r i j f u i f x j c 2 ω ω 2 x j ν f σ ω ν t f ω x j c d k ω c 3 ω 2 k 1 t m f ϕ ω ρ f c 4 ω 1 s c ω k 1 ϕ ν t f ϕ x j ρ s ρ f 1 g j the different coefficient values can be found in table 1 the coefficients associated with the present two equations closure are adopted from their clear fluid counterpart wilcox 2008 the last two terms on the rhs of eq 14 account for the sediment damping effect on the fluid carrier flow turbulence through drag and density stratification respectively according to the numerical experiments described in chauchat et al 2017 for the two phase k ω turbulence model the coefficient c 3ω is chosen to be 0 35 the coefficient associated with the buoyancy term c 4 ω 0 is used in stably stratified condition while it is set to 1 for unstably stratified condition b is left as the only free model calibration parameter from our experience b can be tuned in the range of 0 1 2 for instance increasing b from 0 25 to 1 25 leads to an increase of the associated sediment flux of approximatively 20 on a simple sheet flow case nagel 2018 all the simulations presented in this paper have been undertaken with the default value b 0 25 the fourth term on the rhs of eq 14 denoted as cdkω is a cross diffusion term 15 c d k ω a σ d ω k x j ω x j where the a coefficient is a smoothing term and σd a coefficient that reads 16 σ d h k x j ω x j σ d 0 where σ d 0 1 8 wilcox 2008 h is the heaviside step function which has a value of unity if the argument is zero or positive and a value of zero if the argument is negative the role of this cross diffusion term is to increase the dissipation of tke in the free shear flow by enhancing the production of specific dissipation ω in that region this will reduce the free shear flow spreading rates sensitivity to the free stream boundary conditions wilcox 2008 however it is important to suppress the cross diffusion term near a solid boundary wilcox 2006 when approaching the wall k and ω are respectively decreasing and increasing in the viscous sublayer the argument of the heaviside step function becomes negative and the cross diffusion term is suppressed the a coefficient is a smoother imposing a gradual transition between the regions where the cross diffusion term is activated or not a is only present in the two phase flow version of the model and allows to avoid instabilities 17 a 1 2 1 tanh 40 ϕ 0 1 the coefficient involved in the dissipation of dissipation term second term on the rhs of eq 14 follows the generalization of the pope correction pope 1988 given by wilcox 2008 18 c 2 ω c 2 ω 0 f c 2 ω where 19 c 2 ω 0 0 0708 f c 2 ω 1 85 χ ω 1 100 χ ω and 20 χ ω ω i j ω j k s k i f c μ ω 3 ω i j 1 2 u i f x j u j f x i the idea of pope 1988 is to introduce the χω parameter to describe the vortex stretching the latter is considered as the main mechanism for energy transfer from large to small eddies note that the pope correction must be turned off for 1d or 2d configurations finally the turbulent eddy viscosity ν t f involved in k equation and ω equation is calculated incorporating a stress limiting term 21 ν t f k ω k m a x ω c l i m 2 s i j f s i j f c μ where c l i m 7 8 wilcox 2008 2 3 2 k ε model for the k ε model the turbulent viscosity ν t f is calculated as 22 ν t f c μ k 2 ε the dissipation rate ε can be expressed in term of the specific dissipation rate ω as ε c μ k ω therefore for the k ε turbulence model the tke equation is similar to eq 11 with the second term on the rhs replaced by ε the transport equation for the dissipation rate ε reads 23 ε t u j f ε x j c 1 ε ε k r i j f ρ f u i f x j x j ν f σ ε ν t f ε x j c 2 ε ε 2 k c 3 ε ε k 2 k 1 t m f ϕ k ρ f c 4 ε 1 s c ε k 1 ϕ ν t f ϕ x j ρ s ρ f 1 g j the values of the empirical coefficients σ ε c 1ε c 2ε c 3ε c 4ε cμ are listed in table 2 the detailled description of the two phase k ε turbulence model can be found in hsu et al 2004 cheng et al 2017 chauchat et al 2017 2 3 3 schmidt number the fluid turbulence also affect the drag force acting on the sediment particles in the model description of chauchat et al 2017 the schmidt number sc present in the two phase flow momentum and turbulent equations eqs 3 4 11 and 14 is a constant however van rijn 1984 based on coleman 1970 experimental data proposed a relationship between the schmidt number and the ratio of the fall velocity w fall0 to the bed friction velocity u the so called suspension number sumer et al 1996 in the present work an original local schmidt number definition for the two phase flow model inspired from jha and bombardelli 2009 is used 24 s c min 1 2 w fall0 u u small 2 1 1 3 where u small 10 10 m s 1 is a regularization parameter that is introduced to avoid singularity 2 4 granular stresses the particle phase stress tensor can be split into the normal and off diagonal components corresponding to the particle pressure p s and the particle shear stress τ i j s respectively as established by johnson and jackson 1987 the particle normal stresses or pressure can be generally classified into two contributions a shear induced or collisional component super script s and a permanent contact component super script ff 25 p s p f f p s where the permanent contact component pff is calculated as 26 p f f 0 ϕ ϕ min f r i c f r ϕ ϕ min f r i c η 0 ϕ max ϕ η 1 ϕ ϕ min f r i c with ϕ min f r i c 0 57 ϕ max 0 635 for spheres fr η 0 and η 1 are empirical coefficients following cheng et al 2017 the values are set to f r 0 05 η 0 3 and η 1 5 the permanent contact component is due to enduring contact in highly concentrated region that are often close to quasi static immobile bed this normal pressure increases rapidly when the sediment concentration is close to maximum packing limit and prevents unphysical sediment concentration in the sediment bed the second term in eq 25 accounts for the shear induced particle normal stress the approach chosen for shear induced particle normal stress and shear stress modelling is the dense granular flow rheology or the so called μ i rheology gdrmidi 2004 forterre and pouliquen 2008 this approach is phenomenological and based on dimensional analysis it has successfully been used by revil baudard and chauchat 2013 and chauchat 2018 to model turbulent sheet flows for instance the total particle phase shear stress reads 27 τ i j s r i j s r i j s in which r i j s represents a reynolds stress like contribution for the solid phase and r i j s is the granular stress contribution coming from particle particle interactions the reynolds stress contribution is modeled according to rusche 2003 using the ct model ct is defined as the ratio of particle rms velocity fluctuations to the fluid rms velocity fluctuations this leads to the following reynolds stress contribution for the particle phase 28 r i j s ρ s ϕ c t 2 ν t f s i j s 2 3 c t 2 k δ i j according to rusche 2003 ct depends on the local value of the particle concentration and varies between 1 and 3 in the present model a value of 1 has been chosen based on comparison with sheet flow cases not shown here but see nagel 2018 the reynolds stress like contribution to the particle phase momentum balance seems to be needed to better predict the suspended load the granular contribution is written as 29 r i j s ν f r s s i j s where s i j s is the deviatoric part of sediment phase strain rate tensor 30 s i j s 1 2 u i s x j u j s x i 2 3 u k s x k δ i j in eq 29 the frictional viscosity ν f r s is defined following chauchat and médale 2014 31 ν f r s min μ i p s ρ s s s 2 d s m a l l 2 1 2 ν max in which ν max is the maximum solid phase viscosity ss is the norm of the shear rate tensor and d s m a l l 10 6 s 1 is a regularization parameter that is introduced to avoid singularity in addition to the viscosity regularization ν f r s is also clipped by ν max for numerical stability the frictional shear viscosity ν f r s allows to relate the total particle phase shear stress to the total particle pressure p s by a dynamic friction coefficient μ jop et al 2006 depending on the dimensionless number i in the present study the regime of the granular flow rheology is in the free fall or grain inertia regime in this regime the friction coefficient depends on the inertial number i u s d ρ s p s according to 32 μ i μ s μ 2 μ s i 0 i 1 with μs the static friction coefficient μ 2 an empirical dynamical coefficient and i 0 an empirical constant of the rheology the shear induced contribution to the particle pressure can be obtained from the dilatancy law ϕ i as proposed by boyer et al 2011 for the viscous regime of the granular flow rheology the adaptation to the inertial regime leads to the expression suggested by maurin et al 2016 33 ϕ i ϕ max 1 b ϕ i where b ϕ 2 3 chauchat 2018 inverting eq 33 and substituting the definition of the inertial number i gives the following expression for the shear induced pressure 34 p s b ϕ ϕ ϕ max ϕ 2 ρ s d s s 2 finally the total particle pressure p s can be calculated by eq 25 2 5 numerical implementation the numerical implementation of the present version of the eulerian two phase flow sediment transport model sedfoam is based on the open source finite volume cfd library called openfoam the numerical implementation is similar that the one described in chauchat et al 2017 the only difference lies in the pressure solver used in the present numerical implementation the pressure solver iterate on the reduced pressure p 35 p p ρ f g h where p is the total pressure and ρfgh is the hydrostatic pressure this way of solving the pressure system is similar to what is done in other validated openfoam solvers such as inter foam deshpande et al 2012 it has also been found that this solver is more stable compared to the one described in chauchat et al 2017 allowing to increase the cfl condition and reducing the computational time 3 unidirectional sediment transport simulations before considering the 3d scour problem the first step is to evaluate the capability of the two phase flow model to reproduce a unidirectional sediment transport the objective of these simulations is to i evaluate the sensitivity of the results to the numerical parameter ν max ii provide a general definition of the fluid bed shear stress valid for complex geometries and iii verify the capability of the two phase flow model to reproduce sediment transport rate formulas and establish a reference for the sediment transport law in undisturbed flow conditions i e far from any obstacle this reference will be used for the evaluation of the sediment transport law modification induced by the presence of the obstacle in section 6 of the paper the cases are two dimensional the flow being restricted to a vertical plane with a dominating streamwise velocity in order to drive the flow an external body force or a stream wise pressure gradient is imposed the water depth h f 0 2 m and the initial sediment layer thickness h s 0 1 m are fixed following the live bed configuration of roulund et al 2005 the sediments are made of medium sand with density ρ s 2650 kg m 3 and mean grain size diameter d 0 26 mm the corresponding fall velocity of an individual grain in quiescent water is w f a l l 0 3 4 cm s the fluid is water with density ρ f 1000 kg m 3 and kinematic viscosity ν f 10 6 m2 s 1 the mean fluid flow velocity is u 0 46 m s 1 the initial concentration profile is imposed using a hyperbolic tangent profile the stream wise pressure gradient is computed from the bed friction velocity of u 2 8 cm s estimated from the experiments by roulund et al 2005 36 f p x ρ f u 2 h f the shields parameter at the inlet is the same as is in roulund et al 2005 θ 0 19 it can be seen as the ratio between the destabilizing fluid shear stress τb and stabilizing forces grains weight acting on a particle 37 θ τ b ρ s ρ f g d the water column is discretized using 64 vertical levels with a geometric common ratio r f 1 075 from the initial interface to the top in the sediment bed 50 vertical levels with a geometric common ratio rs 1 086 from the initial interface to the bottom are used the vertical profiles of this configuration will be used as inlet boundary conditions in the 3d simulation presented in section 4 the granular rheology parameters are set up as follows the static friction coefficient is set to μ s 0 63 corresponding to the tangent of the angle of repose for sand in water the dynamical friction coefficient is fixed to μ 2 1 13 and i 0 0 6 these values have been obtained for bed load transport with spheres using the discrete element method maurin et al 2016 in order to account for the particle shape the coefficients μs and μ 2 have been increased by a constant value so that μs matches the tangent of the repose angle for real sand particles β r 32 a sensitivity analysis to the solid phase maximum viscosity νmax has been performed in nagel 2018 the model shows a strong sensitivity at low values of νmax but converges to a constant value when νmax increases the error associated with νmax is called the creeping flow if the maximum viscosity is too low a non negligible velocity gradient will be predicted in the static sediment bed that can give rise to a non negligible spurious sediment transport flux the creeping flux decays exponentially as νmax increases it has been shown that a value of ν m a x 100 m2 s should be used to guarantee a negligible creeping flow by varying the pressure gradient we will investigate the sediment transport flux as a function of the shields parameter the dimensionless depth integrated sediment flux q and the dimensionless transport layer thickness δ are computed from the numerical solutions and plotted against the shields parameter θ in fig 1 the dimensionless depth integrated sediment flux is calculated as the total sediment transport rate including the contribution of the bed load and the suspended load 38 q u s ϕ d z s 1 g d 3 the dimensionless transport layer thickness is computed as the bed normal distance between the iso surfaces ϕ 0 57 and ϕ 0 08 made dimensionless by the particle diameter d 39 δ δ d s where ϕ 0 57 is a proxy for the immobile bed position and ϕ 0 08 corresponds to a an inter particle distance of one particle diameter which is taken as the transition between bedload and suspended load layers bagnold 1956 dohmen janssen et al 2001 in addition to roulund et al 2005 unidirectional bedload case q and δ are also calculated from simulation undertaken with revil baudard et al 2015 and sumer et al 1996 unidirectional sheet flow configurations described in chauchat et al 2017 these three configurations cover a wide range of shields number θ 0 1 2 5 for different particle sizes and densities see table 3 in the left panel of fig 1 the dimensionless sediment transport rate is plotted against the shields number for the three configurations investigated the numerical results are within the scatter of the experimental data namely meyer peter and müller 1948 for θ 0 5 and wilson 1966 for θ 0 5 in the right panel of fig 1 the dimensionless sediment transport layer thickness is plotted against the shields number for revil baudard et al 2015 and roulund et al 2005 configurations the results exactly match wilson 1987 semi empirical model δ 10 θ the results for sumer et al 1996 case does not exactly follow that law but the trend is similar and the numerical results are in the scatter of sumer et al 1996 experiments the definition of the bed shear stress used to evaluate the shields number is also a matter of debate in chauchat 2018 the maximum value of the fluid bed shear stress is used 40 τ b max r x z f this definition corresponds to the red empty circles plotted in the left panel of fig 1 in a unidirectional case computing the bed shear stress as the maximum of the fluid shear stress lead to a very good agreement with literature data see figure a4 of chauchat 2018 however when dealing with complex 3d flow configurations this definition may lead to an inconsistency as the fluid shear stress profile does not necessarily present a monotonous increase toward the bed we propose an alternative consisting of the use of the mixture shear stress computed at the elevation of the iso concentration ϕ 0 0 08 to compute the shields number 41 τ b τ x z f ϕ ϕ 0 τ x z s ϕ ϕ 0 a sensitivity analysis to ϕ 0 0 08 0 45 0 57 has been performed and the shields number estimation is only marginally affected not shown here see nagel 2018 for details for clarity only the results obtained using ϕ 0 0 08 are plotted with the dark empty triangles in the left panel of fig 1 a sensible choice for the bed shear stress definition would be to consider the actual shear stress exerted by the mixture of grains and fluid at the fixed bed interface this corresponds to the latest definition using ϕ 0 0 57 and works well for unidirectional steady uniform flows however when the flow is non uniform with steep bed slopes it is more complex to relate the shields number to the actual shear stress exerted on the immobile bed as other granular processes are involved it should be noted here that the shields number characterizes the fluid drag force exerted by the flow on the particles in the near bed region in the perspective of upscaling the two phase flow results in single phase sediment transport models it is important to use a resolved quantity in the single phase flow model to compute the shields number the shear stress in the dilute region of the flow is solved by the single phase flow model however the shear stress exerted by the grain fluid mixture on the immobile bed is not in order to establish the undisturbed reference solution against which a 3d simulation can be compared the one dimensional results for medium sand in the range of shields parameter between 0 1 to 2 5 can be fitted using a power law of the excess shields number 42 q m o d a θ θ c b where θ c 0 047 is the critical shields number the a and b coefficients obtained from the best fit are summarized in table 4 first of all the values obtained are consistent between the different methods for the bed shear stress estimation the exponent of the power law b is less sensitive and in better agreement with classical empirical formula of meyer peter and müller 1948 or wong and parker 2006 the prefactor a is more sensitive with values ranging between 25 and 32 which is quite far from the empirical values of 3 97 and 8 it should be noted that all the different cases have different suspension numbers according to sumer et al 1996 the suspension number can be written as s u w f a l l 0 u for su 1 corresponding here to θ 0 3 the suspension becomes important in the total sediment flux for the sand case su varies between 1 6 for θ 0 1 and 0 56 for θ 1 therefore a non negligible suspended load components to the total sediment flux is expected in these conditions it is not surprising that the coefficients a and b are different from the values of meyer peter and müller 1948 nevertheless the model is able to recover a power law with a reasonable exponent it is worth mentioning that an exponent b 2 has been obtained in all former studies using two phase flow models hsu et al 2004 revil baudard and chauchat 2013 chauchat 2018 interestingly when using the mixture stress at sediment concentration higher than 0 08 the exponent b tends toward 1 5 consistently with meyer peter and müller 1948 or wong and parker 2006 it is therefore kept as the definition of the fluid bed shear stress to analyze the 3d scour configuration 4 3d scour simulation when an obstacle such as a bridge pier or a river restoration structure is built in a stream its presence can strongly modify the flow field and induce scour for example around a cylindrical pier the flow separation creates a strong adverse pressure gradient as a result the flow plunges toward the bed and if the bottom boundary layer contains a sufficient amount of vorticity a horseshoe vortex hsv is generated at the bed structure junction along the sides of a structure streamline contraction leads to flow acceleration and amplify the bed shear stress at the downstream side of the structure the boundary layer can separate and lead to vortex shedding in the wake in combination the wake vortices and the hsv lead to a local increase of bed shear stress sediment transport rate and bed erosion scour hole development if not correctly predicted and treated may significantly undermine the structure and cause its failure with potentially disastrous consequences breusers et al 1977 dargahi 1990 breusers and raudkivi 1991 melville and coleman 2000 roulund et al 2005 in the previous section it has been demonstrated that the two phase flow model presented in section 2 is able to accurately predict unidirectional sediment transport for medium sand the range of shields number investigated corresponds to the expected range in the 3d scour configuration of roulund et al 2005 furthermore the detailed study of the hydrodynamics around a vertical cylinder in a steady current without sediments is presented in appendix a it ensure that sedfoam is able to accurately reproduce the flow key structures i e the hsv and the lee wake vortices for the scour phenomenon in the present section the two phase flow model will be used to investigate the more complex configuration of the scour around a cylindrical pile 4 1 numerical configuration the numerical domain can be divided into two parts the initial water domain and the initial sediment domain grey part in fig 2 the initial water domain is a three dimensional box with a stream wise length lx 13d a span wise length ly 8d and a height h 2d where d 10 cm is the pile diameter as in roulund et al 2005 at the bottom a thin sediments layer 0 25d extends below the entire water domain except in a region around the pile where a deeper circular pit of height h s d and radius r p i t 2 d has been setup to reduce the grid cells number the sediments properties are the same as in the unidirectional case see section 3 the shields parameter at the inlet and the reynolds number are the same as is in roulund et al 2005 θ 0 19 and r e d 4 6 10 4 respectively the computational domain is discretized using a unstructured mesh see table 5 the mesh is refined around the cylinder and at the initial interface position the mesh refinement area around the cylinder is axisymmetric as for the unidirectional case the water column is discretized using 64 vertical levels with a geometric common ratio r f 1 075 from the initial interface to the top for the sand layer outside the scour pit the mesh is composed of 100 vertical levels having a geometric distribution with a common ratio r s 1 025 in the pit an additional 100 grid points are used with a geometric common ratio r p i t 1 010 the boundary conditions are imposed as follows i at the inlet vertical profiles obtained from the unidirectional simulation are imposed for us uf k ω ϕ zero transverse velocity is prescribed ii at the outlet zero gradient conditions neumann conditions n 0 are specified for all quantities except for the reduced pressure for which a homogeneous dirichlet boundary condition is imposed p 0 for the velocities a homogeneous neumann boundary condition is used when the velocity vector points outside of the domain at the outlet and a homogeneous dirichlet boundary condition u k 0 is used otherwise iii at the top boundary neumann boudary conditions are applied for k ω and uk iv at the walls including the cylinder zero velocity no slip is imposed for the three components and a small value is imposed for the tke the boundary condition for ω is specified using the classical wall function from openfoam at the cylinder and a constant value is imposed at the rigid bottom v at the side cyclic conditions are used for the initial condition the unidirectional solution used for the inlet is imposed over the entire numerical domain finally the granular rheology parameters used are the same as for the unidirectional sediment transport case the scheme used for the divergence operators of the different quantities is a blend between a pure centered second order scheme and a first order upwind scheme in the regions of rapidly changing gradient limitedlinear 1 the laplacian scheme for all quantities is a linear interpolation with non orthogonality correction gauss linear corrected as for the unidirectional configuration the bed shear stress is computed as the mixture shear stress at the concentration ϕ 0 0 08 43 τ b τ x z f ϕ ϕ 0 2 τ y z f ϕ ϕ 0 2 τ x z s ϕ ϕ 0 2 τ y z s ϕ ϕ 0 2 because the scour is deforming the initial flat sediment bed the resulting interface can be inclined and these variations have to be accounted for in the bed shear stress calculation which is taken as the magnitude of the tangential shear stress with respect to the sediment bed surface the bed interface is first interpolated from the original unstructured grid to a cartesian one on each cell of the cartesian grid the normal n and the tangential t x and t y vectors are calculated using the bed interface elevation horizontal gradient the projection of the mixture bed shear stress magnitude on the plane tangential to the local bed surface reads 44 τ b t f t x 2 t f t y 2 t s t x 2 t s t y 2 where tk is the stress vector applied on the sediments bed surface of the phase k it is obtained from the product between the phase shear stress tensor τk and the vector normal to the isosurface ϕ 0 0 08 n 45 t k τ k n for more details about the specific methodology for the bed shear stress determination in a non uniform three dimensional case the interested reader is referred to nagel 2018 in the following the results of the three dimensional two phase flow simulations are presented the reference two phase flow simulation was run for 600 s of real time this computation took approximately 480 h 20 days on 224 processors intel xeon e5 2690 v4 the computational time is approximatively of 108 000 cpu hours which would correspond roughly to 12 years on a single processor 4 2 erosion pattern and maximum erosion depth in order to qualitatively illustrate the model results snapshots of dimensionless bed elevation s d and fluid velocity streamlines are shown at different times t 10 s 60 s 150 s and 600 s in fig 3 the bed interface is defined as the surface of iso concentration ϕ 0 57 these results can be qualitatively compared with figure 33 from roulund et al 2005 it is noted that the vortex shedding and the suspension load are not resolved in roulund et al 2005 s steady state flow simulations despite these differences both models exhibit the following bathymetric features i a semi circular shaped scour mark is predicted at the upstream side of the pile ii sediments eroded from the scour mark first accumulate downstream the pile see fig 3a iii at later stages a scour mark is predicted at the downstream side see figures 3b c and d this comparison supports at least qualitatively the relevance of the two phase flow approach for modeling scour around hydraulic structures the velocity streamlines show that the scour hole erosion modify the hsv but also that vortex shedding is taking place at the downstream side of the pile more quantitatively fig 4 shows the time evolution of the maximum dimensionless scour depth s d at the upstream side top panel and at the downstream side bottom panel of the pile the results of two different two phase flow turbulence models the k ω 2006 blue line and the k ε yellow lline are shown they are compared with experimental data red dots and single phase flow model results from roulund et al 2005 green dashed line and stahlmann et al 2013 magenta dashed line the k ω 2006 simulation has been performed up to 600 s of dynamics the good agreement between this two phase flow simulation and the experiments at the upstream side of the pile shows that the two phase flow model is able to accurately reproduce the upstream scour depth evolution up to 300 s from 300 to 600 s the maximum dimensionless scour depth is underestimated compared with the experimental data as a result at t 600 s the two phase flow results give s d 0 63 whereas roulund et al 2005 measured results show s d 0 8 the k ε simulation has been run for 350 s the results in terms of upstream scour are almost identical to the k ω 2006 up to 150 s beyond that time the results follow a logarithmic growth and are closer to the ones from roulund et al 2005 using a classical sediment transport model the two phase flow simulation results are sensitive to the turbulence model this confirms the simulation results of mathieu et al 2019 for the scour around a pipeline using k ε model leads to an overestimation whereas using k ω 2006 model leads to an underestimation of the scour depth however it is important to notice that both the experimental results of roulund et al 2005 and their best numerical prediction using a classical model stahlmann et al 2013 are within the range of the solutions given by the two phase flow model at the downstream side bottom panel of fig 4 the maximum erosion depth predicted by the k ω 2006 model exhibits temporal fluctuations whereas the k ε model results exhibit a smooth curve unlike the upstream side the position of the maximum scour depth downstream of the cylinder is located away from the structure at about 1 to 2 cylinder diameter downstream the fluctuations which are not present in roulund et al 2005 steady state numerical results are most probably due to the eddies shed downstream of the pile this result indicates that the downstream scour is highly influenced by the vortex shedding a result that has already been pointed out in former studies using classical sediments transport models e g zhao et al 2010 stahlmann et al 2013 baykal et al 2015 however if the maximum erosion depth predicted by the k ω 2006 model follow a tendency similar to the experimental results from roulund et al 2005 the erosion rate is underestimated by the two phase flow model this leads to an underestimation of the erosion depth downstream of the pile as for the upstream side the k ε scour depth results are very similar to roulund et al 2005 classical model results no fluctuations are observed meaning that the two phase k ε model fails to reproduce the vortex shedding 4 3 choice of the granular stress and turbulence model the first point that needs to be discussed is the choice of the granular stress model one could argue that the kinetic theory of granular flows jenkins and savage 1983 ding and gidaspow 1990 jenkins and hanes 1998 shall be preferred to predict sediment transport in scour configuration indeed it describes better the intermediate concentration region 0 08 ϕ 0 3 where collisional interactions dominates however the μ i rheology reproduces more accurately the dense granular flow regime 0 3 ϕ 0 6 where frictional interactions dominates for an unidirectional sheet flows case chauchat et al 2017 have demonstrated that the vertical structure of the flow as well as the repartition of the sediment flux is only slightly affected by the choice of the granular stress model furthermore mathieu et al 2019 recently performed a sensitivity analysis to the choice of the granular stress model using the same numerical model for the scour below a pipeline configuration the authors observed almost no sensitivity to the choice of the granular stress model on the erosion depth due to the very high computational cost of the 3d scour simulations this sensitivity analysis is not performed herein unlike classical sediment transport models two phase flow models are process based models and as such shall not be fine tuned on each configuration for the μ i rheology the parameters have been calibrated on unidirectional sediment transport configurations in section 3 the unicity and accuracy of this calibration could be questionned however for sake of consistency it has been decided not to modify these paremeters in the 3d simulations in classical sediment transport models the sediment transport fluxes are based on emprirical formula obtained under the assumptions of unidirectional steady and uniform flows applying these parametrizations to non uniform and unsteady flow conditions raises potential inconsistencies and a sensitivity analysis to some of the empirical constant is usually needed to improve the model predictions e g stahlmann et al 2013 as already pointed out by mathieu et al 2019 for the scour around the pipeline the near bed erosion is probably better described by the k ε model and the lee wake erosion is better predicted by the k ω 2006 model as a matter of fact in the vertical cylinder configuration the k ω 2006 turbulence model is the only one able to reproduce the vortex shedding downstream of the cylinder and to account for the adverse pressure gradient upstream of it roulund et al 2005 therefore in the following all the results presented are obtained with the k ω 2006 turbulence model 5 analysis of the sediment fluxes 5 1 upstream and around the pile in the case of a flow around a structure the assumption of uniform flow condition is not verified it has been shown in section 3 that the two phase flow model predicts a power law for the relationship between the sediments transport flux and the shields parameter under uniform and steady flow conditions in section 4 2 it has been further demonstrated that the two phase flow model is able to predict reasonably well the bed morphological evolution at the early stages of the scour process in this section the numerical results are further analyzed to investigate the perturbation induced by the pile on sediment transport and how much it differs from the results obtained under steady and uniform flow conditions fig 5a shows the local slope angle β at t 10 s it is determined from the magnitude of the horizontal gradient of the bed elevation 46 β arctan h z b e d where h z b e d z b e d x 2 z b e d y 2 and z b e d z ϕ 0 57 far from the obstacle the bed is almost flat but closer to the cylinder there is a semi circular area where the slope is gently increasing toward the cylinder the upstream distance to the center of the cylinder is defined as ru it is equal to x on the x axis at the upstream side of the cylinder ru d 0 7 an important variation of the bed slope angle is visible β varies between β 30 and β 45 exceeding the angle of repose β r 32 in this region avalanches occur and the sediment flux is predominately driven by gravitational acceleration closer to the cylinder 0 6 ru d 0 5 the slope angle is decreasing and the sediment bed is nearly flat just downstream of the cylinder up to x d 1 the bed slope angle is more noisy and it is hard to distinguish any slope tendency further downstream x d 1 the bed variations are very small and β remains below 10 fig 5c shows the instantaneous dimensionless depth integrated sediment flux calculated by the two dimensional extension of eq 38 the sediment flux starts to increase where the bed slope angle is increasing and it peaks around ru d 0 7 closer to the cylinder where the scour hole is the deepest and the bed is almost flat the sediment flux becomes very small the maximum of the sediment flux is located in the two hsv legs around the cylinder this result indicates that there is an important transverse flux driven by the hsv legs around the cylinder this is in agreement with the description of link et al 2012 the maximum dimensionless sediments flux within these two legs is q max 7 9 downstream of the cylinder the sediment flux is weak probably because the vortex shedding is not fully developed at this early stage t 10 s the patch of sediment flux appears to be due to a vortex shed from the cylinder passing by fig 5b shows the spatial distribution of the shields number its magnitude is slightly increasing with the slope in the scour hole and reaches its maximum at the sides of the cylinder where the shields number values correspond to sheet flow regime θ 0 3 i e for γ 65 120 γ is the angle measured with respect to the upstream x axis downstream of the pile a high shields number area is located around x d 1 and y d 0 25 exactly where an increase of sediments transport was observed in fig 5c here the local bed shear stress has a swirl structure confirming that it is generated by a vortex shed from the cylinder fig 5d shows the dimensionless sediments flux estimated using the power law deduced from unidirectional simulations presented in section 3 47 q a θ θ c s b with a 26 14 and b 2 09 i e using bottom shear stress evaluated at vertical elevation where ϕ 0 0 08 the critical shields number θcs is defined as a function of the local bed slope and orientation the formulation used in the present work is same as in roulund et al 2005 the flow velocity at the particle position and the steepest slope orientation with respect to the flow are used to adjust the critical shields number 48 θ c s θ c cos β 1 sin 2 α tan 2 β μ s 2 cos α sin β μ s where θ c 0 047 is the critical shields number for a flat bed β m i n β β r and α is the angle between the near bed velocity and the direction of maximum slope 49 α arccos h z bed u s ϕ 0 h z bed u s ϕ 0 in which us ϕ is the sediment velocity at the iso concentration ϕ 0 08 this concentration being the best compromise in term of bed shear stress estimation nagel 2018 eq 48 has been slightly modified from roulund et al 2005 definition the original definition provides non physical values for slope angles above the angle of repose β r 32 in classical sediment transport models an avalanche module is required to prevent the bed slope to exceed the angle of repose in the two phase flow model the bed slope is free to exceed that critical value while the solution of the momentum balance will predict a physical description for the avalanching process e g bagnold profile for dry granular flows andreotti et al 2013 the dimensionless sediment flux obtained using eq 47 is locally correlated to the bed shear stress or the shields number as expected the dimensionless sediment flux shown in fig 5d and the shields number shown in fig 5b present the same spatial patterns they increase in the upstream part of the scour hole reach a maximum value for γ 65 120 but are low for γ 0 45 and close to the cylinder due to vortex shedding the instantaneous flow pattern shown in fig 5 is asymmetric the spatial correlation between depth integrated sediments flux as predicted by the two phase flow model fig 5c and by the empirical classical power law given by eq 47 fig 5d is rather poor indeed for γ 0 65 and more particularly around the steep slope upstream the cylinder the important sediment flux observed in fig 5c is not observed in fig 5d this result suggests that in this region sediment transport is not driven by the local fluid bed shear stress but rather by the bed slope the second and third columns of fig 5 show the same quantities for t 60 s and t 150 s respectively the bed slope variations are very similar between t 60 and t 150 s in fig 5e and i the slope angle increases toward the cylinder exceeding the angle of repose between ru d 0 7 and ru d 0 6 the slope starts to be important further upstream at t 150 s this is in good agreement with the upstream extension of the scour hole as time increases between ru d 0 7 and the pile for γ 0 45 the shields number fig 5f and j is below its undisturbed value of 0 19 this is due to the presence of the cylinder which generates the down flow this leads to a reduction of the shields number in front of the cylinder the maximum shields number is located downstream of the cylinder and at the cylinder sides for γ 65 145 where it is decreasing in time downstream of the pile due to the vortex shedding the shields number is important in a narrow channel approximatively aligned with the x axis at t 60 s and t 150 s the depth integrated dimensionless sediments flux obtained directly from the velocity and concentration fields see fig 5g and k have similarities to the one at t 10 s far upstream of the cylinder the sediment flux increases slightly with the increasing bed slope angle around the main slope variation ru d 0 7 the flux drastically increases and remains at a high level q 4 5 where the bed angle exceeds the angle of repose excluding the area just downstream of the cylinder the maximum of the sediment flux is located in the two legs around the cylinder however compared with t 10 s the hsv legs are wider and the maximum sediment flux is slightly decreasing in time q max 7 1 at t 60 s and q max 6 6 at t 150 s the transverse flux driven by the hsv legs around the cylinder seems thus to decrease in time this result is coherent with the fact that the erosion rate is higher at the beginning of the scour process see fig 4 as for t 10 s important differences are observed between the two phase flow sediment flux and the empirical formula fig 5h and i a better understanding of the sediment transport in the cylinder vicinity can be obtained by investigating the vertical structure of the flow fig 6 shows the vertical profiles of the mixture velocity u the sediments concentration ϕ and the dimensionless sediments flux π ϕ u s 2 v s 2 w s 2 s 1 g d 3 for t 10 s in blue t 60 s in magenta and t 150 s in red the location of each profile is given in fig 5c at the upstream slope of the scour hole white circle and in the hsv legs squared symbol the horizontal dotted lines represent the vertical elevation where the sediments concentration is ϕ 0 08 allowing to distinguish between bedload and suspended load the vertical profile upstream of the pile is located where the bed slope angle is approximatively of 25 at t 10 s and above the critical angle β 32 for t 60 s and t 150 s the profiles have a similar shape the velocity is positive i e downstream oriented just above the bed this results in a strong downstream oriented bedload sediment flux above this dense transport layer the mixture velocity becomes negative over more than 5 mm in height for t 10 s and 1cm for t 60 and t 150 s the concentration in that region is lower than 0 08 meaning that sediments are transported upstream as suspension further away from the bed the mixture velocity is positive again but the sediments concentration is so low that the associated sediment flux is negligible in the hsv legs bottom panels of fig 6 the mixture velocity is positive over the entire water depth and the concentration profile is smoother at the bed interface as a result there is a positive sediments flux at that location the peak of sediment flux is located below the vertical position of concentration ϕ 0 08 meaning that bedload dominates nonetheless an important positive contribution from suspended load is also observed at all times in order to better explain the observations obtained from the vertical profiles fig 7 shows a vertical plan view in the plane of symmetry upstream of the pile the velocity vectors and the dimensionless sediments flux π are presented at the same instants 10 s 60 s and 150 s the sediment iso concentration contours ϕ 0 57 and ϕ 0 08 are also plotted in all figures to represent the bedload layer the angle of repose β r 32 is materialized as the red dashed line the vertical magenta dashed line represents the position x d 0 7 of the upstream vertical profile shown in fig 6 by examining the bed evolution and the velocity field it can be concluded that the downward flow in front of the pile acts as a vertical jet impinging the sediment bed this downflow will ultimately be involved in the generation an hsv and both features will lead to sediment erosion as the scour hole deepens in time the bed slope upstream the pile increases and reaches values higher than the angle of repose β 32 a competition between the local bed shear stress resulting from the fluid flow above the sediments bed and the downslope gravitational acceleration is taking place in the scour hole at the upstream part of the scour hole the slope is mild and the velocity vectors are aligned with the sediments flux fig 7 up to x d 1 closer to the cylinder in the suspended load layer sediments are transported upstream by the hsv while in the bedload layer sediments are transported downstream by gravity this result could be corroborated to experimental observation from link 2018 who measured intermittent avalanches in the scour hole link et al 2008 2012 further observed several slope breaks in their experiments that are probably related to the existence of multiple vortices in the hsv as mentioned by dargahi 1990 in the present simulation the velocity vectors allows to identify a single vortex in the hsv its position does not evolve in time and corresponds to the point at which the slope becomes steeper than the angle of repose in the region between the hsv and the pile the slope is steeper than the angle of repose meanwhile the velocity vectors and therefore the fluid bed shear stress are in the opposite direction the downslope gravity flow and the bed shear stress are counteracting each other but as the angle of repose is exceeded the downslope gravity flow dominates and the net sediment flux is positive downslope the observations presented in the plane of symmetry upstream of the pile are in good agreement with the two dimensional depth integrated results showed previously the importance of both the slope and the avalanche phenomenon on the sediments transport is confirmed 5 2 downstream of the pile downstream of the cylinder and for t 60 s the sediment flux predicted by the two phase flow model are very significant see fig 5g and fig 5k the strongest fluxes are located up to 1 5 diameter downstream of the pile fig 8 shows the same quantities as fig 6 but at two locations downstream of the pile the first profile is located in the recirculation cell x d 0 75 y d 0 star symbol just downstream of the pile the mixture velocity shows negative values of up to u 0 35m s 1 for the entire vertical profile shown and the concentration is non negligible ϕ 10 3 in the water column as a consequence there is a negative suspended sediment flux at all times although this upstream flux is small at early stage t 10 s it increase significantly at later stages t 60 s and 150 s as sediment concentration increases further downstream x d 1 75 y d 0 diamond symbol the observations are different for t 10 s the velocity are negative and the flux is much larger than that closer to the cylinder due to higher suspended sediment concentration it generates a more important suspended sediments flux toward the cylinder for t 60 and 150 s the velocity are positive and the sediments are transported downstream by the vortices as bedload and suspended load the present results illustrate the complexity of the instantaneous sediment transport downstream of the pile the sediment concentration profiles at the back of the cylinder drops rapidly away from the bed and suspended load generally dominates bedload this was already pointed out by baykal et al 2015 6 discussion in section 5 the role of the local bed slope on sediment transport in the scour hole has been clearly identified in classical models the downslope contribution is accounted for as a modification of the critical shields number in the bed load flux formula see eq 25 of roulund et al 2005 for instance this correction is only valid at very low bed slopes and it does not represent the avalanching process when the bed slope exceeds the angle of repose an iterative algorithm based on the sediment mass conservation is used to instantaneously limit the bed slope at the angle of repose this model neglects the avalanche dynamics and the associated relaxation time scale in the present two phase flow model the avalanche dynamics is implicitly accounted for by using the dense granular flow rheology for the sediment phase interestingly the numerical solution shows that the bed slope can locally exceed the angle of repose in the scour hole very near the pile this is due to the competition between the fluid bed shear stress associated with the up slope flow generated by the hsv and the downslope sediment flow this can not be predicted by classical single phase flow sediment transport models and illustrates the need for a new modeling approach for this phenomenon in engineering models it is possible to use the present two phase flow model results to infer the local relationship between the sediment fluxes the local fluid bed shear stress and the local bed slope in the scour configuration fig 9 a shows the computed depth integrated dimensionless sediment flux q as a function of the shields parameter along the plane of symmetry γ 0 the local sediment flux and shields parameter are averaged over 10 s of dynamics around time t 60 s the results are compared with the fit given by eq 42 obtained with the same two phase flow model under unidirectional and uniform flow conditions red line see section 3 the two red dashed line represents 100 error with respect to the best fit such confidence interval is considered as reasonable for steady and uniform flow conditions gomez and church 1989 the dimensionless sediment flux values are colored by their spatial distance from the inlet the empty black symbols represent reference points to facilitate the interpretation at the inlet dark blue dots cross symbol where the flow is not influenced by the presence of the pile the value of the local shields number and the dimensionless sediment flux are very close to the uniform flow case θ 0 19 moving downstream x d 2 5 upward triangle symbol both the dimensionless sediment flux and the shields parameter are decreasing due to the adverse pressure gradient generated by the presence of the cylinder despite the fact that the values present a small scatter they remain within a factor two confidence intervals with respect to the uniform and steady flow best fit when getting closer to the cylinder x d 1 5 downward triangle symbol the sediment flux and the shields number slightly increase and are very close to the unidirectional steady flow case this can probably be explained by the increase of the local bed slope see fig 7 and will be discussed later very close to the cylinder x d 1 5 0 7 circle symbol the sediment flux increases drastically by one order of magnitude while the shields number drops to almost zero this is the region where the avalanching occurs the dimensionless sediment flux strongly deviates from the uniform and steady solution the sediment flux is not related to the fluid bed shear stress most probably because of the strong downslope gravitational effect and of the avalanching downstream of the pile x d 0 5 1 75 star and losange symbols the dimensionless sediment flux slowly decreases from 10 to 5 while the shields number oscillates between 0 15 to 0 5 in this region the lee wake vortices dominate the hydrodynamics and the sediment flux is not related to the local fluid bed shear stress instead the sediment flux is dominated by the suspended load see fig 8 either due to local pick up of sediments from the bed or to sediments advected from upstream this explains the poor correlation between the sediment flux and the local shields number as well as the deviation from the best fit further downstream x d 3 from orange to red dots hexagonal symbol the dimensionless sediment flux and the shields parameter decrease due to the weakening of the lee wake vortices the sediment flux become closer to the best fit factor 2 error only and the sediment flux correlates again with the local shields number the overestimation of the sediment flux can be explained by the enhanced suspended load observed in fig 8 to summarize at the downstream side of the pile the dimensionless sediment flux deviation from the uniform and steady state case can be explained by the influence of the lee wake vortices and the enhanced suspended load upstream of the pile the deviation from the uniform and steady state case is probably due to the downslope gravitational effect and the avalanching process in order to infer the dependency of the local sediment flux to the bed slope the dimensionless sediment flux along the plane of symmetry is plotted in fig 9b as a function of the local bed slope angle β at t 60 s the results are only presented between x d 2 and the upstream edge of the pile and are colored with the same colobar as the one used in fig 9a the two phase flow model results exhibit a linear dependency on the bed slope for β 23 as highlighted by the magenta line a simple linear function of the bed slope angle reproduces fairly well the numerical results q β for β 5 25 the good collapse of the sediment flux with the bed slope and the poor correlation of the sediment flux with the bed shear stress fig 9a demonstrate that the sediment flux in the region just upstream of the pile is dominated by the gravity rather than by the bed shear stress for β 23 the sediment flux predicted by the two phase flow model non linearly increases with the bed slope angle before reaching a maximum value at β 35 the local bed slope is on the order or higher than the static friction angle of the μ i rheology meaning that avalanches is taking place this numerical result is supported by experimental observation from link 2018 and further confirms that the μ i rheology is probably the best choice for the granular stress model as it is more accurate to predict avalanches above this angle the sediment flux decreases drastically with the bed slope angle up to β 45 in this region avalanches occurs but sediments are also transported perpendicular to the symmetry plane by the hsv very close to the pile both the sediment flux and the bed slope angle tend toward zero the results presented above show that a competition between fluid bed shear stress driven and gravity driven sediment transport occurs at bed angles lower than the angle of repose β 23 the relationship between the sediment flux and the bed slope is linear below this value above this angle the sediment flux increases nonlinearly with the bed slope while the shields number vanishes showing that the sediment flux only result from the action of gravity this changes the vision of the problem and opens new perspectives on modeling the avalanching effect in sediment transport models 7 summary and conclusion in this paper the first three dimensional eulerian eulerian two phase flow simulation of scour around a cylinder has been presented the model has been firstly validated against existing experimental data for the hydrodynamics and the morphodynamics the relationship between the dimensionless sediment transport flux and the shields number for uniform and steady flow configuration using the two phase flow approach has been established to serve as a reference to analyze the 3d effects in the scour simulation the best fit of a power law of the excess shields number results shows very good agreement with the literature for shields numbers as low as 0 1 these results further demonstrate the capabilities of the two phase flow approach to deal with sediment transport over a wide range of sediment transport regimes from bed load to sheet flows a new methodology to determine the bed shear stress in complex flow configurations is proposed the mixture shear stress computed at the elevation of the iso concentration ϕ 0 0 08 corresponding to top of the bedload layer is used to define the local shields number in non uniform unsteady flow configurations concerning the three dimensional scour simulation the good agreement obtained between the numerical results and the available measurements demonstrates the applicability of two phase flow models to complex sediment transport problems such as scour the temporal evolution of both bed morphology and erosion depth is almost quantitatively reproduced this allows us to further analyze the numerical results in terms of local correlation between sediment flux local bed shear stress and local bed slope upstream of the pile the dimensionless flux deviation from the transport law under uniform and steady flows is within a factor two except in the scour hole where it deviates by almost one order of magnitude in this region the sediment flux results from a competition between the fluid bed shear stress and the downslope gravity effect close to the cylinder the sediment flux is fully correlated with the local bed slope demonstrating that avalanching is dominating according to our numerical results in the major part the scour hole the sediment flux is not correlated with the bed shear stress only the empirical laws on which the classical sediment transport models are build are therefore not accurate the numerical simulation shows that the downslope gravitational effect becomes very significant at a rather low bed slope angle with a linear dependency of the sediment flux to the bed slope angle below β 23 and a nonlinear dependency above this value these results change the vision of the problem and provides new perspectives on modeling the effect of the bed slope and the avalanching process further work is needed to propose new parameterizations that reproduce more accurately the influence of the bed slope concerning the downstream side of the pile the two phase flow results suggests that suspended load is dominant in both the hsv legs and the lee wake vortices this result is consistent with previous work on this topic using single phase flow model stahlmann et al 2013 baykal et al 2015 the main limitation of the two phase flow model for scour modeling stand probably within the urans approach the present k ω 2006 turbulence model could be improved following mathieu et al 2019 recommendations in order to more accurately predict the erosion and the morphodynamics where the interactions between the fluid vortices and the sediment bed are important improving the particle presence feedback on the turbulence in the near bed region seems to be the key to improve results however this is a very fundamental problem in fluid mechanics and in multiphase flows that even in the simplest configurations i e homogeneous isotropic turbulence is not fully understood the present work illustrates the capability and limits of the state of the art parametrization for eulerian eulerian model this point clearly deserves future investigation but we strongly believe that the 3d scour configuration is not the most appropriate partly due to the complexity of the flow hydrodynamics and partly due to the lack of experimental data moreover the urans approach is unable to accurately reproduce the actual dynamics of the hsv such as the bimodal oscillation or the existence of multiple vortices in the lee wake the urans approach is certainly not perfect to predict accurately the vortex shedding and the interaction between these vortices and the sediment dynamics the natural extension of the present work would be to perform two phase flow large eddy simulation les of this problem this approach has been recently applied to unidirectional sheet flows by cheng et al 2018 and the application to 3d scour will be carried out in future work credit authorship contribution statement tim nagel methodology software validation writing original draft writing review editing julien chauchat methodology software validation funding acquisition project administration supervision writing original draft writing review editing cyrille bonamy methodology software validation writing original draft writing review editing xiaofeng liu writing original draft writing review editing zhen cheng writing original draft writing review editing tian jian hsu writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment we would like to thank oscar link for the helpful discussions this work was supported by the french national programme ec2co lefe modsed the authors would also like to acknowledge the financial support from the région rhône alpes through the cmira coopera project and the explorapro grant of j chauchat this research was partially funded by the anr segsed project anr 16 ce01 0005 03 most of the computations presented in this paper were performed using the froggy platform of the ciment infrastructure https ciment ujf grenoble fr which is supported by the rhône alpes region grant cper07 13 cira and the equip meso project reference anr 10 eqpx 29 01 of the programme investissements d avenir supervised by the agence nationale pour la recherche and the genci infrastructure under the allocations dari x2015012153 x2016017567 a0020107567 a0040107567 and a0060107567 z cheng and t j hsu are supported by nsf of usa oce 1635151 we are grateful to the developers involved in openfoam who are the foundation of the model presented in this paper appendix a hydrodynamic validation of the flow around a vertical cylinder mounted on a flat bed hydrodynamic setup computational mesh boundary conditions the numerical domain used for the hydrodynamic validation is a three dimensional box with a stream wise length lx 12d a span wise length ly 8d and a height h d where d 53 6cm is the pile diameter this is the same configuration than the rigid bed rb case presented in roulund et al 2005 the reynolds number based on the pile diameter is r e d u d ν f 1 7 105 where the mean flow velocity is u 0 326 m s 1 the computational domain is discretized using a unstructured mesh refined around the cylinder and at the bottom boundary the mesh refinement area around the cylinder is axisymmetric the mesh characteristics are given in table 6 the boundary conditions are identical to the ones used by roulund et al 2005 i at the inlet profiles obtained from a unidirectional vertical simulation driven by a pressure gradient are imposed for uf k and ω whereas zero transverse velocities are prescribed ii at the outlet zero gradient conditions neumann conditions n 0 are specified for all quantities except for the reduced pressure for which a homogeneous dirichlet boundary condition is imposed p 0 for the velocities a homogeneous neumann boundary condition is used when the velocity vector points outside of the domain at the outlet and a homogeneous dirichlet boundary condition u f 0 is used otherwise iii at the top surface of the computational domain neumann conditions are applied for k and ω and for the three components of the velocity as in roulund et al 2005 work the model does not have a free surface iv on the sides cyclic conditions are used v at the walls bottom and cylinder zero velocity no slip is imposed for the three components consistently with the small non dimensional distance to the wall z z u ν f 5 a very small turbulent kinetic energy is specified for k o 10 6 m2 s 2 the conditions for ω are specified using a wall function in order to account for the flume bottom roughness a roughness height of ks 2 68 10 3 m is imposed at the bottom wall thanks to the tuned ω wall function described in roulund et al 2005 for the cylinder the classical wall function from openfoam is used omegawallfunction for the initial condition the unidirectional vertical solution used for the inlet is imposed over the entire numerical domain results fig 10 shows a comparison of the rb hydrodynamic results with roulund et al 2005 s experimental and numerical results for longitudinal profiles of stream wise fig 10 left panel and wall normal fig 10 right panel velocities in the plane of symmetry at different elevations from the bed 0 5 cm 1 cm 5 cm and 20 cm the results have been averaged over 10 vortex shedding periods corresponding to approximatively 60 s of dynamics the flow upstream of the pile is in good agreement with roulund et al 2005 experimental data the hsv defined as the area in front of the cylinder where the longitudinal velocities are negative is very well captured see fig 10 left panel at 0 5 and 1 cm height downstream the pile the change of sign in the velocities shows that there is a counterclockwise recirculation cell this cell has the correct size compared with experimental data the counterclockwise recirculation cell was not reproduced by roulund et al 2005 steady numerical simulations see fig 10 right panel which confirms the importance of unsteady flow simulations for this configuration stahlmann et al 2013 baykal et al 2015 it must be pointed out that a shift is observed for the wall normal velocities downstream of the pile at 20 cm in the water layer compared with roulund et al 2005 experimental results this is probably due to rigid lid effects and accounting for the free surface could improve the accuracy of the results as shown in zhou 2017 horseshoe vortex fig 11 shows a comparison between the bed shear stress amplification τb τ 0 along the longitudinal axis in the plane of symmetry predicted by the model blue line and roulund et al 2005 experimental and numerical results the bed shear stress amplification is computed as the ratio between the local bed shear stress and its value at the inlet where the flow is undisturbed by the cylinder presence the local bed shear stress τb is computed as 50 τ b τ x z f 2 τ y z f 2 s i g n τ x z f where τ x z f and τ y z f are the components of the fluid shear stress tensor τf at the bottom in fig 11 the zero crossing of the bed shear stress amplification in front of the pile between x d 1 and x d 0 5 shows the location of the hsv the two phase flow model results are in very good agreement with roulund et al 2005 results outside of the hsv region x d 1 however inside the hsv region the negative bed shear stress amplification is underestimated the difference with amplification found in roulund et al 2005 experimental work is about 25 this is slightly improved compared with the findings of roulund et al 2005 and baykal et al 2015 s numerical work were the difference was more than 30 as mentioned in roulund et al 2005 and baykal et al 2015 no clear explanation can be provided for these discrepancies between experimental observations and numerical predictions lee wake vortices the regime of the lee wake vortices generated downstream of a vertical cylinder in a unidirectional flow depends on the pile reynolds number of the flow here red 1 7 105 the flow is in the so called subcritical regime the wake flow is expected to be completely turbulent with vortices shed alternatively at each side of the pile sumer et al 2006 fig 12 shows the bed shear stress vectors and the contour lines of the magnitude of the bed shear stress amplification over one period of vortex shedding at the bottom of the rb case the magnitude of the bed shear stress is calculated as τ τ x z f 2 τ y z f 2 the position of the maximum bed shear stress in the cylinder vicinity can be found around γ 65 where γ is the angle measured with respect to the upstream x axis in roulund et al 2005 and baykal et al 2015 the magnitude of the bed shear stress amplification is compared with the experiments of hjorth 1975 where the pile reynolds number is r e d 1 5 10 4 i e one order of magnitude lower than the present configuration despite the diffence in term of reynolds number it is shown in figure 17 of roulund et al 2005 and in fig 3 of baykal et al 2015 that their numerical simulations also predict the maximum bed shear stress around γ 65 the discrepancies between the numerical prediction and the experimental observation of hjorth 1975 where γ 45 remain unexplained by roulund et al 2005 and baykal et al 2015 again because of the diffence in term of reynolds number between the configurations no definitive comparison can be provided in term of bed shear stress amplification but the order of magnitude found with sedfoam is similar to what is reported in hjorth 1975 configuration max τ τ 0 9 fig 12 also shows the unsteady behavior of the flow downstream of the cylinder in the four panels snapshots during a vortex shedding period t are shown the generation of two vortices at the opposite sides of the pile one at t 0 t fig 12 top left panel and the other at t t t 2 is clearly visible here the vortex shedding period is approximatively 6 s although higher than the theoretical strouhal value str 0 2 the present strouhal number str 0 27 is in good agreement with the one reported in baykal et al 2015 discussion on rigid bed hydrodynamics the detailed study of the hydrodynamics around the cylinder such as the hsv and the lee wake vortices demonstrates the good behavior of the proposed model to reproduce the flow around a vertical cylinder in a unidirectional current without sediments the rigid lid assumption might be questionable as all experiments have been carried out in open channels indeed constraining the domain height could be an over simplification of the problem it is usually accepted that when the froude number is lower than about 0 2 the free surface deformation near the structure is negligible roulund et al 2005 even in this limit the rigid lid treatment is only an approximation in the results presented above the shift of the wall normal velocities downstream of the pile near the free surface compared with roulund et al 2005 experimental data can be attributed to the fact that the free surface deformation is not accounted for this has been shown by zhou 2017 who performed rigid lid and free surface computations of roulund et al 2005 configuration however at the upstream side of the pile in the region where the hsv is generated and the scour occurs the rigid lid approximation has almost no influence on the numerical results it is therefore reasonable to use this approximation to perform 3d scour simulation using the two phase flow model 
506,categorical parameter distributions are common place in hydrogeological systems consisting of geologic facies categories with distinct properties e g high permeability channels embedded in a low permeability matrix parameter estimation is difficult in such systems because the discontinuities in the parameter space hinder the inverse problem previous research in this area has been focused on the use of stochastic methods in this paper we present a novel approach based on traveling pilot points trips combined with subspace parameter estimation methods to generate realistic categorical parameter distributions that honor calibration constraints e g measured water levels in traditional implementations aquifer properties e g hydraulic conductivity are estimated at fixed pilot point locations in the trips implementation both the properties associated with the pilot points and their locations are estimated tikhonov regularization constraints are incorporated in the parameter estimation process to produce realistic parameter depictions for a synthetic aquifer system we solved the categorical inverse problem by combining the trips methodology with two subspace methods null space monte carlo nsmc and posterior covariance pc a posterior ensemble developed with the rejection sampling rs method is compared against the trips ensembles the comparisons indicated similarities between the various ensembles and to the reference parameter distribution between the two subspace methods the nsmc method produced an ensemble with more variability than the pc method these preliminary results suggest that the trips methodology has promise and could be tested on more complicated problems keywords inverse problem categorical inversion traveling pilot points multiple point statistics null space monte carlo linear sub space methods 1 introduction groundwater flow and contaminant transport models are commonly used to answer questions pertaining for example to groundwater management and contaminant migration these models solve the forward problem to answer the question under investigation the forward problem involves model parameterization followed by solving a partial differential equation to obtain a state vector d representing for example the groundwater head or contaminant concentration in response to specified boundary conditions the inverse problem on the other hand involves identifying the model parameter vector m from the state vector d inverse problems in the groundwater modeling context have been studied extensively zhou et al zhou et al 2014 present a recent detailed discussion of the groundwater inversion problem and a review of historical and modern methods the probabilistic formulation of the inverse problem see for example aster et al aster et al 2013 can be expressed in terms of conditional probabilities as shown in eq 1 1 q m d f d m p m c the term q m d is the posterior probability density function and represents the probability of occurrence of a parameter vector conditioned by the observed measured dataset the term p m is known as the prior and represents the probability of occurrence of any model based only on the initial information such as geological knowledge without considering the measurements of the state variables d the term f d m known as the likelihood represents the probability of simulating the measured data d given a model vector m the categorical inverse problem is a special case of the groundwater inverse problem pertaining to aquifers that consist of discrete geological facies categories for example consider a two categories aquifer with fluvial high permeability channels incised in a low permeability matrix at any location in this aquifer we would find only one of the two facies channel or matrix the inverse problem in this case requires us to generate categorical aquifer distributions when presented with prior geologic information about borehole logs static data and measurements of aquifer state e g groundwater heads categorical problems are often more challenging to solve than their continuous counterparts because the parameter space is discontinuous linde et al linde et al 2015 presented an extensive review of existing methods for this class of problems we summarize a few of them here the gradual deformation method gdm formulated by hu et al hu et al 2001 hu 2000 generates a sequence of model realizations that converge to matching the measured data the key underlying concept in gdm is that the linear combinations of multigaussian fields are also multigaussian fields with similar statistics it is therefore possible to explore a part of the model space by adjusting only one single parameter a weight allowing to move between two pre computed simulations if the categorical field is obtained by truncation of one or several multi gaussian realizations this process is straightforward and obtaining a discrete model that matches the measured observations can be treated as a usual continuous optimization problem caers and hoffman caers and hoffman 2006 proposed the probability perturbation method ppm when dealing with non gaussian priors and non linear forward model responses rather than computing the posterior from the prior and likelihood they instead decompose the posterior into a set of pre posterior distributions containing facies and measurement data respectively these pre posterior probability distributions are perturbed until newer model realizations in the sequence increasingly converge to matching measurements ronayne et al ronayne et al 2008 applied the ppm to a transient aquifer test model and generated a distribution of permeable discrete channels embedded within less permeable deposits alcolea and renard alcolea and renard 2010 and hansen et al hansen et al 2012 used an iterative blocking moving window algorithm in conjunction with simulated annealing or a markov chain based method to guide a multiple point statistics mps model in reproducing state variables and honor facies data known from prior knowledge mariethoz et al mariethoz et al 2010 proposed the iterative spatial resampling isr technique a markov chain based method to sample from the posterior distribution the transition from one element to the next in the markov chain is based on sampling the values of the previous field at a set of random locations and using these points as conditioning data for the next iteration while this procedure is straightforward and samples the posterior space in an unbiased manner it is rather time consuming jäggli et al jaggli et al 2017 proposed a faster approach named posterior population expansion popex expanding an initial ensemble of parameter models using mps and local conditioning in such a manner that the new models are likely to belong to the posterior population the popex approach was subsequently modified jäggli et al 2018 to overcome predictive biases by combining machine learning techniques with an adaptive importance sampling strategy several approaches to solve the categorical inverse problem based on pilot points have also been presented pilot points have been used to estimate heterogeneous hydrogeological parameter distributions for several decades certes and de marsily 1991 lavenue and de marsily 2001 doherty 2003 doherty et al doherty et al 2010 define pilot points as surrogate parameters in the inverse modeling process for representing heterogeneity in a lower dimensional space in these applications a location specific hydrogeological attribute e g porosity hydraulic conductivity is associated with the pilot point a pre determined number of pilot points are placed at strategic locations along the model domain to capture the heterogeneity in the system an iteration of the forward problem involves estimation of properties associated with each pilot point followed by spatial interpolation to create a spatially continuous parameter distribution from the discrete pilot point locations the inverse problem involves the estimation of parameter values at the pilot point locations that honor the calibration constraints over the course of the parameter estimation the locations of the pilot points remain static but the parameters associated with the pilot points change in the context of categorical fields li et al li et al 2003 used pilot points to guide an ensemble kalman filter approach to match dynamic head and geologic data simultaneously in this paper we develop and test a new approach where pilot points are used in conjunction with linear subspace methods tonkin and doherty 2008 to solve the categorical inverse problem the primary motivation here is that linear subspace methods are computationally inexpensive and their application in the estimation of continuous real world parameter fields has been well documented keating et al 2010 herckenrath et al 2011 we explore if these same approaches could be used to estimate discrete categorical parameter fields in our approach we use pilot points in a non traditional manner that we refer to as the traveling pilot points trips approach rather than using pilot points for spatial interpolation we iteratively adapt their positions to define the geometries of the discrete categories in our opinion there are two advantages to this approach first by using the positions of the pilot points the categorical problem has been restated as a problem with continuous parameters which is easier to solve second this approach allows us to infer the category geometries rather than to estimate them from spatial interpolation operations such as kriging indirectly the methodology described in this paper has only been tested so far on a synthetic problem with two categories and saturated two dimensional groundwater flow the technique might require additional modifications for more complex problems with multiple facies the subsequent sections of this paper are organized as follows in section 2 we present an overview of the trips method and its applicability in the context of generating categorical parameter distributions in section 3 we present an overview of the various sampling methods used in section 5 in section 4 we present a synthetic groundwater problem with a categorical parameter distribution in section 5 we use the trips approach to develop multiple likely parameter realizations for the synthetic problem finally we present a summary of our findings in section 6 2 trips methodology in section 2 1 we introduce the principle and present the details of the implementation of traveling pilot points trips to solve the categorical inverse problem in contrast to traditional pilot points trips are not fixed in location but instead can travel to locations of interest in the model domain 2 1 the traveling pilot points principle let us consider an aquifer containing permeable channels embedded within an impermeable matrix it is possible to generate such discrete geological fields with different geostatistical techniques one could use for example transition probabilities tprogs plurigaussian simulations object based models or multiple point statistics to model these structures for all these techniques it is possible to set a fixed number of locations where the type of geology is known for example presence of a channel but the locations themselves are unknown providing these locations as conditioning data to the geological simulation algorithm allows to change the parameterization of the geological simulation and to solve the inverse problem in this manner means to search for the optimal locations of these traveling pilot points this approach modifies a discrete inverse problem into a continuous one and should therefore facilitate its resolution this idea is very general and can have many applications 2 2 an example of geological model to test this idea in a simple situation we consider a binary case with channels as illustrated in fig 1 to constrain the geometry of the channels in a simple manner we use a two step approach based on object based simulations constrained by a training image on the one hand the training image fig 1 provides in a graphical manner the size of the channels their sinuosity their spacing and so on this image can be drawn by hand based on a geological concept it offers flexibility and simplicity on the other hand the object based model ensures that all the channels are continuous and that the geological models are generated very rapidly for the object based model we consider that there is a fixed number of channels crossing the area from left to right fig 2 for each channel we define a fixed number of traveling pilot points for example for a channel spanning an x distance of 100m we can characterize it by 5 points spaced 20m apart if the aquifer domain is 100 m 100 m with a typical distribution of 3 channels 15 points are used to track all the channels to simulate the entire domain the channel central lines are interpolated with a spline function using the position of the traveling pilot points as input then a constant thickness is applied along the central lines and all pixels falling within this area are labeled as channel we then have a simple function that relates the pilot point positions to channel geometry to constrain the geometry of those channels in a simple manner and make the link with the training image we assumed that we could reproduce reasonably well the variability of the channels their shapes and their relative positions using a multigaussian distribution of the position of the traveling pilot points in this manner the prior geological model is fully determined by a set of mean values and a prior covariance matrix to estimate the prior covariance matrix the training image has been cut into many sub images having the same lateral extension as the simulation domain the vertical extension was taken larger in order to account for channels that would enter the domain from the top or the bottom of the domain but not being entirely included in the simulation domain for each sub image the positions of channels are tracked by recording the y coordinate of the channel centerline at fixed intervals along the x axis then the mean y values p for every traveling pilot point and an empirical covariance matrix c p representing the covariance of their position along the y axis is calculated from these recorded y coordinates once the covariance matrix is known the generation of a geological model is obtained by first simulating a random vector p and then applying the procedure described above the realizations of p are obtained using the discrete karhunen loève expansion as shown for example by sarma et al sarma et al 2008 2 p p e s 1 2 ρ in the above equation e is the matrix of the eigenvectors of the covariance matrix c p s is a diagonal matrix containing the eigenvalues of c p and ρ is a vector of uncorrelated random normal variables mean 0 and variance 1 2 3 the traveling pilot points approach in the subsequent paragraphs we present a more detailed description of the methodology let us consider a case where trips are used to parameterize a property e g hydraulic conductivity distribution of a categorical aquifer containing f facies categories let ni represent the number of trips in facies i the location of the j th trip in the i th facies in three dimensional 3d space is represented by xij yij zij the property value associated with the i th facies category is represented by vali for example if the x coordinates are known and the y and z coordinates are to be estimated the vector p which contains all the unknowns locations and category values is represented by eq 3 this equation can be extended modified for other problems with complex geometries 3 p y i j z i j v a l i w h e r e i 1 f a n d j 1 n i the model parameter vector m is then determined by a spatial mapping interpolation operation as shown in eq 4 for example m could represent the hydraulic conductivity field containing typically on the order of several tens of thousands of values which can be categorical while p contains only a few tens of continuous unknowns 4 m z p in the above equation the operator z could represent a spatial interpolation method such as kriging or inverse distance weighted interpolation for example in this paper this operator represents the mapping method illustrated in fig 2 and described in section 2 2 a groundwater flow transport model uses the model parameter field m in conjunction with site specific initial and boundary conditions to produce an output vector d of simulated heads velocities concentrations as represented in eq 5 the operator g in eq 5 an abstraction for the groundwater model acts upon the parameter vector m to produce the output vector d of simulated heads concentrations 5 d g m g z p if the vector d obs represents the measured counterparts to d the measurement objective function m which defines the misfit between the model and the measurements is calculated in eq 6 as 6 m d o b s g m t c d 1 d o b s g m where the t superscript represents the matrix transpose operation and c d 1 is a diagonal matrix with element q ii element in the ith row and ith column containing the weight associated with the ith measurement and equal in this paper to the inverse of the measurement error variance doherty 2010 in eq 6 no consideration was given to the nature of the parameter vector in cases where prior preferred knowledge about the underlying parameter distribution exists it is important to include that information to reduce the ill posedness of the problem tonkin and doherty 2005 we incorporate a plausibility regularization term r in eq 7 to represent the deviation of the parameter set from the prior knowledge about their preferred values 7 r p p i t c p 1 p p i in the above equation the vector p i represents our knowledge about preferred conditions here we take for p i the vector containing the simulated initial differences of the y coordinates of the traveling pilot points obtained from the procedure defined in section 2 2 eq 7 ensures that the traveling pilot points can move around the initial position but in a manner that is compatible with the statistics derived from the analysis of the training image furthermore to better constrain the relative positions of the traveling pilot points we also considered the differences between the values in the regularization term this is implemented by assuming that the differences between the updated and initial parameters should remain small the covariance of the differences can be estimated from the covariance matrix of the parameter values as described in appendix a note that for the sake of keeping the above explanations as simple as possible we did not describe how the covariances and mean parameter values were included in the parameter for the hydraulic conductivities this is done in a straightforward manner by assuming that the parameter values were uncorrelated to the positions the final covariance matrix contains in this case two independent blocks one for the position one for the parameter values finally the global objective function g includes both measurement and parameter misfit 8 g m μ 2 r the above equations represent a technique of regularization that was implemented in the parameter estimation software pest doherty 2010 the factor μ2 is a regularization weight multiplier controlling the parameter misfit and is explicitly estimated during the inversion process the inverse problem in the current context is a constrained minimization problem where the global objective function g is minimized while keeping the channel geometry compatible with our prior knowledge expressed through regularization in summary the overall flowchart for the trips algorithm is presented in fig 3 an initial vector p i is generated using eq 2 this information is then transformed into a model parameter field e g hydraulic conductivity with the aid of the spatial interpolation operator an initial forward model simulation is carried out if the misfit is considered acceptable the parameter estimation is stopped otherwise an optimization method in this paper gradient optimization in the pest software is used to minimize the global objective function g and obtain better values of the trips an updated field of model parameters is created forward model simulation is carried out and the objective function is re evaluated this process is repeated until the optimization objectives are met 3 generating ensembles of realizations in this section we describe three different approaches to generate ensembles of realizations the first approach rejection sampling rs is a simple but computationally expensive approach to sample from the posterior distribution since this approach is capable of handling any kind of prior or posterior distributions it serves as a benchmark for the other approaches which rely at least partly on a multigaussian assumption the second approach null space monte carlo nsmc describes how the trips methodology can be used in conjunction with subspace techniques which are computationally faster the third approach posterior covariance pc also a subspace technique uses an alternate way to calculate the covariance matrix of the posterior and generates an ensemble rapidly the second and third approaches are of interest in this paper as they cannot be applied to categorical inverse problems without using an indirect parameterization such as the one proposed here with trips in summary the trips approach provides a framework for generating a channelized categorical aquifer field from pilot points spaced along the channel centerlines the nsmc and pc methods use subspace techniques to sample the positions of these pilot points and the hydraulic conductivities of the aquifer categories these three approaches are applied and compared in section 5 on a synthetic problem 3 1 rejection sampling rejection sampling rs described in mariethoz et al 2010 tarantola 2005 is a simple but computationally expensive way of sampling the posterior distribution in this method many candidate parameters p are generated by sampling from the prior distribution as described in section 2 2 these parameters are converted into model parameters m forward simulations are carried out and misfit between the modeled and measured counterparts are tabulated an acceptance probability p m defined in eq 9 is calculated for each candidate model based on the ratio of the likelihood function l m f d m to the maximum possible value of the likelihood function l max 9 p m l m l max in this paper l max was determined as the maximum sampled value of the prior ensemble the likelihood function is computed according to eq 10 it expresses the likelihood of a candidate model to reproduce the available data it is inversely proportional to the measurement objective function and directly proportional to the standard deviation of the measurement error σ 10 l m exp m m for each candidate model a random number from the uniform distribution u 0 1 is concurrently generated along with the acceptance probability if the acceptance probability is greater than this random number the candidate model is accepted as a member of the posterior distribution otherwise the candidate model is rejected this method may reject many models and therefore it is not computationally efficient but the ensemble of accepted models represents the posterior distribution in an unbiased manner 3 2 null space monte carlo the second method that we use in this paper is the null space monte carlo nsmc methodology described by tonkin and doherty tonkin and doherty 2008 it is a subspace based pseudo linear method capable of generating an ensemble of parameter realizations that have a reasonable fit with the data by construction the nsmc method is described below the first step is to generate a single model with an acceptable level of misfit between the model and measurements we do this using the gradient based optimization method described in section 2 3 the optimized parameter set from this model is denoted by the vector p c the jacobian matrix x is estimated it contains the partial derivatives of the measured data with respect to the components of the vector p c xij representing the value in row i and column j is calculated as the partial derivative of observation i with respect to parameter j the weighted jacobian matrix x t c d 1 x is computed the matrix c d 1 contains observation weights as defined in section 2 3 this weighted jacobian matrix is decomposed using singular value decomposition tonkin and doherty 2008 as the product of three matrices in eq 11 11 x t c d 1 x us v t u is an orthonormal matrix containing the basis vectors for the range space of the weighted jacobian s is a rectangular diagonal matrix containing eigenvalues of the weighted jacobian matrix v is an orthonormal matrix containing the basis vectors for the parameter solution space and parameter null space if there are n eigenvalues and the partition between the solution and null spaces is drawn after the first r eigenvalues the matrix v from eq 11 can be thought of as v v 1 v 2 where v 2 has n r columns which form the basis vectors for the null space moore et al moore and doherty 2005 present a discussion on the impact of this partition on predictive error variance next we generate multiple parameter vectors by sampling from the prior distribution following the methodology described in section 2 2 these parameter vectors constitute the uncalibrated parameters the difference between each uncalibrated parameter set p u and the calibrated parameter set is computed and projected into the parameter null space by multiplying with the null space projection matrix v 2 v 2 t this projected parameter set will lie in the parameter null space if the model were linear and if the null space was delineated accurately the projected differences are added to the calibrated parameter set to create a new parameter set p u new this process is described by eq 12 where 12 p u new p c v 2 v 2 t p u p c since the model is non linear and there is uncertainty about the partition between the null and solution spaces the parameter set from eq 12 does not often result in a calibrated model hence this parameter set is further updated using pest doherty 2010 until the measurement mismatch is acceptable 3 3 posterior covariance calculation in this method the posterior covariance matrix c is estimated from the prior covariance matrix under the assumption of linearity tarantola 2005 13 c c p c p x t x c p x t c d 1 x c p in eq 13 c p is the prior covariance matrix the second term on the right hand side represents the impact of calibrating the model the term c d represents the covariance of the measurement errors the matrix x represents the jacobian matrix of the calibrated model after calculating c several parameter sets are randomly generated using a random parameter generator as described in section 2 2 if the model were perfectly linear each of these parameter sets would reproduce the observed data an inspection of the likelihood functions revealed that it is not the case hence this parameter set is further updated using pest doherty 2010 until the measurement mismatch is acceptable 4 synthetic problem a synthetic problem derived from mariethoz et al mariethoz et al 2010 is analyzed in this paper a constant discharge pump test is conducted in a square shaped 100m 100m confined aquifer the pumping well extracts 0 003 m3 s from the center of the aquifer the aquifer contains high permeability fluvial channels embedded in a low permeability matrix groundwater flow in the aquifer is two dimensional flowing from left to right a constant head boundary of 1m is located on the left edge and a constant head boundary of 0m is located along the right edge 12 monitoring wells are located around the pumping well the aquifer schematic boundary conditions and well locations are shown in fig 4 aquifer heads are recorded at the pumping and monitoring wells once the system reaches steady state the model representing this synthetic reality is referred to as the reference model the facies distribution was developed following the approach described in section 2 2 we used the training image ti introduced in fig 1 it represents channels and matrix in a 2500m 2500m area a large number 30 000 of sub images were extracted from this ti after visually inspecting a subset of these images it was determined that there are typically three fluvial channels of width 13m in a 100m 100m area the covariance matrix c p of the y coordinates along the channel centerline was estimated according to the methodology described in section 2 2 15 points 5 for each channel were used to track the channels the matrix scatter plot of the y coordinates shown in fig 5 depicts the correlation between the various coordinates in this plot the variables y11 to y15 represent the coordinates of the top channel in a left to right direction the variables y21 to y25 represent the coordinates of the middle channel in a left to right direction and the variables y31 to y35 represent the coordinates of the bottom channel in a left to right direction the off diagonal plots show the scatter between two coordinates and the diagonal plots show the histogram of a single coordinate the plot shows that each point is strongly correlated with its neighbors along the same channel and weakly correlated with points in the other channels the discrete karhunen loève expansion expressed in eq 2 was then used to generate 100 000 parameter realizations based on c p for each realization three cubic b splines 27 were used to connect the channel coordinates a buffer of width 6 5m around each of the splines was created to represent a channel of 13m width these channels were overlaid on the model grid and model cells fully covered by the channels were assigned a hydraulic conductivity value randomly generated within a lognormal distribution with mean 2 log10 m s and standard deviation 0 1 log10 m s the remaining cells were assumed to be a part of the matrix and were assigned a hydraulic conductivity randomly generated based on a lognormal distribution with a mean 4 log10 m s standard deviation 0 1 log10 m s a realization was randomly selected to represent the synthetic reality for this selected realization the hydraulic conductivity values of the channel and matrix were 8 7 10 3 m s and 1 1 10 4 m s respectively reference head observations were obtained in the following manner steady state groundwater flow was simulated for the aquifer described above using the usgs modflow nwt simulator niswonger et al 2011 the facies distribution and the head distribution of the reference model are shown in fig 6 the calculated head distribution was sampled at the thirteen 13 observation wells normally distributed random noise mean 0 m standard deviation 0 05 m was added to the sampled heads to simulate measurement error these 13 adjusted heads constituted the reference head measurements 5 results in this section we generate an ensemble of conditional parameter realizations for the synthetic problem using the various methods described in section 3 rs nsmc and pc for each ensemble the cell by cell probability of finding a channel in the model domain mean ensemble head distribution and standard deviation of the simulated head distribution were calculated 5 1 rejection sampling a large set of parameter fields were generated based on the prior covariance matrix described in section 4 forward simulations were undertaken for each of these simulations and the results evaluated under the rejection sampling methodology described in section 3 1 we could obtain 100 models in the posterior distribution by evaluating 100 050 models six of these models were randomly selected and the hydraulic conductivity distributions and the corresponding fits between observed and simulated heads are presented in fig 7 these models demonstrate that several channel hydraulic conductivity distributions can result in reasonable matches to the measurements five of the six realizations have three channels whereas one realization has only two channels 5 2 nsmc method the first step to sample a posterior distribution using the nsmc methods is to obtain a model corresponding to a maximum value of the likelihood section 3 2 here we describe how this model was obtained a parameter set was first randomly generated from the prior covariance matrix c p with the measurement and regularization constraints parameter estimation was carried out by maximizing the likelihood function the optimization was stopped when the modeled heads were considered acceptable facies distribution head contours measured vs simulated heads for the initial two intermediate models and the calibrated model are presented in fig 8 this figure illustrates how the likelihood function increases as the central channel moves closer to the location of the pumping well blue circle enclosing a red cross a total of 484 groundwater flow model evaluations were required during this optimization to evaluate the misfit and the jacobian the resulting model is then used as the starting step for generating the ensemble the nsmc methodology described in section 3 2 was used to generate 100 realizations the computational cost for obtaining this ensemble was 12 754 forward model evaluations six of these models were randomly selected and the hydraulic conductivity distributions and the corresponding fits between observed and simulated heads are presented in fig 9 all the six realizations have three channels with the central channel exhibiting more curvature than the top bottom channels 5 3 pc posterior ensembles the pc methodology described in section 3 3 was used to generate another ensemble consisting of 100 realizations this method is much more computationally efficient since we generated 100 models with only 505 forward model evaluations six of these models were randomly selected and the hydraulic conductivity distributions and the corresponding fits between observed and simulated heads are presented in fig 10 all the six realizations have three channels 5 4 comparison of posterior ensembles the characteristics of the parameter ensembles obtained using the various methods are presented in fig 11 information is presented in a grid with four rows and four columns each row represents the characteristics of a parameter ensemble in the first column of each row cell by cell probabilities of finding a channel for that ensemble are depicted reddish colors imply a higher probability of finding a channel and bluish colors imply a lower probability the probabilities for the prior distribution first row are low everywhere when the head data are not accounted for the proposed geological model can place the channels anywhere in the domain in a uniform manner all the methods that are conditioned by the head data show that they can locate the presence of a channel at the location of the pumping well with a high probability they also indicate a high probability to find matrix above and below the pumping well as well as 2 other channels in the top and bottom of the field however there are some differences in the values of the probabilities when moving away from the location of the pumping well the ensemble obtained with rs is unbiased and considered as the reference in this experiment the rs and the nsmc ensembles exhibit more similarities than rs and pc the pc method shows higher values for the probabilities than the rs and nsmc methods it means that the subspace methods did not capture the complete variability of the posterior ensemble they are much more efficiently numerically but this comes at the cost of an underestimation of the uncertainty some channel configurations that can reproduce the data and belong to the prior geological model are not identified in that case histograms for the log transformed hydraulic conductivities presented in the second column exhibit a bimodal distribution the channel hydraulic conductivities are shown in red and the matrix hydraulic conductivities are in blue the hydraulic conductivities of the reference model are shown as black dots on the histogram the matrix hydraulic conductivities vary more than their channel counterparts as with the ensemble probability the pc method has narrower histograms implying a lack of variability we also see on these graphs that all methods identify properly the hydraulic conductivity of the channels while the matrix conductivity may be overestimated as compared to the reference by the nsmc and pc methods a possible reason for this overestimation could be to compensate for deviations from the geometry in the reference field for maintaining the observed gradients mean and standard deviation of the ensemble head distributions are in the third and fourth columns the prior mean and variance are showing symmetry around the pumping well the uncertainty on the head value is high as shown by the high values of the standard deviation the effect of conditioning to the head values reduces significantly the uncertainty for the three ensembles the ensemble mean head from the nsmc method resembles the ensemble mean head from the rs method and the head from the reference model fig 6 the mean head estimated with the pc ensemble does not show as clearly as the two other methods the shift of the cone of depression toward the bottom of the image furthermore in terms of standard deviation and uncertainty estimation the pc method has a very low ensemble standard deviation lending further credence to the lack of variability in realizations as compared to the reference method rs the nsmc is closer to it but still underestimates the variability especially in the upper part of the domain 6 summary and discussion in this paper we propose a new approach involving traveling pilot points trips and linear subspace methods to solve the categorical inverse problem in a probabilistic framework we summarize some of the main findings below the first key proposition that we make in this paper is in letting pilot points travel and estimating both the locations of the channels and associated properties like hydraulic conductivity we then propose to estimate the prior covariance matrix of the position of the pilot points from a training image the advantage of that approach is in its simplicity the user can provide an image of the type of channels that they want to model and the covariance will be inferred directly if the training image is too small it is possible to use a multiple point statistics simulation algorithm and generate an ensemble of simulations and derive the covariance matrix from the analysis of this simulation in the same manner as we analyze the sub images in this work in addition we use first order difference regularization constraints to preserve the curvature of the channels in the inversion process the proposed trips parametrization was integrated in an optimization framework based on linear subspace methods allowing to obtain solutions of the categorical inverse problem for a synthetic aquifer a posterior ensemble obtained with the rejection sampling method was considered to represent the reference solution and compared against the null space monte carlo nsmc and posterior covariance pc ensembles the comparisons indicate that these parameter ensembles exhibit similarities with the reference distribution the pc method was much more efficient in estimating members of the posterior ensemble however the variability was underestimated fig 11 bottom row the nsmc method was comparably slower because more model evaluations were required however the ensemble probability estimated by this method is closer to the ensemble from rs the nsmc method provides a balance between computational efficiency and representation of the posterior ensemble the number of model evaluations required by the nsmc method were comparable to stochastic approaches like isr mariethoz et al 2010 and popex jaggli et al 2017 while the pc method is much faster overall we believe the trips methodology to be a promising entrant in the field of categorical inversion while the example problem presented in this paper considers only two dimensional channels traversing the domain the methodology can be extended to real world three dimensional datasets with a larger number of facies and more complex geometries for example the trips method could be used to estimate the complex channel framework at a real site such as the one discussed by ronayne et al ronayne et al 2008 for this case the pilot points would represent the positions of channels in three dimensions and three dimensional splines passing through the pilot points could be used to delineate the channels more generally the extension of the proposed methodology is straightforward for all object oriented geological modeling techniques pyrcz and deutsch 2014 since the positions of the objects are controlled in these models by seed points which can be considered as traveling pilot points the prior statistics on the number of objects and relative locations of these points can be derived from a set of initial simulations the proposed algorithm described could then be used to update these locations and solve the inverse problem the shape parameters concerning the three dimensional size and orientation of the objects can be handled as well easily since these are continuous parameters that an inversion code like pest can optimize this step would be analogous to the identification of the hydraulic conductivity values within the channels as illustrated in the example treated in this paper for objects having a flexible shape such as channels with varying width traditional techniques such as the standard pilot points can be coupled with trips one can attach a width parameter to every traveling pilot point and interpolate the width along the channel length and update these parameters during the inversion the trips method could also be used with pixel based geostatistical methods such as plurigaussian or mps simulations pyrcz and deutsch 2014 starting from one or a set of initial realizations we could extract a set of conditioning locations and the corresponding categories from the realization trips would then proceed by moving the locations of these points keeping the value of the categories and simulating again the complete field using these new conditioning data as input in the geostatistical algorithm in this last case developing the appropriate parameter covariance matrix remains a challenge considering the subspace methods tested in this paper one aspect which works to their favor is the large null space as the size of the null space increases trips nsmc methods could prove to be computationally parsimonious in comparison with other methods we have shown in this paper on a simple synthetic problem that the gain in numerical efficiency comes at the cost of an underestimation of the overall uncertainty credit authorship contribution statement prashanth khambhammettu conceptualization methodology software visualization validation writing original draft writing review editing philippe renard conceptualization methodology supervision validation writing review editing john doherty conceptualization methodology supervision validation writing review editing declaration of competing interests the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors the authors wish to thank the editor and the three anonymous reviewers whose comments contributed to an improved version of this paper the authors are also thankful to vivek bedekar julien straubhaar and christoph jäggli for reviewing and commenting upon early drafts of this manuscript the data and codes used to generate results for this paper can be obtained from the corresponding author prashanth khambhammettu arcadis com supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103556 appendix b supplementary materials image application 1 appendix a a 1 calculation of a covariance matrix for parameter differences given the covariance matrix c for a parameter vector p calculation of the covariance matrix c p for the parameter difference vector p is described in this section with an example if the parameter vector p had three parameters y1 y2 and y3 the parameter difference vector p would have the differences y1 y2 y1 y3 and y1 y2 in matrix form this relationship can be expressed by the equation 1 y 1 y 2 y 1 y 3 y 2 y 3 1 1 0 1 0 1 0 1 1 y 1 y 2 y 3 the above equation could be generalized for an arbitrary number of parameters parameter differences by the equation 2 p ap if we have y ax aster et al aster et al 2013 state that the covariance matrix of y c y can be calculated by the equation 3 c y ac x a t combining eqs 2 and 3 the covariance matrix for the parameter difference vector can be calculated by the equation 4 c p ac p a t 
506,categorical parameter distributions are common place in hydrogeological systems consisting of geologic facies categories with distinct properties e g high permeability channels embedded in a low permeability matrix parameter estimation is difficult in such systems because the discontinuities in the parameter space hinder the inverse problem previous research in this area has been focused on the use of stochastic methods in this paper we present a novel approach based on traveling pilot points trips combined with subspace parameter estimation methods to generate realistic categorical parameter distributions that honor calibration constraints e g measured water levels in traditional implementations aquifer properties e g hydraulic conductivity are estimated at fixed pilot point locations in the trips implementation both the properties associated with the pilot points and their locations are estimated tikhonov regularization constraints are incorporated in the parameter estimation process to produce realistic parameter depictions for a synthetic aquifer system we solved the categorical inverse problem by combining the trips methodology with two subspace methods null space monte carlo nsmc and posterior covariance pc a posterior ensemble developed with the rejection sampling rs method is compared against the trips ensembles the comparisons indicated similarities between the various ensembles and to the reference parameter distribution between the two subspace methods the nsmc method produced an ensemble with more variability than the pc method these preliminary results suggest that the trips methodology has promise and could be tested on more complicated problems keywords inverse problem categorical inversion traveling pilot points multiple point statistics null space monte carlo linear sub space methods 1 introduction groundwater flow and contaminant transport models are commonly used to answer questions pertaining for example to groundwater management and contaminant migration these models solve the forward problem to answer the question under investigation the forward problem involves model parameterization followed by solving a partial differential equation to obtain a state vector d representing for example the groundwater head or contaminant concentration in response to specified boundary conditions the inverse problem on the other hand involves identifying the model parameter vector m from the state vector d inverse problems in the groundwater modeling context have been studied extensively zhou et al zhou et al 2014 present a recent detailed discussion of the groundwater inversion problem and a review of historical and modern methods the probabilistic formulation of the inverse problem see for example aster et al aster et al 2013 can be expressed in terms of conditional probabilities as shown in eq 1 1 q m d f d m p m c the term q m d is the posterior probability density function and represents the probability of occurrence of a parameter vector conditioned by the observed measured dataset the term p m is known as the prior and represents the probability of occurrence of any model based only on the initial information such as geological knowledge without considering the measurements of the state variables d the term f d m known as the likelihood represents the probability of simulating the measured data d given a model vector m the categorical inverse problem is a special case of the groundwater inverse problem pertaining to aquifers that consist of discrete geological facies categories for example consider a two categories aquifer with fluvial high permeability channels incised in a low permeability matrix at any location in this aquifer we would find only one of the two facies channel or matrix the inverse problem in this case requires us to generate categorical aquifer distributions when presented with prior geologic information about borehole logs static data and measurements of aquifer state e g groundwater heads categorical problems are often more challenging to solve than their continuous counterparts because the parameter space is discontinuous linde et al linde et al 2015 presented an extensive review of existing methods for this class of problems we summarize a few of them here the gradual deformation method gdm formulated by hu et al hu et al 2001 hu 2000 generates a sequence of model realizations that converge to matching the measured data the key underlying concept in gdm is that the linear combinations of multigaussian fields are also multigaussian fields with similar statistics it is therefore possible to explore a part of the model space by adjusting only one single parameter a weight allowing to move between two pre computed simulations if the categorical field is obtained by truncation of one or several multi gaussian realizations this process is straightforward and obtaining a discrete model that matches the measured observations can be treated as a usual continuous optimization problem caers and hoffman caers and hoffman 2006 proposed the probability perturbation method ppm when dealing with non gaussian priors and non linear forward model responses rather than computing the posterior from the prior and likelihood they instead decompose the posterior into a set of pre posterior distributions containing facies and measurement data respectively these pre posterior probability distributions are perturbed until newer model realizations in the sequence increasingly converge to matching measurements ronayne et al ronayne et al 2008 applied the ppm to a transient aquifer test model and generated a distribution of permeable discrete channels embedded within less permeable deposits alcolea and renard alcolea and renard 2010 and hansen et al hansen et al 2012 used an iterative blocking moving window algorithm in conjunction with simulated annealing or a markov chain based method to guide a multiple point statistics mps model in reproducing state variables and honor facies data known from prior knowledge mariethoz et al mariethoz et al 2010 proposed the iterative spatial resampling isr technique a markov chain based method to sample from the posterior distribution the transition from one element to the next in the markov chain is based on sampling the values of the previous field at a set of random locations and using these points as conditioning data for the next iteration while this procedure is straightforward and samples the posterior space in an unbiased manner it is rather time consuming jäggli et al jaggli et al 2017 proposed a faster approach named posterior population expansion popex expanding an initial ensemble of parameter models using mps and local conditioning in such a manner that the new models are likely to belong to the posterior population the popex approach was subsequently modified jäggli et al 2018 to overcome predictive biases by combining machine learning techniques with an adaptive importance sampling strategy several approaches to solve the categorical inverse problem based on pilot points have also been presented pilot points have been used to estimate heterogeneous hydrogeological parameter distributions for several decades certes and de marsily 1991 lavenue and de marsily 2001 doherty 2003 doherty et al doherty et al 2010 define pilot points as surrogate parameters in the inverse modeling process for representing heterogeneity in a lower dimensional space in these applications a location specific hydrogeological attribute e g porosity hydraulic conductivity is associated with the pilot point a pre determined number of pilot points are placed at strategic locations along the model domain to capture the heterogeneity in the system an iteration of the forward problem involves estimation of properties associated with each pilot point followed by spatial interpolation to create a spatially continuous parameter distribution from the discrete pilot point locations the inverse problem involves the estimation of parameter values at the pilot point locations that honor the calibration constraints over the course of the parameter estimation the locations of the pilot points remain static but the parameters associated with the pilot points change in the context of categorical fields li et al li et al 2003 used pilot points to guide an ensemble kalman filter approach to match dynamic head and geologic data simultaneously in this paper we develop and test a new approach where pilot points are used in conjunction with linear subspace methods tonkin and doherty 2008 to solve the categorical inverse problem the primary motivation here is that linear subspace methods are computationally inexpensive and their application in the estimation of continuous real world parameter fields has been well documented keating et al 2010 herckenrath et al 2011 we explore if these same approaches could be used to estimate discrete categorical parameter fields in our approach we use pilot points in a non traditional manner that we refer to as the traveling pilot points trips approach rather than using pilot points for spatial interpolation we iteratively adapt their positions to define the geometries of the discrete categories in our opinion there are two advantages to this approach first by using the positions of the pilot points the categorical problem has been restated as a problem with continuous parameters which is easier to solve second this approach allows us to infer the category geometries rather than to estimate them from spatial interpolation operations such as kriging indirectly the methodology described in this paper has only been tested so far on a synthetic problem with two categories and saturated two dimensional groundwater flow the technique might require additional modifications for more complex problems with multiple facies the subsequent sections of this paper are organized as follows in section 2 we present an overview of the trips method and its applicability in the context of generating categorical parameter distributions in section 3 we present an overview of the various sampling methods used in section 5 in section 4 we present a synthetic groundwater problem with a categorical parameter distribution in section 5 we use the trips approach to develop multiple likely parameter realizations for the synthetic problem finally we present a summary of our findings in section 6 2 trips methodology in section 2 1 we introduce the principle and present the details of the implementation of traveling pilot points trips to solve the categorical inverse problem in contrast to traditional pilot points trips are not fixed in location but instead can travel to locations of interest in the model domain 2 1 the traveling pilot points principle let us consider an aquifer containing permeable channels embedded within an impermeable matrix it is possible to generate such discrete geological fields with different geostatistical techniques one could use for example transition probabilities tprogs plurigaussian simulations object based models or multiple point statistics to model these structures for all these techniques it is possible to set a fixed number of locations where the type of geology is known for example presence of a channel but the locations themselves are unknown providing these locations as conditioning data to the geological simulation algorithm allows to change the parameterization of the geological simulation and to solve the inverse problem in this manner means to search for the optimal locations of these traveling pilot points this approach modifies a discrete inverse problem into a continuous one and should therefore facilitate its resolution this idea is very general and can have many applications 2 2 an example of geological model to test this idea in a simple situation we consider a binary case with channels as illustrated in fig 1 to constrain the geometry of the channels in a simple manner we use a two step approach based on object based simulations constrained by a training image on the one hand the training image fig 1 provides in a graphical manner the size of the channels their sinuosity their spacing and so on this image can be drawn by hand based on a geological concept it offers flexibility and simplicity on the other hand the object based model ensures that all the channels are continuous and that the geological models are generated very rapidly for the object based model we consider that there is a fixed number of channels crossing the area from left to right fig 2 for each channel we define a fixed number of traveling pilot points for example for a channel spanning an x distance of 100m we can characterize it by 5 points spaced 20m apart if the aquifer domain is 100 m 100 m with a typical distribution of 3 channels 15 points are used to track all the channels to simulate the entire domain the channel central lines are interpolated with a spline function using the position of the traveling pilot points as input then a constant thickness is applied along the central lines and all pixels falling within this area are labeled as channel we then have a simple function that relates the pilot point positions to channel geometry to constrain the geometry of those channels in a simple manner and make the link with the training image we assumed that we could reproduce reasonably well the variability of the channels their shapes and their relative positions using a multigaussian distribution of the position of the traveling pilot points in this manner the prior geological model is fully determined by a set of mean values and a prior covariance matrix to estimate the prior covariance matrix the training image has been cut into many sub images having the same lateral extension as the simulation domain the vertical extension was taken larger in order to account for channels that would enter the domain from the top or the bottom of the domain but not being entirely included in the simulation domain for each sub image the positions of channels are tracked by recording the y coordinate of the channel centerline at fixed intervals along the x axis then the mean y values p for every traveling pilot point and an empirical covariance matrix c p representing the covariance of their position along the y axis is calculated from these recorded y coordinates once the covariance matrix is known the generation of a geological model is obtained by first simulating a random vector p and then applying the procedure described above the realizations of p are obtained using the discrete karhunen loève expansion as shown for example by sarma et al sarma et al 2008 2 p p e s 1 2 ρ in the above equation e is the matrix of the eigenvectors of the covariance matrix c p s is a diagonal matrix containing the eigenvalues of c p and ρ is a vector of uncorrelated random normal variables mean 0 and variance 1 2 3 the traveling pilot points approach in the subsequent paragraphs we present a more detailed description of the methodology let us consider a case where trips are used to parameterize a property e g hydraulic conductivity distribution of a categorical aquifer containing f facies categories let ni represent the number of trips in facies i the location of the j th trip in the i th facies in three dimensional 3d space is represented by xij yij zij the property value associated with the i th facies category is represented by vali for example if the x coordinates are known and the y and z coordinates are to be estimated the vector p which contains all the unknowns locations and category values is represented by eq 3 this equation can be extended modified for other problems with complex geometries 3 p y i j z i j v a l i w h e r e i 1 f a n d j 1 n i the model parameter vector m is then determined by a spatial mapping interpolation operation as shown in eq 4 for example m could represent the hydraulic conductivity field containing typically on the order of several tens of thousands of values which can be categorical while p contains only a few tens of continuous unknowns 4 m z p in the above equation the operator z could represent a spatial interpolation method such as kriging or inverse distance weighted interpolation for example in this paper this operator represents the mapping method illustrated in fig 2 and described in section 2 2 a groundwater flow transport model uses the model parameter field m in conjunction with site specific initial and boundary conditions to produce an output vector d of simulated heads velocities concentrations as represented in eq 5 the operator g in eq 5 an abstraction for the groundwater model acts upon the parameter vector m to produce the output vector d of simulated heads concentrations 5 d g m g z p if the vector d obs represents the measured counterparts to d the measurement objective function m which defines the misfit between the model and the measurements is calculated in eq 6 as 6 m d o b s g m t c d 1 d o b s g m where the t superscript represents the matrix transpose operation and c d 1 is a diagonal matrix with element q ii element in the ith row and ith column containing the weight associated with the ith measurement and equal in this paper to the inverse of the measurement error variance doherty 2010 in eq 6 no consideration was given to the nature of the parameter vector in cases where prior preferred knowledge about the underlying parameter distribution exists it is important to include that information to reduce the ill posedness of the problem tonkin and doherty 2005 we incorporate a plausibility regularization term r in eq 7 to represent the deviation of the parameter set from the prior knowledge about their preferred values 7 r p p i t c p 1 p p i in the above equation the vector p i represents our knowledge about preferred conditions here we take for p i the vector containing the simulated initial differences of the y coordinates of the traveling pilot points obtained from the procedure defined in section 2 2 eq 7 ensures that the traveling pilot points can move around the initial position but in a manner that is compatible with the statistics derived from the analysis of the training image furthermore to better constrain the relative positions of the traveling pilot points we also considered the differences between the values in the regularization term this is implemented by assuming that the differences between the updated and initial parameters should remain small the covariance of the differences can be estimated from the covariance matrix of the parameter values as described in appendix a note that for the sake of keeping the above explanations as simple as possible we did not describe how the covariances and mean parameter values were included in the parameter for the hydraulic conductivities this is done in a straightforward manner by assuming that the parameter values were uncorrelated to the positions the final covariance matrix contains in this case two independent blocks one for the position one for the parameter values finally the global objective function g includes both measurement and parameter misfit 8 g m μ 2 r the above equations represent a technique of regularization that was implemented in the parameter estimation software pest doherty 2010 the factor μ2 is a regularization weight multiplier controlling the parameter misfit and is explicitly estimated during the inversion process the inverse problem in the current context is a constrained minimization problem where the global objective function g is minimized while keeping the channel geometry compatible with our prior knowledge expressed through regularization in summary the overall flowchart for the trips algorithm is presented in fig 3 an initial vector p i is generated using eq 2 this information is then transformed into a model parameter field e g hydraulic conductivity with the aid of the spatial interpolation operator an initial forward model simulation is carried out if the misfit is considered acceptable the parameter estimation is stopped otherwise an optimization method in this paper gradient optimization in the pest software is used to minimize the global objective function g and obtain better values of the trips an updated field of model parameters is created forward model simulation is carried out and the objective function is re evaluated this process is repeated until the optimization objectives are met 3 generating ensembles of realizations in this section we describe three different approaches to generate ensembles of realizations the first approach rejection sampling rs is a simple but computationally expensive approach to sample from the posterior distribution since this approach is capable of handling any kind of prior or posterior distributions it serves as a benchmark for the other approaches which rely at least partly on a multigaussian assumption the second approach null space monte carlo nsmc describes how the trips methodology can be used in conjunction with subspace techniques which are computationally faster the third approach posterior covariance pc also a subspace technique uses an alternate way to calculate the covariance matrix of the posterior and generates an ensemble rapidly the second and third approaches are of interest in this paper as they cannot be applied to categorical inverse problems without using an indirect parameterization such as the one proposed here with trips in summary the trips approach provides a framework for generating a channelized categorical aquifer field from pilot points spaced along the channel centerlines the nsmc and pc methods use subspace techniques to sample the positions of these pilot points and the hydraulic conductivities of the aquifer categories these three approaches are applied and compared in section 5 on a synthetic problem 3 1 rejection sampling rejection sampling rs described in mariethoz et al 2010 tarantola 2005 is a simple but computationally expensive way of sampling the posterior distribution in this method many candidate parameters p are generated by sampling from the prior distribution as described in section 2 2 these parameters are converted into model parameters m forward simulations are carried out and misfit between the modeled and measured counterparts are tabulated an acceptance probability p m defined in eq 9 is calculated for each candidate model based on the ratio of the likelihood function l m f d m to the maximum possible value of the likelihood function l max 9 p m l m l max in this paper l max was determined as the maximum sampled value of the prior ensemble the likelihood function is computed according to eq 10 it expresses the likelihood of a candidate model to reproduce the available data it is inversely proportional to the measurement objective function and directly proportional to the standard deviation of the measurement error σ 10 l m exp m m for each candidate model a random number from the uniform distribution u 0 1 is concurrently generated along with the acceptance probability if the acceptance probability is greater than this random number the candidate model is accepted as a member of the posterior distribution otherwise the candidate model is rejected this method may reject many models and therefore it is not computationally efficient but the ensemble of accepted models represents the posterior distribution in an unbiased manner 3 2 null space monte carlo the second method that we use in this paper is the null space monte carlo nsmc methodology described by tonkin and doherty tonkin and doherty 2008 it is a subspace based pseudo linear method capable of generating an ensemble of parameter realizations that have a reasonable fit with the data by construction the nsmc method is described below the first step is to generate a single model with an acceptable level of misfit between the model and measurements we do this using the gradient based optimization method described in section 2 3 the optimized parameter set from this model is denoted by the vector p c the jacobian matrix x is estimated it contains the partial derivatives of the measured data with respect to the components of the vector p c xij representing the value in row i and column j is calculated as the partial derivative of observation i with respect to parameter j the weighted jacobian matrix x t c d 1 x is computed the matrix c d 1 contains observation weights as defined in section 2 3 this weighted jacobian matrix is decomposed using singular value decomposition tonkin and doherty 2008 as the product of three matrices in eq 11 11 x t c d 1 x us v t u is an orthonormal matrix containing the basis vectors for the range space of the weighted jacobian s is a rectangular diagonal matrix containing eigenvalues of the weighted jacobian matrix v is an orthonormal matrix containing the basis vectors for the parameter solution space and parameter null space if there are n eigenvalues and the partition between the solution and null spaces is drawn after the first r eigenvalues the matrix v from eq 11 can be thought of as v v 1 v 2 where v 2 has n r columns which form the basis vectors for the null space moore et al moore and doherty 2005 present a discussion on the impact of this partition on predictive error variance next we generate multiple parameter vectors by sampling from the prior distribution following the methodology described in section 2 2 these parameter vectors constitute the uncalibrated parameters the difference between each uncalibrated parameter set p u and the calibrated parameter set is computed and projected into the parameter null space by multiplying with the null space projection matrix v 2 v 2 t this projected parameter set will lie in the parameter null space if the model were linear and if the null space was delineated accurately the projected differences are added to the calibrated parameter set to create a new parameter set p u new this process is described by eq 12 where 12 p u new p c v 2 v 2 t p u p c since the model is non linear and there is uncertainty about the partition between the null and solution spaces the parameter set from eq 12 does not often result in a calibrated model hence this parameter set is further updated using pest doherty 2010 until the measurement mismatch is acceptable 3 3 posterior covariance calculation in this method the posterior covariance matrix c is estimated from the prior covariance matrix under the assumption of linearity tarantola 2005 13 c c p c p x t x c p x t c d 1 x c p in eq 13 c p is the prior covariance matrix the second term on the right hand side represents the impact of calibrating the model the term c d represents the covariance of the measurement errors the matrix x represents the jacobian matrix of the calibrated model after calculating c several parameter sets are randomly generated using a random parameter generator as described in section 2 2 if the model were perfectly linear each of these parameter sets would reproduce the observed data an inspection of the likelihood functions revealed that it is not the case hence this parameter set is further updated using pest doherty 2010 until the measurement mismatch is acceptable 4 synthetic problem a synthetic problem derived from mariethoz et al mariethoz et al 2010 is analyzed in this paper a constant discharge pump test is conducted in a square shaped 100m 100m confined aquifer the pumping well extracts 0 003 m3 s from the center of the aquifer the aquifer contains high permeability fluvial channels embedded in a low permeability matrix groundwater flow in the aquifer is two dimensional flowing from left to right a constant head boundary of 1m is located on the left edge and a constant head boundary of 0m is located along the right edge 12 monitoring wells are located around the pumping well the aquifer schematic boundary conditions and well locations are shown in fig 4 aquifer heads are recorded at the pumping and monitoring wells once the system reaches steady state the model representing this synthetic reality is referred to as the reference model the facies distribution was developed following the approach described in section 2 2 we used the training image ti introduced in fig 1 it represents channels and matrix in a 2500m 2500m area a large number 30 000 of sub images were extracted from this ti after visually inspecting a subset of these images it was determined that there are typically three fluvial channels of width 13m in a 100m 100m area the covariance matrix c p of the y coordinates along the channel centerline was estimated according to the methodology described in section 2 2 15 points 5 for each channel were used to track the channels the matrix scatter plot of the y coordinates shown in fig 5 depicts the correlation between the various coordinates in this plot the variables y11 to y15 represent the coordinates of the top channel in a left to right direction the variables y21 to y25 represent the coordinates of the middle channel in a left to right direction and the variables y31 to y35 represent the coordinates of the bottom channel in a left to right direction the off diagonal plots show the scatter between two coordinates and the diagonal plots show the histogram of a single coordinate the plot shows that each point is strongly correlated with its neighbors along the same channel and weakly correlated with points in the other channels the discrete karhunen loève expansion expressed in eq 2 was then used to generate 100 000 parameter realizations based on c p for each realization three cubic b splines 27 were used to connect the channel coordinates a buffer of width 6 5m around each of the splines was created to represent a channel of 13m width these channels were overlaid on the model grid and model cells fully covered by the channels were assigned a hydraulic conductivity value randomly generated within a lognormal distribution with mean 2 log10 m s and standard deviation 0 1 log10 m s the remaining cells were assumed to be a part of the matrix and were assigned a hydraulic conductivity randomly generated based on a lognormal distribution with a mean 4 log10 m s standard deviation 0 1 log10 m s a realization was randomly selected to represent the synthetic reality for this selected realization the hydraulic conductivity values of the channel and matrix were 8 7 10 3 m s and 1 1 10 4 m s respectively reference head observations were obtained in the following manner steady state groundwater flow was simulated for the aquifer described above using the usgs modflow nwt simulator niswonger et al 2011 the facies distribution and the head distribution of the reference model are shown in fig 6 the calculated head distribution was sampled at the thirteen 13 observation wells normally distributed random noise mean 0 m standard deviation 0 05 m was added to the sampled heads to simulate measurement error these 13 adjusted heads constituted the reference head measurements 5 results in this section we generate an ensemble of conditional parameter realizations for the synthetic problem using the various methods described in section 3 rs nsmc and pc for each ensemble the cell by cell probability of finding a channel in the model domain mean ensemble head distribution and standard deviation of the simulated head distribution were calculated 5 1 rejection sampling a large set of parameter fields were generated based on the prior covariance matrix described in section 4 forward simulations were undertaken for each of these simulations and the results evaluated under the rejection sampling methodology described in section 3 1 we could obtain 100 models in the posterior distribution by evaluating 100 050 models six of these models were randomly selected and the hydraulic conductivity distributions and the corresponding fits between observed and simulated heads are presented in fig 7 these models demonstrate that several channel hydraulic conductivity distributions can result in reasonable matches to the measurements five of the six realizations have three channels whereas one realization has only two channels 5 2 nsmc method the first step to sample a posterior distribution using the nsmc methods is to obtain a model corresponding to a maximum value of the likelihood section 3 2 here we describe how this model was obtained a parameter set was first randomly generated from the prior covariance matrix c p with the measurement and regularization constraints parameter estimation was carried out by maximizing the likelihood function the optimization was stopped when the modeled heads were considered acceptable facies distribution head contours measured vs simulated heads for the initial two intermediate models and the calibrated model are presented in fig 8 this figure illustrates how the likelihood function increases as the central channel moves closer to the location of the pumping well blue circle enclosing a red cross a total of 484 groundwater flow model evaluations were required during this optimization to evaluate the misfit and the jacobian the resulting model is then used as the starting step for generating the ensemble the nsmc methodology described in section 3 2 was used to generate 100 realizations the computational cost for obtaining this ensemble was 12 754 forward model evaluations six of these models were randomly selected and the hydraulic conductivity distributions and the corresponding fits between observed and simulated heads are presented in fig 9 all the six realizations have three channels with the central channel exhibiting more curvature than the top bottom channels 5 3 pc posterior ensembles the pc methodology described in section 3 3 was used to generate another ensemble consisting of 100 realizations this method is much more computationally efficient since we generated 100 models with only 505 forward model evaluations six of these models were randomly selected and the hydraulic conductivity distributions and the corresponding fits between observed and simulated heads are presented in fig 10 all the six realizations have three channels 5 4 comparison of posterior ensembles the characteristics of the parameter ensembles obtained using the various methods are presented in fig 11 information is presented in a grid with four rows and four columns each row represents the characteristics of a parameter ensemble in the first column of each row cell by cell probabilities of finding a channel for that ensemble are depicted reddish colors imply a higher probability of finding a channel and bluish colors imply a lower probability the probabilities for the prior distribution first row are low everywhere when the head data are not accounted for the proposed geological model can place the channels anywhere in the domain in a uniform manner all the methods that are conditioned by the head data show that they can locate the presence of a channel at the location of the pumping well with a high probability they also indicate a high probability to find matrix above and below the pumping well as well as 2 other channels in the top and bottom of the field however there are some differences in the values of the probabilities when moving away from the location of the pumping well the ensemble obtained with rs is unbiased and considered as the reference in this experiment the rs and the nsmc ensembles exhibit more similarities than rs and pc the pc method shows higher values for the probabilities than the rs and nsmc methods it means that the subspace methods did not capture the complete variability of the posterior ensemble they are much more efficiently numerically but this comes at the cost of an underestimation of the uncertainty some channel configurations that can reproduce the data and belong to the prior geological model are not identified in that case histograms for the log transformed hydraulic conductivities presented in the second column exhibit a bimodal distribution the channel hydraulic conductivities are shown in red and the matrix hydraulic conductivities are in blue the hydraulic conductivities of the reference model are shown as black dots on the histogram the matrix hydraulic conductivities vary more than their channel counterparts as with the ensemble probability the pc method has narrower histograms implying a lack of variability we also see on these graphs that all methods identify properly the hydraulic conductivity of the channels while the matrix conductivity may be overestimated as compared to the reference by the nsmc and pc methods a possible reason for this overestimation could be to compensate for deviations from the geometry in the reference field for maintaining the observed gradients mean and standard deviation of the ensemble head distributions are in the third and fourth columns the prior mean and variance are showing symmetry around the pumping well the uncertainty on the head value is high as shown by the high values of the standard deviation the effect of conditioning to the head values reduces significantly the uncertainty for the three ensembles the ensemble mean head from the nsmc method resembles the ensemble mean head from the rs method and the head from the reference model fig 6 the mean head estimated with the pc ensemble does not show as clearly as the two other methods the shift of the cone of depression toward the bottom of the image furthermore in terms of standard deviation and uncertainty estimation the pc method has a very low ensemble standard deviation lending further credence to the lack of variability in realizations as compared to the reference method rs the nsmc is closer to it but still underestimates the variability especially in the upper part of the domain 6 summary and discussion in this paper we propose a new approach involving traveling pilot points trips and linear subspace methods to solve the categorical inverse problem in a probabilistic framework we summarize some of the main findings below the first key proposition that we make in this paper is in letting pilot points travel and estimating both the locations of the channels and associated properties like hydraulic conductivity we then propose to estimate the prior covariance matrix of the position of the pilot points from a training image the advantage of that approach is in its simplicity the user can provide an image of the type of channels that they want to model and the covariance will be inferred directly if the training image is too small it is possible to use a multiple point statistics simulation algorithm and generate an ensemble of simulations and derive the covariance matrix from the analysis of this simulation in the same manner as we analyze the sub images in this work in addition we use first order difference regularization constraints to preserve the curvature of the channels in the inversion process the proposed trips parametrization was integrated in an optimization framework based on linear subspace methods allowing to obtain solutions of the categorical inverse problem for a synthetic aquifer a posterior ensemble obtained with the rejection sampling method was considered to represent the reference solution and compared against the null space monte carlo nsmc and posterior covariance pc ensembles the comparisons indicate that these parameter ensembles exhibit similarities with the reference distribution the pc method was much more efficient in estimating members of the posterior ensemble however the variability was underestimated fig 11 bottom row the nsmc method was comparably slower because more model evaluations were required however the ensemble probability estimated by this method is closer to the ensemble from rs the nsmc method provides a balance between computational efficiency and representation of the posterior ensemble the number of model evaluations required by the nsmc method were comparable to stochastic approaches like isr mariethoz et al 2010 and popex jaggli et al 2017 while the pc method is much faster overall we believe the trips methodology to be a promising entrant in the field of categorical inversion while the example problem presented in this paper considers only two dimensional channels traversing the domain the methodology can be extended to real world three dimensional datasets with a larger number of facies and more complex geometries for example the trips method could be used to estimate the complex channel framework at a real site such as the one discussed by ronayne et al ronayne et al 2008 for this case the pilot points would represent the positions of channels in three dimensions and three dimensional splines passing through the pilot points could be used to delineate the channels more generally the extension of the proposed methodology is straightforward for all object oriented geological modeling techniques pyrcz and deutsch 2014 since the positions of the objects are controlled in these models by seed points which can be considered as traveling pilot points the prior statistics on the number of objects and relative locations of these points can be derived from a set of initial simulations the proposed algorithm described could then be used to update these locations and solve the inverse problem the shape parameters concerning the three dimensional size and orientation of the objects can be handled as well easily since these are continuous parameters that an inversion code like pest can optimize this step would be analogous to the identification of the hydraulic conductivity values within the channels as illustrated in the example treated in this paper for objects having a flexible shape such as channels with varying width traditional techniques such as the standard pilot points can be coupled with trips one can attach a width parameter to every traveling pilot point and interpolate the width along the channel length and update these parameters during the inversion the trips method could also be used with pixel based geostatistical methods such as plurigaussian or mps simulations pyrcz and deutsch 2014 starting from one or a set of initial realizations we could extract a set of conditioning locations and the corresponding categories from the realization trips would then proceed by moving the locations of these points keeping the value of the categories and simulating again the complete field using these new conditioning data as input in the geostatistical algorithm in this last case developing the appropriate parameter covariance matrix remains a challenge considering the subspace methods tested in this paper one aspect which works to their favor is the large null space as the size of the null space increases trips nsmc methods could prove to be computationally parsimonious in comparison with other methods we have shown in this paper on a simple synthetic problem that the gain in numerical efficiency comes at the cost of an underestimation of the overall uncertainty credit authorship contribution statement prashanth khambhammettu conceptualization methodology software visualization validation writing original draft writing review editing philippe renard conceptualization methodology supervision validation writing review editing john doherty conceptualization methodology supervision validation writing review editing declaration of competing interests the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors the authors wish to thank the editor and the three anonymous reviewers whose comments contributed to an improved version of this paper the authors are also thankful to vivek bedekar julien straubhaar and christoph jäggli for reviewing and commenting upon early drafts of this manuscript the data and codes used to generate results for this paper can be obtained from the corresponding author prashanth khambhammettu arcadis com supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103556 appendix b supplementary materials image application 1 appendix a a 1 calculation of a covariance matrix for parameter differences given the covariance matrix c for a parameter vector p calculation of the covariance matrix c p for the parameter difference vector p is described in this section with an example if the parameter vector p had three parameters y1 y2 and y3 the parameter difference vector p would have the differences y1 y2 y1 y3 and y1 y2 in matrix form this relationship can be expressed by the equation 1 y 1 y 2 y 1 y 3 y 2 y 3 1 1 0 1 0 1 0 1 1 y 1 y 2 y 3 the above equation could be generalized for an arbitrary number of parameters parameter differences by the equation 2 p ap if we have y ax aster et al aster et al 2013 state that the covariance matrix of y c y can be calculated by the equation 3 c y ac x a t combining eqs 2 and 3 the covariance matrix for the parameter difference vector can be calculated by the equation 4 c p ac p a t 
507,we present the poreflow net a 3d convolutional neural network architecture that provides fast and accurate fluid flow predictions for 3d digital rock images we trained our network to extract spatial relationships between the porous medium morphology and the fluid velocity field our workflow computes simple geometrical information from 3d binary images to train a deep neural network the poreflow net optimized to generalize the problem of flow through porous materials our results show that the extracted information is sufficient to obtain accurate flow field predictions in less than a second without performing expensive numerical simulations providing a speed up of several orders of magnitude we also demonstrate that our model trained with simple synthetic geometries is able to provide accurate results in real samples spanning granular rocks carbonates and slightly consolidated media from a variety of subsurface formations which highlights the ability of the model to generalize the porous media flow problem the workflow presented here shows the successful application of a disruptive technology physics based training of machine learning models to the digital rock physics community keywords fluid flow porous media surrogate models permeability deep learning convolutional neural networks 1 introduction understanding how fluids travel through porous structures of subsurface rock formations is crucial for designing groundwater management hydrocarbon extraction raeini et al 2014 co2 sequestration chen et al 2018 and contaminant remediation projects kang et al 2007 currently most of the energy that we use comes from hydrocarbons extracted from oil and gas reservoirs most of the water for human consumption travels through underground aquifers and the first pilot projects of co2 sequestration in the subsurface are yielding positive results for these reasons it is paramount to accurately describe the flow physics of these fluids to maintain energy security water availability and to potentially avoid climate change blunt 2017 one of the most impactful properties in the decision making process for the areas mentioned above is the permeability of the underground reservoir of interest this quantity provides a directional volume averaged geometric measure of the ease for a fluid to flow through a specific rock volume the permeability is determined by the topology of the porous structures of the formation and it is calculated by computing average velocity based on the fluid velocity through pore space and comparing it to darcy s law see eq 1 this quantity is researched primarily to assess preferential flow channels in the subsurface contaminant tracing hydrocarbon movement in an oil reservoir bottlenecks for fluid flow and to estimate well flow rates hydrocarbon and water extraction and co2 sequestration the permeability is shaped by the processes that formed the rock and the subsequent alterations throughout geological time processes such as deposition of grains in a basin compaction of layers caused by overburden pressure cementation recrystallization and dissolution change the microscopic structure of the rock altering the shapes and sizes of the flow paths available these effects that can span up to kilometers modify the permeability of the rock formation since the behavior of the fluids at the smaller scales is key to make inferences of larger domains in this paper we are going to focus on the flow of fluids at the microscale there are different methods to obtain the flow properties of a rock laboratory measurements are able to obtain the average permeability of a sample through direct measurement nevertheless it is not possible to observe the microscopic physics at the pore scale these measurements also tend to take longer times or even fail in tight porous media lower porosity on the other hand there are existing analytical expersions that estimate the permeability of a rock based on fitting parameters that account for the rock type lithology grain size distribution and depositional processes among others these require a minimal amount of information but they are restricted to a particular rock sometimes even from a specific geographical location xu and yu 2008 finally there are several numerical simulation methods to reproduce the fluid flow physics blunt et al 2013 mehmani et al 2020 among these direct simulation methods dsm are very attractive because they resolve the flow through irregular geometries giving the final user a realistic snapshot of how the fluid flows through the pores of subsurface formations since the subsurface is highly heterogeneous over multiple scales direct simulation on a variety of samples at various scales extracted from wells or outcrops of the reservoir or analogous rock of interest provides valuable information to investigate and model subsurface flow for improved subsurface management with the rapid development of x ray scanners and other non destructive imaging technologies mees et al 2003 the simulation of fluid flow through 3d images of porous materials is a topic of increasing interest the typical workflow for performing direct simulations starts with a gray scale volume the output of the x ray scanner which is then segmented to eliminate artifacts and noise in two phases binary image that are discretized into voxels 3d pixels of solid or space for fluid to flow these simulations provide an accurate picture with resolution of micrometers and even smaller of how fluid flows through complex geometries with the advances in computational performance larger domains are practically simulated nevertheless computing times even on supercomputer clusters can be long and the required computational resources are vast the computational demand of these methods grows at least at the cube of the side length of the domain for homogeneous cubic samples so in most cases running direct simulations on a representative elementary volume with typical desktops is unfeasible additionally real materials tend to have pore size distributions that span and vary over a wide range of scales which increases the size of a representative elementary volume and thus the computational time to perform the simulations there are several numerical methods that are used to obtain flow properties directly from 3d images the finite volume method jenny et al 2003 smoothed particle hydrodynamics tartakovsky and meakin 2005 the finite element method white et al 2006 the lattice boltzmann method lbm among others a comparison of some of these methods and their run times can be found in yang et al 2016 in this work we utilize the lbm due to its simplicity for performing simulations in irregular domains and its well tested capabilities to simulate flow through porous materials pan et al 2004 santos et al 2018 although the method is easily parallelizable its computational time scales increase with domain complexity fig 1 which is common to every method that operates on porous materials we stress however that the workflow presented here does not depend on the method chosen to obtain the fluid velocity field recently deep learning methods have been introduced as a framework for computers to learn from observational data of physical phenomena to predict variables of interest these methods have been applied to study many problems in image segmentation pattern recognition and image captioning and natural language processing deep learning methods benefit from benchmark datasets since 1 supervised deep learning methods require a large amount of validated data to train models and 2 the capabilities of the trained classifiers must be assessed quantitatively these algorithms have been applied successfully to digital rock applications like image segmentation andrew 2018 bihani et al 2019 karimpouli and tahmasebi 2019b calculation of wave propagation through a solid matrix karimpouli and tahmasebi 2019a 3d rock reconstruction using generative models mosser et al 2018 and 2d calculations of permeability in small domains wu et al 2018 either segmented real images or porous media reconstructions are required for direct simulation of flow there are several challenges encountered in applying deep neural networks to predict flow through porous media or upscaled transport properties of a porous medium the biggest challenge is the large number of labeled pairs of data that can come in the form of interpreted seismic cross sections segmented images simulation results etc required to train a model in addition performing numerical simulations of porous volumes could require days of computation on hundreds of cores of a supercomputer to converge fig 1 moreover acquiring the prerequisite many volumes of a similar formation is often challenging since access to the required imaging technologies i e x ray scanners is limited and finally given access to a large training set there is still a memory limitation challenge more on this in the sections below to circumvent the above difficulties we create benchmark datasets reusing images from digital rocks portal prodanovic et al 2015 that are publicly available and propose a comprehensive workflow to obtain a functional relationship between a 3d binary image and the volumetric solution of the navier stokes equation specifically in the context of deep learning and fluid flow carrillo et al 2017 trained an artificial neural network to predict the shape and coordinates of an occlusion blocking a 2d pipe using only the velocity at points along the horizontal direction representing sensors as input data moreover guo et al 2016 trained a convolutional neural network cnn to predict velocity fields of a steady state flow with an obstacle represented by simple geometries for small domains with closed boundaries they used the distance transform of the binary image as the model input for single phase time dependent problems hennigh 2017 proposed the lat net a convolutional neural network architecture that compressed the output of an lbm simulation to be memory efficient and learned the relationship between subsequent compressed time steps specifically for porous media applications wu et al 2018 applied a cnn architecture with a fully connected layer to predict the permeability of 2d images sudakov et al 2018 applied simple 2d 3d architectures to predict the absolute permeability a system obtained by a pore network model a technique which simplifies the pore space into a network of spheres interconnected by cylinders losing all the complex features of the image the authors of this paper santos et al 2018 initially proposed a cnn that used the euclidean distance as an input to predict the velocity field nevertheless the network was not able to generalize to predict for more heterogeneous pore geometries kamrava et al 2020 showed that by using 3d convolutions their model was able to predict permeability for realistic pore geometries that paper also provides a detail explanation of all the main components of a convolutional neural network and we refer it to any reader who is not familiar with the basic structure of a neural network the key difference of our work is that we are able to use large 3d domains with pore geometry that is more complex than in previously published work further compared to other porous media work to date we are able to predict the fluid 3d velocity field instead of only trying to predict the permeability value in this work our main contribution is a new 3d deep learning workflow that is able to generalize the single phase flow of a fluid through granular materials we show that by combining a feature extraction algorithm a custom loss function and a new network architecture our model can be trained with very simple 3d geometries and predict accurately in examples of varying sizes and complexity these predictions require less than a second of computation on a typical desktop computer with a graphics processing unit gpu and are comparable in accuracy to the full physics simulation that might require days of processing on a supercomputer cluster we will also provide a comprehensive 3d data set that spans a wide range of rock formations all around the globe 2 methods in this section we present the numerical method used for simulating the flow physics the morphological feature extraction algorithm and the architecture of the poreflow net 2 1 velocity field simulation to simulate the fluid flow through the domains of interest we selected the lattice boltzmann method lbm sukop and thorne 2007 nevertheless the results of this work are independent of the numerical method used to solve the flow physics the lbm is one of the most popular methods for performing direct simulation of fluid flow through irregular geometries this method simulates the streaming and collision of particles on a grid and it has been demonstrated that is able to recover the full navier stokes equation solution frisch 1991 the advantages of the lbm are that the algorithm is relatively easy to implement is highly parallelizable and it can perform direct simulations on images we used the same model proposed by pan et al 2006 with a relaxation time related to the fluid viscosity equal to one it is a slightly compressible model where a very small pressure gradient 1e 6 lattice units independent to the permeability of the domain is applied to drive the fluid forward all the simulations are in the laminar flow regime where the reynolds number is much smaller than one this is consistent with the typical flow regime through subsurface formations away from fractures or boreholes upon convergence the lbm simulation outputs the 3d velocity field tensor of the image to calculate the permeability of the domain we use darcy s law bear and bachmat 1991 1 k v μ d p d z where v represents the mean of the velocity field in the direction of the pressure gradient d p d z and μ refers to the dynamic viscosity of the fluid to calculate v we calculate the average of the 3d velocity matrix in the direction of flow the permeability expresses the flow rate as a function of pressure gradient it has units of length squared and it is typically expressed in m2 or in darcys 2 2 feature extraction the typical bottlenecks for deep learning applications are the 1 vast amount of data required to train a model and the 2 memory limitations of the computational systems to perform the training of a deep neural network to overcome these issues we added to our workflow a pre training feature extraction step where we extract relevant morphological features of the rock volume since our simulations are time consuming spanning from hours to days in our cluster it would be impractical to run domains hosting every possible 3d structure by adding additional input features to the model our network is trained to find a more robust functional relationship of the image with the flow field it is worth noting that these features are computed in minutes in a desktop computer requiring a minimal computational demand compared to the fluid flow simulation moreover since it would be computationally difficult to train the model using the entire simulation domains 5003 voxels we split the input and output images in subsamples to carry out the training process since the subsampled volumes are shuffled in a training pool along with other examples from different domains including information of the boundaries local with euclidean distance and global with the time of flight gives the model knowledge about the original spatial location of the individual subsample this process is depicted in fig 5 we compute four geometrical features from the binary image fig 2 1 to represent the local characteristics of the binary image we extracted the euclidean distance map also known as the distance transform of each sample this is calculated with the following equation 2 e d i s t x 1 x 2 2 y 1 y 2 2 z 1 z 2 2 1 2 where x1 and 2 y1 and 2 z1 and 2 are the coordinates of each point of the solid and the fluid boundaries respectively this map provides a compact representation of the distribution of space available for fluid to flow and the distance to the closest solid no flow boundary 2 next a maximum inscribed sphere mis map in the direction of flow i e an mis flood is computed this map is a simplified and lightweight representation of a non wetting fluid injection in the direction of flow although mis floods are typically used to describe two phase flow here it acts as a measure of geometry size of pore space and topology connectivity to neighboring pore structures to similar size the mis map provides information about the local pore space characteristics as well as the global simulation conditions it acts as a bridge between the whole domain and its subsamples 3 and 4 finally to inform the network about the global conditions of the domain before subsampling it we employed a detrended time of flight tof we use the fast marching algorithm hassouna and farag 2007 to compute the shortest distance of all the points of the domain to a point source in this case either the xy plane located at the inlet or the outlet this method solves the boundary value problem of the eikonal equation hassouna and farag 2007 represented by 3 t x 1 f x where t represents the time of flight and f x stands for the speed at every location of the image a constant in our case we set the speed of the void space to one while the solid matrix is set to zero impermeable the result of this operation is a map where each of the voxels of the void space are labeled with a number that depicts the shortest distance in voxels to the boundary the first few layers in the z coordinate will be given consecutive numbers starting from one until they find a solid obstacle then the number sequence will continue around the obstacle we then subtract the time of flight of the image map without solid obstacles an image with a porosity of 100 to calculate a detrended normalized map as shown in fig 2 this feature provides data on tortuosity of the global paths within the domain in addition it supplies the model implicit information about the neighboring subsampled blocks we compute two features using this method one where the point source is located at the inlet of the numerical simulation and the second one where the source is at the outlet both pressure gradient boundary conditions these features have been used in literature to characterize porous materials nevertheless since the relationship of these features with the velocity field is highly non linear the selection of the ultimate set of features shown above was a trial and error process these features do not provide an exhaustive description of a 3d porous material however they deliver enough information to our model about the local and global boundary conditions of the domain to be able to structure a relationship in the form of a convolutional neural network model between these inputs and the navier stokes solution 2 3 network 2 3 1 convolutional neural networks convolutional neural networks cnns have excelled in the field of computer vision outperforming classical machine learning methods krizhevsky et al 2012 lecun et al 2015 these models have shown a remarkable capacity to find complex relations in big data sets by utilizing the discrete convolution operation instead of a regular matrix multiplication i e a fully connected feed forward network they generalize local spatial relationships sparse interactions across the domain cnns utilize filters that are much smaller than the input image which extract general and meaningful information about the domain in an efficient manner by stacking convolutional layers the network extracts features at different levels of abstraction with an increasingly wider receptive field fig 3 finally the convolution layers are equivariant to translation which means that if the input feature is shifted their output will be shifted by the same amount by creating in this case a 3d feature map this is particularly useful in pattern recognition because they allow for inputs of variable size using this structure a network can be trained to learn complex non linear relationships between inputs and outputs using the backpropagation algorithm 2 3 2 poreflow net recent studies suggest that the performance of a network can benefit from increased depth longer stack of layers as described in section 2 3 1 szegedy et al 2015 urban et al 2016 apart from being computationally more intensive a deeper network presents issues like vanishing and exploding gradients pascanu et al 2012 and filter saturation by highly correlated features making them very hard to train to improve the gradient propagation and to enhance the training he et al 2016 proposed the residual network resnet the resnet concatenates an identity map to the output of a convolutional layer stack residual unit to facilitate training the authors show that the training is eased by targeting this new referenced residual output avoiding gradient vanishing or saturation further ronneberger et al 2015 proposed the unet this architecture concatenates feature maps from different layers of the encoding branch to the decoder improving segmentation accuracy significantly one of the main advantages of this is that the structure of the network retains high i e lines and edges and low level features i e entire objects to reconstruct the output they show that the networks train with ease and with fewer parameters due to the better flow of information both in the forward and backward computations that the skip connections direct pathways between the encoding and decoding branch provide building up from these two architectures zhang et al 2018 presented the deep residual u net resunet which uses residual units as building blocks and skips connections between them this network prove to be easy to train compared to the u net that needed extensive data augmentation or a pre trained model with an efficient number of parameters and showed accurate results using a small training set in this paper we propose a modification of the resunet which benefits from the information of all the input features by passing them through individual encoding branches dedicated to each of the extracted features from section 2 2 with skip connections we use three residual units for each of the four branches a bridge and a single decoder to recover the velocity field each of these parts is built with residual units fig 4 we use the scaled exponential linear unit selu klambauer et al 2017 as the activation function this is described by the following equation 4 s e l u x λ x i f x 0 α e x α i f x 0 where the values of α and λ are fixed and provided in the publication the purpose of this function is to perform additional internal normalization of the inputs facilitating gradient propagation according to the derivation of the authors problems like gradient exploding or vanishing are mathematically infeasible moreover since internal normalization is cheaper the network converges faster since the velocity distribution spans several orders of magnitude fig 6 we use l1 mean absolute error as the cost function due to the large number of outliers velocity tending to zero near the grain boundaries to increase the attention in tighter geometries we compute the loss as follows 5 l y t r u e y p r e d m where m is a weight vector that accounts for the size of the pores in the direction of flow and stands for an element wise multiplication the algorithm to calculate m can be found in appendix a1 the loss function eq 5 weights the difference between the true values and the predictions so that all the voxels in the training pool have the same relevance high and low porosity subsamples 2 4 training data 2 4 1 dataset creation we used a beadpack comprised by a disordered closed pack of spherical grains originally imaged experimentally by finney it can be downloaded at finney and prodanovic 2016 as our initial domain a 5003 subset of the original spherepack was discretized and segmented to generate training data we performed four one pixel grain dilations to the original sample where we obtained four images of decreasing porosity increasingly tighter that mimic cementation processes in the subsurface but preserves the simple features of the original spherepack these samples range from 29 8 to 11 porosity finally we performed a single phase lbm flow simulation in these four samples where a pressure gradient parallel to the z coordinate direction was applied with no flow boundary conditions in the other faces since the domains are homogeneous packs of spheres the simulation converges much faster in the order of hours compared with real rock x ray scans we used these four samples to train the convolutional neural network 2 4 2 relationships between inputs and outputs the lattice boltzmann simulation outputs a pressure matrix and a velocity tensor in each point of the grid in this work we focused on the z component of the fluid velocity parallel to the pressure gradient which determines the permeability in fig 6 we show the velocity distribution and its relationship with the morphological features extracted from the binary image from the relationships exhibited in fig 6 we can confirm that traditional machine learning methods would not be able to obtain an accurate model due to the complex highly non linear relations between the inputs and the target output 3 results 3 1 impact of the proposed 3d feature extraction as stated above it would not be feasible to train our network over the entire simulation domains hence it is necessary to subsample the 3d matrices into smaller volumes to train the model with batches of data the reasoning behind this is that gpus have a limited amount of memory and the model parameters the inputs and outputs the gradients among others must be locally stored in our experiments the maximum subset size that conventional hardware could accommodate in memory was no larger than 803 the model as described by fig 4 requires 2 7 gigabytes gb of memory to be trained with a batch size of one sample to train the cnn with entire simulation domains one would require approximately 660 gb of memory available which greatly exceeds the current capabilities of graphic processing units spatially aware neural networks benefit greatly from stationary samples because it is easier to find matching patterns in data in theory the subset size of the 3d sample should be equal or larger than the representative element volume rev bachmat and bear 1987 to exhibit a stationary behavior of the property of interest in this case velocity impacting in a positive manner the training performance of the neural network if the subset data size is smaller than the rev we cannot expect to have a stable measure due to the non stationarities in the form of spatial heterogeneities present in the data to show the importance of our proposed feature extraction step in the training of the network we carried out a moving window analysis to assess the variability of the domains with different volume sizes pyrcz and deutsch 2014 using a window of increasing size length we calculate the coefficient of variation the ratio of the mean over the standard deviation of the porosity and fluid velocity within the subset we carried out this experiment in the original spherepack 36 porosity before the grain dilations where performed we executed this procedure iteratively until the variation became not significant we plotted the results of the moving window analysis in fig 7 both of the subplots show the decrease in variability of porosity and velocity respectively with the increase in the size of the window due to the homogeneity of the sample the 3d subset size comparison is shown in fig 8 it is only after 2003 voxels per side 40 of the image side length that the velocity field stabilizes coefficient of variation is less than 1 this behavior is more significant in tighter and less homogenous samples training the neural network using only the binary image of solid and pore as input will hamper the training process resulting in overfitting it fails to generalize causing the training and validation curves to diverge and poor predictive performance we carried out this experiment and the results are plotted in fig 9 since we are interested in creating a predictive model that is able to perform in different geometries we show that using the additional inputs which add additional information about the subvolume as well as how it relates to parts of the image surrounding it the latter in the form of time of flight described in section 2 2 the model increases its training performance and generalizes enough to predict the flow field within acceptable error range in a test set that includes various geometries in other words the model is able to find unique patterns to construct a robust function mapping the image with the fluid velocity 3 2 model training we implemented the model using the keras python library chollet 2015 with tensorflow abadi et al 2015 as the backend the model is optimized by minimizing the cost function eq 5 using adam kingma and ba 2014 with a learning rate of 1e 4 we used four sphere packs that present four subsequent grain dilations from the original sample as highlighted in section 2 4 1 and subsampled them into 1080 803 cubes for training with a 20 random validation split 216 cubes the model was trained with a mini batch size of five on a desktop with an nvidia quadro m6000 gpu for 140 epochs the model training process took twelve hours the inputs and the outputs are transformed using the minmax constraining them from minus one to one a comparison of the performance of three different model setups training with the binary image only training with the four proposed geometrical features and training utilizing the features plus the custom loss function is plotted in fig 9 we observed a significant performance increase in the loss value when using the extracted features and the proposed loss to assess the ability of the three trained models specified above to generalize the training data we first tested the model using the original sphere pack unseen by the models these were trained using the samples with the dilated grains only the model trained with the binary input gave a relative error in permeability of several orders of magnitude whereas the one using the four input features returned and error 15 and finally the model trained using the features plus the custom loss gave a relative error of 13 when compared to the lattice boltzmann simulation we carry out an extensive testing of the latter trained model in the sections below 3 3 model testing using the model trained with the four dilated spherepacks section 3 2 we tested its capabilities vs the navier stokes equation solution approximated by the lbm on domains of different size and complexity 3 3 1 fontainebleau sandstone dataset the first test set was obtained via a simulation of processes that occur during sedimentary rock formation i e sedimentation compaction diagenesis and cementation to obtain 3d volumes that resemble the fontainebleau sandstone formation in france berg 2016 these images are 4803 voxels and vary from 8 to 26 porosity we show a cross section through the middle of four of the samples in fig 10 we present the results in table 1 these are in very good agreement with the full physics simulation carried out to compare the performance of our model to analyze the error more closely we selected the worst performing sample 24 porosity sandstone for further analysis in fig 11 we show a visual comparison cross section of the 3d volume orthogonal to the flow direction of the lattice boltzmann solution with our model it is visible that most of the relevant flow features are preserved a comparison of the velocity histograms is shown in fig 12 it is worth noting that the flow streamlines are not always continuous and the 3d solution is not trained to satisfy mass balance hence the relative error additional constraints can be added to honor this but are out of scope for this work in here we are mostly interested in capturing the main flow characteristics preferred paths and dead ends that impact permeability 3 3 2 tests on different rock types to further test our model we predicted the flow field for different rock types available in digital rocks portal prodanovic et al 2015 we first created a sample similar in shape to the original training image by performing numerical grain erosion this creates a sample of larger porosity where grain boundaries are not as restrictive to fluid flow where the permeability is higher this case is of interest in irrigation garnier et al 1998 we further tested the original sphere pack the one that was numerically dilated to generate our training set our model yield accurate predictions in these two samples even when the porosities were larger with velocities that are also orders of magnitude higher than the training set we then tested the trained model on two outcrop sandstones a limestone and artificially created multiscale microsand image in these the relative error was not higher than 28 yang et al 2016 show that different fluid flow solvers will have a comparable discrepancy among them even when the same geometry is provided we present our results in table 2 we show the different 3d domains of the test set in fig 14 and a cross section of the results is shown in fig 15 these geometries have different pore shapes and in cases of limestone and microsand they have much wider pore size distribution compared to the training set fig 13 they also have different absolute volume sizes while two sandstones have similar absolute volume size 500 voxel on a side the relative error for prediction is very different 1 06 and 27 30 likely because they have different grain pore distribution as well as different number of individual grains per side which determines how well grain or pores are resolved note that our training set as well as the fontainebleau sandstone test in previous section all have similar level of resolution and hence we saw a very good prediction for all cases in table 1 given that the training set was comparatively simple we find the results in great agreement with the full physics simulations 4 conclusion we train a deep neural network architecture as a fast proxy to predict accurately the 3d physics based fluid flow velocity fields within digital rock samples the relationship between details of pore geometry and flow field with its integral measure of permeability is complex and not easily predicted based on the geometry statistics alone nevertheless this fundamental relationship allows describing how fluids move through subsurface formations and is the cornerstone of many research projects in environmental civil petroleum engineering as well as in geological sciences we demonstrated that our convolutional neural network generalizes the flow problem to predict flow velocity in rocks that host much more complex structures than the original training set this is attributed to the capacity of the network to model the complicated relationships between pore shape and domain characteristics with the velocity field the model performs well with rocks of varying types different lithology and of different grain distribution and porosities where the permeability ranged several orders of magnitude fig 16 the poreflow net calculates fluid flow fields in less than a second on a typical desktop compared with the standard simulation procedure which takes hours to days in a supercomputer facility depending on the hardware used as well as complexity of the digitized pore space geometry additionally the model is a lightweight representation around 25 mb whereas the full simulation results takes 20x the hard drive space the model can be reused in any given geometry while the simulation has to be run case by case future work should be focused on finding features that work with fractured domains and ultra tight rocks this method provides a framework for different further applications such as component transport relative permeability rock mechanics applications formation factor or resistivity these models provide a straightforward way to assess important characteristics for improved subsurface management without running expensive physical models and could possibly be a path to data based upscaling given the proliferation of digital rock images as evidenced in the digital rocks portal or online data available by different research groups blunt 2015 wildenschild 2006 credit authorship contribution statement javier e santos conceptualization methodology software validation formal analysis investigation writing original draft visualization duo xu conceptualization methodology visualization honggeun jo validation formal analysis investigation writing original draft writing review editing visualization christopher j landry software writing review editing maša prodanović resources data curation writing review editing supervision michael j pyrcz resources writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper reproducibility the code will be publicly available on the author s repository github com je santos and all the data used will be posted to digital rock portal upon publication acknowledgments we would like to thank risto miikkulainen and santiago gonzalez from the utcs neural networks research group for their valuable comments we would also like to acknowledge ying yin and wenhui song for their feedback on the flow model additionally we would like to thank renan rojas manish bhattarai and nicholas lubbers for their suggestions towards the improvement of the neural network model we gratefully recognize the texas advanced computing center for their high performance computing resources m pyrcz j santos and h jo acknowledge support from direct industry affiliates program iap and c landry and m prodanovic acknowledge support from digital rock petrophysics iap both of the university of texas finally we thank the four anonymous reviewers for their comments which greatly improved this paper supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103539 appendix b supplementary materials image application 1 appendix a1 calculating mask for custom loss function we calculate the weight matrix fig 17 using the following pseudocode image size 500 length of the volume side for i in range 0 image size loop along the z coordinate porosity z sum binary im i image size 2 calculate the porosity of the slice solid mask i 1 porosity z solid mask i multiply by a term that weights lower porosity sections fig 17 solid mask i solid mask i 0 1 replace the solids with a 1 solid mask i solid mask i sum solid mask i image size 2 normalize where the binary image is composed by a 3d matrix of zeros representing the solids and ones representing the space for fluid to flow 
507,we present the poreflow net a 3d convolutional neural network architecture that provides fast and accurate fluid flow predictions for 3d digital rock images we trained our network to extract spatial relationships between the porous medium morphology and the fluid velocity field our workflow computes simple geometrical information from 3d binary images to train a deep neural network the poreflow net optimized to generalize the problem of flow through porous materials our results show that the extracted information is sufficient to obtain accurate flow field predictions in less than a second without performing expensive numerical simulations providing a speed up of several orders of magnitude we also demonstrate that our model trained with simple synthetic geometries is able to provide accurate results in real samples spanning granular rocks carbonates and slightly consolidated media from a variety of subsurface formations which highlights the ability of the model to generalize the porous media flow problem the workflow presented here shows the successful application of a disruptive technology physics based training of machine learning models to the digital rock physics community keywords fluid flow porous media surrogate models permeability deep learning convolutional neural networks 1 introduction understanding how fluids travel through porous structures of subsurface rock formations is crucial for designing groundwater management hydrocarbon extraction raeini et al 2014 co2 sequestration chen et al 2018 and contaminant remediation projects kang et al 2007 currently most of the energy that we use comes from hydrocarbons extracted from oil and gas reservoirs most of the water for human consumption travels through underground aquifers and the first pilot projects of co2 sequestration in the subsurface are yielding positive results for these reasons it is paramount to accurately describe the flow physics of these fluids to maintain energy security water availability and to potentially avoid climate change blunt 2017 one of the most impactful properties in the decision making process for the areas mentioned above is the permeability of the underground reservoir of interest this quantity provides a directional volume averaged geometric measure of the ease for a fluid to flow through a specific rock volume the permeability is determined by the topology of the porous structures of the formation and it is calculated by computing average velocity based on the fluid velocity through pore space and comparing it to darcy s law see eq 1 this quantity is researched primarily to assess preferential flow channels in the subsurface contaminant tracing hydrocarbon movement in an oil reservoir bottlenecks for fluid flow and to estimate well flow rates hydrocarbon and water extraction and co2 sequestration the permeability is shaped by the processes that formed the rock and the subsequent alterations throughout geological time processes such as deposition of grains in a basin compaction of layers caused by overburden pressure cementation recrystallization and dissolution change the microscopic structure of the rock altering the shapes and sizes of the flow paths available these effects that can span up to kilometers modify the permeability of the rock formation since the behavior of the fluids at the smaller scales is key to make inferences of larger domains in this paper we are going to focus on the flow of fluids at the microscale there are different methods to obtain the flow properties of a rock laboratory measurements are able to obtain the average permeability of a sample through direct measurement nevertheless it is not possible to observe the microscopic physics at the pore scale these measurements also tend to take longer times or even fail in tight porous media lower porosity on the other hand there are existing analytical expersions that estimate the permeability of a rock based on fitting parameters that account for the rock type lithology grain size distribution and depositional processes among others these require a minimal amount of information but they are restricted to a particular rock sometimes even from a specific geographical location xu and yu 2008 finally there are several numerical simulation methods to reproduce the fluid flow physics blunt et al 2013 mehmani et al 2020 among these direct simulation methods dsm are very attractive because they resolve the flow through irregular geometries giving the final user a realistic snapshot of how the fluid flows through the pores of subsurface formations since the subsurface is highly heterogeneous over multiple scales direct simulation on a variety of samples at various scales extracted from wells or outcrops of the reservoir or analogous rock of interest provides valuable information to investigate and model subsurface flow for improved subsurface management with the rapid development of x ray scanners and other non destructive imaging technologies mees et al 2003 the simulation of fluid flow through 3d images of porous materials is a topic of increasing interest the typical workflow for performing direct simulations starts with a gray scale volume the output of the x ray scanner which is then segmented to eliminate artifacts and noise in two phases binary image that are discretized into voxels 3d pixels of solid or space for fluid to flow these simulations provide an accurate picture with resolution of micrometers and even smaller of how fluid flows through complex geometries with the advances in computational performance larger domains are practically simulated nevertheless computing times even on supercomputer clusters can be long and the required computational resources are vast the computational demand of these methods grows at least at the cube of the side length of the domain for homogeneous cubic samples so in most cases running direct simulations on a representative elementary volume with typical desktops is unfeasible additionally real materials tend to have pore size distributions that span and vary over a wide range of scales which increases the size of a representative elementary volume and thus the computational time to perform the simulations there are several numerical methods that are used to obtain flow properties directly from 3d images the finite volume method jenny et al 2003 smoothed particle hydrodynamics tartakovsky and meakin 2005 the finite element method white et al 2006 the lattice boltzmann method lbm among others a comparison of some of these methods and their run times can be found in yang et al 2016 in this work we utilize the lbm due to its simplicity for performing simulations in irregular domains and its well tested capabilities to simulate flow through porous materials pan et al 2004 santos et al 2018 although the method is easily parallelizable its computational time scales increase with domain complexity fig 1 which is common to every method that operates on porous materials we stress however that the workflow presented here does not depend on the method chosen to obtain the fluid velocity field recently deep learning methods have been introduced as a framework for computers to learn from observational data of physical phenomena to predict variables of interest these methods have been applied to study many problems in image segmentation pattern recognition and image captioning and natural language processing deep learning methods benefit from benchmark datasets since 1 supervised deep learning methods require a large amount of validated data to train models and 2 the capabilities of the trained classifiers must be assessed quantitatively these algorithms have been applied successfully to digital rock applications like image segmentation andrew 2018 bihani et al 2019 karimpouli and tahmasebi 2019b calculation of wave propagation through a solid matrix karimpouli and tahmasebi 2019a 3d rock reconstruction using generative models mosser et al 2018 and 2d calculations of permeability in small domains wu et al 2018 either segmented real images or porous media reconstructions are required for direct simulation of flow there are several challenges encountered in applying deep neural networks to predict flow through porous media or upscaled transport properties of a porous medium the biggest challenge is the large number of labeled pairs of data that can come in the form of interpreted seismic cross sections segmented images simulation results etc required to train a model in addition performing numerical simulations of porous volumes could require days of computation on hundreds of cores of a supercomputer to converge fig 1 moreover acquiring the prerequisite many volumes of a similar formation is often challenging since access to the required imaging technologies i e x ray scanners is limited and finally given access to a large training set there is still a memory limitation challenge more on this in the sections below to circumvent the above difficulties we create benchmark datasets reusing images from digital rocks portal prodanovic et al 2015 that are publicly available and propose a comprehensive workflow to obtain a functional relationship between a 3d binary image and the volumetric solution of the navier stokes equation specifically in the context of deep learning and fluid flow carrillo et al 2017 trained an artificial neural network to predict the shape and coordinates of an occlusion blocking a 2d pipe using only the velocity at points along the horizontal direction representing sensors as input data moreover guo et al 2016 trained a convolutional neural network cnn to predict velocity fields of a steady state flow with an obstacle represented by simple geometries for small domains with closed boundaries they used the distance transform of the binary image as the model input for single phase time dependent problems hennigh 2017 proposed the lat net a convolutional neural network architecture that compressed the output of an lbm simulation to be memory efficient and learned the relationship between subsequent compressed time steps specifically for porous media applications wu et al 2018 applied a cnn architecture with a fully connected layer to predict the permeability of 2d images sudakov et al 2018 applied simple 2d 3d architectures to predict the absolute permeability a system obtained by a pore network model a technique which simplifies the pore space into a network of spheres interconnected by cylinders losing all the complex features of the image the authors of this paper santos et al 2018 initially proposed a cnn that used the euclidean distance as an input to predict the velocity field nevertheless the network was not able to generalize to predict for more heterogeneous pore geometries kamrava et al 2020 showed that by using 3d convolutions their model was able to predict permeability for realistic pore geometries that paper also provides a detail explanation of all the main components of a convolutional neural network and we refer it to any reader who is not familiar with the basic structure of a neural network the key difference of our work is that we are able to use large 3d domains with pore geometry that is more complex than in previously published work further compared to other porous media work to date we are able to predict the fluid 3d velocity field instead of only trying to predict the permeability value in this work our main contribution is a new 3d deep learning workflow that is able to generalize the single phase flow of a fluid through granular materials we show that by combining a feature extraction algorithm a custom loss function and a new network architecture our model can be trained with very simple 3d geometries and predict accurately in examples of varying sizes and complexity these predictions require less than a second of computation on a typical desktop computer with a graphics processing unit gpu and are comparable in accuracy to the full physics simulation that might require days of processing on a supercomputer cluster we will also provide a comprehensive 3d data set that spans a wide range of rock formations all around the globe 2 methods in this section we present the numerical method used for simulating the flow physics the morphological feature extraction algorithm and the architecture of the poreflow net 2 1 velocity field simulation to simulate the fluid flow through the domains of interest we selected the lattice boltzmann method lbm sukop and thorne 2007 nevertheless the results of this work are independent of the numerical method used to solve the flow physics the lbm is one of the most popular methods for performing direct simulation of fluid flow through irregular geometries this method simulates the streaming and collision of particles on a grid and it has been demonstrated that is able to recover the full navier stokes equation solution frisch 1991 the advantages of the lbm are that the algorithm is relatively easy to implement is highly parallelizable and it can perform direct simulations on images we used the same model proposed by pan et al 2006 with a relaxation time related to the fluid viscosity equal to one it is a slightly compressible model where a very small pressure gradient 1e 6 lattice units independent to the permeability of the domain is applied to drive the fluid forward all the simulations are in the laminar flow regime where the reynolds number is much smaller than one this is consistent with the typical flow regime through subsurface formations away from fractures or boreholes upon convergence the lbm simulation outputs the 3d velocity field tensor of the image to calculate the permeability of the domain we use darcy s law bear and bachmat 1991 1 k v μ d p d z where v represents the mean of the velocity field in the direction of the pressure gradient d p d z and μ refers to the dynamic viscosity of the fluid to calculate v we calculate the average of the 3d velocity matrix in the direction of flow the permeability expresses the flow rate as a function of pressure gradient it has units of length squared and it is typically expressed in m2 or in darcys 2 2 feature extraction the typical bottlenecks for deep learning applications are the 1 vast amount of data required to train a model and the 2 memory limitations of the computational systems to perform the training of a deep neural network to overcome these issues we added to our workflow a pre training feature extraction step where we extract relevant morphological features of the rock volume since our simulations are time consuming spanning from hours to days in our cluster it would be impractical to run domains hosting every possible 3d structure by adding additional input features to the model our network is trained to find a more robust functional relationship of the image with the flow field it is worth noting that these features are computed in minutes in a desktop computer requiring a minimal computational demand compared to the fluid flow simulation moreover since it would be computationally difficult to train the model using the entire simulation domains 5003 voxels we split the input and output images in subsamples to carry out the training process since the subsampled volumes are shuffled in a training pool along with other examples from different domains including information of the boundaries local with euclidean distance and global with the time of flight gives the model knowledge about the original spatial location of the individual subsample this process is depicted in fig 5 we compute four geometrical features from the binary image fig 2 1 to represent the local characteristics of the binary image we extracted the euclidean distance map also known as the distance transform of each sample this is calculated with the following equation 2 e d i s t x 1 x 2 2 y 1 y 2 2 z 1 z 2 2 1 2 where x1 and 2 y1 and 2 z1 and 2 are the coordinates of each point of the solid and the fluid boundaries respectively this map provides a compact representation of the distribution of space available for fluid to flow and the distance to the closest solid no flow boundary 2 next a maximum inscribed sphere mis map in the direction of flow i e an mis flood is computed this map is a simplified and lightweight representation of a non wetting fluid injection in the direction of flow although mis floods are typically used to describe two phase flow here it acts as a measure of geometry size of pore space and topology connectivity to neighboring pore structures to similar size the mis map provides information about the local pore space characteristics as well as the global simulation conditions it acts as a bridge between the whole domain and its subsamples 3 and 4 finally to inform the network about the global conditions of the domain before subsampling it we employed a detrended time of flight tof we use the fast marching algorithm hassouna and farag 2007 to compute the shortest distance of all the points of the domain to a point source in this case either the xy plane located at the inlet or the outlet this method solves the boundary value problem of the eikonal equation hassouna and farag 2007 represented by 3 t x 1 f x where t represents the time of flight and f x stands for the speed at every location of the image a constant in our case we set the speed of the void space to one while the solid matrix is set to zero impermeable the result of this operation is a map where each of the voxels of the void space are labeled with a number that depicts the shortest distance in voxels to the boundary the first few layers in the z coordinate will be given consecutive numbers starting from one until they find a solid obstacle then the number sequence will continue around the obstacle we then subtract the time of flight of the image map without solid obstacles an image with a porosity of 100 to calculate a detrended normalized map as shown in fig 2 this feature provides data on tortuosity of the global paths within the domain in addition it supplies the model implicit information about the neighboring subsampled blocks we compute two features using this method one where the point source is located at the inlet of the numerical simulation and the second one where the source is at the outlet both pressure gradient boundary conditions these features have been used in literature to characterize porous materials nevertheless since the relationship of these features with the velocity field is highly non linear the selection of the ultimate set of features shown above was a trial and error process these features do not provide an exhaustive description of a 3d porous material however they deliver enough information to our model about the local and global boundary conditions of the domain to be able to structure a relationship in the form of a convolutional neural network model between these inputs and the navier stokes solution 2 3 network 2 3 1 convolutional neural networks convolutional neural networks cnns have excelled in the field of computer vision outperforming classical machine learning methods krizhevsky et al 2012 lecun et al 2015 these models have shown a remarkable capacity to find complex relations in big data sets by utilizing the discrete convolution operation instead of a regular matrix multiplication i e a fully connected feed forward network they generalize local spatial relationships sparse interactions across the domain cnns utilize filters that are much smaller than the input image which extract general and meaningful information about the domain in an efficient manner by stacking convolutional layers the network extracts features at different levels of abstraction with an increasingly wider receptive field fig 3 finally the convolution layers are equivariant to translation which means that if the input feature is shifted their output will be shifted by the same amount by creating in this case a 3d feature map this is particularly useful in pattern recognition because they allow for inputs of variable size using this structure a network can be trained to learn complex non linear relationships between inputs and outputs using the backpropagation algorithm 2 3 2 poreflow net recent studies suggest that the performance of a network can benefit from increased depth longer stack of layers as described in section 2 3 1 szegedy et al 2015 urban et al 2016 apart from being computationally more intensive a deeper network presents issues like vanishing and exploding gradients pascanu et al 2012 and filter saturation by highly correlated features making them very hard to train to improve the gradient propagation and to enhance the training he et al 2016 proposed the residual network resnet the resnet concatenates an identity map to the output of a convolutional layer stack residual unit to facilitate training the authors show that the training is eased by targeting this new referenced residual output avoiding gradient vanishing or saturation further ronneberger et al 2015 proposed the unet this architecture concatenates feature maps from different layers of the encoding branch to the decoder improving segmentation accuracy significantly one of the main advantages of this is that the structure of the network retains high i e lines and edges and low level features i e entire objects to reconstruct the output they show that the networks train with ease and with fewer parameters due to the better flow of information both in the forward and backward computations that the skip connections direct pathways between the encoding and decoding branch provide building up from these two architectures zhang et al 2018 presented the deep residual u net resunet which uses residual units as building blocks and skips connections between them this network prove to be easy to train compared to the u net that needed extensive data augmentation or a pre trained model with an efficient number of parameters and showed accurate results using a small training set in this paper we propose a modification of the resunet which benefits from the information of all the input features by passing them through individual encoding branches dedicated to each of the extracted features from section 2 2 with skip connections we use three residual units for each of the four branches a bridge and a single decoder to recover the velocity field each of these parts is built with residual units fig 4 we use the scaled exponential linear unit selu klambauer et al 2017 as the activation function this is described by the following equation 4 s e l u x λ x i f x 0 α e x α i f x 0 where the values of α and λ are fixed and provided in the publication the purpose of this function is to perform additional internal normalization of the inputs facilitating gradient propagation according to the derivation of the authors problems like gradient exploding or vanishing are mathematically infeasible moreover since internal normalization is cheaper the network converges faster since the velocity distribution spans several orders of magnitude fig 6 we use l1 mean absolute error as the cost function due to the large number of outliers velocity tending to zero near the grain boundaries to increase the attention in tighter geometries we compute the loss as follows 5 l y t r u e y p r e d m where m is a weight vector that accounts for the size of the pores in the direction of flow and stands for an element wise multiplication the algorithm to calculate m can be found in appendix a1 the loss function eq 5 weights the difference between the true values and the predictions so that all the voxels in the training pool have the same relevance high and low porosity subsamples 2 4 training data 2 4 1 dataset creation we used a beadpack comprised by a disordered closed pack of spherical grains originally imaged experimentally by finney it can be downloaded at finney and prodanovic 2016 as our initial domain a 5003 subset of the original spherepack was discretized and segmented to generate training data we performed four one pixel grain dilations to the original sample where we obtained four images of decreasing porosity increasingly tighter that mimic cementation processes in the subsurface but preserves the simple features of the original spherepack these samples range from 29 8 to 11 porosity finally we performed a single phase lbm flow simulation in these four samples where a pressure gradient parallel to the z coordinate direction was applied with no flow boundary conditions in the other faces since the domains are homogeneous packs of spheres the simulation converges much faster in the order of hours compared with real rock x ray scans we used these four samples to train the convolutional neural network 2 4 2 relationships between inputs and outputs the lattice boltzmann simulation outputs a pressure matrix and a velocity tensor in each point of the grid in this work we focused on the z component of the fluid velocity parallel to the pressure gradient which determines the permeability in fig 6 we show the velocity distribution and its relationship with the morphological features extracted from the binary image from the relationships exhibited in fig 6 we can confirm that traditional machine learning methods would not be able to obtain an accurate model due to the complex highly non linear relations between the inputs and the target output 3 results 3 1 impact of the proposed 3d feature extraction as stated above it would not be feasible to train our network over the entire simulation domains hence it is necessary to subsample the 3d matrices into smaller volumes to train the model with batches of data the reasoning behind this is that gpus have a limited amount of memory and the model parameters the inputs and outputs the gradients among others must be locally stored in our experiments the maximum subset size that conventional hardware could accommodate in memory was no larger than 803 the model as described by fig 4 requires 2 7 gigabytes gb of memory to be trained with a batch size of one sample to train the cnn with entire simulation domains one would require approximately 660 gb of memory available which greatly exceeds the current capabilities of graphic processing units spatially aware neural networks benefit greatly from stationary samples because it is easier to find matching patterns in data in theory the subset size of the 3d sample should be equal or larger than the representative element volume rev bachmat and bear 1987 to exhibit a stationary behavior of the property of interest in this case velocity impacting in a positive manner the training performance of the neural network if the subset data size is smaller than the rev we cannot expect to have a stable measure due to the non stationarities in the form of spatial heterogeneities present in the data to show the importance of our proposed feature extraction step in the training of the network we carried out a moving window analysis to assess the variability of the domains with different volume sizes pyrcz and deutsch 2014 using a window of increasing size length we calculate the coefficient of variation the ratio of the mean over the standard deviation of the porosity and fluid velocity within the subset we carried out this experiment in the original spherepack 36 porosity before the grain dilations where performed we executed this procedure iteratively until the variation became not significant we plotted the results of the moving window analysis in fig 7 both of the subplots show the decrease in variability of porosity and velocity respectively with the increase in the size of the window due to the homogeneity of the sample the 3d subset size comparison is shown in fig 8 it is only after 2003 voxels per side 40 of the image side length that the velocity field stabilizes coefficient of variation is less than 1 this behavior is more significant in tighter and less homogenous samples training the neural network using only the binary image of solid and pore as input will hamper the training process resulting in overfitting it fails to generalize causing the training and validation curves to diverge and poor predictive performance we carried out this experiment and the results are plotted in fig 9 since we are interested in creating a predictive model that is able to perform in different geometries we show that using the additional inputs which add additional information about the subvolume as well as how it relates to parts of the image surrounding it the latter in the form of time of flight described in section 2 2 the model increases its training performance and generalizes enough to predict the flow field within acceptable error range in a test set that includes various geometries in other words the model is able to find unique patterns to construct a robust function mapping the image with the fluid velocity 3 2 model training we implemented the model using the keras python library chollet 2015 with tensorflow abadi et al 2015 as the backend the model is optimized by minimizing the cost function eq 5 using adam kingma and ba 2014 with a learning rate of 1e 4 we used four sphere packs that present four subsequent grain dilations from the original sample as highlighted in section 2 4 1 and subsampled them into 1080 803 cubes for training with a 20 random validation split 216 cubes the model was trained with a mini batch size of five on a desktop with an nvidia quadro m6000 gpu for 140 epochs the model training process took twelve hours the inputs and the outputs are transformed using the minmax constraining them from minus one to one a comparison of the performance of three different model setups training with the binary image only training with the four proposed geometrical features and training utilizing the features plus the custom loss function is plotted in fig 9 we observed a significant performance increase in the loss value when using the extracted features and the proposed loss to assess the ability of the three trained models specified above to generalize the training data we first tested the model using the original sphere pack unseen by the models these were trained using the samples with the dilated grains only the model trained with the binary input gave a relative error in permeability of several orders of magnitude whereas the one using the four input features returned and error 15 and finally the model trained using the features plus the custom loss gave a relative error of 13 when compared to the lattice boltzmann simulation we carry out an extensive testing of the latter trained model in the sections below 3 3 model testing using the model trained with the four dilated spherepacks section 3 2 we tested its capabilities vs the navier stokes equation solution approximated by the lbm on domains of different size and complexity 3 3 1 fontainebleau sandstone dataset the first test set was obtained via a simulation of processes that occur during sedimentary rock formation i e sedimentation compaction diagenesis and cementation to obtain 3d volumes that resemble the fontainebleau sandstone formation in france berg 2016 these images are 4803 voxels and vary from 8 to 26 porosity we show a cross section through the middle of four of the samples in fig 10 we present the results in table 1 these are in very good agreement with the full physics simulation carried out to compare the performance of our model to analyze the error more closely we selected the worst performing sample 24 porosity sandstone for further analysis in fig 11 we show a visual comparison cross section of the 3d volume orthogonal to the flow direction of the lattice boltzmann solution with our model it is visible that most of the relevant flow features are preserved a comparison of the velocity histograms is shown in fig 12 it is worth noting that the flow streamlines are not always continuous and the 3d solution is not trained to satisfy mass balance hence the relative error additional constraints can be added to honor this but are out of scope for this work in here we are mostly interested in capturing the main flow characteristics preferred paths and dead ends that impact permeability 3 3 2 tests on different rock types to further test our model we predicted the flow field for different rock types available in digital rocks portal prodanovic et al 2015 we first created a sample similar in shape to the original training image by performing numerical grain erosion this creates a sample of larger porosity where grain boundaries are not as restrictive to fluid flow where the permeability is higher this case is of interest in irrigation garnier et al 1998 we further tested the original sphere pack the one that was numerically dilated to generate our training set our model yield accurate predictions in these two samples even when the porosities were larger with velocities that are also orders of magnitude higher than the training set we then tested the trained model on two outcrop sandstones a limestone and artificially created multiscale microsand image in these the relative error was not higher than 28 yang et al 2016 show that different fluid flow solvers will have a comparable discrepancy among them even when the same geometry is provided we present our results in table 2 we show the different 3d domains of the test set in fig 14 and a cross section of the results is shown in fig 15 these geometries have different pore shapes and in cases of limestone and microsand they have much wider pore size distribution compared to the training set fig 13 they also have different absolute volume sizes while two sandstones have similar absolute volume size 500 voxel on a side the relative error for prediction is very different 1 06 and 27 30 likely because they have different grain pore distribution as well as different number of individual grains per side which determines how well grain or pores are resolved note that our training set as well as the fontainebleau sandstone test in previous section all have similar level of resolution and hence we saw a very good prediction for all cases in table 1 given that the training set was comparatively simple we find the results in great agreement with the full physics simulations 4 conclusion we train a deep neural network architecture as a fast proxy to predict accurately the 3d physics based fluid flow velocity fields within digital rock samples the relationship between details of pore geometry and flow field with its integral measure of permeability is complex and not easily predicted based on the geometry statistics alone nevertheless this fundamental relationship allows describing how fluids move through subsurface formations and is the cornerstone of many research projects in environmental civil petroleum engineering as well as in geological sciences we demonstrated that our convolutional neural network generalizes the flow problem to predict flow velocity in rocks that host much more complex structures than the original training set this is attributed to the capacity of the network to model the complicated relationships between pore shape and domain characteristics with the velocity field the model performs well with rocks of varying types different lithology and of different grain distribution and porosities where the permeability ranged several orders of magnitude fig 16 the poreflow net calculates fluid flow fields in less than a second on a typical desktop compared with the standard simulation procedure which takes hours to days in a supercomputer facility depending on the hardware used as well as complexity of the digitized pore space geometry additionally the model is a lightweight representation around 25 mb whereas the full simulation results takes 20x the hard drive space the model can be reused in any given geometry while the simulation has to be run case by case future work should be focused on finding features that work with fractured domains and ultra tight rocks this method provides a framework for different further applications such as component transport relative permeability rock mechanics applications formation factor or resistivity these models provide a straightforward way to assess important characteristics for improved subsurface management without running expensive physical models and could possibly be a path to data based upscaling given the proliferation of digital rock images as evidenced in the digital rocks portal or online data available by different research groups blunt 2015 wildenschild 2006 credit authorship contribution statement javier e santos conceptualization methodology software validation formal analysis investigation writing original draft visualization duo xu conceptualization methodology visualization honggeun jo validation formal analysis investigation writing original draft writing review editing visualization christopher j landry software writing review editing maša prodanović resources data curation writing review editing supervision michael j pyrcz resources writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper reproducibility the code will be publicly available on the author s repository github com je santos and all the data used will be posted to digital rock portal upon publication acknowledgments we would like to thank risto miikkulainen and santiago gonzalez from the utcs neural networks research group for their valuable comments we would also like to acknowledge ying yin and wenhui song for their feedback on the flow model additionally we would like to thank renan rojas manish bhattarai and nicholas lubbers for their suggestions towards the improvement of the neural network model we gratefully recognize the texas advanced computing center for their high performance computing resources m pyrcz j santos and h jo acknowledge support from direct industry affiliates program iap and c landry and m prodanovic acknowledge support from digital rock petrophysics iap both of the university of texas finally we thank the four anonymous reviewers for their comments which greatly improved this paper supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103539 appendix b supplementary materials image application 1 appendix a1 calculating mask for custom loss function we calculate the weight matrix fig 17 using the following pseudocode image size 500 length of the volume side for i in range 0 image size loop along the z coordinate porosity z sum binary im i image size 2 calculate the porosity of the slice solid mask i 1 porosity z solid mask i multiply by a term that weights lower porosity sections fig 17 solid mask i solid mask i 0 1 replace the solids with a 1 solid mask i solid mask i sum solid mask i image size 2 normalize where the binary image is composed by a 3d matrix of zeros representing the solids and ones representing the space for fluid to flow 
508,the depth averaged velocity is the commonly used engineering quantity in natural rivers and it needs to be predicted in advance especially in flood seasons a model that can provide a unified physical foundation for open channel flows with different canopy densities remains lacking despite ongoing researches here we use the concept of the auxiliary bed to describe the influence of momentum exchange on rigid canopy elements with varying density and submergence the auxiliary bed divides the vegetated flow into a basal layer and a suspension layer to predict average velocity in each layer separately in the basal layer the velocity profile is assumed to be uniform in the suspension layer a parameter called penetration depth is applied to present the variations in velocity distribution we also apply a data driven method called genetic programming gp to derive chezy like predictors for average velocity in the suspension layer compared to the hydraulic resistance equation for rough wall flows the new formulae calculated by the weighted combination method show sound physical meanings in addition comparison with other models shows that the new dynamic two layer model achieves high accuracy in flow rate estimation especially for vegetated flow with sparse canopies keywords depth averaged velocity genetic programming open channel flow rigid submerged vegetation dynamic two layer model notation a canopy frontal area per volume b channel width bi observed values c parameter that depends on roughness geometry cb bed related chezy coefficient cd drag coefficient cdv vegetation related drag coefficient corresponding to ubv cu coefficient csl canopy shear layer d diameter of stems f darcy weisbach friction factor fr froude number g gravitational acceleration h water depth h substitute for hs δ e in gp h substitute for δ e in gp h representative length hs depth of water from surface to canopy top hv height of vegetation ks shear scale kinetic energy lh characteristic length scale of the shear scale vortices m parameter that depend on roughness geometry n sum of the datasets pi predicted values qb flow rate per width in the basal layer qc calculated flow rate qm measured flow rate re d reynolds numbers based on stem diameter re h reynolds numbers based on water depth u depth averaged velocity in the entire cross section u instantaneous velocity u time averaged velocity u deviations from the time averaged velocity u friction velocity on the rough river bed ub average velocity in the basal layer ubv average velocity surrounding the stems uh velocity at the top of the canopy us average velocity in the suspension layer u 1 velocity at the auxiliary plane x random value in the dataset x max maximum value of the data x min minimum value of the data xn normalized dimensionless data value β correction factor δ thickness of the csl δ e penetration depth λ solid volume fraction of canopy elements ν kinematic viscosity 1 introduction the presence of vegetation is of great importance in the overall conveyance capacity of natural channels darby 1999 stone and shen 2002 numerous studies have been conducted to explore the flow characteristics of vegetated open channels with many of them focusing on explicit velocity distribution huai et al 2009 nikora et al 2013 tang et al 2014 however in natural rivers depth averaged velocities are used more frequently than distinct velocity profiles in solving practical engineering problems li et al 2015b moreover canopy densities in actual situations are usually variable this means depth averaged velocity formulae that have a unified basis for vegetated flow with different canopy densities are still needed using rigid cylinders to mimic vegetation we attempt to develop a new model of depth averaged velocity in open channel flows with submerged vegetation of different densities the aim of this model is to explore the physical effects of vegetation stems without the additional biological factors such as leaves and root systems two major methods namely analytical and experimental methods are currently utilized to address the issue of depth averaged velocity the two layer division approach based on geometric factors is most commonly used stone and shen 2002 baptist et al 2007 huthoff et al 2007 yang and choi 2010 cheng 2011 shi et al 2019 for instance in the study of yang and choi 2010 submerged vegetated flow is divided into two layers namely vegetation and surface layers with the top of the canopy as the boundary which is shown in fig 1 a in the vegetation layer the velocity distribution is assumed to be uniform whereas in the surface layer a logarithmic velocity profile is adopted in these cases the average velocity in the surface layer is calculated by taking the height average scheme meanwhile the depth averaged velocity in the entire cross section is calculated by using the weighted combination method verification by experimental data or simulated data from numerical models shows that these simplified models are generally in good agreement when used to predict depth averaged velocity in open channel flows with submerged vegetation baptist et al 2007 huthoff et al 2007 yang and choi 2010 cheng 2011 li et al 2015b nonetheless as stated by li et al 2015b a simple layer division method merely based on geometric factors cannot reflect the turbulence features of vegetated flows especially when canopy densities change luhar et al 2008 and nepf 2012 drew attention to the difference in the internal flow mechanisms for vegetated flow with sparse and dense canopies they demonstrated that the difference depends on the relative importance of bed shear stress and canopy drag force for sparse canopies bed shear stress plays a more important role than canopy drag force in the vegetation layer thus the original momentum balance between potential gradients and canopy drag force no longer exists hence the velocity profile in the vegetation layer is close to that shown in open channel flows without vegetation fig 2 a and b for dense canopies the discontinuity in drag force occurs at the interface of submerged vegetated flow this phenomenon causes the kelvin helmholtz k h instability which leads to a region of strong vertical momentum exchange fig 2d in addition the transition between sparse and dense canopies takes place at cdahv 0 1 fig 2c where cd is the drag coefficient a is the canopy frontal area per volume and hv is the height of vegetation belcher et al 2003 for submerged vegetated flow the influence of vertical momentum exchange is not limited to the surface layer as it also penetrates into the vegetation layer this characteristic calls for a layer division method that can show the internal turbulence properties of submerged vegetated flow herein we apply the dynamic boundary based on the concept of auxiliary bed which is initially proposed by li et al 2015b the boundary divides the flow into an upper layer of vertical turbulent exchange called the suspension layer and a lower layer of longitudinal turbulent exchange called the basal layer as shown in fig 1 b nepf and vivoni 2000 for vegetated flow with sparse canopies this boundary overlaps with the channel bottom because the basal layer of longitudinal momentum exchange vanishes as for vegetated flow with dense canopies the dynamic boundary that splits the vertical and longitudinal momentum exchange can easily be observed within the canopies therefore the dynamic division method provides a unified physical basis for vegetated flow with both sparse and dense canopies by effectively representing the turbulence structures applied as a useful formulae derivation tool in previous studies baptist et al 2007 tinoco et al 2015 shi et al 2019 genetic programming gp algorithm is combined with the dynamic boundary to derive the depth averaged velocity in vegetated flow with rigid submerged canopies note that data in this study are collected from flume experiments where canopies are arranged in aligned or staggered forms the average velocity in each layer is considered separately in the basal layer the average velocity is derived from the momentum balance between potential gradients and canopy drag force in the suspension layer the average velocity is deduced from a mass of data by using the gp algorithm then data grouping and pre processing is conducted in terms of the physical basis for the auxiliary bed which is mainly about the generation and formation of k h vortices the maximum dissimilarity algorithm mda is applied to data selection camus et al 2011 goldstein et al 2013 the final formulae of depth averaged velocity for the entire cross section are obtained through weighted combination the physical meaning and performance of the proposed two layer model are illustrated in this study 2 materials and methods 2 1 genetic programming gp is a specific evolutionary technique that is frequently used to solve hydraulic engineering problems babovic et al 2001 huai et al 2018 goldstein and coco 2014 gp has gradually evolved into a useful and practical method for deriving data driven predictors since its development by schmidt and lipson 2009 in contrast to other techniques such as linear regression or artificial neural networks gp is particularly suitable for solving physical problems since it requires no previous knowledge of these problems thus we apply the gp algorithm to explore the internal flow structure in submerged vegetated flows in gp the data bank is divided into three groups namely training validation and testing groups koza 1992 with the validation group as the control group the training group eliminates solutions that show low suitability to the fitness function e g mean absolute error mae applied in this study and obtains the optimal solution the testing group shows no participation in the process of formulae searching the role of this group is to evaluate the feasibility of the result relative to other possible formulae in this study we use the widely tested and well documented gp software eureqa exploited by schmit and lipson 2013 to select a physically sound predictor koza 2010 the mathematical treatments chosen in the searching process include basic arithmetic operators such as multiplication division addition and subtraction and advanced operators such as exponents logarithms square root and power wang et al 2017 each operator exhibits its own complexity previously defined by eureqa in eureqa the default complexity values set for basic operators and advanced operators are 1 2 and 4 5 respectively this means basic operators should be taken as a priority to obtain predictors with smaller complexities during the process of formula searching eureqa continuously adds up the complexities of the possible predictors and keeps the ones with smaller errors under the same complexity in this process the pareto front is produced to view predictors as they rank by accuracy and complexity tinoco et al 2015 in the pareto front complex but accurate predictors appear at the lower right while simple but inaccurate predictors lie at the top left two aspects need to be considered to keep a balance between complexity and accuracy when selecting the best predictor firstly we must be aware that an oversimplified solution cannot reflect the physical relationships among variables meanwhile a solution with high complexity reveals more numerical relations than physical meanings secondly we need to refer to the pareto front and choose the optimal solution with relatively low complexity and high accuracy this optimal solution usually appears as a cliff point in the middle of a figure wang et al 2017 2 2 physical basis for auxiliary bed raupach et al 1996 made an analogy between the flow within terrestrial and aquatic canopies and then explored internal mechanisms of the case with aquatic canopies flow within terrestrial canopies is driven by the vertical momentum transport at the top of the canopy where large coherent vortices form and continually grow downstream without the limitation of a free shear layer kaimal and finnigan 1994 belcher et al 2011 in aquatic canopies potential gradients and turbulent stress are important in driving flow within the canopy nepf 2012 thus with the constraint of the canopy shear layer csl the formation of canopy scale vortices k h vortices due to drag discontinuity is related to a combination of factors such as stem morphology and depth of submergence the growth of the k h vortices stops when the energy balance is reached according to nepf et al 2007a the depth of submergence h hv where h is the water depth is closely connected to the turbulent structure of vegetated flow three different scales of turbulence are present that is the boundary layer vortices the k h vortices and the stem scale vortices the boundary layer vortices usually appear in the upper region of deeply submerged vegetated flow and exhibit the largest scale the k h vortices form at the top of the canopy and the stem scale vortices are as the same scale as canopy elements the relative importance of different vortices to momentum transport changes with the depth of submergence for condition h hv 2 the free water surface constrains the growth of k h vortices nepf and vivoni 2000 for condition 2 h hv 5 k h vortices are limited by neither the water surface nor the river bottom and thus can progress unaffectedly moreover the presence of boundary layer vortices is restricted by the water surface and exerts little influence on the existence of k h vortices as previously mentioned k h vortices in the csl reach a fixed scale when the shear production is balanced by dissipation of canopy drag this fixed shear layer scale is reached at approximately 10hv from the canopy s leading edge ghisalberti and nepf 2002 for condition 5 h hv 10 the state of k h vortices starts to transform from persistent to intermittent during this process the role of boundary layer vortices becomes more important in this condition vegetated flow is driven by turbulent stress and potential gradient in contrast flow within canopies is driven only by the vertical turbulent exchange of momentum for with little contribution from pressure gradients raupach et al 1991 internal mechanism in flow for condition h hv 10 is similar to that in flow within terrestrial canopies nepf et al 2007a noting that the effects of boundary layer vortices are neglected to simplify the problem we concentrate on the energy balance for condition 2 h hv 10 to derive the penetration depth δ e furthermore we restrict our attention to cases for which cdahv 0 1 for sparse canopies no inflection point can be generated without evident velocity disparity at the top of the canopy to trigger k h instability the limit 0 1 is based on canopy experiments conducted by dunn et al 1996 and poggi et al 2004 penetration depth is the distance between the top of canopies and the effective momentum boundary where the reynolds stress drops to 10 of its peak value nepf and vivoni 2000 the definition of penetration depth is based on the shear scale turbulence kinetic energy budget which can be simplified in eq 1 luhar et al 2008 1 d d t k s u w z u 1 2 c d a u 2 u 2 v 2 w 2 with the velocity vector u u v w corresponding to the coordinates x y z the instantaneous velocity is comprised of the time average overbar and deviations from the time average single prime in eq 1 ks represents shear scale kinetic energy the first term on the right hand side is shear production and the second term means canopy dissipation variable ks remains constant as the growth of k h vortices stops hence the balance between shear production and canopy dissipation is achieved we re arrange eq 1 to directly express the relationship between mean flow velocity and turbulence characteristics 2 u c d a u z 2 u w 2 u 2 v 2 w 2 nepf et al 2007a tested eq 2 using experimental data from several studies and verified that the values of the two terms are comparable that is approximately 0 21 we expect the left side term to be a fixed value at the inflection point in the velocity profile the term is defined as the following csl parameter 3 c s l u c d a u z where cd is assumed to be 1 0 as suggested by huai et al 2009 the turbulence scale u u z is regarded as the characteristic length scale of the shear scale vortices lh where the subscript h denotes evaluation at the top of the canopy z hv nepf and vivoni 2000 li et al 2015b 4 l h u u z two approximate assumptions are made to obtain an estimate value of the penetration depth from eq 4 see fig 3 firstly we assume that u u h given that the inflection point is close to z hv secondly the ratio uh δ e is used to estimate the velocity shear u z such an estimation is particularly reasonable for vegetated flow with dense canopies since the velocity at the auxiliary plane u 1 is small enough to be neglected nepf et al 2007b the experiments of nepf and vivoni 2000 indicated that the estimation equation of δ e for conditions h hv 2 and cdahv 0 1 can be obtained by applying eq 5 in eq 5 a fixed value for csl only exists for condition cdahv 0 25 as for condition 0 1 cdahv 0 25 only a coarse approximation of δ e is presented however theoretically δ e should be linearly related to cda 1 in both cases this discrepancy may result from the second assumption we make to derive δ e a further explanation is that for flow with relatively sparse canopies 0 1 cdahv 0 25 the velocity at the auxiliary plane u 1 increases which makes the ignorance of u 1 unreasonable in the estimation of the velocity shear u z therefore we should estimate u z by uh u 1 δ e in this condition the modified equation of δ e is shown in eq 6 the comparison between eqs 5 and 6 shows that the coefficient 0 85 1 0 for 0 1 cdahv 0 25 corresponds to uh u 1 uh 5 δ e 0 21 0 03 c d a 0 85 1 0 h v for c d a h v 0 25 0 1 c d a h v 0 25 6 δ e c s l u h u 1 u h c d a for condition h hv 2 a correction factor β h hv 1 is introduced as a linear simplification in the calculation of δ e see eq 7 li et al 2015b the accuracy of the modified equation is evaluated by the error metrics of discharge in section 4 1 7 δ e β 0 21 0 03 c d a 0 85 1 0 h v for c d a h v 0 25 0 1 c d a h v 0 25 the penetration depth δ e separates the submerged vegetated flow into an upper layer of energetic turbulent transport and a lower layer of diminished transport nepf 2012 thus an auxiliary plane is presumed to be at the level z hv δ e regarding this plane as the effective momentum boundary the flow is segregated into two layers the basal layer z hv δ e and the suspension layer z hv δ e in the basal layer the stem scale turbulence is generated in the wakes of individual canopy elements and the velocity distribution is rather uniform in the suspension layer the shear scale turbulence holds the dominant position and thus leads to a hyperbolic tangent profile in the csl based on the embodied effects of motive turbulence and velocity distribution the new division of layers is valid to reflect the flow structures of submerged vegetated flow the average velocity in each layer is calculated in the next section 2 3 layer averaged velocity the depth averaged velocity in the entire cross section u can be calculated by individually considering the basal and suspension layers cheng 2011 stated that average velocity in the basal layer is close to that in emergent vegetated flow the layer averaged velocity can be deduced from the momentum balance between potential gradients and canopy drag force 8 g s 1 λ 1 2 c d v a u b v 2 where s is the energy slope and λ is the solid fraction of canopy elements ubv is the average velocity surrounding the stems and it can be computed as ubv ub 1 λ to remove the influence of the space occupation of vegetation stems where ub is the average velocity in the basal layer cdv is the drag coefficient developed by cheng and nguyen 2011 9 c d v 130 π 1 λ d 4 λ g s v 2 1 3 0 85 0 8 1 exp π 1 λ d 4 λ g s v 2 1 3 400 where g is the gravitational acceleration and ν is the kinematic viscosity the solution for eq 8 is as follows 10 u b v 2 g s 1 λ c d v a the flow rate per width in the basal layer can be computed by qb ubv hv δ e 1 λ then the average velocity in the suspension layer us can be deduced based on the measured total discharge 11 u s q m q b b h s δ e b where qm is the measured total discharge and b is the channel width 2 4 data grouping and pre processing in flume experiments the setup of vegetation can be altered to explore the influence of certain aspects on vegetated flow for instance vegetation can be arranged in aligned staggered or randomly distributed forms to explore the influence of arrangement mode the vegetation itself can also be in rigid or flexible state to investigate the effect of vegetation flexibility however data collected from one research project are still limited due to the restriction of experiment conditions therefore a predictor obtained from a single dataset of one source may reflect a specific feature rather than represent general characteristics of vegetated flow tinoco et al 2015 thus data should be collected from multiple datasets to represent a broad parameter space to avoid such problems in this study we analyse multiple datasets collected from previous studies shimizu et al 1991 dunn et al 1996 meijer and van velzen 1999 lopez and garcia 2001 stone and shen 2002 stone 1997 poggi et al 2004 ghisalberti and nepf 2004 baptist et al 2005 murphy et al 2007 liu et al 2008 nezu and sanjou 2008 yan 2008 yang 2008 cheng 2011 she et al 2010 hao 2014 yang et al 2018 shi 2018 gualtieri et al 2018 song et al 2019 in total 493 datasets obtained from laboratory experiments are collected see appendix a in most experiments rigid cylinders arranged in aligned or staggered forms are used to simulate submerged canopies the only exception comes from nezu and sanjou 2008 where flat strips were used to represent canopy stems herein the strip width is regarded as the stem diameter d as suggested by cheng 2011 the dataset shows a wide range of relative submergence h hv of 1 08 8 8 reynolds numbers based on water depth re h u h ν 1 are in the range of 3769 09 2 721 109 and reynolds numbers based on stem diameter re d u d ν 1 are in the range of 55 74 9032 73 all datasets are classified based on the concept of auxiliary bed demonstrated above according to the restriction of water surface on the development of k h vortices we divide the entire dataset into two groups one group contains 267 datasets for h 2hv and the other group contains 226 datasets for h 2hv considering the relation between penetration depth δ e and vegetation height hv we further segregate the 267 datasets for h 2hv into two parts one part comprises 149 datasets for δ e hv cdahv 0 1 and the other part comprises 118 datasets for δ e hv cdahv 0 1 the classification of the 226 datasets for h hv 2 is conducted in the same way though the computation method for δ e is slightly different the grouping result is shown in table 1 to derive a physically sound predictor for average velocity in the suspension layer us the grouped data needs to be pre processed to meet the requirement of gp algorithm in the next step many depth averaged velocity formulae were proposed by previous studies baptist et al 2007 huthoff et al 2007 cheng 2011 li et al 2015b tinoco et al 2015 shi et al 2019 some of which are shown in section 4 1 for comparison the common feature of these formulae is that they are all in chezy like form regardless of different hypotheses thus the target solution should be set in chezy like form to obtain a similar predictor that is as effective as previous ones tinoco et al 2015 and wang et al 2017 suggested that the gp algorithm should be fed with non dimensional data groups instead of dimensional parameters to conform to buckingham s pi theorem herein seven related dimensional variables namely us d hv hs s a and δ e are transformed into non dimensional ones the five non dimensional variables are the froude number fr us g hs δ e 0 5 energy slope s solid volume fraction of canopy elements λ and length scale ratios h s δ e δ e h s δ e d and aδ e two non dimensional variables are ignored because they can be calculated with other parameters such as a h s δ e a δ e h s δ e δ e and a d 4 λ π reynolds numbers such as re d u d υ and re h u h υ are related to the target parameter us hence to avoid the self relating problem reynolds numbers are not considered therefore the target predictor is assumed to be like f r s f λ h s δ e δ e h s δ e d a δ e to simplify the expression form of the solutions in gp the target predictor is further transformed to be f r s f λ h h h d a h with h corresponding to hs δ e and h corresponding to δ e in gp the training and validation groups that comprise the processed datasets are used to feed the algorithm the way to obtain such groups is explained in detail in the next step 2 5 data selection data selection is an important procedure in using the gp algorithm that directly determines the applicability of possible solutions here the maximum dissimilarity algorithm mda developed by camus et al 2011 and goldstein et al 2013 is applied to conduct the process of data selection this algorithm has been successfully applied in previous studies tinoco et al 2015 wang et al 2017 huai et al 2018 shi et al 2019 to solve such problems compared with other selection algorithms such as k means algorithm kma and self organizing maps som camus et al 2011 the mda can select data from the periphery of the parameter space in addition the mda requires few data points that are the representative of the data bank to acquire a relatively accurate solution wang et al 2017 three major steps need to be taken to properly perform the mda tinoco et al 2015 firstly since the data ranges of different variables vary greatly we need to rescale the values of these variables to the same magnitude to improve the performance of eureqa herein we normalize the abovementioned dimensionless variables by xn x x min x max x min where x max is the maximum value of the data x min is the minimum value of the data x is a random value in the dataset and xn represents the normalized dimensionless data value secondly the first centroid is selected which is the maximum value of λ in this study according to the work of tinoco et al 2015 the farthest data point from the first centroid is chosen as the second centroid by evaluating the distances between the first centroid and the other data points in the same way a series of centroids is selected which composes a new normalized dataset this dataset consequently comprises the odd data on the edge of the data bank thirdly we de normalize the new dataset into the original data with x xn x max x min x min as can be seen in table 1 the whole dataset is first divided into two categories h 2hv and h 2hv by the submergence for condition h 2hv we simplify the calculation of δ e by introducing the correction factor β see eq 7 which means a small portion of data still deviates from the pre supposed linear relation hence datasets for condition h 2hv are not included in the data selection process to avoid unnecessary errors for condition h 2hv the 267 datasets are further classified into two parts by the canopy density that is the 149 datasets for cdahv 0 1 and the 118 datasets for cdahv 0 1 herein we take the 149 datasets as an example of data selection according to the three major steps when the mda is conducted for the first time the 149 datasets are divided into the rest group and the training group with the latter accounting for 30 of the whole dataset when the mda is performed again for the rest group the validation and testing groups are produced which include 30 and 40 of the whole dataset respectively the data selection process for the 118 datasets is conducted in the same way in the end data from the training and validation groups are fed to the gp algorithm to derive the optimal solution detailed work on the mda is available in the works of tinoco et al 2015 and wang et al 2017 2 6 formula searching first we take the 149 datasets that are in the condition of cdahv 0 1 to perform the process of formulae searching as mentioned above the 90 datasets from the training and validation groups are fed to the gp algorithm the mae is chosen as the fitness function in eureqa tinoco et al 2015 wang et al 2017 huai et al 2018 shi et al 2019 12 m a e 1 n i 1 n p i b i where n is the sum of the datasets pi and bi are the predicted and observed values respectively after 16 h with 1 2 1011 formulae evaluated eureqa produces a list of solutions with different complexities see table 2 the most intricate solution complexity of 19 is the best predictor in terms of the mae but it presents more statistical characteristics than physical meanings considering both accuracy and complexity we choose the solution of complexity 5 as the optimal predictor eq 13 this solution is in chezy like form and appears as a cliff point on the pareto front fig 4 13 u s g h s δ e s 4 42 0 0105 h s δ e d for condition cdahv 0 1 the 118 datasets are also divided into three groups the proportion of which are the same as that of the 149 datasets for condition cdahv 0 1 after formulae searching the pareto front for solutions is shown in fig 5 and the result is listed in table 3 here two solutions appear as cliff points in the figure with the complexity of 5 and 8 respectively compared with the first solution mae of the second solution decreases almost 50 with the complexity increasing only 3 thus the solution with the complexity of 8 eq 14 is chosen as the optimal predictor which strikes a better balance between accuracy and complexity 14 u s g h s 6 26 0 0195 h h v a h v to examine the stability of gp we conduct the data selection process mda again to change the sizes of the training and validation groups into 40 of the whole dataset and then obtain another set of formulae for condition cdahv 0 1 and cdahv 0 1 the optimal solutions are eqs 15 and 16 respectively it can be seen that both eqs 15 and 16 have the same structure as the former solutions see eqs 13 and 14 only with the coefficients being slightly different this corresponds to the findings of tinoco et al 2015 in which a solution with the same structure is found even if the size and composition of datasets change they believed that it is the structure of solutions that reveals the physical meanings of the problem and the slight change in coefficients does not make much difference herein comparisons between the former eqs 13 and 14 and the latter eqs 15 and 16 optimal solutions are made in section 4 1 as a verification the results show that the former solutions perform slightly better than the latter solutions and thus are chosen as the optimal solutions 15 u s g h s δ e s 4 7 0 0101 h s δ e d 16 u s g h s 6 24 0 0196 h h v a h v 3 results the depth averaged velocity in the entire cross section u is computed by taking the weighted average of the average velocity in each layer the equation can be described as follows 17 u u s h s δ e u b v h v δ e 1 λ h then the formulae for depth averaged velocity in different situations are obtained for condition cdahv 0 1 18 u g h s 2 1 λ 3 c d v a h v δ e h 3 2 4 42 0 0105 h s δ e d h s δ e h 3 2 meanwhile for condition cdahv 0 1 19 u u s g h s 6 26 0 0195 h h v a h v nikora et al 2001 derived the relationship between velocity distribution and hydraulic resistance for open channel flow over a rough bed this relationship can explain the physical meanings of data driven predictors for submerged vegetated flow by analogy an estimation formula for the darcy weisbach friction factor is proposed by nikora et al 2001 20 f 8 u 2 u 2 8 c 2 m 2 δ h 2 where u is the friction velocity on the rough river bed u is the time averaged flow velocity c and m are parameters that depend on roughness geometry which are usually considered as constants δ is the thickness of the csl which is approximately equal to the roughness height for conditioncdahv 0 1 the friction velocity on the auxiliary bed is assumed to be u g h s δ e s due to the force balance in the suspension layer thus the average velocity in the suspension layer eq 13 can be transformed to express the friction factor on the auxiliary bed 21 f 8 u 2 u s 2 1 4 42 0 0105 h s δ e d 2 in contrast to eq 20 the following relation is derived 22 4 42 0 0105 h s δ e d c m h s δ e δ e according to nikora et al 2001 and nepf et al 2007a δ e also means the scale of eddies generated in the canopy elements and the scale is the same as the diameter of stems d hence the friction factor effectively reflects the influence of relative submergence on hydraulic resistance on the auxiliary bed for condition cdahv 0 1 the auxiliary bed overlaps with the river bed thereby indicating that the friction factor transformed from eq 19 is also for the river bed 23 f 8 u 2 u 2 1 6 26 0 0195 h h v a h v 2 the following relation is obtained by analogy 24 6 26 0 0195 h h v a h v c m h h v as indicated by eq 24 two parameters c and m which represent the geometric features of the canopy elements are no longer constants that is to say for sparse canopies both relative submergence and canopy density are important in predicting the hydraulic resistance of the river bed in submerged vegetated flow 4 discussion 4 1 comparison with previous models the following is a list of previously proposed models for estimating the depth averaged velocity in the entire cross section 1 baptist et al 2007 baptist et al obtained the following formula by applying the dimensionally aware gp to the simulated data of the one dimensional vertical 1 dv model for submerged vegetation 25 u g h s 1 g c b 2 2 c d λ h v π d 2 5 ln h h v where cb is the bed related chezy coefficient which is approximately computed as 60 m0 5s 1 for the smooth bed and the drag coefficient cd is assumed to be 1 0 2 huthoff et al 2007 huthoff et al utilized the traditional two layer division method and proposed the following formula by taking the weighted combination of average velocity in each layer 26 u g h s π d 2 c d λ h h v h h s h h s π 4 λ 1 d 2 3 1 h h v 5 where the drag coefficient cd is approximately 1 0 3 yang and choi 2010 yang and choi assumed that the velocity profile is uniform in the vegetation layer and logarithmic in the surface layer the following expression was deduced by simply adding up the average velocity in each layer 27 u π g d h s 2 c d h v λ c u g h s s 0 41 ln h h v h s h where cd 1 13 cu 1 for 4λ πd 5 and cu 2 for 4λ πd 5 4 cheng 2011 by transforming the concept of hydraulic radius cheng proposed an estimation of the depth averaged velocity by formulating the representative roughness height of submerged vegetation 28 u g h s π 1 λ 3 2 c d v λ d h v h v h 3 2 4 54 h s d 1 λ λ 1 16 h s h 3 2 where the calculation of cdv is shown in eq 9 5 li et al 2015b li et al proposed a new parameter called effective relative roughness height by using the same dynamic division method to predict the friction factor in the suspension layer meanwhile the calculation of average velocity in the basal layer is also the same as that in the current study 29 u g h s 1 96 h s δ e 5 3 λ δ e 1 6 h 3 2 1 λ h v δ e h 1 2 h 3 2 where the representative length h is computed as h 2 1 λ cdva and the calculation of cdv is shown in eq 9 we choose the mean relative error mre and mean squared error mse as the error metrics to evaluate the accuracy of different formulae 30 m r e 1 n i 1 n p i b i b i 31 m s e 1 n i 1 n p i b i 2 the comparison results of the flow rate estimated by each formula are plotted in fig 6 cdahv 0 1 and fig 7 cdahv 0 1 noting that the unit of flow rate transforms into liters per second the error metrics for different predictors are summarized in table 4 cdahv 0 1 and table 5 cdahv 0 1 table 4 and fig 6 illustrate that for condition cdahv 0 1 eq 18 is in good agreement with data for h 2hv and h 2hv the formulae derived by huthoff et al 2007 cheng 2011 and li et al 2015b present higher accuracies than the other two models this finding may be explained by the fact that both cheng 2011 and li et al 2015b applied a concept similar to the representative roughness height to describe the influence of stem induced roughness although the layer division method was different as shown in fig 6 c the formula given by yang and choi 2010 evidently underestimates the flow rate in the high flow rate region li et al 2015b explained that the deviations may result from adopting a logarithmic velocity profile in the surface layer in contrast the formula given by baptist et al 2007 overestimates the flow rate especially in the low flow rate region this deviation may be due to the derivation of the data driven formula with simulated data from a numerical model in table 4 the comparison of prediction results produced by eqs 13 and 15 shows that eq 13 is the better solution in predicting the discharge for vegetated flow with dense canopies for condition cdahv 0 1 eq 19 apparently shows higher accuracy compared with other formulae as illustrated in table 5 and fig 7 in contrast to cases where canopies are dense the formulae derived by huthoff et al 2007 cheng 2011 and li et al 2015b show a similar tendency to underestimate the discharge for cases where canopies are sparse from fig 7 c it can be seen that the formula given by yang and choi 2010 matches quite well with the data this consistency verifies that for sparse canopies velocity profile in the surface layer fits the logarithmic law the formula proposed by baptist et al 2007 also shows an acceptable fitness to the data by using the gp algorithm in addition we compare eq 14 with eq 16 in predicting the discharge for vegetated flow with sparse canopies with the same structure of expression eq 14 exhibits a slightly higher accuracy than eq 16 by comparing the prediction results when the canopy density changes it can be seen that all formulae from other studies can only perform well for one case that is vegetated flow with sparse or dense canopies in contrast formulae of the present model eqs 18 and 19 show desirable predictive ability in both cases especially for flow with sparse canopies the above mentioned analyses illustrate the superiority of the present dynamic two layer model in two aspects firstly the formula based on the gp algorithm performs effectively in predicting flow rates in vegetated flow with rigid submerged canopies secondly the new dynamic boundary can provide a unified basis for vegetated flow with sparse and dense canopies this unified basis helps reflect the internal turbulent characteristics of vegetated flow in addition it also makes up for the deficiency of the original two layer model in predicting depth averaged velocity of vegetated flow with sparse canopies 4 2 limitation of present model a broad dataset is collected from previous studies to build the dynamic two layer model this model shows fairly good applicability as verified above nonetheless some limitations still exist for the present model for instance among the 118 datasets used to derive the predictor for δ e hv 88 datasets are collected from gualtieri et al 2018 nevertheless the predictor still effectively performs for multiple datasets instead of one specific dataset three reasons are given to confirm the wide applicability of the predictor see eq 19 firstly multiple canopy densities and submergence ratios are included in the 88 datasets which reduces the monotony of the datasets secondly the remaining 30 datasets are collected from 6 sources dunn et al 1996 lopez and garcia 2001 poggi et al 2004 yang 2008 she et al 2010 shi 2018 thirdly the predictor still performs well for datasets in the testing group which are not fed to the gp algorithm another important concern is that only 32 subsets of data exist in the condition δ e hv and h 2hv however the 32 datasets are collected from 6 data sources dunn et al 1996 liu et al 2008 she et al 2010 hao et al 2014 gualtieri et al 2018 shi 2018 thereby making the prediction convincing to some extent substantial experimental work needs to be performed to increase the amount of data diversify the data sources for δ e hv and ultimately solve the two abovementioned problems for flexible canopies the presence of a waving motion triggered by canopy scale vortices leads to a deep penetration of reynolds stress ghisalberti and nepf 2009 consequently the velocity around the stems expands and the momentum transport is less efficient with such a complex dynamic process involved the present model is unsuitable for vegetated flow with flexible vegetation 5 summary in this study we combine the concept of auxiliary bed proposed by li et al 2015b with the gp algorithm to predict the depth averaged velocity in submerged vegetated flow we segregate the vegetated flow into the basal and suspension layers while considering the auxiliary bed as the boundary the average velocity in the basal layer is derived from the momentum balance for the suspension layer the gp algorithm is applied to obtain two sets of predictors for open channel flow with sparse and dense canopies on the analogy of rough bed flow we explain the physical meanings of the two predictors by associating them with the friction factors on the auxiliary bed evidently both relative submergence and canopy density play important roles in hydraulic resistance in submerged vegetated flow the comparison with previous studies shows that the predictors greatly match with the experimental data especially for flow with sparse canopies consequently the new dynamic two layer model can provide a unified physical basis for flow with sparse and dense canopies furthermore this model is distinctly advantageous when predicting the depth averaged velocity in vegetated flow with sparse canopies the model produced in this study may help deal with the hydraulic engineering problems of vegetated open channel flows with various canopy densities credit authorship contribution statement fan yang conceptualization methodology software validation formal analysis investigation writing original draft writing review editing visualization wen xin huai conceptualization methodology writing review editing supervision project administration funding acquisition yu hong zeng writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work is financially supported by the national natural science foundation of china nos 11872285 11672213 and 51439007 the authors thank v pasquino for providing the experimental data to help with the manuscript comments and suggestions made by the editor dr d odorico and reviewers have greatly improved the quality of the paper 
508,the depth averaged velocity is the commonly used engineering quantity in natural rivers and it needs to be predicted in advance especially in flood seasons a model that can provide a unified physical foundation for open channel flows with different canopy densities remains lacking despite ongoing researches here we use the concept of the auxiliary bed to describe the influence of momentum exchange on rigid canopy elements with varying density and submergence the auxiliary bed divides the vegetated flow into a basal layer and a suspension layer to predict average velocity in each layer separately in the basal layer the velocity profile is assumed to be uniform in the suspension layer a parameter called penetration depth is applied to present the variations in velocity distribution we also apply a data driven method called genetic programming gp to derive chezy like predictors for average velocity in the suspension layer compared to the hydraulic resistance equation for rough wall flows the new formulae calculated by the weighted combination method show sound physical meanings in addition comparison with other models shows that the new dynamic two layer model achieves high accuracy in flow rate estimation especially for vegetated flow with sparse canopies keywords depth averaged velocity genetic programming open channel flow rigid submerged vegetation dynamic two layer model notation a canopy frontal area per volume b channel width bi observed values c parameter that depends on roughness geometry cb bed related chezy coefficient cd drag coefficient cdv vegetation related drag coefficient corresponding to ubv cu coefficient csl canopy shear layer d diameter of stems f darcy weisbach friction factor fr froude number g gravitational acceleration h water depth h substitute for hs δ e in gp h substitute for δ e in gp h representative length hs depth of water from surface to canopy top hv height of vegetation ks shear scale kinetic energy lh characteristic length scale of the shear scale vortices m parameter that depend on roughness geometry n sum of the datasets pi predicted values qb flow rate per width in the basal layer qc calculated flow rate qm measured flow rate re d reynolds numbers based on stem diameter re h reynolds numbers based on water depth u depth averaged velocity in the entire cross section u instantaneous velocity u time averaged velocity u deviations from the time averaged velocity u friction velocity on the rough river bed ub average velocity in the basal layer ubv average velocity surrounding the stems uh velocity at the top of the canopy us average velocity in the suspension layer u 1 velocity at the auxiliary plane x random value in the dataset x max maximum value of the data x min minimum value of the data xn normalized dimensionless data value β correction factor δ thickness of the csl δ e penetration depth λ solid volume fraction of canopy elements ν kinematic viscosity 1 introduction the presence of vegetation is of great importance in the overall conveyance capacity of natural channels darby 1999 stone and shen 2002 numerous studies have been conducted to explore the flow characteristics of vegetated open channels with many of them focusing on explicit velocity distribution huai et al 2009 nikora et al 2013 tang et al 2014 however in natural rivers depth averaged velocities are used more frequently than distinct velocity profiles in solving practical engineering problems li et al 2015b moreover canopy densities in actual situations are usually variable this means depth averaged velocity formulae that have a unified basis for vegetated flow with different canopy densities are still needed using rigid cylinders to mimic vegetation we attempt to develop a new model of depth averaged velocity in open channel flows with submerged vegetation of different densities the aim of this model is to explore the physical effects of vegetation stems without the additional biological factors such as leaves and root systems two major methods namely analytical and experimental methods are currently utilized to address the issue of depth averaged velocity the two layer division approach based on geometric factors is most commonly used stone and shen 2002 baptist et al 2007 huthoff et al 2007 yang and choi 2010 cheng 2011 shi et al 2019 for instance in the study of yang and choi 2010 submerged vegetated flow is divided into two layers namely vegetation and surface layers with the top of the canopy as the boundary which is shown in fig 1 a in the vegetation layer the velocity distribution is assumed to be uniform whereas in the surface layer a logarithmic velocity profile is adopted in these cases the average velocity in the surface layer is calculated by taking the height average scheme meanwhile the depth averaged velocity in the entire cross section is calculated by using the weighted combination method verification by experimental data or simulated data from numerical models shows that these simplified models are generally in good agreement when used to predict depth averaged velocity in open channel flows with submerged vegetation baptist et al 2007 huthoff et al 2007 yang and choi 2010 cheng 2011 li et al 2015b nonetheless as stated by li et al 2015b a simple layer division method merely based on geometric factors cannot reflect the turbulence features of vegetated flows especially when canopy densities change luhar et al 2008 and nepf 2012 drew attention to the difference in the internal flow mechanisms for vegetated flow with sparse and dense canopies they demonstrated that the difference depends on the relative importance of bed shear stress and canopy drag force for sparse canopies bed shear stress plays a more important role than canopy drag force in the vegetation layer thus the original momentum balance between potential gradients and canopy drag force no longer exists hence the velocity profile in the vegetation layer is close to that shown in open channel flows without vegetation fig 2 a and b for dense canopies the discontinuity in drag force occurs at the interface of submerged vegetated flow this phenomenon causes the kelvin helmholtz k h instability which leads to a region of strong vertical momentum exchange fig 2d in addition the transition between sparse and dense canopies takes place at cdahv 0 1 fig 2c where cd is the drag coefficient a is the canopy frontal area per volume and hv is the height of vegetation belcher et al 2003 for submerged vegetated flow the influence of vertical momentum exchange is not limited to the surface layer as it also penetrates into the vegetation layer this characteristic calls for a layer division method that can show the internal turbulence properties of submerged vegetated flow herein we apply the dynamic boundary based on the concept of auxiliary bed which is initially proposed by li et al 2015b the boundary divides the flow into an upper layer of vertical turbulent exchange called the suspension layer and a lower layer of longitudinal turbulent exchange called the basal layer as shown in fig 1 b nepf and vivoni 2000 for vegetated flow with sparse canopies this boundary overlaps with the channel bottom because the basal layer of longitudinal momentum exchange vanishes as for vegetated flow with dense canopies the dynamic boundary that splits the vertical and longitudinal momentum exchange can easily be observed within the canopies therefore the dynamic division method provides a unified physical basis for vegetated flow with both sparse and dense canopies by effectively representing the turbulence structures applied as a useful formulae derivation tool in previous studies baptist et al 2007 tinoco et al 2015 shi et al 2019 genetic programming gp algorithm is combined with the dynamic boundary to derive the depth averaged velocity in vegetated flow with rigid submerged canopies note that data in this study are collected from flume experiments where canopies are arranged in aligned or staggered forms the average velocity in each layer is considered separately in the basal layer the average velocity is derived from the momentum balance between potential gradients and canopy drag force in the suspension layer the average velocity is deduced from a mass of data by using the gp algorithm then data grouping and pre processing is conducted in terms of the physical basis for the auxiliary bed which is mainly about the generation and formation of k h vortices the maximum dissimilarity algorithm mda is applied to data selection camus et al 2011 goldstein et al 2013 the final formulae of depth averaged velocity for the entire cross section are obtained through weighted combination the physical meaning and performance of the proposed two layer model are illustrated in this study 2 materials and methods 2 1 genetic programming gp is a specific evolutionary technique that is frequently used to solve hydraulic engineering problems babovic et al 2001 huai et al 2018 goldstein and coco 2014 gp has gradually evolved into a useful and practical method for deriving data driven predictors since its development by schmidt and lipson 2009 in contrast to other techniques such as linear regression or artificial neural networks gp is particularly suitable for solving physical problems since it requires no previous knowledge of these problems thus we apply the gp algorithm to explore the internal flow structure in submerged vegetated flows in gp the data bank is divided into three groups namely training validation and testing groups koza 1992 with the validation group as the control group the training group eliminates solutions that show low suitability to the fitness function e g mean absolute error mae applied in this study and obtains the optimal solution the testing group shows no participation in the process of formulae searching the role of this group is to evaluate the feasibility of the result relative to other possible formulae in this study we use the widely tested and well documented gp software eureqa exploited by schmit and lipson 2013 to select a physically sound predictor koza 2010 the mathematical treatments chosen in the searching process include basic arithmetic operators such as multiplication division addition and subtraction and advanced operators such as exponents logarithms square root and power wang et al 2017 each operator exhibits its own complexity previously defined by eureqa in eureqa the default complexity values set for basic operators and advanced operators are 1 2 and 4 5 respectively this means basic operators should be taken as a priority to obtain predictors with smaller complexities during the process of formula searching eureqa continuously adds up the complexities of the possible predictors and keeps the ones with smaller errors under the same complexity in this process the pareto front is produced to view predictors as they rank by accuracy and complexity tinoco et al 2015 in the pareto front complex but accurate predictors appear at the lower right while simple but inaccurate predictors lie at the top left two aspects need to be considered to keep a balance between complexity and accuracy when selecting the best predictor firstly we must be aware that an oversimplified solution cannot reflect the physical relationships among variables meanwhile a solution with high complexity reveals more numerical relations than physical meanings secondly we need to refer to the pareto front and choose the optimal solution with relatively low complexity and high accuracy this optimal solution usually appears as a cliff point in the middle of a figure wang et al 2017 2 2 physical basis for auxiliary bed raupach et al 1996 made an analogy between the flow within terrestrial and aquatic canopies and then explored internal mechanisms of the case with aquatic canopies flow within terrestrial canopies is driven by the vertical momentum transport at the top of the canopy where large coherent vortices form and continually grow downstream without the limitation of a free shear layer kaimal and finnigan 1994 belcher et al 2011 in aquatic canopies potential gradients and turbulent stress are important in driving flow within the canopy nepf 2012 thus with the constraint of the canopy shear layer csl the formation of canopy scale vortices k h vortices due to drag discontinuity is related to a combination of factors such as stem morphology and depth of submergence the growth of the k h vortices stops when the energy balance is reached according to nepf et al 2007a the depth of submergence h hv where h is the water depth is closely connected to the turbulent structure of vegetated flow three different scales of turbulence are present that is the boundary layer vortices the k h vortices and the stem scale vortices the boundary layer vortices usually appear in the upper region of deeply submerged vegetated flow and exhibit the largest scale the k h vortices form at the top of the canopy and the stem scale vortices are as the same scale as canopy elements the relative importance of different vortices to momentum transport changes with the depth of submergence for condition h hv 2 the free water surface constrains the growth of k h vortices nepf and vivoni 2000 for condition 2 h hv 5 k h vortices are limited by neither the water surface nor the river bottom and thus can progress unaffectedly moreover the presence of boundary layer vortices is restricted by the water surface and exerts little influence on the existence of k h vortices as previously mentioned k h vortices in the csl reach a fixed scale when the shear production is balanced by dissipation of canopy drag this fixed shear layer scale is reached at approximately 10hv from the canopy s leading edge ghisalberti and nepf 2002 for condition 5 h hv 10 the state of k h vortices starts to transform from persistent to intermittent during this process the role of boundary layer vortices becomes more important in this condition vegetated flow is driven by turbulent stress and potential gradient in contrast flow within canopies is driven only by the vertical turbulent exchange of momentum for with little contribution from pressure gradients raupach et al 1991 internal mechanism in flow for condition h hv 10 is similar to that in flow within terrestrial canopies nepf et al 2007a noting that the effects of boundary layer vortices are neglected to simplify the problem we concentrate on the energy balance for condition 2 h hv 10 to derive the penetration depth δ e furthermore we restrict our attention to cases for which cdahv 0 1 for sparse canopies no inflection point can be generated without evident velocity disparity at the top of the canopy to trigger k h instability the limit 0 1 is based on canopy experiments conducted by dunn et al 1996 and poggi et al 2004 penetration depth is the distance between the top of canopies and the effective momentum boundary where the reynolds stress drops to 10 of its peak value nepf and vivoni 2000 the definition of penetration depth is based on the shear scale turbulence kinetic energy budget which can be simplified in eq 1 luhar et al 2008 1 d d t k s u w z u 1 2 c d a u 2 u 2 v 2 w 2 with the velocity vector u u v w corresponding to the coordinates x y z the instantaneous velocity is comprised of the time average overbar and deviations from the time average single prime in eq 1 ks represents shear scale kinetic energy the first term on the right hand side is shear production and the second term means canopy dissipation variable ks remains constant as the growth of k h vortices stops hence the balance between shear production and canopy dissipation is achieved we re arrange eq 1 to directly express the relationship between mean flow velocity and turbulence characteristics 2 u c d a u z 2 u w 2 u 2 v 2 w 2 nepf et al 2007a tested eq 2 using experimental data from several studies and verified that the values of the two terms are comparable that is approximately 0 21 we expect the left side term to be a fixed value at the inflection point in the velocity profile the term is defined as the following csl parameter 3 c s l u c d a u z where cd is assumed to be 1 0 as suggested by huai et al 2009 the turbulence scale u u z is regarded as the characteristic length scale of the shear scale vortices lh where the subscript h denotes evaluation at the top of the canopy z hv nepf and vivoni 2000 li et al 2015b 4 l h u u z two approximate assumptions are made to obtain an estimate value of the penetration depth from eq 4 see fig 3 firstly we assume that u u h given that the inflection point is close to z hv secondly the ratio uh δ e is used to estimate the velocity shear u z such an estimation is particularly reasonable for vegetated flow with dense canopies since the velocity at the auxiliary plane u 1 is small enough to be neglected nepf et al 2007b the experiments of nepf and vivoni 2000 indicated that the estimation equation of δ e for conditions h hv 2 and cdahv 0 1 can be obtained by applying eq 5 in eq 5 a fixed value for csl only exists for condition cdahv 0 25 as for condition 0 1 cdahv 0 25 only a coarse approximation of δ e is presented however theoretically δ e should be linearly related to cda 1 in both cases this discrepancy may result from the second assumption we make to derive δ e a further explanation is that for flow with relatively sparse canopies 0 1 cdahv 0 25 the velocity at the auxiliary plane u 1 increases which makes the ignorance of u 1 unreasonable in the estimation of the velocity shear u z therefore we should estimate u z by uh u 1 δ e in this condition the modified equation of δ e is shown in eq 6 the comparison between eqs 5 and 6 shows that the coefficient 0 85 1 0 for 0 1 cdahv 0 25 corresponds to uh u 1 uh 5 δ e 0 21 0 03 c d a 0 85 1 0 h v for c d a h v 0 25 0 1 c d a h v 0 25 6 δ e c s l u h u 1 u h c d a for condition h hv 2 a correction factor β h hv 1 is introduced as a linear simplification in the calculation of δ e see eq 7 li et al 2015b the accuracy of the modified equation is evaluated by the error metrics of discharge in section 4 1 7 δ e β 0 21 0 03 c d a 0 85 1 0 h v for c d a h v 0 25 0 1 c d a h v 0 25 the penetration depth δ e separates the submerged vegetated flow into an upper layer of energetic turbulent transport and a lower layer of diminished transport nepf 2012 thus an auxiliary plane is presumed to be at the level z hv δ e regarding this plane as the effective momentum boundary the flow is segregated into two layers the basal layer z hv δ e and the suspension layer z hv δ e in the basal layer the stem scale turbulence is generated in the wakes of individual canopy elements and the velocity distribution is rather uniform in the suspension layer the shear scale turbulence holds the dominant position and thus leads to a hyperbolic tangent profile in the csl based on the embodied effects of motive turbulence and velocity distribution the new division of layers is valid to reflect the flow structures of submerged vegetated flow the average velocity in each layer is calculated in the next section 2 3 layer averaged velocity the depth averaged velocity in the entire cross section u can be calculated by individually considering the basal and suspension layers cheng 2011 stated that average velocity in the basal layer is close to that in emergent vegetated flow the layer averaged velocity can be deduced from the momentum balance between potential gradients and canopy drag force 8 g s 1 λ 1 2 c d v a u b v 2 where s is the energy slope and λ is the solid fraction of canopy elements ubv is the average velocity surrounding the stems and it can be computed as ubv ub 1 λ to remove the influence of the space occupation of vegetation stems where ub is the average velocity in the basal layer cdv is the drag coefficient developed by cheng and nguyen 2011 9 c d v 130 π 1 λ d 4 λ g s v 2 1 3 0 85 0 8 1 exp π 1 λ d 4 λ g s v 2 1 3 400 where g is the gravitational acceleration and ν is the kinematic viscosity the solution for eq 8 is as follows 10 u b v 2 g s 1 λ c d v a the flow rate per width in the basal layer can be computed by qb ubv hv δ e 1 λ then the average velocity in the suspension layer us can be deduced based on the measured total discharge 11 u s q m q b b h s δ e b where qm is the measured total discharge and b is the channel width 2 4 data grouping and pre processing in flume experiments the setup of vegetation can be altered to explore the influence of certain aspects on vegetated flow for instance vegetation can be arranged in aligned staggered or randomly distributed forms to explore the influence of arrangement mode the vegetation itself can also be in rigid or flexible state to investigate the effect of vegetation flexibility however data collected from one research project are still limited due to the restriction of experiment conditions therefore a predictor obtained from a single dataset of one source may reflect a specific feature rather than represent general characteristics of vegetated flow tinoco et al 2015 thus data should be collected from multiple datasets to represent a broad parameter space to avoid such problems in this study we analyse multiple datasets collected from previous studies shimizu et al 1991 dunn et al 1996 meijer and van velzen 1999 lopez and garcia 2001 stone and shen 2002 stone 1997 poggi et al 2004 ghisalberti and nepf 2004 baptist et al 2005 murphy et al 2007 liu et al 2008 nezu and sanjou 2008 yan 2008 yang 2008 cheng 2011 she et al 2010 hao 2014 yang et al 2018 shi 2018 gualtieri et al 2018 song et al 2019 in total 493 datasets obtained from laboratory experiments are collected see appendix a in most experiments rigid cylinders arranged in aligned or staggered forms are used to simulate submerged canopies the only exception comes from nezu and sanjou 2008 where flat strips were used to represent canopy stems herein the strip width is regarded as the stem diameter d as suggested by cheng 2011 the dataset shows a wide range of relative submergence h hv of 1 08 8 8 reynolds numbers based on water depth re h u h ν 1 are in the range of 3769 09 2 721 109 and reynolds numbers based on stem diameter re d u d ν 1 are in the range of 55 74 9032 73 all datasets are classified based on the concept of auxiliary bed demonstrated above according to the restriction of water surface on the development of k h vortices we divide the entire dataset into two groups one group contains 267 datasets for h 2hv and the other group contains 226 datasets for h 2hv considering the relation between penetration depth δ e and vegetation height hv we further segregate the 267 datasets for h 2hv into two parts one part comprises 149 datasets for δ e hv cdahv 0 1 and the other part comprises 118 datasets for δ e hv cdahv 0 1 the classification of the 226 datasets for h hv 2 is conducted in the same way though the computation method for δ e is slightly different the grouping result is shown in table 1 to derive a physically sound predictor for average velocity in the suspension layer us the grouped data needs to be pre processed to meet the requirement of gp algorithm in the next step many depth averaged velocity formulae were proposed by previous studies baptist et al 2007 huthoff et al 2007 cheng 2011 li et al 2015b tinoco et al 2015 shi et al 2019 some of which are shown in section 4 1 for comparison the common feature of these formulae is that they are all in chezy like form regardless of different hypotheses thus the target solution should be set in chezy like form to obtain a similar predictor that is as effective as previous ones tinoco et al 2015 and wang et al 2017 suggested that the gp algorithm should be fed with non dimensional data groups instead of dimensional parameters to conform to buckingham s pi theorem herein seven related dimensional variables namely us d hv hs s a and δ e are transformed into non dimensional ones the five non dimensional variables are the froude number fr us g hs δ e 0 5 energy slope s solid volume fraction of canopy elements λ and length scale ratios h s δ e δ e h s δ e d and aδ e two non dimensional variables are ignored because they can be calculated with other parameters such as a h s δ e a δ e h s δ e δ e and a d 4 λ π reynolds numbers such as re d u d υ and re h u h υ are related to the target parameter us hence to avoid the self relating problem reynolds numbers are not considered therefore the target predictor is assumed to be like f r s f λ h s δ e δ e h s δ e d a δ e to simplify the expression form of the solutions in gp the target predictor is further transformed to be f r s f λ h h h d a h with h corresponding to hs δ e and h corresponding to δ e in gp the training and validation groups that comprise the processed datasets are used to feed the algorithm the way to obtain such groups is explained in detail in the next step 2 5 data selection data selection is an important procedure in using the gp algorithm that directly determines the applicability of possible solutions here the maximum dissimilarity algorithm mda developed by camus et al 2011 and goldstein et al 2013 is applied to conduct the process of data selection this algorithm has been successfully applied in previous studies tinoco et al 2015 wang et al 2017 huai et al 2018 shi et al 2019 to solve such problems compared with other selection algorithms such as k means algorithm kma and self organizing maps som camus et al 2011 the mda can select data from the periphery of the parameter space in addition the mda requires few data points that are the representative of the data bank to acquire a relatively accurate solution wang et al 2017 three major steps need to be taken to properly perform the mda tinoco et al 2015 firstly since the data ranges of different variables vary greatly we need to rescale the values of these variables to the same magnitude to improve the performance of eureqa herein we normalize the abovementioned dimensionless variables by xn x x min x max x min where x max is the maximum value of the data x min is the minimum value of the data x is a random value in the dataset and xn represents the normalized dimensionless data value secondly the first centroid is selected which is the maximum value of λ in this study according to the work of tinoco et al 2015 the farthest data point from the first centroid is chosen as the second centroid by evaluating the distances between the first centroid and the other data points in the same way a series of centroids is selected which composes a new normalized dataset this dataset consequently comprises the odd data on the edge of the data bank thirdly we de normalize the new dataset into the original data with x xn x max x min x min as can be seen in table 1 the whole dataset is first divided into two categories h 2hv and h 2hv by the submergence for condition h 2hv we simplify the calculation of δ e by introducing the correction factor β see eq 7 which means a small portion of data still deviates from the pre supposed linear relation hence datasets for condition h 2hv are not included in the data selection process to avoid unnecessary errors for condition h 2hv the 267 datasets are further classified into two parts by the canopy density that is the 149 datasets for cdahv 0 1 and the 118 datasets for cdahv 0 1 herein we take the 149 datasets as an example of data selection according to the three major steps when the mda is conducted for the first time the 149 datasets are divided into the rest group and the training group with the latter accounting for 30 of the whole dataset when the mda is performed again for the rest group the validation and testing groups are produced which include 30 and 40 of the whole dataset respectively the data selection process for the 118 datasets is conducted in the same way in the end data from the training and validation groups are fed to the gp algorithm to derive the optimal solution detailed work on the mda is available in the works of tinoco et al 2015 and wang et al 2017 2 6 formula searching first we take the 149 datasets that are in the condition of cdahv 0 1 to perform the process of formulae searching as mentioned above the 90 datasets from the training and validation groups are fed to the gp algorithm the mae is chosen as the fitness function in eureqa tinoco et al 2015 wang et al 2017 huai et al 2018 shi et al 2019 12 m a e 1 n i 1 n p i b i where n is the sum of the datasets pi and bi are the predicted and observed values respectively after 16 h with 1 2 1011 formulae evaluated eureqa produces a list of solutions with different complexities see table 2 the most intricate solution complexity of 19 is the best predictor in terms of the mae but it presents more statistical characteristics than physical meanings considering both accuracy and complexity we choose the solution of complexity 5 as the optimal predictor eq 13 this solution is in chezy like form and appears as a cliff point on the pareto front fig 4 13 u s g h s δ e s 4 42 0 0105 h s δ e d for condition cdahv 0 1 the 118 datasets are also divided into three groups the proportion of which are the same as that of the 149 datasets for condition cdahv 0 1 after formulae searching the pareto front for solutions is shown in fig 5 and the result is listed in table 3 here two solutions appear as cliff points in the figure with the complexity of 5 and 8 respectively compared with the first solution mae of the second solution decreases almost 50 with the complexity increasing only 3 thus the solution with the complexity of 8 eq 14 is chosen as the optimal predictor which strikes a better balance between accuracy and complexity 14 u s g h s 6 26 0 0195 h h v a h v to examine the stability of gp we conduct the data selection process mda again to change the sizes of the training and validation groups into 40 of the whole dataset and then obtain another set of formulae for condition cdahv 0 1 and cdahv 0 1 the optimal solutions are eqs 15 and 16 respectively it can be seen that both eqs 15 and 16 have the same structure as the former solutions see eqs 13 and 14 only with the coefficients being slightly different this corresponds to the findings of tinoco et al 2015 in which a solution with the same structure is found even if the size and composition of datasets change they believed that it is the structure of solutions that reveals the physical meanings of the problem and the slight change in coefficients does not make much difference herein comparisons between the former eqs 13 and 14 and the latter eqs 15 and 16 optimal solutions are made in section 4 1 as a verification the results show that the former solutions perform slightly better than the latter solutions and thus are chosen as the optimal solutions 15 u s g h s δ e s 4 7 0 0101 h s δ e d 16 u s g h s 6 24 0 0196 h h v a h v 3 results the depth averaged velocity in the entire cross section u is computed by taking the weighted average of the average velocity in each layer the equation can be described as follows 17 u u s h s δ e u b v h v δ e 1 λ h then the formulae for depth averaged velocity in different situations are obtained for condition cdahv 0 1 18 u g h s 2 1 λ 3 c d v a h v δ e h 3 2 4 42 0 0105 h s δ e d h s δ e h 3 2 meanwhile for condition cdahv 0 1 19 u u s g h s 6 26 0 0195 h h v a h v nikora et al 2001 derived the relationship between velocity distribution and hydraulic resistance for open channel flow over a rough bed this relationship can explain the physical meanings of data driven predictors for submerged vegetated flow by analogy an estimation formula for the darcy weisbach friction factor is proposed by nikora et al 2001 20 f 8 u 2 u 2 8 c 2 m 2 δ h 2 where u is the friction velocity on the rough river bed u is the time averaged flow velocity c and m are parameters that depend on roughness geometry which are usually considered as constants δ is the thickness of the csl which is approximately equal to the roughness height for conditioncdahv 0 1 the friction velocity on the auxiliary bed is assumed to be u g h s δ e s due to the force balance in the suspension layer thus the average velocity in the suspension layer eq 13 can be transformed to express the friction factor on the auxiliary bed 21 f 8 u 2 u s 2 1 4 42 0 0105 h s δ e d 2 in contrast to eq 20 the following relation is derived 22 4 42 0 0105 h s δ e d c m h s δ e δ e according to nikora et al 2001 and nepf et al 2007a δ e also means the scale of eddies generated in the canopy elements and the scale is the same as the diameter of stems d hence the friction factor effectively reflects the influence of relative submergence on hydraulic resistance on the auxiliary bed for condition cdahv 0 1 the auxiliary bed overlaps with the river bed thereby indicating that the friction factor transformed from eq 19 is also for the river bed 23 f 8 u 2 u 2 1 6 26 0 0195 h h v a h v 2 the following relation is obtained by analogy 24 6 26 0 0195 h h v a h v c m h h v as indicated by eq 24 two parameters c and m which represent the geometric features of the canopy elements are no longer constants that is to say for sparse canopies both relative submergence and canopy density are important in predicting the hydraulic resistance of the river bed in submerged vegetated flow 4 discussion 4 1 comparison with previous models the following is a list of previously proposed models for estimating the depth averaged velocity in the entire cross section 1 baptist et al 2007 baptist et al obtained the following formula by applying the dimensionally aware gp to the simulated data of the one dimensional vertical 1 dv model for submerged vegetation 25 u g h s 1 g c b 2 2 c d λ h v π d 2 5 ln h h v where cb is the bed related chezy coefficient which is approximately computed as 60 m0 5s 1 for the smooth bed and the drag coefficient cd is assumed to be 1 0 2 huthoff et al 2007 huthoff et al utilized the traditional two layer division method and proposed the following formula by taking the weighted combination of average velocity in each layer 26 u g h s π d 2 c d λ h h v h h s h h s π 4 λ 1 d 2 3 1 h h v 5 where the drag coefficient cd is approximately 1 0 3 yang and choi 2010 yang and choi assumed that the velocity profile is uniform in the vegetation layer and logarithmic in the surface layer the following expression was deduced by simply adding up the average velocity in each layer 27 u π g d h s 2 c d h v λ c u g h s s 0 41 ln h h v h s h where cd 1 13 cu 1 for 4λ πd 5 and cu 2 for 4λ πd 5 4 cheng 2011 by transforming the concept of hydraulic radius cheng proposed an estimation of the depth averaged velocity by formulating the representative roughness height of submerged vegetation 28 u g h s π 1 λ 3 2 c d v λ d h v h v h 3 2 4 54 h s d 1 λ λ 1 16 h s h 3 2 where the calculation of cdv is shown in eq 9 5 li et al 2015b li et al proposed a new parameter called effective relative roughness height by using the same dynamic division method to predict the friction factor in the suspension layer meanwhile the calculation of average velocity in the basal layer is also the same as that in the current study 29 u g h s 1 96 h s δ e 5 3 λ δ e 1 6 h 3 2 1 λ h v δ e h 1 2 h 3 2 where the representative length h is computed as h 2 1 λ cdva and the calculation of cdv is shown in eq 9 we choose the mean relative error mre and mean squared error mse as the error metrics to evaluate the accuracy of different formulae 30 m r e 1 n i 1 n p i b i b i 31 m s e 1 n i 1 n p i b i 2 the comparison results of the flow rate estimated by each formula are plotted in fig 6 cdahv 0 1 and fig 7 cdahv 0 1 noting that the unit of flow rate transforms into liters per second the error metrics for different predictors are summarized in table 4 cdahv 0 1 and table 5 cdahv 0 1 table 4 and fig 6 illustrate that for condition cdahv 0 1 eq 18 is in good agreement with data for h 2hv and h 2hv the formulae derived by huthoff et al 2007 cheng 2011 and li et al 2015b present higher accuracies than the other two models this finding may be explained by the fact that both cheng 2011 and li et al 2015b applied a concept similar to the representative roughness height to describe the influence of stem induced roughness although the layer division method was different as shown in fig 6 c the formula given by yang and choi 2010 evidently underestimates the flow rate in the high flow rate region li et al 2015b explained that the deviations may result from adopting a logarithmic velocity profile in the surface layer in contrast the formula given by baptist et al 2007 overestimates the flow rate especially in the low flow rate region this deviation may be due to the derivation of the data driven formula with simulated data from a numerical model in table 4 the comparison of prediction results produced by eqs 13 and 15 shows that eq 13 is the better solution in predicting the discharge for vegetated flow with dense canopies for condition cdahv 0 1 eq 19 apparently shows higher accuracy compared with other formulae as illustrated in table 5 and fig 7 in contrast to cases where canopies are dense the formulae derived by huthoff et al 2007 cheng 2011 and li et al 2015b show a similar tendency to underestimate the discharge for cases where canopies are sparse from fig 7 c it can be seen that the formula given by yang and choi 2010 matches quite well with the data this consistency verifies that for sparse canopies velocity profile in the surface layer fits the logarithmic law the formula proposed by baptist et al 2007 also shows an acceptable fitness to the data by using the gp algorithm in addition we compare eq 14 with eq 16 in predicting the discharge for vegetated flow with sparse canopies with the same structure of expression eq 14 exhibits a slightly higher accuracy than eq 16 by comparing the prediction results when the canopy density changes it can be seen that all formulae from other studies can only perform well for one case that is vegetated flow with sparse or dense canopies in contrast formulae of the present model eqs 18 and 19 show desirable predictive ability in both cases especially for flow with sparse canopies the above mentioned analyses illustrate the superiority of the present dynamic two layer model in two aspects firstly the formula based on the gp algorithm performs effectively in predicting flow rates in vegetated flow with rigid submerged canopies secondly the new dynamic boundary can provide a unified basis for vegetated flow with sparse and dense canopies this unified basis helps reflect the internal turbulent characteristics of vegetated flow in addition it also makes up for the deficiency of the original two layer model in predicting depth averaged velocity of vegetated flow with sparse canopies 4 2 limitation of present model a broad dataset is collected from previous studies to build the dynamic two layer model this model shows fairly good applicability as verified above nonetheless some limitations still exist for the present model for instance among the 118 datasets used to derive the predictor for δ e hv 88 datasets are collected from gualtieri et al 2018 nevertheless the predictor still effectively performs for multiple datasets instead of one specific dataset three reasons are given to confirm the wide applicability of the predictor see eq 19 firstly multiple canopy densities and submergence ratios are included in the 88 datasets which reduces the monotony of the datasets secondly the remaining 30 datasets are collected from 6 sources dunn et al 1996 lopez and garcia 2001 poggi et al 2004 yang 2008 she et al 2010 shi 2018 thirdly the predictor still performs well for datasets in the testing group which are not fed to the gp algorithm another important concern is that only 32 subsets of data exist in the condition δ e hv and h 2hv however the 32 datasets are collected from 6 data sources dunn et al 1996 liu et al 2008 she et al 2010 hao et al 2014 gualtieri et al 2018 shi 2018 thereby making the prediction convincing to some extent substantial experimental work needs to be performed to increase the amount of data diversify the data sources for δ e hv and ultimately solve the two abovementioned problems for flexible canopies the presence of a waving motion triggered by canopy scale vortices leads to a deep penetration of reynolds stress ghisalberti and nepf 2009 consequently the velocity around the stems expands and the momentum transport is less efficient with such a complex dynamic process involved the present model is unsuitable for vegetated flow with flexible vegetation 5 summary in this study we combine the concept of auxiliary bed proposed by li et al 2015b with the gp algorithm to predict the depth averaged velocity in submerged vegetated flow we segregate the vegetated flow into the basal and suspension layers while considering the auxiliary bed as the boundary the average velocity in the basal layer is derived from the momentum balance for the suspension layer the gp algorithm is applied to obtain two sets of predictors for open channel flow with sparse and dense canopies on the analogy of rough bed flow we explain the physical meanings of the two predictors by associating them with the friction factors on the auxiliary bed evidently both relative submergence and canopy density play important roles in hydraulic resistance in submerged vegetated flow the comparison with previous studies shows that the predictors greatly match with the experimental data especially for flow with sparse canopies consequently the new dynamic two layer model can provide a unified physical basis for flow with sparse and dense canopies furthermore this model is distinctly advantageous when predicting the depth averaged velocity in vegetated flow with sparse canopies the model produced in this study may help deal with the hydraulic engineering problems of vegetated open channel flows with various canopy densities credit authorship contribution statement fan yang conceptualization methodology software validation formal analysis investigation writing original draft writing review editing visualization wen xin huai conceptualization methodology writing review editing supervision project administration funding acquisition yu hong zeng writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work is financially supported by the national natural science foundation of china nos 11872285 11672213 and 51439007 the authors thank v pasquino for providing the experimental data to help with the manuscript comments and suggestions made by the editor dr d odorico and reviewers have greatly improved the quality of the paper 
509,transport processes in watersheds remain challenging to describe accurately with upscaled models because of their intricate complexities at multiple scales that can lead to multi modal non fickian breakthrough curves one of the recent advances in solute transport modeling has been the lagrangian spatial markov model smm which describes transport using velocity increments and models the correlated transitions between them the approach has been applied previously to saturated porous media and fractured media but these successful applications suggest it may be useful for describing watershed scale processes as well an existing 3 d heterogeneous variably saturated model of a headwaters catchment and classical random walk particle tracking were used to generate a forward simulation and the resulting transport was analyzed with a spatial markov framework existing smm methods were used to analyze the transport paths through the complex unconfined domain and we found that the vadose zone plays an important role in the correlation structure as such a new kind of smm is proposed termed a multi domain smm md smm that uses separate correlation models for auto transitions in the vadose zone and the saturated zone and for the cross transitions between them the md smm improves representation of transport relative to the single domain model and can naturally delineate times when a particle is in the vadose zone or the saturated zone adding an additional degree of realism to the upscaled model finally we show that the transition probability matrix for transport in the saturated portion of this unconfined system is approximately markovian which is an important validation of the proposed framework keywords spatial markov model continuous time random walks watershed transport 1 introduction the hydrologic systems that make up freshwater resources have a broad range of features including rivers streams and aquifers every watershed is unique but the presence of complex processes and heterogeneities is universal to them all making these systems challenging to simulate whether the goal is merely a better understanding or to make predictions forecasts in order to adequately model transport of anything be it for example contaminants nutrients other dissolved substances colloids bacteria and viruses models are needed that can realistically account for the impact of heterogeneities that are known to exist in the physical processes these could be variations in the parameters of an underlying physical model or different kinds of processes in different parts of the system among many others that represent the true processes details of heterogeneities vary considerably from system to system and they can span an enormous range of spatial and or temporal scales but they usually result in transport behaviors that significantly deviate from homogenized or overly simplified approximations however significant progress has been made toward upscaled modeling of the impacts of heterogeneities in saturated flow systems and many methods now exist that can provide comparably good descriptions of complex transport processes one of the major potential advantages is that these new methods allow practitioners to reasonably include effects of heterogeneities in simplified models offering more flexibility in the choice between complexity uncertainty and runtime in particular lagrangian models of solute transport are a robust platform for simulating a wide range of transport problems across the spectrum of hydrologic applications salamon et al 2006 benson et al 2017 both as models that aim to fully resolve transport in complex flow settings e g weissmann et al 2002 engdahl and weissmann 2010 atchley et al 2013a as well as within upscaled frameworks e g meyer and tchelepi 2010 dentz et al 2016 wright et al 2019 while many sophisticated lagrangian upscaling frameworks exist some recent rather flexible ones belong to the class of correlated velocity models which are built on the idea that a particle s current velocity can depend on its previous one relaxing assumptions inherent to many previous models in the context of a highly heterogeneous porous medium le borgne et al 2008b a demonstrated that lagrangian velocities were correlated in space and that this behavior could be effectively described with a correlated continuous time random walk ctrw the resulting correlated velocity model has been called the spatial markov model smm by several authors and many successful applications of this upscaled transport framework have been presented since examples include passive massoudieh et al 2017b sherman et al 2017 bolster et al 2014 and reactive sund et al 2017a wright et al 2019 sund et al 2017b transport in porous media with several extensions to fractured media kang et al 2011 2017 2016 however an important point is that all of the previous examples focused exclusively on the saturated zone and were predominately in confined porous media while this is an important set of problems the flexibility of the smm leads us to consider whether or not it can be generalized to a broader class of problems thinking in a more general hydrologic sense watersheds involve a combination of saturated sat vadose vdz and overland ovl flow regimes all of these flow processes are potentially nonlinear can cause feedbacks and exchanges between each other and it is known that omission of the interactions is often detrimental feedbacks significantly complicate upscaling of watershed transport processes and perhaps it is due to this complexity that most of the focus to date has been on integrated response modeling for watersheds botter et al 2011 botter 2012 benettin et al 2013 such response models are usually developed from observations of streamflow or stream chemistry and typically the term integrated implies that only the net combined impact of all transport process is considered however the nonlinear nature of watershed processes means that a model developed from one set of observations may fail when new flow conditions are encountered and the integrated response model cannot easily include many processes of interest like spatially variable reactions though these are common challenges to any simplified model another option for watershed modeling is direct numerical simulation dns based on the governing equations of flow and transport e g kollet and maxwell 2008 atchley et al 2013a engdahl and maxwell 2015 however the dns approach has a heavy data requirement significant room for uncertainty and computational expenses can be prohibitive applications of dns show great potential for hypothesis testing using virtual watersheds but often struggle when making predictions since model calibration is challenging given the potentially vast number of modeling parameters and prohibitively long run times thus an ambitious challenge is to find some middle ground between purely integrated response models and dns for watershed transport that can be used for common watershed modeling forecasting tasks ideally such a model would approximate enough of the physics that it allows delineation of and interaction between the different process domains sat vdz and ovl while being less complicated than a fully detailed 3 d distributed flow and transport model one candidate for such an upscaled transport framework is the smm which is already known to work well in the saturated zone and has had some application to unconfined and river systems kim and kang 2020 sherman et al 2019 smm models are also inherently stochastic which can allow for robust non parametric uncertainty quantification in a relatively short amount of time however at this time there are four potential implementation barriers i to date the smm has not been used in topographically driven unconfined systems ii the spatial markovian hypothesis has not been tested for topographically driven flows iii the smm has not been used in variably saturated flows and iv smms have not been tested extensively in multiple connected flow domains here we aim to explore whether or not these are surmountable barriers given the fact that so many different hydrologic systems display distinct but shared anomalous behaviors we believe it is interesting to ask whether an overarching framework can be combined to successfully upscale transport at watershed scales to this end the purpose of this article is two fold first to evaluate the performance of the smm in a variably saturated system and second to propose a new modified multi domain smm denoted md smm that is designed to more closely represent actual watershed processes in an upscaled framework the basic elements of the new model are the same as the previous single domain smm but we describe the velocity correlations in different flow domains separately and allow them to interact the resulting model is a coupled representation of transport in the different process domains that allows transitions back and forth between them ideally forming a representation of the interactions that occur in real systems the structure of the article lays out the watershed model used to generate the reference forward simulation from random walk particle tracking rwpt in section 2 section 3 introduces the single and multi domain smm formulations and section 4 evaluates the two models against the rwpt simulation finally section 5 considers the important test of whether or not the markovian hypothesis is valid in the context of a full watershed our objective here is not to find or to calibrate a model that perfectly fits the rwpt simulation since some error should be expected when comparing any approximation to results from a complex system rather we aim to consider whether or not a correlated markovian framework can even be applied to reasonably upscale transport in topographically varying unconfined watersheds 2 reference simulation domain the watershed used in this study is the east inlet basin located in central northern colorado usa within rocky mountain national park the domain was previously developed by engdahl and maxwell 2015 to investigate the impacts of climate change on residence time distributions in high order watersheds and the domain is broadly representative of many of the small snowmelt driven headwaters systems throughout the rocky mountains the watershed simulation itself is a fully coupled surface subsurface model constructed using the parflow numerical model ashby and falgout 1996 jones and woodward 2001 maxwell 2013 which solves the mixed form of the 3 d richard s equation coupled to a kinematic wave model for surface routing with a free surface overland flow boundary kollet and maxwell 2006 the domain is about 6km long by 5km wide with roughly 1km of surface relief fig 1 and is characterized by rough irregular topography highly variable slope angles with numerous springs seeps and a series of small lakes feeding into each other along the main axis of the watershed a 3 d categorical hydrogeologic model of the subsurface was developed based on the known geological history of the area and log normally distributed correlated permeability distributions were inserted into each hydrofacies the resulting steady state model provides a good representation of the system s main elements i e lakes streams and springs seeps and its outflow is a good approximation of the seasonal average giving us high confidence in the internal dynamics of the model as a realistic virtual watershed for testing upscaled markovian models transport through the domain was simulated using random walk particle tracking rwpt methods described by maxwell et al 2008 and de rooij et al 2013 the latter of these is important in the context of this study because it explicitly allows for exchange between the subsurface and overland flow domains de rooij et al 2013 accomplished this by using a probabilistic mass transfer scheme between the ovl and subsurface based on a mass balance of the surface and subsurface fluxes interested readers are referred to that work for more details the backward in time rwpt simulation released a total of 225 000 particles into the ovl domain of the east inlet model simulating a water sample taken from the stream the release location is shown in fig 1 as the red diamond the particles were tracked back to their source locations and their paths stored for analysis both maxwell et al 2008 and de rooij et al 2013 implement pollock s method which allowed us to use a reasonably large time step of 5 days for a simulation period of 200 years at the end of the simulation period about 99 of the injected particles had left the domain with a small amount of residual mass in the domain in the lowest permeability regions while such tailing can be important in some cases here we are mainly concerned with the ability of the smm and md smm to reasonably approximate large scale transport not to precisely reproduce it as such complete resolution of the tail is not necessary and we note that field tracer tests also never give perfect recovery of the tracer the reference breakthrough curve btc or cumulative distribution function cdf of transport is shown as the blue histogram bars in fig 2 and the lagrangian velocity distributions as a cdf and probability distribution function pdf are shown in fig 3 since the domain is snowmelt driven and at steady state only about 1 of the particles enter as direct recharge to the streams and the remaining 99 of the particles experience subsurface flow the most notable characteristic is that the btc has distinct multi modal behavior that indicates the presence of fast preferential flow paths arriving before about τ 10 0 t followed shortly after by the larger mass fraction note that all times are given in years such a feature is not readily captured by traditional upscaling models but the smm has been able to reproduce transport with challenging features like these from pore scale e g bolster et al 2014 to aquifer scales e g le borgne et al 2008b 3 spatial markov modeling 3 1 single domain smm the general smm framework is a 1 d upscaled transport model that discretizes the path of a material element particle through a domain into a series of spatially uniform steps and the transition waiting time to make each step is treated as a random variable le borgne et al 2008b 2008a thus the smm fits in the broad class of the ctrw family of methods what makes the smm unique is that subsequent waiting times can be correlated where the next step in the sequence depends on the one just completed the correlation to complete each step is expressed in terms of a discrete transition probability tp matrix between different velocity bins or transition times of the model where the tp matrix controls the transitions between the bins thus embedding correlation into the model conceptually correlation arises because a fast moving particle is more likely to keep moving fast than it is to slow down both outcomes are possible but the latter is generally less likely this approach contrasts other forms of ctrw that do not explicitly model correlations or classical uncorrelated random walks where transition times are fixed and the spatial jump size is the random variable e g labolle et al 1996 more details on the nature of uncorrelated random walks can be found in salamon et al 2006 and noetinger et al 2016 the langevin equation describing how particles transition through space and time within the smm is given by 1a x k 1 x k l 1b t k 1 t k τ i j where i and j denote the starting and ending velocity bins respectively k indexes the steps in the series x is the position of the random walker l is the constant spatial step size and τ i j is the transition time for the i j transition modified after bolster et al 2014 the core of the method is the transition probability matrix which is used to select the final bin j conditional to the starting velocity bin i details on the construction of the tp matrix from high resolution particle trajectory data can be found in sund et al 2015b 2017c and wright et al 2019 among others although parameterization methods from btc data alone also exist e g sherman et al 2017 2018 following le borgne et al 2008b the general form is 2 t i j h p j at x h i at x p j at x h i at x p i at x the transition matrix can be built by directly sampling particle trajectories at separation distances h along the paths and directly applying 2 note that this h is distance along the pathline we then use the columns of the full transition matrix to define the conditional cumulative distribution function ccdf that is used to randomly select the next velocity conditional to the initial velocity to implement a full smm model one chooses the number of random walkers the lengths of their paths and their initial speed then 1a is applied using the ccdf to draw the values of τ i j for each step here we specifically use the discrete points defined by 2 as the points for a velocity interpolation which allows a continuous distribution of τ i j rather than a discrete model 3 2 multi domain smm the md smm is designed to delineate the state of a random walker as it moves through the transport domain in the same way flows evolve in watersheds the watershed is decomposed into three sub domains referred to as process domains representing 1 overland flow ovl 2 vadose zone vdz flows and 3 saturated groundwater sat flow and each must be described by its own transition matrix however these sub domains are not isolated and interactions are allowed by adding cross transition matrices to the model the complete system of transition probabilities are described in a nested transition matrix denoted as t i j m n where i and j index the initial and final velocity bins but we add m and n to keep track of the process domain when m n the transition is an auto transition that keeps the random walker within the same process domain and the transition represents a transfer between process domains anytime m n the number of velocity bins and their cutoff thresholds can differ in every region of the nested transition matrix so for example the first overland bin could span a range of velocities that is orders of magnitude wider than the first bin of the saturated zone the transition probabilities are computed almost identically to section 3 1 but the conditional probability is modified to include multiple process domains the multi domain transition probability is defined as 3 t i j m n h p j at x h n i at x m p j at x h n i at x m p i at x m by bayes theorem where i and j are still indices over the velocity bins p denotes a probability h remains separation distance along the pathline but we add m and n to index the process domains ovl vdz and sat however the i and j indices themselves are now conditional to the domains since each may have a unique distribution of velocity bins in other words t i j m n describes transitioning from the ith bin of the discrete velocity pdf for the mth originating domain into the jth bin of the pdf for the nth destination domain but each pdf may be different like the standard smm the transport simulation for each particle in the ensemble is built by selecting a number of spatial steps where τ is a correlated random variable given an initial domain and velocity for the sequence of transitions we can write the langevin equation 4a x k 1 n x k m l 4b t k 1 n t k m τ i j m n the simulations follow the same procedure as the smm but transitions are now conditional to the mth domain at the kth step the corresponding column is still extracted from the t matrix 3 to build the ccdf that is used to probabilistically select the transition but every sub domain transition is included in the ccdf note that 4a naturally recovers the single domain smm when there is a single category but adds the ability to track the domain of the walker and assign different velocity distributions when multi domains are used we note that at least two other studies have considered some aspects of flow systems that are connected across two process domains the dual domain model of sherman et al 2019 and the free surface and porous model of kim and kang 2020 the former considered hyporheic exchange between a turbulent river and porous continuum whereas the latter solved the pore scale velocity field to consider flow over and through a porous substrate sherman et al 2019 is conceptually similar to the md smm because it is a 2 state model but the transitions were not modeled using a transition probability matrix and neither of these studies explicitly considered vdz flows 4 model evaluation 4 1 transition matrices this section evaluates whether or not the smm and md smm models can be applied to reasonably approximate transport in a realistic watershed to do so we construct descriptive models of the smm and md smm for the transport simulated in the east inlet domain we use the trajectories of the rwpt particles to build the tp matrices which contained over 14 million transitions the procedure to compute t via direct application of 2 or 3 to the trajectories are basically the same the first step is to apply a streamline transformation to the coordinates of the particles see atchley et al 2013b this operation projects the 3 d particle positions onto a 1 d line representing the cumulative length of the path of each particle a separation distance h is chosen for calculating the tps and the times when each particle transitions an interval of h are recorded the initial velocity bin is defined by the time it takes the particle to move from a given starting position s 0 to s 1 s 0 h as v 1 h t s h t s and the final bin is defined based on the time to travel from s 1 to s 2 s 1 h the md smm differs from the smm by adding delineation of the process domain this raises the issue of how to define the domain for a transition since a particle could pass through more than one if a given step is large enough the simplest option is to adopt the domain at the end of each step for example the process domain at s 1 is the initial domain and the process domain at s 2 is the final domain alternatively one could choose whichever category occupies a larger spatial or larger temporal fraction of the step we experimented with all three and found minimal differences thus adopting the ending point definition for simplicity but acknowledge that this question may merit further investigation in other settings with this minor modification 2 and 3 were used independently to build smm tp matrices and nested md smm tp matrices based on the rwpt simulations preliminary testing revealed that there were not enough transitions involving the ovl domain both auto and cross transitions to construct a reasonably smooth t stream ovl cells can only occur in the top layer so they are not abundant compared to vdz and sat cells and this also limits their juxtaposition to a limited subset of the vdz and sat cells furthermore velocities in the ovl are significantly higher than the subsurface domains which implies that the markov scales may not be compatible for these reasons we chose to focus on the two subsurface domains vdz and sat for the smm and md smm models and reserve the ovl issues for future study portions of the particle trajectories that were in the ovl domain were truncated but the remainder of the paths and travel times were unaltered the transition matrices for the smm and md smm vdz and sat models are shown in figs 4 and 5 the pdfs of velocity in vdz and sat were found to cover the same broad ranges so a single set of bins was used for both and 40 bins provided a reasonable description of the system sensitivity to the number of bins is considered in section 4 3 the velocity distribution spans 7 orders of magnitude so a logarithmic transform was applied to them and equally likely binning was used which is standard practice for most smm applications the trajectory analysis provided a distribution of pathline lengths for the particle ensemble and from this we selected smm step size of h 10 m which is half the lateral cell size of the finite difference grid velocity field and well below the heterogeneity length scales of the domain note that different h values are considered in section 5 fig 4 shows that smm transitions are almost symmetric the most likely transition for any initial bin is at most a small change in velocity class and the likelihood of speeding up and slowing down are basically the same these findings are consistent with previous work le borgne et al 2008b 2008a however several interesting tendencies are revealed from the md smm version in fig 5 first the sat sat transitions are nearly identical to the smm showing that the saturated zone is dominating the behavior of the smm next despite the broad range of velocities in the vadose zone vdz vdz transitions are concentrated to the slower speeds fig 5 bin 15 and below where they exhibit some correlation but are generally uncorrelated at higher speeds similar behavior is seen for the sat vdz transition there is a bit more structure to the correlated portion of the vdz sat tp matrix relative to vdz vdz but transitions to and from high bin numbers remain random the vdz sat matrix is unique among the vdz transitions because it exhibits a tendency to accelerate which can clearly be seen in fig 5d where most of the probability mass resides above the diagonal there is some complementary behavior in the sat vdz matrix which tends to slow slightly and both of these behaviors could also be inferred from the offsets in the velocity pdfs fig 3 the key points about these transition matrices are that 1 sat sat transitions exhibit strong correlation 2 correlated vdz transitions tend to occupy a tight region of the chosen velocity space and are uncorrelated outside of this region and 3 vdz sat transitions are somewhat distinct because they show a tendency to speed up 4 2 upscaled transport modeling the forward smm and md smm representation of the rwpt model used n p 20 000 and are simulated following the algorithm described in section 3 the initial velocity bins and step numbers are identical for both approaches but the latter starts all particles in the vadose zone recall that the smm does not distinguish vdz and sat note that the reference simulation was a backward model where particles were released in ovl and tracked back to their source which was always vdz thus the forward md smm simulation must start all particles in vdz to achieve the same behavior the simulated breakthrough curves are shown in fig 6 with vertical bars representing the reference btc it should be evident that there are significant differences between the smm and md smm models the median of the smm is shifted toward early arrivals yet it does a poor job of actually representing the early arrivals the md smm on the other hand does a reasonably good job throughout the early and mid times but does not capture the tail of the btc very well we expect that the deficiency in the tail is caused by the relatively low probability of staying in the same velocity bin for the cross transitions and the scatter around the vdz autotransition however the main point is that the md smm provides a good upscaled model of transport in this watershed for the majority of its btc without any parameter adjustments 4 3 main sensitivities even though the md smm model exhibits a good overall fit to the majority of the btc it is worth considering the sensitivities of the upscaled model to the two major components the number of particles and the number of velocity bins note that the question of markov length scales is addressed in section 5 the original md smm and smm arbitrarily used n p 20 k so we investigated n p 0 1 k 0 25 k 0 5 k 1 k 5 k for comparison the btcs for this exercise are shown in fig 7 for the both the smm and md smm in each case the same tp model was used and the only difference was np the main consequence of using increasingly greater particle numbers is the number of potential fast and late arrivals in the btc so the number of particles for a simulation should be selected to achieve the necessary resolution but this is true of all rwpt based methods however for this specific case both the smm and md smm models exhibited minimal sensitivity to np and the same basic btc was produced with as few as 100 particles though such a small np cannot resolve the leading or tailing edges of the btc with precision the second component we modified was the number of velocity bins different numbers of velocity bins were tested when developing the tp matrices ranging from 20 60 using equally likely bins with logarithmic spacing some details on the selection of bins for the smm can be found in le borgne et al 2011 and sherman et al 2017 but the final number of bins 40 was chosen because this gave good resolution of the tp matrices for both the smm and md smm minimized extreme values high and low transition frequencies and provided a reasonably smooth simulated btc from the md smm there are infinitely many combinations of velocity bin numbers and cutoffs that could be tested and presently there is no conclusive guidance on how to select the best number of categories so some experimentation is necessary to determine a reasonable tp matrix to illustrate these sensitivities we show two alternative smm tp matrices using 20 and 60 bins in fig 8 similar kinds of behaviors are seen for the 2 2 plots for the md smm but these are omitted since this is an illustrative example and not a fundamental result a related point is that we have not yet experimented with the use of separate velocity bins for the vdz and sat zones but doing so may improve the accuracy of the md smm since all the transition matrices involving the vadose zone are biased to the low speed velocity bins however this and several other potential improvements are saved for future investigation in a domain with less complexity 5 is transport in watersheds markovian so far we have proposed and evaluated single and multi domain smm models for describing transport in a variably saturated system doing so explicitly assumes that transport is markovian but we have not yet formally tested the accuracy of this assumption nor has it been tested in the literature to do so we must demonstrate that transition probabilities satisfy the chapman kolmogorov equation following le borgne et al 2008b this implies that the discrete transition matrix t evaluated at a separation distance h and at h h where h 0 are related by 5 t h h t h t h if we require that h is an integer order factor of h such as h h n h where n is an integer then the transition matrix must satisfy 6 t n h t h n note that the right hand side rhs is a matrix product not element wise multiplication the rhs of this equation is t computed at h whereas the left hand side is t computed at nh if the two sides of 6 are equal it means that the tp matrix for completing a sequence of n steps of size h is exactly the same as taking one step of size nh if this is the case it shows formally that the transition probabilities of the sequence of steps are independent random variables markovian behavior can be considered for random processes in space and or time but le borgne et al 2008a already showed that subsurface transport processes are generally not markovian in time so only the spatial markov hypothesis is evaluated eq 6 was tested using the trajectories of the rwpt reference model the tp matrix was computed at h 10 20 30 40 m denoted as t h and the latter three were compared to t 10 using exponents of n 2 3 4 respectively for 6 the comparison for the smm single domain is shown in fig 9 where a point wise comparison of both tp matrices is shown and in fig 10 where we have extracted two columns from each of t to show the similarities more clearly than a full plot of t e g fig 5 the comparison between the different length scales and t 10 n is overall quite good considering the discrete nature of the transition matrices a complete markovian test for the multi domain case would require that the vdz and sat auto and cross transitions are all investigated but the vdz transitions introduced some unexpected challenges the uncorrelated regions of the tp matrices involving the vdz have the effect of erasing correlation when evaluating the matrix multiplication on right hand side of 6 the lack of correlation does not necessarily invalidate the markov hypothesis since for example diffusion is a markovian random walk process with uncorrelated jumps however there were not enough vdz transitions at the longer length scales to reliably populate the matrix on left hand side of 6 so a meaningful analysis was not possible in this case a domain with thicker vdz regions might be able to provide this test but since the experimental tp matrices were too sparse we focus our analysis exclusively on the densely populated sat sat auto transitions fig 5b the same columns were extracted from each t evaluated at the different length scales and are compared to t 10 n fig 11 shows the complete point wise correlation of all the values in the fields i e eq 6 and fig 12 provides a comparison of two columns of the tp matrices the relationship of 6 is not recovered exactly in either case but the correlation coefficients shown in table 1 suggest strong linear correlation which supports the markovian hypothesis the cross sections through the tp matrices figs 10 and 12 both show that good agreement is achieved in the regions of highest density with poorer fits moving towards the lower probability densities this is similar to the comparison given by le borgne et al 2008b and is also similar in agreement the errors tended to be highest in the low probabilities and this is clearly seen in the high scatter across the low values in figs 9 and 11 note that all of the performance metrics table 1 increase by at least 5 if the tps in the regression are truncated at 10 6 the low density scatter is likely caused by a combination of noise in the sampled trajectories and the number of particles used in the rwpt simulation despite these differences the overall agreement between t h n and t nh at different length scales is good when the complexity of the east inlet domain is considered perfect recovery of t h n should not be expected in the first place since this is discrete data from a topographically driven heterogeneous watershed that does not have perfect sampling of the full range of transitions further the various t are discrete and computed from finite data meaning that the sampling of low probabilities may be biased and as such are underestimated with these factors in mind it seems clear that the results of figs 9 and 11 strongly suggest i that spatial markov methods can potentially be good models for watershed scale transport and because it is correlated in space ii that at least within the saturated zone transport remains markovian in multi domain models and iii that unconfined transport in the saturated zone is markovian however evaluating the persistence of correlation and the strict validity of the markov hypothesis for the vdz transitions will require some additional investigations in domains with thicker unsaturated zones 6 discussion transport in watersheds is difficult to describe with any physically based model but the correlated random walks framework used here offers a new tool for approximating transport behaviors it is important to recall that our objective in this article is not to find a flawless fit to the east inlet rwpt simulations but i to investigate whether or not watershed transport appears to be markovian and ii to see if correlated random walks can even be applied to describing this kind of solute transport assessing each of these the results of section 4 show the md smm works well the analysis in section 5 suggests that transport is markovian and we note that this study also represents the first application of a spatial markov framework in a topographically driven unconfined system with a vadose zone this is a reasonable summary of our findings but there are some details worth discussing briefly first it is worth noting the impact of including a distinct vadose zone in the transition matrix which is clearly important the smm and md smm were created from the same rwpt trajectories but the latter provides a more compelling fit without modification which we attribute to the separation of the sat and vdz regions this highlights the major difference between the two the md smm allows some particles to spend many transitions in vdz moving slowly and this is not captured in the smm transition matrices given more bins or just different bins it may be possible to find an smm with comparable fit on average but such a model might not preserve the direct link to the rwpt trajectories might still not be multi modal and obviously would not explicitly separate the two processes another major difference between the two models is the multi modal btc peaks which were not captured by the smm there are several potential causes of this including the use of equally likely bins but ultimately we see the shape of the velocity pdf as the cause inspecting fig 3 the combined pdf has a single velocity peak and this creates the unimodal smm btc the sat and vdz pdfs have non overlapping regions and each has distinct peaks further emphasizing the importance that the md smm keeps vdz and sat distinct second are the problems encountered with the ovl domain the small number of ovl to vdz or sat transitions prevented us from computing tp matrices so no such transitions could be simulated but obviously these transitions occur in real systems the main issue is likely that the spatial markov scales of the surface domain are much smaller than those of the subsurface this might be handled by a two level or more in space approach where the ovl steps are smaller than the sat and vdz and this surely also requires a distinct velocity pdf for the ovl domain application of this for ovl ovl auto transitions would be trivial but it is unclear how the cross transitions e g ovl sat would be handled this problem is not trivial but if a solution can be found it would enable upscaled modeling of the complete coupled surface subsurface system and studies like that of kim and kang 2020 could help with this task further such a model could be combined with a reaction and mixing model e g engdahl et al 2017 sund et al 2017a to develop a coupled reactive transport model for watersheds critically this would keep track of the time spent in each process domain and allow the domains to have distinct reaction processes third is that the flow field through our example site is driven by a complex irregular topography and attenuated by a highly heterogeneous distribution of permeability and porosity engdahl and maxwell 2015 this complexity makes it difficult to isolate specific causes of the discrepancies between the observed and simulated btcs and also complicates the evaluation of the markov hypothesis for this reason we see a need for future work that starts with simpler watersheds where different kinds of complexity are layered on sequentially for example starting with a homogeneous domain with smooth topography one could add a weakly heterogeneous permeability then a stronger heterogeneity and so on this approach would provide valuable information regarding how the transition matrices and velocity distributions are affected by different kinds of complexity furthermore the flow field here was steady state as most all of the smm literature is with the exception of turbulent flow sund et al 2015a transient behaviors that are ubiquitous in small watersheds will need to be evaluated adding another layer of complexity that should be investigated in the future finally an unresolved and often ignored issue is that the smm and md smm share a fundamental limitation with many of their contemporary upscaled transport models it is difficult to confidently develop the models without a velocity field or direct observations of transport however the similarity of the sat sat transition matrix in such a complex watershed to those seen in other works e g le borgne et al 2008b kang et al 2011 suggests that there may be some universality to the transition matrices or that there may be a few fundamental shapes that provide good models for the ranked transition matrix e g massoudieh et al 2017a if this is the case it implies that only the values of the velocities need to be estimated and these could likely be approximated using model analogs or similar sites doing so would also require confirming that the transitions are truly stationary but we are currently exploring the details of how to generalize the smm and md smm frameworks to describe classes of watersheds instead of just specific cases similar concepts form the core of the bernoulli smm dentz et al 2016 massoudieh et al 2017a and an ornstein uhlenbeck smm morales et al 2017 puyguiraud et al 2019a 2019b recent successes with these methods and our own results suggest to us that the md smm and these related models can be combined and this may be a productive area of research going forward credit authorship contribution statement nicholas b engdahl conceptualization methodology diogo bolster conceptualization methodology declaration of competing interest the authors declare that they do not have any financial or nonfinancial conflict of interests acknowledgments ne was supported by the us department of energy office of science under award de sc0019123 db was supported by nsf grant cns 1831669 
509,transport processes in watersheds remain challenging to describe accurately with upscaled models because of their intricate complexities at multiple scales that can lead to multi modal non fickian breakthrough curves one of the recent advances in solute transport modeling has been the lagrangian spatial markov model smm which describes transport using velocity increments and models the correlated transitions between them the approach has been applied previously to saturated porous media and fractured media but these successful applications suggest it may be useful for describing watershed scale processes as well an existing 3 d heterogeneous variably saturated model of a headwaters catchment and classical random walk particle tracking were used to generate a forward simulation and the resulting transport was analyzed with a spatial markov framework existing smm methods were used to analyze the transport paths through the complex unconfined domain and we found that the vadose zone plays an important role in the correlation structure as such a new kind of smm is proposed termed a multi domain smm md smm that uses separate correlation models for auto transitions in the vadose zone and the saturated zone and for the cross transitions between them the md smm improves representation of transport relative to the single domain model and can naturally delineate times when a particle is in the vadose zone or the saturated zone adding an additional degree of realism to the upscaled model finally we show that the transition probability matrix for transport in the saturated portion of this unconfined system is approximately markovian which is an important validation of the proposed framework keywords spatial markov model continuous time random walks watershed transport 1 introduction the hydrologic systems that make up freshwater resources have a broad range of features including rivers streams and aquifers every watershed is unique but the presence of complex processes and heterogeneities is universal to them all making these systems challenging to simulate whether the goal is merely a better understanding or to make predictions forecasts in order to adequately model transport of anything be it for example contaminants nutrients other dissolved substances colloids bacteria and viruses models are needed that can realistically account for the impact of heterogeneities that are known to exist in the physical processes these could be variations in the parameters of an underlying physical model or different kinds of processes in different parts of the system among many others that represent the true processes details of heterogeneities vary considerably from system to system and they can span an enormous range of spatial and or temporal scales but they usually result in transport behaviors that significantly deviate from homogenized or overly simplified approximations however significant progress has been made toward upscaled modeling of the impacts of heterogeneities in saturated flow systems and many methods now exist that can provide comparably good descriptions of complex transport processes one of the major potential advantages is that these new methods allow practitioners to reasonably include effects of heterogeneities in simplified models offering more flexibility in the choice between complexity uncertainty and runtime in particular lagrangian models of solute transport are a robust platform for simulating a wide range of transport problems across the spectrum of hydrologic applications salamon et al 2006 benson et al 2017 both as models that aim to fully resolve transport in complex flow settings e g weissmann et al 2002 engdahl and weissmann 2010 atchley et al 2013a as well as within upscaled frameworks e g meyer and tchelepi 2010 dentz et al 2016 wright et al 2019 while many sophisticated lagrangian upscaling frameworks exist some recent rather flexible ones belong to the class of correlated velocity models which are built on the idea that a particle s current velocity can depend on its previous one relaxing assumptions inherent to many previous models in the context of a highly heterogeneous porous medium le borgne et al 2008b a demonstrated that lagrangian velocities were correlated in space and that this behavior could be effectively described with a correlated continuous time random walk ctrw the resulting correlated velocity model has been called the spatial markov model smm by several authors and many successful applications of this upscaled transport framework have been presented since examples include passive massoudieh et al 2017b sherman et al 2017 bolster et al 2014 and reactive sund et al 2017a wright et al 2019 sund et al 2017b transport in porous media with several extensions to fractured media kang et al 2011 2017 2016 however an important point is that all of the previous examples focused exclusively on the saturated zone and were predominately in confined porous media while this is an important set of problems the flexibility of the smm leads us to consider whether or not it can be generalized to a broader class of problems thinking in a more general hydrologic sense watersheds involve a combination of saturated sat vadose vdz and overland ovl flow regimes all of these flow processes are potentially nonlinear can cause feedbacks and exchanges between each other and it is known that omission of the interactions is often detrimental feedbacks significantly complicate upscaling of watershed transport processes and perhaps it is due to this complexity that most of the focus to date has been on integrated response modeling for watersheds botter et al 2011 botter 2012 benettin et al 2013 such response models are usually developed from observations of streamflow or stream chemistry and typically the term integrated implies that only the net combined impact of all transport process is considered however the nonlinear nature of watershed processes means that a model developed from one set of observations may fail when new flow conditions are encountered and the integrated response model cannot easily include many processes of interest like spatially variable reactions though these are common challenges to any simplified model another option for watershed modeling is direct numerical simulation dns based on the governing equations of flow and transport e g kollet and maxwell 2008 atchley et al 2013a engdahl and maxwell 2015 however the dns approach has a heavy data requirement significant room for uncertainty and computational expenses can be prohibitive applications of dns show great potential for hypothesis testing using virtual watersheds but often struggle when making predictions since model calibration is challenging given the potentially vast number of modeling parameters and prohibitively long run times thus an ambitious challenge is to find some middle ground between purely integrated response models and dns for watershed transport that can be used for common watershed modeling forecasting tasks ideally such a model would approximate enough of the physics that it allows delineation of and interaction between the different process domains sat vdz and ovl while being less complicated than a fully detailed 3 d distributed flow and transport model one candidate for such an upscaled transport framework is the smm which is already known to work well in the saturated zone and has had some application to unconfined and river systems kim and kang 2020 sherman et al 2019 smm models are also inherently stochastic which can allow for robust non parametric uncertainty quantification in a relatively short amount of time however at this time there are four potential implementation barriers i to date the smm has not been used in topographically driven unconfined systems ii the spatial markovian hypothesis has not been tested for topographically driven flows iii the smm has not been used in variably saturated flows and iv smms have not been tested extensively in multiple connected flow domains here we aim to explore whether or not these are surmountable barriers given the fact that so many different hydrologic systems display distinct but shared anomalous behaviors we believe it is interesting to ask whether an overarching framework can be combined to successfully upscale transport at watershed scales to this end the purpose of this article is two fold first to evaluate the performance of the smm in a variably saturated system and second to propose a new modified multi domain smm denoted md smm that is designed to more closely represent actual watershed processes in an upscaled framework the basic elements of the new model are the same as the previous single domain smm but we describe the velocity correlations in different flow domains separately and allow them to interact the resulting model is a coupled representation of transport in the different process domains that allows transitions back and forth between them ideally forming a representation of the interactions that occur in real systems the structure of the article lays out the watershed model used to generate the reference forward simulation from random walk particle tracking rwpt in section 2 section 3 introduces the single and multi domain smm formulations and section 4 evaluates the two models against the rwpt simulation finally section 5 considers the important test of whether or not the markovian hypothesis is valid in the context of a full watershed our objective here is not to find or to calibrate a model that perfectly fits the rwpt simulation since some error should be expected when comparing any approximation to results from a complex system rather we aim to consider whether or not a correlated markovian framework can even be applied to reasonably upscale transport in topographically varying unconfined watersheds 2 reference simulation domain the watershed used in this study is the east inlet basin located in central northern colorado usa within rocky mountain national park the domain was previously developed by engdahl and maxwell 2015 to investigate the impacts of climate change on residence time distributions in high order watersheds and the domain is broadly representative of many of the small snowmelt driven headwaters systems throughout the rocky mountains the watershed simulation itself is a fully coupled surface subsurface model constructed using the parflow numerical model ashby and falgout 1996 jones and woodward 2001 maxwell 2013 which solves the mixed form of the 3 d richard s equation coupled to a kinematic wave model for surface routing with a free surface overland flow boundary kollet and maxwell 2006 the domain is about 6km long by 5km wide with roughly 1km of surface relief fig 1 and is characterized by rough irregular topography highly variable slope angles with numerous springs seeps and a series of small lakes feeding into each other along the main axis of the watershed a 3 d categorical hydrogeologic model of the subsurface was developed based on the known geological history of the area and log normally distributed correlated permeability distributions were inserted into each hydrofacies the resulting steady state model provides a good representation of the system s main elements i e lakes streams and springs seeps and its outflow is a good approximation of the seasonal average giving us high confidence in the internal dynamics of the model as a realistic virtual watershed for testing upscaled markovian models transport through the domain was simulated using random walk particle tracking rwpt methods described by maxwell et al 2008 and de rooij et al 2013 the latter of these is important in the context of this study because it explicitly allows for exchange between the subsurface and overland flow domains de rooij et al 2013 accomplished this by using a probabilistic mass transfer scheme between the ovl and subsurface based on a mass balance of the surface and subsurface fluxes interested readers are referred to that work for more details the backward in time rwpt simulation released a total of 225 000 particles into the ovl domain of the east inlet model simulating a water sample taken from the stream the release location is shown in fig 1 as the red diamond the particles were tracked back to their source locations and their paths stored for analysis both maxwell et al 2008 and de rooij et al 2013 implement pollock s method which allowed us to use a reasonably large time step of 5 days for a simulation period of 200 years at the end of the simulation period about 99 of the injected particles had left the domain with a small amount of residual mass in the domain in the lowest permeability regions while such tailing can be important in some cases here we are mainly concerned with the ability of the smm and md smm to reasonably approximate large scale transport not to precisely reproduce it as such complete resolution of the tail is not necessary and we note that field tracer tests also never give perfect recovery of the tracer the reference breakthrough curve btc or cumulative distribution function cdf of transport is shown as the blue histogram bars in fig 2 and the lagrangian velocity distributions as a cdf and probability distribution function pdf are shown in fig 3 since the domain is snowmelt driven and at steady state only about 1 of the particles enter as direct recharge to the streams and the remaining 99 of the particles experience subsurface flow the most notable characteristic is that the btc has distinct multi modal behavior that indicates the presence of fast preferential flow paths arriving before about τ 10 0 t followed shortly after by the larger mass fraction note that all times are given in years such a feature is not readily captured by traditional upscaling models but the smm has been able to reproduce transport with challenging features like these from pore scale e g bolster et al 2014 to aquifer scales e g le borgne et al 2008b 3 spatial markov modeling 3 1 single domain smm the general smm framework is a 1 d upscaled transport model that discretizes the path of a material element particle through a domain into a series of spatially uniform steps and the transition waiting time to make each step is treated as a random variable le borgne et al 2008b 2008a thus the smm fits in the broad class of the ctrw family of methods what makes the smm unique is that subsequent waiting times can be correlated where the next step in the sequence depends on the one just completed the correlation to complete each step is expressed in terms of a discrete transition probability tp matrix between different velocity bins or transition times of the model where the tp matrix controls the transitions between the bins thus embedding correlation into the model conceptually correlation arises because a fast moving particle is more likely to keep moving fast than it is to slow down both outcomes are possible but the latter is generally less likely this approach contrasts other forms of ctrw that do not explicitly model correlations or classical uncorrelated random walks where transition times are fixed and the spatial jump size is the random variable e g labolle et al 1996 more details on the nature of uncorrelated random walks can be found in salamon et al 2006 and noetinger et al 2016 the langevin equation describing how particles transition through space and time within the smm is given by 1a x k 1 x k l 1b t k 1 t k τ i j where i and j denote the starting and ending velocity bins respectively k indexes the steps in the series x is the position of the random walker l is the constant spatial step size and τ i j is the transition time for the i j transition modified after bolster et al 2014 the core of the method is the transition probability matrix which is used to select the final bin j conditional to the starting velocity bin i details on the construction of the tp matrix from high resolution particle trajectory data can be found in sund et al 2015b 2017c and wright et al 2019 among others although parameterization methods from btc data alone also exist e g sherman et al 2017 2018 following le borgne et al 2008b the general form is 2 t i j h p j at x h i at x p j at x h i at x p i at x the transition matrix can be built by directly sampling particle trajectories at separation distances h along the paths and directly applying 2 note that this h is distance along the pathline we then use the columns of the full transition matrix to define the conditional cumulative distribution function ccdf that is used to randomly select the next velocity conditional to the initial velocity to implement a full smm model one chooses the number of random walkers the lengths of their paths and their initial speed then 1a is applied using the ccdf to draw the values of τ i j for each step here we specifically use the discrete points defined by 2 as the points for a velocity interpolation which allows a continuous distribution of τ i j rather than a discrete model 3 2 multi domain smm the md smm is designed to delineate the state of a random walker as it moves through the transport domain in the same way flows evolve in watersheds the watershed is decomposed into three sub domains referred to as process domains representing 1 overland flow ovl 2 vadose zone vdz flows and 3 saturated groundwater sat flow and each must be described by its own transition matrix however these sub domains are not isolated and interactions are allowed by adding cross transition matrices to the model the complete system of transition probabilities are described in a nested transition matrix denoted as t i j m n where i and j index the initial and final velocity bins but we add m and n to keep track of the process domain when m n the transition is an auto transition that keeps the random walker within the same process domain and the transition represents a transfer between process domains anytime m n the number of velocity bins and their cutoff thresholds can differ in every region of the nested transition matrix so for example the first overland bin could span a range of velocities that is orders of magnitude wider than the first bin of the saturated zone the transition probabilities are computed almost identically to section 3 1 but the conditional probability is modified to include multiple process domains the multi domain transition probability is defined as 3 t i j m n h p j at x h n i at x m p j at x h n i at x m p i at x m by bayes theorem where i and j are still indices over the velocity bins p denotes a probability h remains separation distance along the pathline but we add m and n to index the process domains ovl vdz and sat however the i and j indices themselves are now conditional to the domains since each may have a unique distribution of velocity bins in other words t i j m n describes transitioning from the ith bin of the discrete velocity pdf for the mth originating domain into the jth bin of the pdf for the nth destination domain but each pdf may be different like the standard smm the transport simulation for each particle in the ensemble is built by selecting a number of spatial steps where τ is a correlated random variable given an initial domain and velocity for the sequence of transitions we can write the langevin equation 4a x k 1 n x k m l 4b t k 1 n t k m τ i j m n the simulations follow the same procedure as the smm but transitions are now conditional to the mth domain at the kth step the corresponding column is still extracted from the t matrix 3 to build the ccdf that is used to probabilistically select the transition but every sub domain transition is included in the ccdf note that 4a naturally recovers the single domain smm when there is a single category but adds the ability to track the domain of the walker and assign different velocity distributions when multi domains are used we note that at least two other studies have considered some aspects of flow systems that are connected across two process domains the dual domain model of sherman et al 2019 and the free surface and porous model of kim and kang 2020 the former considered hyporheic exchange between a turbulent river and porous continuum whereas the latter solved the pore scale velocity field to consider flow over and through a porous substrate sherman et al 2019 is conceptually similar to the md smm because it is a 2 state model but the transitions were not modeled using a transition probability matrix and neither of these studies explicitly considered vdz flows 4 model evaluation 4 1 transition matrices this section evaluates whether or not the smm and md smm models can be applied to reasonably approximate transport in a realistic watershed to do so we construct descriptive models of the smm and md smm for the transport simulated in the east inlet domain we use the trajectories of the rwpt particles to build the tp matrices which contained over 14 million transitions the procedure to compute t via direct application of 2 or 3 to the trajectories are basically the same the first step is to apply a streamline transformation to the coordinates of the particles see atchley et al 2013b this operation projects the 3 d particle positions onto a 1 d line representing the cumulative length of the path of each particle a separation distance h is chosen for calculating the tps and the times when each particle transitions an interval of h are recorded the initial velocity bin is defined by the time it takes the particle to move from a given starting position s 0 to s 1 s 0 h as v 1 h t s h t s and the final bin is defined based on the time to travel from s 1 to s 2 s 1 h the md smm differs from the smm by adding delineation of the process domain this raises the issue of how to define the domain for a transition since a particle could pass through more than one if a given step is large enough the simplest option is to adopt the domain at the end of each step for example the process domain at s 1 is the initial domain and the process domain at s 2 is the final domain alternatively one could choose whichever category occupies a larger spatial or larger temporal fraction of the step we experimented with all three and found minimal differences thus adopting the ending point definition for simplicity but acknowledge that this question may merit further investigation in other settings with this minor modification 2 and 3 were used independently to build smm tp matrices and nested md smm tp matrices based on the rwpt simulations preliminary testing revealed that there were not enough transitions involving the ovl domain both auto and cross transitions to construct a reasonably smooth t stream ovl cells can only occur in the top layer so they are not abundant compared to vdz and sat cells and this also limits their juxtaposition to a limited subset of the vdz and sat cells furthermore velocities in the ovl are significantly higher than the subsurface domains which implies that the markov scales may not be compatible for these reasons we chose to focus on the two subsurface domains vdz and sat for the smm and md smm models and reserve the ovl issues for future study portions of the particle trajectories that were in the ovl domain were truncated but the remainder of the paths and travel times were unaltered the transition matrices for the smm and md smm vdz and sat models are shown in figs 4 and 5 the pdfs of velocity in vdz and sat were found to cover the same broad ranges so a single set of bins was used for both and 40 bins provided a reasonable description of the system sensitivity to the number of bins is considered in section 4 3 the velocity distribution spans 7 orders of magnitude so a logarithmic transform was applied to them and equally likely binning was used which is standard practice for most smm applications the trajectory analysis provided a distribution of pathline lengths for the particle ensemble and from this we selected smm step size of h 10 m which is half the lateral cell size of the finite difference grid velocity field and well below the heterogeneity length scales of the domain note that different h values are considered in section 5 fig 4 shows that smm transitions are almost symmetric the most likely transition for any initial bin is at most a small change in velocity class and the likelihood of speeding up and slowing down are basically the same these findings are consistent with previous work le borgne et al 2008b 2008a however several interesting tendencies are revealed from the md smm version in fig 5 first the sat sat transitions are nearly identical to the smm showing that the saturated zone is dominating the behavior of the smm next despite the broad range of velocities in the vadose zone vdz vdz transitions are concentrated to the slower speeds fig 5 bin 15 and below where they exhibit some correlation but are generally uncorrelated at higher speeds similar behavior is seen for the sat vdz transition there is a bit more structure to the correlated portion of the vdz sat tp matrix relative to vdz vdz but transitions to and from high bin numbers remain random the vdz sat matrix is unique among the vdz transitions because it exhibits a tendency to accelerate which can clearly be seen in fig 5d where most of the probability mass resides above the diagonal there is some complementary behavior in the sat vdz matrix which tends to slow slightly and both of these behaviors could also be inferred from the offsets in the velocity pdfs fig 3 the key points about these transition matrices are that 1 sat sat transitions exhibit strong correlation 2 correlated vdz transitions tend to occupy a tight region of the chosen velocity space and are uncorrelated outside of this region and 3 vdz sat transitions are somewhat distinct because they show a tendency to speed up 4 2 upscaled transport modeling the forward smm and md smm representation of the rwpt model used n p 20 000 and are simulated following the algorithm described in section 3 the initial velocity bins and step numbers are identical for both approaches but the latter starts all particles in the vadose zone recall that the smm does not distinguish vdz and sat note that the reference simulation was a backward model where particles were released in ovl and tracked back to their source which was always vdz thus the forward md smm simulation must start all particles in vdz to achieve the same behavior the simulated breakthrough curves are shown in fig 6 with vertical bars representing the reference btc it should be evident that there are significant differences between the smm and md smm models the median of the smm is shifted toward early arrivals yet it does a poor job of actually representing the early arrivals the md smm on the other hand does a reasonably good job throughout the early and mid times but does not capture the tail of the btc very well we expect that the deficiency in the tail is caused by the relatively low probability of staying in the same velocity bin for the cross transitions and the scatter around the vdz autotransition however the main point is that the md smm provides a good upscaled model of transport in this watershed for the majority of its btc without any parameter adjustments 4 3 main sensitivities even though the md smm model exhibits a good overall fit to the majority of the btc it is worth considering the sensitivities of the upscaled model to the two major components the number of particles and the number of velocity bins note that the question of markov length scales is addressed in section 5 the original md smm and smm arbitrarily used n p 20 k so we investigated n p 0 1 k 0 25 k 0 5 k 1 k 5 k for comparison the btcs for this exercise are shown in fig 7 for the both the smm and md smm in each case the same tp model was used and the only difference was np the main consequence of using increasingly greater particle numbers is the number of potential fast and late arrivals in the btc so the number of particles for a simulation should be selected to achieve the necessary resolution but this is true of all rwpt based methods however for this specific case both the smm and md smm models exhibited minimal sensitivity to np and the same basic btc was produced with as few as 100 particles though such a small np cannot resolve the leading or tailing edges of the btc with precision the second component we modified was the number of velocity bins different numbers of velocity bins were tested when developing the tp matrices ranging from 20 60 using equally likely bins with logarithmic spacing some details on the selection of bins for the smm can be found in le borgne et al 2011 and sherman et al 2017 but the final number of bins 40 was chosen because this gave good resolution of the tp matrices for both the smm and md smm minimized extreme values high and low transition frequencies and provided a reasonably smooth simulated btc from the md smm there are infinitely many combinations of velocity bin numbers and cutoffs that could be tested and presently there is no conclusive guidance on how to select the best number of categories so some experimentation is necessary to determine a reasonable tp matrix to illustrate these sensitivities we show two alternative smm tp matrices using 20 and 60 bins in fig 8 similar kinds of behaviors are seen for the 2 2 plots for the md smm but these are omitted since this is an illustrative example and not a fundamental result a related point is that we have not yet experimented with the use of separate velocity bins for the vdz and sat zones but doing so may improve the accuracy of the md smm since all the transition matrices involving the vadose zone are biased to the low speed velocity bins however this and several other potential improvements are saved for future investigation in a domain with less complexity 5 is transport in watersheds markovian so far we have proposed and evaluated single and multi domain smm models for describing transport in a variably saturated system doing so explicitly assumes that transport is markovian but we have not yet formally tested the accuracy of this assumption nor has it been tested in the literature to do so we must demonstrate that transition probabilities satisfy the chapman kolmogorov equation following le borgne et al 2008b this implies that the discrete transition matrix t evaluated at a separation distance h and at h h where h 0 are related by 5 t h h t h t h if we require that h is an integer order factor of h such as h h n h where n is an integer then the transition matrix must satisfy 6 t n h t h n note that the right hand side rhs is a matrix product not element wise multiplication the rhs of this equation is t computed at h whereas the left hand side is t computed at nh if the two sides of 6 are equal it means that the tp matrix for completing a sequence of n steps of size h is exactly the same as taking one step of size nh if this is the case it shows formally that the transition probabilities of the sequence of steps are independent random variables markovian behavior can be considered for random processes in space and or time but le borgne et al 2008a already showed that subsurface transport processes are generally not markovian in time so only the spatial markov hypothesis is evaluated eq 6 was tested using the trajectories of the rwpt reference model the tp matrix was computed at h 10 20 30 40 m denoted as t h and the latter three were compared to t 10 using exponents of n 2 3 4 respectively for 6 the comparison for the smm single domain is shown in fig 9 where a point wise comparison of both tp matrices is shown and in fig 10 where we have extracted two columns from each of t to show the similarities more clearly than a full plot of t e g fig 5 the comparison between the different length scales and t 10 n is overall quite good considering the discrete nature of the transition matrices a complete markovian test for the multi domain case would require that the vdz and sat auto and cross transitions are all investigated but the vdz transitions introduced some unexpected challenges the uncorrelated regions of the tp matrices involving the vdz have the effect of erasing correlation when evaluating the matrix multiplication on right hand side of 6 the lack of correlation does not necessarily invalidate the markov hypothesis since for example diffusion is a markovian random walk process with uncorrelated jumps however there were not enough vdz transitions at the longer length scales to reliably populate the matrix on left hand side of 6 so a meaningful analysis was not possible in this case a domain with thicker vdz regions might be able to provide this test but since the experimental tp matrices were too sparse we focus our analysis exclusively on the densely populated sat sat auto transitions fig 5b the same columns were extracted from each t evaluated at the different length scales and are compared to t 10 n fig 11 shows the complete point wise correlation of all the values in the fields i e eq 6 and fig 12 provides a comparison of two columns of the tp matrices the relationship of 6 is not recovered exactly in either case but the correlation coefficients shown in table 1 suggest strong linear correlation which supports the markovian hypothesis the cross sections through the tp matrices figs 10 and 12 both show that good agreement is achieved in the regions of highest density with poorer fits moving towards the lower probability densities this is similar to the comparison given by le borgne et al 2008b and is also similar in agreement the errors tended to be highest in the low probabilities and this is clearly seen in the high scatter across the low values in figs 9 and 11 note that all of the performance metrics table 1 increase by at least 5 if the tps in the regression are truncated at 10 6 the low density scatter is likely caused by a combination of noise in the sampled trajectories and the number of particles used in the rwpt simulation despite these differences the overall agreement between t h n and t nh at different length scales is good when the complexity of the east inlet domain is considered perfect recovery of t h n should not be expected in the first place since this is discrete data from a topographically driven heterogeneous watershed that does not have perfect sampling of the full range of transitions further the various t are discrete and computed from finite data meaning that the sampling of low probabilities may be biased and as such are underestimated with these factors in mind it seems clear that the results of figs 9 and 11 strongly suggest i that spatial markov methods can potentially be good models for watershed scale transport and because it is correlated in space ii that at least within the saturated zone transport remains markovian in multi domain models and iii that unconfined transport in the saturated zone is markovian however evaluating the persistence of correlation and the strict validity of the markov hypothesis for the vdz transitions will require some additional investigations in domains with thicker unsaturated zones 6 discussion transport in watersheds is difficult to describe with any physically based model but the correlated random walks framework used here offers a new tool for approximating transport behaviors it is important to recall that our objective in this article is not to find a flawless fit to the east inlet rwpt simulations but i to investigate whether or not watershed transport appears to be markovian and ii to see if correlated random walks can even be applied to describing this kind of solute transport assessing each of these the results of section 4 show the md smm works well the analysis in section 5 suggests that transport is markovian and we note that this study also represents the first application of a spatial markov framework in a topographically driven unconfined system with a vadose zone this is a reasonable summary of our findings but there are some details worth discussing briefly first it is worth noting the impact of including a distinct vadose zone in the transition matrix which is clearly important the smm and md smm were created from the same rwpt trajectories but the latter provides a more compelling fit without modification which we attribute to the separation of the sat and vdz regions this highlights the major difference between the two the md smm allows some particles to spend many transitions in vdz moving slowly and this is not captured in the smm transition matrices given more bins or just different bins it may be possible to find an smm with comparable fit on average but such a model might not preserve the direct link to the rwpt trajectories might still not be multi modal and obviously would not explicitly separate the two processes another major difference between the two models is the multi modal btc peaks which were not captured by the smm there are several potential causes of this including the use of equally likely bins but ultimately we see the shape of the velocity pdf as the cause inspecting fig 3 the combined pdf has a single velocity peak and this creates the unimodal smm btc the sat and vdz pdfs have non overlapping regions and each has distinct peaks further emphasizing the importance that the md smm keeps vdz and sat distinct second are the problems encountered with the ovl domain the small number of ovl to vdz or sat transitions prevented us from computing tp matrices so no such transitions could be simulated but obviously these transitions occur in real systems the main issue is likely that the spatial markov scales of the surface domain are much smaller than those of the subsurface this might be handled by a two level or more in space approach where the ovl steps are smaller than the sat and vdz and this surely also requires a distinct velocity pdf for the ovl domain application of this for ovl ovl auto transitions would be trivial but it is unclear how the cross transitions e g ovl sat would be handled this problem is not trivial but if a solution can be found it would enable upscaled modeling of the complete coupled surface subsurface system and studies like that of kim and kang 2020 could help with this task further such a model could be combined with a reaction and mixing model e g engdahl et al 2017 sund et al 2017a to develop a coupled reactive transport model for watersheds critically this would keep track of the time spent in each process domain and allow the domains to have distinct reaction processes third is that the flow field through our example site is driven by a complex irregular topography and attenuated by a highly heterogeneous distribution of permeability and porosity engdahl and maxwell 2015 this complexity makes it difficult to isolate specific causes of the discrepancies between the observed and simulated btcs and also complicates the evaluation of the markov hypothesis for this reason we see a need for future work that starts with simpler watersheds where different kinds of complexity are layered on sequentially for example starting with a homogeneous domain with smooth topography one could add a weakly heterogeneous permeability then a stronger heterogeneity and so on this approach would provide valuable information regarding how the transition matrices and velocity distributions are affected by different kinds of complexity furthermore the flow field here was steady state as most all of the smm literature is with the exception of turbulent flow sund et al 2015a transient behaviors that are ubiquitous in small watersheds will need to be evaluated adding another layer of complexity that should be investigated in the future finally an unresolved and often ignored issue is that the smm and md smm share a fundamental limitation with many of their contemporary upscaled transport models it is difficult to confidently develop the models without a velocity field or direct observations of transport however the similarity of the sat sat transition matrix in such a complex watershed to those seen in other works e g le borgne et al 2008b kang et al 2011 suggests that there may be some universality to the transition matrices or that there may be a few fundamental shapes that provide good models for the ranked transition matrix e g massoudieh et al 2017a if this is the case it implies that only the values of the velocities need to be estimated and these could likely be approximated using model analogs or similar sites doing so would also require confirming that the transitions are truly stationary but we are currently exploring the details of how to generalize the smm and md smm frameworks to describe classes of watersheds instead of just specific cases similar concepts form the core of the bernoulli smm dentz et al 2016 massoudieh et al 2017a and an ornstein uhlenbeck smm morales et al 2017 puyguiraud et al 2019a 2019b recent successes with these methods and our own results suggest to us that the md smm and these related models can be combined and this may be a productive area of research going forward credit authorship contribution statement nicholas b engdahl conceptualization methodology diogo bolster conceptualization methodology declaration of competing interest the authors declare that they do not have any financial or nonfinancial conflict of interests acknowledgments ne was supported by the us department of energy office of science under award de sc0019123 db was supported by nsf grant cns 1831669 
