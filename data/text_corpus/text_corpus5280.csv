index,text
26400,experimental and simulation uncertainties have not been included in many of the statistics used in assessing agricultural model performance the objectives of this study were to develop an f test that can be used to evaluate model performance considering experimental and simulation uncertainties and identify the best datasets to use for model calibration using different water stress functions in a cropping system model data on irrigated maize in colorado usa and the root zone water quality model rzwqm were used as an example to demonstrate model calibration using the modified f test along with other commonly used statistics compared to the d index the f test provided a statistical test under a certain confidence level that better distinguished the goodness of model prediction for both biomass and yield while considering uncertainty to obtain robust model parameters we recommend using multiple treatments across multiple years for model calibration regardless of water stress functions used keywords uncertainty model calibration rzwqm f test goodness of fit maize 1 introduction very few statistics are satisfactory in determining the goodness of model fit in calibration and prediction and model users seem to tolerate a large simulation error in agriculture because of considerable experimental uncertainties in field research ritter and muñoz carpena 2013 the most commonly used statistical metrics for agricultural models are coefficient of determination r2 root mean squared error rmse relative error re nash sutcliffe model efficiency nse and index of agreement d index in addition to graphical visualization ma et al 2011 krause et al 2005 whitmore 1991 however these statistics do not consider either experimental and simulation uncertainties therefore it may be erroneous or subjective to use these statistics in judging the performance of a model using these statistics based on the criteria suggested by moriasi et al 2007 ritter and muñoz carpena 2013 used bootstrapping to create empirical probability distributions of rmse and nse so that significance of rmse and nse in relation to their respective threshold could be tested but they still did not consider experimental nor simulation uncertainties in addition the significance was referring to rmse and nse not to the experimental nor simulation data to account for experimental measurement uncertainties harmel and smith 2007 introduced a correction factor cf for calculating the differences between simulated and observed values in their statistics they found that model performance d index was improved after considering experimental uncertainty in a later study harmel et al 2010 further improved the d index by incorporating both experimental and simulation uncertainties harmel et al 2014 stated that it was critically important to include both measured data and simulation uncertainty in interpreting and communicating model results yen et al 2014 developed an integrated parameter estimation and uncertainty analysis tool ipeat that considered uncertainties due to input data model parameters model structure and calibration validation data using the correction factor cf of harmel and smith 2007 for the nash sutcliffe model efficiency they found that the calibrated model by considering three or more uncertainties was more robust than that without considering any uncertainty in model parameterization however in a later study yen et al 2016 found that including measurement uncertainty in calibration datasets would not significantly affect model calibration unless the uncertainty is greater than 50 however most statistics used in model comparisons are relative and there is no test of significance between model performances for example saseendran et al 2014 compared three water stress functions in the root zone water quality model rzwqm using the rmse and d index they found that the two modified water stress functions based on the nimah hanks water uptake or canopy heating effects provided better predictions of maize yield biomass leaf area index and soil water content using data from three locations in colorado than the original water uptake function in the ceres maize model in another study fensterseifer et al 2017 used relative rmse as a criterion to evaluate the number of datasets needed to calibrate the cropgro soybean model using 21 datasets from eight locations in southern brazil they found that two datasets from each location are needed for model calibration however both studies used trial and error in model calibration and the calibrated parameters may not be rigorous in addition to the subjectivity of the statistics used ma et al 2012a and kersebaum et al 2008 used a lack of fit an f test to calculate the significance of model predictions when experimental uncertainties existed based on the study of whitmore 1991 they found that the f test could be more rigorous than the ranges of indicators proposed by moriasi et al 2007 the objectives of this study were to 1 develop an f test for evaluating model performance by including both experimental and simulation uncertainties 2 compare model performance using various water stress functions in rzwqm and 3 identify the best datasets for model calibration a published dataset on irrigated maize in colorado usa and the root zone water quality model rzwqm were used as an example to demonstrate the modified f test along with three commonly used statistics the d index rmse and r2 since the modeling results were published in previous papers ma et al 2012b 2016 saseendran et al 2014 our emphasis was on quantifying the model performance by applying the newly modified f test rather than analyzing the causes of modeling deficiency from the underlying biophysical processes in the model 2 materials and methods 2 1 experimental dataset and model simulation the field experimental data were obtained from a study conducted from 2008 to 2011 near greeley colorado usa 40 45 n 104 64 w the soil is a sandy loam and is fairly uniform throughout the 200 cm soil profile six irrigation treatments micro irrigation with surface drip tubing adjacent to each row with four replicates were designed to meet a specified percentage of potential crop evapotranspiration et requirements allen et al 1998 2005 during the growing seasons 100 t1 85 t2 75 t3 70 t4 55 t5 and 40 t6 of potential crop et the amount of water for each treatment was estimated at a 3 6 day interval based on reference et demand crop coefficient rainfall and soil water deficit the t1 treatment was irrigated such that water availability irrigation plus precipitation plus stored soil water was adequate to meet crop water requirements as predicted by the reference evapotranspiration and crop coefficients fao 56 methodology allen et al 1998 the remaining treatments were irrigated to meet a certain percentage of water demand in t1 maize cv dekalb 52 59 was planted at an average rate of 81 000 seeds per hectare with 0 76 m row spacing in early may from 2008 to 2011 a detailed description of the experiment is provided by ma et al 2012b and the experimental dataset and detailed methodology can also be found at us department of agriculture national agricultural library ag data commons trout and bausch 2017 the root zone water quality model rzwqm is a comprehensive agricultural system model and has process level simulations of soil water soil temperature plant growth pesticide fate and soil c and n dynamics as influenced by various agricultural management practices ahuja et al 2000 the dssat 4 0 crop models e g ceres maize and ceres wheat models incorporated in rzwqm can be used to simulate crop growth water use and n uptake where rzwqm provides soil water soil temperature and nutrient information for dssat4 0 crop models ma et al 2006 in rzwqm there are three water stress functions users can select the first is from the dssat model that is defined as the ratio of potential root water uptake trwup to potential plant transpiration epo ritchie 1998 referred hereafter as default water stress function wsf1 saseendran et al 2014 1 w s f 1 t r w u p e p o the simplified close form equation of ritchie 1998 used to calculate the trwup in eq 1 is 2 trwup i 1 n k 1 e k 2 s w i l l i k 3 ln r l v i r l v i δ z i where rlv i is root length density in soil layer i cm cm 3 k1 0 00132 k2 45 0 if the drained lower limit ll of soil water permanent wilting point or soil water content at 1 5 mpa suction in the soil layer is greater than 0 30 cm3 cm 3 and k2 130 ll l if ll for the soil layer is less than 0 30 cm3 cm 3 k3 7 01 sw i and ll i are respectively volumetric soil water content and lower limit of plant available water in layer i cm cm 1 z i is soil depth of layer i cm the second water stress function wsf2 estimates trwup from the nimah hanks equation nimah and hanks 1973 the root water uptake part of the sink term s r z t cm hr 1 is computed using the nimah and hanks 1973 equation 3 t r w u p n h i 1 n s r z i t i 1 n h r r r z i h z i t s z i t r z i k i θ δ x δ z i δ z i where θ volumetric soil water content cm3 cm 3 t time hr zi soil depth cm assumed positive downward h soil water pressure head cm ki θ unsaturated hydraulic conductivity cm hr 1 a function of h and z hr an effective root water pressure head cm rr a root resistance term and the product rr zi accounts for gravity term and friction loss in hr assumed 1 05 s zi t the osmotic pressure head assumed 0 cm δx the distance from plant roots to where h zi t is measured assumed 1 cm δz soil depth increment cm r zi proportion of the total root activity in the depth increment δzi obtained from the plant growth model the total potential uptake trwup nh is calculated from summation of eq 3 with hr set equal to 1 5 mpa as the permanent wilting point which may be modified by users according to crop species thus 4 w s f 2 t r w u p n h e p o the third water stress function considers water stress due to heating of the canopy by the latent heat energy partitioned to potential soil evaporation but not used in soil evaporation when the surface soil water content is limiting therefore we explored including stress due to additional canopy heating in calculation of the water stress functions by changing their formulation as described below by including actual soil evaporation es for the day in the numerator and using total evapotranspiration et in the denominator 5 w s f 3 t r w u p n h e s e t with measured soil properties shown in table 1 an automated optimization and parameter estimation software pest doherty 2010 ma et al 2012a 2016 in rzwqm was used to calibrate crop cultivar parameters tables 2 and 3 the six irrigation treatments with four replicates carried out from 2008 to 2011 were used for selecting subsets of observed data to be used for model calibration to investigate the effect of different measured datasets on optimizing crop cultivar parameters and crop growth outputs rzwqm was first calibrated either using sub datasets from one treatment of multiple years trt 1 trt 2 trt 3 trt 4 trt 5 and trt 6 or from multiple treatments of one year year 2008 year 2009 year 2010 and year 2011 or all the treatments and the years the calibrated cultivar parameters were then used to simulate all the datasets and statistics were computed from all the datasets simulated with each set of cultivar parameters detailed information on model calibration using pest in rzwqm can be found in ma et al 2012a the three water stress functions have been modeled and compared with the same data above by saseendran et al 2014 and we are using it again here to re evaluate the performance of the wsfs based on the modified f test below different from saseendran et al 2014 the pest was implemented to derive crop parameters rather than by trial and error 2 2 modified f test with experimental and simulation uncertanity for convenience we first define the following symbols l number of experimental or measurement groups the groups may represent different treatments or different sampling dates ni number of measured replicates for the ith experimental or measurement group mi number of prediction replicates for the ith experimental or measurement group oij jth observation replicate for the ith measurement group oij μi εij and e oij μi pik kth predicted value replicate for the ith measurement group pik λi δik and e pik λi λi true mean of predictions for the ith experimental or measurement group μi true mean of observations for the ith experimental or measurement group p i 1 m i k 1 m i p i k mean of prediction for the ith experimental or measurement group based on a simulation model pi is independent of oij o i 1 n i j 1 n i o i j mean of the ith experimental or measurement group d i 2 1 m i 1 k 1 m i p i k p i 2 prediction variance of ith experimental or measurement group s i 2 1 n i 1 j 1 n i o i j o i 2 sample variance of ith experimental or measurement group when there is no simulation uncertainty for an experiment with n experimental or measurement groups and ki replicates in each group total sum of squared prediction errors tss may be written as ma et al 2012a 6 t s s i 1 l j 1 n i p i o i j 2 which can be rearranged as 7 t s s i 1 l j 1 n i p i o i o i o i j 2 i 1 l j 1 n i p i o i 2 i 1 l j 1 n i o i j o i 2 i 1 l n i p i o i 2 i 1 l j 1 n i o i j o i 2 l o f i t s s e where lofit is the sum of squared errors between predicted and observed mean values due to lack of fit and sse is the sum of squared error due to experimental error εij sse may be rewritten as wackerly et al 2008 8 l o f i t i 1 l n i p i o i 2 and 9 s s e i 1 l j 1 n i o i j o i 2 i 1 l n i 1 s i 2 the mean lofit mslofit and mean sse mse are defined as 10 m s l o f i t l o f i t i 1 l n i a n d m s e s s e i 1 l n i 1 i 1 l n i 1 s i 2 i 1 l n i 1 therefore an f test statistic can be constructed as whitmore 1991 kersebaum et al 2008 11 f 1 m s l o f i t m s e with degrees of freedom of ν1 i 1 l n i for the numerator and ν2 i 1 l n i 1 for the denominator to test whether model predictions pi correctly estimate the true mean of the observations for the ith experimental or measurement group the hypothesis would be ho pi μi for all i ha pi μi for at least one i the rejection of ho would indicate a lack of fit of the simulations with respect to the true experimental means at a given level of significance e g α level a critical fα ν1 ν2 value can be used to test the acceptability of the null hypothesis in this study ν1 96 and ν2 72 as ni 4 and l 24 when there is both experimental and simulation uncertainties for an experiment with l experimental or measurement groups ni measurement replicates in each group and mi predictions in each group total sum of squared prediction errors tss may be written as 12 t s s i 1 l j 1 n i k 1 m i p i k o i j 2 which can be rearranged as 13 t s s i 1 l j 1 n i k 1 m i p i k p i p i o i o i o i j 2 i 1 l j 1 n i k 1 m i p i o i 2 i 1 l j 1 n i k 1 m i p i k p i 2 i 1 l j 1 n i k 1 m i o i o i j 2 i 1 l m i n i p i o i 2 i 1 l n i k 1 m i p i k p i 2 i 1 l m i j 1 n i o i o i j 2 l o f i t s s p s s e where lofit is the sum of squared errors between predicted and observed mean values due to lack of fit sse is the sum of squared error due to experimental uncertainty εik and ssp is the sum of squared error due to prediction uncertainty δij ssp and sse may be rewritten as wackerly et al 2008 14 s s p i 1 l n i k 1 m i p i k p i 2 i 1 l n i m i 1 d i 2 15 s s e i 1 l m i j 1 n i o i o i j 2 i 1 l m i n i 1 s i 2 the mean lofit mslofit and mean ssp sse mspe are defined as 16 m s l o f i t l o f i t i 1 l m i n i a n d m s p e i 1 l n i m i 1 d i 2 i 1 l n i m i 1 i 1 l m i n i 1 s i 2 i 1 l m i n i 1 therefore an f test statistic can be constructed as whitmore 1991 kersebaum et al 2008 17 f 2 m s l o f i t m s p e with degrees of freedom of ν1 i 1 l m i n i for the numerator and ν2 i 1 l n i m i 1 i 1 l m i n i 1 for the denominator to test whether model predictions λi correctly estimate the true mean of the observations for the ith experimental or measurement group the hypothesis would be ho λi μi for all i ha λi μi for at least one i the rejection of ho would indicate a lack of fit of the simulations with respect to the true experimental means at a given level of significance e g α level a critical fα ν1 ν2 value can be used to test the acceptability of the null hypothesis if the calculated f value does not exceed the critical f value the null hypothesis is accepted otherwise the null hypothesis is rejected indicating a lack of fit of the simulation results to the observed means since the critical value of fα ν1 ν2 increases with decreasing α level at the same degrees of freedoms ν1 384 and ν2 576 when mi ni 4 and l 24 in this study the null hypothesis may be rejected more easily at high α level 2 3 modified d index considering experimental and simulation uncertainty willmott 1981 introduced an index of agreement d index 18 d 1 i 1 l o i p i 2 i 1 l p i o a v g o i o a v g 2 to take into account the uncertainty of measured data used for calibration and evaluation harmel and smith 2007 introduced a correction factor cf to modify the numerator in the above equation 19 d 1 1 i 1 l c f m e a s i 0 5 o i p i 2 i 1 l p i o a v g o i o a v g 2 for a normal distribution of experimental uncertainty cf meas i ranges from 0 for oi pi to 0 5 when pi is 3 9 standard deviation away from oi harmel and smith 2007 when there are uncertainties in both experimental and simulation results a new cf function is introduced harmel et al 2010 and a d2 index is defined as 20 d 2 1 i 1 l c f m e a s p r e d i o i p i 2 i 1 l p i o a v g o i o a v g 2 where cf meas pred i 1 doi doi is the degree of overlap for distributions for each measured oi and predicted pi pair harmel et al 2010 and oavg is the mean of measured values 2 4 other statistics in addition to the modified f test and d index two other most commonly used simple statistics are relative root mean squared error rrmse and coefficient of determination r2 which are 21 r r m s e 1 l i 1 l p i o i 2 1 l i 1 l o i 22 r 2 i 1 l o i o a v g p i p a v g 2 i 1 l o i o a v g 2 i 1 l p i p a v g 2 where o a v g 1 l i 1 l o i and p a v g 1 l i 1 l p i among these statistics only the f test is a statistical test for significance the d index rrmse and r2 are only numerical values and used for relative comparison among various model runs their implication for model performance is relative and is subject to interpretation we selected the d index to compare with the modified f test because of the inclusion of experimental and simulation uncertainty as developed by harmel and smith 2007 and harmel et al 2010 we included rrmse to measure the distance between simulated and measured results and r2 to quantify the correlation between simulated and measured data both are basic statistics used by all scientific disciplines to quantify the uncertainty of either measured or simulated results we used the coefficients of variation cv also known as relative standard deviation standard deviation mean of a distribution which measures the dispersion of a distribution of a variable 3 results and discussion 3 1 optimized crop cultivar parameters calibrated crop cultivar parameters varied for each subset of data used for optimization table 2 among the six treatments across four years p1 thermal time from seedling emergence to end of juvenile phase had the least cv followed by phint thermal time required for a leaf tip to emerge and p5 thermal time from silking to physiological maturity p2 day length sensitivity coefficient had the highest cv g2 potential kernel number per plant and g3 potential kernel growth rate were closely related in yield formation as a result g2 and g3 also had high cv among the six irrigation treatments table 2 in addition we noticed smaller cv for wsf3 and highest cv for wsf1 when fitting all the treatments in one year similar trends in cv among years were observed with lowest cvs for p1 phint and p5 which defines crop phenology however there were no obvious trends in cv of fitted parameters among the three water stress functions table 3 except for p1 and p2 all the other parameters had reached the upper boundary for some optimization scenarios which suggests that the fitted parameters may not be reliable in these cases except for p2 the cv among treatments trt 1 to trt 6 table 2 was smaller than that among years year 2008 to year 2011 table 3 which suggests it may be better to fit a treatment across years than to fit all treatments in one year as far as parameter stability concerns regardless of water stress functions used fitting all the datasets derived the most reliable model parameters which suggests that it is best to use all data from one study for model calibration ma et al 2012b 3 2 statistics of prediction after calibration using one treatment across four years after calibrating with one treatment across four years biomass was generally better simulated than yield based on statistics given in tables 4 and 5 all r2s for prediction were greater than 0 83 for all treatments and all water stress functions tables 4 and 5 a majority of d index values were greater than 0 7 which would be satisfactory according to saseendran et al 2010 and ma et al 2011 rrmses range from 7 to 11 for biomass prediction and 7 to 18 for yield prediction although these statistics are all acceptable ma et al 2011 they cannot be used to statistically discriminate among the optimization options in addition they did not consider experimental uncertainty nor simulation uncertainty by considering experimental uncertainty and using the d1 index from harmel and smith 2007 we found an increase in the index values for all the treatments and water stress functions but could not statistically determine which treatment or which water stress functions provided the best biomass and yield prediction the d1 index showed the exact same trends for predicted biomass and yield as the d index to investigate the effects of simulation uncertainty on model performance we used cv of 0 075 as simulation uncertainty in this study which is close to the average cv of experimental uncertainty of yield and biomass this cv for simulation uncertainty was also reasonable according to ma et al 2016 who found that the maximum simulation uncertainty had a cv of 0 07 for both yield and biomass due to spatial variability in soil field capacity model input data in addition if we lumped all the simulation results together in this study from both water stress functions model structure uncertainty and calibration datasets parameterization uncertainty we obtained a cv of 0 065 for biomass and a cv of 0 107 for yield given all the three uncertainties in model simulation using a cv of 0 075 for our study was reasonable as a result if we considered both experimental uncertainty and simulation uncertainty having the same cv of 0 075 the d2 index of harmel et al 2010 provided even high index values but with the same trends in model performance among treatments and water stress functions as d index and d1 index except for no significant differences among water stress functions for biomass prediction thus no statistical power was added to differentiate the various optimization options therefore we evaluated the f test from ma et al 2012a f1 in tables 4 and 5 for wsf1 the f test showed significant differences between experimental and simulated biomass for trt 1 and trt 4 when only experimental uncertainties were considered f1 however these differences became insignificant when both experimental and simulation uncertainties were taken into account f2 in table 4 for yield prediction only trt 2 and trt 3 provided good prediction at significance level of 0 05 when experimental uncertainty was considered after considering simulation uncertainty trt 1 still did not provide significantly good prediction of yield p 0 01 table 5 thus using only full irrigation treatments for model calibration may not always be the best strategy comparisons should be made between water deficit treatments and well watered treatments boote 1999 to improve model responses to water deficits for wsf2 only trt 1 and trt 5 showed significantly satisfactory prediction of biomass with only experimental uncertainties considered p 0 05 table 4 but all treatments provided good prediction of biomass after considering both experimental and simulation uncertainties p 0 05 for yield regardless of experimental or simulation uncertainties trt 5 and trt 6 did not provide statistically satisfactory yield prediction p 0 05 table 5 for wsf3 trt 1 trt 2 and trt 6 did not provide good biomass prediction with only experimental uncertainty p 0 05 but showed good prediction when both experimental and simulation uncertainties were considered p 0 5 table 4 yield prediction showed the same trends as in the cases of wsf1 except for satisfactory prediction for trt 5 after considering simulation uncertainty thus the modified f tests were able to discern the goodness of model prediction among different optimization options and stress functions based on rrmse and d index saseendran et al 2014 concluded that wsf2 and wsf3 were superior to wsf1 based on simulated biomass yield and leaf area index after manually calibrating for trt 1 using wsf1 in our study we found that if both experimental and simulation uncertainties were taken into account there was no significant difference among the three water stress functions among the treatments used for model calibration trt 2 and trt 3 of wsf1 trt 1 of wsf2 and trt 3 and trt 4 of wsf3 provided statistically good prediction for both biomass and yield when only experimental uncertainties were considered based on the f tests p 0 1 tables 4 and 5 when both experimental and simulation uncertainties were considered only trt 1 of wsf1 trt 5 and trt 6 of wsf2 and trt 6 of wsf3 did not satisfy goodness of prediction for yield p 0 05 tables 4 and 5 when all the treatments were used for model calibration there was no difference in goodness of yield and biomass prediction among the three water stress functions statistically p 0 305 tables 4 and 5 to show that the f test was better than the traditional statistics we plotted the simulated and observed biomass predicted with cultivar parameters from trt 1 and trt 2 for wsf1 fig 1 as shown in table 4 trt 1 predicted biomass had a higher r2 than trt 2 predicted biomass although all other traditional statistics d index and rrmse were better for trt 2 prediction thus multiple traditional statistics should be used to evaluate model performance moriasi et al 2007 however the f test not only showed better performance of trt 2 than trt 1 but also provided a significance level test p 0 47 for trt 2 and p 0 003 for trt 1 as shown in fig 1 trt 2 predictions were closer to the 1 1 line than trt 1 predictions in addition the liner regression of trt 1 data points failed the constant variance test p 0 016 which suggested a non zero residual for the linear regression for yield trt 2 predicted higher r2 than trt 1 which was in agreement with the f test fig 1 table 5 fig 2 showed the same biomass data but plotted for treatment by year to visualize the differences between trt 1 and trt 2 predicted biomass trt 1 under predicted biomass for 2008 2009 and 2011 considerably whereas trt 2 under predicted biomass for 2008 but over predicted biomass in 2010 the under prediction of biomass by trt 1 was so severe that both experimental and simulation uncertainties had to be considered to make a statement that simulated and observed results were not significantly different for yield trt 1 under predicted yield in 2010 and 2011 compared to trt 2 fig 3 and the simulation results were significantly different from observed yield even if both experimental and simulation uncertainties were considered p 0 0028 table 5 3 3 statistics of prediction after calibration using all treatments in one year ma et al 2012b suggested calibrating a model with all treatments in one year so that the treatment effects can be taken into account in model optimization however in this study we found the opposite as shown in tables 6 and 7 all statistics were inferior to those obtained when calibrating the model with one treatment from four years similar to treatment options in model calibration it was not possible to discriminate among the calibration options year 2008 year 2009 year 2010 and year 2011 using the d index r2 or rrmse although a combination of these statistics might be helpful ma et al 2011 moriasi et al 2007 however we did see year 2011 provided statistically good prediction of both biomass and yield for wsf1 and wsf2 based on the f tests when experimental uncertainties were considered when both experimental and simulation uncertainties were taken into account year 2011 of wsf1 year 2010 and year 2011 of wsf2 and year 2008 and year 2011 of wsf3 provided statistically satisfactory goodness of model predictions tables 6 and 7 looking at the yield and biomass variations among the years we found that year 2011 had the most differences between highest and lowest treatments for both biomass 10235 22721 kg ha 1 and yield 3434 11809 kg ha 1 this may be the reason that calibrated parameters from year 2011 provided the best goodness of prediction because the calibrated cultivar parameters had compensated for the water stress endured by plants therefore when multiple treatments in one year were used for model calibration selecting the one showing the most treatment effects was warranted 3 4 statistics of prediction after calibration with two treatments in all years simultaneously to evaluate model robustness when two treatments from all four years were used for calibration simultaneously we selected trt 1 plus another treatment as shown in table 8 the obtained cultivar parameters had a lower cv compared to the previous two optimization options except for g2 under wsf3 all the parameters were within their respective specified ranges goodness of prediction of these parameters was much improved compared to those obtained from optimizing either one treatment across all years or all treatments in one year tables 9 and 10 the improvement seems to be more obvious for yield than for biomass for all statistics when only experimental uncertainty was considered there were no significant differences between predicted and observed biomass and yield regardless of water stress functions used p 0 05 except for biomass prediction under wsf1 with parameters from trt 1 trt 6 table 9 when both experimental and simulation uncertainties were taken into account all predictions were acceptable which suggests the three water stress functions and the five optimization options were equally effective therefore the conclusion on water stress functions saseendran et al 2014 may not be valid when more rigorous statistics such as the modified f test were used the results also showed that model calibration would be more stable and reliable if two or more treatments were used in model calibration fensterseifer et al 2017 see table 10 4 conclusion in this study a modified f test was developed to account for experimental and simulation uncertainty the experimental uncertainty was generally taken from measurement uncertainty in data used for calibration and evaluation simulation uncertainties might be from model structure model inputs as well as model parameters an irrigation study was used to exemplify these traditional and enhanced goodness of fit statistics and their application for objectively differentiating goodness of model prediction based on the results goodness of model prediction heavily depends on which sub datasets were used for model calibration and which outputs were compared yield or biomass when taking into account both experimental and simulation uncertainties biomass was well simulated regardless of treatments and water stress functions used for calibration in general biomass was better predicted than yield using one treatment across years for model calibration seemed to be superior to calibration using all treatments in one year especially when both experimental and simulation uncertainties were taken into account it is recommended to use two or more treatments for model calibration to obtain most reliable model parameters and better prediction we found that accounting for uncertainty in both experimental and simulation results increased the d index for all optimization options and water stress functions but such an increase could not be used to discern the goodness of model prediction the power of f test depends on the coefficient of variance cv of both experimental and simulation results if the cv of simulation uncertainty is smaller than 0 075 the modified f test will reject more simulation results and show more significant differences between simulated and observed results in addition if other model outputs e g leaf area index soil water content etc are used in the statistics the conclusion may change in the paper we analyzed statistical significance for each yield and biomass separately but an overall model performance may be developed by pooling all the outputs together in the statistics in conclusion due to its ability to form a statistical significance test the modified f test should be recommended for more rigorous model evaluation than the traditional simple statistics when experimental uncertainty and or simulation uncertainty are available by properly calibrating the model all the three water stress functions provided similar goodness of prediction for yield and biomass in this study where there were more treatment year data available using more data for calibration would increase model performance and predictability acknowledgement the authors wish to thank dr thomas trout retired usda ars employee for sharing the data at https data nal usda gov dataset usda ars colorado maize water productivity dataset 2008 2011 appendix a supplementary data the following is the supplementary data related to this article mmc1 mmc1 appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 03 011 
26400,experimental and simulation uncertainties have not been included in many of the statistics used in assessing agricultural model performance the objectives of this study were to develop an f test that can be used to evaluate model performance considering experimental and simulation uncertainties and identify the best datasets to use for model calibration using different water stress functions in a cropping system model data on irrigated maize in colorado usa and the root zone water quality model rzwqm were used as an example to demonstrate model calibration using the modified f test along with other commonly used statistics compared to the d index the f test provided a statistical test under a certain confidence level that better distinguished the goodness of model prediction for both biomass and yield while considering uncertainty to obtain robust model parameters we recommend using multiple treatments across multiple years for model calibration regardless of water stress functions used keywords uncertainty model calibration rzwqm f test goodness of fit maize 1 introduction very few statistics are satisfactory in determining the goodness of model fit in calibration and prediction and model users seem to tolerate a large simulation error in agriculture because of considerable experimental uncertainties in field research ritter and muñoz carpena 2013 the most commonly used statistical metrics for agricultural models are coefficient of determination r2 root mean squared error rmse relative error re nash sutcliffe model efficiency nse and index of agreement d index in addition to graphical visualization ma et al 2011 krause et al 2005 whitmore 1991 however these statistics do not consider either experimental and simulation uncertainties therefore it may be erroneous or subjective to use these statistics in judging the performance of a model using these statistics based on the criteria suggested by moriasi et al 2007 ritter and muñoz carpena 2013 used bootstrapping to create empirical probability distributions of rmse and nse so that significance of rmse and nse in relation to their respective threshold could be tested but they still did not consider experimental nor simulation uncertainties in addition the significance was referring to rmse and nse not to the experimental nor simulation data to account for experimental measurement uncertainties harmel and smith 2007 introduced a correction factor cf for calculating the differences between simulated and observed values in their statistics they found that model performance d index was improved after considering experimental uncertainty in a later study harmel et al 2010 further improved the d index by incorporating both experimental and simulation uncertainties harmel et al 2014 stated that it was critically important to include both measured data and simulation uncertainty in interpreting and communicating model results yen et al 2014 developed an integrated parameter estimation and uncertainty analysis tool ipeat that considered uncertainties due to input data model parameters model structure and calibration validation data using the correction factor cf of harmel and smith 2007 for the nash sutcliffe model efficiency they found that the calibrated model by considering three or more uncertainties was more robust than that without considering any uncertainty in model parameterization however in a later study yen et al 2016 found that including measurement uncertainty in calibration datasets would not significantly affect model calibration unless the uncertainty is greater than 50 however most statistics used in model comparisons are relative and there is no test of significance between model performances for example saseendran et al 2014 compared three water stress functions in the root zone water quality model rzwqm using the rmse and d index they found that the two modified water stress functions based on the nimah hanks water uptake or canopy heating effects provided better predictions of maize yield biomass leaf area index and soil water content using data from three locations in colorado than the original water uptake function in the ceres maize model in another study fensterseifer et al 2017 used relative rmse as a criterion to evaluate the number of datasets needed to calibrate the cropgro soybean model using 21 datasets from eight locations in southern brazil they found that two datasets from each location are needed for model calibration however both studies used trial and error in model calibration and the calibrated parameters may not be rigorous in addition to the subjectivity of the statistics used ma et al 2012a and kersebaum et al 2008 used a lack of fit an f test to calculate the significance of model predictions when experimental uncertainties existed based on the study of whitmore 1991 they found that the f test could be more rigorous than the ranges of indicators proposed by moriasi et al 2007 the objectives of this study were to 1 develop an f test for evaluating model performance by including both experimental and simulation uncertainties 2 compare model performance using various water stress functions in rzwqm and 3 identify the best datasets for model calibration a published dataset on irrigated maize in colorado usa and the root zone water quality model rzwqm were used as an example to demonstrate the modified f test along with three commonly used statistics the d index rmse and r2 since the modeling results were published in previous papers ma et al 2012b 2016 saseendran et al 2014 our emphasis was on quantifying the model performance by applying the newly modified f test rather than analyzing the causes of modeling deficiency from the underlying biophysical processes in the model 2 materials and methods 2 1 experimental dataset and model simulation the field experimental data were obtained from a study conducted from 2008 to 2011 near greeley colorado usa 40 45 n 104 64 w the soil is a sandy loam and is fairly uniform throughout the 200 cm soil profile six irrigation treatments micro irrigation with surface drip tubing adjacent to each row with four replicates were designed to meet a specified percentage of potential crop evapotranspiration et requirements allen et al 1998 2005 during the growing seasons 100 t1 85 t2 75 t3 70 t4 55 t5 and 40 t6 of potential crop et the amount of water for each treatment was estimated at a 3 6 day interval based on reference et demand crop coefficient rainfall and soil water deficit the t1 treatment was irrigated such that water availability irrigation plus precipitation plus stored soil water was adequate to meet crop water requirements as predicted by the reference evapotranspiration and crop coefficients fao 56 methodology allen et al 1998 the remaining treatments were irrigated to meet a certain percentage of water demand in t1 maize cv dekalb 52 59 was planted at an average rate of 81 000 seeds per hectare with 0 76 m row spacing in early may from 2008 to 2011 a detailed description of the experiment is provided by ma et al 2012b and the experimental dataset and detailed methodology can also be found at us department of agriculture national agricultural library ag data commons trout and bausch 2017 the root zone water quality model rzwqm is a comprehensive agricultural system model and has process level simulations of soil water soil temperature plant growth pesticide fate and soil c and n dynamics as influenced by various agricultural management practices ahuja et al 2000 the dssat 4 0 crop models e g ceres maize and ceres wheat models incorporated in rzwqm can be used to simulate crop growth water use and n uptake where rzwqm provides soil water soil temperature and nutrient information for dssat4 0 crop models ma et al 2006 in rzwqm there are three water stress functions users can select the first is from the dssat model that is defined as the ratio of potential root water uptake trwup to potential plant transpiration epo ritchie 1998 referred hereafter as default water stress function wsf1 saseendran et al 2014 1 w s f 1 t r w u p e p o the simplified close form equation of ritchie 1998 used to calculate the trwup in eq 1 is 2 trwup i 1 n k 1 e k 2 s w i l l i k 3 ln r l v i r l v i δ z i where rlv i is root length density in soil layer i cm cm 3 k1 0 00132 k2 45 0 if the drained lower limit ll of soil water permanent wilting point or soil water content at 1 5 mpa suction in the soil layer is greater than 0 30 cm3 cm 3 and k2 130 ll l if ll for the soil layer is less than 0 30 cm3 cm 3 k3 7 01 sw i and ll i are respectively volumetric soil water content and lower limit of plant available water in layer i cm cm 1 z i is soil depth of layer i cm the second water stress function wsf2 estimates trwup from the nimah hanks equation nimah and hanks 1973 the root water uptake part of the sink term s r z t cm hr 1 is computed using the nimah and hanks 1973 equation 3 t r w u p n h i 1 n s r z i t i 1 n h r r r z i h z i t s z i t r z i k i θ δ x δ z i δ z i where θ volumetric soil water content cm3 cm 3 t time hr zi soil depth cm assumed positive downward h soil water pressure head cm ki θ unsaturated hydraulic conductivity cm hr 1 a function of h and z hr an effective root water pressure head cm rr a root resistance term and the product rr zi accounts for gravity term and friction loss in hr assumed 1 05 s zi t the osmotic pressure head assumed 0 cm δx the distance from plant roots to where h zi t is measured assumed 1 cm δz soil depth increment cm r zi proportion of the total root activity in the depth increment δzi obtained from the plant growth model the total potential uptake trwup nh is calculated from summation of eq 3 with hr set equal to 1 5 mpa as the permanent wilting point which may be modified by users according to crop species thus 4 w s f 2 t r w u p n h e p o the third water stress function considers water stress due to heating of the canopy by the latent heat energy partitioned to potential soil evaporation but not used in soil evaporation when the surface soil water content is limiting therefore we explored including stress due to additional canopy heating in calculation of the water stress functions by changing their formulation as described below by including actual soil evaporation es for the day in the numerator and using total evapotranspiration et in the denominator 5 w s f 3 t r w u p n h e s e t with measured soil properties shown in table 1 an automated optimization and parameter estimation software pest doherty 2010 ma et al 2012a 2016 in rzwqm was used to calibrate crop cultivar parameters tables 2 and 3 the six irrigation treatments with four replicates carried out from 2008 to 2011 were used for selecting subsets of observed data to be used for model calibration to investigate the effect of different measured datasets on optimizing crop cultivar parameters and crop growth outputs rzwqm was first calibrated either using sub datasets from one treatment of multiple years trt 1 trt 2 trt 3 trt 4 trt 5 and trt 6 or from multiple treatments of one year year 2008 year 2009 year 2010 and year 2011 or all the treatments and the years the calibrated cultivar parameters were then used to simulate all the datasets and statistics were computed from all the datasets simulated with each set of cultivar parameters detailed information on model calibration using pest in rzwqm can be found in ma et al 2012a the three water stress functions have been modeled and compared with the same data above by saseendran et al 2014 and we are using it again here to re evaluate the performance of the wsfs based on the modified f test below different from saseendran et al 2014 the pest was implemented to derive crop parameters rather than by trial and error 2 2 modified f test with experimental and simulation uncertanity for convenience we first define the following symbols l number of experimental or measurement groups the groups may represent different treatments or different sampling dates ni number of measured replicates for the ith experimental or measurement group mi number of prediction replicates for the ith experimental or measurement group oij jth observation replicate for the ith measurement group oij μi εij and e oij μi pik kth predicted value replicate for the ith measurement group pik λi δik and e pik λi λi true mean of predictions for the ith experimental or measurement group μi true mean of observations for the ith experimental or measurement group p i 1 m i k 1 m i p i k mean of prediction for the ith experimental or measurement group based on a simulation model pi is independent of oij o i 1 n i j 1 n i o i j mean of the ith experimental or measurement group d i 2 1 m i 1 k 1 m i p i k p i 2 prediction variance of ith experimental or measurement group s i 2 1 n i 1 j 1 n i o i j o i 2 sample variance of ith experimental or measurement group when there is no simulation uncertainty for an experiment with n experimental or measurement groups and ki replicates in each group total sum of squared prediction errors tss may be written as ma et al 2012a 6 t s s i 1 l j 1 n i p i o i j 2 which can be rearranged as 7 t s s i 1 l j 1 n i p i o i o i o i j 2 i 1 l j 1 n i p i o i 2 i 1 l j 1 n i o i j o i 2 i 1 l n i p i o i 2 i 1 l j 1 n i o i j o i 2 l o f i t s s e where lofit is the sum of squared errors between predicted and observed mean values due to lack of fit and sse is the sum of squared error due to experimental error εij sse may be rewritten as wackerly et al 2008 8 l o f i t i 1 l n i p i o i 2 and 9 s s e i 1 l j 1 n i o i j o i 2 i 1 l n i 1 s i 2 the mean lofit mslofit and mean sse mse are defined as 10 m s l o f i t l o f i t i 1 l n i a n d m s e s s e i 1 l n i 1 i 1 l n i 1 s i 2 i 1 l n i 1 therefore an f test statistic can be constructed as whitmore 1991 kersebaum et al 2008 11 f 1 m s l o f i t m s e with degrees of freedom of ν1 i 1 l n i for the numerator and ν2 i 1 l n i 1 for the denominator to test whether model predictions pi correctly estimate the true mean of the observations for the ith experimental or measurement group the hypothesis would be ho pi μi for all i ha pi μi for at least one i the rejection of ho would indicate a lack of fit of the simulations with respect to the true experimental means at a given level of significance e g α level a critical fα ν1 ν2 value can be used to test the acceptability of the null hypothesis in this study ν1 96 and ν2 72 as ni 4 and l 24 when there is both experimental and simulation uncertainties for an experiment with l experimental or measurement groups ni measurement replicates in each group and mi predictions in each group total sum of squared prediction errors tss may be written as 12 t s s i 1 l j 1 n i k 1 m i p i k o i j 2 which can be rearranged as 13 t s s i 1 l j 1 n i k 1 m i p i k p i p i o i o i o i j 2 i 1 l j 1 n i k 1 m i p i o i 2 i 1 l j 1 n i k 1 m i p i k p i 2 i 1 l j 1 n i k 1 m i o i o i j 2 i 1 l m i n i p i o i 2 i 1 l n i k 1 m i p i k p i 2 i 1 l m i j 1 n i o i o i j 2 l o f i t s s p s s e where lofit is the sum of squared errors between predicted and observed mean values due to lack of fit sse is the sum of squared error due to experimental uncertainty εik and ssp is the sum of squared error due to prediction uncertainty δij ssp and sse may be rewritten as wackerly et al 2008 14 s s p i 1 l n i k 1 m i p i k p i 2 i 1 l n i m i 1 d i 2 15 s s e i 1 l m i j 1 n i o i o i j 2 i 1 l m i n i 1 s i 2 the mean lofit mslofit and mean ssp sse mspe are defined as 16 m s l o f i t l o f i t i 1 l m i n i a n d m s p e i 1 l n i m i 1 d i 2 i 1 l n i m i 1 i 1 l m i n i 1 s i 2 i 1 l m i n i 1 therefore an f test statistic can be constructed as whitmore 1991 kersebaum et al 2008 17 f 2 m s l o f i t m s p e with degrees of freedom of ν1 i 1 l m i n i for the numerator and ν2 i 1 l n i m i 1 i 1 l m i n i 1 for the denominator to test whether model predictions λi correctly estimate the true mean of the observations for the ith experimental or measurement group the hypothesis would be ho λi μi for all i ha λi μi for at least one i the rejection of ho would indicate a lack of fit of the simulations with respect to the true experimental means at a given level of significance e g α level a critical fα ν1 ν2 value can be used to test the acceptability of the null hypothesis if the calculated f value does not exceed the critical f value the null hypothesis is accepted otherwise the null hypothesis is rejected indicating a lack of fit of the simulation results to the observed means since the critical value of fα ν1 ν2 increases with decreasing α level at the same degrees of freedoms ν1 384 and ν2 576 when mi ni 4 and l 24 in this study the null hypothesis may be rejected more easily at high α level 2 3 modified d index considering experimental and simulation uncertainty willmott 1981 introduced an index of agreement d index 18 d 1 i 1 l o i p i 2 i 1 l p i o a v g o i o a v g 2 to take into account the uncertainty of measured data used for calibration and evaluation harmel and smith 2007 introduced a correction factor cf to modify the numerator in the above equation 19 d 1 1 i 1 l c f m e a s i 0 5 o i p i 2 i 1 l p i o a v g o i o a v g 2 for a normal distribution of experimental uncertainty cf meas i ranges from 0 for oi pi to 0 5 when pi is 3 9 standard deviation away from oi harmel and smith 2007 when there are uncertainties in both experimental and simulation results a new cf function is introduced harmel et al 2010 and a d2 index is defined as 20 d 2 1 i 1 l c f m e a s p r e d i o i p i 2 i 1 l p i o a v g o i o a v g 2 where cf meas pred i 1 doi doi is the degree of overlap for distributions for each measured oi and predicted pi pair harmel et al 2010 and oavg is the mean of measured values 2 4 other statistics in addition to the modified f test and d index two other most commonly used simple statistics are relative root mean squared error rrmse and coefficient of determination r2 which are 21 r r m s e 1 l i 1 l p i o i 2 1 l i 1 l o i 22 r 2 i 1 l o i o a v g p i p a v g 2 i 1 l o i o a v g 2 i 1 l p i p a v g 2 where o a v g 1 l i 1 l o i and p a v g 1 l i 1 l p i among these statistics only the f test is a statistical test for significance the d index rrmse and r2 are only numerical values and used for relative comparison among various model runs their implication for model performance is relative and is subject to interpretation we selected the d index to compare with the modified f test because of the inclusion of experimental and simulation uncertainty as developed by harmel and smith 2007 and harmel et al 2010 we included rrmse to measure the distance between simulated and measured results and r2 to quantify the correlation between simulated and measured data both are basic statistics used by all scientific disciplines to quantify the uncertainty of either measured or simulated results we used the coefficients of variation cv also known as relative standard deviation standard deviation mean of a distribution which measures the dispersion of a distribution of a variable 3 results and discussion 3 1 optimized crop cultivar parameters calibrated crop cultivar parameters varied for each subset of data used for optimization table 2 among the six treatments across four years p1 thermal time from seedling emergence to end of juvenile phase had the least cv followed by phint thermal time required for a leaf tip to emerge and p5 thermal time from silking to physiological maturity p2 day length sensitivity coefficient had the highest cv g2 potential kernel number per plant and g3 potential kernel growth rate were closely related in yield formation as a result g2 and g3 also had high cv among the six irrigation treatments table 2 in addition we noticed smaller cv for wsf3 and highest cv for wsf1 when fitting all the treatments in one year similar trends in cv among years were observed with lowest cvs for p1 phint and p5 which defines crop phenology however there were no obvious trends in cv of fitted parameters among the three water stress functions table 3 except for p1 and p2 all the other parameters had reached the upper boundary for some optimization scenarios which suggests that the fitted parameters may not be reliable in these cases except for p2 the cv among treatments trt 1 to trt 6 table 2 was smaller than that among years year 2008 to year 2011 table 3 which suggests it may be better to fit a treatment across years than to fit all treatments in one year as far as parameter stability concerns regardless of water stress functions used fitting all the datasets derived the most reliable model parameters which suggests that it is best to use all data from one study for model calibration ma et al 2012b 3 2 statistics of prediction after calibration using one treatment across four years after calibrating with one treatment across four years biomass was generally better simulated than yield based on statistics given in tables 4 and 5 all r2s for prediction were greater than 0 83 for all treatments and all water stress functions tables 4 and 5 a majority of d index values were greater than 0 7 which would be satisfactory according to saseendran et al 2010 and ma et al 2011 rrmses range from 7 to 11 for biomass prediction and 7 to 18 for yield prediction although these statistics are all acceptable ma et al 2011 they cannot be used to statistically discriminate among the optimization options in addition they did not consider experimental uncertainty nor simulation uncertainty by considering experimental uncertainty and using the d1 index from harmel and smith 2007 we found an increase in the index values for all the treatments and water stress functions but could not statistically determine which treatment or which water stress functions provided the best biomass and yield prediction the d1 index showed the exact same trends for predicted biomass and yield as the d index to investigate the effects of simulation uncertainty on model performance we used cv of 0 075 as simulation uncertainty in this study which is close to the average cv of experimental uncertainty of yield and biomass this cv for simulation uncertainty was also reasonable according to ma et al 2016 who found that the maximum simulation uncertainty had a cv of 0 07 for both yield and biomass due to spatial variability in soil field capacity model input data in addition if we lumped all the simulation results together in this study from both water stress functions model structure uncertainty and calibration datasets parameterization uncertainty we obtained a cv of 0 065 for biomass and a cv of 0 107 for yield given all the three uncertainties in model simulation using a cv of 0 075 for our study was reasonable as a result if we considered both experimental uncertainty and simulation uncertainty having the same cv of 0 075 the d2 index of harmel et al 2010 provided even high index values but with the same trends in model performance among treatments and water stress functions as d index and d1 index except for no significant differences among water stress functions for biomass prediction thus no statistical power was added to differentiate the various optimization options therefore we evaluated the f test from ma et al 2012a f1 in tables 4 and 5 for wsf1 the f test showed significant differences between experimental and simulated biomass for trt 1 and trt 4 when only experimental uncertainties were considered f1 however these differences became insignificant when both experimental and simulation uncertainties were taken into account f2 in table 4 for yield prediction only trt 2 and trt 3 provided good prediction at significance level of 0 05 when experimental uncertainty was considered after considering simulation uncertainty trt 1 still did not provide significantly good prediction of yield p 0 01 table 5 thus using only full irrigation treatments for model calibration may not always be the best strategy comparisons should be made between water deficit treatments and well watered treatments boote 1999 to improve model responses to water deficits for wsf2 only trt 1 and trt 5 showed significantly satisfactory prediction of biomass with only experimental uncertainties considered p 0 05 table 4 but all treatments provided good prediction of biomass after considering both experimental and simulation uncertainties p 0 05 for yield regardless of experimental or simulation uncertainties trt 5 and trt 6 did not provide statistically satisfactory yield prediction p 0 05 table 5 for wsf3 trt 1 trt 2 and trt 6 did not provide good biomass prediction with only experimental uncertainty p 0 05 but showed good prediction when both experimental and simulation uncertainties were considered p 0 5 table 4 yield prediction showed the same trends as in the cases of wsf1 except for satisfactory prediction for trt 5 after considering simulation uncertainty thus the modified f tests were able to discern the goodness of model prediction among different optimization options and stress functions based on rrmse and d index saseendran et al 2014 concluded that wsf2 and wsf3 were superior to wsf1 based on simulated biomass yield and leaf area index after manually calibrating for trt 1 using wsf1 in our study we found that if both experimental and simulation uncertainties were taken into account there was no significant difference among the three water stress functions among the treatments used for model calibration trt 2 and trt 3 of wsf1 trt 1 of wsf2 and trt 3 and trt 4 of wsf3 provided statistically good prediction for both biomass and yield when only experimental uncertainties were considered based on the f tests p 0 1 tables 4 and 5 when both experimental and simulation uncertainties were considered only trt 1 of wsf1 trt 5 and trt 6 of wsf2 and trt 6 of wsf3 did not satisfy goodness of prediction for yield p 0 05 tables 4 and 5 when all the treatments were used for model calibration there was no difference in goodness of yield and biomass prediction among the three water stress functions statistically p 0 305 tables 4 and 5 to show that the f test was better than the traditional statistics we plotted the simulated and observed biomass predicted with cultivar parameters from trt 1 and trt 2 for wsf1 fig 1 as shown in table 4 trt 1 predicted biomass had a higher r2 than trt 2 predicted biomass although all other traditional statistics d index and rrmse were better for trt 2 prediction thus multiple traditional statistics should be used to evaluate model performance moriasi et al 2007 however the f test not only showed better performance of trt 2 than trt 1 but also provided a significance level test p 0 47 for trt 2 and p 0 003 for trt 1 as shown in fig 1 trt 2 predictions were closer to the 1 1 line than trt 1 predictions in addition the liner regression of trt 1 data points failed the constant variance test p 0 016 which suggested a non zero residual for the linear regression for yield trt 2 predicted higher r2 than trt 1 which was in agreement with the f test fig 1 table 5 fig 2 showed the same biomass data but plotted for treatment by year to visualize the differences between trt 1 and trt 2 predicted biomass trt 1 under predicted biomass for 2008 2009 and 2011 considerably whereas trt 2 under predicted biomass for 2008 but over predicted biomass in 2010 the under prediction of biomass by trt 1 was so severe that both experimental and simulation uncertainties had to be considered to make a statement that simulated and observed results were not significantly different for yield trt 1 under predicted yield in 2010 and 2011 compared to trt 2 fig 3 and the simulation results were significantly different from observed yield even if both experimental and simulation uncertainties were considered p 0 0028 table 5 3 3 statistics of prediction after calibration using all treatments in one year ma et al 2012b suggested calibrating a model with all treatments in one year so that the treatment effects can be taken into account in model optimization however in this study we found the opposite as shown in tables 6 and 7 all statistics were inferior to those obtained when calibrating the model with one treatment from four years similar to treatment options in model calibration it was not possible to discriminate among the calibration options year 2008 year 2009 year 2010 and year 2011 using the d index r2 or rrmse although a combination of these statistics might be helpful ma et al 2011 moriasi et al 2007 however we did see year 2011 provided statistically good prediction of both biomass and yield for wsf1 and wsf2 based on the f tests when experimental uncertainties were considered when both experimental and simulation uncertainties were taken into account year 2011 of wsf1 year 2010 and year 2011 of wsf2 and year 2008 and year 2011 of wsf3 provided statistically satisfactory goodness of model predictions tables 6 and 7 looking at the yield and biomass variations among the years we found that year 2011 had the most differences between highest and lowest treatments for both biomass 10235 22721 kg ha 1 and yield 3434 11809 kg ha 1 this may be the reason that calibrated parameters from year 2011 provided the best goodness of prediction because the calibrated cultivar parameters had compensated for the water stress endured by plants therefore when multiple treatments in one year were used for model calibration selecting the one showing the most treatment effects was warranted 3 4 statistics of prediction after calibration with two treatments in all years simultaneously to evaluate model robustness when two treatments from all four years were used for calibration simultaneously we selected trt 1 plus another treatment as shown in table 8 the obtained cultivar parameters had a lower cv compared to the previous two optimization options except for g2 under wsf3 all the parameters were within their respective specified ranges goodness of prediction of these parameters was much improved compared to those obtained from optimizing either one treatment across all years or all treatments in one year tables 9 and 10 the improvement seems to be more obvious for yield than for biomass for all statistics when only experimental uncertainty was considered there were no significant differences between predicted and observed biomass and yield regardless of water stress functions used p 0 05 except for biomass prediction under wsf1 with parameters from trt 1 trt 6 table 9 when both experimental and simulation uncertainties were taken into account all predictions were acceptable which suggests the three water stress functions and the five optimization options were equally effective therefore the conclusion on water stress functions saseendran et al 2014 may not be valid when more rigorous statistics such as the modified f test were used the results also showed that model calibration would be more stable and reliable if two or more treatments were used in model calibration fensterseifer et al 2017 see table 10 4 conclusion in this study a modified f test was developed to account for experimental and simulation uncertainty the experimental uncertainty was generally taken from measurement uncertainty in data used for calibration and evaluation simulation uncertainties might be from model structure model inputs as well as model parameters an irrigation study was used to exemplify these traditional and enhanced goodness of fit statistics and their application for objectively differentiating goodness of model prediction based on the results goodness of model prediction heavily depends on which sub datasets were used for model calibration and which outputs were compared yield or biomass when taking into account both experimental and simulation uncertainties biomass was well simulated regardless of treatments and water stress functions used for calibration in general biomass was better predicted than yield using one treatment across years for model calibration seemed to be superior to calibration using all treatments in one year especially when both experimental and simulation uncertainties were taken into account it is recommended to use two or more treatments for model calibration to obtain most reliable model parameters and better prediction we found that accounting for uncertainty in both experimental and simulation results increased the d index for all optimization options and water stress functions but such an increase could not be used to discern the goodness of model prediction the power of f test depends on the coefficient of variance cv of both experimental and simulation results if the cv of simulation uncertainty is smaller than 0 075 the modified f test will reject more simulation results and show more significant differences between simulated and observed results in addition if other model outputs e g leaf area index soil water content etc are used in the statistics the conclusion may change in the paper we analyzed statistical significance for each yield and biomass separately but an overall model performance may be developed by pooling all the outputs together in the statistics in conclusion due to its ability to form a statistical significance test the modified f test should be recommended for more rigorous model evaluation than the traditional simple statistics when experimental uncertainty and or simulation uncertainty are available by properly calibrating the model all the three water stress functions provided similar goodness of prediction for yield and biomass in this study where there were more treatment year data available using more data for calibration would increase model performance and predictability acknowledgement the authors wish to thank dr thomas trout retired usda ars employee for sharing the data at https data nal usda gov dataset usda ars colorado maize water productivity dataset 2008 2011 appendix a supplementary data the following is the supplementary data related to this article mmc1 mmc1 appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 03 011 
26401,despite existence of many developed approaches for identifying optimal time of water meters wms replacement less attention has been paid to the impact of wm failure risk on utilities revenues and the proper time of replacement here the asset management am approach is introduced as a holistic managing framework optimizing life cycle costs lcc especially incorporating wm failure risk in asset replacement decisions the proposed am framework is based on four core steps the application of the proposed framework for a real case study has shown confidence in finding the economical time of wm replacement it was further shown that the risk costs associated with wm failure have higher impacts on optimal time of wm replacement than the revenue lost due to its inaccuracy the sensitivity analyses of input data values show that water price initial investment and accuracy degradation rate have the highest impacts on lccs amongst other parameters keywords asset management failure risk optimal time of replacement sensitivity analyses water meter data availability data used in this study are available in persian in spreadsheet format and may be obtained from the authors on request list of acronyms and abbreviations wm is the water meter am is the asset management lcc is the life cycle cost cri is the composite replacement indicator nrw is the non revenue water oa is the operational age twm is the total water measurement aawm is the annual average water measurement nt is the number of available consumption data br is the annual breakage rate p is the probability of the failure t is the time step hci is the hydraulic criticality index r is the risk measurement of failure npv is the net present value wp is the water price ε is the meter error accuracy degradation n is the number of year r is the real discount rate c in is the capital cost c inst is the installation cost c admin is the administrative cost c lab is the labor cost c sv is the salvage value s is the inflation rate r is the discount rate t is the meter reading frequency n is the number of zero reading of meter d is the conscious delay time of meter replacement 1 introduction international experience has shown that water as the social and economic commodity served by utilities must be better appreciated and compensated through customers water bills barraqué 2011 biswas and tortajada 2010 calculations of these bills are based on two important factors 1 water tariffs allocated to the amount of water consumptions 2 the amount of water measured by the water meters wms since the utility policy makers usually revisit the first factor annually the second factor can play a more effective role in loosing revenues through issuing inaccurate bills wms are the only practical tools for the utilities to measure their revenues and from this perspective they are the most important assets of water distribution networks around the world despite progressive developments in the metering industry and water measurement most of the existing wms in many water distribution networks have been inherited from the past decades water measurement accuracy of these meters is degraded over the years and most of them reach to the end of their useful life while still operating inefficiently this accuracy degradation of wms during their operational lifespan can pose severe challenges for the utilities more often than not in the form of increase in non revenue water supply to help utilities to face the above mentioned challenges ensuring the accuracy and precision of the measurement the developed official standards and regulations present some recommendations about time of testing and replacing of the wms for example based on american water work association the wm size of 5 8 1 1 4 4 and larger should be tested every 10 5 and 1 year respectively american water works association 1999 since the accuracy degradation of wms is dependent on different factors under varying operational conditions these proposed recommendations have not been fully constructive consequently many researchers have tried to go beyond these suggestions therefore many different guidelines or models for predicting wms timely replacement have been proposed the majority of these models are sensitive to their inherent assumptions complexity involved uncertainties and influencing factors such as condition of wms installation and operation age water quality pressure head of water distribution network and thus finding a holistic approach for managing wms services with fewer challenges is very much encouraged for the sake of simplicity many utilities around the world have used simple criteria to judge the time of wms replacement for example some of the utilities use cumulative registered volume passed through meters and some others use the age of wms from its installation date as the criteria for replacement davis 2005 thornton et al 2008 in this type of decision making some thresholds for the criteria like 10 years of operation or 5000 m3 as the total cumulative volume of water measured by one wm are required to be established the idea of wms replacement based on these criteria has been presented through finding the relationship between wms accuracy and their age or the cumulative water registered by any meter most of these relationships were presented in a linear form arregui et al 2006 davis 2005 mutikanga 2012 noss et al 1987 in 1987 noss et al stated that wm accuracy must be measured in three different ranges of flow including high medium intermediate and low flow his results showed that the less the available flow rate is the less the wms accuracy will be moreover it was found that the accuracy degradation rate in low flow versus wm age is more severe than high flow furthermore the optimal testing period of wms is most sensitive to the rate of deterioration of meter accuracy with its age noss et al 1987 some of noss s results were confirmed later by allender 1996 later fontanazza et al 2012 stated that knowing wms age and cumulative water registered are not sufficient criteria for replacement decisions therefore they presented a new criterion called composite replacement indicator cri based on oecd recommendations 2008 it was found that the use of this criterion may result in better replacement decisions another set of research with different points of view has focused on the impact of considering the economic issues such as water and wms prices in wms replacement time noss et al 1987 and yee 1999 can be cited as the pioneer researchers in this field in this viewpoint the right time of replacement is detected when the annual average costs of replacement become minimum in later studies it was found that the proper time of replacement not only depends on the rate of accuracy degradation and economic issues but also strongly sensitive to the opportunity value of time such as discount rate and consequently minimizing cost during entire life of the wms arregui et al 2010 mutikanga 2012 in these life cycle cost lcc analyses several costs of installations replacement policy water lost testing and maintenance salvage water and wm price along with several rates of discount inflation interest and so on were considered these efforts are sometimes presented in the forms of handy tools such as i wamrm in order to determine the optimum time of wms replacement mutikanga 2012 woltman in order to assess weighted error of a meter arregui et al 2010 and econanal in order to define optimum testing periods of wms noss et al 1987 despite all the advantages of these developed tools some points of concern are evident requiring rich databases such as meters accuracy and their degradation rates over the years customer water demand patterns and flows wms accuracy curves limitation of meter types mutikanga 2012 posing difficulties in real practices arregui et al 2010 and performing calculations in the black boxes involving many uncertainties as a result applications of these tools are faced with several fundamental questions comprehensive review of the literature about identifying wms and finding their optimal time of replacement shows that what has been rarely discussed is the costs that water utilities may accept in order to burden the risk of wms failure during their lccs when the meter fails the utility may lose some its revenue due to the unrecorded customer water consumption therefore wm failure can impose risks on the utility s revenue it therefore becomes necessary to investigate whether this risk cost may be considered as one of the effective elements of the wm lcc and its corresponding optimal time of replacement to respond to this necessity a holistic management framework is proposed here as the main contribution of this work which can take economic risk of wm failure into account while maintaining the required level of meter services with the lowest lcc an asset management am approach switching the required annual assets rehabilitation as part of the operation and maintenance program can ideally set the appropriate management framework for making decisions on timely replacement of wms extensive use of this management approach in many disciplines and applied sciences such as business and financial planning transmission and distribution of energy and power smart telecommunication management of infrastructures such as transportation and water distribution short and long term planning and risk based decision making has posed am as an effective integration of engineering and management approaches interestingly the majority of these fields of work are somehow related to the subject of optimizing the replacement of meters and further addressing the increasing interests in smart metering and monitoring in addition to other existing wm optimal replacement options am can help in various ways identify where the utilities have any assets of any given type anticipate risky aging meters by location identify potentials for risk cost reduction assess replacement of which meter is profitable minimize life cost of each meter with regards to the risk cost and identify priority of each meter for optimal replacement the proposed am approach is presented based on a four step framework comprising identifying current state of assets identifying critical assets and their corresponding risks minimizing lcc of each asset and presenting long term funding plans the efficiency of the proposed framework was examined on a water network with high rate of customer metering inaccuracies and missed data as a case study to prove efficiency of the proposed framework for handling many uncertainties involved in meter replacement decision an extensive sensitivity analysis was performed 2 asset management providing appropriate water services of water distribution network for consumers is an everlasting duty for utilities nowadays many utilities decision makers attempt to consider ageing infrastructures as the valuable assets that must be managed and sustained during their long life any element of an infrastructure system that has potential value for utilities may be regarded as an asset some of the most well known assets in water distribution network are pipes pumps valves tanks and flow meters each of these assets has its exclusive management characteristics such as monetary and operational values useful life period failure risk and varying cost and investment aspects despite conventional management practices based on reactive approaches asset management am was first introduced in the 80s in new zealand van heck 2008 focusing mainly on proactive actions with regards to appropriate assets characteristics rapid development of this concept throughout the world has developed many views on what is considered as an asset management the common part of these views is their main aim based on maintaining the desired level of services at the lowest life cycle cost halfawy 2004 usepa 2009 different factors for promoting am such as ageing infrastructure public requests for high level services rigorous regulations population growth risk management limited resources and the development of new technologies have led many countries to develop some frameworks for better implementation of am a brief comparison between some proposed am frameworks with emphasis on water and wastewater utilities are presented in van heck 2008 the bases of these proposed frameworks are often presented in core steps similar to those presented in the current work where they usually start with identifying existing assets and their current state and what is desired followed by analyzing data assigning priorities and making decisions and ending with presenting the best required actions for am including future needs and long term funding plans literature on implementing am in water distribution networks may be chronologically divided into five categories condition based asset management clair and sinha 2012 lansey et al 1992 roshani and filion 2013 judging based on physical and operational conditions of assets performance based asset management hall et al 2004 judging based on whether the assets can cope well with their corresponding duties or not if not what interventions should be made and how much they are needed service based or service level driven asset management heather and bridgeman 2007 judging based on whether the corporation of assets can provide appropriate service levels or not risk based asset management christodoulou et al 2009 parton et al 2011 judging based on how the life cycle costs of assets can be minimized while these assets have their acceptable minimum levels of risks namely economic environmental operational and so on sustainable based asset management cardoso et al 2012 marlow 2010 this kind of am can provide a higher level of management in which sustainable criteria can be implemented externalities can be considered and acceptable risk levels in all dimensions can be achieved 3 problem description existence of many standards global and local regulations as well as numerous studies about wms confirms the undisputable role of these assets in water consumption management and reducing the non revenue water nrw previous meter recordings in the aradan city iran indicated a water consumption figure of 915 cubic meters per month replacing all customer meters of 10 years of age and older indicated that the actual consumption rate was 3182 cubic meters per month showing an under registration of some 71 2 this replacement plan has resulted in an increase of utility revenues of 441 shahmansoorian et al 2016 based on estimations proper replacement of wms in iran can lead to a significant increase of water utility revenues annually around two million us dollars governmental legislation to improve water distribution networks performances in various parts of iran faced with water scarcity has led this study to concentrate on one of the most nrw troubled cities of central iran in the isfahan province the existing water distribution network of the city aged more than 30 years old with an area of 36 km2 serving a population of around 20000 people consists of three municipal districts fig 1 based on local studies replacement of broken and aged wms is one of the most effective activities to reduce the amount of non revenue water significantly it is estimated that around 15 of the inlet water volume to the study network is lost due to the errors of customer s wms the amount of losses is estimated around 358000 m3 per year which is equivalent to the loss of 21175 revenue per year table 1 shows different sizes of wms and their counts in the pilot area furthermore the consumption data recorded by the wms in the study area may be classified as low resolution data cominola et al 2015 since at best these data were recorded every two months the above mentioned problems have led this research to develop an asset management framework in which the optimum time of wm replacement and management with their priority for intervention can be identified in addition to the existing problems in the study network limitations associated with insufficient reliable data have posed extra concern with the precision of estimation of life cycles thus life cycle estimation methodology has been particularly addressed in the proposed am framework 4 methodology in order to support utilities decisions on managing their meters in short and long term and determining the optimum time of their replacement a four steps am framework is proposed in designing the basis of the proposed am framework the desired drivers incentives expectations and type of assets are the key factors the general steps for developing the am framework proposed herein are shown in fig 2 description of each step in the framework is given as follow 4 1 identifying current state of the assets in this step a reliable dataset is needed to make the right decisions required in the next steps this would comprise gathering and completing available wms data assessing their present values assessing the operational conditions of wms detecting unavailable data via field survey and library studies due to the lack of data on precise installation dates analyzed errors and accuracy degradation levels of wms estimating the exact age of wms is not possible therefore a surrogate measurement index named operational age oa is introduced here to assess the estimated age of each wm and average age of all wms in the study area oa of any meter is equivalent to the ratio of total water measured metered by a meter to the average annual metered water consumption for the meter equation 1 1 o a i t w m i a a w m i where oa is the operational age of a wm twm is the total water measured by a specific wm over its life installation date up to now aawm is the average annual flow of water measured by a meter m3 year based on the condition of each meter and its corresponding available data aawm is estimated for each meter in two different ways 1 for any working meter with sufficient recorded data the aawm is considered equal to the average annual water consumption rate this value can be derived from the average of all available annual consumption data over the few past years equation 2 2 for the meters with missed recorded data unrecorded or unreliable consumptions a consumption equal to that of customers with equivalent characteristics can be assigned as a surrogate for aawm 2 a a w m i t 1 n t a a w m i t n t where nt is the number of available annual consumption data aawm i t is the amount of water measured by meter i in year t 4 2 identifying critical wm assets and their failure risks every asset like wms may fail examining the probability and the consequence of a meter failure is essential for adequate risk assessment as the failure of any wm is a discrete event more often than not occurring independently and continuously in time the poisson model equation 3 is capable dhillon 1983 zhuang et al 2012 to allocate the failure probability of the wm the efficiency of using this model for wm failure has previously been proven by lund 1988 and mutikanga et al 2011 3 p i 1 exp b r i j t i where br is the annual breakage rate of meter i with type of j and p is the probability of the meter i failure in time t year in this equation t can be regarded as the surrogate representation of each meter oa lund 1988 and mutikanga et al 2011 assumed constant values of 0 01 and 0 066 as the breakage rate of their selected wm type over the wm s lifetime respectively in terms of failure consequences identifying the failure of those more vulnerable can lead to better management of the assets based on this reasonable principle that failure consequences of wms with higher rate of annual water consumption is more the risk of meter failure will become more hydraulic criticality index hci is introduced here as the wm failure consequences which are equivalent to the mean value of aawm for all the wms of the same type the higher amounts of hci indicate the higher amounts of loss of water under failure conditions therefore the risk measurement of each unbroken working meter failure can be calculated by 4 r i p i h c i i the meters with the highest amount of risk are called critical assets here consequently these meters have higher priority for regular intervention test or replacement based on their more probable potential impact on losing utility s revenues therefore paying special attention to decision making on the optimal replacement time of risky assets is necessary it is worth noting that since the failed broken meters usually have an error of 100 it is presumed that they would pose the highest risk for the water utility consequently these meters must be given the higher priority for replacement and there is no need to consider these assets in the calculation of the hci nor in the assets failure risk estimation 4 3 minimizing life cycle costs the life cycle cost lcc of an asset is the cost spent in different forms such as initial capital operation maintenance repair rehabilitation disposal and replacement costs different methods such as net present value npv method have been introduced in the literature for analyzing lcc of many assets in this method the best time for any intervention like wms testing replacement is usually selected in a manner that lcc becomes minimum for every asset in terms of wm replacement traditionally the npv models have been established based on many input data with high uncertainties and without considering the risk costs of hindering the replacement time of wms it is believed here that the utility as the main responsible body for any consequences of wm replacement not only should maximize their revenue but also must reduce the maximum potential of their economic risk therefore the npv calculation formula is modified in order to consider the cost associated with the risk of postponing wm replacement this risk cost can be aggravated by the impact of utility policies which may increase utility lost revenue in a period of unsatisfactory performance of a failed meter for example existence of any zero reading before the water utility do anything with the failed meter or delay of the utility in replacing the failed meter can expose more costs to the utility which may be termed as the regret cost the new formulated risk cost based on npv is expressed based on the summation of four terms equation 5 the first one assesses the cost that must be invested for the meter replacement investment cost the second one is the lost revenue due to accuracy degradation of the wm lost revenue cost the third one is the cost of working wm failure risk and the last term is the regret cost when these costs are estimated for each time period of wm replacement the time with the lowest amount of cost is selected as the economic optimal time for meter replacement 5 n p v i n i n v e s t m e n t c o s t i n l o s t r e v e n u e c o s t i n r i s k c o s t i n r e g r e t c o s t i n 6 i n v e s t m e n t c o s t i n c i n c i n s t c a d min c l a b c s v i 1 r n 1 r n 1 7 l o s t r e v e n u e c o s t i n n 1 n t w p n h c i i n ε i n 1 r n 1 1 r n 1 r n 1 8 r i s k c o s t i n w p n r i n 12 t 1 r n 1 r n 1 9 r e g r e t c o s t i n w p n h c i i n 12 t n d t 1 r n 1 r n 1 10 r 1 r 1 s 1 11 o p t i m a l r e p l a c e m e n t t i m e i m i n n p v i n wp is the water price ε is the meter error n is the number of years i refers to meter i r is the real discount rate c in c inst c admin and c lab are the capital installation initial administrative labor costs respectively and csv is the salvage value of meter s is inflation rate and r is the discount rate t is the reading frequency measuring frequency for smart metering of customer meter in terms of month t in smart metering is a key variable since it can affect the battery life of wms and the dimensioning of the smart meter networks directly n is the number of zero readings that the water utility considers before it acts and d is the conscious delay the time taken that the utility decides to do something with the meter until it has been done based on the same unit of meter reading interval t it is worth noting that equations 6 and 7 are formulized based on the proposed equations used by arregui et al 2010 and mutikanga 2012 in fact the risk cost is the amount of revenue that the utility may lose when the currently working aged wm fails and the customer water consumption would not be measured until the utility becomes aware of this situation but the regret cost is the cost of ignoring disregarding the risk of failed meters consciously in brief the defined risk cost here has a preventive nature and measures the associated risk cost before the occurrence of a probable wm failure on the contrary the regret cost measures the associated cost that may have reactive characteristics and is entirely dictated through external factors such as technical staff and organizational behaviour of the utility and in no way depends on the technical aspects of the meter mutikanga et al 2011 suggested acceptable values for considering impact of the number of zero readings and delays in replacement of wms on water loss estimation he believes that quantifying these impacts is entirely dependent on the utility replacement policies as this study was aimed at proposing an am framework mainly focusing on preventive actions strong emphasis has been placed on the risk cost while being aware of the impact of the regret cost on the optimal replacement time of the wm in fact it is assumed that urgent required actions field survey testing replacement will be performed as soon as the utility becomes aware of any zero readings or failure of a meter and therefore the term representing the regret cost in the equation 5 can be ignored under the circumstances 4 4 long term financial planning in this step the total costs and the revenues required to implement future replacements interventions based on previous steps are evaluated here relief index is introduced by the comparison of the oa and the optimal replacement time of each meter to estimate time of any replacement equation 12 if the relief index for any meter becomes more than zero it means that there is still time for the replacement of the meter on the other hand if the relief index becomes less than zero it means that the replacement of the meter is a deferred replacement and useful life of the meter has expired these replacements can be presented in detailed schedule of financial and temporal intervention plans it is expected that the utilities benefited from this type of planning can determine their financial forecasts better 12 r e l i e f i n d e x i o p t i m a l r e p l a c e m e n t t i m e i o a i 5 results discussions 5 1 determining current state of the assets field surveys have enabled the isfahan utilities to recognize the majority of unknown meter sizes table 2 furthermore it is shown that 1502 broken wms exist in the study area table 2 comparison of the obtained results from the surveys table 2 with the initially available utility database table 1 shows that among 1238 unknown wm sizes in the utility database there were 1033 198 and 7 wm sizes of 1 2 3 4 and larger respectively these surveys enhanced the wm database of the utilities while detecting some 457 unauthorized connections consuming around 98775 m3 as part of the nrw annually this share of nrw about 4 of total water production is four times the suggested limit set by iwa farley and trow 2003 distribution of the broken wms and unauthorized connections are depicted in figs 3 and 4 respectively most of the troubling wms are located in the districts d and w respectively the estimation of oa was performed for the working meters this average meter age can be used for approximating the time remaining until the wm must be replaced the results of oa for all the meters existing in the study area is presented in table 3 in a condensed form the average registered consumption per meter is estimated to be around 2292 m3 this figure is derived by dividing the total recorded flow by all the meters by the number of meters also the average oa for all the working meters in the study area is assessed to be around 8 83 years 5 2 determining critical wm assets and their failure risks in this step according to the described proposed methodology critical wm assets with higher amounts of risk value are identified the field surveys show there are 10 types of different working wms in the study area based on the available record of failure data the br for each type of wm was elaborated and then used in order to calculate failure probability of wms according to equation 3 fig 5 shows the failure probability of each 10 types of wms with their corresponding br versus different years however it may be stipulated that the older meters have a higher probability of failure but this failure probability strongly depends on the value of br of the meter type the minimum and the maximum values of wm failure probability over the first and the 25 years of wms life span are assessed to be 0 0197 and 0 92 respectively as stated before if the meter fails and the utility does not become aware of this failure it will lose revenues these revenues are directly related to the amount of water consumption which cannot be measured registered within the meter failure time with this point of view annual average recorded consumption of assets for each type of wm was investigated to derive hci of each meter type the hci for each type of wm is shown in table 4 knowing hci and the failure probability of each wm type risk of failure of meter assets can be determined 5 3 determining optimal replacement time for each wm with given known values of input data such as inflation rate discount rate for both water price and wm costs water consumption growth rate accuracy degradation rate of wms over the years and other parameters the economic time of meter replacement for each meter type can be determined the economic time of replacement is when the risk based lcc of any asset becomes the minimum to gain insight into how the economic replacement time of a specific meter type is evaluated an illustrative example is provided in the following table 5 represents the corresponding values used as an input data in this type of meter optimal replacement assessment table 6 and fig 6 present the calculations of the investments for wms replacement the water lost revenue due to accuracy degradation of measuring water consumption the risk costs of water unmeasured through failing meters and npv for different time step of selected wm life span as shown in table 6 and fig 6 the economic optimal time of replacement for the selected type of wm only in terms of wm investment costs and costs of water revenues loss the traditional procedure of npv is nine years if the risk cost of selected wm failure is considered in determining the npv the risk based npv the economic optimal time of replacement of this type of meter is reduced to 8 years consequently based on this optimal replacement time the useful life of this chosen type of meter is 8 years these results show that however considering water revenues loss may reduce optimal replacement periods of selected wm types considering risk costs in npv calculations can reduce this replacement period too with regards to the used values of numerical input data for assessing lcc of this type of wm fig 6 shows that the risk cost is more than water revenues loss in early years of the meter age and gradually the water revenues loss costs become more than the risk costs in other words the effect of risk costs on minimizing lcc of the selected wm type is much more than water revenues loss costs in early years of the wm installation as it is logically and practically impossible to estimate lcc of each wm individually the average amount of recorded aawm as the hcis for each type of wm was adopted to calculate the optimum lcc of the other nine wm types table 7 summarizes the results of optimal replacement time for all the available meter types since the reliability of the final outputs in the process of any wm optimal replacement time assessment strongly depends on is vulnerable to the uncertainty of input data or any other effective assumptions running a sensitivity analysis is vital to find out what would happen if some of these hidden parameters change relative to the supposed base case this necessity is addressed in section 6 for the selected discussed wms in this section 5 4 determining long term financial planning knowing the estimated oa of any asset and comparing it with its corresponding economic time of replacement the relief index of each meter was assessed the positive or negative value of this index can show the remaining useful lifetime or deferred time of replacement for each asset respectively for example if the oa of a wm is 5 5 years and the optimal replacement time of this type of wm is 8 years then it is expected that the risk based lcc of wm would be minimum in the next 2 5 years or if the oa of this meter asset is 13 years this asset is deemed as a deferred replacement this type of analysis was done to assess the required replacement during the next years table 8 summarizes the number and the funds needed for the replacement of wms over the next years it is notable that while 1502 available broken meters need significant investments they have the highest priority for replacement due to their roles in the amount of nrw furthermore the considerable increase in revenues resulting from wm installations for the 457 unauthorized connections can act as the main incentive to cover huge replacement investments during the first year of intervention fig 7 shows the distribution of wms based on their time of replacements during the next years in which the optimal replacement time of zero and 1 stand for the broken and the deferred replacements respectively and the other values show a need for replacements that must be met during the corresponding next years 6 sensitivity analyses as a non limiting example the sensitivity analyses were performed for the same selected wm type previously discussed in section 5 3 in detail in order to evaluate how the uncertainty in values of the input data can affect the optimal replacement time and its corresponding cost these analyses for wm type 9 in tables 4 and 7 were based on variation of seven input data namely water price wp reading frequency of meters t investment cost breakage rate br hci the accuracy degradation rate and the real discount rate r figs 8 and 9 show the effect of variation of mentioned input data versus variation of optimal replacement time and its corresponding npv respectively these sensitivity analyses can enable utility decision makers to track and improve their desired policy it is worth noting that in each of the analyses only the effect of variation of one input data was investigated while in reality more than one input data may change simultaneously with regards to the main aim of this study presenting an am framework benefited from involving risk cost in wm replacement decision making presenting sensitivity analyses for all the wm types or due to the variation of multiple input data at a same time is assumed beyond the scope of this study as seen in fig 8 confirming expectations lower values of t the accuracy degradation rate hci and the water price would lead to higher values of the optimal replacement time it may also be claimed that the economic lifespan of the wm may be affected only when the accuracy degradation rate and the water price have significant variations furthermore it may be deduced that the investment costs are directly proportional to the economic lifespan of the wm while the variation of the input data within the domain of 40 to 40 of the base case would displace the optimal replacement time of selected types of wms only by one year fig 9 which shows the variation of optimal replacement cost of wm versus variation of input data confirms the expected increasing trend of optimal replacement costs with increase of t the accuracy degradation rate the water price hci and the investment costs in this figure the line slopes of different input data can be interpreted as the severity of how optimal cost of replacement depends on the corresponding input data variations for example due to steeper slopes of investment cost hci and water price than the slope of the br t and the accuracy degradation rate greater variation of risk based cost rate can be observed with variation of input data fig 9 however the results presented by mutikanga 2012 show that the variation of the accuracy degradation rate on variation of lcc is more than the variation of water price but the obtained results here prove otherwise one of the main reasons for this discordance is the risk cost introduced here this introduced cost has far greater impact on lcc in the early years of the wm furthermore fig 9 shows that in the range of 20 to 20 changes in base case value of input parameters the optimal costs of replacement do not show noticeable changes moreover the results showed that although the selected domain of variation for real discount rate r has not been affected by the optimal replacement time it may be very effective in variation of the optimal replacement costs of wms this trend is due to the npv formulation in which all the equations 6 8 have the same term for the real discount rate and consequently they attain the same impact from variations of the real discount rate values furthermore the results of the sensitivity analysis show that the response behaviour of the optimal replacement time of the wm to the variations of t and br are identical while similar behaviour is true again for variations of wp and hci parameters the reason for this behaviour is the format of the proposed formulations equations 7 and 8 for the risk costs and the lost revenues costs where changes in values of each individual parameter would have similar effects in the estimation of the mentioned costs 7 conclusions this study has led to the development of an asset management am framework for better management of water meters wms and determining economic time of wms replacements despite existing wm replacement options focusing only on life cycle cost of wms with respect to the initial investment and lost revenue due to the inaccuracy of wms the proposed am framework benefited from a new life cycle cost method reducing the maximum potential of wm failure risk the proposed am framework consists of four main steps 1 identifying the current state of wms assets through defining a new index termed as the operational age oa and through field surveys 2 identifying critical assets and their corresponding risks by using risk analysis 3 identifying economic replacement time of wm types by minimizing the life cycle cost approach 4 presenting long term financial planning the proposed framework was applied to a real case study located near south west of the city of isfahan suffering from high rate of non revenue water due to the low level of wms services the results highlight the critical condition of the wms in the study area in that all the meters have to be replaced within the next years the results show that considering impact of failure risks on optimal replacement of water meters is essential and becomes even more decisive for utilities lacking effective policies for identifying and replacing failed wms furthermore applying the proposed am framework identified 457 unauthorized connections and provided a platform for future decision making in addition in order to investigate the impact of the uncertainties associated with the input data values for the wm replacement decisions appropriate sensitivity analyses were performed the results show that the accuracy degradation rate hci and the water price have more influence on optimal replacement time than the other input parameters in terms of optimal replacement cost variation of the real discount rate initial investment and water price are the most effective input data compared to conventional approaches the proposed am approach introduces a number of advantages comprising identifying optimum replacement time of wm types with respect to risk management of wm failure identifying and ranking the risky meters estimating remaining useful lifetime or deferred replacement time of wm recognizing and substituting missing wm data and finally providing better platforms for future management of wm assets 
26401,despite existence of many developed approaches for identifying optimal time of water meters wms replacement less attention has been paid to the impact of wm failure risk on utilities revenues and the proper time of replacement here the asset management am approach is introduced as a holistic managing framework optimizing life cycle costs lcc especially incorporating wm failure risk in asset replacement decisions the proposed am framework is based on four core steps the application of the proposed framework for a real case study has shown confidence in finding the economical time of wm replacement it was further shown that the risk costs associated with wm failure have higher impacts on optimal time of wm replacement than the revenue lost due to its inaccuracy the sensitivity analyses of input data values show that water price initial investment and accuracy degradation rate have the highest impacts on lccs amongst other parameters keywords asset management failure risk optimal time of replacement sensitivity analyses water meter data availability data used in this study are available in persian in spreadsheet format and may be obtained from the authors on request list of acronyms and abbreviations wm is the water meter am is the asset management lcc is the life cycle cost cri is the composite replacement indicator nrw is the non revenue water oa is the operational age twm is the total water measurement aawm is the annual average water measurement nt is the number of available consumption data br is the annual breakage rate p is the probability of the failure t is the time step hci is the hydraulic criticality index r is the risk measurement of failure npv is the net present value wp is the water price ε is the meter error accuracy degradation n is the number of year r is the real discount rate c in is the capital cost c inst is the installation cost c admin is the administrative cost c lab is the labor cost c sv is the salvage value s is the inflation rate r is the discount rate t is the meter reading frequency n is the number of zero reading of meter d is the conscious delay time of meter replacement 1 introduction international experience has shown that water as the social and economic commodity served by utilities must be better appreciated and compensated through customers water bills barraqué 2011 biswas and tortajada 2010 calculations of these bills are based on two important factors 1 water tariffs allocated to the amount of water consumptions 2 the amount of water measured by the water meters wms since the utility policy makers usually revisit the first factor annually the second factor can play a more effective role in loosing revenues through issuing inaccurate bills wms are the only practical tools for the utilities to measure their revenues and from this perspective they are the most important assets of water distribution networks around the world despite progressive developments in the metering industry and water measurement most of the existing wms in many water distribution networks have been inherited from the past decades water measurement accuracy of these meters is degraded over the years and most of them reach to the end of their useful life while still operating inefficiently this accuracy degradation of wms during their operational lifespan can pose severe challenges for the utilities more often than not in the form of increase in non revenue water supply to help utilities to face the above mentioned challenges ensuring the accuracy and precision of the measurement the developed official standards and regulations present some recommendations about time of testing and replacing of the wms for example based on american water work association the wm size of 5 8 1 1 4 4 and larger should be tested every 10 5 and 1 year respectively american water works association 1999 since the accuracy degradation of wms is dependent on different factors under varying operational conditions these proposed recommendations have not been fully constructive consequently many researchers have tried to go beyond these suggestions therefore many different guidelines or models for predicting wms timely replacement have been proposed the majority of these models are sensitive to their inherent assumptions complexity involved uncertainties and influencing factors such as condition of wms installation and operation age water quality pressure head of water distribution network and thus finding a holistic approach for managing wms services with fewer challenges is very much encouraged for the sake of simplicity many utilities around the world have used simple criteria to judge the time of wms replacement for example some of the utilities use cumulative registered volume passed through meters and some others use the age of wms from its installation date as the criteria for replacement davis 2005 thornton et al 2008 in this type of decision making some thresholds for the criteria like 10 years of operation or 5000 m3 as the total cumulative volume of water measured by one wm are required to be established the idea of wms replacement based on these criteria has been presented through finding the relationship between wms accuracy and their age or the cumulative water registered by any meter most of these relationships were presented in a linear form arregui et al 2006 davis 2005 mutikanga 2012 noss et al 1987 in 1987 noss et al stated that wm accuracy must be measured in three different ranges of flow including high medium intermediate and low flow his results showed that the less the available flow rate is the less the wms accuracy will be moreover it was found that the accuracy degradation rate in low flow versus wm age is more severe than high flow furthermore the optimal testing period of wms is most sensitive to the rate of deterioration of meter accuracy with its age noss et al 1987 some of noss s results were confirmed later by allender 1996 later fontanazza et al 2012 stated that knowing wms age and cumulative water registered are not sufficient criteria for replacement decisions therefore they presented a new criterion called composite replacement indicator cri based on oecd recommendations 2008 it was found that the use of this criterion may result in better replacement decisions another set of research with different points of view has focused on the impact of considering the economic issues such as water and wms prices in wms replacement time noss et al 1987 and yee 1999 can be cited as the pioneer researchers in this field in this viewpoint the right time of replacement is detected when the annual average costs of replacement become minimum in later studies it was found that the proper time of replacement not only depends on the rate of accuracy degradation and economic issues but also strongly sensitive to the opportunity value of time such as discount rate and consequently minimizing cost during entire life of the wms arregui et al 2010 mutikanga 2012 in these life cycle cost lcc analyses several costs of installations replacement policy water lost testing and maintenance salvage water and wm price along with several rates of discount inflation interest and so on were considered these efforts are sometimes presented in the forms of handy tools such as i wamrm in order to determine the optimum time of wms replacement mutikanga 2012 woltman in order to assess weighted error of a meter arregui et al 2010 and econanal in order to define optimum testing periods of wms noss et al 1987 despite all the advantages of these developed tools some points of concern are evident requiring rich databases such as meters accuracy and their degradation rates over the years customer water demand patterns and flows wms accuracy curves limitation of meter types mutikanga 2012 posing difficulties in real practices arregui et al 2010 and performing calculations in the black boxes involving many uncertainties as a result applications of these tools are faced with several fundamental questions comprehensive review of the literature about identifying wms and finding their optimal time of replacement shows that what has been rarely discussed is the costs that water utilities may accept in order to burden the risk of wms failure during their lccs when the meter fails the utility may lose some its revenue due to the unrecorded customer water consumption therefore wm failure can impose risks on the utility s revenue it therefore becomes necessary to investigate whether this risk cost may be considered as one of the effective elements of the wm lcc and its corresponding optimal time of replacement to respond to this necessity a holistic management framework is proposed here as the main contribution of this work which can take economic risk of wm failure into account while maintaining the required level of meter services with the lowest lcc an asset management am approach switching the required annual assets rehabilitation as part of the operation and maintenance program can ideally set the appropriate management framework for making decisions on timely replacement of wms extensive use of this management approach in many disciplines and applied sciences such as business and financial planning transmission and distribution of energy and power smart telecommunication management of infrastructures such as transportation and water distribution short and long term planning and risk based decision making has posed am as an effective integration of engineering and management approaches interestingly the majority of these fields of work are somehow related to the subject of optimizing the replacement of meters and further addressing the increasing interests in smart metering and monitoring in addition to other existing wm optimal replacement options am can help in various ways identify where the utilities have any assets of any given type anticipate risky aging meters by location identify potentials for risk cost reduction assess replacement of which meter is profitable minimize life cost of each meter with regards to the risk cost and identify priority of each meter for optimal replacement the proposed am approach is presented based on a four step framework comprising identifying current state of assets identifying critical assets and their corresponding risks minimizing lcc of each asset and presenting long term funding plans the efficiency of the proposed framework was examined on a water network with high rate of customer metering inaccuracies and missed data as a case study to prove efficiency of the proposed framework for handling many uncertainties involved in meter replacement decision an extensive sensitivity analysis was performed 2 asset management providing appropriate water services of water distribution network for consumers is an everlasting duty for utilities nowadays many utilities decision makers attempt to consider ageing infrastructures as the valuable assets that must be managed and sustained during their long life any element of an infrastructure system that has potential value for utilities may be regarded as an asset some of the most well known assets in water distribution network are pipes pumps valves tanks and flow meters each of these assets has its exclusive management characteristics such as monetary and operational values useful life period failure risk and varying cost and investment aspects despite conventional management practices based on reactive approaches asset management am was first introduced in the 80s in new zealand van heck 2008 focusing mainly on proactive actions with regards to appropriate assets characteristics rapid development of this concept throughout the world has developed many views on what is considered as an asset management the common part of these views is their main aim based on maintaining the desired level of services at the lowest life cycle cost halfawy 2004 usepa 2009 different factors for promoting am such as ageing infrastructure public requests for high level services rigorous regulations population growth risk management limited resources and the development of new technologies have led many countries to develop some frameworks for better implementation of am a brief comparison between some proposed am frameworks with emphasis on water and wastewater utilities are presented in van heck 2008 the bases of these proposed frameworks are often presented in core steps similar to those presented in the current work where they usually start with identifying existing assets and their current state and what is desired followed by analyzing data assigning priorities and making decisions and ending with presenting the best required actions for am including future needs and long term funding plans literature on implementing am in water distribution networks may be chronologically divided into five categories condition based asset management clair and sinha 2012 lansey et al 1992 roshani and filion 2013 judging based on physical and operational conditions of assets performance based asset management hall et al 2004 judging based on whether the assets can cope well with their corresponding duties or not if not what interventions should be made and how much they are needed service based or service level driven asset management heather and bridgeman 2007 judging based on whether the corporation of assets can provide appropriate service levels or not risk based asset management christodoulou et al 2009 parton et al 2011 judging based on how the life cycle costs of assets can be minimized while these assets have their acceptable minimum levels of risks namely economic environmental operational and so on sustainable based asset management cardoso et al 2012 marlow 2010 this kind of am can provide a higher level of management in which sustainable criteria can be implemented externalities can be considered and acceptable risk levels in all dimensions can be achieved 3 problem description existence of many standards global and local regulations as well as numerous studies about wms confirms the undisputable role of these assets in water consumption management and reducing the non revenue water nrw previous meter recordings in the aradan city iran indicated a water consumption figure of 915 cubic meters per month replacing all customer meters of 10 years of age and older indicated that the actual consumption rate was 3182 cubic meters per month showing an under registration of some 71 2 this replacement plan has resulted in an increase of utility revenues of 441 shahmansoorian et al 2016 based on estimations proper replacement of wms in iran can lead to a significant increase of water utility revenues annually around two million us dollars governmental legislation to improve water distribution networks performances in various parts of iran faced with water scarcity has led this study to concentrate on one of the most nrw troubled cities of central iran in the isfahan province the existing water distribution network of the city aged more than 30 years old with an area of 36 km2 serving a population of around 20000 people consists of three municipal districts fig 1 based on local studies replacement of broken and aged wms is one of the most effective activities to reduce the amount of non revenue water significantly it is estimated that around 15 of the inlet water volume to the study network is lost due to the errors of customer s wms the amount of losses is estimated around 358000 m3 per year which is equivalent to the loss of 21175 revenue per year table 1 shows different sizes of wms and their counts in the pilot area furthermore the consumption data recorded by the wms in the study area may be classified as low resolution data cominola et al 2015 since at best these data were recorded every two months the above mentioned problems have led this research to develop an asset management framework in which the optimum time of wm replacement and management with their priority for intervention can be identified in addition to the existing problems in the study network limitations associated with insufficient reliable data have posed extra concern with the precision of estimation of life cycles thus life cycle estimation methodology has been particularly addressed in the proposed am framework 4 methodology in order to support utilities decisions on managing their meters in short and long term and determining the optimum time of their replacement a four steps am framework is proposed in designing the basis of the proposed am framework the desired drivers incentives expectations and type of assets are the key factors the general steps for developing the am framework proposed herein are shown in fig 2 description of each step in the framework is given as follow 4 1 identifying current state of the assets in this step a reliable dataset is needed to make the right decisions required in the next steps this would comprise gathering and completing available wms data assessing their present values assessing the operational conditions of wms detecting unavailable data via field survey and library studies due to the lack of data on precise installation dates analyzed errors and accuracy degradation levels of wms estimating the exact age of wms is not possible therefore a surrogate measurement index named operational age oa is introduced here to assess the estimated age of each wm and average age of all wms in the study area oa of any meter is equivalent to the ratio of total water measured metered by a meter to the average annual metered water consumption for the meter equation 1 1 o a i t w m i a a w m i where oa is the operational age of a wm twm is the total water measured by a specific wm over its life installation date up to now aawm is the average annual flow of water measured by a meter m3 year based on the condition of each meter and its corresponding available data aawm is estimated for each meter in two different ways 1 for any working meter with sufficient recorded data the aawm is considered equal to the average annual water consumption rate this value can be derived from the average of all available annual consumption data over the few past years equation 2 2 for the meters with missed recorded data unrecorded or unreliable consumptions a consumption equal to that of customers with equivalent characteristics can be assigned as a surrogate for aawm 2 a a w m i t 1 n t a a w m i t n t where nt is the number of available annual consumption data aawm i t is the amount of water measured by meter i in year t 4 2 identifying critical wm assets and their failure risks every asset like wms may fail examining the probability and the consequence of a meter failure is essential for adequate risk assessment as the failure of any wm is a discrete event more often than not occurring independently and continuously in time the poisson model equation 3 is capable dhillon 1983 zhuang et al 2012 to allocate the failure probability of the wm the efficiency of using this model for wm failure has previously been proven by lund 1988 and mutikanga et al 2011 3 p i 1 exp b r i j t i where br is the annual breakage rate of meter i with type of j and p is the probability of the meter i failure in time t year in this equation t can be regarded as the surrogate representation of each meter oa lund 1988 and mutikanga et al 2011 assumed constant values of 0 01 and 0 066 as the breakage rate of their selected wm type over the wm s lifetime respectively in terms of failure consequences identifying the failure of those more vulnerable can lead to better management of the assets based on this reasonable principle that failure consequences of wms with higher rate of annual water consumption is more the risk of meter failure will become more hydraulic criticality index hci is introduced here as the wm failure consequences which are equivalent to the mean value of aawm for all the wms of the same type the higher amounts of hci indicate the higher amounts of loss of water under failure conditions therefore the risk measurement of each unbroken working meter failure can be calculated by 4 r i p i h c i i the meters with the highest amount of risk are called critical assets here consequently these meters have higher priority for regular intervention test or replacement based on their more probable potential impact on losing utility s revenues therefore paying special attention to decision making on the optimal replacement time of risky assets is necessary it is worth noting that since the failed broken meters usually have an error of 100 it is presumed that they would pose the highest risk for the water utility consequently these meters must be given the higher priority for replacement and there is no need to consider these assets in the calculation of the hci nor in the assets failure risk estimation 4 3 minimizing life cycle costs the life cycle cost lcc of an asset is the cost spent in different forms such as initial capital operation maintenance repair rehabilitation disposal and replacement costs different methods such as net present value npv method have been introduced in the literature for analyzing lcc of many assets in this method the best time for any intervention like wms testing replacement is usually selected in a manner that lcc becomes minimum for every asset in terms of wm replacement traditionally the npv models have been established based on many input data with high uncertainties and without considering the risk costs of hindering the replacement time of wms it is believed here that the utility as the main responsible body for any consequences of wm replacement not only should maximize their revenue but also must reduce the maximum potential of their economic risk therefore the npv calculation formula is modified in order to consider the cost associated with the risk of postponing wm replacement this risk cost can be aggravated by the impact of utility policies which may increase utility lost revenue in a period of unsatisfactory performance of a failed meter for example existence of any zero reading before the water utility do anything with the failed meter or delay of the utility in replacing the failed meter can expose more costs to the utility which may be termed as the regret cost the new formulated risk cost based on npv is expressed based on the summation of four terms equation 5 the first one assesses the cost that must be invested for the meter replacement investment cost the second one is the lost revenue due to accuracy degradation of the wm lost revenue cost the third one is the cost of working wm failure risk and the last term is the regret cost when these costs are estimated for each time period of wm replacement the time with the lowest amount of cost is selected as the economic optimal time for meter replacement 5 n p v i n i n v e s t m e n t c o s t i n l o s t r e v e n u e c o s t i n r i s k c o s t i n r e g r e t c o s t i n 6 i n v e s t m e n t c o s t i n c i n c i n s t c a d min c l a b c s v i 1 r n 1 r n 1 7 l o s t r e v e n u e c o s t i n n 1 n t w p n h c i i n ε i n 1 r n 1 1 r n 1 r n 1 8 r i s k c o s t i n w p n r i n 12 t 1 r n 1 r n 1 9 r e g r e t c o s t i n w p n h c i i n 12 t n d t 1 r n 1 r n 1 10 r 1 r 1 s 1 11 o p t i m a l r e p l a c e m e n t t i m e i m i n n p v i n wp is the water price ε is the meter error n is the number of years i refers to meter i r is the real discount rate c in c inst c admin and c lab are the capital installation initial administrative labor costs respectively and csv is the salvage value of meter s is inflation rate and r is the discount rate t is the reading frequency measuring frequency for smart metering of customer meter in terms of month t in smart metering is a key variable since it can affect the battery life of wms and the dimensioning of the smart meter networks directly n is the number of zero readings that the water utility considers before it acts and d is the conscious delay the time taken that the utility decides to do something with the meter until it has been done based on the same unit of meter reading interval t it is worth noting that equations 6 and 7 are formulized based on the proposed equations used by arregui et al 2010 and mutikanga 2012 in fact the risk cost is the amount of revenue that the utility may lose when the currently working aged wm fails and the customer water consumption would not be measured until the utility becomes aware of this situation but the regret cost is the cost of ignoring disregarding the risk of failed meters consciously in brief the defined risk cost here has a preventive nature and measures the associated risk cost before the occurrence of a probable wm failure on the contrary the regret cost measures the associated cost that may have reactive characteristics and is entirely dictated through external factors such as technical staff and organizational behaviour of the utility and in no way depends on the technical aspects of the meter mutikanga et al 2011 suggested acceptable values for considering impact of the number of zero readings and delays in replacement of wms on water loss estimation he believes that quantifying these impacts is entirely dependent on the utility replacement policies as this study was aimed at proposing an am framework mainly focusing on preventive actions strong emphasis has been placed on the risk cost while being aware of the impact of the regret cost on the optimal replacement time of the wm in fact it is assumed that urgent required actions field survey testing replacement will be performed as soon as the utility becomes aware of any zero readings or failure of a meter and therefore the term representing the regret cost in the equation 5 can be ignored under the circumstances 4 4 long term financial planning in this step the total costs and the revenues required to implement future replacements interventions based on previous steps are evaluated here relief index is introduced by the comparison of the oa and the optimal replacement time of each meter to estimate time of any replacement equation 12 if the relief index for any meter becomes more than zero it means that there is still time for the replacement of the meter on the other hand if the relief index becomes less than zero it means that the replacement of the meter is a deferred replacement and useful life of the meter has expired these replacements can be presented in detailed schedule of financial and temporal intervention plans it is expected that the utilities benefited from this type of planning can determine their financial forecasts better 12 r e l i e f i n d e x i o p t i m a l r e p l a c e m e n t t i m e i o a i 5 results discussions 5 1 determining current state of the assets field surveys have enabled the isfahan utilities to recognize the majority of unknown meter sizes table 2 furthermore it is shown that 1502 broken wms exist in the study area table 2 comparison of the obtained results from the surveys table 2 with the initially available utility database table 1 shows that among 1238 unknown wm sizes in the utility database there were 1033 198 and 7 wm sizes of 1 2 3 4 and larger respectively these surveys enhanced the wm database of the utilities while detecting some 457 unauthorized connections consuming around 98775 m3 as part of the nrw annually this share of nrw about 4 of total water production is four times the suggested limit set by iwa farley and trow 2003 distribution of the broken wms and unauthorized connections are depicted in figs 3 and 4 respectively most of the troubling wms are located in the districts d and w respectively the estimation of oa was performed for the working meters this average meter age can be used for approximating the time remaining until the wm must be replaced the results of oa for all the meters existing in the study area is presented in table 3 in a condensed form the average registered consumption per meter is estimated to be around 2292 m3 this figure is derived by dividing the total recorded flow by all the meters by the number of meters also the average oa for all the working meters in the study area is assessed to be around 8 83 years 5 2 determining critical wm assets and their failure risks in this step according to the described proposed methodology critical wm assets with higher amounts of risk value are identified the field surveys show there are 10 types of different working wms in the study area based on the available record of failure data the br for each type of wm was elaborated and then used in order to calculate failure probability of wms according to equation 3 fig 5 shows the failure probability of each 10 types of wms with their corresponding br versus different years however it may be stipulated that the older meters have a higher probability of failure but this failure probability strongly depends on the value of br of the meter type the minimum and the maximum values of wm failure probability over the first and the 25 years of wms life span are assessed to be 0 0197 and 0 92 respectively as stated before if the meter fails and the utility does not become aware of this failure it will lose revenues these revenues are directly related to the amount of water consumption which cannot be measured registered within the meter failure time with this point of view annual average recorded consumption of assets for each type of wm was investigated to derive hci of each meter type the hci for each type of wm is shown in table 4 knowing hci and the failure probability of each wm type risk of failure of meter assets can be determined 5 3 determining optimal replacement time for each wm with given known values of input data such as inflation rate discount rate for both water price and wm costs water consumption growth rate accuracy degradation rate of wms over the years and other parameters the economic time of meter replacement for each meter type can be determined the economic time of replacement is when the risk based lcc of any asset becomes the minimum to gain insight into how the economic replacement time of a specific meter type is evaluated an illustrative example is provided in the following table 5 represents the corresponding values used as an input data in this type of meter optimal replacement assessment table 6 and fig 6 present the calculations of the investments for wms replacement the water lost revenue due to accuracy degradation of measuring water consumption the risk costs of water unmeasured through failing meters and npv for different time step of selected wm life span as shown in table 6 and fig 6 the economic optimal time of replacement for the selected type of wm only in terms of wm investment costs and costs of water revenues loss the traditional procedure of npv is nine years if the risk cost of selected wm failure is considered in determining the npv the risk based npv the economic optimal time of replacement of this type of meter is reduced to 8 years consequently based on this optimal replacement time the useful life of this chosen type of meter is 8 years these results show that however considering water revenues loss may reduce optimal replacement periods of selected wm types considering risk costs in npv calculations can reduce this replacement period too with regards to the used values of numerical input data for assessing lcc of this type of wm fig 6 shows that the risk cost is more than water revenues loss in early years of the meter age and gradually the water revenues loss costs become more than the risk costs in other words the effect of risk costs on minimizing lcc of the selected wm type is much more than water revenues loss costs in early years of the wm installation as it is logically and practically impossible to estimate lcc of each wm individually the average amount of recorded aawm as the hcis for each type of wm was adopted to calculate the optimum lcc of the other nine wm types table 7 summarizes the results of optimal replacement time for all the available meter types since the reliability of the final outputs in the process of any wm optimal replacement time assessment strongly depends on is vulnerable to the uncertainty of input data or any other effective assumptions running a sensitivity analysis is vital to find out what would happen if some of these hidden parameters change relative to the supposed base case this necessity is addressed in section 6 for the selected discussed wms in this section 5 4 determining long term financial planning knowing the estimated oa of any asset and comparing it with its corresponding economic time of replacement the relief index of each meter was assessed the positive or negative value of this index can show the remaining useful lifetime or deferred time of replacement for each asset respectively for example if the oa of a wm is 5 5 years and the optimal replacement time of this type of wm is 8 years then it is expected that the risk based lcc of wm would be minimum in the next 2 5 years or if the oa of this meter asset is 13 years this asset is deemed as a deferred replacement this type of analysis was done to assess the required replacement during the next years table 8 summarizes the number and the funds needed for the replacement of wms over the next years it is notable that while 1502 available broken meters need significant investments they have the highest priority for replacement due to their roles in the amount of nrw furthermore the considerable increase in revenues resulting from wm installations for the 457 unauthorized connections can act as the main incentive to cover huge replacement investments during the first year of intervention fig 7 shows the distribution of wms based on their time of replacements during the next years in which the optimal replacement time of zero and 1 stand for the broken and the deferred replacements respectively and the other values show a need for replacements that must be met during the corresponding next years 6 sensitivity analyses as a non limiting example the sensitivity analyses were performed for the same selected wm type previously discussed in section 5 3 in detail in order to evaluate how the uncertainty in values of the input data can affect the optimal replacement time and its corresponding cost these analyses for wm type 9 in tables 4 and 7 were based on variation of seven input data namely water price wp reading frequency of meters t investment cost breakage rate br hci the accuracy degradation rate and the real discount rate r figs 8 and 9 show the effect of variation of mentioned input data versus variation of optimal replacement time and its corresponding npv respectively these sensitivity analyses can enable utility decision makers to track and improve their desired policy it is worth noting that in each of the analyses only the effect of variation of one input data was investigated while in reality more than one input data may change simultaneously with regards to the main aim of this study presenting an am framework benefited from involving risk cost in wm replacement decision making presenting sensitivity analyses for all the wm types or due to the variation of multiple input data at a same time is assumed beyond the scope of this study as seen in fig 8 confirming expectations lower values of t the accuracy degradation rate hci and the water price would lead to higher values of the optimal replacement time it may also be claimed that the economic lifespan of the wm may be affected only when the accuracy degradation rate and the water price have significant variations furthermore it may be deduced that the investment costs are directly proportional to the economic lifespan of the wm while the variation of the input data within the domain of 40 to 40 of the base case would displace the optimal replacement time of selected types of wms only by one year fig 9 which shows the variation of optimal replacement cost of wm versus variation of input data confirms the expected increasing trend of optimal replacement costs with increase of t the accuracy degradation rate the water price hci and the investment costs in this figure the line slopes of different input data can be interpreted as the severity of how optimal cost of replacement depends on the corresponding input data variations for example due to steeper slopes of investment cost hci and water price than the slope of the br t and the accuracy degradation rate greater variation of risk based cost rate can be observed with variation of input data fig 9 however the results presented by mutikanga 2012 show that the variation of the accuracy degradation rate on variation of lcc is more than the variation of water price but the obtained results here prove otherwise one of the main reasons for this discordance is the risk cost introduced here this introduced cost has far greater impact on lcc in the early years of the wm furthermore fig 9 shows that in the range of 20 to 20 changes in base case value of input parameters the optimal costs of replacement do not show noticeable changes moreover the results showed that although the selected domain of variation for real discount rate r has not been affected by the optimal replacement time it may be very effective in variation of the optimal replacement costs of wms this trend is due to the npv formulation in which all the equations 6 8 have the same term for the real discount rate and consequently they attain the same impact from variations of the real discount rate values furthermore the results of the sensitivity analysis show that the response behaviour of the optimal replacement time of the wm to the variations of t and br are identical while similar behaviour is true again for variations of wp and hci parameters the reason for this behaviour is the format of the proposed formulations equations 7 and 8 for the risk costs and the lost revenues costs where changes in values of each individual parameter would have similar effects in the estimation of the mentioned costs 7 conclusions this study has led to the development of an asset management am framework for better management of water meters wms and determining economic time of wms replacements despite existing wm replacement options focusing only on life cycle cost of wms with respect to the initial investment and lost revenue due to the inaccuracy of wms the proposed am framework benefited from a new life cycle cost method reducing the maximum potential of wm failure risk the proposed am framework consists of four main steps 1 identifying the current state of wms assets through defining a new index termed as the operational age oa and through field surveys 2 identifying critical assets and their corresponding risks by using risk analysis 3 identifying economic replacement time of wm types by minimizing the life cycle cost approach 4 presenting long term financial planning the proposed framework was applied to a real case study located near south west of the city of isfahan suffering from high rate of non revenue water due to the low level of wms services the results highlight the critical condition of the wms in the study area in that all the meters have to be replaced within the next years the results show that considering impact of failure risks on optimal replacement of water meters is essential and becomes even more decisive for utilities lacking effective policies for identifying and replacing failed wms furthermore applying the proposed am framework identified 457 unauthorized connections and provided a platform for future decision making in addition in order to investigate the impact of the uncertainties associated with the input data values for the wm replacement decisions appropriate sensitivity analyses were performed the results show that the accuracy degradation rate hci and the water price have more influence on optimal replacement time than the other input parameters in terms of optimal replacement cost variation of the real discount rate initial investment and water price are the most effective input data compared to conventional approaches the proposed am approach introduces a number of advantages comprising identifying optimum replacement time of wm types with respect to risk management of wm failure identifying and ranking the risky meters estimating remaining useful lifetime or deferred replacement time of wm recognizing and substituting missing wm data and finally providing better platforms for future management of wm assets 
26402,addressing continental scale challenges affecting inland aquatic systems requires data at comparable scales critically local in situ observations for both lotic and lentic ecosystems are frequently fragmented across federal state and local agencies and nonprofit or academic organizations and must be linked to other geospatial data to be useful to advance macro scale aquatic ecosystem science better tools are needed to facilitate dataset integration key to integration of aquatic data is the linking of spatial data to the hydrologic network this integration step is challenging as hydrologic network data are large and cumbersome to manage here we develop a new r package hydrolinks to ease linking aquatic data to the hydrologic network we use hydrolinks to evaluate the spatial data quality for all lake and stream sites available through the u s water quality portal we find that 76 5 of lake sites and 13 9 of stream sites do not correspond with mapped waterbodies keywords r package lakes streams hydrologic network limnology data integration macrosystem ecology software availability name of software hydrolinks developers tobi hahn luke winslow taylor leach kevin rose software required r license mit license availability freely available through cran cran r project org development version at github com lawinslow hydrolinks archived version https doi org 10 5281 zenodo 1169399 1 introduction many of today s challenges in understanding aquatic systems operate at the regional to global scale heffernan et al 2014 addressing these macrosystem scale challenges affecting inland aquatic ecosystems requires data at comparably large scales from climate change impacts e g isaak et al 2016 o reilly et al 2015 to eutrophication and algal blooms e g chapra et al 2017 sinha et al 2017 large regional to global scale insights depend on linking observations across diverse and spatially extensive lake and stream regions broad scale data is particularly important as both geographic and morphological heterogeneity of inland waters and diverse watershed characteristics drive how aquatic ecosystems respond to broad scale forcing e g read et al 2015 soranno et al 2015 winslow et al 2015 to this end researchers have built tools and data systems to automate integration and processing of aquatic data and features e g haag and shokoufandeh 2017 horsburgh and reeder 2014 read et al 2011 some datasets relevant to aquatic research such as land cover jin et al 2013 elevation jarvis et al 2008 and climate dee et al 2011 are well curated and have been made publicly available at continental and global scales but many potentially high value in situ aquatic observations are fragmented across government nonprofit and academic organizations soranno et al 2015 further available datasets are frequently described by latitude longitude coordinates often without clear unambiguous reference to mapped surface water features the lack of unique identifiers or unambiguous linking can make it difficult to connect aquatic data to other in situ datasets or important spatial context information such as land use hydrologic connectivity or waterbody morphology hill et al 2016 using alternative site identification schemes while there have been recent efforts to collect and organize fragmented sources of aquatic data and link them to specific mapped waterbodies most current examples are limited in data type temporal span or confined to a regional spatial extent e g oliver et al 2017 soranno et al 2015 to advance macrosystem aquatic research new tools are needed to accelerate the integration of fragmented data across both lentic and lotic ecosystems one powerful way to integrate fragmented aquatic datasets and connect those data with landscape features is to link in situ aquatic data to mapped surface water features using unique identifiers this allows for the unambiguous communication of the surface water feature from which a data point originates unfortunately available tools to enable linking are only available on specialized geographic information system gis platforms that are often foreign to ecologists and require special training one such example is the u s geological survey s usgs hydrologic event management tool hem https nhd usgs gov tools html which is specific to only the usgs national hydrography dataset additionally the hem tool requires manual handling of the hydrologic network data does not support lakes and needs a local license for the arcgis software package bringing hydrologic network linking to general scientific computing platforms used by aquatic ecologists and generalizing the linking to include multiple commonly used large scale hydrologic network datasets would enable better broad scale data integration thus accelerating macrosystem hydrologic science here we introduce hydrolinks an r package to ease linking of aquatic data with the hydrologic network hydrolinks automates access retrieval and local storage of large hydrologic network datasets including the usgs national hydrologic dataset nhd high resolution 1 24k nhd plus currently 1 100k and the global hydrolakes datasets the package includes a number of algorithms for linking data described by latitude and longitude to the hydrologic network including variable width buffer centroid correspondence and point in polygon linking to provide example uses we demonstrate the functioning of hydrolinks by linking a large national scale aquatic dataset to the u s hydrologic network we then show how linking large datasets to the hydrologic network can enable integration of diverse data sources and highlight potential data quality issues in large federal environmental databases 2 methods 2 1 linking tool the hydrolinks package is built to reduce the complexities of linking aquatic ecosystem data that is described by simple latitude longitude geographic referencing to generally available hydrologic network geographic datasets based on the data and type of hydrologic linking requested the package can automatically download required hydrologic network data to link latitude longitude data points to streams or waterbodies generally lakes or reservoirs here we provide an overview of the linking approaches used and how these large complex data are stored and distributed 2 1 1 data access methods one of the novel aspects of hydrolinks is to enable automatic on the fly data access so the user does not need to download and manage the large hydrologic datasets for linking the hydrologic datasets are split up into small quick to download file sizes 50 mb that represent contiguous regions included in the package are data on the geographic bounding boxes associated with the sub region files of each dataset these bounding boxes are used when executing linking functions to determine which sub region pieces of the hydrologic networks are needed these data are downloaded using simple http from an online source verified complete using an md5 hash and then used in the data linking procedure all downloaded files are locally cached to enable rapid re linking of future data the location of the local cache can be user defined using the local path function this may be useful when an alternative cache drive or path is preferred over the default 2 1 2 current available datasets for linking with the initial release of hydrolinks we have included one global and two u s datasets the hydrolakes dataset messager et al 2016 is a globally comprehensive dataset of lakes over 10 ha for lakes and streams both the nhd plus v2 moore and dewald 2016 and nhd high resolution 1 24k simley and carswell 2009 datasets are included the nhd high resolution includes lakes and streams down to very small sizes 0 1 ha for lakes winslow et al 2014 the nhd plus is based on a lower resolution product 1 100k but includes a great deal of ancillary hydrologic data not covered by the base nhd high resolution dataset that may be useful to many users we have opted not to include nhd medium resolution 1 100k due to its similarity in resolution and coverage as the nhd plus further datasets that are freely available for redistribution may be added in future package updates and upon request 2 1 3 linking methods the r package presented here hydrolinks implements several different hydrologic network linking procedures with some differences based on linking to the network of moving water discussed here as flowlines or bodies of still water here as waterbodies unless noted geographic locations being linked to the network are described as geopoints latitude and longitude pairs on the wgs84 datum all methods return an r data frame object with rows that correspond to linked flowlines and waterbodies with an additional column titled match id corresponding to the matched geopoint supplied by the user for flowline linking hydrolinks implements a single flexible implementation the majority of hydrologic network datasets represent streams and most rivers by lines as opposed to polygons so hydrolinks implements a snap to line linking procedure where a point is snapped to a stream flowline with the link to flowlines function while some supplied geopoints may be geographically close to the snapped flowlines other points may fall a large distance the nearest stream flowline to differentiate between points that fall close enough to a flowline and those that may have erroneous geospatial information hydrolinks differentiates geopoints that fall beyond a user configurable distance from the hydrologic flowlines default 100 m points which fall outside of that distance are not linked to the hydrologic network in certain situations the default may not be sufficient so users can specify a custom maximum distance by specifying the buffer parameter lakes have a different linking strategy than stream linking geopoints can be linked to lakes and reservoirs by a simple point in polygon approach this process identifies which geopoints are contained within any given waterbody polygon this linking procedure is implemented in hydrolakes in the included link to waterbodies function geopoints can also be specifically linked to the waterbody centroids of the chosen hydrologic dataset with a point to centroid approach implemented by the link waterbody centroids function however data describing the location of lakes is sometimes inaccurate or taken at a point which does not overlap with the lake fig 1 two common issues are 1 lake associated data being defined by the centroid of the lake polygon where the centroid lies outside the lake polygon itself fig 1a the non overlapping centroid issue can occur on lakes with non convex polygons e g oxbow lakes 2 points may be taken very near to a lake such as at a boat launch but not geographically over the lake fig 1b these potential issues are handled in two ways 1 link to waterbodies has an optional parameter buffer specified in meters to match geopoints which fall within a buffer around each lake polygon 2 the link waterbody centroids has a user defined maximum distance cutoff buffer defaults to 25 m which allows for a loosening of the restriction on matching geopoints to waterbody polygon centroids 2 2 dataset example to show an example of large scale insights enabled by hydrolinks we examined the spatial quality of data available from one of the largest single sources of aquatic data available the usgs water quality portal wqp read et al 2017 the wqp is an interface to query several u s federal databases of aquatic data including the u s environmental protection agency epa storage and retrieval dashboard storet and the u s geological survey usgs national water information system nwis database we downloaded all national scale lake and stream data available from the wqp using the usgs dataretrieval r package hirsch and de cicco 2015 for stream and lake sites from the wqp we used hydrolinks to link observations to mapped waterbodies using all potential methods stream sites were linked to the nhd using link to flowlines with a buffer of 100 m lake sites were linked in three ways first lake sites were linked using point in polygon link to waterbodies with no buffer only lake sites directly over a waterbody polygon were matched lake sites were also linked using link to waterbodies with a buffer of 25 m finally lake sites were linked using link waterbody centroids with a buffer of 25 m 3 results 3 1 water quality portal example there are a large number of uniquely identified sample sites in the wqp figs 2a and 3 a as of the date of access august 1 2017 there were 149 905 and 547 930 unique sites categorized as lakes and streams respectively table 1 of the reported wqp sites 47 151 lake sites 31 5 and 76 262 stream sites 13 9 did not correspond with mapped hydrologic feature in the high resolution nhd based on the linking procedure used here point in polygon with no buffer for lakes snap to line with 100 m buffer for streams using the point to polygon approach with a 25 m buffer increased the number of linked lake sites by 11 866 7 9 with an additional 206 lakes linked using the point to centroid approach with a 25 m buffer table 1 using a larger buffer for lakes showed diminishing returns beyond 25 m supplemental text 1 the number of lake sites without matches to hydrologic features in the nhd varied spatially across u s states figs 2 and 3 states that appear to have a high linked site density on the visualized map fig 2 tended to have a combination of both a high abundance of lakes and a high numerical coverage percentage for example wisconsin minnesota and michigan all have high numbers of natural lakes winslow et al 2014 and had high percent lake coverage table 2 some state s sampling is dominated by fewer large lakes with a large divergence of percent covered by area and number e g utah maryland and tennessee all have high area but low numerical coverage other notable mentions include florida which has a high density of linked sites visually fig 2a and b and a relatively low percent of total observed lake area table 2 in general the lake sites that did not match waterbodies were distributed similarly to the underlying whole population of lake sites with a few exceptions a few states dominated numerically the lake sites which did not match via point in polygon but did match well with a 25 m buffer fig 2c new hampshire wisconsin and ohio wisconsin had the majority of lakes which matched via centroid fig 2d with only a few scattered among the other states for streams the distribution of match and non match sites had a different spatial distribution compared to linked lake sites fig 3a b table 2 some states followed similar patterns with michigan wisconsin minnesota and maryland having top percent observed numbers for both lakes and streams some states showed large divergence between lake and stream coverage while connecticut was 5th in stream length coverage 8 46 it ranked 44th for lake coverage by area 20 09 visually these different linking densities were not as apparent in streams as in lakes though mapping completion dates and resolution may be an important driver of this discrepancy in stream coverage stats using hydrolinks we examined how the distribution of observed lakes and streams compares to the full contiguous u s distribution fig 4 the median area of observed lakes was 17 05 ha compared to 0 14 ha for the complete distribution of contiguous u s lakes winslow et al 2014 fig 4a stream sampling was similarly skewed towards larger higher order systems except at the highest order systems fig 5 a with a length weighted sampled stream order of 2 44 versus the length weighted whole u s distribution stream order of 0 22 4 discussion hydrolinks automates the multiple manual steps required to link coordinate described data to the hydrologic network facilitating this process can help unify different limnological datasets as well as datasets that are best described in relation to the hydrologic network e g watershed or buffer land use lake morphology and stream flow and order characteristics linking these geopoint sites to the hydrologic network can improve data sharing integration and better describe the geographic and morphological representation of inland waters within the observed data record the wqp example shown here highlights how the tools in hydrolinks can quickly link observations to value added data products here linking the wqp sites to the nhd allowed for the comparison of lake size and stream order for observed versus the full network distribution of lakes and streams not surprisingly observations are generally skewed towards larger aquatic systems lakes and streams as previously noted e g hanson et al 2007 though some size discrepancy may be due to higher required geolocation precision required for small lakes it is difficult to make a simple comparison between the size abundance distribution of lakes and streams using stream order normalized by stream length was generally effective in this situation however this strategy may not work well at stream orders over 10 which showed a drop in coverage that may not be representative largely due to the limited number of these large rivers further tools for hydrologic network linking and verification for lakes and streams could be useful to both data providers and users of aquatic database data in our example we show a number of challenges in linking data from the wqp to the high resolution nhd while the specific reasons that wqp sites failed to link are unclear these points warrant further investigation and possible correction by data providers hydrolinks allows users to quickly verify the wqp latitude longitude metadata and slate non linking site data for further examination or removal for example in the wqp data used here the number of lake linking failures was reduced from 31 5 to 23 6 by including the 25 m buffer indicating many sites are too near the lake shoreline for simple point in polygon linking further of the 21 600 lake sites that did not successfully link to a lake 8000 can likely be explained as mis labelled stream sites supplemental text 1 using such techniques hydrolinks can enable data input quality assurance procedures by providing a quick way to verify newly supplied data to the underlying wqp databases e g storet or nwis or identify and correct existing non linking sites different organizations frequently have their own independent identification system for waterbodies further different organizations often collect data on the same waterbodies or stream reaches but catalog and archive the data using organization specific identification systems for example the u s geological survey frequently adopts the national hydrography network http nhd usgs gov as a unifying identifier for aquatic data but many state and local agencies use local identification schemes for waterbody and stream identification e g wisconsin water body identification codes http wi dnr gov while it is unlikely that states and other local agencies will adopt a more national or global sample site id procedure hydrolinks can nonetheless help unify these datasets when integration is desired e g supplemental text 2 without id based linking name or latitude longitude are often not sufficient or unambiguous enough to integrate hydrologic datasets lake names are extremely ambiguous with the most common lake names used in many locations e g long trout emerald clear or mud lakes data taken from effectively the same lake or stream site can frequently have very different locations based on latitude and longitude this is especially challenging when dealing with datasets from both large and small lakes for example in a large lake data sampled from two locations 5 km distant can be thought of as describing the same aquatic system on the other hand in lake rich regions with many small lakes a 5 km distance may cross many small distinct and heterogeneous lakes further the loss of precision on latitude and longitude that can occur through data handling e g through decimal truncation in excel may cause points to no longer geographically match lakes on the landscape open datasets are more frequently being released using unique identifiers based on hydrologic network dataset identifiers for example recent lake datasets on lake depth oliver et al 2016 and water temperature winslow et al 2017 were released with both nhd unique identifiers and standard latitude and longitude geopoints with hydrolinks users of those datasets can quickly integrate their own and other datasets using the hydrologic network dataset identifiers furthermore this tool will enable future datasets to be released using one or more broadly accessible unique identifiers to unambiguously link data to waterbodies and accelerate data integration across different published datasets hydrolinks joins a number of tools available to better integrate diverse aquatic data sets in scientific computing environments data management especially of large and diverse data sets can take outsized amount of time in scientific data analyses lohr 2014 tools that enable better data access and integration are at the forefront of accelerating environmental science and macrosystem ecological research with the release of hydrolinks we hope to enable better communication and integration of lake and stream datasets at large scales acknowledgements authors thank lesley knoll for providing critical insight and early support that resulted in this project and the development this manuscript s d p and t h h received financial assistance from the pennsylvania department of conservation and natural resources wild resource conservation program grant wrp 15533 t h h also received support from new york state energy research and development authority nyserda agreement no 115876 l a w and k c r received support from the national science foundation grant msb 1638704 appendix a supplementary data the following is the supplementary data related to this article supplementary material supplementary material appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 03 012 
26402,addressing continental scale challenges affecting inland aquatic systems requires data at comparable scales critically local in situ observations for both lotic and lentic ecosystems are frequently fragmented across federal state and local agencies and nonprofit or academic organizations and must be linked to other geospatial data to be useful to advance macro scale aquatic ecosystem science better tools are needed to facilitate dataset integration key to integration of aquatic data is the linking of spatial data to the hydrologic network this integration step is challenging as hydrologic network data are large and cumbersome to manage here we develop a new r package hydrolinks to ease linking aquatic data to the hydrologic network we use hydrolinks to evaluate the spatial data quality for all lake and stream sites available through the u s water quality portal we find that 76 5 of lake sites and 13 9 of stream sites do not correspond with mapped waterbodies keywords r package lakes streams hydrologic network limnology data integration macrosystem ecology software availability name of software hydrolinks developers tobi hahn luke winslow taylor leach kevin rose software required r license mit license availability freely available through cran cran r project org development version at github com lawinslow hydrolinks archived version https doi org 10 5281 zenodo 1169399 1 introduction many of today s challenges in understanding aquatic systems operate at the regional to global scale heffernan et al 2014 addressing these macrosystem scale challenges affecting inland aquatic ecosystems requires data at comparably large scales from climate change impacts e g isaak et al 2016 o reilly et al 2015 to eutrophication and algal blooms e g chapra et al 2017 sinha et al 2017 large regional to global scale insights depend on linking observations across diverse and spatially extensive lake and stream regions broad scale data is particularly important as both geographic and morphological heterogeneity of inland waters and diverse watershed characteristics drive how aquatic ecosystems respond to broad scale forcing e g read et al 2015 soranno et al 2015 winslow et al 2015 to this end researchers have built tools and data systems to automate integration and processing of aquatic data and features e g haag and shokoufandeh 2017 horsburgh and reeder 2014 read et al 2011 some datasets relevant to aquatic research such as land cover jin et al 2013 elevation jarvis et al 2008 and climate dee et al 2011 are well curated and have been made publicly available at continental and global scales but many potentially high value in situ aquatic observations are fragmented across government nonprofit and academic organizations soranno et al 2015 further available datasets are frequently described by latitude longitude coordinates often without clear unambiguous reference to mapped surface water features the lack of unique identifiers or unambiguous linking can make it difficult to connect aquatic data to other in situ datasets or important spatial context information such as land use hydrologic connectivity or waterbody morphology hill et al 2016 using alternative site identification schemes while there have been recent efforts to collect and organize fragmented sources of aquatic data and link them to specific mapped waterbodies most current examples are limited in data type temporal span or confined to a regional spatial extent e g oliver et al 2017 soranno et al 2015 to advance macrosystem aquatic research new tools are needed to accelerate the integration of fragmented data across both lentic and lotic ecosystems one powerful way to integrate fragmented aquatic datasets and connect those data with landscape features is to link in situ aquatic data to mapped surface water features using unique identifiers this allows for the unambiguous communication of the surface water feature from which a data point originates unfortunately available tools to enable linking are only available on specialized geographic information system gis platforms that are often foreign to ecologists and require special training one such example is the u s geological survey s usgs hydrologic event management tool hem https nhd usgs gov tools html which is specific to only the usgs national hydrography dataset additionally the hem tool requires manual handling of the hydrologic network data does not support lakes and needs a local license for the arcgis software package bringing hydrologic network linking to general scientific computing platforms used by aquatic ecologists and generalizing the linking to include multiple commonly used large scale hydrologic network datasets would enable better broad scale data integration thus accelerating macrosystem hydrologic science here we introduce hydrolinks an r package to ease linking of aquatic data with the hydrologic network hydrolinks automates access retrieval and local storage of large hydrologic network datasets including the usgs national hydrologic dataset nhd high resolution 1 24k nhd plus currently 1 100k and the global hydrolakes datasets the package includes a number of algorithms for linking data described by latitude and longitude to the hydrologic network including variable width buffer centroid correspondence and point in polygon linking to provide example uses we demonstrate the functioning of hydrolinks by linking a large national scale aquatic dataset to the u s hydrologic network we then show how linking large datasets to the hydrologic network can enable integration of diverse data sources and highlight potential data quality issues in large federal environmental databases 2 methods 2 1 linking tool the hydrolinks package is built to reduce the complexities of linking aquatic ecosystem data that is described by simple latitude longitude geographic referencing to generally available hydrologic network geographic datasets based on the data and type of hydrologic linking requested the package can automatically download required hydrologic network data to link latitude longitude data points to streams or waterbodies generally lakes or reservoirs here we provide an overview of the linking approaches used and how these large complex data are stored and distributed 2 1 1 data access methods one of the novel aspects of hydrolinks is to enable automatic on the fly data access so the user does not need to download and manage the large hydrologic datasets for linking the hydrologic datasets are split up into small quick to download file sizes 50 mb that represent contiguous regions included in the package are data on the geographic bounding boxes associated with the sub region files of each dataset these bounding boxes are used when executing linking functions to determine which sub region pieces of the hydrologic networks are needed these data are downloaded using simple http from an online source verified complete using an md5 hash and then used in the data linking procedure all downloaded files are locally cached to enable rapid re linking of future data the location of the local cache can be user defined using the local path function this may be useful when an alternative cache drive or path is preferred over the default 2 1 2 current available datasets for linking with the initial release of hydrolinks we have included one global and two u s datasets the hydrolakes dataset messager et al 2016 is a globally comprehensive dataset of lakes over 10 ha for lakes and streams both the nhd plus v2 moore and dewald 2016 and nhd high resolution 1 24k simley and carswell 2009 datasets are included the nhd high resolution includes lakes and streams down to very small sizes 0 1 ha for lakes winslow et al 2014 the nhd plus is based on a lower resolution product 1 100k but includes a great deal of ancillary hydrologic data not covered by the base nhd high resolution dataset that may be useful to many users we have opted not to include nhd medium resolution 1 100k due to its similarity in resolution and coverage as the nhd plus further datasets that are freely available for redistribution may be added in future package updates and upon request 2 1 3 linking methods the r package presented here hydrolinks implements several different hydrologic network linking procedures with some differences based on linking to the network of moving water discussed here as flowlines or bodies of still water here as waterbodies unless noted geographic locations being linked to the network are described as geopoints latitude and longitude pairs on the wgs84 datum all methods return an r data frame object with rows that correspond to linked flowlines and waterbodies with an additional column titled match id corresponding to the matched geopoint supplied by the user for flowline linking hydrolinks implements a single flexible implementation the majority of hydrologic network datasets represent streams and most rivers by lines as opposed to polygons so hydrolinks implements a snap to line linking procedure where a point is snapped to a stream flowline with the link to flowlines function while some supplied geopoints may be geographically close to the snapped flowlines other points may fall a large distance the nearest stream flowline to differentiate between points that fall close enough to a flowline and those that may have erroneous geospatial information hydrolinks differentiates geopoints that fall beyond a user configurable distance from the hydrologic flowlines default 100 m points which fall outside of that distance are not linked to the hydrologic network in certain situations the default may not be sufficient so users can specify a custom maximum distance by specifying the buffer parameter lakes have a different linking strategy than stream linking geopoints can be linked to lakes and reservoirs by a simple point in polygon approach this process identifies which geopoints are contained within any given waterbody polygon this linking procedure is implemented in hydrolakes in the included link to waterbodies function geopoints can also be specifically linked to the waterbody centroids of the chosen hydrologic dataset with a point to centroid approach implemented by the link waterbody centroids function however data describing the location of lakes is sometimes inaccurate or taken at a point which does not overlap with the lake fig 1 two common issues are 1 lake associated data being defined by the centroid of the lake polygon where the centroid lies outside the lake polygon itself fig 1a the non overlapping centroid issue can occur on lakes with non convex polygons e g oxbow lakes 2 points may be taken very near to a lake such as at a boat launch but not geographically over the lake fig 1b these potential issues are handled in two ways 1 link to waterbodies has an optional parameter buffer specified in meters to match geopoints which fall within a buffer around each lake polygon 2 the link waterbody centroids has a user defined maximum distance cutoff buffer defaults to 25 m which allows for a loosening of the restriction on matching geopoints to waterbody polygon centroids 2 2 dataset example to show an example of large scale insights enabled by hydrolinks we examined the spatial quality of data available from one of the largest single sources of aquatic data available the usgs water quality portal wqp read et al 2017 the wqp is an interface to query several u s federal databases of aquatic data including the u s environmental protection agency epa storage and retrieval dashboard storet and the u s geological survey usgs national water information system nwis database we downloaded all national scale lake and stream data available from the wqp using the usgs dataretrieval r package hirsch and de cicco 2015 for stream and lake sites from the wqp we used hydrolinks to link observations to mapped waterbodies using all potential methods stream sites were linked to the nhd using link to flowlines with a buffer of 100 m lake sites were linked in three ways first lake sites were linked using point in polygon link to waterbodies with no buffer only lake sites directly over a waterbody polygon were matched lake sites were also linked using link to waterbodies with a buffer of 25 m finally lake sites were linked using link waterbody centroids with a buffer of 25 m 3 results 3 1 water quality portal example there are a large number of uniquely identified sample sites in the wqp figs 2a and 3 a as of the date of access august 1 2017 there were 149 905 and 547 930 unique sites categorized as lakes and streams respectively table 1 of the reported wqp sites 47 151 lake sites 31 5 and 76 262 stream sites 13 9 did not correspond with mapped hydrologic feature in the high resolution nhd based on the linking procedure used here point in polygon with no buffer for lakes snap to line with 100 m buffer for streams using the point to polygon approach with a 25 m buffer increased the number of linked lake sites by 11 866 7 9 with an additional 206 lakes linked using the point to centroid approach with a 25 m buffer table 1 using a larger buffer for lakes showed diminishing returns beyond 25 m supplemental text 1 the number of lake sites without matches to hydrologic features in the nhd varied spatially across u s states figs 2 and 3 states that appear to have a high linked site density on the visualized map fig 2 tended to have a combination of both a high abundance of lakes and a high numerical coverage percentage for example wisconsin minnesota and michigan all have high numbers of natural lakes winslow et al 2014 and had high percent lake coverage table 2 some state s sampling is dominated by fewer large lakes with a large divergence of percent covered by area and number e g utah maryland and tennessee all have high area but low numerical coverage other notable mentions include florida which has a high density of linked sites visually fig 2a and b and a relatively low percent of total observed lake area table 2 in general the lake sites that did not match waterbodies were distributed similarly to the underlying whole population of lake sites with a few exceptions a few states dominated numerically the lake sites which did not match via point in polygon but did match well with a 25 m buffer fig 2c new hampshire wisconsin and ohio wisconsin had the majority of lakes which matched via centroid fig 2d with only a few scattered among the other states for streams the distribution of match and non match sites had a different spatial distribution compared to linked lake sites fig 3a b table 2 some states followed similar patterns with michigan wisconsin minnesota and maryland having top percent observed numbers for both lakes and streams some states showed large divergence between lake and stream coverage while connecticut was 5th in stream length coverage 8 46 it ranked 44th for lake coverage by area 20 09 visually these different linking densities were not as apparent in streams as in lakes though mapping completion dates and resolution may be an important driver of this discrepancy in stream coverage stats using hydrolinks we examined how the distribution of observed lakes and streams compares to the full contiguous u s distribution fig 4 the median area of observed lakes was 17 05 ha compared to 0 14 ha for the complete distribution of contiguous u s lakes winslow et al 2014 fig 4a stream sampling was similarly skewed towards larger higher order systems except at the highest order systems fig 5 a with a length weighted sampled stream order of 2 44 versus the length weighted whole u s distribution stream order of 0 22 4 discussion hydrolinks automates the multiple manual steps required to link coordinate described data to the hydrologic network facilitating this process can help unify different limnological datasets as well as datasets that are best described in relation to the hydrologic network e g watershed or buffer land use lake morphology and stream flow and order characteristics linking these geopoint sites to the hydrologic network can improve data sharing integration and better describe the geographic and morphological representation of inland waters within the observed data record the wqp example shown here highlights how the tools in hydrolinks can quickly link observations to value added data products here linking the wqp sites to the nhd allowed for the comparison of lake size and stream order for observed versus the full network distribution of lakes and streams not surprisingly observations are generally skewed towards larger aquatic systems lakes and streams as previously noted e g hanson et al 2007 though some size discrepancy may be due to higher required geolocation precision required for small lakes it is difficult to make a simple comparison between the size abundance distribution of lakes and streams using stream order normalized by stream length was generally effective in this situation however this strategy may not work well at stream orders over 10 which showed a drop in coverage that may not be representative largely due to the limited number of these large rivers further tools for hydrologic network linking and verification for lakes and streams could be useful to both data providers and users of aquatic database data in our example we show a number of challenges in linking data from the wqp to the high resolution nhd while the specific reasons that wqp sites failed to link are unclear these points warrant further investigation and possible correction by data providers hydrolinks allows users to quickly verify the wqp latitude longitude metadata and slate non linking site data for further examination or removal for example in the wqp data used here the number of lake linking failures was reduced from 31 5 to 23 6 by including the 25 m buffer indicating many sites are too near the lake shoreline for simple point in polygon linking further of the 21 600 lake sites that did not successfully link to a lake 8000 can likely be explained as mis labelled stream sites supplemental text 1 using such techniques hydrolinks can enable data input quality assurance procedures by providing a quick way to verify newly supplied data to the underlying wqp databases e g storet or nwis or identify and correct existing non linking sites different organizations frequently have their own independent identification system for waterbodies further different organizations often collect data on the same waterbodies or stream reaches but catalog and archive the data using organization specific identification systems for example the u s geological survey frequently adopts the national hydrography network http nhd usgs gov as a unifying identifier for aquatic data but many state and local agencies use local identification schemes for waterbody and stream identification e g wisconsin water body identification codes http wi dnr gov while it is unlikely that states and other local agencies will adopt a more national or global sample site id procedure hydrolinks can nonetheless help unify these datasets when integration is desired e g supplemental text 2 without id based linking name or latitude longitude are often not sufficient or unambiguous enough to integrate hydrologic datasets lake names are extremely ambiguous with the most common lake names used in many locations e g long trout emerald clear or mud lakes data taken from effectively the same lake or stream site can frequently have very different locations based on latitude and longitude this is especially challenging when dealing with datasets from both large and small lakes for example in a large lake data sampled from two locations 5 km distant can be thought of as describing the same aquatic system on the other hand in lake rich regions with many small lakes a 5 km distance may cross many small distinct and heterogeneous lakes further the loss of precision on latitude and longitude that can occur through data handling e g through decimal truncation in excel may cause points to no longer geographically match lakes on the landscape open datasets are more frequently being released using unique identifiers based on hydrologic network dataset identifiers for example recent lake datasets on lake depth oliver et al 2016 and water temperature winslow et al 2017 were released with both nhd unique identifiers and standard latitude and longitude geopoints with hydrolinks users of those datasets can quickly integrate their own and other datasets using the hydrologic network dataset identifiers furthermore this tool will enable future datasets to be released using one or more broadly accessible unique identifiers to unambiguously link data to waterbodies and accelerate data integration across different published datasets hydrolinks joins a number of tools available to better integrate diverse aquatic data sets in scientific computing environments data management especially of large and diverse data sets can take outsized amount of time in scientific data analyses lohr 2014 tools that enable better data access and integration are at the forefront of accelerating environmental science and macrosystem ecological research with the release of hydrolinks we hope to enable better communication and integration of lake and stream datasets at large scales acknowledgements authors thank lesley knoll for providing critical insight and early support that resulted in this project and the development this manuscript s d p and t h h received financial assistance from the pennsylvania department of conservation and natural resources wild resource conservation program grant wrp 15533 t h h also received support from new york state energy research and development authority nyserda agreement no 115876 l a w and k c r received support from the national science foundation grant msb 1638704 appendix a supplementary data the following is the supplementary data related to this article supplementary material supplementary material appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 03 012 
26403,the concentration in time and space of tourists and of specific water demanding touristic activities can add considerable pressure on available water supplies in coastal regions the impact of tourism has not been adequately addressed in the water demand literature especially at sub annual scale the present study includes the role of tourism on the monthly water demand in a set of mediterranean coastal municipalities in a panel data framework the influence of both climatic and touristic drivers on the water demand is investigated through a correlation analysis thus deconstructing the seasonal variability of the consumption and the development of both linear and non linear models the results demonstrate the improvement allowed by non linear over linear modelling and the value of the information embedded in both climatic in particular temperature daily maxima and minima and number of rainy days and touristic determinants as drivers for the water demand at sub annual scale keywords water demand modelling residential water uses tourism climate correlation analysis panel data 1 introduction in mediterranean regions inherently affected by water scarcity conditions the gap between water availability and demand is expected to further increase in the near future due to both climatic and anthropogenic drivers in particular the high degree of urbanization and the concentration of population and activities in many coastal areas is often severely impacting the water availability also for the residential sector especially in the dry summer season when the demand is maximum and the water availability is minimum eea 2010 confirming that socio economic in addition to climatic changes will be the most important driver of shifts in future municipal water demand parkinson et al 2016 water demand forecasting is the primary requirement for managing and planning of water supply systems short term forecasting over the coming days weeks or months allows to optimise operational water management decisions reservoir storages emergency measures during water scarcity periods etc and to help estimate revenues from water sales and short term expenditures i e energy pumping costs long term forecasting allows instead to plan the investments on water supply and distribution systems such as accessing new water sources developing new treatment plans or enhancing the distribution networks many water utilities still assume that the demand will evolve simply as a product of per capita demand and a projection of population whereas the predictive power of such methods is inadequate under changing conditions it is therefore now acknowledged that in order to obtain reliable demand forecast it is important evaluating understanding and modeling the factors that influence water use over both short term and long term intervals awwa 2013 urban water demand is guided by complex interactions between human and natural system variables at multiple spatial and temporal scales in the past many studies have focused only on economic and other policy variables that can be decided by policy makers and water utilities so that their future evolution is known but there is the need to keep into account also the factors that are not controlled by the water utilities and are characterized by an uncertain evolution climate is certainly one of such factors a large number of studies see section 2 1 have analysed the causal relationships between the demand and a number of different climatic variables and have developed urban demand models that include such drivers in the explanatory variables these models can successively be used by the water utilities to forecast the future water demand as a function of the predicted evolution of the meteorological variables consisting in either long term climate change scenarios or short term seasonal forecasts as far as the impact of climate change and variability is concerned understanding and modelling the influence of meteorological factors on urban demand is the first step for assessing the long term pressure on the water supply system due to expected climatic scenarios this approach is followed for example by goodchild 2003 babel et al 2014 haque et al 2015b who first set up demand models driven by meteorological factors and then provide in input the same drivers obtained from climate change scenarios analogously for the purpose of operational management decisions identifying the role of the whether variables in a monthly water demand model would immediately allow the inclusion of inputs deriving from weekly to seasonal meteorological forecasts even if such numerical weather predictions are still affected by very large uncertainties over lead times longer than a few days thus resulting in improved short term water demand forecasts tian et al 2016 have recently proposed for the first time the use of weekly weather forecasts in input to a water demand model a full understanding of which variables are significant is a necessary prerequisite for improving the demand models in coastal regions but not only there a very important factor in addition to climatic determinants is the influence of tourism on water use such factor has not been adequately addressed in the literature so far and is generally neglected in water demand analyses provided that an estimate on the expected touristic fluxes is available for example through one of the many tourism demand forecasting models available for the tourism industry also such variables might be directly used in input to the proposed model to obtain a more accurate water demand forecast the present work for the first time introduces the use of the time series of the monthly tourists overnight stays as an additional explanatory variable to model monthly urban water demand in order to provide knowledge on the combined impacts of climatic and touristic factors the case study refers to a set of cities in italy where sub annual analyses are so far not reported in the literature and in particular to the most economically developed coastal region in the country in such and similar contexts the proposed water demand models may be successively used by water utilities to derive more accurate water demand forecasts based on the available climatic and touristic evolution scenarios 2 factors driving urban water demand there is abundant theoretical and empirical literature on urban water demand modelling at different spatial household to municipal and temporal hourly to multi yearly scale the readers may refer to house peters and chang 2011 or donkor et al 2014 for comprehensive reviews of concepts and models a variety of determinants exogenous inputs may have an impact on water demand and have been considered in the literature in addition to information on previous consumptions endogenous input structural and geographical variables such as household or building landscape features and socio economic variables such as population characteristics water price and consumer income water use behaviour the majority of the above variables are not subject to seasonal fluctuations or even when not negligible such sub annual fluctuation is generally not recorded and are considered to change at annual scale allowing to analyse inter annual variability only for modelling the overall behaviour of the demand over time it is instead necessary to take into account not only factors that change from year to year interannual but also the factors that have a seasonal or monthly variation in order to capture also the infra annual expected variations in the demand such as climatic variables and tourism 2 1 influence on water demand of climatic drivers when analysing a sub annual behaviour and the objective is to assess the reasons for seasonal changes in the demand the main influence is generally attributed to climatic variables rainfall temperature evapotranspiration as demonstrated by a very large number of studies analysing and modelling the role of such variables see among the many others zhou et al 2000 gutzler and nims 2005 gato et al 2007 wong et al 2010 bakker et al 2013 and in particular chang et al 2014 and haque et al 2015a also present excellent reviews on the use of climatic determinants it is in fact expected that weather conditions do influence the intensity and or the frequency of important water demanding activities both indoor such as showers and other personal hygiene practises and outdoor such as garden plants irrigation but also car and street washing or swimming pool use temperature and rainfall variables are the most frequently adopted in water demand modelling also due to the good availability of such measures estimates on the other hand derived variables such as evapotranspiration estimates are relevant for only a part of the above mentioned water consuming activities i e irrigation activities for evapotranspiration factors temperature and rainfall can be adopted in several forms in the water demand modelling see haque et al 2015a temperature indexes may be based on mean values or on daily maxima and minima or on the numberof days exceeding a certain threshold in the same way rainfall indexes may include total rainfall depth the number of rainy days or rain events or the duration between the events identifying the temperature and rainfall indexes more suitable for each specific water demand modelling analysis is therefore still an open problem and even more important the outcomes of previous studies on the impact of climatic variables are not always in agreement some studies found that the demand is both positively related to the temperature and negatively related to the rainfall maidment and miaou 1986 lyman 1992 corral et al 1998 olmstead et al 2007 ruijs et al 2007 other authors nauges and thomas 2000 martins and fortunato 2005 haque et al 2015a 2015b showed that high temperatures increase the demand but did not find a significant effect of the precipitation on the contrary in the case studies analysed by zhou et al 2000 klein et al 2007 and schleic and hillenbrand 2009 precipitation was more important than temperature in particular it seems that the touristic vocation of the study area may play an important role in assessing the importance of the meteorological variables and in understanding their influence in fact in not touristic cities rainfall and temperature may do not exert a significant weight on the water demand see martinez espiñeira 2002a b or actually in some cases it was even found a wrong sign that is a negative correlation between temperature and consumption this happened when considering areas that are not highly touristic or at least not during the summer season like the city of zaragoza in spain arbués and villanua 2006 or the german areas analysed by schleic and hillenbrand 2009 the authors identify as a possible explanation the fact that consumption decreases in summer due to the outflow of residents to holiday destinations on the contrary therefore we expect for the reasons stated above that in coastal touristic regions during the summer climatic variables are especially relevant due to the specific touristic water uses 2 2 influence on water demand of touristic drivers tourism is strongly dependent on fresh water resources and its contribution to water consumption is expected to rise due to increases in tourists numbers in hotel standards and in water intensity of tourism activities as highlighted also in the review at global scale presented by gossling et al 2012 exacerbating this impact in coastal regions is the fact that the majority of tourists arrive during the above said critical summer season thus adding considerable strain on available water resources tourism is one of the world s largest industries according to the world travel tourism council wttc 2016 the travel and tourism sector accounts for 9 8 of world gdp and for 108 million jobs in 2015 equal to 5 of total employment that in line with the positive dynamics of arrivals and revenues should further increase of 2 6 over the next decade coastal tourism is one of the fastest growing forms of tourism all over the world page and connell 2006 and in many european and in particular italian regions it has turned into mass tourism already starting in the 1950s on the other hand tourism is also a massive consumer of natural resources water included tourism has in fact a strong influence on urban water consumption first the demand of water for residential uses can be substantially inflated by the presence of tourists to be added to the population to be supplied secondly tourists consumption is different from that of residents see gossling et al 2012 a more lavish use allowed by more leisure time and also related to the fact that water is not included in the hotel or rental bill and price has therefore no limiting influence is in particular enhanced in seaside cities by the habit of additional showers after swimming also the laundry requirement due to the much more frequent changes of bed and bath linens that characterizes touristic rather than residential presences is further increased in seaside resorts by the use of large towels for swimming pools and beach activities thirdly coastal cities are characterised by the presence of specific activities connected with the tourism economy that may be extremely demanding in terms of water requirements not only spas and swimming pools but also for example waterparks in the study area there are six important waterparks with around one million visitors per year furthermore more frequent irrigation is needed for hotel and city gardens and landscaping whose attractiveness is an important asset in a touristic city due to the second and third above points if we want to fully take into account the tourism impact the number of tourists cannot be added directly to the number of permanent residents when modelling the change in water demand not only the water use of holiday makers is different from that of residents but an additional complexity lies in the fact that in touristic cities there are water volumes that have to be supplied irrespective of the number of guests garden irrigation pools waterparks the literature on the impact of touristic variables on urban water demand is very limited and at sub annual scale almost non existent the only notable exception to our knowledge is the study by almutaz et al 2012 that proposes a monthly forecasting model for the city of mecca where very large touristic fluctuations are determined by the religious rituals such study takes into account in addition to other determinants also climatic variables but the touristic presence is considered only through the probability distribution of the number of tourists expected during the year in agreement with the religious calendar and not as an explanatory variable since monthly touristic time series are not available on the other hand it must be underlined that such religious tourism is not directly related to weather conditions as it happens instead in seaside cities as those analysed in the present study in light of the above considerations in a number of increasingly water scarce and touristically exploited regions additional research is necessary on the role of tourism as well as meteorological variables as determinants of water consumption and it is important to carry out such analyses at an appropriate temporal and spatial scale gossling et al 2012 this study contributes to the advancement of knowledge on determinants of water demand at sub annual scale by focusing on a mediterranean highly touristic coastal area and analysing a set of municipalities in a panel data framework 3 study region and data 3 1 study region it is worth noting that in the literature on water demand modelling the majority of case studies refer to north america or australia with a minority of recently published case studies referring to european countries and in particular there are only a few european studies based on intra annual data see worthington and hoffmann 2008 the same unbalanced geographical distribution of the studies was found by cominola et al 2015 in their review on the literature on high resolution water demand modelling and management where only 13 of the reviewed papers presented studies developed in europe but we agree with the authors that driven by the challenges posed by both climatic and anthropogenic factors on urban water supply increasing attention will be paid to such analyses all over the world as far as italy in particular is concerned infra annual water consumption data are generally not available and are often affected by low quality and reliability the national authorities still do not publish official data and analyses of water consumption in italy have been so far possible only with the collaboration of one or more water companies the research on water demands in italian cities is mainly based on annual data mazzanti and montini 2006 musolesi and nosvelli 2007 statzu and strazzera 2009 romano et al 2014 the study area analysed in this work includes all the municipalities on the coastline of the romagna region in northern italy which is one of the most economically developed areas in europe and characterized by an extremely profitable seaside tourist industry it is in fact one of the most attractive touristic areas in the country and the national and international tourists spend in the official accommodation facilities of the analysed cities around 27 million of nights every year mainly concentrated in the summer months corresponding to 7 of all the overnight stays in italy over the analysed years romagnaacque società delle fonti is the regional water supplier and it provides wholesale water to the main retail water company in the three provinces of ravenna forlì cesena and rimini with a total of more than one million permanent residents 3 2 monthly water demand data the water demand data used in the study have been made available by romagnaacque that collects the consumption data at monthly scale for all the towns of the three provinces since relevant uncertainty characterizes the information referring to many municipalities we decided to focus only on the coastal towns where almost half of the permanent residents and the large majority of tourists resides some of such municipalities are very close to each other and the same junction of the water supply network may serve more than one municipal administration in such cases s mauro and riccione denoted with an asterisk in the map in fig 1 more municipalities have been aggregated based on hydraulic boundaries the final list of municipalities or grouped municipalities includes from north to south ravenna cervia cesenatico s mauro including also savignano gatteo and gambettola bellaria rimini and riccione including also misano and cattolica the municipalities boundaries are shown in fig 1 the dependent variable used in the analysis is the monthly average consumption wdem per town collected for the period 7 years from 2009 to 2015 and expressed in cubic meters per month then transformed in an average daily volume m3 day for that month due to the crucial importance of the volumes supplied during the summer touristic season when it is also much more important the influence of the climatic see also gutzler and nims 2005 and touristic drivers the analysis considers only the five months from may to september fig 2 shows the water demands during all the summer months of the observation period for the seven municipalities 3 3 monthly tourists presence data in italy there is a monthly census of the guests hosted in the official touristic accommodation facilities such as hotels bed and breakfast etc the establishment owners are asked to provide such data in real time along with the billing documents this data are aggregated for privacy reasons at municipal level and then published in provincial level nuts 3 databases such data report the number of monthly overnight stays but only in official accommodation facilities the tourism statistics in fact do not include any information on the occupancy of second homes holiday homes and not even on the majority of rental homes of which only a very small percentage is officially registered as far as the towns of the emilia romagna are concerned guizzardi 2005 proposed an indirect estimation of the touristic presence in holiday homes based on the measurements of electric power consumption in households that were not officially occupied by permanent residents based on his assessment at annual level of the total number of nightstays in each municipality we have estimated the second homes occupancy for each month assuming that the tourists lodged in unofficial accommodation facilities vary proportionally to the monthly presences in official structures even if we acknowledge the high uncertainty of such assumption including both official and not official tourists overnights the total population to be supplied in the summer months increases of additional 228000 people on average considering the peak month in every day of august the tourists to be added to the around 492000 permanent residents varies from 373000 to 391000 over the observation years 78 on average 3 4 monthly rainfall and temperature data the climate on the romagna coast is warm and temperate with annual rainfall between 550 and 750 mm and a mean annual temperature between 12 and 14 c summer months are warm but not necessarily dry for the observations period 2009 2015 we have collected daily rainfall and temperature data in the weather stations owned and managed by the regional meteorological and hydrological service arpae simc the point measurements were spatially averaged with an inverse distance weighting approach thus obtaining for each municipality 1 monthly rainfall depths 2 number of rainy 1 mm days 3 monthly average of maximum daily temperatures 4 monthly average of minimum daily temperatures such climatic variables have been chosen based on the literature results that highlight the importance of the rainy days occurrence in fact there is general agreement on the usefulness of considering not only the total rainfall depths but also the number of rainy days that was found by many authors maidment and miaou 1986 martınez espiñeira 2002 schleich and hillenbrand 2009 to be a better explanatory variable than the total rainfall amount other studies highlight instead the possible influence of both day maximum and night minimum temperature data see guhathakurta and gober 2007 praskievicz and chang 2009 3 5 annually varying factors number of residents and water price data for each italian municipality the data on permanent residents are updated and published every year and in the study municipalities there is a slight population increase over the years as far as water price is concerned even if water may be considered an ordinary good its demand is expected to decrease when price increases its price elasticity can be very low especially for higher income countries dalhuisen et al 2003 statzu and strazzera 2009 romano et al 2014 on the other hand garcía valiñas 2005 observed higher price elasticity in peak summer than in off peak periods all other seasons the italian water price as in many countries is based on a complex increasing blocks tariff structure the problem of how to estimate the price elasticity in presence of complex tariff structures is still open in the literature and we decided to use as proxy for water tariff the volumetric price euro for cubic meter of the central block of the tariff structure there are three blocks for residential use that generally includes the large majority of the consumers volumes representing the core of the tariff policy overall our data base includes the variables listed in table 1 whose mean values are reported in table 2 climatic and touristic variables have seasonal i e monthly fluctuations like the water demand whereas number of residents and tariff change at yearly scale and are therefore constant for all the months of the same year the variables wdem tour raind and rdays corresponding to monthly cumulative totals are divided by the number of days in each month so to make all the determinants independent of the length of the different months and the data thus represent the values for an average day in the considered month t 4 methodology and results 4 1 correlation analysis in order to investigate the drivers of the seasonal fluctuations of the water demand we analyse for each municipality the correlation existing between the water demand in the five summer months and the seasonally varying predictors table 3 shows the ranges maximum and minimum values obtained for the different municipalities of the correlation coefficients and corresponding p values obtained relating the predictand wdem with tour raind rdays tmax and tmin all the predictors for all the municipalities are significantly correlated with water demand the number of tourists is as expected strongly positively related with the consumption the temperatures are also very highly correlated with a positive sign thus showing that in a coastal touristic area where residents do not leave the city in the hottest months an increase in temperature causes an increase in the water volumes differently from the case studies analysed by arbues and villanua 2006 for the city of zaragoza by schleic and hillenbrand 2009 for a set of german supply areas and by romano et al 2014 for the main italian chief towns also both the variables describing the rainfall total rainfall depth and number of rainy days have a correlation in this case of negative sign indicating a reduction of consumptions with increasing rain but the correlation of the total rainfall depth raind is less significant than for the other seasonal variables with a p value larger than 1 for four over seven cities on the other hand also the seasonal variables are highly intercorrelated table 4 shows the maximum and minimum values over all the municipalities set of the correlation coefficients computed between each couple of seasonally varying predictors since the explanatory variables are intercorrelated some of them might not contribute with additional information content to the determination of the demand we will therefore explore their role through the application of the panel data modelling carrying out an input saliency analysis 4 2 panel data model structure the studies that present water demand models at monthly or sub monthly scale usually refer to a single spatial entity metropolitan area city or district in econometrics water consumption studies generally developed at annual scale it is instead frequent using a cross section of entities cities taking into account the socioeconomic characteristics of the different cities measured at the same time instant and assumed to be time invariant and the elasticities i e the responsiveness of the predictand to a change in the value of the explanatory variables or determinants are supposed to represent their long term value panel data or pooled or time series cross section tscs analysis combines time series for several cross sections pooled data are characterized by having repeated observations more years on fixed units municipalities this increases the number of observations enhancing the quality and quantity of data and this is especially needed when as in the present case study the number of observation years is unfortunately limited additional more informative data help to overcome problems of multicollinearity to control for unobservable heterogeneity of the cross sectional units and to estimate more reliable parameters arbues et al 2003 gujarati 2004 to the authors knowledge a part from the study based on linear regression analysis by martinez espineira 2002a b there is no literature on the use of a panel data approach that models urban water demand at subannual monthly scale in reference to a set of cities cross section analysis the data analysed in this work has a balanced panel structure and the model can be written as 1 y i t f x i t z i ε i t where i indexes individual municipalities and t indexes time periods months y i t is the dependent variable water demand in the summer month t x i t is a vector of time varying regressors cross sectional time series variables changing in time and in space z i is a vector of time invariant regressors cross sectional time invariant variables and ε i t is the error term time invariant variables z i may be very important to explain the specificity of each entity the municipalities of our study area are extremely different not only in relation to the time varying variables we are considering as predictors but in many physical and socio economic features that we here assume to be time invariant we hypothesise that such specificity is fully captured by one variable only meanm i i e the mean value of the demands in the same month in the available years excepting the year over which we are modelling the demand in the split sample validation approach described later on for the given city 2 z i m e a n m i t 1 n 1 w d e m t i t m o n t h m o f o t h e r y e a r s n 1 such value represents also the best information available in the operational practice for the water company to model the expected monthly demands the present study aims at assessing the potential of exploiting additional information in order to improve such standard of reference estimate our models have therefore the following form 3 w d e m i t f r a i n d i t r d a y s i t t m a x i t t m i n i t t o u r i t r e s i t t a r i t m e a n m i ε i t in the panel data framework all the data predictors and predictand referring to the seven municipalities are merged in an unique data set that is thus formed by a number of records equal to 7 times the number of records available for each city all models are applied in a cross validation procedure with a rigorously independent calibration and test data set i e test data are not used for estimating the parameters of the models given the limited number of observation years we have applied a leave one out split sample calibration procedure where for modelling the water demand in the five summer months of one year all the data referring to such year test year for all the municipalities are removed from the calibration set used to parameterise the model the calibration period is thus formed by the data of all the remaining years the calibrated model is successively applied over the independent test year to assess its performance in validation the procedure is repeated using every year one at a time as independent test period 4 3 linear models stepwise regression the first implemented model is a multiple linear one like for example in haque et al 2015a with a stepwise regression approach where regressors are added or removed one at a time until no additional regressor can be added to improve the model the model is assessed based on the sum of squared errors criterion with p values of the f statistics used to decide if adding or removing a predictor equal corresponding to 0 05 and 0 1 respectively the final selected linear model structure denoted in the following as swrm excludes the following variables permanent residents res rainfall depth raind and both the temperatures tmax and tmin including instead the other four input variables tar tour rdays meanm with the last one as the most significant one and first to be included in the stepwise procedure it appears therefore that when modelling the water demand with a linear regression the role of the number of residents of the rainfall depth and more surprisingly also that of the temperature are already included in the values of the mean demand rainy days tariff and presence of tourists on the other hand the relation among water demand and the explanatory variable function f of equation 3 is not necessarily linear on the contrary we do expect a non linear influences of the climatic variables see maidment and miaou 1986 or miaou 1990 and this also affects the relative influence of the explanatory variables 4 4 non linear models artificial neural networks input saliency analysis non linear models based on artificial neural network ann architectures were tested to model the water demand in the five summer months numerous studies have successfully applied ann in water demand modelling in the recent years among others grino et al 1992 jain et al 2001 jain and ormsbee 2002 liu et al 2003 bougadis et al 2005 adamowski 2008 ghiassi et al 2008 firat et al 2009 adamowski and karapataki 2010 adamowski et al 2012 babel et al 2014 artificial neural networks are massively parallel and distributed information processing systems composed of nodes arranged in layers which are able to infer a non linear input output relationship ann in particular feedforward networks have been widely used in many hydrological and water resources applications see for example the recent review papers by maier et al 2010 by abrahart et al 2012 and the readers may refer to the abundant literature for details on their characteristics and implementation the models applied here are networks formed by one hidden layer with tan sigmoid activation functions and a single output node corresponding to the wdemt i to be estimated with a linear activation function the training algorithm minimizing a learning function expressing the closeness between observations and ann outputs in the present case the mean squared error is the newton levenberg marquardt backpropagation algorithm in order to avoid overfitting which degrades the generalization ability of the model a bayesian regularization of the learning function foresee and hagan 1997 was applied also the panel data regional anns were implemented in a fully independent cross validation leave one out procedure for each year or better for each summer season to be modeled the data of the months of the other summer seasons are used for the training for each validation year the ann is trained starting from 10 different initial networks randomly initialized each one of the trained networks provided their performance over the calibration data is considered acceptable i e with a coefficient of determination greater than 0 9 is then fed by the input variables for each of the municipality of the test year independent data and the water demand of the test year is finally obtained averaging the resulting ann outputs the first implemented ann model has in input all the predictors of eq 3 ann all inputs successively since the stepwise linear regression procedure indicated that number of residents res rainfall depth raind and both the temperature indexes tmax and tmin appeared to be redundant we have carried out an input saliency analysis testing other networks where such input variables are removed one at a time denoted as ann m1 to m4 fig 3 shows the performances in terms of both mae mean absolute error and rmse root mean square error of the stepwise regression model swrm and of the ann models as a term of reference the figure shows also the errors of the naïve model that assumes that the water demands for a given month of the test year is equal to the mean of the monthly demands of the remaining calibration years meanm the mae and rmse indicate that only the removal of the rainfall depth m1 no raind improves the performance of the non linear models whereas removing the values of res tmin and above all tmax actually deteriorates the performance in validation this finding in line with the result on the significance of raind vs wdem obtained in the correlation analysis confirms what emerged also in other studies that is that the total rainfall depth has not a significant impact on water consumption which is instead more affected by rainfall occurrence rdays also the important role of both mean day and night temperatures is confirmed as far as our case study is concerned as an additional test the removal not only of raind but also of each one of other three predictors was tested but there was no additional improvement in the modelling performance in validation in respect to model ann m1 the figure also highlights that the ann non linear models with the exception of the one that does not include tmax outperform both the naïve mean m and the linear regression approach and that in turn swrm is better than meanm thus demonstrating i the importance of including the influence of both weather and touristic explanatory variables for estimating the water demand and ii that such relation appears to be better captured by a non linear model in order to better analyse the modelling capability of the implemented approaches fig 4 shows the disaggregation of the mean absolute error over the different municipalities left panel and over the different months right panel comparing the meanm the linear regression model and the best performing ann the right hand panel of fig 4 indicates that there is a gain allowed by the inclusion of the time varying predictors for every month of the season such gain is the highest for the critical august month whereas it s hardly noticeable for june that appears to be less fluctuating over the years the left panel of fig 4 shows that the highest benefit from the inclusion of the time varying explanatory variables xt i is obtained for the city of rimini one of the most important touristic city in italy whose estimates are shown in fig 5 and secondarily for the municipalities of ravenna and riccione on the other hand for two municipalities bellaria and cesenatico the left hand panel of fig 4 shows that assuming a water demand equal to the mean on the remaining years meanm would be better than the application of the proposed models and for s mauro the improvement is negligible in these cities the smallest of the set the water demand is the less fluctuating from one year to the other and the demands over the different years have the lowest discrepancy from the mean values so that the influence of the time varying determinants is limited since the approach is a panel one each one of the pooled models attempts to mimic simultaneously in addition to the behaviour of such relatively stable municipalities also the behaviour of all the other cities where the monthly water demand fluctuations are much stronger as may be seen for example for the city of rimini it follows that the ann and the swrm model tends to assign also over the less fluctuating municipalities an overestimated influence of the variations in the seasonal predictors thus resulting in a deterioration in comparison with the use of meanm alone for bellaria and cesenatico 5 conclusions the study has analysed the monthly residential water demand referred the municipalities of one of the most important touristic areas in europe where it is extremely important to assess the significance of the water use drivers in particular during the critical summer season beyond the explanatory variables proposed in the past literature including climatic drivers the work has introduced tourism as an important factor that may affect water consumption such factor has been so far neglected in urban water models and its influence is not well documented yet also due to the lack of information at sub annual scale the correlation analysis carried out for all the study cities between the water demand in the summer months and the seasonally varying predictors in order to understand their influence showed that the consumption indeed increases very much with the number of tourists furthermore differently from other non touristic areas in a coastal area where residents do not leave the city in the hot summer months an increase in temperature always causes a significant growth in the water volumes on the other hand the rainfall occurrence number of rainy days has an highly significant negative correlation for all the municipalities while the total rainfall depth does not always exert an equally strong significant effect on the demand in line with similar results obtained in the literature the panel data water demand modelling demonstrates the added value of the inclusion of the determinants analysed in the study if compared with the monthly estimate given solely by the mean value of the demand over the same month of the other years that is the estimate currently used by the water company and that implicitly ignores the influence of the changing climatic economic and societal conditions on the demand in a panel data approach there is not a different model tuned to fit each single city but only one model that simulates the water demand aggregated at municipal scale for all the cities included in the panel the model may therefore be used to simulate also the demand for a city that is not included in the set of cities used to parameterised it provided that such demand is guided by the same underlying causal relationships when comparing the modelling approaches the results show that the non linear model based on an artificial neural network architecture outperforms the linear regression indicating that the influence of the identified predictors appears to be better captured by non linear causal relationships the input saliency analysis for the non linear models has shown that the best performances are obtained when the following exogenous variables are added in input to the model residents tariff number of tourists both day and night temperatures and number of rainy days instead the total rainfall depth is not included in the set of significant drivers identified by the input saliency analysis confirming the results of the correlation analysis in light of the above considerations and of the promising results we believe that additional research on the role of tourism in addition to meteorological variables as determinants of water consumption at seasonal and finer time scale is useful and necessary lack of data currently hinders the development of such analyses and the number of available data is also one of the main limitations of the present study in italy and in many other countries infra annual water consumption data are generally not accessible and often affected by low quality and reliability more complete information is especially needed on water uses by tourists and by specific touristic activities in particular more detailed data on the number of tourists lodged out of official accommodation facilities would be required to fully capture such important phenomenon additional knowledge on the sub annual determinants will help to better understand and model the expected consumption such improved models may be of great help to water utilities to forecast water demand when factoring in the possible evolution of the explanatory variables through climate meteorological and tourism forecast scenarios in order to improve the water supply management policies and practices possible future research stemming from this study includes i exploring the use of numerical weather predictions and of tourism forecasting models for weekly to seasonal urban water demand forecasts over the study area and ii investigating urban water security under changing long term climate and tourism projections such analyses may be needed at aggregated scale for forecasting the need of all the cities supplied by the same water sources or at local scale for planning the evolution and management of the distribution network this kind of analyses in addition to being needed by the water managers may also help to increase the resilience of tourism business to water scarcity risks thus allowing a long term sustainability of mass and quality tourism in the romagna seaside cities and in other highly developed coastal areas eurostat 2009 software data availability the analyses have been developed within the matlab mathworks software development platform the scripts are available upon request from the first author the information on tourists overnight stays and the rainfall and temperature data are public and the data set used in the study are available upon request from the first author whereas the data on water consumptions are based on measurements that are not public and have been provided by romagna acque società delle fonti spa acknowledgements water supply data and precious advice were provided by andrea gambi ceo and giuseppe montanari gilberto forcellini and paolo mazzoli water production sector of romagna acque società delle fonti spa whose help is greatly appreciated the work was partially developed within the framework of the panta rhei research initiative of the international association of hydrological sciences iahs working group on data driven hydrology the authors also wish to thank the editor and the two anonymous referees for their constructive comments 
26403,the concentration in time and space of tourists and of specific water demanding touristic activities can add considerable pressure on available water supplies in coastal regions the impact of tourism has not been adequately addressed in the water demand literature especially at sub annual scale the present study includes the role of tourism on the monthly water demand in a set of mediterranean coastal municipalities in a panel data framework the influence of both climatic and touristic drivers on the water demand is investigated through a correlation analysis thus deconstructing the seasonal variability of the consumption and the development of both linear and non linear models the results demonstrate the improvement allowed by non linear over linear modelling and the value of the information embedded in both climatic in particular temperature daily maxima and minima and number of rainy days and touristic determinants as drivers for the water demand at sub annual scale keywords water demand modelling residential water uses tourism climate correlation analysis panel data 1 introduction in mediterranean regions inherently affected by water scarcity conditions the gap between water availability and demand is expected to further increase in the near future due to both climatic and anthropogenic drivers in particular the high degree of urbanization and the concentration of population and activities in many coastal areas is often severely impacting the water availability also for the residential sector especially in the dry summer season when the demand is maximum and the water availability is minimum eea 2010 confirming that socio economic in addition to climatic changes will be the most important driver of shifts in future municipal water demand parkinson et al 2016 water demand forecasting is the primary requirement for managing and planning of water supply systems short term forecasting over the coming days weeks or months allows to optimise operational water management decisions reservoir storages emergency measures during water scarcity periods etc and to help estimate revenues from water sales and short term expenditures i e energy pumping costs long term forecasting allows instead to plan the investments on water supply and distribution systems such as accessing new water sources developing new treatment plans or enhancing the distribution networks many water utilities still assume that the demand will evolve simply as a product of per capita demand and a projection of population whereas the predictive power of such methods is inadequate under changing conditions it is therefore now acknowledged that in order to obtain reliable demand forecast it is important evaluating understanding and modeling the factors that influence water use over both short term and long term intervals awwa 2013 urban water demand is guided by complex interactions between human and natural system variables at multiple spatial and temporal scales in the past many studies have focused only on economic and other policy variables that can be decided by policy makers and water utilities so that their future evolution is known but there is the need to keep into account also the factors that are not controlled by the water utilities and are characterized by an uncertain evolution climate is certainly one of such factors a large number of studies see section 2 1 have analysed the causal relationships between the demand and a number of different climatic variables and have developed urban demand models that include such drivers in the explanatory variables these models can successively be used by the water utilities to forecast the future water demand as a function of the predicted evolution of the meteorological variables consisting in either long term climate change scenarios or short term seasonal forecasts as far as the impact of climate change and variability is concerned understanding and modelling the influence of meteorological factors on urban demand is the first step for assessing the long term pressure on the water supply system due to expected climatic scenarios this approach is followed for example by goodchild 2003 babel et al 2014 haque et al 2015b who first set up demand models driven by meteorological factors and then provide in input the same drivers obtained from climate change scenarios analogously for the purpose of operational management decisions identifying the role of the whether variables in a monthly water demand model would immediately allow the inclusion of inputs deriving from weekly to seasonal meteorological forecasts even if such numerical weather predictions are still affected by very large uncertainties over lead times longer than a few days thus resulting in improved short term water demand forecasts tian et al 2016 have recently proposed for the first time the use of weekly weather forecasts in input to a water demand model a full understanding of which variables are significant is a necessary prerequisite for improving the demand models in coastal regions but not only there a very important factor in addition to climatic determinants is the influence of tourism on water use such factor has not been adequately addressed in the literature so far and is generally neglected in water demand analyses provided that an estimate on the expected touristic fluxes is available for example through one of the many tourism demand forecasting models available for the tourism industry also such variables might be directly used in input to the proposed model to obtain a more accurate water demand forecast the present work for the first time introduces the use of the time series of the monthly tourists overnight stays as an additional explanatory variable to model monthly urban water demand in order to provide knowledge on the combined impacts of climatic and touristic factors the case study refers to a set of cities in italy where sub annual analyses are so far not reported in the literature and in particular to the most economically developed coastal region in the country in such and similar contexts the proposed water demand models may be successively used by water utilities to derive more accurate water demand forecasts based on the available climatic and touristic evolution scenarios 2 factors driving urban water demand there is abundant theoretical and empirical literature on urban water demand modelling at different spatial household to municipal and temporal hourly to multi yearly scale the readers may refer to house peters and chang 2011 or donkor et al 2014 for comprehensive reviews of concepts and models a variety of determinants exogenous inputs may have an impact on water demand and have been considered in the literature in addition to information on previous consumptions endogenous input structural and geographical variables such as household or building landscape features and socio economic variables such as population characteristics water price and consumer income water use behaviour the majority of the above variables are not subject to seasonal fluctuations or even when not negligible such sub annual fluctuation is generally not recorded and are considered to change at annual scale allowing to analyse inter annual variability only for modelling the overall behaviour of the demand over time it is instead necessary to take into account not only factors that change from year to year interannual but also the factors that have a seasonal or monthly variation in order to capture also the infra annual expected variations in the demand such as climatic variables and tourism 2 1 influence on water demand of climatic drivers when analysing a sub annual behaviour and the objective is to assess the reasons for seasonal changes in the demand the main influence is generally attributed to climatic variables rainfall temperature evapotranspiration as demonstrated by a very large number of studies analysing and modelling the role of such variables see among the many others zhou et al 2000 gutzler and nims 2005 gato et al 2007 wong et al 2010 bakker et al 2013 and in particular chang et al 2014 and haque et al 2015a also present excellent reviews on the use of climatic determinants it is in fact expected that weather conditions do influence the intensity and or the frequency of important water demanding activities both indoor such as showers and other personal hygiene practises and outdoor such as garden plants irrigation but also car and street washing or swimming pool use temperature and rainfall variables are the most frequently adopted in water demand modelling also due to the good availability of such measures estimates on the other hand derived variables such as evapotranspiration estimates are relevant for only a part of the above mentioned water consuming activities i e irrigation activities for evapotranspiration factors temperature and rainfall can be adopted in several forms in the water demand modelling see haque et al 2015a temperature indexes may be based on mean values or on daily maxima and minima or on the numberof days exceeding a certain threshold in the same way rainfall indexes may include total rainfall depth the number of rainy days or rain events or the duration between the events identifying the temperature and rainfall indexes more suitable for each specific water demand modelling analysis is therefore still an open problem and even more important the outcomes of previous studies on the impact of climatic variables are not always in agreement some studies found that the demand is both positively related to the temperature and negatively related to the rainfall maidment and miaou 1986 lyman 1992 corral et al 1998 olmstead et al 2007 ruijs et al 2007 other authors nauges and thomas 2000 martins and fortunato 2005 haque et al 2015a 2015b showed that high temperatures increase the demand but did not find a significant effect of the precipitation on the contrary in the case studies analysed by zhou et al 2000 klein et al 2007 and schleic and hillenbrand 2009 precipitation was more important than temperature in particular it seems that the touristic vocation of the study area may play an important role in assessing the importance of the meteorological variables and in understanding their influence in fact in not touristic cities rainfall and temperature may do not exert a significant weight on the water demand see martinez espiñeira 2002a b or actually in some cases it was even found a wrong sign that is a negative correlation between temperature and consumption this happened when considering areas that are not highly touristic or at least not during the summer season like the city of zaragoza in spain arbués and villanua 2006 or the german areas analysed by schleic and hillenbrand 2009 the authors identify as a possible explanation the fact that consumption decreases in summer due to the outflow of residents to holiday destinations on the contrary therefore we expect for the reasons stated above that in coastal touristic regions during the summer climatic variables are especially relevant due to the specific touristic water uses 2 2 influence on water demand of touristic drivers tourism is strongly dependent on fresh water resources and its contribution to water consumption is expected to rise due to increases in tourists numbers in hotel standards and in water intensity of tourism activities as highlighted also in the review at global scale presented by gossling et al 2012 exacerbating this impact in coastal regions is the fact that the majority of tourists arrive during the above said critical summer season thus adding considerable strain on available water resources tourism is one of the world s largest industries according to the world travel tourism council wttc 2016 the travel and tourism sector accounts for 9 8 of world gdp and for 108 million jobs in 2015 equal to 5 of total employment that in line with the positive dynamics of arrivals and revenues should further increase of 2 6 over the next decade coastal tourism is one of the fastest growing forms of tourism all over the world page and connell 2006 and in many european and in particular italian regions it has turned into mass tourism already starting in the 1950s on the other hand tourism is also a massive consumer of natural resources water included tourism has in fact a strong influence on urban water consumption first the demand of water for residential uses can be substantially inflated by the presence of tourists to be added to the population to be supplied secondly tourists consumption is different from that of residents see gossling et al 2012 a more lavish use allowed by more leisure time and also related to the fact that water is not included in the hotel or rental bill and price has therefore no limiting influence is in particular enhanced in seaside cities by the habit of additional showers after swimming also the laundry requirement due to the much more frequent changes of bed and bath linens that characterizes touristic rather than residential presences is further increased in seaside resorts by the use of large towels for swimming pools and beach activities thirdly coastal cities are characterised by the presence of specific activities connected with the tourism economy that may be extremely demanding in terms of water requirements not only spas and swimming pools but also for example waterparks in the study area there are six important waterparks with around one million visitors per year furthermore more frequent irrigation is needed for hotel and city gardens and landscaping whose attractiveness is an important asset in a touristic city due to the second and third above points if we want to fully take into account the tourism impact the number of tourists cannot be added directly to the number of permanent residents when modelling the change in water demand not only the water use of holiday makers is different from that of residents but an additional complexity lies in the fact that in touristic cities there are water volumes that have to be supplied irrespective of the number of guests garden irrigation pools waterparks the literature on the impact of touristic variables on urban water demand is very limited and at sub annual scale almost non existent the only notable exception to our knowledge is the study by almutaz et al 2012 that proposes a monthly forecasting model for the city of mecca where very large touristic fluctuations are determined by the religious rituals such study takes into account in addition to other determinants also climatic variables but the touristic presence is considered only through the probability distribution of the number of tourists expected during the year in agreement with the religious calendar and not as an explanatory variable since monthly touristic time series are not available on the other hand it must be underlined that such religious tourism is not directly related to weather conditions as it happens instead in seaside cities as those analysed in the present study in light of the above considerations in a number of increasingly water scarce and touristically exploited regions additional research is necessary on the role of tourism as well as meteorological variables as determinants of water consumption and it is important to carry out such analyses at an appropriate temporal and spatial scale gossling et al 2012 this study contributes to the advancement of knowledge on determinants of water demand at sub annual scale by focusing on a mediterranean highly touristic coastal area and analysing a set of municipalities in a panel data framework 3 study region and data 3 1 study region it is worth noting that in the literature on water demand modelling the majority of case studies refer to north america or australia with a minority of recently published case studies referring to european countries and in particular there are only a few european studies based on intra annual data see worthington and hoffmann 2008 the same unbalanced geographical distribution of the studies was found by cominola et al 2015 in their review on the literature on high resolution water demand modelling and management where only 13 of the reviewed papers presented studies developed in europe but we agree with the authors that driven by the challenges posed by both climatic and anthropogenic factors on urban water supply increasing attention will be paid to such analyses all over the world as far as italy in particular is concerned infra annual water consumption data are generally not available and are often affected by low quality and reliability the national authorities still do not publish official data and analyses of water consumption in italy have been so far possible only with the collaboration of one or more water companies the research on water demands in italian cities is mainly based on annual data mazzanti and montini 2006 musolesi and nosvelli 2007 statzu and strazzera 2009 romano et al 2014 the study area analysed in this work includes all the municipalities on the coastline of the romagna region in northern italy which is one of the most economically developed areas in europe and characterized by an extremely profitable seaside tourist industry it is in fact one of the most attractive touristic areas in the country and the national and international tourists spend in the official accommodation facilities of the analysed cities around 27 million of nights every year mainly concentrated in the summer months corresponding to 7 of all the overnight stays in italy over the analysed years romagnaacque società delle fonti is the regional water supplier and it provides wholesale water to the main retail water company in the three provinces of ravenna forlì cesena and rimini with a total of more than one million permanent residents 3 2 monthly water demand data the water demand data used in the study have been made available by romagnaacque that collects the consumption data at monthly scale for all the towns of the three provinces since relevant uncertainty characterizes the information referring to many municipalities we decided to focus only on the coastal towns where almost half of the permanent residents and the large majority of tourists resides some of such municipalities are very close to each other and the same junction of the water supply network may serve more than one municipal administration in such cases s mauro and riccione denoted with an asterisk in the map in fig 1 more municipalities have been aggregated based on hydraulic boundaries the final list of municipalities or grouped municipalities includes from north to south ravenna cervia cesenatico s mauro including also savignano gatteo and gambettola bellaria rimini and riccione including also misano and cattolica the municipalities boundaries are shown in fig 1 the dependent variable used in the analysis is the monthly average consumption wdem per town collected for the period 7 years from 2009 to 2015 and expressed in cubic meters per month then transformed in an average daily volume m3 day for that month due to the crucial importance of the volumes supplied during the summer touristic season when it is also much more important the influence of the climatic see also gutzler and nims 2005 and touristic drivers the analysis considers only the five months from may to september fig 2 shows the water demands during all the summer months of the observation period for the seven municipalities 3 3 monthly tourists presence data in italy there is a monthly census of the guests hosted in the official touristic accommodation facilities such as hotels bed and breakfast etc the establishment owners are asked to provide such data in real time along with the billing documents this data are aggregated for privacy reasons at municipal level and then published in provincial level nuts 3 databases such data report the number of monthly overnight stays but only in official accommodation facilities the tourism statistics in fact do not include any information on the occupancy of second homes holiday homes and not even on the majority of rental homes of which only a very small percentage is officially registered as far as the towns of the emilia romagna are concerned guizzardi 2005 proposed an indirect estimation of the touristic presence in holiday homes based on the measurements of electric power consumption in households that were not officially occupied by permanent residents based on his assessment at annual level of the total number of nightstays in each municipality we have estimated the second homes occupancy for each month assuming that the tourists lodged in unofficial accommodation facilities vary proportionally to the monthly presences in official structures even if we acknowledge the high uncertainty of such assumption including both official and not official tourists overnights the total population to be supplied in the summer months increases of additional 228000 people on average considering the peak month in every day of august the tourists to be added to the around 492000 permanent residents varies from 373000 to 391000 over the observation years 78 on average 3 4 monthly rainfall and temperature data the climate on the romagna coast is warm and temperate with annual rainfall between 550 and 750 mm and a mean annual temperature between 12 and 14 c summer months are warm but not necessarily dry for the observations period 2009 2015 we have collected daily rainfall and temperature data in the weather stations owned and managed by the regional meteorological and hydrological service arpae simc the point measurements were spatially averaged with an inverse distance weighting approach thus obtaining for each municipality 1 monthly rainfall depths 2 number of rainy 1 mm days 3 monthly average of maximum daily temperatures 4 monthly average of minimum daily temperatures such climatic variables have been chosen based on the literature results that highlight the importance of the rainy days occurrence in fact there is general agreement on the usefulness of considering not only the total rainfall depths but also the number of rainy days that was found by many authors maidment and miaou 1986 martınez espiñeira 2002 schleich and hillenbrand 2009 to be a better explanatory variable than the total rainfall amount other studies highlight instead the possible influence of both day maximum and night minimum temperature data see guhathakurta and gober 2007 praskievicz and chang 2009 3 5 annually varying factors number of residents and water price data for each italian municipality the data on permanent residents are updated and published every year and in the study municipalities there is a slight population increase over the years as far as water price is concerned even if water may be considered an ordinary good its demand is expected to decrease when price increases its price elasticity can be very low especially for higher income countries dalhuisen et al 2003 statzu and strazzera 2009 romano et al 2014 on the other hand garcía valiñas 2005 observed higher price elasticity in peak summer than in off peak periods all other seasons the italian water price as in many countries is based on a complex increasing blocks tariff structure the problem of how to estimate the price elasticity in presence of complex tariff structures is still open in the literature and we decided to use as proxy for water tariff the volumetric price euro for cubic meter of the central block of the tariff structure there are three blocks for residential use that generally includes the large majority of the consumers volumes representing the core of the tariff policy overall our data base includes the variables listed in table 1 whose mean values are reported in table 2 climatic and touristic variables have seasonal i e monthly fluctuations like the water demand whereas number of residents and tariff change at yearly scale and are therefore constant for all the months of the same year the variables wdem tour raind and rdays corresponding to monthly cumulative totals are divided by the number of days in each month so to make all the determinants independent of the length of the different months and the data thus represent the values for an average day in the considered month t 4 methodology and results 4 1 correlation analysis in order to investigate the drivers of the seasonal fluctuations of the water demand we analyse for each municipality the correlation existing between the water demand in the five summer months and the seasonally varying predictors table 3 shows the ranges maximum and minimum values obtained for the different municipalities of the correlation coefficients and corresponding p values obtained relating the predictand wdem with tour raind rdays tmax and tmin all the predictors for all the municipalities are significantly correlated with water demand the number of tourists is as expected strongly positively related with the consumption the temperatures are also very highly correlated with a positive sign thus showing that in a coastal touristic area where residents do not leave the city in the hottest months an increase in temperature causes an increase in the water volumes differently from the case studies analysed by arbues and villanua 2006 for the city of zaragoza by schleic and hillenbrand 2009 for a set of german supply areas and by romano et al 2014 for the main italian chief towns also both the variables describing the rainfall total rainfall depth and number of rainy days have a correlation in this case of negative sign indicating a reduction of consumptions with increasing rain but the correlation of the total rainfall depth raind is less significant than for the other seasonal variables with a p value larger than 1 for four over seven cities on the other hand also the seasonal variables are highly intercorrelated table 4 shows the maximum and minimum values over all the municipalities set of the correlation coefficients computed between each couple of seasonally varying predictors since the explanatory variables are intercorrelated some of them might not contribute with additional information content to the determination of the demand we will therefore explore their role through the application of the panel data modelling carrying out an input saliency analysis 4 2 panel data model structure the studies that present water demand models at monthly or sub monthly scale usually refer to a single spatial entity metropolitan area city or district in econometrics water consumption studies generally developed at annual scale it is instead frequent using a cross section of entities cities taking into account the socioeconomic characteristics of the different cities measured at the same time instant and assumed to be time invariant and the elasticities i e the responsiveness of the predictand to a change in the value of the explanatory variables or determinants are supposed to represent their long term value panel data or pooled or time series cross section tscs analysis combines time series for several cross sections pooled data are characterized by having repeated observations more years on fixed units municipalities this increases the number of observations enhancing the quality and quantity of data and this is especially needed when as in the present case study the number of observation years is unfortunately limited additional more informative data help to overcome problems of multicollinearity to control for unobservable heterogeneity of the cross sectional units and to estimate more reliable parameters arbues et al 2003 gujarati 2004 to the authors knowledge a part from the study based on linear regression analysis by martinez espineira 2002a b there is no literature on the use of a panel data approach that models urban water demand at subannual monthly scale in reference to a set of cities cross section analysis the data analysed in this work has a balanced panel structure and the model can be written as 1 y i t f x i t z i ε i t where i indexes individual municipalities and t indexes time periods months y i t is the dependent variable water demand in the summer month t x i t is a vector of time varying regressors cross sectional time series variables changing in time and in space z i is a vector of time invariant regressors cross sectional time invariant variables and ε i t is the error term time invariant variables z i may be very important to explain the specificity of each entity the municipalities of our study area are extremely different not only in relation to the time varying variables we are considering as predictors but in many physical and socio economic features that we here assume to be time invariant we hypothesise that such specificity is fully captured by one variable only meanm i i e the mean value of the demands in the same month in the available years excepting the year over which we are modelling the demand in the split sample validation approach described later on for the given city 2 z i m e a n m i t 1 n 1 w d e m t i t m o n t h m o f o t h e r y e a r s n 1 such value represents also the best information available in the operational practice for the water company to model the expected monthly demands the present study aims at assessing the potential of exploiting additional information in order to improve such standard of reference estimate our models have therefore the following form 3 w d e m i t f r a i n d i t r d a y s i t t m a x i t t m i n i t t o u r i t r e s i t t a r i t m e a n m i ε i t in the panel data framework all the data predictors and predictand referring to the seven municipalities are merged in an unique data set that is thus formed by a number of records equal to 7 times the number of records available for each city all models are applied in a cross validation procedure with a rigorously independent calibration and test data set i e test data are not used for estimating the parameters of the models given the limited number of observation years we have applied a leave one out split sample calibration procedure where for modelling the water demand in the five summer months of one year all the data referring to such year test year for all the municipalities are removed from the calibration set used to parameterise the model the calibration period is thus formed by the data of all the remaining years the calibrated model is successively applied over the independent test year to assess its performance in validation the procedure is repeated using every year one at a time as independent test period 4 3 linear models stepwise regression the first implemented model is a multiple linear one like for example in haque et al 2015a with a stepwise regression approach where regressors are added or removed one at a time until no additional regressor can be added to improve the model the model is assessed based on the sum of squared errors criterion with p values of the f statistics used to decide if adding or removing a predictor equal corresponding to 0 05 and 0 1 respectively the final selected linear model structure denoted in the following as swrm excludes the following variables permanent residents res rainfall depth raind and both the temperatures tmax and tmin including instead the other four input variables tar tour rdays meanm with the last one as the most significant one and first to be included in the stepwise procedure it appears therefore that when modelling the water demand with a linear regression the role of the number of residents of the rainfall depth and more surprisingly also that of the temperature are already included in the values of the mean demand rainy days tariff and presence of tourists on the other hand the relation among water demand and the explanatory variable function f of equation 3 is not necessarily linear on the contrary we do expect a non linear influences of the climatic variables see maidment and miaou 1986 or miaou 1990 and this also affects the relative influence of the explanatory variables 4 4 non linear models artificial neural networks input saliency analysis non linear models based on artificial neural network ann architectures were tested to model the water demand in the five summer months numerous studies have successfully applied ann in water demand modelling in the recent years among others grino et al 1992 jain et al 2001 jain and ormsbee 2002 liu et al 2003 bougadis et al 2005 adamowski 2008 ghiassi et al 2008 firat et al 2009 adamowski and karapataki 2010 adamowski et al 2012 babel et al 2014 artificial neural networks are massively parallel and distributed information processing systems composed of nodes arranged in layers which are able to infer a non linear input output relationship ann in particular feedforward networks have been widely used in many hydrological and water resources applications see for example the recent review papers by maier et al 2010 by abrahart et al 2012 and the readers may refer to the abundant literature for details on their characteristics and implementation the models applied here are networks formed by one hidden layer with tan sigmoid activation functions and a single output node corresponding to the wdemt i to be estimated with a linear activation function the training algorithm minimizing a learning function expressing the closeness between observations and ann outputs in the present case the mean squared error is the newton levenberg marquardt backpropagation algorithm in order to avoid overfitting which degrades the generalization ability of the model a bayesian regularization of the learning function foresee and hagan 1997 was applied also the panel data regional anns were implemented in a fully independent cross validation leave one out procedure for each year or better for each summer season to be modeled the data of the months of the other summer seasons are used for the training for each validation year the ann is trained starting from 10 different initial networks randomly initialized each one of the trained networks provided their performance over the calibration data is considered acceptable i e with a coefficient of determination greater than 0 9 is then fed by the input variables for each of the municipality of the test year independent data and the water demand of the test year is finally obtained averaging the resulting ann outputs the first implemented ann model has in input all the predictors of eq 3 ann all inputs successively since the stepwise linear regression procedure indicated that number of residents res rainfall depth raind and both the temperature indexes tmax and tmin appeared to be redundant we have carried out an input saliency analysis testing other networks where such input variables are removed one at a time denoted as ann m1 to m4 fig 3 shows the performances in terms of both mae mean absolute error and rmse root mean square error of the stepwise regression model swrm and of the ann models as a term of reference the figure shows also the errors of the naïve model that assumes that the water demands for a given month of the test year is equal to the mean of the monthly demands of the remaining calibration years meanm the mae and rmse indicate that only the removal of the rainfall depth m1 no raind improves the performance of the non linear models whereas removing the values of res tmin and above all tmax actually deteriorates the performance in validation this finding in line with the result on the significance of raind vs wdem obtained in the correlation analysis confirms what emerged also in other studies that is that the total rainfall depth has not a significant impact on water consumption which is instead more affected by rainfall occurrence rdays also the important role of both mean day and night temperatures is confirmed as far as our case study is concerned as an additional test the removal not only of raind but also of each one of other three predictors was tested but there was no additional improvement in the modelling performance in validation in respect to model ann m1 the figure also highlights that the ann non linear models with the exception of the one that does not include tmax outperform both the naïve mean m and the linear regression approach and that in turn swrm is better than meanm thus demonstrating i the importance of including the influence of both weather and touristic explanatory variables for estimating the water demand and ii that such relation appears to be better captured by a non linear model in order to better analyse the modelling capability of the implemented approaches fig 4 shows the disaggregation of the mean absolute error over the different municipalities left panel and over the different months right panel comparing the meanm the linear regression model and the best performing ann the right hand panel of fig 4 indicates that there is a gain allowed by the inclusion of the time varying predictors for every month of the season such gain is the highest for the critical august month whereas it s hardly noticeable for june that appears to be less fluctuating over the years the left panel of fig 4 shows that the highest benefit from the inclusion of the time varying explanatory variables xt i is obtained for the city of rimini one of the most important touristic city in italy whose estimates are shown in fig 5 and secondarily for the municipalities of ravenna and riccione on the other hand for two municipalities bellaria and cesenatico the left hand panel of fig 4 shows that assuming a water demand equal to the mean on the remaining years meanm would be better than the application of the proposed models and for s mauro the improvement is negligible in these cities the smallest of the set the water demand is the less fluctuating from one year to the other and the demands over the different years have the lowest discrepancy from the mean values so that the influence of the time varying determinants is limited since the approach is a panel one each one of the pooled models attempts to mimic simultaneously in addition to the behaviour of such relatively stable municipalities also the behaviour of all the other cities where the monthly water demand fluctuations are much stronger as may be seen for example for the city of rimini it follows that the ann and the swrm model tends to assign also over the less fluctuating municipalities an overestimated influence of the variations in the seasonal predictors thus resulting in a deterioration in comparison with the use of meanm alone for bellaria and cesenatico 5 conclusions the study has analysed the monthly residential water demand referred the municipalities of one of the most important touristic areas in europe where it is extremely important to assess the significance of the water use drivers in particular during the critical summer season beyond the explanatory variables proposed in the past literature including climatic drivers the work has introduced tourism as an important factor that may affect water consumption such factor has been so far neglected in urban water models and its influence is not well documented yet also due to the lack of information at sub annual scale the correlation analysis carried out for all the study cities between the water demand in the summer months and the seasonally varying predictors in order to understand their influence showed that the consumption indeed increases very much with the number of tourists furthermore differently from other non touristic areas in a coastal area where residents do not leave the city in the hot summer months an increase in temperature always causes a significant growth in the water volumes on the other hand the rainfall occurrence number of rainy days has an highly significant negative correlation for all the municipalities while the total rainfall depth does not always exert an equally strong significant effect on the demand in line with similar results obtained in the literature the panel data water demand modelling demonstrates the added value of the inclusion of the determinants analysed in the study if compared with the monthly estimate given solely by the mean value of the demand over the same month of the other years that is the estimate currently used by the water company and that implicitly ignores the influence of the changing climatic economic and societal conditions on the demand in a panel data approach there is not a different model tuned to fit each single city but only one model that simulates the water demand aggregated at municipal scale for all the cities included in the panel the model may therefore be used to simulate also the demand for a city that is not included in the set of cities used to parameterised it provided that such demand is guided by the same underlying causal relationships when comparing the modelling approaches the results show that the non linear model based on an artificial neural network architecture outperforms the linear regression indicating that the influence of the identified predictors appears to be better captured by non linear causal relationships the input saliency analysis for the non linear models has shown that the best performances are obtained when the following exogenous variables are added in input to the model residents tariff number of tourists both day and night temperatures and number of rainy days instead the total rainfall depth is not included in the set of significant drivers identified by the input saliency analysis confirming the results of the correlation analysis in light of the above considerations and of the promising results we believe that additional research on the role of tourism in addition to meteorological variables as determinants of water consumption at seasonal and finer time scale is useful and necessary lack of data currently hinders the development of such analyses and the number of available data is also one of the main limitations of the present study in italy and in many other countries infra annual water consumption data are generally not accessible and often affected by low quality and reliability more complete information is especially needed on water uses by tourists and by specific touristic activities in particular more detailed data on the number of tourists lodged out of official accommodation facilities would be required to fully capture such important phenomenon additional knowledge on the sub annual determinants will help to better understand and model the expected consumption such improved models may be of great help to water utilities to forecast water demand when factoring in the possible evolution of the explanatory variables through climate meteorological and tourism forecast scenarios in order to improve the water supply management policies and practices possible future research stemming from this study includes i exploring the use of numerical weather predictions and of tourism forecasting models for weekly to seasonal urban water demand forecasts over the study area and ii investigating urban water security under changing long term climate and tourism projections such analyses may be needed at aggregated scale for forecasting the need of all the cities supplied by the same water sources or at local scale for planning the evolution and management of the distribution network this kind of analyses in addition to being needed by the water managers may also help to increase the resilience of tourism business to water scarcity risks thus allowing a long term sustainability of mass and quality tourism in the romagna seaside cities and in other highly developed coastal areas eurostat 2009 software data availability the analyses have been developed within the matlab mathworks software development platform the scripts are available upon request from the first author the information on tourists overnight stays and the rainfall and temperature data are public and the data set used in the study are available upon request from the first author whereas the data on water consumptions are based on measurements that are not public and have been provided by romagna acque società delle fonti spa acknowledgements water supply data and precious advice were provided by andrea gambi ceo and giuseppe montanari gilberto forcellini and paolo mazzoli water production sector of romagna acque società delle fonti spa whose help is greatly appreciated the work was partially developed within the framework of the panta rhei research initiative of the international association of hydrological sciences iahs working group on data driven hydrology the authors also wish to thank the editor and the two anonymous referees for their constructive comments 
26404,modelling managed resource systems can involve the integration of multiple software modules into a single codebase these modules are often written by non software specialists using heterogeneous terminologies and modelling approaches one approach to model integration is to use a central structure to which each external module connects this common interface acts as an agreed mode of communication for all contributors we propose the python network simulation pynsim framework an open source library for building simulation models of networked systems pynsim s central structure is a network but it also supports non physical entities like organisational hierarchies we present two case studies using pynsim which demonstrate how its use can lead to flexible and maintainable simulation models first is a multi agent model simulating the hydrologic and human components of jordan s water system the second uses a multi objective evolutionary algorithm to identify the best locations for new run of river power plants in switzerland keywords modelling framework simulation python open source software availability program title pynsim developer stephen knox contact address stephen knox manchester ac uk software access https www github com umwrg pynsim year first available 2015 hardware required windows 7 10 tested linux macosx program language python program size 116k availability and cost open source license gpl3 1 introduction the use of simulation to model managed environmental systems is well established buytaert et al 2012 loucks et al 2005 robinson 2014 sánchez 2007 thorp and bronson 2013 as is the need to integrate models from multiple disciplines in order to represent the complexities and interdependencies of environmental systems burroughs 2007 castilla rho et al 2015 knapen et al 2013 integrated modelling aims to combine models from multiple different disciplines such as ecology sociology daloğlu et al 2014 water resources economics harou et al 2009 and water resources sociology barthel et al 2008 in addition to the integration of multiple disciplines some models aim to enable decision making of individual actors within the modelled system the dynamic interaction and communication between actors within the domain can be modelled using an agent based approach schreinemachers and berger 2011 agent based modelling is an established methodology to resource modelling castilla rho et al 2015 kelly et al 2013 tesfatsion et al 2017 and several toolkits and languages are available hiebeler et al 1994 luke et al 2003 collier et al 2003 tisue and wilensky 2004 multi agent based simulation mabs is a widely used technique with several examples of cross disciplinary model integration ghazi et al 2014 bosse et al 2013 daloğlu et al 2014 a common approach to model integration is component based modelling in which processes within an integrated model are represented by pluggable model components these integrated models are known as integrated environmental models or iems component based models are often implemented as an environmental modelling framework which are standards or software systems used to build and integrate models around a single coherent structure emfs provide abstractions for defining the input and output of models and the domains on which the models operate emfs differ in the domain they apply to ranging from the specific hill et al 2004 to the general david et al 2013 bernholdt et al 2002 and in the degree to which they require the model to be altered their invasiveness lloyd et al 2011 dozier et al 2016 the decision to integrate a model into an emf therefore relies on how much the model itself must be modified in order to allow integration and on the value of its inclusion the increasing integration of models and the complexity of the software required to support advances in integrated modelling is hampered by the ability of model developers to create sustainable code bases which are usable beyond the scope of an individual project david et al 2013 development of such code bases is often difficult to justify as academic projects tend to focus on scientific accuracy and expediency over software sustainability and scalability in their vision and roadmap for the future of iem laniak et al 2013 describe the need for the environmental modelling community to make software development and sharing more prominent in addition to considering their work to be a part of a larger ecosystem one step towards this goal is to encourage the use of existing open source technologies which allow model developers to build components and to publish them through well established software repositories this can only be achieved by building a structure for model development and integration which is attractive and simple enough to encourage uptake and involvement from the wider community component based modelling frameworks rely on a consistent underlying structure to which all components integrate some approaches use standards where each model uses the framework to explicitly define the input and output parameters required to run the model gregersen et al 2007 others provide a common structure to which all models must comply for example most water resource management modelling problems can be abstracted to networks of nodes and links letcher et al 2007 recent work on network modelling software generalises network structures allowing them to be applied to more than one domain like water resources energy and transport and any other domain in which network structures are used harou et al 2010 knox et al 2014 meier et al 2014 such an abstraction pushes the responsibility of domain specific representation and functionality to the model developers themselves and in doing so can support models spanning multiple disciplines a generic network representation could allow for example multiple networks stored within the same system to be combined by linking models e g the output of a water resource model is fed into the input of an energy management model by specifying a commonality between two different networks lee et al 2007 such as representing a hydroelectric dam which serves as both a water supply reservoir in a water model and a production source in the energy model using a network structure to tie multiple models together also allows for the support of multi agent behaviour where the model components can not only act on the network as a whole but where each node or combination of nodes within the network can execute code independently at each time step the work presented in this paper is referred to as the python network simulation pynsim framework a python package containing abstract classes which are designed to be extended using an object oriented structure pynsim adopts a modular design allowing multiple users to plug in their code and uses a central network structure to provide a common interface where each module interacts with the network not directly with each other it allows simulations to be performed where multiple sub models adhere to a common representation of a network of nodes and links rather than imposing any particular standard for model communication pynsim provides a basic structure upon which network based simulations can be built laying the groundwork for components of those simulations to be released as public python libraries pynsim is an object oriented framework written in python and attempts to build on the design of existing modelling frameworks it aims to facilitate model integration agent based modelling and the use of a component based design where components can be added and removed with ease in addition to incorporating a component based model integration through the use of pluggable modules it also supports agent based modelling by allowing each network element node link or institution to execute code individually at run time an institution allows pynsim to represent organisational and other non physical hierarchies by acting as a container for nodes links and other institutions the contribution of this work is a component based simulation framework designed specifically for networks including representation of decision making hierarchies and support for multi agent modelling and which is accessible as a standard python library two case studies demonstrate how pynsim s features and associated modelling approach aided development and led to flexible and maintainable human environment system simulation models this paper is structured as follows section 2 describes related work in integrated and agent based modelling section 3 identifies features of related frameworks and then introduces pynsim and its unique functionality implementation details of pynsim are then presented in section 4 two case studies are presented in section 5 finally a discussion and concluding remarks are presented in sections 6 and 7 2 related work 2 1 modelling frameworks environmental modelling frameworks emfs support modular development of integrated models through provision of libraries of core modules and reusable tools for common tasks such as unit conversion language interoperability data manipulation analysis and visualisation argent et al 2006 the object modelling system oms is an open source emf which maintains the design principles of the earlier modular modelling system mms david et al 2013 leavesley et al 2007 oms has a facility to build simulations allowing definition of time steps parameters and models for environmental modelling oms is java based and offers a lightweight non invasive the models themselves change very little if at all framework for integrating models together this is done by using code annotation to describe the required model parameters and a simple scripting language to connect the models oms focusses on reducing the amount of code required to integrate models the open modelling interface openmi gregersen et al 2007 is a standard for the exchange of data between models at runtime castronova et al 2013b openmi is implemented as a set of object oriented interface classes and supports the integration of models guis and data sources where each one can be developed independently and then integrated as linkable components through use of these interfaces legacy models can be integrated to openmi through a wrapper which runs the model code inside an openmi compliant linkable component this minimises the changes required to the model code itself in addition to the standard itself openmi provides a software development kit sdk for java and c to simplify the creation of components and the omied desktop application for graphically linking models the openmi framework has been used in several research projects internationally for environmental modelling knapen et al 2013 goodall et al 2011 2013 in 2014 it was adopted as an official standard by the open geospatial consortium ogc the community surface dynamics modelling system csdms is a modelling framework comprising of two parts the basic modelling interface bmi and the component modelling interface cmi peckham et al 2013 bmi provides an object oriented programming interface similar to openmi which allows a model to plug into the cmi framework the cmi provides the ability to match models written in different programming languages perform unit conversion and provides a gui to manage components to be bmi compliant the model developer must implement three functions from a bmi main interface initialize to set up the component update where the main functionality is implemented and which updates the state variables at each time step and finalize which tears down the model for instance deallocating memory or saving results bmi is the basis of the lighter weight emeli experimental modelling environment for linking and interoperability a modelling framework written in python that was designed to allow the re use of component models by using a standardised interface most recently emeli has been extended as a web service allowing it to integrate bmi enabled web services thereby making them language agnostic peckham 2014 jiang et al 2017 projects aimed at linking bmi to openmi are under way in an effort to create a more cohesive offering of integrated model frameworks goodall and peckman 2016 a web based approach is also used by the dmif distributed model integration framework which connects models deployed on different hardware and software platforms using web services belete et al 2017 the technical interoperability within dmif was tested by connecting gams and netlogo the former an optimisation based language and the latter an agent based simulator this shows a clear path of development towards combining agent based simulations with external optimisation techniques a capability offered in pynsim 2 2 multi agent modelling multi agent modelling is a popular approach to environmental modelling as it allows complex questions to be broken down into atomic parts where the interaction of sub components of a system are modelled independently bousquet et al 1999 argue that the theory of multi agent systems not only offers pertinent and powerful formalization tools but also provides a better framework for computer simulations many different definitions of agent based modelling exist and have been discussed extensively thiele et al 2011 castilla rho et al 2015 davidsson 2000 we refer to an agent as something which takes input from the environment and produces actions as outputs that affect the environment but with incomplete information at the agent level and without a global control mechanism wooldridge 2009 several agent based languages and toolkits are available and used in environmental modelling these include netlogo tisue and wilensky 2004 repast galán et al 2009 jade pipattanasomporn et al 2009 agent factory and nxsim to name a few of these netlogo repast and cormas have been used within environmental modelling and are described here nxsim being python based is also described netlogo tisue and wilensky 2004 has been used for modelling social and environmental interactions in groundwater systems castilla rho et al 2015 netlogo is a generalised simulation environment allowing agent based simulations in several domains netlogo supports both grid based and network based agent connections in addition to having a user interface it provides a built in scripting language for defining agent behaviour for integrating with external models and for more advanced developers netlogo provides extension libraries for integrating programming languages such as java r and matlab repast is a suite of generic open source simulation platforms written in java which has been used to model water management systems galán et al 2009 repast is aimed at both novice developers through its relogo platform but can be used to build scalable distributed simulations using repast symphony repast is a java api providing a suite of tools for running simulations and developed using a philosophy of abstraction of simulation infrastructure extensibility and good enough performance collier 2003 one of the approaches employed by repast to simplify initial development is to incorporate python scripting being an api repast passes the responsibility of code organisation to the developer rather than prescribing a particular structure cormas common pool resources and multi agent systems is a multi agent platform written in smalltalk bousquet et al 1998 originally designed for modelling resource management cormas has been applied to several other areas using multi agent simulation through its user interface an environment of agents can be created where each agent is either a subclass of a spatial agent with geographic information but with limited ability to communicate or a communicating agent with no spatial properties but which can send messages to other communicating agents these agents can then be programmed as necessary this structure reflects the design presented by bousquet et al 1999 which describes the need for institutions which can represent abstract hierarchies as well as spatial agents reflecting physical entities cormas has been applied to multiple environmental multi agent systems such as simulating irrigation systems barreteau and bousquet 2000 river catchments becu et al 2003 and social ecological systems saqalli et al 2010 nxsim is a python library designed for network based agent based modelling nxsim is designed to support large networks of a single type of agent nxsim is open source and based on the well known networkx hagbert et al 2004 library to represent topology and on simpy lünsdorf and scherfke 2013 for discrete time simulation 3 pynsim a common theme with recent developments in model frameworks is the goal to abstract the complexity of the software infrastructure with the assumption that many model developers have limited skills in software development and architecture müller 2010 tisue and wilensky 2004 by contrast scripting has become a common feature of modelling particularly the use of python marta almeida et al 2011 thorp and bronson 2013 as resource models become increasingly sophisticated castronova et al 2013a ames et al 2009 a flexible approach is becoming more relevant where through a well defined software architecture modellers can define their own modules write their own code and rapidly build resource network models to keep up with modern technologies the approach should allow for the use of components buahin and horsburgh 2015 whelan et al 2014 which can be interchanged and be able to represent both the physical and non physical aspects of a domain given an appropriate structure scripting can become more accessible to modellers and the steep initial learning curve is outweighed by the flexibility gained and the potential of benefiting from a wider community of software developers the hydroshare platform demonstrates that such a software development community already exists within the water resources community tarboton et al 2013 morsy et al 2017 several technologies and solutions exist for integrated environmental modelling summarised in kelly et al 2013 but many solutions tend to focus on one specific problem area or domain even in a cross disciplinary context for example the agent based framework emlab chappin et al 2017 focusses on energy and climate specifically by using a simple basic structure capable of being extended a more general framework could be used widening the number of applications and models which can be integrated pynsim pronounced pinsim is a modelling framework designed to allow building networked resource system simulators in a structured way pynsim uses an object oriented approach to define the network its properties and simulation behaviour this approach allows the structure to be general and modular meaning pynsim can be applied to many areas of network modelling and allows multiple behaviour defining codes to be integrated into a single simulation pynsim is a modelling framework in that it supports the integration of multiple modules acting on a central data structure a network where the network is effectively the means of communication between modules pynsim takes several design cues from existing modelling frameworks detailed in section 2 such as adopting object oriented classes for structure lightweight design and a component based architecture but narrows the focus of application to the simulation of managed resource system networks pynsim does not attempt to formalise attribute matching unit conversion or provide cross language interoperability in designing pynsim best practices and design philosophies from related works led to a set of requirements for the new modelling framework the framework should support the simulation of a network of agents it should be generalised to cater for multiple domains and should allow model integration using object oriented classes as the semantic glue it should also provide a means to add and remove algorithms and processes from the simulation with ease this framework should be a standard software library therefore depending on external systems for visualisation data analysis and management pynsim s novelty is that it is a generic network simulation framework written in python capable of supporting multi agent modelling and representing the physical and hierarchical aspects of network based systems the use of python has several benefits python is already a recognised tool in resource modelling marta almeida et al 2011 fienen and plant 2015 thorp and bronson 2013 python scripts can be made openmi and bmi compliant allowing broad integration into an established environmental modelling ecosystem bulatewicz et al 2013 python offers numerical and scientific libraries such as pandas numpy and scipy in pyomo python has a native optimisation language ready made allowing tightly coupled model integration extensions to core libraries can be published and downloaded through the python package index pypi pynsim supports component based modelling whelan et al 2014 buahin and horsburgh 2015 by virtue of its object oriented structure and through its ability to configure and manage multiple engines see section 4 additionally pynsim is suitable for agent based modelling wooldridge 2009 castilla rho et al 2015 as each component of a network is capable of running its own decision making code pynsim does not impose a component based or agent based approach instead it provides the framework in which one or both of these approaches can be adopted the pynsim codebase is lightweight in that it has no dependencies on external libraries and does not present a significant computational overhead see section 6 definitions pynsim uses the following terminology to describe its elements these mirror the class names used within the pynsim code module a file or folder containing python definitions and statements object an instance of a class as defined within a module from object oriented design principles network component type the blueprint of a network component node link or the network itself with a unique set of properties to represent a structural element in the network network component an instance of a component type computation can take place within a component in pynsim a component refers to the constituent parts of a network a component is an object engine a piece of software that performs calculations i e a sub model an engine calls an algorithm or a collection of algorithms that simulates or optimises a process multiple engines can exist within a generic model and provide a means of controlling the sequence of processes generic model a collection of defined component types and engines model an instance of a generic model applied to a particular system this includes the network topology but without data simulation a run or instance of a model with a particular set of model parameters boundary and initial conditions also termed a model run 3 1 design with pynsim a developer first creates a generic model defining component types and engines and their behaviour next a model is created by defining instances of these component types after applying input data to these components the model can be run a simulation pynsim uses an object oriented design providing a set of abstract classes which must be extended to build a simulator see fig 1 building a model in pynsim requires first creating subclasses of the base network components which we call building a generic model these classes illustrated in fig 1 are network node link institution a grouping of nodes and links engines and a simulator the abstract classes provided by pynsim are designed to be extended using inheritance a fundamental feature of object oriented programming oop inheritance is a mechanism for establishing is a relationships between objects whereby an object is based on a higher level object in this way the more specific object sub class exhibits the same behaviour and contains the same properties as that of the higher level object super class but with additional properties and behaviour the classes created for a generic model are what make it specific to a domain in one domain a subclass of node class may represent a power station while in another the class may represent a junction in a transport network or a group of farms in an agricultural region the same principle applies to links institutions and networks one or more engines must be defined by extending the engine abstract class engines contain the generic model s logic implemented either by activating an external sub model or by implementing the logic directly in python it is the model developer s responsibility to write linking code to external processes and therefore gives the developer control over the level of invasiveness required for implementing modifications engines are executed at each time step in a specific order defining an explicit sequence of processes the last step in building the model is creating instances of the network components and engines this is done in a python script adding the network and engines to the simulator defining the model run s time steps assigning data to the network components and then starting the simulation pynsim handles the progression of time as a series of discrete time steps the discretisation of time is defined before a simulation is run as pynsim iterates over the list of time steps a pre defined sequence is executed the sequence of a pynsim simulation is illustrated in fig 2 and occurs as follows 1 simulation starts 2 simulation begins iterating over the user defined time steps 3 for each time step t each network component node link and institution in the network sets itself up in preparation for being used in the engines this is the setup phase 4 at time step t one or more engines perform an action on the network or part of the network 5 at the end of time step t the network state is saved and the simulation continues the setup phase decouples the extraction of data for a given time step from operations performed on the network this makes engine code less complex as it only deals with the network at a single time step on each iteration 3 2 network components components comprise the topological structure of the network they include the network itself nodes links and institutions a component has some baseline properties like name description and component type but also supports user defined attributes which represent the properties relevant to the model and whose changes can be automatically recorded as the simulation progresses pynsim components contain a setup function at each time step of the simulation this function is called for every component individually the setup function has two roles the first role is to allow each component to retrieve and set property values for the current time step this may involve querying external databases or other forms of exogenous data structures data calculated during previous time steps may also be retrieved during setup all the components in the network then set these properties locally having set parameters locally the second role of the setup function is to implement some more intelligent and autonomous decision making behaviour based on its current or past state this is where a component can take the role of an agent as the setup code is run on each component independently 3 2 1 nodes and links nodes and links provide the basic structure of a network a node can represent any physical or abstract entity provided it has a name and a coordinate a link is defined by a name a start node and an end node and therefore cannot exist without nodes nodes and links act in the same way in that they are both set up at the beginning of each time step and have a set of user defined properties which an engine can access 3 2 2 institution institutions represent some grouping of other network components this grouping can represent a physical similarity all farms in a district or a more abstract grouping such as all power stations owned by owner x an institution can contain multiple nodes links and other institutions in addition to creating logical groupings for physical components institutions can be used to implement hierarchical decision making such as national and regional government policy being a network component like nodes and links institutions are also set up at each time step 3 2 3 network the network is the container for all the nodes links and institutions the network class contains several functions to manage its sub components such as functions for adding and removing nodes and links in addition a network has basic utility functions for visualising its topology and graphing properties over time a model is associated with exactly one network system topology 3 2 4 properties in pynsim a list of properties are defined for each component type a property is a state simulation or decision optimisation variable as opposed to temporary or transient variables used during calculations or fixed parameters that do not change over the course of the model run a property often stores a model result or a value required by another component in the current time step or by itself in a future time step at each time step in a pynsim simulation the properties of an individual network component can be set either during the setup phase or by an engine the types of properties that the components have are defined in their subclass pynsim provides a standardised way of defining properties making it easy to distinguish a property pertinent to the model from other temporary variables or fixed parameters the primary reason for defining properties explicitly is that it allows pynsim to track changes to these properties over time the value of each property is stored in an internal history structure at the end of each time step when the simulation is complete the history of each property can be interrogated allowing for in depth post processing history can also be interrogated by components mid simulation allowing them to make decisions based on historical data pynsim provides a visualisation function in which the changes to a property can be plotted over time 3 3 engines an engine is a piece of software that performs calculations gregersen et al 2007 pynsim models must contain at least one engine which performs an operation on a target a target can be the network itself as well as an institution in the network or an individual node in pynsim an engine s operations can be performed fully within its own functions using an external model or by calling functions on components within the target engines can be initialised at the start of the simulation run at each time step and finalised at the simulation s end reflecting the intialise update finalise design seen in other component based architectures pynsim supports multiple engines running sequentially this allows the same network to be used in several sub models guaranteeing consistency of data and allowing sub models focussing on different aspects of the problem area to be integrated into the same system the operation of the engine itself does not need to be written in python code written in external languages may require the developer to convert the network into input files for the external model it is here that more specialised frameworks for integration of sub models could be used when the external code is run the results could be parsed in python and saved using this approach any new or legacy code can be integrated with pynsim provided the developer writes the input and output parsing in the engine class no automatic standardisation of units or attribute names is performed by pynsim it is the responsibility of the engine developers to ensure consistency of data and attribute names 3 4 simulator the pynsim simulator controls the model runs and acts as a container for the network and engines the time steps for the model run are specified in the simulator when the simulation starts the simulator initialises each engine by calling its initialise function it then iterates over these time steps setting up the network calling the setup function of each component then running each engine in turn calling the run function of each engine for each time step finally each engine is finalized by calling its teardown function 4 implementation pynsim provides a suite of abstract classes with a simple code structure all of which can be but don t necessarily need to be extended there are three modules providing the base classes and functionality engine component and simulator the component module contains the base classes for the network topology network node link and institution these classes must be extended to define the elements of the network the engine module contains the abstract class engine this class must be extended for the simulator to provide functionality the simulator module holds the simulator class it is here that a simulation is controlled the simulator class contains simple features such as start add engine add network etc a simulator class must be instantiated and the network and engine must be loaded into the simulator the time steps for the simulation must also be defined explicitly 4 1 time steps the only rule for time steps is that they must be specified as an iterator there is no restriction on what format the time step itself takes time steps are a simulator property so must be set on the simulator object by default time steps is an empty list so if no time steps are specified before the simulation is started pynsim will return an error valid time steps might be mon tue wed thu fri or 2018 01 01 2018 02 01 2018 03 01 2018 04 01 when the simulation is started it iterates over the time steps list calling the setup functions and then running the engines for each time step the network and each engine has access to the current time step as well as the time step index the time step index is the current numerical point in the time step list for example in the daily time steps above wed has a time step index of 2 by accessing the time step index engines can be defined to perform certain processes at only specific time steps e g an annual process that is only run at every 12 time steps for a monthly model 4 2 properties exogenous data can be set as a regular attribute on a component but pynsim also provides a means of allowing the model to define and then keep track of properties which may require analysis once the simulation has been completed this is done using the properties attribute the underscore postfix is a python convention used to indicate an attribute which is private to an object and not meant to be accessed externally properties must be defined as an attribute of every component and is a python dictionary the keys of this dictionary are the component s properties and the values are its defaults upon creation of each component the contents of this dictionary are converted into object attributes defaulted to the value specified in the dictionary for example a class defining a reservoir might have a water level property image 1 when instantiated the reservoir object will have a water level attribute from the example above an object myres myres water level will yield 100 this approach is taken so pynsim can track certain properties while ignoring others at the end of each time step every property which was defined in the properties dictionary is recorded in an internal history structure every network component has a history property history this is a python dictionary keyed on property name the values of the dictionary are implemented as lists which is appended at the end of each time step with the current value of that property by the end of the simulation the change to every one of these properties has been stored and indexed by time step this allows for analysis of data changes throughout the simulation 4 3 engines an engine is implemented as an abstract python class with three functions initialise run teardown when implementing an engine a developer must subclass this abstract class and implement at least the run function this function is called during every time step of the simulation the initialise and teardown functions are called at the beginning and end of the simulation respectively this approach matches the design pattern commonly used in object oriented component modelling interfaces like bmi openmi and oms the contents of an engine s functions are at the discretion of the developer with the initialisation step typically used for loading external data the run function used to propagate a sub model in time and teardown used for storing or parsing result data when instantiating an engine a target must be specified this represents the network or component of the network upon which the engine will perform its calculations a target must be a subclass of the component type i e network node link institution the run function can be used in two ways to perform a function which can be written natively in python or to run an external program in the latter case the target must be converted into an input for the external program and the result of this program must be interpreted with the resulting data set back on the target engines are added to a simulator using the add engine function which appends the engine object to an iterator simulator engines within the simulation when the simulation begins it iterates over this list calling engine run on each engine allowing for an explicit sequencing of model processes through the ordering of the engines list 4 4 data and result analysis pynsim provides several high level features for data analysis including drawing the topology of the network analysing results data and identifying areas of poor performance in terms of run time we briefly detail these features here pynsim records the changes to the properties of components at each time step by calling a component s get history my property function the value of a specified property can be retrieved for each time step a simple suite of visualisation tools are provided to allow a user to graph changes to a property over time this is implemented in the network plot my property function and takes a property name as an argument this inbuilt data analysis functionality is designed to provide quick high level information to developers which may be extended as necessary rather than as an in depth analysis tool like that presented by white et al 2016 and jin et al 2017 no assumption is made about what kind of analysis a user might require so more detailed analysis is left to the developer to perform visualisations are produced using matplotlib but pynsim does not rely on matplotlib being installed to run only when the relevant graphical functions are called this maintains pynsim s lightweight but readily expandable functionality while availing of existing python libraries in addition to data analysis pynsim provides analyses on computational performance the time taken to run each engine and each setup function can be recorded by setting the record time argument of the simulator to true timings can be visualised by calling the simulator plot timing function this function provides a graph of the cumulative time taken for the setup function of every resource in the network and for each engine for more detailed performance analysis the timings of each node link and institutions can also be graphed individually using the network object s plot timing function likewise if the simulator contains multiple engines the performance of each can be plotted using the simulator s plot engine timing function these tools allow a developer to identify bottlenecks quickly without having to use external profiling tools as with the data analysis the philosophy of pynsim is to provide high level analysis tools to identify obvious irregularities but detailed analysis is left to the developer 5 case studies this section presents two case studies in which pynsim has been used they highlight different aspects of pynsim demonstrating its use in multiple applications 5 1 the jordan water project the jordan water project jwp is a collaborative interdisciplinary research effort focused on the development of a multi agent hydroeconomic model for the evaluation of policy interventions in jordan which ranks as one of the most vulnerable countries in the world in terms of freshwater supply padowski et al 2015 rajsekhar and gorelick 2017 the goal of the project is to enhance jordan s long term water security in the face of climate and socioeconomic change the central feature of the jwp is an integrated model which couples spatially explicit representation of hydrologic systems with multi agent representation of water allocation and use at both institutional and consumer levels of human decision making through pynsim s component and engine architecture the model adopts a modular structure with individual modules developed and calibrated independently and subsequently linked through the identification of important interactions and feedbacks in the system the overarching model structure is simulation based i e non optimization though sub system level optimization algorithms are adopted for specific modules the project team includes researchers from a variety of disciplines hydrology water resource systems analysis economics geography each responsible for development of specific modules given the interdisciplinary makeup of the team and the complexity of the model structure the jwp serves as an example for utilising the pynsim framework in enhancing complex human natural model development while an in depth analysis of the model is beyond the scope of this paper we illustrate some modules of the jordan water project that highlight the use and value of pynsim focussing on a cross section of the physical social and institutional aspects of the system the groundwater system is represented through a set of approximately 200 groundwater nodes each node uses a pynsim property which tracks the groundwater lift from the water table to the ground surface a response function is written using a pynsim engine which consolidates pumping information from the human agents then calculates the response of the groundwater system at every groundwater node using a response matrix maddock 1972 these engines use external drawdown tables pre processed from hundreds of modflow simulations illustrating how a pynsim engine is linked to an external source to perform calculations or access information at each time period households implemented as pynsim nodes request and purchase water from multiple water sources institutional allocators and private water tankers in response to prices and availability of the various sources and in accordance with a unique demand curve klassert et al 2015 households make initial demand calculations independently based on their current circumstance executed during the setup phase of the time step the amount of water purchased the price of purchase and the consumer surplus of every household node is tracked for all model time periods using pynsim s properties these are later used for model validation and analysis private tankers act as an informal water market between farmers who own private groundwater wells and urban households the private tanker water market is implemented as an institution and uses a market algorithm that matches willing farm sellers with urban buyers factoring in transportation cost based upon distance between any two farm and urban nodes the tanker market uses the flexibility of the pynsim institution class to model non spatial abstractions such as a water market applied to resource networks farms implemented as pynsim nodes attempt to maximize profit under a set of physical and behavioural constraints many of which are imposed by other pynsim components in the system farms use the dynamic groundwater lift stored in the groundwater nodes as input to their optimisation calculation which is performed through an engine that calls an external gams model run here the support for agent based decision making integrated with external optimization solvers is demonstrated with each farm needing to dynamically decide on whether to sell its water or use it for irrigation organizational level allocator agents are implemented as pynsim institution classes in contrast to the water user agents which are implemented as spatial nodes the institutional agents are entities that contain a subset of the nodes and links in the system and make decisions over them in the jordan model these institutions represent real world agencies which allocate water from their supply nodes to their water user nodes each institution uses a linear programming formulation that minimizes water deficit the difference between allocated water volume and baseline demand in determining current and projected water allocations to the water user nodes pynsim s ability to represent non physical hierarchies makes possible the deployment of such institutional agents the simulation is run for a 10 year historical period and a 50 year future period for a diverse set of scenario and intervention combinations pynsim tracks component properties of interest e g groundwater head levels at each groundwater node water purchases at each water user node etc over time which are used for system performance evaluation pynsim provides a common framework for the development of a complex integrated model streamlining software architecture design and easing module compatibility particularly in a collaborative interdisciplinary model development environment the framework provides a common architecture for development while also allowing for a high degree of flexibility for component extension as demonstrated by the ability to use pynsim components to simulate a wide range of processes from physical hydrologic flow to an abstracted private water tanker market the component based structure of pynsim allowed the code base to be broken up into manageable parts and for each developer to build and test their engine in isolation this allowed new engines or updates to be integrated in a structured and controlled way for the jordan water project the framework serves as a means to standardize model conceptualization and development among a group of researchers from a variety of disciplines each approaching environmental modelling from a unique disciplinary and methodological perspective 5 2 investment planning for run of river power plants with an increasing electricity demand and the decision to phase out nuclear power plants the swiss energy strategy plans for an increase in hydropower production the already high degree of exploited potential shifts the focus of hydropower expansion to small run of river power plants as riverine ecosystems are already exposed to multiple stressors affecting ecosystem functioning the impact of disrupted network connectivity within a river network should be included in the planning process altermatt 2013 this case study presents a tool to evaluate pareto optimal configurations of run of river power plants considering their effect on river network connectivity the positioning of run of river hydropower plants within a river network is formulated as a multi objective problem and solved with a multi objective evolutionary algorithm moea different objectives are considered such as total electricity production investment cost flow deficit and network connectivity each of which is implemented as a separate engine pareto optimal extension options are derived by linking a simulation model to the moea in this case borgmoea hadka and reed 2013 searching for optimal decision variable sets based on multiple objective values calculated by engines this requires the evaluation of different potential configurations running the simulation multiple times before evaluating one specific configuration the network topology needs to be defined based on decision variables provided by the optimisation algorithm see fig 3 this demonstrates the ability of pynsim to build a network topology through code based on exogenous data sources to save computation time those parts of the network that do not change during the optimisation process i e the river itself are generated beforehand this allows reuse of the basic network structure including data without the need for instantiating a new network object for each simulation run parameter values provided by the optimisation algorithm can be set on an existing network thanks to the object oriented design of pynsim in order to represent the structures of a power plant as a whole the water intake the powerhouse and corresponding pipes are combined as institutions the investment cost is calculated at the institutional level institutions provide an intermediate hierarchy level well suited for representing institutional units in a model multiple engines are used before each objective is calculated a flow routing engine sets the discharges on each link in the whole network the use of an evolutionary optimisation algorithm imposes the need for a fast simulation model pynsim supports fast simulations by leaving the model developer in control over what code is executed pynsim s use of engines allows for enough granularity to include or exclude certain calculations with little effort this makes developing the model easier and less error prone 6 discussion pynsim was applied successfully to two case studies with different requirements and the lessons learned from these applications and in the continued development of pynsim have highlighted a number of benefits and limitations for the jordan water project pynsim provided a common framework for the development of a complex integrated model serving as a foundation to standardize model conceptualization and development among a group of researchers from a variety of disciplines hydrology systems analysis economics geography each approaching environmental modelling from a unique disciplinary and methodological perspective this foundation is based on pynsim s object oriented design and provision of a common network through which sub modules can interact pynsim s support for institutions hierarchical groupings of nodes and links were used to represent governance structures and their decision making processes additionally the deployment of engines institutions and agent nodes allowed for the use of optimisation in addition to rule based agent decision making processes pynsim s property history structures were relied on extensively for both processing of results as well as in agent s decision making processes finally pynsim s distinction of tracked properties for each agent simplified data management by providing a system to focus on variables of interest in the swiss power plant project the benefit of pynsim s object oriented structure is demonstrated in this case the modeller was an experienced python developer so pynsim s online documentation and availability through pypi were factors in choosing it for this project these are often considered a necessity for uptake of python libraries pynsim s institution class is used for the swiss model to provide grouping for a set of interdependent nodes rather than representing an organisational entity as in the jordan project linking to a multi objective evolutionary algorithm moea is achieved using one of python s freely available libraries pynsim s object oriented design is used because optimising the location of new hydropower plants required a network configuration which could be updated easily through code the primary limitations of pynsim can be broadly split into two categories performance how pynsim s overhead affects run times and its level of formalisation and standardization being written in python an interpreted scripting language pynsim has an inherent drawback in performance compared to compiled languages such as c or c our experience is that the benefits of ease of use and accessibility outweighs potential limitations of computational performance the two case studies demonstrated that computational efficiency of pynsim engines have the most impact on model run durations the inherent drawback therefore is not necessarily in pynsim but in the engine and component setup code which is the responsibility of the developer to streamline fig 4 shows the overhead of pynsim as a function of the number of time steps and the number of components in the network in these test cases a single empty engine is used with increasing numbers of nodes containing empty setup functions and an increasing number of time steps the linear increase indicates stable performance while the general network structure and flexible approach to integration makes pynsim applicable to several areas one could argue that pynsim is too flexible affording model developers too much freedom the responsibility for non python experts to build an entire python based structure for a simulator may be infeasible for some developers we have endeavoured for pynsim to strike an effective balance between flexibility and structure as demonstrated in the jordan water project pynsim comes with extensive online documentation and includes several examples but even with this support we are aware that some model developers will be apprehensive to build models from scratch in python this is where we anticipate that the model development community can come together to build pynsim extensions for their areas of expertise with libraries of component types and standardised ways of importing and exporting data to common external formats pynsim is under continual development with ongoing feedback of application developers taken into account some notable areas of planned pynsim development are integration with existing model development platforms improvement of documentation and formalisation of how add on packages can be used and published improving efficiency is a constant goal such as streamlining storage of the history of component properties e g only saving the values when they change to reduce memory usage in addition the ability to easily run multiple engines in parallel would allow developers to maximise their computing resources the online documentation would benefit from more examples including those of greater technical complexity this is an area which needs continuous improvement finally compliance is a goal with efforts currently underway to make engines compatible with the bmi standard while out of scope of current pynsim develpment the availability of python libraries make bmi integration feasible with openmi compliance a longer term goal when support for openmi in python becomes more mature openmi compliance would give model developers within pynsim access to an existing community of models in addition to working towards a common future vision where model frameworks are more interoperable laniak et al 2013 7 conclusions as many models of environmental resource systems benefit from an integrated and multidisciplinary multi actor representation of the modelled domain integrating specialised models at runtime is increasingly useful there are multiple ways of performing model integration from adhering to static input output standards to directly developing components around a single software structure component based modelling achieving a sustainable reusable model can be a challenge as most model developers do not have a formal background in software development and require a framework which is initially accessible but which can be extended to support sophisticated scientific aims and methods the jordan water project is an example of this situation we presented pynsim a python library designed to aid in the rapid development of customised networked resource system simulators pynsim uses a network structure as the common data representation and employs a modular design where external sub models or engines interact with the network instead of directly with each other engines take the data they need from the network perform a calculation either directly in python or by calling an external model or service and then save results back on the network s components it is within these network components that input data and results are expected to be stored as a simulation progresses pynsim records changes to properties of the nodes and links allowing for post processing of data and analysis using the network as the central data storage structure ensures a common means of communication between engines a setup function is called on each component individually at each time step and each component object has access to current and historical simulation data this approach allows components to act as independent agents within the simulation in addition to nodes and links a pynsim network can contain institutions groupings of nodes and links allowing pynsim to support representation of non physical hierarchies such as government institutions or social groups the jwp used institutions to represent organisational hierarchies while the swiss model used institutions to represent an interdependent set of nodes the practical application of pynsim is demonstrated by two case studies the details of which are summarised in table 1 the jordan water project jwp benefitted from pynsim s component based architecture as multiple sub models were integrated into a single multi agent model of jordan s water resources system the jwp was developed by a diverse group of scientists none of whom had any formal prior software development experience using pynsim a modular code base was produced which streamlined updates testing and integration several external data sources and models were used by this model all connected using pynsim s engines pynsim s support for agents was used for independent decision making of some nodes while its institutions allowed the representation of hierarchical decision processes pynsim s flexibility is demonstrated by the second case study in which the network s topology is dynamically created from an external source and then altered while searching for the optimal placement of new power plants on an existing river network this project used a multi objective evolutionary algorithm illustrating how pynsim can be connected to an external processing source through institutions groupings of interconnecting nodes could be referred to as one entity pynsim relies on model developers embracing python as the language linking their models to data and other models opportunely python is becoming more common in water resources and environmental modelling and so this approach may be attractive to model developers seeking to integrate multiple models acknowledgments this work was conducted as part of the belmont forum water security theme funded in the uk by the natural environment research council nerc under grant ne l009285 2 to the university of manchester and grant ne l009285 1 to university college london and in the us by the national science foundation under grant geo oad 1342869 to stanford university appendix a supplementary data the following is the supplementary data related to this article data profile data profile appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 01 019 
26404,modelling managed resource systems can involve the integration of multiple software modules into a single codebase these modules are often written by non software specialists using heterogeneous terminologies and modelling approaches one approach to model integration is to use a central structure to which each external module connects this common interface acts as an agreed mode of communication for all contributors we propose the python network simulation pynsim framework an open source library for building simulation models of networked systems pynsim s central structure is a network but it also supports non physical entities like organisational hierarchies we present two case studies using pynsim which demonstrate how its use can lead to flexible and maintainable simulation models first is a multi agent model simulating the hydrologic and human components of jordan s water system the second uses a multi objective evolutionary algorithm to identify the best locations for new run of river power plants in switzerland keywords modelling framework simulation python open source software availability program title pynsim developer stephen knox contact address stephen knox manchester ac uk software access https www github com umwrg pynsim year first available 2015 hardware required windows 7 10 tested linux macosx program language python program size 116k availability and cost open source license gpl3 1 introduction the use of simulation to model managed environmental systems is well established buytaert et al 2012 loucks et al 2005 robinson 2014 sánchez 2007 thorp and bronson 2013 as is the need to integrate models from multiple disciplines in order to represent the complexities and interdependencies of environmental systems burroughs 2007 castilla rho et al 2015 knapen et al 2013 integrated modelling aims to combine models from multiple different disciplines such as ecology sociology daloğlu et al 2014 water resources economics harou et al 2009 and water resources sociology barthel et al 2008 in addition to the integration of multiple disciplines some models aim to enable decision making of individual actors within the modelled system the dynamic interaction and communication between actors within the domain can be modelled using an agent based approach schreinemachers and berger 2011 agent based modelling is an established methodology to resource modelling castilla rho et al 2015 kelly et al 2013 tesfatsion et al 2017 and several toolkits and languages are available hiebeler et al 1994 luke et al 2003 collier et al 2003 tisue and wilensky 2004 multi agent based simulation mabs is a widely used technique with several examples of cross disciplinary model integration ghazi et al 2014 bosse et al 2013 daloğlu et al 2014 a common approach to model integration is component based modelling in which processes within an integrated model are represented by pluggable model components these integrated models are known as integrated environmental models or iems component based models are often implemented as an environmental modelling framework which are standards or software systems used to build and integrate models around a single coherent structure emfs provide abstractions for defining the input and output of models and the domains on which the models operate emfs differ in the domain they apply to ranging from the specific hill et al 2004 to the general david et al 2013 bernholdt et al 2002 and in the degree to which they require the model to be altered their invasiveness lloyd et al 2011 dozier et al 2016 the decision to integrate a model into an emf therefore relies on how much the model itself must be modified in order to allow integration and on the value of its inclusion the increasing integration of models and the complexity of the software required to support advances in integrated modelling is hampered by the ability of model developers to create sustainable code bases which are usable beyond the scope of an individual project david et al 2013 development of such code bases is often difficult to justify as academic projects tend to focus on scientific accuracy and expediency over software sustainability and scalability in their vision and roadmap for the future of iem laniak et al 2013 describe the need for the environmental modelling community to make software development and sharing more prominent in addition to considering their work to be a part of a larger ecosystem one step towards this goal is to encourage the use of existing open source technologies which allow model developers to build components and to publish them through well established software repositories this can only be achieved by building a structure for model development and integration which is attractive and simple enough to encourage uptake and involvement from the wider community component based modelling frameworks rely on a consistent underlying structure to which all components integrate some approaches use standards where each model uses the framework to explicitly define the input and output parameters required to run the model gregersen et al 2007 others provide a common structure to which all models must comply for example most water resource management modelling problems can be abstracted to networks of nodes and links letcher et al 2007 recent work on network modelling software generalises network structures allowing them to be applied to more than one domain like water resources energy and transport and any other domain in which network structures are used harou et al 2010 knox et al 2014 meier et al 2014 such an abstraction pushes the responsibility of domain specific representation and functionality to the model developers themselves and in doing so can support models spanning multiple disciplines a generic network representation could allow for example multiple networks stored within the same system to be combined by linking models e g the output of a water resource model is fed into the input of an energy management model by specifying a commonality between two different networks lee et al 2007 such as representing a hydroelectric dam which serves as both a water supply reservoir in a water model and a production source in the energy model using a network structure to tie multiple models together also allows for the support of multi agent behaviour where the model components can not only act on the network as a whole but where each node or combination of nodes within the network can execute code independently at each time step the work presented in this paper is referred to as the python network simulation pynsim framework a python package containing abstract classes which are designed to be extended using an object oriented structure pynsim adopts a modular design allowing multiple users to plug in their code and uses a central network structure to provide a common interface where each module interacts with the network not directly with each other it allows simulations to be performed where multiple sub models adhere to a common representation of a network of nodes and links rather than imposing any particular standard for model communication pynsim provides a basic structure upon which network based simulations can be built laying the groundwork for components of those simulations to be released as public python libraries pynsim is an object oriented framework written in python and attempts to build on the design of existing modelling frameworks it aims to facilitate model integration agent based modelling and the use of a component based design where components can be added and removed with ease in addition to incorporating a component based model integration through the use of pluggable modules it also supports agent based modelling by allowing each network element node link or institution to execute code individually at run time an institution allows pynsim to represent organisational and other non physical hierarchies by acting as a container for nodes links and other institutions the contribution of this work is a component based simulation framework designed specifically for networks including representation of decision making hierarchies and support for multi agent modelling and which is accessible as a standard python library two case studies demonstrate how pynsim s features and associated modelling approach aided development and led to flexible and maintainable human environment system simulation models this paper is structured as follows section 2 describes related work in integrated and agent based modelling section 3 identifies features of related frameworks and then introduces pynsim and its unique functionality implementation details of pynsim are then presented in section 4 two case studies are presented in section 5 finally a discussion and concluding remarks are presented in sections 6 and 7 2 related work 2 1 modelling frameworks environmental modelling frameworks emfs support modular development of integrated models through provision of libraries of core modules and reusable tools for common tasks such as unit conversion language interoperability data manipulation analysis and visualisation argent et al 2006 the object modelling system oms is an open source emf which maintains the design principles of the earlier modular modelling system mms david et al 2013 leavesley et al 2007 oms has a facility to build simulations allowing definition of time steps parameters and models for environmental modelling oms is java based and offers a lightweight non invasive the models themselves change very little if at all framework for integrating models together this is done by using code annotation to describe the required model parameters and a simple scripting language to connect the models oms focusses on reducing the amount of code required to integrate models the open modelling interface openmi gregersen et al 2007 is a standard for the exchange of data between models at runtime castronova et al 2013b openmi is implemented as a set of object oriented interface classes and supports the integration of models guis and data sources where each one can be developed independently and then integrated as linkable components through use of these interfaces legacy models can be integrated to openmi through a wrapper which runs the model code inside an openmi compliant linkable component this minimises the changes required to the model code itself in addition to the standard itself openmi provides a software development kit sdk for java and c to simplify the creation of components and the omied desktop application for graphically linking models the openmi framework has been used in several research projects internationally for environmental modelling knapen et al 2013 goodall et al 2011 2013 in 2014 it was adopted as an official standard by the open geospatial consortium ogc the community surface dynamics modelling system csdms is a modelling framework comprising of two parts the basic modelling interface bmi and the component modelling interface cmi peckham et al 2013 bmi provides an object oriented programming interface similar to openmi which allows a model to plug into the cmi framework the cmi provides the ability to match models written in different programming languages perform unit conversion and provides a gui to manage components to be bmi compliant the model developer must implement three functions from a bmi main interface initialize to set up the component update where the main functionality is implemented and which updates the state variables at each time step and finalize which tears down the model for instance deallocating memory or saving results bmi is the basis of the lighter weight emeli experimental modelling environment for linking and interoperability a modelling framework written in python that was designed to allow the re use of component models by using a standardised interface most recently emeli has been extended as a web service allowing it to integrate bmi enabled web services thereby making them language agnostic peckham 2014 jiang et al 2017 projects aimed at linking bmi to openmi are under way in an effort to create a more cohesive offering of integrated model frameworks goodall and peckman 2016 a web based approach is also used by the dmif distributed model integration framework which connects models deployed on different hardware and software platforms using web services belete et al 2017 the technical interoperability within dmif was tested by connecting gams and netlogo the former an optimisation based language and the latter an agent based simulator this shows a clear path of development towards combining agent based simulations with external optimisation techniques a capability offered in pynsim 2 2 multi agent modelling multi agent modelling is a popular approach to environmental modelling as it allows complex questions to be broken down into atomic parts where the interaction of sub components of a system are modelled independently bousquet et al 1999 argue that the theory of multi agent systems not only offers pertinent and powerful formalization tools but also provides a better framework for computer simulations many different definitions of agent based modelling exist and have been discussed extensively thiele et al 2011 castilla rho et al 2015 davidsson 2000 we refer to an agent as something which takes input from the environment and produces actions as outputs that affect the environment but with incomplete information at the agent level and without a global control mechanism wooldridge 2009 several agent based languages and toolkits are available and used in environmental modelling these include netlogo tisue and wilensky 2004 repast galán et al 2009 jade pipattanasomporn et al 2009 agent factory and nxsim to name a few of these netlogo repast and cormas have been used within environmental modelling and are described here nxsim being python based is also described netlogo tisue and wilensky 2004 has been used for modelling social and environmental interactions in groundwater systems castilla rho et al 2015 netlogo is a generalised simulation environment allowing agent based simulations in several domains netlogo supports both grid based and network based agent connections in addition to having a user interface it provides a built in scripting language for defining agent behaviour for integrating with external models and for more advanced developers netlogo provides extension libraries for integrating programming languages such as java r and matlab repast is a suite of generic open source simulation platforms written in java which has been used to model water management systems galán et al 2009 repast is aimed at both novice developers through its relogo platform but can be used to build scalable distributed simulations using repast symphony repast is a java api providing a suite of tools for running simulations and developed using a philosophy of abstraction of simulation infrastructure extensibility and good enough performance collier 2003 one of the approaches employed by repast to simplify initial development is to incorporate python scripting being an api repast passes the responsibility of code organisation to the developer rather than prescribing a particular structure cormas common pool resources and multi agent systems is a multi agent platform written in smalltalk bousquet et al 1998 originally designed for modelling resource management cormas has been applied to several other areas using multi agent simulation through its user interface an environment of agents can be created where each agent is either a subclass of a spatial agent with geographic information but with limited ability to communicate or a communicating agent with no spatial properties but which can send messages to other communicating agents these agents can then be programmed as necessary this structure reflects the design presented by bousquet et al 1999 which describes the need for institutions which can represent abstract hierarchies as well as spatial agents reflecting physical entities cormas has been applied to multiple environmental multi agent systems such as simulating irrigation systems barreteau and bousquet 2000 river catchments becu et al 2003 and social ecological systems saqalli et al 2010 nxsim is a python library designed for network based agent based modelling nxsim is designed to support large networks of a single type of agent nxsim is open source and based on the well known networkx hagbert et al 2004 library to represent topology and on simpy lünsdorf and scherfke 2013 for discrete time simulation 3 pynsim a common theme with recent developments in model frameworks is the goal to abstract the complexity of the software infrastructure with the assumption that many model developers have limited skills in software development and architecture müller 2010 tisue and wilensky 2004 by contrast scripting has become a common feature of modelling particularly the use of python marta almeida et al 2011 thorp and bronson 2013 as resource models become increasingly sophisticated castronova et al 2013a ames et al 2009 a flexible approach is becoming more relevant where through a well defined software architecture modellers can define their own modules write their own code and rapidly build resource network models to keep up with modern technologies the approach should allow for the use of components buahin and horsburgh 2015 whelan et al 2014 which can be interchanged and be able to represent both the physical and non physical aspects of a domain given an appropriate structure scripting can become more accessible to modellers and the steep initial learning curve is outweighed by the flexibility gained and the potential of benefiting from a wider community of software developers the hydroshare platform demonstrates that such a software development community already exists within the water resources community tarboton et al 2013 morsy et al 2017 several technologies and solutions exist for integrated environmental modelling summarised in kelly et al 2013 but many solutions tend to focus on one specific problem area or domain even in a cross disciplinary context for example the agent based framework emlab chappin et al 2017 focusses on energy and climate specifically by using a simple basic structure capable of being extended a more general framework could be used widening the number of applications and models which can be integrated pynsim pronounced pinsim is a modelling framework designed to allow building networked resource system simulators in a structured way pynsim uses an object oriented approach to define the network its properties and simulation behaviour this approach allows the structure to be general and modular meaning pynsim can be applied to many areas of network modelling and allows multiple behaviour defining codes to be integrated into a single simulation pynsim is a modelling framework in that it supports the integration of multiple modules acting on a central data structure a network where the network is effectively the means of communication between modules pynsim takes several design cues from existing modelling frameworks detailed in section 2 such as adopting object oriented classes for structure lightweight design and a component based architecture but narrows the focus of application to the simulation of managed resource system networks pynsim does not attempt to formalise attribute matching unit conversion or provide cross language interoperability in designing pynsim best practices and design philosophies from related works led to a set of requirements for the new modelling framework the framework should support the simulation of a network of agents it should be generalised to cater for multiple domains and should allow model integration using object oriented classes as the semantic glue it should also provide a means to add and remove algorithms and processes from the simulation with ease this framework should be a standard software library therefore depending on external systems for visualisation data analysis and management pynsim s novelty is that it is a generic network simulation framework written in python capable of supporting multi agent modelling and representing the physical and hierarchical aspects of network based systems the use of python has several benefits python is already a recognised tool in resource modelling marta almeida et al 2011 fienen and plant 2015 thorp and bronson 2013 python scripts can be made openmi and bmi compliant allowing broad integration into an established environmental modelling ecosystem bulatewicz et al 2013 python offers numerical and scientific libraries such as pandas numpy and scipy in pyomo python has a native optimisation language ready made allowing tightly coupled model integration extensions to core libraries can be published and downloaded through the python package index pypi pynsim supports component based modelling whelan et al 2014 buahin and horsburgh 2015 by virtue of its object oriented structure and through its ability to configure and manage multiple engines see section 4 additionally pynsim is suitable for agent based modelling wooldridge 2009 castilla rho et al 2015 as each component of a network is capable of running its own decision making code pynsim does not impose a component based or agent based approach instead it provides the framework in which one or both of these approaches can be adopted the pynsim codebase is lightweight in that it has no dependencies on external libraries and does not present a significant computational overhead see section 6 definitions pynsim uses the following terminology to describe its elements these mirror the class names used within the pynsim code module a file or folder containing python definitions and statements object an instance of a class as defined within a module from object oriented design principles network component type the blueprint of a network component node link or the network itself with a unique set of properties to represent a structural element in the network network component an instance of a component type computation can take place within a component in pynsim a component refers to the constituent parts of a network a component is an object engine a piece of software that performs calculations i e a sub model an engine calls an algorithm or a collection of algorithms that simulates or optimises a process multiple engines can exist within a generic model and provide a means of controlling the sequence of processes generic model a collection of defined component types and engines model an instance of a generic model applied to a particular system this includes the network topology but without data simulation a run or instance of a model with a particular set of model parameters boundary and initial conditions also termed a model run 3 1 design with pynsim a developer first creates a generic model defining component types and engines and their behaviour next a model is created by defining instances of these component types after applying input data to these components the model can be run a simulation pynsim uses an object oriented design providing a set of abstract classes which must be extended to build a simulator see fig 1 building a model in pynsim requires first creating subclasses of the base network components which we call building a generic model these classes illustrated in fig 1 are network node link institution a grouping of nodes and links engines and a simulator the abstract classes provided by pynsim are designed to be extended using inheritance a fundamental feature of object oriented programming oop inheritance is a mechanism for establishing is a relationships between objects whereby an object is based on a higher level object in this way the more specific object sub class exhibits the same behaviour and contains the same properties as that of the higher level object super class but with additional properties and behaviour the classes created for a generic model are what make it specific to a domain in one domain a subclass of node class may represent a power station while in another the class may represent a junction in a transport network or a group of farms in an agricultural region the same principle applies to links institutions and networks one or more engines must be defined by extending the engine abstract class engines contain the generic model s logic implemented either by activating an external sub model or by implementing the logic directly in python it is the model developer s responsibility to write linking code to external processes and therefore gives the developer control over the level of invasiveness required for implementing modifications engines are executed at each time step in a specific order defining an explicit sequence of processes the last step in building the model is creating instances of the network components and engines this is done in a python script adding the network and engines to the simulator defining the model run s time steps assigning data to the network components and then starting the simulation pynsim handles the progression of time as a series of discrete time steps the discretisation of time is defined before a simulation is run as pynsim iterates over the list of time steps a pre defined sequence is executed the sequence of a pynsim simulation is illustrated in fig 2 and occurs as follows 1 simulation starts 2 simulation begins iterating over the user defined time steps 3 for each time step t each network component node link and institution in the network sets itself up in preparation for being used in the engines this is the setup phase 4 at time step t one or more engines perform an action on the network or part of the network 5 at the end of time step t the network state is saved and the simulation continues the setup phase decouples the extraction of data for a given time step from operations performed on the network this makes engine code less complex as it only deals with the network at a single time step on each iteration 3 2 network components components comprise the topological structure of the network they include the network itself nodes links and institutions a component has some baseline properties like name description and component type but also supports user defined attributes which represent the properties relevant to the model and whose changes can be automatically recorded as the simulation progresses pynsim components contain a setup function at each time step of the simulation this function is called for every component individually the setup function has two roles the first role is to allow each component to retrieve and set property values for the current time step this may involve querying external databases or other forms of exogenous data structures data calculated during previous time steps may also be retrieved during setup all the components in the network then set these properties locally having set parameters locally the second role of the setup function is to implement some more intelligent and autonomous decision making behaviour based on its current or past state this is where a component can take the role of an agent as the setup code is run on each component independently 3 2 1 nodes and links nodes and links provide the basic structure of a network a node can represent any physical or abstract entity provided it has a name and a coordinate a link is defined by a name a start node and an end node and therefore cannot exist without nodes nodes and links act in the same way in that they are both set up at the beginning of each time step and have a set of user defined properties which an engine can access 3 2 2 institution institutions represent some grouping of other network components this grouping can represent a physical similarity all farms in a district or a more abstract grouping such as all power stations owned by owner x an institution can contain multiple nodes links and other institutions in addition to creating logical groupings for physical components institutions can be used to implement hierarchical decision making such as national and regional government policy being a network component like nodes and links institutions are also set up at each time step 3 2 3 network the network is the container for all the nodes links and institutions the network class contains several functions to manage its sub components such as functions for adding and removing nodes and links in addition a network has basic utility functions for visualising its topology and graphing properties over time a model is associated with exactly one network system topology 3 2 4 properties in pynsim a list of properties are defined for each component type a property is a state simulation or decision optimisation variable as opposed to temporary or transient variables used during calculations or fixed parameters that do not change over the course of the model run a property often stores a model result or a value required by another component in the current time step or by itself in a future time step at each time step in a pynsim simulation the properties of an individual network component can be set either during the setup phase or by an engine the types of properties that the components have are defined in their subclass pynsim provides a standardised way of defining properties making it easy to distinguish a property pertinent to the model from other temporary variables or fixed parameters the primary reason for defining properties explicitly is that it allows pynsim to track changes to these properties over time the value of each property is stored in an internal history structure at the end of each time step when the simulation is complete the history of each property can be interrogated allowing for in depth post processing history can also be interrogated by components mid simulation allowing them to make decisions based on historical data pynsim provides a visualisation function in which the changes to a property can be plotted over time 3 3 engines an engine is a piece of software that performs calculations gregersen et al 2007 pynsim models must contain at least one engine which performs an operation on a target a target can be the network itself as well as an institution in the network or an individual node in pynsim an engine s operations can be performed fully within its own functions using an external model or by calling functions on components within the target engines can be initialised at the start of the simulation run at each time step and finalised at the simulation s end reflecting the intialise update finalise design seen in other component based architectures pynsim supports multiple engines running sequentially this allows the same network to be used in several sub models guaranteeing consistency of data and allowing sub models focussing on different aspects of the problem area to be integrated into the same system the operation of the engine itself does not need to be written in python code written in external languages may require the developer to convert the network into input files for the external model it is here that more specialised frameworks for integration of sub models could be used when the external code is run the results could be parsed in python and saved using this approach any new or legacy code can be integrated with pynsim provided the developer writes the input and output parsing in the engine class no automatic standardisation of units or attribute names is performed by pynsim it is the responsibility of the engine developers to ensure consistency of data and attribute names 3 4 simulator the pynsim simulator controls the model runs and acts as a container for the network and engines the time steps for the model run are specified in the simulator when the simulation starts the simulator initialises each engine by calling its initialise function it then iterates over these time steps setting up the network calling the setup function of each component then running each engine in turn calling the run function of each engine for each time step finally each engine is finalized by calling its teardown function 4 implementation pynsim provides a suite of abstract classes with a simple code structure all of which can be but don t necessarily need to be extended there are three modules providing the base classes and functionality engine component and simulator the component module contains the base classes for the network topology network node link and institution these classes must be extended to define the elements of the network the engine module contains the abstract class engine this class must be extended for the simulator to provide functionality the simulator module holds the simulator class it is here that a simulation is controlled the simulator class contains simple features such as start add engine add network etc a simulator class must be instantiated and the network and engine must be loaded into the simulator the time steps for the simulation must also be defined explicitly 4 1 time steps the only rule for time steps is that they must be specified as an iterator there is no restriction on what format the time step itself takes time steps are a simulator property so must be set on the simulator object by default time steps is an empty list so if no time steps are specified before the simulation is started pynsim will return an error valid time steps might be mon tue wed thu fri or 2018 01 01 2018 02 01 2018 03 01 2018 04 01 when the simulation is started it iterates over the time steps list calling the setup functions and then running the engines for each time step the network and each engine has access to the current time step as well as the time step index the time step index is the current numerical point in the time step list for example in the daily time steps above wed has a time step index of 2 by accessing the time step index engines can be defined to perform certain processes at only specific time steps e g an annual process that is only run at every 12 time steps for a monthly model 4 2 properties exogenous data can be set as a regular attribute on a component but pynsim also provides a means of allowing the model to define and then keep track of properties which may require analysis once the simulation has been completed this is done using the properties attribute the underscore postfix is a python convention used to indicate an attribute which is private to an object and not meant to be accessed externally properties must be defined as an attribute of every component and is a python dictionary the keys of this dictionary are the component s properties and the values are its defaults upon creation of each component the contents of this dictionary are converted into object attributes defaulted to the value specified in the dictionary for example a class defining a reservoir might have a water level property image 1 when instantiated the reservoir object will have a water level attribute from the example above an object myres myres water level will yield 100 this approach is taken so pynsim can track certain properties while ignoring others at the end of each time step every property which was defined in the properties dictionary is recorded in an internal history structure every network component has a history property history this is a python dictionary keyed on property name the values of the dictionary are implemented as lists which is appended at the end of each time step with the current value of that property by the end of the simulation the change to every one of these properties has been stored and indexed by time step this allows for analysis of data changes throughout the simulation 4 3 engines an engine is implemented as an abstract python class with three functions initialise run teardown when implementing an engine a developer must subclass this abstract class and implement at least the run function this function is called during every time step of the simulation the initialise and teardown functions are called at the beginning and end of the simulation respectively this approach matches the design pattern commonly used in object oriented component modelling interfaces like bmi openmi and oms the contents of an engine s functions are at the discretion of the developer with the initialisation step typically used for loading external data the run function used to propagate a sub model in time and teardown used for storing or parsing result data when instantiating an engine a target must be specified this represents the network or component of the network upon which the engine will perform its calculations a target must be a subclass of the component type i e network node link institution the run function can be used in two ways to perform a function which can be written natively in python or to run an external program in the latter case the target must be converted into an input for the external program and the result of this program must be interpreted with the resulting data set back on the target engines are added to a simulator using the add engine function which appends the engine object to an iterator simulator engines within the simulation when the simulation begins it iterates over this list calling engine run on each engine allowing for an explicit sequencing of model processes through the ordering of the engines list 4 4 data and result analysis pynsim provides several high level features for data analysis including drawing the topology of the network analysing results data and identifying areas of poor performance in terms of run time we briefly detail these features here pynsim records the changes to the properties of components at each time step by calling a component s get history my property function the value of a specified property can be retrieved for each time step a simple suite of visualisation tools are provided to allow a user to graph changes to a property over time this is implemented in the network plot my property function and takes a property name as an argument this inbuilt data analysis functionality is designed to provide quick high level information to developers which may be extended as necessary rather than as an in depth analysis tool like that presented by white et al 2016 and jin et al 2017 no assumption is made about what kind of analysis a user might require so more detailed analysis is left to the developer to perform visualisations are produced using matplotlib but pynsim does not rely on matplotlib being installed to run only when the relevant graphical functions are called this maintains pynsim s lightweight but readily expandable functionality while availing of existing python libraries in addition to data analysis pynsim provides analyses on computational performance the time taken to run each engine and each setup function can be recorded by setting the record time argument of the simulator to true timings can be visualised by calling the simulator plot timing function this function provides a graph of the cumulative time taken for the setup function of every resource in the network and for each engine for more detailed performance analysis the timings of each node link and institutions can also be graphed individually using the network object s plot timing function likewise if the simulator contains multiple engines the performance of each can be plotted using the simulator s plot engine timing function these tools allow a developer to identify bottlenecks quickly without having to use external profiling tools as with the data analysis the philosophy of pynsim is to provide high level analysis tools to identify obvious irregularities but detailed analysis is left to the developer 5 case studies this section presents two case studies in which pynsim has been used they highlight different aspects of pynsim demonstrating its use in multiple applications 5 1 the jordan water project the jordan water project jwp is a collaborative interdisciplinary research effort focused on the development of a multi agent hydroeconomic model for the evaluation of policy interventions in jordan which ranks as one of the most vulnerable countries in the world in terms of freshwater supply padowski et al 2015 rajsekhar and gorelick 2017 the goal of the project is to enhance jordan s long term water security in the face of climate and socioeconomic change the central feature of the jwp is an integrated model which couples spatially explicit representation of hydrologic systems with multi agent representation of water allocation and use at both institutional and consumer levels of human decision making through pynsim s component and engine architecture the model adopts a modular structure with individual modules developed and calibrated independently and subsequently linked through the identification of important interactions and feedbacks in the system the overarching model structure is simulation based i e non optimization though sub system level optimization algorithms are adopted for specific modules the project team includes researchers from a variety of disciplines hydrology water resource systems analysis economics geography each responsible for development of specific modules given the interdisciplinary makeup of the team and the complexity of the model structure the jwp serves as an example for utilising the pynsim framework in enhancing complex human natural model development while an in depth analysis of the model is beyond the scope of this paper we illustrate some modules of the jordan water project that highlight the use and value of pynsim focussing on a cross section of the physical social and institutional aspects of the system the groundwater system is represented through a set of approximately 200 groundwater nodes each node uses a pynsim property which tracks the groundwater lift from the water table to the ground surface a response function is written using a pynsim engine which consolidates pumping information from the human agents then calculates the response of the groundwater system at every groundwater node using a response matrix maddock 1972 these engines use external drawdown tables pre processed from hundreds of modflow simulations illustrating how a pynsim engine is linked to an external source to perform calculations or access information at each time period households implemented as pynsim nodes request and purchase water from multiple water sources institutional allocators and private water tankers in response to prices and availability of the various sources and in accordance with a unique demand curve klassert et al 2015 households make initial demand calculations independently based on their current circumstance executed during the setup phase of the time step the amount of water purchased the price of purchase and the consumer surplus of every household node is tracked for all model time periods using pynsim s properties these are later used for model validation and analysis private tankers act as an informal water market between farmers who own private groundwater wells and urban households the private tanker water market is implemented as an institution and uses a market algorithm that matches willing farm sellers with urban buyers factoring in transportation cost based upon distance between any two farm and urban nodes the tanker market uses the flexibility of the pynsim institution class to model non spatial abstractions such as a water market applied to resource networks farms implemented as pynsim nodes attempt to maximize profit under a set of physical and behavioural constraints many of which are imposed by other pynsim components in the system farms use the dynamic groundwater lift stored in the groundwater nodes as input to their optimisation calculation which is performed through an engine that calls an external gams model run here the support for agent based decision making integrated with external optimization solvers is demonstrated with each farm needing to dynamically decide on whether to sell its water or use it for irrigation organizational level allocator agents are implemented as pynsim institution classes in contrast to the water user agents which are implemented as spatial nodes the institutional agents are entities that contain a subset of the nodes and links in the system and make decisions over them in the jordan model these institutions represent real world agencies which allocate water from their supply nodes to their water user nodes each institution uses a linear programming formulation that minimizes water deficit the difference between allocated water volume and baseline demand in determining current and projected water allocations to the water user nodes pynsim s ability to represent non physical hierarchies makes possible the deployment of such institutional agents the simulation is run for a 10 year historical period and a 50 year future period for a diverse set of scenario and intervention combinations pynsim tracks component properties of interest e g groundwater head levels at each groundwater node water purchases at each water user node etc over time which are used for system performance evaluation pynsim provides a common framework for the development of a complex integrated model streamlining software architecture design and easing module compatibility particularly in a collaborative interdisciplinary model development environment the framework provides a common architecture for development while also allowing for a high degree of flexibility for component extension as demonstrated by the ability to use pynsim components to simulate a wide range of processes from physical hydrologic flow to an abstracted private water tanker market the component based structure of pynsim allowed the code base to be broken up into manageable parts and for each developer to build and test their engine in isolation this allowed new engines or updates to be integrated in a structured and controlled way for the jordan water project the framework serves as a means to standardize model conceptualization and development among a group of researchers from a variety of disciplines each approaching environmental modelling from a unique disciplinary and methodological perspective 5 2 investment planning for run of river power plants with an increasing electricity demand and the decision to phase out nuclear power plants the swiss energy strategy plans for an increase in hydropower production the already high degree of exploited potential shifts the focus of hydropower expansion to small run of river power plants as riverine ecosystems are already exposed to multiple stressors affecting ecosystem functioning the impact of disrupted network connectivity within a river network should be included in the planning process altermatt 2013 this case study presents a tool to evaluate pareto optimal configurations of run of river power plants considering their effect on river network connectivity the positioning of run of river hydropower plants within a river network is formulated as a multi objective problem and solved with a multi objective evolutionary algorithm moea different objectives are considered such as total electricity production investment cost flow deficit and network connectivity each of which is implemented as a separate engine pareto optimal extension options are derived by linking a simulation model to the moea in this case borgmoea hadka and reed 2013 searching for optimal decision variable sets based on multiple objective values calculated by engines this requires the evaluation of different potential configurations running the simulation multiple times before evaluating one specific configuration the network topology needs to be defined based on decision variables provided by the optimisation algorithm see fig 3 this demonstrates the ability of pynsim to build a network topology through code based on exogenous data sources to save computation time those parts of the network that do not change during the optimisation process i e the river itself are generated beforehand this allows reuse of the basic network structure including data without the need for instantiating a new network object for each simulation run parameter values provided by the optimisation algorithm can be set on an existing network thanks to the object oriented design of pynsim in order to represent the structures of a power plant as a whole the water intake the powerhouse and corresponding pipes are combined as institutions the investment cost is calculated at the institutional level institutions provide an intermediate hierarchy level well suited for representing institutional units in a model multiple engines are used before each objective is calculated a flow routing engine sets the discharges on each link in the whole network the use of an evolutionary optimisation algorithm imposes the need for a fast simulation model pynsim supports fast simulations by leaving the model developer in control over what code is executed pynsim s use of engines allows for enough granularity to include or exclude certain calculations with little effort this makes developing the model easier and less error prone 6 discussion pynsim was applied successfully to two case studies with different requirements and the lessons learned from these applications and in the continued development of pynsim have highlighted a number of benefits and limitations for the jordan water project pynsim provided a common framework for the development of a complex integrated model serving as a foundation to standardize model conceptualization and development among a group of researchers from a variety of disciplines hydrology systems analysis economics geography each approaching environmental modelling from a unique disciplinary and methodological perspective this foundation is based on pynsim s object oriented design and provision of a common network through which sub modules can interact pynsim s support for institutions hierarchical groupings of nodes and links were used to represent governance structures and their decision making processes additionally the deployment of engines institutions and agent nodes allowed for the use of optimisation in addition to rule based agent decision making processes pynsim s property history structures were relied on extensively for both processing of results as well as in agent s decision making processes finally pynsim s distinction of tracked properties for each agent simplified data management by providing a system to focus on variables of interest in the swiss power plant project the benefit of pynsim s object oriented structure is demonstrated in this case the modeller was an experienced python developer so pynsim s online documentation and availability through pypi were factors in choosing it for this project these are often considered a necessity for uptake of python libraries pynsim s institution class is used for the swiss model to provide grouping for a set of interdependent nodes rather than representing an organisational entity as in the jordan project linking to a multi objective evolutionary algorithm moea is achieved using one of python s freely available libraries pynsim s object oriented design is used because optimising the location of new hydropower plants required a network configuration which could be updated easily through code the primary limitations of pynsim can be broadly split into two categories performance how pynsim s overhead affects run times and its level of formalisation and standardization being written in python an interpreted scripting language pynsim has an inherent drawback in performance compared to compiled languages such as c or c our experience is that the benefits of ease of use and accessibility outweighs potential limitations of computational performance the two case studies demonstrated that computational efficiency of pynsim engines have the most impact on model run durations the inherent drawback therefore is not necessarily in pynsim but in the engine and component setup code which is the responsibility of the developer to streamline fig 4 shows the overhead of pynsim as a function of the number of time steps and the number of components in the network in these test cases a single empty engine is used with increasing numbers of nodes containing empty setup functions and an increasing number of time steps the linear increase indicates stable performance while the general network structure and flexible approach to integration makes pynsim applicable to several areas one could argue that pynsim is too flexible affording model developers too much freedom the responsibility for non python experts to build an entire python based structure for a simulator may be infeasible for some developers we have endeavoured for pynsim to strike an effective balance between flexibility and structure as demonstrated in the jordan water project pynsim comes with extensive online documentation and includes several examples but even with this support we are aware that some model developers will be apprehensive to build models from scratch in python this is where we anticipate that the model development community can come together to build pynsim extensions for their areas of expertise with libraries of component types and standardised ways of importing and exporting data to common external formats pynsim is under continual development with ongoing feedback of application developers taken into account some notable areas of planned pynsim development are integration with existing model development platforms improvement of documentation and formalisation of how add on packages can be used and published improving efficiency is a constant goal such as streamlining storage of the history of component properties e g only saving the values when they change to reduce memory usage in addition the ability to easily run multiple engines in parallel would allow developers to maximise their computing resources the online documentation would benefit from more examples including those of greater technical complexity this is an area which needs continuous improvement finally compliance is a goal with efforts currently underway to make engines compatible with the bmi standard while out of scope of current pynsim develpment the availability of python libraries make bmi integration feasible with openmi compliance a longer term goal when support for openmi in python becomes more mature openmi compliance would give model developers within pynsim access to an existing community of models in addition to working towards a common future vision where model frameworks are more interoperable laniak et al 2013 7 conclusions as many models of environmental resource systems benefit from an integrated and multidisciplinary multi actor representation of the modelled domain integrating specialised models at runtime is increasingly useful there are multiple ways of performing model integration from adhering to static input output standards to directly developing components around a single software structure component based modelling achieving a sustainable reusable model can be a challenge as most model developers do not have a formal background in software development and require a framework which is initially accessible but which can be extended to support sophisticated scientific aims and methods the jordan water project is an example of this situation we presented pynsim a python library designed to aid in the rapid development of customised networked resource system simulators pynsim uses a network structure as the common data representation and employs a modular design where external sub models or engines interact with the network instead of directly with each other engines take the data they need from the network perform a calculation either directly in python or by calling an external model or service and then save results back on the network s components it is within these network components that input data and results are expected to be stored as a simulation progresses pynsim records changes to properties of the nodes and links allowing for post processing of data and analysis using the network as the central data storage structure ensures a common means of communication between engines a setup function is called on each component individually at each time step and each component object has access to current and historical simulation data this approach allows components to act as independent agents within the simulation in addition to nodes and links a pynsim network can contain institutions groupings of nodes and links allowing pynsim to support representation of non physical hierarchies such as government institutions or social groups the jwp used institutions to represent organisational hierarchies while the swiss model used institutions to represent an interdependent set of nodes the practical application of pynsim is demonstrated by two case studies the details of which are summarised in table 1 the jordan water project jwp benefitted from pynsim s component based architecture as multiple sub models were integrated into a single multi agent model of jordan s water resources system the jwp was developed by a diverse group of scientists none of whom had any formal prior software development experience using pynsim a modular code base was produced which streamlined updates testing and integration several external data sources and models were used by this model all connected using pynsim s engines pynsim s support for agents was used for independent decision making of some nodes while its institutions allowed the representation of hierarchical decision processes pynsim s flexibility is demonstrated by the second case study in which the network s topology is dynamically created from an external source and then altered while searching for the optimal placement of new power plants on an existing river network this project used a multi objective evolutionary algorithm illustrating how pynsim can be connected to an external processing source through institutions groupings of interconnecting nodes could be referred to as one entity pynsim relies on model developers embracing python as the language linking their models to data and other models opportunely python is becoming more common in water resources and environmental modelling and so this approach may be attractive to model developers seeking to integrate multiple models acknowledgments this work was conducted as part of the belmont forum water security theme funded in the uk by the natural environment research council nerc under grant ne l009285 2 to the university of manchester and grant ne l009285 1 to university college london and in the us by the national science foundation under grant geo oad 1342869 to stanford university appendix a supplementary data the following is the supplementary data related to this article data profile data profile appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 01 019 
