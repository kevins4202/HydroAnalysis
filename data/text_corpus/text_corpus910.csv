index,text
4550,hydrological exchange flows hefs across the river aquifer interface and the associated transit time of river water in the aquifer have important implications for contaminant plume migration and biogeochemical processes in the river corridor hefs and transit time are influenced by both subsurface physical features and hydrologic forcing related to the transport process which can exhibit complex spatial and temporal variations in this study we used a massively parallel subsurface flow model and a particle tracking model to study the influences of different control factors on spatial variability of hefs and transit time distributions in the hanford reach of the columbia river in washington state 100 million particles were randomly injected in time and space and then tracked in a model domain that covers a 51 km2 area 15 1million model cells we used hourly river stages and groundwater levels to drive the model to provide dynamic velocity fields for the particle tracking in the two year simulation period the groundwater flow simulation and particle tracking results provide a comprehensive assessment of the spatial distribution of hefs and transit time in a large complex river corridor our results show that the aquifer hydrogeological structure has strong correlations with the extent and magnitude of exchange flux the transit time exhibits complex patterns that are affected by all the river geomorphologic hydrodynamic and hydrogeologic factors and are strongly correlated with the downwelling ratio of exchange flux the new insights gained through this study can be used to support the development of reduced order models of hefs and transit time distributions for large complex river systems keywords hydrological exchange flows transit time distribution discrete wavelet transform surface water groundwater interactions river corridor subsurface hydrogeology 1 introduction hydrologic exchange flows hefs are the bidirectional exchange flows between the mainstream channel and off channel riparian and floodplain areas including hyporheic exchange bank storage and overbank flow onto floodplains harvey and gooseff 2015 considered to be major players in biogeochemical cycles in the river corridor hefs modulate the supply transit time and temperature of substrates involved in biogeochemical cycles e g carbon nutrients and trace elements which account for up to 96 of respiration within river ecosystems gomez velez et al 2015 naegeli and uehlinger 1997 stegen et al 2016 quantification of the volume and transport time scale of hefs has been a central focus in river corridor research boano et al 2014 cardenas 2015 early studies revealed that hefs are influenced by multiple physical aspects including river geomorphology features such as the sequence of pools and riffles tonina and buffington 2007 stream meanders bars and dunes cardenas and wilson 2007 packman et al 2004 stonedahl et al 2013 riverbed sediments and underlain aquifer hydraulic properties such as hydraulic conductivity and porosity cardenas et al 2004 salehin et al 2004 river and floodplain hydrodynamic factors such as natural flow events e g flooding evapotranspiration tides and recharge larsen et al 2014 musial et al 2016 and anthropogenic activities e g dam induced stage fluctuations sawyer et al 2009 song et al 2018 these various influential factors exhibit distinct scale dependent variations which collectively induce co occurring and nested hef patterns across multiple spatial scales boano et al 2014 covino 2016 recently an increasing number of integrated models have been used to account for the joint influences of multiple physical aspects of hefs in real world settings brunner et al 2017 paniconi and putti 2015 for example gutiérrez jurado et al 2019 used the three dimensional 3d fully integrated surface subsurface model hydrogeosphere to simulate intermittent rivers and ephemeral streams and evaluate their control factors chow et al 2016 compared four different simulators hydrogeosphere watflow modflow and fellow to predict hefs in a 79 km2 watershed epting et al 2018 adopted modflow with conductance boundaries to identify river sections with intensified hefs however one question yet to be answered is how the spatial characteristics of complex physical aspects interact with and influence the spatial variabilities of hefs and transit times knowing the answer is critical to building predictive models of hefs at watershed to basin scales boano et al 2014 among the various influencing physical factors of hefs the hydraulic conductivity of the riverbed sediments is a particularly important first order control boano et al 2014 mattle et al 2001 numerical studies revealed that the riverbed hydraulic conductivity and its spatial heterogeneity have significant impacts on the magnitude bao et al 2018 kurtz et al 2013 lackey et al 2015 spatial extent schilling et al 2017b transit time and associated biogeochemical hot spots dai et al 2019 song et al 2018 of hefs however directly characterizing the riverbed hydraulic conductivity especially in large rivers has always been a great challenge due to the physical inaccessibility to deeper river channels and limitation on field samples hou et al 2017 moser et al 2003 thus uniform riverbed hydraulic conductivity conductance coefficient assumptions irvine et al 2012 were still widely used in numerical models schilling et al 2017a song et al 2020 recently data fusion methods showed promising results in improving riverbed sediment characterization by incorporating various indirect field measurements partington et al 2017 one representative data fusion approach is to estimate riverbed hydraulic conductivity from in situ monitoring data such as piezometric head temperature and tracer concentration by using data assimilation techniques kurtz et al 2014 tang et al 2018 2017 2015 alternatively we developed a novel machine learning based feature selection framework which can generate riverbed sediment facies maps based on more feasible hydrodynamic and bathymetric data hou et al 2019 the facies classification approach aims to provide an efficient way to systemically estimate riverbed conductivity at reach and watershed scales which in turn offers the potential to improve large scale predictions of river corridor hydrogeochemical processes in this study we evaluate the collective impacts of various river and subsurface features on hefs and their transport time scale in a representative large river corridor by using a massively parallel 3d subsurface flow and transport model and particle tracking simulations this comprehensive modeling study relies on the long term and extensive hydrologic and geologic datasets collected at the hanford site in south central washington state and high performance computing resources available at pacific northwest national laboratory our newly developed machine learning framework hou et al 2019 was adopted to create a heterogeneous representation of riverbed sediments for the groundwater model which was then driven by river stages extracted from a calibrated two dimensional 2d hydrodynamics river routing model to provide velocity fields for particle tracking we used a novel wavelet based spatial analysis method to evaluate the scale specific variabilities and correlations between various model predictors e g hydrogeologic parameters and response variables e g exchange flux rate and transit time this study improved understanding of scale dependent interaction among multiple geologic geomorphic and hydrogeologic features and their impacts on hefs in a typical large river corridor system 2 materials and methods 2 1 study site the study site is situated in the 100h area at the hanford reach of the columbia river the hanford reach is an 80 km free flowing river section in southeastern washington state fig 1 a the climate is characterized as arid to semiarid with an average annual precipitation of less than 180 mm conrad et al 2007 river discharge in the hanford reach is regulated by a series of upstream hydroelectric dams the river stage at the study site fluctuates up to 2 3 m annually and 0 5 m daily because of annual snowmelting events and power generation schedules arntzen et al 2006 the riverbed sediment in the hanford reach is predominantly coarse gravel ranging in size from granules to boulders rakowski et al 2006 the unconfined aquifer in the river corridor consists of two major geologic units 1 the upper coarse grained hanford formation and 2 the lower less permeable ringold formation thorne et al 2006 the ringold formation in the 100h area can be divided into three textural subunits 1 ringold e 2 ringold taylor flats and 3 ringold lower mud based on borehole data and geophysical logs shuai et al 2019 previous studies in the integrated field research challenge site at hanford 300 area characterized the strong heterogeneous distributions of highly permeable clast supported gravels and less permeable lenses of silty within the hanford formation chen et al 2012 however a similar high resolution 10 100 m characterization effort was not available for most parts of the hanford site in this study the permeability hydraulic conductivity field was assumed to be homogenous within each aquifer geologic unit with vertical permeability being an order of magnitude smaller than the horizontal permeability the hydraulic properties for the three hydrogeological units are listed in table 1 the land surface in the area is relatively flat as shown in the land surface topography map fig 1b because of historical nuclear fuel and weapons material production large amounts of chemical and radioactive waste were released to the soil surface and vadose zone at the hanford site usdoe 2017 these releases have created numerous groundwater contamination plumes and some of the plumes discharge directly to the columbia river dark blue contours in fig 1a these contaminant plumes in the river corridor exhibit complex temporal and spatial patterns that are influenced by river stage fluctuations zachara et al 2016 a large network of monitoring wells and near shore aquifer tubes has been developed to assess the quality of groundwater and river water and to trace contaminant plume migration data collected in the hanford site support numerous studies such as contaminant plume migration liu et al 2017 yabusaki et al 2008 zachara et al 2020 2016 groundwater surface water interactions shuai et al 2019 song et al 2020 2018 and carbon and nitrogen cycling stegen et al 2016 2 2 groundwater model a 3d groundwater flow and transport model was built for the hanford 100h area by refining a coarser groundwater model for the entire hanford reach shuai et al 2019 the previous reach scale model covered 3600 km2 in the hanford reach with 100 100 2 m resolution i e the area within the orange dashed line box in fig 1a and provided groundwater boundaries for this study i e the area within the red solid line box in fig 1a b our model domain was 7480 6800 m in the horizontal direction and 30 m in the vertical direction with a uniform structured grid of 10 10 1 m fig 2 the geologic layers in the model were interpolated from the hanford site database with a grid resolution of 30 m http phoenix pnnl gov the river bathymetry was resampled from columbia river bathymetry data coleman et al 2010 with a 1 m resolution we used the massively parallel subsurface flow and reactive transport simulator pflotran hammond et al 2018 to simulate the subsurface flow the governing flow equation in pflotran is based on the richards equation as shown in equation 1 1 ρ s θ t ρ q q w with water density ρ kg m 3 porosity θ water saturation s time t s and water source sink q w kg m 3 s 1 the darcy velocity q m s is calculated by equation 2 2 q k k r μ p ρ g z with liquid pressure p pa intrinsic permeability k m 2 relative permeability k r viscosity μ kg m 1 s 1 gravitational acceleration g m s 2 and vertical component of the position vector z m for unsaturated flow the van genuchten model van genuchten 1980 was used to relate capillary pressure to water saturation and the burdine relation burdine 1953 was used for the relative permeability function the groundwater model simulation was run from years 2013 to 2015 with the first ten months of the period used for model spin up the initial pressure field was interpolated from the 2012 result of the previous reach scale model simulation shuai et al 2019 the top and bottom boundaries were set as no flow because surface recharge is small 5 0 25 4 mm yr rockhold et al 1995 while the bottom of the modeling domain was constrained by the fine grained ringold units that serve as a local aquitard the four lateral flow boundaries were prescribed as hydrostatic conditions using transient pressures interpolated from the reach scale simulation shuai et al 2019 a variant of the seepage boundary condition the so called conductance boundary was applied to the riverbed to represent the low permeable interface between the river and aquifer hammond and lichtner 2010 the definition and configuration of the conductance boundary are discussed in section 2 3 the transient pressure heads on the river conductance boundary were simulated using a 2d depth averaged hydrodynamics and transport model the modular aquatic simulation system in two dimensions perkins and richmond 2007 modular aquatic simulation system in two dimensions was calibrated to multiple river gauge data along the hanford reach and provided time varying distributions of water surface elevations on the riverbed a non reactive numerical tracer was placed along the river boundary with a unit concentration representing 100 river water to track the movement of river water into the subsurface the initial and groundwater boundaries were assigned as a zero tracer concentration the initial and maximum time steps were 0 01 and 1 h respectively the hourly velocity outputs of the pflotran simulation were used as inputs for particle tracking to estimate pathways and transit times of hefs see section 2 4 2 3 representation of riverbed sediments as in many river systems a thin 1 3 m thick alluvial sediment layer constitutes the interface between the river and the adjacent aquifer formations along the hanford reach this alluvial layer is known to be highly heterogeneous and relatively impermeable which dampens the river pulse propagation into the aquifer hammond and lichtner 2010 following our previous modeling studies on the hanford site shuai et al 2019 song et al 2020 zachara et al 2020 a river conductance boundary condition was used to represent this lower permeable river sediment interface take a structured finite volume model mesh for example the boundary flux at an exterior face b of the boundary cell n is given by equation 3 3 f nb ρ nb k k r μ nb p b p n ρ nb g z nb d nb where p b pa and p n pa are the pressures at the face and cell center respectively and d nb m is the distance between the face and cell center by applying the conductance boundary the intrinsic permeability in eq 3 is replaced by 4 k c d nb where the quantity c m is referred to as the boundary conductance coefficient eqs 3 4 indicate that exchange flow rates across the river sediments interface are proportional to the conductance coefficients in previous studies at the hanford site measured groundwater level and specific conductance data have been used to calibrate several km scale groundwater models by adjusting their conductance coefficients hammond and lichtner 2010 song et al 2020 zachara et al 2020 however a similar level of long term monitoring data was not available for the current larger modeling domain alternatively we adopted the machine learning results from a recent riverbed sediments characterization effort hou et al 2019 which delineated the riverbed to several facies with distinct hydraulic properties based on multiple hydrodynamic and bathymetric variables a baseline case was built upon the four facies map published in hou et al 2019 two comparative cases a homogenous case and a seven facies case were used to further evaluate how different representations of riverbed sediment affect model predictions fig 3 b the conductance values of the three cases are listed in table 2 the conductance coefficients of three cases have the same area weighted geometric means as 1 00 10 12 m 2 4 particle tracking we adopted the same forward particle tracking algorithm as modpath pollock 1994 to simulate the pathways of exchange flows and estimate their transit times this classical particle tracking algorithm takes simulated velocity fields as input data and tracks each particle from one cell to the next using a semi analytical solution until the particle satisfies certain termination criteria e g the end of the simulation time or a particle reaching the model boundary numerical particles were released from 100 000 randomly sampled locations on the river boundary at 1 000 time points randomly selected between october 2013 and september 2014 the successful tracking of all 100 million particles was made possible by a recently developed parallel particle tracking software package https github com xuehangsong particle tracking para more details of the particle tracking scheme is described in song et al 2020 convergence tests have been conducted to ensure the number of released particles was large enough to provide stable results the transit time of each particle is defined as the time elapsed from entering the riverbed to exiting through the aquifer the particle transit times were weighted by the fluxes corresponding to the location and time when they were released to estimate the empirical cumulative transit time distribution f rt t stonedahl et al 2013 as shown in equation 5 5 f tt t f tt t i 1 n v i i t i t i 1 n v i where f rt t is the empirical cumulative distribution n is the number of particles v i m s 1 is the darcy flux when and where the particle i is released t i s is the particle transit time and i t i t is an indicator function as shown in equation 6 6 i t i t 1 if t i t 0 if t i t the cumulative transit time distribution f tt t was then used to derive the transit time distribution f tt t as shown in equation 7 7 f tt t d dt f tt t 2 5 wavelet based spatial analysis hydrologic exchange flux transit time and their controlling geomorphological hydrogeologic and hydrodynamic variables often exhibit nonstationary spatial variations across scales boano et al 2014 harvey and gooseff 2015 the spatial dependencies among these variables are complex because the variation of the predictors e g hydrogeologic parameters at one spatial scale may influence response variables e g exchange flux rate and transit time at multiple scales in this study a wavelet based spatial analysis method maximum overlap discrete wavelet transform modwt was adopted to quantify the variability and correlations among different spatial variables this method has been demonstrated as an efficient multivariate multiscale spatial analysis tool in various research disciplines such as soil science lark and webster 2004 ecology ma and zhang 2015 ye et al 2015 and biogeography carl et al 2016 studies the basic theory of modwt is briefly described below discrete wavelet transform dwt is a linear transformation technique that decomposes an original signal f x into several orthogonal and additive components at several scales using wavelet functions taking one dimensional dwt 1d dwt for example the dwt of f x can be obtained by integrating f x with a wavelet and scaling functions as shown in equations 8 and 9 8 d j k ψ j k f x d x 9 s j k ϕ j k f x d x where j 1 2 3 j j is a scale parameter of the wavelet function ψ j k and scaling function ϕ j k the wavelet function and scaling functions are dilated and translated from a basic mother wavelet ψ x and father wavelet ϕ x such as 10 ψ j k x 2 j 2 ψ x 2 j k 2 j 2 j 2 ψ 2 j x k 11 ϕ j k x 2 j 2 ϕ x 2 j k 2 j 2 j 2 ϕ 2 j x k where k is a position parameter of the mother wavelet ψ x and father wavelet ϕ x that ranges from 1 to the number of coefficients for a specific scale j daubechies 1992 the so called dilation factor 2 j 2 scales the width of ψ x and ϕ x so that the data series f x can be analyzed for various frequency components over space with a series of orthonormal basis functions ψ j k x and ϕ j k x f x can be represented by the sum of the product of the basis functions and their coefficients daubechies 1992 as follows in equation 12 12 f x k s j k ϕ j k x k d j k ψ j k x k d j 1 k ψ j 1 k x k d 1 k ψ 1 k x s j x d j x d j 1 x d 1 x where s j x reflects the average trend of the data series f x at scale j and is called smooth components of f x d j x is called the details of f x for scale j that describe local fluctuation variation of f x in some locations at scale j this orthogonal wavelet transform also is called multi resolution analysis the two dimensional dwt 2d dwt is an extension of the 1d dwt following the same basic principles while an additional step is needed to decompose the signal in a higher dimension walker 2008 decomposition of a 2d data matrix f x 1 x 2 is accomplished using equation 13 13 f x 1 x 2 j 1 j d j v j 1 j d j h j 1 j d j d s j where the matrix d j v represents only vertical components of variations in f x 1 x 2 at scale j the matrix d j h represents only horizontal components of variations in f x 1 x 2 at scale j the matrix d j d represents fluctuations between the diagonals of f x 1 x 2 and the matrix s j is smoothed components along both rows and columns at scale j one problem with the conventional dwt is the lack of translation invariance that the wavelet analysis results change with the starting location of the transformation in this study we adopted a modified version of the 2d dwt two dimensional maximum overlap discrete wavelet transform 2d modwt for the wavelet transformation modwt also known as the stationary wavelet transform is a reductant non orthogonal transform and shift invariant the above formulations of dwt still hold for modwt except that the number of coefficients at each level of the modwt is equal to the original dimensions of the data while the number of coefficients of conventional dwt depends on the scale modwt is less affected by the type of wavelet template and more efficient at estimating wavelet variance percival and walden 2000 with the 2d modwt transformation the scale specific dataset variance can be estimated by equation 14 14 v a r j 1 n i 1 n d j v 2 1 n i 1 n d j h 2 1 n i 1 n d j d 2 where d j v d j h and d j d are components of the matrix d j v d j h and d j d respectively the term n is the number of components in dataset f x 1 x 2 similarly the scale specific covariance between datasets f x 1 x 2 and g x 1 x 2 is 15 c o v f g j 1 n i 1 n d f j v d g j v 1 n i 1 n d f j h d g j h 1 n i 1 n d f j d d g j d where the subscripts f and g represent the data set source then the scale specific correlation between datasets f x 1 x 2 and g x 1 x 2 is 16 c o r f g j co v f g j va r f j v a r g j i 1 n d f j v d g j v i 1 n d f j h d g j h i 1 n d f j d d g j d i 1 n d f j v 2 i 1 n d f j h 2 i 1 n d f j d 2 i 1 n d g j v 2 i 1 n d g j h 2 i 1 n d g j d 2 in section 3 3 we evaluated the wavelet based scale specific variance and correlation of various predictors e g hydrogeologic parameters and response variables e g exchange flux and transit time because of model resolution and river width limitations we evaluated only four spatial scales from 8 m to 64 m it should be noted that numerous choices of wavelet templates exist for the mother and father wavelets we chose the haar wavelet for our study because of its simplicity and wide acceptance and its ability to analyze signals with sudden transitions or anomalies 3 results 3 1 spatial extent of river water exchange a unit non reactive numerical tracer was continually released at the river boundary during the entire three year simulation period which was used to examine the river water fractions in the shoreline and riverbed aquifers fig 4 a shows the river hydrograph between 2013 2015 at the midstream location fig 4b and fig 4c show the river water fractions in the aquifer at high river stage 06 01 2014 and low river stage 09 15 2014 periods respectively river stage variations significantly affected the fractions of river water i e the concentration profile of the numerical river tracer in the riverbed for all cross sections lower river water fractions were found during the low river stage period less red color in fig 4c compared to fig 4b this was expected as the groundwater was flowing more toward the river during river drought periods however the largest extent of river water intrusion i e the entire colored area with river water fraction 0 01 was relatively time invariant and mostly controlled by the local hydrogeological structures and river geomorphologic features on the one hand the extent of river water intrusion was highly constrained by the local elevation of aquitards for example the cross section with a smaller portion of permeable hanford unit cross section b b in both fig 4b and fig 4c has much less river water intrusion compared to the cross section with a larger portion of hanford cross section a a in both fig 4b and 4c on the other hand the extent of river water intrusion varied with the river channel features for example the geological structures of cross sections c c and d d are very similar fig 2b while cross section c c had a much larger extent of river water intrusion compared to cross section d d fig 4b c this was because cross section c c was in the upstream portion of an island that induced more river water downwelling while cross section d d was in the downstream portion of the island that was dominated by groundwater upwelling 3 2 spatial patterns of exchange flux and transit time in total 100 million numerical particles were randomly released on the river boundary between october 2013 to september 2014 the gray shaded time window in fig 5 a indicates the model spin up period january 2013 to september 2013 the yellow shaded time window indicates the particle release period october 2013 to september 2014 the particles were continually tracked until the end of 2015 the particle tracking results revealed complex and dynamic water flow paths fig 5b and fig 5c show the particle trajectories exchange flux rates and transit times of particles released at representative high river stage 06 01 2014 and low river stage 09 15 2014 periods respectively the particle trajectories were colored by the final status of each particle the first subplots in fig 5b and fig 5c the interaction between river dynamics and regional groundwater gradients leads to great temporal and spatial variations of losing and gaining conditions in the hanford reach most of the particles returned to the river channel blue while less than 5 of the particles were either lost at the groundwater boundaries green or were still in the aquifer at the end of the simulations red by comparing the particle trajectories we also found that the particles released during the high river stage period had longer travel distances the first subplots in fig 5b compared to the first subplot in fig 5c as the higher river stage pushed the river water further inland the exchange flux rate on the riverbed exhibited strong heterogeneous patterns the second subplot in fig 5b and fig 5c it is not surprising to see that the low river stage period had the smaller riparian coverage e g the second river channel in the southeast corner of the model domain disappeared in the second subplot of fig 5c the red color in the two exchange flux maps indicates the locations with stronger upwelling while the blue color indicates locations with strong downwelling although these hot spots of exchange flow varied over time the contours of the exchange flux at different time windows had similar spatial patterns i e there were more exchange flow hot spots closer to the inland and meander area because of their larger contrast between river stage and groundwater level the similarity of the spatial patterns can also be found in the contours of transit times the last subplot in fig 5b and 5c it is also noticeable that particle transit time decreased from the high river stage period to the low river stage period less red color in the last subplot of fig 5c compared to fig 5b 3 3 wavelet based spatial analysis based on our previous modeling studies shuai et al 2019 song et al 2020 zachara et al 2020 on contaminant migration and hefs in the hanford reach nine important variables were identified and extracted from the model inputs and outputs for spatial variability and correlation evaluations river bathymetry was chosen as a predictive variable to represent river geomorphology the mean and standard deviation of river depth were extracted from the model inputs as representations of the river hydrodynamic components the thickness of the hanford unit was chosen to represent hydrogeologic information because of its distinct high permeability value the five response variables include 1 the mean absolute exchange flux rate 2 the standard deviation of exchange flux rate 3 the ratio of downwelling flux 4 the mean transit time and 5 the standard deviation of transit time note that riverbed conductance was not included in the wavelet based spatial analysis because the facies based approach focuses on large scale features and neglects small scale variations and the general spatial scales of facies bodies is larger than the largest specific scales evaluated in this study 100 m vs 64 m visual inspection of the spatial contours of the nine variables fig 6 illustrated distinct groups of spatial characteristics the river bathymetry fig 6a mean river depth fig 6b and standard deviation of river depth fig 6c tended to have the smoothest spatial patterns i e small local variations among the nine variables while the ratio of downwelling flux fig 6g mean transit time fig 6h and standard deviation of transit time fig 6i had the most complex spatial variations the differences in scale dependent variations among the nine evaluated variables were more evident in the wavelet analysis results as shown in the scale specific variances based on 2d modwt fig 7 the river bathymetry mean river depth and standard deviation of river depth had similar trends of scale specific variances that increased with spatial scale the spatial variations of the mean and standard deviation of the exchange flux had similar trends as the hanford thickness that decreased with spatial scale the last three response variables the downwelling ratio the mean transit time and the standard deviation of transit time had the most interesting spatial specific variations that first decreased and then increased with scales wavelet correlation analysis provided more insights on the interactions among different predictive and response variables across scales the blue dashed box in fig 8 marks the scale specific correlations between the predictive variable correlations among the four predictive values were similar across scales river bathymetry and mean river depth were highly correlated with co r f g j 0 9 subplot marked with green which simply demonstrated that the river was deeper at the lower riverbed the standard deviation of river depth exhibited a moderate positive correlation co r f g j 0 4 with mean river depth subplot marked with light blue which means the deeper water fluctuated more the hanford thickness had no obvious correlation co r f g j 0 2 with the other three predictive variables these results imply that hydrogeologic data had unique spatial characteristics while river geomorphology and river hydrodynamic parameters were correlated there were two pairs of strongly correlated response variables across all four scales box enclosed by the red dashed line in fig 8 the first pair is the standard deviation of exchange flux and the mean absolute exchange flux co r f g j 0 9 subplot marked in pink which means locations with higher magnitude exchange fluxes also had higher variations of exchange flux the second pair is the downwelling ratio and mean transit time co r f g j 0 9 subplot marked in orange which implies that the downwelling ratio from the groundwater simulation results had predictive power on the mean transit time estimated from the particle tracking the standard deviations of transit time and mean transit time were barely spatially correlated with co r f g j 0 2 correlations between the predictive and response variables were generally weak but increased with scale box enclosed by the purple dashed lines in fig 8 we found that the mean and standard deviations of exchange flux were less affected by the river geomorphology and hydrodynamic variables while they had a positive correlation with the hanford thickness subplots marked with pink and orange patches this finding confirmed our previous reach scale study that aquifer permeability plays an important role in controlling the intensity of exchange flux under a homogenous river conductance setting shuai et al 2019 the transit time was influenced by all four predictive variables which partially explains the complexity observed in the spatial contours of the transit time mean river depth or river bathymetry as it was strongly correlated with river mean depth appeared to have the strongest impact on transit time the results showed that deeper river depths tended to induce longer and less variable transit times subplots marked with blue and orange patches 4 discussion 4 1 impacts of riverbed heterogeneity on hef prediction the facies mapping approach allowed us to model the heterogonous distributed riverbed sediments which has never been done before in the hanford reach we adopted the four facies map in the base case because kolmogorov smirnov tests showed that the four facies model captured the distinct distributions of sediment texture with a significance level less than 0 01 hou et al 2019 however it is possible that the four facies delineation is still insufficient in predicting hefs after being further integrated into transient groundwater flow models thus two additional cases a simplified homogenous case and a more complicated seven facies case were built to evaluate the impacts of riverbed heterogeneity on hef predictions fig 9 a compares the probability density functions pdfs of the exchange flux rate of the base case black solid line homogenous case red dashed line and seven facies case orange dashed line the base case provided almost identical pdfs of exchange flux rate as the seven facies case for the whole modeled river reach while the homogenous case predicted lower peak in its pdf the first subplot in fig 9a we then grouped the particles based on their releasing locations to estimate the exchange flux rate for each facies of the base case the homogenous case had similar pdf of exchange flux rate across all facies while the exchange flux rates of the base case and seven facies varied by facies of the three cases the homogenous case had the smallest exchange flux components the central red of the orange dash line in fig 9a for all four facies as we expected the seven facies case provided more complex transit time distributions ttds estimations for the whole reach and within individual facies of the base case because it is the most heterogeneous one fig 9b however the base case agreed well with the seven facies case in each individual facies except for facies 3 which only accounted for less than 5 of the riverbed fig 3a as a result the base case had a similar ttd estimation as the seven facies in the whole modeled river reach the first subplot in fig 9b the homogenous case had almost identical ttds across all facies and generally underestimated the short time components of ttds compared to the facies based cases these results demonstrated that the four facies cases are sufficient to represent the riverbed heterogeneity on predicting hefs and ttds 4 2 simulation of hydrological exchange flows using coupled surface subsurface models hefs vary with river size and type and their extents span a spatial scale ranging from millimeters or centimeters to hundreds even thousands of meters with temporal scales ranging from seconds to tens of years boano et al 2014 early numerical modeling of hefs mainly focused on mechanism understanding of specific physical processes at lab or small field scales 100 m more recent studies including the presented study seek to address the concurrent impacts of multiple physical processes in complex real world systems which often need extensive efforts on field characterization and sophisticated model setup using high performance computing hefs are the water exchange across two distinct flow zones including river water in open channel and groundwater in porous medium the multidomain modeling of hefs is challenging because the characteristic spatial and temporal scales in the two flow zones are very different a typical approach for simulating hef is to model each zone separately using different control equations and then couple them using either one way or fully coupling techniques the most commonly used one way coupling method is applying the hydraulic head simulated by river models as seepage face boundaries of groundwater models cardenas and wilson 2007 zhou et al 2018 the most commonly used fully coupling method is imposing continuous fluxes of water and solutes at the interface between the two flow zones li et al 2020 maxwell et al 2014 the groundwater flow is usually solved using richchards equation while the river water flow can be modeled using either 1d saint venant equation shuai et al 2019 2d shallow water equation boano et al 2010 or even fully 3d computational fluid dynamics models li et al 2020 zhou et al 2018 the coupled surface subsurface modeling features have been included in multiple open source and commercial groundwater simulators paniconi and putti 2015 for example parflow kollet and maxwell 2006 couples 2d saint venant equation with 3d richards equation through pressure continuity hydrogeosphere brunner and simmons 2012 couples 2d diffusive wave equation with 3d richards equation through first order exchange flux and cathy camporese et al 2010 couples 1d kinematic approximation of the saint venant equation with 3d richards equation through boundary condition switching techniques the fully coupling approaches are superior to one way coupling approaches especially for modeling low order streams because they can fully account for the bidirectional influences between river water and groundwater however this study applied one way coupling and only used the simulated river stage to drive the subsurface model the reason is that the hanford reach is a high order river section where the exchange flux across the entire reach less than1 m3 s is less than 0 1 of the river discharge 1 050 m3 s 9 880 m3 s with an average of 3 390 m3 s arntzen et al 2006 bao et al 2018 shuai et al 2019 thus the contribution of exchange flow to river water is negligible 4 3 implications on larger scale hef modeling benefitting from decades of field characterization efforts in the hanford cleanup mission usdoe 2017 this study was able to evaluate the collective influences of complex real world geomorphologic hydrogeologic and hydrodynamic setting on hefs and transit time in a typical gravel bed river corridor it will become more challenging to extend a similar modeling scheme to other river corridors or even larger watershed scale studies because of the high demand for data and computational power harvey and gooseff 2015 evaluating hefs at larger scales watershed to basin scale often involves developing surrogate models such as empirical upscaling methods and reduced complexity models with modest requirements for hydrologic and hydrogeologic data and computational resources ward et al 2018 reduced complexity models e g the classic transient storage model bencala and walters 1983 usually treat an entire river reach or watershed as a whole control volume and neglect its internal spatial variability empirical upscaling methods e g the networks with exchange and subsurface storage model gomez velez and harvey 2014 can provide the mechanistic understanding of the most important processes in exchange flows other hydrologic processes were selectively omitted because they were perceived to be unimportant an important drawback of empirical upscaling methods is assuming model processes simulated at one scale are the dominant processes across the continuum of nested scales of hydrologic exchanges in a river corridor ward et al 2018 our finding reveals the scale related variation and correlation among various predictors e g hydrogeologic and bathymetric parameters and response variables e g exchange flux rate and transit time which can be included in the future watershed to basin scale studies for better estimation of hefs fang et al 2020 4 4 model limitations our modeling approach has several limitations that should be acknowledged first the assumption of homogeneity in each geologic unit ignores heterogeneity at the local scale the local heterogeneity inside geological unit has been estimated in the integrated field scale subsurface research challenge site at the hanford 300 area by assimilating groundwater level and tracer experiments data chen et al 2012 song et al 2019 while similar level field characterization data is not available for the 100 area although our previous sensitivity study showed that the local heterogeneity within a given geological unit is less important for controlling hefs compared to aquifer stratigraphy dai et al 2019 the flow pattern would be complicated in a fully heterogeneous model and would lead to longer transit time second the facies based conductance boundaries only capture the heterogeneity of sediment permeability on the riverbed porosity on the riverbed in the model was assumed to be the same as the underlying geological units 0 2 0 43 which may have induced 0 5 2x bias on the simulated pore velocity at the top of the riverbed third while the facies classification approach provides an efficient way to estimate riverbed conductivity at reach and watershed scales it has a much coarser spatial resolution 100 m compared to all other variables 5 10 m in this study thus the conductance value facies map was not included in the wavelet based spatial analysis it is expected that riverbed conductance would have likely been one of the dominant explanatory variables in the wavelet transform analysis if it was implemented on a similar spatial scale as other variables 5 conclusions hydrologic exchange flows play a critical role in river corridor biogeochemical and ecological functions this study used 3d high spatiotemporal resolution models and massively particle tracking to simulate the exchange flow and associated transit time in a typical gravel bed river section located at the hanford reach of columbia river wavelet based multiresolution analysis was applied to investigate the spatial characteristics and cross dependence among exchange flux rate transit time and their river geomorphologic hydrodynamic and hydrogeologic controlling factors a recently developed machine learning based riverbed facies mapping technique was applied in this study to account for heterogeneously distributed riverbed hydraulic conductivity the comparison between the homogenous four facies and seven facies cases demonstrated the facies delineation results recommended by hou et al 2019 could well capture the spatial distributions of exchange flow rate and transit time under highly dynamic flow conditions we found that the spatial extent of the exchanged river water is highly influenced by the local elevation of aquitards and the river geomorphology features the exchanged river was highly constrained at locations with higher aquitard while extensive river intrusion was observed at locations underlaid by a highly permeable aquifer formation much larger exchange zones were found in the upstream portion of channel islands where river water downwelling is promoted the exchange flow rate transit time and their physical controlling factors exhibited complex scale dependent variation and correlations as summarized below 1 the river hydrodynamic features e g the mean and standard deviations of the river depth were strongly correlated across all scales while they were independent of hydrogeological data e g hanford formation thickness 2 the exchange flux rate was highly affected by the thickness of the high permeable hanford unit with increasing correlations over larger scales which indicated the strong influence of aquifer stratigraphy on hefs 3 the transit time was influenced by all river geomorphologic hydrodynamic and hydrogeologic factors and exhibited the most complex patterns the mean river depth exhibited the strongest spatial correlation with transit time among all the predictive variables and deeper water led to longer and less variant transit time 4 it is interesting to observe that the mean transit time was strongly correlated with the downwelling ratio of the exchange flux implying that the downwelling ratio can potentially be used to predict mean transit time without running particle tracking it should be noted the multiresolution analysis in this study describes the linear correspondence among the influential factors and response variables for our future work nonlinear machine learning methods e g random forest gradient boosting models will be used to further explore the combined nonlinear influences of these factors on exchange flux and transit time the insights gained through this study will also be used to support the development of reduced order models of hefs and ttds for large complex river systems using machine learning techniques credit authorship contribution statement xuehang song conceptualization methodology software formal analysis visualization writing original draft yilin fang software validation writing review editing jie bao conceptualization project administration writing review editing huiying ren formal analysis writing review editing zhuoran duan software visualization william perkins software huifen zhou data curation zhangshuan hou formal analysis writing review editing yunxiang chen software tim scheibe conceptualization funding acquisition supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the doe office of biological and environmental research subsurface biogeochemical research program through the pacific northwest national laboratory pnnl subsurface science scientific focus area project http sbrsfa pnnl gov pnnl is operated for doe by battelle under contract no de ac05 76rl01830 data and modeling products are retained in the scientific focus area data management system and are available from the authors on request the high performance computing resources were provided by the environmental molecular sciences laboratory s cascade computer we thank the two anonymous reviewers that provided us with valuable comments that clearly improved our manuscript 
4550,hydrological exchange flows hefs across the river aquifer interface and the associated transit time of river water in the aquifer have important implications for contaminant plume migration and biogeochemical processes in the river corridor hefs and transit time are influenced by both subsurface physical features and hydrologic forcing related to the transport process which can exhibit complex spatial and temporal variations in this study we used a massively parallel subsurface flow model and a particle tracking model to study the influences of different control factors on spatial variability of hefs and transit time distributions in the hanford reach of the columbia river in washington state 100 million particles were randomly injected in time and space and then tracked in a model domain that covers a 51 km2 area 15 1million model cells we used hourly river stages and groundwater levels to drive the model to provide dynamic velocity fields for the particle tracking in the two year simulation period the groundwater flow simulation and particle tracking results provide a comprehensive assessment of the spatial distribution of hefs and transit time in a large complex river corridor our results show that the aquifer hydrogeological structure has strong correlations with the extent and magnitude of exchange flux the transit time exhibits complex patterns that are affected by all the river geomorphologic hydrodynamic and hydrogeologic factors and are strongly correlated with the downwelling ratio of exchange flux the new insights gained through this study can be used to support the development of reduced order models of hefs and transit time distributions for large complex river systems keywords hydrological exchange flows transit time distribution discrete wavelet transform surface water groundwater interactions river corridor subsurface hydrogeology 1 introduction hydrologic exchange flows hefs are the bidirectional exchange flows between the mainstream channel and off channel riparian and floodplain areas including hyporheic exchange bank storage and overbank flow onto floodplains harvey and gooseff 2015 considered to be major players in biogeochemical cycles in the river corridor hefs modulate the supply transit time and temperature of substrates involved in biogeochemical cycles e g carbon nutrients and trace elements which account for up to 96 of respiration within river ecosystems gomez velez et al 2015 naegeli and uehlinger 1997 stegen et al 2016 quantification of the volume and transport time scale of hefs has been a central focus in river corridor research boano et al 2014 cardenas 2015 early studies revealed that hefs are influenced by multiple physical aspects including river geomorphology features such as the sequence of pools and riffles tonina and buffington 2007 stream meanders bars and dunes cardenas and wilson 2007 packman et al 2004 stonedahl et al 2013 riverbed sediments and underlain aquifer hydraulic properties such as hydraulic conductivity and porosity cardenas et al 2004 salehin et al 2004 river and floodplain hydrodynamic factors such as natural flow events e g flooding evapotranspiration tides and recharge larsen et al 2014 musial et al 2016 and anthropogenic activities e g dam induced stage fluctuations sawyer et al 2009 song et al 2018 these various influential factors exhibit distinct scale dependent variations which collectively induce co occurring and nested hef patterns across multiple spatial scales boano et al 2014 covino 2016 recently an increasing number of integrated models have been used to account for the joint influences of multiple physical aspects of hefs in real world settings brunner et al 2017 paniconi and putti 2015 for example gutiérrez jurado et al 2019 used the three dimensional 3d fully integrated surface subsurface model hydrogeosphere to simulate intermittent rivers and ephemeral streams and evaluate their control factors chow et al 2016 compared four different simulators hydrogeosphere watflow modflow and fellow to predict hefs in a 79 km2 watershed epting et al 2018 adopted modflow with conductance boundaries to identify river sections with intensified hefs however one question yet to be answered is how the spatial characteristics of complex physical aspects interact with and influence the spatial variabilities of hefs and transit times knowing the answer is critical to building predictive models of hefs at watershed to basin scales boano et al 2014 among the various influencing physical factors of hefs the hydraulic conductivity of the riverbed sediments is a particularly important first order control boano et al 2014 mattle et al 2001 numerical studies revealed that the riverbed hydraulic conductivity and its spatial heterogeneity have significant impacts on the magnitude bao et al 2018 kurtz et al 2013 lackey et al 2015 spatial extent schilling et al 2017b transit time and associated biogeochemical hot spots dai et al 2019 song et al 2018 of hefs however directly characterizing the riverbed hydraulic conductivity especially in large rivers has always been a great challenge due to the physical inaccessibility to deeper river channels and limitation on field samples hou et al 2017 moser et al 2003 thus uniform riverbed hydraulic conductivity conductance coefficient assumptions irvine et al 2012 were still widely used in numerical models schilling et al 2017a song et al 2020 recently data fusion methods showed promising results in improving riverbed sediment characterization by incorporating various indirect field measurements partington et al 2017 one representative data fusion approach is to estimate riverbed hydraulic conductivity from in situ monitoring data such as piezometric head temperature and tracer concentration by using data assimilation techniques kurtz et al 2014 tang et al 2018 2017 2015 alternatively we developed a novel machine learning based feature selection framework which can generate riverbed sediment facies maps based on more feasible hydrodynamic and bathymetric data hou et al 2019 the facies classification approach aims to provide an efficient way to systemically estimate riverbed conductivity at reach and watershed scales which in turn offers the potential to improve large scale predictions of river corridor hydrogeochemical processes in this study we evaluate the collective impacts of various river and subsurface features on hefs and their transport time scale in a representative large river corridor by using a massively parallel 3d subsurface flow and transport model and particle tracking simulations this comprehensive modeling study relies on the long term and extensive hydrologic and geologic datasets collected at the hanford site in south central washington state and high performance computing resources available at pacific northwest national laboratory our newly developed machine learning framework hou et al 2019 was adopted to create a heterogeneous representation of riverbed sediments for the groundwater model which was then driven by river stages extracted from a calibrated two dimensional 2d hydrodynamics river routing model to provide velocity fields for particle tracking we used a novel wavelet based spatial analysis method to evaluate the scale specific variabilities and correlations between various model predictors e g hydrogeologic parameters and response variables e g exchange flux rate and transit time this study improved understanding of scale dependent interaction among multiple geologic geomorphic and hydrogeologic features and their impacts on hefs in a typical large river corridor system 2 materials and methods 2 1 study site the study site is situated in the 100h area at the hanford reach of the columbia river the hanford reach is an 80 km free flowing river section in southeastern washington state fig 1 a the climate is characterized as arid to semiarid with an average annual precipitation of less than 180 mm conrad et al 2007 river discharge in the hanford reach is regulated by a series of upstream hydroelectric dams the river stage at the study site fluctuates up to 2 3 m annually and 0 5 m daily because of annual snowmelting events and power generation schedules arntzen et al 2006 the riverbed sediment in the hanford reach is predominantly coarse gravel ranging in size from granules to boulders rakowski et al 2006 the unconfined aquifer in the river corridor consists of two major geologic units 1 the upper coarse grained hanford formation and 2 the lower less permeable ringold formation thorne et al 2006 the ringold formation in the 100h area can be divided into three textural subunits 1 ringold e 2 ringold taylor flats and 3 ringold lower mud based on borehole data and geophysical logs shuai et al 2019 previous studies in the integrated field research challenge site at hanford 300 area characterized the strong heterogeneous distributions of highly permeable clast supported gravels and less permeable lenses of silty within the hanford formation chen et al 2012 however a similar high resolution 10 100 m characterization effort was not available for most parts of the hanford site in this study the permeability hydraulic conductivity field was assumed to be homogenous within each aquifer geologic unit with vertical permeability being an order of magnitude smaller than the horizontal permeability the hydraulic properties for the three hydrogeological units are listed in table 1 the land surface in the area is relatively flat as shown in the land surface topography map fig 1b because of historical nuclear fuel and weapons material production large amounts of chemical and radioactive waste were released to the soil surface and vadose zone at the hanford site usdoe 2017 these releases have created numerous groundwater contamination plumes and some of the plumes discharge directly to the columbia river dark blue contours in fig 1a these contaminant plumes in the river corridor exhibit complex temporal and spatial patterns that are influenced by river stage fluctuations zachara et al 2016 a large network of monitoring wells and near shore aquifer tubes has been developed to assess the quality of groundwater and river water and to trace contaminant plume migration data collected in the hanford site support numerous studies such as contaminant plume migration liu et al 2017 yabusaki et al 2008 zachara et al 2020 2016 groundwater surface water interactions shuai et al 2019 song et al 2020 2018 and carbon and nitrogen cycling stegen et al 2016 2 2 groundwater model a 3d groundwater flow and transport model was built for the hanford 100h area by refining a coarser groundwater model for the entire hanford reach shuai et al 2019 the previous reach scale model covered 3600 km2 in the hanford reach with 100 100 2 m resolution i e the area within the orange dashed line box in fig 1a and provided groundwater boundaries for this study i e the area within the red solid line box in fig 1a b our model domain was 7480 6800 m in the horizontal direction and 30 m in the vertical direction with a uniform structured grid of 10 10 1 m fig 2 the geologic layers in the model were interpolated from the hanford site database with a grid resolution of 30 m http phoenix pnnl gov the river bathymetry was resampled from columbia river bathymetry data coleman et al 2010 with a 1 m resolution we used the massively parallel subsurface flow and reactive transport simulator pflotran hammond et al 2018 to simulate the subsurface flow the governing flow equation in pflotran is based on the richards equation as shown in equation 1 1 ρ s θ t ρ q q w with water density ρ kg m 3 porosity θ water saturation s time t s and water source sink q w kg m 3 s 1 the darcy velocity q m s is calculated by equation 2 2 q k k r μ p ρ g z with liquid pressure p pa intrinsic permeability k m 2 relative permeability k r viscosity μ kg m 1 s 1 gravitational acceleration g m s 2 and vertical component of the position vector z m for unsaturated flow the van genuchten model van genuchten 1980 was used to relate capillary pressure to water saturation and the burdine relation burdine 1953 was used for the relative permeability function the groundwater model simulation was run from years 2013 to 2015 with the first ten months of the period used for model spin up the initial pressure field was interpolated from the 2012 result of the previous reach scale model simulation shuai et al 2019 the top and bottom boundaries were set as no flow because surface recharge is small 5 0 25 4 mm yr rockhold et al 1995 while the bottom of the modeling domain was constrained by the fine grained ringold units that serve as a local aquitard the four lateral flow boundaries were prescribed as hydrostatic conditions using transient pressures interpolated from the reach scale simulation shuai et al 2019 a variant of the seepage boundary condition the so called conductance boundary was applied to the riverbed to represent the low permeable interface between the river and aquifer hammond and lichtner 2010 the definition and configuration of the conductance boundary are discussed in section 2 3 the transient pressure heads on the river conductance boundary were simulated using a 2d depth averaged hydrodynamics and transport model the modular aquatic simulation system in two dimensions perkins and richmond 2007 modular aquatic simulation system in two dimensions was calibrated to multiple river gauge data along the hanford reach and provided time varying distributions of water surface elevations on the riverbed a non reactive numerical tracer was placed along the river boundary with a unit concentration representing 100 river water to track the movement of river water into the subsurface the initial and groundwater boundaries were assigned as a zero tracer concentration the initial and maximum time steps were 0 01 and 1 h respectively the hourly velocity outputs of the pflotran simulation were used as inputs for particle tracking to estimate pathways and transit times of hefs see section 2 4 2 3 representation of riverbed sediments as in many river systems a thin 1 3 m thick alluvial sediment layer constitutes the interface between the river and the adjacent aquifer formations along the hanford reach this alluvial layer is known to be highly heterogeneous and relatively impermeable which dampens the river pulse propagation into the aquifer hammond and lichtner 2010 following our previous modeling studies on the hanford site shuai et al 2019 song et al 2020 zachara et al 2020 a river conductance boundary condition was used to represent this lower permeable river sediment interface take a structured finite volume model mesh for example the boundary flux at an exterior face b of the boundary cell n is given by equation 3 3 f nb ρ nb k k r μ nb p b p n ρ nb g z nb d nb where p b pa and p n pa are the pressures at the face and cell center respectively and d nb m is the distance between the face and cell center by applying the conductance boundary the intrinsic permeability in eq 3 is replaced by 4 k c d nb where the quantity c m is referred to as the boundary conductance coefficient eqs 3 4 indicate that exchange flow rates across the river sediments interface are proportional to the conductance coefficients in previous studies at the hanford site measured groundwater level and specific conductance data have been used to calibrate several km scale groundwater models by adjusting their conductance coefficients hammond and lichtner 2010 song et al 2020 zachara et al 2020 however a similar level of long term monitoring data was not available for the current larger modeling domain alternatively we adopted the machine learning results from a recent riverbed sediments characterization effort hou et al 2019 which delineated the riverbed to several facies with distinct hydraulic properties based on multiple hydrodynamic and bathymetric variables a baseline case was built upon the four facies map published in hou et al 2019 two comparative cases a homogenous case and a seven facies case were used to further evaluate how different representations of riverbed sediment affect model predictions fig 3 b the conductance values of the three cases are listed in table 2 the conductance coefficients of three cases have the same area weighted geometric means as 1 00 10 12 m 2 4 particle tracking we adopted the same forward particle tracking algorithm as modpath pollock 1994 to simulate the pathways of exchange flows and estimate their transit times this classical particle tracking algorithm takes simulated velocity fields as input data and tracks each particle from one cell to the next using a semi analytical solution until the particle satisfies certain termination criteria e g the end of the simulation time or a particle reaching the model boundary numerical particles were released from 100 000 randomly sampled locations on the river boundary at 1 000 time points randomly selected between october 2013 and september 2014 the successful tracking of all 100 million particles was made possible by a recently developed parallel particle tracking software package https github com xuehangsong particle tracking para more details of the particle tracking scheme is described in song et al 2020 convergence tests have been conducted to ensure the number of released particles was large enough to provide stable results the transit time of each particle is defined as the time elapsed from entering the riverbed to exiting through the aquifer the particle transit times were weighted by the fluxes corresponding to the location and time when they were released to estimate the empirical cumulative transit time distribution f rt t stonedahl et al 2013 as shown in equation 5 5 f tt t f tt t i 1 n v i i t i t i 1 n v i where f rt t is the empirical cumulative distribution n is the number of particles v i m s 1 is the darcy flux when and where the particle i is released t i s is the particle transit time and i t i t is an indicator function as shown in equation 6 6 i t i t 1 if t i t 0 if t i t the cumulative transit time distribution f tt t was then used to derive the transit time distribution f tt t as shown in equation 7 7 f tt t d dt f tt t 2 5 wavelet based spatial analysis hydrologic exchange flux transit time and their controlling geomorphological hydrogeologic and hydrodynamic variables often exhibit nonstationary spatial variations across scales boano et al 2014 harvey and gooseff 2015 the spatial dependencies among these variables are complex because the variation of the predictors e g hydrogeologic parameters at one spatial scale may influence response variables e g exchange flux rate and transit time at multiple scales in this study a wavelet based spatial analysis method maximum overlap discrete wavelet transform modwt was adopted to quantify the variability and correlations among different spatial variables this method has been demonstrated as an efficient multivariate multiscale spatial analysis tool in various research disciplines such as soil science lark and webster 2004 ecology ma and zhang 2015 ye et al 2015 and biogeography carl et al 2016 studies the basic theory of modwt is briefly described below discrete wavelet transform dwt is a linear transformation technique that decomposes an original signal f x into several orthogonal and additive components at several scales using wavelet functions taking one dimensional dwt 1d dwt for example the dwt of f x can be obtained by integrating f x with a wavelet and scaling functions as shown in equations 8 and 9 8 d j k ψ j k f x d x 9 s j k ϕ j k f x d x where j 1 2 3 j j is a scale parameter of the wavelet function ψ j k and scaling function ϕ j k the wavelet function and scaling functions are dilated and translated from a basic mother wavelet ψ x and father wavelet ϕ x such as 10 ψ j k x 2 j 2 ψ x 2 j k 2 j 2 j 2 ψ 2 j x k 11 ϕ j k x 2 j 2 ϕ x 2 j k 2 j 2 j 2 ϕ 2 j x k where k is a position parameter of the mother wavelet ψ x and father wavelet ϕ x that ranges from 1 to the number of coefficients for a specific scale j daubechies 1992 the so called dilation factor 2 j 2 scales the width of ψ x and ϕ x so that the data series f x can be analyzed for various frequency components over space with a series of orthonormal basis functions ψ j k x and ϕ j k x f x can be represented by the sum of the product of the basis functions and their coefficients daubechies 1992 as follows in equation 12 12 f x k s j k ϕ j k x k d j k ψ j k x k d j 1 k ψ j 1 k x k d 1 k ψ 1 k x s j x d j x d j 1 x d 1 x where s j x reflects the average trend of the data series f x at scale j and is called smooth components of f x d j x is called the details of f x for scale j that describe local fluctuation variation of f x in some locations at scale j this orthogonal wavelet transform also is called multi resolution analysis the two dimensional dwt 2d dwt is an extension of the 1d dwt following the same basic principles while an additional step is needed to decompose the signal in a higher dimension walker 2008 decomposition of a 2d data matrix f x 1 x 2 is accomplished using equation 13 13 f x 1 x 2 j 1 j d j v j 1 j d j h j 1 j d j d s j where the matrix d j v represents only vertical components of variations in f x 1 x 2 at scale j the matrix d j h represents only horizontal components of variations in f x 1 x 2 at scale j the matrix d j d represents fluctuations between the diagonals of f x 1 x 2 and the matrix s j is smoothed components along both rows and columns at scale j one problem with the conventional dwt is the lack of translation invariance that the wavelet analysis results change with the starting location of the transformation in this study we adopted a modified version of the 2d dwt two dimensional maximum overlap discrete wavelet transform 2d modwt for the wavelet transformation modwt also known as the stationary wavelet transform is a reductant non orthogonal transform and shift invariant the above formulations of dwt still hold for modwt except that the number of coefficients at each level of the modwt is equal to the original dimensions of the data while the number of coefficients of conventional dwt depends on the scale modwt is less affected by the type of wavelet template and more efficient at estimating wavelet variance percival and walden 2000 with the 2d modwt transformation the scale specific dataset variance can be estimated by equation 14 14 v a r j 1 n i 1 n d j v 2 1 n i 1 n d j h 2 1 n i 1 n d j d 2 where d j v d j h and d j d are components of the matrix d j v d j h and d j d respectively the term n is the number of components in dataset f x 1 x 2 similarly the scale specific covariance between datasets f x 1 x 2 and g x 1 x 2 is 15 c o v f g j 1 n i 1 n d f j v d g j v 1 n i 1 n d f j h d g j h 1 n i 1 n d f j d d g j d where the subscripts f and g represent the data set source then the scale specific correlation between datasets f x 1 x 2 and g x 1 x 2 is 16 c o r f g j co v f g j va r f j v a r g j i 1 n d f j v d g j v i 1 n d f j h d g j h i 1 n d f j d d g j d i 1 n d f j v 2 i 1 n d f j h 2 i 1 n d f j d 2 i 1 n d g j v 2 i 1 n d g j h 2 i 1 n d g j d 2 in section 3 3 we evaluated the wavelet based scale specific variance and correlation of various predictors e g hydrogeologic parameters and response variables e g exchange flux and transit time because of model resolution and river width limitations we evaluated only four spatial scales from 8 m to 64 m it should be noted that numerous choices of wavelet templates exist for the mother and father wavelets we chose the haar wavelet for our study because of its simplicity and wide acceptance and its ability to analyze signals with sudden transitions or anomalies 3 results 3 1 spatial extent of river water exchange a unit non reactive numerical tracer was continually released at the river boundary during the entire three year simulation period which was used to examine the river water fractions in the shoreline and riverbed aquifers fig 4 a shows the river hydrograph between 2013 2015 at the midstream location fig 4b and fig 4c show the river water fractions in the aquifer at high river stage 06 01 2014 and low river stage 09 15 2014 periods respectively river stage variations significantly affected the fractions of river water i e the concentration profile of the numerical river tracer in the riverbed for all cross sections lower river water fractions were found during the low river stage period less red color in fig 4c compared to fig 4b this was expected as the groundwater was flowing more toward the river during river drought periods however the largest extent of river water intrusion i e the entire colored area with river water fraction 0 01 was relatively time invariant and mostly controlled by the local hydrogeological structures and river geomorphologic features on the one hand the extent of river water intrusion was highly constrained by the local elevation of aquitards for example the cross section with a smaller portion of permeable hanford unit cross section b b in both fig 4b and fig 4c has much less river water intrusion compared to the cross section with a larger portion of hanford cross section a a in both fig 4b and 4c on the other hand the extent of river water intrusion varied with the river channel features for example the geological structures of cross sections c c and d d are very similar fig 2b while cross section c c had a much larger extent of river water intrusion compared to cross section d d fig 4b c this was because cross section c c was in the upstream portion of an island that induced more river water downwelling while cross section d d was in the downstream portion of the island that was dominated by groundwater upwelling 3 2 spatial patterns of exchange flux and transit time in total 100 million numerical particles were randomly released on the river boundary between october 2013 to september 2014 the gray shaded time window in fig 5 a indicates the model spin up period january 2013 to september 2013 the yellow shaded time window indicates the particle release period october 2013 to september 2014 the particles were continually tracked until the end of 2015 the particle tracking results revealed complex and dynamic water flow paths fig 5b and fig 5c show the particle trajectories exchange flux rates and transit times of particles released at representative high river stage 06 01 2014 and low river stage 09 15 2014 periods respectively the particle trajectories were colored by the final status of each particle the first subplots in fig 5b and fig 5c the interaction between river dynamics and regional groundwater gradients leads to great temporal and spatial variations of losing and gaining conditions in the hanford reach most of the particles returned to the river channel blue while less than 5 of the particles were either lost at the groundwater boundaries green or were still in the aquifer at the end of the simulations red by comparing the particle trajectories we also found that the particles released during the high river stage period had longer travel distances the first subplots in fig 5b compared to the first subplot in fig 5c as the higher river stage pushed the river water further inland the exchange flux rate on the riverbed exhibited strong heterogeneous patterns the second subplot in fig 5b and fig 5c it is not surprising to see that the low river stage period had the smaller riparian coverage e g the second river channel in the southeast corner of the model domain disappeared in the second subplot of fig 5c the red color in the two exchange flux maps indicates the locations with stronger upwelling while the blue color indicates locations with strong downwelling although these hot spots of exchange flow varied over time the contours of the exchange flux at different time windows had similar spatial patterns i e there were more exchange flow hot spots closer to the inland and meander area because of their larger contrast between river stage and groundwater level the similarity of the spatial patterns can also be found in the contours of transit times the last subplot in fig 5b and 5c it is also noticeable that particle transit time decreased from the high river stage period to the low river stage period less red color in the last subplot of fig 5c compared to fig 5b 3 3 wavelet based spatial analysis based on our previous modeling studies shuai et al 2019 song et al 2020 zachara et al 2020 on contaminant migration and hefs in the hanford reach nine important variables were identified and extracted from the model inputs and outputs for spatial variability and correlation evaluations river bathymetry was chosen as a predictive variable to represent river geomorphology the mean and standard deviation of river depth were extracted from the model inputs as representations of the river hydrodynamic components the thickness of the hanford unit was chosen to represent hydrogeologic information because of its distinct high permeability value the five response variables include 1 the mean absolute exchange flux rate 2 the standard deviation of exchange flux rate 3 the ratio of downwelling flux 4 the mean transit time and 5 the standard deviation of transit time note that riverbed conductance was not included in the wavelet based spatial analysis because the facies based approach focuses on large scale features and neglects small scale variations and the general spatial scales of facies bodies is larger than the largest specific scales evaluated in this study 100 m vs 64 m visual inspection of the spatial contours of the nine variables fig 6 illustrated distinct groups of spatial characteristics the river bathymetry fig 6a mean river depth fig 6b and standard deviation of river depth fig 6c tended to have the smoothest spatial patterns i e small local variations among the nine variables while the ratio of downwelling flux fig 6g mean transit time fig 6h and standard deviation of transit time fig 6i had the most complex spatial variations the differences in scale dependent variations among the nine evaluated variables were more evident in the wavelet analysis results as shown in the scale specific variances based on 2d modwt fig 7 the river bathymetry mean river depth and standard deviation of river depth had similar trends of scale specific variances that increased with spatial scale the spatial variations of the mean and standard deviation of the exchange flux had similar trends as the hanford thickness that decreased with spatial scale the last three response variables the downwelling ratio the mean transit time and the standard deviation of transit time had the most interesting spatial specific variations that first decreased and then increased with scales wavelet correlation analysis provided more insights on the interactions among different predictive and response variables across scales the blue dashed box in fig 8 marks the scale specific correlations between the predictive variable correlations among the four predictive values were similar across scales river bathymetry and mean river depth were highly correlated with co r f g j 0 9 subplot marked with green which simply demonstrated that the river was deeper at the lower riverbed the standard deviation of river depth exhibited a moderate positive correlation co r f g j 0 4 with mean river depth subplot marked with light blue which means the deeper water fluctuated more the hanford thickness had no obvious correlation co r f g j 0 2 with the other three predictive variables these results imply that hydrogeologic data had unique spatial characteristics while river geomorphology and river hydrodynamic parameters were correlated there were two pairs of strongly correlated response variables across all four scales box enclosed by the red dashed line in fig 8 the first pair is the standard deviation of exchange flux and the mean absolute exchange flux co r f g j 0 9 subplot marked in pink which means locations with higher magnitude exchange fluxes also had higher variations of exchange flux the second pair is the downwelling ratio and mean transit time co r f g j 0 9 subplot marked in orange which implies that the downwelling ratio from the groundwater simulation results had predictive power on the mean transit time estimated from the particle tracking the standard deviations of transit time and mean transit time were barely spatially correlated with co r f g j 0 2 correlations between the predictive and response variables were generally weak but increased with scale box enclosed by the purple dashed lines in fig 8 we found that the mean and standard deviations of exchange flux were less affected by the river geomorphology and hydrodynamic variables while they had a positive correlation with the hanford thickness subplots marked with pink and orange patches this finding confirmed our previous reach scale study that aquifer permeability plays an important role in controlling the intensity of exchange flux under a homogenous river conductance setting shuai et al 2019 the transit time was influenced by all four predictive variables which partially explains the complexity observed in the spatial contours of the transit time mean river depth or river bathymetry as it was strongly correlated with river mean depth appeared to have the strongest impact on transit time the results showed that deeper river depths tended to induce longer and less variable transit times subplots marked with blue and orange patches 4 discussion 4 1 impacts of riverbed heterogeneity on hef prediction the facies mapping approach allowed us to model the heterogonous distributed riverbed sediments which has never been done before in the hanford reach we adopted the four facies map in the base case because kolmogorov smirnov tests showed that the four facies model captured the distinct distributions of sediment texture with a significance level less than 0 01 hou et al 2019 however it is possible that the four facies delineation is still insufficient in predicting hefs after being further integrated into transient groundwater flow models thus two additional cases a simplified homogenous case and a more complicated seven facies case were built to evaluate the impacts of riverbed heterogeneity on hef predictions fig 9 a compares the probability density functions pdfs of the exchange flux rate of the base case black solid line homogenous case red dashed line and seven facies case orange dashed line the base case provided almost identical pdfs of exchange flux rate as the seven facies case for the whole modeled river reach while the homogenous case predicted lower peak in its pdf the first subplot in fig 9a we then grouped the particles based on their releasing locations to estimate the exchange flux rate for each facies of the base case the homogenous case had similar pdf of exchange flux rate across all facies while the exchange flux rates of the base case and seven facies varied by facies of the three cases the homogenous case had the smallest exchange flux components the central red of the orange dash line in fig 9a for all four facies as we expected the seven facies case provided more complex transit time distributions ttds estimations for the whole reach and within individual facies of the base case because it is the most heterogeneous one fig 9b however the base case agreed well with the seven facies case in each individual facies except for facies 3 which only accounted for less than 5 of the riverbed fig 3a as a result the base case had a similar ttd estimation as the seven facies in the whole modeled river reach the first subplot in fig 9b the homogenous case had almost identical ttds across all facies and generally underestimated the short time components of ttds compared to the facies based cases these results demonstrated that the four facies cases are sufficient to represent the riverbed heterogeneity on predicting hefs and ttds 4 2 simulation of hydrological exchange flows using coupled surface subsurface models hefs vary with river size and type and their extents span a spatial scale ranging from millimeters or centimeters to hundreds even thousands of meters with temporal scales ranging from seconds to tens of years boano et al 2014 early numerical modeling of hefs mainly focused on mechanism understanding of specific physical processes at lab or small field scales 100 m more recent studies including the presented study seek to address the concurrent impacts of multiple physical processes in complex real world systems which often need extensive efforts on field characterization and sophisticated model setup using high performance computing hefs are the water exchange across two distinct flow zones including river water in open channel and groundwater in porous medium the multidomain modeling of hefs is challenging because the characteristic spatial and temporal scales in the two flow zones are very different a typical approach for simulating hef is to model each zone separately using different control equations and then couple them using either one way or fully coupling techniques the most commonly used one way coupling method is applying the hydraulic head simulated by river models as seepage face boundaries of groundwater models cardenas and wilson 2007 zhou et al 2018 the most commonly used fully coupling method is imposing continuous fluxes of water and solutes at the interface between the two flow zones li et al 2020 maxwell et al 2014 the groundwater flow is usually solved using richchards equation while the river water flow can be modeled using either 1d saint venant equation shuai et al 2019 2d shallow water equation boano et al 2010 or even fully 3d computational fluid dynamics models li et al 2020 zhou et al 2018 the coupled surface subsurface modeling features have been included in multiple open source and commercial groundwater simulators paniconi and putti 2015 for example parflow kollet and maxwell 2006 couples 2d saint venant equation with 3d richards equation through pressure continuity hydrogeosphere brunner and simmons 2012 couples 2d diffusive wave equation with 3d richards equation through first order exchange flux and cathy camporese et al 2010 couples 1d kinematic approximation of the saint venant equation with 3d richards equation through boundary condition switching techniques the fully coupling approaches are superior to one way coupling approaches especially for modeling low order streams because they can fully account for the bidirectional influences between river water and groundwater however this study applied one way coupling and only used the simulated river stage to drive the subsurface model the reason is that the hanford reach is a high order river section where the exchange flux across the entire reach less than1 m3 s is less than 0 1 of the river discharge 1 050 m3 s 9 880 m3 s with an average of 3 390 m3 s arntzen et al 2006 bao et al 2018 shuai et al 2019 thus the contribution of exchange flow to river water is negligible 4 3 implications on larger scale hef modeling benefitting from decades of field characterization efforts in the hanford cleanup mission usdoe 2017 this study was able to evaluate the collective influences of complex real world geomorphologic hydrogeologic and hydrodynamic setting on hefs and transit time in a typical gravel bed river corridor it will become more challenging to extend a similar modeling scheme to other river corridors or even larger watershed scale studies because of the high demand for data and computational power harvey and gooseff 2015 evaluating hefs at larger scales watershed to basin scale often involves developing surrogate models such as empirical upscaling methods and reduced complexity models with modest requirements for hydrologic and hydrogeologic data and computational resources ward et al 2018 reduced complexity models e g the classic transient storage model bencala and walters 1983 usually treat an entire river reach or watershed as a whole control volume and neglect its internal spatial variability empirical upscaling methods e g the networks with exchange and subsurface storage model gomez velez and harvey 2014 can provide the mechanistic understanding of the most important processes in exchange flows other hydrologic processes were selectively omitted because they were perceived to be unimportant an important drawback of empirical upscaling methods is assuming model processes simulated at one scale are the dominant processes across the continuum of nested scales of hydrologic exchanges in a river corridor ward et al 2018 our finding reveals the scale related variation and correlation among various predictors e g hydrogeologic and bathymetric parameters and response variables e g exchange flux rate and transit time which can be included in the future watershed to basin scale studies for better estimation of hefs fang et al 2020 4 4 model limitations our modeling approach has several limitations that should be acknowledged first the assumption of homogeneity in each geologic unit ignores heterogeneity at the local scale the local heterogeneity inside geological unit has been estimated in the integrated field scale subsurface research challenge site at the hanford 300 area by assimilating groundwater level and tracer experiments data chen et al 2012 song et al 2019 while similar level field characterization data is not available for the 100 area although our previous sensitivity study showed that the local heterogeneity within a given geological unit is less important for controlling hefs compared to aquifer stratigraphy dai et al 2019 the flow pattern would be complicated in a fully heterogeneous model and would lead to longer transit time second the facies based conductance boundaries only capture the heterogeneity of sediment permeability on the riverbed porosity on the riverbed in the model was assumed to be the same as the underlying geological units 0 2 0 43 which may have induced 0 5 2x bias on the simulated pore velocity at the top of the riverbed third while the facies classification approach provides an efficient way to estimate riverbed conductivity at reach and watershed scales it has a much coarser spatial resolution 100 m compared to all other variables 5 10 m in this study thus the conductance value facies map was not included in the wavelet based spatial analysis it is expected that riverbed conductance would have likely been one of the dominant explanatory variables in the wavelet transform analysis if it was implemented on a similar spatial scale as other variables 5 conclusions hydrologic exchange flows play a critical role in river corridor biogeochemical and ecological functions this study used 3d high spatiotemporal resolution models and massively particle tracking to simulate the exchange flow and associated transit time in a typical gravel bed river section located at the hanford reach of columbia river wavelet based multiresolution analysis was applied to investigate the spatial characteristics and cross dependence among exchange flux rate transit time and their river geomorphologic hydrodynamic and hydrogeologic controlling factors a recently developed machine learning based riverbed facies mapping technique was applied in this study to account for heterogeneously distributed riverbed hydraulic conductivity the comparison between the homogenous four facies and seven facies cases demonstrated the facies delineation results recommended by hou et al 2019 could well capture the spatial distributions of exchange flow rate and transit time under highly dynamic flow conditions we found that the spatial extent of the exchanged river water is highly influenced by the local elevation of aquitards and the river geomorphology features the exchanged river was highly constrained at locations with higher aquitard while extensive river intrusion was observed at locations underlaid by a highly permeable aquifer formation much larger exchange zones were found in the upstream portion of channel islands where river water downwelling is promoted the exchange flow rate transit time and their physical controlling factors exhibited complex scale dependent variation and correlations as summarized below 1 the river hydrodynamic features e g the mean and standard deviations of the river depth were strongly correlated across all scales while they were independent of hydrogeological data e g hanford formation thickness 2 the exchange flux rate was highly affected by the thickness of the high permeable hanford unit with increasing correlations over larger scales which indicated the strong influence of aquifer stratigraphy on hefs 3 the transit time was influenced by all river geomorphologic hydrodynamic and hydrogeologic factors and exhibited the most complex patterns the mean river depth exhibited the strongest spatial correlation with transit time among all the predictive variables and deeper water led to longer and less variant transit time 4 it is interesting to observe that the mean transit time was strongly correlated with the downwelling ratio of the exchange flux implying that the downwelling ratio can potentially be used to predict mean transit time without running particle tracking it should be noted the multiresolution analysis in this study describes the linear correspondence among the influential factors and response variables for our future work nonlinear machine learning methods e g random forest gradient boosting models will be used to further explore the combined nonlinear influences of these factors on exchange flux and transit time the insights gained through this study will also be used to support the development of reduced order models of hefs and ttds for large complex river systems using machine learning techniques credit authorship contribution statement xuehang song conceptualization methodology software formal analysis visualization writing original draft yilin fang software validation writing review editing jie bao conceptualization project administration writing review editing huiying ren formal analysis writing review editing zhuoran duan software visualization william perkins software huifen zhou data curation zhangshuan hou formal analysis writing review editing yunxiang chen software tim scheibe conceptualization funding acquisition supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the doe office of biological and environmental research subsurface biogeochemical research program through the pacific northwest national laboratory pnnl subsurface science scientific focus area project http sbrsfa pnnl gov pnnl is operated for doe by battelle under contract no de ac05 76rl01830 data and modeling products are retained in the scientific focus area data management system and are available from the authors on request the high performance computing resources were provided by the environmental molecular sciences laboratory s cascade computer we thank the two anonymous reviewers that provided us with valuable comments that clearly improved our manuscript 
4551,ecological remediation with subsurface flow wetland is one of the most widely used methods for pollution abatement assessment on its implementation efficiency is necessary but difficult to evaluate the pollutant removal effect of constructed subsurface flow wetlands a wetland growth model coupling with a hydrodynamic water quality model has been put forward the coupled model has been used to assess the impact of constructed subsurface flow wetlands on a polluted lake in hubei province china four pieces of constructed subsurface flow wetlands composed of reed and smooth cordgrass with total area of 38 9 thousand square meters for pollutant removal have been designed for the lake results showed that reductions of chemical oxygen demand cod total phosphorus tp and total nitrogen tn were 246 38 28 14 and 3 29 tons year respectively compared with the different pollutants the removal efficiency of subsurface flow wetlands on tn 49 is bigger than tp 34 but less than cod 60 furthermore the higher water temperature smaller flow velocity and bigger water depth will improve the pollutants removal performance of subsurface flow wetlands keywords constructed subsurface flow wetland water ecological model pollutant removal assessment ecological remediation 1 introduction controlling water pollution and restoring the water environment have become national strategic activities in many countries ecological remediation is a significant method of environmental governance sun et al 2017 subsurface flow wetland is the most widely used in water ecological restoration ranieri et al 2011 a subsurface flow wetland is a kind of aerobic wetland which always contains free water surface submerged plants and floating plants the treatment of sewage by constructed wetland is the comprehensive result of the physical chemical and biological processes among plants substrate and internal microorganisms including precipitation filtration oxidation degradation and adsorption wu et al 2018 experimental researches have been done to assess pollutant removal performances of wetlands to wastewater results of which showed that different kinds of wetlands have different removal efficiency to different pollutants hu et al 2020 saeed et al 2018 however wastewater removal efficiency of wetland is highly correlated with solar radiation intensity temperature nutrient availability and hydrodynamic condition huang et al 2010 in different water the performance of the same wetland system is completely different based on the previous experimental research it is still indispensable to develop pre assessment models for removal efficiency evaluation of wetland for wetland engineering design and construction plans nevertheless as the complexity of pollutants water wetland system it is still challenging to assess how much pollutants that subsurface flow wetland can remove before the subsurface flow wetlands project is implemented many methods such as simple design models first order k c model plant growth model and monod type equations have been proposed to evaluate the efficiency of ecological remediation measures rules of thumb and regression equations are two typical kinds of simple design models for example the horizontal subsurface flow ssf constructed treatment wetlands assess equations are the fastest but the roughest herrera melián et al 2020 kadlec 1997 several authors have studied regression equations of inlet and outlet pollutant concentrations of horizontal ssf constructed treatment wetlands boog et al 2019 griffin et al 1999 however due to neglecting many important factors of wetlands growth these equations are always oversimplified and have great uncertainty rousseau et al 2004 wang et al 2020 the plant growth model is based on the empirical relationship between plant biomass and environmental conditions many researches have studied the relationship among plant growth water temperature nutrients and sunlight nxawe et al 2010 weerakoon et al 2020 monod type equation is a kind of first order models in which the relatively low concentrations are used for representing first order rate reactions instead of high concentrations used for zero order rate reactions research has found that monod type model over performs a first order model in simulation accuracy a i et al 2019 mitchell and mcnevin 2001 nevertheless without considering the ecological process these methods are simplified and based on assumptions which cause errors in fitting with the complex operating conditions of subsurface flow wetlands saeed and sun 2011 to describe the physical chemical and biological processes of subsurface flow wetlands more completely many mechanisms or processes based numerical models have been developed fioreze and mancuso 2019 savickis et al 2016 smesrud et al 2014 in these models the typical transformation and degradation processes of carbon and nitrogen the water and oxygen balances as well as plant growth and decay processes are considered some of these processes have been developed in modules for example the multi component reactive transport module cw2d langergraber 2002 including 12 components dissolved oxygen organic matter ammonium nitrite nitrate nitrogen gas inorganic phosphorus as well as heterotrophic and two species of autotrophic micro organisms and 9 processes hydrolysis mineralization of organic matter nitrification denitrification and a lysis process for the micro organisms langergraber et al 2009 and numerical models describe the changing processes of a large number of components in detail sanchez ramos et al 2019 whereas the extension and application of these numerical models are always difficult for their complex characters and abundant data requirements for the design of subsurface flow wetlands the assessment tool should be precise and be applicable under the conditions of limited data this study has provided a coupled method to evaluate the efficiency of pollutant reduction in constructed subsurface flow wetlands in a lake in china it simplifies the numerical plant growth model integrated with hydrodynamic and water quality model and will be appropriate in areas where data are limited therefore the objectives of this study are a to develop a hybrid water ecological model for the design of subsurface flow wetlands and b to assess the pollutant reduction capacity of a practical constructed subsurface flow wetlands project 2 methods and materials 2 1 study areas the baitanhu lake containing baitan lake bt gutan lake gt and chiye lake cy are located in huanggang city hubei province china as shown in fig 1 these three lakes are heavily polluted mainly by organic materials and nutrient sources especially in the chemical oxygen demand cod total phosphorus tp and total nitrogen tn in recent years the government has realized the importance of water environmental protection and increased investments in environmental improvement a project which is in accordance with the huanggang urban master plan 2011 2030 and the baitan lake area control plan has been set up to improve the water quality within the 25 27 km2 of the baitan lake planning area in this project constructed subsurface flow wetlands were designed for water quality improvement this project was designed in 2013 and four constructed wetlands w1 w2 w3 w4 will be planted as shown in fig 1 a the w1 w2 subsurface flow wetlands will be constructed in the arm of baitan lake and gutan lake the w3 subsurface flow wetland will be constructed in chiye lake and the w4 subsurface flow wetland will be constructed in the south east of a baitan island fig 1 b shows a typical cross section of the subsurface flow wetland the subsurface flow wetland will be created as a floating island wetland which is a recent bio engineering technology for improving water quality aquatic species are planted on a floating raft with their roots extending into the water column underneath the raft thus able to absorb and remove nutrients such as nitrogen and phosphorus from the water the common local species such as reed and smooth cordgrass have been selected to be planted in the subsurface flow wetland up till now only one wetland w3 has been finished measured data in 2013 before and after planting of w3 planted have been used for model verification the other three wetlands were used for pollutants removal efficiency assessment by numerical models 2 2 models developments water and subsurface flow wetlands coupled with bottom sediment compose an independent ecosystem during the processes of growth maturity decline and death subsurface flow wetlands not only assimilate nutriment from waters and sediments for primary production but return nutrients to the environment after death pincam et al 2020 which is influenced by water hydrodynamic water nutrient substance and other environmental factors considering these processes a coupled model consisting of a hydrodynamic water quality model a sediment model and a water ecological model has been developed as shown in fig 2 2 2 1 hydrodynamic and water quality model the hydrodynamic model and water quality model were based on a common two dimensional hydrodynamic and water quality lake model xu et al 2020 including continuity equation 1 momentum equations in and y directions 2 3 and diffusion control equations of nutrients 4 1 z t h u x h v y 0 2 h u t h u u x h v u y g h z x g n 2 h u 2 v 2 u h 4 3 h f v ρ a f w w x 2 w y 2 w x ρ w x h γ t u x y h γ t u y 3 h v t h u v x h v v y g h z y g n 2 h u 2 v 2 v h 4 3 h f u ρ a f w w x 2 w y 2 w y ρ w x h γ t v x y h γ t v y 4 h c i t hu c i x hv c i y x h k x c i x y h k y c i y h k d c i s m s p where u and v are respectively the average velocity in x and y directions m s z is water level m h is water depth m f is coriolis coefficient f 2ωsin lat and ω is the earth rotation angular frequency while lat is latitude γ t is turbulent viscosity coefficient m2 s ρa and ρw are air density and water density respectively fw is wind stress coefficient wx and wy are respectively wind speed in x and y directions n is the roughness factor ct is the concentration of nutrients in the water mg l kx and ky are nutrients diffusion coefficient in x and y directions s m2 respectively kd is the degradation coefficient of nutrients s 1 sm is nutrient load from lakebed sediments kg and sm can be calculated as 5 s m λ c c d where λ is the nutrients release coefficient of sediment mg m2 d c and cd are nutrient concentrations in the water and sediment respectively c is calculated by the water quality model cd is computed by the sediment flux model sp represents the nutrient removed by subsurface flow wetlands through sediment including plants absorbed by plants sorb and consumed by the microorganisms attached to roots scon 6 s p s orb s con s con λ s s orb t λ k k d sorb can be calculated by biomass through a proportion of nutrients c n p carbon nitrogen and phosphorus constituting the total biomass while both λs and λk are the coefficient 2 2 2 sediment flux model nutrient concentration in sediment is affected by physical chemical and biological processes including diffusion adsorption mineralization nitrification and denitrification and plants absorption process ge et al 2020 zhang et al 2014 the basic equation is as follows 7 θ f ρ k d c i s t t θ d c i s z q c i s t φ c i s k θ ρ s 2 i φ k θ ρ 1 f k d θ λ 1 f ρ k d λ 2 8 s 2 i t k θ 1 f k d c i s s 2 i λ 3 s 2 i where c i s is nutrients concentration in the aqueous phase of sediment mg l θ is the percentage of saturated water content ρ is sediment density kd is distribution coefficient of water and sediment k is first order adsorption rate constant d is dispersion coefficient z is the depth of sediment λ 1 λ 2 and λ 3 are first order degradation rate coefficient in the aqueous phase equilibrium adsorption phase and non equilibrium adsorption phase respectively s2 is the adsorbent concentration in non equilibrium adsorption phase 2 2 3 growth model of wetlands during the growth of subsurface flow wetlands pollutants will be absorbed and reduced previous studies have reported that the growth of subsurface flow wetlands is influenced by water temperature water and nutrients oliver et al 2017 steinman et al 2014 in an ideal condition plant growth can be regarded as a time change function of its maximum growth rate and environmental factors a common function for subsurface flow wetlands growth is as follows hem 1971 9 db dt g b max t g t t g n u t g i t g w t b where b is the biomass of subsurface flow wetlands g m2 g b max t is the maximum growth rate for plants g m2 d g t t is temperature limiting factor g n u t is the nutrient limiting factor g i t is the illumination limiting factor g w t is the water limiting factor related to water depth and flow velocity t is the time of plants growing d during realistic simulation realistic temperature nutrient and illumination the detailed relationships between plant growth and environmental conditions depend on the plant species thus equation 9 can be 10 db dt g b max t b 2 2 4 model conditions the boundary conditions and initial condition are as follows 1 inflow boundary conditions 11 q q in x y t c c in x y t 2 outflow boundary condition 12 q q out x y t 3 initial condition 13 φ φ x y 0 where qin is the quantity of inflow m3 s x y are respectively the locations of elements t is the time c is the pollutant concentration mg l φ is indicators initial values of modeling including water level pollutant concentration equations will be solved by the finite control volume method with an upwind scheme 2 2 5 removal efficiency to evaluate the nutrient remove efficiency of subsurface flow wetlands a removal efficiency ref index was set as follows 14 ref i 1 m c it v it i 1 m c it v it i 1 m c it v it where t is the date i is the number of grid cells in the two dimensional model v is the volume of the grid l c is the nutrient concentration without subsurface flow wetlands c is the nutrient concentration with subsurface flow wetlands the processes of calculating removal efficiency are shown in fig 3 firstly the wetland growth model is used to simulate the total biomass of wetlands according to the proportion of carbon nitrogen and phosphorus in biomass the nutrients absorbed by wetlands can be calculated in this process the botanical photosynthesis respiration and nutrient absorption through the stem and leaf are ignored secondly assuming that nutrients in sediment are dynamically balanced the nutrients absorbed by wetlands will be supplemented by water with this assumption the sediment flux model will be operated which will get nutrients concentration in sediment for every grid thirdly the nutrient in water in two scenarios with or without wetlands will be simulated by the water quality model using equation 10 the total volume the removal efficiency of different nutrients removed by wetlands in the whole lake and every grid in time series or within a specific time can be computed 2 3 model conditions setting two dimensional regular grids have been used for model simulation with mesh size of 10 30 m according to the current situation of water quality of lakes cod tn and tp were set as three water quality indexes inflow from chushui river and outflow from jinshui river are the boundary conditions of two tributaries in addition two sluice gates have been set to control the inflow and outflow through field investigation and monitoring we have obtained the loads of pollutants source hydrological and water quality conditions of the lakes based on the survey data there are almost 15 outfalls around the lakes as shown in fig 3 wastewater carrying pollutants from storm water runoff fish farming agriculture and soil erosion enter into the lakes the external pollution source loads are estimated as shown in table 1 for shoreline protection the non points sources pollutants are gathered and entered into the lake through 15 sewage outfalls with 403 26 tons per year t a cod 9 58 t a tn and 66 87 t a tp which have been treated as lateral input conditions pollutant loads from external pollutant sources are much larger than pollutants in stock with cod of 403 26 tons tn of 66 87 tons and tp of 5 77 tons every year the water level of the outlet shown in fig 4 measured data has been set as a boundary condition initial conditions of each grid were gained from the measured value of 14 measured sites in early spring by inverse distance weighted interpolation as shown in table 2 for model calibration and validation measured data at 9 and 12 from march 5 2013 to the march 4 2014 were used for model calibration data at 1 6 7 9 and 13 selection of measuring sites is random which is evenly distributed in the three lakes were set for model validation 2 4 scenarios of simulation two scenarios have been designed for the model simulation the first one is the scenario without subsurface flow wetlands while the second one is a comparable scenario with 4 subsurface flow wetlands as shown in fig 3 there are 4 subsurface flow wetlands in three lakes and sizes of subsurface flow wetlands w1 w2 w3 w4 are 14 515 m2 9 211 m2 5 870 m2 and 9 304 m2 respectively in these four wetlands the reed and smooth cordgrass are both planted about 50 percent of the total a full year period was set for simulation from march 5 2013 without wetlands to march 4 of the next year planned year with wetlands in the wetland scenario it is assumed that the water temperature and light factors are all in an appropriate state while plant growth is mainly restricted by nutrients thus the gbmax t is the main factor affecting the biomass of wetland according to the pervious study the gbmax t can be obtained from table 3 in the different growing period of wetlands the proportion of nutrients is different which can be gained from table 4 2 5 parameters calibration and model validation 2 5 1 sensitive parameters and value ranges for the hydrodynamic model the roughness coefficient is the deterministic parameter comparing measured flow velocity water level and simulated results the roughness coefficient of these three lakes is around 0 2 to 0 25 for the water quality model the degradation coefficient kd nutrients diffusion coefficient kxy and nutrient release rate λ from sediment in three lakes are calibrated as shown in table 5 parameters of the sediment flux model are calibrated with the same values in three lakes as shown in table 6 to simplify models the λs and λk were set as 1 2 5 2 model calibration and validation 1 scenario without wetlands model calibration results of water level and flow velocity are shown in fig 4 and the calibration results of cod tn and tp concentration without wetlands at 9 and 12 in 2013 are shown in fig 5 as shown in fig 4 after parameters calibration the simulated water level and measured water level match well where the coefficient of the determinant r2 is over 0 99 in addition it also indicates that the model can simulate the flow velocity characteristics of temporal and spatial variation with r2 bigger than 0 8 in four seasons the fig 5 shows that the measured data and simulated data of cod tn and tp at locations 9 in the baitan lake and 12 in the chiye lake which are also matching well the relative errors range from 14 to 12 and the errors of90 samples are between 10 and 10 2 scenario with wetlands after wetland w3 planted the water quality concentration was simulated and the parameters were calibrated the coefficient of the determinant r2 and relative error have been used for water quality model validation furthermore results of measured data and simulated data in five sections 1 6 7 12 and 13 on march 29 may 17 and june 9 were shown in fig 6 as shown in fig 6 the r2 of cod tp tn are respectively 0 7618 0 9221 and 0 9395 the relative errors of these three water quality indexes are 9 7 11 and 7 69 respectively for many previous studies about water quality models that r2 larger than 0 6 is can be judged as satisfactory masocha et al 2018 moriasi et al 2007 shi et al 2011 additionally the relative errors of this model are all less than 10 in scenarios with or without wetlands which present that the model used in this paper is reasonable for water quality and wetland simulation 3 results and discussion 3 1 removal efficiency of wetlands to different pollutants comparing spatial distribution of cod tp tn on july 30 in these two different scenarios results are shown in fig 7 as shown in fig 7 in the scenario without wetlands the concentration of pollutants is larger in the bays than that in the middle of lakes pollutants are usually discharged into the lake from sewage outfalls around the bays mu et al 2013 most outfalls are located in the bays of gutan lake and chiye lake because of this water quality of the gutan lake and chiye lake is worse than that of the baitan lake the results of the scenario without project indicated that the water quality of cod and tn in gutan lake and chiye lake would deteriorate to some extent additionally the pollutant concentration in areas around the sewage outfalls is the highest in the water according to the right portion of fig 7 the water quality is obviously improved after planting the subsurface flow wetlands especially the cod and tn are mostly removed by wetlands without wetlands the concentration of cod in the baitan lake is almost over 20 mg l half of which is over 30 mg l however with wetlands the cod concentration drops below 20 mg l a large reduction of cod occurred along the bays in gutan lake and chiye lake for tn it has the same phenomenon as the cod whereas the decrease of tp is not obvious especially in the bays it is indicated that the absorption of phosphorus by wetlands is relatively poor according to the simulation results the quantity and efficiency of pollutant removal by wetlands were shown in table 7 the impact of the wetlands is expected to lead to the annual reduction of cod 246 38 tons tn 32 85 tons and tp 3 29 tons the wetlands in lakes with a very good retention storage and purification function have an active role in reduction of pollution load into the lakes with removal rates to external pollutants loads cod 61 tn 49 and tp 34 most of the cod input from external sources will be removed by wetlands which are similar to previous studies displaying highest removal on cod less on tn and the least on tp zhou et al 2017 zurita et al 2009 3 2 removal efficiency of wetlands at different time periods the pollutant concentration at 9 and 12 during one year from march 5 to march 4 in the next year is shown in fig 8 without wetlands in the center of baitan lake 9 the concentration of cod is almost over 25 mg l tn is over 1 6 mg l and tp ranges from 0 06 to 0 07 which indicates a serious pollution during the whole year water quality concentration of cod tn tp at 9 tends to stay fairly flat but with wetlands the trends of cod and tn are dramatically changed especially in june and early july the concentration of cod at 9 on july 9 decrease to 15 8 mg l from 29 3 mg l with over forty five percent lower on the other hand water quality concentration fluctuates at 12 due to the external pollutant input as the main pollutant source of the lake is non point sources a lot of pollutants will be washed into the lake by initial rain during the early rainy season from early may to mid june grand clement et al 2013 after that until august the temperature and rainfall are gradually increasing but pollutants reduce which makes pollution be generally diluted by runoff around the lake this is why the water quality concentration of cod tn tp is lowest at 12 during the period from june to august during this period with wetland the pollutants of cod and tn will be largely removed at 12 nevertheless compared with cod and tn the reduction of tp concentration is very small the temporal distribution of pollutant concentration means that with wetlands comparatively there will be a larger drop of pollutants during the late spring the whole summer on cod and tn but a smaller drop on tp 3 3 factors influencing pollutants removing efficiency of wetlands water temperature flow velocity and water depth are the major impact factors to the nutrients absorbing ability of wetlands bai et al 2017 seybold et al 2002 wen et al 2013 for different pollutants the main impact factors are various 3 3 1 pollutants characteristic generally the mechanism of wetlands removing pollutants is that the plant roots stems leaves and root parts of the wetland matrix layer can intercept the suspended material in the polluted water and make it deposit to the base layer during pollutants entering into the wetland for wetlands dissolved pollutants are more readily absorbed than particle pollutants most of the cod from the external sources are dissolved forms zeng et al 2020 while phosphorus is constituted by dissolved and particulate phosphorus björkman et al 2018 most of the phosphorus is easily adsorbed by sediments and deposited at the bottom of the lake which makes wetlands not disadvantageous to assimilate phosphorus ding et al 2018 zhou et al 2005 however the average removal rate is less than the removal rate of 80 70 and 50 found by the researcher zurita et al 2009 who used a vertical subsurface flow constructed wetlands vfcw for domestic wastewater treatment especially the tp only one third of the tp can be cleaned besides several studies discovered that the phosphorus removal in constructed wetland system is almost adsorbed by matrix and only a small part of total phosphorus can be removed by plant absorption hussain et al 2015 kumar et al 2011 compared with the experimental studies the matrix is not considered in this study which may be the reason that removal efficiency of organics and nitrogen from wastewater is less 3 3 2 water temperature generally plants have limited ability to directly purify pollutants of cod only contributing 15 19 and tn almost 20 40 while microorganisms in plant roots play a greater role in removing cod and tn vymazal 2009 in this paper the degradation of pollutants is set according to the plant growth which is affected by water temperature the correlation analysis between removal efficiency and water temperature is shown in fig 9 in winter and early spring the removal efficiency of the three pollutants was the lowest when the temperature was below 15 for example the lowest removal rates of cod tn and tp in this system were 24 24 33 0 and 20 7 respectively researches indicated that the root activity of wetland and life activity of microorganism would decrease when temperature approach 10 gotor vila et al 2017 which made that the ability of wetlands and microorganism to remove pollutants was weak with the temperature rising at the end of spring and reaching above 25 degrees in mid to late august wetland activities were intensified meanwhile the large roots of wetland provided favorable conditions for the reproduction of microorganisms and then accelerated the pollutants removal speed of microorganisms saeed et al 2018 in august the removal efficiency of the three pollutants reached the maximum for instance the removal of cod will reach 93 together with tn 63 and tp 45 when temperature drops in autumn the removal efficiency of pollutants will decrease and the trend will continue to decline until winter this result is similar to many experimental analysis studies wu et al 2018 2017 suggesting that temperature has a significant impact on the removal efficiency of wetlands and models in this paper can simulate this phenomenon 3 3 3 flow velocity and water depth flow velocity is an important impact factor for pollution degradation generally higher flow velocity makes faster pollutant diffusion and degradation zhao et al 2018 flow velocity in the middle of lakes is higher than that in the bays fig 10 shows the average flow velocity in lakes water flow velocity will influence hydraulic load which is an important parameter affecting the purifying effect of wetland damanik ambarita et al 2016 soini et al 2002 as shown in fig 9 flow velocities around wetland areas in this lake are all below 0 005 m s which makes pollutants hard to diffuse however smaller hydraulic load will result in better removal efficiency andrade et al 2013 on the whole the flow velocity in the chiye river is faster and brings pollutants from the chiye river to chiye lake and baitan lake which leads to water quality in the chiye lake worse than that in the other two lakes as shown in fig 9 there is an obvious moving trace of pollutants following water movement in the scenarios without subsurface flow wetlands average annual removal efficiency per area of cod tn tp is shown in fig 11 flow velocity in wetland w3 is higher than that in wetlands w2 and w4 which leads to lower quantity of average pollutants removal per area and all other factors are similar for example the removal of quantity per area of cod tp tn is respectively 6 883 kg m2 0 080 kg m2 and 1 039 kg m2 at wetland w3 which is less than w4 with 15 4 12 2 and 4 7 respectively due to the lower flow velocity the pollutants residence time increases correspondingly then it is conducive to the absorption of plant roots and the decomposition of microorganisms zou et al 2009 especially the components of tp which are almost absorbed by sediment will be easily taken away by the water flow this leads to the removal of tp in w3 being the least spatially the water temperature and flow velocity among wetlands w1 w2 w4 have little difference however the removal efficiency of w1 and w2 is less than that of w4 on the other hand flow velocity in w1 is less than that in w3 but the removal of cod and tn is still less that is to say the flow velocity is not the significant factor that makes the difference of removal among the wetlands moreover previous studies indicated that water depth is a key factor in pollutant removal of wetland cameron et al 2003 xu et al 2016 water depth of these four wetlands is different in fig 10 summer water depth of w1 is almost one meter smaller than that of w4 and 0 5 m less than that of w3 the result shows that the average quantity per area of annual pollutant removal in w1 is 35 9 and 47 5 less than w4 on cod and tn respectively as for diffluent cod and tn the increase of water depth increased the contact area and contact time between each component of wetlands and pollutants so the removal rate of cod and tn increased with the increase of water depth since there is little difference in different wetland areas the positive effect of increasing water depth on removal rate is greater than the negative effect of decreasing flow velocity 4 conclusion ecological remediation methods especially the subsurface flow wetlands are have been widely used for water pollution control it is necessary to evaluate the efficiency of wetlands in reducing water pollutants according to the growing characteristics of aquatic plant and nutrient migration theory in the plant sediment water interface a numerical model combined with hydrodynamic water quality model sediment flux model and wetlands growth model has been developed besides an algorithm of wetlands pollutants removal efficiency based on this model was put forward these methods were used to evaluate the capacity of subsurface flow wetlands including the reed and smooth cordgrass to reduce pollutants in a polluted lake the accuracy of models used in the lake is acceptable spatial and temporal distribution of pollutants with or without subsurface flow wetlands were analyzed results showed that with four wetlands annual reductions are cod 246 38 tons tn 32 85 tons and tp 3 29 tons with the reduced rate of external pollutant loads for cod 61 tn 49 and tp 34 wetlands can purify cod and tn significantly but tp faintly additionally water temperature greatly influences the pollutant removal performances of wetlands with a positive relationship in august when the water temperature reaches the highest the removal rate will reach higher with cod 93 tn 63 and tp 45 this is higher than that in the winter with cod 24 24 tn 33 0 and tp 20 7 when the water temperature is below 15 flow velocity and water depth also had some effect on the removal efficiency models developed in this paper are suitable for areas with limited data which makes the extensive use of these models can be obtained while in different growth periods wetland has different pollutant removal capacity the adsorption capacity of wetlands is not only influenced by do ph varieties of wetlands but also by flow velocity water depth and other factors except water temperature these topics will be studied in further research credit authorship contribution statement yonggui wang writing original draft writing review editing qiang li writing review editing visualization wanshun zhang supervision methodology shaofei wang supervision methodology hong peng funding acquisition conceptualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national nature science foundation of china no 41807471 41877531 the open research fund program of mnr key laboratory for geo environmental monitoring of great bay area szu51029202010 and the open research foundation of key laboratory of the pearl river estuarine dynamics and associated process regulation ministry of water resources 
4551,ecological remediation with subsurface flow wetland is one of the most widely used methods for pollution abatement assessment on its implementation efficiency is necessary but difficult to evaluate the pollutant removal effect of constructed subsurface flow wetlands a wetland growth model coupling with a hydrodynamic water quality model has been put forward the coupled model has been used to assess the impact of constructed subsurface flow wetlands on a polluted lake in hubei province china four pieces of constructed subsurface flow wetlands composed of reed and smooth cordgrass with total area of 38 9 thousand square meters for pollutant removal have been designed for the lake results showed that reductions of chemical oxygen demand cod total phosphorus tp and total nitrogen tn were 246 38 28 14 and 3 29 tons year respectively compared with the different pollutants the removal efficiency of subsurface flow wetlands on tn 49 is bigger than tp 34 but less than cod 60 furthermore the higher water temperature smaller flow velocity and bigger water depth will improve the pollutants removal performance of subsurface flow wetlands keywords constructed subsurface flow wetland water ecological model pollutant removal assessment ecological remediation 1 introduction controlling water pollution and restoring the water environment have become national strategic activities in many countries ecological remediation is a significant method of environmental governance sun et al 2017 subsurface flow wetland is the most widely used in water ecological restoration ranieri et al 2011 a subsurface flow wetland is a kind of aerobic wetland which always contains free water surface submerged plants and floating plants the treatment of sewage by constructed wetland is the comprehensive result of the physical chemical and biological processes among plants substrate and internal microorganisms including precipitation filtration oxidation degradation and adsorption wu et al 2018 experimental researches have been done to assess pollutant removal performances of wetlands to wastewater results of which showed that different kinds of wetlands have different removal efficiency to different pollutants hu et al 2020 saeed et al 2018 however wastewater removal efficiency of wetland is highly correlated with solar radiation intensity temperature nutrient availability and hydrodynamic condition huang et al 2010 in different water the performance of the same wetland system is completely different based on the previous experimental research it is still indispensable to develop pre assessment models for removal efficiency evaluation of wetland for wetland engineering design and construction plans nevertheless as the complexity of pollutants water wetland system it is still challenging to assess how much pollutants that subsurface flow wetland can remove before the subsurface flow wetlands project is implemented many methods such as simple design models first order k c model plant growth model and monod type equations have been proposed to evaluate the efficiency of ecological remediation measures rules of thumb and regression equations are two typical kinds of simple design models for example the horizontal subsurface flow ssf constructed treatment wetlands assess equations are the fastest but the roughest herrera melián et al 2020 kadlec 1997 several authors have studied regression equations of inlet and outlet pollutant concentrations of horizontal ssf constructed treatment wetlands boog et al 2019 griffin et al 1999 however due to neglecting many important factors of wetlands growth these equations are always oversimplified and have great uncertainty rousseau et al 2004 wang et al 2020 the plant growth model is based on the empirical relationship between plant biomass and environmental conditions many researches have studied the relationship among plant growth water temperature nutrients and sunlight nxawe et al 2010 weerakoon et al 2020 monod type equation is a kind of first order models in which the relatively low concentrations are used for representing first order rate reactions instead of high concentrations used for zero order rate reactions research has found that monod type model over performs a first order model in simulation accuracy a i et al 2019 mitchell and mcnevin 2001 nevertheless without considering the ecological process these methods are simplified and based on assumptions which cause errors in fitting with the complex operating conditions of subsurface flow wetlands saeed and sun 2011 to describe the physical chemical and biological processes of subsurface flow wetlands more completely many mechanisms or processes based numerical models have been developed fioreze and mancuso 2019 savickis et al 2016 smesrud et al 2014 in these models the typical transformation and degradation processes of carbon and nitrogen the water and oxygen balances as well as plant growth and decay processes are considered some of these processes have been developed in modules for example the multi component reactive transport module cw2d langergraber 2002 including 12 components dissolved oxygen organic matter ammonium nitrite nitrate nitrogen gas inorganic phosphorus as well as heterotrophic and two species of autotrophic micro organisms and 9 processes hydrolysis mineralization of organic matter nitrification denitrification and a lysis process for the micro organisms langergraber et al 2009 and numerical models describe the changing processes of a large number of components in detail sanchez ramos et al 2019 whereas the extension and application of these numerical models are always difficult for their complex characters and abundant data requirements for the design of subsurface flow wetlands the assessment tool should be precise and be applicable under the conditions of limited data this study has provided a coupled method to evaluate the efficiency of pollutant reduction in constructed subsurface flow wetlands in a lake in china it simplifies the numerical plant growth model integrated with hydrodynamic and water quality model and will be appropriate in areas where data are limited therefore the objectives of this study are a to develop a hybrid water ecological model for the design of subsurface flow wetlands and b to assess the pollutant reduction capacity of a practical constructed subsurface flow wetlands project 2 methods and materials 2 1 study areas the baitanhu lake containing baitan lake bt gutan lake gt and chiye lake cy are located in huanggang city hubei province china as shown in fig 1 these three lakes are heavily polluted mainly by organic materials and nutrient sources especially in the chemical oxygen demand cod total phosphorus tp and total nitrogen tn in recent years the government has realized the importance of water environmental protection and increased investments in environmental improvement a project which is in accordance with the huanggang urban master plan 2011 2030 and the baitan lake area control plan has been set up to improve the water quality within the 25 27 km2 of the baitan lake planning area in this project constructed subsurface flow wetlands were designed for water quality improvement this project was designed in 2013 and four constructed wetlands w1 w2 w3 w4 will be planted as shown in fig 1 a the w1 w2 subsurface flow wetlands will be constructed in the arm of baitan lake and gutan lake the w3 subsurface flow wetland will be constructed in chiye lake and the w4 subsurface flow wetland will be constructed in the south east of a baitan island fig 1 b shows a typical cross section of the subsurface flow wetland the subsurface flow wetland will be created as a floating island wetland which is a recent bio engineering technology for improving water quality aquatic species are planted on a floating raft with their roots extending into the water column underneath the raft thus able to absorb and remove nutrients such as nitrogen and phosphorus from the water the common local species such as reed and smooth cordgrass have been selected to be planted in the subsurface flow wetland up till now only one wetland w3 has been finished measured data in 2013 before and after planting of w3 planted have been used for model verification the other three wetlands were used for pollutants removal efficiency assessment by numerical models 2 2 models developments water and subsurface flow wetlands coupled with bottom sediment compose an independent ecosystem during the processes of growth maturity decline and death subsurface flow wetlands not only assimilate nutriment from waters and sediments for primary production but return nutrients to the environment after death pincam et al 2020 which is influenced by water hydrodynamic water nutrient substance and other environmental factors considering these processes a coupled model consisting of a hydrodynamic water quality model a sediment model and a water ecological model has been developed as shown in fig 2 2 2 1 hydrodynamic and water quality model the hydrodynamic model and water quality model were based on a common two dimensional hydrodynamic and water quality lake model xu et al 2020 including continuity equation 1 momentum equations in and y directions 2 3 and diffusion control equations of nutrients 4 1 z t h u x h v y 0 2 h u t h u u x h v u y g h z x g n 2 h u 2 v 2 u h 4 3 h f v ρ a f w w x 2 w y 2 w x ρ w x h γ t u x y h γ t u y 3 h v t h u v x h v v y g h z y g n 2 h u 2 v 2 v h 4 3 h f u ρ a f w w x 2 w y 2 w y ρ w x h γ t v x y h γ t v y 4 h c i t hu c i x hv c i y x h k x c i x y h k y c i y h k d c i s m s p where u and v are respectively the average velocity in x and y directions m s z is water level m h is water depth m f is coriolis coefficient f 2ωsin lat and ω is the earth rotation angular frequency while lat is latitude γ t is turbulent viscosity coefficient m2 s ρa and ρw are air density and water density respectively fw is wind stress coefficient wx and wy are respectively wind speed in x and y directions n is the roughness factor ct is the concentration of nutrients in the water mg l kx and ky are nutrients diffusion coefficient in x and y directions s m2 respectively kd is the degradation coefficient of nutrients s 1 sm is nutrient load from lakebed sediments kg and sm can be calculated as 5 s m λ c c d where λ is the nutrients release coefficient of sediment mg m2 d c and cd are nutrient concentrations in the water and sediment respectively c is calculated by the water quality model cd is computed by the sediment flux model sp represents the nutrient removed by subsurface flow wetlands through sediment including plants absorbed by plants sorb and consumed by the microorganisms attached to roots scon 6 s p s orb s con s con λ s s orb t λ k k d sorb can be calculated by biomass through a proportion of nutrients c n p carbon nitrogen and phosphorus constituting the total biomass while both λs and λk are the coefficient 2 2 2 sediment flux model nutrient concentration in sediment is affected by physical chemical and biological processes including diffusion adsorption mineralization nitrification and denitrification and plants absorption process ge et al 2020 zhang et al 2014 the basic equation is as follows 7 θ f ρ k d c i s t t θ d c i s z q c i s t φ c i s k θ ρ s 2 i φ k θ ρ 1 f k d θ λ 1 f ρ k d λ 2 8 s 2 i t k θ 1 f k d c i s s 2 i λ 3 s 2 i where c i s is nutrients concentration in the aqueous phase of sediment mg l θ is the percentage of saturated water content ρ is sediment density kd is distribution coefficient of water and sediment k is first order adsorption rate constant d is dispersion coefficient z is the depth of sediment λ 1 λ 2 and λ 3 are first order degradation rate coefficient in the aqueous phase equilibrium adsorption phase and non equilibrium adsorption phase respectively s2 is the adsorbent concentration in non equilibrium adsorption phase 2 2 3 growth model of wetlands during the growth of subsurface flow wetlands pollutants will be absorbed and reduced previous studies have reported that the growth of subsurface flow wetlands is influenced by water temperature water and nutrients oliver et al 2017 steinman et al 2014 in an ideal condition plant growth can be regarded as a time change function of its maximum growth rate and environmental factors a common function for subsurface flow wetlands growth is as follows hem 1971 9 db dt g b max t g t t g n u t g i t g w t b where b is the biomass of subsurface flow wetlands g m2 g b max t is the maximum growth rate for plants g m2 d g t t is temperature limiting factor g n u t is the nutrient limiting factor g i t is the illumination limiting factor g w t is the water limiting factor related to water depth and flow velocity t is the time of plants growing d during realistic simulation realistic temperature nutrient and illumination the detailed relationships between plant growth and environmental conditions depend on the plant species thus equation 9 can be 10 db dt g b max t b 2 2 4 model conditions the boundary conditions and initial condition are as follows 1 inflow boundary conditions 11 q q in x y t c c in x y t 2 outflow boundary condition 12 q q out x y t 3 initial condition 13 φ φ x y 0 where qin is the quantity of inflow m3 s x y are respectively the locations of elements t is the time c is the pollutant concentration mg l φ is indicators initial values of modeling including water level pollutant concentration equations will be solved by the finite control volume method with an upwind scheme 2 2 5 removal efficiency to evaluate the nutrient remove efficiency of subsurface flow wetlands a removal efficiency ref index was set as follows 14 ref i 1 m c it v it i 1 m c it v it i 1 m c it v it where t is the date i is the number of grid cells in the two dimensional model v is the volume of the grid l c is the nutrient concentration without subsurface flow wetlands c is the nutrient concentration with subsurface flow wetlands the processes of calculating removal efficiency are shown in fig 3 firstly the wetland growth model is used to simulate the total biomass of wetlands according to the proportion of carbon nitrogen and phosphorus in biomass the nutrients absorbed by wetlands can be calculated in this process the botanical photosynthesis respiration and nutrient absorption through the stem and leaf are ignored secondly assuming that nutrients in sediment are dynamically balanced the nutrients absorbed by wetlands will be supplemented by water with this assumption the sediment flux model will be operated which will get nutrients concentration in sediment for every grid thirdly the nutrient in water in two scenarios with or without wetlands will be simulated by the water quality model using equation 10 the total volume the removal efficiency of different nutrients removed by wetlands in the whole lake and every grid in time series or within a specific time can be computed 2 3 model conditions setting two dimensional regular grids have been used for model simulation with mesh size of 10 30 m according to the current situation of water quality of lakes cod tn and tp were set as three water quality indexes inflow from chushui river and outflow from jinshui river are the boundary conditions of two tributaries in addition two sluice gates have been set to control the inflow and outflow through field investigation and monitoring we have obtained the loads of pollutants source hydrological and water quality conditions of the lakes based on the survey data there are almost 15 outfalls around the lakes as shown in fig 3 wastewater carrying pollutants from storm water runoff fish farming agriculture and soil erosion enter into the lakes the external pollution source loads are estimated as shown in table 1 for shoreline protection the non points sources pollutants are gathered and entered into the lake through 15 sewage outfalls with 403 26 tons per year t a cod 9 58 t a tn and 66 87 t a tp which have been treated as lateral input conditions pollutant loads from external pollutant sources are much larger than pollutants in stock with cod of 403 26 tons tn of 66 87 tons and tp of 5 77 tons every year the water level of the outlet shown in fig 4 measured data has been set as a boundary condition initial conditions of each grid were gained from the measured value of 14 measured sites in early spring by inverse distance weighted interpolation as shown in table 2 for model calibration and validation measured data at 9 and 12 from march 5 2013 to the march 4 2014 were used for model calibration data at 1 6 7 9 and 13 selection of measuring sites is random which is evenly distributed in the three lakes were set for model validation 2 4 scenarios of simulation two scenarios have been designed for the model simulation the first one is the scenario without subsurface flow wetlands while the second one is a comparable scenario with 4 subsurface flow wetlands as shown in fig 3 there are 4 subsurface flow wetlands in three lakes and sizes of subsurface flow wetlands w1 w2 w3 w4 are 14 515 m2 9 211 m2 5 870 m2 and 9 304 m2 respectively in these four wetlands the reed and smooth cordgrass are both planted about 50 percent of the total a full year period was set for simulation from march 5 2013 without wetlands to march 4 of the next year planned year with wetlands in the wetland scenario it is assumed that the water temperature and light factors are all in an appropriate state while plant growth is mainly restricted by nutrients thus the gbmax t is the main factor affecting the biomass of wetland according to the pervious study the gbmax t can be obtained from table 3 in the different growing period of wetlands the proportion of nutrients is different which can be gained from table 4 2 5 parameters calibration and model validation 2 5 1 sensitive parameters and value ranges for the hydrodynamic model the roughness coefficient is the deterministic parameter comparing measured flow velocity water level and simulated results the roughness coefficient of these three lakes is around 0 2 to 0 25 for the water quality model the degradation coefficient kd nutrients diffusion coefficient kxy and nutrient release rate λ from sediment in three lakes are calibrated as shown in table 5 parameters of the sediment flux model are calibrated with the same values in three lakes as shown in table 6 to simplify models the λs and λk were set as 1 2 5 2 model calibration and validation 1 scenario without wetlands model calibration results of water level and flow velocity are shown in fig 4 and the calibration results of cod tn and tp concentration without wetlands at 9 and 12 in 2013 are shown in fig 5 as shown in fig 4 after parameters calibration the simulated water level and measured water level match well where the coefficient of the determinant r2 is over 0 99 in addition it also indicates that the model can simulate the flow velocity characteristics of temporal and spatial variation with r2 bigger than 0 8 in four seasons the fig 5 shows that the measured data and simulated data of cod tn and tp at locations 9 in the baitan lake and 12 in the chiye lake which are also matching well the relative errors range from 14 to 12 and the errors of90 samples are between 10 and 10 2 scenario with wetlands after wetland w3 planted the water quality concentration was simulated and the parameters were calibrated the coefficient of the determinant r2 and relative error have been used for water quality model validation furthermore results of measured data and simulated data in five sections 1 6 7 12 and 13 on march 29 may 17 and june 9 were shown in fig 6 as shown in fig 6 the r2 of cod tp tn are respectively 0 7618 0 9221 and 0 9395 the relative errors of these three water quality indexes are 9 7 11 and 7 69 respectively for many previous studies about water quality models that r2 larger than 0 6 is can be judged as satisfactory masocha et al 2018 moriasi et al 2007 shi et al 2011 additionally the relative errors of this model are all less than 10 in scenarios with or without wetlands which present that the model used in this paper is reasonable for water quality and wetland simulation 3 results and discussion 3 1 removal efficiency of wetlands to different pollutants comparing spatial distribution of cod tp tn on july 30 in these two different scenarios results are shown in fig 7 as shown in fig 7 in the scenario without wetlands the concentration of pollutants is larger in the bays than that in the middle of lakes pollutants are usually discharged into the lake from sewage outfalls around the bays mu et al 2013 most outfalls are located in the bays of gutan lake and chiye lake because of this water quality of the gutan lake and chiye lake is worse than that of the baitan lake the results of the scenario without project indicated that the water quality of cod and tn in gutan lake and chiye lake would deteriorate to some extent additionally the pollutant concentration in areas around the sewage outfalls is the highest in the water according to the right portion of fig 7 the water quality is obviously improved after planting the subsurface flow wetlands especially the cod and tn are mostly removed by wetlands without wetlands the concentration of cod in the baitan lake is almost over 20 mg l half of which is over 30 mg l however with wetlands the cod concentration drops below 20 mg l a large reduction of cod occurred along the bays in gutan lake and chiye lake for tn it has the same phenomenon as the cod whereas the decrease of tp is not obvious especially in the bays it is indicated that the absorption of phosphorus by wetlands is relatively poor according to the simulation results the quantity and efficiency of pollutant removal by wetlands were shown in table 7 the impact of the wetlands is expected to lead to the annual reduction of cod 246 38 tons tn 32 85 tons and tp 3 29 tons the wetlands in lakes with a very good retention storage and purification function have an active role in reduction of pollution load into the lakes with removal rates to external pollutants loads cod 61 tn 49 and tp 34 most of the cod input from external sources will be removed by wetlands which are similar to previous studies displaying highest removal on cod less on tn and the least on tp zhou et al 2017 zurita et al 2009 3 2 removal efficiency of wetlands at different time periods the pollutant concentration at 9 and 12 during one year from march 5 to march 4 in the next year is shown in fig 8 without wetlands in the center of baitan lake 9 the concentration of cod is almost over 25 mg l tn is over 1 6 mg l and tp ranges from 0 06 to 0 07 which indicates a serious pollution during the whole year water quality concentration of cod tn tp at 9 tends to stay fairly flat but with wetlands the trends of cod and tn are dramatically changed especially in june and early july the concentration of cod at 9 on july 9 decrease to 15 8 mg l from 29 3 mg l with over forty five percent lower on the other hand water quality concentration fluctuates at 12 due to the external pollutant input as the main pollutant source of the lake is non point sources a lot of pollutants will be washed into the lake by initial rain during the early rainy season from early may to mid june grand clement et al 2013 after that until august the temperature and rainfall are gradually increasing but pollutants reduce which makes pollution be generally diluted by runoff around the lake this is why the water quality concentration of cod tn tp is lowest at 12 during the period from june to august during this period with wetland the pollutants of cod and tn will be largely removed at 12 nevertheless compared with cod and tn the reduction of tp concentration is very small the temporal distribution of pollutant concentration means that with wetlands comparatively there will be a larger drop of pollutants during the late spring the whole summer on cod and tn but a smaller drop on tp 3 3 factors influencing pollutants removing efficiency of wetlands water temperature flow velocity and water depth are the major impact factors to the nutrients absorbing ability of wetlands bai et al 2017 seybold et al 2002 wen et al 2013 for different pollutants the main impact factors are various 3 3 1 pollutants characteristic generally the mechanism of wetlands removing pollutants is that the plant roots stems leaves and root parts of the wetland matrix layer can intercept the suspended material in the polluted water and make it deposit to the base layer during pollutants entering into the wetland for wetlands dissolved pollutants are more readily absorbed than particle pollutants most of the cod from the external sources are dissolved forms zeng et al 2020 while phosphorus is constituted by dissolved and particulate phosphorus björkman et al 2018 most of the phosphorus is easily adsorbed by sediments and deposited at the bottom of the lake which makes wetlands not disadvantageous to assimilate phosphorus ding et al 2018 zhou et al 2005 however the average removal rate is less than the removal rate of 80 70 and 50 found by the researcher zurita et al 2009 who used a vertical subsurface flow constructed wetlands vfcw for domestic wastewater treatment especially the tp only one third of the tp can be cleaned besides several studies discovered that the phosphorus removal in constructed wetland system is almost adsorbed by matrix and only a small part of total phosphorus can be removed by plant absorption hussain et al 2015 kumar et al 2011 compared with the experimental studies the matrix is not considered in this study which may be the reason that removal efficiency of organics and nitrogen from wastewater is less 3 3 2 water temperature generally plants have limited ability to directly purify pollutants of cod only contributing 15 19 and tn almost 20 40 while microorganisms in plant roots play a greater role in removing cod and tn vymazal 2009 in this paper the degradation of pollutants is set according to the plant growth which is affected by water temperature the correlation analysis between removal efficiency and water temperature is shown in fig 9 in winter and early spring the removal efficiency of the three pollutants was the lowest when the temperature was below 15 for example the lowest removal rates of cod tn and tp in this system were 24 24 33 0 and 20 7 respectively researches indicated that the root activity of wetland and life activity of microorganism would decrease when temperature approach 10 gotor vila et al 2017 which made that the ability of wetlands and microorganism to remove pollutants was weak with the temperature rising at the end of spring and reaching above 25 degrees in mid to late august wetland activities were intensified meanwhile the large roots of wetland provided favorable conditions for the reproduction of microorganisms and then accelerated the pollutants removal speed of microorganisms saeed et al 2018 in august the removal efficiency of the three pollutants reached the maximum for instance the removal of cod will reach 93 together with tn 63 and tp 45 when temperature drops in autumn the removal efficiency of pollutants will decrease and the trend will continue to decline until winter this result is similar to many experimental analysis studies wu et al 2018 2017 suggesting that temperature has a significant impact on the removal efficiency of wetlands and models in this paper can simulate this phenomenon 3 3 3 flow velocity and water depth flow velocity is an important impact factor for pollution degradation generally higher flow velocity makes faster pollutant diffusion and degradation zhao et al 2018 flow velocity in the middle of lakes is higher than that in the bays fig 10 shows the average flow velocity in lakes water flow velocity will influence hydraulic load which is an important parameter affecting the purifying effect of wetland damanik ambarita et al 2016 soini et al 2002 as shown in fig 9 flow velocities around wetland areas in this lake are all below 0 005 m s which makes pollutants hard to diffuse however smaller hydraulic load will result in better removal efficiency andrade et al 2013 on the whole the flow velocity in the chiye river is faster and brings pollutants from the chiye river to chiye lake and baitan lake which leads to water quality in the chiye lake worse than that in the other two lakes as shown in fig 9 there is an obvious moving trace of pollutants following water movement in the scenarios without subsurface flow wetlands average annual removal efficiency per area of cod tn tp is shown in fig 11 flow velocity in wetland w3 is higher than that in wetlands w2 and w4 which leads to lower quantity of average pollutants removal per area and all other factors are similar for example the removal of quantity per area of cod tp tn is respectively 6 883 kg m2 0 080 kg m2 and 1 039 kg m2 at wetland w3 which is less than w4 with 15 4 12 2 and 4 7 respectively due to the lower flow velocity the pollutants residence time increases correspondingly then it is conducive to the absorption of plant roots and the decomposition of microorganisms zou et al 2009 especially the components of tp which are almost absorbed by sediment will be easily taken away by the water flow this leads to the removal of tp in w3 being the least spatially the water temperature and flow velocity among wetlands w1 w2 w4 have little difference however the removal efficiency of w1 and w2 is less than that of w4 on the other hand flow velocity in w1 is less than that in w3 but the removal of cod and tn is still less that is to say the flow velocity is not the significant factor that makes the difference of removal among the wetlands moreover previous studies indicated that water depth is a key factor in pollutant removal of wetland cameron et al 2003 xu et al 2016 water depth of these four wetlands is different in fig 10 summer water depth of w1 is almost one meter smaller than that of w4 and 0 5 m less than that of w3 the result shows that the average quantity per area of annual pollutant removal in w1 is 35 9 and 47 5 less than w4 on cod and tn respectively as for diffluent cod and tn the increase of water depth increased the contact area and contact time between each component of wetlands and pollutants so the removal rate of cod and tn increased with the increase of water depth since there is little difference in different wetland areas the positive effect of increasing water depth on removal rate is greater than the negative effect of decreasing flow velocity 4 conclusion ecological remediation methods especially the subsurface flow wetlands are have been widely used for water pollution control it is necessary to evaluate the efficiency of wetlands in reducing water pollutants according to the growing characteristics of aquatic plant and nutrient migration theory in the plant sediment water interface a numerical model combined with hydrodynamic water quality model sediment flux model and wetlands growth model has been developed besides an algorithm of wetlands pollutants removal efficiency based on this model was put forward these methods were used to evaluate the capacity of subsurface flow wetlands including the reed and smooth cordgrass to reduce pollutants in a polluted lake the accuracy of models used in the lake is acceptable spatial and temporal distribution of pollutants with or without subsurface flow wetlands were analyzed results showed that with four wetlands annual reductions are cod 246 38 tons tn 32 85 tons and tp 3 29 tons with the reduced rate of external pollutant loads for cod 61 tn 49 and tp 34 wetlands can purify cod and tn significantly but tp faintly additionally water temperature greatly influences the pollutant removal performances of wetlands with a positive relationship in august when the water temperature reaches the highest the removal rate will reach higher with cod 93 tn 63 and tp 45 this is higher than that in the winter with cod 24 24 tn 33 0 and tp 20 7 when the water temperature is below 15 flow velocity and water depth also had some effect on the removal efficiency models developed in this paper are suitable for areas with limited data which makes the extensive use of these models can be obtained while in different growth periods wetland has different pollutant removal capacity the adsorption capacity of wetlands is not only influenced by do ph varieties of wetlands but also by flow velocity water depth and other factors except water temperature these topics will be studied in further research credit authorship contribution statement yonggui wang writing original draft writing review editing qiang li writing review editing visualization wanshun zhang supervision methodology shaofei wang supervision methodology hong peng funding acquisition conceptualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national nature science foundation of china no 41807471 41877531 the open research fund program of mnr key laboratory for geo environmental monitoring of great bay area szu51029202010 and the open research foundation of key laboratory of the pearl river estuarine dynamics and associated process regulation ministry of water resources 
4552,in mountainous terrain reliable snow simulations are crucial for many applications however except in highly instrumented research catchments meteorological data are usually limited and so the interpolated spatial fields used to force snow models are uncertain moreover certain potentially important processes cannot presently be simulated at catchment scales using entirely physical algorithms it is therefore often appropriate to introduce empirical parameters into otherwise physically based snow models many opportunities to incorporate snow observations into the parameter estimation process now exist but they remain to be fully exploited in this context a novel approach to the calibration of an energy balance based snow model that additionally accounts for gravitational redistribution is presented several important parameters were estimated using an efficient gradient based method with respect to two complementary observation types landsat 8 derived snow extent maps and reconstructed snow water equivalent swe time series when assessed on a per pixel basis observed patterns were ultimately reproduced with a mean accuracy of 85 spatial performance metrics compared favourably with those previously reported whilst the temporal evolution of swe at the stations was also satisfactorily captured subsequent uncertainty and data worth analyses revealed that i the propensity for model predictions to be erroneous was substantially reduced by calibration ii pre calibration uncertainty was largely associated with two parameters which modify the longwave component of the energy balance but this uncertainty was greatly diminished by calibration and iii a lower elevation swe series was particularly valuable despite containing comparatively few observations overall our work demonstrates that contemporary snow models observation technologies and inverse approaches can be combined to both constrain and quantify the uncertainty associated with simulations of alpine snow dynamics 1 introduction 1 1 the significance of mountainous water resources meltwater derived from seasonal snowpacks currently dominates annual groundwater recharge and cumulative streamflow of many mid elevation temperate mountainous catchments at higher elevations the progressive ablation of firn and glacier ice throughout summer periods represent major additional inputs of liquid water to the terrestrial hydrosphere globally these snow and ice derived meltwaters directly sustain millions of people pritchard 2019 and constitute an ecosystem service of enormous value sturm et al 2017 however hydrological regimes which have historically been heavily influenced by snow and ice are likely to be greatly affected by ongoing warming barnett et al 2005 viviroli et al 2011 with summer low flow magnitudes particularly vulnerable jenicek et al 2016 dierauer et al 2018 indeed a wealth of evidence attesting the widespread decline of glaciers and other hydrologically relevant components of the mountain cryosphere now exists klein et al 2016 huss et al 2017 beniston et al 2018 bolch et al 2012 bormann et al 2018 vuille et al 2018 and the resultant impacts on stream discharges are increasingly detectable casassa et al 2009 micheletti lane 2016 lane nienow 2019 predictions of the future quantity and timing of mountain runoff accordingly remain in high demand and the substantial body of literature in which hydrological models are applied to generate such predictions continues to grow e g fatichi et al 2015 huss hock 2018 rain on snow events convective thunderstorms and more sustained episodes of frontal rainfall also have high and potentially increasing importance alpine terrain including with respect to floods debris flows and landslide hazard papathoma köhle et al 2011 rössler et al 2014 leonarduzzi et al 2017 as such spatio temporal patterns of liquid precipitation must also be given due consideration the same applies to evapotransporative losses herrnegger et al 2012 mutzner et al 2015 cochand et al 2019 1 2 progress in incorporating spatial snow information although many widely used box type hydrological models can often consistently reproduce even independent discharge observations following calibration against measurements of this variable alone observed internal spatial dynamics including those pertaining to the snowpack may remain poorly captured duethmann et al 2014 shrestha et al 2014 this can be attributed to the considerable freedom that traditional calibration approaches afford as well as the fact that discharge measurements provide only indirect integrated information on internal system functioning assessing simulated patterns of model state variables against spatially distributed observations provides a more stringent test of model capabilities and so represents a means by which the internal consistency of hydrological models can be enhanced indeed ensuring that the spatio temporal dynamics of all potentially relevant hydrological processes can be acceptably reproduced i e that the right answers in terms of discharge are obtained for the right reasons kirchner 2006 is likely to lead to more reliable future predictions much progress has already been made in incorporating snow information into hydrological models for example finger et al 2011 used snow cover images alongside glacier mass balance and discharge measurements in a snow and ice dominated catchment in switzerland to identify the best performing distributed model parameters from a large randomly generated set duethmann et al 2014 also employed a monte carlo approach here in an attempt to quantify the relationship between the information content and the number of snow cover images included in the calibration of a model covering several mountainous catchments in central asia in comparing two alternative strategies for simulating hydrological processes the high elevation andes ragettli et al 2014 likewise considered snowcover data although purely for evaluative purposes more recently costa et al 2018 calibrated a simple snow model using distributed snow observations to investigate the mechanisms responsible for increases in suspended sediment concentrations that were observed in the upper rhône in the 1980s developments in snow remote sensing and modelling have also been made recently in the western united states thorough the airbourne snow observatory aso and nasa s snowex campaign behrangi et al 2018 mcgrath et al 2019 hedrick et al 2018 however these efforts are geographically and temporally limited and generally rely on observation technologies that are unavailable in other global mountain regions finally some studies have employed distributed snow images not as calibration or evaluation criteria but as model inputs berezowski et al 2015 wulf et al 2016 1 3 outstanding snow modelling challenges despite these advancements given the considerable spatio temporal variability and complexity that many of the factors and processes influencing snow dynamics in rugged terrain exhibit clark et al 2011 many of the simulation approaches that currently prevail in the hydrological literature may be somewhat limited in their ability to represent snow dynamics reliably especially in moderately large topographically complex and data limited headwater regions for instance despite the now widespread availability of relevant spatial data spatially lumped e g wagner et al 2017 or only partially distributed duethmann et al 2014 staudinger et al 2017 hydrological models remain common although such lumped models have their uses they cannot represent heterogeneity below the aggregation unit and so provide little information on spatial snow patterns this is unfortunate because spatial patterns of snowcover are imperative for winter tourism grünewald et al 2010 and predicting vegetation species distributions randin et al 2015 amongst other applications more specifically integrating distributed observations with lumped models is somewhat complicated one must resort to comparing spatially averaged snow covered areas scas ragettli et al 2014 or else somehow re impose spatial variability in the simulations parajka blöschl 2008 irrespective of their spatial discretisation most hydrological modelling studies that have incorporated distributed snow observations have relied on products from the moderate resolution imaging spectroradiometer modis clark et al 2006 duethmann et al 2014 ragettli et al 2014 engel et al 2017 costa et al 2018 however the 500 m pixel resolution at which binary snow or no snow and or snow covered fraction f sca data are provided rittger et al 2013 is simply too coarse for certain applications for instance both ragettli et al 2014 and hanzer et al 2016 report difficulties capturing the complex snow patterns that are commonly observed in rugged terrain such as small patches and snow free ridges using modis imagery such relatively fine scale processes can substantially influence the internal hydrological functioning of steep mountain catchments much higher resolution 30 m and long term global snow maps can be derived from landsat imagery but have been mostly applied for model corroboration evaluation rather than calibration but see schattan et al 2020 additionally with the notable exceptions of hanzer et al 2016 and wayand et al 2018 previous studies involved only a handful of images bernhardt et al 2012 warscher et al 2013 schöber et al 2010 empirical temperature and other index based methods for estimating snow and ice melt rates hock 2003 also remain standard ragettli pellicciotti 2012 addor et al 2014 etter et al 2017 despite their abilty to satisfactorily reproduce snow dynamics in complex alpine terrain being questionable warscher et al 2013 provided additional meteorological data are available more sophisticated distributed energy balance approaches both full physics multiple snow layer configurations as well as simplified alternatives have been recommended magnusson et al 2015 meeks et al 2017 one attraction of such models in steep complex terrain is that they explicitly represent most of the fluxes influencing melt including the often pronounced spatio temporal variability thereof e g the effects of slope aspect and topographic shading effects on incoming radiation another advantage is that they can simulate melt during critical events e g rain on snow events which are mainly driven by turbulent fluxes better than their simpler counterparts würzer et al 2017 finally energy balance models are more likely to perform reliably under forcing conditions that exceed the range of historical observations as is typical in climate change impact assessments mas et al 2018 the most sophisticated energy balance models e g alpine3d lehning et al 2006 include full physics multi layered snowpack representations and therefore theoretically provide the most comprehensive representation of the complex mass and energy exchange processes that affect mountain snowpacks however for the purposes of hydrological predictions they are coupled with highly simplified conceptual or bucket type representations of subsurface processes and flow routing gallice et al 2016 in geologically complex settings which many alpine regions inherently are such simplifications may be unsuitable moreover the simulation of wind and gravitational snow redistribution processes at catchment or larger scales using physical algorithms remains computationally prohibitive mott lehning 2010 musselman et al 2015 brauchli et al 2017 yet in very steep terrain in particular accounting for gravitational snow redistribution is paramount to produce hydrologically realistic simulations of the evolution of snow water equivalent swe and thus patterns of meltwater generation bernhardt et al 2012 kerr et al 2013 sommer et al 2015 in extremis failure to do so can lead to snow towers which are undesirable model artifacts freudiger et al 2017 gravitational redistribution is also often critical to glacier accumulation mott et al 2019 various pragmatic empirical correction methods and algorithms have been developed enable such processes to still be represented e g bernhardt et al 2012 vögeli et al 2016 marshall et al 2019 a persistent fundamental challenge associated with modelling mountain hydrological systems is that the meteorological inputs are often very poorly constrained due to wind induced gauge undercatch precipitation measurements at stations are typically underestimated pan et al 2016 kochendorfer et al 2017 this bias is most pronounced when the precipitation phase is solid and at higher wind speeds in addition even in comparatively well instrumented regions like the european alps meteorological station density decreases substantially with elevation pepin et al 2015 coupled with the high spatial variability that characterises mountain meteorology mott et al 2014 this means that even if the original ground measurements could be made perfectly subsequent interpolated spatial fields would still be highly uncertainty as such irrespective of its complexity snow model performance will always be intimately related to forcing data quality 1 4 inverse approaches and uncertainty quantification assessing the error characteristics of common instruments see e g the wmo spice project kochendorfer et al 2017 and systematically testing various spatial interpolation methods tobin et al 2011 have both been pursued to address the aforementioned deficiencies in forcing datasets inverse methods whereby distributed models and snow observations are combined to estimate the values of important but uncertain correction parameters are also beginning to be applied to this end for instance in a snow model analysis involving both modis and landsat derived snow observations for evaluation engel et al 2017 found modifying a snow correction factor to be necessary to compensate for biased winter precipitation measurement shrestha et al 2014 actually calibrated a distributed multi layer water and energy balance model web dhm s in order to minimise the cumulative error in snow cover pattern again according to modis and discharge simulations in so doing an elevation dependent snowfall correction factor was optimised a particular novelty of this study was that correspondence between simulated and observed patterns was expressed at the pixel level naseer et al 2019 applied the same code but avoided traditional linear elevation dependent lapse rates for meteorological data interpolation which may break down in complex terrain by integrating 3d temperature profiles derived from climate model reanalysis data the calibration undertaken had no spatial component however most recently ruelland 2020 sought to infer uncertain mountain precipitation and temperature gradients in the french alps via inversion using a very simple snow and hydrological model alongside discharge and modis snow cover data lastly uncertainty quantification should ideally form a central pillar of any environmental modelling exercise although some previous studies have directly assessed uncertainty in swe reconstructions franz et al 2010 he et al 2011 slater et al 2013 meeks et al 2017 this has largely been undertaken only at discrete station locations i e using non distributed models as one seeks to progress beyond this situation the efficiency of calibration and uncertainty quantification algorithms becomes a crucial consideration especially as the sophistication scale and resolution a given forward model increases despite ever increasing computational power brute force approaches involving thousands of monte carlo simulations can still quickly become impractical 1 5 the present study in this context and with the intention of improving the representation of meltwater dynamics in relatively data scarce and rugged mountain settings this study proposes a model independent framework for integrating high resolution snow observations in distributed snowpack simulations it is not our intention to focus here on the development of combinstion of improved physically based algorithms for representing the various complex individual processes and phenomena that can influence snow variability in alpine terrain but rather to present a novel means by which complementary snow data can be used to constrain a series of generally important but highly uncertain parameters within any distributed snow model the moderate complexity snow code selected for our exemplification of the framework aligns well with our expectation that in this specific setting as well as likely many others especially at larger spatial scales any uncertainties associated with internal snow model structures will often be overshadowed by those from other sources e g uncertainties in forcing data fields in our approach not only are the major uncertainties involved in a typical simulation chain explicitly acknowledged but they are overcome as far as is possible more specifically a fully distributed energy balance based snow model that additionally represents gravitational redistribution is initially established at high spatio temporal resolution 25 m hourly then an objective function incorporating both high resolution snow cover maps derived from satellite imagery and reconstructed swe time series at two locations is developed and minimised using an efficient iterative calibration algorithm a single layer snowpack configuration is applied in wasim v10 04 01 schulla 2017 this code provides an appropriate balance between snow model simplicity and complexity and also enabled several additional steps to be incorporated relatively easily namely i the correction and spatial interpolation of meteorological station data ii the representation of gravitational snow redistribution which is important given the steepness of the study catchment in questions iii the representation of glacier mass balance melt and iv the generation of commensurate potential evapotranspiration et p estimates for subsequent hydrological modelling this is one of the first instances in which landsat derived snow cover images are included in the calibration of a distributed snow model in a spatially explicit i e per pixel fashion other distinguishing features of this study are that spatial fit metrics are computed for a much larger catalogue of images than previously and that the uncertainties associated with selected key predictions as well as the contributions of different parameters and groups of observations to uncertainty reduction are elucidated by including high resolution distributed snow observations swe time series and a model that accounts for gravitational redistribution this approach builds somewhat upon that of shrestha et al 2014 providing a framework that is more suited to steep and rugged terrain finally given the open source software used throughout and the long temporal coverage and global availability of the landsat archive our approach has great potential to improve the representation of snow dynamics in many mountain regions globally the input files and model data linking code are provided with the intention of helping to facilitate this furthermore because the methodology is fundamentally code and data agnostic alternative distributed codes and snowcover products can easily be substituted the model is not extended here to generate streamflow outputs this decision was taken because the study catchment under consideration is extremely geologically complex replete with folded faulted sequences of limestones shales and marls whilst the representation of subsurface processes in wasim as in most popular hydrological models is rather simplistic instead the resultant high resolution spatio temporal gridded datasets representing the arrival of snowmelt firn melt ice melt and liquid precipitation at the land surface collectively all liquid water and et p have been applied as boundary conditions for a fully integrated i e surface subsurface evapotranspiration model presented separately thornton et al under review such integrated models can ingest 3d representations of geology and simulate the mechanistic interactions between various components of hydrological systems in a physically based spatially explicit fashion as such they offer considerable potential to better understand and predict the nuances of such systems including their possible responses to external change in a more comprehensive and robust fashion than hitherto possible however most integrated models also rely on simplified empirical snow processes representations hence our broader effort seeks to leverage the respective benefits of alternative simulation approaches whilst mitigating their respective limitations 2 study area the 36 7 km2 study area includes two adjacent headwater catchments the vallon de nant and the vallon de la vare of the western swiss alps fig 1 the elevational range is considerable extending from 950 to over 3050 m a s l and slopes are accordingly extremely steep mean 35 the topography is rugged and lower parts of the study area are forested at the last glacial maximum only the highest peaks protruded above the ice bini et al 2009 an array of quaternary unconsolidated sedimentary features with glacial fluvial and mass movement origins overly the complex mesozoic bedrock several of which likely act as aquifers approximately 45 of annual precipitation 1400 mm falls as snow due to the catchment s steepness gravitational snow redistribution occurs frequently as evidenced by snow free slopes and cliffs in the winter months the photographs of fig s1 taken in the vallon de nant on the 31 january 2018 following a period of exceptional snowfall bründl et al 2019 illustrate the considerable redistribution that can occur under more extreme conditions intense summer thunderstorms are a further noteworthy feature of the area s meteorological regime the surficial hydrology of the vallon de nant is characterised by numerous temporary torrents whose discharge responds rapidly to rainfall and snowmelt being shaded by surrounding cliffs several small glaciers persist at relatively low elevations in the north facing upper reaches of both sub catchments the region remains in a highly natural state making it rather unusual in the context of the european alps reflecting this several recent environmental investigations have focused upon the area including those of vittoz et al 2009 grand et al 2016 lane et al 2016 benoit et al 2018 and giaccone et al 2019 3 data availability and processing 3 1 meteorological forcing the model required gridded estimates of incoming shortwave radiation precipitation relative humidity sunshine duration air temperature vapour pressure and wind speed no third party meteorological datasets with the desired spatio temporal resolution and which were contemporaneous with the available field measurements the earliest of which began in 2016 existed at the outset forcing datasets were therefore developed from meteorological station measurements fig 1 table s1 most of the stations used belonged to the official networks of meteoswiss and the wsl institute for snow and avalanche research slf and were located several kilometres from the study catchment and crucially at lower elevations at these stations hourly sums for precipitation and hourly means for all other variables were downloaded from idaweb the online data portal of meteoswiss meteoswiss 2019 for the hydrological years 2015 2018 i e 1 october 2014 to 30 september 2018 these data were complemented by observations from stations belonging to a local network operated by the university of lausanne s hiscox pers comm michelon et al 2017 and subsequent updates via personal communication some of which are located within the study catchment itself unsurprisingly given the harsh environment and limited access especially in winter the local stations had a higher proportion of missing data than the nationally operated ones meaning intensive processing and quality assurance efforts were required irrespective of the station operator precipitation data from unheated gauges were not considered also the precipitation data at sor were eventually removed from the input dataset as the cululative totals were deemed unrepresentative specifically they were unduly low compared with nearby stations at similar elevations brauchli et al 2018 the processed time series were plotted and inspected interactively using nivis slf 2019a the hourly time series themselves are presented in fig s14 whilst the temporal coverage of variables between stations and overall missing data percentages are shown in figures s3 to s9 the simulation period was limited to the four hydrological years 2015 2018 by lack of reliable local meteorological data prior to this although relatively short the simulation period contains a reasonable diversity of snow conditions including relatively snow rich and snow poor winters the challenge of obtaining accurate spatial fields of meteorological variables in mountainous regions hastwo direct implications for modelling the first is that precipitation measurements made using traditional instruments must be corrected for wind induced undercatch and any other factors that induce systematic bias towards underestimation here different corrections were applied depending on the incident precipitation phase equation 1 schulla 2017 1 p corr p s n o a w s s n o b t a r s t t p corr p l i q a w s l i q b t a r s t t where p is station measured precipitation mm pcorr is corrected precipitation mm snoa and snob are global correction factors for solid precipitation liqa and liqb are global correction factors for solid precipitation ws is wind speed m s 1 and rstt is the rain snow threshold temperature c the rain snow threshold temperature here denoted by rstt cannot be reliably determined a priori because it varies in time and space on large scales jennings et al 2018 as such its value was optimised alongside several others through our calibration approach incorporating atmospheric humidity data could have resulted in more reliable phase determination the magnitude of precipitation underestimation is likewise highly uncertain although solid precipitation measurements are usually more affected than liquid precipitation ones for this reason both snob and snoa were also calibrated whilst liqa and liqb were assigned fixed values 0 01 and 1 02 respectively as neither the error characteristics of solid nor liquid precipitation were known at individual stations and or for individual events more targeted corrections were not possible the second implication is that spatial interpolation algorithms must be carefully selected generally speaking given the pronounced and complex topography both spatial and elevation dependencies in the various meteorological variables should ideally be accounted for a 25 m resolution digital terrain model dtm swisstopo 2018 defined the model grid then an appropriate algorithm was applied to interpolate all available measurements of each variable at every time step to account for their strong elevational dependence air temperature wind speed relative humidity and vapour pressure measurements were interpolated using elevation dependent regression edr for air temperature the possibility of the linear relationships varying across elevation bands including full temperature inversions per time step was permitted for precipitation meanwhile a linear combination of fields generated independently by inverse distance weighting idw and edr was applied the ratio of the former to the latter idwedr was also calibrated in this way a certain balance between spatial patterns and spatially constant elevational dependence in the station measurements was achieved since incoming shortwave radiation and sunshine duration demonstrate more limited elevation dependence they were simply interpolated using idw whenever idw was applied the maximum search radius was set such that no stations were excluded this approach differs from that taken in certain other studies which applied either predefined or else calibrated constant linear temperature elevation gradients or elevation precipitation gradients for example brauchli et al 2017 distributed corrected single station precipitation measurements across their study catchment by applying a constant lapse rate of 2 100 m this and other studies e g naseer et al 2019 suggest that in complex terrain such constant lapse rates may be unrealistic avoiding the use of such constant gradients can therefore be considered a strength of the present approach as more of the spatial and temporal structure of the local meteorological measurements should be retained that said with such an approach the temporal coverage or cross over between the underlying station data shown in figures s3 to s9 becomes important this is because for a given meteorological variable and time step only stations returning observations contribute to the resultant spatial field in other words no temporal gap filling or interpolation is undertaken and each time step s field is independent from the last consequently uncertainty in the interpolated spatial fields is not constant in time but rather varies with both the number and locations of stations providing measurements finally the interpolated hourly temperature and radiation grids were corrected to account for topographic shading effects using the scheme of oke 1987 an empirical temperature factor involved radc was also calibrated the aforementioned steps were all undertaken using the distributed model wasim schulla 2017 3 2 satellite and in situ snow observations two complementary types of observed snow data were prepared to constrain the model i binary observed snow extent maps derived from landsat 8 imagery and ii swe time series at two station locations the former provides complete spatial coverage but only for temporal snapshots and moreover provides no direct information on snowpack water storage conversely the latter provide high frequency temporally continuous information on swe but only at discrete locations 17 landsat 8 scenes that fall within the period of meteorological data availability i e the hydrological years 2015 2018 and were cloud free over the study area were considired for each the normalised difference snow index ndsi dozier 1989 of every pixel was first calculated according to equation 2 2 ndsi l8 b 3 b 6 b 3 b 6 where b3 and b6 are bands 3 0 525 0 600 µm and 6 1 560 1 660 µm of a given landsat 8 l8 image respectively lakes were masked out because their reflectance signatures gave rise to ndsi value peaks that obscured the boundary between snow and snow free pixels in some image histograms snow extents were then delineated by applying a threshold to the nsdi maps an iterative process of threshold adjustment and visual comparison of the binary snow maps and the corresponding true colour composite tcc images was followed until a satisfactory final classification was reached fig 2 illustrates the main steps involved the final thresholds varied somewhat between images see härer et al 2018 for a dedicated exploration of ndsi threshold choice whilst the manual approach to threshold identification employed here was feasible for this fairly small image catalogue generating accurate snow maps for a larger catalogue would require a more automated procedure to facilitate their integration in the automated calibration process the maps were reprojected to the ch1903 system epsg 21781 and clipped to the study catchment using the nearest neighbour approach they were then downscaled from their native 30 m resolution to align with the 25 m resolution model grid the full catalogue of observed snow extents which encompasses practically the full range of possible snow cover conditions is shown in fig 3 fig s11 meanwhile provides comparisons of all tcc images and delineated observed snow extents alongside the corresponding final simulated outputs besides the more general issues of cloud cover and temporal gaps between satellite overpasses dark forest canopies and areas of shadow represent the main challenges associated with using mapping snow extents using ndsi in steep mountainous terrain wang et al 2015 in this case whilst a small number of snow covered pixels under dark forest and in heavily shaded snow covered terrain may have been misclassified as snow free the maps generally compare very well the tcc images moreover a sensitivity assessment of the classified snow extents to various plausible thresholds not shown found it to be small as such the maps can be taken to represent snow extents with a reasonably high degree of accuracy especially in the more open upper regions of the catchment where snow patterns are of most interest to provide more direct information on snow water storage to the model swe time series were reconstructed at two contrasting station locations swe reconstruction was also required to enable direct comparisons with the model outputs since the snow model configuration employed only provides total water storage rather than full information on the interrelation between snowpack density depth and swe different methods were used at each station according to data availability the two stations providing regular snow measurements over the period in question are located just outside the study catchment with each lying towards one extreme of its elevational range see fig 1 the data were again obtained from idaweb the higher station grand cor cor elevation 2602 m belongs to the slf s intercantonal measurement and information system imis slf 2019b these stations do not measure solid precipitation directly but instead record snow depth and several other variables that can be used to drive the 1d physically based multi layer model snowpack lehning et al 2002 an hourly time series swe evolution at cor over the entire four year simulation period was constructed in this fashion the second lower elevation station is located in gryon gry elevation 1146 m unlike at cor only manual daily snow height measurements are made here which prevented an application of snowpack the empirical model of jonas et al 2009 which was constructed using a large sample of snow observations from the swiss alps was therefore applied this approach facilitates the estimation of snow density as a function of geographic region month of the year and site elevation parameters corresponding to the elevation band 1400 m and the region 1 offset were taken see tables 1 and 2 of jonas et al 2009 these being applicable to gry the resultant densities were then multiplied by measured snow heights to give daily swe estimates due to this reconstruction work neither of the observed swe time series are actually direct measurements the simulation domain was extended slightly to allow these data to be used in the model calibration 4 numerical modelling and calibration 4 1 simulating snow accumulation redistribution and melt as for the previous steps wasim schulla 2017 formed the foundation of the snow modelling approach this decision was made following a review and testing of possible alternatives including alpine3d which although a strong contender did not enable gravitational snow redistribution to be accounted for although slightly more sophisticated snow models are available few fully distributed codes offer such a broad range of functionality as wasim snow accumulation gravitational redistribution and melt were calculated on the 25 m model grid on an hourly time step first the corrected precipitation phase per pixel and time step was estimated according to the interpolated air temperature and a transitional range within which both solid and precipitation can occur equation 3 3 s frac rstt t trans t a 2 t trans f o r r s t t t trans t a r s t t t trans where sfrac is the fraction of the totalprecipitation that is snow 0 1 ta is the air temperature c rstt c is the same rain snow threshold temperature applied in equation 1 and ttrans is half the rain snow transition temperature range c ttrans was fixed to 1 c i e the total transition range was 2 c whilst rstt took the same calibrated value as that applied to distinguish precipitation phase equation 1 snowmelt was then calculated by solving the surface energy balance for the energy available for melt following the approach of warscher et al 2013 in this scheme the snowpack is treated as a single homogeneous layer beneath the surface for which the energy balance is computed equation 4 4 q h e a g m ae 0 where q is the shortwave and longwave radiation balance h is the sensible heat flux e is the latent heat flux a is the advective energy supplied by solid or liquid precipitation g is the soil heat flux which is small compared to other fluxes and here was set equal to 2 and mae is the energy potentially available for melting during a given time step the units of all terms are w m 2 melting and non melting conditions were distinguished according to rstt when the energy balance is positive i e mae 0 and air temperature favourable melt m can occur see warscher et al 2013 for an explanation of the use of air temperature as a proxy to differentiate melting from non melting conditions finally m per time step dt is expressed in mm of water by introducing the latent heat of fusion ci equation 5 5 m m ae d t c i sublimation which can be an important component of alpine water balances strasser et al 2008 is explicitly accounted for in this approach two additional scaling parameters lwin and lwout were available to fine tune the incoming and outgoing longwave components of the energy balance respectively raleigh et al 2016 showed that behind temperature and precipitation longwave radiation estimates most strongly affect energy balance snow simulations results and moreover noted that longwave measurements are uncommon in high elevation terrain such considerations justify including parameters related to longwave radiation in the calibration here both parameters were subjected to calibration albeit within relatively narrow bounds see table 1 in this way potential errors in both surface albedo and cloudiness as determined from the interpolated sunshine duration fields used in the calculation of incoming longwave radiation could be accounted for in addition gravitational redistribution was simulated using a mass conservative algorithm that is underpinned by a topographic analysis this algorithm was implemented in wasim by warscher et al 2013 several steps are involved as with the previously summarised algorithms they are comprehensively described in warscher et al 2013 and schulla 2017 here only the main parameters are discussed two represent critical local slope limits mids is the lower inclination limit for gravitational slides to occur and mads is the upper inclination angle above which all incoming snow is immediately transported downslope because these slope angles are dependent on the model grid scale they cannot easily be transferred from previous studies and were therefore calibratated following the advice of schulla 2017 two further parameters related to gravitational redistribution were also calibrated the first is the fraction of the current snow storage in a cell that can form a slide in any given time step frss it is recommended that its value be set to some small fraction typically 1 although this depends somewhat on the time step at which the model is run the second scmd is an upper depositional mass limit mm for snow flows i e the maximum permitted transfer from one cell to another again per time step whilst such an approach can estimate plausible snow redistribution patterns it should be noted that the specific timing of avalanches cannot be predicted warscher et al 2013 warscher et al 2013 also proposed a simple algorithm designed to account for snow redistribution by wind more recently still methods seeking to improve wasim s representation of snow and coniferous forest canopy interactions have been published förster et al 2018 however for several reasons neither of these algorithm sets was included in our final model here firstly given the study area s steepness we decided to focus on gravitational redistribution secondly including wind algorithm actually resulted in poorer model observation fits see section 5 7 finally the wasim release containing the extensions of förster et al 2018 came too late in the course of our work to be evaluated thoroughly 4 2 multi objective calibration the 11 empirical parameters that required estimation are listed alongside the upper and lower bounds that were assigned to each based on prior knowledge in table 1 for numerical reasons all parameters were log transformed this step is recommended when using pest so that the linearity assumption of model outputs to varied parameters holds better and to normalize parameters with respect to their inherent variability to this end the lower bounds of three parameters which would ordinarily have been zero were marginally raised the final estimated values are also listed in table 1 to prevent later duplication being necessary a novel multi objective calibration approach that incorporated both the spatial snow extents and the reconstructed swe time series was then developed for each of the 17 days with an observed extent map and model iteration the spatial component of goodness of fit was quantified as follows 1 simulated swe maps at the end of the days for which observed maps were available were extracted and clipped to the study catchment 2 pixels in the simulated swe maps were reclassified to either snow or no snow using a 5 mm exceedance threshold i e pixels with swe 5 mm were classified as snow covered 3 all pixels were binned into one of the quadrants of the contingency matrix shown in table 2 according to whether snow presence absence had been correctly simulated with respect to the observed maps 4 three related performance metrics were calculated after aronica et al 2002 using equations 6 to 8 6 f 1 i 1 n a i 1 n d n 7 f 2 i 1 n a i 1 n a i 1 n b i 1 n c 8 f 3 i 1 n a i 1 n b i 1 n a i 1 n b i 1 n c where a b and c are the quadrants of the contingency matrix table 2 and n is the total number of pixels f 1 corresponds to the overall proportion of correctly simulated pixels f 2 and f 3 expressly discount pixels that are snow free in both simulations and observations and so typically result in lower scores on many days this quadrant can be heavily populated as snow free pixels at lower elevations are generally relatively easy to reproduce warscher et al 2013 in each case a perfect fit between simulations and observations would return a value of one therefore for each model iteration the squared residuals between the three f statistics obtained and one was calculated model performance with respect to the observed swe time series was quantified using the squared residuals between simulated and observed values per time step to construct a single multi objective function that could be minimised and thus produce the best overall fit according to both types of observations weights had to be assigned to each squared residual this subjective process aimed to ensure that each observation maintained a certain visibility in the calibration process whilst an appropriate balance between the two data types was achieved the hierarchical weighting scheme illustrated in fig s2 was ultimately implemented in summary a slightly higher weighting was applied to the spatial data than the time series 60 40 to reflect their more stringent nature f 2 and f 3 values were assigned double the weight of f 1 values finally to account for the disparity in measurement frequency at the snow stations hourly at cor but only daily at gry observations at the latter were assigned weights 24 times higher than those at the former the objective function of is expressed in equation 9 9 of i 1 17 wf 1 1 f 1 2 i 1 17 wf 2 1 f 2 2 i 1 17 wf 3 1 f 3 2 i 1 35063 w c o r cor s w e sim cor s w e obs 2 i 1 1461 w g r y gry s w e sim gry s w e obs 2 where wf 1 wf 2 wf 3 wcor and wgry are the relative weights that were assigned to each observation belonging to the different observation groups as illustrated in fig s2 i e 0 706 1 412 1 412 0 0057 and 0 01368 respectively f 1 f 2 and f 3 are the fit statistics calculated for each of the 17 pairs of images according to equations 6 to 8 and cor swesim and cor sweobs gry swesim and gry sweobs are the observed and simulated swe values at each time time step at the cor and gry stations respectively the wasim model was then linked with pest doherty 2019 a model independent gradient based parameter estimation tool which uses the levenberg marquardt algorithm pest repeatedly runs the model altering the calibration parameter values each iteration in an attempt to minimise the objective function in a least squares sense pest was selected primarily due to its efficiency which is considerably higher than that of commonly applied monte carlo oriented approaches indeed parameter search efficiency was crucial given the relatively high computational demands of the energy balance snow model the coupling was achieved by implementing routines to extract the spatial and temporal model outputs corresponding to the observations and then calculate the required statistics see the appendix a the final parameters values obtained are presented in table 1 note that another valid approach to assign weights and one that may have accounted better for their contrasting magnitudes would have been to run the model once and then automatically adjust the weights using pest s pwtadj1 utility such that each observation group gave an approximately equal contribution 4 3 predictive uncertainty and data worth analyses a linear analysis was then conducted to quantify the pre and post calibration uncertainty associated with selected individual predictions of interest the term predictions is not used here to allude to the future namely the swe at cor on 1 april in each of the simulated hydrological years 2015 2018 and the spatial f 1 metric for 22 may 2017 this strategy enables any reduction in uncertainty achieved through the calibration process to be evaluated 1 april swe at station locations is an indicator commonly employed by environmental managers in snowmelt dependent regions to predict water availability throughout the subsequent summer the spatial prediction was included because few if any previous studies have specifically considered uncertainty in snow pattern predictions analyses quantifying the contribution of individual parameters to pre and post calibration uncertainty variance as well as the information provided by the five observation groups the calibration process i e data worth were also undertaken to achieve these tasks tools from pest s genlinpred suite were applied for a through description see doherty 2010 2019 in contrast to the model calibration phase for these analyses identical weights were assigned to all non zero weighted observations zero weighed observations being the predictions of interest following the advice of doherty 2010 this weight was estimated by taking the number of non zero weighted observations here 36 570 calculating its square root and dividing the result by the calibrated model objective function 91 150 giving a value of 0 002098 4 4 estimating glacial melt liquid precipitation and potential evapotranspiration to generate comprehensive forcing data for subsequent distributed integrated hydrological simulations four additional datasets were also generated using the model liquid precipitation firn melt ice melt and et p firstly to account for liquid precipitation in addition to snowmelt snowcover outflow grids were written at each time step these represent the snowmelt as calculated by the snow model from snow covered pixels plus any liquid precipitation falling on snow free pixels as section 3 1 explained modest fixed corrections were applied to the raw liquid precipitation measurements to account for undercatch accordingly for snow free pixels the snowcover outflow values correspond to any corrected interpolated rainfall falling as the coverage of glaciers is small 3 glacial melt makes a much more modest contribution to annual catchment averaged meltwater input than snowmelt nevertheless glacial meltwater generation can be locally considerable in summer as such a dynamic glacier model employing a simple volume area scaling relationship with default parameter values see schulla 2017 that accounts for accumulation dynamics and ablation with radiation correction was applied in wasim the parameters of this model were not calibrated due to the overall dominance of snowmelt and a lack of glacial data the glacier des martinets for instance has not been actively monitored since 1975 scnat 2018 rather the intention was simply to ensure that ice melt was not entirely neglected for snow on the glaciers an identical approach to the main snow model was taken in this way distinct hourly 25 m resolution grids representing snowmelt firn melt and ice melt from glacierised areas were produced besides containing all the optimised snow related parameters the wasim control file in appendix a indicates the values of the fixed parameters that were applied to generate these additional datasets with only slight modification possibly related to the distinction between snow and bare glacier ice in the ndsi images the approach could be easily transferred to more glacierised catchments the glacier meltwater estimates had to be normalized according to the glacier covered fraction of each cell per time step which ranged from 0 to 1 having done this the off glacier snowcover outflow rasters were summed together with the corresponding normalised snowmelt on glacier firn melt and ice melt grids per time step to produce a single set of hourly all liquid water grids these calculations were carried out by executing batch gdal scripts gdal 2019 osgeo4w 2019 units were also converted for subsequent hydrological modelling finally the penman monteith method was used to estimate 25 m resolution hourly et p to achieve this classes in a land cover map developed from existing swisstopo datasets swisstopo 2019 fig s10 were attributed with appropriate physical parameters e g leaf area index lia fuhrer and jasper 2012 describe a dedicated application of wasim to this end apart from unit conversion for subsequent hydrological modelling no additional processing of the et p grids was required in possessing identical spatio temporal resolution and having been generated using predominantly physically based approaches all resultant datasets can be considered broadly commensurate with one another 5 results and discussion 5 1 estimated parameter values the parameter values estimated via inversion table 1 constitute an initial set of results two in particular are interesting to consider briefly firstly the high value of 1 45 taken by the wind speed independent snow correction constant snob which actually reached the permitted upper bound attests to the considerable underestimation bias generally contained within the winter station precipitation measurements recall here that this constant factor was combined with the wind speed dependent factor snoa which was estimated to be 0 0283 i e an increase of 2 83 per additional m s 1 of wind speed and the interpolated wind speed to determine effective precipitation secondly idwedr took its lowest permitted value i e improved fits were obtained when any elevational gradients present in the station data were enforced upon the interpolated precipitation fields this likely reflects substantial differences in cumulative precipitation between the lowest elevation stations and those at elevations that correspond more closely to the study catchment the estimated solid precipitation correction factor magnitude is broadly consistent with existing literature for instance sevruk 1985 suggested that precipitation in switzerland is underestimated by between 4 in summer at low elevations and approximately 40 at high altitudes in winter in a simulation of a 200 km2 region of switzerland bavera et al 2014 applied a fixed 30 factor to solid precipitation pan et al 2016 meanwhile found the sheltering effect of surrounding vegetation to be an important influence on the magnitude of any underestimation in northern canada with well sheltered sites requiring much less correction at open sites the bias corrections they applied increased annual precipitation by between 15 and 34 at windy sites with high snowfall proportions even larger corrections sometimes exceeding 50 were sometimes be necessary finally jimeno sáez et al 2020 found that very large undercatch uplift factors 78 for solid precipitation were required in a basin in the sierra nevada southern spain therefore the upper bounds of our solid precipitation correction factors could perhaps have been set more generously 5 2 correspondence with observations the spatial goodness of fit statistics i e f 1 f 2 and f 3 obtained following calibration are shown in table 3 the corresponding observed and simulated snow maps from which these statistics were calculated are shown in fig s11 the f statistics returned are generally high across the 17 days the average percentage of correctly simulated pixels is 85 as expected the scores decline progressively from f 1 to f 3 moreover the variability in the statistics between images was observed with the highest scores naturally being achieved on completely snow covered mid winter days the lowest f 1 value was for the 29 april 2017 when the model missed a late season snowstorm that briefly blanketed the catchment fig 4 shows the comparison between simulated and observed swe time series at the two measurement stations the dynamics of snowpack evolution are replicated adequately including the contrast between seasonal snowpack at the higher elevation station cor and the more intermittent pattern at the lower one gry the colder prevailing conditions at cor allow the results to be discussed explicitly in terms of the accumulation and ablation phases this simulated onset of accumulation closely matches the observations here as do changes in accumulation rate the timing and rate of ablation is likewise broadly consistent with the observations however there does seem to be a general tendency towards underestimation of accumulation totals a similar underestimation is evident in the first three years at gry across both stations observations from winter 2017 2018 are reproduced best perhaps due to increased local data availability in evaluating these results it must be highlighted that the key meteorological variables of precipitation at cor and both precipitation and temperature at gry were not actually measured at these locations but rather had to be spatially interpolated onto the corresponding model cells from station measurements elsewhere as such much of the remaining post calibration difference is likely to be associated with uncertainties in these interpolated fields in addition as explained earlier the observations themselves were reconstructed finally the observations were made at discrete locations whilst the simulated values correspond to the 25 m pixel within which each station was located hence should the terrain at the station locations not be entirely representative of its immediate surroundings this would represent another potential source of mismatch a shaded region corresponding to 20 around the observations that being roughly the maximum swe mismatch one could expect purely for this reason t jonas pers comm is shown to reflect this 5 3 comparison of simulated spatial statistics with previous studies in fig 5 the f statistics obtained are compared to those reported in previous studies that also employed these metrics to quantify the fit between distributed snow models and maps derived from landsat imagery three such studies are known each of which reported statistics for only a small number of days between one and three schöber et al 2010 presented f 1 values for two days but numerous catchments while bernhardt et al 2012 and warscher et al 2013 provided all three f statistics for their respective study catchments and selected days in contrast to the present study which also included mid winter and late summer days in the calibration catalogue the previously published statistics correspond to spring and early summer periods exclusively i e partially snow covered conditions as such to ensure the fairest possible comparisons only our statistics corresponding to this spring and early summer are included the underlying data are compiled in table s2 the f statistic distributions obtained seem to have a tendency to be slightly higher than those of previous studies even if the mean and median of f 1 are marginally lower than those calculated from the published values this tendency appears to be most pronounced for f 2 and f 3 in both cases the mean values obtained here are higher than their previously published counterparts importantly with the possible exception of schöber et al 2010 who may have used the spatial snow observations in an informal fashion to adjust certain model parameters ambiguity remains as this step was not fully explained the previous studies used the spatial data purely for model evaluation in contrast to the present study in which they formed calibration targets as such while perhaps slightly disappointing that the explicit calibration did not yield higher f 1 scores a real benefit of calibration can arguably be seen in the noticeably higher f 2 and f 3 scores these metrics were assigned enhanced weight in the calibration processes that said the small sample sizes must be borne in mind when making such interpretations an additional consideration is that our calibration was not informed solely by the observed snow extent maps but rather sought to achieve an acceptable balance between fits according to both the maps and swe time series improved spatial fits could probably have been achieved if the maps alone comprised the objective function but this may have come at the expense of reduced accuracy in simulated catchment wide snow water storage a much larger catalogue of published f statistics would be required to assess the statistical significance of these results i e whether the calibration approach proposed does lead to real improvements in the capacity of distributed snow models to reproduce high resolution observed extents nevertheless the comparisons presented confirm the overall appropriateness of the approach taken and perhaps even alludes to some added value finally given the variability in the f statistics obtained between days the larger number of days for which performance statistics were presented here which elucidate this is a strength of this study because previous studies considered fewer days it is unclear how consistent in time their generally good model performance might be 5 4 snowpack evolution and hydrological plausibility a key benefit of the model and indeed any distributed transient simulator is that it fills in the gaps in space and time between the available observations to visualise this animation s1 presents the simulated evolution of swe at a daily time step during winter 2017 2018 the redistribution of snow from steep slopes is particularly apparent with patterns being broadly consistent with both our local field experience during the period fig s1 and the avalanche activity that occurred in the region more generally bühler et al 2019 fig 6 illustrates the spatio temporal distribution of a all liquid water comprised of liquid precipitation snowmelt firn melt and ice melt and b et p over the last hydrological year of the simulation period aggregated on a monthly basis as expected very little simulated meltwater input occurs during the winter months when temperatures are generally below freezing conversely the highest meltwater volumes are generated during the spring melt especially the months of april may and june the elevation at which the majority of melt water is produced increases as the season progresses and the localised contribution of the glaciers during the summer months is also evident indeed extremely high values are generated locally from the glaciers especially in summer 2018 when heatwave conditions were experienced in our simulation the glaciers can exhibit strongly negative mass balance liquid precipitation during the summer and autumn months which can be highly concentrated in space and time is naturally smoothed out in these plots appearing as a fairly low and constant daily mean value in non glacierised areas that said fig s12 presents the same underlying data in an alternative fashion as hourly catchment averaged series indicating the dynamism of the system strong seasonality and elevational influences are apparent in the spatial patterns of et p with estimated values being widely low in winter but restricted to higher elevations in summer to further verify the hydrological plausibility of these results without recourse to a full hydrological model simulated snowcover outflow and observed discharge were compared for the vallon de nant sub catchment a concrete weir gauging station at the outlet of this sub catchment avançon weir fig 1 provides high frequency streamflow estimates from spring 2016 onwards from which hourly mean flows were calculated the empirical stage discharge relationship i e rating curve was developed by salt dilution gauging ceperley et al 2018 despite the regular cross section these data are somewhat uncertain especially at flow extremes at low flows this is due to shifting channel configurations immediately upstream of the weir in fig 7 a hourly catchment averaged snowcover outflow i e snowmelt from non glaciated areas plus any liquid precipitation is plotted against hourly observed catchment area normalised discharge measured at the avançon weir over spring 2018 april to june inclusive simply comparing the two cumulative totals gives an estimated runoff ratio of 0 61 over the three month period although this value is only tentative given uncertainties associated with precipitation the model and the observed discharge data at the diurnal timescale simulated snowmelt is associated with increasing observed streamflow which seems reasonable dependence remains present on slightly longer frequencies also for example the decrease in measured streamflow just before the start of may coincides with a marked reduction in simulated water inputs extending this plot to later summer not shown revealed that a certain proportion of the excess spring melt inputs arrive in the stream later reflecting the buffering capacity of relatively shallow groundwater storage in reality a proportion of meltwater will of course also be lost to actual evapotranspiration and perhaps also to deeper groundwater storage and or groundwater exportation across topographic divides fig 7 b meanwhile shows the relationship between these data aggregated to a daily time step as the lagged and strongly dampened observed streamflow response relative to the simulated melt inputs complicates hourly comparisons a clear relationship between the variables is apparent which can be approximated by a power law function illustrated by the estimated non linear least squares regression line a certain hysteresis is also present meaning that less meltwater is required to produce a given magnitude of flow response as the season progresses this is consistent with increasing groundwater storage saturation throughout the period in subsequent work the gridded estimates generated here have been combined with a specifically developed 3d model of bedrock geology thornton et al 2018 and other data to inform a sophisticated fully integrated surface subsurface hydrological model thornton et al under review the generally good simulated streamflow and groundwater level results presented therein further reinforce the hydrological plausibly of our snow simulations 5 5 predictive uncertainty and data worth analyses table 4 shows the estimated pre and post calibration uncertainty standard deviation of the selected predictions the calibration process substantially reduced the uncertainty associated with the predictions by a factor of approximately four fig 8 provides an indication of contribution of the different model parameters to the uncertainty variance both pre and post calibration for two of the five predictions in these plots the uncertainty variance contributions have been normalised with respect to the pre calibration uncertainty variance associated with the respective predictions fig 8 a which concerns the prediction of swe on 1 april 2016 reveals firstly that many parameters that either do not or hardly contribute to predictive uncertainty either before or after calibration i e the prediction is insensitive to these parameters a slight reduction in the contribution to uncertainty variance can however be observed for idwedr snob and snoa the presence of many parameters that do not contribute to either the pre or post calibration uncertainty in the swe prediction is to be expected this is because most of these parameters concern the model s gravitational redistribution component whereas the cor measurement station will have undoubtedly been sited strategically such that the measurements are generally unaffected by such processes another striking feature of this plot is the large reduction in the predictive uncertainty associated with the longwave correction parameters lwin and lwout that calibration induced the results for the three other 1 april swe predictions were similar and so are not presented in the interests of space for the prediction of spatial snow extent on the 22 may 2017 quantified according to the f 1 statistic fig 8 b practically all parameters make some discernible contribution to uncertainty variance both pre and post calibration interestingly as with the swe prediction a large reduction in the post calibration uncertainty associated with lwin is observed but the post calibration uncertainty associated with lwou in relation to this prediction is actually higher than the pre calibration value this counterintuitive situation can occasionally arise when a parameter to which the prediction is insensitive can only be made in conjunction with another parameter to which the prediction is indeed sensitive see doherty 2010 for further explanation in this instance it may be because these two parameters are not entirely independent of one another for all other parameters the uncertainty contribution post calibration is very similar to the pre calibration level suggesting a certain insensitivity of the simulated snow extents to varying these parameter values the robustness that the similarity between pre and post calibration parameter contributions to uncertainty in the spatial prediction indicates could in fact be particularly beneficial in applications where only spatial snow patterns as opposed to water volumes are of primary importance e g assessing the influence of snow patterns on vegetation fig 9 provides two alternative representations of the worth of the observations belonging to the five different groups in the calibration process fig 9 a shows the increase in post calibration predictive uncertainty variance associated with each of the five selected predictions again relative to pre calibration uncertainty variance that is incurred by omitting each observation group from the calibration dataset in turn removing either f 1 f 2 or f 3 has very little adverse effect on any of the predictions this may be explained by the fact that when one of these groups is omitted similar information is retained in other two groups the comparatively small number of observations in these groups coupled with the uniform weighing applied to all observations for the purposes of this analysis could also partially explain these results combining these observations into a single group and or adjusting the relative weights assigned could have suggested enhanced importance of these observations this plot furthermore reveals the notable contribution that both time series but most especially that at gry make to the prediction the prediction s uncertainty variance increases markedly if either of these observation groups is removed four of the five predictions under consideration correspond to the swe predicted at the high elevation cor station in light of this the analysis suggests perhaps surprisingly that removing the data at gry from the calibration dataset has a more detrimental effect than removing the other observations at cor itself the very location of the predictions fig 9 b provides an indication of the decrease in uncertainty variance accrued relative to the pre calibration uncertainty variance when each observation group comprises the sole member of the calibration dataset including any one of the observation groups f 1 f 2 or f 3 alone in the calibration datasets leads to only modest reductions in the pre calibration uncertainty variance associated with the predictions although this is not to say that they do not have a more pronounced effect in combination in contrast including either of cor or gry swe time series observations as the sole calibration dataset leads to similarly large reductions in the uncertainty associated with the prediction of swe at cor the uncertainty around the f 1 prediction on 22 may 2017 is also greatly reduced by including either of these groups as the sole calibration dataset although only by about half as much as the reduction seen for the 1 april swe predictions this result that even including only one of the time series as the sole calibration dataset substantially reduces the uncertainty in the spatial prediction indicates an important flow of information from the time series to the predicted spatial snow patterns and can probably be generalised to the other days on which simulated spatial patterns were compared with observations the apparent significance of the gry data that both analyses indicate is especially notable given that the number of observations at this site is substantially lower than at gry due to lower measurement frequency it could be that being straddled more frequently by the 0 c isotherm the swe time series at gry contains more important information about temperature and therefore temperature gradients and snow limits than the cor data which contains distinct accumulation and ablation phases are apparent more generally the notable contributions that the time series data seem to make demonstrates the importance of obtaining various complementary data types and employing them within multi objective approaches this result is consistent with the tuo et al 2018 for instance who also showed that swe data can be included to good effect in the hydrological model calibration in alpine catchments lastly because a consideration in this study was to generate the best possible inputs for subsequent hydrological modelling that also coincide in time with other measurements from the study region such as groundwater levels not shown no snow observations were specifically withheld for evaluation future research should certainly explore the influence of the chosen calibration period and or assess model s performance under different condition although the uncertainty analysis can be considered a partial replacement traditional split sample model evaluation should be undertaken whenever sufficiently long time series are available 5 6 potential sources of residual mismatch uncertainty in snow observations aside a large proportion of the residual spatio temporal mismatch between the simulations and observations can probably be attributed to the meteorological forcing data due to the combination of relatively low station density and variable but sometimes high data gap frequency figures s3 to s9 the interpolated spatial fields of meteorological variables used to drive the model are undoubtedly uncertain more specifically whilst the temporal coverage and therefore crossover of the meteorological data varies throughout the simulation period the parameters in the model are global this means that the rain snow threshold temperature rstt and solid precipitation correction factors snoa and snob for example remained constant in time and space hence when estimated though the calibration processes values producing best overall outcomes with respect to the observations were returned in reality however the error distribution associated with precipitation measurements likely varies per station and per event smith et al 2020 reported difficulties in finding undercatch correction factors that perform comparably well across multiple sites in other words it may be that in not permitting bespoke per station event corrections the model structure is insufficiently flexible to compensate fully for deficiencies in meteorological measurements during certain periods and or at certain locations in this sense improved fits could perhaps have been achieved by simply scaling relatively complete time series measured at an individual location s using linear elevation dependent relationships although such an approach would have been less satisfactorily during periods with high meteorological data availability since much of it would have essentially been discarded in addition the spatial dependencies in meteorological variables away from the station locations which the interpolation processes attempted to characterise probably also demonstrate some temporal non stationarity in reality e g spatial structures may differ depending on whether precipitation is frontal or convective 5 7 some remarks on wind redistribution spatially distributed drift solid precipitation correction factors have been applied to account for the influence of wind transport processes on snowpack heterogeneity e g hanzer et al 2016 marshall et al 2019 including based on lidar derived snow depth maps where available vögeli et al 2016 however as mentioned earlier after testing wasim s wind redistribution algorithm was not included in our final model because doing so led to poorer observation fits the algorithm in question computes a temporally invariant spatially distributed correction factor grid that acts as a multiplier to the interpolated precipitation fields such that precipitation falling on predominantly sheltered slopes and on the leeward side of ridges is augmented deposited whilst that falling on exposed slopes is reduced scoured to generate such a grid a single prevailing wind direction in fact a sector must be prescribed however an analysis of the relationship between high elevation winter wind speeds these conditions being those under which snow redistribution by wind is most relevant and directions revealed that no such single prevailing wind direction can be identified across the study area fig s13 strong winter winds can apparently originate from contrasting directions probably according to larger scale synoptic meteorology some influence of the complex local topography on wind patterns is also evident similar patterns could be expected in other mountainous regions furthermore the calculated wind redistribution factor range seemed somewhat high leading to both too much deposition and scouring depending upon pixel exposition with respect to the admittedly limited swe data another potential issue is that unlike the gravitational redistribution algorithm applied the wind redistribution approach does not conserve mass within a given area e g a catchment ultimately it may be that in mountainous regions where large scale meteorological phenomena interacting with extremely complex topography give rise to considerable spatio temporal variability in near surface wind fields such comparatively simple algorithms are unable to match highly resolved site specific snow observations thus the development of extended empirical approaches that could include directly measured high elevation wind directions and or are calibrated explicitly to observed redistribution magnitudes near ridges could form an appropriate intermediate objective until physics based wind induced snow transport can be simulated in a physically based fashion at high resolution across entire catchments in any case in this particular study area snow redistribution by wind is likely of secondary hydrological importance to that by gravity 5 8 ongoing debates regarding hydrological model calibration whilst it is increasingly clear that internal states should be verified at some stage in the calibration or evaluation of hydrological models the most appropriate approach for including snow data remains under debate on the one hand it has been argued that since the volumetric information contained within discharge measurements complements the internal spatial pattern information embedded in distributed snow observations finger et al 2011 these two observation types should be considered simultaneously e g finger et al 2011 2014 shrestha et al 2014 the argument runs that the discharge constraint can help ensure that in aggregate the total simulated system water volume is approximately correct which is important given uncertain precipitation measurements and gridded products whilst the snow pattern constraints help ensure that runoff is being generated in the right areas others however posit that calibration is best tackled more sequentially whereby snow simulations are initially optimised independently before one proceeds to simulate intermediate hydrological variables and ultimately discharge the principal argument in favour of this approach is that simultaneous calibration may enable error compensation ragettli pellicciotti 2012 magnusson et al 2015 that can be hidden or easily overlooked at least unless extremely careful evaluative work with respect to observed spatial patterns in undertaken which remains rare provided a given set of snow observations are sufficiently informative and it is hoped those employed here are despite being somewhat limited by practical considerations such as the risks associated with conducting regular winter snow surveys in such terrain then the latter approach which was taken here should automatically ensure that the total water volumes are reasonably accurate indeed both binary spatial and volumetric time series at contrasting sites were considered in the snow model calibration for this precise reason the hydrological plausibly assessment undertaken section 5 4 and subsequent work thornton et al under review provides reassurance that this is indeed the case splitting the calibration phases essentially reduced the potential for model parameters related to the surface or subsurface to compensate for poor snow simulations or vice versa and additionally enabled a more advanced fully integrated code to be applied for the simulation of the remaining hydrological processes thornton et al under review 6 conclusions this paper has presented and exemplified a novel computationally efficient approach for the calibration and uncertainty analysis of distributed snow models in steep rugged alpine terrain the physically based core of the model explicitly captures the spatio temporal variability in energy balance components which is largely responsible for heterogeneous snow patterns and therefore melt rates in such terrain substantial uncertainties related to biased solid precipitation measurements and other observational deficiencies were addressed using empirical correction factors gravitational redistribution can also substantially influence meltwater patterns in steep regions but cannot presently be represented on an entirely physical basis at catchment or larger scales a pragmatic empirical algorithm was therefore also included to represent this process reliably simulating the spatio temporal evolution of swe thus hinged upon the estimation of several parameters which was not trivial given the reasonable computational expense associated with the forward model a single parallelized simulation took several hours to this end a novel multi objective calibration stratergy that involved a gradient based algorithm and incorporated two complementary types of high resolution snow observations snow extent maps and swe time series was developed the study represents one of the first such occasions on which a distributed snow model has actually been calibrated rather than merely evaluated according to an objective function that is partially spatially explicit whereby mismatches are penalised at the pixel level this was achieved by quantifying model performance with respect to landsat derived observed snow maps using so called f statistics substantial corrections to measured winter precipitation totals were required to minimise model data mismatches following calibration spatio temporal snow dynamics could be satisfactorily reproduced with respect to the available observations and the spatial fit metrics obtained moreover compared favourably with the few equivalent statistics reported previously subsequent uncertainty and data worth analyses indicated that i the uncertainty variance of indicative predictions of snow states both spatial and volumetric were substantially reduced through calibration ii including two parameters that enable the longwave component of the surface energy balance to be adjusted and thus potential errors in cloudiness and albedo compensated for was especially beneficial and iii the swe time series at the lower elevation station gry was particularly informative despite the comparatively small number of observations at this site any snow observation uncertainties notwithstanding much of the residual mismatch between simulations and observations is likely associated with the meteorological forcing data both the raw measurements especially for precipitation and interpolated spatial fields as such efforts to better characterise and account for the uncertainties and biases in mountain meteorological measurements and interpolated downscaled gridded products should be prioritised the generic model data integration framework presented extends well beyond standard treatments of snow in hydrological modelling and could be easily applied in different settings in addition in our view the specific application of it presented here achieved an appropriate balance between model complexity and data availability nevertheless the implications of some potential limitations associated with the core of the model employed here could be investigated for instance fairly basic spatial interpolation schemes were used a single rather than multi layer snow model was employed and wind redistribution was not accounted for indeed acknowledging that even sophisticated multi physics snow models contain uncertain parameters that must be identified see also günther et al 2020 future work should explore the extent to which using even more sophisticated snow simulation approaches might further reduce both pre and post calibration predictive uncertainties specifically such work could involve testing more sophisticated interpolation algorithms e g that of liston and elder 2006 for wind deploying a more process rich and advanced snow code that includes at least three snow layers and or accounts for wind redistribution provided increased data availability and quality accompanies increased model complexity a further reduction in uncertainty should be realised although this remains to be tested however the outcomes of such experiments must be interpreted with respect to the magnitudes of irreducible uncertainties associated with both forcing and observed calibration data i e uncertainties that will persist under many circumstances in summary distributed meltwater datasets generated via calibration constrained simulations of snow dynamics demonstrate great potential to inform the next generation of comprehensive physically based spatially explicit hydrological simulations in complex alpine terrain such efforts are urgently needed to provide a sound basis for decision making under hydrological system change a range of other applications which also require spatio temporally comprehensive snow information could also benefit from such an approach employing model data integration frameworks such as that presented here more routinely perhaps eventually in conjunction with even more advanced snow codes where data availability makes it appropriate to do will lead to improved snow simulations but also greater appreciation of their currently somewhat overlooked outstanding uncertainties declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the work was conducted as part of the integralp project funded by the swiss national science foundation snf project cr23i2 162754 professor b schaefli and dr j schulla are thanked for useful discussions and answers to questions regarding the use of wasim respectively the two anonymous reviewers are thanked for their valuable feedback all model related datasets and code that can be shared are accessible at https dx doi org 10 17632 84ph9rpnhr 1 high resolution versions of all supplementary figures are also available at this location as is the animation the meteorological data obtained from meteoswiss and the terrain and land cover data obtained from swisstopo remain subject to restrictions therefore the processed model inputs relating to these aspects are not included requests for these datasets should be directed to the respective organisation third party executables are similarly excluded but are obtainable as follows wasim executables and documentation can be downloaded from http www wasim ch en products html whilst pest executables and documentation can be downloaded from http www pesthomepage org downloads php author contributions j m t conceived this project independently and conducted the vast majority of the work including obtaining and processing the meteorological satellite and gry swe time series data establishing the model designing and implementing the calibration approach preparing the figures and drafting the manuscript t b conducted the simulation using the snowpack model at the cor station and provided guidance regarding some of the meteorological data g m and p b provided advice and support at all stages and all authors participated in the finalisation of the manuscript appendix a supplementary data supplementary data to this article can be found online at https dx doi org 10 17632 84ph9rpnhr 1 appendix a supplementary data the following are the supplementary data to this article supplementary video 1 supplementary data 2 
4552,in mountainous terrain reliable snow simulations are crucial for many applications however except in highly instrumented research catchments meteorological data are usually limited and so the interpolated spatial fields used to force snow models are uncertain moreover certain potentially important processes cannot presently be simulated at catchment scales using entirely physical algorithms it is therefore often appropriate to introduce empirical parameters into otherwise physically based snow models many opportunities to incorporate snow observations into the parameter estimation process now exist but they remain to be fully exploited in this context a novel approach to the calibration of an energy balance based snow model that additionally accounts for gravitational redistribution is presented several important parameters were estimated using an efficient gradient based method with respect to two complementary observation types landsat 8 derived snow extent maps and reconstructed snow water equivalent swe time series when assessed on a per pixel basis observed patterns were ultimately reproduced with a mean accuracy of 85 spatial performance metrics compared favourably with those previously reported whilst the temporal evolution of swe at the stations was also satisfactorily captured subsequent uncertainty and data worth analyses revealed that i the propensity for model predictions to be erroneous was substantially reduced by calibration ii pre calibration uncertainty was largely associated with two parameters which modify the longwave component of the energy balance but this uncertainty was greatly diminished by calibration and iii a lower elevation swe series was particularly valuable despite containing comparatively few observations overall our work demonstrates that contemporary snow models observation technologies and inverse approaches can be combined to both constrain and quantify the uncertainty associated with simulations of alpine snow dynamics 1 introduction 1 1 the significance of mountainous water resources meltwater derived from seasonal snowpacks currently dominates annual groundwater recharge and cumulative streamflow of many mid elevation temperate mountainous catchments at higher elevations the progressive ablation of firn and glacier ice throughout summer periods represent major additional inputs of liquid water to the terrestrial hydrosphere globally these snow and ice derived meltwaters directly sustain millions of people pritchard 2019 and constitute an ecosystem service of enormous value sturm et al 2017 however hydrological regimes which have historically been heavily influenced by snow and ice are likely to be greatly affected by ongoing warming barnett et al 2005 viviroli et al 2011 with summer low flow magnitudes particularly vulnerable jenicek et al 2016 dierauer et al 2018 indeed a wealth of evidence attesting the widespread decline of glaciers and other hydrologically relevant components of the mountain cryosphere now exists klein et al 2016 huss et al 2017 beniston et al 2018 bolch et al 2012 bormann et al 2018 vuille et al 2018 and the resultant impacts on stream discharges are increasingly detectable casassa et al 2009 micheletti lane 2016 lane nienow 2019 predictions of the future quantity and timing of mountain runoff accordingly remain in high demand and the substantial body of literature in which hydrological models are applied to generate such predictions continues to grow e g fatichi et al 2015 huss hock 2018 rain on snow events convective thunderstorms and more sustained episodes of frontal rainfall also have high and potentially increasing importance alpine terrain including with respect to floods debris flows and landslide hazard papathoma köhle et al 2011 rössler et al 2014 leonarduzzi et al 2017 as such spatio temporal patterns of liquid precipitation must also be given due consideration the same applies to evapotransporative losses herrnegger et al 2012 mutzner et al 2015 cochand et al 2019 1 2 progress in incorporating spatial snow information although many widely used box type hydrological models can often consistently reproduce even independent discharge observations following calibration against measurements of this variable alone observed internal spatial dynamics including those pertaining to the snowpack may remain poorly captured duethmann et al 2014 shrestha et al 2014 this can be attributed to the considerable freedom that traditional calibration approaches afford as well as the fact that discharge measurements provide only indirect integrated information on internal system functioning assessing simulated patterns of model state variables against spatially distributed observations provides a more stringent test of model capabilities and so represents a means by which the internal consistency of hydrological models can be enhanced indeed ensuring that the spatio temporal dynamics of all potentially relevant hydrological processes can be acceptably reproduced i e that the right answers in terms of discharge are obtained for the right reasons kirchner 2006 is likely to lead to more reliable future predictions much progress has already been made in incorporating snow information into hydrological models for example finger et al 2011 used snow cover images alongside glacier mass balance and discharge measurements in a snow and ice dominated catchment in switzerland to identify the best performing distributed model parameters from a large randomly generated set duethmann et al 2014 also employed a monte carlo approach here in an attempt to quantify the relationship between the information content and the number of snow cover images included in the calibration of a model covering several mountainous catchments in central asia in comparing two alternative strategies for simulating hydrological processes the high elevation andes ragettli et al 2014 likewise considered snowcover data although purely for evaluative purposes more recently costa et al 2018 calibrated a simple snow model using distributed snow observations to investigate the mechanisms responsible for increases in suspended sediment concentrations that were observed in the upper rhône in the 1980s developments in snow remote sensing and modelling have also been made recently in the western united states thorough the airbourne snow observatory aso and nasa s snowex campaign behrangi et al 2018 mcgrath et al 2019 hedrick et al 2018 however these efforts are geographically and temporally limited and generally rely on observation technologies that are unavailable in other global mountain regions finally some studies have employed distributed snow images not as calibration or evaluation criteria but as model inputs berezowski et al 2015 wulf et al 2016 1 3 outstanding snow modelling challenges despite these advancements given the considerable spatio temporal variability and complexity that many of the factors and processes influencing snow dynamics in rugged terrain exhibit clark et al 2011 many of the simulation approaches that currently prevail in the hydrological literature may be somewhat limited in their ability to represent snow dynamics reliably especially in moderately large topographically complex and data limited headwater regions for instance despite the now widespread availability of relevant spatial data spatially lumped e g wagner et al 2017 or only partially distributed duethmann et al 2014 staudinger et al 2017 hydrological models remain common although such lumped models have their uses they cannot represent heterogeneity below the aggregation unit and so provide little information on spatial snow patterns this is unfortunate because spatial patterns of snowcover are imperative for winter tourism grünewald et al 2010 and predicting vegetation species distributions randin et al 2015 amongst other applications more specifically integrating distributed observations with lumped models is somewhat complicated one must resort to comparing spatially averaged snow covered areas scas ragettli et al 2014 or else somehow re impose spatial variability in the simulations parajka blöschl 2008 irrespective of their spatial discretisation most hydrological modelling studies that have incorporated distributed snow observations have relied on products from the moderate resolution imaging spectroradiometer modis clark et al 2006 duethmann et al 2014 ragettli et al 2014 engel et al 2017 costa et al 2018 however the 500 m pixel resolution at which binary snow or no snow and or snow covered fraction f sca data are provided rittger et al 2013 is simply too coarse for certain applications for instance both ragettli et al 2014 and hanzer et al 2016 report difficulties capturing the complex snow patterns that are commonly observed in rugged terrain such as small patches and snow free ridges using modis imagery such relatively fine scale processes can substantially influence the internal hydrological functioning of steep mountain catchments much higher resolution 30 m and long term global snow maps can be derived from landsat imagery but have been mostly applied for model corroboration evaluation rather than calibration but see schattan et al 2020 additionally with the notable exceptions of hanzer et al 2016 and wayand et al 2018 previous studies involved only a handful of images bernhardt et al 2012 warscher et al 2013 schöber et al 2010 empirical temperature and other index based methods for estimating snow and ice melt rates hock 2003 also remain standard ragettli pellicciotti 2012 addor et al 2014 etter et al 2017 despite their abilty to satisfactorily reproduce snow dynamics in complex alpine terrain being questionable warscher et al 2013 provided additional meteorological data are available more sophisticated distributed energy balance approaches both full physics multiple snow layer configurations as well as simplified alternatives have been recommended magnusson et al 2015 meeks et al 2017 one attraction of such models in steep complex terrain is that they explicitly represent most of the fluxes influencing melt including the often pronounced spatio temporal variability thereof e g the effects of slope aspect and topographic shading effects on incoming radiation another advantage is that they can simulate melt during critical events e g rain on snow events which are mainly driven by turbulent fluxes better than their simpler counterparts würzer et al 2017 finally energy balance models are more likely to perform reliably under forcing conditions that exceed the range of historical observations as is typical in climate change impact assessments mas et al 2018 the most sophisticated energy balance models e g alpine3d lehning et al 2006 include full physics multi layered snowpack representations and therefore theoretically provide the most comprehensive representation of the complex mass and energy exchange processes that affect mountain snowpacks however for the purposes of hydrological predictions they are coupled with highly simplified conceptual or bucket type representations of subsurface processes and flow routing gallice et al 2016 in geologically complex settings which many alpine regions inherently are such simplifications may be unsuitable moreover the simulation of wind and gravitational snow redistribution processes at catchment or larger scales using physical algorithms remains computationally prohibitive mott lehning 2010 musselman et al 2015 brauchli et al 2017 yet in very steep terrain in particular accounting for gravitational snow redistribution is paramount to produce hydrologically realistic simulations of the evolution of snow water equivalent swe and thus patterns of meltwater generation bernhardt et al 2012 kerr et al 2013 sommer et al 2015 in extremis failure to do so can lead to snow towers which are undesirable model artifacts freudiger et al 2017 gravitational redistribution is also often critical to glacier accumulation mott et al 2019 various pragmatic empirical correction methods and algorithms have been developed enable such processes to still be represented e g bernhardt et al 2012 vögeli et al 2016 marshall et al 2019 a persistent fundamental challenge associated with modelling mountain hydrological systems is that the meteorological inputs are often very poorly constrained due to wind induced gauge undercatch precipitation measurements at stations are typically underestimated pan et al 2016 kochendorfer et al 2017 this bias is most pronounced when the precipitation phase is solid and at higher wind speeds in addition even in comparatively well instrumented regions like the european alps meteorological station density decreases substantially with elevation pepin et al 2015 coupled with the high spatial variability that characterises mountain meteorology mott et al 2014 this means that even if the original ground measurements could be made perfectly subsequent interpolated spatial fields would still be highly uncertainty as such irrespective of its complexity snow model performance will always be intimately related to forcing data quality 1 4 inverse approaches and uncertainty quantification assessing the error characteristics of common instruments see e g the wmo spice project kochendorfer et al 2017 and systematically testing various spatial interpolation methods tobin et al 2011 have both been pursued to address the aforementioned deficiencies in forcing datasets inverse methods whereby distributed models and snow observations are combined to estimate the values of important but uncertain correction parameters are also beginning to be applied to this end for instance in a snow model analysis involving both modis and landsat derived snow observations for evaluation engel et al 2017 found modifying a snow correction factor to be necessary to compensate for biased winter precipitation measurement shrestha et al 2014 actually calibrated a distributed multi layer water and energy balance model web dhm s in order to minimise the cumulative error in snow cover pattern again according to modis and discharge simulations in so doing an elevation dependent snowfall correction factor was optimised a particular novelty of this study was that correspondence between simulated and observed patterns was expressed at the pixel level naseer et al 2019 applied the same code but avoided traditional linear elevation dependent lapse rates for meteorological data interpolation which may break down in complex terrain by integrating 3d temperature profiles derived from climate model reanalysis data the calibration undertaken had no spatial component however most recently ruelland 2020 sought to infer uncertain mountain precipitation and temperature gradients in the french alps via inversion using a very simple snow and hydrological model alongside discharge and modis snow cover data lastly uncertainty quantification should ideally form a central pillar of any environmental modelling exercise although some previous studies have directly assessed uncertainty in swe reconstructions franz et al 2010 he et al 2011 slater et al 2013 meeks et al 2017 this has largely been undertaken only at discrete station locations i e using non distributed models as one seeks to progress beyond this situation the efficiency of calibration and uncertainty quantification algorithms becomes a crucial consideration especially as the sophistication scale and resolution a given forward model increases despite ever increasing computational power brute force approaches involving thousands of monte carlo simulations can still quickly become impractical 1 5 the present study in this context and with the intention of improving the representation of meltwater dynamics in relatively data scarce and rugged mountain settings this study proposes a model independent framework for integrating high resolution snow observations in distributed snowpack simulations it is not our intention to focus here on the development of combinstion of improved physically based algorithms for representing the various complex individual processes and phenomena that can influence snow variability in alpine terrain but rather to present a novel means by which complementary snow data can be used to constrain a series of generally important but highly uncertain parameters within any distributed snow model the moderate complexity snow code selected for our exemplification of the framework aligns well with our expectation that in this specific setting as well as likely many others especially at larger spatial scales any uncertainties associated with internal snow model structures will often be overshadowed by those from other sources e g uncertainties in forcing data fields in our approach not only are the major uncertainties involved in a typical simulation chain explicitly acknowledged but they are overcome as far as is possible more specifically a fully distributed energy balance based snow model that additionally represents gravitational redistribution is initially established at high spatio temporal resolution 25 m hourly then an objective function incorporating both high resolution snow cover maps derived from satellite imagery and reconstructed swe time series at two locations is developed and minimised using an efficient iterative calibration algorithm a single layer snowpack configuration is applied in wasim v10 04 01 schulla 2017 this code provides an appropriate balance between snow model simplicity and complexity and also enabled several additional steps to be incorporated relatively easily namely i the correction and spatial interpolation of meteorological station data ii the representation of gravitational snow redistribution which is important given the steepness of the study catchment in questions iii the representation of glacier mass balance melt and iv the generation of commensurate potential evapotranspiration et p estimates for subsequent hydrological modelling this is one of the first instances in which landsat derived snow cover images are included in the calibration of a distributed snow model in a spatially explicit i e per pixel fashion other distinguishing features of this study are that spatial fit metrics are computed for a much larger catalogue of images than previously and that the uncertainties associated with selected key predictions as well as the contributions of different parameters and groups of observations to uncertainty reduction are elucidated by including high resolution distributed snow observations swe time series and a model that accounts for gravitational redistribution this approach builds somewhat upon that of shrestha et al 2014 providing a framework that is more suited to steep and rugged terrain finally given the open source software used throughout and the long temporal coverage and global availability of the landsat archive our approach has great potential to improve the representation of snow dynamics in many mountain regions globally the input files and model data linking code are provided with the intention of helping to facilitate this furthermore because the methodology is fundamentally code and data agnostic alternative distributed codes and snowcover products can easily be substituted the model is not extended here to generate streamflow outputs this decision was taken because the study catchment under consideration is extremely geologically complex replete with folded faulted sequences of limestones shales and marls whilst the representation of subsurface processes in wasim as in most popular hydrological models is rather simplistic instead the resultant high resolution spatio temporal gridded datasets representing the arrival of snowmelt firn melt ice melt and liquid precipitation at the land surface collectively all liquid water and et p have been applied as boundary conditions for a fully integrated i e surface subsurface evapotranspiration model presented separately thornton et al under review such integrated models can ingest 3d representations of geology and simulate the mechanistic interactions between various components of hydrological systems in a physically based spatially explicit fashion as such they offer considerable potential to better understand and predict the nuances of such systems including their possible responses to external change in a more comprehensive and robust fashion than hitherto possible however most integrated models also rely on simplified empirical snow processes representations hence our broader effort seeks to leverage the respective benefits of alternative simulation approaches whilst mitigating their respective limitations 2 study area the 36 7 km2 study area includes two adjacent headwater catchments the vallon de nant and the vallon de la vare of the western swiss alps fig 1 the elevational range is considerable extending from 950 to over 3050 m a s l and slopes are accordingly extremely steep mean 35 the topography is rugged and lower parts of the study area are forested at the last glacial maximum only the highest peaks protruded above the ice bini et al 2009 an array of quaternary unconsolidated sedimentary features with glacial fluvial and mass movement origins overly the complex mesozoic bedrock several of which likely act as aquifers approximately 45 of annual precipitation 1400 mm falls as snow due to the catchment s steepness gravitational snow redistribution occurs frequently as evidenced by snow free slopes and cliffs in the winter months the photographs of fig s1 taken in the vallon de nant on the 31 january 2018 following a period of exceptional snowfall bründl et al 2019 illustrate the considerable redistribution that can occur under more extreme conditions intense summer thunderstorms are a further noteworthy feature of the area s meteorological regime the surficial hydrology of the vallon de nant is characterised by numerous temporary torrents whose discharge responds rapidly to rainfall and snowmelt being shaded by surrounding cliffs several small glaciers persist at relatively low elevations in the north facing upper reaches of both sub catchments the region remains in a highly natural state making it rather unusual in the context of the european alps reflecting this several recent environmental investigations have focused upon the area including those of vittoz et al 2009 grand et al 2016 lane et al 2016 benoit et al 2018 and giaccone et al 2019 3 data availability and processing 3 1 meteorological forcing the model required gridded estimates of incoming shortwave radiation precipitation relative humidity sunshine duration air temperature vapour pressure and wind speed no third party meteorological datasets with the desired spatio temporal resolution and which were contemporaneous with the available field measurements the earliest of which began in 2016 existed at the outset forcing datasets were therefore developed from meteorological station measurements fig 1 table s1 most of the stations used belonged to the official networks of meteoswiss and the wsl institute for snow and avalanche research slf and were located several kilometres from the study catchment and crucially at lower elevations at these stations hourly sums for precipitation and hourly means for all other variables were downloaded from idaweb the online data portal of meteoswiss meteoswiss 2019 for the hydrological years 2015 2018 i e 1 october 2014 to 30 september 2018 these data were complemented by observations from stations belonging to a local network operated by the university of lausanne s hiscox pers comm michelon et al 2017 and subsequent updates via personal communication some of which are located within the study catchment itself unsurprisingly given the harsh environment and limited access especially in winter the local stations had a higher proportion of missing data than the nationally operated ones meaning intensive processing and quality assurance efforts were required irrespective of the station operator precipitation data from unheated gauges were not considered also the precipitation data at sor were eventually removed from the input dataset as the cululative totals were deemed unrepresentative specifically they were unduly low compared with nearby stations at similar elevations brauchli et al 2018 the processed time series were plotted and inspected interactively using nivis slf 2019a the hourly time series themselves are presented in fig s14 whilst the temporal coverage of variables between stations and overall missing data percentages are shown in figures s3 to s9 the simulation period was limited to the four hydrological years 2015 2018 by lack of reliable local meteorological data prior to this although relatively short the simulation period contains a reasonable diversity of snow conditions including relatively snow rich and snow poor winters the challenge of obtaining accurate spatial fields of meteorological variables in mountainous regions hastwo direct implications for modelling the first is that precipitation measurements made using traditional instruments must be corrected for wind induced undercatch and any other factors that induce systematic bias towards underestimation here different corrections were applied depending on the incident precipitation phase equation 1 schulla 2017 1 p corr p s n o a w s s n o b t a r s t t p corr p l i q a w s l i q b t a r s t t where p is station measured precipitation mm pcorr is corrected precipitation mm snoa and snob are global correction factors for solid precipitation liqa and liqb are global correction factors for solid precipitation ws is wind speed m s 1 and rstt is the rain snow threshold temperature c the rain snow threshold temperature here denoted by rstt cannot be reliably determined a priori because it varies in time and space on large scales jennings et al 2018 as such its value was optimised alongside several others through our calibration approach incorporating atmospheric humidity data could have resulted in more reliable phase determination the magnitude of precipitation underestimation is likewise highly uncertain although solid precipitation measurements are usually more affected than liquid precipitation ones for this reason both snob and snoa were also calibrated whilst liqa and liqb were assigned fixed values 0 01 and 1 02 respectively as neither the error characteristics of solid nor liquid precipitation were known at individual stations and or for individual events more targeted corrections were not possible the second implication is that spatial interpolation algorithms must be carefully selected generally speaking given the pronounced and complex topography both spatial and elevation dependencies in the various meteorological variables should ideally be accounted for a 25 m resolution digital terrain model dtm swisstopo 2018 defined the model grid then an appropriate algorithm was applied to interpolate all available measurements of each variable at every time step to account for their strong elevational dependence air temperature wind speed relative humidity and vapour pressure measurements were interpolated using elevation dependent regression edr for air temperature the possibility of the linear relationships varying across elevation bands including full temperature inversions per time step was permitted for precipitation meanwhile a linear combination of fields generated independently by inverse distance weighting idw and edr was applied the ratio of the former to the latter idwedr was also calibrated in this way a certain balance between spatial patterns and spatially constant elevational dependence in the station measurements was achieved since incoming shortwave radiation and sunshine duration demonstrate more limited elevation dependence they were simply interpolated using idw whenever idw was applied the maximum search radius was set such that no stations were excluded this approach differs from that taken in certain other studies which applied either predefined or else calibrated constant linear temperature elevation gradients or elevation precipitation gradients for example brauchli et al 2017 distributed corrected single station precipitation measurements across their study catchment by applying a constant lapse rate of 2 100 m this and other studies e g naseer et al 2019 suggest that in complex terrain such constant lapse rates may be unrealistic avoiding the use of such constant gradients can therefore be considered a strength of the present approach as more of the spatial and temporal structure of the local meteorological measurements should be retained that said with such an approach the temporal coverage or cross over between the underlying station data shown in figures s3 to s9 becomes important this is because for a given meteorological variable and time step only stations returning observations contribute to the resultant spatial field in other words no temporal gap filling or interpolation is undertaken and each time step s field is independent from the last consequently uncertainty in the interpolated spatial fields is not constant in time but rather varies with both the number and locations of stations providing measurements finally the interpolated hourly temperature and radiation grids were corrected to account for topographic shading effects using the scheme of oke 1987 an empirical temperature factor involved radc was also calibrated the aforementioned steps were all undertaken using the distributed model wasim schulla 2017 3 2 satellite and in situ snow observations two complementary types of observed snow data were prepared to constrain the model i binary observed snow extent maps derived from landsat 8 imagery and ii swe time series at two station locations the former provides complete spatial coverage but only for temporal snapshots and moreover provides no direct information on snowpack water storage conversely the latter provide high frequency temporally continuous information on swe but only at discrete locations 17 landsat 8 scenes that fall within the period of meteorological data availability i e the hydrological years 2015 2018 and were cloud free over the study area were considired for each the normalised difference snow index ndsi dozier 1989 of every pixel was first calculated according to equation 2 2 ndsi l8 b 3 b 6 b 3 b 6 where b3 and b6 are bands 3 0 525 0 600 µm and 6 1 560 1 660 µm of a given landsat 8 l8 image respectively lakes were masked out because their reflectance signatures gave rise to ndsi value peaks that obscured the boundary between snow and snow free pixels in some image histograms snow extents were then delineated by applying a threshold to the nsdi maps an iterative process of threshold adjustment and visual comparison of the binary snow maps and the corresponding true colour composite tcc images was followed until a satisfactory final classification was reached fig 2 illustrates the main steps involved the final thresholds varied somewhat between images see härer et al 2018 for a dedicated exploration of ndsi threshold choice whilst the manual approach to threshold identification employed here was feasible for this fairly small image catalogue generating accurate snow maps for a larger catalogue would require a more automated procedure to facilitate their integration in the automated calibration process the maps were reprojected to the ch1903 system epsg 21781 and clipped to the study catchment using the nearest neighbour approach they were then downscaled from their native 30 m resolution to align with the 25 m resolution model grid the full catalogue of observed snow extents which encompasses practically the full range of possible snow cover conditions is shown in fig 3 fig s11 meanwhile provides comparisons of all tcc images and delineated observed snow extents alongside the corresponding final simulated outputs besides the more general issues of cloud cover and temporal gaps between satellite overpasses dark forest canopies and areas of shadow represent the main challenges associated with using mapping snow extents using ndsi in steep mountainous terrain wang et al 2015 in this case whilst a small number of snow covered pixels under dark forest and in heavily shaded snow covered terrain may have been misclassified as snow free the maps generally compare very well the tcc images moreover a sensitivity assessment of the classified snow extents to various plausible thresholds not shown found it to be small as such the maps can be taken to represent snow extents with a reasonably high degree of accuracy especially in the more open upper regions of the catchment where snow patterns are of most interest to provide more direct information on snow water storage to the model swe time series were reconstructed at two contrasting station locations swe reconstruction was also required to enable direct comparisons with the model outputs since the snow model configuration employed only provides total water storage rather than full information on the interrelation between snowpack density depth and swe different methods were used at each station according to data availability the two stations providing regular snow measurements over the period in question are located just outside the study catchment with each lying towards one extreme of its elevational range see fig 1 the data were again obtained from idaweb the higher station grand cor cor elevation 2602 m belongs to the slf s intercantonal measurement and information system imis slf 2019b these stations do not measure solid precipitation directly but instead record snow depth and several other variables that can be used to drive the 1d physically based multi layer model snowpack lehning et al 2002 an hourly time series swe evolution at cor over the entire four year simulation period was constructed in this fashion the second lower elevation station is located in gryon gry elevation 1146 m unlike at cor only manual daily snow height measurements are made here which prevented an application of snowpack the empirical model of jonas et al 2009 which was constructed using a large sample of snow observations from the swiss alps was therefore applied this approach facilitates the estimation of snow density as a function of geographic region month of the year and site elevation parameters corresponding to the elevation band 1400 m and the region 1 offset were taken see tables 1 and 2 of jonas et al 2009 these being applicable to gry the resultant densities were then multiplied by measured snow heights to give daily swe estimates due to this reconstruction work neither of the observed swe time series are actually direct measurements the simulation domain was extended slightly to allow these data to be used in the model calibration 4 numerical modelling and calibration 4 1 simulating snow accumulation redistribution and melt as for the previous steps wasim schulla 2017 formed the foundation of the snow modelling approach this decision was made following a review and testing of possible alternatives including alpine3d which although a strong contender did not enable gravitational snow redistribution to be accounted for although slightly more sophisticated snow models are available few fully distributed codes offer such a broad range of functionality as wasim snow accumulation gravitational redistribution and melt were calculated on the 25 m model grid on an hourly time step first the corrected precipitation phase per pixel and time step was estimated according to the interpolated air temperature and a transitional range within which both solid and precipitation can occur equation 3 3 s frac rstt t trans t a 2 t trans f o r r s t t t trans t a r s t t t trans where sfrac is the fraction of the totalprecipitation that is snow 0 1 ta is the air temperature c rstt c is the same rain snow threshold temperature applied in equation 1 and ttrans is half the rain snow transition temperature range c ttrans was fixed to 1 c i e the total transition range was 2 c whilst rstt took the same calibrated value as that applied to distinguish precipitation phase equation 1 snowmelt was then calculated by solving the surface energy balance for the energy available for melt following the approach of warscher et al 2013 in this scheme the snowpack is treated as a single homogeneous layer beneath the surface for which the energy balance is computed equation 4 4 q h e a g m ae 0 where q is the shortwave and longwave radiation balance h is the sensible heat flux e is the latent heat flux a is the advective energy supplied by solid or liquid precipitation g is the soil heat flux which is small compared to other fluxes and here was set equal to 2 and mae is the energy potentially available for melting during a given time step the units of all terms are w m 2 melting and non melting conditions were distinguished according to rstt when the energy balance is positive i e mae 0 and air temperature favourable melt m can occur see warscher et al 2013 for an explanation of the use of air temperature as a proxy to differentiate melting from non melting conditions finally m per time step dt is expressed in mm of water by introducing the latent heat of fusion ci equation 5 5 m m ae d t c i sublimation which can be an important component of alpine water balances strasser et al 2008 is explicitly accounted for in this approach two additional scaling parameters lwin and lwout were available to fine tune the incoming and outgoing longwave components of the energy balance respectively raleigh et al 2016 showed that behind temperature and precipitation longwave radiation estimates most strongly affect energy balance snow simulations results and moreover noted that longwave measurements are uncommon in high elevation terrain such considerations justify including parameters related to longwave radiation in the calibration here both parameters were subjected to calibration albeit within relatively narrow bounds see table 1 in this way potential errors in both surface albedo and cloudiness as determined from the interpolated sunshine duration fields used in the calculation of incoming longwave radiation could be accounted for in addition gravitational redistribution was simulated using a mass conservative algorithm that is underpinned by a topographic analysis this algorithm was implemented in wasim by warscher et al 2013 several steps are involved as with the previously summarised algorithms they are comprehensively described in warscher et al 2013 and schulla 2017 here only the main parameters are discussed two represent critical local slope limits mids is the lower inclination limit for gravitational slides to occur and mads is the upper inclination angle above which all incoming snow is immediately transported downslope because these slope angles are dependent on the model grid scale they cannot easily be transferred from previous studies and were therefore calibratated following the advice of schulla 2017 two further parameters related to gravitational redistribution were also calibrated the first is the fraction of the current snow storage in a cell that can form a slide in any given time step frss it is recommended that its value be set to some small fraction typically 1 although this depends somewhat on the time step at which the model is run the second scmd is an upper depositional mass limit mm for snow flows i e the maximum permitted transfer from one cell to another again per time step whilst such an approach can estimate plausible snow redistribution patterns it should be noted that the specific timing of avalanches cannot be predicted warscher et al 2013 warscher et al 2013 also proposed a simple algorithm designed to account for snow redistribution by wind more recently still methods seeking to improve wasim s representation of snow and coniferous forest canopy interactions have been published förster et al 2018 however for several reasons neither of these algorithm sets was included in our final model here firstly given the study area s steepness we decided to focus on gravitational redistribution secondly including wind algorithm actually resulted in poorer model observation fits see section 5 7 finally the wasim release containing the extensions of förster et al 2018 came too late in the course of our work to be evaluated thoroughly 4 2 multi objective calibration the 11 empirical parameters that required estimation are listed alongside the upper and lower bounds that were assigned to each based on prior knowledge in table 1 for numerical reasons all parameters were log transformed this step is recommended when using pest so that the linearity assumption of model outputs to varied parameters holds better and to normalize parameters with respect to their inherent variability to this end the lower bounds of three parameters which would ordinarily have been zero were marginally raised the final estimated values are also listed in table 1 to prevent later duplication being necessary a novel multi objective calibration approach that incorporated both the spatial snow extents and the reconstructed swe time series was then developed for each of the 17 days with an observed extent map and model iteration the spatial component of goodness of fit was quantified as follows 1 simulated swe maps at the end of the days for which observed maps were available were extracted and clipped to the study catchment 2 pixels in the simulated swe maps were reclassified to either snow or no snow using a 5 mm exceedance threshold i e pixels with swe 5 mm were classified as snow covered 3 all pixels were binned into one of the quadrants of the contingency matrix shown in table 2 according to whether snow presence absence had been correctly simulated with respect to the observed maps 4 three related performance metrics were calculated after aronica et al 2002 using equations 6 to 8 6 f 1 i 1 n a i 1 n d n 7 f 2 i 1 n a i 1 n a i 1 n b i 1 n c 8 f 3 i 1 n a i 1 n b i 1 n a i 1 n b i 1 n c where a b and c are the quadrants of the contingency matrix table 2 and n is the total number of pixels f 1 corresponds to the overall proportion of correctly simulated pixels f 2 and f 3 expressly discount pixels that are snow free in both simulations and observations and so typically result in lower scores on many days this quadrant can be heavily populated as snow free pixels at lower elevations are generally relatively easy to reproduce warscher et al 2013 in each case a perfect fit between simulations and observations would return a value of one therefore for each model iteration the squared residuals between the three f statistics obtained and one was calculated model performance with respect to the observed swe time series was quantified using the squared residuals between simulated and observed values per time step to construct a single multi objective function that could be minimised and thus produce the best overall fit according to both types of observations weights had to be assigned to each squared residual this subjective process aimed to ensure that each observation maintained a certain visibility in the calibration process whilst an appropriate balance between the two data types was achieved the hierarchical weighting scheme illustrated in fig s2 was ultimately implemented in summary a slightly higher weighting was applied to the spatial data than the time series 60 40 to reflect their more stringent nature f 2 and f 3 values were assigned double the weight of f 1 values finally to account for the disparity in measurement frequency at the snow stations hourly at cor but only daily at gry observations at the latter were assigned weights 24 times higher than those at the former the objective function of is expressed in equation 9 9 of i 1 17 wf 1 1 f 1 2 i 1 17 wf 2 1 f 2 2 i 1 17 wf 3 1 f 3 2 i 1 35063 w c o r cor s w e sim cor s w e obs 2 i 1 1461 w g r y gry s w e sim gry s w e obs 2 where wf 1 wf 2 wf 3 wcor and wgry are the relative weights that were assigned to each observation belonging to the different observation groups as illustrated in fig s2 i e 0 706 1 412 1 412 0 0057 and 0 01368 respectively f 1 f 2 and f 3 are the fit statistics calculated for each of the 17 pairs of images according to equations 6 to 8 and cor swesim and cor sweobs gry swesim and gry sweobs are the observed and simulated swe values at each time time step at the cor and gry stations respectively the wasim model was then linked with pest doherty 2019 a model independent gradient based parameter estimation tool which uses the levenberg marquardt algorithm pest repeatedly runs the model altering the calibration parameter values each iteration in an attempt to minimise the objective function in a least squares sense pest was selected primarily due to its efficiency which is considerably higher than that of commonly applied monte carlo oriented approaches indeed parameter search efficiency was crucial given the relatively high computational demands of the energy balance snow model the coupling was achieved by implementing routines to extract the spatial and temporal model outputs corresponding to the observations and then calculate the required statistics see the appendix a the final parameters values obtained are presented in table 1 note that another valid approach to assign weights and one that may have accounted better for their contrasting magnitudes would have been to run the model once and then automatically adjust the weights using pest s pwtadj1 utility such that each observation group gave an approximately equal contribution 4 3 predictive uncertainty and data worth analyses a linear analysis was then conducted to quantify the pre and post calibration uncertainty associated with selected individual predictions of interest the term predictions is not used here to allude to the future namely the swe at cor on 1 april in each of the simulated hydrological years 2015 2018 and the spatial f 1 metric for 22 may 2017 this strategy enables any reduction in uncertainty achieved through the calibration process to be evaluated 1 april swe at station locations is an indicator commonly employed by environmental managers in snowmelt dependent regions to predict water availability throughout the subsequent summer the spatial prediction was included because few if any previous studies have specifically considered uncertainty in snow pattern predictions analyses quantifying the contribution of individual parameters to pre and post calibration uncertainty variance as well as the information provided by the five observation groups the calibration process i e data worth were also undertaken to achieve these tasks tools from pest s genlinpred suite were applied for a through description see doherty 2010 2019 in contrast to the model calibration phase for these analyses identical weights were assigned to all non zero weighted observations zero weighed observations being the predictions of interest following the advice of doherty 2010 this weight was estimated by taking the number of non zero weighted observations here 36 570 calculating its square root and dividing the result by the calibrated model objective function 91 150 giving a value of 0 002098 4 4 estimating glacial melt liquid precipitation and potential evapotranspiration to generate comprehensive forcing data for subsequent distributed integrated hydrological simulations four additional datasets were also generated using the model liquid precipitation firn melt ice melt and et p firstly to account for liquid precipitation in addition to snowmelt snowcover outflow grids were written at each time step these represent the snowmelt as calculated by the snow model from snow covered pixels plus any liquid precipitation falling on snow free pixels as section 3 1 explained modest fixed corrections were applied to the raw liquid precipitation measurements to account for undercatch accordingly for snow free pixels the snowcover outflow values correspond to any corrected interpolated rainfall falling as the coverage of glaciers is small 3 glacial melt makes a much more modest contribution to annual catchment averaged meltwater input than snowmelt nevertheless glacial meltwater generation can be locally considerable in summer as such a dynamic glacier model employing a simple volume area scaling relationship with default parameter values see schulla 2017 that accounts for accumulation dynamics and ablation with radiation correction was applied in wasim the parameters of this model were not calibrated due to the overall dominance of snowmelt and a lack of glacial data the glacier des martinets for instance has not been actively monitored since 1975 scnat 2018 rather the intention was simply to ensure that ice melt was not entirely neglected for snow on the glaciers an identical approach to the main snow model was taken in this way distinct hourly 25 m resolution grids representing snowmelt firn melt and ice melt from glacierised areas were produced besides containing all the optimised snow related parameters the wasim control file in appendix a indicates the values of the fixed parameters that were applied to generate these additional datasets with only slight modification possibly related to the distinction between snow and bare glacier ice in the ndsi images the approach could be easily transferred to more glacierised catchments the glacier meltwater estimates had to be normalized according to the glacier covered fraction of each cell per time step which ranged from 0 to 1 having done this the off glacier snowcover outflow rasters were summed together with the corresponding normalised snowmelt on glacier firn melt and ice melt grids per time step to produce a single set of hourly all liquid water grids these calculations were carried out by executing batch gdal scripts gdal 2019 osgeo4w 2019 units were also converted for subsequent hydrological modelling finally the penman monteith method was used to estimate 25 m resolution hourly et p to achieve this classes in a land cover map developed from existing swisstopo datasets swisstopo 2019 fig s10 were attributed with appropriate physical parameters e g leaf area index lia fuhrer and jasper 2012 describe a dedicated application of wasim to this end apart from unit conversion for subsequent hydrological modelling no additional processing of the et p grids was required in possessing identical spatio temporal resolution and having been generated using predominantly physically based approaches all resultant datasets can be considered broadly commensurate with one another 5 results and discussion 5 1 estimated parameter values the parameter values estimated via inversion table 1 constitute an initial set of results two in particular are interesting to consider briefly firstly the high value of 1 45 taken by the wind speed independent snow correction constant snob which actually reached the permitted upper bound attests to the considerable underestimation bias generally contained within the winter station precipitation measurements recall here that this constant factor was combined with the wind speed dependent factor snoa which was estimated to be 0 0283 i e an increase of 2 83 per additional m s 1 of wind speed and the interpolated wind speed to determine effective precipitation secondly idwedr took its lowest permitted value i e improved fits were obtained when any elevational gradients present in the station data were enforced upon the interpolated precipitation fields this likely reflects substantial differences in cumulative precipitation between the lowest elevation stations and those at elevations that correspond more closely to the study catchment the estimated solid precipitation correction factor magnitude is broadly consistent with existing literature for instance sevruk 1985 suggested that precipitation in switzerland is underestimated by between 4 in summer at low elevations and approximately 40 at high altitudes in winter in a simulation of a 200 km2 region of switzerland bavera et al 2014 applied a fixed 30 factor to solid precipitation pan et al 2016 meanwhile found the sheltering effect of surrounding vegetation to be an important influence on the magnitude of any underestimation in northern canada with well sheltered sites requiring much less correction at open sites the bias corrections they applied increased annual precipitation by between 15 and 34 at windy sites with high snowfall proportions even larger corrections sometimes exceeding 50 were sometimes be necessary finally jimeno sáez et al 2020 found that very large undercatch uplift factors 78 for solid precipitation were required in a basin in the sierra nevada southern spain therefore the upper bounds of our solid precipitation correction factors could perhaps have been set more generously 5 2 correspondence with observations the spatial goodness of fit statistics i e f 1 f 2 and f 3 obtained following calibration are shown in table 3 the corresponding observed and simulated snow maps from which these statistics were calculated are shown in fig s11 the f statistics returned are generally high across the 17 days the average percentage of correctly simulated pixels is 85 as expected the scores decline progressively from f 1 to f 3 moreover the variability in the statistics between images was observed with the highest scores naturally being achieved on completely snow covered mid winter days the lowest f 1 value was for the 29 april 2017 when the model missed a late season snowstorm that briefly blanketed the catchment fig 4 shows the comparison between simulated and observed swe time series at the two measurement stations the dynamics of snowpack evolution are replicated adequately including the contrast between seasonal snowpack at the higher elevation station cor and the more intermittent pattern at the lower one gry the colder prevailing conditions at cor allow the results to be discussed explicitly in terms of the accumulation and ablation phases this simulated onset of accumulation closely matches the observations here as do changes in accumulation rate the timing and rate of ablation is likewise broadly consistent with the observations however there does seem to be a general tendency towards underestimation of accumulation totals a similar underestimation is evident in the first three years at gry across both stations observations from winter 2017 2018 are reproduced best perhaps due to increased local data availability in evaluating these results it must be highlighted that the key meteorological variables of precipitation at cor and both precipitation and temperature at gry were not actually measured at these locations but rather had to be spatially interpolated onto the corresponding model cells from station measurements elsewhere as such much of the remaining post calibration difference is likely to be associated with uncertainties in these interpolated fields in addition as explained earlier the observations themselves were reconstructed finally the observations were made at discrete locations whilst the simulated values correspond to the 25 m pixel within which each station was located hence should the terrain at the station locations not be entirely representative of its immediate surroundings this would represent another potential source of mismatch a shaded region corresponding to 20 around the observations that being roughly the maximum swe mismatch one could expect purely for this reason t jonas pers comm is shown to reflect this 5 3 comparison of simulated spatial statistics with previous studies in fig 5 the f statistics obtained are compared to those reported in previous studies that also employed these metrics to quantify the fit between distributed snow models and maps derived from landsat imagery three such studies are known each of which reported statistics for only a small number of days between one and three schöber et al 2010 presented f 1 values for two days but numerous catchments while bernhardt et al 2012 and warscher et al 2013 provided all three f statistics for their respective study catchments and selected days in contrast to the present study which also included mid winter and late summer days in the calibration catalogue the previously published statistics correspond to spring and early summer periods exclusively i e partially snow covered conditions as such to ensure the fairest possible comparisons only our statistics corresponding to this spring and early summer are included the underlying data are compiled in table s2 the f statistic distributions obtained seem to have a tendency to be slightly higher than those of previous studies even if the mean and median of f 1 are marginally lower than those calculated from the published values this tendency appears to be most pronounced for f 2 and f 3 in both cases the mean values obtained here are higher than their previously published counterparts importantly with the possible exception of schöber et al 2010 who may have used the spatial snow observations in an informal fashion to adjust certain model parameters ambiguity remains as this step was not fully explained the previous studies used the spatial data purely for model evaluation in contrast to the present study in which they formed calibration targets as such while perhaps slightly disappointing that the explicit calibration did not yield higher f 1 scores a real benefit of calibration can arguably be seen in the noticeably higher f 2 and f 3 scores these metrics were assigned enhanced weight in the calibration processes that said the small sample sizes must be borne in mind when making such interpretations an additional consideration is that our calibration was not informed solely by the observed snow extent maps but rather sought to achieve an acceptable balance between fits according to both the maps and swe time series improved spatial fits could probably have been achieved if the maps alone comprised the objective function but this may have come at the expense of reduced accuracy in simulated catchment wide snow water storage a much larger catalogue of published f statistics would be required to assess the statistical significance of these results i e whether the calibration approach proposed does lead to real improvements in the capacity of distributed snow models to reproduce high resolution observed extents nevertheless the comparisons presented confirm the overall appropriateness of the approach taken and perhaps even alludes to some added value finally given the variability in the f statistics obtained between days the larger number of days for which performance statistics were presented here which elucidate this is a strength of this study because previous studies considered fewer days it is unclear how consistent in time their generally good model performance might be 5 4 snowpack evolution and hydrological plausibility a key benefit of the model and indeed any distributed transient simulator is that it fills in the gaps in space and time between the available observations to visualise this animation s1 presents the simulated evolution of swe at a daily time step during winter 2017 2018 the redistribution of snow from steep slopes is particularly apparent with patterns being broadly consistent with both our local field experience during the period fig s1 and the avalanche activity that occurred in the region more generally bühler et al 2019 fig 6 illustrates the spatio temporal distribution of a all liquid water comprised of liquid precipitation snowmelt firn melt and ice melt and b et p over the last hydrological year of the simulation period aggregated on a monthly basis as expected very little simulated meltwater input occurs during the winter months when temperatures are generally below freezing conversely the highest meltwater volumes are generated during the spring melt especially the months of april may and june the elevation at which the majority of melt water is produced increases as the season progresses and the localised contribution of the glaciers during the summer months is also evident indeed extremely high values are generated locally from the glaciers especially in summer 2018 when heatwave conditions were experienced in our simulation the glaciers can exhibit strongly negative mass balance liquid precipitation during the summer and autumn months which can be highly concentrated in space and time is naturally smoothed out in these plots appearing as a fairly low and constant daily mean value in non glacierised areas that said fig s12 presents the same underlying data in an alternative fashion as hourly catchment averaged series indicating the dynamism of the system strong seasonality and elevational influences are apparent in the spatial patterns of et p with estimated values being widely low in winter but restricted to higher elevations in summer to further verify the hydrological plausibility of these results without recourse to a full hydrological model simulated snowcover outflow and observed discharge were compared for the vallon de nant sub catchment a concrete weir gauging station at the outlet of this sub catchment avançon weir fig 1 provides high frequency streamflow estimates from spring 2016 onwards from which hourly mean flows were calculated the empirical stage discharge relationship i e rating curve was developed by salt dilution gauging ceperley et al 2018 despite the regular cross section these data are somewhat uncertain especially at flow extremes at low flows this is due to shifting channel configurations immediately upstream of the weir in fig 7 a hourly catchment averaged snowcover outflow i e snowmelt from non glaciated areas plus any liquid precipitation is plotted against hourly observed catchment area normalised discharge measured at the avançon weir over spring 2018 april to june inclusive simply comparing the two cumulative totals gives an estimated runoff ratio of 0 61 over the three month period although this value is only tentative given uncertainties associated with precipitation the model and the observed discharge data at the diurnal timescale simulated snowmelt is associated with increasing observed streamflow which seems reasonable dependence remains present on slightly longer frequencies also for example the decrease in measured streamflow just before the start of may coincides with a marked reduction in simulated water inputs extending this plot to later summer not shown revealed that a certain proportion of the excess spring melt inputs arrive in the stream later reflecting the buffering capacity of relatively shallow groundwater storage in reality a proportion of meltwater will of course also be lost to actual evapotranspiration and perhaps also to deeper groundwater storage and or groundwater exportation across topographic divides fig 7 b meanwhile shows the relationship between these data aggregated to a daily time step as the lagged and strongly dampened observed streamflow response relative to the simulated melt inputs complicates hourly comparisons a clear relationship between the variables is apparent which can be approximated by a power law function illustrated by the estimated non linear least squares regression line a certain hysteresis is also present meaning that less meltwater is required to produce a given magnitude of flow response as the season progresses this is consistent with increasing groundwater storage saturation throughout the period in subsequent work the gridded estimates generated here have been combined with a specifically developed 3d model of bedrock geology thornton et al 2018 and other data to inform a sophisticated fully integrated surface subsurface hydrological model thornton et al under review the generally good simulated streamflow and groundwater level results presented therein further reinforce the hydrological plausibly of our snow simulations 5 5 predictive uncertainty and data worth analyses table 4 shows the estimated pre and post calibration uncertainty standard deviation of the selected predictions the calibration process substantially reduced the uncertainty associated with the predictions by a factor of approximately four fig 8 provides an indication of contribution of the different model parameters to the uncertainty variance both pre and post calibration for two of the five predictions in these plots the uncertainty variance contributions have been normalised with respect to the pre calibration uncertainty variance associated with the respective predictions fig 8 a which concerns the prediction of swe on 1 april 2016 reveals firstly that many parameters that either do not or hardly contribute to predictive uncertainty either before or after calibration i e the prediction is insensitive to these parameters a slight reduction in the contribution to uncertainty variance can however be observed for idwedr snob and snoa the presence of many parameters that do not contribute to either the pre or post calibration uncertainty in the swe prediction is to be expected this is because most of these parameters concern the model s gravitational redistribution component whereas the cor measurement station will have undoubtedly been sited strategically such that the measurements are generally unaffected by such processes another striking feature of this plot is the large reduction in the predictive uncertainty associated with the longwave correction parameters lwin and lwout that calibration induced the results for the three other 1 april swe predictions were similar and so are not presented in the interests of space for the prediction of spatial snow extent on the 22 may 2017 quantified according to the f 1 statistic fig 8 b practically all parameters make some discernible contribution to uncertainty variance both pre and post calibration interestingly as with the swe prediction a large reduction in the post calibration uncertainty associated with lwin is observed but the post calibration uncertainty associated with lwou in relation to this prediction is actually higher than the pre calibration value this counterintuitive situation can occasionally arise when a parameter to which the prediction is insensitive can only be made in conjunction with another parameter to which the prediction is indeed sensitive see doherty 2010 for further explanation in this instance it may be because these two parameters are not entirely independent of one another for all other parameters the uncertainty contribution post calibration is very similar to the pre calibration level suggesting a certain insensitivity of the simulated snow extents to varying these parameter values the robustness that the similarity between pre and post calibration parameter contributions to uncertainty in the spatial prediction indicates could in fact be particularly beneficial in applications where only spatial snow patterns as opposed to water volumes are of primary importance e g assessing the influence of snow patterns on vegetation fig 9 provides two alternative representations of the worth of the observations belonging to the five different groups in the calibration process fig 9 a shows the increase in post calibration predictive uncertainty variance associated with each of the five selected predictions again relative to pre calibration uncertainty variance that is incurred by omitting each observation group from the calibration dataset in turn removing either f 1 f 2 or f 3 has very little adverse effect on any of the predictions this may be explained by the fact that when one of these groups is omitted similar information is retained in other two groups the comparatively small number of observations in these groups coupled with the uniform weighing applied to all observations for the purposes of this analysis could also partially explain these results combining these observations into a single group and or adjusting the relative weights assigned could have suggested enhanced importance of these observations this plot furthermore reveals the notable contribution that both time series but most especially that at gry make to the prediction the prediction s uncertainty variance increases markedly if either of these observation groups is removed four of the five predictions under consideration correspond to the swe predicted at the high elevation cor station in light of this the analysis suggests perhaps surprisingly that removing the data at gry from the calibration dataset has a more detrimental effect than removing the other observations at cor itself the very location of the predictions fig 9 b provides an indication of the decrease in uncertainty variance accrued relative to the pre calibration uncertainty variance when each observation group comprises the sole member of the calibration dataset including any one of the observation groups f 1 f 2 or f 3 alone in the calibration datasets leads to only modest reductions in the pre calibration uncertainty variance associated with the predictions although this is not to say that they do not have a more pronounced effect in combination in contrast including either of cor or gry swe time series observations as the sole calibration dataset leads to similarly large reductions in the uncertainty associated with the prediction of swe at cor the uncertainty around the f 1 prediction on 22 may 2017 is also greatly reduced by including either of these groups as the sole calibration dataset although only by about half as much as the reduction seen for the 1 april swe predictions this result that even including only one of the time series as the sole calibration dataset substantially reduces the uncertainty in the spatial prediction indicates an important flow of information from the time series to the predicted spatial snow patterns and can probably be generalised to the other days on which simulated spatial patterns were compared with observations the apparent significance of the gry data that both analyses indicate is especially notable given that the number of observations at this site is substantially lower than at gry due to lower measurement frequency it could be that being straddled more frequently by the 0 c isotherm the swe time series at gry contains more important information about temperature and therefore temperature gradients and snow limits than the cor data which contains distinct accumulation and ablation phases are apparent more generally the notable contributions that the time series data seem to make demonstrates the importance of obtaining various complementary data types and employing them within multi objective approaches this result is consistent with the tuo et al 2018 for instance who also showed that swe data can be included to good effect in the hydrological model calibration in alpine catchments lastly because a consideration in this study was to generate the best possible inputs for subsequent hydrological modelling that also coincide in time with other measurements from the study region such as groundwater levels not shown no snow observations were specifically withheld for evaluation future research should certainly explore the influence of the chosen calibration period and or assess model s performance under different condition although the uncertainty analysis can be considered a partial replacement traditional split sample model evaluation should be undertaken whenever sufficiently long time series are available 5 6 potential sources of residual mismatch uncertainty in snow observations aside a large proportion of the residual spatio temporal mismatch between the simulations and observations can probably be attributed to the meteorological forcing data due to the combination of relatively low station density and variable but sometimes high data gap frequency figures s3 to s9 the interpolated spatial fields of meteorological variables used to drive the model are undoubtedly uncertain more specifically whilst the temporal coverage and therefore crossover of the meteorological data varies throughout the simulation period the parameters in the model are global this means that the rain snow threshold temperature rstt and solid precipitation correction factors snoa and snob for example remained constant in time and space hence when estimated though the calibration processes values producing best overall outcomes with respect to the observations were returned in reality however the error distribution associated with precipitation measurements likely varies per station and per event smith et al 2020 reported difficulties in finding undercatch correction factors that perform comparably well across multiple sites in other words it may be that in not permitting bespoke per station event corrections the model structure is insufficiently flexible to compensate fully for deficiencies in meteorological measurements during certain periods and or at certain locations in this sense improved fits could perhaps have been achieved by simply scaling relatively complete time series measured at an individual location s using linear elevation dependent relationships although such an approach would have been less satisfactorily during periods with high meteorological data availability since much of it would have essentially been discarded in addition the spatial dependencies in meteorological variables away from the station locations which the interpolation processes attempted to characterise probably also demonstrate some temporal non stationarity in reality e g spatial structures may differ depending on whether precipitation is frontal or convective 5 7 some remarks on wind redistribution spatially distributed drift solid precipitation correction factors have been applied to account for the influence of wind transport processes on snowpack heterogeneity e g hanzer et al 2016 marshall et al 2019 including based on lidar derived snow depth maps where available vögeli et al 2016 however as mentioned earlier after testing wasim s wind redistribution algorithm was not included in our final model because doing so led to poorer observation fits the algorithm in question computes a temporally invariant spatially distributed correction factor grid that acts as a multiplier to the interpolated precipitation fields such that precipitation falling on predominantly sheltered slopes and on the leeward side of ridges is augmented deposited whilst that falling on exposed slopes is reduced scoured to generate such a grid a single prevailing wind direction in fact a sector must be prescribed however an analysis of the relationship between high elevation winter wind speeds these conditions being those under which snow redistribution by wind is most relevant and directions revealed that no such single prevailing wind direction can be identified across the study area fig s13 strong winter winds can apparently originate from contrasting directions probably according to larger scale synoptic meteorology some influence of the complex local topography on wind patterns is also evident similar patterns could be expected in other mountainous regions furthermore the calculated wind redistribution factor range seemed somewhat high leading to both too much deposition and scouring depending upon pixel exposition with respect to the admittedly limited swe data another potential issue is that unlike the gravitational redistribution algorithm applied the wind redistribution approach does not conserve mass within a given area e g a catchment ultimately it may be that in mountainous regions where large scale meteorological phenomena interacting with extremely complex topography give rise to considerable spatio temporal variability in near surface wind fields such comparatively simple algorithms are unable to match highly resolved site specific snow observations thus the development of extended empirical approaches that could include directly measured high elevation wind directions and or are calibrated explicitly to observed redistribution magnitudes near ridges could form an appropriate intermediate objective until physics based wind induced snow transport can be simulated in a physically based fashion at high resolution across entire catchments in any case in this particular study area snow redistribution by wind is likely of secondary hydrological importance to that by gravity 5 8 ongoing debates regarding hydrological model calibration whilst it is increasingly clear that internal states should be verified at some stage in the calibration or evaluation of hydrological models the most appropriate approach for including snow data remains under debate on the one hand it has been argued that since the volumetric information contained within discharge measurements complements the internal spatial pattern information embedded in distributed snow observations finger et al 2011 these two observation types should be considered simultaneously e g finger et al 2011 2014 shrestha et al 2014 the argument runs that the discharge constraint can help ensure that in aggregate the total simulated system water volume is approximately correct which is important given uncertain precipitation measurements and gridded products whilst the snow pattern constraints help ensure that runoff is being generated in the right areas others however posit that calibration is best tackled more sequentially whereby snow simulations are initially optimised independently before one proceeds to simulate intermediate hydrological variables and ultimately discharge the principal argument in favour of this approach is that simultaneous calibration may enable error compensation ragettli pellicciotti 2012 magnusson et al 2015 that can be hidden or easily overlooked at least unless extremely careful evaluative work with respect to observed spatial patterns in undertaken which remains rare provided a given set of snow observations are sufficiently informative and it is hoped those employed here are despite being somewhat limited by practical considerations such as the risks associated with conducting regular winter snow surveys in such terrain then the latter approach which was taken here should automatically ensure that the total water volumes are reasonably accurate indeed both binary spatial and volumetric time series at contrasting sites were considered in the snow model calibration for this precise reason the hydrological plausibly assessment undertaken section 5 4 and subsequent work thornton et al under review provides reassurance that this is indeed the case splitting the calibration phases essentially reduced the potential for model parameters related to the surface or subsurface to compensate for poor snow simulations or vice versa and additionally enabled a more advanced fully integrated code to be applied for the simulation of the remaining hydrological processes thornton et al under review 6 conclusions this paper has presented and exemplified a novel computationally efficient approach for the calibration and uncertainty analysis of distributed snow models in steep rugged alpine terrain the physically based core of the model explicitly captures the spatio temporal variability in energy balance components which is largely responsible for heterogeneous snow patterns and therefore melt rates in such terrain substantial uncertainties related to biased solid precipitation measurements and other observational deficiencies were addressed using empirical correction factors gravitational redistribution can also substantially influence meltwater patterns in steep regions but cannot presently be represented on an entirely physical basis at catchment or larger scales a pragmatic empirical algorithm was therefore also included to represent this process reliably simulating the spatio temporal evolution of swe thus hinged upon the estimation of several parameters which was not trivial given the reasonable computational expense associated with the forward model a single parallelized simulation took several hours to this end a novel multi objective calibration stratergy that involved a gradient based algorithm and incorporated two complementary types of high resolution snow observations snow extent maps and swe time series was developed the study represents one of the first such occasions on which a distributed snow model has actually been calibrated rather than merely evaluated according to an objective function that is partially spatially explicit whereby mismatches are penalised at the pixel level this was achieved by quantifying model performance with respect to landsat derived observed snow maps using so called f statistics substantial corrections to measured winter precipitation totals were required to minimise model data mismatches following calibration spatio temporal snow dynamics could be satisfactorily reproduced with respect to the available observations and the spatial fit metrics obtained moreover compared favourably with the few equivalent statistics reported previously subsequent uncertainty and data worth analyses indicated that i the uncertainty variance of indicative predictions of snow states both spatial and volumetric were substantially reduced through calibration ii including two parameters that enable the longwave component of the surface energy balance to be adjusted and thus potential errors in cloudiness and albedo compensated for was especially beneficial and iii the swe time series at the lower elevation station gry was particularly informative despite the comparatively small number of observations at this site any snow observation uncertainties notwithstanding much of the residual mismatch between simulations and observations is likely associated with the meteorological forcing data both the raw measurements especially for precipitation and interpolated spatial fields as such efforts to better characterise and account for the uncertainties and biases in mountain meteorological measurements and interpolated downscaled gridded products should be prioritised the generic model data integration framework presented extends well beyond standard treatments of snow in hydrological modelling and could be easily applied in different settings in addition in our view the specific application of it presented here achieved an appropriate balance between model complexity and data availability nevertheless the implications of some potential limitations associated with the core of the model employed here could be investigated for instance fairly basic spatial interpolation schemes were used a single rather than multi layer snow model was employed and wind redistribution was not accounted for indeed acknowledging that even sophisticated multi physics snow models contain uncertain parameters that must be identified see also günther et al 2020 future work should explore the extent to which using even more sophisticated snow simulation approaches might further reduce both pre and post calibration predictive uncertainties specifically such work could involve testing more sophisticated interpolation algorithms e g that of liston and elder 2006 for wind deploying a more process rich and advanced snow code that includes at least three snow layers and or accounts for wind redistribution provided increased data availability and quality accompanies increased model complexity a further reduction in uncertainty should be realised although this remains to be tested however the outcomes of such experiments must be interpreted with respect to the magnitudes of irreducible uncertainties associated with both forcing and observed calibration data i e uncertainties that will persist under many circumstances in summary distributed meltwater datasets generated via calibration constrained simulations of snow dynamics demonstrate great potential to inform the next generation of comprehensive physically based spatially explicit hydrological simulations in complex alpine terrain such efforts are urgently needed to provide a sound basis for decision making under hydrological system change a range of other applications which also require spatio temporally comprehensive snow information could also benefit from such an approach employing model data integration frameworks such as that presented here more routinely perhaps eventually in conjunction with even more advanced snow codes where data availability makes it appropriate to do will lead to improved snow simulations but also greater appreciation of their currently somewhat overlooked outstanding uncertainties declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the work was conducted as part of the integralp project funded by the swiss national science foundation snf project cr23i2 162754 professor b schaefli and dr j schulla are thanked for useful discussions and answers to questions regarding the use of wasim respectively the two anonymous reviewers are thanked for their valuable feedback all model related datasets and code that can be shared are accessible at https dx doi org 10 17632 84ph9rpnhr 1 high resolution versions of all supplementary figures are also available at this location as is the animation the meteorological data obtained from meteoswiss and the terrain and land cover data obtained from swisstopo remain subject to restrictions therefore the processed model inputs relating to these aspects are not included requests for these datasets should be directed to the respective organisation third party executables are similarly excluded but are obtainable as follows wasim executables and documentation can be downloaded from http www wasim ch en products html whilst pest executables and documentation can be downloaded from http www pesthomepage org downloads php author contributions j m t conceived this project independently and conducted the vast majority of the work including obtaining and processing the meteorological satellite and gry swe time series data establishing the model designing and implementing the calibration approach preparing the figures and drafting the manuscript t b conducted the simulation using the snowpack model at the cor station and provided guidance regarding some of the meteorological data g m and p b provided advice and support at all stages and all authors participated in the finalisation of the manuscript appendix a supplementary data supplementary data to this article can be found online at https dx doi org 10 17632 84ph9rpnhr 1 appendix a supplementary data the following are the supplementary data to this article supplementary video 1 supplementary data 2 
4553,this study aims to present an accurate and efficient finite volume approach for overland flow modelling in rural and urban areas through solving the two dimensional shallow water equations the proposed approach introduces a hybrid procedure that utilizes the sharpness of discontinuity to identify flow conditions in the entire computational domain and then a low accuracy high efficiency scheme the rusanov scheme is used in regular flows whereas a high accuracy low efficiency scheme the hllc scheme is adopted in strong discontinuous flows regions that simultaneously adopt the two schemes are artificially specified to diminish numerical unbalances between the two schemes model calibration is carried out through three strong discontinuous flow cases with the exact solutions model verification is next described by three benchmark cases including rainfall runoff around buildings flash floods towards buildings and street junction flows model efficiency assessment is also conducted to present the numerical efficiency improvement of the proposed approach for various flow conditions technical attention is devoted to the numerical performances on local accuracy and global efficiency of the proposed approach the simulated results indicate that the proposed approach can simulate as accurate as the hllc scheme with significant reduction on its computational time how efficient the proposed hybrid approach can reach depends on flow conditions involved it is more efficient than the hllc scheme as the portion of strong discontinuous flows in the computational domain is relatively smaller the proposed approach has proved its accuracy and efficiency for overland flow modeling and it can also be used together with other speed up techniques such as local time stepping and parallelization to improve its efficiency other finite volume schemes can also be utilized to improve the efficiency and accuracy of the proposed approach therefore the solver has considerable potentials as a useful tool in flood inundation simulations keywords shallow water equations overland flow in rural and urban areas finite volume method hybrid approach the rusanov scheme the hllc scheme 1 introduction flood is one of the most common natural disasters in the world it can be generally classified into three main types as fluvial pluvial and coastal floods chow et al 2013 as modeling these three types of floods an overland flow module is always a key element to connect with river flow storm sewer flow and storm surge modules respectively thus overland flow modeling is essential for any types of flood inundation modeling chang et al 2015 2018 overland flow is an important process of the hydrologic cycle basically it is runoff that occurs on land surface before reaching a channel chow et al 2013 the two dimensional shallow water equations the 2d swes are widely adopted to analyze overland flow dynamics castro orgaz and hager 2019 mathematically the 2d swes are the depth averaged version of the three dimensional navier stokes equations which are a time dependent set of nonlinear hyperbolic partial differential equations with a topography source term in the past two decades varieties of numerical methods have been introduced in modeling shallow water overland flows castro orgaz and hager 2019 have extensive summary on this topic among various numerical methodologies due to its enhanced capability in dealing with flow transition the finite volume method is so far the most commonly used modeling method to solve the 2d swes toro 2001 many finite volume strategies mostly originated from shock capturing techniques in aerodynamics have been applied to shallow water hydraulics such as the approximate riemann schemes bradford and sanders 2002 soares frazão et al 2008 nikolos and delis 2009 the godunov type schemes liang et al 2008 sanders et al 2008 abderrezzak et al 2009 kim et al 2009 costabile et al 2017 xia et al 2017 sanders and schubert 2019 the roe scheme rogers et al 2003 ferrari et al 2017 martins et al 2018 the total variation diminishing tvd scheme liang et al 2007 bai et al 2018 khoperskov and khrapov 2018 the simplified scheme e g the dhd scheme by cea and bladé 2015 etc recently some matured finite volume schemes have been further implemented on the gpu framework for full scale flood modeling xia et al 2019 aureli et al 2020 it should be noted that the godunov type and roe schemes are widely used to establish shallow water solvers toro 2001 in particular first order modules of the hllc and roe schemes have recently been applied to field scale flood inundation modeling martins et al 2017 the aforementioned hllc and roe schemes are noteworthy for their strong abilities to improve the numerical accuracy of handling transcritical flows as well as wet dry interfaces toro 2001 overland flow dynamic may change rapidly due to various situations such as terrain alternation sudden overtopping inflow that introduce strong discontinuities in flow conditions chang et al 2014 2016 however not all of overland flow computations involve such complicated flow conditions numerical accuracy and efficiency are often going with the opposite way castro orgaz and hager 2019 the above accurate schemes requiring heavy numerical procedures are not economically suitable for modeling regular flows that have relatively smooth profiles of water depths and velocities in overland flows as evaluating the numerical performances of various overland flow models accuracy and efficiency are both crucial a hybrid approach that is capable of analyzing complicated flow conditions with high accuracy low efficiency schemes and simulating regular flows with low accuracy high efficiency schemes is not yet available for a wide range of flood modelling applications to fill this gap the main objective of the study is to develop a novel hybrid finite volume method for balancing the modes of numerical accuracy and efficiency in 2d overland flow computation a hybrid procedure is proposed to incorporate the rusanov and hllc schemes the sharpness of discontinuity is used to identify flow condition of each cell interface in the entire computational domain flow conditions are divided into strong discontinuous flows with significant variations in water depths and velocities and regular flows other than strong discontinuous flows as considering strong discontinuous flows the hllc scheme is adopted and the rusanov scheme is used in regular flows regions that simultaneously utilize the two schemes are also artificially specified to diminish numerical unbalances between the two schemes model calibration is carried out by three strong discontinuous flow cases with the exact solutions the proposed hybrid approach is then verified by three benchmark cases including rainfall runoff around buildings flash floods towards buildings and street junction flows to demonstrate the strength and limitation of the methodology model efficiency assessment is also conducted to present the numerical efficiency improvement of the proposed approach for various portions of strong discontinuous flows in the computational domain technical attention is devoted to the numerical performances on local accuracy and global efficiency of the proposed approach 2 hybrid shallow water solver 2 1 governing equations the conservative form of the two dimensional shallow water equations the 2d swes with source terms can be written in a vector form as toro 2001 kao and chang 2012 1 u t f u x g u y r s b s f where 2 u h hu hv f u hu u 2 h 1 2 g h 2 huv g u hv huv v 2 h 1 2 g h 2 r r 0 0 s b 0 g h z b x g h z b y s f 0 g n 2 u u 2 v 2 h 1 3 g n 2 v u 2 v 2 h 1 3 in which t is the time x and y are the coordinates h is the water depth u and v are the x and y components of the depth averaged velocity respectively r is the effective rainfall intensity total rainfall intensity minus infiltration rate z b is the bed elevation n is the manning roughness coefficient g is the gravitational acceleration 9 81 m s2 u is the vector of conserved flow variables f u and g u are the flux vectors in the x and y directions respectively s b and s f are the bed slope and friction slope vectors respectively 2 2 numerical discretization in the present study the first order upwind godunov type finite volume scheme is used to conduct the spatial discretization and the first order forward euler scheme is adopted to perform the temporal discretization hence the discretized form of eq 1 on cartesian cells can be given as 3 u i j s 1 u i j s δ t l f i 1 2 j s f i 1 2 j s g i j 1 2 s g i j 1 2 s δ t r i j s s b i j s s f i j s 1 where subscripts i and j denote the x and y cell indexes of the cell respectively s and s 1 denote the current and next steps respectively l is the cell size δ t is the time step f i 1 2 j s f i 1 2 j s g i j 1 2 s and g i j 1 2 s are the flux vectors at the left right bottom and top cell edges respectively the hybrid shallow water solver in this study is established by solving eq 3 to calculate the flux vectors f i 1 2 j s f i 1 2 j s g i j 1 2 s and g i j 1 2 s and the bed slope vector s b i j s in eq 3 the reconstruction of the riemann states at cell edges is required the correctness of reconstructing riemann states at cell edges can significantly influence the accuracy of the scheme audusse et al 2004 xia et al 2017 this study adopts the first order cn reconstruction method proposed by chen and noelle 2017 considering a cell interface at i 1 2 j and its two adjacent cells i j and i 1 j along the x direction the bed elevation at the cell interface is first reconstructed by 4 z b i 1 2 j s min max z b i j z b i 1 j min z b i j h i j s z b i 1 j h i 1 j s and the reconstructed water depths at the left hand and right hand sides of the cell interface are given as 5 h i 1 2 j l s min z b i j h i j s z b i 1 2 j s h i j s h i 1 2 j r s min z b i 1 j s h i 1 j s z b i 1 2 j s h i 1 j s positivity of water depth is preserved since the reconstructed bed elevation at the cell interface by eq 4 is less than or equals to the minimum of the two water surface levels chen and noelle 2017 as for the velocities at the left hand and right hand sides they are 6 u i 1 2 j l s u i j s u i 1 2 j r s u i 1 j s 2 2 1 discretization of the flux vectors the four flux vectors f i 1 2 j s f i 1 2 j s g i j 1 2 s and g i j 1 2 s in eq 3 are discretized explicitly xia and liang 2018 the rusanov and hllc schemes that are regarded to be in the same category of approximated riemann schemes toro 2001 are interchangeably used to calculate the four flux vectors by utilizing the reconstructed water depths and velocities the two schemes are briefly introduced next there are several hllc schemes and the present study adopts the version provided by toro 2001 in this hllc scheme the left middle and right characteristic wave speeds are considered when determining the flux vectors several procedures are introduced to give the estimations of the three characteristic wave speeds toro 2001 specifically in the presence of wet dry interfaces this hllc scheme utilizes the exact solution of the dry bed problem to determine these characteristic wave speeds the determinations of the four flux vectors are expressed by taking the flux vector f i 1 2 j s as an example 7 f i 1 2 j s f i 1 2 j l s 0 c i 1 2 j l s f i 1 2 j l s c i 1 2 j l s 0 c i 1 2 j m s f i 1 2 j r s c i 1 2 j m s 0 c i 1 2 j r s f i 1 2 j r s c i 1 2 j r s 0 with 8 f i 1 2 j l s f i 1 2 j l s c i 1 2 j l s u i 1 2 j l s u i 1 2 j l s f i 1 2 j r s f i 1 2 j r s c i 1 2 j r s u i 1 2 j r s u i 1 2 j r s u i 1 2 j l s u i 1 2 j r s u i 1 2 j l s and u i 1 2 j r s are 9 u i 1 2 j l s h i 1 2 j l s hu i 1 2 j l s hv i 1 2 j l s u i 1 2 j r s h i 1 2 j r s hu i 1 2 j r s hv i 1 2 j r s u i 1 2 j l s h i 1 2 j l s c i 1 2 j l s u i 1 2 j l s c i 1 2 j l s c i 1 2 j m s 1 c i 1 2 j m s v i 1 2 j l s t u i 1 2 j r s h i 1 2 j r s c i 1 2 j r s u i 1 2 j r s c i 1 2 j r s c i 1 2 j m s 1 c i 1 2 j m s v i 1 2 j r s t in eq 7 c i 1 2 j l s c i 1 2 j m s and c i 1 2 j r s are the left middle and right characteristic wave speeds respectively f i 1 2 j l s and f i 1 2 j r s are the flux vectors determined by the reconstructed variables water depths and velocities at the left hand and right hand sides of the cell interface respectively as to the rusanov scheme it can be seen as a simplified version of the hllc scheme toro 2001 the left and right characteristic wave speeds have the same magnitude with opposite signs whereas the middle waves are not considered rusanov 1961 toro 2001 considering two adjacent cells i j and i 1 j along the x direction and their common cell interface as an example the flux vector f i 1 2 j s is given as 10 f i 1 2 j s 1 2 f i 1 2 j l s f i 1 2 j r s 1 2 c i 1 2 j s u i 1 2 j r s u i 1 2 j l s where 11 c i 1 2 j s max u i 1 2 j l s g h i 1 2 j l s u i 1 2 j r s g h i 1 2 j r s 2 2 2 discretization of the bed slope vector to compute a constant free surface level when water is at rest velocities are zero an exact balance between the bed slope and the hydrostatic water pressure gradient should be maintained the well balanced property or the so called c property the bed slope vector in eq 3 is discretized explicitly as chen and noelle 2017 12 s b i j s 0 g 2 l h i j s h i 1 2 j l s z b i j z b i 1 2 j s h i j s h i 1 2 j r s z b i j z b i 1 2 j s g 2 l h i j s h i j 1 2 l s z b i j z b i j 1 2 s h i j s h i j 1 2 r s z b i j z b i j 1 2 s this formula is proved to preserve the well balanced property chen and noelle 2017 2 2 3 discretization of the friction slope vector the friction slope vector s f i j s 1 is discretized by a semi implicit scheme as cea et al 2010 rousseau et al 2015 13 s f i j s 1 0 g n 2 q s q x s 1 h 7 3 s i j g n 2 q s q y s 1 h 7 3 s i j t where q x and q y are defined as hu and hv respectively q s q x s 2 q y s 2 the semi implicit friction slope discretization is used herein to avoid the numerical instability when the water depth tends to zero rousseau et al 2015 2 2 4 stability criterion the stability criterion of the hybrid shallow water solver is the courant friedrichs lewy cfl condition given as 14 δ t cfl min i j l u i j g h i j in which u i j is defined as u i j 2 v i j 2 cfl number ranges from 0 to 1 2 3 theoretical comparison between the rusanov and hllc schemes a theoretical comparison of numerical efficiency and accuracy between the two schemes are conducted herein by utilizing the formulas of the two schemes for the numerical efficiency it is evaluated by the count of operations in the schemes as to the rusanov scheme it takes four steps to calculate the flux vector including the first two steps to find the wave celerity at the left hand and right hand sides g h i 1 2 j l s and g h i 1 2 j r s in eq 11 respectively the third step for the characteristic wave speeds c i 1 2 j s in eq 11 and the final step to determine the flux vector eq 10 for the hllc scheme the first step is to identify whether the cell interface is a wet dry interface or not in the presence of wet dry interfaces the hllc scheme takes three steps to calculate the left and right characteristic wave speeds by utilizing the exact solutions determination of the wave celerity at left hand or right hand sides calculations of the left and right characteristic wave speeds if the cell interface is not a wet dry interface the hllc scheme takes seven steps to determine the left and right characteristic wave speeds two steps for wave celerity at both sides one step for water depth in the star region four steps for left and right characteristic wave speeds after the left and right characteristic wave speeds are both determined the hllc scheme calculates the middle characteristic wave speed then the hllc scheme goes through eqs 7 8 and 9 in two to three steps for calculating the fluxes in summary the hllc scheme takes seven to eleven steps to determine the fluxes at cell edges as a result the hllc scheme needs three to seven more steps to determine the flux vector as to numerical accuracy viewpoint in the rusanov scheme only a maximum characteristic wave speed is considered eq 11 in the calculation of fluxes eq 10 hence in the presence of strong discontinuities the rusanov scheme gives smoother profiles of water depths and velocities for the hllc scheme the three characteristic wave speeds are all calculated for determining the fluxes eqs 7 8 and 9 the hllc scheme is thus more accurate than the rusanov scheme when simulating strong discontinuities based on the above comparison the proposed hybrid shallow water solver utilizes the rusanov scheme the low accuracy high efficiency scheme for regular flows and simulates strong discontinuous flows with the hllc scheme the high accuracy low efficiency scheme regions that simultaneously utilize the two schemes are required to be delineated into the computational domain to avoid numerical unbalances between the two schemes the details of the hybridization are introduced in subsection 2 4 2 4 the hybrid approach for flux calculation the major contribution of this manuscript is that we develop a novel hybrid shallow water solver to comprise low accuracy high efficiency and high accuracy low efficiency schemes for various overland flow conditions the hllc scheme is adopted to analyze strong discontinuous flows whereas the rusanov scheme is used for regular flows to numerically incorporate these two schemes together each cell interface in the entire computational domain is assigned with a weight ws that ranges from 0 to 1 when ws is 0 1 and between 0 and 1 the calculation of the fluxes uses the hllc scheme only the rusanov scheme only and both the rusanov and hllc schemes respectively two steps of the hybrid procedure are next introduced the flowchart of the hybrid shallow water solver including the proposed hybrid procedure is displayed in fig 1 a the reconstruction of the riemann states at cell edges and the calculation of fluxes are executed after the weight of each cell interface is determined in the second step of the hybrid procedure 2 4 1 identification of strong discontinuous flows in the first step each cell interface in the entire computational domain is visited to identify strong discontinuous flows herein strong discontinuous flows are defined as flows with significant variations in water depths and velocities as such flows often involve significant discontinuities across the cell interfaces the sharpness of discontinuity is used as the indicator considering the cell interface locating at i 1 2 j with the two adjacent cells i j and i 1 j the judgement to identify strong discontinuous flows across the cell interface is 15 h i j s h i 1 j s min h i j s h i 1 j s δ the left hand side in eq 15 is the sharpness of discontinuity and δ is the threshold value to judge whether the sharpness of discontinuity is large enough δ is a model parameter that is hereinafter referred to as the discontinuity threshold when the sharpness of discontinuity of the cell interface exceeds δ the rusanov scheme is regarded to be inappropriate to calculate the fluxes and the hllc scheme is adopted alternatively with ws 0 significant discontinuities such as hydraulic jumps hydraulic drops and wet dry interfaces can all be recognized by eq 15 for simplicity a cell interface identified in strong discontinuous flows is hereinafter to be referred to as the seed interface for the cell interface that is not identified in strong discontinuous flows it is marked to be in regular flows with ws as 1 however as encountering very shallow flows the numerator and denominator in the sharpness of discontinuity are both very small consequently the hybrid procedure can identify a spuriously large portion of strong discontinuous flows to avoid this situation the numerator in the sharpness of discontinuity is required to be larger than a difference threshold ε in the present study ε is given as 10 5 m throughout all the simulations 2 4 2 flux calculation in the second step the fluxes at each cell interface are calculated based on the weight determined in the previous step however as the weight of any cell interface is either 1 or 0 after the first step instantaneously switching from the rusanov scheme to the hllc scheme can introduce some side effects to the accuracy of simulations because of the numerical gaps between the two schemes wang et al 2016 used a continuous weight function to decide the weights of the roe and rusanov schemes according to the pressure gradient to diminish the artificial numerical unbalances between the two schemes however using such weight functions may introduce large regions where the roe and rusanov schemes are both used the computational time is increased under this circumstance to maintain global efficiency and mitigate the artificial numerical unbalances at the same time such weight functions are not used in the present study instead the cell interfaces that are identified to use the hllc scheme in the first step the seed interfaces are used as the starting positions to specify the regions that adopt both the rusanov and hllc schemes for simplicity the regions that simultaneously adopt the two schemes are hereinafter referred to as the transition regions furthermore because of the numerical gaps between the two schemes the regions adjacent to the seed interfaces are re adjusted to use the hllc scheme so as to maintain local accuracy those regions are hereinafter referred to as the hllc regions for simplicity the delineations of the hllc regions and the transition regions are executed over each seed interface and each seed interface has its hllc and transition regions the hllc regions are created before the transition regions the illustrations of the hllc and transition regions around a seed interface locating at i 1 2 j are depicted in fig 1b in this figure the hllc regions the regions where the cell interfaces are marked as the dark blue lines are created adjacent to the seed interface drawn as the red line and the transition regions the regions where the cell interfaces are depicted as the orange lines are specified next to the hllc regions the symmetric length of the hllc region is calculated based on the flow condition of the seed interface at present time it is formulated in analog to the experimental formulas for calculating the length of a hydraulic jump chaudhry 2008 16 l i 1 2 j h l l c s max h i j s h i 1 j s u i j s 2 g u i 1 j s 2 g l in eq 16 the length of the hllc region equals to or is larger than l to avoid the situation that no cell interfaces are included within this region the weight of the cell interface within the hllc region is modified to be 0 in terms of the transition regions they are specified to make the weight gradually change in the computational domain the symmetric length of the transition region is 17 l i 1 2 j t r a n s i t i o n s l i 1 2 j h l l c s the weight of the cell interface within the transition region is given by 18 w i 1 2 j j s 1 n i 1 2 j t r a n s i t i o n s 1 j n i 1 2 j h l l c s where 19 n i 1 2 j h l l c s l i 1 2 j h l l c s l n i 1 2 j t r a n s i t i o n s l i 1 2 j t r a n s i t i o n s l in eq 18 the index j represents the absolute difference of indexes between a cell interface and the seed interface see fig 1b for details in eq 19 n i 1 2 j h l l c s and n i 1 2 j t r a n s i t i o n s are the equivalent counts of the included cell interfaces within the hllc region and the transition region respectively they are both positive integers a cell interface is visited more than once when there are multiple seed interfaces since the delineations of the hllc and transition regions are sequentially performed over each seed interface the weight of such cell interface is continuously assigned with the minimum between the lastly assigned weight and the newly determined weight from the specific seed interface finally after all of the seed interfaces are processed the fluxes at the cell interface are determined by 20 f i 1 2 j s w i 1 2 j s f i 1 2 j r u s a n o v s 1 w i 1 2 j s f i 1 2 j h l l c s where f i 1 2 j r u s a n o v s and f i 1 2 j h l l c s denote the flux vectors by the rusanov and hllc schemes respectively it is stressed that the mass conservation over the computational domain is ensured by eq 20 since the proposed hybrid shallow water solver uses the first order upwind godunov type finite volume scheme for the spatial discretization 3 model calibration the sharpness of discontinuity in eq 15 is used to identify flow condition of each cell interface by the discontinuity threshold δ once the sharpness of discontinuity is above the threshold value the rusanov scheme is not suitable to calculate the fluxes in this section three cases with the exact solutions are used to calibrate δ in each case several runs are performed by the proposed hybrid approach with various δ the rusanov scheme the hllc scheme and the proposed hybrid approach are written in the same code structure to minimize the differences in the numerical implementation it is expected that the proposed hybrid approach requires some additional cpu time to perform the hybrid procedure all of the simulations use square cells to discretize the computational domain the numerical simulations are all conducted on an intel r core tm i9 pc equipped with a 16 0 gb ram the numerical accuracy is evaluated by l2 norm used to quantify the difference between the numerical and measured exact results as chang et al 2011 2016 21 l 2 h p h p 2 h p 2 in which hp refers to the numerical result h p refers to the measured result since the hllc scheme is regarded to be the most accurate scheme here the relative differences of l2 norm of the hllc scheme between the other two schemes are used to discover the accuracy among the schemes used 3 1 case a flows with hydraulic jumps and hydraulic drops case a involves flows over planes with hydraulic jumps and drops this case was originally studied by zhou and stansby 1999 the computational domain is composed of two planes the first plane on the left is a rectangle with 14 5 m long and 1 4 m width and the second plane on the right is a rectangle with 16 m long and 1 4 m width the slopes of the first and second planes are 0 and 0 03 respectively the left edge of the computational domain is used for the inflow boundary condition with u 3 571 m s v 0 m s and d 0 54 m no outflow boundary condition is required to be given since the outflow is in supercritical flows due to the steep slope of the second plane the inflow and outflow are both in supercritical flows so the flows change from supercritical into subcritical through hydraulic jumps and then returning backs to supercritical through hydraulic drops the simulated results of water depths and velocities by zhou and stansby 1999 are herein used as the exact solution initially the computational domain is dry the simulation lasts for 600 s to let the flow regime become steady the computational domain is discretized by square cells the length of each square cell is 0 145 m thus there are 2 110 cells the manning roughness coefficient is 0 019 s m1 3 suggested by zhou and stansby 1999 to focus on the numerical performances in the proximity of the hydraulic jumps and hydraulic drops only data with its x coordinate being between 5 m and 15 m is adopted to calculate l2 norms for water depths and velocities at t 600 s thus each l2 norm is determined by 690 uniformly distributed data to calibrate δ several simulations by the proposed hybrid approach with various δ are carried out for simplicity we only present the simulated results of the proposed hybrid approach with δ 1 2 and 3 the simulated profiles of water levels and velocities along x axis are displayed in figs 2 a and 2b respectively the exact solution is also given in these two figures the domain where the data is used for calculating l2 norm is depicted as l2 norm test domain in fig 2a from figs 2a and 2b the simulated profiles of water levels and velocities by the rusanov scheme are both relatively smooth in regions where the hydraulic jump and drop locate the simulated results by the hllc scheme and the proposed approach with δ 1 and 2 are all in good agreement with the exact solution whereas the simulated results by the proposed hybrid approach with δ 3 exist significant differences in the proximity of the hydraulic jump the comparison of numerical accuracy among all the schemes used is listed in table 1 the relative differences of l2 norms for water depths and velocities between the rusanov and hllc schemes are 18800 00 and 982200 00 respectively as for the proposed hybrid approach with δ 1 and 2 the relative differences of l2 norms for water depths and velocities between them and the hllc scheme are all 0 01 however the relative differences of l2 norms for water depths and velocities between the proposed approach with δ 3 and the hllc scheme are 100 00 and 200 00 respectively thus the proposed hybrid approach with δ 1 and 2 can accurately simulate the hydraulic jumps and hydraulic drops which also demonstrates the correctness of the proposed hybrid approach as a result δ is suggested to be 1 and 2 by the comparison of numerical accuracy in case a 3 2 case b subcritical flows over an undulating bed elevation the flow conditions in case b represent steady subcritical flows over a rugged floodplain the exact solution provided by macdonald et al 1997 is utilized to calibrate δ the computational domain is a rectangle with a length of 120 m and a width of 10 m the upstream boundary is prescribed on the left edge with the time invariant inflow as 20 m3 s and the downstream boundary is set on the right edge with the time invariant exact depth initially the computational domain is filled with the exact depths the simulation lasts for 600 s to let the flow regime become steady again the whole domain is discretized by square cells with a cell size of 0 4 m there are thus 7 826 cells the manning roughness coefficient is given as 0 03 s m1 3 macdonald et al 1997 all data within the computational domain is used to calculate l2 norms for water depths and velocities at t 600 s thus each l2 norm is determined by 7 826 data uniformly distributed in the computational domain a number of runs are carried out to perform the parameter calibration of δ here we show the simulated results of the proposed approach with δ being as 1 2 and 3 for the sake of demonstration the simulated profiles of water levels and velocities along x axis are displayed in figs 3 a and 3b respectively the exact solutions of water levels and velocities are plotted in the figures as well from these figures the simulated profiles by the proposed approach with δ as 1 and 2 and the hllc scheme are all in agreement with the exact solutions the simulated results by the rusanov scheme and the proposed hybrid approach with δ 3 are very similar but they all exist obvious differences from the exact solutions the comparison of numerical accuracy among all the schemes used is presented in table 1 the relative differences of l2 norms for water depths and velocities between the rusanov and hllc schemes are 500 00 and 1550 00 respectively in consideration with the proposed hybrid approach with δ 1 and 2 the relative differences of l2 norms for water depths and velocities between them and the hllc scheme are all 0 01 and this result is quite satisfactory as to the proposed approach with δ 3 the relative differences of l2 norms between it and the hllc scheme are both 500 00 thus it is concluded that the proposed hybrid approach can have almost the same accuracy as the hllc scheme with δ to be 1 and 2 3 3 case c dam break flows on dry bed condition case c refers to dam break flows on dry bed condition with moving wet dry interfaces toro 2001 the computational domain is a rectangle and the length and width of it are 50 m and 5 m respectively the surface is frictionless initially there are two reservoirs separated by a dam locating at 10 m along x direction the water depths on the left and right reservoirs are given as 0 08 m and 0 m respectively and the water velocities in the left and right reservoirs are 1 0 m s and 0 0 m s respectively the water depth on the left reservoir and the velocity in the left reservoir are given to introduce supercritical flows in the entire computational domain at the beginning of the simulation the dam is broken immediately left critical rarefactions or called as depression waves propagate upstream and the tails of them move downstream as moving wet dry interfaces the exact solution is determined by utilizing the exact riemann solver toro 2001 trans missive boundary conditions are prescribed on the left and right edges the simulation lasts for 4 s the computational domain is discretized by square cells with a cell size of 0 1 m and thus there are 25 000 cells the simulated profiles of water depths and velocities at t 4 s are utilized to calculate l2 norms for water depths and velocities respectively to focus on the numerical performance in regions where major differences between the rusanov and hllc schemes are observed each l2 norm is determined by using data with its x coordinate being from 8 m to 12 m the left l2 norm test domain with the rarefactions or from 18 m to 22 m the right l2 norm test domain with the moving wet dry interfaces as a result each l2 norm is calculated by 4 000 data that is uniformly distributed within the selected domains several runs of the proposed approach with various δ are carried out for the parameter calibration of δ here the simulated results of the proposed approach with δ 1 2 and 3 are presented the simulated profiles of water depths and velocities along x axis are drawn in figs 4 a 4b respectively the exact solution is displayed in figs 4a and 4b as well the simulated profiles of water depths and velocities by the rusanov scheme are relatively smooth in the left and right l2 norm test domains the hllc scheme and the proposed hybrid approach with δ 1 and 2 all give relatively better predictions and their simulated results are very similar the major difference in the simulated profiles of the proposed hybrid approach between δ 2 and 3 is observed in the left l2 norm test domain in the right l2 norm test domain the three proposed hybrid approach and the hllc scheme give almost the same simulated results the comparison of numerical accuracy among the schemes used is depicted in table 1 the relative differences of l2 norms for water depths and velocities between the rusanov and hllc schemes are 237 50 and 15 73 respectively as to the proposed hybrid approach with δ 1 and 2 the relative differences in l2 norms for water depths and velocities between them and the hllc scheme are all 0 01 with respect to the proposed approach with δ 3 the relative differences of l2 norms for water depths and velocities between it and the hllc scheme are 25 00 and 0 02 respectively as a result the above results indicate that the proposed hybrid approach can accurately simulate dam break flows involving moving wet dry interfaces as δ is 1 and 2 in summary from all the three cases in this section the best value of δ is given as 2 this value is then used for the rest simulations in the manuscript 4 model verification and efficiency assessment in this section the proposed hybrid approach is evaluated through experimental measurements to compare its numerical accuracy and efficiency to the rusanov and hllc schemes through three benchmark cases each case represents distinct overland flow features that commonly happen in rural and urban areas case 1 refers to rainfall runoff around buildings that commonly occurs in rural and urban areas case 2 is flash floods towards buildings discharge flows this flow condition is also commonly seen both in rural and urban areas case 3 represents street flows in urban areas as the numerical accuracy is demonstrated to be satisfactory through case 1 to 3 an extension of case 3 as the street junction flows with various slopes is used to discover how fast the proposed hybrid approach can be within these case studies significant discontinuities such as hydraulic jumps hydraulic drops and wet dry interfaces in strong discontinuous flows all occur the comparison of numerical accuracy is performed by l2 norm eq 21 as to numerical efficiency the total cpu times of the hllc scheme and the proposed hybrid approach are all recorded although the rusanov scheme is the simplest and fastest scheme in this study the numerical accuracy of it is the worst among the three schemes thus the relative difference of total cpu times between the hllc scheme and the proposed hybrid approach is utilized to investigate the numerical efficiency of the proposed approach and it is 22 t hllc t hybrid t hybrid in which thllc and thybrid are the total cpu times of the hllc scheme and the proposed hybrid approach respectively in the proposed hybrid approach each cell interface adopts either the rusanov scheme or the hllc scheme according to its identified flow condition at each time step to identify the relative usage between the rusanov and hllc schemes in each case the ratio of the hllc scheme used is recorded at each time step the ratio of the hllc scheme used is the count of the cell interfaces using the hllc scheme divided by the total count of cell interfaces this ratio has a positive correlation to the portion of strong discontinuous flows the larger the portion of strong discontinuous flows is the higher the ratio of the hllc scheme used is and hence the less the improvement on numerical efficiency of the proposed approach is theoretically when the ratio of the hllc scheme used equals to 1 the proposed hybrid approach is the same as the hllc scheme but with additional cpu time to perform the hybrid procedure 4 1 case 1 rainfall runoff around buildings case 1 is an experiment of rainfall runoff around buildings cea et al 2010 representing a typical rainfall runoff process in rural and urban areas among several configurations provided by cea et al 2010 the s20 configuration a staggered configuration of buildings is herein selected for the numerical verification three planes with approximate slope as 0 05 comprise the 2 m 2 5 m computational domain the topography and buildings layout are presented in fig 5 a the material of the computational domain is stainless steel infiltration is not considered since the bed surface is impervious rainfall was simulated by 100 evenly distributed nozzles buildings were represented by small blocks with size as 30 cm 20 cm each block has four vertical walls with height as 20 cm and roof with slope as 45 the bottom edge was designed to be the outlet of basin while the other three edges were closed fig 5a outflow hydrograph at the outlet of basin was measured since the water depths are extremely small within the basin no water depth measurement was provided three rainfall durations 20 40 and 60 s and three rainfall intensities 84 180 and 300 mm hr give nine rainfall hyetographs in the experiment in the present study among the nine rainfall hyetographs q25t20 and q25t60 rainfall hyetographs are herein selected as the two numerical scenarios for the model verification in case 1 the rainfall durations of q25t20 and q25t60 scenarios are 20 and 60 s respectively the rainfall intensities of the two scenarios are both 300 mm hr and the total simulation durations of the two scenarios are both 200 s the computational domain is discretized by square cells with cell size as 1 cm in total there are 50 000 cells buildings are represented in the model by raising the elevation of cells where the buildings locate the manning roughness coefficient is 0 016 s m1 3 by cea et al 2010 there are 200 cells at the outlet of basin the simulated outflow hydrographs at the outlet of basin are derived by summing up the outflow hydrographs of the 200 cells for each observed time totally the outflow hydrograph contains 10 893 measured data during the event and they are all used to compute l2 norm for outflow hydrograph the simulated and experimental outflow hydrographs for q25t20 and q25t60 scenarios are displayed in figs 5b and 5c respectively inspection of figs 5b and 5c reveals that the simulated peak discharges by the rusanov scheme are lower than the measured data since it theoretically gives relatively smooth profiles of water depths and velocities in the presence of strong discontinuous flows by contrast the simulated results of the proposed hybrid approach and the hllc scheme both exhibit better agreement with the experimental data the comparison of numerical accuracy and efficiency among the three schemes is summarized in table 2 from numerical accuracy viewpoint the relative differences of l2 norms between the rusanov and hllc schemes in the two scenarios are 35 50 and 26 67 respectively and the relative differences of l2 norms between the proposed hybrid approach and the hllc scheme in the two scenarios are 2 96 and 0 01 therefore the proposed approach has much better performance on numerical accuracy than the rusanov scheme and it can provide as accurate results as the hllc scheme as to numerical efficiency viewpoint the relative differences of total cpu times between the hllc scheme and the proposed hybrid approach in the two scenarios are 21 73 and 16 46 respectively this result is quite satisfactory nevertheless how fast the proposed approach can achieve depends on flow conditions of the computational domain at each time step as the computational domain contains small portion of strong discontinuous flows the proposed hybrid approach can deliver noticeable improvement on numerical efficiency in spite of the additional cpu time to perform the hybrid procedure the ratios of the hllc scheme used at each time step in the two scenarios are displayed in fig 5d since the rainfall duration of q25t60 scenario is larger than that of q25t20 scenario there are more strong discontinuous flows in q25t60 scenario than q25t20 scenario in q25t60 scenario the hllc scheme is used more frequently fig 5d and the proposed approach has less improvement on its numerical efficiency thus it is confirmed that the larger the portion of strong discontinuous flows is the less the numerical efficiency improvement of the proposed approach is through the above analysis the proposed approach has the same numerical accuracy as the hllc scheme but in terms of numerical efficiency it outperforms the hllc scheme by 16 46 21 73 therefore the proposed hybrid approach is shown to maintain good accuracy and to provide significant improvement on computational efficiency in case 1 moreover when the portion of strong discontinuous flows is increased the improvement on numerical efficiency of the proposed approach is decreased it is also demonstrated that the corrections of strong discontinuous flows can consequently recover the simulated results at the outlet of basin 4 2 case 2 flash floods towards buildings discharge flows the second case represents flash floods towards buildings discharge flows which was carried out by impact and cadam projects testa et al 2007 the physical model of this experiment was scaled down from the toce river valley in italy 100 times low medium and high inflow hydrographs were tested in the experiment cubic concrete blocks representing buildings with side length as 0 15 m were placed in the computational domain in the aligned or staggered configurations original valley geometry and modified valley geometry of terrain were both investigated in the experiment thus there are twelve experimental combinations ten water depths measurement gauges were placed in to record time varied water depths in this case verification we adopt the aligned buildings layout with the original valley geometry as the simulation case see fig 6 a for details three inflow hydrographs are all considered fig 6b so that there are three scenarios used low medium and high inflow hydrographs the total simulation durations are 60 s for all the three scenarios the simulated domain is discretized by square cells and the cell size of each square cell is 2 5 cm totally there are 54 964 cells buildings are represented by raising the elevation 0 15 m of cells where the buildings locate the manning roughness coefficient is suggested to be 0 0162 s m1 3 by testa et al 2007 the measured water depths during the experiment at gauges p3 to p10 are used to calculate l2 norm for water depth costabile et al 2017 the positions of the water depths measurement gauges are given in fig 6a totally there are 2 408 measured data during the event to compute l2 norm for water depth figs 6c 6d and 6e depict the simulated and experimental profiles of water depths at gauges p3 to p10 for low medium and high inflow scenarios respectively in these figures the proposed hybrid approach and the hllc scheme both yield accurate results that match the measured data well whereas the simulated profiles provided by the rusanov scheme have relatively large discrepancies l2 norms and total cpu times of the three schemes are depicted in table 3 with respect to numerical accuracy the proposed hybrid approach shows its capability to deal with various strong discontinuous flows as shown in figs 6c 6d and 6e in table 3 the relative differences of l2 norms between the rusanov and hllc schemes in the three scenarios are 16 94 58 47 and 70 74 respectively and the relative differences of l2 norms between the proposed hybrid approach and the hllc scheme are 0 90 0 01 and 0 96 respectively apparently the proposed approach performs much better on numerical accuracy than the rusanov scheme and it is as accurate as the hllc scheme in consideration of numerical efficiency the relative differences of total cpu times between the hllc scheme and the proposed hybrid approach in the three scenarios are 17 42 16 33 and 15 74 respectively hence despite the additional cpu time required to execute the hybrid procedure the numerical efficiency improvement of the proposed approach in case 2 is significant the ratios of the hllc scheme used during the simulations in the three scenarios are displayed in fig 6f in fig 6f the portion of the strong discontinuous flows is increased as the inflow discharge is higher the high inflow scenario has the highest inflow discharge the largest ratio of the hllc scheme used in the simulations displayed in fig 6f and the least improvement on numerical efficiency of the proposed hybrid approach by contrast the low inflow scenario has the lowest inflow discharge the smallest ratio of the hllc scheme used presented in fig 6f and the highest improvement on numerical efficiency hence it is proved that the improvement on numerical efficiency of the proposed approach has a negative correlation to the portion of strong discontinuous flows figs 6c 6d and 6e and table 3 reveal that in all the three scenarios the proposed hybrid approach is as accurate as the hllc scheme but it is 15 74 17 42 faster than the hllc scheme thus the proposed approach has the ability to handle complicated flow conditions in case 2 accurately and efficiently moreover the proposed hybrid approach can be more efficient when the portion of strong discontinuous flows is smaller 4 3 case 3 street junction flows the third case study represents transcritical flow conditions like hydraulic jumps and wet dry interfaces in a 90 four branch street junction nania et al 2011 see fig 7 a for details two sloped open channels representing two roads are intersected in a horizontal square zone the slopes of channels aligned with x axis and y axis are 0 01 m m and 0 02 m m respectively the inflow discharges for two channels were q in x 0 0429 m3 s and q in y 0 1 m3 s respectively surfaces of both channels were made of concrete the flow is subcritical in the inlet of the channel aligned with x axis and supercritical in the inlet of the channel aligned with y axis under such a condition hydraulic jumps are formed in the junction the flows in the two channels both return to supercritical after the junction after the flow regime became steady experimental water depths and velocities were measured along x 0 675 m and y 0 675 m initially the computational domain is completely dry the total simulation duration is given as 200 s to let the flow regime become completely steady the entire simulation domain is discretized by square cells with a cell size of 5 cm as a consequence there are 8 700 cells the manning roughness coefficient is given as 0 016 s m1 3 because of the concrete surface after the simulation starts the water comes from the two inlets and moves along the channels with moving wet dry interfaces hydraulic jumps then form at the junction right after the flows from the two inlets collide with each other apart from the junction flow conditions in two channels return to supercritical flows thus with such simulation settings strong discontinuous flows occur the simulated water depths at t 200 s along x 0 675 m and y 0 675 m are used together with the measured data to calculate a single l2 norm for water depths and the simulated velocities at t 200 s along x 0 675 m and y 0 675 m are adopted together to calculate a single l2 norm for water velocities thus there are 123 measured data utilized to determine each l2 norm the simulated water depths and velocities at t 200 s along x 0 675 m and y 0 675 m are all shown in fig 7b the measured data of nania et al 2011 is plotted in fig 7b as well from fig 7b the proposed hybrid approach and the hllc scheme both have better prediction than the rusanov scheme the comparison of numerical accuracy and efficiency among the three schemes is summarized in table 4 it can be clearly seen from fig 7b that the hllc scheme and the proposed hybrid approach both simulate sharper profiles of water depths and velocities compared to those of the rusanov scheme this means that the proposed hybrid approach and the hllc scheme both have better capability to deal with strong transcritical flows compared to the rusanov scheme as a result in terms of numerical accuracy the relative differences of l2 norms for water depths and velocities between the rusanov and hllc schemes are 17 50 and 20 97 respectively and those between the proposed hybrid approach and the hllc scheme are 0 83 and 0 37 respectively as to numerical efficiency the relative difference of total cpu times between the hllc scheme and the proposed hybrid approach is 13 71 hence the proposed approach is proved to efficiently handle strong discontinuous flows in case 3 regardless of the additional cpu time to run the hybrid procedure it is apparent from the results in fig 7b and table 4 that the proposed hybrid approach has good ability to handle strong transcritical flows it can maintain good local accuracy as the hllc scheme but regarding numerical efficiency it outperforms the hllc scheme by 13 71 therefore the proposed approach can accurately and efficiently deal with such strong transcritical flows in case 3 4 4 extension of case 3 street junction flows with various slopes in subsections 4 1 4 3 the numerical performances on accuracy and efficiency of the proposed hybrid approach have been verified through three benchmark cases it is concluded that the proposed approach can be at most 13 71 21 73 faster than the hllc scheme with providing almost the same accuracy as a result the proposed approach has proved its capability to accurately and efficiently handle such complicated flow conditions in the previous benchmark case studies nevertheless the proposed approach needs additional cpu time to perform the hybrid procedure at each time step as the accuracy of the solver is demonstrated to be satisfactory the next issue is about how fast the solver can be generally speaking how efficient the proposed hybrid approach can reach in each case depends on flow conditions involved as the computational domain has a relatively small part of strong discontinuous flows the proposed approach should be more efficient to confirm this idea a model efficiency assessment extended from case 3 is next conducted to discover how fast the proposed approach can go the numerical accuracy among the three schemes are thus not compared the extended case adopts the layout of case 3 in the original layout the slopes of channels aligned with x axis and y axis are 0 01 m m and 0 02 m m respectively in this extension the slopes of the two channels are both decreased by the same factor in order to slow down water velocities six factors are used as 1 2 3 1 3 1 6 1 12 and 1 24 thus giving six sets of slopes for different flow conditions it is expected to decrease the portion of strong discontinuous flows as the slopes are decreased other simulation settings are the same as in case 3 the comparison of numerical efficiency among the three schemes is depicted in table 5 in the table the relative differences of total cpu times between the hllc scheme and the proposed hybrid approach in the six slopes are 13 71 15 87 17 26 25 14 34 59 and 40 27 respectively it can be clearly confirmed from table 5 that numerical efficiency is increasing as the slope is decreasing the proposed approach can at most be 40 27 faster than the hllc scheme demonstrating its ability to provide significant reduction on the computational time the ratios of the hllc scheme used in the six slopes are presented in fig 7c as the slopes of the two channels are decreased slowing down water velocities the portion of strong discontinuous flows is decreased inspection of fig 7c reveals that the ratio of the hllc scheme used is decreased as the slope is decreased furthermore it can be seen from table 5 that the milder the slopes are the higher the improvement on numerical efficiency of the proposed approach can be therefore how efficient the proposed approach can reach depends on flow conditions involved the proposed approach is more efficient than the hllc scheme as the portion of strong discontinuous flows in the computational domain is relatively smaller 4 5 analysis of additional cpu time the additional cpu time mentioned in subsections 4 1 4 4 is the cpu time used for performing the hybrid procedure in the proposed approach this extra overhead can significantly influence the numerical efficiency of the proposed approach hence the codes of the proposed hybrid approach are written to sum the additional cpu time for executing the hybrid procedure of each case in subsections 4 1 4 4 the additional cpu time is then divided by the total cpu time of the proposed hybrid approach tables 2 5 to give the ratio of the additional cpu time moreover the time varied ratio of the hllc scheme used in each case study shown in figs 5d 6f and 7c is integrated over time and then divided by the total simulation duration to give the averaged ratio of the hllc scheme used the calculated results are all displayed in table 6 from table 6 the additional cpu time is between 1 2 and 4 5 s and the ratios of the additional cpu time are between 4 27 and 13 71 therefore the hybrid procedure is proved to be efficient as the ratios of the additional cpu time are acceptable also it is deduced that the proposed hybrid approach can be more efficient if the additional cpu time is further lowered taking q25t20 scenario in case 1 as an example although it takes 3 2 s 4 27 as the additional cpu time to perform the hybrid procedure there is still 16 3 s 21 73 saved by using the proposed approach compared to the hllc scheme hence if the additional cpu time can be minimized the proposed hybrid approach can save at most 19 5 s 26 00 from the hllc scheme with the same accuracy finally it is concluded from table 6 that the ratio of the additional cpu time is independent of cells number and total simulation duration it is proportional to the averaged ratio of the hllc scheme used 5 future work discussion through all of the case studies in the manuscript the proposed hybrid procedure is demonstrated to be a useful framework to incorporate the two finite volume schemes the two schemes for fluxes and the reconstruction method for the riemann states at cell edges can all be replaced with other selections according to the problems considered table 7 depicts some numerical schemes that can be possibly used by the proposed approach among them this study adopts the rusanov scheme with the cn method for regular flows and the hllc scheme with the cn method for strong discontinuous flows to construct the proposed hybrid approach in particular the hllc scheme is adopted because of its popularity in 2d overland flow modeling modelers can adopt different numerical schemes such as the rusanov scheme with the cn method for regular flows and the hllc scheme with the tvd version of the muscl hancock method for strong discontinuous flows to establish the unique hybrid shallow water solver for specific hydraulic engineering problems 6 conclusions in this manuscript a hybrid shallow water equations solver for modeling overland flows in rural and urban areas is proposed this hybrid approach switches the solver to be used based on the local flow conditions according to the sharpness of discontinuity a low accuracy high efficiency scheme the rusanov scheme is utilized in regular flows whereas a high accuracy low efficiency scheme the hllc scheme is adopted in strong discontinuous flows regions that simultaneously adopt the two schemes are artificially specified to diminish artificial numerical unbalances of the two schemes model calibration is carried out through three cases with the exact solutions the proposed hybrid approach is then verified through three benchmark cases which represent flow conditions that commonly happen in surface runoff propagation in rural and urban areas including rainfall runoff around buildings flash floods towards buildings discharge flows and street flows in junction based on the comparison of numerical accuracy and efficiency among the three schemes from numerical accuracy viewpoint the proposed hybrid approach has the same accuracy as the hllc scheme for all the three cases as for numerical efficiency viewpoint it can provide significant improvement on computational efficiency compared to the hllc scheme at most 13 71 21 73 faster than the hllc scheme for the three benchmark cases the proposed hybrid approach is demonstrated to show its capability for maintaining similar accuracy as the hllc scheme with significant reduction on its computational time nevertheless the proposed approach requires additional cpu time to perform the hybrid procedure at each time step as summarized in table 6 the ratios of the additional cpu time to the total cpu time are between 4 27 and 13 71 how efficient the proposed approach can achieve depends on flow conditions involved in each case a model efficiency assessment extended from the benchmark case involing street flows in junction is hence conducted to test six different flow conditions which confirms that the proposed hybrid approach can be at most 40 27 faster than the hllc scheme the improvement on numerical efficiency is increased as the portion of strong discontinuous flows in the computational domain is smaller finally the major outcome of this research is that we develop a hybrid solver to comprise low accuracy high efficiency and high accuracy low efficiency schemes for various overland flow conditions other finite volume schemes that can be possibly used by the proposed hybrid approach are also listed in table 7 speed up techniques such as local time stepping and parallelization can also be utilized in the proposed approach therefore the hybrid solver has considerable potentials to be a useful tool in flood inundation simulations credit authorship contribution statement hsiang lin yu conceptualization methodology software validation formal analysis investigation data curation visualization writing original draft writing review editing tsang jung chang conceptualization methodology validation writing original draft supervision writing review editing project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the accomplishment of this work is partially supported by the ministry of science and technology taiwan under grant nos 109 2221 e 002 010 my3 and 109 2625 m 002 010 the authors are grateful for the support 
4553,this study aims to present an accurate and efficient finite volume approach for overland flow modelling in rural and urban areas through solving the two dimensional shallow water equations the proposed approach introduces a hybrid procedure that utilizes the sharpness of discontinuity to identify flow conditions in the entire computational domain and then a low accuracy high efficiency scheme the rusanov scheme is used in regular flows whereas a high accuracy low efficiency scheme the hllc scheme is adopted in strong discontinuous flows regions that simultaneously adopt the two schemes are artificially specified to diminish numerical unbalances between the two schemes model calibration is carried out through three strong discontinuous flow cases with the exact solutions model verification is next described by three benchmark cases including rainfall runoff around buildings flash floods towards buildings and street junction flows model efficiency assessment is also conducted to present the numerical efficiency improvement of the proposed approach for various flow conditions technical attention is devoted to the numerical performances on local accuracy and global efficiency of the proposed approach the simulated results indicate that the proposed approach can simulate as accurate as the hllc scheme with significant reduction on its computational time how efficient the proposed hybrid approach can reach depends on flow conditions involved it is more efficient than the hllc scheme as the portion of strong discontinuous flows in the computational domain is relatively smaller the proposed approach has proved its accuracy and efficiency for overland flow modeling and it can also be used together with other speed up techniques such as local time stepping and parallelization to improve its efficiency other finite volume schemes can also be utilized to improve the efficiency and accuracy of the proposed approach therefore the solver has considerable potentials as a useful tool in flood inundation simulations keywords shallow water equations overland flow in rural and urban areas finite volume method hybrid approach the rusanov scheme the hllc scheme 1 introduction flood is one of the most common natural disasters in the world it can be generally classified into three main types as fluvial pluvial and coastal floods chow et al 2013 as modeling these three types of floods an overland flow module is always a key element to connect with river flow storm sewer flow and storm surge modules respectively thus overland flow modeling is essential for any types of flood inundation modeling chang et al 2015 2018 overland flow is an important process of the hydrologic cycle basically it is runoff that occurs on land surface before reaching a channel chow et al 2013 the two dimensional shallow water equations the 2d swes are widely adopted to analyze overland flow dynamics castro orgaz and hager 2019 mathematically the 2d swes are the depth averaged version of the three dimensional navier stokes equations which are a time dependent set of nonlinear hyperbolic partial differential equations with a topography source term in the past two decades varieties of numerical methods have been introduced in modeling shallow water overland flows castro orgaz and hager 2019 have extensive summary on this topic among various numerical methodologies due to its enhanced capability in dealing with flow transition the finite volume method is so far the most commonly used modeling method to solve the 2d swes toro 2001 many finite volume strategies mostly originated from shock capturing techniques in aerodynamics have been applied to shallow water hydraulics such as the approximate riemann schemes bradford and sanders 2002 soares frazão et al 2008 nikolos and delis 2009 the godunov type schemes liang et al 2008 sanders et al 2008 abderrezzak et al 2009 kim et al 2009 costabile et al 2017 xia et al 2017 sanders and schubert 2019 the roe scheme rogers et al 2003 ferrari et al 2017 martins et al 2018 the total variation diminishing tvd scheme liang et al 2007 bai et al 2018 khoperskov and khrapov 2018 the simplified scheme e g the dhd scheme by cea and bladé 2015 etc recently some matured finite volume schemes have been further implemented on the gpu framework for full scale flood modeling xia et al 2019 aureli et al 2020 it should be noted that the godunov type and roe schemes are widely used to establish shallow water solvers toro 2001 in particular first order modules of the hllc and roe schemes have recently been applied to field scale flood inundation modeling martins et al 2017 the aforementioned hllc and roe schemes are noteworthy for their strong abilities to improve the numerical accuracy of handling transcritical flows as well as wet dry interfaces toro 2001 overland flow dynamic may change rapidly due to various situations such as terrain alternation sudden overtopping inflow that introduce strong discontinuities in flow conditions chang et al 2014 2016 however not all of overland flow computations involve such complicated flow conditions numerical accuracy and efficiency are often going with the opposite way castro orgaz and hager 2019 the above accurate schemes requiring heavy numerical procedures are not economically suitable for modeling regular flows that have relatively smooth profiles of water depths and velocities in overland flows as evaluating the numerical performances of various overland flow models accuracy and efficiency are both crucial a hybrid approach that is capable of analyzing complicated flow conditions with high accuracy low efficiency schemes and simulating regular flows with low accuracy high efficiency schemes is not yet available for a wide range of flood modelling applications to fill this gap the main objective of the study is to develop a novel hybrid finite volume method for balancing the modes of numerical accuracy and efficiency in 2d overland flow computation a hybrid procedure is proposed to incorporate the rusanov and hllc schemes the sharpness of discontinuity is used to identify flow condition of each cell interface in the entire computational domain flow conditions are divided into strong discontinuous flows with significant variations in water depths and velocities and regular flows other than strong discontinuous flows as considering strong discontinuous flows the hllc scheme is adopted and the rusanov scheme is used in regular flows regions that simultaneously utilize the two schemes are also artificially specified to diminish numerical unbalances between the two schemes model calibration is carried out by three strong discontinuous flow cases with the exact solutions the proposed hybrid approach is then verified by three benchmark cases including rainfall runoff around buildings flash floods towards buildings and street junction flows to demonstrate the strength and limitation of the methodology model efficiency assessment is also conducted to present the numerical efficiency improvement of the proposed approach for various portions of strong discontinuous flows in the computational domain technical attention is devoted to the numerical performances on local accuracy and global efficiency of the proposed approach 2 hybrid shallow water solver 2 1 governing equations the conservative form of the two dimensional shallow water equations the 2d swes with source terms can be written in a vector form as toro 2001 kao and chang 2012 1 u t f u x g u y r s b s f where 2 u h hu hv f u hu u 2 h 1 2 g h 2 huv g u hv huv v 2 h 1 2 g h 2 r r 0 0 s b 0 g h z b x g h z b y s f 0 g n 2 u u 2 v 2 h 1 3 g n 2 v u 2 v 2 h 1 3 in which t is the time x and y are the coordinates h is the water depth u and v are the x and y components of the depth averaged velocity respectively r is the effective rainfall intensity total rainfall intensity minus infiltration rate z b is the bed elevation n is the manning roughness coefficient g is the gravitational acceleration 9 81 m s2 u is the vector of conserved flow variables f u and g u are the flux vectors in the x and y directions respectively s b and s f are the bed slope and friction slope vectors respectively 2 2 numerical discretization in the present study the first order upwind godunov type finite volume scheme is used to conduct the spatial discretization and the first order forward euler scheme is adopted to perform the temporal discretization hence the discretized form of eq 1 on cartesian cells can be given as 3 u i j s 1 u i j s δ t l f i 1 2 j s f i 1 2 j s g i j 1 2 s g i j 1 2 s δ t r i j s s b i j s s f i j s 1 where subscripts i and j denote the x and y cell indexes of the cell respectively s and s 1 denote the current and next steps respectively l is the cell size δ t is the time step f i 1 2 j s f i 1 2 j s g i j 1 2 s and g i j 1 2 s are the flux vectors at the left right bottom and top cell edges respectively the hybrid shallow water solver in this study is established by solving eq 3 to calculate the flux vectors f i 1 2 j s f i 1 2 j s g i j 1 2 s and g i j 1 2 s and the bed slope vector s b i j s in eq 3 the reconstruction of the riemann states at cell edges is required the correctness of reconstructing riemann states at cell edges can significantly influence the accuracy of the scheme audusse et al 2004 xia et al 2017 this study adopts the first order cn reconstruction method proposed by chen and noelle 2017 considering a cell interface at i 1 2 j and its two adjacent cells i j and i 1 j along the x direction the bed elevation at the cell interface is first reconstructed by 4 z b i 1 2 j s min max z b i j z b i 1 j min z b i j h i j s z b i 1 j h i 1 j s and the reconstructed water depths at the left hand and right hand sides of the cell interface are given as 5 h i 1 2 j l s min z b i j h i j s z b i 1 2 j s h i j s h i 1 2 j r s min z b i 1 j s h i 1 j s z b i 1 2 j s h i 1 j s positivity of water depth is preserved since the reconstructed bed elevation at the cell interface by eq 4 is less than or equals to the minimum of the two water surface levels chen and noelle 2017 as for the velocities at the left hand and right hand sides they are 6 u i 1 2 j l s u i j s u i 1 2 j r s u i 1 j s 2 2 1 discretization of the flux vectors the four flux vectors f i 1 2 j s f i 1 2 j s g i j 1 2 s and g i j 1 2 s in eq 3 are discretized explicitly xia and liang 2018 the rusanov and hllc schemes that are regarded to be in the same category of approximated riemann schemes toro 2001 are interchangeably used to calculate the four flux vectors by utilizing the reconstructed water depths and velocities the two schemes are briefly introduced next there are several hllc schemes and the present study adopts the version provided by toro 2001 in this hllc scheme the left middle and right characteristic wave speeds are considered when determining the flux vectors several procedures are introduced to give the estimations of the three characteristic wave speeds toro 2001 specifically in the presence of wet dry interfaces this hllc scheme utilizes the exact solution of the dry bed problem to determine these characteristic wave speeds the determinations of the four flux vectors are expressed by taking the flux vector f i 1 2 j s as an example 7 f i 1 2 j s f i 1 2 j l s 0 c i 1 2 j l s f i 1 2 j l s c i 1 2 j l s 0 c i 1 2 j m s f i 1 2 j r s c i 1 2 j m s 0 c i 1 2 j r s f i 1 2 j r s c i 1 2 j r s 0 with 8 f i 1 2 j l s f i 1 2 j l s c i 1 2 j l s u i 1 2 j l s u i 1 2 j l s f i 1 2 j r s f i 1 2 j r s c i 1 2 j r s u i 1 2 j r s u i 1 2 j r s u i 1 2 j l s u i 1 2 j r s u i 1 2 j l s and u i 1 2 j r s are 9 u i 1 2 j l s h i 1 2 j l s hu i 1 2 j l s hv i 1 2 j l s u i 1 2 j r s h i 1 2 j r s hu i 1 2 j r s hv i 1 2 j r s u i 1 2 j l s h i 1 2 j l s c i 1 2 j l s u i 1 2 j l s c i 1 2 j l s c i 1 2 j m s 1 c i 1 2 j m s v i 1 2 j l s t u i 1 2 j r s h i 1 2 j r s c i 1 2 j r s u i 1 2 j r s c i 1 2 j r s c i 1 2 j m s 1 c i 1 2 j m s v i 1 2 j r s t in eq 7 c i 1 2 j l s c i 1 2 j m s and c i 1 2 j r s are the left middle and right characteristic wave speeds respectively f i 1 2 j l s and f i 1 2 j r s are the flux vectors determined by the reconstructed variables water depths and velocities at the left hand and right hand sides of the cell interface respectively as to the rusanov scheme it can be seen as a simplified version of the hllc scheme toro 2001 the left and right characteristic wave speeds have the same magnitude with opposite signs whereas the middle waves are not considered rusanov 1961 toro 2001 considering two adjacent cells i j and i 1 j along the x direction and their common cell interface as an example the flux vector f i 1 2 j s is given as 10 f i 1 2 j s 1 2 f i 1 2 j l s f i 1 2 j r s 1 2 c i 1 2 j s u i 1 2 j r s u i 1 2 j l s where 11 c i 1 2 j s max u i 1 2 j l s g h i 1 2 j l s u i 1 2 j r s g h i 1 2 j r s 2 2 2 discretization of the bed slope vector to compute a constant free surface level when water is at rest velocities are zero an exact balance between the bed slope and the hydrostatic water pressure gradient should be maintained the well balanced property or the so called c property the bed slope vector in eq 3 is discretized explicitly as chen and noelle 2017 12 s b i j s 0 g 2 l h i j s h i 1 2 j l s z b i j z b i 1 2 j s h i j s h i 1 2 j r s z b i j z b i 1 2 j s g 2 l h i j s h i j 1 2 l s z b i j z b i j 1 2 s h i j s h i j 1 2 r s z b i j z b i j 1 2 s this formula is proved to preserve the well balanced property chen and noelle 2017 2 2 3 discretization of the friction slope vector the friction slope vector s f i j s 1 is discretized by a semi implicit scheme as cea et al 2010 rousseau et al 2015 13 s f i j s 1 0 g n 2 q s q x s 1 h 7 3 s i j g n 2 q s q y s 1 h 7 3 s i j t where q x and q y are defined as hu and hv respectively q s q x s 2 q y s 2 the semi implicit friction slope discretization is used herein to avoid the numerical instability when the water depth tends to zero rousseau et al 2015 2 2 4 stability criterion the stability criterion of the hybrid shallow water solver is the courant friedrichs lewy cfl condition given as 14 δ t cfl min i j l u i j g h i j in which u i j is defined as u i j 2 v i j 2 cfl number ranges from 0 to 1 2 3 theoretical comparison between the rusanov and hllc schemes a theoretical comparison of numerical efficiency and accuracy between the two schemes are conducted herein by utilizing the formulas of the two schemes for the numerical efficiency it is evaluated by the count of operations in the schemes as to the rusanov scheme it takes four steps to calculate the flux vector including the first two steps to find the wave celerity at the left hand and right hand sides g h i 1 2 j l s and g h i 1 2 j r s in eq 11 respectively the third step for the characteristic wave speeds c i 1 2 j s in eq 11 and the final step to determine the flux vector eq 10 for the hllc scheme the first step is to identify whether the cell interface is a wet dry interface or not in the presence of wet dry interfaces the hllc scheme takes three steps to calculate the left and right characteristic wave speeds by utilizing the exact solutions determination of the wave celerity at left hand or right hand sides calculations of the left and right characteristic wave speeds if the cell interface is not a wet dry interface the hllc scheme takes seven steps to determine the left and right characteristic wave speeds two steps for wave celerity at both sides one step for water depth in the star region four steps for left and right characteristic wave speeds after the left and right characteristic wave speeds are both determined the hllc scheme calculates the middle characteristic wave speed then the hllc scheme goes through eqs 7 8 and 9 in two to three steps for calculating the fluxes in summary the hllc scheme takes seven to eleven steps to determine the fluxes at cell edges as a result the hllc scheme needs three to seven more steps to determine the flux vector as to numerical accuracy viewpoint in the rusanov scheme only a maximum characteristic wave speed is considered eq 11 in the calculation of fluxes eq 10 hence in the presence of strong discontinuities the rusanov scheme gives smoother profiles of water depths and velocities for the hllc scheme the three characteristic wave speeds are all calculated for determining the fluxes eqs 7 8 and 9 the hllc scheme is thus more accurate than the rusanov scheme when simulating strong discontinuities based on the above comparison the proposed hybrid shallow water solver utilizes the rusanov scheme the low accuracy high efficiency scheme for regular flows and simulates strong discontinuous flows with the hllc scheme the high accuracy low efficiency scheme regions that simultaneously utilize the two schemes are required to be delineated into the computational domain to avoid numerical unbalances between the two schemes the details of the hybridization are introduced in subsection 2 4 2 4 the hybrid approach for flux calculation the major contribution of this manuscript is that we develop a novel hybrid shallow water solver to comprise low accuracy high efficiency and high accuracy low efficiency schemes for various overland flow conditions the hllc scheme is adopted to analyze strong discontinuous flows whereas the rusanov scheme is used for regular flows to numerically incorporate these two schemes together each cell interface in the entire computational domain is assigned with a weight ws that ranges from 0 to 1 when ws is 0 1 and between 0 and 1 the calculation of the fluxes uses the hllc scheme only the rusanov scheme only and both the rusanov and hllc schemes respectively two steps of the hybrid procedure are next introduced the flowchart of the hybrid shallow water solver including the proposed hybrid procedure is displayed in fig 1 a the reconstruction of the riemann states at cell edges and the calculation of fluxes are executed after the weight of each cell interface is determined in the second step of the hybrid procedure 2 4 1 identification of strong discontinuous flows in the first step each cell interface in the entire computational domain is visited to identify strong discontinuous flows herein strong discontinuous flows are defined as flows with significant variations in water depths and velocities as such flows often involve significant discontinuities across the cell interfaces the sharpness of discontinuity is used as the indicator considering the cell interface locating at i 1 2 j with the two adjacent cells i j and i 1 j the judgement to identify strong discontinuous flows across the cell interface is 15 h i j s h i 1 j s min h i j s h i 1 j s δ the left hand side in eq 15 is the sharpness of discontinuity and δ is the threshold value to judge whether the sharpness of discontinuity is large enough δ is a model parameter that is hereinafter referred to as the discontinuity threshold when the sharpness of discontinuity of the cell interface exceeds δ the rusanov scheme is regarded to be inappropriate to calculate the fluxes and the hllc scheme is adopted alternatively with ws 0 significant discontinuities such as hydraulic jumps hydraulic drops and wet dry interfaces can all be recognized by eq 15 for simplicity a cell interface identified in strong discontinuous flows is hereinafter to be referred to as the seed interface for the cell interface that is not identified in strong discontinuous flows it is marked to be in regular flows with ws as 1 however as encountering very shallow flows the numerator and denominator in the sharpness of discontinuity are both very small consequently the hybrid procedure can identify a spuriously large portion of strong discontinuous flows to avoid this situation the numerator in the sharpness of discontinuity is required to be larger than a difference threshold ε in the present study ε is given as 10 5 m throughout all the simulations 2 4 2 flux calculation in the second step the fluxes at each cell interface are calculated based on the weight determined in the previous step however as the weight of any cell interface is either 1 or 0 after the first step instantaneously switching from the rusanov scheme to the hllc scheme can introduce some side effects to the accuracy of simulations because of the numerical gaps between the two schemes wang et al 2016 used a continuous weight function to decide the weights of the roe and rusanov schemes according to the pressure gradient to diminish the artificial numerical unbalances between the two schemes however using such weight functions may introduce large regions where the roe and rusanov schemes are both used the computational time is increased under this circumstance to maintain global efficiency and mitigate the artificial numerical unbalances at the same time such weight functions are not used in the present study instead the cell interfaces that are identified to use the hllc scheme in the first step the seed interfaces are used as the starting positions to specify the regions that adopt both the rusanov and hllc schemes for simplicity the regions that simultaneously adopt the two schemes are hereinafter referred to as the transition regions furthermore because of the numerical gaps between the two schemes the regions adjacent to the seed interfaces are re adjusted to use the hllc scheme so as to maintain local accuracy those regions are hereinafter referred to as the hllc regions for simplicity the delineations of the hllc regions and the transition regions are executed over each seed interface and each seed interface has its hllc and transition regions the hllc regions are created before the transition regions the illustrations of the hllc and transition regions around a seed interface locating at i 1 2 j are depicted in fig 1b in this figure the hllc regions the regions where the cell interfaces are marked as the dark blue lines are created adjacent to the seed interface drawn as the red line and the transition regions the regions where the cell interfaces are depicted as the orange lines are specified next to the hllc regions the symmetric length of the hllc region is calculated based on the flow condition of the seed interface at present time it is formulated in analog to the experimental formulas for calculating the length of a hydraulic jump chaudhry 2008 16 l i 1 2 j h l l c s max h i j s h i 1 j s u i j s 2 g u i 1 j s 2 g l in eq 16 the length of the hllc region equals to or is larger than l to avoid the situation that no cell interfaces are included within this region the weight of the cell interface within the hllc region is modified to be 0 in terms of the transition regions they are specified to make the weight gradually change in the computational domain the symmetric length of the transition region is 17 l i 1 2 j t r a n s i t i o n s l i 1 2 j h l l c s the weight of the cell interface within the transition region is given by 18 w i 1 2 j j s 1 n i 1 2 j t r a n s i t i o n s 1 j n i 1 2 j h l l c s where 19 n i 1 2 j h l l c s l i 1 2 j h l l c s l n i 1 2 j t r a n s i t i o n s l i 1 2 j t r a n s i t i o n s l in eq 18 the index j represents the absolute difference of indexes between a cell interface and the seed interface see fig 1b for details in eq 19 n i 1 2 j h l l c s and n i 1 2 j t r a n s i t i o n s are the equivalent counts of the included cell interfaces within the hllc region and the transition region respectively they are both positive integers a cell interface is visited more than once when there are multiple seed interfaces since the delineations of the hllc and transition regions are sequentially performed over each seed interface the weight of such cell interface is continuously assigned with the minimum between the lastly assigned weight and the newly determined weight from the specific seed interface finally after all of the seed interfaces are processed the fluxes at the cell interface are determined by 20 f i 1 2 j s w i 1 2 j s f i 1 2 j r u s a n o v s 1 w i 1 2 j s f i 1 2 j h l l c s where f i 1 2 j r u s a n o v s and f i 1 2 j h l l c s denote the flux vectors by the rusanov and hllc schemes respectively it is stressed that the mass conservation over the computational domain is ensured by eq 20 since the proposed hybrid shallow water solver uses the first order upwind godunov type finite volume scheme for the spatial discretization 3 model calibration the sharpness of discontinuity in eq 15 is used to identify flow condition of each cell interface by the discontinuity threshold δ once the sharpness of discontinuity is above the threshold value the rusanov scheme is not suitable to calculate the fluxes in this section three cases with the exact solutions are used to calibrate δ in each case several runs are performed by the proposed hybrid approach with various δ the rusanov scheme the hllc scheme and the proposed hybrid approach are written in the same code structure to minimize the differences in the numerical implementation it is expected that the proposed hybrid approach requires some additional cpu time to perform the hybrid procedure all of the simulations use square cells to discretize the computational domain the numerical simulations are all conducted on an intel r core tm i9 pc equipped with a 16 0 gb ram the numerical accuracy is evaluated by l2 norm used to quantify the difference between the numerical and measured exact results as chang et al 2011 2016 21 l 2 h p h p 2 h p 2 in which hp refers to the numerical result h p refers to the measured result since the hllc scheme is regarded to be the most accurate scheme here the relative differences of l2 norm of the hllc scheme between the other two schemes are used to discover the accuracy among the schemes used 3 1 case a flows with hydraulic jumps and hydraulic drops case a involves flows over planes with hydraulic jumps and drops this case was originally studied by zhou and stansby 1999 the computational domain is composed of two planes the first plane on the left is a rectangle with 14 5 m long and 1 4 m width and the second plane on the right is a rectangle with 16 m long and 1 4 m width the slopes of the first and second planes are 0 and 0 03 respectively the left edge of the computational domain is used for the inflow boundary condition with u 3 571 m s v 0 m s and d 0 54 m no outflow boundary condition is required to be given since the outflow is in supercritical flows due to the steep slope of the second plane the inflow and outflow are both in supercritical flows so the flows change from supercritical into subcritical through hydraulic jumps and then returning backs to supercritical through hydraulic drops the simulated results of water depths and velocities by zhou and stansby 1999 are herein used as the exact solution initially the computational domain is dry the simulation lasts for 600 s to let the flow regime become steady the computational domain is discretized by square cells the length of each square cell is 0 145 m thus there are 2 110 cells the manning roughness coefficient is 0 019 s m1 3 suggested by zhou and stansby 1999 to focus on the numerical performances in the proximity of the hydraulic jumps and hydraulic drops only data with its x coordinate being between 5 m and 15 m is adopted to calculate l2 norms for water depths and velocities at t 600 s thus each l2 norm is determined by 690 uniformly distributed data to calibrate δ several simulations by the proposed hybrid approach with various δ are carried out for simplicity we only present the simulated results of the proposed hybrid approach with δ 1 2 and 3 the simulated profiles of water levels and velocities along x axis are displayed in figs 2 a and 2b respectively the exact solution is also given in these two figures the domain where the data is used for calculating l2 norm is depicted as l2 norm test domain in fig 2a from figs 2a and 2b the simulated profiles of water levels and velocities by the rusanov scheme are both relatively smooth in regions where the hydraulic jump and drop locate the simulated results by the hllc scheme and the proposed approach with δ 1 and 2 are all in good agreement with the exact solution whereas the simulated results by the proposed hybrid approach with δ 3 exist significant differences in the proximity of the hydraulic jump the comparison of numerical accuracy among all the schemes used is listed in table 1 the relative differences of l2 norms for water depths and velocities between the rusanov and hllc schemes are 18800 00 and 982200 00 respectively as for the proposed hybrid approach with δ 1 and 2 the relative differences of l2 norms for water depths and velocities between them and the hllc scheme are all 0 01 however the relative differences of l2 norms for water depths and velocities between the proposed approach with δ 3 and the hllc scheme are 100 00 and 200 00 respectively thus the proposed hybrid approach with δ 1 and 2 can accurately simulate the hydraulic jumps and hydraulic drops which also demonstrates the correctness of the proposed hybrid approach as a result δ is suggested to be 1 and 2 by the comparison of numerical accuracy in case a 3 2 case b subcritical flows over an undulating bed elevation the flow conditions in case b represent steady subcritical flows over a rugged floodplain the exact solution provided by macdonald et al 1997 is utilized to calibrate δ the computational domain is a rectangle with a length of 120 m and a width of 10 m the upstream boundary is prescribed on the left edge with the time invariant inflow as 20 m3 s and the downstream boundary is set on the right edge with the time invariant exact depth initially the computational domain is filled with the exact depths the simulation lasts for 600 s to let the flow regime become steady again the whole domain is discretized by square cells with a cell size of 0 4 m there are thus 7 826 cells the manning roughness coefficient is given as 0 03 s m1 3 macdonald et al 1997 all data within the computational domain is used to calculate l2 norms for water depths and velocities at t 600 s thus each l2 norm is determined by 7 826 data uniformly distributed in the computational domain a number of runs are carried out to perform the parameter calibration of δ here we show the simulated results of the proposed approach with δ being as 1 2 and 3 for the sake of demonstration the simulated profiles of water levels and velocities along x axis are displayed in figs 3 a and 3b respectively the exact solutions of water levels and velocities are plotted in the figures as well from these figures the simulated profiles by the proposed approach with δ as 1 and 2 and the hllc scheme are all in agreement with the exact solutions the simulated results by the rusanov scheme and the proposed hybrid approach with δ 3 are very similar but they all exist obvious differences from the exact solutions the comparison of numerical accuracy among all the schemes used is presented in table 1 the relative differences of l2 norms for water depths and velocities between the rusanov and hllc schemes are 500 00 and 1550 00 respectively in consideration with the proposed hybrid approach with δ 1 and 2 the relative differences of l2 norms for water depths and velocities between them and the hllc scheme are all 0 01 and this result is quite satisfactory as to the proposed approach with δ 3 the relative differences of l2 norms between it and the hllc scheme are both 500 00 thus it is concluded that the proposed hybrid approach can have almost the same accuracy as the hllc scheme with δ to be 1 and 2 3 3 case c dam break flows on dry bed condition case c refers to dam break flows on dry bed condition with moving wet dry interfaces toro 2001 the computational domain is a rectangle and the length and width of it are 50 m and 5 m respectively the surface is frictionless initially there are two reservoirs separated by a dam locating at 10 m along x direction the water depths on the left and right reservoirs are given as 0 08 m and 0 m respectively and the water velocities in the left and right reservoirs are 1 0 m s and 0 0 m s respectively the water depth on the left reservoir and the velocity in the left reservoir are given to introduce supercritical flows in the entire computational domain at the beginning of the simulation the dam is broken immediately left critical rarefactions or called as depression waves propagate upstream and the tails of them move downstream as moving wet dry interfaces the exact solution is determined by utilizing the exact riemann solver toro 2001 trans missive boundary conditions are prescribed on the left and right edges the simulation lasts for 4 s the computational domain is discretized by square cells with a cell size of 0 1 m and thus there are 25 000 cells the simulated profiles of water depths and velocities at t 4 s are utilized to calculate l2 norms for water depths and velocities respectively to focus on the numerical performance in regions where major differences between the rusanov and hllc schemes are observed each l2 norm is determined by using data with its x coordinate being from 8 m to 12 m the left l2 norm test domain with the rarefactions or from 18 m to 22 m the right l2 norm test domain with the moving wet dry interfaces as a result each l2 norm is calculated by 4 000 data that is uniformly distributed within the selected domains several runs of the proposed approach with various δ are carried out for the parameter calibration of δ here the simulated results of the proposed approach with δ 1 2 and 3 are presented the simulated profiles of water depths and velocities along x axis are drawn in figs 4 a 4b respectively the exact solution is displayed in figs 4a and 4b as well the simulated profiles of water depths and velocities by the rusanov scheme are relatively smooth in the left and right l2 norm test domains the hllc scheme and the proposed hybrid approach with δ 1 and 2 all give relatively better predictions and their simulated results are very similar the major difference in the simulated profiles of the proposed hybrid approach between δ 2 and 3 is observed in the left l2 norm test domain in the right l2 norm test domain the three proposed hybrid approach and the hllc scheme give almost the same simulated results the comparison of numerical accuracy among the schemes used is depicted in table 1 the relative differences of l2 norms for water depths and velocities between the rusanov and hllc schemes are 237 50 and 15 73 respectively as to the proposed hybrid approach with δ 1 and 2 the relative differences in l2 norms for water depths and velocities between them and the hllc scheme are all 0 01 with respect to the proposed approach with δ 3 the relative differences of l2 norms for water depths and velocities between it and the hllc scheme are 25 00 and 0 02 respectively as a result the above results indicate that the proposed hybrid approach can accurately simulate dam break flows involving moving wet dry interfaces as δ is 1 and 2 in summary from all the three cases in this section the best value of δ is given as 2 this value is then used for the rest simulations in the manuscript 4 model verification and efficiency assessment in this section the proposed hybrid approach is evaluated through experimental measurements to compare its numerical accuracy and efficiency to the rusanov and hllc schemes through three benchmark cases each case represents distinct overland flow features that commonly happen in rural and urban areas case 1 refers to rainfall runoff around buildings that commonly occurs in rural and urban areas case 2 is flash floods towards buildings discharge flows this flow condition is also commonly seen both in rural and urban areas case 3 represents street flows in urban areas as the numerical accuracy is demonstrated to be satisfactory through case 1 to 3 an extension of case 3 as the street junction flows with various slopes is used to discover how fast the proposed hybrid approach can be within these case studies significant discontinuities such as hydraulic jumps hydraulic drops and wet dry interfaces in strong discontinuous flows all occur the comparison of numerical accuracy is performed by l2 norm eq 21 as to numerical efficiency the total cpu times of the hllc scheme and the proposed hybrid approach are all recorded although the rusanov scheme is the simplest and fastest scheme in this study the numerical accuracy of it is the worst among the three schemes thus the relative difference of total cpu times between the hllc scheme and the proposed hybrid approach is utilized to investigate the numerical efficiency of the proposed approach and it is 22 t hllc t hybrid t hybrid in which thllc and thybrid are the total cpu times of the hllc scheme and the proposed hybrid approach respectively in the proposed hybrid approach each cell interface adopts either the rusanov scheme or the hllc scheme according to its identified flow condition at each time step to identify the relative usage between the rusanov and hllc schemes in each case the ratio of the hllc scheme used is recorded at each time step the ratio of the hllc scheme used is the count of the cell interfaces using the hllc scheme divided by the total count of cell interfaces this ratio has a positive correlation to the portion of strong discontinuous flows the larger the portion of strong discontinuous flows is the higher the ratio of the hllc scheme used is and hence the less the improvement on numerical efficiency of the proposed approach is theoretically when the ratio of the hllc scheme used equals to 1 the proposed hybrid approach is the same as the hllc scheme but with additional cpu time to perform the hybrid procedure 4 1 case 1 rainfall runoff around buildings case 1 is an experiment of rainfall runoff around buildings cea et al 2010 representing a typical rainfall runoff process in rural and urban areas among several configurations provided by cea et al 2010 the s20 configuration a staggered configuration of buildings is herein selected for the numerical verification three planes with approximate slope as 0 05 comprise the 2 m 2 5 m computational domain the topography and buildings layout are presented in fig 5 a the material of the computational domain is stainless steel infiltration is not considered since the bed surface is impervious rainfall was simulated by 100 evenly distributed nozzles buildings were represented by small blocks with size as 30 cm 20 cm each block has four vertical walls with height as 20 cm and roof with slope as 45 the bottom edge was designed to be the outlet of basin while the other three edges were closed fig 5a outflow hydrograph at the outlet of basin was measured since the water depths are extremely small within the basin no water depth measurement was provided three rainfall durations 20 40 and 60 s and three rainfall intensities 84 180 and 300 mm hr give nine rainfall hyetographs in the experiment in the present study among the nine rainfall hyetographs q25t20 and q25t60 rainfall hyetographs are herein selected as the two numerical scenarios for the model verification in case 1 the rainfall durations of q25t20 and q25t60 scenarios are 20 and 60 s respectively the rainfall intensities of the two scenarios are both 300 mm hr and the total simulation durations of the two scenarios are both 200 s the computational domain is discretized by square cells with cell size as 1 cm in total there are 50 000 cells buildings are represented in the model by raising the elevation of cells where the buildings locate the manning roughness coefficient is 0 016 s m1 3 by cea et al 2010 there are 200 cells at the outlet of basin the simulated outflow hydrographs at the outlet of basin are derived by summing up the outflow hydrographs of the 200 cells for each observed time totally the outflow hydrograph contains 10 893 measured data during the event and they are all used to compute l2 norm for outflow hydrograph the simulated and experimental outflow hydrographs for q25t20 and q25t60 scenarios are displayed in figs 5b and 5c respectively inspection of figs 5b and 5c reveals that the simulated peak discharges by the rusanov scheme are lower than the measured data since it theoretically gives relatively smooth profiles of water depths and velocities in the presence of strong discontinuous flows by contrast the simulated results of the proposed hybrid approach and the hllc scheme both exhibit better agreement with the experimental data the comparison of numerical accuracy and efficiency among the three schemes is summarized in table 2 from numerical accuracy viewpoint the relative differences of l2 norms between the rusanov and hllc schemes in the two scenarios are 35 50 and 26 67 respectively and the relative differences of l2 norms between the proposed hybrid approach and the hllc scheme in the two scenarios are 2 96 and 0 01 therefore the proposed approach has much better performance on numerical accuracy than the rusanov scheme and it can provide as accurate results as the hllc scheme as to numerical efficiency viewpoint the relative differences of total cpu times between the hllc scheme and the proposed hybrid approach in the two scenarios are 21 73 and 16 46 respectively this result is quite satisfactory nevertheless how fast the proposed approach can achieve depends on flow conditions of the computational domain at each time step as the computational domain contains small portion of strong discontinuous flows the proposed hybrid approach can deliver noticeable improvement on numerical efficiency in spite of the additional cpu time to perform the hybrid procedure the ratios of the hllc scheme used at each time step in the two scenarios are displayed in fig 5d since the rainfall duration of q25t60 scenario is larger than that of q25t20 scenario there are more strong discontinuous flows in q25t60 scenario than q25t20 scenario in q25t60 scenario the hllc scheme is used more frequently fig 5d and the proposed approach has less improvement on its numerical efficiency thus it is confirmed that the larger the portion of strong discontinuous flows is the less the numerical efficiency improvement of the proposed approach is through the above analysis the proposed approach has the same numerical accuracy as the hllc scheme but in terms of numerical efficiency it outperforms the hllc scheme by 16 46 21 73 therefore the proposed hybrid approach is shown to maintain good accuracy and to provide significant improvement on computational efficiency in case 1 moreover when the portion of strong discontinuous flows is increased the improvement on numerical efficiency of the proposed approach is decreased it is also demonstrated that the corrections of strong discontinuous flows can consequently recover the simulated results at the outlet of basin 4 2 case 2 flash floods towards buildings discharge flows the second case represents flash floods towards buildings discharge flows which was carried out by impact and cadam projects testa et al 2007 the physical model of this experiment was scaled down from the toce river valley in italy 100 times low medium and high inflow hydrographs were tested in the experiment cubic concrete blocks representing buildings with side length as 0 15 m were placed in the computational domain in the aligned or staggered configurations original valley geometry and modified valley geometry of terrain were both investigated in the experiment thus there are twelve experimental combinations ten water depths measurement gauges were placed in to record time varied water depths in this case verification we adopt the aligned buildings layout with the original valley geometry as the simulation case see fig 6 a for details three inflow hydrographs are all considered fig 6b so that there are three scenarios used low medium and high inflow hydrographs the total simulation durations are 60 s for all the three scenarios the simulated domain is discretized by square cells and the cell size of each square cell is 2 5 cm totally there are 54 964 cells buildings are represented by raising the elevation 0 15 m of cells where the buildings locate the manning roughness coefficient is suggested to be 0 0162 s m1 3 by testa et al 2007 the measured water depths during the experiment at gauges p3 to p10 are used to calculate l2 norm for water depth costabile et al 2017 the positions of the water depths measurement gauges are given in fig 6a totally there are 2 408 measured data during the event to compute l2 norm for water depth figs 6c 6d and 6e depict the simulated and experimental profiles of water depths at gauges p3 to p10 for low medium and high inflow scenarios respectively in these figures the proposed hybrid approach and the hllc scheme both yield accurate results that match the measured data well whereas the simulated profiles provided by the rusanov scheme have relatively large discrepancies l2 norms and total cpu times of the three schemes are depicted in table 3 with respect to numerical accuracy the proposed hybrid approach shows its capability to deal with various strong discontinuous flows as shown in figs 6c 6d and 6e in table 3 the relative differences of l2 norms between the rusanov and hllc schemes in the three scenarios are 16 94 58 47 and 70 74 respectively and the relative differences of l2 norms between the proposed hybrid approach and the hllc scheme are 0 90 0 01 and 0 96 respectively apparently the proposed approach performs much better on numerical accuracy than the rusanov scheme and it is as accurate as the hllc scheme in consideration of numerical efficiency the relative differences of total cpu times between the hllc scheme and the proposed hybrid approach in the three scenarios are 17 42 16 33 and 15 74 respectively hence despite the additional cpu time required to execute the hybrid procedure the numerical efficiency improvement of the proposed approach in case 2 is significant the ratios of the hllc scheme used during the simulations in the three scenarios are displayed in fig 6f in fig 6f the portion of the strong discontinuous flows is increased as the inflow discharge is higher the high inflow scenario has the highest inflow discharge the largest ratio of the hllc scheme used in the simulations displayed in fig 6f and the least improvement on numerical efficiency of the proposed hybrid approach by contrast the low inflow scenario has the lowest inflow discharge the smallest ratio of the hllc scheme used presented in fig 6f and the highest improvement on numerical efficiency hence it is proved that the improvement on numerical efficiency of the proposed approach has a negative correlation to the portion of strong discontinuous flows figs 6c 6d and 6e and table 3 reveal that in all the three scenarios the proposed hybrid approach is as accurate as the hllc scheme but it is 15 74 17 42 faster than the hllc scheme thus the proposed approach has the ability to handle complicated flow conditions in case 2 accurately and efficiently moreover the proposed hybrid approach can be more efficient when the portion of strong discontinuous flows is smaller 4 3 case 3 street junction flows the third case study represents transcritical flow conditions like hydraulic jumps and wet dry interfaces in a 90 four branch street junction nania et al 2011 see fig 7 a for details two sloped open channels representing two roads are intersected in a horizontal square zone the slopes of channels aligned with x axis and y axis are 0 01 m m and 0 02 m m respectively the inflow discharges for two channels were q in x 0 0429 m3 s and q in y 0 1 m3 s respectively surfaces of both channels were made of concrete the flow is subcritical in the inlet of the channel aligned with x axis and supercritical in the inlet of the channel aligned with y axis under such a condition hydraulic jumps are formed in the junction the flows in the two channels both return to supercritical after the junction after the flow regime became steady experimental water depths and velocities were measured along x 0 675 m and y 0 675 m initially the computational domain is completely dry the total simulation duration is given as 200 s to let the flow regime become completely steady the entire simulation domain is discretized by square cells with a cell size of 5 cm as a consequence there are 8 700 cells the manning roughness coefficient is given as 0 016 s m1 3 because of the concrete surface after the simulation starts the water comes from the two inlets and moves along the channels with moving wet dry interfaces hydraulic jumps then form at the junction right after the flows from the two inlets collide with each other apart from the junction flow conditions in two channels return to supercritical flows thus with such simulation settings strong discontinuous flows occur the simulated water depths at t 200 s along x 0 675 m and y 0 675 m are used together with the measured data to calculate a single l2 norm for water depths and the simulated velocities at t 200 s along x 0 675 m and y 0 675 m are adopted together to calculate a single l2 norm for water velocities thus there are 123 measured data utilized to determine each l2 norm the simulated water depths and velocities at t 200 s along x 0 675 m and y 0 675 m are all shown in fig 7b the measured data of nania et al 2011 is plotted in fig 7b as well from fig 7b the proposed hybrid approach and the hllc scheme both have better prediction than the rusanov scheme the comparison of numerical accuracy and efficiency among the three schemes is summarized in table 4 it can be clearly seen from fig 7b that the hllc scheme and the proposed hybrid approach both simulate sharper profiles of water depths and velocities compared to those of the rusanov scheme this means that the proposed hybrid approach and the hllc scheme both have better capability to deal with strong transcritical flows compared to the rusanov scheme as a result in terms of numerical accuracy the relative differences of l2 norms for water depths and velocities between the rusanov and hllc schemes are 17 50 and 20 97 respectively and those between the proposed hybrid approach and the hllc scheme are 0 83 and 0 37 respectively as to numerical efficiency the relative difference of total cpu times between the hllc scheme and the proposed hybrid approach is 13 71 hence the proposed approach is proved to efficiently handle strong discontinuous flows in case 3 regardless of the additional cpu time to run the hybrid procedure it is apparent from the results in fig 7b and table 4 that the proposed hybrid approach has good ability to handle strong transcritical flows it can maintain good local accuracy as the hllc scheme but regarding numerical efficiency it outperforms the hllc scheme by 13 71 therefore the proposed approach can accurately and efficiently deal with such strong transcritical flows in case 3 4 4 extension of case 3 street junction flows with various slopes in subsections 4 1 4 3 the numerical performances on accuracy and efficiency of the proposed hybrid approach have been verified through three benchmark cases it is concluded that the proposed approach can be at most 13 71 21 73 faster than the hllc scheme with providing almost the same accuracy as a result the proposed approach has proved its capability to accurately and efficiently handle such complicated flow conditions in the previous benchmark case studies nevertheless the proposed approach needs additional cpu time to perform the hybrid procedure at each time step as the accuracy of the solver is demonstrated to be satisfactory the next issue is about how fast the solver can be generally speaking how efficient the proposed hybrid approach can reach in each case depends on flow conditions involved as the computational domain has a relatively small part of strong discontinuous flows the proposed approach should be more efficient to confirm this idea a model efficiency assessment extended from case 3 is next conducted to discover how fast the proposed approach can go the numerical accuracy among the three schemes are thus not compared the extended case adopts the layout of case 3 in the original layout the slopes of channels aligned with x axis and y axis are 0 01 m m and 0 02 m m respectively in this extension the slopes of the two channels are both decreased by the same factor in order to slow down water velocities six factors are used as 1 2 3 1 3 1 6 1 12 and 1 24 thus giving six sets of slopes for different flow conditions it is expected to decrease the portion of strong discontinuous flows as the slopes are decreased other simulation settings are the same as in case 3 the comparison of numerical efficiency among the three schemes is depicted in table 5 in the table the relative differences of total cpu times between the hllc scheme and the proposed hybrid approach in the six slopes are 13 71 15 87 17 26 25 14 34 59 and 40 27 respectively it can be clearly confirmed from table 5 that numerical efficiency is increasing as the slope is decreasing the proposed approach can at most be 40 27 faster than the hllc scheme demonstrating its ability to provide significant reduction on the computational time the ratios of the hllc scheme used in the six slopes are presented in fig 7c as the slopes of the two channels are decreased slowing down water velocities the portion of strong discontinuous flows is decreased inspection of fig 7c reveals that the ratio of the hllc scheme used is decreased as the slope is decreased furthermore it can be seen from table 5 that the milder the slopes are the higher the improvement on numerical efficiency of the proposed approach can be therefore how efficient the proposed approach can reach depends on flow conditions involved the proposed approach is more efficient than the hllc scheme as the portion of strong discontinuous flows in the computational domain is relatively smaller 4 5 analysis of additional cpu time the additional cpu time mentioned in subsections 4 1 4 4 is the cpu time used for performing the hybrid procedure in the proposed approach this extra overhead can significantly influence the numerical efficiency of the proposed approach hence the codes of the proposed hybrid approach are written to sum the additional cpu time for executing the hybrid procedure of each case in subsections 4 1 4 4 the additional cpu time is then divided by the total cpu time of the proposed hybrid approach tables 2 5 to give the ratio of the additional cpu time moreover the time varied ratio of the hllc scheme used in each case study shown in figs 5d 6f and 7c is integrated over time and then divided by the total simulation duration to give the averaged ratio of the hllc scheme used the calculated results are all displayed in table 6 from table 6 the additional cpu time is between 1 2 and 4 5 s and the ratios of the additional cpu time are between 4 27 and 13 71 therefore the hybrid procedure is proved to be efficient as the ratios of the additional cpu time are acceptable also it is deduced that the proposed hybrid approach can be more efficient if the additional cpu time is further lowered taking q25t20 scenario in case 1 as an example although it takes 3 2 s 4 27 as the additional cpu time to perform the hybrid procedure there is still 16 3 s 21 73 saved by using the proposed approach compared to the hllc scheme hence if the additional cpu time can be minimized the proposed hybrid approach can save at most 19 5 s 26 00 from the hllc scheme with the same accuracy finally it is concluded from table 6 that the ratio of the additional cpu time is independent of cells number and total simulation duration it is proportional to the averaged ratio of the hllc scheme used 5 future work discussion through all of the case studies in the manuscript the proposed hybrid procedure is demonstrated to be a useful framework to incorporate the two finite volume schemes the two schemes for fluxes and the reconstruction method for the riemann states at cell edges can all be replaced with other selections according to the problems considered table 7 depicts some numerical schemes that can be possibly used by the proposed approach among them this study adopts the rusanov scheme with the cn method for regular flows and the hllc scheme with the cn method for strong discontinuous flows to construct the proposed hybrid approach in particular the hllc scheme is adopted because of its popularity in 2d overland flow modeling modelers can adopt different numerical schemes such as the rusanov scheme with the cn method for regular flows and the hllc scheme with the tvd version of the muscl hancock method for strong discontinuous flows to establish the unique hybrid shallow water solver for specific hydraulic engineering problems 6 conclusions in this manuscript a hybrid shallow water equations solver for modeling overland flows in rural and urban areas is proposed this hybrid approach switches the solver to be used based on the local flow conditions according to the sharpness of discontinuity a low accuracy high efficiency scheme the rusanov scheme is utilized in regular flows whereas a high accuracy low efficiency scheme the hllc scheme is adopted in strong discontinuous flows regions that simultaneously adopt the two schemes are artificially specified to diminish artificial numerical unbalances of the two schemes model calibration is carried out through three cases with the exact solutions the proposed hybrid approach is then verified through three benchmark cases which represent flow conditions that commonly happen in surface runoff propagation in rural and urban areas including rainfall runoff around buildings flash floods towards buildings discharge flows and street flows in junction based on the comparison of numerical accuracy and efficiency among the three schemes from numerical accuracy viewpoint the proposed hybrid approach has the same accuracy as the hllc scheme for all the three cases as for numerical efficiency viewpoint it can provide significant improvement on computational efficiency compared to the hllc scheme at most 13 71 21 73 faster than the hllc scheme for the three benchmark cases the proposed hybrid approach is demonstrated to show its capability for maintaining similar accuracy as the hllc scheme with significant reduction on its computational time nevertheless the proposed approach requires additional cpu time to perform the hybrid procedure at each time step as summarized in table 6 the ratios of the additional cpu time to the total cpu time are between 4 27 and 13 71 how efficient the proposed approach can achieve depends on flow conditions involved in each case a model efficiency assessment extended from the benchmark case involing street flows in junction is hence conducted to test six different flow conditions which confirms that the proposed hybrid approach can be at most 40 27 faster than the hllc scheme the improvement on numerical efficiency is increased as the portion of strong discontinuous flows in the computational domain is smaller finally the major outcome of this research is that we develop a hybrid solver to comprise low accuracy high efficiency and high accuracy low efficiency schemes for various overland flow conditions other finite volume schemes that can be possibly used by the proposed hybrid approach are also listed in table 7 speed up techniques such as local time stepping and parallelization can also be utilized in the proposed approach therefore the hybrid solver has considerable potentials to be a useful tool in flood inundation simulations credit authorship contribution statement hsiang lin yu conceptualization methodology software validation formal analysis investigation data curation visualization writing original draft writing review editing tsang jung chang conceptualization methodology validation writing original draft supervision writing review editing project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the accomplishment of this work is partially supported by the ministry of science and technology taiwan under grant nos 109 2221 e 002 010 my3 and 109 2625 m 002 010 the authors are grateful for the support 
4554,climate warming is expected to have significant impacts on the global hydrologic cycle including changes in precipitation induced extremes such as droughts using 28 cmip5 global climate models gcms this study presents a global scale analysis of the joint return periods t of meteorological drought characteristics duration d severity s and peak p at the 6 and 12 month scales under the representative concentration pathways scenarios rcp2 6 and rcp4 5 the d s and p estimated based on the runs theory are used to calculated from the standardized precipitation index spi at the global 1 1 grids six marginal probability distributions are used to fit s p and d whereas three archimedean copula functions clayton gh and frank are used to estimate t for the paired drought characteristics s d p d and s p large spatial variability is found globally in the best fitted copulas for the paired drought characteristics with the frank frank and gh of the largest global percentage for spi6 spi12 relative to the baseline 1971 2000 the t of the paired drought characteristics above the moderate drought s 1 p 1 and d 3 is projected to decrease mostly in north america and asia 0 22 year during the 2021 2050 near future nf period and in south america and australia 0 47 year during the 2071 2100 far future ff period in contrast an increase in t is projected during nf 3 year mostly in south america and australia and during ff 49 year mostly in asia europe and north america furthermore a larger increase in t is projected under higher rcp and at longer timescales our results suggest a generally nonlinear response of the projected drought risk changes to anthropogenic forcing during the 21st century keywords meteorological droughts spi copula joint return period global projection cmip5 1 introduction drought is a recurring and devastating natural disaster causing significant agricultural economic and environmental damages globally wilhite 2000 wilhite et al 2007 bento et al 2018 evidence is accumulating that anthropogenic warming has affected the hydrologic cycle over recent decades kelley et al 2015 lehner et al 2017b yeh and wu 2018 potentially amplifying the drought risks particularly in semiarid and arid regions diffenbaugh et al 2015 williams et al 2015 sharafati et al 2020 qutbudin et al 2019 the global drought affected areas have expanded significantly at a rate of 1 74 per decade during 1950 2008 dai 2011 yu et al 2014 ongoing climate change is expected to exacerbate the occurrence of precipitation related water disasters and extremes sillmann et al 2013 wang et al 2017 xu et al 2019 sharafati and pezeshki 2020 with one of the main consequences to increase the risks of future drought occurrence and magnitude in many drought prone regions ault et al 2016 cook et al 2015 duffy et al 2015 hoerling et al 2012 lehner et al 2017a drought assessment is thus urgently important for climate change mitigation and water resources management ford and labosier 2017 nabaei et al 2019 meteorological droughts generally develop slowly starting with the deficiency in precipitation pr over a period of time sharma and smakhtin 2006 and lead to hydrologic agricultural and socio economical droughts park et al 2017 van loon 2015 meteorological droughts are multi dimensional hazardous events commonly characterized by their duration d severity s peak p and the areal extent sheffield and wood 2007 tsakiris et al 2016 zhang et al 2015 zhang et al 2017a she and xia 2018 the multi dimensional characteristics of drought make accurate evaluation of its adverse consequences a grand challenge over the past several decades the univariate analyses of drought characteristics have been applied to investigate drought risks e g cancelliere and salas 2004 serinaldi et al 2009 however most previous drought assessment studies applied the univariate probabilistic analysis to examine different drought characteristic separately cannot offer a holistic appraisal on drought development and impacts since the interdependence and combined effects of different drought characteristics were not jointly considered shiau and shen 2001 genest and favre 2007 liu et al 2015 ayantobo et al 2017 different drought characteristics as well as their correlation structures and mutual impacts should be examined together for providing accurate drought assessment nabaei et al 2019 recent efforts in drought characterization have been devoted to examining drought risks in the multivariate probability framework shiau 2006 shiau and modarres 2009 mishra and singh 2010 flexible copula functions are considered a promising method to assess the multivariable probability distributions of drought characteristics bhuyan erhardt et al 2019 the major advantage of copulas is that no assumptions on the independence and normality of the marginal distributions have to be made zhang and singh 2007a nabaei et al 2019 copulas have been used extensively in the multivariate frequency analysis of rainfall characteristics kuhn et al 2007 singh and zhang 2007 wee and shitan 2013 liu et al 2018 floods renard and lang 2007 fan and qian 2016 droughts shiau 2006 shiau and modarres 2009 maity et al 2013 zhang et al 2013a 2013b 2015 2017a xu et al 2015 ayantobo et al 2018 she and xia 2018 nabaei et al 2019 and other hydro meteorological variables such as rainfall temperature water availability sea level and soil moisture das and maity 2015 rana et al 2017 zhang et al 2017b wang and fu 2018 despite several copula based studies of drought risk assessment have been reported e g shiau 2006 shiau and modarres 2009 kao and govindaraju 2010 van de vyver and van den bergh 2018 zuo et al 2018 nabaei et al 2019 very few have presented the global scale analysis on the joint return periods t of different paired drought characteristics such as d s and p improved predictions of drought occurrence under the 21st century warming climates often require the estimation of projected hydroclimatic variability and trends cook et al 2015 global climate model gcm or regional climate model rcm capable to simulate future hydro meteorological time series e g mainly temperature and precipitation provide the effective long term high resolution simulation data for systematical analyses of the potential hydrologic impacts due to climate change wetherald and manabe 2002 wu et al 2018 numerous climate model based studies have been published for climate change assessment in particular on investigating the spatio temporal variability of various drought characteristics described by a multitude of drought indices e g dai 2013 trenberth et al 2014 swain and hayhoe 2015 wu et al 2016 2020 chen and sun 2017 spinoni et al 2018 ayantobo et al 2018 however there are only few studies exploring the influences of climate change on the spatio temporal distribution of the joint t of various drought characteristics e g s d p d and s p under various emission scenarios of greenhouse gases ghgs and aerosols better understanding of these critical drought issues requires the analyses of joint t of drought characteristics for elucidating the mutual influences of hydrometeorological variables during drought development based on the standardized precipitation index spi a widely used meteorological drought index this study provides a global scale analysis of the projected changes in the bivariate joint t of drought characteristics at the 6 month and 12 month timescales under several climate change scenarios by using copula specifically the performance of six marginal distribution functions in fitting s p and d is investigated by using the kolmogorov smirnov k s test kolmogorov 1933 smirnov 1948 and the root mean square error rmse methods three archimedean copulas functions are used to fit the joint probability distributions for each pair of drought characteristics s d p d and s p based on the k s test and rmse methods finally two types of the joint t for s d p d and s p are estimated globally to analyze their projected changes under rcp2 6 and rcp4 5 based on the multi model 28 gcm ensembles of simulated precipitation pr data obtained from the 5th phases of the coupled model intercomparison project cmip5 2 data the simulated monthly precipitation pr data from 28 cmip5 gcms provided by the canadian climate data and scenarios ccds wu et al 2018 for the atmosphere table s1 in supplemental material are used in this study in this dataset each gcm contains one ensemble member making a total 28 ensemble members under each of the two rcp scenarios all the data were statistically downscaled onto the global common 1 1 grids by ccds available at http climatescenarios canada ca page main the data have been used to assess the hydrologic impacts of climate change over several major river basins in china wu et al 2018 a baseline bl period 1971 2000 and two future periods are considered in this study the near future nf 2021 2050 and far future ff 2071 2100 periods for the bias correction we also collected the high resolution global gridded 0 5 0 5 monthly pr dataset from the climatic research unit cru ts 3 22 available at https crudata uea ac uk cru data hrg compiled based on daily or sub daily observational pr by national meteorological services harris et al 2014 the cru ts 3 22 data from 1971 to 2000 are used to correct the biases in pr data simulated by each gcm based on the quantile mapping technique see section 3 1 for details to ensure the consistency in spatial resolution among datasets used the cru ts 3 22 pr data were re scaled from a 0 5 to 1 resolution over the global land using the bilinear interpolation the bias corrected multi model 28 gcm ensemble mean monthly pr data were computed at each 1 grid over three periods bl nf and ff for subsequent analyses of global drought characteristics fig 1 plots the global mean pr distribution during bl as shown the humid climates pr 2000 mm yr are located in northern south america central africa and southern asia near the equator whereas the arid climates pr 500 mm yr are mainly located in western north america western and central asia northern and southern africa and most of australia 3 methods 3 1 bias correction for simulated monthly precipitation data the following quantile mapping method was applied in this study to correct the simulated monthly pr data li et al 2010 lu et al 2014 1 x m p q m x m p f o h 1 f m p x m p f m h 1 f m p x m p where f is the cumulative distribution function cdf of either the observations o or model m for the historical training period 1971 2000 h or the future projection periods nf and ff p x and x are the uncorrected and corrected pr respectively a two parameter gamma distribution was used for fitting pr with the distribution parameters estimated by the method of maximum likelihood estimation mle venables and ripley 2002 we selected the gamma distribution because it has the closed analytical form that can be readily inverted which is effective for the less experience with the distribution of pr intensity simulated by dynamic climate models ines and hansen 2006 in addition a mixed type of gamma distribution was used to account for the locations with zero pr li et al 2010 3 2 standardized precipitation index spi a number of drought indices have been developed for charactering and monitoring meteorological droughts examples of them and their strengths and weakness have been reviewed by mishra and singh 2010 spi is one of the widely used indices for meteorological droughts as recommended by world meteorological organization svoboda et al 2012 spi can quantify both dry and wet pr anomalies at multiple timescales e g 3 6 12 24 months based on the extent to which pr deviates from its median corresponding to a specific timescale mckee et al 1993 compared with other drought indices spi offers several advantages including unambiguous theoretical development robustness temporal flexibility and the simplicity in that only the pr data are required mckee et al 1993 spi is calculated globally at the 6 and 12 month timescales spi6 and spi12 respectively in this study spi6 describes the droughts affecting vegetation and agricultural practices while spi12 serves as a meaningful indicator for water resource management bonaccorso et al 2003 considering that the spi calculation may be biased due to the limited data length used to fit the distribution mishra and singh 2010 we used the 1971 2000 as a reference period to fit the gamma distribution in calculating spi for both the bl and future two periods nf and ff a spi 0 indicates the occurrence of a meteorological drought event the severity s peak p and duration d of each event are computed globally at each grid by using the runs theory yevjevich 1967 as described schematically in fig s1 in supplemental material with the following definitions d is the number of consecutive months for which spi 0 p is the largest absolute value of spi within a specific duration d and s is the absolute value of the cumulative spi within d there are generally different classification of s p and d used in drought assessment studies according to the definitions in previous studies zuo et al 2018 nabaei et al 2019 the s and p above the moderate drought s 1 and p 1 and d longer than 3 month d 3 are used here for the multivariate analysis of droughts 3 3 marginal distribution in the univariate analyses several marginal distribution functions have been recommended for fitting various drought characteristics xu et al 2015 in this study six widely used probability distribution functions pdfs including the 1 normal 2 lognormal 3 gamma 4 exponential 5 generalized extreme value gev and 6 weibull distributions are used for fitting the pdfs of s p and d table 1 the parameter estimation of pdfs is determined by using the mle method the goodness of fit of each univariate distribution at each grid is then tested by the k s test and rmse which are expressed as follows 2 k n x 1 n i 1 n i x x i 3 rmse 1 n i 1 n x e x o 2 where k n x is the k s statistic and i x x i is an indicator function which is equal to 1 if xi x and otherwise equal to 0 in eq 3 x o and x e are observed and expected values respectively in this study all the k s tests are performed at the 95 significant level 3 4 copulas the concept of copula was developed by sklar 1959 which stated that if two random variables x and y with their marginal distribution function fx x and fy y respectively there is a copula c function that can link these two marginal distribution functions to form a joint distribution function f x y x y as follows nelsen 2006 4 f x y x y c f x x f y y note that the copula function is used for describing the joint probability of multiple random variables not the marginal distribution for a single random variable there are three main families of copulas elliptical archimedean and quadratic the archimedean copula family which allows for greater flexibility and simplicity of use is consider more suitable for hydro meteorological analyses zhang and singh 2007a 2007b the most common three 2 d archimedean copulas including the clayton copula the gumbel hougaard gh copula and the frank copula table 2 are employed in this study the parameters of the copula functions are estimated at each global 1 grid by the mle method the goodness of fit of copula functions is assessed at each global 1 grid using the k s test eq 2 and rmse eq 3 the best copula at each global 1 grid is selected when it passes the k s test and has the smallest rmse 3 5 joint t in the univariate setting t with a drought feature d s or p is equal to or greater than a certain threshold value x can be defined as shiau and shen 2001 shiau 2006 5 t x e l 1 f x x where f x x is the cdf of x e l denotes the average inter arrival time of the events in the observed sequence which can be computed as xu et al 2015 6 e l n year n drought where n year and n drought are the length of the study period i e 30 yr in this study and the number of years with occurrence of drought events respectively different types of the joint probability distributions can be defined and estimated here the following two types of bivariate joint probabilities p x y and p x y are considered shiau 2006 nabaei et al 2019 7a p x y p x x y y 1 f x x f y y c f x x f y y 7b p x y p x x o r y y 1 c f x x f y y where the symbol denotes the intersection and and denotes the union or the corresponding t of p x y and p x y can be computed as follows 8a t x y e l 1 f x x f y y c f x x f y y 8b t x y e l 1 c f x x f y y 4 results 4 1 bias correction evaluation the cru ts 3 22 gridded dataset was used to correct the biases in simulated monthly pr by using the quantile mapping technique eq 1 the spatial distributions of the relative mean error of the uncorrected and bias corrected pr during bl are compared in fig 2 the uncorrected gcm simulated pr is underestimated over many global regions such as northern south america eastern north america and southwest asia up to 100 while it is overestimated in western and southern south america northern africa western china and northwest north america up to 300 fig 2a after bias correction the relative mean error is reduced to 9 8 for most of global regions with only slight underestimation overestimation found in northern hemisphere south america and northern africa overall the bias corrected monthly pr show a good performance over most global regions and therefore suitable to be used for the subsequent analyses of drought characteristics notice that the relatively large overestimation 29 of pr can be found in northern africa which may introduce large uncertainty in the projections of meteorological drought 4 2 selection of marginal distribution the percentage of global grids identified with the best fitted marginal distribution functions of s p and d i e passing the k s test with the smallest rmse for spi6 and spi12 is summarized in table 3 for the bl nf and ff periods under 2 rcps considered for spi6 the weibull gamma and lognormal are the best fitted marginal distribution functions of s for most global grids ranging respectively 26 9 44 9 28 3 30 9 and 15 5 23 2 among different periods and rcps for p the weibull 25 3 37 gev 14 4 21 3 and gamma 11 1 17 4 are the best fitted functions for most global grids for d the exponential 19 8 31 9 lognormal 17 8 42 2 and weibull 13 8 16 6 are the best fitted distribution functions globally for spi12 however the gamma 29 6 41 7 and lognormal 25 5 32 6 are the best fitted marginal distribution functions of s for most glo0bal grids for p the gamma 14 8 26 7 exponential 18 1 24 and weibull 11 5 22 4 distributions are the best fitted distribution functions for most global grids for d the lognormal 17 2 41 8 and weibull 15 7 25 6 are the best fitted distribution functions for most global grids it is also found that the numbers of total grids identified with the best fitted marginal distribution functions of s and p tend to decrease from rcp2 6 to rcp4 5 and from nf to ff furthermore the total grids identified with the best fitted marginal distribution functions of d of spi12 are apparently larger than that of spi6 suggesting it is more likely to find the optimal marginal distribution functions of d at a longer timescale the global distribution of the best fitted types of pdfs for s p and d of spi6 during bl is shown in fig s2 in supplemental material as seen the best fitted pdfs of s p and d can be identified at most global grids except for those small areas located in northern africa where all the marginal pdfs considered were failed to pass the k s test at 95 significant level this finding is consistent with that of spi12 not displayed in addition a similar spatial distribution pattern can also be observed for both nf and ff periods and under both rcp scenarios not displayed 4 3 selection of copula functions the mle method is applied to all the grids with the identified best fitted marginal distributions for estimating the copula parameters the rmse and k s test are used as the criteria in the goodness of fit test section 3 3 the global grid percentages with the best fitted copula functions for the joint s p s d and p d pdfs of spi6 and spi12 are summarized in table 4 respectively during bl nf and ff periods under both rcps as seen the best fitted copula functions can be identified in most of global grids particularly for the s p joint pdf 90 for the best fitted copula functions of s p pdf of both spi6 and spi12 the frank function has the largest percentage during all bl nf and ff periods under rcp2 6 up to 60 while the clayton function has the largest percentage under rcp4 5 for the best fitted copula of s d joint pdf the frank function has the largest percentage during all three periods and under both rcps except for spi12 during ff under rcp4 5 for the best fitted copula of p d joint pdf during all three periods considered the frank function still has the largest percentage for spi6 74 5 while the gh function has the largest percentage up to 93 5 for spi12 spatially taking the s p s d and p d joint pdfs for spi6 during bl as an example see fig s3 in supplemental material the best fitted copula functions were identified for most global grids except for some regions located in northern africa a similar pattern is found for spi6 and spi12 during nf and ff periods under both rcps not displayed compared with bl the areas without the best fitted copula functions identified for the s d and p d joint pdfs are generally larger up to 27 table 4 during nf and ff periods under both scenarios and these areas located mainly in northern africa coincide with the areas without the marginal pdfs of d identified as shown previously up to 26 8 see table 3 4 4 projected changes in the joint t of drought characteristics 4 4 1 bivariate joint period t x y using equation 8a the specified thresholds of p and s for the above moderate drought defined as s 1 and p 1 and d 3 are used to calculate t x y of the paired drought characteristics p d s d and s p during all the bl nf and ff periods figs 3 5 plot the global distribution of 28 gcm mean changes in t s 1 p 1 t s 1 d 3 and t p 1 d 3 in years respectively for spi6 and spi12 during the nf and ff relative to bl period under both rcps the corresponding continental scale statistics of these mean changes for spi6 and spi12 are summarized in tables s2 and s3 in supplemental material respectively the 28 gcm mean changes are expressed as the differences in the joint t relative to that during bl with a positive negative change denoting a decrease increase in the future drought risk as shown in fig 3 the projected changes in t s 1 p 1 exhibit larger spatial variability during nf than ff for both rcps a decrease in t s 1 p 1 i e higher drought risks during nf 2021 2050 is projected under rcp2 6 in northern and southern north america northern africa southern and northern asia and western australia and under rcp4 5 for most of the northern hemisphere central africa most of sahara desert and western australia in contrast during ff a decrease in t s 1 p 1 is projected under both rcps in most of the southern hemisphere including central and south asia most of northern and southern africa eastern australia and northern south america while a projected increase in t s 1 p 1 found in many parts of the high latitude northern hemisphere particularly in i e northern north america and northern asia overall under rcp4 5 the relative change in t s 1 p 1 generally shows an opposite sign between nf and ff for most of the northern hemisphere and south america relative to spi6 fig 3a the increase in t s 1 p 1 for spi12 fig 3b is expected to occur over the wider global regions and the magnitude is larger 150 years in northern high latitude regions during ff under rcp4 5 comparisons of t s 1 p 1 in fig 3 and t s 1 d 3 in fig 4 reveal the similar global patterns for the projected changes in t s 1 p 1 and t s 1 d 3 however the projected decreases in t s 1 d 3 6 years is significantly smaller than that of t s 1 p 1 37 years overall a larger decrease is projected in t p 1 d 3 up to 70 years suggests larger future drought risks of p 1 and d 3 fig 5 a larger increases in t p 1 d 3 150 years for spi12 during ff is found in most of northern high latitude areas under rcp4 5 indicating a lower probability of the above moderate drought future occurrence over these regions at the continental scales tables s2 and s3 the t s 1 p 1 t s 1 d 3 and t p 1 d 3 for spi6 and spi12 under rcp2 6 are projected to increase lower drought risks during nf over all continents except for t s 1 d 3 in the northern hemisphere the t s 1 p 1 t s 1 d 3 and t p 1 d 3 under rcp2 6 during ff are projected to decrease mainly over oceania and south america for spi6 0 223 year and over oceania for spi12 0 447 year the t s 1 p 1 t s 1 d 3 and t p 1 d 3 during nf under rcp4 5 are projected to decrease over africa asia europe and north america for spi6 0 224 year and over asia and europe 0 244 year for spi12 except for t s 1 p 1 the t s 1 p 1 t s 1 d 3 and t p 1 d 3 under rcp4 5 are projected to decrease only over south america during ff for both spi6 and spi12 0 474 year while the larger increases in t s 1 p 1 t s 1 d 3 and t p 1 d 3 are projected in asia europe and north america particular for spi12 up to 49 years in north america 4 4 2 bivariate joint period t x y figs 6 8 plot the global distributions of 28 gcm mean changes in t s 1 p 1 t s 1 d 3 and t p 1 d 3 in years of the paired drought characteristics p d s d and s p respectively for spi6 and spi12 during nf and ff relative to bl under both rcps with the corresponding continental scale statistics of all t changes summarized in tables s2 spi6 and s3 spi12 in supplemental material for respectively fig 6 shows that a relatively small decrease in t s 1 p 1 increasing drought risks during nf is projected under rcp2 6 in the most parts of north america asia and western australia and under rcp4 5 for most parts of the northern hemisphere and central africa a projected increase in t s 1 p 1 during ff is found in most of the northern hemisphere particularly northern north america and northern asia especially under rcp4 5 20 years in contrast a projected decrease in t s 1 p 1 during ff is found in southwest asia northern and southern africa eastern australia and northern south america fig 6 compared with spi6 the increase in t s 1 p 1 for spi12 during ff is expected to occur in larger global regions particularly in northern asia under both rcps overall the spatial pattern of projected changes in t s 1 p 1 is similar to that of t s 1 p 1 but the magnitude of changes in t s 1 p 1 is significantly smaller than that of t s 1 p 1 fig 3 the projected changes in t s 1 d 3 and t p 1 d 3 figs 7 and 8 exhibit similar global pattern with that of t s 1 p 1 fig 6 the largest increases in t s 1 d 3 and t p 1 d 3 of spi6 and spi12 are mostly found in northern north america and northern asia however the projected decreases in t s 1 d 3 1 7 years and t p 1 d 3 2 years tend to be smaller than that of t s 1 p 1 3 years at the continental scales a large discrepancy in the projected t t s 1 p 1 t s 1 d 3 and t p 1 d 3 can be found between two rcps during nf and ff tables 2 and 3 for both spi6 and spi12 the t s 1 p 1 t s 1 d 3 and t p 1 d 3 are projected to decrease slightly in asia and north america 0 05 year during nf under rcp2 6 during ff under rcp2 6 the t s 1 p 1 t s 1 d 3 and t p 1 d 3 are expected to decrease in africa and oceania for spi6 and only in oceania for spi12 during nf under rcp4 5 the projected decreases in t s 1 p 1 t s 1 d 3 and t p 1 d 3 are found in africa asia europe and north america for spi6 and in asia europe and north america for spi12 in contrast the projected decreases in t s 1 p 1 t s 1 d 3 and t p 1 d 3 during ff under rcp4 5 are found only in south america for spi6 and in oceania and south america for spi12 5 discussion 5 1 influences of climate change on drought risk this study aims at the global analysis of projected changes in the joint t of the paired drought characteristics under 2 rcp scenarios based on the 28 cmip5 gcms simulation data the results indicate that different global regions are projected to suffer varying degrees of drought risks as indicated by the projected t under future climates e g figs 3 8 however a generally opposite sign in the projected changes of joint t is found between nf and ff in some global regions the drought risks during nf ff are projected to increase mainly in north america and asia south america and australia in contrast a decrease in drought risks during nf ff is projected mostly in south america and australia asia europe and north america overall our results indicate a nonlinear response of projected drought risk changes to anthropogenic forcing during the 21st century over many global regions e g north america asia south america and australia suggesting the necessity for adjusting the strategies for managing future drought risks our finding is somewhat different from several previous drought assessment studies using other drought indices which included a measure of the atmospheric demand for moisture burke and brown 2008 sheffield and wood 2008 burke 2011 dai 2013 zhao and dai 2017 prudhomme et al 2014 touma et al 2015 samaniego et al 2018 most of these previous studies reported the consistent monotonical increases in global and regional drought occurrence throughout the 21st century primarily resulting from the increasing evaporation under warming climates the drought index spi used in this study only reflects the precipitation induced meteorological droughts and provides no information on the other drought types and their potential impacts on agriculture ecosystems and societies wu et al 2020 considerable discrepancies in model projected drought characteristics among different drought indices e g spi the palmer drought severity index pdsi the soil moisture anomalies sma the precipitation and potential evaporation anomaly ppea the standardized precipitation evapotranspiration index spei have been reported in numerous previous studies e g burke and brown 2008 touma et al 2015 rhee and cho 2016 in particular burke and brown 2008 indicated that relative to other indices highly responsive to temperature changes spi in general estimates a smaller change in the proportion of land areas under drought the sign and magnitude of changes in drought characteristics are highly dependent on the index definition and hence the selection of appropriate drought indices is of high importance for climate change impact studies 5 2 potential uncertainties in copula based drought risk projections the impacts of climate change and variability on drought characteristics are highly uncertain owing to the complexity of the feedback processes involved in this study six commonly used marginal pdfs normal lognormal gamma exponential gev and weibull were used to fit drought characteristics s p and d and three archimedean copulas clayton gh and frank were used to estimate the joint t of the paired drought characteristics s d p d and s p the results indicate that different drought characteristics follow different distributions resulting in large spatio temporal variability in their best fitted marginal pdfs table 3 and fig s2 as well as the best fitted copulas for their paired drought characteristics table 4 and fig s3 therefore substantial uncertainties may exist in the probability estimation of drought characteristics if only one or few pdfs were selected for analysis in addition to the subjective selection of drought indices and pdfs mentioned above the large uncertainty in projected t of joint drought characteristics s d p d and s p can also be attributed to several other factors first only the multi model 28 gcms mean ensemble changes in the drought characteristics were considered in this study but not the differences among individual gcms therefore the large uncertainties in projected drought regions among gcms as identified in previous cmip3 and cmip5 studies kay et al 2009 giuntoli et al 2015 vetter et al 2017 xu et al 2019 cannot be evaluated here note that this study did not include all available cmip5 models and also only considered one ensemble member for each model and hence cannot account for the full ranges of ensemble averages the selection of models and ensemble members is often subjective and limited by data availability and hence different studies may have used vastly different numbers of models recent studies have shown that the ensemble average and its robustness could be highly dependent on the model choice particularly for the metrics with large systematic differences among models ukkola et al 2018 therefore a large discrepancy among gcms should be accounted for in most projection studies to provide more reliable estimates of future drought projections second although the bias correction method used here shows an overall satisfactory performance in reproducing the spatio temporal variability of pr for most global regions there still exist biases in the corrected pr in certain regions such as the overestimations up to 29 in northern africa and southwest asia and the underestimations up to 9 in central china fig 2 this can introduce large uncertainties in projected drought characteristics over these regions in addition under the univariate and bivariate analyses some regions e g northern and southern africa figs s2 and s3 are not identified with the best fitted marginal distribution and copula functions for d table 3 and for d p and d s table 4 the estimation of drought characteristics using the spatial interpolation or insufficient data over these regions could also be another source of uncertainties to reduce these uncertainties the comprehensive investigations on the sensitivities of drought indices to temperature changes by using more gcms and ensemble members as well as more advanced statistical downscaling methods are indispensable in future research 6 conclusions in this study a global scale projection of meteorological drought characteristics for the near future nf period 2021 2050 and far future ff period 2070 2100 is conducted by using the simulated monthly precipitation data from 28 cmip5 gcms under the rcp2 6 and rcp4 5 scenarios three drought characteristics duration d severity s peak p computed based on the drought index spi were extracted globally at each 1 1 grid by using the runs theory at the 6 and 12 month timescales spi6 and spi12 six marginal distribution functions were used to fit the computed s p and d and three archimedean copula functions were used for generating the global distributions of two different joint return periods t t x y and t x y of various paired drought characteristics for the above moderate drought s 1 p 1 and d 3 the results indicate that different drought characteristics follow different statistical distributions leading to large spatio temporal variability globally in the best fitted marginal probability distributions of drought characteristics as well as the best fitted copulas of the paired drought characteristics overall in terms of the largest percentage of global grids the weibull gamma distribution is the best fitted marginal distribution of s and p of spi6 spi12 while the lognormal distribution is the best fitted distribution of d of both spi6 and spi12 among the best fitted copula functions of spi6 spi12 frank frank and gh has the largest global percentages the t x y and t x y show generally similar spatio temporal patterns but the magnitude of projected changes in t x y is significantly larger than that of t x y an increasing drought risk i e decreasing t x y and t x y is projected during nf mainly in north america and asia 0 22 year and during ff in south america and australia 0 47 year in contrast a decreasing drought risk i e increased t x y and t x y during nf is projected mostly in south america and australia 3 year and during ff in asia europe and north america 49 year furthermore a larger decreasing drought risk is projected under a higher rcp scenario and at a longer timescale overall our results indicate a generally nonlinear response of the projected changes in drought risk to anthropogenic forcing during the 21st century however there are considerable uncertainties in the projected t of various drought characteristics including the choices of drought index gcms and bias correction methods specifically larger uncertainties are found in northern africa due to large errors in gcm data and insufficient grids identified with the best fitted copula functions therefore more comprehensive analyses on the sensitivities of alternative drought indices to temperature changes with the uses of more gcms and ensemble members with different initial conditions and more advanced statistical downscaling methods are necessary in future research directions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by funding from the national natural science foundation of china grant no 51909106 51879108 the natural science foundation of guangdong province china grant no 2020a1515011038 2018a030310653 the high level talent project for the pearl river talent plan of guangdong province grant no 2017gc010397 the youth innovative talents project for guangdong colleges and universities grant no 2017kqncx010 and the fundamental research funds for the central universities grant no 21617301 monthly precipitation data from 28 cmip5 gcms were provided by the canadian climate data and scenarios ccds available at http climatescenarios canada ca page main global gridded 0 5 0 5 monthly precipitation data were obtained from the climatic research unit cru ts 3 22 available at https crudata uea ac uk cru data hrg appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126265 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4554,climate warming is expected to have significant impacts on the global hydrologic cycle including changes in precipitation induced extremes such as droughts using 28 cmip5 global climate models gcms this study presents a global scale analysis of the joint return periods t of meteorological drought characteristics duration d severity s and peak p at the 6 and 12 month scales under the representative concentration pathways scenarios rcp2 6 and rcp4 5 the d s and p estimated based on the runs theory are used to calculated from the standardized precipitation index spi at the global 1 1 grids six marginal probability distributions are used to fit s p and d whereas three archimedean copula functions clayton gh and frank are used to estimate t for the paired drought characteristics s d p d and s p large spatial variability is found globally in the best fitted copulas for the paired drought characteristics with the frank frank and gh of the largest global percentage for spi6 spi12 relative to the baseline 1971 2000 the t of the paired drought characteristics above the moderate drought s 1 p 1 and d 3 is projected to decrease mostly in north america and asia 0 22 year during the 2021 2050 near future nf period and in south america and australia 0 47 year during the 2071 2100 far future ff period in contrast an increase in t is projected during nf 3 year mostly in south america and australia and during ff 49 year mostly in asia europe and north america furthermore a larger increase in t is projected under higher rcp and at longer timescales our results suggest a generally nonlinear response of the projected drought risk changes to anthropogenic forcing during the 21st century keywords meteorological droughts spi copula joint return period global projection cmip5 1 introduction drought is a recurring and devastating natural disaster causing significant agricultural economic and environmental damages globally wilhite 2000 wilhite et al 2007 bento et al 2018 evidence is accumulating that anthropogenic warming has affected the hydrologic cycle over recent decades kelley et al 2015 lehner et al 2017b yeh and wu 2018 potentially amplifying the drought risks particularly in semiarid and arid regions diffenbaugh et al 2015 williams et al 2015 sharafati et al 2020 qutbudin et al 2019 the global drought affected areas have expanded significantly at a rate of 1 74 per decade during 1950 2008 dai 2011 yu et al 2014 ongoing climate change is expected to exacerbate the occurrence of precipitation related water disasters and extremes sillmann et al 2013 wang et al 2017 xu et al 2019 sharafati and pezeshki 2020 with one of the main consequences to increase the risks of future drought occurrence and magnitude in many drought prone regions ault et al 2016 cook et al 2015 duffy et al 2015 hoerling et al 2012 lehner et al 2017a drought assessment is thus urgently important for climate change mitigation and water resources management ford and labosier 2017 nabaei et al 2019 meteorological droughts generally develop slowly starting with the deficiency in precipitation pr over a period of time sharma and smakhtin 2006 and lead to hydrologic agricultural and socio economical droughts park et al 2017 van loon 2015 meteorological droughts are multi dimensional hazardous events commonly characterized by their duration d severity s peak p and the areal extent sheffield and wood 2007 tsakiris et al 2016 zhang et al 2015 zhang et al 2017a she and xia 2018 the multi dimensional characteristics of drought make accurate evaluation of its adverse consequences a grand challenge over the past several decades the univariate analyses of drought characteristics have been applied to investigate drought risks e g cancelliere and salas 2004 serinaldi et al 2009 however most previous drought assessment studies applied the univariate probabilistic analysis to examine different drought characteristic separately cannot offer a holistic appraisal on drought development and impacts since the interdependence and combined effects of different drought characteristics were not jointly considered shiau and shen 2001 genest and favre 2007 liu et al 2015 ayantobo et al 2017 different drought characteristics as well as their correlation structures and mutual impacts should be examined together for providing accurate drought assessment nabaei et al 2019 recent efforts in drought characterization have been devoted to examining drought risks in the multivariate probability framework shiau 2006 shiau and modarres 2009 mishra and singh 2010 flexible copula functions are considered a promising method to assess the multivariable probability distributions of drought characteristics bhuyan erhardt et al 2019 the major advantage of copulas is that no assumptions on the independence and normality of the marginal distributions have to be made zhang and singh 2007a nabaei et al 2019 copulas have been used extensively in the multivariate frequency analysis of rainfall characteristics kuhn et al 2007 singh and zhang 2007 wee and shitan 2013 liu et al 2018 floods renard and lang 2007 fan and qian 2016 droughts shiau 2006 shiau and modarres 2009 maity et al 2013 zhang et al 2013a 2013b 2015 2017a xu et al 2015 ayantobo et al 2018 she and xia 2018 nabaei et al 2019 and other hydro meteorological variables such as rainfall temperature water availability sea level and soil moisture das and maity 2015 rana et al 2017 zhang et al 2017b wang and fu 2018 despite several copula based studies of drought risk assessment have been reported e g shiau 2006 shiau and modarres 2009 kao and govindaraju 2010 van de vyver and van den bergh 2018 zuo et al 2018 nabaei et al 2019 very few have presented the global scale analysis on the joint return periods t of different paired drought characteristics such as d s and p improved predictions of drought occurrence under the 21st century warming climates often require the estimation of projected hydroclimatic variability and trends cook et al 2015 global climate model gcm or regional climate model rcm capable to simulate future hydro meteorological time series e g mainly temperature and precipitation provide the effective long term high resolution simulation data for systematical analyses of the potential hydrologic impacts due to climate change wetherald and manabe 2002 wu et al 2018 numerous climate model based studies have been published for climate change assessment in particular on investigating the spatio temporal variability of various drought characteristics described by a multitude of drought indices e g dai 2013 trenberth et al 2014 swain and hayhoe 2015 wu et al 2016 2020 chen and sun 2017 spinoni et al 2018 ayantobo et al 2018 however there are only few studies exploring the influences of climate change on the spatio temporal distribution of the joint t of various drought characteristics e g s d p d and s p under various emission scenarios of greenhouse gases ghgs and aerosols better understanding of these critical drought issues requires the analyses of joint t of drought characteristics for elucidating the mutual influences of hydrometeorological variables during drought development based on the standardized precipitation index spi a widely used meteorological drought index this study provides a global scale analysis of the projected changes in the bivariate joint t of drought characteristics at the 6 month and 12 month timescales under several climate change scenarios by using copula specifically the performance of six marginal distribution functions in fitting s p and d is investigated by using the kolmogorov smirnov k s test kolmogorov 1933 smirnov 1948 and the root mean square error rmse methods three archimedean copulas functions are used to fit the joint probability distributions for each pair of drought characteristics s d p d and s p based on the k s test and rmse methods finally two types of the joint t for s d p d and s p are estimated globally to analyze their projected changes under rcp2 6 and rcp4 5 based on the multi model 28 gcm ensembles of simulated precipitation pr data obtained from the 5th phases of the coupled model intercomparison project cmip5 2 data the simulated monthly precipitation pr data from 28 cmip5 gcms provided by the canadian climate data and scenarios ccds wu et al 2018 for the atmosphere table s1 in supplemental material are used in this study in this dataset each gcm contains one ensemble member making a total 28 ensemble members under each of the two rcp scenarios all the data were statistically downscaled onto the global common 1 1 grids by ccds available at http climatescenarios canada ca page main the data have been used to assess the hydrologic impacts of climate change over several major river basins in china wu et al 2018 a baseline bl period 1971 2000 and two future periods are considered in this study the near future nf 2021 2050 and far future ff 2071 2100 periods for the bias correction we also collected the high resolution global gridded 0 5 0 5 monthly pr dataset from the climatic research unit cru ts 3 22 available at https crudata uea ac uk cru data hrg compiled based on daily or sub daily observational pr by national meteorological services harris et al 2014 the cru ts 3 22 data from 1971 to 2000 are used to correct the biases in pr data simulated by each gcm based on the quantile mapping technique see section 3 1 for details to ensure the consistency in spatial resolution among datasets used the cru ts 3 22 pr data were re scaled from a 0 5 to 1 resolution over the global land using the bilinear interpolation the bias corrected multi model 28 gcm ensemble mean monthly pr data were computed at each 1 grid over three periods bl nf and ff for subsequent analyses of global drought characteristics fig 1 plots the global mean pr distribution during bl as shown the humid climates pr 2000 mm yr are located in northern south america central africa and southern asia near the equator whereas the arid climates pr 500 mm yr are mainly located in western north america western and central asia northern and southern africa and most of australia 3 methods 3 1 bias correction for simulated monthly precipitation data the following quantile mapping method was applied in this study to correct the simulated monthly pr data li et al 2010 lu et al 2014 1 x m p q m x m p f o h 1 f m p x m p f m h 1 f m p x m p where f is the cumulative distribution function cdf of either the observations o or model m for the historical training period 1971 2000 h or the future projection periods nf and ff p x and x are the uncorrected and corrected pr respectively a two parameter gamma distribution was used for fitting pr with the distribution parameters estimated by the method of maximum likelihood estimation mle venables and ripley 2002 we selected the gamma distribution because it has the closed analytical form that can be readily inverted which is effective for the less experience with the distribution of pr intensity simulated by dynamic climate models ines and hansen 2006 in addition a mixed type of gamma distribution was used to account for the locations with zero pr li et al 2010 3 2 standardized precipitation index spi a number of drought indices have been developed for charactering and monitoring meteorological droughts examples of them and their strengths and weakness have been reviewed by mishra and singh 2010 spi is one of the widely used indices for meteorological droughts as recommended by world meteorological organization svoboda et al 2012 spi can quantify both dry and wet pr anomalies at multiple timescales e g 3 6 12 24 months based on the extent to which pr deviates from its median corresponding to a specific timescale mckee et al 1993 compared with other drought indices spi offers several advantages including unambiguous theoretical development robustness temporal flexibility and the simplicity in that only the pr data are required mckee et al 1993 spi is calculated globally at the 6 and 12 month timescales spi6 and spi12 respectively in this study spi6 describes the droughts affecting vegetation and agricultural practices while spi12 serves as a meaningful indicator for water resource management bonaccorso et al 2003 considering that the spi calculation may be biased due to the limited data length used to fit the distribution mishra and singh 2010 we used the 1971 2000 as a reference period to fit the gamma distribution in calculating spi for both the bl and future two periods nf and ff a spi 0 indicates the occurrence of a meteorological drought event the severity s peak p and duration d of each event are computed globally at each grid by using the runs theory yevjevich 1967 as described schematically in fig s1 in supplemental material with the following definitions d is the number of consecutive months for which spi 0 p is the largest absolute value of spi within a specific duration d and s is the absolute value of the cumulative spi within d there are generally different classification of s p and d used in drought assessment studies according to the definitions in previous studies zuo et al 2018 nabaei et al 2019 the s and p above the moderate drought s 1 and p 1 and d longer than 3 month d 3 are used here for the multivariate analysis of droughts 3 3 marginal distribution in the univariate analyses several marginal distribution functions have been recommended for fitting various drought characteristics xu et al 2015 in this study six widely used probability distribution functions pdfs including the 1 normal 2 lognormal 3 gamma 4 exponential 5 generalized extreme value gev and 6 weibull distributions are used for fitting the pdfs of s p and d table 1 the parameter estimation of pdfs is determined by using the mle method the goodness of fit of each univariate distribution at each grid is then tested by the k s test and rmse which are expressed as follows 2 k n x 1 n i 1 n i x x i 3 rmse 1 n i 1 n x e x o 2 where k n x is the k s statistic and i x x i is an indicator function which is equal to 1 if xi x and otherwise equal to 0 in eq 3 x o and x e are observed and expected values respectively in this study all the k s tests are performed at the 95 significant level 3 4 copulas the concept of copula was developed by sklar 1959 which stated that if two random variables x and y with their marginal distribution function fx x and fy y respectively there is a copula c function that can link these two marginal distribution functions to form a joint distribution function f x y x y as follows nelsen 2006 4 f x y x y c f x x f y y note that the copula function is used for describing the joint probability of multiple random variables not the marginal distribution for a single random variable there are three main families of copulas elliptical archimedean and quadratic the archimedean copula family which allows for greater flexibility and simplicity of use is consider more suitable for hydro meteorological analyses zhang and singh 2007a 2007b the most common three 2 d archimedean copulas including the clayton copula the gumbel hougaard gh copula and the frank copula table 2 are employed in this study the parameters of the copula functions are estimated at each global 1 grid by the mle method the goodness of fit of copula functions is assessed at each global 1 grid using the k s test eq 2 and rmse eq 3 the best copula at each global 1 grid is selected when it passes the k s test and has the smallest rmse 3 5 joint t in the univariate setting t with a drought feature d s or p is equal to or greater than a certain threshold value x can be defined as shiau and shen 2001 shiau 2006 5 t x e l 1 f x x where f x x is the cdf of x e l denotes the average inter arrival time of the events in the observed sequence which can be computed as xu et al 2015 6 e l n year n drought where n year and n drought are the length of the study period i e 30 yr in this study and the number of years with occurrence of drought events respectively different types of the joint probability distributions can be defined and estimated here the following two types of bivariate joint probabilities p x y and p x y are considered shiau 2006 nabaei et al 2019 7a p x y p x x y y 1 f x x f y y c f x x f y y 7b p x y p x x o r y y 1 c f x x f y y where the symbol denotes the intersection and and denotes the union or the corresponding t of p x y and p x y can be computed as follows 8a t x y e l 1 f x x f y y c f x x f y y 8b t x y e l 1 c f x x f y y 4 results 4 1 bias correction evaluation the cru ts 3 22 gridded dataset was used to correct the biases in simulated monthly pr by using the quantile mapping technique eq 1 the spatial distributions of the relative mean error of the uncorrected and bias corrected pr during bl are compared in fig 2 the uncorrected gcm simulated pr is underestimated over many global regions such as northern south america eastern north america and southwest asia up to 100 while it is overestimated in western and southern south america northern africa western china and northwest north america up to 300 fig 2a after bias correction the relative mean error is reduced to 9 8 for most of global regions with only slight underestimation overestimation found in northern hemisphere south america and northern africa overall the bias corrected monthly pr show a good performance over most global regions and therefore suitable to be used for the subsequent analyses of drought characteristics notice that the relatively large overestimation 29 of pr can be found in northern africa which may introduce large uncertainty in the projections of meteorological drought 4 2 selection of marginal distribution the percentage of global grids identified with the best fitted marginal distribution functions of s p and d i e passing the k s test with the smallest rmse for spi6 and spi12 is summarized in table 3 for the bl nf and ff periods under 2 rcps considered for spi6 the weibull gamma and lognormal are the best fitted marginal distribution functions of s for most global grids ranging respectively 26 9 44 9 28 3 30 9 and 15 5 23 2 among different periods and rcps for p the weibull 25 3 37 gev 14 4 21 3 and gamma 11 1 17 4 are the best fitted functions for most global grids for d the exponential 19 8 31 9 lognormal 17 8 42 2 and weibull 13 8 16 6 are the best fitted distribution functions globally for spi12 however the gamma 29 6 41 7 and lognormal 25 5 32 6 are the best fitted marginal distribution functions of s for most glo0bal grids for p the gamma 14 8 26 7 exponential 18 1 24 and weibull 11 5 22 4 distributions are the best fitted distribution functions for most global grids for d the lognormal 17 2 41 8 and weibull 15 7 25 6 are the best fitted distribution functions for most global grids it is also found that the numbers of total grids identified with the best fitted marginal distribution functions of s and p tend to decrease from rcp2 6 to rcp4 5 and from nf to ff furthermore the total grids identified with the best fitted marginal distribution functions of d of spi12 are apparently larger than that of spi6 suggesting it is more likely to find the optimal marginal distribution functions of d at a longer timescale the global distribution of the best fitted types of pdfs for s p and d of spi6 during bl is shown in fig s2 in supplemental material as seen the best fitted pdfs of s p and d can be identified at most global grids except for those small areas located in northern africa where all the marginal pdfs considered were failed to pass the k s test at 95 significant level this finding is consistent with that of spi12 not displayed in addition a similar spatial distribution pattern can also be observed for both nf and ff periods and under both rcp scenarios not displayed 4 3 selection of copula functions the mle method is applied to all the grids with the identified best fitted marginal distributions for estimating the copula parameters the rmse and k s test are used as the criteria in the goodness of fit test section 3 3 the global grid percentages with the best fitted copula functions for the joint s p s d and p d pdfs of spi6 and spi12 are summarized in table 4 respectively during bl nf and ff periods under both rcps as seen the best fitted copula functions can be identified in most of global grids particularly for the s p joint pdf 90 for the best fitted copula functions of s p pdf of both spi6 and spi12 the frank function has the largest percentage during all bl nf and ff periods under rcp2 6 up to 60 while the clayton function has the largest percentage under rcp4 5 for the best fitted copula of s d joint pdf the frank function has the largest percentage during all three periods and under both rcps except for spi12 during ff under rcp4 5 for the best fitted copula of p d joint pdf during all three periods considered the frank function still has the largest percentage for spi6 74 5 while the gh function has the largest percentage up to 93 5 for spi12 spatially taking the s p s d and p d joint pdfs for spi6 during bl as an example see fig s3 in supplemental material the best fitted copula functions were identified for most global grids except for some regions located in northern africa a similar pattern is found for spi6 and spi12 during nf and ff periods under both rcps not displayed compared with bl the areas without the best fitted copula functions identified for the s d and p d joint pdfs are generally larger up to 27 table 4 during nf and ff periods under both scenarios and these areas located mainly in northern africa coincide with the areas without the marginal pdfs of d identified as shown previously up to 26 8 see table 3 4 4 projected changes in the joint t of drought characteristics 4 4 1 bivariate joint period t x y using equation 8a the specified thresholds of p and s for the above moderate drought defined as s 1 and p 1 and d 3 are used to calculate t x y of the paired drought characteristics p d s d and s p during all the bl nf and ff periods figs 3 5 plot the global distribution of 28 gcm mean changes in t s 1 p 1 t s 1 d 3 and t p 1 d 3 in years respectively for spi6 and spi12 during the nf and ff relative to bl period under both rcps the corresponding continental scale statistics of these mean changes for spi6 and spi12 are summarized in tables s2 and s3 in supplemental material respectively the 28 gcm mean changes are expressed as the differences in the joint t relative to that during bl with a positive negative change denoting a decrease increase in the future drought risk as shown in fig 3 the projected changes in t s 1 p 1 exhibit larger spatial variability during nf than ff for both rcps a decrease in t s 1 p 1 i e higher drought risks during nf 2021 2050 is projected under rcp2 6 in northern and southern north america northern africa southern and northern asia and western australia and under rcp4 5 for most of the northern hemisphere central africa most of sahara desert and western australia in contrast during ff a decrease in t s 1 p 1 is projected under both rcps in most of the southern hemisphere including central and south asia most of northern and southern africa eastern australia and northern south america while a projected increase in t s 1 p 1 found in many parts of the high latitude northern hemisphere particularly in i e northern north america and northern asia overall under rcp4 5 the relative change in t s 1 p 1 generally shows an opposite sign between nf and ff for most of the northern hemisphere and south america relative to spi6 fig 3a the increase in t s 1 p 1 for spi12 fig 3b is expected to occur over the wider global regions and the magnitude is larger 150 years in northern high latitude regions during ff under rcp4 5 comparisons of t s 1 p 1 in fig 3 and t s 1 d 3 in fig 4 reveal the similar global patterns for the projected changes in t s 1 p 1 and t s 1 d 3 however the projected decreases in t s 1 d 3 6 years is significantly smaller than that of t s 1 p 1 37 years overall a larger decrease is projected in t p 1 d 3 up to 70 years suggests larger future drought risks of p 1 and d 3 fig 5 a larger increases in t p 1 d 3 150 years for spi12 during ff is found in most of northern high latitude areas under rcp4 5 indicating a lower probability of the above moderate drought future occurrence over these regions at the continental scales tables s2 and s3 the t s 1 p 1 t s 1 d 3 and t p 1 d 3 for spi6 and spi12 under rcp2 6 are projected to increase lower drought risks during nf over all continents except for t s 1 d 3 in the northern hemisphere the t s 1 p 1 t s 1 d 3 and t p 1 d 3 under rcp2 6 during ff are projected to decrease mainly over oceania and south america for spi6 0 223 year and over oceania for spi12 0 447 year the t s 1 p 1 t s 1 d 3 and t p 1 d 3 during nf under rcp4 5 are projected to decrease over africa asia europe and north america for spi6 0 224 year and over asia and europe 0 244 year for spi12 except for t s 1 p 1 the t s 1 p 1 t s 1 d 3 and t p 1 d 3 under rcp4 5 are projected to decrease only over south america during ff for both spi6 and spi12 0 474 year while the larger increases in t s 1 p 1 t s 1 d 3 and t p 1 d 3 are projected in asia europe and north america particular for spi12 up to 49 years in north america 4 4 2 bivariate joint period t x y figs 6 8 plot the global distributions of 28 gcm mean changes in t s 1 p 1 t s 1 d 3 and t p 1 d 3 in years of the paired drought characteristics p d s d and s p respectively for spi6 and spi12 during nf and ff relative to bl under both rcps with the corresponding continental scale statistics of all t changes summarized in tables s2 spi6 and s3 spi12 in supplemental material for respectively fig 6 shows that a relatively small decrease in t s 1 p 1 increasing drought risks during nf is projected under rcp2 6 in the most parts of north america asia and western australia and under rcp4 5 for most parts of the northern hemisphere and central africa a projected increase in t s 1 p 1 during ff is found in most of the northern hemisphere particularly northern north america and northern asia especially under rcp4 5 20 years in contrast a projected decrease in t s 1 p 1 during ff is found in southwest asia northern and southern africa eastern australia and northern south america fig 6 compared with spi6 the increase in t s 1 p 1 for spi12 during ff is expected to occur in larger global regions particularly in northern asia under both rcps overall the spatial pattern of projected changes in t s 1 p 1 is similar to that of t s 1 p 1 but the magnitude of changes in t s 1 p 1 is significantly smaller than that of t s 1 p 1 fig 3 the projected changes in t s 1 d 3 and t p 1 d 3 figs 7 and 8 exhibit similar global pattern with that of t s 1 p 1 fig 6 the largest increases in t s 1 d 3 and t p 1 d 3 of spi6 and spi12 are mostly found in northern north america and northern asia however the projected decreases in t s 1 d 3 1 7 years and t p 1 d 3 2 years tend to be smaller than that of t s 1 p 1 3 years at the continental scales a large discrepancy in the projected t t s 1 p 1 t s 1 d 3 and t p 1 d 3 can be found between two rcps during nf and ff tables 2 and 3 for both spi6 and spi12 the t s 1 p 1 t s 1 d 3 and t p 1 d 3 are projected to decrease slightly in asia and north america 0 05 year during nf under rcp2 6 during ff under rcp2 6 the t s 1 p 1 t s 1 d 3 and t p 1 d 3 are expected to decrease in africa and oceania for spi6 and only in oceania for spi12 during nf under rcp4 5 the projected decreases in t s 1 p 1 t s 1 d 3 and t p 1 d 3 are found in africa asia europe and north america for spi6 and in asia europe and north america for spi12 in contrast the projected decreases in t s 1 p 1 t s 1 d 3 and t p 1 d 3 during ff under rcp4 5 are found only in south america for spi6 and in oceania and south america for spi12 5 discussion 5 1 influences of climate change on drought risk this study aims at the global analysis of projected changes in the joint t of the paired drought characteristics under 2 rcp scenarios based on the 28 cmip5 gcms simulation data the results indicate that different global regions are projected to suffer varying degrees of drought risks as indicated by the projected t under future climates e g figs 3 8 however a generally opposite sign in the projected changes of joint t is found between nf and ff in some global regions the drought risks during nf ff are projected to increase mainly in north america and asia south america and australia in contrast a decrease in drought risks during nf ff is projected mostly in south america and australia asia europe and north america overall our results indicate a nonlinear response of projected drought risk changes to anthropogenic forcing during the 21st century over many global regions e g north america asia south america and australia suggesting the necessity for adjusting the strategies for managing future drought risks our finding is somewhat different from several previous drought assessment studies using other drought indices which included a measure of the atmospheric demand for moisture burke and brown 2008 sheffield and wood 2008 burke 2011 dai 2013 zhao and dai 2017 prudhomme et al 2014 touma et al 2015 samaniego et al 2018 most of these previous studies reported the consistent monotonical increases in global and regional drought occurrence throughout the 21st century primarily resulting from the increasing evaporation under warming climates the drought index spi used in this study only reflects the precipitation induced meteorological droughts and provides no information on the other drought types and their potential impacts on agriculture ecosystems and societies wu et al 2020 considerable discrepancies in model projected drought characteristics among different drought indices e g spi the palmer drought severity index pdsi the soil moisture anomalies sma the precipitation and potential evaporation anomaly ppea the standardized precipitation evapotranspiration index spei have been reported in numerous previous studies e g burke and brown 2008 touma et al 2015 rhee and cho 2016 in particular burke and brown 2008 indicated that relative to other indices highly responsive to temperature changes spi in general estimates a smaller change in the proportion of land areas under drought the sign and magnitude of changes in drought characteristics are highly dependent on the index definition and hence the selection of appropriate drought indices is of high importance for climate change impact studies 5 2 potential uncertainties in copula based drought risk projections the impacts of climate change and variability on drought characteristics are highly uncertain owing to the complexity of the feedback processes involved in this study six commonly used marginal pdfs normal lognormal gamma exponential gev and weibull were used to fit drought characteristics s p and d and three archimedean copulas clayton gh and frank were used to estimate the joint t of the paired drought characteristics s d p d and s p the results indicate that different drought characteristics follow different distributions resulting in large spatio temporal variability in their best fitted marginal pdfs table 3 and fig s2 as well as the best fitted copulas for their paired drought characteristics table 4 and fig s3 therefore substantial uncertainties may exist in the probability estimation of drought characteristics if only one or few pdfs were selected for analysis in addition to the subjective selection of drought indices and pdfs mentioned above the large uncertainty in projected t of joint drought characteristics s d p d and s p can also be attributed to several other factors first only the multi model 28 gcms mean ensemble changes in the drought characteristics were considered in this study but not the differences among individual gcms therefore the large uncertainties in projected drought regions among gcms as identified in previous cmip3 and cmip5 studies kay et al 2009 giuntoli et al 2015 vetter et al 2017 xu et al 2019 cannot be evaluated here note that this study did not include all available cmip5 models and also only considered one ensemble member for each model and hence cannot account for the full ranges of ensemble averages the selection of models and ensemble members is often subjective and limited by data availability and hence different studies may have used vastly different numbers of models recent studies have shown that the ensemble average and its robustness could be highly dependent on the model choice particularly for the metrics with large systematic differences among models ukkola et al 2018 therefore a large discrepancy among gcms should be accounted for in most projection studies to provide more reliable estimates of future drought projections second although the bias correction method used here shows an overall satisfactory performance in reproducing the spatio temporal variability of pr for most global regions there still exist biases in the corrected pr in certain regions such as the overestimations up to 29 in northern africa and southwest asia and the underestimations up to 9 in central china fig 2 this can introduce large uncertainties in projected drought characteristics over these regions in addition under the univariate and bivariate analyses some regions e g northern and southern africa figs s2 and s3 are not identified with the best fitted marginal distribution and copula functions for d table 3 and for d p and d s table 4 the estimation of drought characteristics using the spatial interpolation or insufficient data over these regions could also be another source of uncertainties to reduce these uncertainties the comprehensive investigations on the sensitivities of drought indices to temperature changes by using more gcms and ensemble members as well as more advanced statistical downscaling methods are indispensable in future research 6 conclusions in this study a global scale projection of meteorological drought characteristics for the near future nf period 2021 2050 and far future ff period 2070 2100 is conducted by using the simulated monthly precipitation data from 28 cmip5 gcms under the rcp2 6 and rcp4 5 scenarios three drought characteristics duration d severity s peak p computed based on the drought index spi were extracted globally at each 1 1 grid by using the runs theory at the 6 and 12 month timescales spi6 and spi12 six marginal distribution functions were used to fit the computed s p and d and three archimedean copula functions were used for generating the global distributions of two different joint return periods t t x y and t x y of various paired drought characteristics for the above moderate drought s 1 p 1 and d 3 the results indicate that different drought characteristics follow different statistical distributions leading to large spatio temporal variability globally in the best fitted marginal probability distributions of drought characteristics as well as the best fitted copulas of the paired drought characteristics overall in terms of the largest percentage of global grids the weibull gamma distribution is the best fitted marginal distribution of s and p of spi6 spi12 while the lognormal distribution is the best fitted distribution of d of both spi6 and spi12 among the best fitted copula functions of spi6 spi12 frank frank and gh has the largest global percentages the t x y and t x y show generally similar spatio temporal patterns but the magnitude of projected changes in t x y is significantly larger than that of t x y an increasing drought risk i e decreasing t x y and t x y is projected during nf mainly in north america and asia 0 22 year and during ff in south america and australia 0 47 year in contrast a decreasing drought risk i e increased t x y and t x y during nf is projected mostly in south america and australia 3 year and during ff in asia europe and north america 49 year furthermore a larger decreasing drought risk is projected under a higher rcp scenario and at a longer timescale overall our results indicate a generally nonlinear response of the projected changes in drought risk to anthropogenic forcing during the 21st century however there are considerable uncertainties in the projected t of various drought characteristics including the choices of drought index gcms and bias correction methods specifically larger uncertainties are found in northern africa due to large errors in gcm data and insufficient grids identified with the best fitted copula functions therefore more comprehensive analyses on the sensitivities of alternative drought indices to temperature changes with the uses of more gcms and ensemble members with different initial conditions and more advanced statistical downscaling methods are necessary in future research directions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by funding from the national natural science foundation of china grant no 51909106 51879108 the natural science foundation of guangdong province china grant no 2020a1515011038 2018a030310653 the high level talent project for the pearl river talent plan of guangdong province grant no 2017gc010397 the youth innovative talents project for guangdong colleges and universities grant no 2017kqncx010 and the fundamental research funds for the central universities grant no 21617301 monthly precipitation data from 28 cmip5 gcms were provided by the canadian climate data and scenarios ccds available at http climatescenarios canada ca page main global gridded 0 5 0 5 monthly precipitation data were obtained from the climatic research unit cru ts 3 22 available at https crudata uea ac uk cru data hrg appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126265 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
