index,text
2965,flow in a fractured rock aquifer beneath the edwards air force base in california was characterized by depth profiling two wells with in well point velocity probes iwpvps the probes which were originally designed for use in porous media wells were optimized for use in fractured rock wells and to meet several challenges including sampling depths up to 38 m high background site water salinity and variable well construction screened vs open borehole and well diameters of 7 62 cm and 15 8 cm the iwpvp measures water flux inside the probe internal flux which is converted to fluxes in the aquifer through calibration at this site the internal fluxes ranged from 3 to 53 m d the channeled internal design of the probe inherently provides information about general flow directions and allows further interpretation of specific flow direction within 15 which at this site was generally consistent with the expected regional flow direction notably a significant shift in the flow system was observed following a rain event up to 180 shift in the flow direction the iwpvp identified highly transmissive zones in the fractured rock which were independently confirmed by passive flux meters and oxidation reduction potential sensors transmissivity profiles determined during a flute flexible liner underground technologies liner deployment also showed similarities in the depths of potentially high flow rates particularly in the shallower portion of the well 20 m with additional information on fracture apertures provided by an acoustic televiewer the internal fluxes were converted to water fluxes in the observed fractures indicating seepage velocities in the rock aquifer between 3 7 m d and 22 4 m d abbreviations iwpvp in well point velocity probe flute flexible liner underground technologies frpfm fractured rock passive flux meter pfm passive flux meter dfn discrete fracture network ffa fracture flow apparatus bgs below ground surface hb half bridge abs acrylonitrile butadiene styrene di deionized water btc breakthrough curve atv acoustic borehole televiewer orp oxidation reduction potential keywords fractured rock in well point velocity probe velocity flux passive flux meter oxidation reduction potential data availability data will be made available on request 1 introduction conventionally flow in fractured rock is characterized by performing hydraulic tests to permit the estimation of empirical effective aquifer parameters including fracture hydraulic conductivity kf fracture porosity nf hydraulic gradient i and fracture aperture 2b these values are used in a form of darcy s law derivable from the cubic law to relate hydraulic gradient to flow rates witherspoon et al 1980 this approach can be used to approximate flow in single fractures or more commonly fracture sets making up a rock aquifer in the latter case an assumption is made that fracture density is sufficient to satisfy equivalent porous medium conditions ghasemizadeh et al 2015 van der kamp 1992 if this assumption is not satisfied darcy calculations based on hydraulic head measurements from wells can result in misleading predictions of groundwater velocity due to both the discrete nature of the fractures and the inherent limitations of the darcy approach alexander et al 2011 butler et al 2007 devlin mcelwee 2007 post von asmuth 2013 ricciardi et al 2009 in addition hydraulic testing commonly involves pumping or pressurization of some portion of a borehole that can dilate or otherwise alter fractures biasing the estimates of kf nf and 2b novakowski et al 1985 parker et al 2012 these tests may be unreliable when performed in open boreholes or well casings where short circuiting of flow across multiple depths is possible i e between fractures not normally connected hydraulically which does not represent ambient flow conditions this can lead to underestimated solute migration predictions berkowitz 2002 the interpretation of hydraulic tests in fractured rock may therefore require a high level of specialized training highlighting a need for new tools not subject to these shortcomings the need for simple effective and reliable tools to identify fracture occurrences in boreholes where flow is occurring and for the quantification of flow is driving the development of new technologies a specific group of these tools is aimed at measuring flow rates with individual fractures or fracture sets without reference to the empirical parameters needed for darcy s law calculations examples of such technologies have been reviewed in some detail elsewhere heyer et al 2021 devlin 2020 and include the fractured rock passive flux meter frpfm which adapts the passive flux meter pfm hatfield et al 2004 to fractured rock settings klammler et al 2016 and flexible impervious liners flexible liner underground technologies http www flute com which have been adapted to measure transmissivity as a function of depth during installation keller et al 2013 the flute liner has the added benefit of sealing the borehole in which it is deployed limiting or preventing cross depth flow flute liners have also been used to support depth specific temperature measurements from which zones of active groundwater flow could be identified cherry et al 2007 novakowski et al 2006 pehme et al 2010 shapiro 2002 while fiber optic distributed temperature sensing has been successful for detailed characterization of fracture networks read et al 2013 this method may be used in conjunction with borehole liners and idealized parallel plate and homogenous rock porosity assumptions in order to quantify depth specific flow at natural gradients maldaner et al 2019 the variety of technologies and the niches they serve has led to the development of a comprehensive approach to fractured rock characterization the discrete fracture network dfn approach this helps guide decision making for the selection of hydraulic and borehole methods to apply in fractured media investigations parker et al 2012 of all the technologies mentioned above none are well suited for quick deployment and able to measure flow from individual fractures spaced less than a meter apart this kind of measurement can be of value for characterizing contaminant migration in fractured rock since contaminants can be restricted to particular fractures or fracture sets a more recent technology that shows promise for addressing this gap in characterization technologies is the in well point velocity probe iwpvp this instrument has provided useful horizontal flow magnitudes and directions from porous media wells both in the laboratory osorno et al 2018 and the field osorno et al 2020 briefly the iwpvp consists of a cylindrical probe through which two perpendicular intersecting channels run water is captured by funnel shaped inlets to the internal measurement channels and is directed through the middle of the probe before exiting the probe on the opposite side tracer is introduced in the center of the probe and is carried through the channels where it is detected and monitored fig 1 the resulting signals can then be interpreted to provide information on both horizontal flow magnitude and direction the iwpvp channels are about 3 cm in height making the probe small enough to measure flow in single fractures in rock or other media or closely spaced fracture sets to test the hypothesis that iwpvps are suitable for use in fractured media laboratory testing was undertaken heyer et al 2021 a fracture flow apparatus ffa was constructed to mimic a single horizontal fracture the ffa was equipped with a mock well allowing deployment of an iwpvp across the simulated fracture by varying flow rates through the ffa and comparing known water fluxes in the fracture qf to fluxes measured inside the probe qp calibration factors could be determined α c qf qp these factors depend on the effective aperture of the fracture also the laboratory work demonstrated that the iwpvp could detect a flow direction to within about 15 to 20 these encouraging findings led to further testing of the probe in field fractured rock wells the goals of this work were to evaluate the iwpvp performance in fractured rock boreholes by identifying the locations of fractures intersecting the borehole and providing estimates of the associated water fluxes and directions of horizontal flow 2 field site the study was conducted at the edwards air force base in california fig 2 the bedrock at the site was classified as the basement complex for a surface deposit of quaternary age overlaying a deposit of tertiary age dutcher and worts 1963 and consists of deeply weathered granites that can be locally unconsolidated wells in this formation typically only yield small quantities of water gsi environmental inc hereafter referred to as gsi described the rock as granitic to dioritic with a strong phaneritic texture and mineralogy consisting of quartz feldspar hornblende and muscovite biotite cm mok personal communication january 2019 depth to groundwater across the study site is typically about 15 m below ground surface bgs with a relatively flat ground surface elevation 3 methods and materials 3 1 gsi instrumentation of the site two boreholes were selected for iwpvp profiling iw 01 and ibh 1 the boreholes were previously installed by gsi for use in a larger scale tracer test the groundwater at the site is known to contain chlorinated ethenes associated with aircraft maintenance and repair the plume extends south and eastward 150 clockwise from n consistent with the regional flow documented by dutcher and worts 1963 fig 2 the first borehole iw 01 was installed with 7 62 cm 3 in inside diameter pvc casing and screen to a depth of about 43 m bgs the second borehole ibh 1 was drilled and cased with a diameter of 22 9 cm 9 in to a depth of 9 m and then telescoped down to a diameter of about 15 8 cm 6 25 in borehole ibh 1 was completed to a depth of about 43 m without casing in addition to the deployment of the iwpvps gsi employed a variety of tools to profile iw 01 and ibh 1 this additional information was used to decide upon depths to be targeted for velocity profiling notably a flute liner was installed in ibh 1 and the transmissivity was determined as a function of depth depth profiles for fracture identification were also obtained from oxidation reduction potential sensors suspended in iw 01 a string of passive flux meters was deployed in iw 01 for a period of about three weeks after the iwpvp profiling these efforts were used in comparisons with the iwpvp profiles 3 2 iwpvp instrumentation the iwpvp fieldwork was carried out early in 2019 the iwpvps were designed to fit the two wells in which they were deployed using a 3d modeling software the probe bodies were fabricated from acrylonitrile butadiene styrene abs plastic and a 3d printer fig 1 the channel lengths funnel sizes and overall diameters of the probe bodies were customized to fit the boreholes with a small amount of annular space that was filled with brushes to limit flow around the outside of the probe the brush packers were not expected to create perfect seals but they established relatively low permeability barriers that directed flow preferentially through the center of the probe fig 1 a b the probes were lowered into place on 0 95 cm diameter stainless steel rods the plastic probe bodies were reinforced with steel brackets the brackets provided the strength required to maintain probe integrity during the probe positioning maneuvers over the 38 m descent into and recovery from the borehole centralizer springs were fixed to the rod immediately above the iwpvp to ensure that the probe remained centered and fully vertical during deployment and measurements the springs consisted of three 1 m long 3 18 mm diameter steel wires fig 3 3 3 procedures prior to iwpvp profiling the probes were fully assembled and the wire tracer lines threaded through the steel rods the alignment of one channel on each of the iwpvps was marked on the full length of steel rod so that the orientation of the probe was always known in the borehole tests were conducted sequentially progressing upward from the deepest measurement location at predetermined intervals selected on the basis of expected zones of water flow and maximizing the number of measurements within a limited testing period deionized water di was selected as the iwpvp tracer because it posed no regulatory concerns and exhibited a clear and measurable conductivity contrast with the background groundwater which had an electrical conductance on the order of 200 μs cm all tracer injections were conducted using an automated syringe pump ne 4000 programmable syringe pump new era pump systems inc each time the probe was repositioned in the borehole the tracer line was flushed with about 5 to 7 ml of di to ensure that any volume injected would enter the central mixing chamber in the probe fig 1d the testing was conducted with injections of between 0 2 ml and 2 ml all tests were repeated until they returned repeated interpretable breakthrough curves the 7 62 cm screened well iw 01 was characterized in a single day from depths of 38 m to 25 m at intervals of about 1 5 m and from depths of 25 m to 18 m in 0 6 m intervals reflecting the anticipated zones of highest fracture density from prior work after decontamination of the rods and lines the larger probe was attached to the lead rod and the 15 8 cm uncased well ibh 1 was profiled over the course of the next three days the longer execution time was due to in part to time spent decontaminating the equipment and to a rain delay midway through the profiling 1 88 cm of precipitation in addition the larger well was subjected to an increased number of tests 18 m to 25 m bgs was characterized at 0 6 m intervals on day 1 on day 2 after the rain event 2 locations of interest 18 9 m and 16 5 m bgs identified during flute deployment were tested depths between 38 m and 21 m bgs were profiled at 1 5 m intervals on day 3 3 4 data analysis iwpvp resistivity data in the form of tracer breakthrough curves btcs were collected and stored with cr1000 dataloggers campbell scientific and analyzed using velprobepe 3 1 beta d schillig 2012 schillig and devlin 2018 which estimates flux on the basis of either one dimensional advection dispersion or method of moments calculations as discussed in heyer et al 2021 the ratio of flux in a fracture q1 l t to that in the probe q2 l t is given by 1 q 1 q 2 b 2 2 b 2 b 1 2 b 1 where b1 is the capture width the probe exerts in the fracture l b2 is the height of the channels in the probe 2 7 cm 2b1 is the aperture of the fracture l and 2b2 is the width of a channels in the probe 0 45 cm because information on the fracture apertures was not known a priori the measured fluxes could not immediately be converted to fluxes in the fractures however relative depth specific apparent fluxes were readily discernible in cases where signals were observed in two probe channels the horizontal flow direction in the aquifer relative to the orientation of the iwpvp during testing was interpreted as described by osorno et al 2018 eq 2 and subsequently corrected for magnetic declination 12 east at the study site determining the apparent angle of flow in the aquifer θ app relative to the probe channel carrying the dominant flow channel1 requires the estimated velocities in the two channels with detected flow v 1 v 2 and the mass fraction weights of the tracer area under the btcs w 1 w 2 2 θ app t a n 1 v 1 w 1 v 2 w 2 3 5 estimation of water flux in the fractures several months after the field campaign acoustic borehole televiewer atv data were acquired from ibh 1 by gsi with this dataset it was possible to visually identify some of the fractures that intersected the borehole and estimate their aperture sizes at the borehole walls note that the visible apertures are not necessarily representative of aperture sizes in the aquifer removed from the borehole in many cases they might be enlarged due to pressure relief or chipping of the borehole wall during drilling so uncertainty exists in any interpretations using these observations nevertheless the apertures determined with the atv provide a starting point for assessing the flow rates in fractures and these can be refined with subsequent data from hydraulic or other forms of testing the range of fracture apertures determined from the atv profile was from a maximum of 14 000 μm to a minimum of 2 500 µm the instrument detection limit pacific surveys www pacificsurveys com smaller aperture fractures that may have been hydraulically active were not included in the subsequent analysis these aperture data were used to estimate fracture fluxes following the approach of heyer et al 2021 briefly a single fracture parallel plate model was used to relate capture zone width to fracture aperture for the observed range of aperture sizes corresponding capture zones of ibh 1 were calculated allowing the determination of calibration factors relating fluxes measured in the probe with those in the fractures 4 results 4 1 iwpvp depth profiles of horizontal flux to assess the trends in relative horizontal flux as a function of depth all iwpvp test results were initially examined as in probe fluxes in borehole iw 01 flow was detected at every depth tested above 36 5 m bgs where no flow was measurable fig 4 a point specific apparent fluxes internal to the probe between about 3 m d and 12 5 m d were observed from depths of 18 m to 29 m at depths greater than 30 m flow rates observed were generally greater with the highest flux 2 47 m d measured at 31 m bgs these measurements were notably above the limits of detection of the probe used in this work which was 1 m d in the probe channels the true detection limits of the probe were not established in this work due to the lower limits of flow imposed by the pump in the fracture apparatus the extended calibration range necessary to span the range of possible velocities at the site devlin 1996 and details of the probe design which are currently being examined for optimization in low flow settings the calibrated relationship between flow in the probe and flow in the surrounding fractures is discussed later in section 4 4 in uncased borehole ibh 1 water flow was detected at all sampled depths except 19 8 m and 22 m bgs fig 4b in general the apparent flux was more variable with depth than had been observed at iw 01 with a range of about 4 m d to 53 m d a similar trend to that observed at iw 01 of higher flow rates at depths greater than 30 m was also observed at ibh 1 4 2 iwpvp derived flow directions all iwpvp flux measurements are accompanied with an apparent horizontal flow direction fig 4 a b the majority of measurements in iw 01 indicated a flow angle between 15 and 110 clockwise from true north with the higher angle dominating fig 4c considering the scale difference of the analysis this compares reasonably well to the sse direction 150 generally expected for the region as reported by dutcher and worts 1963 and shown in fig 4 in the case of borehole ibh 1 flow directions were found to respond very strongly to a prolonged rain event fig 4d prior to the precipitation event measured horizontal flow directions at ibh 1 were dominantly about 105 clockwise from true north consistent with iw 01 measurements conducted after the rain event showed a shift of approximately 180 in groundwater flow direction with flow towards the nnw duplicate measurements were made at both depths 21 m and 24 5 m bgs before and after the rain recorded this flow direction reversal establishing that it was real since all other variables associated with the measurements were either constant or considered the precipitation was the apparent cause of the change in flow direction we also note that in ibh 1 at depths below 27 m which were only tested after the rain the flow direction was predominantly nnw while tests at similar depths in iw 01 before the rain were ese again suggesting the rain caused a pronounced change in flow direction 4 3 alternate tools depth profiles a few months prior to the iwpvp work flute liners were deployed in ibh 1 from which depth specific transmissivities were determined fig 5 the flute method identified zones of relatively high transmissivity at 22 m 28 m and 38 m bgs and zones of very low transmissivity at 21 m bgs and 24 m bgs as discussed below these observations were generally consistent with direct or indirect measurements of flux by other methods oxidation reduction potentials orp were profiled in iw 01 orp can reflect flow distributions when redox sensitive substances such as dissolved oxygen are carried in different concentrations by groundwater in zones of differing velocity under such conditions variations in orp with depth can signify zones of differing flow rates fig 5 for example zones with relatively high orp values may be interpreted as zones of high velocity since in these zones dissolved oxygen can penetrate farther before being reduced biologically or by reactions with chemically reduced mineral phases in the rock the highest flow rates appeared to be at depths of about 22 m 28 m and 34 to 37 m bgs while the lowest apparent flow rates were identified at 27 m and 37 m bgs additionally a string of passive flux meters was deployed in iw 01 over a period of about three weeks beginning immediately after the iwpvp testing was completed the pfms provided time averaged depth specific darcy fluxes fig 5 values shown are approximately corrected for vertical averaging by considering that each 1 m pfm length sampled a combined fracture opening of 0 1 m which was supported by vertical observations of fractures in a neighboring borehole in this case relatively high rates of flow were identified at depths of about 24 m 32 to 35 m and 39 m bgs and relatively low rates at 26 to 29 m and 35 to 38 m bgs the time averaged nature of the pfm data and the somewhat larger sampling interval presumably contributed to less pronounced contrast between the fluxes at various depths with these considerations taken into account the general trends of high and low flow rates identified by the iwpvp and the pfm were consistent with one another and the other methods examined 4 4 preliminary estimation of flow in the aquifer eq 1 can be used to estimate water fluxes of horizontal flow in fractures if the apertures of the fractures are known or can be reasonably estimated this condition was met at five locations where both iwpvp tests and acoustic borehole televiewer logs identified open fractures the physical apertures of these fractures ranged from about 7 500 to 12 000 µm reflecting the highly weathered nature of the rock section 2 0 using this range of apertures the capture zone widths of the well containing the probe were modeled completing the parameter requirement for eq 1 fig 6 a e capture zone widths were obtained from the numerical modeling as the distances between flow lines that converged on and entered the well the calculations showed that larger apertures correspond to smaller capture zone widths as a result of less resistance to flow in the formation compared to the probe the resulting calibration factors for the relevant range of apertures 7 500 to 12 000 µm ranged between 0 783 and 0 991 fig 6f flux in the identified fracture s was then estimated following the method described by heyer et al 2021 application of these factors to obtain water fluxes in the fractures yielded values of 3 7 m d to 22 4 m d fig 7 5 discussion 5 1 characterization of horizontal fluxes in five days of work including set up and teardown and weather interruptions around 150 iwpvp tests were carried out through a total of 80 linear meters of borehole a comparison of iwpvp horizontal flux profiles with those obtained from the pfm orp and flute profiles shows similar trends these trends were pronounced enough to supersede differences in spatial components related to their deployments within different boreholes briefly relatively high values were observed in the depth range 21 m to 24 m lower values in the range 24 m to 26 5 m relatively large values between 32 m bgs and 36 5 m and finally a rise in values near the bottom of the boreholes at a depth of about 39 m fig 5 the variations between the different methods are attributable in part to the fact that the tools were not simultaneously deployed i e the temporal variability in the flow system may lead to differences between measurement techniques in addition there were differences in the locations where the various measurements were made i e instrument positions in the boreholes were not identical and the two wells iw 01 and ibh 1 were located several meters apart finally the sampling intervals time and space were method specific and could have contributed to differences in the profiles for example the pfm measurements represent fluxes averaged over approximately 1 m vertically and are representative of average flow conditions over the three week sampling period in contrast the iwpvp provided a centimeter scale spatial measurement maximum vertical interval of 3 cm over testing periods of 10 to 15 min in summary despite differences in the methods employed there was general consistency in the relative trends of the flow profiles which is encouraging the absolute values of measured flux were not expected to be comparable due to the time intervals and spatial distances sampled neither the flute liner data nor the orp data were suitable for generating flux values so comparisons were not possible between the iwpvp and those technologies the pfm method returned corrected fluxes in the range of 5 m d to 20 m d iw 01 while the iwpvp method returned a range of 0 5 m d to 30 m d in the same well there are a few reasons that account for any discrepancy between the two techniques 1 the pfms could have been suspended in the wells in a manner that allowed water to bypass the instruments and bias measurements low 2 the pfms in the well screen may not have been sufficiently more permeable than the fractures outside the well leading to flow redirection around the well rather than through it 3 the corrected flux values are approximate and do not specifically account for each fracture that may have intersected the borehole 4 apertures measurements applied to the iwpvp calculations were only representative of the borehole walls possible inflated values this would have resulted in flux estimates that are similarly biased high 5 the rock may have an overall higher effective porosity than was represented by the laboratory apparatus from which calibration factors were derived this could have caused a positive bias in flux estimation by the iwpvp and 6 the equations used to relate capture width to aperture are empirical and derived from an ideal fracture while the real world fractures may have deviated introducing error the role of vertical flow in the borehole is uncertain but the consistency of the relative trends in flux with depth by the various methods reported here suggests that vertical short circuiting in the borehole was not very pronounced during the various tests at ibh 1 a transmissivity depth profile was generated during flute liner deployment and was the only dataset available for direct comparison to the iwpvp results in the same borehole it is noted that flute liner estimates of transmissivity lose fidelity in the vicinity of highly permeable zones and are subject to potential losses of sensitivity with depth keller et al 2013 nevertheless the resulting profiles can be useful in identifying relatively high transmissive zones as before good comparisons with the iwpvp data set exist locations of relatively fast flow indicated by the iwpvp generally coincided with indications of high transmissivity by the flute liner fig 5 it is acknowledged that in spite of overall good agreement the methods differed in some details for example the flute liner suggested a transmissive zone at a depth of about 21 3 m that was not recorded by any of the other methods employed in both iw 01 and ibh 1 similarly the iwpvp detected flow at about 32 m depth that showed no correspondence in the flute dataset the orp and pfm profiles suggest an area of maximum flow rates just above 40 m bgs in iw 01 the iwpvp measured a significant jump in flow rates in this same area but not quite to the same degree as the other technologies in the same vein the orp profile reports a large increase in flow at about 27 to 28 m bgs that is not equally reported in the iwpvp and pfm profiles in the iwpvp and pfm profiles the average flows in the shallower half of the borehole are less than those in the deeper half of the borehole but this trend is not as obvious in the orp profile as previously discussed these discrepancies can most likely be attributed to the variance in method specific factors the atv analysis of fracture apertures within borehole ibh 1 revealed physical apertures ranging from about 7 500 to 12 000 µm taking these into account aquifer flux values from 3 70 m d to 22 4 m d were estimated for the respective fractures as alluded to previously these values are likely conservatively high for this site due in part to the atv s detection limit of physical fractures 2 500 µm and the possibility that drilling artificially enhanced fracture apertures at the borehole wall while in this project only a few sampling depths could be used to estimate aquifer fluxes the objective of demonstrating that the iwpvp can be used to measure flow in fractures was achieved 5 2 flow directions the dominant flow directions determined by the iwpvp in iw 01 110 clockwise from n compare reasonably well to the regional flow direction 150 clockwise from n based on historic water table measurements for the site and considering the difference in scales being observed fig 2 fig 4 the occurrence of an apparent secondary flow direction 15 clockwise from n in iw 01 which was 90 from the primary direction raised the possibility that the secondary flow direction was an artifact of the probe with its 90 offset channels however during the testing period the probe was rotated to different orientations in each borehole with no meaningful change to the depth specific flow directions relative to true north the observed stability in measured flow direction independent of iwpvp orientation strongly indicates that the measured flow directions were primarily influenced by the flow in the aquifer rather than imposed by the probe on this basis the flow directions found by the iwpvp are considered representative of aquifer flow within at least 45 a probe quadrant fig 4 in only a few cases flow directions different from the two dominant angles were measured this suggests that although the majority of flow was directed through similarly oriented dominant fractures some flow was possible in less dominant directions a finding that is not unreasonable since the rock at the site has been described as deeply weathered to the point of being potentially locally unconsolidated dutcher and worts 1963 the dominant flow directions at ibh 1 prior to a notable rain event were also in reasonable accordance with expected regional flow direction however following the rain the flow directions apparently and unexpectedly shifted between 180 and 280 measured clockwise from n it is noted that most of the flow measurements after the rainfall were made in the upper section of ibh 1 which had not been sampled before the rain this offered no direct evidence that flow shifted direction in response to the rain however direct evidence of a response to the rainfall was obtained at two sampling locations in ibh 1 at depths of 21 and 24 5 m bgs at both these locations velocity measurements were made before and after the rain and the results confirmed a pronounced directional change also the relatively consistent flow directions in iw 01 at all depths before the rain strongly suggests that the shallow and deep zones in the rock conducted similarly oriented flow before the rain these lines of evidence support the conclusions that the shallow flow at the site was profoundly altered by recharge from the rain 5 3 preliminary identification of vertical flow in a borehole two depths in ibh 1 exhibited unusual characteristics in the iwpvp signals that might have been associated with vertical flow in the borehole at 20 m and 24 m depths tests involving an over injection of tracer volumes 5 ml produced only weak signals this is the expected response if tracer is cleared from the central mixing chamber primarily along the ceiling or floor of the channels through the spaces where detector wires are insulated by the shoes see fig 1 this might be the preferred flow path if flow was passing through the probe with a high vertical component of flow a second line of evidence for vertical flow was explored by plotting the cumulative flux ordinate versus depth measured by the iwpvp abscissa fig 8 steep slopes on the resulting lines develop when horizontal flow continuously adds to the flux total a low slope line results when no new flux adds to the total over a given depth range in such cases second derivatives of these lines will approach zero because the measured flow remains constant over the depth interval any measured flow at this rate is therefore not new flow entering the borehole but is suggestive of vertical flow it must be conceded that the same signal trend could hypothetically be produced if horizontal flow over an interval was the same at every depth tested but this possibility is expected to be a rare occurrence as mentioned previously a few depths in borehole ibh 1 exhibited iwpvp responses that could have been influenced by vertical flow in the borehole most notably at depths 20 m and 24 m as previously mentioned corroborating evidence for this was found in the depth range 24 to 26 m bgs where the second derivative of the cumulative flux curve approached zero suggesting dominantly vertical flow in the borehole this range corresponded to unfractured zone in the atv log 6 conclusion the pilot fieldwork with the iwpvp in fractured media showed for the first time that iwpvps were viable tools for measuring flow in fractured media at depths up to 38 m bgs the technology was shown to be adaptable for well diameters in the range of 7 62 cm and 15 cm 3 in and 6 in respectively design modifications that contributed to the success of the iwpvp in this application included a repositioned tracer injection point inside the probe relocated from the top of the mixing chamber to its center the addition of reinforcing plates to strengthen the probe body for deeper deployment and the addition of a centralizer to the rod immediately above the probe to maintain proper positioning of the probe in the borehole in the screened well iw 01 darcy fluxes internal to the probe were found to vary between 3 and 35 m d in the uncased well ibh 1 higher internal fluxes were achieved but the overall range 4 to 53 m d was not significantly different from iw 01 flow appeared to be dominantly horizontal throughout both boreholes profiled though the iwpvp suggested vertical flow in borehole ibh 1 was likely over the depth range of 24 to 26 m bgs further work is required to better define and differentiate the occurrences of vertical flow in the boreholes trends in flow with depth determined by the iwpvp compared favorably with trends in fracture transmissivity based on flute liner deployment orp measurements made with probes suspended in iw 01 and pfm devices in general the four methods revealed minimally variable flows to a depth of about 30 m higher flows between 30 and 35 m a decline in flow between 35 m and 38 m and indications of increasing flow at greater depths the various technologies produced profiles that differed in the finer details but these differences are attributable to differences in the timings of the measurements i e not simultaneous measurements slight differences in the placements of the instrumentation in the boreholes as well as differences in spatial and temporal averaging associated with the instrument sizes and deployment times the iwpvp indicated a dominant flow direction that was within about 40 of the expected regional direction based on an historical water table map the probe also showed that the shallow fractures were highly responsive to rainfall and exhibited a pronounced change in the dominant direction of flow in borehole ibh 1 after one such an event the iwpvp was shown to be a viable tool for measuring horizontal flow and flow directions in a field setting with fractured media at the edwards air force base the probe was effective in identifying discretely transmissive zones that could be responsible for moving significant contaminant mass moreover the measurements were completed inexpensively and in near real time additional work is recommended to refine methods for the conversion of fluxes inside the probe to fluxes within the fractures and to differentiate vertical from horizontal flow although not an issue in this work ongoing effort is directed at determining the true flow detection limits of the probe used in this work in addition work should continue to optimize the design for settings in which flow rates may be much slower than those observed here credit authorship contribution statement b r heyer methodology formal analysis investigation writing original draft t c osorno methodology investigation writing review editing b a carrera writing review editing c m w mok conceptualization funding acquisition writing review editing j f devlin conceptualization funding acquisition methodology formal analysis investigation supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements gsi environmental inc the department of geology at the university of kansas the university consortium for field focused groundwater research university of guelph bp remediation management services company and air force civil engineering center are acknowledged for providing funding for this research andrew kirkman beth parker allison cormican and matt jones are acknowledged for helpful discussions allen hase and mark stockham of the physics workshop at the university of kansas are acknowledged for providing assistance with model fabrication 
2965,flow in a fractured rock aquifer beneath the edwards air force base in california was characterized by depth profiling two wells with in well point velocity probes iwpvps the probes which were originally designed for use in porous media wells were optimized for use in fractured rock wells and to meet several challenges including sampling depths up to 38 m high background site water salinity and variable well construction screened vs open borehole and well diameters of 7 62 cm and 15 8 cm the iwpvp measures water flux inside the probe internal flux which is converted to fluxes in the aquifer through calibration at this site the internal fluxes ranged from 3 to 53 m d the channeled internal design of the probe inherently provides information about general flow directions and allows further interpretation of specific flow direction within 15 which at this site was generally consistent with the expected regional flow direction notably a significant shift in the flow system was observed following a rain event up to 180 shift in the flow direction the iwpvp identified highly transmissive zones in the fractured rock which were independently confirmed by passive flux meters and oxidation reduction potential sensors transmissivity profiles determined during a flute flexible liner underground technologies liner deployment also showed similarities in the depths of potentially high flow rates particularly in the shallower portion of the well 20 m with additional information on fracture apertures provided by an acoustic televiewer the internal fluxes were converted to water fluxes in the observed fractures indicating seepage velocities in the rock aquifer between 3 7 m d and 22 4 m d abbreviations iwpvp in well point velocity probe flute flexible liner underground technologies frpfm fractured rock passive flux meter pfm passive flux meter dfn discrete fracture network ffa fracture flow apparatus bgs below ground surface hb half bridge abs acrylonitrile butadiene styrene di deionized water btc breakthrough curve atv acoustic borehole televiewer orp oxidation reduction potential keywords fractured rock in well point velocity probe velocity flux passive flux meter oxidation reduction potential data availability data will be made available on request 1 introduction conventionally flow in fractured rock is characterized by performing hydraulic tests to permit the estimation of empirical effective aquifer parameters including fracture hydraulic conductivity kf fracture porosity nf hydraulic gradient i and fracture aperture 2b these values are used in a form of darcy s law derivable from the cubic law to relate hydraulic gradient to flow rates witherspoon et al 1980 this approach can be used to approximate flow in single fractures or more commonly fracture sets making up a rock aquifer in the latter case an assumption is made that fracture density is sufficient to satisfy equivalent porous medium conditions ghasemizadeh et al 2015 van der kamp 1992 if this assumption is not satisfied darcy calculations based on hydraulic head measurements from wells can result in misleading predictions of groundwater velocity due to both the discrete nature of the fractures and the inherent limitations of the darcy approach alexander et al 2011 butler et al 2007 devlin mcelwee 2007 post von asmuth 2013 ricciardi et al 2009 in addition hydraulic testing commonly involves pumping or pressurization of some portion of a borehole that can dilate or otherwise alter fractures biasing the estimates of kf nf and 2b novakowski et al 1985 parker et al 2012 these tests may be unreliable when performed in open boreholes or well casings where short circuiting of flow across multiple depths is possible i e between fractures not normally connected hydraulically which does not represent ambient flow conditions this can lead to underestimated solute migration predictions berkowitz 2002 the interpretation of hydraulic tests in fractured rock may therefore require a high level of specialized training highlighting a need for new tools not subject to these shortcomings the need for simple effective and reliable tools to identify fracture occurrences in boreholes where flow is occurring and for the quantification of flow is driving the development of new technologies a specific group of these tools is aimed at measuring flow rates with individual fractures or fracture sets without reference to the empirical parameters needed for darcy s law calculations examples of such technologies have been reviewed in some detail elsewhere heyer et al 2021 devlin 2020 and include the fractured rock passive flux meter frpfm which adapts the passive flux meter pfm hatfield et al 2004 to fractured rock settings klammler et al 2016 and flexible impervious liners flexible liner underground technologies http www flute com which have been adapted to measure transmissivity as a function of depth during installation keller et al 2013 the flute liner has the added benefit of sealing the borehole in which it is deployed limiting or preventing cross depth flow flute liners have also been used to support depth specific temperature measurements from which zones of active groundwater flow could be identified cherry et al 2007 novakowski et al 2006 pehme et al 2010 shapiro 2002 while fiber optic distributed temperature sensing has been successful for detailed characterization of fracture networks read et al 2013 this method may be used in conjunction with borehole liners and idealized parallel plate and homogenous rock porosity assumptions in order to quantify depth specific flow at natural gradients maldaner et al 2019 the variety of technologies and the niches they serve has led to the development of a comprehensive approach to fractured rock characterization the discrete fracture network dfn approach this helps guide decision making for the selection of hydraulic and borehole methods to apply in fractured media investigations parker et al 2012 of all the technologies mentioned above none are well suited for quick deployment and able to measure flow from individual fractures spaced less than a meter apart this kind of measurement can be of value for characterizing contaminant migration in fractured rock since contaminants can be restricted to particular fractures or fracture sets a more recent technology that shows promise for addressing this gap in characterization technologies is the in well point velocity probe iwpvp this instrument has provided useful horizontal flow magnitudes and directions from porous media wells both in the laboratory osorno et al 2018 and the field osorno et al 2020 briefly the iwpvp consists of a cylindrical probe through which two perpendicular intersecting channels run water is captured by funnel shaped inlets to the internal measurement channels and is directed through the middle of the probe before exiting the probe on the opposite side tracer is introduced in the center of the probe and is carried through the channels where it is detected and monitored fig 1 the resulting signals can then be interpreted to provide information on both horizontal flow magnitude and direction the iwpvp channels are about 3 cm in height making the probe small enough to measure flow in single fractures in rock or other media or closely spaced fracture sets to test the hypothesis that iwpvps are suitable for use in fractured media laboratory testing was undertaken heyer et al 2021 a fracture flow apparatus ffa was constructed to mimic a single horizontal fracture the ffa was equipped with a mock well allowing deployment of an iwpvp across the simulated fracture by varying flow rates through the ffa and comparing known water fluxes in the fracture qf to fluxes measured inside the probe qp calibration factors could be determined α c qf qp these factors depend on the effective aperture of the fracture also the laboratory work demonstrated that the iwpvp could detect a flow direction to within about 15 to 20 these encouraging findings led to further testing of the probe in field fractured rock wells the goals of this work were to evaluate the iwpvp performance in fractured rock boreholes by identifying the locations of fractures intersecting the borehole and providing estimates of the associated water fluxes and directions of horizontal flow 2 field site the study was conducted at the edwards air force base in california fig 2 the bedrock at the site was classified as the basement complex for a surface deposit of quaternary age overlaying a deposit of tertiary age dutcher and worts 1963 and consists of deeply weathered granites that can be locally unconsolidated wells in this formation typically only yield small quantities of water gsi environmental inc hereafter referred to as gsi described the rock as granitic to dioritic with a strong phaneritic texture and mineralogy consisting of quartz feldspar hornblende and muscovite biotite cm mok personal communication january 2019 depth to groundwater across the study site is typically about 15 m below ground surface bgs with a relatively flat ground surface elevation 3 methods and materials 3 1 gsi instrumentation of the site two boreholes were selected for iwpvp profiling iw 01 and ibh 1 the boreholes were previously installed by gsi for use in a larger scale tracer test the groundwater at the site is known to contain chlorinated ethenes associated with aircraft maintenance and repair the plume extends south and eastward 150 clockwise from n consistent with the regional flow documented by dutcher and worts 1963 fig 2 the first borehole iw 01 was installed with 7 62 cm 3 in inside diameter pvc casing and screen to a depth of about 43 m bgs the second borehole ibh 1 was drilled and cased with a diameter of 22 9 cm 9 in to a depth of 9 m and then telescoped down to a diameter of about 15 8 cm 6 25 in borehole ibh 1 was completed to a depth of about 43 m without casing in addition to the deployment of the iwpvps gsi employed a variety of tools to profile iw 01 and ibh 1 this additional information was used to decide upon depths to be targeted for velocity profiling notably a flute liner was installed in ibh 1 and the transmissivity was determined as a function of depth depth profiles for fracture identification were also obtained from oxidation reduction potential sensors suspended in iw 01 a string of passive flux meters was deployed in iw 01 for a period of about three weeks after the iwpvp profiling these efforts were used in comparisons with the iwpvp profiles 3 2 iwpvp instrumentation the iwpvp fieldwork was carried out early in 2019 the iwpvps were designed to fit the two wells in which they were deployed using a 3d modeling software the probe bodies were fabricated from acrylonitrile butadiene styrene abs plastic and a 3d printer fig 1 the channel lengths funnel sizes and overall diameters of the probe bodies were customized to fit the boreholes with a small amount of annular space that was filled with brushes to limit flow around the outside of the probe the brush packers were not expected to create perfect seals but they established relatively low permeability barriers that directed flow preferentially through the center of the probe fig 1 a b the probes were lowered into place on 0 95 cm diameter stainless steel rods the plastic probe bodies were reinforced with steel brackets the brackets provided the strength required to maintain probe integrity during the probe positioning maneuvers over the 38 m descent into and recovery from the borehole centralizer springs were fixed to the rod immediately above the iwpvp to ensure that the probe remained centered and fully vertical during deployment and measurements the springs consisted of three 1 m long 3 18 mm diameter steel wires fig 3 3 3 procedures prior to iwpvp profiling the probes were fully assembled and the wire tracer lines threaded through the steel rods the alignment of one channel on each of the iwpvps was marked on the full length of steel rod so that the orientation of the probe was always known in the borehole tests were conducted sequentially progressing upward from the deepest measurement location at predetermined intervals selected on the basis of expected zones of water flow and maximizing the number of measurements within a limited testing period deionized water di was selected as the iwpvp tracer because it posed no regulatory concerns and exhibited a clear and measurable conductivity contrast with the background groundwater which had an electrical conductance on the order of 200 μs cm all tracer injections were conducted using an automated syringe pump ne 4000 programmable syringe pump new era pump systems inc each time the probe was repositioned in the borehole the tracer line was flushed with about 5 to 7 ml of di to ensure that any volume injected would enter the central mixing chamber in the probe fig 1d the testing was conducted with injections of between 0 2 ml and 2 ml all tests were repeated until they returned repeated interpretable breakthrough curves the 7 62 cm screened well iw 01 was characterized in a single day from depths of 38 m to 25 m at intervals of about 1 5 m and from depths of 25 m to 18 m in 0 6 m intervals reflecting the anticipated zones of highest fracture density from prior work after decontamination of the rods and lines the larger probe was attached to the lead rod and the 15 8 cm uncased well ibh 1 was profiled over the course of the next three days the longer execution time was due to in part to time spent decontaminating the equipment and to a rain delay midway through the profiling 1 88 cm of precipitation in addition the larger well was subjected to an increased number of tests 18 m to 25 m bgs was characterized at 0 6 m intervals on day 1 on day 2 after the rain event 2 locations of interest 18 9 m and 16 5 m bgs identified during flute deployment were tested depths between 38 m and 21 m bgs were profiled at 1 5 m intervals on day 3 3 4 data analysis iwpvp resistivity data in the form of tracer breakthrough curves btcs were collected and stored with cr1000 dataloggers campbell scientific and analyzed using velprobepe 3 1 beta d schillig 2012 schillig and devlin 2018 which estimates flux on the basis of either one dimensional advection dispersion or method of moments calculations as discussed in heyer et al 2021 the ratio of flux in a fracture q1 l t to that in the probe q2 l t is given by 1 q 1 q 2 b 2 2 b 2 b 1 2 b 1 where b1 is the capture width the probe exerts in the fracture l b2 is the height of the channels in the probe 2 7 cm 2b1 is the aperture of the fracture l and 2b2 is the width of a channels in the probe 0 45 cm because information on the fracture apertures was not known a priori the measured fluxes could not immediately be converted to fluxes in the fractures however relative depth specific apparent fluxes were readily discernible in cases where signals were observed in two probe channels the horizontal flow direction in the aquifer relative to the orientation of the iwpvp during testing was interpreted as described by osorno et al 2018 eq 2 and subsequently corrected for magnetic declination 12 east at the study site determining the apparent angle of flow in the aquifer θ app relative to the probe channel carrying the dominant flow channel1 requires the estimated velocities in the two channels with detected flow v 1 v 2 and the mass fraction weights of the tracer area under the btcs w 1 w 2 2 θ app t a n 1 v 1 w 1 v 2 w 2 3 5 estimation of water flux in the fractures several months after the field campaign acoustic borehole televiewer atv data were acquired from ibh 1 by gsi with this dataset it was possible to visually identify some of the fractures that intersected the borehole and estimate their aperture sizes at the borehole walls note that the visible apertures are not necessarily representative of aperture sizes in the aquifer removed from the borehole in many cases they might be enlarged due to pressure relief or chipping of the borehole wall during drilling so uncertainty exists in any interpretations using these observations nevertheless the apertures determined with the atv provide a starting point for assessing the flow rates in fractures and these can be refined with subsequent data from hydraulic or other forms of testing the range of fracture apertures determined from the atv profile was from a maximum of 14 000 μm to a minimum of 2 500 µm the instrument detection limit pacific surveys www pacificsurveys com smaller aperture fractures that may have been hydraulically active were not included in the subsequent analysis these aperture data were used to estimate fracture fluxes following the approach of heyer et al 2021 briefly a single fracture parallel plate model was used to relate capture zone width to fracture aperture for the observed range of aperture sizes corresponding capture zones of ibh 1 were calculated allowing the determination of calibration factors relating fluxes measured in the probe with those in the fractures 4 results 4 1 iwpvp depth profiles of horizontal flux to assess the trends in relative horizontal flux as a function of depth all iwpvp test results were initially examined as in probe fluxes in borehole iw 01 flow was detected at every depth tested above 36 5 m bgs where no flow was measurable fig 4 a point specific apparent fluxes internal to the probe between about 3 m d and 12 5 m d were observed from depths of 18 m to 29 m at depths greater than 30 m flow rates observed were generally greater with the highest flux 2 47 m d measured at 31 m bgs these measurements were notably above the limits of detection of the probe used in this work which was 1 m d in the probe channels the true detection limits of the probe were not established in this work due to the lower limits of flow imposed by the pump in the fracture apparatus the extended calibration range necessary to span the range of possible velocities at the site devlin 1996 and details of the probe design which are currently being examined for optimization in low flow settings the calibrated relationship between flow in the probe and flow in the surrounding fractures is discussed later in section 4 4 in uncased borehole ibh 1 water flow was detected at all sampled depths except 19 8 m and 22 m bgs fig 4b in general the apparent flux was more variable with depth than had been observed at iw 01 with a range of about 4 m d to 53 m d a similar trend to that observed at iw 01 of higher flow rates at depths greater than 30 m was also observed at ibh 1 4 2 iwpvp derived flow directions all iwpvp flux measurements are accompanied with an apparent horizontal flow direction fig 4 a b the majority of measurements in iw 01 indicated a flow angle between 15 and 110 clockwise from true north with the higher angle dominating fig 4c considering the scale difference of the analysis this compares reasonably well to the sse direction 150 generally expected for the region as reported by dutcher and worts 1963 and shown in fig 4 in the case of borehole ibh 1 flow directions were found to respond very strongly to a prolonged rain event fig 4d prior to the precipitation event measured horizontal flow directions at ibh 1 were dominantly about 105 clockwise from true north consistent with iw 01 measurements conducted after the rain event showed a shift of approximately 180 in groundwater flow direction with flow towards the nnw duplicate measurements were made at both depths 21 m and 24 5 m bgs before and after the rain recorded this flow direction reversal establishing that it was real since all other variables associated with the measurements were either constant or considered the precipitation was the apparent cause of the change in flow direction we also note that in ibh 1 at depths below 27 m which were only tested after the rain the flow direction was predominantly nnw while tests at similar depths in iw 01 before the rain were ese again suggesting the rain caused a pronounced change in flow direction 4 3 alternate tools depth profiles a few months prior to the iwpvp work flute liners were deployed in ibh 1 from which depth specific transmissivities were determined fig 5 the flute method identified zones of relatively high transmissivity at 22 m 28 m and 38 m bgs and zones of very low transmissivity at 21 m bgs and 24 m bgs as discussed below these observations were generally consistent with direct or indirect measurements of flux by other methods oxidation reduction potentials orp were profiled in iw 01 orp can reflect flow distributions when redox sensitive substances such as dissolved oxygen are carried in different concentrations by groundwater in zones of differing velocity under such conditions variations in orp with depth can signify zones of differing flow rates fig 5 for example zones with relatively high orp values may be interpreted as zones of high velocity since in these zones dissolved oxygen can penetrate farther before being reduced biologically or by reactions with chemically reduced mineral phases in the rock the highest flow rates appeared to be at depths of about 22 m 28 m and 34 to 37 m bgs while the lowest apparent flow rates were identified at 27 m and 37 m bgs additionally a string of passive flux meters was deployed in iw 01 over a period of about three weeks beginning immediately after the iwpvp testing was completed the pfms provided time averaged depth specific darcy fluxes fig 5 values shown are approximately corrected for vertical averaging by considering that each 1 m pfm length sampled a combined fracture opening of 0 1 m which was supported by vertical observations of fractures in a neighboring borehole in this case relatively high rates of flow were identified at depths of about 24 m 32 to 35 m and 39 m bgs and relatively low rates at 26 to 29 m and 35 to 38 m bgs the time averaged nature of the pfm data and the somewhat larger sampling interval presumably contributed to less pronounced contrast between the fluxes at various depths with these considerations taken into account the general trends of high and low flow rates identified by the iwpvp and the pfm were consistent with one another and the other methods examined 4 4 preliminary estimation of flow in the aquifer eq 1 can be used to estimate water fluxes of horizontal flow in fractures if the apertures of the fractures are known or can be reasonably estimated this condition was met at five locations where both iwpvp tests and acoustic borehole televiewer logs identified open fractures the physical apertures of these fractures ranged from about 7 500 to 12 000 µm reflecting the highly weathered nature of the rock section 2 0 using this range of apertures the capture zone widths of the well containing the probe were modeled completing the parameter requirement for eq 1 fig 6 a e capture zone widths were obtained from the numerical modeling as the distances between flow lines that converged on and entered the well the calculations showed that larger apertures correspond to smaller capture zone widths as a result of less resistance to flow in the formation compared to the probe the resulting calibration factors for the relevant range of apertures 7 500 to 12 000 µm ranged between 0 783 and 0 991 fig 6f flux in the identified fracture s was then estimated following the method described by heyer et al 2021 application of these factors to obtain water fluxes in the fractures yielded values of 3 7 m d to 22 4 m d fig 7 5 discussion 5 1 characterization of horizontal fluxes in five days of work including set up and teardown and weather interruptions around 150 iwpvp tests were carried out through a total of 80 linear meters of borehole a comparison of iwpvp horizontal flux profiles with those obtained from the pfm orp and flute profiles shows similar trends these trends were pronounced enough to supersede differences in spatial components related to their deployments within different boreholes briefly relatively high values were observed in the depth range 21 m to 24 m lower values in the range 24 m to 26 5 m relatively large values between 32 m bgs and 36 5 m and finally a rise in values near the bottom of the boreholes at a depth of about 39 m fig 5 the variations between the different methods are attributable in part to the fact that the tools were not simultaneously deployed i e the temporal variability in the flow system may lead to differences between measurement techniques in addition there were differences in the locations where the various measurements were made i e instrument positions in the boreholes were not identical and the two wells iw 01 and ibh 1 were located several meters apart finally the sampling intervals time and space were method specific and could have contributed to differences in the profiles for example the pfm measurements represent fluxes averaged over approximately 1 m vertically and are representative of average flow conditions over the three week sampling period in contrast the iwpvp provided a centimeter scale spatial measurement maximum vertical interval of 3 cm over testing periods of 10 to 15 min in summary despite differences in the methods employed there was general consistency in the relative trends of the flow profiles which is encouraging the absolute values of measured flux were not expected to be comparable due to the time intervals and spatial distances sampled neither the flute liner data nor the orp data were suitable for generating flux values so comparisons were not possible between the iwpvp and those technologies the pfm method returned corrected fluxes in the range of 5 m d to 20 m d iw 01 while the iwpvp method returned a range of 0 5 m d to 30 m d in the same well there are a few reasons that account for any discrepancy between the two techniques 1 the pfms could have been suspended in the wells in a manner that allowed water to bypass the instruments and bias measurements low 2 the pfms in the well screen may not have been sufficiently more permeable than the fractures outside the well leading to flow redirection around the well rather than through it 3 the corrected flux values are approximate and do not specifically account for each fracture that may have intersected the borehole 4 apertures measurements applied to the iwpvp calculations were only representative of the borehole walls possible inflated values this would have resulted in flux estimates that are similarly biased high 5 the rock may have an overall higher effective porosity than was represented by the laboratory apparatus from which calibration factors were derived this could have caused a positive bias in flux estimation by the iwpvp and 6 the equations used to relate capture width to aperture are empirical and derived from an ideal fracture while the real world fractures may have deviated introducing error the role of vertical flow in the borehole is uncertain but the consistency of the relative trends in flux with depth by the various methods reported here suggests that vertical short circuiting in the borehole was not very pronounced during the various tests at ibh 1 a transmissivity depth profile was generated during flute liner deployment and was the only dataset available for direct comparison to the iwpvp results in the same borehole it is noted that flute liner estimates of transmissivity lose fidelity in the vicinity of highly permeable zones and are subject to potential losses of sensitivity with depth keller et al 2013 nevertheless the resulting profiles can be useful in identifying relatively high transmissive zones as before good comparisons with the iwpvp data set exist locations of relatively fast flow indicated by the iwpvp generally coincided with indications of high transmissivity by the flute liner fig 5 it is acknowledged that in spite of overall good agreement the methods differed in some details for example the flute liner suggested a transmissive zone at a depth of about 21 3 m that was not recorded by any of the other methods employed in both iw 01 and ibh 1 similarly the iwpvp detected flow at about 32 m depth that showed no correspondence in the flute dataset the orp and pfm profiles suggest an area of maximum flow rates just above 40 m bgs in iw 01 the iwpvp measured a significant jump in flow rates in this same area but not quite to the same degree as the other technologies in the same vein the orp profile reports a large increase in flow at about 27 to 28 m bgs that is not equally reported in the iwpvp and pfm profiles in the iwpvp and pfm profiles the average flows in the shallower half of the borehole are less than those in the deeper half of the borehole but this trend is not as obvious in the orp profile as previously discussed these discrepancies can most likely be attributed to the variance in method specific factors the atv analysis of fracture apertures within borehole ibh 1 revealed physical apertures ranging from about 7 500 to 12 000 µm taking these into account aquifer flux values from 3 70 m d to 22 4 m d were estimated for the respective fractures as alluded to previously these values are likely conservatively high for this site due in part to the atv s detection limit of physical fractures 2 500 µm and the possibility that drilling artificially enhanced fracture apertures at the borehole wall while in this project only a few sampling depths could be used to estimate aquifer fluxes the objective of demonstrating that the iwpvp can be used to measure flow in fractures was achieved 5 2 flow directions the dominant flow directions determined by the iwpvp in iw 01 110 clockwise from n compare reasonably well to the regional flow direction 150 clockwise from n based on historic water table measurements for the site and considering the difference in scales being observed fig 2 fig 4 the occurrence of an apparent secondary flow direction 15 clockwise from n in iw 01 which was 90 from the primary direction raised the possibility that the secondary flow direction was an artifact of the probe with its 90 offset channels however during the testing period the probe was rotated to different orientations in each borehole with no meaningful change to the depth specific flow directions relative to true north the observed stability in measured flow direction independent of iwpvp orientation strongly indicates that the measured flow directions were primarily influenced by the flow in the aquifer rather than imposed by the probe on this basis the flow directions found by the iwpvp are considered representative of aquifer flow within at least 45 a probe quadrant fig 4 in only a few cases flow directions different from the two dominant angles were measured this suggests that although the majority of flow was directed through similarly oriented dominant fractures some flow was possible in less dominant directions a finding that is not unreasonable since the rock at the site has been described as deeply weathered to the point of being potentially locally unconsolidated dutcher and worts 1963 the dominant flow directions at ibh 1 prior to a notable rain event were also in reasonable accordance with expected regional flow direction however following the rain the flow directions apparently and unexpectedly shifted between 180 and 280 measured clockwise from n it is noted that most of the flow measurements after the rainfall were made in the upper section of ibh 1 which had not been sampled before the rain this offered no direct evidence that flow shifted direction in response to the rain however direct evidence of a response to the rainfall was obtained at two sampling locations in ibh 1 at depths of 21 and 24 5 m bgs at both these locations velocity measurements were made before and after the rain and the results confirmed a pronounced directional change also the relatively consistent flow directions in iw 01 at all depths before the rain strongly suggests that the shallow and deep zones in the rock conducted similarly oriented flow before the rain these lines of evidence support the conclusions that the shallow flow at the site was profoundly altered by recharge from the rain 5 3 preliminary identification of vertical flow in a borehole two depths in ibh 1 exhibited unusual characteristics in the iwpvp signals that might have been associated with vertical flow in the borehole at 20 m and 24 m depths tests involving an over injection of tracer volumes 5 ml produced only weak signals this is the expected response if tracer is cleared from the central mixing chamber primarily along the ceiling or floor of the channels through the spaces where detector wires are insulated by the shoes see fig 1 this might be the preferred flow path if flow was passing through the probe with a high vertical component of flow a second line of evidence for vertical flow was explored by plotting the cumulative flux ordinate versus depth measured by the iwpvp abscissa fig 8 steep slopes on the resulting lines develop when horizontal flow continuously adds to the flux total a low slope line results when no new flux adds to the total over a given depth range in such cases second derivatives of these lines will approach zero because the measured flow remains constant over the depth interval any measured flow at this rate is therefore not new flow entering the borehole but is suggestive of vertical flow it must be conceded that the same signal trend could hypothetically be produced if horizontal flow over an interval was the same at every depth tested but this possibility is expected to be a rare occurrence as mentioned previously a few depths in borehole ibh 1 exhibited iwpvp responses that could have been influenced by vertical flow in the borehole most notably at depths 20 m and 24 m as previously mentioned corroborating evidence for this was found in the depth range 24 to 26 m bgs where the second derivative of the cumulative flux curve approached zero suggesting dominantly vertical flow in the borehole this range corresponded to unfractured zone in the atv log 6 conclusion the pilot fieldwork with the iwpvp in fractured media showed for the first time that iwpvps were viable tools for measuring flow in fractured media at depths up to 38 m bgs the technology was shown to be adaptable for well diameters in the range of 7 62 cm and 15 cm 3 in and 6 in respectively design modifications that contributed to the success of the iwpvp in this application included a repositioned tracer injection point inside the probe relocated from the top of the mixing chamber to its center the addition of reinforcing plates to strengthen the probe body for deeper deployment and the addition of a centralizer to the rod immediately above the probe to maintain proper positioning of the probe in the borehole in the screened well iw 01 darcy fluxes internal to the probe were found to vary between 3 and 35 m d in the uncased well ibh 1 higher internal fluxes were achieved but the overall range 4 to 53 m d was not significantly different from iw 01 flow appeared to be dominantly horizontal throughout both boreholes profiled though the iwpvp suggested vertical flow in borehole ibh 1 was likely over the depth range of 24 to 26 m bgs further work is required to better define and differentiate the occurrences of vertical flow in the boreholes trends in flow with depth determined by the iwpvp compared favorably with trends in fracture transmissivity based on flute liner deployment orp measurements made with probes suspended in iw 01 and pfm devices in general the four methods revealed minimally variable flows to a depth of about 30 m higher flows between 30 and 35 m a decline in flow between 35 m and 38 m and indications of increasing flow at greater depths the various technologies produced profiles that differed in the finer details but these differences are attributable to differences in the timings of the measurements i e not simultaneous measurements slight differences in the placements of the instrumentation in the boreholes as well as differences in spatial and temporal averaging associated with the instrument sizes and deployment times the iwpvp indicated a dominant flow direction that was within about 40 of the expected regional direction based on an historical water table map the probe also showed that the shallow fractures were highly responsive to rainfall and exhibited a pronounced change in the dominant direction of flow in borehole ibh 1 after one such an event the iwpvp was shown to be a viable tool for measuring horizontal flow and flow directions in a field setting with fractured media at the edwards air force base the probe was effective in identifying discretely transmissive zones that could be responsible for moving significant contaminant mass moreover the measurements were completed inexpensively and in near real time additional work is recommended to refine methods for the conversion of fluxes inside the probe to fluxes within the fractures and to differentiate vertical from horizontal flow although not an issue in this work ongoing effort is directed at determining the true flow detection limits of the probe used in this work in addition work should continue to optimize the design for settings in which flow rates may be much slower than those observed here credit authorship contribution statement b r heyer methodology formal analysis investigation writing original draft t c osorno methodology investigation writing review editing b a carrera writing review editing c m w mok conceptualization funding acquisition writing review editing j f devlin conceptualization funding acquisition methodology formal analysis investigation supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements gsi environmental inc the department of geology at the university of kansas the university consortium for field focused groundwater research university of guelph bp remediation management services company and air force civil engineering center are acknowledged for providing funding for this research andrew kirkman beth parker allison cormican and matt jones are acknowledged for helpful discussions allen hase and mark stockham of the physics workshop at the university of kansas are acknowledged for providing assistance with model fabrication 
2966,as an important technology for measuring water levels satellite altimetry has been widely using in the lake river and wetland in the past two decades however the waveform pollution limits its application in areas with complex topography the accuracy of the existing retracking algorithms need to be further improved in this study a new retracking algorithm named improved narrow primary peak threshold retracking algorithm inpptr based on narrow primary peak threshold retracking algorithm npptr is presented this retracking algorithm eliminates the noise in the waveform extracts more accurate main peaks of the waveform and performs gaussian fitting on the main peaks with serious waveform pollution finally the more stable water levels in areas with complex terrain can be obtained from cryosat 2 synthetic aperture radar interferometer sarin waveform to verify the accuracy of retracking algorithms the water level time series of eight lakes and one river were retrieved using inpptr and other three retracking algorithms npptr nppor and mwapp then were compared to the in situ data for qinghai lake namco lake selin lake zhair namco lake issyk lake great salt lake tahoe lake and great slave lake where sarin mode is used and the root mean squared errors rmse obtained by inpptr are 18 09 cm 21 69 cm 20 48 cm 34 82 cm 17 39 cm 39 68 cm 26 25 cm and 18 43 cm respectively compared with npptr the rmse of inpptr is reduced by 9 91 14 83 7 62 14 74 6 70 4 11 105 37 and 25 02 respectively for the amazon river the rmse of inpptr is 58 24 cm compared with the other three retracking algorithms the rmse obtained by inpptr is the lowest as well in summary the accuracy of inpptr is significantly higher than the other three retracking algorithms and inpptr can process cryosat 2 sarin data effectively and provide more stable and effective water levels laying the foundation for long term high accuracy water levels monitoring of inland water bodies with complex terrain keywords satellite altimetry cryosat 2 sarin inpptr inland water water levels data availability no data was used for the research described in the article 1 introduction there are approximately 117 million lakes and 200 international rivers on the earth s land surface verpoorter et al 2014 these lakes and rivers provide habitats for many species and provide the necessary freshwater resources for human activities the spatial distribution of water resources reflects the regional differences and utilization of surface water resources to some extent in addition the spatial and temporal variability of water resources reflects the effects of climate change surface processes and human activities on the water cycle therefore long term and high accuracy of the inland water levels monitoring of waters has become more and more important traditional lake and river levels are usually measured by hydrological stations which are expensive to build and maintain and consume a lot of labor and material therefore the number of global hydrological stations continues to decrease resulting in a reduction in the amount of on site measurements which is not conducive to monitoring the dynamic balance of global hydrology many scholars use physical models e g water balance models climate model systems and hydrological models to estimate changes in lake water levels bengtsson and malm 1997 however due to changes in physical factors in different regions it is difficult to establish a physical model that is applicable to all regions after 20 years of development satellite altimetry has become an important method for monitoring inland water levels independent of infrastructure especially in remote areas where maintenance of monitoring stations is expensive berry et al 2005 birkett 1995 birkett 1998 duan and bastiaanssen 2013 frappart et al 2005 jiang et al 2017a which has the significance of great water resources management in addition the role of satellite altimetry data in near real time and long term series has also been proven in several studies such as discharge modeling and flood warning liu et al 2019 the arrival of the esa s cryosat 2 mission in april 2010 marked a new era of satellite radar altimetry cryosat 2 carries the state of the art synthetic aperture interferometric radar altimeter siral on board which can operate in three different modes low resolution mode lrm synthetic aperture radar sar and sar interferometer sarin traditional altimeter radars are equipped with low resolution lrm radars such as envisat satellites due to factors of the duration pulse of radar satellite orbit height and the roughness of the reflecting surface the effective coverage diameter of envisat satellite radar altimeters is 1 6 13 4 km chelton et al 2001 compared to the circular footprint of the conventional pulse limited altimeter 10 km in diameter the cryosat 2 orbit has a smaller footprint band 300 m along the orbit and 1 km across the orbit using the beam wingham et al 2006 the reduced of footprint size of cryosat 2 reduces the effects of complex nearshore topography and improves the accuracy of water levels estimates in small lakes and rivers jiang et al 2017b the revisit period of conventional altimetry satellites is 10 35 days which results in low spatial coverage of the orbit orbital separation near the equator is at least 80 km jarihani et al 2013 so it is difficult to monitor lakes with a small area cryosat 2 satellite adopts a long repetitive 369 days drift orbit and has the advantages of the short distance between tracks and high spatial coverage providing the possibility of monitoring small lakes the quality of water level data obtained from satellite altimetry can be improved by waveform retracking i e modifying the initial range derived from the two way travel time of radar short pulses sent to the inland water surface and reflected birkett 1998 many studies are available on waveform retracking in wingham et al 1986 they proposed the offset centre of gravity ocog retracking algorithm and obtained relatively good results in davis 1995 he proposed the threshold retracking algorithm threshold which turned out to be superior to the 5 β retracking algorithm and the 9 β retracking algorithm however the traditional ocog threshold 5 β retracking algorithm and 9 β retracking algorithm developed for lrm are not applicable to sar and sarin jain et al 2015 in andersen et al 2015 they proposed the narrow primary peak ocog retracking algorithm nppor and the narrow primary peak threshold retracking algorithm npptr the by improving ocog and threshold in nielsen et al 2015 they proposed the narrow primary peak retractor nppr verified the measurement results according to the in situ data and obtained the highest accuracy of lake level measurement at that time with the rmse between 7 and 20 cm in villadsen et al 2016 they proposed the empirical methods multiple waveform persistent peak mwapp retracking algorithm and combined it with the samosa3 physical retracker however the sarin and sar waveforms of the cryosat 2 satellite are very different in the sarin mode the bin of the waveform data is 1 024 and the nominal range bin number is 256 so the applicability of the above method to sarin still needs further improvement based on the npptr this paper proposes the improved narrow primary peak threshold retracking algorithm inpptr for sarin waveform to obtain stable water levels in plateau areas the inpptr solves the problem that the npptr is greatly affected by the waveform noise when extracting the endpoint of the main peak of the complex waveform and based on the gaussian normal distribution curve to simulate the disturbed waveform data it also solves the problem of low water levels measurement accuracy of the npptr in areas with complex terrain such as mountains and glaciers it can obtain stable water level even in areas with complex topography and provides a low cost high efficiency and high precision water level estimation method for remote plateau areas finally in order to verify the accuracy of the inpptr the water levels of eight lakes and one river were calculated by the four retracking algorithms inpptr npptr nppor and mwapp are compared with the in situ data 2 data and study area 2 1 cryosat 2 20 hz sarin data esa provides cryosat 2 data in level 1 l1 and level 2 l2 mode this paper uses the 20 hz l1b data of sarin from the cryosat 2 satellite unlike other satellites cryosat 2 does not have a fixed orbit and can use the following websites to assist in downloading data https science pds cryosat esa int l1 contains the orbit information and the echoes received by the altimeter also called waveforms l2 contains the geophysical corrections for the sarin mode the bin of the waveform data is 1 024 and the nominal range bin number is 512 when using cryosat 2 data to obtain the water levels the return waveform deviates from the default preset point of the airborne retracking algorithm due to the irregular surface of the water body in order to obtain accurate water levels it is necessary to use different retracking algorithms to relocate the preset point of the waveform davis 1997 fig 1 shows the waveforms of traditional lrm mode sar and sarin mode from cryosat 2 the return waveform of the sar mode and sarin mode is of difference from the lrm and have a leading edge and a narrower trailing edge therefore a new retracking algorithm is required to obtain more accurate water levels 2 2 study area this paper selects seven lakes from four countries china u s kyrgyzstan and canada and amazon river in brazil and peru covered by sarin mode as the study area the geographical location of the water bodies and the corresponding cryosat 2 orbits are shown in fig 2 table 1 gives the details of the research water bodies the data covered periods and the observation mode of the data used among them the four lakes on the qinghai tibet plateau qinghai lake zhair namco lake namco lake and selin lake issyk lake in kyrgyzstan great salt lake and tahoe lake in the united states all have the following characteristics 1 the surrounding terrain is complex which will cause great interference to the data 2 high altitude the average altitude is higher than 1 000 m 3 long ice period in winter the ice period is from november to march of the next year the terrain around the great slave lake in canada is complex with low altitude located in high latitudes and has a long ice period in winter which is an excellent water body to verify inpptr the amazon river in brazil and peru is the widest and most flowing river in the world its water levels change evident in season and the river is more expansive the width of the dry season is a few kilometers the rainy season can reach 48 km so it is suitable for verifying the accuracy of the retracking algorithm the in situ water level observations of the great salt lake and tahoe lake are available at the national water information system https maps waterdata usgs gov with the elevation datum of navd29 the two lakes mentioned above were converted to the benchmarks where the in situ data are located using the vdatum tool https vdatum noaa gov vdatumweb provided by noaa the in situ water level of the great slave lake can be downloaded from the official website of the government of canada https wateroffice ec gc ca mainmenu historical data index e html which using the geodetic survey of assumed datum as the elevation datum daily water levels of amazon river were obtained through the national service of meteorology and hydrology of peru https www gob pe senamhi the elevation datum for the area is unknown since great slave lake and amazon river do not use a standard elevation datum a mean deviation is subtracted when comparing the retrieved water levels to this data the in situ data of lakes in china and kyrgyzstan are not available using the water level products from certain database instead for qinghai lake namco lake and selin lake the water levels from the hydroweb database http www legos obs mip fr soa hydrologie hydroweb are chosen as the in situ data since the hydroweb database lacking the water levels records for zhair namco lake and issyk lake take the dahiti http dahiti dgfi tum de en as a supplement the in situ data of the above database has passed the verification of multiple papers and the data accuracy is reliable bhagwat et al 2019 chen et al 2018 schwatke et al 2020 shu et al 2020 vickers et al 2019 2 3 water mask global lakes and wetlands database glwd was created by the world nature foundation and the center for environmental systems research the university of kassel using existing maps data and information combined with geographic information system gis and global lakes and wetlands best available resources three levels of databases https www worldwildlife org pages global lakes and wetlands database level 1 database glwd 1 includes 3 607 largest lakes area 50 km2 worldwide and the largest 645 reservoirs of the world storage capacity 0 5 km2 level 2 glwd 2 comprises permanent open water bodies with a surface area 0 1 km2 excluding the water bodies contained in glwd 1 level 3 database contains a boundary file of the reservoir the vector boundaries of the amazon river research area in this paper are extracted by landsat 8 landsat 8 is the eighth satellite in the u s land satellite plan with the successful launch on january 16 2021 http glovis usgs gov 3 methodology 3 1 inland water level estimation satellite altimetry technology uses satellites as carriers and uses space borne microwave radar altimeters to emit microwave pulses to the surface of water body the pulse returns to the radar altimeter after being reflected by the water body passing the time difference t between the departure pulse and the returning pulse the distance hrange from the satellite to the water body can be calculated in eq 1 the diagram of the principle of satellite altimetry is shown in fig 3 1 h range c t 2 where hrange is the height of the satellite relative to the water body c is the speed of light and t is the pulse round trip time using the orbit height of the satellite above the reference ellipsoid minus the distance from the satellite to the water and the height of the geoid above the reference ellipsoid the water levels h can be obtained as shown in eq 2 2 h h alt h range n geoid where halt is the orbit height of the satellite above the reference ellipsoid and ngeoid is the geoid height above the reference ellipsoid hrange is not given in the cryosat 2 satellite and it is calculated by the central window delay wd for retracking correction hretrack plus the sum of other corrections hgeo hgeo includes ionospheric correction dry tropospheric correction wet tropospheric correction solid tide correction tide correction and sea deviation correction all of which are given in level 1b product all retracked heights presented in this paper were transferred from the wgs84 ellipsoid to the egm08 geoid egm2008 provides detailed and accurate gravity data for the first time in history and the result is comparable to the regional geoid algorithm andersen and knudsen 2009 pavlis et al 2012 the process of using retracking technology to determine the height of the water surface is shown in eq 30 andersen and scharroo 2011 3 h range c 2 w d h retrack h geo h retrack b spc c npt c rtck where bspc is the bin spacing in meters in the waveform window and is the equivalent distance between two bins in the waveform this equivalent distance for cryosat 2 baseline b data processed here is 23 42 cm cntp and crtrk are the distances in units of bin numbers from the first bin of the waveform window to the nominal tracking position and the retracking position respectively 3 2 the improved narrow primary peak threshold retracking algorithm inpptr in jain et al 2015 they improved the ocog and the threshold for cryosat 2 sar mode waveform data and obtained the nppor and the npptr the terrain of the lakes in the sar mode measurement area of the cryosat 2 satellite is relatively flat and low while the sarin mainly observes high mountain glaciers and the topography around the lakes in the measurement area is complicated compared with flat areas complex terrain around the lake will produce more noise and it is more difficult to perform retracking and there is a big difference between sarin data and sar data e g the bins are different sar mode is 256 sarin mode is 1024 therefore this paper proposes a new improved retracking algorithm named inpptr that is more suitable for sarin waveform and lakes with complex terrain the inpptr solves the problem that the npptr is greatly affected by the waveform noise when extracting the endpoint of the main peak of the complex waveform and based on the gaussian normal distribution curve to simulate the disturbed waveform data it also solves the problem of low water levels measurement accuracy of the npptr in areas with complex terrain such as mountains and glaciers the flow chart of the inpptr is shown in fig 4 the detailed process of retracking the sarin data using the inpptr will be introduced in the following section first for each 20 hz sarin waveforms search for peaks at intervals of 40 bins and mark the peaks compare 10 of the power of the largest peak with the peak before the bin corresponding to the largest peak if there are some peaks greater than 10 of the maximum peak it is considered that the waveform has noise then assign the power corresponding to all bins before the bin corresponding to the peak and the 5 bins after the bin corresponding to the peak to 0 nothing will be done if there is no peak value exceeding 10 of the maximum peak power compared with the npptr the inpptr eliminates the influence of noise by discriminating abnormal waveforms and avoids identifying the wrong main peak next extract the main peak of the waveform use the difference between the power of the waveform to calculate the starting threshold of the main peak waveform see eq 4 and 6 and then compare the starting threshold with the continuous power difference d1 i in eq 5 when the d1 i exceeds the starting threshold for the first time the corresponding bin is marked as the starting point 4 d 2 i p i 2 p i 5 d 1 i p i 1 p i 6 t h start n 2 i 1 n 2 d 2 i 2 i 1 n 2 d 2 i 2 n 2 n 3 where thstart is the start threshold of the main peak n is the number of waveform bins and d1 i and d2 i are the power differences of the powers corresponding to different bins then extract all powers greater than 20 of amplitude a calculated in eq 8 mark them and mark the bin corresponding to the last marked power as the endpoint the endpoint of the npptr is obtained by comparing the end threshold and the power difference in a waveform with more noise the wrong endpoint will be identified as shown in fig 5 after completing the above steps extract the main peak from the start point to the endpoint of the waveform and assign other powers to zero according to the similarity between standard waveform and gaussian distribution kurtz et al 2014 and the waveform above the ice surface is a double peak structure this paper uses quadratic gaussian fitting n 2 the fitting formula is shown in eq 7 7 p i 1 n a i exp x b i c i 2 where p is the power corresponding to each bin x is the bin value i is the number of fittings ai is the peak value of the waveform bi is the position of the peak and ci is the half power width of the waveform finally calculate the amplitude a of the main peak according to eq 8 80 of the amplitude of the main peak is recorded as the threshold pthres the bin corresponding to the first power greater than the threshold pthres in the main peak is identified as ithres in eq 9 the retracking position crtrk is obtained by interpolation between the bin ithres and the bin before it ithres 1 as shown in eq 10 the retracking position thus obtained through the interpolation is used in eq 3 to compute the heights of water body 8 a i 1 n pp p i 4 i 1 n pp p i 2 where npp is the total number of waveform bins involved in the calculation and pi is the power 9 if p i p thres i i s i t h r e s 10 c rtrk i t h r e s 1 p thres p ithres 1 p ithres p ithres 1 to illustrate the advantages of the inpptr fig 5 shows the comparison of the main peaks extracted by the inpptr and the npptr in qinghai lake on january 27 2016 it can be seen from the figure that when using npptr to mark the starting point and the endpoint the wrong main peak is obtained due to the influence of noise which causes the retracking point to be inaccurate while the inpptr is used the interference waveform is removed the correct main peak of the waveform is extracted and performs gaussian fitting on the main peaks with serious waveform pollution after obtaining the water levels additional error elimination method is added 1 obtain satellite data within a 50 km radius of the virtual station and hydrological station locations 2 eliminate gross errors of the water levels inversion according to the criterion of three standard deviation 3 for the amazon river since the river slope has a great influence on the surface runoff the water levels will vary greatly in different locations therefore rivers of the same longitude have the same water levels assuming that the river slope varies uniformly use the data in the website in section 2 2 to obtain the longitude difference and the in situ water levels difference between two adjacent stations in the amazon river interpolate the water levels at intervals of 0 01 of longitude finally linear interpolation the inversion water levels at the same longitude as the station is obtained to reduce errors caused by excessive river slopes 4 results and discussion 4 1 comparison of retracking algorithms to compare the retracking results of different retracking algorithms the three most representative research areas among the nine regions are selected qinghai lake great slave lake and amazon river fig 6 shows the cryosat 2 sarin tracks of qinghai lake on september 12 2018 great slave lake on january 13 2016 and amazon river on january 1 2018 and the corresponding water levels obtained by the four retracking algorithms of mwapp npptr nppor and inpptr it can be seen from fig 6 that for qinghai lake the water levels obtained by the inpptr is not obviously abnormal and the overall water levels is relatively stable the water levels obtained by the mwapp the npptr and the nppor have obvious anomalies near the 36 66 n for great slave lake except for the obvious anomaly of the npptr and nppor around 61 92 n inpptr and mwapp retracking algorithms provide a stable water level the four retracking algorithms in the amazon river all provide relatively stable water levels data without obvious abnormalities the water levels obtained by the inpptr has the best stability in general the water levels obtained from one satellite pass remains stable and does not show significant jumps therefore the standard deviation of water levels obtained from each satellite pass can be used as a criterion to measure the accuracy of the water levels retrieved by various retracking algorithms table 2 shows the track standard deviation of the water levels obtained by using four retracking algorithms in qinghai lake on september 12 2018 great slave lake on january 13 2016 and amazon river on january 1 2018 it is seen from the table that the inpptr has the lowest standard deviation of water levels in qinghai lake and great slave lake which were 36 78 cm and 52 30 cm respectively which is to be expected since the method is improved for the sarin it can reduce the interference of abnormal waveforms and identify the main peak more accurately for the amazon river inpptr obtained the lowest standard deviation 7 81 cm as well due to the small cross section of the amazon river the waveform affected by the terrain along the coast resulting in more noise in summary inpptr has obvious advantages over other retracking algorithms in areas with complex terrain 4 2 time series of water levels the water level time series of the three study areas selected in section 4 1 are shown in fig 7 see the appendix for the other six study areas fig 7 compares the water levels obtained by satellite altimetry with the in situ data and the corresponding rmse is shown in table 3 for the time series of qinghai lake in fig 7 the inversion water levels calculated by the four retracking algorithms has a high fit with the in situ water levels except for the mwapp the water levels obtained by other retracking algorithms during the qinghai lake ice period from january to march have no obvious deviation as shown by the box in the figure among them the inpptr has the highest accuracy with the rmse of 18 09 cm using ocog 10 threshold 20 threshold 50 threshold and 5β parameters roohi et al 2021 explored the accuracy of water levels inversion in qinghai lake from may 2010 to december 2013 on the full waveform the first sub waveform and all waveforms of the cryosat 2 lrm data respectively the highest accuracy was achieved when 10 threshold and the average of all waveforms were used with an rmse of 15 cm the reason for the slightly lower accuracy of the inversion result in this paper may be that the daily water level obtained by interpolation from the hydroweb database is used in this paper and there is a certain deviation from the daily in situ data liu et al 2019 proposed a concentrated probability density function pdf method to process the gdr data of cryosat 2 to obtain the water level of qinghai lake compared with the dahiti water level data the rmse obtained is 0 25 m which is lower than the accuracy of inpptr in this paper it can be seen from the time series of great slave lake that around may the water levels retrieved by the mwapp npptr and nppor are significantly different from the in situ water levels and inpptr have a higher degree of consistency with the in situ water levels in the ice period january march except for inpptr the other three retracking algorithms have large deviations from the in situ and even the change trend of the measured water levels around january 2018 is opposite beckers et al 2017 used the cryosat 2 data to obtain the lake ice thickness and water levels of the great slave lake the rmse of the obtained water levels was 0 280 m which was slightly lower than the accuracy of the inpptr 18 43 cm in this paper from the time series of the amazon river it can be seen that the difference between the water levels obtained by the four retracking algorithms is slight and the smallest rmse is inpptr the rmse is 58 24 cm specially developed for the sarin waveform the rmse of the mwapp npptr and nppor are 68 55 cm 79 82 cm and 81 36 cm respectively villadsen et al 2016 used the cryosat 2 data to obtain the lower amazon river water levels with the rmse of 38 5 cm which was lower than this paper the reason for this discrepancy may be that the research area of this paper is the upper amazon river where the sarin mode is used the lower amazon river is wider the slope is gentler and the terrain along the coast relatively flat which has little impact on the accuracy of water levels inversion in the upper amazon river due to the large river slope and the complex terrain along the coast the inversion accuracy of water levels is low according to table 3 among the eight lakes using sarin data the rmse of water levels obtained by inpptr in qing lake namco lake selin lake zhair namco lake issyk lake great salt lake tahoe lake and great slave lake decreased by 9 91 14 83 7 62 14 74 6 70 4 11 105 37 and 25 02 with respect to that of the npptr compared with mwapp the rmse of inpptr is reduced by 29 11 16 38 45 78 11 15 3 17 46 70 81 94 and 60 93 respectively compared with nppor the rmse of inpptr is reduced by 25 83 16 44 17 76 22 33 7 30 9 73 84 11 and 15 68 respectively it shows that the inpptr has better performances than the npptr for the high altitude and complex terrain water bodies passed by the sarin and can obtain more accurate water levels in amazon river the inpptr also obtains the lowest rmse and the rmse is reduced by 37 05 17 70 and 39 70 compared with npptr mwapp and nppor the above results show that the inpptr is not only suitable for high altitude and complex terrain water bodies covered by the sarin mode but also can be used for water levels inversion of small water bodies such as rivers according to table 2 table 3 fig 1 and fig a1 all four retracking algorithms can obtain high accuracy water levels when the sarin passes through of qinghai lake namco lake selin lake zhair namco lake issyk lake great salt lake tahoe lake and great slave lake the rmse of the water levels obtained by the inpptr is the smallest which are 18 09 cm 21 69 cm 20 48 cm 34 82 cm 17 39 cm 39 68 cm 26 25 cm and 18 43 cm respectively the rmse of the amazon river using the inpptr is the smallest which is 58 24 cm in summary the water levels retrieved by the inpptr in high altitude areas with complex terrain passed by the sarin is more stable while the mwapp can obtain the stable water levels in areas with flat terrain if the ice age is not considered for rivers with a small area and greater influence by the boundary the water levels provided by the inpptr is more stable it can be seen from table 1 and table 3 that the accuracy of the water levels obtained by the inpptr decreases as the lake area becomes smaller for example qinghai lake selin lake namco lake and zhari namco lake located on the qinghai tibet plateau the rmse increases as the water area becomes smaller the reason for the above phenomenon may be that the smaller the lake area the closer the distance between the center and the boundary of the lake the waveform is affected by the land and produces noise which leads to a decrease in the accuracy of the finally obtained water levels the four retrackers introduced in this paper all have good accuracy in the above research areas the inpptr proposed in this paper can obtain more accurate retracking points from the reflected waveform of complex terrain so the accuracy is higher than the others there are many errors sources for inland water altimetry especially over smaller lakes and rivers e g in case of strong winds where water might be retained in certain areas of the lake or if the river morphology differs from place to place causing higher water levels in some areas and lower in others rainfall and evaporation are the two most direct factors affecting lake water levels after reviewing the historical rainfall and temperature data on the qinghai tibet plateau it was found that the temperature and rainfall in the region increased year by year they are positively correlated with the changes in the water levels of the four lakes on the qinghai tibet plateau in this paper indicating that the water levels of inland water bodies can reflect climate changes to a certain extent therefore the water level in remote areas lacking measured data can be obtained according to the inpptr algorithm providing an important reference for climate change in the region and ultimately providing assistance for the monitoring of global climate change 5 conclusions and outlook in this paper a new improved retracking algorithm named inpptr suitable for cryosat 2 sarin waveforms in inland waters is proposed the retracking algorithm can effectively deal with the interference waveform caused by the inland complex terrain obtain a more accurate main peak than the npptr and perform gaussian fitting of the main peak to obtain more accurate retracking points to test the retracking performance of the four retracking algorithms on cryosat 2 waveform this paper selected eight lakes and one river with different characteristics for experiments and compared the inversion results with the in situ data the results show that the inpptr has significantly higher accuracy than the other three retracking algorithms when processing cryosat 2 sarin data therefore the inpptr can be used to obtain the water level time series of plateau lakes which is of great significance for lake monitoring in plateau areas lacking hydrological stations in addition the inpptr has good performance in both icing and ice free periods and the observation results of lakes with ice period are the best compared to other retracking algorithms in order to further improve the applicability of the inpptr a more accurate method of identifying interference waveforms will be developed so that it can be used in both sar and sarin at the same time without being disturbed by terrain this retracking algorithm is expected to be applied to different satellites to improve further the temporal and spatial resolution of the water levels thereby enabling long term high accuracy water levels monitoring in various regions credit authorship contribution statement peng chen conceptualization methodology writing review editing supervision zhiyuan an software writing original draft writing review editing visualization hui xue software validation yibin yao conceptualization writing review editing resources xueying yang software validation writing original draft writing review editing rong wang validation writing review editing zhihao wang validation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to thank the esa for providing cryosat 2 data glwd and landsat 8 for providing boundary data of water bodies and hydroweb database dahiti database the national water information system the official website of the government of canada and the national service of meteorology and hydrology of peru for providing in situ water level data this work was supported in part by the national natural science foundation of china under grant 41404031 in part by the state key laboratory of geodesy and earth s dynamics innovation academy for precision measurement science and technology under grant sklged2022 3 5 in part by beijing key laboratory of urban spatial information engineering under grant 20210206 appendix 
2966,as an important technology for measuring water levels satellite altimetry has been widely using in the lake river and wetland in the past two decades however the waveform pollution limits its application in areas with complex topography the accuracy of the existing retracking algorithms need to be further improved in this study a new retracking algorithm named improved narrow primary peak threshold retracking algorithm inpptr based on narrow primary peak threshold retracking algorithm npptr is presented this retracking algorithm eliminates the noise in the waveform extracts more accurate main peaks of the waveform and performs gaussian fitting on the main peaks with serious waveform pollution finally the more stable water levels in areas with complex terrain can be obtained from cryosat 2 synthetic aperture radar interferometer sarin waveform to verify the accuracy of retracking algorithms the water level time series of eight lakes and one river were retrieved using inpptr and other three retracking algorithms npptr nppor and mwapp then were compared to the in situ data for qinghai lake namco lake selin lake zhair namco lake issyk lake great salt lake tahoe lake and great slave lake where sarin mode is used and the root mean squared errors rmse obtained by inpptr are 18 09 cm 21 69 cm 20 48 cm 34 82 cm 17 39 cm 39 68 cm 26 25 cm and 18 43 cm respectively compared with npptr the rmse of inpptr is reduced by 9 91 14 83 7 62 14 74 6 70 4 11 105 37 and 25 02 respectively for the amazon river the rmse of inpptr is 58 24 cm compared with the other three retracking algorithms the rmse obtained by inpptr is the lowest as well in summary the accuracy of inpptr is significantly higher than the other three retracking algorithms and inpptr can process cryosat 2 sarin data effectively and provide more stable and effective water levels laying the foundation for long term high accuracy water levels monitoring of inland water bodies with complex terrain keywords satellite altimetry cryosat 2 sarin inpptr inland water water levels data availability no data was used for the research described in the article 1 introduction there are approximately 117 million lakes and 200 international rivers on the earth s land surface verpoorter et al 2014 these lakes and rivers provide habitats for many species and provide the necessary freshwater resources for human activities the spatial distribution of water resources reflects the regional differences and utilization of surface water resources to some extent in addition the spatial and temporal variability of water resources reflects the effects of climate change surface processes and human activities on the water cycle therefore long term and high accuracy of the inland water levels monitoring of waters has become more and more important traditional lake and river levels are usually measured by hydrological stations which are expensive to build and maintain and consume a lot of labor and material therefore the number of global hydrological stations continues to decrease resulting in a reduction in the amount of on site measurements which is not conducive to monitoring the dynamic balance of global hydrology many scholars use physical models e g water balance models climate model systems and hydrological models to estimate changes in lake water levels bengtsson and malm 1997 however due to changes in physical factors in different regions it is difficult to establish a physical model that is applicable to all regions after 20 years of development satellite altimetry has become an important method for monitoring inland water levels independent of infrastructure especially in remote areas where maintenance of monitoring stations is expensive berry et al 2005 birkett 1995 birkett 1998 duan and bastiaanssen 2013 frappart et al 2005 jiang et al 2017a which has the significance of great water resources management in addition the role of satellite altimetry data in near real time and long term series has also been proven in several studies such as discharge modeling and flood warning liu et al 2019 the arrival of the esa s cryosat 2 mission in april 2010 marked a new era of satellite radar altimetry cryosat 2 carries the state of the art synthetic aperture interferometric radar altimeter siral on board which can operate in three different modes low resolution mode lrm synthetic aperture radar sar and sar interferometer sarin traditional altimeter radars are equipped with low resolution lrm radars such as envisat satellites due to factors of the duration pulse of radar satellite orbit height and the roughness of the reflecting surface the effective coverage diameter of envisat satellite radar altimeters is 1 6 13 4 km chelton et al 2001 compared to the circular footprint of the conventional pulse limited altimeter 10 km in diameter the cryosat 2 orbit has a smaller footprint band 300 m along the orbit and 1 km across the orbit using the beam wingham et al 2006 the reduced of footprint size of cryosat 2 reduces the effects of complex nearshore topography and improves the accuracy of water levels estimates in small lakes and rivers jiang et al 2017b the revisit period of conventional altimetry satellites is 10 35 days which results in low spatial coverage of the orbit orbital separation near the equator is at least 80 km jarihani et al 2013 so it is difficult to monitor lakes with a small area cryosat 2 satellite adopts a long repetitive 369 days drift orbit and has the advantages of the short distance between tracks and high spatial coverage providing the possibility of monitoring small lakes the quality of water level data obtained from satellite altimetry can be improved by waveform retracking i e modifying the initial range derived from the two way travel time of radar short pulses sent to the inland water surface and reflected birkett 1998 many studies are available on waveform retracking in wingham et al 1986 they proposed the offset centre of gravity ocog retracking algorithm and obtained relatively good results in davis 1995 he proposed the threshold retracking algorithm threshold which turned out to be superior to the 5 β retracking algorithm and the 9 β retracking algorithm however the traditional ocog threshold 5 β retracking algorithm and 9 β retracking algorithm developed for lrm are not applicable to sar and sarin jain et al 2015 in andersen et al 2015 they proposed the narrow primary peak ocog retracking algorithm nppor and the narrow primary peak threshold retracking algorithm npptr the by improving ocog and threshold in nielsen et al 2015 they proposed the narrow primary peak retractor nppr verified the measurement results according to the in situ data and obtained the highest accuracy of lake level measurement at that time with the rmse between 7 and 20 cm in villadsen et al 2016 they proposed the empirical methods multiple waveform persistent peak mwapp retracking algorithm and combined it with the samosa3 physical retracker however the sarin and sar waveforms of the cryosat 2 satellite are very different in the sarin mode the bin of the waveform data is 1 024 and the nominal range bin number is 256 so the applicability of the above method to sarin still needs further improvement based on the npptr this paper proposes the improved narrow primary peak threshold retracking algorithm inpptr for sarin waveform to obtain stable water levels in plateau areas the inpptr solves the problem that the npptr is greatly affected by the waveform noise when extracting the endpoint of the main peak of the complex waveform and based on the gaussian normal distribution curve to simulate the disturbed waveform data it also solves the problem of low water levels measurement accuracy of the npptr in areas with complex terrain such as mountains and glaciers it can obtain stable water level even in areas with complex topography and provides a low cost high efficiency and high precision water level estimation method for remote plateau areas finally in order to verify the accuracy of the inpptr the water levels of eight lakes and one river were calculated by the four retracking algorithms inpptr npptr nppor and mwapp are compared with the in situ data 2 data and study area 2 1 cryosat 2 20 hz sarin data esa provides cryosat 2 data in level 1 l1 and level 2 l2 mode this paper uses the 20 hz l1b data of sarin from the cryosat 2 satellite unlike other satellites cryosat 2 does not have a fixed orbit and can use the following websites to assist in downloading data https science pds cryosat esa int l1 contains the orbit information and the echoes received by the altimeter also called waveforms l2 contains the geophysical corrections for the sarin mode the bin of the waveform data is 1 024 and the nominal range bin number is 512 when using cryosat 2 data to obtain the water levels the return waveform deviates from the default preset point of the airborne retracking algorithm due to the irregular surface of the water body in order to obtain accurate water levels it is necessary to use different retracking algorithms to relocate the preset point of the waveform davis 1997 fig 1 shows the waveforms of traditional lrm mode sar and sarin mode from cryosat 2 the return waveform of the sar mode and sarin mode is of difference from the lrm and have a leading edge and a narrower trailing edge therefore a new retracking algorithm is required to obtain more accurate water levels 2 2 study area this paper selects seven lakes from four countries china u s kyrgyzstan and canada and amazon river in brazil and peru covered by sarin mode as the study area the geographical location of the water bodies and the corresponding cryosat 2 orbits are shown in fig 2 table 1 gives the details of the research water bodies the data covered periods and the observation mode of the data used among them the four lakes on the qinghai tibet plateau qinghai lake zhair namco lake namco lake and selin lake issyk lake in kyrgyzstan great salt lake and tahoe lake in the united states all have the following characteristics 1 the surrounding terrain is complex which will cause great interference to the data 2 high altitude the average altitude is higher than 1 000 m 3 long ice period in winter the ice period is from november to march of the next year the terrain around the great slave lake in canada is complex with low altitude located in high latitudes and has a long ice period in winter which is an excellent water body to verify inpptr the amazon river in brazil and peru is the widest and most flowing river in the world its water levels change evident in season and the river is more expansive the width of the dry season is a few kilometers the rainy season can reach 48 km so it is suitable for verifying the accuracy of the retracking algorithm the in situ water level observations of the great salt lake and tahoe lake are available at the national water information system https maps waterdata usgs gov with the elevation datum of navd29 the two lakes mentioned above were converted to the benchmarks where the in situ data are located using the vdatum tool https vdatum noaa gov vdatumweb provided by noaa the in situ water level of the great slave lake can be downloaded from the official website of the government of canada https wateroffice ec gc ca mainmenu historical data index e html which using the geodetic survey of assumed datum as the elevation datum daily water levels of amazon river were obtained through the national service of meteorology and hydrology of peru https www gob pe senamhi the elevation datum for the area is unknown since great slave lake and amazon river do not use a standard elevation datum a mean deviation is subtracted when comparing the retrieved water levels to this data the in situ data of lakes in china and kyrgyzstan are not available using the water level products from certain database instead for qinghai lake namco lake and selin lake the water levels from the hydroweb database http www legos obs mip fr soa hydrologie hydroweb are chosen as the in situ data since the hydroweb database lacking the water levels records for zhair namco lake and issyk lake take the dahiti http dahiti dgfi tum de en as a supplement the in situ data of the above database has passed the verification of multiple papers and the data accuracy is reliable bhagwat et al 2019 chen et al 2018 schwatke et al 2020 shu et al 2020 vickers et al 2019 2 3 water mask global lakes and wetlands database glwd was created by the world nature foundation and the center for environmental systems research the university of kassel using existing maps data and information combined with geographic information system gis and global lakes and wetlands best available resources three levels of databases https www worldwildlife org pages global lakes and wetlands database level 1 database glwd 1 includes 3 607 largest lakes area 50 km2 worldwide and the largest 645 reservoirs of the world storage capacity 0 5 km2 level 2 glwd 2 comprises permanent open water bodies with a surface area 0 1 km2 excluding the water bodies contained in glwd 1 level 3 database contains a boundary file of the reservoir the vector boundaries of the amazon river research area in this paper are extracted by landsat 8 landsat 8 is the eighth satellite in the u s land satellite plan with the successful launch on january 16 2021 http glovis usgs gov 3 methodology 3 1 inland water level estimation satellite altimetry technology uses satellites as carriers and uses space borne microwave radar altimeters to emit microwave pulses to the surface of water body the pulse returns to the radar altimeter after being reflected by the water body passing the time difference t between the departure pulse and the returning pulse the distance hrange from the satellite to the water body can be calculated in eq 1 the diagram of the principle of satellite altimetry is shown in fig 3 1 h range c t 2 where hrange is the height of the satellite relative to the water body c is the speed of light and t is the pulse round trip time using the orbit height of the satellite above the reference ellipsoid minus the distance from the satellite to the water and the height of the geoid above the reference ellipsoid the water levels h can be obtained as shown in eq 2 2 h h alt h range n geoid where halt is the orbit height of the satellite above the reference ellipsoid and ngeoid is the geoid height above the reference ellipsoid hrange is not given in the cryosat 2 satellite and it is calculated by the central window delay wd for retracking correction hretrack plus the sum of other corrections hgeo hgeo includes ionospheric correction dry tropospheric correction wet tropospheric correction solid tide correction tide correction and sea deviation correction all of which are given in level 1b product all retracked heights presented in this paper were transferred from the wgs84 ellipsoid to the egm08 geoid egm2008 provides detailed and accurate gravity data for the first time in history and the result is comparable to the regional geoid algorithm andersen and knudsen 2009 pavlis et al 2012 the process of using retracking technology to determine the height of the water surface is shown in eq 30 andersen and scharroo 2011 3 h range c 2 w d h retrack h geo h retrack b spc c npt c rtck where bspc is the bin spacing in meters in the waveform window and is the equivalent distance between two bins in the waveform this equivalent distance for cryosat 2 baseline b data processed here is 23 42 cm cntp and crtrk are the distances in units of bin numbers from the first bin of the waveform window to the nominal tracking position and the retracking position respectively 3 2 the improved narrow primary peak threshold retracking algorithm inpptr in jain et al 2015 they improved the ocog and the threshold for cryosat 2 sar mode waveform data and obtained the nppor and the npptr the terrain of the lakes in the sar mode measurement area of the cryosat 2 satellite is relatively flat and low while the sarin mainly observes high mountain glaciers and the topography around the lakes in the measurement area is complicated compared with flat areas complex terrain around the lake will produce more noise and it is more difficult to perform retracking and there is a big difference between sarin data and sar data e g the bins are different sar mode is 256 sarin mode is 1024 therefore this paper proposes a new improved retracking algorithm named inpptr that is more suitable for sarin waveform and lakes with complex terrain the inpptr solves the problem that the npptr is greatly affected by the waveform noise when extracting the endpoint of the main peak of the complex waveform and based on the gaussian normal distribution curve to simulate the disturbed waveform data it also solves the problem of low water levels measurement accuracy of the npptr in areas with complex terrain such as mountains and glaciers the flow chart of the inpptr is shown in fig 4 the detailed process of retracking the sarin data using the inpptr will be introduced in the following section first for each 20 hz sarin waveforms search for peaks at intervals of 40 bins and mark the peaks compare 10 of the power of the largest peak with the peak before the bin corresponding to the largest peak if there are some peaks greater than 10 of the maximum peak it is considered that the waveform has noise then assign the power corresponding to all bins before the bin corresponding to the peak and the 5 bins after the bin corresponding to the peak to 0 nothing will be done if there is no peak value exceeding 10 of the maximum peak power compared with the npptr the inpptr eliminates the influence of noise by discriminating abnormal waveforms and avoids identifying the wrong main peak next extract the main peak of the waveform use the difference between the power of the waveform to calculate the starting threshold of the main peak waveform see eq 4 and 6 and then compare the starting threshold with the continuous power difference d1 i in eq 5 when the d1 i exceeds the starting threshold for the first time the corresponding bin is marked as the starting point 4 d 2 i p i 2 p i 5 d 1 i p i 1 p i 6 t h start n 2 i 1 n 2 d 2 i 2 i 1 n 2 d 2 i 2 n 2 n 3 where thstart is the start threshold of the main peak n is the number of waveform bins and d1 i and d2 i are the power differences of the powers corresponding to different bins then extract all powers greater than 20 of amplitude a calculated in eq 8 mark them and mark the bin corresponding to the last marked power as the endpoint the endpoint of the npptr is obtained by comparing the end threshold and the power difference in a waveform with more noise the wrong endpoint will be identified as shown in fig 5 after completing the above steps extract the main peak from the start point to the endpoint of the waveform and assign other powers to zero according to the similarity between standard waveform and gaussian distribution kurtz et al 2014 and the waveform above the ice surface is a double peak structure this paper uses quadratic gaussian fitting n 2 the fitting formula is shown in eq 7 7 p i 1 n a i exp x b i c i 2 where p is the power corresponding to each bin x is the bin value i is the number of fittings ai is the peak value of the waveform bi is the position of the peak and ci is the half power width of the waveform finally calculate the amplitude a of the main peak according to eq 8 80 of the amplitude of the main peak is recorded as the threshold pthres the bin corresponding to the first power greater than the threshold pthres in the main peak is identified as ithres in eq 9 the retracking position crtrk is obtained by interpolation between the bin ithres and the bin before it ithres 1 as shown in eq 10 the retracking position thus obtained through the interpolation is used in eq 3 to compute the heights of water body 8 a i 1 n pp p i 4 i 1 n pp p i 2 where npp is the total number of waveform bins involved in the calculation and pi is the power 9 if p i p thres i i s i t h r e s 10 c rtrk i t h r e s 1 p thres p ithres 1 p ithres p ithres 1 to illustrate the advantages of the inpptr fig 5 shows the comparison of the main peaks extracted by the inpptr and the npptr in qinghai lake on january 27 2016 it can be seen from the figure that when using npptr to mark the starting point and the endpoint the wrong main peak is obtained due to the influence of noise which causes the retracking point to be inaccurate while the inpptr is used the interference waveform is removed the correct main peak of the waveform is extracted and performs gaussian fitting on the main peaks with serious waveform pollution after obtaining the water levels additional error elimination method is added 1 obtain satellite data within a 50 km radius of the virtual station and hydrological station locations 2 eliminate gross errors of the water levels inversion according to the criterion of three standard deviation 3 for the amazon river since the river slope has a great influence on the surface runoff the water levels will vary greatly in different locations therefore rivers of the same longitude have the same water levels assuming that the river slope varies uniformly use the data in the website in section 2 2 to obtain the longitude difference and the in situ water levels difference between two adjacent stations in the amazon river interpolate the water levels at intervals of 0 01 of longitude finally linear interpolation the inversion water levels at the same longitude as the station is obtained to reduce errors caused by excessive river slopes 4 results and discussion 4 1 comparison of retracking algorithms to compare the retracking results of different retracking algorithms the three most representative research areas among the nine regions are selected qinghai lake great slave lake and amazon river fig 6 shows the cryosat 2 sarin tracks of qinghai lake on september 12 2018 great slave lake on january 13 2016 and amazon river on january 1 2018 and the corresponding water levels obtained by the four retracking algorithms of mwapp npptr nppor and inpptr it can be seen from fig 6 that for qinghai lake the water levels obtained by the inpptr is not obviously abnormal and the overall water levels is relatively stable the water levels obtained by the mwapp the npptr and the nppor have obvious anomalies near the 36 66 n for great slave lake except for the obvious anomaly of the npptr and nppor around 61 92 n inpptr and mwapp retracking algorithms provide a stable water level the four retracking algorithms in the amazon river all provide relatively stable water levels data without obvious abnormalities the water levels obtained by the inpptr has the best stability in general the water levels obtained from one satellite pass remains stable and does not show significant jumps therefore the standard deviation of water levels obtained from each satellite pass can be used as a criterion to measure the accuracy of the water levels retrieved by various retracking algorithms table 2 shows the track standard deviation of the water levels obtained by using four retracking algorithms in qinghai lake on september 12 2018 great slave lake on january 13 2016 and amazon river on january 1 2018 it is seen from the table that the inpptr has the lowest standard deviation of water levels in qinghai lake and great slave lake which were 36 78 cm and 52 30 cm respectively which is to be expected since the method is improved for the sarin it can reduce the interference of abnormal waveforms and identify the main peak more accurately for the amazon river inpptr obtained the lowest standard deviation 7 81 cm as well due to the small cross section of the amazon river the waveform affected by the terrain along the coast resulting in more noise in summary inpptr has obvious advantages over other retracking algorithms in areas with complex terrain 4 2 time series of water levels the water level time series of the three study areas selected in section 4 1 are shown in fig 7 see the appendix for the other six study areas fig 7 compares the water levels obtained by satellite altimetry with the in situ data and the corresponding rmse is shown in table 3 for the time series of qinghai lake in fig 7 the inversion water levels calculated by the four retracking algorithms has a high fit with the in situ water levels except for the mwapp the water levels obtained by other retracking algorithms during the qinghai lake ice period from january to march have no obvious deviation as shown by the box in the figure among them the inpptr has the highest accuracy with the rmse of 18 09 cm using ocog 10 threshold 20 threshold 50 threshold and 5β parameters roohi et al 2021 explored the accuracy of water levels inversion in qinghai lake from may 2010 to december 2013 on the full waveform the first sub waveform and all waveforms of the cryosat 2 lrm data respectively the highest accuracy was achieved when 10 threshold and the average of all waveforms were used with an rmse of 15 cm the reason for the slightly lower accuracy of the inversion result in this paper may be that the daily water level obtained by interpolation from the hydroweb database is used in this paper and there is a certain deviation from the daily in situ data liu et al 2019 proposed a concentrated probability density function pdf method to process the gdr data of cryosat 2 to obtain the water level of qinghai lake compared with the dahiti water level data the rmse obtained is 0 25 m which is lower than the accuracy of inpptr in this paper it can be seen from the time series of great slave lake that around may the water levels retrieved by the mwapp npptr and nppor are significantly different from the in situ water levels and inpptr have a higher degree of consistency with the in situ water levels in the ice period january march except for inpptr the other three retracking algorithms have large deviations from the in situ and even the change trend of the measured water levels around january 2018 is opposite beckers et al 2017 used the cryosat 2 data to obtain the lake ice thickness and water levels of the great slave lake the rmse of the obtained water levels was 0 280 m which was slightly lower than the accuracy of the inpptr 18 43 cm in this paper from the time series of the amazon river it can be seen that the difference between the water levels obtained by the four retracking algorithms is slight and the smallest rmse is inpptr the rmse is 58 24 cm specially developed for the sarin waveform the rmse of the mwapp npptr and nppor are 68 55 cm 79 82 cm and 81 36 cm respectively villadsen et al 2016 used the cryosat 2 data to obtain the lower amazon river water levels with the rmse of 38 5 cm which was lower than this paper the reason for this discrepancy may be that the research area of this paper is the upper amazon river where the sarin mode is used the lower amazon river is wider the slope is gentler and the terrain along the coast relatively flat which has little impact on the accuracy of water levels inversion in the upper amazon river due to the large river slope and the complex terrain along the coast the inversion accuracy of water levels is low according to table 3 among the eight lakes using sarin data the rmse of water levels obtained by inpptr in qing lake namco lake selin lake zhair namco lake issyk lake great salt lake tahoe lake and great slave lake decreased by 9 91 14 83 7 62 14 74 6 70 4 11 105 37 and 25 02 with respect to that of the npptr compared with mwapp the rmse of inpptr is reduced by 29 11 16 38 45 78 11 15 3 17 46 70 81 94 and 60 93 respectively compared with nppor the rmse of inpptr is reduced by 25 83 16 44 17 76 22 33 7 30 9 73 84 11 and 15 68 respectively it shows that the inpptr has better performances than the npptr for the high altitude and complex terrain water bodies passed by the sarin and can obtain more accurate water levels in amazon river the inpptr also obtains the lowest rmse and the rmse is reduced by 37 05 17 70 and 39 70 compared with npptr mwapp and nppor the above results show that the inpptr is not only suitable for high altitude and complex terrain water bodies covered by the sarin mode but also can be used for water levels inversion of small water bodies such as rivers according to table 2 table 3 fig 1 and fig a1 all four retracking algorithms can obtain high accuracy water levels when the sarin passes through of qinghai lake namco lake selin lake zhair namco lake issyk lake great salt lake tahoe lake and great slave lake the rmse of the water levels obtained by the inpptr is the smallest which are 18 09 cm 21 69 cm 20 48 cm 34 82 cm 17 39 cm 39 68 cm 26 25 cm and 18 43 cm respectively the rmse of the amazon river using the inpptr is the smallest which is 58 24 cm in summary the water levels retrieved by the inpptr in high altitude areas with complex terrain passed by the sarin is more stable while the mwapp can obtain the stable water levels in areas with flat terrain if the ice age is not considered for rivers with a small area and greater influence by the boundary the water levels provided by the inpptr is more stable it can be seen from table 1 and table 3 that the accuracy of the water levels obtained by the inpptr decreases as the lake area becomes smaller for example qinghai lake selin lake namco lake and zhari namco lake located on the qinghai tibet plateau the rmse increases as the water area becomes smaller the reason for the above phenomenon may be that the smaller the lake area the closer the distance between the center and the boundary of the lake the waveform is affected by the land and produces noise which leads to a decrease in the accuracy of the finally obtained water levels the four retrackers introduced in this paper all have good accuracy in the above research areas the inpptr proposed in this paper can obtain more accurate retracking points from the reflected waveform of complex terrain so the accuracy is higher than the others there are many errors sources for inland water altimetry especially over smaller lakes and rivers e g in case of strong winds where water might be retained in certain areas of the lake or if the river morphology differs from place to place causing higher water levels in some areas and lower in others rainfall and evaporation are the two most direct factors affecting lake water levels after reviewing the historical rainfall and temperature data on the qinghai tibet plateau it was found that the temperature and rainfall in the region increased year by year they are positively correlated with the changes in the water levels of the four lakes on the qinghai tibet plateau in this paper indicating that the water levels of inland water bodies can reflect climate changes to a certain extent therefore the water level in remote areas lacking measured data can be obtained according to the inpptr algorithm providing an important reference for climate change in the region and ultimately providing assistance for the monitoring of global climate change 5 conclusions and outlook in this paper a new improved retracking algorithm named inpptr suitable for cryosat 2 sarin waveforms in inland waters is proposed the retracking algorithm can effectively deal with the interference waveform caused by the inland complex terrain obtain a more accurate main peak than the npptr and perform gaussian fitting of the main peak to obtain more accurate retracking points to test the retracking performance of the four retracking algorithms on cryosat 2 waveform this paper selected eight lakes and one river with different characteristics for experiments and compared the inversion results with the in situ data the results show that the inpptr has significantly higher accuracy than the other three retracking algorithms when processing cryosat 2 sarin data therefore the inpptr can be used to obtain the water level time series of plateau lakes which is of great significance for lake monitoring in plateau areas lacking hydrological stations in addition the inpptr has good performance in both icing and ice free periods and the observation results of lakes with ice period are the best compared to other retracking algorithms in order to further improve the applicability of the inpptr a more accurate method of identifying interference waveforms will be developed so that it can be used in both sar and sarin at the same time without being disturbed by terrain this retracking algorithm is expected to be applied to different satellites to improve further the temporal and spatial resolution of the water levels thereby enabling long term high accuracy water levels monitoring in various regions credit authorship contribution statement peng chen conceptualization methodology writing review editing supervision zhiyuan an software writing original draft writing review editing visualization hui xue software validation yibin yao conceptualization writing review editing resources xueying yang software validation writing original draft writing review editing rong wang validation writing review editing zhihao wang validation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to thank the esa for providing cryosat 2 data glwd and landsat 8 for providing boundary data of water bodies and hydroweb database dahiti database the national water information system the official website of the government of canada and the national service of meteorology and hydrology of peru for providing in situ water level data this work was supported in part by the national natural science foundation of china under grant 41404031 in part by the state key laboratory of geodesy and earth s dynamics innovation academy for precision measurement science and technology under grant sklged2022 3 5 in part by beijing key laboratory of urban spatial information engineering under grant 20210206 appendix 
2967,transient measurements from soil water monitoring installments are frequently coupled with richards based solvers to inversely estimate soil hydraulic parameters shps and numerically describe vadose zone water fluxes such as groundwater recharge to reduce model predictive uncertainty the experimental setup should be designed to maximize the information content of observations however in practice this is generally done by relying on the a priori expertise of the scientist user without exploiting the advantages of model based experimental design thus the main aim of this study is to demonstrate how model based experimental design can be used to maximize the information content of observations in multiple synthetic scenarios encompassing different soil textural compositions and climatic conditions the hydrological model hydrus is coupled with a nested sampling estimator to calculate the parameters posterior distributions and the kullback leibler divergences results indicate that the combination of seepage flow soil water content and soil matric potential measurements generally leads to highly informative designs especially for fine textured soils while results from coarse soils are generally affected by higher uncertainty additionally the propagation of parameter uncertainties in a contrasting dry climate scenario strongly increased prediction uncertainties for sandy soil not only in terms of the cumulative amount and magnitude of the peak but also in the temporal variability of the seepage flow a complementary real world application with a sandy soil lysimeter identified a combination of seepage data and matric potential as the most informative design and confirmed findings of the synthetic scenarios in which matric potential proved to be more informative than soil water content measurements keywords lysimeter water flow modeling hydrus nested sampling bayesian data analysis groundwater recharge data availability data will be made available on request 1 introduction knowledge on vadose zone recharge fluxes is important for the sustainable management of groundwater as a resource for drinking and irrigation water as it represents the maximum amount of water that may be withdrawn from an aquifer without irreversibly depleting it taylor et al 2013 a large proportion of groundwater recharge is contributed by water infiltrating soil and flowing through the vadose zone döll and fiedler 2008 nolan et al 2007 the water flow through the vadose zone determines the cumulative amount of recharge important for the quantitative management of groundwater resources it also results in the temporal variability and magnitude of peaks in the recharge flux which are especially relevant for the management of water quality with regard to contaminants leaching to groundwater potentially deteriorating its ecological functions and usability for drinking water supply e g scanlon et al 2005 suchy et al 2018 zanello et al 2021 zhang et al 2020 various physically based modeling approaches exist for the estimation of soil water fluxes through the vadose zone and consequently of groundwater recharge scanlon 2011 šimůnek et al 2003 vereecken et al 2016 these models are often parameterized via the inverse estimation of soil hydraulic parameters shps from measured state variables inverse estimation can be advantageous over establishing parameter values from laboratory experiments since it grants flexibility in the adaption of experimental conditions to the spatial and temporal scale of interest dyck and kachanoski 2010 measurements from small scale samples in laboratories on the other hand are often found to be poorly transferable to field conditions e g stumpp et al 2012 vereecken et al 2008 vrugt et al 2008 wöhling et al 2008 the only option for directly measuring vadose zone fluxes are lysimeters especially when provided with sensors for additionally measuring soil water content and matric potential lysimeters represent good systems for establishing soil hydraulic processes durner et al 2008 however they may be biased in the construction of their lower boundary especially with seepage face conditions when the hydraulic gradient is disrupted they can also be biased in their assumption of a one dimensional water flow barkle et al 2011 pütz et al 2018 wöhling et al 2012 only few studies have investigated in the use of different types of measurements from soil water monitoring installments for the inverse estimation of effective shps in order to identify which information was needed for a unique parameter estimation as well as a reliable prediction of boundary fluxes durner et al 2008 groh et al 2018 schelle et al 2012 the most frequently used methods approach inverse parameter estimation as an optimization problem where a unique solution is obtained e g by least squares inversion information on the uncertainties related to the estimation in such an approach remains largely unavailable model predictions with inversely estimated parameters may fail or be associated with high uncertainties if either the model fails to include relevant components and processes for the prediction or because of issues with the quality and scope of the calibration data resulting in model parameters which are not known at a sufficient level of accuracy and precision finsterle 2015 vrugt and sadegh 2013 even under the assumption that the model structure adequately describes water transport processes the type quality and combination of data assimilated in the calibration process influence the extent of the parameter and consequently model predictive uncertainty furthermore uncertainties in the predictions might increase when climatic conditions deviate strongly from the calibration period moeck et al 2018 for an efficient soil water monitoring design that is aimed at the estimation of groundwater recharge evaluating the worth of calibration data from soil water monitoring installments for reducing prediction uncertainty is a key step this data worth depends on the type of prediction to be made wöhling et al 2015 overall it is not yet well understood how different types of calibration data affect uncertainties in modeling soil water fluxes a comprehensive sensitivity and data worth analysis is required which evaluates the efficiency of observational data for reducing uncertainty in the recharge prediction sensitivity analyses sa have gained importance as a tool to identify key processes and determine influential factors on model predictions finsterle 2015 gupta and razavi 2017 they make it possible to rank screen and potentially reduce the number of model parameters to be estimated for adequately predicting the variable of interest in the context of a data worth analysis the sa helps to identify observational data that deliver useful information specifically about the relevant sensitive parameters finsterle 2015 in order to properly evaluate how uncertainty in the estimation of sensitive parameters is reduced and how this affects the prediction uncertainty the sa can be combined with a comprehensive uncertainty analysis finsterle 2015 pan et al 2011 younes et al 2020 2013 soil hydrological modeling underlies uncertainties resulting from different sources of systematic and random errors they include uncertainty in measurements and forcing data in the initial and boundary conditions model structural or conceptual uncertainty as well as heterogeneity and scale effects which can all interact in a non linear way beven 2006 vereecken et al 2016 in a real world application it is difficult to separate these different error sources and properly account for them for a robust assessment of data worth and data related uncertainty it is therefore useful to reduce the influence of unknown sources of uncertainty by using synthetic scenarios brunetti et al 2020b for this purpose artificial measurement values can be generated via forward simulations with a given model parameterization and forcing data and afterwards perturbed by adding an artificial measurement error this approach has the advantage that the true data generating process is known exactly for a statistically robust information and uncertainty analysis the inverse parameter estimation is best integrated into a probabilistic framework based on the bayesian approach to statistics this approach relies on the idea of integrating a priori knowledge of the system in the statistical inference to combine it with the observed data i e measurements of soil water content matric potential and outflow in order to derive the posterior probabilities of model parameters monte carlo methods provide a tool for a statistically rigorous evaluation of the posterior however their application for a data worth analysis with soil hydrological models have certain limitations they must be compatible with strongly nonlinear and discontinuous models brunetti et al 2019 elsheikh et al 2014 mansouri et al 2013 and they ideally allow for the quantification of the information gain as relative entropy also called kullback leibler divergence between prior and posterior from the data assimilation brunetti et al 2020a several methods exist for the numerical evaluation of the bayesian integral and alongside the information gain most of which are computationally expensive schöniger et al 2014 skilling 2006 introduced nested sampling as an efficient monte carlo method for bayesian inference elsheikh et al 2013 described nested sampling as an efficient tool to address challenges in calibration uncertainty quantification and model selection with non linear subsurface flow models brunetti et al 2020b used nested sampling for model selection and uncertainty estimation in biogeochemical modeling including an assessment of the information gain from different measurements to our knowledge there is not yet a statistically rigorous analysis which accounts for different soil textures and climates and assesses the most efficient soil water monitoring design for groundwater recharge estimation there have been only few studies employing the kullback leibler divergence for similar vadose zone related purposes brunetti et al 2020a kikuchi et al 2015 overall this study aims to evaluate the optimal exploitation of soil water monitoring data for the estimation of shps and for seepage prediction for a range of different soil textures in order to account for both quantity and temporal variability in the recharge flux in this study we define annual cumulative amounts and the magnitude of the peak in the seepage flow as the variables of interest for prediction in a first step we carry out a global sensitivity analysis in order to determine influential shps for the prediction of the variables of interest under contrasting climatic conditions we further evaluate the information gain from synthetic soil water monitoring data for different soils and assess the data s effectiveness in reducing uncertainties about sensitive model parameters for this purpose we make use of a bayesian framework built on nested sampling which allows to assess the gain in information from the calibration data with rigorous statistical measures first we use synthetic data scenarios in the inference which allow us to exclude uncertainty stemming from system heterogeneities and unknown error characteristics thus we focus on the uncertainties which originate from the use of different types of measurements for model calibration and how they are impacted by different soil properties and climatic conditions we then test our approach in a real world application using data from a long term lysimeter experiment to see if results obtained from synthetic scenarios still hold under real conditions results of these scenarios should provide a basis for the improved assessment of real data as well as guidance for soil water monitoring installments designed for the estimation of groundwater recharge 2 material and methods 2 1 water flow and root water uptake the software for the simulation of water transport used in this study was hydrus 1d a finite elements model which numerically solves the water transport equations šimůnek et al 2008 its high computational efficiency was especially beneficial in this analysis which required a large number of model evaluations hydrus 1d provides an implementation of the richards equation presented in eq 1 for one dimensional equilibrium water flow where θ l3l 3 is the volumetric water content t t is the time variable z l is a vertical coordinate positive upward k h l t 1 is the unsaturated hydraulic conductivity function and h l is the water pressure head s is a sink term accounting for water uptake by plant roots which was simulated according to the model of feddes et al 1978 for an equally distributed root zone eq 2 where rd l is the root depth tp l is the potential transpiration and α h is a prescribed water stress response function depending on the crop type in this case with parameterization for grass cover taylor et al 1972 1 δ θ δ t δ δ z k h δ h δ z 1 s h 2 s h α h 1 r d t p the unimodal van genuchten mualem model vgm was selected to describe the soil water retention and hydraulic conductivity functions the former describes the relation between soil water content and soil pressure heads given in eq 3 where θr l3l 3 is the residual water content θs l3l 3 is the saturated water content α l 1 n and m are van genuchten shape parameters with the relation given in eq 4 the latter describes the relation between the unsaturated hydraulic conductivity and soil pressure heads given in eq 5 where se is the effective saturation defined in eq 6 and l l is a pore connectivity parameter 3 θ h θ r θ s θ r 1 α h n m i f h 0 θ s i f h 0 4 m 1 1 n n 1 5 k h k s s e l 1 1 s e 1 m m 2 6 s e θ θ r θ s θ r it has to be noted that the vgm model does not provide an ideal representation of all soils and conditions schaap and van genuchten 2006 and that a unimodal pore size distribution is often not given in natural soils which may exhibit structure and spatial heterogeneity durner 1994 however these assumptions have been found to be a good approximation to real systems for different applications in many studies e g brunetti et al 2020b dettmann et al 2014 in order not to introduce unwarranted complexity into this study it is reasonable to consider the simple and well established case of the unimodal vgm model 2 2 model setup and data scenarios 2 2 1 synthetic scenarios an atmospheric boundary condition was set at the soil surface where zero pressure was prescribed during ponding when both infiltration and surface runoff occur and an equilibrium was prescribed between the soil surface pressure and the atmospheric water vapor pressure when the atmospheric evaporative demand could not be met by evaporation from the soil profile for scenarios including seepage measurements the lower boundary condition at the bottom of the model domain was set to seepage face to reflect conditions of a lysimeter installment without control of the lower boundary for scenarios dealing exclusively with proxy measurements soil water content matric potential the lower boundary was set to free drainage the numerical domain in hydrus 1d was discretized into 100 finite elements for 100 cm profile depth all soils were assigned with a grass cover and a constant vertical root density with a rooting depth of rd 20 cm the forcing data for all simulations in this study were real meteorological observations obtained from the zamg central institution for meteorology and geodynamics austria and are therefore representative for austrian climate scenarios daily observations of precipitation and potential evapotranspiration for moderately humid climate conditions with 880 mm year precipitation fig 1 a and 463 mm year potential evapotranspiration fig 1c and for dry climate conditions with 253 mm year precipitation fig 1b and 561 mm year potential evapotranspiration fig 1d were used for the gsa for generating the synthetic data and for calibrating the models in the bayesian analysis the simulation of one year with an intermediate climate was used as a warm up period to obtain initial conditions for all further simulations five numerical homogeneous soil profiles of 1 m depth were established with shps corresponding to a range of soil textures according to the soil catalogue of carsel and parrish 1988 the synthetic soils are summarized in table 1 the artificial data for this study was generated as forward simulations of transient water regime in daily time steps this included matric potential mp and volumetric soil water content swc in 25 and 75 cm depth as well as lysimeter outflow q in 100 cm depth where the boundary condition was set to seepage face the partitioning of potential evapotranspiration into potential evaporation and potential transpiration in the simulations followed beer s law šimůnek 2015 with a leaf area index of lai 1 artificial homoscedastic independent gaussian measurement errors were applied as noise to the generated data and were intended to reflect the data quality from common seepage face lysimeters equipped with a balance for seepage water collection from time domain reflectometry tdr and from tensiometers the standard deviations of measurement errors for the lysimeter outflow was set to σq 0 1 mm e g schelle et al 2012 for matric potential measurements with tensiometers to σh 1 0 hpa e g schelle et al 2012 wöhling and vrugt 2011 and for the volumetric soil water content measurements with tdr the error was set to σθ 0 01 cm3 cm 3 e g durner et al 2008 evett et al 2005 the size and characteristics of the residuals correspond to errors originating only from the measurements residuals may be larger and potentially autocorrelated and or heteroscedastic non gaussian when they include additional error sources such as model structural errors höge et al 2019 wöhling et al 2015 wöhling and vrugt 2011 in the synthetic scenarios of this study we assumed our model to perfectly account for the data generating processes and exclusively focused on the uncertainty related to the observational data this circumvents having to account for other error sources and characteristics fig 2 shows the soil water retention curves corresponding to the 5 synthetic soils and the daily artificial soil water content and matric potential data points generated for model calibration in the bayesian inference based on the artificially generated time series 7 data scenarios were established using lysimeter outflow data q soil water content swc and matric potential mp data in all possible combinations the 7 data scenarios were consequently q swc mp q swc q mp swc mp and q swc mp 2 2 2 real data application neuherberg lysimeter experiment in order to test our approach in a real world application we used data from a long term lysimeter experiment which was conducted under conditions similar to those assumed for the synthetic scenarios the neuherberg lysimeter experiment 1997 2003 has been described in asadollahi et al 2020 stumpp et al 2009 and stumpp and maloszewski 2010 the lysimeter was constructed of stainless steel with 2 0 m depth 1 0 m2 surface and a seepage face boundary the soil was an undisturbed sandy soil humic cambisol for the purpose of this study we selected a 357 day calibration period 07 10 1997 28 09 1998 during cultivation of barley we used volumetric soil water content and matric potential both measured at 30 cm and 50 cm depth using tdr probes and tensiometers and weekly lysimeter outflow measurements at 200 cm depth the analysis for the real world application thus included the same 7 data combinations as in the synthetic scenarios of this study the hydrus 1d numerical domain was similar to the synthetic scenarios it included one material layer assuming a homogeneous profile daily weather data for variable boundary conditions were provided by the german weather service and daily potential evapotranspiration rates were calculated based on penman monteith and fao crop coefficients for barley according to allen et al 1998 the amounts of precipitation and calculated potential evapotranspiration during the calibration period were 668 mm and 444 mm respectively corresponding to an intermediate between the humid and dry scenario in the synthetic analysis 2 3 sensitivity analysis a sensitivity analysis served to identify which of the uncertain shps in the unimodal vgm hydrus 1d model have the greatest effect on model predictions and prediction uncertainties a parameter is called sensitive when changing its value leads to a noticeable difference in the model response gupta and razavi 2017 the variables of interest were the cumulative amount of seepage after 365 days and the magnitude of the peak in the seepage flow during that time the variance based global sensitivity analysis gsa according to sobol 2001 was used to explore the relationship between parameter values and model response sobol indices quantify the ratio of partial variances conditional on the respective model parameter and the total unconditional variance in the specified model output variable thus providing a measure for the contribution of each model parameter as predictors to the variance in the model output the first order s1 sobol indices are calculated for each parameter according to eq 7 where v is the variance e is the expectation y is the model output and xi is the respective parameter they represent the main impact of each parameter without statistical interactions sobol indices of several orders account for statistical interactions of the parameters the total indices st saltelli et al 2010 sum up the main impact plus the impact of all interactions which include the respective parameter according to eq 8 where x i is the matrix of all parameters except xi 7 s i v e y x i v y 8 s ti v e y x i v y the calculation of the partial variances is based on a quasi monte carlo method according to saltelli 2002 details on the sobol method and on the numerical quasi monte carlo approach can be found in saltelli 2002 and saltelli et al 2010 for the implementation in this study we used the sensitivity analysis library salib in python herman and usher 2017 since the forcing data were expected to influence parameter sensitivities the gsa was performed both for the humid and for the dry climate scenario the first order and total indices were calculated for the shps θ s α n k s and l for each climate scenario using 12 000 model runs the parameter θ r was fixed in order to not introduce arbitrariness in the absolute values of θ s and θ r for the seepage simulation it was set to 0 045 as a compromise for the soil types investigated in this study sand sandy loam loam silt loam and silt described in section 2 2 1 the range of parameter values evaluated in the gsa are given in table 2 the method relies on the successful evaluation of practically all sampled parameter combinations parameter ranges therefore have been limited in order to avoid non converging model runs but the ranges cover the true soil hydraulic properties and true differences θ s θ r of all soil types in this study confidence intervals for the sobol indices were derived from 1000 bootstrap resamples 2 4 bayesian information and uncertainty analysis 2 4 1 bayesian inference the parameter posterior distributions in the bayesian inference were estimated using the bayes theorem eq 9 where p ω d m is the posterior distribution of the model parameters ω given the data d and the model m p d m ω is the data likelihood p ω m is the prior parameter distribution and p d m is the marginal likelihood or bayesian model evidence bme 9 p ω d m p d m ω p ω m p d m the likelihood function was defined according to the data used in the inference for a singular measurement type with error characteristics as described in section 2 2 1 it can be formulated according to eq 10 where k is the number of model realizations and corresponding observed values σ is the standard deviation in the measurement error m i ω is the model realization and y i is the corresponding observed value 10 l ω i 1 k 1 2 π σ 2 exp 1 2 σ 2 m i ω y i 2 given several measurement types the data likelihood was aggregated as the product of likelihoods from the individual data types or for the purpose of algebraic simplicity as sum of the logarithmic likelihoods eq 11 shows the case of aggregating all three measurements where l q is the log likelihood from lysimeter outflow data l swc is the log likelihood from soil water content data and l mp is the log likelihood from matric potential data 11 l ω l q ω l swc ω l mp ω standard deviations of the measurement errors were estimated in the bayesian inference alongside with the shps physically reasonable ranges were established to constrain the uniform prior distributions for the model parameters as well as the measurement error standard deviations in order to avoid problems in the sampling procedure when peaks in the posterior get too close to the edge of the prior and in order to not assume too detailed prior knowledge on shps the prior ranges have been relaxed compared to the gsa upper and lower bounds of the prior distributions are given in table 3 the kullback leibler divergence kld eq 12 is a statistical measure for the difference between the prior π ω and posterior p ω parameter distributions as such it can be used as utility function to quantify the gain in information from the data assimilation 12 kld p ω l n p ω π ω d ω the posterior uncertainty in shps is represented by the coefficient of variation cv in the marginal posterior distributions of each parameter x and was calculated from standard deviations and means of the distributions eq 13 13 cv x σ x μ x in the bayesian analysis we evaluated the 7 data scenarios as described in section 2 2 1 for 5 numerical soil types and both climate scenarios as well as for the real world application the resulting posterior parameter uncertainties were propagated in the model to seepage flow the variances in the cumulative seepage and magnitude of the seepage peak resulting from this propagation were calculated as measure for the posterior predictive uncertainty to validate the models and to evaluate the effect of parameter uncertainties in a contrasting climate we propagated the parameter uncertainties from the synthetic scenarios a second time while interchanging the atmospheric boundary conditions of the climate scenarios for the real world application an adaption of prior bounds was necessary in order to not cut off posteriors and to allow for higher errors table a1 in appendix in contrast to our synthetic data scenarios we must expect the residuals between model predictions and observations in the real data application to include systematic errors from structural deficits of the model and uncertainty in the initial and boundary conditions höge et al 2019 vrugt et al 2004 the investigation of error residuals and the resulting issues for the adaptation of the likelihood function scharnagl et al 2015 wöhling and vrugt 2011 were beyond the scope of this study instead we aimed to test whether the negligence of such error characteristics in a real world application may influence the outcome of our study we therefore used the same bayesian framework both in synthetic scenarios and the real world application 2 4 2 nested sampling nested sampling was first introduced by skilling 2006 as an efficient monte carlo method for the estimation of the bayesian model evidence eq 14 where z is the evidence l ω is the likelihood π ω is the prior and d is the dimensionality of the parameter space the nested sampling algorithm transforms this equation to a one dimensional integral eq 15 which can be solved iteratively 14 z l ω π ω d d ω 15 z 0 1 l x d x samples from the prior live points are evenly distributed in the parameter space at the beginning in each iteration the live points are sorted according to their likelihoods and replaced under the condition of a likelihood threshold the prior volume represents the fraction of the prior integral which lies within this likelihood threshold the iteration proceeds until the prior volume shrinks to the bulk of the posterior this procedure allows to accumulate the information given by the kld eq 10 alongside with the evidence z and to obtain the parameter posterior distributions as a by product from the discarded live points the efficiency of the method was further improved with ellipsoidal nested sampling mukherjee et al 2006 where a d dimensional ellipsoid from the covariance matrix of the active live points is estimated to draw the isolikelihood contours and consequently sample from within the ellipsoid instead of blindly from the prior finally multimodal nested sampling allows to sample multiple modes of the posterior through the identification of well separated clusters of live points via recursive clustering these improvements are implemented in the algorithm multinest by feroz and hobson 2008 and feroz et al 2009 2019 further details about the method can be found in these publications in this study we used the python module pymultinest developed by buchner et al 2014 a stopping criterion is required when it can be assumed that the bulk of the posterior has been sampled sufficiently that is when the remaining contribution from the current live points to the evidence integral is expected to be smaller than a certain tolerance value the current maximum likelihood sample point after an iteration is multiplied with the remaining prior volume to estimate the maximum remaining volume of the evidence integral in this study the tolerance parameter in multinest was set to 1 the number of live points of n 100 used in this study has been established with a sensitivity analysis in previous studies by brunetti et al 2020a 2020b with similar model applications showing that a larger number of life points led only to a negligible reduction of the variation in the resulting evidence in few runs in this study n was increased to 150 200 live points when optima were close to the edge of the prior this helped to successfully terminate the sampling runs the multinest output provided samples from marginal posterior distributions as well as the kullback leibler divergences 2 5 workflow a summary of the workflow for the information and uncertainty analysis using synthetic data scenarios is given below 1 setup of hydrus 1d models for humid and dry climate scenario prescribing model structure boundary conditions and forcing data 2 global parameter sensitivity analysis gsa sobol with hydrus 1d models for both climate scenarios to identify sensitive shps for seepage prediction 3 generation of synthetic data specification of model parameters for 5 numerical soil types forward simulation and addition of artificial gaussian measurement errors combination of synthetic data in 7 data scenarios corresponding to respective soil water monitoring designs 4 bayesian analysis coupling of set up hydrus 1d models with the nested sampling algorithm in python to include synthetic data sets from each scenario in the bayesian inference for inverse shp estimation and propagation of parameter uncertainties in seepage prediction 5 model validation exchange of forcing data in calibrated models to evaluate fit of seepage simulations with the respective contrasting climate scenario in total we performed and evaluated 70 nested sampling runs for the synthetic part of the study including 7 data combinations monitoring designs 5 soil types and 2 climate scenarios we repeated the bayesian analysis step 4 of the workflow in the real world application using an adapted version of the hydrus 1d model setup and real measurements from the neuherberg lysimeter experiment 3 results and discussion of synthetic scenarios 3 1 parameter sensitivities for seepage simulation table 4 shows the first order and total sobol indices for the humid and the dry climate scenario parameter sensitivities increase with sobol indices approaching 1 the variance in the simulated cumulative seepage qc in the humid scenario was equally explained by the vgm shape parameters α and n and their respective interactions in the dry scenario however it was predominantly explained by n and its interactions in a recent study wesseling et al 2020a b investigated the sensitivity of vgm parameters for the prediction of various soil water model outputs in their case study and similarly found n to have the greatest influence on the bottom flux in the vgm model n defines the steepness of the soil water retention curve and therefore strongly determines the soil s capacity to hold water against gravity this in turn determines how much water is available for root water uptake and evapotranspiration which is potentially greater in a warm and dry climate it thereby strongly influences the partitioning of the soil water balance the variance in the magnitude of the seepage peak qm in the humid scenario was mainly explained by the saturated hydraulic conductivity ks and interactions followed by the saturated water content θs in the dry scenario the most sensitive parameter for the peak prediction was α followed by n and ks the sensitivity of ks for peak seepage prediction was large under humid conditions where the peak immediately following a precipitation event is the result of the downward flux governed by the hydraulic conductivity in the dry climate the soil is hardly ever close to saturation therefore ks loses its importance for the peak prediction but the shape of the hydraulic conductivity function α and n becomes more important the pore connectivity parameter l played an almost negligible role for the simulation of either cumulative amount or magnitude of seepage peak in both climates similarly l was found to be insensitive for the simulation of boundary fluxes with the vgm model by wesseling et al 2020b mualem 1976 stated that l can be estimated to be about 0 5 as an average for many soils this parameter is therefore often neglected in parameter estimations which is supported by our findings in both climate scenarios the models proved to be non additive first order indices not adding up to 1 the most important second order interactions in both climate scenarios were α n for qc and α ks for qm statistical interactions between the parameters were more important in the dry scenario than in the humid scenario with the exception of the θs ks interaction for the qm response which was more important in the humid scenario the parameters α and n are both crucial in determining the water retention capacity of the soil and therefore qc the parameter α however determines at the transition between saturated and unsaturated conditions whether a change in matric potential actually triggers a change in soil water content ks is most sensitive for the recharge peak however at the seepage face boundary a water flux is only generated when the pressure at the lower boundary is zero the parameter α can therefore influence whether the main sensitive parameters n for qc and ks for qm come into effect this was more important in the dry climate where conditions were more often shifting into the dry part of the water retention curve the sensitivity of θs and ks for the qm response is high in wet conditions consequently their interaction as well was more important in the humid climate scenario 3 2 shp estimation with multinest true parameter values of θs α n and ks were generally well identified by maximum a posteriori map estimates from nested sampling in the humid climate scenario the addition of matric potential data however introduced a bias in the shp estimates for sand ks α and θs whereas additional soil water content and matric potential data mitigated biases in shp estimation in all other soils both ks and α were overestimated for silt in the humid scenario with mp assimilation the parameter most often not accurately identified was the pore connectivity parameter l which also proved to be insensitive for the seepage prediction in this study the dry climate scenario resulted in larger deviations between true shps and map estimates for fine textured soils especially ks was overestimated by the map under dry conditions in fine soil types when only seepage data was assimilated q scenario this estimation however was also associated with higher uncertainties as will be further discussed in section 3 3 and 3 4 the map estimates for the parameters from all data scenarios are shown in table a2 humid climate scenario and table a3 dry climate scenario in the appendix exemplary corner plots of the marginal posterior distributions from the humid calibration with the base data scenario for sand are shown in the appendix in fig a1 3 3 gain in information for different soils kullback leibler divergences for each soil and both climate scenarios 7 data scenarios were assimilated in the bayesian inference and the resulting kullback leibler kl divergences between the joint priors and posteriors were evaluated fig 3 a higher kl divergence in this representation reflects a higher overall gain in information from the data which includes information on shps θs α n ks and l and the artificial measurement errors of the data the results for the humid climate scenario show that the gain in information from the same type and quality of data obtained with the same devices and temporal resolution increased from coarse to fine textures there was little difference between the two finest soil textures silt loam and silt where a small decrease in the kl divergences from silt loam to silt was found for the swc q swc and q mp scenarios the dry scenario however produced the opposite result for assimilation of seepage data alone q scenario here the information gain shrunk with increasingly fine soil texture and was generally smaller than from the humid climate scenario with the inclusion of soil water content data in the dry scenario q swc the information gain was relatively similar for the coarser soils sand sandy loam loam and moderately increased for the finer textured soils silt loam and silt where the higher information from soil water content data compensated the small informativeness of the seepage data the information gain however remained lower than in the humid scenario with the inclusion of matric potential data mp q mp swc mp and q swc mp scenarios in the dry climate the information gain improved and was similar to or even higher than in the humid climate for these scenarios the data assimilation again resulted in a continuous and pronounced increase in information gain from the coarse to the fine soil types similar to our study gao et al 2019 also observed a smaller reduction in parameter uncertainties and thus a smaller information gain for a sandy as compared to a finer loamy soil layer from observational data in a bayesian inference from an infiltration experiment we can assume that the seepage time series produced in this study were in general more informative for the finer textured soils because the temporal resolution of daily measurements more closely described their slower water flow processes the coarser textures drained faster resulting in less distinct dynamics of the lysimeter outflow for coarser soil textures as compared to fine textures in the humid scenario the dry scenario however led to an increasing occurrence of zero seepage in fine textured soils which reduced the information content of the seepage data it is important to note that different data sets influence the shape and dimensionality of the joint prior and posterior distributions and therefore limit the comparability of the total information gain between the data scenarios in this representation in order to better compare the informativeness of the data scenarios for each soil type we further assessed the reduction of uncertainty of the sensitive shps 3 4 parameter uncertainties from calibration scenarios from the joint posterior distribution marginal distributions for each estimated shp were obtained as one dimensional projections reflecting the uncertainty in each individual parameter these uncertainties were quantified as the coefficients of variation cv of the marginal distributions shown in fig 4 in the humid climate the data scenarios with smallest cvs and thus lowest uncertainties in sensitive parameters included q mp notably ks α n in sand sandy loam and silt loam or swc mp notably ks α n in silt in some cases the addition of the third measurement type q swc mp scenario further reduced parameter uncertainty ks in loam and silt α in loam and silt loam while in others it did not reduce or even slightly increase parameter uncertainty uncertainties ks α and n were highest in the swc scenario in all soils parameter uncertainties in the humid scenario decreased when soil water content and more importantly matric potential data was combined with seepage data in the assimilation this was more pronounced for the coarse than for the fine textured soils where parameter uncertainties were small already in the q scenario in accordance with the lower information gain section 3 3 the parameter uncertainties were higher in the coarse than in the fine soils with little difference between silt loam and silt in the dry climate scenario parameter uncertainties for sand in the q scenario were similar to the humid climate while for all other soil types they were considerably higher which corresponds to the decreased information gain shown by the lower kl divergences section 3 3 for the three finer soil types loam silt loam and silt parameter uncertainties decreased in the dry climate with the inclusion of soil water content and matric potential data again more pronouncedly with matric potential data for sand in contrast the uncertainty in θs α and ks increased uncertainties in n for sand and sensitive parameters in sandy loam under dry conditions were only reduced with additional matric potential data not with soil water content data and they remained higher than in the humid climate scenario in general the inclusion of matric potential measurements considerably reduced parameter uncertainties this corresponds to findings of schelle et al 2012 who also observed a marked increase in precision in shp estimation with additional matric potential data in a synthetic lysimeter scenario the soil water content and matric potential time series for the coarse soil textures did not cover the wet part of soil water retention and conductivity curves well this might also be the reason for the more biased estimation of ks α and θs when including matric potential measurements for sand previous studies have shown that inverse shp estimation is often biased when observational soil water data covers only a limited range and is extrapolated from the calibration durner et al 2008 schelle et al 2010 with finer textures the values shifted and captured the curves better which probably informed the underlying shps more effectively see fig 2 3 5 uncertainty propagation for seepage prediction and validation in contrasting climate the parameter uncertainties from each calibration data scenario were propagated as forward simulations to the seepage flow in the models variances in cumulative amount of seepage qc and in the magnitude of the seepage peak qm resulting from this uncertainty propagation were evaluated as measure for predictive uncertainty figures af 2 3 in the appendix they were validated against the true values in the respective contrasting climate scenario figures af 4 5 in the appendix the ranking of scenarios according to the uncertainty propagation within the calibration period was similar in both climate scenarios however predictive uncertainties in qm and qc were considerably lower in the dry scenario than in the humid scenario when including matric potential and soil water content data in both climate scenarios uncertainty in qc was similarly low in the q mp and q swc mp scenarios for sand and sandy loam for loam and silt loam it was lowest in the q mp scenario and for silt in the swc mp scenario in most cases this could be linked to the data scenarios with the smallest uncertainties for the vgm shape parameters α and n generally all scenarios including matric potential were relatively close to each other only for the coarse sand texture the q scenario was similarly good the uncertainty propagation to qm showed that the assimilation of all three data types q swc mp scenario was most successful for reducing uncertainties in peak recharge prediction in all soils for the coarse textures sand and sandy loam all scenarios including seepage data were however similarly efficient propagated uncertainties in both qc and in qm were highest in the swc scenario for all soils except qm prediction for silt where uncertainty was highest in the q scenario this also corresponded to the highest uncertainties in sensitive parameters ks α and n and lowest information gain for all soil textures in both climates in the validation of the dry scenario in the humid climate the temporal variability of the seepage flow was generally well captured but the uncertainty propagation led to higher uncertainties in cumulative and maximum seepage for all soils figures a4 a5 in the fine soil textures silt and silt loam the true values of qm and qc where mostly not within the uncertainty range reflecting the biases in the parameter estimation see section 3 2 the validation and uncertainty propagation of the humid scenario in the dry climate on the other hand showed a clear mismatch the combined use of matric potential and seepage data q mp and q swc mp scenarios in the humid calibration with sand had introduced a bias in the posterior distribution for α and ks which were both sensitive parameters for the seepage peak prediction under dry conditions the temporal variability of the true seepage flow was not well captured in this transfer scenario since individual samples from the biased parameter posteriors led to the erroneous simulation of additional peaks in the dry validation period fig 5 therefore the inclusion of matric potential data from the humid calibration scenario while reducing uncertainty in cumulative seepage and sensitive shps introduced uncertainty about the timing and number of occurring peaks in the seepage flow under dry conditions this shows that even in the ideal case with well known error characteristics in the observations and with the exclusion of model structural errors the uncertainties from soil water calibration data here matric potential specifically may lead to erroneous predictions of the temporal variability in groundwater recharge especially when atmospheric boundary conditions differ strongly from those of the calibration period similarly moeck et al 2018 observed a bias in the estimation of groundwater recharge when transferring results from a wet calibration period to dry conditions they obtained best results when either combining a wet and a dry scenario in the calibration or when climatic conditions of the validation period corresponded to those of the calibration period wöhling et al 2015 also made the observation that including a proxy variable soil water content with the boundary flux actual evapotranspiration data in the calibration reduced uncertainty but also introduced a bias in the prediction 3 6 discussion of data worth from synthetic scenarios when using only one single measurement type in the humid climate for coarse soil textures sand and sandy loam daily seepage data had the highest data worth with a high gain in information and low parameter and predictive uncertainties in dry climate seepage data was still more informative for sand and produced small predictive uncertainties for sand and sandy loam but for the finer soil types it lost its worth for loam silt loam and silt in the dry climate informativeness of seepage data was little and corresponding uncertainties were high instead soil water content and most of all matric potential data were more important this was especially true for the scenarios with an undisturbed lower boundary swc mp swc mp results for combining two measurement types showed a higher data worth in scenarios including matric potential for silt loam and silt the swc mp scenario in the dry climate was by far the most informative for silt in both climates and for silt loam in the dry climate the swc mp scenario corresponded to the smallest parameter and predictive uncertainties for silt loam in the humid climate as well as for coarser textures sand sandy loam and loam in both climates the q mp scenario resulted in smaller uncertainties and higher information gain than q swc and swc mp combining all three measurement types provided the highest absolute information gain per soil and climate except for silt loam in the dry and silt in both climate scenarios where it was surpassed by the swc mp scenario the q swc mp scenario also reliably resulted in low parameter and predictive uncertainties however it was often equaled or even surpassed by other data scenarios mainly by the q mp scenario with coarse textures and humid climate and the swc mp scenario in fine textures and dry climate a guideline summarizing the recommended prioritization of measurement types according to our results is presented in fig 6 for all scenarios considered in this study matric potential proved to be more informative and its use for calibration resulted in smaller uncertainties in seepage prediction than soil water content data a reason why matric potential had a higher data worth than soil water content in these scenarios might be that it is usually more variable over time compared to soil water content a change in matric potential does not necessarily lead to a change in water content depending on soil water retention characteristics and the part of the soil water retention function where a hydrological flux is occurring a wider range of values and especially more negative matric potential increased the informativeness of soil water content and matric potential data in fine soil textures and dry climate the non disruptive lower boundary in scenarios without seepage measurements also increased the dynamics and measurement range of these variables we cannot exclude the possibility that there are cases where soil water content is more informative this however requires further assessment in practice soil water content measurements have the advantage of being often easier to implement and to obtain than matric potential and seepage measurements while the latter are hardly transferrable to a larger scale there are a number of remote sensing techniques available to measure soil water content also on an area basis at least near soil surface which is advantageous for informing models for recharge prediction on a larger scale mohanty 2013 wöhling et al 2015 found that soil water content measurements from different profile depths provide important information for soil water model calibration and reduced predictive uncertainty of the seepage flux especially when combined with other calibration data similarly in our study we found that soil water content reduced uncertainty in the seepage prediction and increased the information gain when used as additional measurement to the seepage data we observed the same and even more pronounced for matric potential measurements similar to wöhling et al 2015 we observed in our synthetic scenarios with humid climate conditions that the data worth of the boundary flux was higher than the data worth of soil water content measurements as proxy variable and resulted in a less uncertain and less biased prediction however we also found that where the magnitude of the boundary flux was smaller the seepage flux in the dry climate scenario with fine soil textures the proxy variables became more important a limitation of this study is its focus on local measurements using simple lysimeter setups and probes in the soil profile where we assumed typical measurement precisions of such designs the size of the measurement error in the calibration data however can be expected to have an important influence on their ability to reduce model predictive uncertainties e g brunner et al 2012 finsterle 2015 this is also important concerning larger scale measurements where the precision tends to be lower xie et al 2018 for example found that soil moisture measurements with an assumed error of 10 were not helpful in reducing model predictive uncertainties in their study they also noted that the relation of temporal variation of the measured variable to the size of the error has a crucial impact on its usefulness for constraining uncertainties despite a low precision a measurement can therefore still be useful in soil types and under conditions where the temporal variation is high enough a systematic assessment of the influence of different measurement errors on the information content of calibration data is still required further for the monitoring designs in this study we did not take into account measurements of actual evapotranspiration eta which are usually more challenging to obtain than matric potential and soil water content as proxy variables for seepage flow however eta can be estimated using various methods including precision weighing lysimeters eddy covariance methods or remote sensing e g chen et al 2021 liebhard et al 2022 schrader et al 2013 eta measurements have been found to be beneficial for characterizing vadose zone properties and predicting recharge in several studies brunner et al 2012 wöhling et al 2015 and xie et al 2018 all found that eta measurements were efficient in reducing uncertainty in shp estimation and predicting soil water fluxes especially in combination with other observation types on the other hand schneider zapp et al 2010 showed that eta data alone were not sufficient for estimating the saturated hydraulic conductivity and required additional matric potential measurements groh et al 2018 found that in general the measurement of lysimeter boundary fluxes improved shp estimation we expect that measuring eta would be especially useful under conditions where it constitutes the dominant vertical water flux the impact of eta measurements according to different soil types and climates however should be systematically assessed in further studies 4 results and discussion of the real world application 4 1 estimated soil hydraulic parameters and measurement errors the estimated map parameters and measurement errors for the real world application with the neuherberg lysimeter experiment are given in table 5 map estimates varied depending on the data used for calibration scenarios with calibration of soil water content data resulted in much higher estimates for α and ks while the ks estimate from the q scenario was low the widely differing estimates from these scenarios were however associated with high uncertainties as shown in the next section 4 2 and fig 7 systematic deviations between simulated and observed values can be seen in the seepage flow fig 8 as well as in matric potential and soil water content measurements figures af 6 9 in the appendix assimilation of matric potential here led to a systematic offset in the simulation of soil water content but the temporal dynamics were generally well fitted this might be due to local heterogeneities at the measurement probes or an offset in the calibration of the probes structural errors in a real world application can be considerably larger than measurement errors in the calibration data vrugt and sadegh 2013 here the calibrated errors were several times higher than what we would assume purely from the measuring devices factor 2 3 for soil water content factor 2 5 for lysimeter outflow and factor 7 25 for matric potential measurements strategies to handle uncertainty about the true model structure include multi model approaches where several possible model structures are tested and combined as done for example by moeck et al 2016 they can also be integrated into a bayesian model averaging bma framework which allows to simultaneously evaluate data worth for model discrimination calibration and characterizing structural errors wöhling et al 2015 further multi objective functions can be used to summarize fits between model and different observation types to filter out structural deficits of the model e g wöhling et al 2013 vrugt and sadegh 2013 introduced approximate bayesian computation abc using signature based metrics instead of explicit likelihood functions to allow for a greater diagnostic power in identifying error sources and characteristics a proper treatment of structural errors where they are not lumped together with measurement noise as done here however remains a difficult task to which there is no universal solution doherty and welter 2010 4 2 parameter uncertainty and information gain the information gain in the real data application was overall highest in the q mp scenario this also corresponded to the lowest parameter uncertainties given by their coefficients of variation cvs in all key parameters fig 7 this outcome is similar to the synthetic scenario for sandy soil textures where however the q mp scenario was rivaled by the q swc mp scenario in informativeness and reduction of uncertainty presumably the inconsistencies in the real scenario with imperfectly matched measurement data caused the q swc mp scenario to lose here uncertainty in ks and α was highest in the q and q swc scenario respectively for one single measurement type as well as in combination with other measurement types matric potential data proved to be most informative similar as in the synthetic scenarios the lower information gain from the q scenario assimilation of seepage data alone can be mainly explained by the lower temporal resolution of seepage measurements in the neuherberg scenario weekly instead of daily measurements 4 3 uncertainty propagation the propagation of parameter uncertainties to cumulative seepage is shown in fig 8 the highest uncertainty and highest rmse in seepage prediction of all real data scenarios resulted from the assimilation of weekly lysimeter outflow rates alone a lower prediction uncertainty was achieved in scenarios with matric potential assimilation than in those without in these scenarios however a bias is visible especially at the beginning and the end of the time series this might be due to unknown initial conditions which were assumed to be a matric potential distribution from 100 hpa top to 25 hpa bottom in reality the soil profile was also not entirely homogeneous while uncertainty in the swc and q swc scenarios was higher than in the mp and q mp scenarios the rmse was lower the best fits to measured cumulative seepage were obtained with combination of matric potential and soil water content swc mp q swc mp 4 4 discussion of data worth from real world application overall the highest information gain and smallest uncertainties in parameters and seepage simulation in the neuherberg lysimeter analysis have been achieved in the q mp scenario the fit to seepage measurements improved with additional inclusion of swc data as in the synthetic scenarios matric potential proved to be the more informative variable than soil water content in addition to the reasons discussed in section 3 6 under real world conditions this might also be due to the fact that matric potential in the profile can reach equilibrium more or less immediately while soil water content does not diamantopoulos et al 2015 schultze et al 1997 in our real world application the unaccounted presence of model structural errors heterogeneity in the profile and inaccuracies forcing data might have led to an underestimation of parameter and model predictive uncertainty renard et al 2010 schoups and vrugt 2010 and the absolute data worth might have been diluted to some degree in terms of relative data worth and optimal design however the results were similar to the outcome of the synthetic scenarios for the corresponding coarse soil types this increases our confidence that despite the simplifying modeling assumptions the conclusions from the synthetic scenarios of this study are useful for real world applications a further assessment including real data from various soils and climates and an assessment of the effects of heterogeneity in the soil profile however is recommended 5 summary and conclusions the aim of the study was to evaluate the optimal exploitation of soil water monitoring data from simple monitoring setups for the estimation of shps and for the reduction of uncertainty in groundwater recharge prediction considering a range of soil textures and the influence of changing climatic conditions we demonstrated that knowledge on the soil water retention function in terms of the vgm shape parameters α and n is essential for determining the cumulative seepage in both the humid and dry climate scenario the greatest reduction of uncertainty in n mostly led to the lowest uncertainty in cumulative seepage prediction depending on the soil type this was achieved by the simultaneous assimilation of either seepage plus matric potential data soil water content plus matric potential data or all three data types together for predicting the magnitude of the peak in the seepage flow under humid conditions the saturated hydraulic conductivity parameter ks was most influential this was relevant for the silt soil where the assimilation of all three data types led to a better estimation and lower uncertainty in ks and consequently less uncertainty and a better fit in the validation of the seepage peak the gain in information from the same extent and quality of calibration data i e obtained with the same devices and temporal and spatial resolution generally led to a higher information gain and lower parameter uncertainties in fine as compared to coarse soil textures the only exception to this was when only seepage data was assimilated in the dry climate scenario in this case the information gain decreased from coarse to fine soil textures where less seepage events occurred throughout the calibration period leading to higher parameter and predictive uncertainties than in coarse soil types when the atmospheric boundary conditions changed from humid calibration to a dry validation period biased parameter estimation for sandy soil introduced additional uncertainty about the temporal variability in the seepage flow the results here suggest to rather increase the temporal resolution of the calibration data in a coarse soil in order to better capture the soil hydraulic processes and to further reduce predictive uncertainties the effect of different temporal resolutions of the calibration data on model uncertainties however needs to be further investigated in the real world application with a sandy soil lysimeter we identified a combination of matric potential and seepage measurements to be most informative and to produce the smallest parameter and predictive uncertainties for the seepage flow simulation in the real data case despite apparent systematic errors we obtained similar outcomes on the data worth of measurements as in the synthetic scenarios this supports that conclusions from the synthetic scenarios are useful for application under real field conditions based on our results we particularly recommend to measure matric potential in addition to lysmeter outflow in order to adequately estimate shps for groundwater recharge prediction in a moderate to humid climate for fine soil textures in dry climates measurements of matric potential and or soil water content are especially required for these cases a combination of matric potential and soil water content measurements in an otherwise undisrupted soil profile seems advantageous over a seepage face lysimeter setup for sandy soil in a dry climate on the other hand additional data to lysimeter outflow appeared to be inefficient in very coarse soil types we suggest to increase the temporal resolution of measurements to more than daily in order to avoid biases and unreliable predictions in conclusion the results of this study can help to prioritize measurement types for soil water monitoring installments for the estimation of shps and groundwater recharge and to better assess the reliability of estimations from real experiments for assessing the effect of conceptual model uncertainty and heterogeneity in soil profiles further testing with real world applications is recommended credit authorship contribution statement marleen schübl conceptualization methodology software formal analysis visualization writing original draft christine stumpp conceptualization methodology writing review editing supervision project administration funding acquisition giuseppe brunetti conceptualization methodology writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the austrian academy of sciences öaw vienna austria meteorological data was provided by the central institution for meteorology and geodynamics zamg vienna austria and the german weather service dwd offenbach germany we would like to thank the reviewers for their valuable input which improved this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128429 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
2967,transient measurements from soil water monitoring installments are frequently coupled with richards based solvers to inversely estimate soil hydraulic parameters shps and numerically describe vadose zone water fluxes such as groundwater recharge to reduce model predictive uncertainty the experimental setup should be designed to maximize the information content of observations however in practice this is generally done by relying on the a priori expertise of the scientist user without exploiting the advantages of model based experimental design thus the main aim of this study is to demonstrate how model based experimental design can be used to maximize the information content of observations in multiple synthetic scenarios encompassing different soil textural compositions and climatic conditions the hydrological model hydrus is coupled with a nested sampling estimator to calculate the parameters posterior distributions and the kullback leibler divergences results indicate that the combination of seepage flow soil water content and soil matric potential measurements generally leads to highly informative designs especially for fine textured soils while results from coarse soils are generally affected by higher uncertainty additionally the propagation of parameter uncertainties in a contrasting dry climate scenario strongly increased prediction uncertainties for sandy soil not only in terms of the cumulative amount and magnitude of the peak but also in the temporal variability of the seepage flow a complementary real world application with a sandy soil lysimeter identified a combination of seepage data and matric potential as the most informative design and confirmed findings of the synthetic scenarios in which matric potential proved to be more informative than soil water content measurements keywords lysimeter water flow modeling hydrus nested sampling bayesian data analysis groundwater recharge data availability data will be made available on request 1 introduction knowledge on vadose zone recharge fluxes is important for the sustainable management of groundwater as a resource for drinking and irrigation water as it represents the maximum amount of water that may be withdrawn from an aquifer without irreversibly depleting it taylor et al 2013 a large proportion of groundwater recharge is contributed by water infiltrating soil and flowing through the vadose zone döll and fiedler 2008 nolan et al 2007 the water flow through the vadose zone determines the cumulative amount of recharge important for the quantitative management of groundwater resources it also results in the temporal variability and magnitude of peaks in the recharge flux which are especially relevant for the management of water quality with regard to contaminants leaching to groundwater potentially deteriorating its ecological functions and usability for drinking water supply e g scanlon et al 2005 suchy et al 2018 zanello et al 2021 zhang et al 2020 various physically based modeling approaches exist for the estimation of soil water fluxes through the vadose zone and consequently of groundwater recharge scanlon 2011 šimůnek et al 2003 vereecken et al 2016 these models are often parameterized via the inverse estimation of soil hydraulic parameters shps from measured state variables inverse estimation can be advantageous over establishing parameter values from laboratory experiments since it grants flexibility in the adaption of experimental conditions to the spatial and temporal scale of interest dyck and kachanoski 2010 measurements from small scale samples in laboratories on the other hand are often found to be poorly transferable to field conditions e g stumpp et al 2012 vereecken et al 2008 vrugt et al 2008 wöhling et al 2008 the only option for directly measuring vadose zone fluxes are lysimeters especially when provided with sensors for additionally measuring soil water content and matric potential lysimeters represent good systems for establishing soil hydraulic processes durner et al 2008 however they may be biased in the construction of their lower boundary especially with seepage face conditions when the hydraulic gradient is disrupted they can also be biased in their assumption of a one dimensional water flow barkle et al 2011 pütz et al 2018 wöhling et al 2012 only few studies have investigated in the use of different types of measurements from soil water monitoring installments for the inverse estimation of effective shps in order to identify which information was needed for a unique parameter estimation as well as a reliable prediction of boundary fluxes durner et al 2008 groh et al 2018 schelle et al 2012 the most frequently used methods approach inverse parameter estimation as an optimization problem where a unique solution is obtained e g by least squares inversion information on the uncertainties related to the estimation in such an approach remains largely unavailable model predictions with inversely estimated parameters may fail or be associated with high uncertainties if either the model fails to include relevant components and processes for the prediction or because of issues with the quality and scope of the calibration data resulting in model parameters which are not known at a sufficient level of accuracy and precision finsterle 2015 vrugt and sadegh 2013 even under the assumption that the model structure adequately describes water transport processes the type quality and combination of data assimilated in the calibration process influence the extent of the parameter and consequently model predictive uncertainty furthermore uncertainties in the predictions might increase when climatic conditions deviate strongly from the calibration period moeck et al 2018 for an efficient soil water monitoring design that is aimed at the estimation of groundwater recharge evaluating the worth of calibration data from soil water monitoring installments for reducing prediction uncertainty is a key step this data worth depends on the type of prediction to be made wöhling et al 2015 overall it is not yet well understood how different types of calibration data affect uncertainties in modeling soil water fluxes a comprehensive sensitivity and data worth analysis is required which evaluates the efficiency of observational data for reducing uncertainty in the recharge prediction sensitivity analyses sa have gained importance as a tool to identify key processes and determine influential factors on model predictions finsterle 2015 gupta and razavi 2017 they make it possible to rank screen and potentially reduce the number of model parameters to be estimated for adequately predicting the variable of interest in the context of a data worth analysis the sa helps to identify observational data that deliver useful information specifically about the relevant sensitive parameters finsterle 2015 in order to properly evaluate how uncertainty in the estimation of sensitive parameters is reduced and how this affects the prediction uncertainty the sa can be combined with a comprehensive uncertainty analysis finsterle 2015 pan et al 2011 younes et al 2020 2013 soil hydrological modeling underlies uncertainties resulting from different sources of systematic and random errors they include uncertainty in measurements and forcing data in the initial and boundary conditions model structural or conceptual uncertainty as well as heterogeneity and scale effects which can all interact in a non linear way beven 2006 vereecken et al 2016 in a real world application it is difficult to separate these different error sources and properly account for them for a robust assessment of data worth and data related uncertainty it is therefore useful to reduce the influence of unknown sources of uncertainty by using synthetic scenarios brunetti et al 2020b for this purpose artificial measurement values can be generated via forward simulations with a given model parameterization and forcing data and afterwards perturbed by adding an artificial measurement error this approach has the advantage that the true data generating process is known exactly for a statistically robust information and uncertainty analysis the inverse parameter estimation is best integrated into a probabilistic framework based on the bayesian approach to statistics this approach relies on the idea of integrating a priori knowledge of the system in the statistical inference to combine it with the observed data i e measurements of soil water content matric potential and outflow in order to derive the posterior probabilities of model parameters monte carlo methods provide a tool for a statistically rigorous evaluation of the posterior however their application for a data worth analysis with soil hydrological models have certain limitations they must be compatible with strongly nonlinear and discontinuous models brunetti et al 2019 elsheikh et al 2014 mansouri et al 2013 and they ideally allow for the quantification of the information gain as relative entropy also called kullback leibler divergence between prior and posterior from the data assimilation brunetti et al 2020a several methods exist for the numerical evaluation of the bayesian integral and alongside the information gain most of which are computationally expensive schöniger et al 2014 skilling 2006 introduced nested sampling as an efficient monte carlo method for bayesian inference elsheikh et al 2013 described nested sampling as an efficient tool to address challenges in calibration uncertainty quantification and model selection with non linear subsurface flow models brunetti et al 2020b used nested sampling for model selection and uncertainty estimation in biogeochemical modeling including an assessment of the information gain from different measurements to our knowledge there is not yet a statistically rigorous analysis which accounts for different soil textures and climates and assesses the most efficient soil water monitoring design for groundwater recharge estimation there have been only few studies employing the kullback leibler divergence for similar vadose zone related purposes brunetti et al 2020a kikuchi et al 2015 overall this study aims to evaluate the optimal exploitation of soil water monitoring data for the estimation of shps and for seepage prediction for a range of different soil textures in order to account for both quantity and temporal variability in the recharge flux in this study we define annual cumulative amounts and the magnitude of the peak in the seepage flow as the variables of interest for prediction in a first step we carry out a global sensitivity analysis in order to determine influential shps for the prediction of the variables of interest under contrasting climatic conditions we further evaluate the information gain from synthetic soil water monitoring data for different soils and assess the data s effectiveness in reducing uncertainties about sensitive model parameters for this purpose we make use of a bayesian framework built on nested sampling which allows to assess the gain in information from the calibration data with rigorous statistical measures first we use synthetic data scenarios in the inference which allow us to exclude uncertainty stemming from system heterogeneities and unknown error characteristics thus we focus on the uncertainties which originate from the use of different types of measurements for model calibration and how they are impacted by different soil properties and climatic conditions we then test our approach in a real world application using data from a long term lysimeter experiment to see if results obtained from synthetic scenarios still hold under real conditions results of these scenarios should provide a basis for the improved assessment of real data as well as guidance for soil water monitoring installments designed for the estimation of groundwater recharge 2 material and methods 2 1 water flow and root water uptake the software for the simulation of water transport used in this study was hydrus 1d a finite elements model which numerically solves the water transport equations šimůnek et al 2008 its high computational efficiency was especially beneficial in this analysis which required a large number of model evaluations hydrus 1d provides an implementation of the richards equation presented in eq 1 for one dimensional equilibrium water flow where θ l3l 3 is the volumetric water content t t is the time variable z l is a vertical coordinate positive upward k h l t 1 is the unsaturated hydraulic conductivity function and h l is the water pressure head s is a sink term accounting for water uptake by plant roots which was simulated according to the model of feddes et al 1978 for an equally distributed root zone eq 2 where rd l is the root depth tp l is the potential transpiration and α h is a prescribed water stress response function depending on the crop type in this case with parameterization for grass cover taylor et al 1972 1 δ θ δ t δ δ z k h δ h δ z 1 s h 2 s h α h 1 r d t p the unimodal van genuchten mualem model vgm was selected to describe the soil water retention and hydraulic conductivity functions the former describes the relation between soil water content and soil pressure heads given in eq 3 where θr l3l 3 is the residual water content θs l3l 3 is the saturated water content α l 1 n and m are van genuchten shape parameters with the relation given in eq 4 the latter describes the relation between the unsaturated hydraulic conductivity and soil pressure heads given in eq 5 where se is the effective saturation defined in eq 6 and l l is a pore connectivity parameter 3 θ h θ r θ s θ r 1 α h n m i f h 0 θ s i f h 0 4 m 1 1 n n 1 5 k h k s s e l 1 1 s e 1 m m 2 6 s e θ θ r θ s θ r it has to be noted that the vgm model does not provide an ideal representation of all soils and conditions schaap and van genuchten 2006 and that a unimodal pore size distribution is often not given in natural soils which may exhibit structure and spatial heterogeneity durner 1994 however these assumptions have been found to be a good approximation to real systems for different applications in many studies e g brunetti et al 2020b dettmann et al 2014 in order not to introduce unwarranted complexity into this study it is reasonable to consider the simple and well established case of the unimodal vgm model 2 2 model setup and data scenarios 2 2 1 synthetic scenarios an atmospheric boundary condition was set at the soil surface where zero pressure was prescribed during ponding when both infiltration and surface runoff occur and an equilibrium was prescribed between the soil surface pressure and the atmospheric water vapor pressure when the atmospheric evaporative demand could not be met by evaporation from the soil profile for scenarios including seepage measurements the lower boundary condition at the bottom of the model domain was set to seepage face to reflect conditions of a lysimeter installment without control of the lower boundary for scenarios dealing exclusively with proxy measurements soil water content matric potential the lower boundary was set to free drainage the numerical domain in hydrus 1d was discretized into 100 finite elements for 100 cm profile depth all soils were assigned with a grass cover and a constant vertical root density with a rooting depth of rd 20 cm the forcing data for all simulations in this study were real meteorological observations obtained from the zamg central institution for meteorology and geodynamics austria and are therefore representative for austrian climate scenarios daily observations of precipitation and potential evapotranspiration for moderately humid climate conditions with 880 mm year precipitation fig 1 a and 463 mm year potential evapotranspiration fig 1c and for dry climate conditions with 253 mm year precipitation fig 1b and 561 mm year potential evapotranspiration fig 1d were used for the gsa for generating the synthetic data and for calibrating the models in the bayesian analysis the simulation of one year with an intermediate climate was used as a warm up period to obtain initial conditions for all further simulations five numerical homogeneous soil profiles of 1 m depth were established with shps corresponding to a range of soil textures according to the soil catalogue of carsel and parrish 1988 the synthetic soils are summarized in table 1 the artificial data for this study was generated as forward simulations of transient water regime in daily time steps this included matric potential mp and volumetric soil water content swc in 25 and 75 cm depth as well as lysimeter outflow q in 100 cm depth where the boundary condition was set to seepage face the partitioning of potential evapotranspiration into potential evaporation and potential transpiration in the simulations followed beer s law šimůnek 2015 with a leaf area index of lai 1 artificial homoscedastic independent gaussian measurement errors were applied as noise to the generated data and were intended to reflect the data quality from common seepage face lysimeters equipped with a balance for seepage water collection from time domain reflectometry tdr and from tensiometers the standard deviations of measurement errors for the lysimeter outflow was set to σq 0 1 mm e g schelle et al 2012 for matric potential measurements with tensiometers to σh 1 0 hpa e g schelle et al 2012 wöhling and vrugt 2011 and for the volumetric soil water content measurements with tdr the error was set to σθ 0 01 cm3 cm 3 e g durner et al 2008 evett et al 2005 the size and characteristics of the residuals correspond to errors originating only from the measurements residuals may be larger and potentially autocorrelated and or heteroscedastic non gaussian when they include additional error sources such as model structural errors höge et al 2019 wöhling et al 2015 wöhling and vrugt 2011 in the synthetic scenarios of this study we assumed our model to perfectly account for the data generating processes and exclusively focused on the uncertainty related to the observational data this circumvents having to account for other error sources and characteristics fig 2 shows the soil water retention curves corresponding to the 5 synthetic soils and the daily artificial soil water content and matric potential data points generated for model calibration in the bayesian inference based on the artificially generated time series 7 data scenarios were established using lysimeter outflow data q soil water content swc and matric potential mp data in all possible combinations the 7 data scenarios were consequently q swc mp q swc q mp swc mp and q swc mp 2 2 2 real data application neuherberg lysimeter experiment in order to test our approach in a real world application we used data from a long term lysimeter experiment which was conducted under conditions similar to those assumed for the synthetic scenarios the neuherberg lysimeter experiment 1997 2003 has been described in asadollahi et al 2020 stumpp et al 2009 and stumpp and maloszewski 2010 the lysimeter was constructed of stainless steel with 2 0 m depth 1 0 m2 surface and a seepage face boundary the soil was an undisturbed sandy soil humic cambisol for the purpose of this study we selected a 357 day calibration period 07 10 1997 28 09 1998 during cultivation of barley we used volumetric soil water content and matric potential both measured at 30 cm and 50 cm depth using tdr probes and tensiometers and weekly lysimeter outflow measurements at 200 cm depth the analysis for the real world application thus included the same 7 data combinations as in the synthetic scenarios of this study the hydrus 1d numerical domain was similar to the synthetic scenarios it included one material layer assuming a homogeneous profile daily weather data for variable boundary conditions were provided by the german weather service and daily potential evapotranspiration rates were calculated based on penman monteith and fao crop coefficients for barley according to allen et al 1998 the amounts of precipitation and calculated potential evapotranspiration during the calibration period were 668 mm and 444 mm respectively corresponding to an intermediate between the humid and dry scenario in the synthetic analysis 2 3 sensitivity analysis a sensitivity analysis served to identify which of the uncertain shps in the unimodal vgm hydrus 1d model have the greatest effect on model predictions and prediction uncertainties a parameter is called sensitive when changing its value leads to a noticeable difference in the model response gupta and razavi 2017 the variables of interest were the cumulative amount of seepage after 365 days and the magnitude of the peak in the seepage flow during that time the variance based global sensitivity analysis gsa according to sobol 2001 was used to explore the relationship between parameter values and model response sobol indices quantify the ratio of partial variances conditional on the respective model parameter and the total unconditional variance in the specified model output variable thus providing a measure for the contribution of each model parameter as predictors to the variance in the model output the first order s1 sobol indices are calculated for each parameter according to eq 7 where v is the variance e is the expectation y is the model output and xi is the respective parameter they represent the main impact of each parameter without statistical interactions sobol indices of several orders account for statistical interactions of the parameters the total indices st saltelli et al 2010 sum up the main impact plus the impact of all interactions which include the respective parameter according to eq 8 where x i is the matrix of all parameters except xi 7 s i v e y x i v y 8 s ti v e y x i v y the calculation of the partial variances is based on a quasi monte carlo method according to saltelli 2002 details on the sobol method and on the numerical quasi monte carlo approach can be found in saltelli 2002 and saltelli et al 2010 for the implementation in this study we used the sensitivity analysis library salib in python herman and usher 2017 since the forcing data were expected to influence parameter sensitivities the gsa was performed both for the humid and for the dry climate scenario the first order and total indices were calculated for the shps θ s α n k s and l for each climate scenario using 12 000 model runs the parameter θ r was fixed in order to not introduce arbitrariness in the absolute values of θ s and θ r for the seepage simulation it was set to 0 045 as a compromise for the soil types investigated in this study sand sandy loam loam silt loam and silt described in section 2 2 1 the range of parameter values evaluated in the gsa are given in table 2 the method relies on the successful evaluation of practically all sampled parameter combinations parameter ranges therefore have been limited in order to avoid non converging model runs but the ranges cover the true soil hydraulic properties and true differences θ s θ r of all soil types in this study confidence intervals for the sobol indices were derived from 1000 bootstrap resamples 2 4 bayesian information and uncertainty analysis 2 4 1 bayesian inference the parameter posterior distributions in the bayesian inference were estimated using the bayes theorem eq 9 where p ω d m is the posterior distribution of the model parameters ω given the data d and the model m p d m ω is the data likelihood p ω m is the prior parameter distribution and p d m is the marginal likelihood or bayesian model evidence bme 9 p ω d m p d m ω p ω m p d m the likelihood function was defined according to the data used in the inference for a singular measurement type with error characteristics as described in section 2 2 1 it can be formulated according to eq 10 where k is the number of model realizations and corresponding observed values σ is the standard deviation in the measurement error m i ω is the model realization and y i is the corresponding observed value 10 l ω i 1 k 1 2 π σ 2 exp 1 2 σ 2 m i ω y i 2 given several measurement types the data likelihood was aggregated as the product of likelihoods from the individual data types or for the purpose of algebraic simplicity as sum of the logarithmic likelihoods eq 11 shows the case of aggregating all three measurements where l q is the log likelihood from lysimeter outflow data l swc is the log likelihood from soil water content data and l mp is the log likelihood from matric potential data 11 l ω l q ω l swc ω l mp ω standard deviations of the measurement errors were estimated in the bayesian inference alongside with the shps physically reasonable ranges were established to constrain the uniform prior distributions for the model parameters as well as the measurement error standard deviations in order to avoid problems in the sampling procedure when peaks in the posterior get too close to the edge of the prior and in order to not assume too detailed prior knowledge on shps the prior ranges have been relaxed compared to the gsa upper and lower bounds of the prior distributions are given in table 3 the kullback leibler divergence kld eq 12 is a statistical measure for the difference between the prior π ω and posterior p ω parameter distributions as such it can be used as utility function to quantify the gain in information from the data assimilation 12 kld p ω l n p ω π ω d ω the posterior uncertainty in shps is represented by the coefficient of variation cv in the marginal posterior distributions of each parameter x and was calculated from standard deviations and means of the distributions eq 13 13 cv x σ x μ x in the bayesian analysis we evaluated the 7 data scenarios as described in section 2 2 1 for 5 numerical soil types and both climate scenarios as well as for the real world application the resulting posterior parameter uncertainties were propagated in the model to seepage flow the variances in the cumulative seepage and magnitude of the seepage peak resulting from this propagation were calculated as measure for the posterior predictive uncertainty to validate the models and to evaluate the effect of parameter uncertainties in a contrasting climate we propagated the parameter uncertainties from the synthetic scenarios a second time while interchanging the atmospheric boundary conditions of the climate scenarios for the real world application an adaption of prior bounds was necessary in order to not cut off posteriors and to allow for higher errors table a1 in appendix in contrast to our synthetic data scenarios we must expect the residuals between model predictions and observations in the real data application to include systematic errors from structural deficits of the model and uncertainty in the initial and boundary conditions höge et al 2019 vrugt et al 2004 the investigation of error residuals and the resulting issues for the adaptation of the likelihood function scharnagl et al 2015 wöhling and vrugt 2011 were beyond the scope of this study instead we aimed to test whether the negligence of such error characteristics in a real world application may influence the outcome of our study we therefore used the same bayesian framework both in synthetic scenarios and the real world application 2 4 2 nested sampling nested sampling was first introduced by skilling 2006 as an efficient monte carlo method for the estimation of the bayesian model evidence eq 14 where z is the evidence l ω is the likelihood π ω is the prior and d is the dimensionality of the parameter space the nested sampling algorithm transforms this equation to a one dimensional integral eq 15 which can be solved iteratively 14 z l ω π ω d d ω 15 z 0 1 l x d x samples from the prior live points are evenly distributed in the parameter space at the beginning in each iteration the live points are sorted according to their likelihoods and replaced under the condition of a likelihood threshold the prior volume represents the fraction of the prior integral which lies within this likelihood threshold the iteration proceeds until the prior volume shrinks to the bulk of the posterior this procedure allows to accumulate the information given by the kld eq 10 alongside with the evidence z and to obtain the parameter posterior distributions as a by product from the discarded live points the efficiency of the method was further improved with ellipsoidal nested sampling mukherjee et al 2006 where a d dimensional ellipsoid from the covariance matrix of the active live points is estimated to draw the isolikelihood contours and consequently sample from within the ellipsoid instead of blindly from the prior finally multimodal nested sampling allows to sample multiple modes of the posterior through the identification of well separated clusters of live points via recursive clustering these improvements are implemented in the algorithm multinest by feroz and hobson 2008 and feroz et al 2009 2019 further details about the method can be found in these publications in this study we used the python module pymultinest developed by buchner et al 2014 a stopping criterion is required when it can be assumed that the bulk of the posterior has been sampled sufficiently that is when the remaining contribution from the current live points to the evidence integral is expected to be smaller than a certain tolerance value the current maximum likelihood sample point after an iteration is multiplied with the remaining prior volume to estimate the maximum remaining volume of the evidence integral in this study the tolerance parameter in multinest was set to 1 the number of live points of n 100 used in this study has been established with a sensitivity analysis in previous studies by brunetti et al 2020a 2020b with similar model applications showing that a larger number of life points led only to a negligible reduction of the variation in the resulting evidence in few runs in this study n was increased to 150 200 live points when optima were close to the edge of the prior this helped to successfully terminate the sampling runs the multinest output provided samples from marginal posterior distributions as well as the kullback leibler divergences 2 5 workflow a summary of the workflow for the information and uncertainty analysis using synthetic data scenarios is given below 1 setup of hydrus 1d models for humid and dry climate scenario prescribing model structure boundary conditions and forcing data 2 global parameter sensitivity analysis gsa sobol with hydrus 1d models for both climate scenarios to identify sensitive shps for seepage prediction 3 generation of synthetic data specification of model parameters for 5 numerical soil types forward simulation and addition of artificial gaussian measurement errors combination of synthetic data in 7 data scenarios corresponding to respective soil water monitoring designs 4 bayesian analysis coupling of set up hydrus 1d models with the nested sampling algorithm in python to include synthetic data sets from each scenario in the bayesian inference for inverse shp estimation and propagation of parameter uncertainties in seepage prediction 5 model validation exchange of forcing data in calibrated models to evaluate fit of seepage simulations with the respective contrasting climate scenario in total we performed and evaluated 70 nested sampling runs for the synthetic part of the study including 7 data combinations monitoring designs 5 soil types and 2 climate scenarios we repeated the bayesian analysis step 4 of the workflow in the real world application using an adapted version of the hydrus 1d model setup and real measurements from the neuherberg lysimeter experiment 3 results and discussion of synthetic scenarios 3 1 parameter sensitivities for seepage simulation table 4 shows the first order and total sobol indices for the humid and the dry climate scenario parameter sensitivities increase with sobol indices approaching 1 the variance in the simulated cumulative seepage qc in the humid scenario was equally explained by the vgm shape parameters α and n and their respective interactions in the dry scenario however it was predominantly explained by n and its interactions in a recent study wesseling et al 2020a b investigated the sensitivity of vgm parameters for the prediction of various soil water model outputs in their case study and similarly found n to have the greatest influence on the bottom flux in the vgm model n defines the steepness of the soil water retention curve and therefore strongly determines the soil s capacity to hold water against gravity this in turn determines how much water is available for root water uptake and evapotranspiration which is potentially greater in a warm and dry climate it thereby strongly influences the partitioning of the soil water balance the variance in the magnitude of the seepage peak qm in the humid scenario was mainly explained by the saturated hydraulic conductivity ks and interactions followed by the saturated water content θs in the dry scenario the most sensitive parameter for the peak prediction was α followed by n and ks the sensitivity of ks for peak seepage prediction was large under humid conditions where the peak immediately following a precipitation event is the result of the downward flux governed by the hydraulic conductivity in the dry climate the soil is hardly ever close to saturation therefore ks loses its importance for the peak prediction but the shape of the hydraulic conductivity function α and n becomes more important the pore connectivity parameter l played an almost negligible role for the simulation of either cumulative amount or magnitude of seepage peak in both climates similarly l was found to be insensitive for the simulation of boundary fluxes with the vgm model by wesseling et al 2020b mualem 1976 stated that l can be estimated to be about 0 5 as an average for many soils this parameter is therefore often neglected in parameter estimations which is supported by our findings in both climate scenarios the models proved to be non additive first order indices not adding up to 1 the most important second order interactions in both climate scenarios were α n for qc and α ks for qm statistical interactions between the parameters were more important in the dry scenario than in the humid scenario with the exception of the θs ks interaction for the qm response which was more important in the humid scenario the parameters α and n are both crucial in determining the water retention capacity of the soil and therefore qc the parameter α however determines at the transition between saturated and unsaturated conditions whether a change in matric potential actually triggers a change in soil water content ks is most sensitive for the recharge peak however at the seepage face boundary a water flux is only generated when the pressure at the lower boundary is zero the parameter α can therefore influence whether the main sensitive parameters n for qc and ks for qm come into effect this was more important in the dry climate where conditions were more often shifting into the dry part of the water retention curve the sensitivity of θs and ks for the qm response is high in wet conditions consequently their interaction as well was more important in the humid climate scenario 3 2 shp estimation with multinest true parameter values of θs α n and ks were generally well identified by maximum a posteriori map estimates from nested sampling in the humid climate scenario the addition of matric potential data however introduced a bias in the shp estimates for sand ks α and θs whereas additional soil water content and matric potential data mitigated biases in shp estimation in all other soils both ks and α were overestimated for silt in the humid scenario with mp assimilation the parameter most often not accurately identified was the pore connectivity parameter l which also proved to be insensitive for the seepage prediction in this study the dry climate scenario resulted in larger deviations between true shps and map estimates for fine textured soils especially ks was overestimated by the map under dry conditions in fine soil types when only seepage data was assimilated q scenario this estimation however was also associated with higher uncertainties as will be further discussed in section 3 3 and 3 4 the map estimates for the parameters from all data scenarios are shown in table a2 humid climate scenario and table a3 dry climate scenario in the appendix exemplary corner plots of the marginal posterior distributions from the humid calibration with the base data scenario for sand are shown in the appendix in fig a1 3 3 gain in information for different soils kullback leibler divergences for each soil and both climate scenarios 7 data scenarios were assimilated in the bayesian inference and the resulting kullback leibler kl divergences between the joint priors and posteriors were evaluated fig 3 a higher kl divergence in this representation reflects a higher overall gain in information from the data which includes information on shps θs α n ks and l and the artificial measurement errors of the data the results for the humid climate scenario show that the gain in information from the same type and quality of data obtained with the same devices and temporal resolution increased from coarse to fine textures there was little difference between the two finest soil textures silt loam and silt where a small decrease in the kl divergences from silt loam to silt was found for the swc q swc and q mp scenarios the dry scenario however produced the opposite result for assimilation of seepage data alone q scenario here the information gain shrunk with increasingly fine soil texture and was generally smaller than from the humid climate scenario with the inclusion of soil water content data in the dry scenario q swc the information gain was relatively similar for the coarser soils sand sandy loam loam and moderately increased for the finer textured soils silt loam and silt where the higher information from soil water content data compensated the small informativeness of the seepage data the information gain however remained lower than in the humid scenario with the inclusion of matric potential data mp q mp swc mp and q swc mp scenarios in the dry climate the information gain improved and was similar to or even higher than in the humid climate for these scenarios the data assimilation again resulted in a continuous and pronounced increase in information gain from the coarse to the fine soil types similar to our study gao et al 2019 also observed a smaller reduction in parameter uncertainties and thus a smaller information gain for a sandy as compared to a finer loamy soil layer from observational data in a bayesian inference from an infiltration experiment we can assume that the seepage time series produced in this study were in general more informative for the finer textured soils because the temporal resolution of daily measurements more closely described their slower water flow processes the coarser textures drained faster resulting in less distinct dynamics of the lysimeter outflow for coarser soil textures as compared to fine textures in the humid scenario the dry scenario however led to an increasing occurrence of zero seepage in fine textured soils which reduced the information content of the seepage data it is important to note that different data sets influence the shape and dimensionality of the joint prior and posterior distributions and therefore limit the comparability of the total information gain between the data scenarios in this representation in order to better compare the informativeness of the data scenarios for each soil type we further assessed the reduction of uncertainty of the sensitive shps 3 4 parameter uncertainties from calibration scenarios from the joint posterior distribution marginal distributions for each estimated shp were obtained as one dimensional projections reflecting the uncertainty in each individual parameter these uncertainties were quantified as the coefficients of variation cv of the marginal distributions shown in fig 4 in the humid climate the data scenarios with smallest cvs and thus lowest uncertainties in sensitive parameters included q mp notably ks α n in sand sandy loam and silt loam or swc mp notably ks α n in silt in some cases the addition of the third measurement type q swc mp scenario further reduced parameter uncertainty ks in loam and silt α in loam and silt loam while in others it did not reduce or even slightly increase parameter uncertainty uncertainties ks α and n were highest in the swc scenario in all soils parameter uncertainties in the humid scenario decreased when soil water content and more importantly matric potential data was combined with seepage data in the assimilation this was more pronounced for the coarse than for the fine textured soils where parameter uncertainties were small already in the q scenario in accordance with the lower information gain section 3 3 the parameter uncertainties were higher in the coarse than in the fine soils with little difference between silt loam and silt in the dry climate scenario parameter uncertainties for sand in the q scenario were similar to the humid climate while for all other soil types they were considerably higher which corresponds to the decreased information gain shown by the lower kl divergences section 3 3 for the three finer soil types loam silt loam and silt parameter uncertainties decreased in the dry climate with the inclusion of soil water content and matric potential data again more pronouncedly with matric potential data for sand in contrast the uncertainty in θs α and ks increased uncertainties in n for sand and sensitive parameters in sandy loam under dry conditions were only reduced with additional matric potential data not with soil water content data and they remained higher than in the humid climate scenario in general the inclusion of matric potential measurements considerably reduced parameter uncertainties this corresponds to findings of schelle et al 2012 who also observed a marked increase in precision in shp estimation with additional matric potential data in a synthetic lysimeter scenario the soil water content and matric potential time series for the coarse soil textures did not cover the wet part of soil water retention and conductivity curves well this might also be the reason for the more biased estimation of ks α and θs when including matric potential measurements for sand previous studies have shown that inverse shp estimation is often biased when observational soil water data covers only a limited range and is extrapolated from the calibration durner et al 2008 schelle et al 2010 with finer textures the values shifted and captured the curves better which probably informed the underlying shps more effectively see fig 2 3 5 uncertainty propagation for seepage prediction and validation in contrasting climate the parameter uncertainties from each calibration data scenario were propagated as forward simulations to the seepage flow in the models variances in cumulative amount of seepage qc and in the magnitude of the seepage peak qm resulting from this uncertainty propagation were evaluated as measure for predictive uncertainty figures af 2 3 in the appendix they were validated against the true values in the respective contrasting climate scenario figures af 4 5 in the appendix the ranking of scenarios according to the uncertainty propagation within the calibration period was similar in both climate scenarios however predictive uncertainties in qm and qc were considerably lower in the dry scenario than in the humid scenario when including matric potential and soil water content data in both climate scenarios uncertainty in qc was similarly low in the q mp and q swc mp scenarios for sand and sandy loam for loam and silt loam it was lowest in the q mp scenario and for silt in the swc mp scenario in most cases this could be linked to the data scenarios with the smallest uncertainties for the vgm shape parameters α and n generally all scenarios including matric potential were relatively close to each other only for the coarse sand texture the q scenario was similarly good the uncertainty propagation to qm showed that the assimilation of all three data types q swc mp scenario was most successful for reducing uncertainties in peak recharge prediction in all soils for the coarse textures sand and sandy loam all scenarios including seepage data were however similarly efficient propagated uncertainties in both qc and in qm were highest in the swc scenario for all soils except qm prediction for silt where uncertainty was highest in the q scenario this also corresponded to the highest uncertainties in sensitive parameters ks α and n and lowest information gain for all soil textures in both climates in the validation of the dry scenario in the humid climate the temporal variability of the seepage flow was generally well captured but the uncertainty propagation led to higher uncertainties in cumulative and maximum seepage for all soils figures a4 a5 in the fine soil textures silt and silt loam the true values of qm and qc where mostly not within the uncertainty range reflecting the biases in the parameter estimation see section 3 2 the validation and uncertainty propagation of the humid scenario in the dry climate on the other hand showed a clear mismatch the combined use of matric potential and seepage data q mp and q swc mp scenarios in the humid calibration with sand had introduced a bias in the posterior distribution for α and ks which were both sensitive parameters for the seepage peak prediction under dry conditions the temporal variability of the true seepage flow was not well captured in this transfer scenario since individual samples from the biased parameter posteriors led to the erroneous simulation of additional peaks in the dry validation period fig 5 therefore the inclusion of matric potential data from the humid calibration scenario while reducing uncertainty in cumulative seepage and sensitive shps introduced uncertainty about the timing and number of occurring peaks in the seepage flow under dry conditions this shows that even in the ideal case with well known error characteristics in the observations and with the exclusion of model structural errors the uncertainties from soil water calibration data here matric potential specifically may lead to erroneous predictions of the temporal variability in groundwater recharge especially when atmospheric boundary conditions differ strongly from those of the calibration period similarly moeck et al 2018 observed a bias in the estimation of groundwater recharge when transferring results from a wet calibration period to dry conditions they obtained best results when either combining a wet and a dry scenario in the calibration or when climatic conditions of the validation period corresponded to those of the calibration period wöhling et al 2015 also made the observation that including a proxy variable soil water content with the boundary flux actual evapotranspiration data in the calibration reduced uncertainty but also introduced a bias in the prediction 3 6 discussion of data worth from synthetic scenarios when using only one single measurement type in the humid climate for coarse soil textures sand and sandy loam daily seepage data had the highest data worth with a high gain in information and low parameter and predictive uncertainties in dry climate seepage data was still more informative for sand and produced small predictive uncertainties for sand and sandy loam but for the finer soil types it lost its worth for loam silt loam and silt in the dry climate informativeness of seepage data was little and corresponding uncertainties were high instead soil water content and most of all matric potential data were more important this was especially true for the scenarios with an undisturbed lower boundary swc mp swc mp results for combining two measurement types showed a higher data worth in scenarios including matric potential for silt loam and silt the swc mp scenario in the dry climate was by far the most informative for silt in both climates and for silt loam in the dry climate the swc mp scenario corresponded to the smallest parameter and predictive uncertainties for silt loam in the humid climate as well as for coarser textures sand sandy loam and loam in both climates the q mp scenario resulted in smaller uncertainties and higher information gain than q swc and swc mp combining all three measurement types provided the highest absolute information gain per soil and climate except for silt loam in the dry and silt in both climate scenarios where it was surpassed by the swc mp scenario the q swc mp scenario also reliably resulted in low parameter and predictive uncertainties however it was often equaled or even surpassed by other data scenarios mainly by the q mp scenario with coarse textures and humid climate and the swc mp scenario in fine textures and dry climate a guideline summarizing the recommended prioritization of measurement types according to our results is presented in fig 6 for all scenarios considered in this study matric potential proved to be more informative and its use for calibration resulted in smaller uncertainties in seepage prediction than soil water content data a reason why matric potential had a higher data worth than soil water content in these scenarios might be that it is usually more variable over time compared to soil water content a change in matric potential does not necessarily lead to a change in water content depending on soil water retention characteristics and the part of the soil water retention function where a hydrological flux is occurring a wider range of values and especially more negative matric potential increased the informativeness of soil water content and matric potential data in fine soil textures and dry climate the non disruptive lower boundary in scenarios without seepage measurements also increased the dynamics and measurement range of these variables we cannot exclude the possibility that there are cases where soil water content is more informative this however requires further assessment in practice soil water content measurements have the advantage of being often easier to implement and to obtain than matric potential and seepage measurements while the latter are hardly transferrable to a larger scale there are a number of remote sensing techniques available to measure soil water content also on an area basis at least near soil surface which is advantageous for informing models for recharge prediction on a larger scale mohanty 2013 wöhling et al 2015 found that soil water content measurements from different profile depths provide important information for soil water model calibration and reduced predictive uncertainty of the seepage flux especially when combined with other calibration data similarly in our study we found that soil water content reduced uncertainty in the seepage prediction and increased the information gain when used as additional measurement to the seepage data we observed the same and even more pronounced for matric potential measurements similar to wöhling et al 2015 we observed in our synthetic scenarios with humid climate conditions that the data worth of the boundary flux was higher than the data worth of soil water content measurements as proxy variable and resulted in a less uncertain and less biased prediction however we also found that where the magnitude of the boundary flux was smaller the seepage flux in the dry climate scenario with fine soil textures the proxy variables became more important a limitation of this study is its focus on local measurements using simple lysimeter setups and probes in the soil profile where we assumed typical measurement precisions of such designs the size of the measurement error in the calibration data however can be expected to have an important influence on their ability to reduce model predictive uncertainties e g brunner et al 2012 finsterle 2015 this is also important concerning larger scale measurements where the precision tends to be lower xie et al 2018 for example found that soil moisture measurements with an assumed error of 10 were not helpful in reducing model predictive uncertainties in their study they also noted that the relation of temporal variation of the measured variable to the size of the error has a crucial impact on its usefulness for constraining uncertainties despite a low precision a measurement can therefore still be useful in soil types and under conditions where the temporal variation is high enough a systematic assessment of the influence of different measurement errors on the information content of calibration data is still required further for the monitoring designs in this study we did not take into account measurements of actual evapotranspiration eta which are usually more challenging to obtain than matric potential and soil water content as proxy variables for seepage flow however eta can be estimated using various methods including precision weighing lysimeters eddy covariance methods or remote sensing e g chen et al 2021 liebhard et al 2022 schrader et al 2013 eta measurements have been found to be beneficial for characterizing vadose zone properties and predicting recharge in several studies brunner et al 2012 wöhling et al 2015 and xie et al 2018 all found that eta measurements were efficient in reducing uncertainty in shp estimation and predicting soil water fluxes especially in combination with other observation types on the other hand schneider zapp et al 2010 showed that eta data alone were not sufficient for estimating the saturated hydraulic conductivity and required additional matric potential measurements groh et al 2018 found that in general the measurement of lysimeter boundary fluxes improved shp estimation we expect that measuring eta would be especially useful under conditions where it constitutes the dominant vertical water flux the impact of eta measurements according to different soil types and climates however should be systematically assessed in further studies 4 results and discussion of the real world application 4 1 estimated soil hydraulic parameters and measurement errors the estimated map parameters and measurement errors for the real world application with the neuherberg lysimeter experiment are given in table 5 map estimates varied depending on the data used for calibration scenarios with calibration of soil water content data resulted in much higher estimates for α and ks while the ks estimate from the q scenario was low the widely differing estimates from these scenarios were however associated with high uncertainties as shown in the next section 4 2 and fig 7 systematic deviations between simulated and observed values can be seen in the seepage flow fig 8 as well as in matric potential and soil water content measurements figures af 6 9 in the appendix assimilation of matric potential here led to a systematic offset in the simulation of soil water content but the temporal dynamics were generally well fitted this might be due to local heterogeneities at the measurement probes or an offset in the calibration of the probes structural errors in a real world application can be considerably larger than measurement errors in the calibration data vrugt and sadegh 2013 here the calibrated errors were several times higher than what we would assume purely from the measuring devices factor 2 3 for soil water content factor 2 5 for lysimeter outflow and factor 7 25 for matric potential measurements strategies to handle uncertainty about the true model structure include multi model approaches where several possible model structures are tested and combined as done for example by moeck et al 2016 they can also be integrated into a bayesian model averaging bma framework which allows to simultaneously evaluate data worth for model discrimination calibration and characterizing structural errors wöhling et al 2015 further multi objective functions can be used to summarize fits between model and different observation types to filter out structural deficits of the model e g wöhling et al 2013 vrugt and sadegh 2013 introduced approximate bayesian computation abc using signature based metrics instead of explicit likelihood functions to allow for a greater diagnostic power in identifying error sources and characteristics a proper treatment of structural errors where they are not lumped together with measurement noise as done here however remains a difficult task to which there is no universal solution doherty and welter 2010 4 2 parameter uncertainty and information gain the information gain in the real data application was overall highest in the q mp scenario this also corresponded to the lowest parameter uncertainties given by their coefficients of variation cvs in all key parameters fig 7 this outcome is similar to the synthetic scenario for sandy soil textures where however the q mp scenario was rivaled by the q swc mp scenario in informativeness and reduction of uncertainty presumably the inconsistencies in the real scenario with imperfectly matched measurement data caused the q swc mp scenario to lose here uncertainty in ks and α was highest in the q and q swc scenario respectively for one single measurement type as well as in combination with other measurement types matric potential data proved to be most informative similar as in the synthetic scenarios the lower information gain from the q scenario assimilation of seepage data alone can be mainly explained by the lower temporal resolution of seepage measurements in the neuherberg scenario weekly instead of daily measurements 4 3 uncertainty propagation the propagation of parameter uncertainties to cumulative seepage is shown in fig 8 the highest uncertainty and highest rmse in seepage prediction of all real data scenarios resulted from the assimilation of weekly lysimeter outflow rates alone a lower prediction uncertainty was achieved in scenarios with matric potential assimilation than in those without in these scenarios however a bias is visible especially at the beginning and the end of the time series this might be due to unknown initial conditions which were assumed to be a matric potential distribution from 100 hpa top to 25 hpa bottom in reality the soil profile was also not entirely homogeneous while uncertainty in the swc and q swc scenarios was higher than in the mp and q mp scenarios the rmse was lower the best fits to measured cumulative seepage were obtained with combination of matric potential and soil water content swc mp q swc mp 4 4 discussion of data worth from real world application overall the highest information gain and smallest uncertainties in parameters and seepage simulation in the neuherberg lysimeter analysis have been achieved in the q mp scenario the fit to seepage measurements improved with additional inclusion of swc data as in the synthetic scenarios matric potential proved to be the more informative variable than soil water content in addition to the reasons discussed in section 3 6 under real world conditions this might also be due to the fact that matric potential in the profile can reach equilibrium more or less immediately while soil water content does not diamantopoulos et al 2015 schultze et al 1997 in our real world application the unaccounted presence of model structural errors heterogeneity in the profile and inaccuracies forcing data might have led to an underestimation of parameter and model predictive uncertainty renard et al 2010 schoups and vrugt 2010 and the absolute data worth might have been diluted to some degree in terms of relative data worth and optimal design however the results were similar to the outcome of the synthetic scenarios for the corresponding coarse soil types this increases our confidence that despite the simplifying modeling assumptions the conclusions from the synthetic scenarios of this study are useful for real world applications a further assessment including real data from various soils and climates and an assessment of the effects of heterogeneity in the soil profile however is recommended 5 summary and conclusions the aim of the study was to evaluate the optimal exploitation of soil water monitoring data from simple monitoring setups for the estimation of shps and for the reduction of uncertainty in groundwater recharge prediction considering a range of soil textures and the influence of changing climatic conditions we demonstrated that knowledge on the soil water retention function in terms of the vgm shape parameters α and n is essential for determining the cumulative seepage in both the humid and dry climate scenario the greatest reduction of uncertainty in n mostly led to the lowest uncertainty in cumulative seepage prediction depending on the soil type this was achieved by the simultaneous assimilation of either seepage plus matric potential data soil water content plus matric potential data or all three data types together for predicting the magnitude of the peak in the seepage flow under humid conditions the saturated hydraulic conductivity parameter ks was most influential this was relevant for the silt soil where the assimilation of all three data types led to a better estimation and lower uncertainty in ks and consequently less uncertainty and a better fit in the validation of the seepage peak the gain in information from the same extent and quality of calibration data i e obtained with the same devices and temporal and spatial resolution generally led to a higher information gain and lower parameter uncertainties in fine as compared to coarse soil textures the only exception to this was when only seepage data was assimilated in the dry climate scenario in this case the information gain decreased from coarse to fine soil textures where less seepage events occurred throughout the calibration period leading to higher parameter and predictive uncertainties than in coarse soil types when the atmospheric boundary conditions changed from humid calibration to a dry validation period biased parameter estimation for sandy soil introduced additional uncertainty about the temporal variability in the seepage flow the results here suggest to rather increase the temporal resolution of the calibration data in a coarse soil in order to better capture the soil hydraulic processes and to further reduce predictive uncertainties the effect of different temporal resolutions of the calibration data on model uncertainties however needs to be further investigated in the real world application with a sandy soil lysimeter we identified a combination of matric potential and seepage measurements to be most informative and to produce the smallest parameter and predictive uncertainties for the seepage flow simulation in the real data case despite apparent systematic errors we obtained similar outcomes on the data worth of measurements as in the synthetic scenarios this supports that conclusions from the synthetic scenarios are useful for application under real field conditions based on our results we particularly recommend to measure matric potential in addition to lysmeter outflow in order to adequately estimate shps for groundwater recharge prediction in a moderate to humid climate for fine soil textures in dry climates measurements of matric potential and or soil water content are especially required for these cases a combination of matric potential and soil water content measurements in an otherwise undisrupted soil profile seems advantageous over a seepage face lysimeter setup for sandy soil in a dry climate on the other hand additional data to lysimeter outflow appeared to be inefficient in very coarse soil types we suggest to increase the temporal resolution of measurements to more than daily in order to avoid biases and unreliable predictions in conclusion the results of this study can help to prioritize measurement types for soil water monitoring installments for the estimation of shps and groundwater recharge and to better assess the reliability of estimations from real experiments for assessing the effect of conceptual model uncertainty and heterogeneity in soil profiles further testing with real world applications is recommended credit authorship contribution statement marleen schübl conceptualization methodology software formal analysis visualization writing original draft christine stumpp conceptualization methodology writing review editing supervision project administration funding acquisition giuseppe brunetti conceptualization methodology writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the austrian academy of sciences öaw vienna austria meteorological data was provided by the central institution for meteorology and geodynamics zamg vienna austria and the german weather service dwd offenbach germany we would like to thank the reviewers for their valuable input which improved this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128429 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
2968,statistical calibration of precipitation forecasts from numerical weather prediction nwp models is routinely performed grid cell by grid cell aiming to produce accurate and reliable ensemble forecasts for precipitation fields calibrated ensemble members from different grid cells are then connected using ensemble reordering to form spatially structured ensemble forecasts however ensemble reordering approaches such as the well known schaake shuffle method are often criticized for not considering real physical atmospheric states of precipitation events in this paper we propose a spatial mode based calibration smoc model for post processing forecast precipitation fields and producing ensemble forecasts with an inbuilt spatial structure so that ensemble reordering is not required the smoc model is developed based on spatial modes derived from empirical orthogonal function eof analyses of precipitation fields and linear regressions of derived eof expansion coefficients of the first few dominant modes unlike conventional calibration models that are applied to forecast grid cells individually smoc is applied to the whole forecast fields and the spatial structure is inherently present in calibrated ensemble forecasts there is therefore no need to rely on ensemble reordering for spatial reconstruction the performance of smoc is evaluated by applying it to nwp forecasts of substantive precipitation events over the brisbane drainage basin in eastern australia cross validated results show that smoc calibrated forecasts are of high quality at both grid cell and basin scales the spatial structure of precipitation is found to be well embedded in the ensemble members of the calibrated forecasts for the basin keywords forecast precipitation fields numerical weather prediction statistical calibration spatial structure empirical orthogonal function spatial modes data availability the authors do not have permission to share data 1 introduction short term precipitation forecasts are commonly produced using numerical weather prediction nwp models in major meteorological centers worldwide however current nwp models cannot fully simulate dynamic physics of the atmosphere due to various sources of uncertainty including model structures model initial and boundary conditions and model parameters palmer et al 2007 consequently raw forecasts from nwp models are often subject to systematic bias gneiting et al 2007 li et al 2017 and can be even less skillful than naïve climatology forecasts zhao et al 2020 additionally raw forecasts from ensemble nwp models are often subject to dispersion errors buizza 2018 these deficiencies need to be addressed to improve the usefulness of raw precipitation forecasts a number of statistical calibration models have been developed in the past few decades to improve raw precipitation forecasts notable models include but are not limited to ensemble model output statistics emos gneiting et al 2005 scheuerer 2014 baran and lerch 2015 taillardat et al 2016 bayesian model averaging bma raftery et al 2005 sloughter et al 2007 schmeits and kok 2010 wang et al 2012a möller et al 2013 baran and möller 2015 the bayesian joint probability bjp model robertson et al 2013 shrestha et al 2015 zhao et al 2015 wang et al 2019a cattoën et al 2020 w li et al 2020 y li et al 2020 li et al 2022 the seasonally coherent calibration scc model wang et al 2019b zhao et al 2020 yang et al 2021 zhao et al 2022 and machine learning based regression models dogulu et al 2015 these calibration models are typically aimed at producing ensemble forecasts that are free from bias reliable in ensemble spread and as skillful as possible current forecast calibration is mostly performed separately at individual grid cells for forecast precipitation fields however the resulting calibrated ensemble members from different grid cells are not spatially connected and thus cannot reproduce the spatial structure of corresponding observed precipitation events shrestha et al 2015 consequently several ensemble reordering approaches have been proposed to connect calibrated ensemble members from different grid cells so that the spatial structure can be reconstructed in calibrated forecasts schefzik and möller 2018 van straaten et al 2018 the two most popular ensemble reordering approaches are the schaake shuffle clark et al 2004 scheuerer et al 2017 and the ensemble copula coupling ecc schefzik et al 2013 schefzik 2017 however both have drawbacks the schaake shuffle which reorders calibrated ensemble members based on ranks of selected historical observations is often criticized for not considering real physical atmospheric states of the forecasted precipitation events bellier et al 2017 scheuerer et al 2017 besides schaake shuffle becomes problematic when applied to precipitation forecasts as there are often many zero values in observed precipitation that will result in tied ranks in constructing spatial dependence templates clark et al 2004 bellier et al 2017 wu et al 2018 ecc takes raw ensembles as templates of spatial dependence so it is only applicable to raw ensemble forecasts as there is no available template for raw deterministic forecasts its usefulness is therefore largely limited by the size of raw ensembles and the quality of raw ensemble structures in view of the above mentioned limitations of existing methods of calibration of forecast precipitation fields it would be highly valuable if the spatial structure can be inherently embedded in the calibration process thereby eliminating the need for further spatial reconstruction using ensemble reordering approaches however precipitation fields are often high dimensional in space and therefore it is difficult to achieve the synchronous calibration for all of the grid cells in the fields one possible way is to first reduce the precipitation fields to only a few representative variables and then calibrate these dimensionally reduced variables the empirical orthogonal function eof analysis is the most widely used technique for dimensionality reduction and pattern extraction of spatial temporal fields lorenz 1956 hannachi et al 2007 monahan et al 2009 schmidt et al 2019 eof can decompose high dimensional data into a set of orthogonal spatial modes along with a set of associated uncorrelated expansion coefficients these two features can give a spatial display and a temporal display of the large high dimensional meteorological data and provide valuable insights into the main physical characteristics by focusing on a few dominant eof modes the eof technique and its variants have been widely applied in a variety of studies including meteorology oceanography and remote sensing for example barnett 1978 used eof to examine space time variations of surface air temperature over the northern hemisphere servain and legler 1986 applied eof to analyze the seasonal variability of monthly sea surface temperature and wind stress within the tropical atlantic region lintner 2002 identified the interannual variability of global carbon dioxide using the first few eof modes wang et al 2015 studied the asian summer monsoon precipitation by employing an eof variant with emphasis on seasonal predictability and feng et al 2016 proposed an eof based data integration algorithm to improve the estimation of terrestrial latent heat flux from multiple remote sensing data sources in this study we set out to develop a new approach based on the eof analysis for post processing forecast precipitation fields from nwp models and producing ensemble forecasts with an inbuilt spatial structure for this purpose we extract representative variables from forecasts and corresponding observations of precipitation fields based on spatial modes derived from the eof analysis of long term climatology of observations and establish calibration models for these extracted variables we call this approach a spatial mode based calibration smoc in this paper we introduce the rationale and mathematical formulations of the smoc model in detail and evaluate its performance through a case study 2 model formulation here we consider daily deterministic nwp forecast precipitation fields at a single lead time we aim to calibrate raw forecast fields and produce spatially structured ensemble forecasts that are of high quality at both grid cell and field scales the developed spatial mode based calibration smoc model in this paper involves data normalizations of precipitation data empirical orthogonal function eof analysis and calibration of eof variables the framework of the smoc formulation is illustrated in fig 1 and detailed in sections 2 1 and 2 2 in this section we first introduce the eof analysis by demonstrating its application to long term observations of precipitation fields thereafter we explain how eof is used to establish the smoc model for raw precipitation forecasts and corresponding observations finally we present how we apply smoc to calibrate new forecast fields for clear notation we set up three time variables t t and t to distinguish three different sets of precipitation data as shown in table 1 the long term observation period t 1 2 t may or may not overlap with the period of forecast data used for model training t 1 2 t where t and t denote the number of days in the long term observation period and the period of forecast data respectively t represents the time of a new forecast event that will be calibrated using the smoc model in section 2 3 and t does not overlap with the long term observation period or the forecast period 2 1 eof analysis of long term observation fields we apply the eof analysis to long term observation fields to derive representative patterns with long term statistical characteristics of climatology given a gridded precipitation field long term observations can be represented as 1 y y 1 1 y 1 2 y 1 s y 2 1 y 2 2 y 2 s y t 1 y t 2 y t s where t and s denote the number of days in the long term observation period and the number of grid cells in the gridded field respectively y t s in the data matrix y represents the observed precipitation at day t in grid cell s t 1 2 t and s 1 2 s 2 1 1 data normalization statistical treatment on precipitation values is always challenging due to highly skewed distribution of precipitation data it has therefore been a common practice to apply data transformation for normalizing precipitation data before formal analysis wang et al 2012b wang et al 2019b zhao et al 2022 to ensure the spatial consistency of data normalizations among different grid cells we apply an approach of regionally optimized power transformation as recommended by du et al 2022 to transform the long term precipitation observation fields from y to y p details of the power transformation can be found in text s1 and fig s1 of supplementary material s1 2 1 2 eof decomposition as an integral part of the eof analysis we center precipitation values i e subtracting the temporal average from the values for each grid cell the centering process assures that the eof technique only focuses on the variance within the precipitation data rather than taking the overall average of the data as an important piece of extracted information for y p temporal averages of precipitation values can be calculated as 2 y p y p 1 y p 2 y p s where for each grid cell s the precipitation average is calculated as 3 y p s 1 t t 1 t y p t s where y p t s is the power transformed observed precipitation at day t in grid cell s t 1 2 t and s 1 2 s the centered precipitation field y p can be produced by subtracting y p from each row of y p and then decomposed using eof as 4 y p c y u y 5 c y c y 1 1 c y 1 2 c y 1 k c y 2 1 c y 2 2 c y 2 k c y t 1 c y t 2 c y t k 6 u y u y 1 1 u y 1 2 u y 1 s u y 2 1 u y 2 2 u y 2 s u y k 1 u y k 2 u y k s where k is the number of derived eof modes after the decomposition and generally equals to the smaller dimension of the original spatial temporal patterns i e the smaller of t and s equation 4 can also be written as 7 y p k 1 k c y t k u y k s where c y t k t 1 2 t is a column vector and varies with day t representing expansion coefficients of the k th eof mode u y k s s 1 2 s is a row vector and varies with grid cell s representing spatial modes of the k th eof mode in this way the original gridded long term observation fields i e y can be represented using a set of temporal variables expansion coefficients c y t k t 1 2 t and a set of spatial variables spatial modes u y k s s 1 2 s 2 2 establishing relationships between raw forecasts and observations for a given k th eof mode c y t k t 1 2 t is a function of day t which is analogical to the fact that the occurrence of natural precipitation events varies with time in the field we therefore choose to relate raw precipitation forecasts to corresponding observations by matching their respectively derived expansion coefficients 2 2 1 expansion coefficients of raw forecast fields and corresponding observation fields raw forecast fields in the period of training forecast data a k a forecast period from hereon can be represented as 8 x x 1 1 x 1 2 x 1 s x 2 1 x 2 2 x 2 s x t 1 x t 2 x t s where t and s denote the number of days in the forecast period and the number of grid cells in the gridded field respectively x t s in the data matrix x represents the precipitation forecast at day t in grid cell s t 1 2 t and s 1 2 s similar to the processing of long term observation fields we apply the data normalization and the centering process to raw forecast fields and obtain x p to derive expansion coefficients of raw forecasts one way is to simply apply the eof decomposition to x p however two independent eof analyses performed separately on raw forecasts and corresponding observations will produce different spatial modes this makes it hard to match the two sets of derived expansion coefficients in this study instead of repeating the eof decomposition we employ the spatial modes of the long term observation fields i e u y and a variant of equation 4 to derive expansion coefficients from x p 9 c x x p u y 1 where u y 1 is the inverse of u y c x represents the derived expansion coefficients of raw forecasts likewise for corresponding observation fields in the forecast period 10 y y 1 1 y 1 2 y 1 s y 2 1 y 2 2 y 2 s y t 1 y t 2 y t s where t and s denote the number of days in the forecast period and the number of grid cells in the gridded field respectively y t s in the data matrix y represents the observed precipitation at day t in grid cell s t 1 2 t and s 1 2 s we apply the same data normalization and centering process to obtain y p it should be noted that we use the parameters of the data normalization and the centering process from long term observation fields to normalize and center corresponding observation fields as these parameters are derived from long term statistical characteristics of climatology and are more sensible for use we then derive expansion coefficients from y p using the spatial modes of the long term observations 11 c y y p u y 1 where u y 1 is the inverse of u y c y represents the derived expansion coefficients of corresponding observations in this way c x and c y are both derived from the same spatial modes that represent long term climatology statistics this assures that these two expansion coefficients are comparable in a reasonable manner similarly this use of the eof analysis has been performed for hydrodynamic model inundation simulations in fraehr et al 2022 which derives expansion coefficients of low resolution models using the spatial modes of high resolution models in the eof analysis the first few modes are often selected to represent the whole set of original data without compromising much of the explained data variance the high dimensional datasets can therefore be reduced to only a few representative variables in practice the number of the selected modes is often determined by specifying a certain amount of the total variance e g 90 and then finding the minimum number of modes needed to explain this amount of variance in this study we select expansion coefficients from the first m eof modes i e c x t k and c y t k t 1 2 t and k 1 2 m to represent the whole sets of expansion coefficients where m is the number of the selected eof modes the actual value of m will vary with application for example in the case study later shown in section 3 2 the first 10 modes are chosen which account for 95 of the long term observation data variance in addition detailed illustrations of the spatial modes and expansion coefficients from the first 10 eof modes are also provided in section 3 2 to further demonstrate the eof analysis of the precipitation field data 2 2 2 seasonality removal in expansion coefficients in establishing calibration models based on the two selected sets of expansion coefficients we aim to produce ensembles that are not only free from bias reliable in ensemble spread and as skillful as possible but also coherent with a seasonally varying climatology that exists in both forecasts and observations as well as in their respective expansion coefficients this is especially important for forecasts at long lead times when forecast skill becomes low and forecasts approach climatology wang et al 2019b however it is challenging to produce coherent calibrated ensembles as nwp models tend to be updated regularly and available nwp forecasts to establish coherent calibration models are often limited to resolve this problem we choose to remove the seasonality in expansion coefficients and pool the data from all year round together to establish calibration models when applying the established smoc model for forecast calibration we add the removed seasonality back to calibrated expansion coefficients and finally produce coherent calibrated forecasts see section 2 3 later in this study we remove the seasonality by using daily climatological mean and daily climatological standard deviation to standardize expansion coefficients of forecasts and corresponding observations for the k th eof mode k 1 2 3 m we first employ the spectral method in narapusetty et al 2009 to estimate the daily climatological mean μ c y t k t 1 2 3 t for expansion coefficients of observations from the long term period we then use the daily climatological mean to calculate the squared error of expansion coefficients and employ the spectral method again to estimate the daily climatological standard deviation σ c y t k t 1 2 3 t for expansion coefficients of observations from the long term period we apply these two estimated variables to produce daily climatological mean and daily climatological standard deviation for expansion coefficients of observations at day t t 1 2 t during the forecast period i e μ c y t k and σ c y t k the standardization goes as 12 c x t k c x t k μ c y t k σ c y t k 13 c y t k c y t k μ c y t k σ c y t k where c x t k and c y t k are expansion coefficients of forecasts and corresponding observations for the k th mode at day t respectively c x t k and c y t k are standardized c x t k and c y t k respectively 2 2 3 linear regressions of expansion coefficients after the standardization we establish calibration models based on these two sets of expansion coefficients as expansion coefficients from different eof modes are independent from each other we establish calibration models separately for the m modes specifically we fit an ordinary least square linear regression for each mode for the k th mode k 1 2 3 m at day t t 1 2 t the regression can be formulated as 14 c y t k a k c x t k b k ε t k where a k and b k denote linear regression coefficients and the residual term ε t k follows a normal distribution 15 ε t k n 0 σ ε 2 k estimates of a k b k and σ ε k can be found by using the method of maximum likelihood estimation 2 3 model use for calibrating new forecasts once parameters of the data normalization data centering spatial modes u y standardization of expansion coefficients and linear regressions in sections 2 1 2 2 are derived from training datasets we can apply the established smoc model to calibrate new forecasts given a new forecast field x t s s 1 2 s at day t a calibrated ensemble forecast can be produced following the steps shown in fig 2 and detailed as below a apply the data normalization and the centering process to produce x p t s s 1 2 s b derive expansion coefficients c x t k k 1 2 k using equation 9 c select the first m eof modes of c x t k k 1 2 k and remove the seasonality of expansion coefficients to give c x t k k 1 2 m using equations 12 and 13 d for the k th mode draw a random ε t k from equation 15 then a predicted c y t k can be obtained using c x t k and equation 14 results for the m eof modes are pooled together to produce c y t k k 1 2 m e add the removed seasonality back to c y t k k 1 2 m to give c y t k k 1 2 m using variants of equations 12 and 13 f derive y p t s s 1 2 s using equation 4 16 y p t s c y t k u y g inverse the centering process and the data normalization to y p t s s 1 2 s and obtain a calibrated forecast field y t s s 1 2 s in the original spatial dimension for day t negative values in the inverse of data normalization are set to zero to give zero precipitation forecasts h repeat steps d g n times to produce a calibrated ensemble forecast field y t s n s 1 2 s and n 1 2 n for day t n being the size of the ensemble following above steps raw forecast precipitation fields are calibrated as a whole not grid cell by grid cell the calibrated ensemble forecast field for one precipitation event contains n ensemble members each being a forecast ensemble member for the whole precipitation field the spatial structure is inherently embedded in calibrated ensemble members and therefore there is no need to further apply conventional ensemble reordering approaches for spatial reconstruction 3 case study 3 1 research basin and data we apply the smoc model to calibrate nwp forecasts from a case study to demonstrate the model performance the brisbane drainage basin located in eastern australia is selected as the research basin shown in fig 3 a the basin area is 13 549 2 km2 and the average annual precipitation in the basin is 866 mm per year observed precipitation data are obtained from the australian water availability project s awap jones et al 2009 climate datasets which are commonly considered the best available reference climate data for australia awap datasets have a horizontal grid spacing of 0 05 x 0 05 and are produced by interpolating rain gauge observations across australia daily observations for a period of 30 years from 3 november 1988 to 2 november 2018 are used as long term observations for eof analysis and estimation of long term statistics of seasonality daily observations for a period of 3 years from 3 november 2018 to 2 november 2021 are used as reference data for forecast calibration and forecast evaluation raw precipitation forecasts are generated from the australian community climate and earth system simulator global 3 access g3 model developed by the australian bureau of meteorology access g3 model produces deterministic nwp forecasts with a horizontal grid spacing of 0 18 longitude by 0 12 latitude with a forecasting horizon of 10 days access g3 forecasts are issued at 0000 utc 0600 utc 1200 utc and 1800 utc every day and are available at an hourly temporal resolution access g3 forecasts have been operational since 25 july 2019 to minimize possible impacts of sample size on calibration performance we integrate experimental forecasts from 3 november 2018 to 24 july 2019 and operational forecasts from 25 july 2019 to 2 november 2021 to obtain 3 years of forecasts to match the daily awap data we adjust the spatial and temporal resolutions of access g3 forecasts we apply bilinear interpolation to re grid the forecasts to the horizontal grid spacing of observations and we aggregate the hourly forecasts to daily values by accumulating forecast values according to the daily period on which the awap data are produced consequently precipitation forecasts and observations are both provided at a grid spacing of 0 05 x 0 05 and on a daily basis for this study brisbane drainage basin covers 493 grid cells at the 0 05 x 0 05 scale and average annual precipitation values of the 33 years of awap data at these grid cells are shown in fig 3 b 3 2 smoc model setup the smoc model is set up for application to 30 years of long term observations and 3 years of forecasts and corresponding observations for the case study the total number of days in the long term period and the forecast period i e t and t are therefore 10 957 and 1096 respectively the total number of grid cells in the research basin i e s is 493 the size of the generated ensemble of calibrated forecasts i e n is set as 1 000 members the model is applied to forecasts of day 1 ahead which represent the best performing forecasts among different lead times in the smoc model establishment the number of the first few eof modes i e m is set as 10 from our case study the first 10 modes are found to account for 96 of the long term data variance shown in fig s7 from supplementary material s1 the large number of no and little precipitation days in the research basin as typically in most regions means that there are numerous very small values of expansion coefficients shown in fig s6 from supplementary material s1 when all these values are used to derive the linear relationships between forecasts and observations the model fit will be heavily geared towards the no and little precipitation events neglecting the model fit to the substantive precipitation events which the public cares about the most lerch et al 2017 therefore we choose only to fit linear regressions to expansion coefficients of substantive precipitation events whose corresponding basin average of raw forecasts is beyond a pre defined threshold in the 3 year forecast period the threshold is set as 90 quantile of raw forecast basin averages and equals to 5 47 mm per day and the resulting number of chosen substantive precipitation events is 110 to help readers understand the eof analysis and the smoc model more intuitively we produce a number of figures figs s2 s5 in supplementary material s1 to illustrate the spatial modes and expansion coefficients of the precipitation data used in our case study specifically we apply the eof analysis to decompose 30 years of normalized and centered observations to obtain a set of spatial modes u y along with a set of expansion coefficients c y the first 10 spatial modes i e the first 10 rows of u y are shown in fig s2 each representing one spatial pattern across the brisbane drainage basin over the 30 year period the first 10 expansion coefficients i e the first 10 columns of c y are shown in fig s3 each representing one temporal pattern in the 30 year period for its corresponding spatial mode the first 10 expansion coefficients of 3 years of normalized and centered forecasts as well as corresponding observations i e the first 10 columns of c x and c y that are derived using u y are shown in figs s3 s4 we also select five precipitation events of different magnitudes in the 3 year period shown in figs s4 s5 and investigate if original forecasts and observations can be reconstructed using the first 10 eof modes of the spatial modes u y and expansion coefficients c x and c y results in fig s5 show that the eof analysis can reconstruct the precipitation fields reasonably well even with only the first 10 eof modes both for light and heavy precipitation events therefore it is suggested that the calibration of raw forecast precipitation fields can be represented by the calibration of raw forecast expansion coefficients using linear regressions in section 2 2 3 3 forecast evaluation in this study the performance of smoc calibrated forecasts is evaluated using a leave one event out cross validation to assess different aspects of forecast quality over the precipitation field we use continuous ranked probability score crps hersbach 2000 probability integral transform pit renard et al 2010 and structure amplitude location sal spatial verification wernli et al 2008 radanovics et al 2018 to perform a comprehensive evaluation furthermore we implement the forecast evaluation at both grid cell and basin scales with the evaluation at grid cell scale assessing model calibration performance for individual grid cells and the evaluation at basin scale for the whole basin forecasts and corresponding evaluation metrics are presented in table 2 and detailed in sections 3 3 1 and 3 3 2 3 3 1 forecast evaluation at grid cell scale we apply crps and pit to evaluate forecast skill and forecast reliability of forecasts at each of the 493 grid cells crps measures the difference between ensemble forecast cumulative distributions and corresponding observations the average crps for calibrated ensemble forecasts at day i 1 2 i is evaluated as 17 crps 1 i i 1 i f i x h x y i 2 d x where f i x is the forecast cumulative density function and y i is the observation at day i h is the heaviside step function that equals 1 if x y i 0 and equals 0 otherwise and i is the number of the evaluated precipitation events in practice we often use crps skill score to evaluate the relative forecast skill improvement of forecasts compared to reference forecasts in this study we produce a reference ensemble climatology forecast for each substantive precipitation event for this purpose we first fit a normal distribution in power transformed space for 30 years of awap observations of the month in which the event occurred we then draw a random sample from the distribution and inverse the power transformation to generate an ensemble climatology forecast for the event the sample size is also set as 1 000 then we calculate the average crps of reference climatology ensemble forecasts crps ref for the evaluated precipitation events and give a crps skill score 18 crps skill score crps ref crps crps ref 100 the crps skill score is positively oriented with a maximum skill score of 100 indicating perfect forecasts and a skill score of 0 indicating that forecasts have comparable errors to the reference forecasts a negative skill score indicates that forecasts are less skillful than reference forecasts for deterministic precipitation forecasts crps is equivalent to the mean absolute error mae 19 mae 1 i i 1 i x i y i where x i and y i are the forecast and corresponding observation at day i respectively and i is the number of the evaluated precipitation events similarly we use crps skill score to demonstrate the performance of raw forecasts relative to reference climatology forecasts to have a fair evaluation we use the same reference crps for raw deterministic forecasts and calibrated ensemble forecasts we use pit to evaluate the reliability of ensemble forecasts ensemble spread not too narrow or too wide statistically forecast reliability represents the consistency between ensemble forecast probability distributions and the observed frequency of corresponding observations the pit of an ensemble forecast at day i is calculated as 20 π i f i x y i where f i x is the forecast cumulative density function and y i is the corresponding observation for a set of reliable forecasts π i follows a uniform distribution and the uniformity can be examined by the well known pit alpha index 21 pit alpha index 1 2 i i 1 i π i i i 1 where π i is the sorted π i in an increasing order and i is the number of the evaluated precipitation events pit alpha index is also positively oriented and ranges from 0 poorest reliability to 1 perfect reliability 3 3 2 forecast evaluation at basin scale we evaluate basin average forecasts to give an overall assessment of forecast precipitation fields for raw forecasts we calculate the basin average of forecasts and corresponding observations then we calculate crps skill score of raw basin average forecasts for calibrated ensemble forecasts we calculate the basin average of each ensemble member to produce a basin average ensemble forecast for each evaluated precipitation event then we calculate crps skill score of calibrated basin average ensemble forecasts likewise the reference ensemble climatology forecast used for calculating crps skill score of each event is sampled from the distribution fitted for 30 year basin average observations of the month in which the event occurred besides calculating the pit alpha index of calibrated basin average ensemble forecasts we also apply the pit uniform probability plot to visualize the forecast reliability where sorted pit values π i of all evaluated precipitation events are plotted against corresponding theoretical quantiles of the uniform distribution reliable forecasts will display a scatter plot close to the 1 1 line to indicate whether smoc calibrated ensemble forecasts are spatially correlated in an appropriate way across the grid cells we evaluate reliability of ensemble spreads of basin average precipitation forecasts the rationale is as follows when forecast spatial correlation is low the ensemble spreads of basin average forecasts will be narrow because much of the randomness across the grid cells will be averaged out on the contrary when forecast spatial correlation is high the ensemble spreads of basin average precipitation forecasts will be wide because there is less randomness across the grid cells in individual ensemble members therefore when ensemble spreads of forecasts of individual grid cells and basin average are both reliable appropriate spatial correlation is strongly indicated we also apply sal spatial verification to evaluate the structure s amplitude a and location l of precipitation forecasts for the research basin sal is an object based and dimensionless quality measure formulas for calculating these three sal components are presented in appendix a s measures the size and shape of precipitation objects assessing whether the predicted precipitation objects are too large positive s or too small negative s s ranges from 2 to 2 and a s value of 0 indicates perfect forecasts a measures the relative deviation of the basin average forecasts from corresponding observations positive negative a values indicate that forecasts overestimate underestimate the basin average precipitation similarly a ranges from 2 to 2 and an a value of 0 indicates perfect forecasts l measures the displacement of the center of mass of predicted precipitation field and the error in the weighted average distance of the individual precipitation objects from the total precipitation field s center of mass l ranges from 0 to 2 with 0 indicating perfect forecasts and positive values indicating spatial forecasts that have location errors in addition we plot spatial precipitation maps for several selected ensemble members of calibrated ensemble forecasts to check whether calibrated ensemble members are capable of capturing the intensity and spatial features of observed precipitation in the research basin specifically we select three extreme precipitation events in terms of either raw forecasts or observations or both to investigate the smoc model performance in different forecasting situations to facilitate visualization we choose to plot 10 ensemble members for each calibrated ensemble forecast corresponding to 10 equally divided quantiles from 5 to 95 based on basin averages of the 1 000 calibrated ensemble members for the whole research basin 4 results 4 1 forecast evaluation at grid cell scale 4 1 1 forecast skill results of crps skill score for raw forecasts and calibrated ensemble forecasts at individual grid cells of the research basin are shown in fig 4 to have a fair comparison we also provide calibrated ensemble median forecasts as deterministic style forecasts for comparing with raw deterministic forecasts as mae is found to work better for ensemble median than for ensemble mean gneiting 2011 it can be seen from the figure that raw forecasts overall perform the worst among these three forecasts in terms of forecast skill there are negative crps skill score values of raw forecasts across most grid cells especially for grid cells in the middle and southeast areas of the basin by contrast the smoc model markedly improves the forecast skill of raw forecasts with the average of crps skill scores across all of the grid cells increasing from 7 21 to 19 25 calibrated ensemble median forecasts and 40 29 calibrated ensemble forecasts the calibrated forecasts have positive crps skill score values at all of the grid cells suggesting that they are more skillful than reference climatology forecasts in addition calibrated ensemble forecasts have clearly greater crps skill scores than calibrated ensemble median forecasts this is due to the benefits of the ensemble spread information included in calibrated ensemble forecasts and this highlights the advantages of forecast calibration models that can produce ensembles even when taking raw deterministic forecasts as model inputs schaake et al 2007 shrestha et al 2015 4 1 2 forecast reliability results of pit alpha index for calibrated ensemble forecasts at individual grid cells of the research basin are shown in fig 5 it is obvious that pit alpha index values at almost all of the grid cells are close to 1 with the average across all of the grid cells being 0 9491 therefore the ensemble spread of calibrated ensemble forecasts at grid cell scale is overall reliable in the research basin this indicates that the assumed normal distributions of residuals in the linear regressions can reliably quantify the uncertainty of predicted expansion coefficients as well as the uncertainty of calibrated ensemble forecasts in addition we calculate the root mean square errors of smoc ensemble mean forecasts and plot them against the square root values of average smoc ensemble variance over the 110 substantive precipitation events both for grid cell and basin scales as shown in fig s11 from supplementary material s1 it is found that smoc calibrated ensemble forecasts in grid cell scale perform well in terms of the well known spread error correlation whitaker and loughe 1998 fortin et al 2014 van schaeybroeck and vannitsem 2016 as well as the ensemble forecast reliability however it should be noted that the ensemble forecasts tend to be over dispersed especially for grid cells with large ensemble forecast variance 4 2 forecast evaluation at basin scale for forecasts at basin scale we first evaluate the performance of basin average forecasts fig 6 shows 90 and 50 ensemble intervals and ensemble medians of calibrated basin average ensemble forecasts against raw basin average forecasts for substantive precipitation events in the research basin corresponding observations are also provided for visual forecast verification the width of calibrated basin average ensemble intervals generally increases with raw basin average forecasts this is in line with the well known consensus that forecast uncertainty on precipitation events increases with precipitation amounts calibrated ensemble medians are shown to be overall closer to corresponding observations than raw forecasts especially for the several extremely substantive precipitation events on the far right of fig 6 statistically the distribution of observations is visually consistent with the shown 90 and 50 ensemble forecast intervals to further assess the quality of basin average forecasts we provide evaluation results on forecast skill and forecast reliability in section 4 2 1 4 2 1 forecast skill and forecast reliability of basin average forecasts results of crps skill score for basin average forecasts are summarized in table 3 similar to the evaluation at grid cell scale in the order of raw forecasts calibrated ensemble median forecasts and calibrated ensemble forecasts crps skill scores are found to increase successively indicating gradual forecast skill improvements for reliability of calibrated basin average ensemble forecasts pit alpha index is calculated as 0 9692 and pit uniform probability plot is close to the uniform distribution fig 7 showing that these ensemble forecasts have good performance in forecast reliability the spread error correlation results in fig s11 from supplementary material s1 also show that smoc calibrated basin average ensemble forecasts in basin scale perform well in forecast reliability although there is a potential over dispersion issue of ensemble forecasts together with the forecast reliability results presented in section 4 1 2 it can be concluded that calibrated ensemble forecasts are reliable at both grid cell and basin scales this indicates that calibrated ensemble members from different grid cells are connected in an appropriate way so that basin average forecasts are reliable in ensemble spread spatial correlation is well embedded in smoc calibrated forecasts of the whole research basin 4 2 2 sal verification of forecast precipitation fields results of sal verification for substantive precipitation forecasts of the whole research basin are shown in fig 8 in addition to raw forecasts and calibrated ensemble forecasts we also evaluate the sal of climatology forecasts as a reference forecasts of high quality are illustrated as small dots in the center of the sal diagram most climatology forecasts are located in the third quadrant of the diagram where both structure and amplitude are underestimated this is because climatology forecasts are produced based on historical precipitation events with all magnitudes of precipitation amounts when such climatology forecasts are used to predict substantive precipitation events they tend to provide light forecasts and therefore underestimate the size of precipitation objects and the capacity of precipitation amounts most of raw forecasts and calibrated ensemble forecasts however are found in the first quadrant of the diagram where both structure and amplitude are overestimated raw forecasts tend to overestimate the precipitation amounts by producing too large precipitation objects while calibrated ensemble forecasts though with a similar tendency have weaker overestimation issues especially for structure for dots in top right corner of the diagram substantive precipitation is predicted in terms of structure and amplitude but little precipitation is observed these cases are generally considered as false alarms by contrast there are few blue and green dots in the bottom left corner of the diagram indicating that the raw and calibrated forecasts rarely miss the prediction of substantive precipitation events furthermore calibrated ensemble forecasts also have smaller location errors than raw forecasts and climatology forecasts dots with the largest sizes are mainly found at the top right corner of the diagram green dots have overall smaller sizes than blue dots indicating that calibrated ensemble forecasts perform better than raw forecasts in terms of the largest location errors to sum up calibrated ensemble forecasts have the best forecast quality among these three forecasts in terms of the sal verification 4 2 3 spatial visualization plots of forecast examples figs 9 11 provide visualization of forecast examples from three selected extreme precipitation events corresponding to three different forecast performances of calibrated ensemble forecasts each example contains a raw forecast the corresponding observation and 10 selected calibrated ensemble members overall ensemble members from figs 9 11 have smooth precipitation surfaces across the research basin meaning that there are similar predicted precipitation amounts in adjacent grid cells this is an important feature in correctly structured precipitation forecasts for a spatial field in fig 9 extreme precipitation is forecasted by raw forecast but not observed in the basin although the raw forecast clearly overestimates precipitation amounts we still obtain several calibrated ensemble members e g quantiles of 25 and 35 that can predict a similar amount of precipitation to the observation for the whole basin however calibrated ensemble members with large precipitation i e high quantiles should not be considered useless as extreme precipitation events might occur with any magnitude of forecasted precipitation amounts especially with high magnitudes predicted in raw forecasts this will be further illustrated with the following two forecast examples in fig 10 extreme precipitation is not forecasted by raw forecast but observed in the research basin it can be seen that there is intense observed precipitation in the northeast of the research basin however raw forecast fails to capture the large amount of observed precipitation and its spatial distribution this is a typical case that raw forecasts cannot successfully predict extreme precipitation events which might lead to severe flooding events when people have no precautions fortunately smoc model can generate more forecast possibilities even when only relatively light precipitation is predicted in raw forecasts for example the two calibrated ensemble members of 85 and 95 quantiles are approximately able to predict the intensity of the observed precipitation event indeed it is crucial for forecast users to be aware of possible extreme precipitation events in flooding risk management wu et al 2020 in fig 11 extreme precipitation is forecasted by raw forecast and also observed in the research basin however there are differences between the raw forecast and the observation in terms of the intensity and spatial distribution of precipitation for example the raw forecast has intense precipitation amounts in the west where the intensity is much lower for the observed event by contrast many calibrated ensemble members e g quantiles of 35 45 and 55 are shown to be capable of predicting the intensity of the observed precipitation this is especially the case for the ensemble member of 35 quantile which has similar spatial patterns to the observed precipitation event in addition to the displayed quantiles from 5 to 95 of basin averages of smoc calibrated ensemble members we provide a few more calibrated ensemble members for forecast visualization by using animation as shown in animations s1 s3 from supplementary material s1 apart from the basin scale quantiles we also produce spatial precipitation plots based on the grid cell scale quantiles of calibrated ensemble members for the three selected forecast examples as shown in figs s8 s10 from supplementary material s1 the quantiles are also set to 10 equally divided values from 5 to 95 but applied to the 1 000 calibrated ensemble members from each grid cell different from figs 9 11 that display multiple quantiles of calibrated ensemble members for the whole research basin figs s8 s10 offer insight into the forecast uncertainty information present in individual grid cells smoc calibrated ensemble members are found to contain diverse forecast possibilities at both basin and grid cell scales 5 discussion in the case study we select the first 10 eof modes that account for over 95 of the data variance to represent all the 493 modes to investigate the influence of the number of selected eof modes on the smoc model performance we conduct further experiments using some other numbers of eof modes results of crps skill score and pit alpha index for grid cell scale calibrated forecasts and calibrated basin average forecasts are shown in fig s12 from supplementary material s1 it can be seen that crps skill scores do not change much with the number of eof modes used especially for numbers larger than 2 by contrast pit alpha index values increase dramatically with the increase in the number of eof modes used initially and then have only small fluctuations when the number of eof modes is larger than 9 these results indicate that we can achieve the highest possible forecast skill with only a few eof modes however a relatively large number of eof modes is required to reliably quantify the forecast uncertainty in our analysis we standardize the eof expansion coefficients prior to linear regressions by removing the embedded seasonality so that we can pool values from different months together to establish the smoc model and produce coherent calibrated forecasts as a comparison we also establish a calibration model without the standardization of expansion coefficients results of crps skill score and pit alpha index for grid cell scale calibrated forecasts and calibrated basin average forecasts are summarized in table s1 from supplementary material s1 it can be found that the standardization of expansion coefficients does not have a significant impact on forecast reliability but leads to higher forecast skill of calibrated ensemble forecasts at both grid cell and basin scales the removal of seasonality also helps demonstrate the true correspondence between expansion coefficients of forecasts and corresponding observations zhao et al 2020 this facilitates the establishment of a robust calibration model and improves the performance of calibrated forecasts the eof analysis is well known as an effective tool to perform dimension reduction for climate data typically for gaussian distributed data such as temperature variables barnett 1978 servain and legler 1986 however for climate data that are not gaussian distributed such as the daily precipitation investigated in this study the use of eof for dimension reduction may lead to loss of useful data information lim et al 2012 to alleviate this issue we apply power transformations to normalize precipitation data before the eof analysis and standardize eof expansion coefficients before the gaussian based linear regressions the eof analysis is found to perform well for this study according to the fairly good representation of precipitation field data shown in fig s5 and fig s7 from supplementary material s1 and the remarkable calibration results of the smoc model despite these performances it would be of interest to further investigate the possible effects of eof on the loss of precipitation data information it would also be worthwhile to try out other dimension reduction methods that are suitable for non gaussian distributed data such as the independent component analysis ica lim et al 2012 we acknowledge that the smoc model is only used to calibrate forecasts of substantive precipitation events in our case study theoretically if we have a long record of nwp forecasts it will be more sensible to establish multiple calibration models respectively for events with different magnitudes of precipitation li et al 2019 wang et al 2019b however the archived record of forecasts is commonly short as nwp models are frequently updated and there are only a limited number of nwp models producing hindcasts the developed smoc model might be further improved using longer archived nwp forecasts and could be extended to calibrate events with other magnitudes of precipitation indeed extending the smoc model for calibration of non substantive precipitation events in the research basin will be investigated in our future work smoc calibrated ensemble forecasts are found to be reliable in ensemble spread however it should be noted that the produced ensemble members tend to be over dispersed to some extent as shown in fig s11 from supplementary material s1 in other words these ensemble forecasts are not sharp in terms of ensemble spread according to the well known paradigm of forecast calibration in gneiting et al 2007 the sharpness of predictive ensembles should be maximized subject to forecast reliability indeed this issue could potentially be alleviated by using a longer record of archived nwp forecasts in which case we will be able to establish a calibration model specifically for those extremely substantive events in this way the residuals of linear regressions for expansion coefficients can exclusively apply to the fitted extreme precipitation events which helps to reduce the forecast uncertainty information and thus enlarges the sharpness of calibrated ensemble forecasts in this study the ordinary least square linear regression is employed to establish statistical calibration models for forecast expansion coefficients and is found to perform well in producing high quality calibrated ensemble forecasts indeed this classical linear regression also named model output statistics mos has been extended to incorporate many complexities for accommodating a variety of objectives of forecast calibration van schaeybroeck and vannitsem 2011 for example the error in variable mos evmos method vannitsem 2009 was developed to take into account the errors in both observations and forecasts unlike the original mos method that only considers the errors in observations consequently evmos was found to produce more appropriate variabilities for calibrated forecasts even at long lead times other extended linear regression methods include the time dependent tikhonov regularization tdtr golub and loan 1996 the total least square tls huffel and vandewalle 1991 golub and loan 1996 and the geometric mean gm teissier 1948 it would be valuable to further investigate if the uses of these extended linear regression methods and some other methods like machine learning dogulu et al 2015 can produce improved model performance compared to the ordinary least square linear regression used in the current smoc model the smoc model is innovatively developed to calibrate forecast precipitation fields as a whole rather than calibrating univariate forecasts separately for each grid cell as in conventional calibration models the main advantage is that calibrated ensemble forecasts are produced with an inbuilt spatial structure and there is no need to further employ ensemble reordering to connect calibrated ensemble members from different grid cells and forecast post processing no longer suffers from the aforementioned drawbacks of ensemble reordering approaches e g the schaake shuffle and ecc as smoc calibrated ensemble forecasts in our case study have shown good performance it would be highly valuable to compare the smoc model to conventional calibration models along with ensemble reordering approaches in future study in addition to the spatial structure across different grid cells calibrated ensemble forecasts should also have a correct temporal structure across different forecasting lead times clark et al 2004 especially for adjacent ones substantive precipitation events often occur at consecutive days and so does light precipitation events in practice meteorological centers often issue precipitation forecasts for several lead times raw forecasts are produced from different temporal phases of the evolution of simulated atmospheric states in nwp models and are therefore temporally correlated the smoc model is currently capable of calibrating raw forecasts of different lead times individually e g forecasts of day 1 ahead in our case study in our future work we will apply smoc to calibrate raw precipitation forecasts of other lead times especially long lead times and further investigate how to connect smoc calibrated ensemble members from different lead times in a sensible way 6 summary and conclusions in this paper a spatial mode based calibration smoc model for calibrating forecast precipitation fields from nwp models is presented we aim to produce calibrated ensemble forecasts that are of high quality at both grid cell and field scales and crucially with a correct spatial structure the smoc model is developed based on the eof analysis and linear regressions representative eof variables are derived from forecasts and corresponding observations using the same spatial modes that represent long term climatology statistics so that forecasts and observations are related in a sensible manner linear regression models are established for calibrating the extracted eof variables with distributions of regression residuals provided as uncertainty information to produce ensemble forecasts smoc is an innovative model developed to post process forecasts from multiple grid cells as a whole and produce calibrated ensemble forecasts with an inbuilt spatial structure by contrast conventional post processing of forecast fields typically requires two steps i e statistical calibration of raw forecasts separately for individual grid cells and ensemble reordering of calibrated ensemble members from different grid cells the smoc model turns the two step post processing to only one step and avoids a few well known drawbacks of ensemble reordering approaches the performance of smoc is evaluated by applying it to forecasts of substantive precipitation events over the brisbane drainage basin in eastern australia a number of evaluation measures are used for verification of calibrated ensemble forecasts including crps pit sal verification and also spatial visualization plots cross validated results show that calibrated forecasts are reliable in ensemble spread and have much improved forecast skill compared to raw forecasts at both grid cell and basin scales calibrated ensemble members from different grid cells are shown to be spatially correlated appropriately calibrated forecasts are also found to outperform both raw forecasts and climatology forecasts in terms of the structure amplitude and location of substantive precipitation forecasts for the whole research basin future work of the smoc model is being undertaken on the improvement of smoc using other dimension reduction and statistical regression methods the application of smoc for calibrating forecasts of non substantive precipitation events and forecasts of long lead times the maximization of the sharpness of calibrated ensemble forecasts the comparison between smoc and conventional calibration models along with ensemble reordering approaches the construction of the temporal structure among calibrated ensemble forecasts from different lead times and the extension of smoc to calibrate forecast fields of other weather variables credit authorship contribution statement pengcheng zhao methodology validation formal analysis writing original draft quan j wang conceptualization methodology supervision writing review editing wenyan wu resources supervision writing review editing qichun yang data curation supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is funded by an australian research council linkage project grant no lp170100922 and a collaborative project grant no tp707466 between the university of melbourne and australian bureau of meteorology wenyan wu acknowledges support from the australian research council via the discovery early career researcher award de210100117 we thank the australian bureau of meteorology for supplying the access g3 and awap precipitation data we gratefully acknowledge the editor and the two reviewers for their thorough reviews and constructive comments appendix a structure amplitude location sal spatial verification we employ an object based spatial verification the sal method wernli et al 2008 radanovics et al 2018 to compare the structure s amplitude a and location l components between precipitation forecasts and corresponding observations considering a precipitation field that contains a number of grid cells precipitation objects are identified as contiguous grid cells where precipitation amount is above a given threshold the identification of objects is implemented separately for forecast and observed precipitation fields following an approach in wernli et al 2009 we determine the threshold as 1 15 of the 95th percentile of all grid cell precipitation amounts in the field larger than 0 2 mm day here we display the formulas of sal for deterministic forecasts of the precipitation field in this study given a forecast precipitation field x t s s 1 2 s and a corresponding observed precipitation field y t s s 1 2 s at day t the three components a l and s are calculated in order from easy to difficult as follows 1 the amplitude component a the amplitude component corresponds to the relative difference in field average precipitation between the forecast field and the observation field a1 a 2 x t s y t s x t s y t s where the overbar represents the field average precipitation of x t s and y t s a provides a simple evaluation on the quantitative accuracy of total precipitation amount in the field 2 the location component l the location component consists of two parts l1 and l2 l1 measures the relative distance between the centers of mass of the forecast field and the observation field a2 l 1 c x t s c y t s d where c denotes the center of mass of the precipitation in the field and d represents the largest distance between any two grid cells within the field l1 gives a first order evaluation on the overall distribution accuracy of the precipitation in the field however a zero value of l1 does not guarantee a perfect forecast in terms of the location error as more detailed distribution features can be very different between the forecast field and the observation field l2 is therefore introduced to capture such difference by considering the weighted average distance between the center of mass of the precipitation field and identified precipitation objects specifically assuming the number of the precipitation objects is j for the forecast precipitation field x t s the weighted average distance is calculated as a3 r x t s j 1 j p j c x t s c x j j 1 j p j where p j is total precipitation amount that integrates all grid cell precipitation amounts in the j th precipitation object x j j 1 2 j the same calculation is applied to the observation precipitation field y t s to obtain r y t s l2 is then calculated as a4 l 2 2 r x t s r y t s d and l is finally obtained as a5 l l 1 l 2 3 the structure component s the structure component aims to measure the size and shape of precipitation objects for this purpose a scaled volume for the j th forecast precipitation object x j j 1 2 j is calculated as a6 v j p j x j max where x j max denotes the grid cell maximum precipitation amount in the precipitation object x j a weighted average of scaled volumes for all forecast precipitation objects is then produced by a7 v x t s j 1 j p j v j j 1 j p j the same calculation is applied to the observation precipitation field y t s to obtain v y t s s is then defined as the relative difference in weighted average of scaled volumes between the forecast field and the observation field which is analogous to the component a equation a1 a8 s 2 v x t s v y t s v x t s v y t s sal for ensemble forecast precipitation fields has similar forms to the introduced deterministic sal taking an ensemble forecast field as an example each ensemble member is treated as a deterministic forecast and the x t s c x t s and v x t s calculation results of all ensemble members are averaged to be used in equations a1 a2 and a8 to derive a l1 and s respectively the calculation of l2 is defined as 2 times the continuous ranked probability score crps of r x t s calculation results of all ensemble members compared to r y t s divided by d this relationship between the deterministic l2 and the ensemble l2 is similar to the relationship between the mean absolute error mae of deterministic forecasts and the crps of ensemble forecasts introduced in section 3 3 further details of the deterministic sal and ensemble sal can be found in radanovics et al 2018 appendix b supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128432 appendix b supplementary data the following are the supplementary data to this article supplementary data 1 
2968,statistical calibration of precipitation forecasts from numerical weather prediction nwp models is routinely performed grid cell by grid cell aiming to produce accurate and reliable ensemble forecasts for precipitation fields calibrated ensemble members from different grid cells are then connected using ensemble reordering to form spatially structured ensemble forecasts however ensemble reordering approaches such as the well known schaake shuffle method are often criticized for not considering real physical atmospheric states of precipitation events in this paper we propose a spatial mode based calibration smoc model for post processing forecast precipitation fields and producing ensemble forecasts with an inbuilt spatial structure so that ensemble reordering is not required the smoc model is developed based on spatial modes derived from empirical orthogonal function eof analyses of precipitation fields and linear regressions of derived eof expansion coefficients of the first few dominant modes unlike conventional calibration models that are applied to forecast grid cells individually smoc is applied to the whole forecast fields and the spatial structure is inherently present in calibrated ensemble forecasts there is therefore no need to rely on ensemble reordering for spatial reconstruction the performance of smoc is evaluated by applying it to nwp forecasts of substantive precipitation events over the brisbane drainage basin in eastern australia cross validated results show that smoc calibrated forecasts are of high quality at both grid cell and basin scales the spatial structure of precipitation is found to be well embedded in the ensemble members of the calibrated forecasts for the basin keywords forecast precipitation fields numerical weather prediction statistical calibration spatial structure empirical orthogonal function spatial modes data availability the authors do not have permission to share data 1 introduction short term precipitation forecasts are commonly produced using numerical weather prediction nwp models in major meteorological centers worldwide however current nwp models cannot fully simulate dynamic physics of the atmosphere due to various sources of uncertainty including model structures model initial and boundary conditions and model parameters palmer et al 2007 consequently raw forecasts from nwp models are often subject to systematic bias gneiting et al 2007 li et al 2017 and can be even less skillful than naïve climatology forecasts zhao et al 2020 additionally raw forecasts from ensemble nwp models are often subject to dispersion errors buizza 2018 these deficiencies need to be addressed to improve the usefulness of raw precipitation forecasts a number of statistical calibration models have been developed in the past few decades to improve raw precipitation forecasts notable models include but are not limited to ensemble model output statistics emos gneiting et al 2005 scheuerer 2014 baran and lerch 2015 taillardat et al 2016 bayesian model averaging bma raftery et al 2005 sloughter et al 2007 schmeits and kok 2010 wang et al 2012a möller et al 2013 baran and möller 2015 the bayesian joint probability bjp model robertson et al 2013 shrestha et al 2015 zhao et al 2015 wang et al 2019a cattoën et al 2020 w li et al 2020 y li et al 2020 li et al 2022 the seasonally coherent calibration scc model wang et al 2019b zhao et al 2020 yang et al 2021 zhao et al 2022 and machine learning based regression models dogulu et al 2015 these calibration models are typically aimed at producing ensemble forecasts that are free from bias reliable in ensemble spread and as skillful as possible current forecast calibration is mostly performed separately at individual grid cells for forecast precipitation fields however the resulting calibrated ensemble members from different grid cells are not spatially connected and thus cannot reproduce the spatial structure of corresponding observed precipitation events shrestha et al 2015 consequently several ensemble reordering approaches have been proposed to connect calibrated ensemble members from different grid cells so that the spatial structure can be reconstructed in calibrated forecasts schefzik and möller 2018 van straaten et al 2018 the two most popular ensemble reordering approaches are the schaake shuffle clark et al 2004 scheuerer et al 2017 and the ensemble copula coupling ecc schefzik et al 2013 schefzik 2017 however both have drawbacks the schaake shuffle which reorders calibrated ensemble members based on ranks of selected historical observations is often criticized for not considering real physical atmospheric states of the forecasted precipitation events bellier et al 2017 scheuerer et al 2017 besides schaake shuffle becomes problematic when applied to precipitation forecasts as there are often many zero values in observed precipitation that will result in tied ranks in constructing spatial dependence templates clark et al 2004 bellier et al 2017 wu et al 2018 ecc takes raw ensembles as templates of spatial dependence so it is only applicable to raw ensemble forecasts as there is no available template for raw deterministic forecasts its usefulness is therefore largely limited by the size of raw ensembles and the quality of raw ensemble structures in view of the above mentioned limitations of existing methods of calibration of forecast precipitation fields it would be highly valuable if the spatial structure can be inherently embedded in the calibration process thereby eliminating the need for further spatial reconstruction using ensemble reordering approaches however precipitation fields are often high dimensional in space and therefore it is difficult to achieve the synchronous calibration for all of the grid cells in the fields one possible way is to first reduce the precipitation fields to only a few representative variables and then calibrate these dimensionally reduced variables the empirical orthogonal function eof analysis is the most widely used technique for dimensionality reduction and pattern extraction of spatial temporal fields lorenz 1956 hannachi et al 2007 monahan et al 2009 schmidt et al 2019 eof can decompose high dimensional data into a set of orthogonal spatial modes along with a set of associated uncorrelated expansion coefficients these two features can give a spatial display and a temporal display of the large high dimensional meteorological data and provide valuable insights into the main physical characteristics by focusing on a few dominant eof modes the eof technique and its variants have been widely applied in a variety of studies including meteorology oceanography and remote sensing for example barnett 1978 used eof to examine space time variations of surface air temperature over the northern hemisphere servain and legler 1986 applied eof to analyze the seasonal variability of monthly sea surface temperature and wind stress within the tropical atlantic region lintner 2002 identified the interannual variability of global carbon dioxide using the first few eof modes wang et al 2015 studied the asian summer monsoon precipitation by employing an eof variant with emphasis on seasonal predictability and feng et al 2016 proposed an eof based data integration algorithm to improve the estimation of terrestrial latent heat flux from multiple remote sensing data sources in this study we set out to develop a new approach based on the eof analysis for post processing forecast precipitation fields from nwp models and producing ensemble forecasts with an inbuilt spatial structure for this purpose we extract representative variables from forecasts and corresponding observations of precipitation fields based on spatial modes derived from the eof analysis of long term climatology of observations and establish calibration models for these extracted variables we call this approach a spatial mode based calibration smoc in this paper we introduce the rationale and mathematical formulations of the smoc model in detail and evaluate its performance through a case study 2 model formulation here we consider daily deterministic nwp forecast precipitation fields at a single lead time we aim to calibrate raw forecast fields and produce spatially structured ensemble forecasts that are of high quality at both grid cell and field scales the developed spatial mode based calibration smoc model in this paper involves data normalizations of precipitation data empirical orthogonal function eof analysis and calibration of eof variables the framework of the smoc formulation is illustrated in fig 1 and detailed in sections 2 1 and 2 2 in this section we first introduce the eof analysis by demonstrating its application to long term observations of precipitation fields thereafter we explain how eof is used to establish the smoc model for raw precipitation forecasts and corresponding observations finally we present how we apply smoc to calibrate new forecast fields for clear notation we set up three time variables t t and t to distinguish three different sets of precipitation data as shown in table 1 the long term observation period t 1 2 t may or may not overlap with the period of forecast data used for model training t 1 2 t where t and t denote the number of days in the long term observation period and the period of forecast data respectively t represents the time of a new forecast event that will be calibrated using the smoc model in section 2 3 and t does not overlap with the long term observation period or the forecast period 2 1 eof analysis of long term observation fields we apply the eof analysis to long term observation fields to derive representative patterns with long term statistical characteristics of climatology given a gridded precipitation field long term observations can be represented as 1 y y 1 1 y 1 2 y 1 s y 2 1 y 2 2 y 2 s y t 1 y t 2 y t s where t and s denote the number of days in the long term observation period and the number of grid cells in the gridded field respectively y t s in the data matrix y represents the observed precipitation at day t in grid cell s t 1 2 t and s 1 2 s 2 1 1 data normalization statistical treatment on precipitation values is always challenging due to highly skewed distribution of precipitation data it has therefore been a common practice to apply data transformation for normalizing precipitation data before formal analysis wang et al 2012b wang et al 2019b zhao et al 2022 to ensure the spatial consistency of data normalizations among different grid cells we apply an approach of regionally optimized power transformation as recommended by du et al 2022 to transform the long term precipitation observation fields from y to y p details of the power transformation can be found in text s1 and fig s1 of supplementary material s1 2 1 2 eof decomposition as an integral part of the eof analysis we center precipitation values i e subtracting the temporal average from the values for each grid cell the centering process assures that the eof technique only focuses on the variance within the precipitation data rather than taking the overall average of the data as an important piece of extracted information for y p temporal averages of precipitation values can be calculated as 2 y p y p 1 y p 2 y p s where for each grid cell s the precipitation average is calculated as 3 y p s 1 t t 1 t y p t s where y p t s is the power transformed observed precipitation at day t in grid cell s t 1 2 t and s 1 2 s the centered precipitation field y p can be produced by subtracting y p from each row of y p and then decomposed using eof as 4 y p c y u y 5 c y c y 1 1 c y 1 2 c y 1 k c y 2 1 c y 2 2 c y 2 k c y t 1 c y t 2 c y t k 6 u y u y 1 1 u y 1 2 u y 1 s u y 2 1 u y 2 2 u y 2 s u y k 1 u y k 2 u y k s where k is the number of derived eof modes after the decomposition and generally equals to the smaller dimension of the original spatial temporal patterns i e the smaller of t and s equation 4 can also be written as 7 y p k 1 k c y t k u y k s where c y t k t 1 2 t is a column vector and varies with day t representing expansion coefficients of the k th eof mode u y k s s 1 2 s is a row vector and varies with grid cell s representing spatial modes of the k th eof mode in this way the original gridded long term observation fields i e y can be represented using a set of temporal variables expansion coefficients c y t k t 1 2 t and a set of spatial variables spatial modes u y k s s 1 2 s 2 2 establishing relationships between raw forecasts and observations for a given k th eof mode c y t k t 1 2 t is a function of day t which is analogical to the fact that the occurrence of natural precipitation events varies with time in the field we therefore choose to relate raw precipitation forecasts to corresponding observations by matching their respectively derived expansion coefficients 2 2 1 expansion coefficients of raw forecast fields and corresponding observation fields raw forecast fields in the period of training forecast data a k a forecast period from hereon can be represented as 8 x x 1 1 x 1 2 x 1 s x 2 1 x 2 2 x 2 s x t 1 x t 2 x t s where t and s denote the number of days in the forecast period and the number of grid cells in the gridded field respectively x t s in the data matrix x represents the precipitation forecast at day t in grid cell s t 1 2 t and s 1 2 s similar to the processing of long term observation fields we apply the data normalization and the centering process to raw forecast fields and obtain x p to derive expansion coefficients of raw forecasts one way is to simply apply the eof decomposition to x p however two independent eof analyses performed separately on raw forecasts and corresponding observations will produce different spatial modes this makes it hard to match the two sets of derived expansion coefficients in this study instead of repeating the eof decomposition we employ the spatial modes of the long term observation fields i e u y and a variant of equation 4 to derive expansion coefficients from x p 9 c x x p u y 1 where u y 1 is the inverse of u y c x represents the derived expansion coefficients of raw forecasts likewise for corresponding observation fields in the forecast period 10 y y 1 1 y 1 2 y 1 s y 2 1 y 2 2 y 2 s y t 1 y t 2 y t s where t and s denote the number of days in the forecast period and the number of grid cells in the gridded field respectively y t s in the data matrix y represents the observed precipitation at day t in grid cell s t 1 2 t and s 1 2 s we apply the same data normalization and centering process to obtain y p it should be noted that we use the parameters of the data normalization and the centering process from long term observation fields to normalize and center corresponding observation fields as these parameters are derived from long term statistical characteristics of climatology and are more sensible for use we then derive expansion coefficients from y p using the spatial modes of the long term observations 11 c y y p u y 1 where u y 1 is the inverse of u y c y represents the derived expansion coefficients of corresponding observations in this way c x and c y are both derived from the same spatial modes that represent long term climatology statistics this assures that these two expansion coefficients are comparable in a reasonable manner similarly this use of the eof analysis has been performed for hydrodynamic model inundation simulations in fraehr et al 2022 which derives expansion coefficients of low resolution models using the spatial modes of high resolution models in the eof analysis the first few modes are often selected to represent the whole set of original data without compromising much of the explained data variance the high dimensional datasets can therefore be reduced to only a few representative variables in practice the number of the selected modes is often determined by specifying a certain amount of the total variance e g 90 and then finding the minimum number of modes needed to explain this amount of variance in this study we select expansion coefficients from the first m eof modes i e c x t k and c y t k t 1 2 t and k 1 2 m to represent the whole sets of expansion coefficients where m is the number of the selected eof modes the actual value of m will vary with application for example in the case study later shown in section 3 2 the first 10 modes are chosen which account for 95 of the long term observation data variance in addition detailed illustrations of the spatial modes and expansion coefficients from the first 10 eof modes are also provided in section 3 2 to further demonstrate the eof analysis of the precipitation field data 2 2 2 seasonality removal in expansion coefficients in establishing calibration models based on the two selected sets of expansion coefficients we aim to produce ensembles that are not only free from bias reliable in ensemble spread and as skillful as possible but also coherent with a seasonally varying climatology that exists in both forecasts and observations as well as in their respective expansion coefficients this is especially important for forecasts at long lead times when forecast skill becomes low and forecasts approach climatology wang et al 2019b however it is challenging to produce coherent calibrated ensembles as nwp models tend to be updated regularly and available nwp forecasts to establish coherent calibration models are often limited to resolve this problem we choose to remove the seasonality in expansion coefficients and pool the data from all year round together to establish calibration models when applying the established smoc model for forecast calibration we add the removed seasonality back to calibrated expansion coefficients and finally produce coherent calibrated forecasts see section 2 3 later in this study we remove the seasonality by using daily climatological mean and daily climatological standard deviation to standardize expansion coefficients of forecasts and corresponding observations for the k th eof mode k 1 2 3 m we first employ the spectral method in narapusetty et al 2009 to estimate the daily climatological mean μ c y t k t 1 2 3 t for expansion coefficients of observations from the long term period we then use the daily climatological mean to calculate the squared error of expansion coefficients and employ the spectral method again to estimate the daily climatological standard deviation σ c y t k t 1 2 3 t for expansion coefficients of observations from the long term period we apply these two estimated variables to produce daily climatological mean and daily climatological standard deviation for expansion coefficients of observations at day t t 1 2 t during the forecast period i e μ c y t k and σ c y t k the standardization goes as 12 c x t k c x t k μ c y t k σ c y t k 13 c y t k c y t k μ c y t k σ c y t k where c x t k and c y t k are expansion coefficients of forecasts and corresponding observations for the k th mode at day t respectively c x t k and c y t k are standardized c x t k and c y t k respectively 2 2 3 linear regressions of expansion coefficients after the standardization we establish calibration models based on these two sets of expansion coefficients as expansion coefficients from different eof modes are independent from each other we establish calibration models separately for the m modes specifically we fit an ordinary least square linear regression for each mode for the k th mode k 1 2 3 m at day t t 1 2 t the regression can be formulated as 14 c y t k a k c x t k b k ε t k where a k and b k denote linear regression coefficients and the residual term ε t k follows a normal distribution 15 ε t k n 0 σ ε 2 k estimates of a k b k and σ ε k can be found by using the method of maximum likelihood estimation 2 3 model use for calibrating new forecasts once parameters of the data normalization data centering spatial modes u y standardization of expansion coefficients and linear regressions in sections 2 1 2 2 are derived from training datasets we can apply the established smoc model to calibrate new forecasts given a new forecast field x t s s 1 2 s at day t a calibrated ensemble forecast can be produced following the steps shown in fig 2 and detailed as below a apply the data normalization and the centering process to produce x p t s s 1 2 s b derive expansion coefficients c x t k k 1 2 k using equation 9 c select the first m eof modes of c x t k k 1 2 k and remove the seasonality of expansion coefficients to give c x t k k 1 2 m using equations 12 and 13 d for the k th mode draw a random ε t k from equation 15 then a predicted c y t k can be obtained using c x t k and equation 14 results for the m eof modes are pooled together to produce c y t k k 1 2 m e add the removed seasonality back to c y t k k 1 2 m to give c y t k k 1 2 m using variants of equations 12 and 13 f derive y p t s s 1 2 s using equation 4 16 y p t s c y t k u y g inverse the centering process and the data normalization to y p t s s 1 2 s and obtain a calibrated forecast field y t s s 1 2 s in the original spatial dimension for day t negative values in the inverse of data normalization are set to zero to give zero precipitation forecasts h repeat steps d g n times to produce a calibrated ensemble forecast field y t s n s 1 2 s and n 1 2 n for day t n being the size of the ensemble following above steps raw forecast precipitation fields are calibrated as a whole not grid cell by grid cell the calibrated ensemble forecast field for one precipitation event contains n ensemble members each being a forecast ensemble member for the whole precipitation field the spatial structure is inherently embedded in calibrated ensemble members and therefore there is no need to further apply conventional ensemble reordering approaches for spatial reconstruction 3 case study 3 1 research basin and data we apply the smoc model to calibrate nwp forecasts from a case study to demonstrate the model performance the brisbane drainage basin located in eastern australia is selected as the research basin shown in fig 3 a the basin area is 13 549 2 km2 and the average annual precipitation in the basin is 866 mm per year observed precipitation data are obtained from the australian water availability project s awap jones et al 2009 climate datasets which are commonly considered the best available reference climate data for australia awap datasets have a horizontal grid spacing of 0 05 x 0 05 and are produced by interpolating rain gauge observations across australia daily observations for a period of 30 years from 3 november 1988 to 2 november 2018 are used as long term observations for eof analysis and estimation of long term statistics of seasonality daily observations for a period of 3 years from 3 november 2018 to 2 november 2021 are used as reference data for forecast calibration and forecast evaluation raw precipitation forecasts are generated from the australian community climate and earth system simulator global 3 access g3 model developed by the australian bureau of meteorology access g3 model produces deterministic nwp forecasts with a horizontal grid spacing of 0 18 longitude by 0 12 latitude with a forecasting horizon of 10 days access g3 forecasts are issued at 0000 utc 0600 utc 1200 utc and 1800 utc every day and are available at an hourly temporal resolution access g3 forecasts have been operational since 25 july 2019 to minimize possible impacts of sample size on calibration performance we integrate experimental forecasts from 3 november 2018 to 24 july 2019 and operational forecasts from 25 july 2019 to 2 november 2021 to obtain 3 years of forecasts to match the daily awap data we adjust the spatial and temporal resolutions of access g3 forecasts we apply bilinear interpolation to re grid the forecasts to the horizontal grid spacing of observations and we aggregate the hourly forecasts to daily values by accumulating forecast values according to the daily period on which the awap data are produced consequently precipitation forecasts and observations are both provided at a grid spacing of 0 05 x 0 05 and on a daily basis for this study brisbane drainage basin covers 493 grid cells at the 0 05 x 0 05 scale and average annual precipitation values of the 33 years of awap data at these grid cells are shown in fig 3 b 3 2 smoc model setup the smoc model is set up for application to 30 years of long term observations and 3 years of forecasts and corresponding observations for the case study the total number of days in the long term period and the forecast period i e t and t are therefore 10 957 and 1096 respectively the total number of grid cells in the research basin i e s is 493 the size of the generated ensemble of calibrated forecasts i e n is set as 1 000 members the model is applied to forecasts of day 1 ahead which represent the best performing forecasts among different lead times in the smoc model establishment the number of the first few eof modes i e m is set as 10 from our case study the first 10 modes are found to account for 96 of the long term data variance shown in fig s7 from supplementary material s1 the large number of no and little precipitation days in the research basin as typically in most regions means that there are numerous very small values of expansion coefficients shown in fig s6 from supplementary material s1 when all these values are used to derive the linear relationships between forecasts and observations the model fit will be heavily geared towards the no and little precipitation events neglecting the model fit to the substantive precipitation events which the public cares about the most lerch et al 2017 therefore we choose only to fit linear regressions to expansion coefficients of substantive precipitation events whose corresponding basin average of raw forecasts is beyond a pre defined threshold in the 3 year forecast period the threshold is set as 90 quantile of raw forecast basin averages and equals to 5 47 mm per day and the resulting number of chosen substantive precipitation events is 110 to help readers understand the eof analysis and the smoc model more intuitively we produce a number of figures figs s2 s5 in supplementary material s1 to illustrate the spatial modes and expansion coefficients of the precipitation data used in our case study specifically we apply the eof analysis to decompose 30 years of normalized and centered observations to obtain a set of spatial modes u y along with a set of expansion coefficients c y the first 10 spatial modes i e the first 10 rows of u y are shown in fig s2 each representing one spatial pattern across the brisbane drainage basin over the 30 year period the first 10 expansion coefficients i e the first 10 columns of c y are shown in fig s3 each representing one temporal pattern in the 30 year period for its corresponding spatial mode the first 10 expansion coefficients of 3 years of normalized and centered forecasts as well as corresponding observations i e the first 10 columns of c x and c y that are derived using u y are shown in figs s3 s4 we also select five precipitation events of different magnitudes in the 3 year period shown in figs s4 s5 and investigate if original forecasts and observations can be reconstructed using the first 10 eof modes of the spatial modes u y and expansion coefficients c x and c y results in fig s5 show that the eof analysis can reconstruct the precipitation fields reasonably well even with only the first 10 eof modes both for light and heavy precipitation events therefore it is suggested that the calibration of raw forecast precipitation fields can be represented by the calibration of raw forecast expansion coefficients using linear regressions in section 2 2 3 3 forecast evaluation in this study the performance of smoc calibrated forecasts is evaluated using a leave one event out cross validation to assess different aspects of forecast quality over the precipitation field we use continuous ranked probability score crps hersbach 2000 probability integral transform pit renard et al 2010 and structure amplitude location sal spatial verification wernli et al 2008 radanovics et al 2018 to perform a comprehensive evaluation furthermore we implement the forecast evaluation at both grid cell and basin scales with the evaluation at grid cell scale assessing model calibration performance for individual grid cells and the evaluation at basin scale for the whole basin forecasts and corresponding evaluation metrics are presented in table 2 and detailed in sections 3 3 1 and 3 3 2 3 3 1 forecast evaluation at grid cell scale we apply crps and pit to evaluate forecast skill and forecast reliability of forecasts at each of the 493 grid cells crps measures the difference between ensemble forecast cumulative distributions and corresponding observations the average crps for calibrated ensemble forecasts at day i 1 2 i is evaluated as 17 crps 1 i i 1 i f i x h x y i 2 d x where f i x is the forecast cumulative density function and y i is the observation at day i h is the heaviside step function that equals 1 if x y i 0 and equals 0 otherwise and i is the number of the evaluated precipitation events in practice we often use crps skill score to evaluate the relative forecast skill improvement of forecasts compared to reference forecasts in this study we produce a reference ensemble climatology forecast for each substantive precipitation event for this purpose we first fit a normal distribution in power transformed space for 30 years of awap observations of the month in which the event occurred we then draw a random sample from the distribution and inverse the power transformation to generate an ensemble climatology forecast for the event the sample size is also set as 1 000 then we calculate the average crps of reference climatology ensemble forecasts crps ref for the evaluated precipitation events and give a crps skill score 18 crps skill score crps ref crps crps ref 100 the crps skill score is positively oriented with a maximum skill score of 100 indicating perfect forecasts and a skill score of 0 indicating that forecasts have comparable errors to the reference forecasts a negative skill score indicates that forecasts are less skillful than reference forecasts for deterministic precipitation forecasts crps is equivalent to the mean absolute error mae 19 mae 1 i i 1 i x i y i where x i and y i are the forecast and corresponding observation at day i respectively and i is the number of the evaluated precipitation events similarly we use crps skill score to demonstrate the performance of raw forecasts relative to reference climatology forecasts to have a fair evaluation we use the same reference crps for raw deterministic forecasts and calibrated ensemble forecasts we use pit to evaluate the reliability of ensemble forecasts ensemble spread not too narrow or too wide statistically forecast reliability represents the consistency between ensemble forecast probability distributions and the observed frequency of corresponding observations the pit of an ensemble forecast at day i is calculated as 20 π i f i x y i where f i x is the forecast cumulative density function and y i is the corresponding observation for a set of reliable forecasts π i follows a uniform distribution and the uniformity can be examined by the well known pit alpha index 21 pit alpha index 1 2 i i 1 i π i i i 1 where π i is the sorted π i in an increasing order and i is the number of the evaluated precipitation events pit alpha index is also positively oriented and ranges from 0 poorest reliability to 1 perfect reliability 3 3 2 forecast evaluation at basin scale we evaluate basin average forecasts to give an overall assessment of forecast precipitation fields for raw forecasts we calculate the basin average of forecasts and corresponding observations then we calculate crps skill score of raw basin average forecasts for calibrated ensemble forecasts we calculate the basin average of each ensemble member to produce a basin average ensemble forecast for each evaluated precipitation event then we calculate crps skill score of calibrated basin average ensemble forecasts likewise the reference ensemble climatology forecast used for calculating crps skill score of each event is sampled from the distribution fitted for 30 year basin average observations of the month in which the event occurred besides calculating the pit alpha index of calibrated basin average ensemble forecasts we also apply the pit uniform probability plot to visualize the forecast reliability where sorted pit values π i of all evaluated precipitation events are plotted against corresponding theoretical quantiles of the uniform distribution reliable forecasts will display a scatter plot close to the 1 1 line to indicate whether smoc calibrated ensemble forecasts are spatially correlated in an appropriate way across the grid cells we evaluate reliability of ensemble spreads of basin average precipitation forecasts the rationale is as follows when forecast spatial correlation is low the ensemble spreads of basin average forecasts will be narrow because much of the randomness across the grid cells will be averaged out on the contrary when forecast spatial correlation is high the ensemble spreads of basin average precipitation forecasts will be wide because there is less randomness across the grid cells in individual ensemble members therefore when ensemble spreads of forecasts of individual grid cells and basin average are both reliable appropriate spatial correlation is strongly indicated we also apply sal spatial verification to evaluate the structure s amplitude a and location l of precipitation forecasts for the research basin sal is an object based and dimensionless quality measure formulas for calculating these three sal components are presented in appendix a s measures the size and shape of precipitation objects assessing whether the predicted precipitation objects are too large positive s or too small negative s s ranges from 2 to 2 and a s value of 0 indicates perfect forecasts a measures the relative deviation of the basin average forecasts from corresponding observations positive negative a values indicate that forecasts overestimate underestimate the basin average precipitation similarly a ranges from 2 to 2 and an a value of 0 indicates perfect forecasts l measures the displacement of the center of mass of predicted precipitation field and the error in the weighted average distance of the individual precipitation objects from the total precipitation field s center of mass l ranges from 0 to 2 with 0 indicating perfect forecasts and positive values indicating spatial forecasts that have location errors in addition we plot spatial precipitation maps for several selected ensemble members of calibrated ensemble forecasts to check whether calibrated ensemble members are capable of capturing the intensity and spatial features of observed precipitation in the research basin specifically we select three extreme precipitation events in terms of either raw forecasts or observations or both to investigate the smoc model performance in different forecasting situations to facilitate visualization we choose to plot 10 ensemble members for each calibrated ensemble forecast corresponding to 10 equally divided quantiles from 5 to 95 based on basin averages of the 1 000 calibrated ensemble members for the whole research basin 4 results 4 1 forecast evaluation at grid cell scale 4 1 1 forecast skill results of crps skill score for raw forecasts and calibrated ensemble forecasts at individual grid cells of the research basin are shown in fig 4 to have a fair comparison we also provide calibrated ensemble median forecasts as deterministic style forecasts for comparing with raw deterministic forecasts as mae is found to work better for ensemble median than for ensemble mean gneiting 2011 it can be seen from the figure that raw forecasts overall perform the worst among these three forecasts in terms of forecast skill there are negative crps skill score values of raw forecasts across most grid cells especially for grid cells in the middle and southeast areas of the basin by contrast the smoc model markedly improves the forecast skill of raw forecasts with the average of crps skill scores across all of the grid cells increasing from 7 21 to 19 25 calibrated ensemble median forecasts and 40 29 calibrated ensemble forecasts the calibrated forecasts have positive crps skill score values at all of the grid cells suggesting that they are more skillful than reference climatology forecasts in addition calibrated ensemble forecasts have clearly greater crps skill scores than calibrated ensemble median forecasts this is due to the benefits of the ensemble spread information included in calibrated ensemble forecasts and this highlights the advantages of forecast calibration models that can produce ensembles even when taking raw deterministic forecasts as model inputs schaake et al 2007 shrestha et al 2015 4 1 2 forecast reliability results of pit alpha index for calibrated ensemble forecasts at individual grid cells of the research basin are shown in fig 5 it is obvious that pit alpha index values at almost all of the grid cells are close to 1 with the average across all of the grid cells being 0 9491 therefore the ensemble spread of calibrated ensemble forecasts at grid cell scale is overall reliable in the research basin this indicates that the assumed normal distributions of residuals in the linear regressions can reliably quantify the uncertainty of predicted expansion coefficients as well as the uncertainty of calibrated ensemble forecasts in addition we calculate the root mean square errors of smoc ensemble mean forecasts and plot them against the square root values of average smoc ensemble variance over the 110 substantive precipitation events both for grid cell and basin scales as shown in fig s11 from supplementary material s1 it is found that smoc calibrated ensemble forecasts in grid cell scale perform well in terms of the well known spread error correlation whitaker and loughe 1998 fortin et al 2014 van schaeybroeck and vannitsem 2016 as well as the ensemble forecast reliability however it should be noted that the ensemble forecasts tend to be over dispersed especially for grid cells with large ensemble forecast variance 4 2 forecast evaluation at basin scale for forecasts at basin scale we first evaluate the performance of basin average forecasts fig 6 shows 90 and 50 ensemble intervals and ensemble medians of calibrated basin average ensemble forecasts against raw basin average forecasts for substantive precipitation events in the research basin corresponding observations are also provided for visual forecast verification the width of calibrated basin average ensemble intervals generally increases with raw basin average forecasts this is in line with the well known consensus that forecast uncertainty on precipitation events increases with precipitation amounts calibrated ensemble medians are shown to be overall closer to corresponding observations than raw forecasts especially for the several extremely substantive precipitation events on the far right of fig 6 statistically the distribution of observations is visually consistent with the shown 90 and 50 ensemble forecast intervals to further assess the quality of basin average forecasts we provide evaluation results on forecast skill and forecast reliability in section 4 2 1 4 2 1 forecast skill and forecast reliability of basin average forecasts results of crps skill score for basin average forecasts are summarized in table 3 similar to the evaluation at grid cell scale in the order of raw forecasts calibrated ensemble median forecasts and calibrated ensemble forecasts crps skill scores are found to increase successively indicating gradual forecast skill improvements for reliability of calibrated basin average ensemble forecasts pit alpha index is calculated as 0 9692 and pit uniform probability plot is close to the uniform distribution fig 7 showing that these ensemble forecasts have good performance in forecast reliability the spread error correlation results in fig s11 from supplementary material s1 also show that smoc calibrated basin average ensemble forecasts in basin scale perform well in forecast reliability although there is a potential over dispersion issue of ensemble forecasts together with the forecast reliability results presented in section 4 1 2 it can be concluded that calibrated ensemble forecasts are reliable at both grid cell and basin scales this indicates that calibrated ensemble members from different grid cells are connected in an appropriate way so that basin average forecasts are reliable in ensemble spread spatial correlation is well embedded in smoc calibrated forecasts of the whole research basin 4 2 2 sal verification of forecast precipitation fields results of sal verification for substantive precipitation forecasts of the whole research basin are shown in fig 8 in addition to raw forecasts and calibrated ensemble forecasts we also evaluate the sal of climatology forecasts as a reference forecasts of high quality are illustrated as small dots in the center of the sal diagram most climatology forecasts are located in the third quadrant of the diagram where both structure and amplitude are underestimated this is because climatology forecasts are produced based on historical precipitation events with all magnitudes of precipitation amounts when such climatology forecasts are used to predict substantive precipitation events they tend to provide light forecasts and therefore underestimate the size of precipitation objects and the capacity of precipitation amounts most of raw forecasts and calibrated ensemble forecasts however are found in the first quadrant of the diagram where both structure and amplitude are overestimated raw forecasts tend to overestimate the precipitation amounts by producing too large precipitation objects while calibrated ensemble forecasts though with a similar tendency have weaker overestimation issues especially for structure for dots in top right corner of the diagram substantive precipitation is predicted in terms of structure and amplitude but little precipitation is observed these cases are generally considered as false alarms by contrast there are few blue and green dots in the bottom left corner of the diagram indicating that the raw and calibrated forecasts rarely miss the prediction of substantive precipitation events furthermore calibrated ensemble forecasts also have smaller location errors than raw forecasts and climatology forecasts dots with the largest sizes are mainly found at the top right corner of the diagram green dots have overall smaller sizes than blue dots indicating that calibrated ensemble forecasts perform better than raw forecasts in terms of the largest location errors to sum up calibrated ensemble forecasts have the best forecast quality among these three forecasts in terms of the sal verification 4 2 3 spatial visualization plots of forecast examples figs 9 11 provide visualization of forecast examples from three selected extreme precipitation events corresponding to three different forecast performances of calibrated ensemble forecasts each example contains a raw forecast the corresponding observation and 10 selected calibrated ensemble members overall ensemble members from figs 9 11 have smooth precipitation surfaces across the research basin meaning that there are similar predicted precipitation amounts in adjacent grid cells this is an important feature in correctly structured precipitation forecasts for a spatial field in fig 9 extreme precipitation is forecasted by raw forecast but not observed in the basin although the raw forecast clearly overestimates precipitation amounts we still obtain several calibrated ensemble members e g quantiles of 25 and 35 that can predict a similar amount of precipitation to the observation for the whole basin however calibrated ensemble members with large precipitation i e high quantiles should not be considered useless as extreme precipitation events might occur with any magnitude of forecasted precipitation amounts especially with high magnitudes predicted in raw forecasts this will be further illustrated with the following two forecast examples in fig 10 extreme precipitation is not forecasted by raw forecast but observed in the research basin it can be seen that there is intense observed precipitation in the northeast of the research basin however raw forecast fails to capture the large amount of observed precipitation and its spatial distribution this is a typical case that raw forecasts cannot successfully predict extreme precipitation events which might lead to severe flooding events when people have no precautions fortunately smoc model can generate more forecast possibilities even when only relatively light precipitation is predicted in raw forecasts for example the two calibrated ensemble members of 85 and 95 quantiles are approximately able to predict the intensity of the observed precipitation event indeed it is crucial for forecast users to be aware of possible extreme precipitation events in flooding risk management wu et al 2020 in fig 11 extreme precipitation is forecasted by raw forecast and also observed in the research basin however there are differences between the raw forecast and the observation in terms of the intensity and spatial distribution of precipitation for example the raw forecast has intense precipitation amounts in the west where the intensity is much lower for the observed event by contrast many calibrated ensemble members e g quantiles of 35 45 and 55 are shown to be capable of predicting the intensity of the observed precipitation this is especially the case for the ensemble member of 35 quantile which has similar spatial patterns to the observed precipitation event in addition to the displayed quantiles from 5 to 95 of basin averages of smoc calibrated ensemble members we provide a few more calibrated ensemble members for forecast visualization by using animation as shown in animations s1 s3 from supplementary material s1 apart from the basin scale quantiles we also produce spatial precipitation plots based on the grid cell scale quantiles of calibrated ensemble members for the three selected forecast examples as shown in figs s8 s10 from supplementary material s1 the quantiles are also set to 10 equally divided values from 5 to 95 but applied to the 1 000 calibrated ensemble members from each grid cell different from figs 9 11 that display multiple quantiles of calibrated ensemble members for the whole research basin figs s8 s10 offer insight into the forecast uncertainty information present in individual grid cells smoc calibrated ensemble members are found to contain diverse forecast possibilities at both basin and grid cell scales 5 discussion in the case study we select the first 10 eof modes that account for over 95 of the data variance to represent all the 493 modes to investigate the influence of the number of selected eof modes on the smoc model performance we conduct further experiments using some other numbers of eof modes results of crps skill score and pit alpha index for grid cell scale calibrated forecasts and calibrated basin average forecasts are shown in fig s12 from supplementary material s1 it can be seen that crps skill scores do not change much with the number of eof modes used especially for numbers larger than 2 by contrast pit alpha index values increase dramatically with the increase in the number of eof modes used initially and then have only small fluctuations when the number of eof modes is larger than 9 these results indicate that we can achieve the highest possible forecast skill with only a few eof modes however a relatively large number of eof modes is required to reliably quantify the forecast uncertainty in our analysis we standardize the eof expansion coefficients prior to linear regressions by removing the embedded seasonality so that we can pool values from different months together to establish the smoc model and produce coherent calibrated forecasts as a comparison we also establish a calibration model without the standardization of expansion coefficients results of crps skill score and pit alpha index for grid cell scale calibrated forecasts and calibrated basin average forecasts are summarized in table s1 from supplementary material s1 it can be found that the standardization of expansion coefficients does not have a significant impact on forecast reliability but leads to higher forecast skill of calibrated ensemble forecasts at both grid cell and basin scales the removal of seasonality also helps demonstrate the true correspondence between expansion coefficients of forecasts and corresponding observations zhao et al 2020 this facilitates the establishment of a robust calibration model and improves the performance of calibrated forecasts the eof analysis is well known as an effective tool to perform dimension reduction for climate data typically for gaussian distributed data such as temperature variables barnett 1978 servain and legler 1986 however for climate data that are not gaussian distributed such as the daily precipitation investigated in this study the use of eof for dimension reduction may lead to loss of useful data information lim et al 2012 to alleviate this issue we apply power transformations to normalize precipitation data before the eof analysis and standardize eof expansion coefficients before the gaussian based linear regressions the eof analysis is found to perform well for this study according to the fairly good representation of precipitation field data shown in fig s5 and fig s7 from supplementary material s1 and the remarkable calibration results of the smoc model despite these performances it would be of interest to further investigate the possible effects of eof on the loss of precipitation data information it would also be worthwhile to try out other dimension reduction methods that are suitable for non gaussian distributed data such as the independent component analysis ica lim et al 2012 we acknowledge that the smoc model is only used to calibrate forecasts of substantive precipitation events in our case study theoretically if we have a long record of nwp forecasts it will be more sensible to establish multiple calibration models respectively for events with different magnitudes of precipitation li et al 2019 wang et al 2019b however the archived record of forecasts is commonly short as nwp models are frequently updated and there are only a limited number of nwp models producing hindcasts the developed smoc model might be further improved using longer archived nwp forecasts and could be extended to calibrate events with other magnitudes of precipitation indeed extending the smoc model for calibration of non substantive precipitation events in the research basin will be investigated in our future work smoc calibrated ensemble forecasts are found to be reliable in ensemble spread however it should be noted that the produced ensemble members tend to be over dispersed to some extent as shown in fig s11 from supplementary material s1 in other words these ensemble forecasts are not sharp in terms of ensemble spread according to the well known paradigm of forecast calibration in gneiting et al 2007 the sharpness of predictive ensembles should be maximized subject to forecast reliability indeed this issue could potentially be alleviated by using a longer record of archived nwp forecasts in which case we will be able to establish a calibration model specifically for those extremely substantive events in this way the residuals of linear regressions for expansion coefficients can exclusively apply to the fitted extreme precipitation events which helps to reduce the forecast uncertainty information and thus enlarges the sharpness of calibrated ensemble forecasts in this study the ordinary least square linear regression is employed to establish statistical calibration models for forecast expansion coefficients and is found to perform well in producing high quality calibrated ensemble forecasts indeed this classical linear regression also named model output statistics mos has been extended to incorporate many complexities for accommodating a variety of objectives of forecast calibration van schaeybroeck and vannitsem 2011 for example the error in variable mos evmos method vannitsem 2009 was developed to take into account the errors in both observations and forecasts unlike the original mos method that only considers the errors in observations consequently evmos was found to produce more appropriate variabilities for calibrated forecasts even at long lead times other extended linear regression methods include the time dependent tikhonov regularization tdtr golub and loan 1996 the total least square tls huffel and vandewalle 1991 golub and loan 1996 and the geometric mean gm teissier 1948 it would be valuable to further investigate if the uses of these extended linear regression methods and some other methods like machine learning dogulu et al 2015 can produce improved model performance compared to the ordinary least square linear regression used in the current smoc model the smoc model is innovatively developed to calibrate forecast precipitation fields as a whole rather than calibrating univariate forecasts separately for each grid cell as in conventional calibration models the main advantage is that calibrated ensemble forecasts are produced with an inbuilt spatial structure and there is no need to further employ ensemble reordering to connect calibrated ensemble members from different grid cells and forecast post processing no longer suffers from the aforementioned drawbacks of ensemble reordering approaches e g the schaake shuffle and ecc as smoc calibrated ensemble forecasts in our case study have shown good performance it would be highly valuable to compare the smoc model to conventional calibration models along with ensemble reordering approaches in future study in addition to the spatial structure across different grid cells calibrated ensemble forecasts should also have a correct temporal structure across different forecasting lead times clark et al 2004 especially for adjacent ones substantive precipitation events often occur at consecutive days and so does light precipitation events in practice meteorological centers often issue precipitation forecasts for several lead times raw forecasts are produced from different temporal phases of the evolution of simulated atmospheric states in nwp models and are therefore temporally correlated the smoc model is currently capable of calibrating raw forecasts of different lead times individually e g forecasts of day 1 ahead in our case study in our future work we will apply smoc to calibrate raw precipitation forecasts of other lead times especially long lead times and further investigate how to connect smoc calibrated ensemble members from different lead times in a sensible way 6 summary and conclusions in this paper a spatial mode based calibration smoc model for calibrating forecast precipitation fields from nwp models is presented we aim to produce calibrated ensemble forecasts that are of high quality at both grid cell and field scales and crucially with a correct spatial structure the smoc model is developed based on the eof analysis and linear regressions representative eof variables are derived from forecasts and corresponding observations using the same spatial modes that represent long term climatology statistics so that forecasts and observations are related in a sensible manner linear regression models are established for calibrating the extracted eof variables with distributions of regression residuals provided as uncertainty information to produce ensemble forecasts smoc is an innovative model developed to post process forecasts from multiple grid cells as a whole and produce calibrated ensemble forecasts with an inbuilt spatial structure by contrast conventional post processing of forecast fields typically requires two steps i e statistical calibration of raw forecasts separately for individual grid cells and ensemble reordering of calibrated ensemble members from different grid cells the smoc model turns the two step post processing to only one step and avoids a few well known drawbacks of ensemble reordering approaches the performance of smoc is evaluated by applying it to forecasts of substantive precipitation events over the brisbane drainage basin in eastern australia a number of evaluation measures are used for verification of calibrated ensemble forecasts including crps pit sal verification and also spatial visualization plots cross validated results show that calibrated forecasts are reliable in ensemble spread and have much improved forecast skill compared to raw forecasts at both grid cell and basin scales calibrated ensemble members from different grid cells are shown to be spatially correlated appropriately calibrated forecasts are also found to outperform both raw forecasts and climatology forecasts in terms of the structure amplitude and location of substantive precipitation forecasts for the whole research basin future work of the smoc model is being undertaken on the improvement of smoc using other dimension reduction and statistical regression methods the application of smoc for calibrating forecasts of non substantive precipitation events and forecasts of long lead times the maximization of the sharpness of calibrated ensemble forecasts the comparison between smoc and conventional calibration models along with ensemble reordering approaches the construction of the temporal structure among calibrated ensemble forecasts from different lead times and the extension of smoc to calibrate forecast fields of other weather variables credit authorship contribution statement pengcheng zhao methodology validation formal analysis writing original draft quan j wang conceptualization methodology supervision writing review editing wenyan wu resources supervision writing review editing qichun yang data curation supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is funded by an australian research council linkage project grant no lp170100922 and a collaborative project grant no tp707466 between the university of melbourne and australian bureau of meteorology wenyan wu acknowledges support from the australian research council via the discovery early career researcher award de210100117 we thank the australian bureau of meteorology for supplying the access g3 and awap precipitation data we gratefully acknowledge the editor and the two reviewers for their thorough reviews and constructive comments appendix a structure amplitude location sal spatial verification we employ an object based spatial verification the sal method wernli et al 2008 radanovics et al 2018 to compare the structure s amplitude a and location l components between precipitation forecasts and corresponding observations considering a precipitation field that contains a number of grid cells precipitation objects are identified as contiguous grid cells where precipitation amount is above a given threshold the identification of objects is implemented separately for forecast and observed precipitation fields following an approach in wernli et al 2009 we determine the threshold as 1 15 of the 95th percentile of all grid cell precipitation amounts in the field larger than 0 2 mm day here we display the formulas of sal for deterministic forecasts of the precipitation field in this study given a forecast precipitation field x t s s 1 2 s and a corresponding observed precipitation field y t s s 1 2 s at day t the three components a l and s are calculated in order from easy to difficult as follows 1 the amplitude component a the amplitude component corresponds to the relative difference in field average precipitation between the forecast field and the observation field a1 a 2 x t s y t s x t s y t s where the overbar represents the field average precipitation of x t s and y t s a provides a simple evaluation on the quantitative accuracy of total precipitation amount in the field 2 the location component l the location component consists of two parts l1 and l2 l1 measures the relative distance between the centers of mass of the forecast field and the observation field a2 l 1 c x t s c y t s d where c denotes the center of mass of the precipitation in the field and d represents the largest distance between any two grid cells within the field l1 gives a first order evaluation on the overall distribution accuracy of the precipitation in the field however a zero value of l1 does not guarantee a perfect forecast in terms of the location error as more detailed distribution features can be very different between the forecast field and the observation field l2 is therefore introduced to capture such difference by considering the weighted average distance between the center of mass of the precipitation field and identified precipitation objects specifically assuming the number of the precipitation objects is j for the forecast precipitation field x t s the weighted average distance is calculated as a3 r x t s j 1 j p j c x t s c x j j 1 j p j where p j is total precipitation amount that integrates all grid cell precipitation amounts in the j th precipitation object x j j 1 2 j the same calculation is applied to the observation precipitation field y t s to obtain r y t s l2 is then calculated as a4 l 2 2 r x t s r y t s d and l is finally obtained as a5 l l 1 l 2 3 the structure component s the structure component aims to measure the size and shape of precipitation objects for this purpose a scaled volume for the j th forecast precipitation object x j j 1 2 j is calculated as a6 v j p j x j max where x j max denotes the grid cell maximum precipitation amount in the precipitation object x j a weighted average of scaled volumes for all forecast precipitation objects is then produced by a7 v x t s j 1 j p j v j j 1 j p j the same calculation is applied to the observation precipitation field y t s to obtain v y t s s is then defined as the relative difference in weighted average of scaled volumes between the forecast field and the observation field which is analogous to the component a equation a1 a8 s 2 v x t s v y t s v x t s v y t s sal for ensemble forecast precipitation fields has similar forms to the introduced deterministic sal taking an ensemble forecast field as an example each ensemble member is treated as a deterministic forecast and the x t s c x t s and v x t s calculation results of all ensemble members are averaged to be used in equations a1 a2 and a8 to derive a l1 and s respectively the calculation of l2 is defined as 2 times the continuous ranked probability score crps of r x t s calculation results of all ensemble members compared to r y t s divided by d this relationship between the deterministic l2 and the ensemble l2 is similar to the relationship between the mean absolute error mae of deterministic forecasts and the crps of ensemble forecasts introduced in section 3 3 further details of the deterministic sal and ensemble sal can be found in radanovics et al 2018 appendix b supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128432 appendix b supplementary data the following are the supplementary data to this article supplementary data 1 
2969,evaluation of peak flood magnitude and frequency in the future at a catchment scale under global warming is crucial for water resource management and flood risk management climate model outputs provide a leading source of information to quantify the effect of the foreseen natural and anthropogenic climate change on the environment and natural systems however modelling climate change impact on peak flow is subject to considerable uncertainties from the climate model discrepancies bias correction methods and hydrological model parameters this study develops a framework to examine changes and disentangle uncertainties in peak flow which is tested at five awash catchments in ethiopia a region exposed to extreme flood risk the results showed that projected extreme precipitation and peak flow magnitude could increase substantially in the coming decades by 30 to 55 the uncertainty analysis confirms that the dominant factor in peak flood projection is climate models in catchments like akaki 55 and awash h 51 but the bias correction methods in awash b 58 and kela 50 respectively the least important factor is the hydrological parameter set for flood projections moreover the findings reveal that peak flood risks would noticeably increase in the near and far future in all catchments in awash located in the tropical dry region therefore various state water agencies from local to national scales must take certain non structural structural measures to mitigate flood risks in the future and to adapt to future climate keywords uncertainty projection flood climate change model bias correction data availability no data was used for the research described in the article 1 introduction climate change will likely become one of the primary problems affecting extreme hydrological regimes and water resource quantity and availability in the coming decades significant changes in atmospheric temperature and precipitation are expected resulting in increased extreme events including floods and heavy rainfall with intensive socio economics disasters knutti sedláček 2013 ipcc 2013 serdeczny et al 2016 rojas et al 2013 serdeczny et al 2016 documented that african flood magnitude frequency pattern and timing are shifting due to climate change and its consequences are not uniform across the region in ethiopia summer peak flows are significantly increasing due to climate change which leads to floods in contrast increasing air temperature in the autumn and winter seasons lead to increased drought frequency due to the increasing evapotranspiration coulibaly et al 2020 thober et al 2018 balke nilsson 2019 tariku et al 2021 understanding catchment scale flood projections is crucial for water resource planning and flood risk management however it is challenging to quantify its impact at different modeling stages that possess such as downscaling the gcms rcms to catchment scale the projection of hydrological extremes using the bias corrected climate variables the estimation of the impact of climate change on design flow values at different return periods and the quantification of associated uncertainties the impacts of climate change on the local extreme hydrological extremes are uncertain and complicated meresa and zhang 2021 joseph et al 2018a joseph et al 2018b wang et al 2019 osman et al 2019 byun et al 2019 wang et al 2019 gao et al 2020 her et al 2019 hattermann et al 2017 meresa and romanowicz 2017 studied the critical uncertainty embedded hydrological parameter uncertainty hydrologiska byråns vattenbalansavdelning hbv climate models representative concentration pathway rcp and the distribution parameter uncertainty generalized extreme value gev in the projection of hydrological extremes they then addressed that regional impact studies are highly prone to climate model chain errors joseph et al 2018 also considered hydrological parameters variable infiltration capacity vic and pathways rcp for uncertainty assessment in seasonal flow projections soriano et al 2019 evaluated the uncertainty of bias correction methods on flood frequency and found that the climate model s biases had a significant change in the magnitude of flood design values therefore the changes in peak flow due to discrepancies in the climate model evaluation are associated with various sources of uncertainties thus it is crucial to estimate and understand its complex and uncertain impact and to identify the main sources of uncertainty in future flood risk and extremes management in the last decades various climate scenarios like series report emission scenarios sres representative concentration pathways rcp and shared socio economic pathways ssp along with several regional climate models global climate models rcms gcms have been deployed under different atmospheric land physical formulations therefore the projected hydrological extremes at the local scale are highly dependent on the spreads of the rcms gcms romanowicz et al 2016 meresa and romanowicz 2017 hattermann et al 2017 charles et al 2019 meresa 2020 lawrence 2020 the information from multiple rcms gcms and their discrepancies are considered uncertain and can be estimated using the variance of the climate models lawrence 2020 meresa and zhang 2021 imprecise probability aven 2020 the probabilistic combination technique das et al 2017 and the variance of the error between the observed and each climate model approach eghdamirad et al 2019 this study focused on the uncertainty of the climate model s interpretation and other factors e g bias correction were not explored in detail bias correction methods have a significant impact on the projected hydrological extremes frequency magnitude and direction hattermann et al 2017 charles et al 2019 nowadays many researchers have been addressed the importance of climate bias correction techniques kay et al 2009 meresa and gatachew 2018 saini et al 2015 soriano et al 2019 empirical mapping quantile mapping simple statistical transformation and joint probability are the most popular and widely applied bias correction techniques for climate model bias correction these techniques help to reduce the original climate model variability and outliers the primary source of uncertainty in climate projection can be explained by the selection of bias correction techniques and the spread of selected climate models besides bias correction techniques it is also challenging to obtain the most representative hydrological model parameter sets in space and time in the projection of hydrological extremes the combination of the hydrological parameters play a significant role in minimizing the uncertainty related to catchment hydrology pechlivanidis et al 2017 joseph et al 2018a joseph et al 2018b her et al 2019 many studies attempt to address the uncertainty of the hydrological parameters in climate change impact studies by using generalized likelihood uncertainty estimation glue beven binley 1992 the multi objective function optimization approach dakhlaoui et al 2017 zhang et al 2019 and bayesian model averaging beigi et al 2019 similarly the flood frequency associated uncertainty is also essential collet et al 2017 and lawrence 2020 found that the flood frequency distribution models are highly dependent on the distribution of extreme floods the number of events and the size and shape of the catchment therefore significant efforts have been put to evaluate climate change impacts on extreme hydrology primarily focusing on low flow and high flow magnitude and trend analysis with their associated uncertainty estimation however there is little attention to uncertainty and impact estimation in projected peak flows this study develops a comprehensive framework for the uncertainty and impact estimation of climate change on peak flow the main objectives of this study include i comparing different bias correction techniques for climate change impact assessment ii estimating the role of hbv hydrological model parameters iii evaluating the impact and role of climate change and bias correction approach on flood projections and iv identifying the source of uncertainty associated with projected peak flows 2 observed and projected hydro climate datasets and description of study area 2 1 observed hydrometeorological data and description of study area five sub catchments were chosen for the climate change impact assessment in the upper awash river basin we used 47 meteorological and five hydrological gauged stations an areal precipitation was calculated based on the thiessen polygon method and using these 47 meteorological stations the green dot point in fig 1 indicates the geographical location of all these 47 meteorological stations listed in table s1 they are located in different hydro climatic and geographical conditions table 1 and fig 1 the awash k at u s of koka akaki at aba s kela at welen awash b at bello and awash h at melka h catchments best represent peak flood estimation under the influence of climate change these selected catchments have drainage areas ranging from 67 5 km2 at welen to 7093 9 km2 u s of koka and their elevation varies from 1602 m u s of koka to 2300 m at melka h the historical daily precipitation temperature and streamflow data records were taken from the ethiopian meteorological and hydrological institute from 1981 to 2010 the annual maximum flow varies from 81 12 m3 s at welen to 883 93 m3 s at u s of koka representing different watershed drainage area simultaneously the annual maximum precipitation or the upper 5 of annual precipitation is not proportional with watershed drainage area and annual maximum flow lastly the high mean of surface runoff is directly related to the high coefficient of variance in river flow at u s of koka table 1 2 2 coupled model intercomparison project phase 6 cmip6 cmip6 is a new climate dataset https pcmdi llnl gov cmip6 that was released by a collaborative effort from different climate research institutes to advance climate change knowledge and applicability the daily time scale of precipitation and air temperature time series from the cmip6 simulation datasets https esgf node llnl gov search cmip6 were used for impact estimation the climate model s output covers the period from 1981 to 2100 and provides global regional scale spatial resolution varying from 50 to 250 km in this study three cmip6 scenarios shared socioeconomic pathways ssps 585 high level 370 medium level and 126 low level with 12 climate models each were used to assess the projected flood s uncertainty with their respective impact in the selected awash catchments see table 2 for climate model name and model details each grid data of daily temperature and precipitation time series was extracted from the gridded data overlaying the catchment centroid point the 12 climate models is selected based on the relatively good climate model resolution adequate data availability from 1981 to 2100 and satisfactory model discrepancy this includes three criteria first we selected gcms with less than or equal to 250 km resolution and data length from 1981 to 2100 second we evaluated the ability of gcms uncorrected gcm output in reproducing the observed climate signal finally we used the 12 selected gcms for further investigation these earth system models cmip6 can capture the variability and seasonality of precipitation and temperature better than those with a high resolution almazroui et al 2019 3 modeling and numerical experiments a framework for quantifying the uncertainty and respective impacts of projected peak flow comprising four stages of cascade modeling was developed the framework starts by selecting most representative catchments natural and or semi natural and then extracting rectifying and evaluating climate time series variables obtained from the cmip6 archive this is done with three bias correction methods distribution quantile mapping dqm empirical quantile mapping eqm and statistical quantile factor sqf a sampling of 30 000 hydrological model parameters was taken using monte carlos simulation mcs for hydrological parameter uncertainty estimation by using the generalized likelihood uncertainty estimation glue approach beven binley 1992 then the generalized extreme value gev frequency distribution model was applied to estimate the frequency and magnitude of peak flow values fig 2 lastly the flood quantiles estimated at rt 20 50 and 100 years were compared by calculating relative differences between future simulated and reference quantiles the rt 20 50 100 years quantiles represent short medium and long quantile values in climate change impact studies furthermore the different sources of uncertainty were also compared based on the magnitude and frequency of these estimates by aggregated values in the range between the upper 95 and lower 5 confidence interval 3 1 bias correction techniques global regional climate models are essential for enlightening our understanding of annual seasonal and daily precipitation as well as air temperature characteristics these climate models are a complex and dynamic mathematical representation of the physical process of atmospheric land ocean interaction results in all the climate models exhibit biases in their outputs giorgi gao 2018 krinner flanner 2018 making it challenging to develop accurate and reliable climate information some studies have confirmed the need for climate model outputs post processing before its routine in hydrological extremes projections ehret et al 2012 teng et al 2012 meresa and romanowicz 2017 however reducing the bias in the gcm rcms model output is still a big problem and challenge there is a problem in developing a vigorous climate bias correction technique that minimizes the biases between the simulated and observed climate signals in the reference period several studies used different bias correction approaches in different hydroclimate regimes and have shown mixed performance results the performance of each bias correction technique is mainly depending on the precipitation characteristics and rainfall regime for example one bias correction technique can be performed good in africa climate but not necessary performed well in european climate for instance teutschbein seibert 2013 and yang et al 2010 showed that quantile mapping based bias correction technique was perform better than theoretical distribution mapping local transformation and change factor techniques similarly berg et al 2012 and chen et al 2013 documented that theoretical distribution mapping performs marginally better than or similar to empirical quantile or other statistical methods on the contrary gudmundsson et al 2012 and lafon et al 2013 concluded that empirical quantile reveals better performance than theoretical distribution technique in systematically correcting daily precipitation in this study three climate bias techniques were used to correct the raw climate output and to examine the contribution of bias correction techniques to the peak flood frequency and magnitude 3 1 1 statistical quantile factor sqf in this study a new bias correction method was developed and compared with the commonly used methods distribution quantile mapping and empirical quantile mapping the statistical quantile factor technique sqf is a straightforward approach that helps to reduces the bias in climate models the approach considered a simple error estimation between the observed and simulated climate variables in the reference period and then transfer the error from the reference to a future period the general procedure involves correcting the future precipitation p fut c o r r by multiplying the average reciprocal ratio of the observed precipitation p obs and the reference precipitation simulation p ref r a w to the raw climate model precipitation p fur r a w whereas for correcting future daily air temperature t fut c o r r it is by adding up the difference between the observed air temperature t obs and the simulated daily raw air temperature simulated at reference period t ref r a w to the raw climate output t fur r a w 1 p fut c o r r p fur r a w 2 p obs p ref r a w p ref r a w p obs 2 t fut c o r r t fur r a w m i n t obs t ref r a w 2 2 in this new mathematical equation it is assumed that the future precipitation characteristics not only depend on the slope of the reference period hawkins et al 2013 but also on the future climate condition this helps to consider fully the temporal dynamics of the precipitation series in the daily air temperature correction 2 2 c was used as a threshold to correct the future projections tropical temperature which is more reasonable for africa compared to the global increment of 1 5 c ipcc 2021 3 1 2 distribution quantile mapping dqm distribution quantile mapping is a parameter bias correction technique that depends on the type of distribution fitted to the observed and simulated climate data piani et al 2010 this distribution based approach can be single or double distribution quantile mapping s dqm or other distributions the excess number of dry days drizzles and wet days were considered and properly corrected in this method for every n year the zero precipitation values were excluded before the single gamma distribution is fitted to the upper 75 of daily precipitation in contrast the double gamma distribution is fitted to both the upper and lower parts of the 75 of daily precipitation 3 p corr f dg 1 f dg p raw t α raw β raw α obs β obs 4 t corr f dn 1 f dn t raw t σ raw μ raw σ obs β μ obs where pcorr and tcorr represent the bias corrected daily precipitation and temperature respectively likewise p raw and t raw represent the raw climate output for daily precipitation and air temperature respectively the raw climate output inverse cumulative density is represented by fdg and fdn for precipitation and temperature respectively the dn and dg subscripts stand for the normal for temperature and gamma for precipitation distributions the gamma distributions with two parameters shape α and scale β was used to correct the wet dry spell of precipitation characteristics similarly the normal distributions with two parameters standard deviation σ and mean μ was used to correct the seasonal temperature characteristics 3 1 3 empirical quantile mapping unlike the distribution mapping approach empirical quantile mapping is based on a paired wise comparison between the empirical cumulative density function ecdf of the observed and simulated precipitation at the reference period from 1981 to 2010 this is purely empirical and is a direct matching of the histogram quantiles of the observed to the raw climate precipitation or temperature in the reference period the future precipitation and temperature are corrected using the inverse of ecdf ecdf 1 and fitted ecdf 5 p hst cor ecdf obs 1 ecdf hst p hst 6 t hst cor ecdf obs 1 ecdf hst t hst where pcor hst and tcor hst stand for the corrected precipitation and temperature respectively likewise phst and thst stand for the raw climate model output uncorrected precipitation and temperature respectively lastly the obs subscript stands for the observed temperature and precipitation 3 2 bias correction performance evaluation the performance of the chosen bias correction technique was assessed using four statistical measures percent of bias pbias correlation coefficient rr root mean square error rmse mean absolute error mae and maximum weighting root means square error mwrmse these statistical measures were used to evaluate the daily precipitation and air temperature data of climate model output with respect to observed climate data in the reference period the performance of each bias correction techniques were evaluated their capacity in reproducing the observed maximum time series of precipitation and temperature 7 rr p s p s p c p c p s p s 2 p c p c 2 a n d m a e i 1 n p s p c n 8 pbias i 1 n p s p c i 1 n p s a n d p w r m s e i 1 n p s p c 2 p s p s p s n 0 5 where ps is the observed precipitation at a given station pc is the corrected precipitation and n is the number of observations a similar performance criterion was also used for daily air temperature bias correction methods 3 3 hydrological modelling parameter selection and evaluation the hydrologiska byråns vattenbalansavdelning hbv bergström 1981 is a lumped conceptual hydrological model and is applied in different hydro climate conditions around the world meresa and zhang 2021 her et al 2019 meresa gatachew 2018 hbv is primarily designed to simulate daily streamflow using daily precipitation daily air temperature and evapotranspiration estimated using hamon 1964 these climate variables are used as primary inputs to the model in this study the hbv with nine parameters was used table 3 and the snow routing storage was excluded from the original hbv model structure this model structure has three consecutive stores one related to the surface the second associated with the saturated soil layer and the other to the unsaturated routing store the upper and lower limits of the hydrological model are listed in table 3 by excluding the snow routine in the model structure the structure of the hbv model comprises of three main storage layers it essentially connects the water flow channel of these three water storages from precipitation in the surface soil layer to runoff estimation as the quick and slow simulation outputs the main parameters that govern the hbv model structure to represent the actual catchment responses are the field capacity fc the evapotranspiration limitation lp the water flowing up through the top soil layer due tocapillarityforce cflux the water flowing down to the unsaturated layer as a part of the naturalpercolationprocess perc the sub surface discharge coefficient kf groundwater discharge coefficient ks the sub surface discharge power coefficient α and the recharge and percolation power coefficient β these parameters are firmly interlinked and they define various hydroclimate variables inside the model zhang and lindstrom 1997 there are various ways of model parameter sampling from the lower and upper boundary of parameters which mainly depends on the number of parameters and computing times beven and binley 2014 stated that there is no static divide in parameter selecting and that it can vary from five thousand to a couple hundred thousand parameter samples in this study 30 000 parameter samples were generated from the model parameters range characteristics for high flow and low flows have different and need two parallel calibration techniques meresa and romanowicz 2017 meresa and romanowicz 2017 stated that the nash sutcliffe efficiency nse likelihood function is relatively useful for high flow simulation due to the interest in peak flow and logarithmic nash sutcliffe efficiency lognse for low flow similarly vormoor et al 2015 showed the impact of the hbv s hydrological model parameters instability on seasonal flood simulation they concluded that the parameter plays a significant role in changing the flood magnitude the nse objective function was used to simulate high flow regimes and was evaluated against observed streamflow based on the model performance 2000 sets of hydrological model simulations were selected as behavioural conditions 9 nse 1 t 1 j q o t q m t 2 t 1 j q o t q o 2 where qo t and qm t are observed and simulated flow at time t respectively qo is the mean observed flow and j is the length of the jth time series the best values of the nse are selected for parameter uncertainty analyses this study uses the generalized likelihood uncertainty estimation beven and binley 1992 to estimate the uncertainty associated with the hydrological parameters approach glue is a non formal statistical technique that includes the monte carlos simulations assume likelihood function h x to separate the non behavioural and behavioural simulations produced by the different variables x such as input data hydrological model parameters hydrological model structures and the extreme frequency models every ith variable x has its own likelihood measure at time t the ensemble of each variable xi i 1 m provides the multi likelihood measure values h xi 10 h x i 1 v e v o where ve is the estimated variance from the generated set and vo is observed variance from the observed set 3 4 flood frequency and magnitude estimation flood frequency analysis is vital to understanding the reoccurrence probability of peak flood at different return periods such information plays an critical role in extreme flood control design and water resource management and planning peak flow frequency primarily depends on the data length frequency distribution model type number of peak events and the number of distribution parameters in the last two decades depending on the hydroclimatic background many distribution types are deployed in several countries to estimate the frequencies of peak flow for example griffis and stedinger 2007 proposed log pearson iii distribution model in the usa and australia climate for infrastructure design refsgaard et al 2013 recommended the pearson type iii and general extreme value distribution types for europe climate meresa and gatachew 2018 confirmed that the gev and gamma distribution types are more fit to african hydroclimate and chen et al 2012 proposed to use wakeby and log normal distribution types for asian countries climate therefore the most used distribution type gev was applied for flood frequency and magnitude curve development similarly the maximum likelihood estimation mle method is more widely used than the probability weighted moment pwm and the l moment method lm in estimating the gev parameters rahman et al 2013 rahman et al 2014 therefore in this study the maximum likelihood method was used to estimate gev distribution parameters the distribution was fitted to peak flow to understand the changes and associated uncertainty in flood magnitude and frequency in the selected awash catchments in equation 11 the probability density function pdf is presented and it has three parameters 11 gev f x 1 α exp 1 k z 1 k 1 k z 1 1 k k 0 1 α exp z exp z k o where z x β α α is the scale parameter β location parameter and k is the shape parameter 3 5 uncertainty decomposition and estimation three main sources of uncertainty in peak flood projections were considered the climate models bias correction methods and hydrological parameters were estimated for their interaction using the variances decomposition approach anova n way of anova basically 3 way was used to disintegrate the effects of the main variable and their interaction component on the aggregated peak flow magnitude and frequency first the variance of the aggregated total sum standard error sst decomposed into three main effects sscm ssbc and sshp the squared deviations of single values from their respective factor mean which are effects directly attributable to climate models cms bias correction methods bcs and hydrological parameters hps respectively it can be further decomposed into three interaction terms sscmbc sscmhp and sshpbc the following equation can be written to represent sst 12 sst ss cm ss bc ss hp ss cmbc ss cmhp ss bchp e r r o r where sst is the total sum standard error sscm is the sum standard error of the climate models ssbc stands for the sum standard error of the bias correction methods sshp is these sum standard of hydrological parameters sscmbc is the sum standard error of the combined effect of climate models and bias correction methods sscmhp is the sum standard error of the combined effect of climate models and hydrological parameters and ssbchp is the sum standard error of the combined impact of climate bias correction methods and hydrological parameters 4 results 4 1 evaluation and validation of different climate bias correction techniques four statistical matrices were used to measure the accuracy and reliability of the 12 climate models to reproduce the daily seasonal and annual maximum time series of the observed precipitation and air temperature in the reference period 1981 2010 we chose the reference period only up to 2010 to coincide and keep the consistency with the previous studies and ipcc report ipcc 2021 fig s1 shows the comparison of the three bias correction techniques in correcting the seasonal mean precipitation obtained for the five catchments in the upper awash basin the bias correction techniques perform well and improved the reliability and accuracy of the climate models for future hydrological process simulation the performance measures show lower in the mae pwrmse and pbias values in almost all the climate models in reproducing observed seasonal precipitation for the selected catchments in general the statistical performance matrix values found were slightly different for each climate model the mae values vary in the ranges of 1 1 to 16 for seasonal mean precipitation the pbias values range from 25 to 25 the pwrmse values range from 0 to 1 3 and the rr values range from 0 to 0 75 in all the selected catchments relatively the bias correction methods performed better in s1 and s3 than s4 s2 and s5 due to their lower temporal climate variability fig 3 shows the comparison of the ensemble climate models and the three bias correction statistical techniques used for the simulation of monthly maximum precipitation average over each catchment the ensemble of climate models are represented by color bands single model shown as a straight line the observed monthly maximum precipitation is represented by a straight blue line for the period between 1981and 2010 overall the 12 gcms give a broader spread in the rainy season and a relatively narrow band of climate models in the dry season this indicates that the rainy season from the ensemble of the 12 climate models are highly exposed to uncertainty and a larger climate model discrepancy compared to the dry season the observed precipitation does not exceed the upper and lower limit of the spread of the 12 climate models in the reference period however the width of these 12 climate models mainly depends on the type of bias correction method the eqm method has relatively a narrower band spread than the other comparatively the dqm and sqf methods provided a wider range of climate model spreads for the s1 s2 and s3 catchments and a smaller ranger for the s4 and s5 catchments fig 3 this implies that the smaller range using dqm and sqf methods are more appropriate to capture the climate models temporal variability than the eqm method and the wider range leads to a higher uncertainty it significantly improved the raw precipitation by 30 50 during the rainy season in catchments s1 s2 and s3 therefore the linear eqm transformation mostly lacks in reproducing temporal variability of output precipitation values for the climate models this is due to the high influence of drizzle day precipitation characteristics overall the annual and seasonal cycle of maximum precipitation shows that the uncorrected climate models have a considerable bias due to inadequate knowledge of the mathematical representation and physical processes similarly the three bias correction techniques performance is not the same in reproducing the observed maximum precipitation across the chosen catchments the corrected monthly precipitation range band of the 12 climate models is smaller using empirical interpolation than distribution quantile mapping and using the statistical quantile factor this indicates that empirical interpolation is highly underestimated in both extremely high and drizzle day precipitation 4 2 air temperature and precipitation changes in the 21st century the future daily precipitation and air temperature was corrected using three bias correction methods and compared the changes in the 2040 2069 near future clim2 and 2070 2099 far future clim3 with respect to the reference ref 1981 2010 period the influence of each bias correction technique on the precipitation and temperature magnitude of change was assessed figs 4 5 fig 4 show the projected maximum precipitation under each climate scenarios for the ensemble of the 12 climate models for each time slices and bias corrected using sqf dqm eqm techniques most likely the annual maximum precipitation will be increased in the clim1 2010 2039 period and clim2 periods by all climate scenarios fig 4 however the individual climate models show a clear difference in simulation of the magnitude and direction of changes in annual maximum precipitation similarly changes from each bias correction technique showed a slight difference in magnitude in changing annual maximum precipitation for example in the catchments of awash koka and awash hombole a higher change in annual maximum precipitation in all the bias corrections is shown ranging from 10 to 150 the other catchments show a 10 to 80 change in extreme precipitation moreover the changes are smaller in the awash koka and awash bello catchments using the dqm methods whereas in akaki and kela the changes are smaller using eqm and dqm the climate change signals also indicate a higher change using the ssp585 scenario than the ssp370 and ssp126 scenario in all the catchments due to a higher emission radiation value interestingly a linear relationship exists between the annual maximum precipitation changes in 2040 2069 near future and 2070 2099 far future with proportional magnitude this indicates that the gradient of these changes in 2040 2069 near future and 2070 2099 far future is a positive trend fig 5 show the projected maximum air temperature under each climate scenarios for the ensemble of the 12 climate models for each time slices and bias corrected using sqf dqm eqm techniques the changes in air temperature in ethiopia is more stable with time and space meresa and getachew 2018 the projected air temperature from the cmip6 dataset and scenarios provides a reasonable air temperature change increasing by 1 9 3 5 c and they maintain relatively uniform results in the selected catchments fig 5 however the spreads of the selected climate models are more extensive in the awash koka and awash hombole catchments overall the projected air temperature has a positive change across all the catchments and scenarios and is continuously increasing in the future periods 4 3 hydrological modeling and parameter uncertainty evaluation conceptual hydrological model performance for africa catchments is not uniform across the selected basins due to physiographic and runoff intensity meresa and zhang 2021 meresa and gatachew 2018 the hbv hydrological parameter sets for each of nine hbv parameters had a sample size of 30 000 which were generated through uniform distributions therefore considering enough parameter samples is required to understand the role of hydrological parameters in this study therefore we used number of best hydrological simulation as cut off threshold out of 30 000 fig 6a shows the value of nse left and observations inside the 95 confidence interval ci right of using different number of best simulations out of the 30 000 samples the number of observations inside the 95 ci is increasing by lowering the nse value the lower the number of best simulation sample gives the lower of observations in the 95 ci similarly the performance of each catchment is not the same due to the sediment and physiographic factors and backwater effect in awash catchments akaki catchment shows relatively a lower performance with lower nse range in contrast awash koka shows higher nse but lower percent of number of observations inside the 95 ci relatively the difference in percent of observations inside the 95 is reasonably acceptable using the 300 best simulations and above 0 3 nse therefore for further hydrological parameter uncertainty investigation we used only 300 best simulations out of 30 000 samples the glue based hydrological parameter uncertainty method was adopted to simulate a possible ensemble of daily runoff and the runoff simulation ensembles with a value larger than the 0 3 nse threshold value and best 300 simulations was selected to separate the behavioural and non behavioural simulations the likelihood values which were greater than the nse threshold value of the hbv parameter sets were considered as behavioural beven and binley 2014 meresa and romanowicz 2017 fig 6b shows the comparison of seasonal maximum flow simulation results from the best parameter behavioral sets with its 95 and 5 confidence interval value and observations in the 1981 2010 period it indicated that the observed maximum seasonal flow falls mostly between the 95 and 5 confidence bands except in the awash koka catchment particularly the lower band is mostly exposed to seasonal peak flows in the dry season january february and march this indicates that the hbv conceptual model is not recommended for simulating seasonal low flow however the seasonal peak flow was well captured during the main rainy season of the basin 83 of the observed maximum flow time series fell under the shaded area confidence internally and there was a wide range of nse values 0 3 0 75 overall it is promising to use for climate change impact study 4 4 performance of hydrological model under different bias correction approaches the long term internal variability of the simulated flow dynamics from 1981 to 2100 are shown in fig 7 the x axis is the time in the year and the y axis is the seasonal maximum flow it is perceived that the primary rainy peak flow season is covered by a yellow color called ethiopian kiremt season which is mainly june july and august for each station the maximum flow during rainy seasons has increased noticeably since 2010 there is a relatively strong increasing trend in annual and seasonal flow in the awash koka catchment compared to the akaki catchment overall the seasonal and annual projected maximum flow temporal trend shows that the peak flow increased for the coming three periods 2040 2069 and 2070 2099 this increase appears to be more substantial during the summer season with a mean peak flow increasing from 60 m3 s to 70 m3 s also the projected seasonal flows seem to be smoothed during the winter and late autumn seasons with a mean peak flow of about 35 m3 s furthermore the future conditions show an inevitable monthly variability from about 25 m3 s in may to 55 m3 s in october and november fig 7 similarly the spatial variability of mean peak flow during summer is also visible the mean flow increasing from 85 m3 s to 100 m3 s at hombole and varying from 20 m3 s to 30 m3 s at kela the changes in peak flow simulations that forced using corrected climate variables have been compared and presented in fig 8 overall it noted positive future changes in both clim2 and clim3 periods in annual maximum flow using dqm 10 eqm 17 and sqf 23 in the awash koka catchment however there is a slight difference among these bias correction techniques for example the sqf shows a smaller change in peak flow in the awash bello 12 and awash hombole 16 catchments whereas catchment awash koka 23 and akaki 35 shows a higher change in peak flow generally the magnitude of the annual maximum flow changes is not the same however these are not uniform across the selected catchments bias correction methods and climate scenarios the empirical quantile mapping method give smaller changes in peak flow whilst the dqm and sqf show a higher change in peak flow this indicates that the wet day frequency correction considered in the dqm method is important in understanding the future peak flow projections mainly the peak flow changes using the eqm give a smaller spread range and uncertainty across the selected catchments except in s4 interestingly noted that the peak flow changes have a smaller uncertainty size of the box in ssp370 and higher uncertainty in ssp126 and ssp585 scenarios fig 8 therefore correcting the wet days and precipitation intensity may significantly change the magnitude and direction to ultimately minimize the uncertainty due to bias correction methods overall s5 has a higher change in peak flow in the future whereas s4 using sqf has shown lower change than dqm and eqm similarly s3 has lower change in peak flow using sqf than dqm and eqm therefore difficult to conclude that one particular technique is overestimated or underestimate the peak flow in the future across all the catchment samples this implies that the techniques are comparable and their performance is not uniform across the catchments and climate sceneries therefore the magnitude of changes was varied with type of bias correction methods catchments climate scenarios and time slices 4 5 flood hazard projections under varying climate conditions the best fitted distribution model to annual maximum flow was chosen for each catchment and climate model with the best distribution being selected based on the akaike information criteria aic table 4 from table 4 it is noticed that the gev gamma and weibull distributions are the most dominant distribution types the projected annual maximum series has different distribution characteristics resulting from different flood magnitude and risk levels of which the three most prevalent and best fitted distribution models have similar probability density functions pdf using the most dominant frequency model gev the peak flood quantile changes under climate change have been estimated fig 9 shows peak flow quantile changes in clim1 2010 2039 clim2 2040 2069 and clim3 2070 2099 with respect to the reference period estimated using an ensemble of the 12 gcms and the three bias correction methods the ensemble average of the 12 climate models for each of the three scenarios assessed and the three bias correction methods in the five catchments show a significant increase in flood quantile magnitudes and frequency in the future fig 9 mostly the changes in flood quantiles are consistent with changes in peak flow due to its direct relationship to building the probability distribution function however the changes in the magnitude in the flood quantiles and peak flow are not a one to one relationship in all the catchments the changes in peak flow are higher than their respective change in flood quantiles at a return period of 50 years at s4 and s5 whereas at s1 s2 and s3 there are proportional changes in magnitude the future flood quantile changes are not the same in space and bias correction methods and the frequency of the larger return period flood increases to higher than once in 20 years the smallest changes in the 50 year quantile magnitudes are seen in the awash koka catchment using the eqm 55 the awash bello catchment using the sqf 40 and the awash hombola catchment using the dqm 75 relatively the methods show a consistently in the akaki and kelo catchments in providing information about peak flood quantile changes in the future furthermore the different hydroclimatic conditions were reflected in the flood quantile changes at different return periods for example the awash koka catchment has a peak flow quantile change range from 0 to 100 using the eqm but using the dqm method the changes range from 0 to 170 similarly the changes in the awash hombole catchment range from 0 to 100 using the dqm but 0 200 using the eqm therefore in addition to the hydrological parameters and climate model uncertainties the bias correction techniques also play a significant role in peak flow magnitude 4 6 uncertainty estimation and decomposition of associated sources in flood estimation fig 10 shows the primary sources of uncertainty hydrological parameter sets climate models and bias correction methods and their respective bands at specific return periods and catchments it considers the main factors interdependence using anova the contribution of individual sources of uncertainty and their interaction contribution to the flood magnitude and frequency changes in the future the decomposition of source uncertainty from the main variables and their interactions were separated based on the variance in flood values calculated out of 100 meaning the sum of all the sources is 100 the role hydrological parameter sets play in flood projection is not substantially changed the magnitude of peak flood and less uncertain in the chosen catchments in comparison the climate change variability and discrepancy show a considerable uncertainty and impact on the projection of floods this may be due to the projected precipitation intensity higher temperature and the time of concentration in the area on the other side the contribution of hydrological parameter sets is not significant in flood estimation floods are not dominated by hydrological processes like ground and interflow fig 10 in general the dominant source of uncertainty in this cascade peak flow projection modelling is with the climate models whereas the uncertainty related to hydrological parameter sets is not significant in future flood design value estimation furthermore the share of climate models frequency distributions and bias correction are significant in design flow estimation at a 100 year return period the magnitude of the uncertainty has a significant impact on the flood risk management plan and adaptation strategies for example in the awash koka catchments future flood risk management is highly uncertain due to climate model discrepancy and variability and their respective bias correction methods comparatively in the akaki catchment the climate model variability plays a major role in the reliability and accuracy of future flood risk management therefore the higher uncertainty source in peak flood projection might lead to having more impact on hydraulic infrastructure stability in the future due to climate change 5 discussion 5 1 future flood hazard the impact of climate change on peak floods was evaluated through the gev distribution model the peak flood quantiles in the reference and future period simulations of each catchment were calculated from 12 climate models gcms for each of the catchment various distribution types are commonly used in the us europe and africa kay et al 2009 collet et al 2017 meresa romanowicz 2017 meresa gatachew 2018 lawrence 2020 in this study many numerical experiments were performed by fitting the frequency distribution model to the annual maximum flow time series then based on the majority rule principle the most dominant flood frequency model was selected for flood estimation the estimated magnitude of peak flow quantiles at different return periods using the gev distribution with maximum likelihood parameter estimation method are not the same in magnitude and uncertainty band across all the catchments and climate models each climate model at each different catchment gives a very wide range of flood quantile values overall smaller flood quantiles were observed in the s3 catchment whereas the highest was estimated from the s1 and s4 catchments the estimated quantiles total range is relatively smaller in the s3 and s2 catchments whereas the highest uncertainty range is estimated in the s4 and s1 catchments moreover the changes in flood quantile values are not the same significance difference across the catchment and type of bias correction methods for example in the s2 and s3 catchments the flood quantiles at different return periods are expected to be larger in the near far and very far future in comparison the changes in peak flow are higher in the s1 and s4 catchments and they are expected to be more higher in the very far future period this is mainly due to the magnitude of flood events and its distribution in the given period keast ellison 2013 5 2 projected flood associated uncertainty estimation and decomposition in this study 12 climate models from the new dataset three bias correction methods the hbv hydrological model with 30 000 parameter sets and the gev flood frequency model was used to analyze the impact of future floods in the five chosen awash catchments the associated uncertainty was estimated and the climate models were highly uncertain in characterizing the future climate variables in the last few decades various studies concluded that the rcp and sres climate scenarios outputs are very weak in reproducing the historical extreme climate fowler et al 2007 saini et al 2015 this uncertainty may be due to the structure parametrization and spatial resolution of the gcms using multiple models in climate change impact analysis would lead to an improved understanding of the uncertainty associated with climate models it is essential in flood risk and water resource management the multiple climate models were evaluated for flood projection in the awash basin and it was found that the spread of climate models impact is significant there is also an important uncertainty component that is associated with the climate bias correction methods the catchment scale characteristics are not the same as the gcms spatial and temporal characteristics therefore it is essential to use highly relevant climate bias correction techniques to understand and minimize the uncertainty the three bias correction techniques were effectively corrected in the historical period and then the parameters were adopted for future climate corrections there are few studies related to flood frequency and bias correction method uncertainties kay et al 2009 saini et al 2015 meresa and romanowicz 2017 soriano et al 2019 however the preexisting studies that do exist found that the climate bias correction could alter the magnitude of the flood this study also confirmed this using three climate bias correction methods and the gcms from the cmip6 in ethiopia s selected catchments it was found that that the uncertainty associated to wet days and the intensity of precipitation has a significant impact on the flood magnitude e g s4 catchment the hydrological model parameters with its structure represent the hydrological full process the hydrological parameters govern the flow from of the source of rain to the deep catchment infiltration and percolation in this work more sensitive parameter sets of the hbv hydrological model were selected using the nse objective function values with 0 3 as a threshold glue was applied to identify the role of hydrological parameters in peak flood quantile estimation in the chosen catchments this was performed by using a hypercubic sampling approach from the given hbv parameter ranges the ranges of the hbv were procured from meresa gatachew 2019 the simulated flow in the historical period is relatively good for mean and high flow simulation the simulated band width does not significantly increase by changing the threshold for peak flow simulation generally the uncertainty due to model parameter changes is not significant in flood quantile estimation the finds confirmed that the role of model parameter sets is less in all the chosen catchments similarly yan et al 2015 meresa romanowicz 2017 joseph et al 2018b appear with a similar conclusion that high flow is less sensitive to hydrological parameters the uncertainty related to flood frequency under climate change is not extensively investigated and it has been very challenging to integrate with other sources of uncertainties each peak flow extracted from each climate model and bias corrected simulations were fitted to most of the dominant frequency model several researchers have conducted flood frequency analysis and they concluded that the extreme value ev and gev distribution models are the most repetitively used distribution models in the awash catchments ahilan et al 2012 tegegne et al 2020 similarly the numerical experiment results from this study confirmed that the gev is the most dominant model for all the climate models and selected catchments however the uncertainty band from frequency models is not significant in the chosen catchments therefore the uncertainty of the flood distribution models in these catchments is avoidably due to smaller differences in the hydro climate projections overall the results should be considered with care because the probability of extreme peak flow recurrence in the selected catchments is becoming more frequent and intense in the near and far future periods 6 conclusions this study focuses on disentangling uncertainty sources in future floods and developed a comprehensive framework to fit this purpose the proposed framework was tested in five awash catchments in ethiopia a region exposed to extreme flood risk the findings clearly show that hydrological model parameters the spread of climate models and bias correction techniques are not equally important sources of uncertainty in flood estimation in particular the climate models and bias correction methods are the most substantial sources of uncertainty in future flood frequency and magnitude estimation our results show that the impacts of climate change on peak floods magnitude and frequency are substantial resulting in an increased both magnitude and occurrence of peak floods in the selected awash river the disentangling a source of uncertainty in future peak flow estimation was performed based on the aggregated variance in changes of peak flood value at q20 flood event at a 20 year return period q50 flood event at a 50 year return period and q100 flood event at a 100 year return period the results confirm that climate change is the dominant factor in peak flow frequency in the awash koka and akaki catchments whereas in the kela catchment it is bias correction and in the awash bello catchment it is the distribution type anova also confirms that the contribution of their interactions is significant the contribution of climate models and bias correction methods with their interaction is incredibly substantial and nonnegligible in flood estimation uncertainty in the hydrological model parameters is not substantially change the magnitude and frequency of peak flood and thus there is no need to routinely take account of this uncertainty into water resource management and flood risk management studies however the findings of this study confirmed that the uncertainty associated with climate models can result a significant change in water infrastructure design and flood risk management and must considered this uncertainty into peak flood magnitude and frequency study similarly the uncertainty associated with bias correction methods may lead into a reasonably similar range of peak flood uncertainty arising from climate models however more importantly the climate models discrepancy results in a considerable shift in the magnitude of future peak flood as well as the range of the models the findings reveal that peak flood risks would noticeably increase in the near and far future in all catchments in awash located in the tropical dry region therefore the awash authority and national and local stakeholders must take certain non structural structural measures to mitigate flood risks in the future and to adapt to future climate flood risk management and policies need to consider these main factors and their management policy interaction however the value range of each source is large and challenging to communicate with decision makers and stakeholders therefore it is strongly recommended to consider using each factor spread and their median values for future flood risk management and take as basic information on extreme flood risk adaptation and mitigation measures declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is supported by the cas pioneer talents program the cas president s international fellowship initiative pifi project no 2020pe0048 and the national natural science foundation of china grant no 41971032 the authors would like to thank both the ethiopian meteorology agency and the ministry of irrigation and water resources for providing hydrometeorological data the data contributed greatly to advancing hydrological sciences by sharing their long time series data data availability statement both the observed meteorological and hydrological data were acquired from the meteorological agency and the water resource ministry of ethiopia respectively the data is available on request from the corresponding organizations but it is not publicly available due to the privacy and ethical restrictions of the ethiopian organizations author contributions hadush meresa and yongqiang zhang designed the research analyzed the results and wrote the initial version hadush meresa conducted modelling and plotting all authors contributed to paper revisions and result interpretations appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128426 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
2969,evaluation of peak flood magnitude and frequency in the future at a catchment scale under global warming is crucial for water resource management and flood risk management climate model outputs provide a leading source of information to quantify the effect of the foreseen natural and anthropogenic climate change on the environment and natural systems however modelling climate change impact on peak flow is subject to considerable uncertainties from the climate model discrepancies bias correction methods and hydrological model parameters this study develops a framework to examine changes and disentangle uncertainties in peak flow which is tested at five awash catchments in ethiopia a region exposed to extreme flood risk the results showed that projected extreme precipitation and peak flow magnitude could increase substantially in the coming decades by 30 to 55 the uncertainty analysis confirms that the dominant factor in peak flood projection is climate models in catchments like akaki 55 and awash h 51 but the bias correction methods in awash b 58 and kela 50 respectively the least important factor is the hydrological parameter set for flood projections moreover the findings reveal that peak flood risks would noticeably increase in the near and far future in all catchments in awash located in the tropical dry region therefore various state water agencies from local to national scales must take certain non structural structural measures to mitigate flood risks in the future and to adapt to future climate keywords uncertainty projection flood climate change model bias correction data availability no data was used for the research described in the article 1 introduction climate change will likely become one of the primary problems affecting extreme hydrological regimes and water resource quantity and availability in the coming decades significant changes in atmospheric temperature and precipitation are expected resulting in increased extreme events including floods and heavy rainfall with intensive socio economics disasters knutti sedláček 2013 ipcc 2013 serdeczny et al 2016 rojas et al 2013 serdeczny et al 2016 documented that african flood magnitude frequency pattern and timing are shifting due to climate change and its consequences are not uniform across the region in ethiopia summer peak flows are significantly increasing due to climate change which leads to floods in contrast increasing air temperature in the autumn and winter seasons lead to increased drought frequency due to the increasing evapotranspiration coulibaly et al 2020 thober et al 2018 balke nilsson 2019 tariku et al 2021 understanding catchment scale flood projections is crucial for water resource planning and flood risk management however it is challenging to quantify its impact at different modeling stages that possess such as downscaling the gcms rcms to catchment scale the projection of hydrological extremes using the bias corrected climate variables the estimation of the impact of climate change on design flow values at different return periods and the quantification of associated uncertainties the impacts of climate change on the local extreme hydrological extremes are uncertain and complicated meresa and zhang 2021 joseph et al 2018a joseph et al 2018b wang et al 2019 osman et al 2019 byun et al 2019 wang et al 2019 gao et al 2020 her et al 2019 hattermann et al 2017 meresa and romanowicz 2017 studied the critical uncertainty embedded hydrological parameter uncertainty hydrologiska byråns vattenbalansavdelning hbv climate models representative concentration pathway rcp and the distribution parameter uncertainty generalized extreme value gev in the projection of hydrological extremes they then addressed that regional impact studies are highly prone to climate model chain errors joseph et al 2018 also considered hydrological parameters variable infiltration capacity vic and pathways rcp for uncertainty assessment in seasonal flow projections soriano et al 2019 evaluated the uncertainty of bias correction methods on flood frequency and found that the climate model s biases had a significant change in the magnitude of flood design values therefore the changes in peak flow due to discrepancies in the climate model evaluation are associated with various sources of uncertainties thus it is crucial to estimate and understand its complex and uncertain impact and to identify the main sources of uncertainty in future flood risk and extremes management in the last decades various climate scenarios like series report emission scenarios sres representative concentration pathways rcp and shared socio economic pathways ssp along with several regional climate models global climate models rcms gcms have been deployed under different atmospheric land physical formulations therefore the projected hydrological extremes at the local scale are highly dependent on the spreads of the rcms gcms romanowicz et al 2016 meresa and romanowicz 2017 hattermann et al 2017 charles et al 2019 meresa 2020 lawrence 2020 the information from multiple rcms gcms and their discrepancies are considered uncertain and can be estimated using the variance of the climate models lawrence 2020 meresa and zhang 2021 imprecise probability aven 2020 the probabilistic combination technique das et al 2017 and the variance of the error between the observed and each climate model approach eghdamirad et al 2019 this study focused on the uncertainty of the climate model s interpretation and other factors e g bias correction were not explored in detail bias correction methods have a significant impact on the projected hydrological extremes frequency magnitude and direction hattermann et al 2017 charles et al 2019 nowadays many researchers have been addressed the importance of climate bias correction techniques kay et al 2009 meresa and gatachew 2018 saini et al 2015 soriano et al 2019 empirical mapping quantile mapping simple statistical transformation and joint probability are the most popular and widely applied bias correction techniques for climate model bias correction these techniques help to reduce the original climate model variability and outliers the primary source of uncertainty in climate projection can be explained by the selection of bias correction techniques and the spread of selected climate models besides bias correction techniques it is also challenging to obtain the most representative hydrological model parameter sets in space and time in the projection of hydrological extremes the combination of the hydrological parameters play a significant role in minimizing the uncertainty related to catchment hydrology pechlivanidis et al 2017 joseph et al 2018a joseph et al 2018b her et al 2019 many studies attempt to address the uncertainty of the hydrological parameters in climate change impact studies by using generalized likelihood uncertainty estimation glue beven binley 1992 the multi objective function optimization approach dakhlaoui et al 2017 zhang et al 2019 and bayesian model averaging beigi et al 2019 similarly the flood frequency associated uncertainty is also essential collet et al 2017 and lawrence 2020 found that the flood frequency distribution models are highly dependent on the distribution of extreme floods the number of events and the size and shape of the catchment therefore significant efforts have been put to evaluate climate change impacts on extreme hydrology primarily focusing on low flow and high flow magnitude and trend analysis with their associated uncertainty estimation however there is little attention to uncertainty and impact estimation in projected peak flows this study develops a comprehensive framework for the uncertainty and impact estimation of climate change on peak flow the main objectives of this study include i comparing different bias correction techniques for climate change impact assessment ii estimating the role of hbv hydrological model parameters iii evaluating the impact and role of climate change and bias correction approach on flood projections and iv identifying the source of uncertainty associated with projected peak flows 2 observed and projected hydro climate datasets and description of study area 2 1 observed hydrometeorological data and description of study area five sub catchments were chosen for the climate change impact assessment in the upper awash river basin we used 47 meteorological and five hydrological gauged stations an areal precipitation was calculated based on the thiessen polygon method and using these 47 meteorological stations the green dot point in fig 1 indicates the geographical location of all these 47 meteorological stations listed in table s1 they are located in different hydro climatic and geographical conditions table 1 and fig 1 the awash k at u s of koka akaki at aba s kela at welen awash b at bello and awash h at melka h catchments best represent peak flood estimation under the influence of climate change these selected catchments have drainage areas ranging from 67 5 km2 at welen to 7093 9 km2 u s of koka and their elevation varies from 1602 m u s of koka to 2300 m at melka h the historical daily precipitation temperature and streamflow data records were taken from the ethiopian meteorological and hydrological institute from 1981 to 2010 the annual maximum flow varies from 81 12 m3 s at welen to 883 93 m3 s at u s of koka representing different watershed drainage area simultaneously the annual maximum precipitation or the upper 5 of annual precipitation is not proportional with watershed drainage area and annual maximum flow lastly the high mean of surface runoff is directly related to the high coefficient of variance in river flow at u s of koka table 1 2 2 coupled model intercomparison project phase 6 cmip6 cmip6 is a new climate dataset https pcmdi llnl gov cmip6 that was released by a collaborative effort from different climate research institutes to advance climate change knowledge and applicability the daily time scale of precipitation and air temperature time series from the cmip6 simulation datasets https esgf node llnl gov search cmip6 were used for impact estimation the climate model s output covers the period from 1981 to 2100 and provides global regional scale spatial resolution varying from 50 to 250 km in this study three cmip6 scenarios shared socioeconomic pathways ssps 585 high level 370 medium level and 126 low level with 12 climate models each were used to assess the projected flood s uncertainty with their respective impact in the selected awash catchments see table 2 for climate model name and model details each grid data of daily temperature and precipitation time series was extracted from the gridded data overlaying the catchment centroid point the 12 climate models is selected based on the relatively good climate model resolution adequate data availability from 1981 to 2100 and satisfactory model discrepancy this includes three criteria first we selected gcms with less than or equal to 250 km resolution and data length from 1981 to 2100 second we evaluated the ability of gcms uncorrected gcm output in reproducing the observed climate signal finally we used the 12 selected gcms for further investigation these earth system models cmip6 can capture the variability and seasonality of precipitation and temperature better than those with a high resolution almazroui et al 2019 3 modeling and numerical experiments a framework for quantifying the uncertainty and respective impacts of projected peak flow comprising four stages of cascade modeling was developed the framework starts by selecting most representative catchments natural and or semi natural and then extracting rectifying and evaluating climate time series variables obtained from the cmip6 archive this is done with three bias correction methods distribution quantile mapping dqm empirical quantile mapping eqm and statistical quantile factor sqf a sampling of 30 000 hydrological model parameters was taken using monte carlos simulation mcs for hydrological parameter uncertainty estimation by using the generalized likelihood uncertainty estimation glue approach beven binley 1992 then the generalized extreme value gev frequency distribution model was applied to estimate the frequency and magnitude of peak flow values fig 2 lastly the flood quantiles estimated at rt 20 50 and 100 years were compared by calculating relative differences between future simulated and reference quantiles the rt 20 50 100 years quantiles represent short medium and long quantile values in climate change impact studies furthermore the different sources of uncertainty were also compared based on the magnitude and frequency of these estimates by aggregated values in the range between the upper 95 and lower 5 confidence interval 3 1 bias correction techniques global regional climate models are essential for enlightening our understanding of annual seasonal and daily precipitation as well as air temperature characteristics these climate models are a complex and dynamic mathematical representation of the physical process of atmospheric land ocean interaction results in all the climate models exhibit biases in their outputs giorgi gao 2018 krinner flanner 2018 making it challenging to develop accurate and reliable climate information some studies have confirmed the need for climate model outputs post processing before its routine in hydrological extremes projections ehret et al 2012 teng et al 2012 meresa and romanowicz 2017 however reducing the bias in the gcm rcms model output is still a big problem and challenge there is a problem in developing a vigorous climate bias correction technique that minimizes the biases between the simulated and observed climate signals in the reference period several studies used different bias correction approaches in different hydroclimate regimes and have shown mixed performance results the performance of each bias correction technique is mainly depending on the precipitation characteristics and rainfall regime for example one bias correction technique can be performed good in africa climate but not necessary performed well in european climate for instance teutschbein seibert 2013 and yang et al 2010 showed that quantile mapping based bias correction technique was perform better than theoretical distribution mapping local transformation and change factor techniques similarly berg et al 2012 and chen et al 2013 documented that theoretical distribution mapping performs marginally better than or similar to empirical quantile or other statistical methods on the contrary gudmundsson et al 2012 and lafon et al 2013 concluded that empirical quantile reveals better performance than theoretical distribution technique in systematically correcting daily precipitation in this study three climate bias techniques were used to correct the raw climate output and to examine the contribution of bias correction techniques to the peak flood frequency and magnitude 3 1 1 statistical quantile factor sqf in this study a new bias correction method was developed and compared with the commonly used methods distribution quantile mapping and empirical quantile mapping the statistical quantile factor technique sqf is a straightforward approach that helps to reduces the bias in climate models the approach considered a simple error estimation between the observed and simulated climate variables in the reference period and then transfer the error from the reference to a future period the general procedure involves correcting the future precipitation p fut c o r r by multiplying the average reciprocal ratio of the observed precipitation p obs and the reference precipitation simulation p ref r a w to the raw climate model precipitation p fur r a w whereas for correcting future daily air temperature t fut c o r r it is by adding up the difference between the observed air temperature t obs and the simulated daily raw air temperature simulated at reference period t ref r a w to the raw climate output t fur r a w 1 p fut c o r r p fur r a w 2 p obs p ref r a w p ref r a w p obs 2 t fut c o r r t fur r a w m i n t obs t ref r a w 2 2 in this new mathematical equation it is assumed that the future precipitation characteristics not only depend on the slope of the reference period hawkins et al 2013 but also on the future climate condition this helps to consider fully the temporal dynamics of the precipitation series in the daily air temperature correction 2 2 c was used as a threshold to correct the future projections tropical temperature which is more reasonable for africa compared to the global increment of 1 5 c ipcc 2021 3 1 2 distribution quantile mapping dqm distribution quantile mapping is a parameter bias correction technique that depends on the type of distribution fitted to the observed and simulated climate data piani et al 2010 this distribution based approach can be single or double distribution quantile mapping s dqm or other distributions the excess number of dry days drizzles and wet days were considered and properly corrected in this method for every n year the zero precipitation values were excluded before the single gamma distribution is fitted to the upper 75 of daily precipitation in contrast the double gamma distribution is fitted to both the upper and lower parts of the 75 of daily precipitation 3 p corr f dg 1 f dg p raw t α raw β raw α obs β obs 4 t corr f dn 1 f dn t raw t σ raw μ raw σ obs β μ obs where pcorr and tcorr represent the bias corrected daily precipitation and temperature respectively likewise p raw and t raw represent the raw climate output for daily precipitation and air temperature respectively the raw climate output inverse cumulative density is represented by fdg and fdn for precipitation and temperature respectively the dn and dg subscripts stand for the normal for temperature and gamma for precipitation distributions the gamma distributions with two parameters shape α and scale β was used to correct the wet dry spell of precipitation characteristics similarly the normal distributions with two parameters standard deviation σ and mean μ was used to correct the seasonal temperature characteristics 3 1 3 empirical quantile mapping unlike the distribution mapping approach empirical quantile mapping is based on a paired wise comparison between the empirical cumulative density function ecdf of the observed and simulated precipitation at the reference period from 1981 to 2010 this is purely empirical and is a direct matching of the histogram quantiles of the observed to the raw climate precipitation or temperature in the reference period the future precipitation and temperature are corrected using the inverse of ecdf ecdf 1 and fitted ecdf 5 p hst cor ecdf obs 1 ecdf hst p hst 6 t hst cor ecdf obs 1 ecdf hst t hst where pcor hst and tcor hst stand for the corrected precipitation and temperature respectively likewise phst and thst stand for the raw climate model output uncorrected precipitation and temperature respectively lastly the obs subscript stands for the observed temperature and precipitation 3 2 bias correction performance evaluation the performance of the chosen bias correction technique was assessed using four statistical measures percent of bias pbias correlation coefficient rr root mean square error rmse mean absolute error mae and maximum weighting root means square error mwrmse these statistical measures were used to evaluate the daily precipitation and air temperature data of climate model output with respect to observed climate data in the reference period the performance of each bias correction techniques were evaluated their capacity in reproducing the observed maximum time series of precipitation and temperature 7 rr p s p s p c p c p s p s 2 p c p c 2 a n d m a e i 1 n p s p c n 8 pbias i 1 n p s p c i 1 n p s a n d p w r m s e i 1 n p s p c 2 p s p s p s n 0 5 where ps is the observed precipitation at a given station pc is the corrected precipitation and n is the number of observations a similar performance criterion was also used for daily air temperature bias correction methods 3 3 hydrological modelling parameter selection and evaluation the hydrologiska byråns vattenbalansavdelning hbv bergström 1981 is a lumped conceptual hydrological model and is applied in different hydro climate conditions around the world meresa and zhang 2021 her et al 2019 meresa gatachew 2018 hbv is primarily designed to simulate daily streamflow using daily precipitation daily air temperature and evapotranspiration estimated using hamon 1964 these climate variables are used as primary inputs to the model in this study the hbv with nine parameters was used table 3 and the snow routing storage was excluded from the original hbv model structure this model structure has three consecutive stores one related to the surface the second associated with the saturated soil layer and the other to the unsaturated routing store the upper and lower limits of the hydrological model are listed in table 3 by excluding the snow routine in the model structure the structure of the hbv model comprises of three main storage layers it essentially connects the water flow channel of these three water storages from precipitation in the surface soil layer to runoff estimation as the quick and slow simulation outputs the main parameters that govern the hbv model structure to represent the actual catchment responses are the field capacity fc the evapotranspiration limitation lp the water flowing up through the top soil layer due tocapillarityforce cflux the water flowing down to the unsaturated layer as a part of the naturalpercolationprocess perc the sub surface discharge coefficient kf groundwater discharge coefficient ks the sub surface discharge power coefficient α and the recharge and percolation power coefficient β these parameters are firmly interlinked and they define various hydroclimate variables inside the model zhang and lindstrom 1997 there are various ways of model parameter sampling from the lower and upper boundary of parameters which mainly depends on the number of parameters and computing times beven and binley 2014 stated that there is no static divide in parameter selecting and that it can vary from five thousand to a couple hundred thousand parameter samples in this study 30 000 parameter samples were generated from the model parameters range characteristics for high flow and low flows have different and need two parallel calibration techniques meresa and romanowicz 2017 meresa and romanowicz 2017 stated that the nash sutcliffe efficiency nse likelihood function is relatively useful for high flow simulation due to the interest in peak flow and logarithmic nash sutcliffe efficiency lognse for low flow similarly vormoor et al 2015 showed the impact of the hbv s hydrological model parameters instability on seasonal flood simulation they concluded that the parameter plays a significant role in changing the flood magnitude the nse objective function was used to simulate high flow regimes and was evaluated against observed streamflow based on the model performance 2000 sets of hydrological model simulations were selected as behavioural conditions 9 nse 1 t 1 j q o t q m t 2 t 1 j q o t q o 2 where qo t and qm t are observed and simulated flow at time t respectively qo is the mean observed flow and j is the length of the jth time series the best values of the nse are selected for parameter uncertainty analyses this study uses the generalized likelihood uncertainty estimation beven and binley 1992 to estimate the uncertainty associated with the hydrological parameters approach glue is a non formal statistical technique that includes the monte carlos simulations assume likelihood function h x to separate the non behavioural and behavioural simulations produced by the different variables x such as input data hydrological model parameters hydrological model structures and the extreme frequency models every ith variable x has its own likelihood measure at time t the ensemble of each variable xi i 1 m provides the multi likelihood measure values h xi 10 h x i 1 v e v o where ve is the estimated variance from the generated set and vo is observed variance from the observed set 3 4 flood frequency and magnitude estimation flood frequency analysis is vital to understanding the reoccurrence probability of peak flood at different return periods such information plays an critical role in extreme flood control design and water resource management and planning peak flow frequency primarily depends on the data length frequency distribution model type number of peak events and the number of distribution parameters in the last two decades depending on the hydroclimatic background many distribution types are deployed in several countries to estimate the frequencies of peak flow for example griffis and stedinger 2007 proposed log pearson iii distribution model in the usa and australia climate for infrastructure design refsgaard et al 2013 recommended the pearson type iii and general extreme value distribution types for europe climate meresa and gatachew 2018 confirmed that the gev and gamma distribution types are more fit to african hydroclimate and chen et al 2012 proposed to use wakeby and log normal distribution types for asian countries climate therefore the most used distribution type gev was applied for flood frequency and magnitude curve development similarly the maximum likelihood estimation mle method is more widely used than the probability weighted moment pwm and the l moment method lm in estimating the gev parameters rahman et al 2013 rahman et al 2014 therefore in this study the maximum likelihood method was used to estimate gev distribution parameters the distribution was fitted to peak flow to understand the changes and associated uncertainty in flood magnitude and frequency in the selected awash catchments in equation 11 the probability density function pdf is presented and it has three parameters 11 gev f x 1 α exp 1 k z 1 k 1 k z 1 1 k k 0 1 α exp z exp z k o where z x β α α is the scale parameter β location parameter and k is the shape parameter 3 5 uncertainty decomposition and estimation three main sources of uncertainty in peak flood projections were considered the climate models bias correction methods and hydrological parameters were estimated for their interaction using the variances decomposition approach anova n way of anova basically 3 way was used to disintegrate the effects of the main variable and their interaction component on the aggregated peak flow magnitude and frequency first the variance of the aggregated total sum standard error sst decomposed into three main effects sscm ssbc and sshp the squared deviations of single values from their respective factor mean which are effects directly attributable to climate models cms bias correction methods bcs and hydrological parameters hps respectively it can be further decomposed into three interaction terms sscmbc sscmhp and sshpbc the following equation can be written to represent sst 12 sst ss cm ss bc ss hp ss cmbc ss cmhp ss bchp e r r o r where sst is the total sum standard error sscm is the sum standard error of the climate models ssbc stands for the sum standard error of the bias correction methods sshp is these sum standard of hydrological parameters sscmbc is the sum standard error of the combined effect of climate models and bias correction methods sscmhp is the sum standard error of the combined effect of climate models and hydrological parameters and ssbchp is the sum standard error of the combined impact of climate bias correction methods and hydrological parameters 4 results 4 1 evaluation and validation of different climate bias correction techniques four statistical matrices were used to measure the accuracy and reliability of the 12 climate models to reproduce the daily seasonal and annual maximum time series of the observed precipitation and air temperature in the reference period 1981 2010 we chose the reference period only up to 2010 to coincide and keep the consistency with the previous studies and ipcc report ipcc 2021 fig s1 shows the comparison of the three bias correction techniques in correcting the seasonal mean precipitation obtained for the five catchments in the upper awash basin the bias correction techniques perform well and improved the reliability and accuracy of the climate models for future hydrological process simulation the performance measures show lower in the mae pwrmse and pbias values in almost all the climate models in reproducing observed seasonal precipitation for the selected catchments in general the statistical performance matrix values found were slightly different for each climate model the mae values vary in the ranges of 1 1 to 16 for seasonal mean precipitation the pbias values range from 25 to 25 the pwrmse values range from 0 to 1 3 and the rr values range from 0 to 0 75 in all the selected catchments relatively the bias correction methods performed better in s1 and s3 than s4 s2 and s5 due to their lower temporal climate variability fig 3 shows the comparison of the ensemble climate models and the three bias correction statistical techniques used for the simulation of monthly maximum precipitation average over each catchment the ensemble of climate models are represented by color bands single model shown as a straight line the observed monthly maximum precipitation is represented by a straight blue line for the period between 1981and 2010 overall the 12 gcms give a broader spread in the rainy season and a relatively narrow band of climate models in the dry season this indicates that the rainy season from the ensemble of the 12 climate models are highly exposed to uncertainty and a larger climate model discrepancy compared to the dry season the observed precipitation does not exceed the upper and lower limit of the spread of the 12 climate models in the reference period however the width of these 12 climate models mainly depends on the type of bias correction method the eqm method has relatively a narrower band spread than the other comparatively the dqm and sqf methods provided a wider range of climate model spreads for the s1 s2 and s3 catchments and a smaller ranger for the s4 and s5 catchments fig 3 this implies that the smaller range using dqm and sqf methods are more appropriate to capture the climate models temporal variability than the eqm method and the wider range leads to a higher uncertainty it significantly improved the raw precipitation by 30 50 during the rainy season in catchments s1 s2 and s3 therefore the linear eqm transformation mostly lacks in reproducing temporal variability of output precipitation values for the climate models this is due to the high influence of drizzle day precipitation characteristics overall the annual and seasonal cycle of maximum precipitation shows that the uncorrected climate models have a considerable bias due to inadequate knowledge of the mathematical representation and physical processes similarly the three bias correction techniques performance is not the same in reproducing the observed maximum precipitation across the chosen catchments the corrected monthly precipitation range band of the 12 climate models is smaller using empirical interpolation than distribution quantile mapping and using the statistical quantile factor this indicates that empirical interpolation is highly underestimated in both extremely high and drizzle day precipitation 4 2 air temperature and precipitation changes in the 21st century the future daily precipitation and air temperature was corrected using three bias correction methods and compared the changes in the 2040 2069 near future clim2 and 2070 2099 far future clim3 with respect to the reference ref 1981 2010 period the influence of each bias correction technique on the precipitation and temperature magnitude of change was assessed figs 4 5 fig 4 show the projected maximum precipitation under each climate scenarios for the ensemble of the 12 climate models for each time slices and bias corrected using sqf dqm eqm techniques most likely the annual maximum precipitation will be increased in the clim1 2010 2039 period and clim2 periods by all climate scenarios fig 4 however the individual climate models show a clear difference in simulation of the magnitude and direction of changes in annual maximum precipitation similarly changes from each bias correction technique showed a slight difference in magnitude in changing annual maximum precipitation for example in the catchments of awash koka and awash hombole a higher change in annual maximum precipitation in all the bias corrections is shown ranging from 10 to 150 the other catchments show a 10 to 80 change in extreme precipitation moreover the changes are smaller in the awash koka and awash bello catchments using the dqm methods whereas in akaki and kela the changes are smaller using eqm and dqm the climate change signals also indicate a higher change using the ssp585 scenario than the ssp370 and ssp126 scenario in all the catchments due to a higher emission radiation value interestingly a linear relationship exists between the annual maximum precipitation changes in 2040 2069 near future and 2070 2099 far future with proportional magnitude this indicates that the gradient of these changes in 2040 2069 near future and 2070 2099 far future is a positive trend fig 5 show the projected maximum air temperature under each climate scenarios for the ensemble of the 12 climate models for each time slices and bias corrected using sqf dqm eqm techniques the changes in air temperature in ethiopia is more stable with time and space meresa and getachew 2018 the projected air temperature from the cmip6 dataset and scenarios provides a reasonable air temperature change increasing by 1 9 3 5 c and they maintain relatively uniform results in the selected catchments fig 5 however the spreads of the selected climate models are more extensive in the awash koka and awash hombole catchments overall the projected air temperature has a positive change across all the catchments and scenarios and is continuously increasing in the future periods 4 3 hydrological modeling and parameter uncertainty evaluation conceptual hydrological model performance for africa catchments is not uniform across the selected basins due to physiographic and runoff intensity meresa and zhang 2021 meresa and gatachew 2018 the hbv hydrological parameter sets for each of nine hbv parameters had a sample size of 30 000 which were generated through uniform distributions therefore considering enough parameter samples is required to understand the role of hydrological parameters in this study therefore we used number of best hydrological simulation as cut off threshold out of 30 000 fig 6a shows the value of nse left and observations inside the 95 confidence interval ci right of using different number of best simulations out of the 30 000 samples the number of observations inside the 95 ci is increasing by lowering the nse value the lower the number of best simulation sample gives the lower of observations in the 95 ci similarly the performance of each catchment is not the same due to the sediment and physiographic factors and backwater effect in awash catchments akaki catchment shows relatively a lower performance with lower nse range in contrast awash koka shows higher nse but lower percent of number of observations inside the 95 ci relatively the difference in percent of observations inside the 95 is reasonably acceptable using the 300 best simulations and above 0 3 nse therefore for further hydrological parameter uncertainty investigation we used only 300 best simulations out of 30 000 samples the glue based hydrological parameter uncertainty method was adopted to simulate a possible ensemble of daily runoff and the runoff simulation ensembles with a value larger than the 0 3 nse threshold value and best 300 simulations was selected to separate the behavioural and non behavioural simulations the likelihood values which were greater than the nse threshold value of the hbv parameter sets were considered as behavioural beven and binley 2014 meresa and romanowicz 2017 fig 6b shows the comparison of seasonal maximum flow simulation results from the best parameter behavioral sets with its 95 and 5 confidence interval value and observations in the 1981 2010 period it indicated that the observed maximum seasonal flow falls mostly between the 95 and 5 confidence bands except in the awash koka catchment particularly the lower band is mostly exposed to seasonal peak flows in the dry season january february and march this indicates that the hbv conceptual model is not recommended for simulating seasonal low flow however the seasonal peak flow was well captured during the main rainy season of the basin 83 of the observed maximum flow time series fell under the shaded area confidence internally and there was a wide range of nse values 0 3 0 75 overall it is promising to use for climate change impact study 4 4 performance of hydrological model under different bias correction approaches the long term internal variability of the simulated flow dynamics from 1981 to 2100 are shown in fig 7 the x axis is the time in the year and the y axis is the seasonal maximum flow it is perceived that the primary rainy peak flow season is covered by a yellow color called ethiopian kiremt season which is mainly june july and august for each station the maximum flow during rainy seasons has increased noticeably since 2010 there is a relatively strong increasing trend in annual and seasonal flow in the awash koka catchment compared to the akaki catchment overall the seasonal and annual projected maximum flow temporal trend shows that the peak flow increased for the coming three periods 2040 2069 and 2070 2099 this increase appears to be more substantial during the summer season with a mean peak flow increasing from 60 m3 s to 70 m3 s also the projected seasonal flows seem to be smoothed during the winter and late autumn seasons with a mean peak flow of about 35 m3 s furthermore the future conditions show an inevitable monthly variability from about 25 m3 s in may to 55 m3 s in october and november fig 7 similarly the spatial variability of mean peak flow during summer is also visible the mean flow increasing from 85 m3 s to 100 m3 s at hombole and varying from 20 m3 s to 30 m3 s at kela the changes in peak flow simulations that forced using corrected climate variables have been compared and presented in fig 8 overall it noted positive future changes in both clim2 and clim3 periods in annual maximum flow using dqm 10 eqm 17 and sqf 23 in the awash koka catchment however there is a slight difference among these bias correction techniques for example the sqf shows a smaller change in peak flow in the awash bello 12 and awash hombole 16 catchments whereas catchment awash koka 23 and akaki 35 shows a higher change in peak flow generally the magnitude of the annual maximum flow changes is not the same however these are not uniform across the selected catchments bias correction methods and climate scenarios the empirical quantile mapping method give smaller changes in peak flow whilst the dqm and sqf show a higher change in peak flow this indicates that the wet day frequency correction considered in the dqm method is important in understanding the future peak flow projections mainly the peak flow changes using the eqm give a smaller spread range and uncertainty across the selected catchments except in s4 interestingly noted that the peak flow changes have a smaller uncertainty size of the box in ssp370 and higher uncertainty in ssp126 and ssp585 scenarios fig 8 therefore correcting the wet days and precipitation intensity may significantly change the magnitude and direction to ultimately minimize the uncertainty due to bias correction methods overall s5 has a higher change in peak flow in the future whereas s4 using sqf has shown lower change than dqm and eqm similarly s3 has lower change in peak flow using sqf than dqm and eqm therefore difficult to conclude that one particular technique is overestimated or underestimate the peak flow in the future across all the catchment samples this implies that the techniques are comparable and their performance is not uniform across the catchments and climate sceneries therefore the magnitude of changes was varied with type of bias correction methods catchments climate scenarios and time slices 4 5 flood hazard projections under varying climate conditions the best fitted distribution model to annual maximum flow was chosen for each catchment and climate model with the best distribution being selected based on the akaike information criteria aic table 4 from table 4 it is noticed that the gev gamma and weibull distributions are the most dominant distribution types the projected annual maximum series has different distribution characteristics resulting from different flood magnitude and risk levels of which the three most prevalent and best fitted distribution models have similar probability density functions pdf using the most dominant frequency model gev the peak flood quantile changes under climate change have been estimated fig 9 shows peak flow quantile changes in clim1 2010 2039 clim2 2040 2069 and clim3 2070 2099 with respect to the reference period estimated using an ensemble of the 12 gcms and the three bias correction methods the ensemble average of the 12 climate models for each of the three scenarios assessed and the three bias correction methods in the five catchments show a significant increase in flood quantile magnitudes and frequency in the future fig 9 mostly the changes in flood quantiles are consistent with changes in peak flow due to its direct relationship to building the probability distribution function however the changes in the magnitude in the flood quantiles and peak flow are not a one to one relationship in all the catchments the changes in peak flow are higher than their respective change in flood quantiles at a return period of 50 years at s4 and s5 whereas at s1 s2 and s3 there are proportional changes in magnitude the future flood quantile changes are not the same in space and bias correction methods and the frequency of the larger return period flood increases to higher than once in 20 years the smallest changes in the 50 year quantile magnitudes are seen in the awash koka catchment using the eqm 55 the awash bello catchment using the sqf 40 and the awash hombola catchment using the dqm 75 relatively the methods show a consistently in the akaki and kelo catchments in providing information about peak flood quantile changes in the future furthermore the different hydroclimatic conditions were reflected in the flood quantile changes at different return periods for example the awash koka catchment has a peak flow quantile change range from 0 to 100 using the eqm but using the dqm method the changes range from 0 to 170 similarly the changes in the awash hombole catchment range from 0 to 100 using the dqm but 0 200 using the eqm therefore in addition to the hydrological parameters and climate model uncertainties the bias correction techniques also play a significant role in peak flow magnitude 4 6 uncertainty estimation and decomposition of associated sources in flood estimation fig 10 shows the primary sources of uncertainty hydrological parameter sets climate models and bias correction methods and their respective bands at specific return periods and catchments it considers the main factors interdependence using anova the contribution of individual sources of uncertainty and their interaction contribution to the flood magnitude and frequency changes in the future the decomposition of source uncertainty from the main variables and their interactions were separated based on the variance in flood values calculated out of 100 meaning the sum of all the sources is 100 the role hydrological parameter sets play in flood projection is not substantially changed the magnitude of peak flood and less uncertain in the chosen catchments in comparison the climate change variability and discrepancy show a considerable uncertainty and impact on the projection of floods this may be due to the projected precipitation intensity higher temperature and the time of concentration in the area on the other side the contribution of hydrological parameter sets is not significant in flood estimation floods are not dominated by hydrological processes like ground and interflow fig 10 in general the dominant source of uncertainty in this cascade peak flow projection modelling is with the climate models whereas the uncertainty related to hydrological parameter sets is not significant in future flood design value estimation furthermore the share of climate models frequency distributions and bias correction are significant in design flow estimation at a 100 year return period the magnitude of the uncertainty has a significant impact on the flood risk management plan and adaptation strategies for example in the awash koka catchments future flood risk management is highly uncertain due to climate model discrepancy and variability and their respective bias correction methods comparatively in the akaki catchment the climate model variability plays a major role in the reliability and accuracy of future flood risk management therefore the higher uncertainty source in peak flood projection might lead to having more impact on hydraulic infrastructure stability in the future due to climate change 5 discussion 5 1 future flood hazard the impact of climate change on peak floods was evaluated through the gev distribution model the peak flood quantiles in the reference and future period simulations of each catchment were calculated from 12 climate models gcms for each of the catchment various distribution types are commonly used in the us europe and africa kay et al 2009 collet et al 2017 meresa romanowicz 2017 meresa gatachew 2018 lawrence 2020 in this study many numerical experiments were performed by fitting the frequency distribution model to the annual maximum flow time series then based on the majority rule principle the most dominant flood frequency model was selected for flood estimation the estimated magnitude of peak flow quantiles at different return periods using the gev distribution with maximum likelihood parameter estimation method are not the same in magnitude and uncertainty band across all the catchments and climate models each climate model at each different catchment gives a very wide range of flood quantile values overall smaller flood quantiles were observed in the s3 catchment whereas the highest was estimated from the s1 and s4 catchments the estimated quantiles total range is relatively smaller in the s3 and s2 catchments whereas the highest uncertainty range is estimated in the s4 and s1 catchments moreover the changes in flood quantile values are not the same significance difference across the catchment and type of bias correction methods for example in the s2 and s3 catchments the flood quantiles at different return periods are expected to be larger in the near far and very far future in comparison the changes in peak flow are higher in the s1 and s4 catchments and they are expected to be more higher in the very far future period this is mainly due to the magnitude of flood events and its distribution in the given period keast ellison 2013 5 2 projected flood associated uncertainty estimation and decomposition in this study 12 climate models from the new dataset three bias correction methods the hbv hydrological model with 30 000 parameter sets and the gev flood frequency model was used to analyze the impact of future floods in the five chosen awash catchments the associated uncertainty was estimated and the climate models were highly uncertain in characterizing the future climate variables in the last few decades various studies concluded that the rcp and sres climate scenarios outputs are very weak in reproducing the historical extreme climate fowler et al 2007 saini et al 2015 this uncertainty may be due to the structure parametrization and spatial resolution of the gcms using multiple models in climate change impact analysis would lead to an improved understanding of the uncertainty associated with climate models it is essential in flood risk and water resource management the multiple climate models were evaluated for flood projection in the awash basin and it was found that the spread of climate models impact is significant there is also an important uncertainty component that is associated with the climate bias correction methods the catchment scale characteristics are not the same as the gcms spatial and temporal characteristics therefore it is essential to use highly relevant climate bias correction techniques to understand and minimize the uncertainty the three bias correction techniques were effectively corrected in the historical period and then the parameters were adopted for future climate corrections there are few studies related to flood frequency and bias correction method uncertainties kay et al 2009 saini et al 2015 meresa and romanowicz 2017 soriano et al 2019 however the preexisting studies that do exist found that the climate bias correction could alter the magnitude of the flood this study also confirmed this using three climate bias correction methods and the gcms from the cmip6 in ethiopia s selected catchments it was found that that the uncertainty associated to wet days and the intensity of precipitation has a significant impact on the flood magnitude e g s4 catchment the hydrological model parameters with its structure represent the hydrological full process the hydrological parameters govern the flow from of the source of rain to the deep catchment infiltration and percolation in this work more sensitive parameter sets of the hbv hydrological model were selected using the nse objective function values with 0 3 as a threshold glue was applied to identify the role of hydrological parameters in peak flood quantile estimation in the chosen catchments this was performed by using a hypercubic sampling approach from the given hbv parameter ranges the ranges of the hbv were procured from meresa gatachew 2019 the simulated flow in the historical period is relatively good for mean and high flow simulation the simulated band width does not significantly increase by changing the threshold for peak flow simulation generally the uncertainty due to model parameter changes is not significant in flood quantile estimation the finds confirmed that the role of model parameter sets is less in all the chosen catchments similarly yan et al 2015 meresa romanowicz 2017 joseph et al 2018b appear with a similar conclusion that high flow is less sensitive to hydrological parameters the uncertainty related to flood frequency under climate change is not extensively investigated and it has been very challenging to integrate with other sources of uncertainties each peak flow extracted from each climate model and bias corrected simulations were fitted to most of the dominant frequency model several researchers have conducted flood frequency analysis and they concluded that the extreme value ev and gev distribution models are the most repetitively used distribution models in the awash catchments ahilan et al 2012 tegegne et al 2020 similarly the numerical experiment results from this study confirmed that the gev is the most dominant model for all the climate models and selected catchments however the uncertainty band from frequency models is not significant in the chosen catchments therefore the uncertainty of the flood distribution models in these catchments is avoidably due to smaller differences in the hydro climate projections overall the results should be considered with care because the probability of extreme peak flow recurrence in the selected catchments is becoming more frequent and intense in the near and far future periods 6 conclusions this study focuses on disentangling uncertainty sources in future floods and developed a comprehensive framework to fit this purpose the proposed framework was tested in five awash catchments in ethiopia a region exposed to extreme flood risk the findings clearly show that hydrological model parameters the spread of climate models and bias correction techniques are not equally important sources of uncertainty in flood estimation in particular the climate models and bias correction methods are the most substantial sources of uncertainty in future flood frequency and magnitude estimation our results show that the impacts of climate change on peak floods magnitude and frequency are substantial resulting in an increased both magnitude and occurrence of peak floods in the selected awash river the disentangling a source of uncertainty in future peak flow estimation was performed based on the aggregated variance in changes of peak flood value at q20 flood event at a 20 year return period q50 flood event at a 50 year return period and q100 flood event at a 100 year return period the results confirm that climate change is the dominant factor in peak flow frequency in the awash koka and akaki catchments whereas in the kela catchment it is bias correction and in the awash bello catchment it is the distribution type anova also confirms that the contribution of their interactions is significant the contribution of climate models and bias correction methods with their interaction is incredibly substantial and nonnegligible in flood estimation uncertainty in the hydrological model parameters is not substantially change the magnitude and frequency of peak flood and thus there is no need to routinely take account of this uncertainty into water resource management and flood risk management studies however the findings of this study confirmed that the uncertainty associated with climate models can result a significant change in water infrastructure design and flood risk management and must considered this uncertainty into peak flood magnitude and frequency study similarly the uncertainty associated with bias correction methods may lead into a reasonably similar range of peak flood uncertainty arising from climate models however more importantly the climate models discrepancy results in a considerable shift in the magnitude of future peak flood as well as the range of the models the findings reveal that peak flood risks would noticeably increase in the near and far future in all catchments in awash located in the tropical dry region therefore the awash authority and national and local stakeholders must take certain non structural structural measures to mitigate flood risks in the future and to adapt to future climate flood risk management and policies need to consider these main factors and their management policy interaction however the value range of each source is large and challenging to communicate with decision makers and stakeholders therefore it is strongly recommended to consider using each factor spread and their median values for future flood risk management and take as basic information on extreme flood risk adaptation and mitigation measures declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is supported by the cas pioneer talents program the cas president s international fellowship initiative pifi project no 2020pe0048 and the national natural science foundation of china grant no 41971032 the authors would like to thank both the ethiopian meteorology agency and the ministry of irrigation and water resources for providing hydrometeorological data the data contributed greatly to advancing hydrological sciences by sharing their long time series data data availability statement both the observed meteorological and hydrological data were acquired from the meteorological agency and the water resource ministry of ethiopia respectively the data is available on request from the corresponding organizations but it is not publicly available due to the privacy and ethical restrictions of the ethiopian organizations author contributions hadush meresa and yongqiang zhang designed the research analyzed the results and wrote the initial version hadush meresa conducted modelling and plotting all authors contributed to paper revisions and result interpretations appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128426 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
