index,text
24380,solar induced chlorophyll fluorescence sif has been regarded as proxy data of vegetation photosynthesis thus it is assimilated into the terrestrial carbon cycle modeling the soil canopy observation of photosynthesis and energy fluxes scope model is one of the most utilized models of sif simulation however the currently incomplete understanding of scope sif factors and the lack of exploring how scope works under different vegetation types would deteriorate further carbon cycle research herein this study disentangled decisive sif factors in the scope model then a sample sif dataset synsif with spatial resolutions of both 0 02 and 0 05 was simulated through scope model using factors above then this study validated how far scope simulating sif could capture gpp compared with other sif datasets the results showed that 1 there are five decisive sif factors in scope model including plant status leaf chlorophyll content and leaf area index and meteorological parameters incoming shortwave radiation air temperature and atmospheric vapor pressure 2 the linear relationship of synsif gpp outachieved other sif datasets across all six vegetation types in southern south america asia and africa improving r 2 averagely by 0 33 0 28 and 0 15 respectively 3 synsif in oceania and europe revealing gpp better in shrublands with synsif gpp r 2 increasing by 0 15 and 0 16 respectively and grasslands with synsif gpp coefficients increasing by 0 14 and 0 06 respectively illustrated spatially complementary characteristics with gosif across varying vegetation types thus we anticipate that this study could provide more complete information for scope simulating sif in different biome research when estimating the terrestrial carbon cycle keywords sif gpp relationship sensitivity analysis cross vegetation type gpp abbreviations sif solar induced chlorophyll fluorescence gpp gross primary pruductivity data availability datasets utilized in this study are all public and available datasets 1 introduction solar induced chlorophyll fluorescence sif is emitted by plants during photosynthesis along with energy utilized for light reactions and heat dissipation porcar castell et al 2014 although gross primary productivity gpp is essential in monitoring terrestrial ecosystems sif has also gained significance as explicit information of vegetation condition due to its high correlation with gpp frankenberg et al 2011 sun et al 2017 consequently sif is being widely used in stress detection photosynthesis monitoring and drought diagnosis meroni et al 2009 mohammed et al 2019 jonard et al 2020 crucially sif has been incorporated into terrestrial carbon cycling systems together with atmospheric co2 the fraction of absorbed photosynthetically active radiation fapar soil moisture and terrestrial biomass scholze et al 2017 however sif has a restrictive spectral range a coverage from 650 nm to 800 nm and emits a little amount of signals 3 5 of total absorbed light yield frankenberg et al 2011 porcar castell et al 2014 consequently monitoring sif from satellite platforms compromises spatial details nevertheless sif offers a new perspective on incorporating sif into carbon cycle monitoring and encourages researchers to find ways to overcome its emitting inefficiency sif can now be measured from the field airborne and satellite levels owning to the state of art sensor developments and methods illustrated in table 1 joiner et al 2013 köhler et al 2015 however current satellite based sif products have been hampered by a paradox between spatial continuity and spatial resolution and by coarse spatial resolutions and short term coverage refer to table 1 for example the global ozone monitoring experiment 2 gome 2 and the tropospheric monitoring instrument tropomi offer spatially continuous coverage but coarse resolution whilst the greenhouse gases observing satellite gosat the orbiting carbon observatory 2 oco 2 the orbiting carbon observatory 3 oco 3 and the tansat provide high spatial resolution but geographical discontinuity duveiller et al 2020 as a result researchers have been focusing on downscaling or gap filling satellite derived sif products to resolve existing conflicting situation between spatial continuity and resolution and also to improve spatial temporal resolutions for instance in table 1 csif sif oco2 005 and gosif achieved gap filling of oco 2 sif products and sif005 sif lue and rsif datasets downscale spatial continue satellite sif datasets such as gome 2 moreover the state of art remote sensing technologies and sif retrieval algorithms also progress sif model developments and sif models have been assimilated into the carbon cycle modeling for example the fluorsail model and the soil canopy observation of photosynthesis and energy fluxes scope model as one dimensional 1 d models describes the vegetation canopy as homogeneous layers miller et al 2003 van der tol verhoef et al 2009 the dart model considers the 3d radiative budget and 3d landscapes gastellu etchegorry et al 1996 gastellu etchegorry et al 2015 gastellu etchegorry et al 2017 consequently modeling the chlorophyll fluorescence through the canopy helps understanding plant photosynthesis terrestrial carbon cycle and climate research for instance the scope model has been utilized from untangling seasonal relation of sif and transpiration detecting abiotic changes and water stress to assessing sif estimation uncertainties lu et al 2018 sinha et al 2020 damm et al 2021 de cannière herbst et al 2021 xu et al 2021 zhang et al 2021 zeng et al 2022 specifically the scope model is widely used in applications across differing biomes such as tropical deciduous forests and temperate mixed forests sinha et al 2020 damm et al 2021 furthermore various terrestrial biosphere models have coupled with the scope model in order to fulfill the big picture of terrestrial photosynthesis and carbon cycle such as the orchidee bethy and beps norton et al 2018 bacour et al 2019 cui et al 2020 however as a 1 d model the scope model could not simulate spatial and structural heterogeneity and variability of vegetation horizontally for instance cui tianxiang et al coupled beps scope model and analyzed global distribution of scope sif simulation but it lacks cross vegetation analysis cui et al 2020 from this point of view validating the cross vegetation type effectiveness of scope simulated sif provides validity of scope in different plant photosynthesis conditions and also helps understand sif modeling thus this study analyzes decisive sif factors in the scope model and validates scope simulated sif across vegetation types using our proposed scope sif simulating methodology and gpp datasets specifically this study 1 analyzes decisive plant and climate factors of sif from confounding properties in the scope model thereby designing a scope sif simulation procedure 2 calculates global and regional sif samples synsif in 0 05 and 0 02 using factors selected in 1 3 explores how far synsif capture gpp across vegetation types validating by the correlation between sif and gpp finally we provide a comprehensive evaluation of synsif and other sif datasets from a unique perspective helping uncover the utility of the scope model in sif reconstruction thus we anticipate that our study will contribute to a deeper understanding of the scope model and its intense applications in monitoring terrestrial carbon cycle 2 materials and methods 2 1 a radiative transfer model the soil canopy observation of photosynthesis and energy fluxes scope model is a multi algorithm integrated 1 d vegetation radiative transfer model van der tol verhoef et al 2009 yang et al 2020 this model requires soil parameters leaf canopy optical variables aerodynamic and micrometeorological conditions and geometric observations the scope could retrieve outgoing canopy reflectance the turbulent heat fluxes chlorophyll fluorescence and photosynthesis conditions through physical processes incorporating radiative fluxes energy balance and multiple climate turbulences consequently scope as a sophisticated evaluation approach has been utilized in series of research focusing on ecosystem status monitoring and stress detection celesti et al 2018 shan et al 2021 2 2 sif factors sensitivity analysis sa involves calculating the relative contribution of several given variables to the variance of an output variable cannavó 2012 sa of the scope model was conducted to identify the contribution of variability in the 53 total input parameters to the variability in leaf chlorophyll fluorescence previous research has shown that some variables are showing more vital influence towards sif 1 leaf chlorophyll content cab leaf inclination lidfa and leaf area index lai determined 77 9 of the sif variability 2 in addition to the vital vegetation variables micrometeorological variables were significant in driving sif variability especially incoming shortwave radiation rs and air temperature ta and atmospheric vapor pressure vp verrelst et al 2015 overall the influential interpretive properties could be carefully categorized as leaf canopy biochemical and structural variables micrometeorological variables further accessible links are illustrated in table 2 leaf canopy biochemical and structural variables and their origins contain 1 cab and carotenoid concentration car derive from the mcd43a4 v6 nadir bidirectional reflectance distribution function adjusted reflectance nbar product in 500 m resolution another surrogate dataset refers to mcd43c3 providing brdf adjusted reflectance in 0 05 mcd43a4 has been deriving biochemical parameters from aboveground biomass evi to sif zhang et al 2018 he et al 2019 li and xiao 2019 yu et al 2019 wen et al 2020 2 500 m lai statistics are provided by the myd15a2h v6 combined leaf area index lai and fraction of photosynthetically active radiation fpar product micrometeorological variables include 1 rs and incoming longwave radiation rl come from the modern era retrospective analysis for research and applications version 2 merra 2 m2t1nxrad hourly time averaged 2 dimensional data collection 2 ta and wind speed data collections derive from m2t1nxflx from merra 2 as well 3 vp could be calculated from relative humidity and corresponding air temperatures in m2t3nvasm 2 3 sif simulation workflow the scope simulation workflow includes data preprocessing data integrating scope simulating and data postprocessing illustrated in fig 1 in data preprocessing we produced grid shapefiles both 0 02 and 0 05 screened qualified data and resampled all statistics into the consistent resolutions we initially removed cloud pixels for modis leaf canopy level variables surface reflectance and lai by filtering brdf quality bands in the google earth engine platform gorelick et al 2017 subsequently we utilized the look up table lut to retrieve foliage cab car from reflectance sets for each grid and lai was obtained from myd15a2h product other parameters such as leaf water content brown pigments and the internal structure parameter are ignorable compared with other sif drivers based on the sa result specifically the lut approach of acquiring vegetation properties is one of the common and efficient ways this approach involves repeating spectral simulations by using a specific model with all combinations of the input vegetation parameters constrained by reasonable ranges and distributions this study created a lut as a function of foliage cab car and cm including 9911 samples table 3 we then averaged different temporal datasets an hourly time averaged of m2t1nxrad and m2t1nxflx and a 3 hourly time averaged of m2t3nvasm into 8 day information for merra 2 micrometeorological variables vp derives from relative humidity datasets and corresponding air temperatures in the m2t3nvasm collection formulated as eq 1 abtew and melesse 2013 1 e a e t m i n r h m a x 100 e t m a x r h m i n 100 2 where e a refers to vapor pressure e t m i n and e t m a x refer to vapor pressure in corresponding least and highest air temperature daily respectively and r h m a x and r h m i n refer to the least and highest relative humidity daily respectively and e t is demonstrated in eq 2 2 e t 0 6108 e 17 27 t t 237 3 where t refers to specific air temperature the following data integrating step includes 1 calculating geometry including longitude and latitude for each point respectively in arcgis 10 and 2 extracting different formats into shapefiles then the scope simulation stage calculated sif in the scope 2 0 model for each point in shapefiles ultimately data postprocessing an elective and flexible procedure includes 1 using inverse distance weighted idw interpolation to fill in the vacant pixels bartier and keller 1996 2 the shapefiles are converted to other formats in arcgis 10 and a specific projection is also defined 3 clipping and merging operations are also conducted when necessary in this work postprocessing is skipped because the original products could reveal the sif essence of scope duveiller et al 2020 however those blank regions could readily be resampled fully through our elective procedure 2 4 appraising agreement previous studies demonstrate a universal sif gpp linear relationship eq 3 thus we validated scope sif product through a sif gpp linear correlation analysis frankenberg et al 2011 guanter et al 2012 sun et al 2017 3 g p p φ c o 2 β φ f s i f where φ c o 2 and φ f refer to light use efficiency of co2 assimilation and sif respectively and β is the escaping rate of sif photons energy partitioning in photosynthesis varies across climates and biomes implying that a linear equation might not accurately describe the sif gpp relationship however the consistency of spatial temporal dynamics in sif and gpp remains a robust experimental result and we transfer this linear correlation as the benchmark of sif products sun et al 2017 validating datasets include two gpp datasets used in evaluation sif s ability to monitor vegetation productivity and some satellite retrieved and downscaled sif datasets to further contrast different sif products detailed information is in table 3 the validating method used in our study is the sif gpp correlation analysis including λ index of eq 4 and linear regression analysis in eq 5 duveiller et al 2016 4 λ 1 n 1 i 1 n x i y i 2 σ x 2 σ y 2 μ x μ y 2 where μ and σ represent the mean and standard deviation respectively λ ranges from 0 to 1 indicating a reliable agreement 5 r 2 1 i 1 n x i x y i y i 1 n x i x 2 i 1 n y i y 2 where x refers to gpp y refers to sif and x and y mean average statistics 3 results 3 1 how synsif capture gpp spatially before evaluating how far synsif could capture gpp this section firstly displays different sif products we chose a classic and widely using machine learning based product gosif a newly half experimental dataset sif lue and gome 2 satellite product even four sif products have uniform spatial patterns different datasets reveal subtle differences the simulated synsif as shown in fig 2 a is highly coherent with other published products in most areas specifically southeastern north america amazon rainforests in south america mid region of eurasia and southeast asia all illustrate high sif in synsif gosif and gome 2 products sif lue faces some inconsistency with other data because it indicates that southeastern south america and africa have higher values and that sif in high latitudinal areas is absent this anomaly of sif lue might be due to sensor degradation in the corresponding temporal profile because its performance in their article is superior duveiller et al 2020 furthermore sif lue is quantitatively compatible with synsif because they both display far red maxima band 740 nm sif gosif reconstructs sif of 757 nm at which the sif signals are less high quantitatively than 740 nm although the gome 2 product retrieved sif in 740 nm observations from satellites suffer a signal loss during atmospheric absorption and transition zhang et al 2018 the sif gpp agreement indicated by λ index illustrates that scope simulating synsif could reveal global sif reciprocally with gosif shown in fig 3 this agreement also provides scope validity of the globe specifically in southeast asia fig 3 a synsif is an ideal proxy data for gpp and its index is higher than 0 7 in λ index by contrast other products including gosif sif lue and gome 2 show bottommost λ index 0 0 in most mid latitude regions among south north america and asia south america africa and oceania synsif gosif and gome 2 provide similar spatial patterns nevertheless we concede that gosif and gome 2 have stable consistency with gpp in high latitudinal regions whereas synsif performs inferior and sif lue lacks accessible data another agreement index demonstrated by sif gpp correlation coefficient r 2 in fig 4 further suggests how scope simulating synsif capture gpp across different vegetation type zones across six vegetation types forests gpp could hardly be captured across all sif products in most vegetation situations sif gpp r 2 rarely reach 0 2 fig 4 shows that in south america asia and africa scope simulated synsif could better reveal vegetation gpp across all six vegetation types compared with other three sif datasets the sif gpp linear relationship of synsif attains over 0 60 in south america amongst shrublands 0 64 grasslands 0 62 wetlands 0 63 and croplands 0 66 whereas other samples cannot reach 0 40 as shown in fig 4 b specifically sif gpp linear relationships of sif lue and gome 2 sif fluctuate around 0 1 among six vegetation types gosif showed a slightly higher consistency of sif gpp than sif lue and gome 2 sif r 2 of 0 34 in shrublands the synsif coefficients in forests and savannas show increases compared with gosif synsif increased r 2 by 0 10 and 0 28 respectively in asia as shown in fig 4 c the promotion of synsif is more dramatic in dense vegetation areas synsif outperforms gosif r 2 increase by 0 38 0 24 and 0 38 in forests shrublands and savannas respectively the performance of synsif further reaches 0 75 0 73 and 0 63 in sparse vegetation regions grasslands wetlands and croplands fig 4 e of african sparse vegetation areas also show a good agreement for synsif to gpp across all vegetation types the r 2 of forests shrublands savannas grasslands wetlands and croplands increase by 0 01 0 03 0 05 0 21 0 45 and 0 14 respectively fig 4 d and 4 f illustrate that synsif gpp r 2 outstrips gosif gpp r 2 in certain vegetation types synsif nicely reveals gpp under conditions of european shrublands grasslands and croplands with the highest sif gpp r 2 of 0 62 0 58 and 0 76 compared with other three datasets respectively moreover oceania shrublands grasslands and wetlands are advantageous regions to demonstrate gpp using synsif with r 2 of 0 67 0 58 and 0 67 respectively gosif is worthwhile in the complementary land of the regions above additionally fig 4 a shows a limited practicality of synsif in north america despite that synsif lags less than 0 1 in r 2 on average compared with gosif our experimental results recommend gosif to evaluate sif gpp in north america from both global continental and across vegetation type perspectives both synsif and gosif achieve an appealing correlation with the modis gpp product indicating that the scope model could capture global gpp in south america asia and africa when scope simulation has limited ability in some plant types gosif achieves better specifically gosif remains accurate and practical in high latitude areas of north america and asia however in low latitude areas synsif performs outstandingly across differing dominant vegetation types in southeastern asia southern south america and africa which could be further examined in the r2 comparison we would advise careful utility in north america because the agreements of synsif and gpp indicate that the scope model is unsuitable for estimating plant photosynthesis or vegetation production 3 2 how synsif capture gpp in time series fig 5 reflects the temporal sequences of two 8 8 areas in 0 02 grids which served as an exemplary continuous record for the seasonal dynamics of sif the wax and wane of vegetation productivity are captured in the us corn belt fig 5 a and england fig 5 b it is clear that scope simulation could reveal time series of vegetation photosynthesis we then further focused on parts of the us corn belt from 2017 to 2020 in fig 6 to further analyze the time series of scope simulation and its coherency with current gpp products in addition we quantitatively reorganized the synsif series with two gpp products produced by modis 500 m and landsat 30 m platforms in fig 7 as for seasonal variations the rise and fall of sif and gpp are consistent for instance in 2019 synsif landsat gpp and modis gpp show similar increasing and decreasing trend the variation of forests from june to july is lower than that from july to august for all three datasets specifically synsif increased 0 04 mwum 1sr 1 from june to july and decreased 0 14 mwum 1sr 1 from july to august modis gpp and landsat gpp both experienced increases of 0 01 kgcm 2 during june july while the former and the latter decreased 0 02 kgcm 2 and 0 03 kgcm 2 during july august respectively other vegetation types also shared this trend although classified by dominant vegetation types 0 02 synsif and 500 m modis gpp hardly capture quantitative variation inside the dense fig 7 a and d and sparse fig 7 b and c vegetation regions however the landsat gpp clearly perceives vegetation differences a more drastic fluctuation of croplands in 2019 and 2020 in fig 7 b modis gpp shows a counterintuitive fall and rise in july 2020 fig 7 a d e whereas synsif and landsat gpp demonstrate slight fluctuation and dramatic rise and fall respectively the reason is that scope simulating sif avoids biases stemming from the degradation of modis sensors because of scope computation thereby also illustrating conformity with landsat gpp specifically the lai dataset derives from aqua exclusively through which systematic biases would affect synsif more slightly running and zhao 2015 the compromise of synsif between the excellent performance of landsat and relatively deteriorated modis gpp products attributes partly to the use of both terra aqua reflectance dataset and aqua only lai dataset products meantime weakening a severe impact of degradation of sensors 4 discussion 4 1 sif factors in scope simulation from this study s results we suggest that cab and lai are two critical properties when simulating sif using the scope model moreover scope users should also consider different responsible parameters while adopting differing spectral regions of sif in the scope model our analysis holds that the spatial and seasonal sif differences are mainly controlled by fluctuant cab and lai derived from 500 m modis projects in our study despite different microclimates merra 2 at 50 50 km grids spatially consistent with the sensitivity analysis literature the effect of spatial cab on sif at 740 nm is more significant while the change of lai takes relatively minor responsibility revealed in fig 8 verrelst et al 2015 nevertheless sif in september 2020 shows that low level lai in the eastern area accounts for the weak sif thus when promoting spatial temporal resolutions of the scope model users would better choose accurate and precise cab and lai datasets and also consider essential climate factors despite coarse pixels for example users could modify specific parameters in lut to improve the accuracy of cab or replace the retrieval results with different sensor datasets such as landsat reflectance thereby avoiding notoriously suggested sensor degradation of modis and overcoming persistent cloudiness and coarse spatial resolutions scholze et al 2017 the sa also indicates that the relative influence of different properties both plant and climate factors varies in distinct bands verrelst et al 2015 thus when modifying the target sif spectral bands and promoting finer temporal resolutions using scope we suggest analyzing influential series of all variables in sa and putting more spatial resolution concerns on higher sensitive properties further details should also be considered in field level research to reflect micro details such as leaf inclination and the maximum rate of carboxylation verrelst et al 2015 merra 2 provides hourly meteorological information which would play a key role in promoting finer temporal resolutions 4 2 sif factors of artificial sif products our study simulated sif with radiative transfer model and our sample synsif reveals a superior correlation with gpp and also a geographically complementary characteristic with gosif amongst other three sif datasets gosif is a widely used data driven product sif lue placed an opening endeavor towards semi physiologically downscaling method gome 2 remains a classic satellite retrieving sif product however these four products above provide different sif factor consideration when focusing on interpretative parameters of sif eq 6 represents a well accepted interpretation of sif joiner et al 2014 6 s i f λ par f p a r c h l φ f λ f e s c λ τ a t m λ where f p a r c h l the fraction of chlorophyll absorbed par is a function of vegetation cover fraction lai leaf cab and also plant structure f e s c λ known as the escape ratio depends on leaf inclination distribution and sun target sensor geometry par and τ a t m λ are influenced by a complex combination of incident energy water availability and atmospheric scattering and φ f λ the fluorescence quantum yield turns on water availability most data driven methods in table 1 adapted modis brdf corrected surface reflectance representing geometry correction as the only ancillary dataset gentine and alemohammad 2018 zhang et al 2018 yu et al 2019 wen et al 2020 however previous studies show that both short term variability of environmental stress and plant status would cause seasonal patterns of sif and surface reflectance rarely presents the whole picture jonard et al 2020 thus utilizing surface reflectance solely for gap filling or downscaling sif is relatively inappropriate as for synsif and gosif both grasp vegetation and meteorological conditions as primary factors of sif while gosif selects evi as the proxy of vegetation status synsif directly captures foliage conditions and canopy structures from cab car and lai it has been stated that satellite derived vegetation indices either evi or ndvi are more indicative of vegetation greenness grace et al 2007 however physiologically when facing climate turbulences such as drought plants would firstly reduce internal functions photosynthesis followed by a decrease of cab then exterior greenness could be revealed by vegetation indices zhang et al 2018 consequently as synsif utilized measuring pigment concentrations and lai from both foliage and canopy levels helps clarify plants responses towards climate variability more directly scholze et al 2017 we suggest that future sif products adopt plant biochemical parameters such as cab car and lai rather than proxy properties like ndvi synsif is also highly consistent with gosif in meteorological property selection gosif used meteorological parameters including par vapor pressure deficit and air temperature to account for solar radiance water availability and temperature stress li and xiao 2019 in this method par serves as a component of downward shortwave radiation and is also driven by atmospheric opacity and scattering wang et al 2020 in this study synsif also considers incoming shortwave radiate directly leading to par air temperature and atmospheric vapor pressure along with incoming longwave radiation and wind speed data to depict microclimate turbulence further completely sif lue advances from data driven methods toward a semi experimental exploration duveiller et al 2020 sif lue develops its explanatory variables nirv ndwi and afternoon overpassing lst and unique semi experimental equation thus it achieves confirmative validation with tropomi collection duveiller et al 2020 specifically sif lue applies a calibrated function of a vegetation index water and thermal stress indicators nirv and ndwi both derive from specific vegetation or water sensitive surface reflectance wavelengths however previous studies have shown that the differences of plant physiology and canopy structure such as lai and cab profiles rather than reflectance based indices affect across biomes when revealing spatially details scholze et al 2017 sun et al 2017 additionally lst and air temperature have different responses to atmospheric conditions mutiibwa et al 2015 and the complex interaction of the surface energy balance system further differs lst from air temperature especially diurnally zhu et al 2013 gome 2 is one of the primary since 2009 satellite inversion products contributing to the exploration and estimation of vegetation or crop productivity he et al 2017 sloat et al 2021 exemplary sif datasets such as sif005 and rsif also utilized gome 2 as original sets to further investigate downscaling methods gentine and alemohammad 2018 wen et al 2020 however its 40 km 40 km resolution obscured spatial details and consequently suffered lattice like inaccuracy in fig 3 which is the primary motive for most fine spatial resolution sif solutions from sif factors point of view considering and selecting decisive sif factors is unavoidable when reconstructing downscaling or gap filling sif products although scope model is 1 d it could capture and reveal photosynthesis and vegetation gpp thus considering radiative transfer modeling and referring scope sa results into data driven methods might contribute to sif dataset production 4 3 opportunities and caveats of scope sif simulation the scope model plays a key role in much research ranging from estimating terrestrial vegetation photosynthesis to advancing terrestrial biosphere models such as beps scope and bethy scope norton et al 2018 cui et al 2020 sinha et al 2020 the scope has also been utilized worldwide including various vegetation types such as forests croplands and different hemispheres indicates its robustness bacour et al 2019 raczka et al 2019 xu et al 2021 in the study from cui sun et al it is proved that the scope simulated sif and the gome 2 sif were highly correlated with r2 0 5 rmse 0 36 mwum 1sr 1 wu et al 2022 another study also indicates that the scope model can also reliably illustrate sif diurnal cycles with the rrmses for all 106 spectral measurements of 24 35 hu et al 2018 these studies demonstrate the overall accuracy and precision of the scope model there are also studies however indicating inconsistency of the sif gpp linear relationship in specific areas thus in this study we simulated sif through scope and pointed out its ability to capture gpp products across vegetation types on different continents through our study we summarized some advantages of scope simulation 1 firstly this study distinguishes five key interpretative properties leaf chlorophyll content leaf area index incoming shortwave radiation air temperature and atmospheric vapor pressure from confounding sif factors in scope model exemplifies global and regional sample datasets we would recommend these factors not only in scope simulation but also in future sif downscaling and gap filling product construction this advantage can be attributed to physiological theories that remain rarely permeable for data driven strategies sif is far from a simple phenomenon mohammed et al 2019 however most previous datasets conservatively extract characteristic traits from modis surface reflectance gentine and alemohammad 2018 zhang et al 2018 yu et al 2019 wen et al 2020 furthermore prevalent machine learning methods focus on fitting sample characteristics with sif thus selecting surrogate variables and training samples are vital for data driven methods however uneven training sampling occurs and varies in different locations and temporal profiles due to the sparse observations of satellite instruments thus predicting uncertainty remains a challenge to quantify as mentioned in a previous dataset oriented article de cannière herbst et al 2021 thus our study proposes valid sif factors through sensitive analysis which could also be tested by data driven methods in the future 1 another merit refers to facilitating applications due to satisfactory spatial resolution long term series and completely spectral coverage using scope thus accelerating the synergy of ground based airborne and satellite observations for terrestrial data assimilation systems as the direct proxy of photosynthesis sif has been considered as a vital component to be utilized within the carbon cycle data assimilation system koffi et al 2015 for example many terrestrial biosphere models including the orchidee bethy and beps have coupled sif to reduce the uncertainty of model estimation and improve the understanding of the earth s climate carbon system norton et al 2018 bacour et al 2019 cui et al 2020 the global carbon cycle is entangled with hydrological turbulence energy cycles and ecosystem dynamics thus assimilating various in situ observations and satellite measurements is critical scholze et al 2017 however such efforts were hampered from satellite levels because coarse spatial resolutions complicate harmonious infusion with ground measurements lu et al 2018 through the scope model simulated sif would facilitate synergy from satellite airborne and ground platforms spectrally scope retrieves entirely fluorescent spectra from 650 nm to 800 nm at 1 nm resolution simultaneously covering 680 nm 740 nm and 760 nm on which are widely focused on sif applications goulas et al 2017 he et al 2017 gonsamo et al 2019 dechant et al 2020 furthermore hand held devices stationary and mobile field systems uavs and other airborne sensors have achieved full spectral measurement damm et al 2015 amir et al 2021 thus we expect full spectra applications in globally terrestrial vegetation monitoring however simulated sif still fails to recover sif in tropical rainforests semi arid regions and northern tundra partly due to its 1 d vertical property and unsatisfactory consideration of regionally unique parameters moreover simulating sif also faces computing expenses 1 a relatively weak correlation between synsif and other sif products and gpp was examined in tropical rainforests semi arid regions and northern tundra one possibility is that modis exhibits small infidelity in forest seasonality and experiences sensor degradation huete et al 2006 sayer et al 2015 whereas sif reveals stronger seasonal variations joiner et al 2014 smith et al 2018 magney et al 2019 li et al 2020 another extrapolation is that incorporating climate variables and plant traits could improve sif prediction as proposed in previous work wen et al 2020 as eq 6 shown we would consider more climate and plant parameters in the future porcar castell et al 2014 for example clumping index and lidfa could indicate the differences across biomes in plant physiology and canopy structure and carbon dioxide concentration plays a role in atmospheric fluctuation gentine and alemohammad 2018 liu et al 2022 luo et al 2022 pei et al 2022 xu et al 2022 in semi arid and tundra regions sif signals are generally lower in magnitude and thus more susceptible to noisy signals compared with other more productive biomes wang et al 2019 wang et al 2019 furthermore the scope model extrapolates that the vegetation layer is one dimensional thus it lacks physical bedrock applying in dense vegetation types such as forests 1 using radiative transfer models would lead to expensive computing consumption jacquemoud et al 2009 specifically a single graph in fig 6 took 12 h in our macos 11 with intel core i7 due to the limitation of model processing speed the global scale long term series scope simulation is hindered 5 conclusion this study disentangled decisive sif factors in scope radiative transfer model from its confounding properties then we designed scope sif simulation procedure and calculated sif in 0 05 globally and 0 02 regionally spatial synsif then we explore the quantified agreements between gpp and different sif products including widely used artificial sif datasets and scope simulated synsif analyzing how simulated sif capture gpp across vegetation types our main conclusions are 1 there are five decisive sif factors in scope model including plant status leaf chlorophyll content and leaf area index and meteorological parameters incoming shortwave radiation air temperature and atmospheric vapor pressure 2 the linear relationship of synsif gpp outachieved other sif datasets across all six vegetation types in southern south america asia and africa improving r 2 averagely by 0 33 0 28 and 0 15 respectively 3 synsif in oceania and europe revealing gpp better in shrublands with synsif gpp r 2 increasing by 0 15 and 0 16 respectively and grasslands with synsif gpp coefficients increasing by 0 14 and 0 06 respectively illustrated spatially complementary characteristics with gosif across varying vegetation types we thus anticipate that our study would deepen further understanding in scope simulated sif in multi vegetation type applications especially terrestrial biosphere model coupling credit author statement s y j y and s shi designed the study s y and y z carried out computations s y j y s shi and s song provided the analysis s y made the tables and figures s y and j y wrote the first draft and revised the manuscript with s shi and s song y z y l and l d declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research received funding from the national natural science foundation of china nsfc 41801268 we acknowledge the open access of the scope 2 0 model and prospect d model we also thank google earth engine a free platform of cloud computing satellite projects including modis merra 2 gome 2 and landsat series and previous downscaling sif datasets gosif and sif lue lead the way for this research 
24380,solar induced chlorophyll fluorescence sif has been regarded as proxy data of vegetation photosynthesis thus it is assimilated into the terrestrial carbon cycle modeling the soil canopy observation of photosynthesis and energy fluxes scope model is one of the most utilized models of sif simulation however the currently incomplete understanding of scope sif factors and the lack of exploring how scope works under different vegetation types would deteriorate further carbon cycle research herein this study disentangled decisive sif factors in the scope model then a sample sif dataset synsif with spatial resolutions of both 0 02 and 0 05 was simulated through scope model using factors above then this study validated how far scope simulating sif could capture gpp compared with other sif datasets the results showed that 1 there are five decisive sif factors in scope model including plant status leaf chlorophyll content and leaf area index and meteorological parameters incoming shortwave radiation air temperature and atmospheric vapor pressure 2 the linear relationship of synsif gpp outachieved other sif datasets across all six vegetation types in southern south america asia and africa improving r 2 averagely by 0 33 0 28 and 0 15 respectively 3 synsif in oceania and europe revealing gpp better in shrublands with synsif gpp r 2 increasing by 0 15 and 0 16 respectively and grasslands with synsif gpp coefficients increasing by 0 14 and 0 06 respectively illustrated spatially complementary characteristics with gosif across varying vegetation types thus we anticipate that this study could provide more complete information for scope simulating sif in different biome research when estimating the terrestrial carbon cycle keywords sif gpp relationship sensitivity analysis cross vegetation type gpp abbreviations sif solar induced chlorophyll fluorescence gpp gross primary pruductivity data availability datasets utilized in this study are all public and available datasets 1 introduction solar induced chlorophyll fluorescence sif is emitted by plants during photosynthesis along with energy utilized for light reactions and heat dissipation porcar castell et al 2014 although gross primary productivity gpp is essential in monitoring terrestrial ecosystems sif has also gained significance as explicit information of vegetation condition due to its high correlation with gpp frankenberg et al 2011 sun et al 2017 consequently sif is being widely used in stress detection photosynthesis monitoring and drought diagnosis meroni et al 2009 mohammed et al 2019 jonard et al 2020 crucially sif has been incorporated into terrestrial carbon cycling systems together with atmospheric co2 the fraction of absorbed photosynthetically active radiation fapar soil moisture and terrestrial biomass scholze et al 2017 however sif has a restrictive spectral range a coverage from 650 nm to 800 nm and emits a little amount of signals 3 5 of total absorbed light yield frankenberg et al 2011 porcar castell et al 2014 consequently monitoring sif from satellite platforms compromises spatial details nevertheless sif offers a new perspective on incorporating sif into carbon cycle monitoring and encourages researchers to find ways to overcome its emitting inefficiency sif can now be measured from the field airborne and satellite levels owning to the state of art sensor developments and methods illustrated in table 1 joiner et al 2013 köhler et al 2015 however current satellite based sif products have been hampered by a paradox between spatial continuity and spatial resolution and by coarse spatial resolutions and short term coverage refer to table 1 for example the global ozone monitoring experiment 2 gome 2 and the tropospheric monitoring instrument tropomi offer spatially continuous coverage but coarse resolution whilst the greenhouse gases observing satellite gosat the orbiting carbon observatory 2 oco 2 the orbiting carbon observatory 3 oco 3 and the tansat provide high spatial resolution but geographical discontinuity duveiller et al 2020 as a result researchers have been focusing on downscaling or gap filling satellite derived sif products to resolve existing conflicting situation between spatial continuity and resolution and also to improve spatial temporal resolutions for instance in table 1 csif sif oco2 005 and gosif achieved gap filling of oco 2 sif products and sif005 sif lue and rsif datasets downscale spatial continue satellite sif datasets such as gome 2 moreover the state of art remote sensing technologies and sif retrieval algorithms also progress sif model developments and sif models have been assimilated into the carbon cycle modeling for example the fluorsail model and the soil canopy observation of photosynthesis and energy fluxes scope model as one dimensional 1 d models describes the vegetation canopy as homogeneous layers miller et al 2003 van der tol verhoef et al 2009 the dart model considers the 3d radiative budget and 3d landscapes gastellu etchegorry et al 1996 gastellu etchegorry et al 2015 gastellu etchegorry et al 2017 consequently modeling the chlorophyll fluorescence through the canopy helps understanding plant photosynthesis terrestrial carbon cycle and climate research for instance the scope model has been utilized from untangling seasonal relation of sif and transpiration detecting abiotic changes and water stress to assessing sif estimation uncertainties lu et al 2018 sinha et al 2020 damm et al 2021 de cannière herbst et al 2021 xu et al 2021 zhang et al 2021 zeng et al 2022 specifically the scope model is widely used in applications across differing biomes such as tropical deciduous forests and temperate mixed forests sinha et al 2020 damm et al 2021 furthermore various terrestrial biosphere models have coupled with the scope model in order to fulfill the big picture of terrestrial photosynthesis and carbon cycle such as the orchidee bethy and beps norton et al 2018 bacour et al 2019 cui et al 2020 however as a 1 d model the scope model could not simulate spatial and structural heterogeneity and variability of vegetation horizontally for instance cui tianxiang et al coupled beps scope model and analyzed global distribution of scope sif simulation but it lacks cross vegetation analysis cui et al 2020 from this point of view validating the cross vegetation type effectiveness of scope simulated sif provides validity of scope in different plant photosynthesis conditions and also helps understand sif modeling thus this study analyzes decisive sif factors in the scope model and validates scope simulated sif across vegetation types using our proposed scope sif simulating methodology and gpp datasets specifically this study 1 analyzes decisive plant and climate factors of sif from confounding properties in the scope model thereby designing a scope sif simulation procedure 2 calculates global and regional sif samples synsif in 0 05 and 0 02 using factors selected in 1 3 explores how far synsif capture gpp across vegetation types validating by the correlation between sif and gpp finally we provide a comprehensive evaluation of synsif and other sif datasets from a unique perspective helping uncover the utility of the scope model in sif reconstruction thus we anticipate that our study will contribute to a deeper understanding of the scope model and its intense applications in monitoring terrestrial carbon cycle 2 materials and methods 2 1 a radiative transfer model the soil canopy observation of photosynthesis and energy fluxes scope model is a multi algorithm integrated 1 d vegetation radiative transfer model van der tol verhoef et al 2009 yang et al 2020 this model requires soil parameters leaf canopy optical variables aerodynamic and micrometeorological conditions and geometric observations the scope could retrieve outgoing canopy reflectance the turbulent heat fluxes chlorophyll fluorescence and photosynthesis conditions through physical processes incorporating radiative fluxes energy balance and multiple climate turbulences consequently scope as a sophisticated evaluation approach has been utilized in series of research focusing on ecosystem status monitoring and stress detection celesti et al 2018 shan et al 2021 2 2 sif factors sensitivity analysis sa involves calculating the relative contribution of several given variables to the variance of an output variable cannavó 2012 sa of the scope model was conducted to identify the contribution of variability in the 53 total input parameters to the variability in leaf chlorophyll fluorescence previous research has shown that some variables are showing more vital influence towards sif 1 leaf chlorophyll content cab leaf inclination lidfa and leaf area index lai determined 77 9 of the sif variability 2 in addition to the vital vegetation variables micrometeorological variables were significant in driving sif variability especially incoming shortwave radiation rs and air temperature ta and atmospheric vapor pressure vp verrelst et al 2015 overall the influential interpretive properties could be carefully categorized as leaf canopy biochemical and structural variables micrometeorological variables further accessible links are illustrated in table 2 leaf canopy biochemical and structural variables and their origins contain 1 cab and carotenoid concentration car derive from the mcd43a4 v6 nadir bidirectional reflectance distribution function adjusted reflectance nbar product in 500 m resolution another surrogate dataset refers to mcd43c3 providing brdf adjusted reflectance in 0 05 mcd43a4 has been deriving biochemical parameters from aboveground biomass evi to sif zhang et al 2018 he et al 2019 li and xiao 2019 yu et al 2019 wen et al 2020 2 500 m lai statistics are provided by the myd15a2h v6 combined leaf area index lai and fraction of photosynthetically active radiation fpar product micrometeorological variables include 1 rs and incoming longwave radiation rl come from the modern era retrospective analysis for research and applications version 2 merra 2 m2t1nxrad hourly time averaged 2 dimensional data collection 2 ta and wind speed data collections derive from m2t1nxflx from merra 2 as well 3 vp could be calculated from relative humidity and corresponding air temperatures in m2t3nvasm 2 3 sif simulation workflow the scope simulation workflow includes data preprocessing data integrating scope simulating and data postprocessing illustrated in fig 1 in data preprocessing we produced grid shapefiles both 0 02 and 0 05 screened qualified data and resampled all statistics into the consistent resolutions we initially removed cloud pixels for modis leaf canopy level variables surface reflectance and lai by filtering brdf quality bands in the google earth engine platform gorelick et al 2017 subsequently we utilized the look up table lut to retrieve foliage cab car from reflectance sets for each grid and lai was obtained from myd15a2h product other parameters such as leaf water content brown pigments and the internal structure parameter are ignorable compared with other sif drivers based on the sa result specifically the lut approach of acquiring vegetation properties is one of the common and efficient ways this approach involves repeating spectral simulations by using a specific model with all combinations of the input vegetation parameters constrained by reasonable ranges and distributions this study created a lut as a function of foliage cab car and cm including 9911 samples table 3 we then averaged different temporal datasets an hourly time averaged of m2t1nxrad and m2t1nxflx and a 3 hourly time averaged of m2t3nvasm into 8 day information for merra 2 micrometeorological variables vp derives from relative humidity datasets and corresponding air temperatures in the m2t3nvasm collection formulated as eq 1 abtew and melesse 2013 1 e a e t m i n r h m a x 100 e t m a x r h m i n 100 2 where e a refers to vapor pressure e t m i n and e t m a x refer to vapor pressure in corresponding least and highest air temperature daily respectively and r h m a x and r h m i n refer to the least and highest relative humidity daily respectively and e t is demonstrated in eq 2 2 e t 0 6108 e 17 27 t t 237 3 where t refers to specific air temperature the following data integrating step includes 1 calculating geometry including longitude and latitude for each point respectively in arcgis 10 and 2 extracting different formats into shapefiles then the scope simulation stage calculated sif in the scope 2 0 model for each point in shapefiles ultimately data postprocessing an elective and flexible procedure includes 1 using inverse distance weighted idw interpolation to fill in the vacant pixels bartier and keller 1996 2 the shapefiles are converted to other formats in arcgis 10 and a specific projection is also defined 3 clipping and merging operations are also conducted when necessary in this work postprocessing is skipped because the original products could reveal the sif essence of scope duveiller et al 2020 however those blank regions could readily be resampled fully through our elective procedure 2 4 appraising agreement previous studies demonstrate a universal sif gpp linear relationship eq 3 thus we validated scope sif product through a sif gpp linear correlation analysis frankenberg et al 2011 guanter et al 2012 sun et al 2017 3 g p p φ c o 2 β φ f s i f where φ c o 2 and φ f refer to light use efficiency of co2 assimilation and sif respectively and β is the escaping rate of sif photons energy partitioning in photosynthesis varies across climates and biomes implying that a linear equation might not accurately describe the sif gpp relationship however the consistency of spatial temporal dynamics in sif and gpp remains a robust experimental result and we transfer this linear correlation as the benchmark of sif products sun et al 2017 validating datasets include two gpp datasets used in evaluation sif s ability to monitor vegetation productivity and some satellite retrieved and downscaled sif datasets to further contrast different sif products detailed information is in table 3 the validating method used in our study is the sif gpp correlation analysis including λ index of eq 4 and linear regression analysis in eq 5 duveiller et al 2016 4 λ 1 n 1 i 1 n x i y i 2 σ x 2 σ y 2 μ x μ y 2 where μ and σ represent the mean and standard deviation respectively λ ranges from 0 to 1 indicating a reliable agreement 5 r 2 1 i 1 n x i x y i y i 1 n x i x 2 i 1 n y i y 2 where x refers to gpp y refers to sif and x and y mean average statistics 3 results 3 1 how synsif capture gpp spatially before evaluating how far synsif could capture gpp this section firstly displays different sif products we chose a classic and widely using machine learning based product gosif a newly half experimental dataset sif lue and gome 2 satellite product even four sif products have uniform spatial patterns different datasets reveal subtle differences the simulated synsif as shown in fig 2 a is highly coherent with other published products in most areas specifically southeastern north america amazon rainforests in south america mid region of eurasia and southeast asia all illustrate high sif in synsif gosif and gome 2 products sif lue faces some inconsistency with other data because it indicates that southeastern south america and africa have higher values and that sif in high latitudinal areas is absent this anomaly of sif lue might be due to sensor degradation in the corresponding temporal profile because its performance in their article is superior duveiller et al 2020 furthermore sif lue is quantitatively compatible with synsif because they both display far red maxima band 740 nm sif gosif reconstructs sif of 757 nm at which the sif signals are less high quantitatively than 740 nm although the gome 2 product retrieved sif in 740 nm observations from satellites suffer a signal loss during atmospheric absorption and transition zhang et al 2018 the sif gpp agreement indicated by λ index illustrates that scope simulating synsif could reveal global sif reciprocally with gosif shown in fig 3 this agreement also provides scope validity of the globe specifically in southeast asia fig 3 a synsif is an ideal proxy data for gpp and its index is higher than 0 7 in λ index by contrast other products including gosif sif lue and gome 2 show bottommost λ index 0 0 in most mid latitude regions among south north america and asia south america africa and oceania synsif gosif and gome 2 provide similar spatial patterns nevertheless we concede that gosif and gome 2 have stable consistency with gpp in high latitudinal regions whereas synsif performs inferior and sif lue lacks accessible data another agreement index demonstrated by sif gpp correlation coefficient r 2 in fig 4 further suggests how scope simulating synsif capture gpp across different vegetation type zones across six vegetation types forests gpp could hardly be captured across all sif products in most vegetation situations sif gpp r 2 rarely reach 0 2 fig 4 shows that in south america asia and africa scope simulated synsif could better reveal vegetation gpp across all six vegetation types compared with other three sif datasets the sif gpp linear relationship of synsif attains over 0 60 in south america amongst shrublands 0 64 grasslands 0 62 wetlands 0 63 and croplands 0 66 whereas other samples cannot reach 0 40 as shown in fig 4 b specifically sif gpp linear relationships of sif lue and gome 2 sif fluctuate around 0 1 among six vegetation types gosif showed a slightly higher consistency of sif gpp than sif lue and gome 2 sif r 2 of 0 34 in shrublands the synsif coefficients in forests and savannas show increases compared with gosif synsif increased r 2 by 0 10 and 0 28 respectively in asia as shown in fig 4 c the promotion of synsif is more dramatic in dense vegetation areas synsif outperforms gosif r 2 increase by 0 38 0 24 and 0 38 in forests shrublands and savannas respectively the performance of synsif further reaches 0 75 0 73 and 0 63 in sparse vegetation regions grasslands wetlands and croplands fig 4 e of african sparse vegetation areas also show a good agreement for synsif to gpp across all vegetation types the r 2 of forests shrublands savannas grasslands wetlands and croplands increase by 0 01 0 03 0 05 0 21 0 45 and 0 14 respectively fig 4 d and 4 f illustrate that synsif gpp r 2 outstrips gosif gpp r 2 in certain vegetation types synsif nicely reveals gpp under conditions of european shrublands grasslands and croplands with the highest sif gpp r 2 of 0 62 0 58 and 0 76 compared with other three datasets respectively moreover oceania shrublands grasslands and wetlands are advantageous regions to demonstrate gpp using synsif with r 2 of 0 67 0 58 and 0 67 respectively gosif is worthwhile in the complementary land of the regions above additionally fig 4 a shows a limited practicality of synsif in north america despite that synsif lags less than 0 1 in r 2 on average compared with gosif our experimental results recommend gosif to evaluate sif gpp in north america from both global continental and across vegetation type perspectives both synsif and gosif achieve an appealing correlation with the modis gpp product indicating that the scope model could capture global gpp in south america asia and africa when scope simulation has limited ability in some plant types gosif achieves better specifically gosif remains accurate and practical in high latitude areas of north america and asia however in low latitude areas synsif performs outstandingly across differing dominant vegetation types in southeastern asia southern south america and africa which could be further examined in the r2 comparison we would advise careful utility in north america because the agreements of synsif and gpp indicate that the scope model is unsuitable for estimating plant photosynthesis or vegetation production 3 2 how synsif capture gpp in time series fig 5 reflects the temporal sequences of two 8 8 areas in 0 02 grids which served as an exemplary continuous record for the seasonal dynamics of sif the wax and wane of vegetation productivity are captured in the us corn belt fig 5 a and england fig 5 b it is clear that scope simulation could reveal time series of vegetation photosynthesis we then further focused on parts of the us corn belt from 2017 to 2020 in fig 6 to further analyze the time series of scope simulation and its coherency with current gpp products in addition we quantitatively reorganized the synsif series with two gpp products produced by modis 500 m and landsat 30 m platforms in fig 7 as for seasonal variations the rise and fall of sif and gpp are consistent for instance in 2019 synsif landsat gpp and modis gpp show similar increasing and decreasing trend the variation of forests from june to july is lower than that from july to august for all three datasets specifically synsif increased 0 04 mwum 1sr 1 from june to july and decreased 0 14 mwum 1sr 1 from july to august modis gpp and landsat gpp both experienced increases of 0 01 kgcm 2 during june july while the former and the latter decreased 0 02 kgcm 2 and 0 03 kgcm 2 during july august respectively other vegetation types also shared this trend although classified by dominant vegetation types 0 02 synsif and 500 m modis gpp hardly capture quantitative variation inside the dense fig 7 a and d and sparse fig 7 b and c vegetation regions however the landsat gpp clearly perceives vegetation differences a more drastic fluctuation of croplands in 2019 and 2020 in fig 7 b modis gpp shows a counterintuitive fall and rise in july 2020 fig 7 a d e whereas synsif and landsat gpp demonstrate slight fluctuation and dramatic rise and fall respectively the reason is that scope simulating sif avoids biases stemming from the degradation of modis sensors because of scope computation thereby also illustrating conformity with landsat gpp specifically the lai dataset derives from aqua exclusively through which systematic biases would affect synsif more slightly running and zhao 2015 the compromise of synsif between the excellent performance of landsat and relatively deteriorated modis gpp products attributes partly to the use of both terra aqua reflectance dataset and aqua only lai dataset products meantime weakening a severe impact of degradation of sensors 4 discussion 4 1 sif factors in scope simulation from this study s results we suggest that cab and lai are two critical properties when simulating sif using the scope model moreover scope users should also consider different responsible parameters while adopting differing spectral regions of sif in the scope model our analysis holds that the spatial and seasonal sif differences are mainly controlled by fluctuant cab and lai derived from 500 m modis projects in our study despite different microclimates merra 2 at 50 50 km grids spatially consistent with the sensitivity analysis literature the effect of spatial cab on sif at 740 nm is more significant while the change of lai takes relatively minor responsibility revealed in fig 8 verrelst et al 2015 nevertheless sif in september 2020 shows that low level lai in the eastern area accounts for the weak sif thus when promoting spatial temporal resolutions of the scope model users would better choose accurate and precise cab and lai datasets and also consider essential climate factors despite coarse pixels for example users could modify specific parameters in lut to improve the accuracy of cab or replace the retrieval results with different sensor datasets such as landsat reflectance thereby avoiding notoriously suggested sensor degradation of modis and overcoming persistent cloudiness and coarse spatial resolutions scholze et al 2017 the sa also indicates that the relative influence of different properties both plant and climate factors varies in distinct bands verrelst et al 2015 thus when modifying the target sif spectral bands and promoting finer temporal resolutions using scope we suggest analyzing influential series of all variables in sa and putting more spatial resolution concerns on higher sensitive properties further details should also be considered in field level research to reflect micro details such as leaf inclination and the maximum rate of carboxylation verrelst et al 2015 merra 2 provides hourly meteorological information which would play a key role in promoting finer temporal resolutions 4 2 sif factors of artificial sif products our study simulated sif with radiative transfer model and our sample synsif reveals a superior correlation with gpp and also a geographically complementary characteristic with gosif amongst other three sif datasets gosif is a widely used data driven product sif lue placed an opening endeavor towards semi physiologically downscaling method gome 2 remains a classic satellite retrieving sif product however these four products above provide different sif factor consideration when focusing on interpretative parameters of sif eq 6 represents a well accepted interpretation of sif joiner et al 2014 6 s i f λ par f p a r c h l φ f λ f e s c λ τ a t m λ where f p a r c h l the fraction of chlorophyll absorbed par is a function of vegetation cover fraction lai leaf cab and also plant structure f e s c λ known as the escape ratio depends on leaf inclination distribution and sun target sensor geometry par and τ a t m λ are influenced by a complex combination of incident energy water availability and atmospheric scattering and φ f λ the fluorescence quantum yield turns on water availability most data driven methods in table 1 adapted modis brdf corrected surface reflectance representing geometry correction as the only ancillary dataset gentine and alemohammad 2018 zhang et al 2018 yu et al 2019 wen et al 2020 however previous studies show that both short term variability of environmental stress and plant status would cause seasonal patterns of sif and surface reflectance rarely presents the whole picture jonard et al 2020 thus utilizing surface reflectance solely for gap filling or downscaling sif is relatively inappropriate as for synsif and gosif both grasp vegetation and meteorological conditions as primary factors of sif while gosif selects evi as the proxy of vegetation status synsif directly captures foliage conditions and canopy structures from cab car and lai it has been stated that satellite derived vegetation indices either evi or ndvi are more indicative of vegetation greenness grace et al 2007 however physiologically when facing climate turbulences such as drought plants would firstly reduce internal functions photosynthesis followed by a decrease of cab then exterior greenness could be revealed by vegetation indices zhang et al 2018 consequently as synsif utilized measuring pigment concentrations and lai from both foliage and canopy levels helps clarify plants responses towards climate variability more directly scholze et al 2017 we suggest that future sif products adopt plant biochemical parameters such as cab car and lai rather than proxy properties like ndvi synsif is also highly consistent with gosif in meteorological property selection gosif used meteorological parameters including par vapor pressure deficit and air temperature to account for solar radiance water availability and temperature stress li and xiao 2019 in this method par serves as a component of downward shortwave radiation and is also driven by atmospheric opacity and scattering wang et al 2020 in this study synsif also considers incoming shortwave radiate directly leading to par air temperature and atmospheric vapor pressure along with incoming longwave radiation and wind speed data to depict microclimate turbulence further completely sif lue advances from data driven methods toward a semi experimental exploration duveiller et al 2020 sif lue develops its explanatory variables nirv ndwi and afternoon overpassing lst and unique semi experimental equation thus it achieves confirmative validation with tropomi collection duveiller et al 2020 specifically sif lue applies a calibrated function of a vegetation index water and thermal stress indicators nirv and ndwi both derive from specific vegetation or water sensitive surface reflectance wavelengths however previous studies have shown that the differences of plant physiology and canopy structure such as lai and cab profiles rather than reflectance based indices affect across biomes when revealing spatially details scholze et al 2017 sun et al 2017 additionally lst and air temperature have different responses to atmospheric conditions mutiibwa et al 2015 and the complex interaction of the surface energy balance system further differs lst from air temperature especially diurnally zhu et al 2013 gome 2 is one of the primary since 2009 satellite inversion products contributing to the exploration and estimation of vegetation or crop productivity he et al 2017 sloat et al 2021 exemplary sif datasets such as sif005 and rsif also utilized gome 2 as original sets to further investigate downscaling methods gentine and alemohammad 2018 wen et al 2020 however its 40 km 40 km resolution obscured spatial details and consequently suffered lattice like inaccuracy in fig 3 which is the primary motive for most fine spatial resolution sif solutions from sif factors point of view considering and selecting decisive sif factors is unavoidable when reconstructing downscaling or gap filling sif products although scope model is 1 d it could capture and reveal photosynthesis and vegetation gpp thus considering radiative transfer modeling and referring scope sa results into data driven methods might contribute to sif dataset production 4 3 opportunities and caveats of scope sif simulation the scope model plays a key role in much research ranging from estimating terrestrial vegetation photosynthesis to advancing terrestrial biosphere models such as beps scope and bethy scope norton et al 2018 cui et al 2020 sinha et al 2020 the scope has also been utilized worldwide including various vegetation types such as forests croplands and different hemispheres indicates its robustness bacour et al 2019 raczka et al 2019 xu et al 2021 in the study from cui sun et al it is proved that the scope simulated sif and the gome 2 sif were highly correlated with r2 0 5 rmse 0 36 mwum 1sr 1 wu et al 2022 another study also indicates that the scope model can also reliably illustrate sif diurnal cycles with the rrmses for all 106 spectral measurements of 24 35 hu et al 2018 these studies demonstrate the overall accuracy and precision of the scope model there are also studies however indicating inconsistency of the sif gpp linear relationship in specific areas thus in this study we simulated sif through scope and pointed out its ability to capture gpp products across vegetation types on different continents through our study we summarized some advantages of scope simulation 1 firstly this study distinguishes five key interpretative properties leaf chlorophyll content leaf area index incoming shortwave radiation air temperature and atmospheric vapor pressure from confounding sif factors in scope model exemplifies global and regional sample datasets we would recommend these factors not only in scope simulation but also in future sif downscaling and gap filling product construction this advantage can be attributed to physiological theories that remain rarely permeable for data driven strategies sif is far from a simple phenomenon mohammed et al 2019 however most previous datasets conservatively extract characteristic traits from modis surface reflectance gentine and alemohammad 2018 zhang et al 2018 yu et al 2019 wen et al 2020 furthermore prevalent machine learning methods focus on fitting sample characteristics with sif thus selecting surrogate variables and training samples are vital for data driven methods however uneven training sampling occurs and varies in different locations and temporal profiles due to the sparse observations of satellite instruments thus predicting uncertainty remains a challenge to quantify as mentioned in a previous dataset oriented article de cannière herbst et al 2021 thus our study proposes valid sif factors through sensitive analysis which could also be tested by data driven methods in the future 1 another merit refers to facilitating applications due to satisfactory spatial resolution long term series and completely spectral coverage using scope thus accelerating the synergy of ground based airborne and satellite observations for terrestrial data assimilation systems as the direct proxy of photosynthesis sif has been considered as a vital component to be utilized within the carbon cycle data assimilation system koffi et al 2015 for example many terrestrial biosphere models including the orchidee bethy and beps have coupled sif to reduce the uncertainty of model estimation and improve the understanding of the earth s climate carbon system norton et al 2018 bacour et al 2019 cui et al 2020 the global carbon cycle is entangled with hydrological turbulence energy cycles and ecosystem dynamics thus assimilating various in situ observations and satellite measurements is critical scholze et al 2017 however such efforts were hampered from satellite levels because coarse spatial resolutions complicate harmonious infusion with ground measurements lu et al 2018 through the scope model simulated sif would facilitate synergy from satellite airborne and ground platforms spectrally scope retrieves entirely fluorescent spectra from 650 nm to 800 nm at 1 nm resolution simultaneously covering 680 nm 740 nm and 760 nm on which are widely focused on sif applications goulas et al 2017 he et al 2017 gonsamo et al 2019 dechant et al 2020 furthermore hand held devices stationary and mobile field systems uavs and other airborne sensors have achieved full spectral measurement damm et al 2015 amir et al 2021 thus we expect full spectra applications in globally terrestrial vegetation monitoring however simulated sif still fails to recover sif in tropical rainforests semi arid regions and northern tundra partly due to its 1 d vertical property and unsatisfactory consideration of regionally unique parameters moreover simulating sif also faces computing expenses 1 a relatively weak correlation between synsif and other sif products and gpp was examined in tropical rainforests semi arid regions and northern tundra one possibility is that modis exhibits small infidelity in forest seasonality and experiences sensor degradation huete et al 2006 sayer et al 2015 whereas sif reveals stronger seasonal variations joiner et al 2014 smith et al 2018 magney et al 2019 li et al 2020 another extrapolation is that incorporating climate variables and plant traits could improve sif prediction as proposed in previous work wen et al 2020 as eq 6 shown we would consider more climate and plant parameters in the future porcar castell et al 2014 for example clumping index and lidfa could indicate the differences across biomes in plant physiology and canopy structure and carbon dioxide concentration plays a role in atmospheric fluctuation gentine and alemohammad 2018 liu et al 2022 luo et al 2022 pei et al 2022 xu et al 2022 in semi arid and tundra regions sif signals are generally lower in magnitude and thus more susceptible to noisy signals compared with other more productive biomes wang et al 2019 wang et al 2019 furthermore the scope model extrapolates that the vegetation layer is one dimensional thus it lacks physical bedrock applying in dense vegetation types such as forests 1 using radiative transfer models would lead to expensive computing consumption jacquemoud et al 2009 specifically a single graph in fig 6 took 12 h in our macos 11 with intel core i7 due to the limitation of model processing speed the global scale long term series scope simulation is hindered 5 conclusion this study disentangled decisive sif factors in scope radiative transfer model from its confounding properties then we designed scope sif simulation procedure and calculated sif in 0 05 globally and 0 02 regionally spatial synsif then we explore the quantified agreements between gpp and different sif products including widely used artificial sif datasets and scope simulated synsif analyzing how simulated sif capture gpp across vegetation types our main conclusions are 1 there are five decisive sif factors in scope model including plant status leaf chlorophyll content and leaf area index and meteorological parameters incoming shortwave radiation air temperature and atmospheric vapor pressure 2 the linear relationship of synsif gpp outachieved other sif datasets across all six vegetation types in southern south america asia and africa improving r 2 averagely by 0 33 0 28 and 0 15 respectively 3 synsif in oceania and europe revealing gpp better in shrublands with synsif gpp r 2 increasing by 0 15 and 0 16 respectively and grasslands with synsif gpp coefficients increasing by 0 14 and 0 06 respectively illustrated spatially complementary characteristics with gosif across varying vegetation types we thus anticipate that our study would deepen further understanding in scope simulated sif in multi vegetation type applications especially terrestrial biosphere model coupling credit author statement s y j y and s shi designed the study s y and y z carried out computations s y j y s shi and s song provided the analysis s y made the tables and figures s y and j y wrote the first draft and revised the manuscript with s shi and s song y z y l and l d declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research received funding from the national natural science foundation of china nsfc 41801268 we acknowledge the open access of the scope 2 0 model and prospect d model we also thank google earth engine a free platform of cloud computing satellite projects including modis merra 2 gome 2 and landsat series and previous downscaling sif datasets gosif and sif lue lead the way for this research 
24381,citizens community groups and local institutions participate in voluntary biological monitoring of population status and trends by providing species data e g for regulations and conservation sophisticated statistical methods are required to unlock the potential of such data in the assessment of wildlife populations we develop a statistical modelling framework for identifying territories based on presence only citizen science data the framework can be used to jointly estimate the number of active animal territories and their locations in time our approach is based on a data generating model which consists of a dynamic submodel for the appearance removal of territories and an observation submodel that accounts for the varying observation intensity and links the data to the territories we first estimate the observation intensity using past presence only observations made by citizens conditioning on previously known territories we then infer the territories using a state of the art sequential monte carlo method which extends earlier approaches by allowing for spatial inhomogeneity in the observation process we verify our data generating model and inference method successfully in synthetic scenarios we apply our framework for estimating the locations and number of wolf territories in march 2020 in finland using one year of confirmed citizen made wolf observations the observation intensity is estimated using wolf observation data collected in 2011 2019 conditioning on official territory estimates and data from gps collared wolves our experiments with synthetic data suggest that the estimation of territories can be feasible with presence only data our location and territory count inferences for march 2020 based on past data are comparable to the official wolf population assessment of march 2020 by the natural resources institute finland the results suggest that the framework can provide useful information for assessing populations of territorial animals furthermore our methods and findings such as the developed data generating model and the estimation of the spatio temporal observation intensity can be relevant also beyond the strictly territorial setting keywords citizen science data bayesian statistics sequential monte carlo spatio temporal model territory identification presence only data data accessibility statement the code used to reach the conclusions of the paper is available at the repositories https github com antiphon tassu intensity intensity analysis https github com skarppinen tassu filtering particle filter implementation and experiments of sections 3 2 3 4 the repositories and links therein also contain simulation data and results related to the experiments the data on the finnish wolf population is not publicly available because it contains sensitive information on local wolf behaviour that could be exploited in poaching or disturbing wolves 1 introduction volunteers contribute to many wildlife monitoring programs but standardised monitoring schemes are available for only a small number of taxa in a few countries gregory et al 2005 isaac 2014 citizens community groups and local institutions participate in biological monitoring of population status and trends by providing species data e g for regulations and conservation conrad and hichley 2011 lawrence 2006 the involvement of citizens as data collectors has demonstrated its ability to gather massive amounts of data at a spatio temporal scale unattainable by research teams and state authorities active in biodiversity monitoring silvertown 2009 for instance in many european countries hunters are integrated as data providers in wildlife management structures that are intended to support sustainable harvest bragina et al 2015 cretois et al 2020 linnell et al 2015 statistical developments in data integration as well as more rigorous protocols for data collection are needed to unlock further the potential that volunteers data holds cretois et al 2020 isaac 2014 the statistical interpretation of citizen collected data faces problems less frequently encountered in traditional scientific research for example the spatio temporal sampling effort of citizens is usually not known nor controllable sophisticated methods that model the data collection process offer the greatest potential to estimate e g timely trends isaac 2014 in this paper we propose a statistical modelling framework that can be used to make inferences about animal populations with territorial behaviour using observations reported voluntarily by citizens more specifically our focus is on the following scenario citizens report presence only observations of territorial animals each observation consists of a gps coordinate and an approximate time stamp we wish to estimate the number and locations of the animal territories within some area and time interval using the data collected by the citizens prior knowledge on the territorial behaviour of the species is assumed to exist in the form of a typical territory size and on the rate of appearance and disappearance of territories because of the high spatio temporal variability common in citizen science observation processes modelling of the varying sampling effort that is the observation intensity is a crucial first part of our framework we take this variation into account by modelling the intensity based on past data this yields intensity functions that capture the spatio temporal variation in the observations reported by citizens these functions are then fed into a data generating model consisting of two submodels that model the appearance and removal of territories and the generation of citizen science observations from the territories respectively to estimate the number of territories and their locations we use the latest available citizen science data and perform bayesian inference for the data generating model the data generating model jointly approximates the evolution of the number of active territories and their locations in time characterised by a sequence of posterior distributions conditioned on observation sets of increasing size in the engineering literature similar models are called tracking models cf goodman et al 1997 indeed the inference algorithm we develop is a rao blackwellised particle filter similar to those developed for tracking särkkä et al 2007 vihola 2007 we further elaborate these methods by employing a state of the art optimal resampling of fearnhead and clifford 2003 and further refine the inference algorithm so that it can incorporate the spatial inhomogeneity arising from our observation model our data generating model is similar to dynamic occupancy models royle and kéry 2007 and open n mixture models zhao et al 2017 in the sense that it has a latent process model for the appearance and disappearance occupancy of animal territories and a variable observation intensity however unlike in the work of zhao et al 2017 the principal objects of analysis in our model are animal territories rather than individual animals in addition our model does not assume a fixed set of potentially occupied sites but operates in continuous space where territories are delineated without a pre defined grid finally our model is formulated in continuous time which allows the estimation of the state of the population at any time points within the interval of interest for example our model can be used to track the state of the population at daily or weekly time steps in contrast the methods of royle and kéry 2007 and zhao et al 2017 operate in discrete time and are typically used for annual data with a considerably smaller number of time steps the motivation for the development of our modelling framework has been to aid in the task of assessing the finnish wolf canis lupus population although the framework can be relevant for other territorial species as well currently the finnish wolf population is assessed annually in march by the natural resources institute finland luke in the assessments wolf observations provided by citizens from the beginning of august to the end of february are combined with non invasive genetic samples tracks of gps collared wolves and records of known mortality kojola et al 2018 the assessments are carried out in two phases in the first phase a panel of experts conducts a systematic review of all the data and judges territory boundaries that are potentially occupied by wolf packs or pairs in march in the second phase a bayesian state space model is used to infer the number of wolves living in each territory by combining wolf observations dna recaptures and known mortality heikkinen et al 2020 in particular we envision that the developed framework can work as a useful tool in the first phase providing a statistical look at the citizen science data and an aid in judging the territory boundaries we examine the performance of the developed particle filter with a sequence of simulation experiments where we start from simple simulated conditions and work towards conditions that resemble more closely our concluding experiment which is a realistic situation that could be faced in the assessment of the finnish wolf population here we use previous estimates of territory locations and citizen provided observations to estimate the spatio temporal variation of the conditional probability of wolf observations given known existence of wolf territories even though similar approaches have been used for species abundance estimations e g renner et al 2015 ver hoef et al 2021 tang et al 2021 the conditioning requirement provides a novel challenge using the results of said intensity modelling we apply our data generating model to a real data set consisting of wolf observations made by finnish citizens between april 2019 and march 2020 we estimate the number and locations of wolf territories and compare the result to the official estimates by the natural resources institute finland luke which are based on the method discussed above the main contributions of this paper are as follows first we believe that the developed framework is of interest in assessing populations of territorial species using presence only citizen science data we focus on the application to wolves but our methods are readily adaptable for other territorial species second we believe that the observation intensity estimation is of its own independent interest because it addresses the problem of estimating the conditional spatio temporal intensity of presence only citizen science observations third from a methodological point of view the developed data generating model and particle filter might be relevant also in the context of general purpose target tracking e g vihola 2007 särkkä et al 2007 applications where a spatially varying observation process is needed 2 materials and methods the general modelling framework proposed in this paper can be summarised into four successive analysis steps numbered from one to four the flowchart in fig 1 depicts their dependencies and relation with each other highlighting the inputs outputs and datasets associated with each step the following subsections will explain how we apply the framework in the context of wolf territory estimation section 2 1 discusses the datasets a b and c section 2 2 then describes the data generating model which motivates the intensity estimation consisting of steps 1 and 2 which in turn are discussed in sections 2 3 and 2 4 respectively section 2 5 describes step 3 of the analysis the statistical inference based on the data generating model using a particle filter we have developed for the problem finally in section 2 6 we conclude with a description of step 4 where we extract the number and locations of the territories from the output of the particle filter 2 1 data in this section we will discuss the datasets a b and c seen in the framework of fig 1 in summary the datasets a and b contain past data used in the construction of the data generating model and dataset c contains the latest data to be processed by the particle filter each datum in datasets a and c is a spatio temporal point that is it has the form t y where t is the time of observation and y is a two dimensional point on a domain we denote by d y the difference between datasets a and c is that dataset a is past data and dataset c corresponds to the latest data we wish to infer the territories with in contrast dataset b is more heterogeneous and contains all additional data such as covariates and expert knowledge required in the construction of the data generating model 2 1 1 datasets a and c we extract the spatio temporal points in datasets a and c from a digital large carnivore observation database named tassu meaning a paw in finnish kojola et al 2018 the observations enter the database through a network of approximately 2000 large carnivore contact persons lccps who are nominated by management associations and educated by the finnish wildlife agency and luke in the biology ecology and movement behaviour of wolves as well as footprint identification there are however no formal exams used in the nomination process the lccps have their own local trusted network of people who report their observations of wolves to the lccp these networks consist mostly of hunters that are proficient in identifying wolves based on sightings tracks prey kills and camera trap documents in addition it is in principle possible for any citizen to report their observations since the contact details of the lccps are publicly available and known in local rural societies pellikka and hiedanpää 2017 however the networks of the lccp are particularly relevant for wolf sightings in snow free conditions because such observations usually cannot be verified afterwards wolf observations found to be valid by the lccps are saved into the tassu database each saved datum includes information about the time and location of the observation the type of observation such as wolf track sighting droppings game camera photograph prey kill site or livestock predation and the estimated count of wolves observed simultaneously the count estimate is based on the judgement of the lccp based on the information available since the observations saved to the database are subject to the confirmation of the lccp possibly days after the initial report we consider the observation times to be accurate on a daily granularity in total datasets a and c contain all observations from the tassu database that reported two or more wolves between january 2011 and march 2020 since the purpose of our framework is to infer the number and locations of wolf territories we only focus on observations that report more than one wolf since this indicates that the observed wolves form a wolf pack and very likely exhibit territorial behaviour in contrast observations of single wolves can originate from lone vagrant wolves that do not yet maintain a territory furthermore for simplicity we make no distinction for data points with different observation types we regard each observation simply as a spatio temporal point we return to this matter in the discussion we split the data such that dataset c contains the observations made between april 1st 2019 and march 31st 2020 and dataset a the observations before this the locations in dataset c are illustrated in fig 2 top left the domain of the locations d y is mainland finland south of the reindeer husbandry region in the north the wolf territories in the reindeer husbandry region are few and short term owing to lethal control that is justified by the prevention of damages to reindeer husbandry we organise the datasets a and c according to so called wolf years a wolf year starts april 1st and ends in march 31st of the next year hence dataset c consists of the observations made during the wolf year 2019 2020 the organisation of the data to wolf years has two reasons first as described in the introduction the annual finnish wolf population assessments describe the state of the wolf population in march second the data indicate that the highest observation intensity is reached during the winter season and declines towards the spring year by year changes in the observation activity are expected to occur between the winter seasons rather than between calendar years we will also use the term wolf month to refer to the months within a wolf year such that the first wolf month corresponds to april the second to may and so on 2 1 2 dataset b dataset b contains two kinds of information most importantly dataset b contains information about past known wolf territories until march 2019 that is before the wolf year associated with dataset c in addition dataset b also contains covariates dataset b is primarily used in the intensity modelling described in section 2 3 but also for setting certain parameters in the data generating model the details on how the data sources described below are used in the intensity modelling are given in section 2 3 the relation of dataset b to the parameters of the data generating model is discussed in the results of section 3 3 the information about past wolf territories was constructed from two sources of data independently of datasets a and c we call the resulting territories auxiliary territories the first source consists of the space time trajectories of 34 gps collared wolves that were tracked between 2011 and 2019 the transmitters in the collars stored the wolf s position at one or four hour intervals depending on the season the capture handling and immobilisation protocols of these wolves are described in kojola et al 2016 we assumed that each collared wolf was part of a wolf territory the trajectories contain outlier recordings such as test measurements at a lab or glitch jumps of hundreds of kilometres occurring due to device malfunction or other reason some trajectories also cover two clearly separate territories we therefore preprocessed the data as follows first the recorded gps trajectories were divided into separate contiguous trajectories at temporal jumps of more than two weeks or spatial jumps of more than 100 km trajectories less than 24 h were rejected second each contiguous trajectory was processed by assigning to each trajectory point a probability of being an outlier the probability was given by the velocity density v e x p 28 8 with median at 20 km h multiplied by the function w d c x 1 x 5 σ 1 x 5 σ exp 0 5 x 5 σ 2 4000 0 2 where d c denotes a point s distance from the trajectory s centre of mass and σ is the 90 truncated standard deviation of the centre of mass distances points with probability less than 50 were excluded from the trajectory finally the first and second steps were repeated to account for significant gaps after the outlier detection second step from each remaining trajectory an auxiliary territory was constructed as a polytope in d y t b where t b denotes the time span 2003 03 04 2019 03 31 by taking the cartesian product of the convex hull of the spatial locations and the time interval of the trajectory in total 59 auxiliary territories were constructed from the gps trajectories covering approximately 74 000 km 2 and with time spans that add up to approximately 36 5 years the second type of auxiliary territories were constructed based on expert knowledge using the official population assessments of luke from 2017 onwards the assessments include estimates of active wolf pack territories as polygons in d y during march of the corresponding years fig 2 bottom left shows the active pack territory location estimates of experts in the assessment of march 2019 we assumed that these territories were active also during january and february we then constructed polytopes in d y t b as the cartesian products of the polygons and january march intervals of each year between 2017 2019 the resulting 203 expert judgement auxiliary territories covered approximately 180 000 km 2 with time spans that add up to approximately 35 3 years the additional covariates in dataset b consist of two datasets the first of these is the corine land cover data for 2018 finnish environment institute syke 2018 the dataset comes as a raster covering finland and contains an approximate land use class e g river small road for each of its 20 by 20 metre cells the original 49 classes were first reclassed down to 8 residential areas other build areas roads cultivated fields lakes and rivers swamps and other wetlands closed forests and open forests for each of the 8 classes we aggregated their frequency in 1 km 2 cells and to slightly reduce the amount of zeros applied smoothing with a gaussian blur with standard deviation 3 km each cell of the resulting 8 layer raster stack then contained a vector giving the smoothed frequencies of each land use class in and near the 1 km 2 cell since the resulting vector for each cell k corine k 1 corine k 8 is nearly a simplex we dropped the first class residential areas and kept the remaining 7 as frequencies a log ratio transformation which is a popular approach in compositional data analysis might have been more suitable here but was not done due to numerous zeros in all classes the corine road information capture larger streets and highways and to describe accessible forest areas we computed an additional forest road frequency variable to dataset b this variable is derived from the national road and street database digiroad finnish transport infrastructure agency 2021 from the database we extracted the polyline feature class 12 roads and paths traversable by offroad vehicle we binarised the polylines on to the 20 by 20 metre cells of the corine land cover data and then computed the frequencies of those cells on a 1 1 km raster we denote the value of this variable in the k th 1 km 2 cell by f o r e s t r o a d k 2 2 data generating model in this section we discuss the data generating model we have developed for citizen science observations of a territorial species the model we have developed is more general than the instance of it that we use for modelling the wolf data therefore this section will also highlight certain modelling decisions we make in the present application furthermore the data generating model we describe here is ideal in the sense that it must be approximated further to be tractable for our inference method we will discuss this in more detail in section 2 5 that is devoted to the filtering algorithm for the interested reader the mathematical details of the general data generating model are given in sections 1 1 and 1 2 of the supplementary material the data generating model consists of two submodels the birth and death process and the observation model which we will discuss in sections 2 2 1 and 2 2 2 respectively in summary the birth and death process models how new territories emerge and disappear and the observation model describes how each existing territory produces citizen science observations spatio temporal points as in dataset c 2 2 1 birth and death process our model assumes that the territories of interest exist and emerge within a domain denoted by d μ r 2 with d μ d y the location of the territory i is represented by its centroid μ i d μ which is assumed to be constant in time new territories emerge within d μ with the instantaneous birth intensity λ b u n u λ b0 where λ b u is the known birth intensity function and n u stands for the number of existing territories at time u the function λ b u can be interpreted as birth intensity per each existing territory the baseline birth intensity parameter λ b0 on the other hand models additional birth intensity due to external factors such as inflow from outside d μ for modelling of the wolf data we simplify λ b u to a constant denoted by λ b and set λ b0 0 as a new territory emerges its centroid follows the uniform distribution on d μ similarly each existing territory disappears with the instantaneous death intensity λ d u that is the total instantaneous death intensity induced by all territories equals λ d u n u in case of the wolf data we fix λ d u to a constant that we denote by λ d therefore the lifetime of a single territory follows an exponential distribution with mean λ d 1 furthermore in a similar fashion as was done in vihola 2007 we symmetrise the birth and death process by setting λ b λ d λ bd where λ bd then remains the only birth death intensity parameter this minimises the bias in the birth and death process and a priori leads to a constant conditional expectation for the number of territories in time the initial distribution of the model is a joint distribution of the number of territories and the locations of their centroids the initial locations of the territory centroids can either be distributed uniformly on d μ or subject to gaussian error truncated to d μ around some location estimate 2 2 2 observation model the observation model conditional on the territory locations and lifetimes generated by the birth and death process describes how each territory with its centroid on d μ produces citizen science observations the baseline underlying model for an observation from a single territory i that exists at any given time point is bivariate normal n μ i σ obs where σ obs describes the size and shape of the territories we assume that the territories are roughly circular in shape by setting σ obs σ obs 2 i where i denotes the 2 2 identity matrix and σ obs 0 is a standard deviation related to the territory size it is useful to interpret this territory model using the circular contours of the distribution n μ i σ obs 2 i a circle of radius 1 χ α 2 2 σ obs centred at μ i is assumed to enclose the instantaneous location of the wolves belonging to the territory with probability α here χ α 2 2 corresponds to the 100 α quantile of the chi squared distribution with two degrees of freedom because of the temporal and spatial variability inherent to citizen science observation processes the observation model modulates the number of observations produced from the territories based on a temporal intensity function λ obs τ defined on a time interval of interest 0 t and a spatial intensity function λ obs s defined on the domain of the observed locations d y these intensity functions are assumed spatio temporally separable since there is limited data for their estimation which is further discussed in section 2 3 the values of these functions are tied to the number of observations the territories produce in time and space for constant functions λ obs s y l x 0 and λ obs τ u l t 0 our model assumes that the expected number of observations that a single territory produces on d y in a unit of time is approximately λ obs l x l t where λ obs is a scalar multiplier for the intensity functions the intensity functions λ obs τ and λ obs s are assumed known fixed and we discuss their estimation in sections 2 3 2 4 in addition to the observations originating from the territories the observation model also accommodates so called clutter observations that are understood as erroneous observations not originating from actual territories these observations are assumed to be distributed uniformly on d y and their intensity is likewise modulated by λ obs τ and λ obs s but multiplied by a different scalar parameter λ c the relative values of the scalar multipliers λ obs and λ c can be used to model the rate of the total number of observations believed to originate from the territories mathematically conditional on the territory locations and lifetimes our observation model defines a three dimensional inhomogeneous poisson process in time and space whose intensity function is given in equation 5 of the supplementary material the data generating model parameters in fig 1 are given by θ λ obs λ bd λ c σ obs d y d μ and the intensity functions λ obs τ and λ obs s 2 3 observation intensity modelling the following two sections discuss how we estimate the intensity functions λ obs τ and λ obs s in the observation model of section 2 2 2 this section focuses on step 1 of the modelling framework in fig 1 detailing the intensity model we fit to the past datasets a and b discussed in section 2 1 the primary data for this step are the spatio temporal points in dataset a discussed in section 2 1 1 we assume that each of these observations originated from an active wolf territory in this section we denote by ψ s i t i the spatio temporal point pattern of the wolf observations in dataset a with locations s i d y and dates t i t a 2011 01 01 2019 03 31 we assume the arrival of tassu reports ψ can be approximated by an inhomogeneous poisson process illian et al 2008 note that reporting depends on two consecutive events an observer is at a territory and they make and report an observation the data contains no information if an observer was on a territory but did not observe wolf activity the observer and reporting intensities are therefore confounded the situation is notably different from presence absence citizen science data such as for birding analysed with point processes by tang et al 2021 as in addition to absences not being measured the observers cannot be assumed to have been actively looking for wolf activity in the first place our situation is more akin to presence only analysis renner et al 2015 ver hoef et al 2021 with the nuance that instead of estimating species abundances the goal is to estimate the connection between a wolf territory s presence and the emergence of the tassu reports to account for the conditioning on a wolf territory s presence in this estimation we constrain the tassu observations to the auxiliary territories in dataset b detailed in section 2 1 2 given the observations on the auxiliary territories we estimate the intensities by aggregating the observations and then using standard poisson regression in the generalised additive models gam framework more specifically we fit the model on observation units given by spatio temporal grid cells c k v k t k with temporal resolution t k 1 month and spatial resolution v k 1 km 1 km from this discretisation of d y t a we only consider the subset of cells that intersect the auxiliary territories which is 11 9 million cells and then count the tassu reports in each such cell denoted by n k ψ c k resulting in 4816 non empty cells the auxiliary territory polytope which a cell c k overlaps is denoted by a k for each cell c k we let u k and y k represent its centroid in time and space respectively and finally define λ k τ t k λ obs τ u d u and λ k s v k λ obs s y d y then the counts in the grid cells are modelled with a poisson regression model of the following form 2 n k poisson λ k τ λ k s a k log λ k τ λ k s month u k year u k x y k β smooth y k x y k 1 expert a k corine k forestroad k t the offset a k is the area of the territory that grid cell c k belongs to and accounts for an assumption of the instantaneous location of the wolves following a uniform distribution within a k i e a pack on a larger territory is harder to observe the year and month effect were included as factors to model seasonal effects and year to year differences we used wolf years as discussed in section 2 1 1 for the factors year and month we did not include weather station information e g snow depth mainly because their monthly aggregates are highly correlated with month effects but also in order to avoid spatio temporal interaction terms to reduce model complexity given we have only 1 non zero units the spatial effects are modelled with covariates x and a residual smooth term the indicator 1 expert a k was included to adjust for potential discrepancies between the different types of auxiliary territories gps tracks expert estimates the numerical covariates corine k corine k 2 corine k 8 and forestroad k were described in section 2 1 2 and capture environmental variability the estimation was carried out using the statistical software r and the gam function mgcv bam with a smooth term smooth y k defined as a tensor product te term in x and y coordinates of the cell centroid y k the smoothness penalty choice was left to the default which is generalised cross validation wood 2017 2 4 computing intensity functions for the data generating model next we discuss how we compute the intensity functions λ obs τ and λ obs s based on the intensity model of section 2 3 fit to the past datasets a and b this section focuses on step 2 in the modelling framework of fig 1 the aim is to obtain intensity functions for the data generating model that anticipate the spatio temporal intensity of the observations in dataset c we model the intensity functions as piecewise constant such that λ obs τ takes on the value c t i during wolf month i i 1 12 and λ obs s takes on the value c v j in each cell v j d y in summary the c t i s and c v j s are computed by using quantities calculated from the predictions of the intensity model 2 in eq 4 below the computation proceeds as follows first assume that the intensity model 2 is fit using the datasets a and b then using the fitted model we predict the spatial effect λ k s excluding the term 1 expert a k for all 1 km 2 grid cells v k d y this grid is then smoothed using gaussian blur and we denote the value in the smoothed grid cell v k by λ k s more specifically we use a border preserving gaussian blur that only smooths cells that are within d y and normalises the blur weights in the smoothing window such that only non zero intensity values contribute to the smoothed grid we use σ obs as the standard deviation in the gaussian blur and set the window size to the first integer larger than 2 σ obs in kilometres we report the σ obs value used in this step together with the results of section 3 the smoothing of the predicted grid is motivated by an assumption of smoothness that our inference method places on the spatial intensity function we will discuss this assumption c in more detail in section 2 5 after computing the predicted and smoothed spatial effect we also predict the temporal effect for the wolf year associated with dataset c by setting λ i τ exp β year β month i where λ i τ is the predicted temporal effect for wolf month i 1 2 12 during the wolf year of interest here β year corresponds to a predicted wolf year regression coefficient obtained by running a linear regression on the previous wolf years regression coefficients available from fitting model 2 the coefficients β month i on the other hand correspond to the estimated wolf month coefficients from model 2 the linear regression for the year coefficients was carried out to take into account a slight increasing trend in the yearly regression coefficients of model 2 to compute the distinct values c t i and c v j that the piecewise constant functions λ obs τ and λ obs s take we match the predicted intensities such that 3 λ i τ λ j s a j t i v j λ obs τ u λ obs s y a j d y d u where a j is defined as in section 2 3 evaluating the integral 3 and taking the logarithm yields log λ i τ log λ j s log t i log v j log c t i log c v j to obtain equality in this equation c t i and c v j can be chosen such that 4 c t i exp log t i 1 log λ i τ k c v j exp log v j 1 log λ j s k where k is a constant that needs to be chosen our choice for k is k max j log v j 1 log λ j s which scales λ obs s 0 1 finally for the purposes of sections 3 3 and 3 4 we note that when λ obs s is computed as discussed above one of the territory centroids seen in fig 2 is outside the domain of λ obs s therefore in the case of the wolf territory estimation we additionally widen the domain of λ obs s by 27 kilometres at the boundaries by repeating the maximal intensity value found in the neighbouring cells of the borders 2 5 filtering algorithm and its constraints this section discusses step 3 of the framework in fig 1 the statistical inference of the territories given dataset c assuming the data generating model of section 2 2 this section gives an overview of the inference and the mathematical details are given in section 1 6 of the supplementary material in summary given dataset c and the data generating model of section 2 2 with fixed parameters and intensity functions the inference procedure outputs a sequence of joint filtering distributions of the territory centroid locations and their number at chosen times t 1 t 2 t n that are also input to the procedure the filtering distribution at time t is the distribution of the locations of the territory centroids and their number conditional on the observations of dataset c up to time t the inference method we use is somewhat involved and computationally intensive and based on sequential monte carlo particle filtering cf doucet et al 2000 more specifically the method is a rao blackwellised particle filter similar to the works of särkkä et al 2007 vihola 2007 but employing a state of the art optimal resampling algorithm developed by fearnhead and clifford 2003 a summary of the method s operation can be given as follows denote by y 1 k y 1 y 2 y k the k temporally ordered observations with observation times t 1 t 2 t k here the input timepoints t 1 t 2 t n are among the t i s and each y i is a spatial location from dataset c or y i 0 see also discussion on assumption a below the method works by processing the observations y 1 k sequentially such that the processing of y k yields the filtering distribution at time t k during the algorithm each filtering distribution is characterised by a set of m weighted particles more specifically at time index k 1 each of the m particles represents a hypothesis about the locations and number of territory centroids on d μ conditional on the observations y 1 k 1 seen so far with y 1 0 understood as the empty set the observation y k is processed such that first a set of possible territory birth territory death and observation association outcomes is built which consist of all one step futures that could happen for any existing hypothesis at time index k 1 conditional on y k and the time passed since y k 1 this set of outcomes is then probabilistically pruned using the optimal resampling algorithm of fearnhead and clifford 2003 which yields a set of m chosen outcomes and their normalised weights finally based on the chosen outcomes and the previous hypotheses a new set of m updated and weighted hypotheses particles is constructed by adding and deleting territories and associating y k if y k 0 to a territory using an approximate kalman filter update the filtering distribution at time index k is characterised by these m particles the process then repeats for the observation y k 1 the ideal data generating model of section 2 2 is time discretised and approximated before the filter can be used the approximations used can be justified by introducing a set of additional assumptions some of which are primarily computational and some of which help reduce the discrepancy between the approximate and the ideal model the following list highlights these assumptions which we will refer to as assumptions a to d a the observed data can be processed sequentially one at a time in other words each datum has an associated time and the observation times are strictly increasing b compared to the rate of observations arriving from the territories birth and death events of territories are rare c the spatial intensity function λ obs s is smooth slowly varying with respect to the territory size parameter σ obs this means that for any centroid μ d μ λ obs s μ is a good approximation for λ obs s x in the region where the distribution n μ σ obs has most of its probability mass d for most territories the territory centroid μ i is not close to the boundary of d μ in the sense that a region of high probability of n μ i σ obs is contained within d μ we conclude this section with a brief discussion on these assumptions assumption a is satisfied for many datasets that are collected in real time however as mentioned in section 2 1 the observation times in dataset c are pooled with a granularity of one day in order to make assumption a hold we introduce a preprocessing step before the filtering that artificially disperses the daily pooled observations in time generating a pseudotime for each observation within the day that it occurred this step introduces a bias which is small since the arrival intensity of the observations still remains practically the same as with the pooled data the preprocessing of the data is related to the time discretisation of the model which we make fine enough so that during filtering we may assume that practically at most one territory birth or death may occur during each time discretised interval and that the time discretised model approximates the ideal model sufficiently well we ensure this by introducing discretisation points to the dataset that contain no spatial location that is y k 0 for further discussion on these matters see sections 1 3 1 4 in the supplementary material assumption b is necessary for the identification of the territories based on the data in the present application assumption b holds since the births and deaths of wolf territories are relatively rare events on the daily timescale at which the observations in dataset c arrive assumption c is necessary for approximating certain intractable integrals that arise in the filtering algorithm and are related to the spatial intensity function λ obs s in section 2 4 we described a smoothing step for the predicted spatial grid which was carried out in order to satisfy assumption c finally assumption d arises since our method does not involve explicit edge correction the computations in the particle filter are approximate for territories and observations close to the boundary of the finite domain d μ this may entail some bias which is small under assumption d we investigate empirically the bias caused by the edge effect in section 3 2 2 6 extracting the number and locations of the territories from the output of the particle filter this section focuses on the final step of the framework of fig 1 and describes how we extract the number and locations of the territories from the filtering result our estimate for the number of territories at time t is the marginal filtering distribution of the number of territories at time t computed as follows denoting by n i i 1 2 p the unique numbers of territories found among the m particles at time t the marginal filtering distribution for the number of territories consists of the tuples n 1 π 1 n 2 π 2 n p π p where π i is the sum of the normalised weights of the particles having exactly n i territories in section 3 4 we will summarise these distributions by taking their mean mode and standard deviation and by computing probability intervals i α that is intervals whose end points are given by the 100 α and α quantiles of the distribution where α is a given percentage point a common way to visualise the probabilistic location information of an unknown number of objects is to plot the so called probability hypothesis density goodman et al 1997 phd of the filtering distribution which in the present context corresponds to the expected intensity of territory centroids more specifically the phd is defined for the territory centroids at time t by phd μ j 1 m w j i i t j f j i μ here w j is the j th normalised particle weight at time t i t j enumerates the territories in particle j at time t and f j i is the i th density in particle j at time t the densities f j i i i t j each represent the knowledge about a particular territory centroid location within one of the particles hypotheses in the context of our model these densities are either normal densities n μ m j i c j i with known means m j i and covariances c j i computed by our particle filter or uniform densities u μ d μ the form of the density uniform or normal depends on whether an observation has been associated with a particular territory centroid in the particle for more details regarding this see section 1 of the supplementary material our approach for visualising the territory locations differs slightly from standard phd and is as follows first we compute the phd but with the f j i s at the observation level meaning that for territories associated at least once f j i corresponds to the normal density n y m j i c j i σ obs for territories never associated we take f j i y u y d μ after computing the phd in this manner we furthermore truncate the phd values from above to the density value n 0 0 σ obs this value corresponds to the maximal contribution to the phd value from a single territory which is known to exist and whose location has been estimated with maximal precision in section 3 4 we will visualise the estimated territory locations on the map using this computation the rationale for this procedure is clearer visualisation of the regions where the filtering algorithm places the territories in section 3 we focus mostly on the estimation of the number of territories because it is relevant from the point of view of assessing the reproductive capacity of a wolf population the number of territories is also easy to work with from a model validation perspective since it is straightforward to compare it numerically to ground truths of simulation experiments and to results of other estimation methods in contrast the phd is important for graphical validation visualisation and interpretation of the filtering result 3 results we first discuss results regarding the observation intensity modelling in section 3 1 we then move on to the experiments with the data generating model and the developed particle filter starting with a synthetic scenario in section 3 2 and then moving on to a semisynthetic scenario in section 3 3 that resembles the situation with dataset c but is still based on simulated observations we conclude with the real data scenario based on dataset c in section 3 4 3 1 tassu observation arrival intensity estimation fig 3 displays the estimated intensity functions λ obs τ and λ obs x as well as the predicted spatial effect of the intensity model 2 based on the figure the temporal intensity function λ obs τ is seen to capture the rise in observation intensity in the winter time and the spatial intensity function λ obs s especially accounts for the high observation intensities in western finland the overdispersion of the poisson regression modelling of the observation intensities eq 2 fit was 1 83 after accounting for the overdispersion the yearly effects were not statistically significant at 5 level but monthly effects were clear the fluctuations with respect to the baseline month of april ranged from a 78 95 confidence interval 54 91 reduction in may to 371 206 592 increase in november with smooth transitions in between the corine landcover variable effects were mostly increasing when considering a 1 increase in the proportion of each cover class in turn the estimated increase in intensity was cultivated fields 19 9 29 closed forests 18 8 28 open forests 16 7 27 rivers and lakes 16 6 26 and other wetlands 19 10 30 effect of larger roads was not significant but a 1 increase in forest roads increased the intensity by 5 1 8 the smooth component was significant with a clear reduction effect in the central region and an increase in the west south west and south regions the explained deviance was 12 6 for diagnostics we first checked the pearson residuals aggregated at a month resolution dropping the spatial dimension see figure 4 in the supplementary material the cell counts showed slightly higher proportion of 0 s than the model predictions otherwise the overall quantiles were reasonably matched there were no obvious patterns in time apart from a potential positive trend during 2015 the residual variability was the same during 2011 2016 with only gps tracking auxiliary territories and during 2017 2019 when both auxiliary territory types were available pearson residuals exceeded 2 during five months 2014 10 2017 12 2018 01 2018 09 2019 02 with no clear pattern with three over estimates predicted v observed counts 39 v 14 257 v 175 543 v 475 and two under estimates 6 v 21 9 v 21 we then studied the pearson residuals in space without the time dimension to visually check troubling areas we aggregated the observed and predicted counts to 10 10 km cells observed counts had again slightly larger amount of 0 s and also some higher than expected values the latter mostly from the 2017 2019 period no obvious spatial structure was visible in the pearson residual map with large residuals dotted around the domain see figure 4 in the supplementary material we checked a version where the largest count in the temporal sum per cell was omitted before aggregation in space the residual sizes were greatly reduced max abs from 12 to 3 this sensitivity suggests that the observation counts are more concentrated in time and space than what we can capture with the model additionally spatially contiguous regions of underestimation particularly on the west coast were revealed indicating insufficient information in the spatial components of the model a further check of before and after 2017 spatial sums revealed a tight cluster of unexpectedly high observation counts in the border region of eastern kainuu 3 2 synthetic scenario and the edge effect our first territory estimation experiment is a purely synthetic simple scenario the purpose of the experiment is to ensure that the estimation algorithm works correctly we also investigate explicitly the bias caused by the edge effect as discussed in section 2 5 in this experiment we skip the intensity modelling discussed in sections 2 3 2 4 and focus on the filtering of simulated datasets we define the data generating model such that d μ 0 100 0 100 λ obs τ u 1 and λ obs s y 1 for all u 0 50 and y d y r 2 for the remaining parameters we set λ bd 0 0015 λ c 0 λ obs 1 this configuration corresponds to a simple scenario for our particle filter since there is no spatial inhomogeneity and the largest approximation in the filtering arises from the finite domain under these settings for all combinations of the number of particles m 128 256 512 1024 2048 and σ obs 1 2 5 10 15 we simulated 450 datasets as follows first we simulated the territory locations from the ideal birth and death model and then conditional on the territories simulated the observations from the ideal observation model each time preprocessing the observations with the method discussed in section 2 5 the initial distribution for the number of territories in the birth and death process was poisson 20 truncated to the interval 10 30 for each sampled initial territory we set the uniform distribution on d μ as the initial distribution for the centroid of the territory we filtered each simulated dataset assuming that the initial distribution above was known and computed the deviations n ˆ t n t for t 1 50 where n ˆ t is the estimated mean number of territories at time t from the particle filter and where n t is the true number of territories for the dataset we investigated the bias e n ˆ t n t which would be zero for an ideal bayes estimator by computing the empirical mean of the 450 deviations per t m and σ obs fig 4 summarises the results of this experiment with a small territory size compared to the size of the domain d μ we observe little or no bias in the estimation of the number of territories given that a sufficient m is used in the filtering algorithm for greater values of the territory size the bias is more significant and appears to only slightly diminish with increasing m this is expected since with higher territory sizes assumption d of section 2 5 is more likely to be violated leading to observations outside or near the boundary of d μ 3 3 semisynthetic scenario and feasibility of territory estimation next we consider a more realistic semisynthetic scenario with closer resemblance to the situation with dataset c in this scenario the idea was to fix the territory centroids to realistic locations use plausible parameter values and the intensity functions estimated as discussed in sections 2 3 2 4 we then simulated data to see how well the particle filter can recover the true number of territories under a more realistic setting more specifically we assumed that d μ corresponds to the domain of the tassu data fig 2 top left and the territory centroid locations were fixed to the centroids fig 2 bottom left of the territories found by luke in the wolf population assessment of 2019 we further assumed that each of these 47 territory centroids existed for a period of one year and that the territory count did not change we used the intensity functions in figs 3 c and 3 b as λ obs τ and λ obs s in the data generating model to set the value for the territory size parameter σ obs σ obs 2 i we examined the shapes and sizes of the territory polygons in dataset b discussed in section 2 1 2 as many of these territories were noncircular in shape see fig 2 bottom left for some similar polygons we estimated σ obs as follows first we computed the 95 quantile d 0 95 from the empirical distribution of the diameters of the territory polygons in dataset b then we used eq 1 with α 0 95 to compute the σ obs value that corresponds to a radius of d 0 95 2 yielding the value σ obs 13376 67 m here the diameter of a polygon means the maximal length between any two points of the polygon this procedure guarantees that typical territories fit inside the 95 probability region of the territory model for the remaining filter parameters we used the values λ obs 1 0 λ c 0 475 and λ bd 0 0015 the choice of the relative values of λ obs and λ c here corresponds to a situation where 1 of the total observation intensity is assumed to arise from clutter observations when the spatial and temporal intensity functions are constant one and there are 47 territories for a period of one year the choice of λ bd corresponds to a mean territory lifetime of 1 0 0015 667 days a little less than two years this choice averages between the fact that in reality some wolf territories are short lived but some can exists for years the chosen value also a priori predicts reasonable changes in the territory count over a period of one year while maintaining a good agreement between the ideal and approximate birth and death models see figure 1 in the supplementary material with these settings we simulated a total of 240 datasets for each particle count m 2 7 2 12 and applied the particle filter to each estimating the mean number of territories at approximately weekly intervals each time the filter was initialised with the initial number of territories following poisson 47 truncated to 37 57 with each territory centroid initially following the uniform distribution on d μ fig 5 shows the deviations computed by subtracting the true number of territories from the estimated mean territory count trajectories for each simulation and all particle counts in addition the average deviation and the average absolute deviation are shown on average the particle filter appears to recover the true number of territories quite accurately with increasing numbers of particles a slight underestimation of the true territory count is revealed the average absolute deviation further indicates that the discrepancy from the true territory count is typically less than 3 given that a moderate amount of data has been processed 3 4 application to the tassu dataset next we applied the developed particle filter with 16384 particles to dataset c as the initial distribution for the territory centroids we used the centroids seen in fig 2 bottom left with gaussian noise with covariance σ obs added to each this way the prior knowledge from the population assessment of march 2019 can be utilised in the filter we report results for four model variants as follows models 1 and 2 correspond to the same model configuration we used in the semisynthetic experiment but with model 1 having λ c 0 models 3 and 4 correspond to models 1 and 2 respectively but with another set of intensity functions λ obs τ and λ obs s obtained by dropping the terms corine k forestroad k and smooth y k from the intensity model 2 and then estimating λ obs τ and λ obs s as before as described in section 2 4 the resulting spatial intensity function in models 3 and 4 is constant one in d y for a plot of λ obs s and λ obs τ for models 3 and 4 see figure 2 in the supplementary material fig 6 displays the estimated territory locations and table 1 shows summary statistics of the filtering distribution for the number of territories based on models 1 4 at the end of march 2020 after the full dataset c has been filtered the computations underlying these quantities were carried out as explained in section 2 6 the overlaid territory polygons in fig 6 correspond to the territories found by luke in the wolf territory assessment of spring 2020 the plots show that each of the models 1 4 seem to find many of the wolf territories found by luke however it appears that models 1 and 3 with λ c 0 place multiple extra territories to central and southeast finland that are not found among the official territories these territories are most likely not real wolf territories since only a small number of observations have been reported from these areas see fig 2 top left the territories most likely arise since the observation intensity is low see fig 3 b and perhaps underestimated in these regions causing the filter to attempt to explain these observations with additional territories based on the plots for model 2 and 4 setting λ c 0 475 seems to mitigate this issue a bit as these observations are no longer interpreted as real observations from wolf territories we also experimented with a higher value for λ c but this resulted in a territory count distribution not well aligned with the count estimates by luke see also discussion below there is also no reason to believe that a substantial proportion of the data would not originate from the wolf territories another observation from fig 6 is that models 3 and 4 with the simplified intensity functions seem to somewhat better capture the cluster of territories in west and southwest finland in comparison to models 1 and 2 this difference in the results occurs since the spatial intensity function for models 1 and 2 assumes that in these regions the reporting intensity of the observations is higher than in other parts of finland this in turn results in less territories being needed to explain the observations arriving from these regions under models 1 and 2 based on the territory count distributions summarised in table 1 the territory counts for models 1 and 2 are best aligned with the estimate of luke in comparison the territory count for models 3 and 4 is somewhat overestimated fig 7 reports the sample standard deviations of the obtained mean territory counts at approximately weekly time points when we repeated the filtering of the tassu data 195 times with the configuration of model 2 and different particle counts the observation is that the variability in the estimated mean territory counts is seen to diminish with increasing numbers of particles but still remains noticeable even with 16384 particles we also experimented with different λ bd σ obs and intensity functions but the phenomenon persisted in contrast when a dataset is simulated from the model the results of this experiment are markedly different as is seen from the second pane in the figure similarly there is also some variability in the estimated territory locations figure 3 in the supplementary material shows the estimated territory locations after 10 independent runs of the filter to the tassu data 4 discussion we presented a statistical modelling framework for the analysis of citizen science data from territorial animals at the core of our framework is the data generating model discussed in section 2 2 that consists of a birth and death model giving rise to the animal territories and an observation model that links the citizen science observations to the territories in the developed data generating model the high variability common to citizen science observation processes is modelled through a temporal and a spatial intensity function which are assumed fixed and known the rao blackwellised particle filter described in section 2 5 estimates the sequence of filtering distributions for the locations and number of territories that describe the knowledge of the animal territories in time as more data is brought in we found that the fitted intensity model and the estimated intensity functions were able to capture general trends in the arrival of the citizen science observations as is seen from the estimated intensity functions in fig 3 clearly the model captures the higher arrival intensity of observations in the winter which mainly occurs because of snow that leaves wolf tracks visible for potentially long periods of time the estimated spatial intensity function on the other hand captures the high intensity of observations in western finland and the low intensity of observations in middle finland compared to other regions the intensity model did however struggle to explain some characteristics adequately for instance sometimes the observations arrived in unexpected bursts or were highly localised in space and these features the model was not flexible enough to capture cf figure 4 in the supplementary material a potential remedy for this might be the addition of random effects e g an additional noise component to each spatial pixel but it would be better to include interpretable rare event overdispersion components based on the social analysis of the mechanisms for reporting the wolf observations in fact the outliers are worth a closer look to gain such insight the model also struggled with an excess of 0 count cells due to how the conditioning on the auxiliary territories in dataset b was constructed another improvement for the intensity model could be a zero inflation component with its own regression structure on for example environmental covariates however an even better option would be to forgo the aggregation and model the data as a spatio temporal marked point pattern sicacha parada et al 2021 tang et al 2021 modelled this way events such as an observation being exactly on a road or snow cover of previous days would not be averaged out yet coarser resolutions for downstream analysis could still be easily computed other possible improvements include using the type of observation sightings paw prints game cameras etc in the intensity model and the improvement of the process of deriving the auxiliary wolf territories from the gps trajectories finally it might be beneficial to investigate the possibility to relax the space time separability assumption which would allow for the incorporation of weather data such as snow cover and or allow for individual time trends for western and eastern finland for example such complex models could then be estimated from longer period or more frequent observation series if available our synthetic experiment in section 3 2 investigated the mean territory count estimates of our particle filter under a simple data generating model and found that our method works as expected when assumption d of section 2 5 holds with high territory sizes this assumption is violated and there is some bias in the estimation of the mean territory count this edge effect arises due to the finiteness of the domain d μ in particular the violation of assumption d reduces the accuracy of the approximation 25 in the supplementary material which likely causes the bias in this experiment territory parameters on a scale of 1 2 of the width of the rectangular region led to small bias noting that the distance between the western and eastern borders of finland is approximately 500 kilometres we therefore expect that the bias caused by the edge effect should be small in the realistic experiments discussed in sections 3 3 3 4 the semisynthetic experiment of section 3 3 showed that under realistic conditions resembling the situation with the tassu dataset the estimation of the territory count is possible there was a slight underestimation of the true territory count with increasing numbers of particles which we think occurs because of the discrepancy between the scenario and the ideal model or the approximations used this experiment was a proof of concept that showed that the territory estimation can be feasible even with presence only data when the model is correct while experimenting with different parameter values for the data generating model we found that in general the model and especially the count estimation is most sensitive to the values of the territory size parameter σ obs and the intensity functions and least sensitive to the choice of the constant and equal birth rate λ bd this is expected since large territory sizes increase the probability of an observation being associated with a territory that is far away decreasing the relative probability of a new territory emerging in a similar vein the intensity functions are directly tied to the amount of territories needed to explain the number of observations arriving with a fixed dataset lowering the observation intensity results in more births since a higher number of territories is then needed to explain the data the concluding analysis in section 3 4 applied the developed data generating model and particle filter to analyse citizen science observations of wolves from april 2019 to march 2020 the results show similar patterns as the counts and locations reported by the natural resources institute finland luke in the official assessment of march 2020 however the results do not reach the accuracy of expert judgement this cannot be expected because the official assessment also incorporated additional information sources such as dna samples gps collared wolves and mortality records based on table 1 the inference of model 2 incorporating the estimated spatial intensity function and clutter observations resulted in a slightly smaller estimated territory count and smaller variability than the official estimate by luke in general such differences can occur because the estimates of luke are based on a very different model and assumptions and also take advantage of additional data when using the citizen science data only it is also possible that the particle filter might not find territories which rarely produce observations leading into underestimation of the territory count furthermore the uncertainty reported by the particle filter can be underestimated because the results are based on a single particle filter run if monte carlo variability is taken into account the uncertainty is inflated see also discussion below we noticed that with models using a constant one spatial intensity the cluster of territories in the west and southwest finland was captured better than with models that used the estimated intensity functions as was seen from fig 6 this might suggest that the observation intensities in the more complex models are overestimated in these regions at the time of the observations arriving indeed based on the pearson residuals in figure 4 of the supplementary material the intensity model fit could not capture all of the variation in these regions despite this it appears that using the spatially varying intensity improves and is likely a requirement for the accurate estimation of the territory count this is supported by the territory count distribution in table 1 which indicates that the territory count estimates of the more complex models were better aligned with the official territory count estimates of luke in general we found that estimating the territory count and locations of the territories reliably is challenging by only using the citizen science observations from the tassu database the challenges faced may be partly explained by unsatisfactory observation intensity modelling but it appears that the inference algorithm is also struggling with real data fig 7 and 3 in the supplementary material show repeated runs of the filter in our concluding analysis indicating some monte carlo variability we believe that the main challenge for the inference is the presence only nature of the observations these observations are quite informative about the births of new territories since a territory needs to exists so that an observation may occur in contrast the observations are not very informative about the deaths of the territories because the information about a death of a territory is indirect and only mediated by the absence of observations arriving from a particular area this difficulty with the data might explain the monte carlo variability in our particle filter and further suggests that it could still benefit from further specialisation to the territory estimation task for instance this specialisation could come in the form of further heuristics that eliminate territories more efficiently when no observations have been associated for a long time all in all we think that the results obtained suggest that the developed modelling framework might be useful as an additional tool in the annual wolf population assessment reducing the amount of subjectivity in the estimation process by providing a preliminary statistical interpretation of the citizen made observations integration of the dna samples gps collared wolves and other data with the results of the particle filter would still remain a task for the panel of experts our analysis with datasets a b and c of section 2 1 showcased the intended use of the modelling framework in the context of the wolf population assessments first the intensity functions required by the data generating model are estimated based on the latest historical data then the particle filter is initialised with the territory count and location distribution available from the latest population assessment finally the yearly observations are analysed in a batch to obtain a model based view on the status of the wolf population at the time of the next population assessment filtering a year of data from april 2019 to march 2020 allowed both the comparison to the official wolf population assessment of 2020 and the use of prior information from the assessment of 2019 however this yearly batch estimation is not the only way in which the developed data generating model and particle filter could be used in fact one of the motivations for the development of the data generating model and the particle filter was that the developed modelling framework could also be used in an online fashion this way smaller batches of new observations could be used to update the posterior distribution of the territory locations and track the population in finer timescales in the context of the wolf territory estimation the results from such an online estimation could provide dynamic feedback for the volunteers collecting the data highlighting that their work is important such feedback might also be used to direct the effort of the volunteers to areas with the most uncertainty about the existence of territories we envision that our modelling scheme could also be a noteworthy tool for refining the population assessment of other large carnivores for example the female eurasian lynx lynx lynx are known to show territorial behaviour with cubs this could be exploited in the estimation of lynx reproduction it might also be possible to couple the developed framework with other developments for assessing animal populations such as the spatial capture recapture scr model which estimates wolf density based on dna samples bischof et al 2020 for example the two approaches might be used sequentially the scr model could be used first to estimate the spatial wolf density based on dna samples and then the density could provide another source of prior information about potential territory locations for our data generating model on the other hand in case that the dna samples are collected by volunteers the modelling of the sampling effort in the scr model could be done by similar techniques as in this work besides the context of territorial animals our methods might be relevant in target tracking where the modelling of the temporal and spatial variability of the observation process is required the methods may also be regarded as a form of dynamic clustering in different applications the modular nature of the developed framework can be exploited to carry out the intensity modelling in a way that fits the application there are a number of ways how the developed data generating model and the inference algorithm could be improved in future works the core of the filtering computation consists of evaluating the posterior probabilities for the birth death and association variables see section 1 6 of the supplementary material the main approximations made in the computation arise from the intractable integrals related to the spatial domains d μ and d y and the spatial intensity function λ obs s we concentrated on the situation where λ obs s may be assumed to be slowly varying by assumption c allowing for straightforward approximation of the intractable integrals in the probability computations and the measurement update introducing a numerical integration scheme could mitigate the bias from the approximations in the former it might also be possible to incorporate a no overlap condition to the model that penalises large overlaps of the territories the developed particle filtering approach assumes fixed parameter values even with the limited and noisy citizen science data it might be possible to estimate some parameters of the data generating model such as the intensity scaling parameter λ obs and or parameters related to the birth and death intensity functions λ b and λ d this could result in a better fit of the data and model and might result in improved location and count estimates in theory estimating the model parameters is possible using for example the particle marginal metropolis hastings algorithm andrieu et al 2010 similar to kokkala and särkkä 2015 using these methods would however require the derivation of an unbiased estimate of the marginal likelihood of the observed data under the employed optimal resampling scheme of fearnhead and clifford 2003 for the current model and a moderate to large dataset such estimation procedures are also computationally intensive and would likely require a tailored parallel implementation the methods might also be difficult to tune in practice the data generating model could in principle readily incorporate moving territories as well perhaps using an ornstein uhlenbeck type movement model as in the work of johnson et al 2008 we did not attempt this with the wolf territory estimation because our main interest was in immobile territories in addition we suspect that the additional flexibility in the model allowing for movement would make the inference task substantially more difficult or even infeasible furthermore we do not believe that in our dataset each territory is observed frequently enough to make the inference with an additional movement model practical the observation model could also be further refined we did not separate between the different observation types but some observation types can be more reliable than others and may be subject to different observation intensity detectability consider for instance tracks vs sightings we chose to simplify since we do not believe that adequate intensity estimation is possible for the different observation types separately with our dataset in another context however it would in principle be possible to modify the observation model to also accommodate different observation types the intensity function of the observation model see equation 5 in the supplementary material could be augmented with independent data streams for the different observation types each with their own spatio temporal and clutter intensities this could lead to interesting observation models such as ones that designate higher clutter intensity for more uncertain observations types such as sightings another means of model improvement are more fine grained birth death models in ecological applications for example further information such as mating seasons or typical lifespans of the species could be encoded into the birth and death intensity functions λ b and λ d in the general model described in the supplementary material however these kinds of models would likely achieve their full potential when coupled with parameter estimation discussed above in our wolf territory estimation we did not investigate time varying birth death intensity functions and opted for a model where a territory can emerge at any time even though wolves only reproduce in the spring new wolf territories can form at any time of the year when vagrant wolves pair up and establish new territories furthermore the majority of the citizen science wolf observations are made in the winter time and it is possible that the first observation from a territory formed in the spring comes later in the winter credit authorship contribution statement santeri karppinen conceptualization methodology software validation formal analysis investigation data curation writing original draft writing review editing visualization project administration tuomas rajala conceptualization methodology software validation formal analysis investigation data curation writing original draft writing review editing visualization project administration samu mäntyniemi conceptualization writing original draft resources writing review editing supervision project administration ilpo kojola resources writing original draft project administration matti vihola conceptualization methodology project administration writing original draft writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we thank gabriel kasmi who was involved with early experiments related to this research sk and mv were supported by the academy of finland research grant 315619 the authors wish to acknowledge csc it center for science finland for computational resources appendix a supplementary data supplementary material related to this article can be found online at https doi org 10 1016 j ecolmodel 2022 110101 appendix a supplementary data the following is the supplementary material related to this article mmc s1 additional figures and the details of the the data generating model and particle filter 
24381,citizens community groups and local institutions participate in voluntary biological monitoring of population status and trends by providing species data e g for regulations and conservation sophisticated statistical methods are required to unlock the potential of such data in the assessment of wildlife populations we develop a statistical modelling framework for identifying territories based on presence only citizen science data the framework can be used to jointly estimate the number of active animal territories and their locations in time our approach is based on a data generating model which consists of a dynamic submodel for the appearance removal of territories and an observation submodel that accounts for the varying observation intensity and links the data to the territories we first estimate the observation intensity using past presence only observations made by citizens conditioning on previously known territories we then infer the territories using a state of the art sequential monte carlo method which extends earlier approaches by allowing for spatial inhomogeneity in the observation process we verify our data generating model and inference method successfully in synthetic scenarios we apply our framework for estimating the locations and number of wolf territories in march 2020 in finland using one year of confirmed citizen made wolf observations the observation intensity is estimated using wolf observation data collected in 2011 2019 conditioning on official territory estimates and data from gps collared wolves our experiments with synthetic data suggest that the estimation of territories can be feasible with presence only data our location and territory count inferences for march 2020 based on past data are comparable to the official wolf population assessment of march 2020 by the natural resources institute finland the results suggest that the framework can provide useful information for assessing populations of territorial animals furthermore our methods and findings such as the developed data generating model and the estimation of the spatio temporal observation intensity can be relevant also beyond the strictly territorial setting keywords citizen science data bayesian statistics sequential monte carlo spatio temporal model territory identification presence only data data accessibility statement the code used to reach the conclusions of the paper is available at the repositories https github com antiphon tassu intensity intensity analysis https github com skarppinen tassu filtering particle filter implementation and experiments of sections 3 2 3 4 the repositories and links therein also contain simulation data and results related to the experiments the data on the finnish wolf population is not publicly available because it contains sensitive information on local wolf behaviour that could be exploited in poaching or disturbing wolves 1 introduction volunteers contribute to many wildlife monitoring programs but standardised monitoring schemes are available for only a small number of taxa in a few countries gregory et al 2005 isaac 2014 citizens community groups and local institutions participate in biological monitoring of population status and trends by providing species data e g for regulations and conservation conrad and hichley 2011 lawrence 2006 the involvement of citizens as data collectors has demonstrated its ability to gather massive amounts of data at a spatio temporal scale unattainable by research teams and state authorities active in biodiversity monitoring silvertown 2009 for instance in many european countries hunters are integrated as data providers in wildlife management structures that are intended to support sustainable harvest bragina et al 2015 cretois et al 2020 linnell et al 2015 statistical developments in data integration as well as more rigorous protocols for data collection are needed to unlock further the potential that volunteers data holds cretois et al 2020 isaac 2014 the statistical interpretation of citizen collected data faces problems less frequently encountered in traditional scientific research for example the spatio temporal sampling effort of citizens is usually not known nor controllable sophisticated methods that model the data collection process offer the greatest potential to estimate e g timely trends isaac 2014 in this paper we propose a statistical modelling framework that can be used to make inferences about animal populations with territorial behaviour using observations reported voluntarily by citizens more specifically our focus is on the following scenario citizens report presence only observations of territorial animals each observation consists of a gps coordinate and an approximate time stamp we wish to estimate the number and locations of the animal territories within some area and time interval using the data collected by the citizens prior knowledge on the territorial behaviour of the species is assumed to exist in the form of a typical territory size and on the rate of appearance and disappearance of territories because of the high spatio temporal variability common in citizen science observation processes modelling of the varying sampling effort that is the observation intensity is a crucial first part of our framework we take this variation into account by modelling the intensity based on past data this yields intensity functions that capture the spatio temporal variation in the observations reported by citizens these functions are then fed into a data generating model consisting of two submodels that model the appearance and removal of territories and the generation of citizen science observations from the territories respectively to estimate the number of territories and their locations we use the latest available citizen science data and perform bayesian inference for the data generating model the data generating model jointly approximates the evolution of the number of active territories and their locations in time characterised by a sequence of posterior distributions conditioned on observation sets of increasing size in the engineering literature similar models are called tracking models cf goodman et al 1997 indeed the inference algorithm we develop is a rao blackwellised particle filter similar to those developed for tracking särkkä et al 2007 vihola 2007 we further elaborate these methods by employing a state of the art optimal resampling of fearnhead and clifford 2003 and further refine the inference algorithm so that it can incorporate the spatial inhomogeneity arising from our observation model our data generating model is similar to dynamic occupancy models royle and kéry 2007 and open n mixture models zhao et al 2017 in the sense that it has a latent process model for the appearance and disappearance occupancy of animal territories and a variable observation intensity however unlike in the work of zhao et al 2017 the principal objects of analysis in our model are animal territories rather than individual animals in addition our model does not assume a fixed set of potentially occupied sites but operates in continuous space where territories are delineated without a pre defined grid finally our model is formulated in continuous time which allows the estimation of the state of the population at any time points within the interval of interest for example our model can be used to track the state of the population at daily or weekly time steps in contrast the methods of royle and kéry 2007 and zhao et al 2017 operate in discrete time and are typically used for annual data with a considerably smaller number of time steps the motivation for the development of our modelling framework has been to aid in the task of assessing the finnish wolf canis lupus population although the framework can be relevant for other territorial species as well currently the finnish wolf population is assessed annually in march by the natural resources institute finland luke in the assessments wolf observations provided by citizens from the beginning of august to the end of february are combined with non invasive genetic samples tracks of gps collared wolves and records of known mortality kojola et al 2018 the assessments are carried out in two phases in the first phase a panel of experts conducts a systematic review of all the data and judges territory boundaries that are potentially occupied by wolf packs or pairs in march in the second phase a bayesian state space model is used to infer the number of wolves living in each territory by combining wolf observations dna recaptures and known mortality heikkinen et al 2020 in particular we envision that the developed framework can work as a useful tool in the first phase providing a statistical look at the citizen science data and an aid in judging the territory boundaries we examine the performance of the developed particle filter with a sequence of simulation experiments where we start from simple simulated conditions and work towards conditions that resemble more closely our concluding experiment which is a realistic situation that could be faced in the assessment of the finnish wolf population here we use previous estimates of territory locations and citizen provided observations to estimate the spatio temporal variation of the conditional probability of wolf observations given known existence of wolf territories even though similar approaches have been used for species abundance estimations e g renner et al 2015 ver hoef et al 2021 tang et al 2021 the conditioning requirement provides a novel challenge using the results of said intensity modelling we apply our data generating model to a real data set consisting of wolf observations made by finnish citizens between april 2019 and march 2020 we estimate the number and locations of wolf territories and compare the result to the official estimates by the natural resources institute finland luke which are based on the method discussed above the main contributions of this paper are as follows first we believe that the developed framework is of interest in assessing populations of territorial species using presence only citizen science data we focus on the application to wolves but our methods are readily adaptable for other territorial species second we believe that the observation intensity estimation is of its own independent interest because it addresses the problem of estimating the conditional spatio temporal intensity of presence only citizen science observations third from a methodological point of view the developed data generating model and particle filter might be relevant also in the context of general purpose target tracking e g vihola 2007 särkkä et al 2007 applications where a spatially varying observation process is needed 2 materials and methods the general modelling framework proposed in this paper can be summarised into four successive analysis steps numbered from one to four the flowchart in fig 1 depicts their dependencies and relation with each other highlighting the inputs outputs and datasets associated with each step the following subsections will explain how we apply the framework in the context of wolf territory estimation section 2 1 discusses the datasets a b and c section 2 2 then describes the data generating model which motivates the intensity estimation consisting of steps 1 and 2 which in turn are discussed in sections 2 3 and 2 4 respectively section 2 5 describes step 3 of the analysis the statistical inference based on the data generating model using a particle filter we have developed for the problem finally in section 2 6 we conclude with a description of step 4 where we extract the number and locations of the territories from the output of the particle filter 2 1 data in this section we will discuss the datasets a b and c seen in the framework of fig 1 in summary the datasets a and b contain past data used in the construction of the data generating model and dataset c contains the latest data to be processed by the particle filter each datum in datasets a and c is a spatio temporal point that is it has the form t y where t is the time of observation and y is a two dimensional point on a domain we denote by d y the difference between datasets a and c is that dataset a is past data and dataset c corresponds to the latest data we wish to infer the territories with in contrast dataset b is more heterogeneous and contains all additional data such as covariates and expert knowledge required in the construction of the data generating model 2 1 1 datasets a and c we extract the spatio temporal points in datasets a and c from a digital large carnivore observation database named tassu meaning a paw in finnish kojola et al 2018 the observations enter the database through a network of approximately 2000 large carnivore contact persons lccps who are nominated by management associations and educated by the finnish wildlife agency and luke in the biology ecology and movement behaviour of wolves as well as footprint identification there are however no formal exams used in the nomination process the lccps have their own local trusted network of people who report their observations of wolves to the lccp these networks consist mostly of hunters that are proficient in identifying wolves based on sightings tracks prey kills and camera trap documents in addition it is in principle possible for any citizen to report their observations since the contact details of the lccps are publicly available and known in local rural societies pellikka and hiedanpää 2017 however the networks of the lccp are particularly relevant for wolf sightings in snow free conditions because such observations usually cannot be verified afterwards wolf observations found to be valid by the lccps are saved into the tassu database each saved datum includes information about the time and location of the observation the type of observation such as wolf track sighting droppings game camera photograph prey kill site or livestock predation and the estimated count of wolves observed simultaneously the count estimate is based on the judgement of the lccp based on the information available since the observations saved to the database are subject to the confirmation of the lccp possibly days after the initial report we consider the observation times to be accurate on a daily granularity in total datasets a and c contain all observations from the tassu database that reported two or more wolves between january 2011 and march 2020 since the purpose of our framework is to infer the number and locations of wolf territories we only focus on observations that report more than one wolf since this indicates that the observed wolves form a wolf pack and very likely exhibit territorial behaviour in contrast observations of single wolves can originate from lone vagrant wolves that do not yet maintain a territory furthermore for simplicity we make no distinction for data points with different observation types we regard each observation simply as a spatio temporal point we return to this matter in the discussion we split the data such that dataset c contains the observations made between april 1st 2019 and march 31st 2020 and dataset a the observations before this the locations in dataset c are illustrated in fig 2 top left the domain of the locations d y is mainland finland south of the reindeer husbandry region in the north the wolf territories in the reindeer husbandry region are few and short term owing to lethal control that is justified by the prevention of damages to reindeer husbandry we organise the datasets a and c according to so called wolf years a wolf year starts april 1st and ends in march 31st of the next year hence dataset c consists of the observations made during the wolf year 2019 2020 the organisation of the data to wolf years has two reasons first as described in the introduction the annual finnish wolf population assessments describe the state of the wolf population in march second the data indicate that the highest observation intensity is reached during the winter season and declines towards the spring year by year changes in the observation activity are expected to occur between the winter seasons rather than between calendar years we will also use the term wolf month to refer to the months within a wolf year such that the first wolf month corresponds to april the second to may and so on 2 1 2 dataset b dataset b contains two kinds of information most importantly dataset b contains information about past known wolf territories until march 2019 that is before the wolf year associated with dataset c in addition dataset b also contains covariates dataset b is primarily used in the intensity modelling described in section 2 3 but also for setting certain parameters in the data generating model the details on how the data sources described below are used in the intensity modelling are given in section 2 3 the relation of dataset b to the parameters of the data generating model is discussed in the results of section 3 3 the information about past wolf territories was constructed from two sources of data independently of datasets a and c we call the resulting territories auxiliary territories the first source consists of the space time trajectories of 34 gps collared wolves that were tracked between 2011 and 2019 the transmitters in the collars stored the wolf s position at one or four hour intervals depending on the season the capture handling and immobilisation protocols of these wolves are described in kojola et al 2016 we assumed that each collared wolf was part of a wolf territory the trajectories contain outlier recordings such as test measurements at a lab or glitch jumps of hundreds of kilometres occurring due to device malfunction or other reason some trajectories also cover two clearly separate territories we therefore preprocessed the data as follows first the recorded gps trajectories were divided into separate contiguous trajectories at temporal jumps of more than two weeks or spatial jumps of more than 100 km trajectories less than 24 h were rejected second each contiguous trajectory was processed by assigning to each trajectory point a probability of being an outlier the probability was given by the velocity density v e x p 28 8 with median at 20 km h multiplied by the function w d c x 1 x 5 σ 1 x 5 σ exp 0 5 x 5 σ 2 4000 0 2 where d c denotes a point s distance from the trajectory s centre of mass and σ is the 90 truncated standard deviation of the centre of mass distances points with probability less than 50 were excluded from the trajectory finally the first and second steps were repeated to account for significant gaps after the outlier detection second step from each remaining trajectory an auxiliary territory was constructed as a polytope in d y t b where t b denotes the time span 2003 03 04 2019 03 31 by taking the cartesian product of the convex hull of the spatial locations and the time interval of the trajectory in total 59 auxiliary territories were constructed from the gps trajectories covering approximately 74 000 km 2 and with time spans that add up to approximately 36 5 years the second type of auxiliary territories were constructed based on expert knowledge using the official population assessments of luke from 2017 onwards the assessments include estimates of active wolf pack territories as polygons in d y during march of the corresponding years fig 2 bottom left shows the active pack territory location estimates of experts in the assessment of march 2019 we assumed that these territories were active also during january and february we then constructed polytopes in d y t b as the cartesian products of the polygons and january march intervals of each year between 2017 2019 the resulting 203 expert judgement auxiliary territories covered approximately 180 000 km 2 with time spans that add up to approximately 35 3 years the additional covariates in dataset b consist of two datasets the first of these is the corine land cover data for 2018 finnish environment institute syke 2018 the dataset comes as a raster covering finland and contains an approximate land use class e g river small road for each of its 20 by 20 metre cells the original 49 classes were first reclassed down to 8 residential areas other build areas roads cultivated fields lakes and rivers swamps and other wetlands closed forests and open forests for each of the 8 classes we aggregated their frequency in 1 km 2 cells and to slightly reduce the amount of zeros applied smoothing with a gaussian blur with standard deviation 3 km each cell of the resulting 8 layer raster stack then contained a vector giving the smoothed frequencies of each land use class in and near the 1 km 2 cell since the resulting vector for each cell k corine k 1 corine k 8 is nearly a simplex we dropped the first class residential areas and kept the remaining 7 as frequencies a log ratio transformation which is a popular approach in compositional data analysis might have been more suitable here but was not done due to numerous zeros in all classes the corine road information capture larger streets and highways and to describe accessible forest areas we computed an additional forest road frequency variable to dataset b this variable is derived from the national road and street database digiroad finnish transport infrastructure agency 2021 from the database we extracted the polyline feature class 12 roads and paths traversable by offroad vehicle we binarised the polylines on to the 20 by 20 metre cells of the corine land cover data and then computed the frequencies of those cells on a 1 1 km raster we denote the value of this variable in the k th 1 km 2 cell by f o r e s t r o a d k 2 2 data generating model in this section we discuss the data generating model we have developed for citizen science observations of a territorial species the model we have developed is more general than the instance of it that we use for modelling the wolf data therefore this section will also highlight certain modelling decisions we make in the present application furthermore the data generating model we describe here is ideal in the sense that it must be approximated further to be tractable for our inference method we will discuss this in more detail in section 2 5 that is devoted to the filtering algorithm for the interested reader the mathematical details of the general data generating model are given in sections 1 1 and 1 2 of the supplementary material the data generating model consists of two submodels the birth and death process and the observation model which we will discuss in sections 2 2 1 and 2 2 2 respectively in summary the birth and death process models how new territories emerge and disappear and the observation model describes how each existing territory produces citizen science observations spatio temporal points as in dataset c 2 2 1 birth and death process our model assumes that the territories of interest exist and emerge within a domain denoted by d μ r 2 with d μ d y the location of the territory i is represented by its centroid μ i d μ which is assumed to be constant in time new territories emerge within d μ with the instantaneous birth intensity λ b u n u λ b0 where λ b u is the known birth intensity function and n u stands for the number of existing territories at time u the function λ b u can be interpreted as birth intensity per each existing territory the baseline birth intensity parameter λ b0 on the other hand models additional birth intensity due to external factors such as inflow from outside d μ for modelling of the wolf data we simplify λ b u to a constant denoted by λ b and set λ b0 0 as a new territory emerges its centroid follows the uniform distribution on d μ similarly each existing territory disappears with the instantaneous death intensity λ d u that is the total instantaneous death intensity induced by all territories equals λ d u n u in case of the wolf data we fix λ d u to a constant that we denote by λ d therefore the lifetime of a single territory follows an exponential distribution with mean λ d 1 furthermore in a similar fashion as was done in vihola 2007 we symmetrise the birth and death process by setting λ b λ d λ bd where λ bd then remains the only birth death intensity parameter this minimises the bias in the birth and death process and a priori leads to a constant conditional expectation for the number of territories in time the initial distribution of the model is a joint distribution of the number of territories and the locations of their centroids the initial locations of the territory centroids can either be distributed uniformly on d μ or subject to gaussian error truncated to d μ around some location estimate 2 2 2 observation model the observation model conditional on the territory locations and lifetimes generated by the birth and death process describes how each territory with its centroid on d μ produces citizen science observations the baseline underlying model for an observation from a single territory i that exists at any given time point is bivariate normal n μ i σ obs where σ obs describes the size and shape of the territories we assume that the territories are roughly circular in shape by setting σ obs σ obs 2 i where i denotes the 2 2 identity matrix and σ obs 0 is a standard deviation related to the territory size it is useful to interpret this territory model using the circular contours of the distribution n μ i σ obs 2 i a circle of radius 1 χ α 2 2 σ obs centred at μ i is assumed to enclose the instantaneous location of the wolves belonging to the territory with probability α here χ α 2 2 corresponds to the 100 α quantile of the chi squared distribution with two degrees of freedom because of the temporal and spatial variability inherent to citizen science observation processes the observation model modulates the number of observations produced from the territories based on a temporal intensity function λ obs τ defined on a time interval of interest 0 t and a spatial intensity function λ obs s defined on the domain of the observed locations d y these intensity functions are assumed spatio temporally separable since there is limited data for their estimation which is further discussed in section 2 3 the values of these functions are tied to the number of observations the territories produce in time and space for constant functions λ obs s y l x 0 and λ obs τ u l t 0 our model assumes that the expected number of observations that a single territory produces on d y in a unit of time is approximately λ obs l x l t where λ obs is a scalar multiplier for the intensity functions the intensity functions λ obs τ and λ obs s are assumed known fixed and we discuss their estimation in sections 2 3 2 4 in addition to the observations originating from the territories the observation model also accommodates so called clutter observations that are understood as erroneous observations not originating from actual territories these observations are assumed to be distributed uniformly on d y and their intensity is likewise modulated by λ obs τ and λ obs s but multiplied by a different scalar parameter λ c the relative values of the scalar multipliers λ obs and λ c can be used to model the rate of the total number of observations believed to originate from the territories mathematically conditional on the territory locations and lifetimes our observation model defines a three dimensional inhomogeneous poisson process in time and space whose intensity function is given in equation 5 of the supplementary material the data generating model parameters in fig 1 are given by θ λ obs λ bd λ c σ obs d y d μ and the intensity functions λ obs τ and λ obs s 2 3 observation intensity modelling the following two sections discuss how we estimate the intensity functions λ obs τ and λ obs s in the observation model of section 2 2 2 this section focuses on step 1 of the modelling framework in fig 1 detailing the intensity model we fit to the past datasets a and b discussed in section 2 1 the primary data for this step are the spatio temporal points in dataset a discussed in section 2 1 1 we assume that each of these observations originated from an active wolf territory in this section we denote by ψ s i t i the spatio temporal point pattern of the wolf observations in dataset a with locations s i d y and dates t i t a 2011 01 01 2019 03 31 we assume the arrival of tassu reports ψ can be approximated by an inhomogeneous poisson process illian et al 2008 note that reporting depends on two consecutive events an observer is at a territory and they make and report an observation the data contains no information if an observer was on a territory but did not observe wolf activity the observer and reporting intensities are therefore confounded the situation is notably different from presence absence citizen science data such as for birding analysed with point processes by tang et al 2021 as in addition to absences not being measured the observers cannot be assumed to have been actively looking for wolf activity in the first place our situation is more akin to presence only analysis renner et al 2015 ver hoef et al 2021 with the nuance that instead of estimating species abundances the goal is to estimate the connection between a wolf territory s presence and the emergence of the tassu reports to account for the conditioning on a wolf territory s presence in this estimation we constrain the tassu observations to the auxiliary territories in dataset b detailed in section 2 1 2 given the observations on the auxiliary territories we estimate the intensities by aggregating the observations and then using standard poisson regression in the generalised additive models gam framework more specifically we fit the model on observation units given by spatio temporal grid cells c k v k t k with temporal resolution t k 1 month and spatial resolution v k 1 km 1 km from this discretisation of d y t a we only consider the subset of cells that intersect the auxiliary territories which is 11 9 million cells and then count the tassu reports in each such cell denoted by n k ψ c k resulting in 4816 non empty cells the auxiliary territory polytope which a cell c k overlaps is denoted by a k for each cell c k we let u k and y k represent its centroid in time and space respectively and finally define λ k τ t k λ obs τ u d u and λ k s v k λ obs s y d y then the counts in the grid cells are modelled with a poisson regression model of the following form 2 n k poisson λ k τ λ k s a k log λ k τ λ k s month u k year u k x y k β smooth y k x y k 1 expert a k corine k forestroad k t the offset a k is the area of the territory that grid cell c k belongs to and accounts for an assumption of the instantaneous location of the wolves following a uniform distribution within a k i e a pack on a larger territory is harder to observe the year and month effect were included as factors to model seasonal effects and year to year differences we used wolf years as discussed in section 2 1 1 for the factors year and month we did not include weather station information e g snow depth mainly because their monthly aggregates are highly correlated with month effects but also in order to avoid spatio temporal interaction terms to reduce model complexity given we have only 1 non zero units the spatial effects are modelled with covariates x and a residual smooth term the indicator 1 expert a k was included to adjust for potential discrepancies between the different types of auxiliary territories gps tracks expert estimates the numerical covariates corine k corine k 2 corine k 8 and forestroad k were described in section 2 1 2 and capture environmental variability the estimation was carried out using the statistical software r and the gam function mgcv bam with a smooth term smooth y k defined as a tensor product te term in x and y coordinates of the cell centroid y k the smoothness penalty choice was left to the default which is generalised cross validation wood 2017 2 4 computing intensity functions for the data generating model next we discuss how we compute the intensity functions λ obs τ and λ obs s based on the intensity model of section 2 3 fit to the past datasets a and b this section focuses on step 2 in the modelling framework of fig 1 the aim is to obtain intensity functions for the data generating model that anticipate the spatio temporal intensity of the observations in dataset c we model the intensity functions as piecewise constant such that λ obs τ takes on the value c t i during wolf month i i 1 12 and λ obs s takes on the value c v j in each cell v j d y in summary the c t i s and c v j s are computed by using quantities calculated from the predictions of the intensity model 2 in eq 4 below the computation proceeds as follows first assume that the intensity model 2 is fit using the datasets a and b then using the fitted model we predict the spatial effect λ k s excluding the term 1 expert a k for all 1 km 2 grid cells v k d y this grid is then smoothed using gaussian blur and we denote the value in the smoothed grid cell v k by λ k s more specifically we use a border preserving gaussian blur that only smooths cells that are within d y and normalises the blur weights in the smoothing window such that only non zero intensity values contribute to the smoothed grid we use σ obs as the standard deviation in the gaussian blur and set the window size to the first integer larger than 2 σ obs in kilometres we report the σ obs value used in this step together with the results of section 3 the smoothing of the predicted grid is motivated by an assumption of smoothness that our inference method places on the spatial intensity function we will discuss this assumption c in more detail in section 2 5 after computing the predicted and smoothed spatial effect we also predict the temporal effect for the wolf year associated with dataset c by setting λ i τ exp β year β month i where λ i τ is the predicted temporal effect for wolf month i 1 2 12 during the wolf year of interest here β year corresponds to a predicted wolf year regression coefficient obtained by running a linear regression on the previous wolf years regression coefficients available from fitting model 2 the coefficients β month i on the other hand correspond to the estimated wolf month coefficients from model 2 the linear regression for the year coefficients was carried out to take into account a slight increasing trend in the yearly regression coefficients of model 2 to compute the distinct values c t i and c v j that the piecewise constant functions λ obs τ and λ obs s take we match the predicted intensities such that 3 λ i τ λ j s a j t i v j λ obs τ u λ obs s y a j d y d u where a j is defined as in section 2 3 evaluating the integral 3 and taking the logarithm yields log λ i τ log λ j s log t i log v j log c t i log c v j to obtain equality in this equation c t i and c v j can be chosen such that 4 c t i exp log t i 1 log λ i τ k c v j exp log v j 1 log λ j s k where k is a constant that needs to be chosen our choice for k is k max j log v j 1 log λ j s which scales λ obs s 0 1 finally for the purposes of sections 3 3 and 3 4 we note that when λ obs s is computed as discussed above one of the territory centroids seen in fig 2 is outside the domain of λ obs s therefore in the case of the wolf territory estimation we additionally widen the domain of λ obs s by 27 kilometres at the boundaries by repeating the maximal intensity value found in the neighbouring cells of the borders 2 5 filtering algorithm and its constraints this section discusses step 3 of the framework in fig 1 the statistical inference of the territories given dataset c assuming the data generating model of section 2 2 this section gives an overview of the inference and the mathematical details are given in section 1 6 of the supplementary material in summary given dataset c and the data generating model of section 2 2 with fixed parameters and intensity functions the inference procedure outputs a sequence of joint filtering distributions of the territory centroid locations and their number at chosen times t 1 t 2 t n that are also input to the procedure the filtering distribution at time t is the distribution of the locations of the territory centroids and their number conditional on the observations of dataset c up to time t the inference method we use is somewhat involved and computationally intensive and based on sequential monte carlo particle filtering cf doucet et al 2000 more specifically the method is a rao blackwellised particle filter similar to the works of särkkä et al 2007 vihola 2007 but employing a state of the art optimal resampling algorithm developed by fearnhead and clifford 2003 a summary of the method s operation can be given as follows denote by y 1 k y 1 y 2 y k the k temporally ordered observations with observation times t 1 t 2 t k here the input timepoints t 1 t 2 t n are among the t i s and each y i is a spatial location from dataset c or y i 0 see also discussion on assumption a below the method works by processing the observations y 1 k sequentially such that the processing of y k yields the filtering distribution at time t k during the algorithm each filtering distribution is characterised by a set of m weighted particles more specifically at time index k 1 each of the m particles represents a hypothesis about the locations and number of territory centroids on d μ conditional on the observations y 1 k 1 seen so far with y 1 0 understood as the empty set the observation y k is processed such that first a set of possible territory birth territory death and observation association outcomes is built which consist of all one step futures that could happen for any existing hypothesis at time index k 1 conditional on y k and the time passed since y k 1 this set of outcomes is then probabilistically pruned using the optimal resampling algorithm of fearnhead and clifford 2003 which yields a set of m chosen outcomes and their normalised weights finally based on the chosen outcomes and the previous hypotheses a new set of m updated and weighted hypotheses particles is constructed by adding and deleting territories and associating y k if y k 0 to a territory using an approximate kalman filter update the filtering distribution at time index k is characterised by these m particles the process then repeats for the observation y k 1 the ideal data generating model of section 2 2 is time discretised and approximated before the filter can be used the approximations used can be justified by introducing a set of additional assumptions some of which are primarily computational and some of which help reduce the discrepancy between the approximate and the ideal model the following list highlights these assumptions which we will refer to as assumptions a to d a the observed data can be processed sequentially one at a time in other words each datum has an associated time and the observation times are strictly increasing b compared to the rate of observations arriving from the territories birth and death events of territories are rare c the spatial intensity function λ obs s is smooth slowly varying with respect to the territory size parameter σ obs this means that for any centroid μ d μ λ obs s μ is a good approximation for λ obs s x in the region where the distribution n μ σ obs has most of its probability mass d for most territories the territory centroid μ i is not close to the boundary of d μ in the sense that a region of high probability of n μ i σ obs is contained within d μ we conclude this section with a brief discussion on these assumptions assumption a is satisfied for many datasets that are collected in real time however as mentioned in section 2 1 the observation times in dataset c are pooled with a granularity of one day in order to make assumption a hold we introduce a preprocessing step before the filtering that artificially disperses the daily pooled observations in time generating a pseudotime for each observation within the day that it occurred this step introduces a bias which is small since the arrival intensity of the observations still remains practically the same as with the pooled data the preprocessing of the data is related to the time discretisation of the model which we make fine enough so that during filtering we may assume that practically at most one territory birth or death may occur during each time discretised interval and that the time discretised model approximates the ideal model sufficiently well we ensure this by introducing discretisation points to the dataset that contain no spatial location that is y k 0 for further discussion on these matters see sections 1 3 1 4 in the supplementary material assumption b is necessary for the identification of the territories based on the data in the present application assumption b holds since the births and deaths of wolf territories are relatively rare events on the daily timescale at which the observations in dataset c arrive assumption c is necessary for approximating certain intractable integrals that arise in the filtering algorithm and are related to the spatial intensity function λ obs s in section 2 4 we described a smoothing step for the predicted spatial grid which was carried out in order to satisfy assumption c finally assumption d arises since our method does not involve explicit edge correction the computations in the particle filter are approximate for territories and observations close to the boundary of the finite domain d μ this may entail some bias which is small under assumption d we investigate empirically the bias caused by the edge effect in section 3 2 2 6 extracting the number and locations of the territories from the output of the particle filter this section focuses on the final step of the framework of fig 1 and describes how we extract the number and locations of the territories from the filtering result our estimate for the number of territories at time t is the marginal filtering distribution of the number of territories at time t computed as follows denoting by n i i 1 2 p the unique numbers of territories found among the m particles at time t the marginal filtering distribution for the number of territories consists of the tuples n 1 π 1 n 2 π 2 n p π p where π i is the sum of the normalised weights of the particles having exactly n i territories in section 3 4 we will summarise these distributions by taking their mean mode and standard deviation and by computing probability intervals i α that is intervals whose end points are given by the 100 α and α quantiles of the distribution where α is a given percentage point a common way to visualise the probabilistic location information of an unknown number of objects is to plot the so called probability hypothesis density goodman et al 1997 phd of the filtering distribution which in the present context corresponds to the expected intensity of territory centroids more specifically the phd is defined for the territory centroids at time t by phd μ j 1 m w j i i t j f j i μ here w j is the j th normalised particle weight at time t i t j enumerates the territories in particle j at time t and f j i is the i th density in particle j at time t the densities f j i i i t j each represent the knowledge about a particular territory centroid location within one of the particles hypotheses in the context of our model these densities are either normal densities n μ m j i c j i with known means m j i and covariances c j i computed by our particle filter or uniform densities u μ d μ the form of the density uniform or normal depends on whether an observation has been associated with a particular territory centroid in the particle for more details regarding this see section 1 of the supplementary material our approach for visualising the territory locations differs slightly from standard phd and is as follows first we compute the phd but with the f j i s at the observation level meaning that for territories associated at least once f j i corresponds to the normal density n y m j i c j i σ obs for territories never associated we take f j i y u y d μ after computing the phd in this manner we furthermore truncate the phd values from above to the density value n 0 0 σ obs this value corresponds to the maximal contribution to the phd value from a single territory which is known to exist and whose location has been estimated with maximal precision in section 3 4 we will visualise the estimated territory locations on the map using this computation the rationale for this procedure is clearer visualisation of the regions where the filtering algorithm places the territories in section 3 we focus mostly on the estimation of the number of territories because it is relevant from the point of view of assessing the reproductive capacity of a wolf population the number of territories is also easy to work with from a model validation perspective since it is straightforward to compare it numerically to ground truths of simulation experiments and to results of other estimation methods in contrast the phd is important for graphical validation visualisation and interpretation of the filtering result 3 results we first discuss results regarding the observation intensity modelling in section 3 1 we then move on to the experiments with the data generating model and the developed particle filter starting with a synthetic scenario in section 3 2 and then moving on to a semisynthetic scenario in section 3 3 that resembles the situation with dataset c but is still based on simulated observations we conclude with the real data scenario based on dataset c in section 3 4 3 1 tassu observation arrival intensity estimation fig 3 displays the estimated intensity functions λ obs τ and λ obs x as well as the predicted spatial effect of the intensity model 2 based on the figure the temporal intensity function λ obs τ is seen to capture the rise in observation intensity in the winter time and the spatial intensity function λ obs s especially accounts for the high observation intensities in western finland the overdispersion of the poisson regression modelling of the observation intensities eq 2 fit was 1 83 after accounting for the overdispersion the yearly effects were not statistically significant at 5 level but monthly effects were clear the fluctuations with respect to the baseline month of april ranged from a 78 95 confidence interval 54 91 reduction in may to 371 206 592 increase in november with smooth transitions in between the corine landcover variable effects were mostly increasing when considering a 1 increase in the proportion of each cover class in turn the estimated increase in intensity was cultivated fields 19 9 29 closed forests 18 8 28 open forests 16 7 27 rivers and lakes 16 6 26 and other wetlands 19 10 30 effect of larger roads was not significant but a 1 increase in forest roads increased the intensity by 5 1 8 the smooth component was significant with a clear reduction effect in the central region and an increase in the west south west and south regions the explained deviance was 12 6 for diagnostics we first checked the pearson residuals aggregated at a month resolution dropping the spatial dimension see figure 4 in the supplementary material the cell counts showed slightly higher proportion of 0 s than the model predictions otherwise the overall quantiles were reasonably matched there were no obvious patterns in time apart from a potential positive trend during 2015 the residual variability was the same during 2011 2016 with only gps tracking auxiliary territories and during 2017 2019 when both auxiliary territory types were available pearson residuals exceeded 2 during five months 2014 10 2017 12 2018 01 2018 09 2019 02 with no clear pattern with three over estimates predicted v observed counts 39 v 14 257 v 175 543 v 475 and two under estimates 6 v 21 9 v 21 we then studied the pearson residuals in space without the time dimension to visually check troubling areas we aggregated the observed and predicted counts to 10 10 km cells observed counts had again slightly larger amount of 0 s and also some higher than expected values the latter mostly from the 2017 2019 period no obvious spatial structure was visible in the pearson residual map with large residuals dotted around the domain see figure 4 in the supplementary material we checked a version where the largest count in the temporal sum per cell was omitted before aggregation in space the residual sizes were greatly reduced max abs from 12 to 3 this sensitivity suggests that the observation counts are more concentrated in time and space than what we can capture with the model additionally spatially contiguous regions of underestimation particularly on the west coast were revealed indicating insufficient information in the spatial components of the model a further check of before and after 2017 spatial sums revealed a tight cluster of unexpectedly high observation counts in the border region of eastern kainuu 3 2 synthetic scenario and the edge effect our first territory estimation experiment is a purely synthetic simple scenario the purpose of the experiment is to ensure that the estimation algorithm works correctly we also investigate explicitly the bias caused by the edge effect as discussed in section 2 5 in this experiment we skip the intensity modelling discussed in sections 2 3 2 4 and focus on the filtering of simulated datasets we define the data generating model such that d μ 0 100 0 100 λ obs τ u 1 and λ obs s y 1 for all u 0 50 and y d y r 2 for the remaining parameters we set λ bd 0 0015 λ c 0 λ obs 1 this configuration corresponds to a simple scenario for our particle filter since there is no spatial inhomogeneity and the largest approximation in the filtering arises from the finite domain under these settings for all combinations of the number of particles m 128 256 512 1024 2048 and σ obs 1 2 5 10 15 we simulated 450 datasets as follows first we simulated the territory locations from the ideal birth and death model and then conditional on the territories simulated the observations from the ideal observation model each time preprocessing the observations with the method discussed in section 2 5 the initial distribution for the number of territories in the birth and death process was poisson 20 truncated to the interval 10 30 for each sampled initial territory we set the uniform distribution on d μ as the initial distribution for the centroid of the territory we filtered each simulated dataset assuming that the initial distribution above was known and computed the deviations n ˆ t n t for t 1 50 where n ˆ t is the estimated mean number of territories at time t from the particle filter and where n t is the true number of territories for the dataset we investigated the bias e n ˆ t n t which would be zero for an ideal bayes estimator by computing the empirical mean of the 450 deviations per t m and σ obs fig 4 summarises the results of this experiment with a small territory size compared to the size of the domain d μ we observe little or no bias in the estimation of the number of territories given that a sufficient m is used in the filtering algorithm for greater values of the territory size the bias is more significant and appears to only slightly diminish with increasing m this is expected since with higher territory sizes assumption d of section 2 5 is more likely to be violated leading to observations outside or near the boundary of d μ 3 3 semisynthetic scenario and feasibility of territory estimation next we consider a more realistic semisynthetic scenario with closer resemblance to the situation with dataset c in this scenario the idea was to fix the territory centroids to realistic locations use plausible parameter values and the intensity functions estimated as discussed in sections 2 3 2 4 we then simulated data to see how well the particle filter can recover the true number of territories under a more realistic setting more specifically we assumed that d μ corresponds to the domain of the tassu data fig 2 top left and the territory centroid locations were fixed to the centroids fig 2 bottom left of the territories found by luke in the wolf population assessment of 2019 we further assumed that each of these 47 territory centroids existed for a period of one year and that the territory count did not change we used the intensity functions in figs 3 c and 3 b as λ obs τ and λ obs s in the data generating model to set the value for the territory size parameter σ obs σ obs 2 i we examined the shapes and sizes of the territory polygons in dataset b discussed in section 2 1 2 as many of these territories were noncircular in shape see fig 2 bottom left for some similar polygons we estimated σ obs as follows first we computed the 95 quantile d 0 95 from the empirical distribution of the diameters of the territory polygons in dataset b then we used eq 1 with α 0 95 to compute the σ obs value that corresponds to a radius of d 0 95 2 yielding the value σ obs 13376 67 m here the diameter of a polygon means the maximal length between any two points of the polygon this procedure guarantees that typical territories fit inside the 95 probability region of the territory model for the remaining filter parameters we used the values λ obs 1 0 λ c 0 475 and λ bd 0 0015 the choice of the relative values of λ obs and λ c here corresponds to a situation where 1 of the total observation intensity is assumed to arise from clutter observations when the spatial and temporal intensity functions are constant one and there are 47 territories for a period of one year the choice of λ bd corresponds to a mean territory lifetime of 1 0 0015 667 days a little less than two years this choice averages between the fact that in reality some wolf territories are short lived but some can exists for years the chosen value also a priori predicts reasonable changes in the territory count over a period of one year while maintaining a good agreement between the ideal and approximate birth and death models see figure 1 in the supplementary material with these settings we simulated a total of 240 datasets for each particle count m 2 7 2 12 and applied the particle filter to each estimating the mean number of territories at approximately weekly intervals each time the filter was initialised with the initial number of territories following poisson 47 truncated to 37 57 with each territory centroid initially following the uniform distribution on d μ fig 5 shows the deviations computed by subtracting the true number of territories from the estimated mean territory count trajectories for each simulation and all particle counts in addition the average deviation and the average absolute deviation are shown on average the particle filter appears to recover the true number of territories quite accurately with increasing numbers of particles a slight underestimation of the true territory count is revealed the average absolute deviation further indicates that the discrepancy from the true territory count is typically less than 3 given that a moderate amount of data has been processed 3 4 application to the tassu dataset next we applied the developed particle filter with 16384 particles to dataset c as the initial distribution for the territory centroids we used the centroids seen in fig 2 bottom left with gaussian noise with covariance σ obs added to each this way the prior knowledge from the population assessment of march 2019 can be utilised in the filter we report results for four model variants as follows models 1 and 2 correspond to the same model configuration we used in the semisynthetic experiment but with model 1 having λ c 0 models 3 and 4 correspond to models 1 and 2 respectively but with another set of intensity functions λ obs τ and λ obs s obtained by dropping the terms corine k forestroad k and smooth y k from the intensity model 2 and then estimating λ obs τ and λ obs s as before as described in section 2 4 the resulting spatial intensity function in models 3 and 4 is constant one in d y for a plot of λ obs s and λ obs τ for models 3 and 4 see figure 2 in the supplementary material fig 6 displays the estimated territory locations and table 1 shows summary statistics of the filtering distribution for the number of territories based on models 1 4 at the end of march 2020 after the full dataset c has been filtered the computations underlying these quantities were carried out as explained in section 2 6 the overlaid territory polygons in fig 6 correspond to the territories found by luke in the wolf territory assessment of spring 2020 the plots show that each of the models 1 4 seem to find many of the wolf territories found by luke however it appears that models 1 and 3 with λ c 0 place multiple extra territories to central and southeast finland that are not found among the official territories these territories are most likely not real wolf territories since only a small number of observations have been reported from these areas see fig 2 top left the territories most likely arise since the observation intensity is low see fig 3 b and perhaps underestimated in these regions causing the filter to attempt to explain these observations with additional territories based on the plots for model 2 and 4 setting λ c 0 475 seems to mitigate this issue a bit as these observations are no longer interpreted as real observations from wolf territories we also experimented with a higher value for λ c but this resulted in a territory count distribution not well aligned with the count estimates by luke see also discussion below there is also no reason to believe that a substantial proportion of the data would not originate from the wolf territories another observation from fig 6 is that models 3 and 4 with the simplified intensity functions seem to somewhat better capture the cluster of territories in west and southwest finland in comparison to models 1 and 2 this difference in the results occurs since the spatial intensity function for models 1 and 2 assumes that in these regions the reporting intensity of the observations is higher than in other parts of finland this in turn results in less territories being needed to explain the observations arriving from these regions under models 1 and 2 based on the territory count distributions summarised in table 1 the territory counts for models 1 and 2 are best aligned with the estimate of luke in comparison the territory count for models 3 and 4 is somewhat overestimated fig 7 reports the sample standard deviations of the obtained mean territory counts at approximately weekly time points when we repeated the filtering of the tassu data 195 times with the configuration of model 2 and different particle counts the observation is that the variability in the estimated mean territory counts is seen to diminish with increasing numbers of particles but still remains noticeable even with 16384 particles we also experimented with different λ bd σ obs and intensity functions but the phenomenon persisted in contrast when a dataset is simulated from the model the results of this experiment are markedly different as is seen from the second pane in the figure similarly there is also some variability in the estimated territory locations figure 3 in the supplementary material shows the estimated territory locations after 10 independent runs of the filter to the tassu data 4 discussion we presented a statistical modelling framework for the analysis of citizen science data from territorial animals at the core of our framework is the data generating model discussed in section 2 2 that consists of a birth and death model giving rise to the animal territories and an observation model that links the citizen science observations to the territories in the developed data generating model the high variability common to citizen science observation processes is modelled through a temporal and a spatial intensity function which are assumed fixed and known the rao blackwellised particle filter described in section 2 5 estimates the sequence of filtering distributions for the locations and number of territories that describe the knowledge of the animal territories in time as more data is brought in we found that the fitted intensity model and the estimated intensity functions were able to capture general trends in the arrival of the citizen science observations as is seen from the estimated intensity functions in fig 3 clearly the model captures the higher arrival intensity of observations in the winter which mainly occurs because of snow that leaves wolf tracks visible for potentially long periods of time the estimated spatial intensity function on the other hand captures the high intensity of observations in western finland and the low intensity of observations in middle finland compared to other regions the intensity model did however struggle to explain some characteristics adequately for instance sometimes the observations arrived in unexpected bursts or were highly localised in space and these features the model was not flexible enough to capture cf figure 4 in the supplementary material a potential remedy for this might be the addition of random effects e g an additional noise component to each spatial pixel but it would be better to include interpretable rare event overdispersion components based on the social analysis of the mechanisms for reporting the wolf observations in fact the outliers are worth a closer look to gain such insight the model also struggled with an excess of 0 count cells due to how the conditioning on the auxiliary territories in dataset b was constructed another improvement for the intensity model could be a zero inflation component with its own regression structure on for example environmental covariates however an even better option would be to forgo the aggregation and model the data as a spatio temporal marked point pattern sicacha parada et al 2021 tang et al 2021 modelled this way events such as an observation being exactly on a road or snow cover of previous days would not be averaged out yet coarser resolutions for downstream analysis could still be easily computed other possible improvements include using the type of observation sightings paw prints game cameras etc in the intensity model and the improvement of the process of deriving the auxiliary wolf territories from the gps trajectories finally it might be beneficial to investigate the possibility to relax the space time separability assumption which would allow for the incorporation of weather data such as snow cover and or allow for individual time trends for western and eastern finland for example such complex models could then be estimated from longer period or more frequent observation series if available our synthetic experiment in section 3 2 investigated the mean territory count estimates of our particle filter under a simple data generating model and found that our method works as expected when assumption d of section 2 5 holds with high territory sizes this assumption is violated and there is some bias in the estimation of the mean territory count this edge effect arises due to the finiteness of the domain d μ in particular the violation of assumption d reduces the accuracy of the approximation 25 in the supplementary material which likely causes the bias in this experiment territory parameters on a scale of 1 2 of the width of the rectangular region led to small bias noting that the distance between the western and eastern borders of finland is approximately 500 kilometres we therefore expect that the bias caused by the edge effect should be small in the realistic experiments discussed in sections 3 3 3 4 the semisynthetic experiment of section 3 3 showed that under realistic conditions resembling the situation with the tassu dataset the estimation of the territory count is possible there was a slight underestimation of the true territory count with increasing numbers of particles which we think occurs because of the discrepancy between the scenario and the ideal model or the approximations used this experiment was a proof of concept that showed that the territory estimation can be feasible even with presence only data when the model is correct while experimenting with different parameter values for the data generating model we found that in general the model and especially the count estimation is most sensitive to the values of the territory size parameter σ obs and the intensity functions and least sensitive to the choice of the constant and equal birth rate λ bd this is expected since large territory sizes increase the probability of an observation being associated with a territory that is far away decreasing the relative probability of a new territory emerging in a similar vein the intensity functions are directly tied to the amount of territories needed to explain the number of observations arriving with a fixed dataset lowering the observation intensity results in more births since a higher number of territories is then needed to explain the data the concluding analysis in section 3 4 applied the developed data generating model and particle filter to analyse citizen science observations of wolves from april 2019 to march 2020 the results show similar patterns as the counts and locations reported by the natural resources institute finland luke in the official assessment of march 2020 however the results do not reach the accuracy of expert judgement this cannot be expected because the official assessment also incorporated additional information sources such as dna samples gps collared wolves and mortality records based on table 1 the inference of model 2 incorporating the estimated spatial intensity function and clutter observations resulted in a slightly smaller estimated territory count and smaller variability than the official estimate by luke in general such differences can occur because the estimates of luke are based on a very different model and assumptions and also take advantage of additional data when using the citizen science data only it is also possible that the particle filter might not find territories which rarely produce observations leading into underestimation of the territory count furthermore the uncertainty reported by the particle filter can be underestimated because the results are based on a single particle filter run if monte carlo variability is taken into account the uncertainty is inflated see also discussion below we noticed that with models using a constant one spatial intensity the cluster of territories in the west and southwest finland was captured better than with models that used the estimated intensity functions as was seen from fig 6 this might suggest that the observation intensities in the more complex models are overestimated in these regions at the time of the observations arriving indeed based on the pearson residuals in figure 4 of the supplementary material the intensity model fit could not capture all of the variation in these regions despite this it appears that using the spatially varying intensity improves and is likely a requirement for the accurate estimation of the territory count this is supported by the territory count distribution in table 1 which indicates that the territory count estimates of the more complex models were better aligned with the official territory count estimates of luke in general we found that estimating the territory count and locations of the territories reliably is challenging by only using the citizen science observations from the tassu database the challenges faced may be partly explained by unsatisfactory observation intensity modelling but it appears that the inference algorithm is also struggling with real data fig 7 and 3 in the supplementary material show repeated runs of the filter in our concluding analysis indicating some monte carlo variability we believe that the main challenge for the inference is the presence only nature of the observations these observations are quite informative about the births of new territories since a territory needs to exists so that an observation may occur in contrast the observations are not very informative about the deaths of the territories because the information about a death of a territory is indirect and only mediated by the absence of observations arriving from a particular area this difficulty with the data might explain the monte carlo variability in our particle filter and further suggests that it could still benefit from further specialisation to the territory estimation task for instance this specialisation could come in the form of further heuristics that eliminate territories more efficiently when no observations have been associated for a long time all in all we think that the results obtained suggest that the developed modelling framework might be useful as an additional tool in the annual wolf population assessment reducing the amount of subjectivity in the estimation process by providing a preliminary statistical interpretation of the citizen made observations integration of the dna samples gps collared wolves and other data with the results of the particle filter would still remain a task for the panel of experts our analysis with datasets a b and c of section 2 1 showcased the intended use of the modelling framework in the context of the wolf population assessments first the intensity functions required by the data generating model are estimated based on the latest historical data then the particle filter is initialised with the territory count and location distribution available from the latest population assessment finally the yearly observations are analysed in a batch to obtain a model based view on the status of the wolf population at the time of the next population assessment filtering a year of data from april 2019 to march 2020 allowed both the comparison to the official wolf population assessment of 2020 and the use of prior information from the assessment of 2019 however this yearly batch estimation is not the only way in which the developed data generating model and particle filter could be used in fact one of the motivations for the development of the data generating model and the particle filter was that the developed modelling framework could also be used in an online fashion this way smaller batches of new observations could be used to update the posterior distribution of the territory locations and track the population in finer timescales in the context of the wolf territory estimation the results from such an online estimation could provide dynamic feedback for the volunteers collecting the data highlighting that their work is important such feedback might also be used to direct the effort of the volunteers to areas with the most uncertainty about the existence of territories we envision that our modelling scheme could also be a noteworthy tool for refining the population assessment of other large carnivores for example the female eurasian lynx lynx lynx are known to show territorial behaviour with cubs this could be exploited in the estimation of lynx reproduction it might also be possible to couple the developed framework with other developments for assessing animal populations such as the spatial capture recapture scr model which estimates wolf density based on dna samples bischof et al 2020 for example the two approaches might be used sequentially the scr model could be used first to estimate the spatial wolf density based on dna samples and then the density could provide another source of prior information about potential territory locations for our data generating model on the other hand in case that the dna samples are collected by volunteers the modelling of the sampling effort in the scr model could be done by similar techniques as in this work besides the context of territorial animals our methods might be relevant in target tracking where the modelling of the temporal and spatial variability of the observation process is required the methods may also be regarded as a form of dynamic clustering in different applications the modular nature of the developed framework can be exploited to carry out the intensity modelling in a way that fits the application there are a number of ways how the developed data generating model and the inference algorithm could be improved in future works the core of the filtering computation consists of evaluating the posterior probabilities for the birth death and association variables see section 1 6 of the supplementary material the main approximations made in the computation arise from the intractable integrals related to the spatial domains d μ and d y and the spatial intensity function λ obs s we concentrated on the situation where λ obs s may be assumed to be slowly varying by assumption c allowing for straightforward approximation of the intractable integrals in the probability computations and the measurement update introducing a numerical integration scheme could mitigate the bias from the approximations in the former it might also be possible to incorporate a no overlap condition to the model that penalises large overlaps of the territories the developed particle filtering approach assumes fixed parameter values even with the limited and noisy citizen science data it might be possible to estimate some parameters of the data generating model such as the intensity scaling parameter λ obs and or parameters related to the birth and death intensity functions λ b and λ d this could result in a better fit of the data and model and might result in improved location and count estimates in theory estimating the model parameters is possible using for example the particle marginal metropolis hastings algorithm andrieu et al 2010 similar to kokkala and särkkä 2015 using these methods would however require the derivation of an unbiased estimate of the marginal likelihood of the observed data under the employed optimal resampling scheme of fearnhead and clifford 2003 for the current model and a moderate to large dataset such estimation procedures are also computationally intensive and would likely require a tailored parallel implementation the methods might also be difficult to tune in practice the data generating model could in principle readily incorporate moving territories as well perhaps using an ornstein uhlenbeck type movement model as in the work of johnson et al 2008 we did not attempt this with the wolf territory estimation because our main interest was in immobile territories in addition we suspect that the additional flexibility in the model allowing for movement would make the inference task substantially more difficult or even infeasible furthermore we do not believe that in our dataset each territory is observed frequently enough to make the inference with an additional movement model practical the observation model could also be further refined we did not separate between the different observation types but some observation types can be more reliable than others and may be subject to different observation intensity detectability consider for instance tracks vs sightings we chose to simplify since we do not believe that adequate intensity estimation is possible for the different observation types separately with our dataset in another context however it would in principle be possible to modify the observation model to also accommodate different observation types the intensity function of the observation model see equation 5 in the supplementary material could be augmented with independent data streams for the different observation types each with their own spatio temporal and clutter intensities this could lead to interesting observation models such as ones that designate higher clutter intensity for more uncertain observations types such as sightings another means of model improvement are more fine grained birth death models in ecological applications for example further information such as mating seasons or typical lifespans of the species could be encoded into the birth and death intensity functions λ b and λ d in the general model described in the supplementary material however these kinds of models would likely achieve their full potential when coupled with parameter estimation discussed above in our wolf territory estimation we did not investigate time varying birth death intensity functions and opted for a model where a territory can emerge at any time even though wolves only reproduce in the spring new wolf territories can form at any time of the year when vagrant wolves pair up and establish new territories furthermore the majority of the citizen science wolf observations are made in the winter time and it is possible that the first observation from a territory formed in the spring comes later in the winter credit authorship contribution statement santeri karppinen conceptualization methodology software validation formal analysis investigation data curation writing original draft writing review editing visualization project administration tuomas rajala conceptualization methodology software validation formal analysis investigation data curation writing original draft writing review editing visualization project administration samu mäntyniemi conceptualization writing original draft resources writing review editing supervision project administration ilpo kojola resources writing original draft project administration matti vihola conceptualization methodology project administration writing original draft writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we thank gabriel kasmi who was involved with early experiments related to this research sk and mv were supported by the academy of finland research grant 315619 the authors wish to acknowledge csc it center for science finland for computational resources appendix a supplementary data supplementary material related to this article can be found online at https doi org 10 1016 j ecolmodel 2022 110101 appendix a supplementary data the following is the supplementary material related to this article mmc s1 additional figures and the details of the the data generating model and particle filter 
24382,we developed a spatially explicit agent based model abm deerlandscapedisease dld to investigate the effects of landscape structure disease transmission and management alternatives on dynamics of chronic wasting disease cwd in white tailed deer odocoileus virginianus we fitted biased random walk models to data from gps collared deer to simulate movements of individual deer and deer groups in an agricultural landscape with fragmented forest patches and a forest dominated landscape we estimated behavioral and demographic parameters from field data and published literature of deer ecology we considered both direct and indirect transmission routes and assumed that bioavailability of infectious pathogens deposited in the environment decreased exponentially over time we tuned transmission parameters to match observed trajectories of cwd prevalence in wisconsin and assumed that infection probability during an encounter was equal for all age classes thus infection prevalence varied with sex and age specific behavior dld simulations demonstrated significant effects of landscape structure social behavior and transmission mode on temporal changes in prevalence prevalence rose faster and reached higher levels in fragmented forest landscapes due to aggregation of deer within small forest patches furthermore simulation results suggested that cwd might be driven through a mix of frequency and density dependent processes potentially facilitating coexistence of cwd and deer populations these results demonstrate the utility of abms and the importance of including spatial and behavioral heterogeneity when modeling disease transmission keywords agent based modeling spatially explicit white tailed deer empirical based movement chronic wasting disease deer behavior data availability the model code has been uploaded to figshare and a link is provided 1 introduction wildlife epizootics are challenging to predict or control and any hope of doing so requires understanding of the routes and patterns of transmission epizootiological models can inform predictions of disease and impacts and the success of control efforts based on observed or hypothesized transmission patterns classical mathematical models assume that force of infection is dependent on either the proportion of infected hosts frequency dependent transmission or the population density of infected hosts density dependent transmission may and anderson 1979 o keefe 2005 yet many diseases may not fit well within this strict dichotomy in addition the establishment and transmission of disease within a population are both stochastic and intrinsically spatial affected by demography population dispersion and habitat heterogeneity drake 2005 fa et al 2001 gudelj and white 2004 parratt et al 2016 rees et al 2013 an animal may die before it can transmit the disease extinguishing an epizootic before it can begin once the disease is established an infected animal might become spatially isolated or surrounded by other infected animals thus reducing the transmission of disease to susceptible hosts spatially explicit agent based models abms are advantageous because they can reproduce stochastic spatio temporal segregation of infected and uninfected individuals fa et al 2001 gudelj and white 2004 and can incorporate detailed spatio temporal variables individual variations and demographic stochasticity conner et al 2007 rees et al 2013 wilson 1998 most abms on epizootiology only incorporate direct transmission pathways and do not base individual behaviors on empirical movement data e g rabbit viral hemorrhagic disease fa et al 2001 bovine tuberculosis in badgers smith et al 2001 and chronic wasting disease belsare et al 2018 belsare and stewart 2020 several diseases such as bovine tuberculosis and chronic wasting disease cwd may be spread through both direct and indirect contact palmer and whipple 2006 williams et al 2002 furthermore disease transmission is dependent on contact rates that in turn are determined by how animals move within their environment indirect contact and in relation to other animals direct contact previous models on cwd transmission have not incorporated empirical based movement gross and miller 2001 nor indirect transmission of the disease belsare et al 2018 belsare and stewart 2020 but the effect of animal movement on contact rates and thus disease transmission indicates that incorporating realistic movement behaviors into models of disease transmission may be of great importance we developed deerlandscapedisease dld a spatially explicit abm to simulate disease transmission in white tailed deer using published data on cwd and empirical data on deer behavior and movement cwd is the only transmissible spongiform encephalopathy found in free ranging wildlife affecting deer odocoileus hemionus odocoileus virginianus elk cervus canadensis miller et al 2000 saunders et al 2012 williams et al 2002 reindeer rangifer tarandus benestad et al 2016 and moose alces alces baeten et al 2007 colorado division of wildlife 2012 cwd affects the central nervous tissue and is characterized by behavioral changes such as excessive salivation tremors lack of coordination difficulty swallowing and increased drinking and urination followed by loss of body condition and ultimately death miller et al 2000 the prion agent causing cwd has been found in saliva blood urine and feces haley et al 2009a c k mathiason et al 2006 and can remain infective in the environment for years mathiason et al 2009 miller and williams 2003 williams et al 2002 thus both direct and indirect transmission of cwd may occur however little is known about the strength of each infection route and the subsequent long term effect of cwd on population densities within wild animal populations the animal model in dld specifically simulates behavior of white tailed deer thought to influence population dynamics and disease transmission such as movement mating and grouping behavior the disease component in dld allows for pathogen build up in the environment and contacts between individual deer either direct or indirect are modeled as a stochastic process depending on movement of the animals involved we used dld to investigate the following research questions 1 how does landscape composition affect deer behavior and movement and thus cwd transmission 2 how will different transmission pathways direct vs indirect transmission affect long term host disease dynamics frequency vs density dependent transmission and 3 will deer removal aid in controlling cwd in wildlife populations our description of dld follows the odd overview design concepts details protocol grimm et al 2006 2010 2020 detailing methods for modeling individual and group movement within home ranges based on gps collar locations in appendices 2 materials and methods 2 1 programming platform dld was created using the repast simphony platform north et al 2013 2007 2005 and java programming language arnold et al 2005 we chose repast simphony due to its user friendly graphical user interface its ability to incorporate raster files and shape files the versatility of the java programming language and the ability to run from standalone batch files furthermore repast simphony is free and open source 2 2 landscape data the landscapes in dld are based on two study sites in illinois usa fig 1 one is a predominantly forested landscape in southern illinois whereas the east central illinois study site is dominated by agricultural fields and fragmented forest patches table 1 in dld we refer to the southern illinois landscape as the contiguous forest landscape and the east central illinois landscape as the fragmented forest landscape 2 3 model overview dld is a stochastic spatio temporal simulation model that runs with 2 hour time steps the model is agent based and incorporates demographic processes of white tailed deer such as birth and death mating grouping as well as a detailed empirically based movement model dld furthermore includes a disease component simulating the transmission of cwd both directly via animal to animal contact and indirectly as cwd prion build up and decay in the environment 2 4 summary odd a complete detailed model description following the odd protocol grimm et al 2020 2010 2006 is provided in appendix a and a summary odd following the template by grimm et al 2020 follows the overall purpose of dld is to understand the transmission dynamics and long term impacts of cwd in white tailed deer populations we are specifically addressing how landscape structure and transmission mode affect population level cwd dynamics in white tailed deer frequency vs density dependent transmission under realistic movement and social behaviors in addition we aim to assess the effectiveness of alternative culling strategies for disease control to consider our model realistic enough for its purpose we use patterns in mortality reproduction mating age home range grouping and movement the model comprises the following entities individual deer adult females adult males and fawns landscape square grid cells of 25 25 m referred to as pixels time and disease individual deer are characterized by the state variables identity number age sex identity of the home range where the individual lives group membership and disease status individual deer are assigned specific behavioral states that are dependent on season age and sex of the animal each behavioral state is associated with state specific movement and behavior and transitions between states are triggered by events such as dispersing or mating states in the model are normal dispersal mating and exploratory behavior fig 2 as for the spatial and temporal resolution and extent each time step in the model is 2 h and simulations are run for 50 years dld is spatially explicit but landscape structure and habitat types are held constant within the model the most important processes of the model which are repeated every time step are the update of indirect and direct contacts produced by moving deer agents as well as the update of the landscape pixels regarding build up and decay of cwd prions indirect contact furthermore the following deer behaviors and attributes heavily influence the above processes 1 individual movement at each time step as it is dependent on the age sex and behavioral state of the agent whether it is member of a group tending to a fawn female movement only following a female during the mating season male movement only dispersing or conducting exploratory behavior see appendix a and c for details on modeling movement based on empirical data 2 cwd status as direct infectivity rates prion deposition rates and mortality rates due to cwd are modeled as functions of time resulting in infected agents becoming more infectious with time shedding more prions in the environment with time and mortality increasing as the disease progresses see appendix a and b for details as we allow for cwd prions to accumulate in a landscape pixel we added prion decay to simulate an exponential decline over time of prions in a pixel appendix a a decay that is also updated at each time step see appendix a and b for details empirical data on the bioavailability of prions in the environment is not available so we set a half life of 6 months as a starting point see appendix a and b the most important design concepts of the model are the way dld incorporates behavior dependent deer movement based on empirical data from field studies movement sub model appendix a and c and the incorporation of a cwd sub model governing direct and indirect contact rates and cwd prion build up and decay in the landscape pixels these components allow for emergent patterns of disease dynamics based on individual behaviors and movements within dld 2 5 dld scenarios we created 6 different scenarios to investigate the importance of landscape structure mode of transmission and deer removal on disease transmission and host population dynamics we ran direct and indirect transmission scenarios separate for both the fragmented forest landscape and the contiguous forest landscape 4 scenarios we separated the two transmission modes as the contribution of each transmission pathway in nature is unknown and we wanted to assess how different transmission modes can affect long term disease dynamics we explored the efficacy of general e g increased public harvest as opposed to localized culling e g sharpshooting entire groups by reducing maximum group sizes to half of the default values female group size 2 male group size 5 at the same overall population size for default groups sizes see appendix b we only reduced group sizes given direct transmission because we expected the effect of reduced groups to be higher for direct contacts schauber et al 2007 we also ran each landscape without any disease present and thus ended up with 8 scenarios total we ran 500 replicates of each scenario for 50 simulation years including a 5 year burn in period and checked for convergence 2 6 data analysis 2 6 1 cwd prevalence and force of infection we first checked if 500 replicate runs were adequate to reach convergence of the standard deviation for prevalence then we compared temporal patterns of prevalence arcsine square root transformed among scenarios using repeated measures anova omitting year 1 5 to avoid initial transient dynamics we used the same analysis to compare prevalence between males females and fawns within scenarios we also compared prevalence between young 3 years and old 3 years males and females to examine how prevalence changes with age to investigate whether differences between observed prevalence patterns in our model and prevalence found in field studies could be attributed to difficulties in detecting early disease infection we re analyzed our data using only animals infected for at least 6 months infectious prevalence using same methods as above to assess whether transmission patterns that emerged in our model corresponded better to density dependent or frequency dependent concepts we used a power law regression to compare how strongly force of infection ζ proportion of susceptible in year i surviving to year i 1 that became infected during that year was related to the density of infectious infected 6 months animals in year i i density dependence versus infectious prevalence in year i i n frequency dependence 1 ζ e b 0 i b 1 i n b 2 l n ζ b 0 b 1 l n i b 2 l n i n if ζ is linearly density dependent then b1 should 1 and b2 should 0 and vice versa for linear frequency dependence nonlinearity can be handled by exponents different from 1 we only included animals infected 6 months in i and i n because cwd in dld is modeled as having a latent period with animals at an advanced disease stage assumed to be more infectious to account for delays in prion accumulation in the indirect transmission scenarios we also used power law regression to model ζ in year i against i and i n in year i and prior years 2 l a g 1 l n ζ i b 0 b 1 l n i i b 2 l n i n i b 3 l n i i 1 b 4 l n i n i 1 3 l a g 2 l n ζ i b 0 b 1 l n i i b 2 l n i n i b 3 l n i i 1 b 4 l n i n i 1 b 5 l n i i 2 b 6 l n i n i 2 to account for collinearity of i and i n we used standard linear regression to compare the fit of the above models with models involving either i alone or i n alone and calculated the partial r2 for each predictor 4 p a r t i a l r 2 b r 2 a a n d b r 2 a o n l y 1 r 2 a o n l y all analyses were conducted in r 3 5 2 r development core team 2018 and we omitted year 1 to 7 for all power law analyses to avoid initial transient dynamics and account for time lags up to 2 years 2 6 2 sensitivity analysis we conducted a one factor at a time local sensitivity analysis on prion half life by decreasing and increasing it by 2 months half life of 4 and 8 months respectively the half life of prion proteins is largely unknown thus we varied our default half life of 6 months by 33 33 to assess how different magnitudes of this parameter would impact prevalence the analysis was carried out for indirect scenarios and run for 50 years with the same initial parameters as the original runs during the transmission coefficient calibration process to fit our prevalence patterns to observed prevalence patterns in wisconsin see appendix a we observed a very high sensitivity of the model to this parameter both for the direct and indirect scenarios thus we did not conduct sensitivity analysis on this parameter 3 results 3 1 dld simulation runs convergence of prevalence standard deviations was reached with 500 replicates of each scenario appendix d fig d1 indicating that 500 replicates were enough to distinguish between scenarios and to perform statistical hypotheses testing on the simulation results all repeated measures analyses of total infection prevalence and infectious prevalence proportion infected 6 months indicated significant scenario time all f 220 134 730 100 p 0 0001 and age sex category time interactions all f 176 673 650 10 p 0 0001 3 1 1 landscape effects and transmission mode without the disease component populations grew at an average rate of ca 3 per year and population sizes after 50 years averaged ca 4500 animals for both landscapes not depicted adding the disease component to the model caused population decline in all of the fragmented forest scenarios where effective population densities were higher because less of the landscape was suitable for home ranges the direct transmission runs showed an average peak population decline average of peak declines of all replicates omitting year 1 5 of 11 3 with an average population size of ca 502 in year 50 of the simulation run fig 3 a in the indirect transmission scenario the average peak population decline was 11 3 with an average population size of ca 546 in year 50 for the contiguous forest landscape populations also decreased in the direct transmission scenarios with default group sizes with an average peak decline of 7 8 and a population size of ca 884 in year 50 of the simulation runs for the continuous indirect transmission scenario the average peak decline was 7 3 with an average population size of ca 1061 in year 50 of the simulation runs fig 3a for both direct and indirect transmission cwd prevalence reached higher values and peaked earlier in the fragmented forest landscape where the deer population was compressed into less space than the contiguous forest landscape fig 3b in both landscapes direct transmission resulted in higher prevalence than did indirect transmission with direct transmission prevalence was higher in males whereas prevalence values in fawns females and old females were similar fig 4 when only including animals infected longer than 6 months the difference between age and sex groups in the direct scenarios was mainly due to higher prevalence in males and lower prevalence in fawns fig 5 prevalence in old males was higher than in young males for the direct scenarios for the indirect scenarios the differences in prevalence levels were mainly due to lower prevalence in fawns fig 4 and fig 5 3 1 2 deer removal population size for the direct fragmented forest scenario with reduced group size showed an average peak decline of 9 9 and ended with an average size of ca 631 in year 50 fig 3a the contiguous forest scenarios generally increased in population size but had an average peak decline of 6 5 and an average population size of ca 1255 in year 50 fig 3a reducing group sizes produced lower prevalence and later epizootic peaks than with default group sizes for both the fragmented and contiguous forest scenarios fig 3b as with default group size we found that cwd prevalence was higher in males with similar prevalence for fawns and females for both the fragmented and contiguous forest scenarios fig 4 when looking at animals infected longer than 6 months we found higher prevalence in males and lower prevalence in fawns fig 5 3 1 3 force of infection and host disease dynamics force of infection ζ showed similar relationships with the density of infectious individuals i those infected 6 months and infectious prevalence i n across the different scenarios fig 6 the density and frequency of infected animals i and i n respectively tracked similar trajectories over time fig 6 making it difficult to determine which was the stronger driver of changes in force of infection however power law regression of output with direct transmission lent more support for frequency dependent than density dependent transmission tables 2 4 whether comparing the relative sizes of the coefficients representing density dependence and frequency dependence table 2 the percentage of runs where each coefficient was statistically significant table 3 or their partial r2 values table 4 frequency dependence received about twice the support or more than density dependence across scenarios with direct transmission in contrast results from indirect transmission scenarios yielded balanced support for density and frequency dependent transmission in the contiguous landscape and greater support for density dependence in the fragmented landscape tables 2 4 output from simulations with indirect transmission yielded little evidence for lagged effects of i or i n on ζ tables 2 4 adding lagged predictors did not substantially improve r2 table 4 and resulted in unstable coefficient estimates table 2 that achieved statistical significance in less than 11 of replicate runs table 3 3 2 prion half life sensitivity analysis performed on prion half life showed that disease prevalence was highly sensitive to this parameter compared to the original 6 month half life a shorter half life of 4 months resulted in lower prevalence for both the contiguous and fragmented forest scenarios where at the prevalence peak prevalence for both scenarios were almost half of the prevalence produced by a 6 month half life appendix d fig d2 this resulted in a higher deer population size than in the original scenarios with a still increasing population for the contiguous forest landscape appendix d fig d3 a half life of 8 months resulted in almost a doubling of the prevalence at the prevalence peak for both the contiguous and fragmented forest scenarios compared to scenarios with a 6 month half life appendix d fig d2 population size for these scenarios were much lower than for the original scenarios with a much earlier decrease in deer numbers appendix d fig d3 4 discussion we developed an agent based spatially explicit model on cwd transmission in white tailed deer to investigate how landscape and transmission mode may affect overall and sex specific cwd prevalence and subsequently host disease dynamics we simulated culling by reducing group sizes to investigate whether deer removal could aid in controlling cwd in white tailed deer we furthermore used force of infection to assess whether the emerging transmission patterns corresponded better to density dependent or frequency dependent concepts 4 1 landscape effects on cwd transmission cwd transmission and mortality were sufficient to cause deer population declines in both contiguous and fragmented landscapes but disease spread more rapidly and produced earlier and more severe population impact in the fragmented landscape these population impacts can be explained by differences in effective population density between the two landscapes white tailed deer need a component of forest cover within their home range marchington and hirth 1984 concentrating and increasing the local density of deer in landscapes with small forest patches and thus the potential for both direct and indirect contacts farnsworth et al 2005 found that destruction of suitable habitat due to development might cause a concentration of mule deer o hemionus in suitable fragmented patches increasing local population density and thus accelerating transmission of cwd storm et al 2013 found cwd incidence in wisconsin to be positively related to forest edge density length of edge relative to the total area analyzed and in canada norbert et al 2016 found high cwd risk in high deer density riparian forest patches surrounded by agriculture as simulated population sizes decreased in dld prevalence in the fragmented forest landscape still increased for multiple years when transmission was both direct and indirect until the host disease system somewhat approached a stable equilibrium by the end of the simulations this could be due to landscape configuration where deer in the fragmented scenario would be aggregated in forest patches with local densities being still high enough to drive prevalence until a certain threshold a different pattern is found in the contiguous forest scenarios where direct transmission scenarios show a more concomitant relationship between population size and prevalence these results highlight that cwd control efforts may need to be both more intensive due to enhanced transmission and more spatially extensive to be effective in landscapes where deer habitat is highly fragmented such as in much of the midwest and great plains urbanization and agricultural expansion are continuously causing forest fragmentation in the us and elsewhere fynn and campbell 2018 high effective density of deer within small strips and patches of forest cover combined with the greater dispersal tendency and distance of white tailed deer in open landscapes kelly et al 2014 long et al 2005 lutz et al 2015 nixon et al 2007 amplify the challenge in illinois where cwd is found within agriculture dominated areas in the northern tier of the state efforts to control cwd have arguably been successful in slowing the rise in prevalence manjerovic et al 2014 mateus pinilla et al 2013 but continual geographic spread is straining capacity when cwd is first detected in a fragmented landscape there may be a unique opportunity to locally suppress or even eradicate the disease but only with intensive effort around the area of initial discovery varga et al 2021 4 2 transmission mode of cwd and host disease dynamics 4 2 1 direct and indirect transmission cwd can be transmitted through both direct animal contact and environmental sources haley et al 2009a mathiason et al 2009 c k 2006 miller and williams 2003 williams and miller 2003 but the strength of each pathway and how much they each contribute to the transmission and persistence of cwd in free living populations are unknown we chose to separate the different modes of transmission in our model runs to investigate possible effects on model outcome the difference in prevalence could be due to direct transmission being more stochastic as contacts are very time dependent and there is a higher chance of disease extinction due to death of diseased animals indirect transmission can continue even after the death of the diseased individual due to accumulation of prions in the environment thus disease transmission is more reliably dependent on duration of exposure schauber et al 2007 2015 found that indirect contact rates among female deer were much less strongly influenced by social group membership than were direct contact rates with indirect contacts being driven mainly by the amount of shared space transmission mode greatly affected age and sex specific prevalence patterns for the direct transmission scenarios the observed patterns roughly reflected those seen in wild deer populations impacted by cwd the higher prevalence in male deer especially older males is also observed in empirical studies of cwd potentially due to differences in behavior or physiology farnsworth et al 2005 grear et al 2006 miller and conner 2005 osnas et al 2009 samuel and storm 2016 in our model males are part of larger groups and move around more than females leaving and joining new groups furthermore we model males to follow females around during the rut which could potentially add to infection exposure infection prevalence was very similar in fawns and adult females when we included all infected animals in empirical studies however observed cwd prevalence is generally lower in fawns than adults grear et al 2006 wisconsin department of natural resources 2012 this discrepancy could be explained by difficulties in detecting early stage infection with standard diagnostic tests haley et al 2009b mathiason et al 2009 our results when including only animals infected longer than 6 months mirror the lower apparent prevalence in fawns compared to all other age classes although indirect transmission is dependent on how animals move and overlap in habitat and space use it does not require simultaneous space use which could explain similar prevalence across adult sex and age classes in the indirect scenarios the observed lower prevalence in fawns could be explained by transmission not being a result of contact between individuals but being a question of time of exposure to the pathogen fawns would have had less time to be exposed to prions in the environment these results suggest that the age and sex specific differences in cwd prevalence observed in wild deer populations may mostly be driven by direct transmission given no evidence of increased genetic cwd susceptibility in males rogers et al 2022 as they could be a result of differences in behavior the higher prevalence in males along with greater male mobility hawkins et al 1971 nixon et al 2007 1994 rosenberry et al 1999 could lead managers to conclude that cwd control may be better applied focusing on males however with indirect transmission or if transmission is primarily from females to males this form of male focused culling may only work in areas where cwd has not yet been established recent simulation models on harvest based cwd management have suggested that higher disease prevalence in males may not necessarily indicate that male deer are more responsible for disease transmission only that they may experience higher exposure or susceptibility rogers et al 2022 these models showed that for management interventions to be efficient in limiting cwd epidemics harvest of both male and female deer is required rogers et al 2022 emphasizing how sex selective harvest based on prevalence alone might be misleading 4 2 2 host disease dynamics density or frequency dependent transmission of cwd the force of infection measures the rate of disease spread within a population and our results varied between landscapes and transmission modes within a landscape direct transmission seemed to produce a higher force of infection than indirect transmission except when group sizes were reduced force of infection was better predicted by infectious prevalence than density of infected animals infected 6 months in the direct transmission scenarios whereas the pattern was unclear or leaned toward density dependence for the indirect transmission scenarios these statistical results are in contrast to the overall epizootic dynamics that are strongly consistent with density dependent transmission namely the fact that the cwd epizootic peaked earlier and at higher prevalence in the fragmented forested landscape scenarios where local population density was greater than in the contiguous landscape overall these findings suggest that disease transmission of cwd may be dependent on the combination of transmission mode and landscape structure also the true nature of cwd transmission whether through direct or indirect contacts may be intermediate between density and frequency dependent transmission but unlikely to destabilize host populations in a cwd study from wisconsin storm et al 2013 found that models with intermediate transmission modes performed better than strictly density or frequency dependent transmission models when predicting incidence rates in harvested yearling deer also suggesting that mode of transmission may not be completely linear both density dependent transmission and an intermediate of density and frequency dependent transmission could potentially result in co existence of cwd and deer but the lack of long term empirical data prevents us from validating our findings in studies from both wisconsin and illinois samuel and storm 2016 found that although estimated values for force of infection varied across years and states they report average yearly increases in the force of infection rate of 26 8 6 3 and 2 5 for males females and yearlings respectively this suggests an increase over time in the rates of cwd transmission across the areas for our scenarios force of infection decreased or leveled over time as the numbers of susceptible host were decreasing the discrepancy between our model results and the above mentioned study suggests that more studies are needed to estimate force of infection rates in cwd endemic areas and if possible relate them to population density and prevalence rates to determine transmission patterns of cwd 4 3 deer removal to control cwd in wildlife populations transmission of disease within social groups has often been used as a justification to assume frequency dependent transmission as group composition and number of encounters between or among individuals may be more or less constant despite variations in population size may and anderson 1979 o keefe 2005 however some species may exhibit more flexible group structures with varying group sizes and this pattern is especially seen in white tailed deer male bachelor groups halls 1984 hirth 1977 marchington and hirth 1984 nixon et al 1994 our results showed that reduction of deer group sizes affected prevalence levels in the direct transmission scenarios for both landscapes this reduction of group sizes in the model reduced the transmission potential within groups and thus affected disease transmission between groups as well we explored these scenarios to compare increased hunting pressure or unselective culling which would increase mortality generally to strategies where entire groups are culled which would reduce the number of groups but not group size both selective and non selective culling have been the preferred means of cwd management in free ranging populations uehlinger et al 2016 wasserberg et al 2009 williams and miller 2002 uncertainties about mode of transmission can hinder choosing management strategies for disease eradication uehlinger et al 2016 wasserberg et al 2009 assuming direct transmission culling and reduction of populations could result in population thresholds below which the disease is not able to persist in the population anderson and may 1978 using a multi state computer simulation model wasserberg et al 2009 found that hunted deer populations exhibited lower cwd prevalence than non hunted populations suggesting that population density and turnover affect cwd transmission and that culling may be a suitable strategy for cwd management lower population densities might reduce joint space use and chance of indirect contacts however the potential for re colonization and subsequent reemergence of the disease caused by environmental contaminants poses a challenge to disease management and further research is needed to expand our understanding of environmental prion accumulation as a route of disease transmission 4 4 long term effects of cwd cwd has only recently been discovered in wildlife populations and is of great concern to wildlife managers and public alike the need to understand and predict cwd dynamics is evident and developing models to make predictions and pinpoint areas of interest in cwd research could be of great value gross and miller 2001 developed a mechanistic abm simulating cwd transmission in mule deer populations their model failed to predict long term co existence of disease and deer populations but their model lacked spatial components and assumed fixed contact rates publications of the agent based cwd model developed by belsare et al belsare et al 2020 belsare and stewart 2020 do not investigate long term effect of cwd on deer populations but are focused on surveillance and detection and thus we cannot compare our results to predictions from this model this model however uses fixed contact rate matrices with direct transmission only dld incorporates spatial and temporal stochasticity and imposes no top down assumptions regarding contact rates in this model contact rates both indirect and direct are emergent properties of the movement behavior of agents within the model gross and miller 2001 acknowledge that the limited amount of data from long term surveillance can complicate making long term predictions because of this limitation we chose to run dld for a maximum of 50 years since further predictions would need to be validated by field studies in areas where cwd has been occurring for a prolonged time evidence exists that cwd does affect population dynamics of wild cervids in northern colorado miller et al 2008 found prevalence levels in mule deer ranging from 20 to 40 in a population that had been declining over the last 20 years and this decline coincided with the emergence of cwd in the population edmunds et al 2016 reported an annual decline of 10 4 in white tailed deer populations in cwd positive areas in wyoming where prevalence levels ranged from 28 8 in males to 42 in females also in wyoming devivo et al 2017 found average annual cwd prevalence in mule deer to be 24 coinciding with annual population declines of 21 our model scenario prevalence patterns showed increasing prevalence levels and decreasing deer populations particularly in the fragmented forest scenarios still prevalence and population sizes seemed to reach a relatively stable equilibrium for all scenarios by year 50 suggesting a potential for co existence of cwd and deer however as with any model caution must be taken not to rely too heavily on projected scenarios many aspects of cwd dynamics are still unknown and we strongly support further surveillance of cwd and research into the underlying factors promoting prion transmission more extensive research into infectivity prion decay and environmental pathways is needed to improve on predictive modeling 4 5 model utility dld provides an excellent tool for investigating how different disease transmission pathways and control efforts can affect epizootic dynamics within a population our results indicate that indirect transmission produces dynamics more consistent with density dependent transmission despite posing a greater challenge to disease eradication or control potapov et al 2012 furthermore prevalence levels in the model with indirect transmission were less affected by behavioral differences between the sexes and age groups as well as current population density than with direct transmission however conclusion is tentative as some age and sex specific behaviors e g scraping and other marking behaviors or fighting were not included in the model dld is adaptable to simulate most diseases in deer disease parameters can be altered to fit the disease under investigation and landscapes can be imported to fit the desired habitat of interest dld is still being developed and fine tuned and the current version does not include density dependence in survival and recruitment rates in the model but density dependence could prevent or reduce decreases in population size due to disease gross and miller 2001 density dependence could be incorporated into later versions of dld we also did not include the potential for infected carcasses to stay in the landscape and add to environmental contamination miller et al 2004 williams and miller 2002 nor did we add scraping sites of bucks that may also serve as a potential hot spot for indirect disease transmission alexy et al 2017 furthermore we did not remove home range fidelity at end stages of the disease to simulate behavioral anomalies caused by cwd edmunds et al 2018 miller and wild 2004 williams and miller 2000 these aspects might have an effect on transmission levels and may be incorporated in later versions of dld 5 conclusions dld simulations of chronic wasting disease transmission in white tailed deer showed that landscape structure social behavior and mode of transmission all affected prevalence within deer populations furthermore dld results suggest that cwd transmission may be driven by a mixture of density and frequency dependent processes which can potentially lead to co existence of cwd and deer populations these results emphasize the importance of spatial temporal and behavioral heterogeneity in disease modeling and demonstrate the utility of abms in incorporating spatio temporal variables as well as animal behavior when predicting and modeling disease spread software availability model name deerlandscapedisease dld availability javadocs and entire dld program code have been uploaded to figshare https figshare com articles online resource deerlandscapedisease zip 17430101 language java funding primary funding for this research was provided by the illinois department of natural resources through the federal aid in wildlife restoration project w 87 r with additional support from the siuc graduate school and the cooperative wildlife research laboratory credit authorship contribution statement lene j kjær conceptualization methodology formal analysis writing original draft writing review editing eric m schauber conceptualization methodology formal analysis writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements thanks to dr clayton k nielsen for scientific support as well as logistical and field assistance thanks to p shelton for providing logistical support and to d storm j rohm c anderson and multiple technicians for field assistance special thanks goes to the open science grid organization https opensciencegrid org that facilitated high throughput computing for dld model runs and replicates supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2022 110114 appendix supplementary materials image application 1 image application 2 image application 3 image application 4 
24382,we developed a spatially explicit agent based model abm deerlandscapedisease dld to investigate the effects of landscape structure disease transmission and management alternatives on dynamics of chronic wasting disease cwd in white tailed deer odocoileus virginianus we fitted biased random walk models to data from gps collared deer to simulate movements of individual deer and deer groups in an agricultural landscape with fragmented forest patches and a forest dominated landscape we estimated behavioral and demographic parameters from field data and published literature of deer ecology we considered both direct and indirect transmission routes and assumed that bioavailability of infectious pathogens deposited in the environment decreased exponentially over time we tuned transmission parameters to match observed trajectories of cwd prevalence in wisconsin and assumed that infection probability during an encounter was equal for all age classes thus infection prevalence varied with sex and age specific behavior dld simulations demonstrated significant effects of landscape structure social behavior and transmission mode on temporal changes in prevalence prevalence rose faster and reached higher levels in fragmented forest landscapes due to aggregation of deer within small forest patches furthermore simulation results suggested that cwd might be driven through a mix of frequency and density dependent processes potentially facilitating coexistence of cwd and deer populations these results demonstrate the utility of abms and the importance of including spatial and behavioral heterogeneity when modeling disease transmission keywords agent based modeling spatially explicit white tailed deer empirical based movement chronic wasting disease deer behavior data availability the model code has been uploaded to figshare and a link is provided 1 introduction wildlife epizootics are challenging to predict or control and any hope of doing so requires understanding of the routes and patterns of transmission epizootiological models can inform predictions of disease and impacts and the success of control efforts based on observed or hypothesized transmission patterns classical mathematical models assume that force of infection is dependent on either the proportion of infected hosts frequency dependent transmission or the population density of infected hosts density dependent transmission may and anderson 1979 o keefe 2005 yet many diseases may not fit well within this strict dichotomy in addition the establishment and transmission of disease within a population are both stochastic and intrinsically spatial affected by demography population dispersion and habitat heterogeneity drake 2005 fa et al 2001 gudelj and white 2004 parratt et al 2016 rees et al 2013 an animal may die before it can transmit the disease extinguishing an epizootic before it can begin once the disease is established an infected animal might become spatially isolated or surrounded by other infected animals thus reducing the transmission of disease to susceptible hosts spatially explicit agent based models abms are advantageous because they can reproduce stochastic spatio temporal segregation of infected and uninfected individuals fa et al 2001 gudelj and white 2004 and can incorporate detailed spatio temporal variables individual variations and demographic stochasticity conner et al 2007 rees et al 2013 wilson 1998 most abms on epizootiology only incorporate direct transmission pathways and do not base individual behaviors on empirical movement data e g rabbit viral hemorrhagic disease fa et al 2001 bovine tuberculosis in badgers smith et al 2001 and chronic wasting disease belsare et al 2018 belsare and stewart 2020 several diseases such as bovine tuberculosis and chronic wasting disease cwd may be spread through both direct and indirect contact palmer and whipple 2006 williams et al 2002 furthermore disease transmission is dependent on contact rates that in turn are determined by how animals move within their environment indirect contact and in relation to other animals direct contact previous models on cwd transmission have not incorporated empirical based movement gross and miller 2001 nor indirect transmission of the disease belsare et al 2018 belsare and stewart 2020 but the effect of animal movement on contact rates and thus disease transmission indicates that incorporating realistic movement behaviors into models of disease transmission may be of great importance we developed deerlandscapedisease dld a spatially explicit abm to simulate disease transmission in white tailed deer using published data on cwd and empirical data on deer behavior and movement cwd is the only transmissible spongiform encephalopathy found in free ranging wildlife affecting deer odocoileus hemionus odocoileus virginianus elk cervus canadensis miller et al 2000 saunders et al 2012 williams et al 2002 reindeer rangifer tarandus benestad et al 2016 and moose alces alces baeten et al 2007 colorado division of wildlife 2012 cwd affects the central nervous tissue and is characterized by behavioral changes such as excessive salivation tremors lack of coordination difficulty swallowing and increased drinking and urination followed by loss of body condition and ultimately death miller et al 2000 the prion agent causing cwd has been found in saliva blood urine and feces haley et al 2009a c k mathiason et al 2006 and can remain infective in the environment for years mathiason et al 2009 miller and williams 2003 williams et al 2002 thus both direct and indirect transmission of cwd may occur however little is known about the strength of each infection route and the subsequent long term effect of cwd on population densities within wild animal populations the animal model in dld specifically simulates behavior of white tailed deer thought to influence population dynamics and disease transmission such as movement mating and grouping behavior the disease component in dld allows for pathogen build up in the environment and contacts between individual deer either direct or indirect are modeled as a stochastic process depending on movement of the animals involved we used dld to investigate the following research questions 1 how does landscape composition affect deer behavior and movement and thus cwd transmission 2 how will different transmission pathways direct vs indirect transmission affect long term host disease dynamics frequency vs density dependent transmission and 3 will deer removal aid in controlling cwd in wildlife populations our description of dld follows the odd overview design concepts details protocol grimm et al 2006 2010 2020 detailing methods for modeling individual and group movement within home ranges based on gps collar locations in appendices 2 materials and methods 2 1 programming platform dld was created using the repast simphony platform north et al 2013 2007 2005 and java programming language arnold et al 2005 we chose repast simphony due to its user friendly graphical user interface its ability to incorporate raster files and shape files the versatility of the java programming language and the ability to run from standalone batch files furthermore repast simphony is free and open source 2 2 landscape data the landscapes in dld are based on two study sites in illinois usa fig 1 one is a predominantly forested landscape in southern illinois whereas the east central illinois study site is dominated by agricultural fields and fragmented forest patches table 1 in dld we refer to the southern illinois landscape as the contiguous forest landscape and the east central illinois landscape as the fragmented forest landscape 2 3 model overview dld is a stochastic spatio temporal simulation model that runs with 2 hour time steps the model is agent based and incorporates demographic processes of white tailed deer such as birth and death mating grouping as well as a detailed empirically based movement model dld furthermore includes a disease component simulating the transmission of cwd both directly via animal to animal contact and indirectly as cwd prion build up and decay in the environment 2 4 summary odd a complete detailed model description following the odd protocol grimm et al 2020 2010 2006 is provided in appendix a and a summary odd following the template by grimm et al 2020 follows the overall purpose of dld is to understand the transmission dynamics and long term impacts of cwd in white tailed deer populations we are specifically addressing how landscape structure and transmission mode affect population level cwd dynamics in white tailed deer frequency vs density dependent transmission under realistic movement and social behaviors in addition we aim to assess the effectiveness of alternative culling strategies for disease control to consider our model realistic enough for its purpose we use patterns in mortality reproduction mating age home range grouping and movement the model comprises the following entities individual deer adult females adult males and fawns landscape square grid cells of 25 25 m referred to as pixels time and disease individual deer are characterized by the state variables identity number age sex identity of the home range where the individual lives group membership and disease status individual deer are assigned specific behavioral states that are dependent on season age and sex of the animal each behavioral state is associated with state specific movement and behavior and transitions between states are triggered by events such as dispersing or mating states in the model are normal dispersal mating and exploratory behavior fig 2 as for the spatial and temporal resolution and extent each time step in the model is 2 h and simulations are run for 50 years dld is spatially explicit but landscape structure and habitat types are held constant within the model the most important processes of the model which are repeated every time step are the update of indirect and direct contacts produced by moving deer agents as well as the update of the landscape pixels regarding build up and decay of cwd prions indirect contact furthermore the following deer behaviors and attributes heavily influence the above processes 1 individual movement at each time step as it is dependent on the age sex and behavioral state of the agent whether it is member of a group tending to a fawn female movement only following a female during the mating season male movement only dispersing or conducting exploratory behavior see appendix a and c for details on modeling movement based on empirical data 2 cwd status as direct infectivity rates prion deposition rates and mortality rates due to cwd are modeled as functions of time resulting in infected agents becoming more infectious with time shedding more prions in the environment with time and mortality increasing as the disease progresses see appendix a and b for details as we allow for cwd prions to accumulate in a landscape pixel we added prion decay to simulate an exponential decline over time of prions in a pixel appendix a a decay that is also updated at each time step see appendix a and b for details empirical data on the bioavailability of prions in the environment is not available so we set a half life of 6 months as a starting point see appendix a and b the most important design concepts of the model are the way dld incorporates behavior dependent deer movement based on empirical data from field studies movement sub model appendix a and c and the incorporation of a cwd sub model governing direct and indirect contact rates and cwd prion build up and decay in the landscape pixels these components allow for emergent patterns of disease dynamics based on individual behaviors and movements within dld 2 5 dld scenarios we created 6 different scenarios to investigate the importance of landscape structure mode of transmission and deer removal on disease transmission and host population dynamics we ran direct and indirect transmission scenarios separate for both the fragmented forest landscape and the contiguous forest landscape 4 scenarios we separated the two transmission modes as the contribution of each transmission pathway in nature is unknown and we wanted to assess how different transmission modes can affect long term disease dynamics we explored the efficacy of general e g increased public harvest as opposed to localized culling e g sharpshooting entire groups by reducing maximum group sizes to half of the default values female group size 2 male group size 5 at the same overall population size for default groups sizes see appendix b we only reduced group sizes given direct transmission because we expected the effect of reduced groups to be higher for direct contacts schauber et al 2007 we also ran each landscape without any disease present and thus ended up with 8 scenarios total we ran 500 replicates of each scenario for 50 simulation years including a 5 year burn in period and checked for convergence 2 6 data analysis 2 6 1 cwd prevalence and force of infection we first checked if 500 replicate runs were adequate to reach convergence of the standard deviation for prevalence then we compared temporal patterns of prevalence arcsine square root transformed among scenarios using repeated measures anova omitting year 1 5 to avoid initial transient dynamics we used the same analysis to compare prevalence between males females and fawns within scenarios we also compared prevalence between young 3 years and old 3 years males and females to examine how prevalence changes with age to investigate whether differences between observed prevalence patterns in our model and prevalence found in field studies could be attributed to difficulties in detecting early disease infection we re analyzed our data using only animals infected for at least 6 months infectious prevalence using same methods as above to assess whether transmission patterns that emerged in our model corresponded better to density dependent or frequency dependent concepts we used a power law regression to compare how strongly force of infection ζ proportion of susceptible in year i surviving to year i 1 that became infected during that year was related to the density of infectious infected 6 months animals in year i i density dependence versus infectious prevalence in year i i n frequency dependence 1 ζ e b 0 i b 1 i n b 2 l n ζ b 0 b 1 l n i b 2 l n i n if ζ is linearly density dependent then b1 should 1 and b2 should 0 and vice versa for linear frequency dependence nonlinearity can be handled by exponents different from 1 we only included animals infected 6 months in i and i n because cwd in dld is modeled as having a latent period with animals at an advanced disease stage assumed to be more infectious to account for delays in prion accumulation in the indirect transmission scenarios we also used power law regression to model ζ in year i against i and i n in year i and prior years 2 l a g 1 l n ζ i b 0 b 1 l n i i b 2 l n i n i b 3 l n i i 1 b 4 l n i n i 1 3 l a g 2 l n ζ i b 0 b 1 l n i i b 2 l n i n i b 3 l n i i 1 b 4 l n i n i 1 b 5 l n i i 2 b 6 l n i n i 2 to account for collinearity of i and i n we used standard linear regression to compare the fit of the above models with models involving either i alone or i n alone and calculated the partial r2 for each predictor 4 p a r t i a l r 2 b r 2 a a n d b r 2 a o n l y 1 r 2 a o n l y all analyses were conducted in r 3 5 2 r development core team 2018 and we omitted year 1 to 7 for all power law analyses to avoid initial transient dynamics and account for time lags up to 2 years 2 6 2 sensitivity analysis we conducted a one factor at a time local sensitivity analysis on prion half life by decreasing and increasing it by 2 months half life of 4 and 8 months respectively the half life of prion proteins is largely unknown thus we varied our default half life of 6 months by 33 33 to assess how different magnitudes of this parameter would impact prevalence the analysis was carried out for indirect scenarios and run for 50 years with the same initial parameters as the original runs during the transmission coefficient calibration process to fit our prevalence patterns to observed prevalence patterns in wisconsin see appendix a we observed a very high sensitivity of the model to this parameter both for the direct and indirect scenarios thus we did not conduct sensitivity analysis on this parameter 3 results 3 1 dld simulation runs convergence of prevalence standard deviations was reached with 500 replicates of each scenario appendix d fig d1 indicating that 500 replicates were enough to distinguish between scenarios and to perform statistical hypotheses testing on the simulation results all repeated measures analyses of total infection prevalence and infectious prevalence proportion infected 6 months indicated significant scenario time all f 220 134 730 100 p 0 0001 and age sex category time interactions all f 176 673 650 10 p 0 0001 3 1 1 landscape effects and transmission mode without the disease component populations grew at an average rate of ca 3 per year and population sizes after 50 years averaged ca 4500 animals for both landscapes not depicted adding the disease component to the model caused population decline in all of the fragmented forest scenarios where effective population densities were higher because less of the landscape was suitable for home ranges the direct transmission runs showed an average peak population decline average of peak declines of all replicates omitting year 1 5 of 11 3 with an average population size of ca 502 in year 50 of the simulation run fig 3 a in the indirect transmission scenario the average peak population decline was 11 3 with an average population size of ca 546 in year 50 for the contiguous forest landscape populations also decreased in the direct transmission scenarios with default group sizes with an average peak decline of 7 8 and a population size of ca 884 in year 50 of the simulation runs for the continuous indirect transmission scenario the average peak decline was 7 3 with an average population size of ca 1061 in year 50 of the simulation runs fig 3a for both direct and indirect transmission cwd prevalence reached higher values and peaked earlier in the fragmented forest landscape where the deer population was compressed into less space than the contiguous forest landscape fig 3b in both landscapes direct transmission resulted in higher prevalence than did indirect transmission with direct transmission prevalence was higher in males whereas prevalence values in fawns females and old females were similar fig 4 when only including animals infected longer than 6 months the difference between age and sex groups in the direct scenarios was mainly due to higher prevalence in males and lower prevalence in fawns fig 5 prevalence in old males was higher than in young males for the direct scenarios for the indirect scenarios the differences in prevalence levels were mainly due to lower prevalence in fawns fig 4 and fig 5 3 1 2 deer removal population size for the direct fragmented forest scenario with reduced group size showed an average peak decline of 9 9 and ended with an average size of ca 631 in year 50 fig 3a the contiguous forest scenarios generally increased in population size but had an average peak decline of 6 5 and an average population size of ca 1255 in year 50 fig 3a reducing group sizes produced lower prevalence and later epizootic peaks than with default group sizes for both the fragmented and contiguous forest scenarios fig 3b as with default group size we found that cwd prevalence was higher in males with similar prevalence for fawns and females for both the fragmented and contiguous forest scenarios fig 4 when looking at animals infected longer than 6 months we found higher prevalence in males and lower prevalence in fawns fig 5 3 1 3 force of infection and host disease dynamics force of infection ζ showed similar relationships with the density of infectious individuals i those infected 6 months and infectious prevalence i n across the different scenarios fig 6 the density and frequency of infected animals i and i n respectively tracked similar trajectories over time fig 6 making it difficult to determine which was the stronger driver of changes in force of infection however power law regression of output with direct transmission lent more support for frequency dependent than density dependent transmission tables 2 4 whether comparing the relative sizes of the coefficients representing density dependence and frequency dependence table 2 the percentage of runs where each coefficient was statistically significant table 3 or their partial r2 values table 4 frequency dependence received about twice the support or more than density dependence across scenarios with direct transmission in contrast results from indirect transmission scenarios yielded balanced support for density and frequency dependent transmission in the contiguous landscape and greater support for density dependence in the fragmented landscape tables 2 4 output from simulations with indirect transmission yielded little evidence for lagged effects of i or i n on ζ tables 2 4 adding lagged predictors did not substantially improve r2 table 4 and resulted in unstable coefficient estimates table 2 that achieved statistical significance in less than 11 of replicate runs table 3 3 2 prion half life sensitivity analysis performed on prion half life showed that disease prevalence was highly sensitive to this parameter compared to the original 6 month half life a shorter half life of 4 months resulted in lower prevalence for both the contiguous and fragmented forest scenarios where at the prevalence peak prevalence for both scenarios were almost half of the prevalence produced by a 6 month half life appendix d fig d2 this resulted in a higher deer population size than in the original scenarios with a still increasing population for the contiguous forest landscape appendix d fig d3 a half life of 8 months resulted in almost a doubling of the prevalence at the prevalence peak for both the contiguous and fragmented forest scenarios compared to scenarios with a 6 month half life appendix d fig d2 population size for these scenarios were much lower than for the original scenarios with a much earlier decrease in deer numbers appendix d fig d3 4 discussion we developed an agent based spatially explicit model on cwd transmission in white tailed deer to investigate how landscape and transmission mode may affect overall and sex specific cwd prevalence and subsequently host disease dynamics we simulated culling by reducing group sizes to investigate whether deer removal could aid in controlling cwd in white tailed deer we furthermore used force of infection to assess whether the emerging transmission patterns corresponded better to density dependent or frequency dependent concepts 4 1 landscape effects on cwd transmission cwd transmission and mortality were sufficient to cause deer population declines in both contiguous and fragmented landscapes but disease spread more rapidly and produced earlier and more severe population impact in the fragmented landscape these population impacts can be explained by differences in effective population density between the two landscapes white tailed deer need a component of forest cover within their home range marchington and hirth 1984 concentrating and increasing the local density of deer in landscapes with small forest patches and thus the potential for both direct and indirect contacts farnsworth et al 2005 found that destruction of suitable habitat due to development might cause a concentration of mule deer o hemionus in suitable fragmented patches increasing local population density and thus accelerating transmission of cwd storm et al 2013 found cwd incidence in wisconsin to be positively related to forest edge density length of edge relative to the total area analyzed and in canada norbert et al 2016 found high cwd risk in high deer density riparian forest patches surrounded by agriculture as simulated population sizes decreased in dld prevalence in the fragmented forest landscape still increased for multiple years when transmission was both direct and indirect until the host disease system somewhat approached a stable equilibrium by the end of the simulations this could be due to landscape configuration where deer in the fragmented scenario would be aggregated in forest patches with local densities being still high enough to drive prevalence until a certain threshold a different pattern is found in the contiguous forest scenarios where direct transmission scenarios show a more concomitant relationship between population size and prevalence these results highlight that cwd control efforts may need to be both more intensive due to enhanced transmission and more spatially extensive to be effective in landscapes where deer habitat is highly fragmented such as in much of the midwest and great plains urbanization and agricultural expansion are continuously causing forest fragmentation in the us and elsewhere fynn and campbell 2018 high effective density of deer within small strips and patches of forest cover combined with the greater dispersal tendency and distance of white tailed deer in open landscapes kelly et al 2014 long et al 2005 lutz et al 2015 nixon et al 2007 amplify the challenge in illinois where cwd is found within agriculture dominated areas in the northern tier of the state efforts to control cwd have arguably been successful in slowing the rise in prevalence manjerovic et al 2014 mateus pinilla et al 2013 but continual geographic spread is straining capacity when cwd is first detected in a fragmented landscape there may be a unique opportunity to locally suppress or even eradicate the disease but only with intensive effort around the area of initial discovery varga et al 2021 4 2 transmission mode of cwd and host disease dynamics 4 2 1 direct and indirect transmission cwd can be transmitted through both direct animal contact and environmental sources haley et al 2009a mathiason et al 2009 c k 2006 miller and williams 2003 williams and miller 2003 but the strength of each pathway and how much they each contribute to the transmission and persistence of cwd in free living populations are unknown we chose to separate the different modes of transmission in our model runs to investigate possible effects on model outcome the difference in prevalence could be due to direct transmission being more stochastic as contacts are very time dependent and there is a higher chance of disease extinction due to death of diseased animals indirect transmission can continue even after the death of the diseased individual due to accumulation of prions in the environment thus disease transmission is more reliably dependent on duration of exposure schauber et al 2007 2015 found that indirect contact rates among female deer were much less strongly influenced by social group membership than were direct contact rates with indirect contacts being driven mainly by the amount of shared space transmission mode greatly affected age and sex specific prevalence patterns for the direct transmission scenarios the observed patterns roughly reflected those seen in wild deer populations impacted by cwd the higher prevalence in male deer especially older males is also observed in empirical studies of cwd potentially due to differences in behavior or physiology farnsworth et al 2005 grear et al 2006 miller and conner 2005 osnas et al 2009 samuel and storm 2016 in our model males are part of larger groups and move around more than females leaving and joining new groups furthermore we model males to follow females around during the rut which could potentially add to infection exposure infection prevalence was very similar in fawns and adult females when we included all infected animals in empirical studies however observed cwd prevalence is generally lower in fawns than adults grear et al 2006 wisconsin department of natural resources 2012 this discrepancy could be explained by difficulties in detecting early stage infection with standard diagnostic tests haley et al 2009b mathiason et al 2009 our results when including only animals infected longer than 6 months mirror the lower apparent prevalence in fawns compared to all other age classes although indirect transmission is dependent on how animals move and overlap in habitat and space use it does not require simultaneous space use which could explain similar prevalence across adult sex and age classes in the indirect scenarios the observed lower prevalence in fawns could be explained by transmission not being a result of contact between individuals but being a question of time of exposure to the pathogen fawns would have had less time to be exposed to prions in the environment these results suggest that the age and sex specific differences in cwd prevalence observed in wild deer populations may mostly be driven by direct transmission given no evidence of increased genetic cwd susceptibility in males rogers et al 2022 as they could be a result of differences in behavior the higher prevalence in males along with greater male mobility hawkins et al 1971 nixon et al 2007 1994 rosenberry et al 1999 could lead managers to conclude that cwd control may be better applied focusing on males however with indirect transmission or if transmission is primarily from females to males this form of male focused culling may only work in areas where cwd has not yet been established recent simulation models on harvest based cwd management have suggested that higher disease prevalence in males may not necessarily indicate that male deer are more responsible for disease transmission only that they may experience higher exposure or susceptibility rogers et al 2022 these models showed that for management interventions to be efficient in limiting cwd epidemics harvest of both male and female deer is required rogers et al 2022 emphasizing how sex selective harvest based on prevalence alone might be misleading 4 2 2 host disease dynamics density or frequency dependent transmission of cwd the force of infection measures the rate of disease spread within a population and our results varied between landscapes and transmission modes within a landscape direct transmission seemed to produce a higher force of infection than indirect transmission except when group sizes were reduced force of infection was better predicted by infectious prevalence than density of infected animals infected 6 months in the direct transmission scenarios whereas the pattern was unclear or leaned toward density dependence for the indirect transmission scenarios these statistical results are in contrast to the overall epizootic dynamics that are strongly consistent with density dependent transmission namely the fact that the cwd epizootic peaked earlier and at higher prevalence in the fragmented forested landscape scenarios where local population density was greater than in the contiguous landscape overall these findings suggest that disease transmission of cwd may be dependent on the combination of transmission mode and landscape structure also the true nature of cwd transmission whether through direct or indirect contacts may be intermediate between density and frequency dependent transmission but unlikely to destabilize host populations in a cwd study from wisconsin storm et al 2013 found that models with intermediate transmission modes performed better than strictly density or frequency dependent transmission models when predicting incidence rates in harvested yearling deer also suggesting that mode of transmission may not be completely linear both density dependent transmission and an intermediate of density and frequency dependent transmission could potentially result in co existence of cwd and deer but the lack of long term empirical data prevents us from validating our findings in studies from both wisconsin and illinois samuel and storm 2016 found that although estimated values for force of infection varied across years and states they report average yearly increases in the force of infection rate of 26 8 6 3 and 2 5 for males females and yearlings respectively this suggests an increase over time in the rates of cwd transmission across the areas for our scenarios force of infection decreased or leveled over time as the numbers of susceptible host were decreasing the discrepancy between our model results and the above mentioned study suggests that more studies are needed to estimate force of infection rates in cwd endemic areas and if possible relate them to population density and prevalence rates to determine transmission patterns of cwd 4 3 deer removal to control cwd in wildlife populations transmission of disease within social groups has often been used as a justification to assume frequency dependent transmission as group composition and number of encounters between or among individuals may be more or less constant despite variations in population size may and anderson 1979 o keefe 2005 however some species may exhibit more flexible group structures with varying group sizes and this pattern is especially seen in white tailed deer male bachelor groups halls 1984 hirth 1977 marchington and hirth 1984 nixon et al 1994 our results showed that reduction of deer group sizes affected prevalence levels in the direct transmission scenarios for both landscapes this reduction of group sizes in the model reduced the transmission potential within groups and thus affected disease transmission between groups as well we explored these scenarios to compare increased hunting pressure or unselective culling which would increase mortality generally to strategies where entire groups are culled which would reduce the number of groups but not group size both selective and non selective culling have been the preferred means of cwd management in free ranging populations uehlinger et al 2016 wasserberg et al 2009 williams and miller 2002 uncertainties about mode of transmission can hinder choosing management strategies for disease eradication uehlinger et al 2016 wasserberg et al 2009 assuming direct transmission culling and reduction of populations could result in population thresholds below which the disease is not able to persist in the population anderson and may 1978 using a multi state computer simulation model wasserberg et al 2009 found that hunted deer populations exhibited lower cwd prevalence than non hunted populations suggesting that population density and turnover affect cwd transmission and that culling may be a suitable strategy for cwd management lower population densities might reduce joint space use and chance of indirect contacts however the potential for re colonization and subsequent reemergence of the disease caused by environmental contaminants poses a challenge to disease management and further research is needed to expand our understanding of environmental prion accumulation as a route of disease transmission 4 4 long term effects of cwd cwd has only recently been discovered in wildlife populations and is of great concern to wildlife managers and public alike the need to understand and predict cwd dynamics is evident and developing models to make predictions and pinpoint areas of interest in cwd research could be of great value gross and miller 2001 developed a mechanistic abm simulating cwd transmission in mule deer populations their model failed to predict long term co existence of disease and deer populations but their model lacked spatial components and assumed fixed contact rates publications of the agent based cwd model developed by belsare et al belsare et al 2020 belsare and stewart 2020 do not investigate long term effect of cwd on deer populations but are focused on surveillance and detection and thus we cannot compare our results to predictions from this model this model however uses fixed contact rate matrices with direct transmission only dld incorporates spatial and temporal stochasticity and imposes no top down assumptions regarding contact rates in this model contact rates both indirect and direct are emergent properties of the movement behavior of agents within the model gross and miller 2001 acknowledge that the limited amount of data from long term surveillance can complicate making long term predictions because of this limitation we chose to run dld for a maximum of 50 years since further predictions would need to be validated by field studies in areas where cwd has been occurring for a prolonged time evidence exists that cwd does affect population dynamics of wild cervids in northern colorado miller et al 2008 found prevalence levels in mule deer ranging from 20 to 40 in a population that had been declining over the last 20 years and this decline coincided with the emergence of cwd in the population edmunds et al 2016 reported an annual decline of 10 4 in white tailed deer populations in cwd positive areas in wyoming where prevalence levels ranged from 28 8 in males to 42 in females also in wyoming devivo et al 2017 found average annual cwd prevalence in mule deer to be 24 coinciding with annual population declines of 21 our model scenario prevalence patterns showed increasing prevalence levels and decreasing deer populations particularly in the fragmented forest scenarios still prevalence and population sizes seemed to reach a relatively stable equilibrium for all scenarios by year 50 suggesting a potential for co existence of cwd and deer however as with any model caution must be taken not to rely too heavily on projected scenarios many aspects of cwd dynamics are still unknown and we strongly support further surveillance of cwd and research into the underlying factors promoting prion transmission more extensive research into infectivity prion decay and environmental pathways is needed to improve on predictive modeling 4 5 model utility dld provides an excellent tool for investigating how different disease transmission pathways and control efforts can affect epizootic dynamics within a population our results indicate that indirect transmission produces dynamics more consistent with density dependent transmission despite posing a greater challenge to disease eradication or control potapov et al 2012 furthermore prevalence levels in the model with indirect transmission were less affected by behavioral differences between the sexes and age groups as well as current population density than with direct transmission however conclusion is tentative as some age and sex specific behaviors e g scraping and other marking behaviors or fighting were not included in the model dld is adaptable to simulate most diseases in deer disease parameters can be altered to fit the disease under investigation and landscapes can be imported to fit the desired habitat of interest dld is still being developed and fine tuned and the current version does not include density dependence in survival and recruitment rates in the model but density dependence could prevent or reduce decreases in population size due to disease gross and miller 2001 density dependence could be incorporated into later versions of dld we also did not include the potential for infected carcasses to stay in the landscape and add to environmental contamination miller et al 2004 williams and miller 2002 nor did we add scraping sites of bucks that may also serve as a potential hot spot for indirect disease transmission alexy et al 2017 furthermore we did not remove home range fidelity at end stages of the disease to simulate behavioral anomalies caused by cwd edmunds et al 2018 miller and wild 2004 williams and miller 2000 these aspects might have an effect on transmission levels and may be incorporated in later versions of dld 5 conclusions dld simulations of chronic wasting disease transmission in white tailed deer showed that landscape structure social behavior and mode of transmission all affected prevalence within deer populations furthermore dld results suggest that cwd transmission may be driven by a mixture of density and frequency dependent processes which can potentially lead to co existence of cwd and deer populations these results emphasize the importance of spatial temporal and behavioral heterogeneity in disease modeling and demonstrate the utility of abms in incorporating spatio temporal variables as well as animal behavior when predicting and modeling disease spread software availability model name deerlandscapedisease dld availability javadocs and entire dld program code have been uploaded to figshare https figshare com articles online resource deerlandscapedisease zip 17430101 language java funding primary funding for this research was provided by the illinois department of natural resources through the federal aid in wildlife restoration project w 87 r with additional support from the siuc graduate school and the cooperative wildlife research laboratory credit authorship contribution statement lene j kjær conceptualization methodology formal analysis writing original draft writing review editing eric m schauber conceptualization methodology formal analysis writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements thanks to dr clayton k nielsen for scientific support as well as logistical and field assistance thanks to p shelton for providing logistical support and to d storm j rohm c anderson and multiple technicians for field assistance special thanks goes to the open science grid organization https opensciencegrid org that facilitated high throughput computing for dld model runs and replicates supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2022 110114 appendix supplementary materials image application 1 image application 2 image application 3 image application 4 
24383,describing and understanding species distributions and the factors driving them is fundamental to ecology and biogeography species distribution models sdms allow one to investigate objectives of identifying ecologically important factors to the distribution estimating species environment responses predicting the probability of species occurrence and predicting species presence or absence mosquito occurrence records used in sdms are often imprecise and represented as a centroid of a geopolitical administrative boundary using a virtual species we investigated the effect of centroids on sdms and determined which methodology was best suited to provide accurate and applicable conclusions for each of the objectives we compared 12 distinct algorithms four levels of pseudo absences and three predictor sets to determine the optimal sdm methodology for each objective the ability of methodology considerations to account for the effects of centroids varied for each objective ecologically important predictors were misidentified but could be best approximated by generalized additive models with 10 000 pseudo absences response curves only captured the expected positive or negative trends centroids limited sdms ability to differentiate expected probabilities resulting in overprediction of high probability areas response curves and occurrence probabilities were best estimated by generalized boosting regression models species presence was largely over estimated within southern regions but underpredicted in northern regions and was best estimated by weighted mean ensembles overall generalized boosting regression methods and weighted mean ensembles provided the most reliable conclusions across all four objectives further the most reliable conclusions were consistently observed with equal pseudo absences when considered with the removal of low contributing predictors except for predictor identification keywords aedes centroid ecological niche modelling imprecise response scale species distribution modelling data availability data will be made available on request 1 introduction species distribution models sdms also known as ecological niche models are powerful tools to correlate the occurrence of a species with environmental predictors to explain and or predict a distribution guisan and zimmermann 2000 explanations of distributions include testing hypotheses related to identifying ecologically important conditions which determine the distribution bradie and leung 2017 and or estimating species environment response curves e g ikegami and jenkins 2018 meanwhile sdms predict the probability of occurrence e g jarnevich and reynolds 2011 and or the expected presence or absence of a species e g johnson et al 2017 in geographic and temporal space the ability of sdms to explain and or predict a distribution depends on but not limited to the algorithm number and quality of response and predictor variables considered wisz et al 2008 synes and osborne 2011 heikkinen et al 2012 previous comparisons have indicated that different algorithms are better suited for other objectives and input data heikkinen et al 2012 aguirre gutiérrez et al 2013 the response variable consists of presences absences abundance or species richness of target species or subjects elith et al 2006 wisz et al 2008 absence records are rarely available or reliable with pseudo absences applied instead barbet massin et al 2012 pseudo absences represent a location where the species has not been observed whether sampled or not and is presumed to be absent without a validating absence record grimmett et al 2020 predictors reflect the abiotic or biotic conditions for which responses are considered guisan and zimmermann 2000 though only predictors with solid evidence indicating a causal relationship with the species distribution should be considered when possible and generally higher number of response variables is recommended austin 2002 wisz et al 2008 but see boria and blois 2018 scale is one of the qualities of response and predictor variables that affects sdm performance lechner et al 2012 lecours et al 2015 depending on the context scale relates to the spatial relationship at which a species interacts with the environmental influences i e dispersal range jackson and fahrig 2015 the spatial characteristics of the occurrence records i e sampling unit area of observation positional accuracy or predictors i e cell size grain resolution or the spatial and temporal accuracy applied to the sdm to analyze the distribution lecours et al 2015 for this paper we use scale to describe the level of spatial detail for each form of data failure to explicitly consider the scale can limit sdms ability to provide reliable conclusions which are applicable and accurate to aid management actions are directly affected moudrý et al 2019 the applied scale must satisfy sdms assumptions of i the occurrence records contain no error and ii the provided environmental predictors are representative of the physiological tolerances or resource requirements of the species niche austin 2002 osborne and leitão 2009 however response quality and predictor variable availability limit the choice of scale specifically irregular lattice occurrence records i e administrative regions centroids with high geographic uncertainty cheng et al 2021 connor et al 2018 response quality limits the geographic precision while predictor scale limits the level of environmental and temporal detail available connor et al 2018 lawler et al 2006 previous investigations suggested that half or more of repository occurrence records i e presence absence within the united states and select species in europe are geographically inaccurate and represent centroids of administrative geopolitical boundaries hereafter centroids collins et al 2017 park and davis 2017 cheng et al 2021 consideration of centroids in sdms alters variable contribution assessment interpretation of responses and an overall decrease in predictive ability johnson and gillingham 2008 osborne and leitão 2009 naimi et al 2011 many methodological approaches have been suggested but cannot entirely correct the imprecision of centroids e g araújo and new 2007 pacifici et al 2019 considering the mean predictor value within each boundary may limit the effect of centroids park and davis 2017 however aggregation causes a loss of fine scale variation which may be an important determinant of species distributions therefore is not practical for large boundaries collins et al 2017 cheng et al 2021 additionally aggregation increases potential artifact effects through the modifiable areal unit problem maup openshaw 1984 maup is a source of statistical bias where correlations can vary from positive to negative depending on the aggregation scale i e county state goodchild 2011 accordingly the resulting aggregated scale satisfies assumption i but potentially violates ii through obscuring fine scale variation and maup effects pearson and dawson 2003 moudrý and šímová 2012 manzoor et al 2018 further sdms calibrated with centroids are often misleading nelson 2001 lecours et al 2015 sdm applications are limited owing to the abundance of centroids for some species and geographic regions to produce sophisticated sdms duputié et al 2014 reliable sdms conclusions can only be established if the applied scale captures important environmental characteristics of the species distribution vergara et al 2016 issues related to centroids remain impossible to solve without accurate occurrence data josselin and louvet 2019 regardless the application of centroids is common practice in sdms of epidemiologically relevant species in north america e g escobar et al 2013 johnson et al 2017 for example occurrence records of the arbovirus vector mosquitoes aedes aegypti and aedes albopictus are predominately available as county centroids within the u s hahn et al 2017 a aegeypti and a albopictus can transmit over 20 pathogens including zika chikungunya dengue and yellow fever viruses leta et al 2018 aided by human mediated dispersal and high eco plasticity both species have rapidly expanded their range in recent years causing increased introduction and incidence of pathogens within novel regions weaver 2014 ibañez justicia 2020 johnson et al 2017 predicted the distribution of a aegpyti and a albopictus within the contiguous u s from county centroids they indicated the unlikely occurrence of both species within wayne county mi johnson et al 2017 however both species were recorded across the border in the windsor essex region of south western ontario canada from 2017 to 2019 giordano et al 2019 with a albopictus continuing to be present through june 2021 windsor essex health unit 2021 therefore concern exists that sdms trained with centroids may not provide reliable conclusions there is increasing awareness that sdms must be tested and designed for the desired objective using available data aguirre gutiérrez et al 2013 guillera arroita et al 2015 araújo et al 2019 the effect of centroids on different sdm algorithms quantity of response and predictor variables is unknown previous investigations of sdms calibrated with centroids are limited to the probability of occurrence predictions by maximum entropy maxent collins et al 2017 park and davis 2017 cheng et al 2021 given the availability of multiple algorithms it is therefore vital to assess the effect of administrative centroids on different algorithms to achieve common sdm objectives common sdm objectives include identifying ecologically important predictors estimating species environment response curves predicting the probability of occurrence and classifying presence absence maps aguirre gutiérrez et al 2013 araújo et al 2019 here we provide an in depth analysis of sdms ability to achieve these common objectives for epidemiologically relevant species of mosquitoes based on centroid occurrences of a virtual species in north america to simulate reality we created a virtual species to resemble epidemiologically relevant species with known administrative region centroid occurrences a aegypti and a albopictus we focus on assessing sdm s ability to explain a species niche by identifying the correct ecologically important predictors and estimating appropriate species environment responses additionally we determine the ability of sdms to predict the probability of occurrence and binary presence absence maps from centroids lastly we investigated which sdm methodology is best suited to interpret centroids across all described objectives this work will guide the use of centroids in sdms to improve the reliability of conclusions for public health applications 2 methods we constructed a realistic virtual species to simulate real world application of centroids with the environmental suitability traits based on a aegypti and a albopictus environmental suitability of both species has been primarily related to temperature for development and survival brady et al 2013 eisen et al 2014 additionally both species are container breeding species that rely on precipitation for suitable reproduction conditions in natural or human made containers i e tires flower plots gama and islamiyah 2013 dhimal et al 2015 a albopictus has successfully established in more northern areas attributed to its ability to diapause and survive cold winters denlinger and armbruster 2014 a aegypti has only demonstrated diapause in some populations lima et al 2016 both species occur beyond environmentally suitable areas by employing micro niches as refugia when the macro climate is unsuitable hayden et al 2010 murdock et al 2017 a aegypti is mainly found in urban areas and has an anthropophilic feeding habit a albopictus inhabits urban peri urban rural or forested habitats and is an opportunistic feeder yang et al 2021 when species distributions overlap a albopictus is a superior larval competitor and a albopictus males will cross mate with a aegypti females causing reproductive losses braks et al 2004 lounibos et al 2016 2 1 predictor variables based on the literature we considered predictors that have direct and indirect effects on a albopictus and a aegypti including climate topography land cover and use vegetation indices and socioeconomic predictors larson et al 2010 mughini gras et al 2014 alahmed et al 2015 we calculated the aggregate means of each predictor to represent mean administrative boundary predictor values with zonal statistics in arcgis 10 6 esri 2008 boundary land cover and use categories were represented by the mean percent land cover and use per category within a boundary we assessed multi collinearity using pearson s correlation matrix followed by the variance inflation factor vif leroy et al 2016 naimi et al 2014 multi collinearity was evaluated at the original 1 km2 and aggregated scale to address all potential collinearity we excluded highly correlated variables r 0 7 vif 10 to prevent analysis errors dormann et al 2013 we manually selected a single predictor from each highly correlated group table 1 s1 we calculated some predictors before aggregation growing degree days gdd represented the magnitude of mean monthly temperatures above a baseline temperature of 5 c below which development or survival cannot occur mcmaster and wilhelm 1997 we calculated the selected bioclimatic variables annual mean temperature bio1 mean diurnal temperature bio2 precipitation of the wettest month bio13 and precipitation of the driest month bio14 and gdd from daymet version 4 monthly climate summaries thornton et al 1997 2017 in dismo and envirem r packages respectively hijmans et al 2017 bemmels 2018 additionally we estimated human population density from the most recent census data for each administrative boundary as a proxy for rural and urban areas as well as anthropophilic nature of a aegpyti national institute of statistics and geography 2018 statistics canada 2018 u s census bureau 2017 yang et al 2021 we applied the normalized difference vegetation index ndvi to quantify vegetation greenness and provide an understanding of vegetation density pettorelli et al 2005 we restricted the geographic extent to north america with administrative regions represented by canadian health regions u s counties and mexican states resulting in a mean scale of 6424 km2 table s2 2 2 virtual species design we designed a virtual species through the virtualspecies r package leroy et al 2016 we designed the habitat suitability to reflect common characteristics of a aegypti and a albopictus based on annual mean temperature precipitation of the wettest month and elevation at the most detailed available scale of 1 km2 this scale was appropriate as both species have mean flight ranges of 1 km verdonschot and besse lototskaya 2014 however this scale would not reflect appropriate micro niches or refugia annual mean temperature related to survival and development reinhold et al 2018 precipitation of the wettest month indicated the availability and quality of oviposition sites for reproduction becker et al 2010 lower elevation related to increased human disturbance creating more breeding habitats through artificial water holding containers gama and islamiyah 2013 dhimal et al 2015 accordingly we determined the virtual species habitat suitability from defined responses of each predictor within north america fig 1a we modeled the virtual species habitat suitability by a multiplicative suitability index of annual mean temperature precipitation of the wettest month and elevation as β function logistic and linear responses respectively fig 1a c supplementary methods a β function pattern allowed for specific upper and lower thresholds with different slopes representing temperature thresholds for survival and development cunze et al 2016 koch et al 2016 the logistic function represented a gradual increase in suitability to a maximum asymptote reflecting the availability of oviposition sites as precipitation increased alaniz et al 2017 we expressed elevation as a piecewise linear decrease representing lower host population and pooling water availability at higher elevations alaniz et al 2017 santos and meneses 2017 we interpreted habitat suitability as the probability of occurrence for comparison of sdms the final probability map was visually examined to ensure similarity to published predictions of a aegypti and a albopictus for ecological realism fig 1b 2 3 modeling building to train sdms we created a geographically structured response by converting the suitability index into presence absence records fig 1b c we randomly generated 3500 unique 1 km spatially thinned and corrected by suitability presence only records within the contiguous u s and mexico these records were then converted into centroids such that all occurrences within a boundary were represented by one centroid resulting in 1414 centroids to assess sdm methodology for centroid occurrences we investigated common model building choices of the algorithm the number of pseudo absences generated and predictor variable selection fig 1d e these choices represent how the species environment relationship is interpreted characterized and assessed and predicted against elith et al 2006 wisz et al 2008 aguirre gutiérrez et al 2013 2 3 1 algorithms we applied twelve different distinct algorithms in either their original software denoted by o or as part of ensemble sdm software biomod2 thuiller et al 2020 denoted by b table 2 the software or platform applied potentially impacts sdm performance as each has its unique features and considerations aguirre gutiérrez et al 2013 guillera arroita et al 2015 the ensemble sdm framework provided by biomod2 is the most widely used within the sdm literature hao et al 2019 however the black box nature of the biomod2 framework results in only rough model calibrations it inflates model evaluations by rescaling predictions by a binomial generalized linear model thuiller et al 2009 not present in the original software thus a comparison of original and biomod2 methods assesses the consideration of software selection on model reliability we constructed the original regression and random forest models using additive formulas also we calibrated the original generalized linear models with first and second order polynomial variables of all predictors to reflect corresponding biomod2 formulas otherwise all algorithms were run with default settings for simplicity and comparison table s3 for descriptions of each algorithm see elith et al 2006 araújo and new 2007 reiss et al 2011 and fitzpatrick et al 2013 2 3 2 pseudo absences we considered pseudo absences for model training to simulate common practice instead of known absence pseudo absences must be derived from areas accessible to the species barve et al 2011 a aegypti and a albopictus are primarily distributed by human activity eritja et al 2017 thus all administrative boundaries were considered accessible accordingly we generated 100 000 pseudo absences at least 1 km apart within the 1761 boundaries without a centroid occurrence in the contiguous u s and mexico we considered pseudo absence numbers equal double or triple the number of centroids 1 1 1 2 1 3 respectively e g tiffin et al 2019 or a total of 10 000 we determined 100 unique training sets per pseudo absence level consisting of all centroid occurrences and a random subset without replacement of all pseudo absences to ensure consistent training fig 1d 2 3 3 predictor selection we considered predictor selection by a priori automated and expert selection a priori represented all predictors with suspected direct indirect or resource effects e g low et al 2021 alternatively ecologically important predictors are estimated from a priori by the percent reduction in model fit when each predictor is randomly permuted hereafter automated harisena et al 2021 to demonstrate each predictor selection we first trained sdms with all predictors to represent a priori table 1 for each a priori training set we calculated predictor importance per algorithm and pseudo absence level predictor importance was assessed by randomizing a single predictor variable position then making a new prediction with the new randomized predictor variables predictor importance reflects the difference between pearson s correlation of the original and randomized predictors prediction from one thuiller et al 2020 we repeated this process 1500 times per predictor to allow for adequate convergence predictor importance was determined by functions in biomod2 or equivalent functions in caret r packages for original algorithms kuhn 2020 liaw et al 2019 thuiller et al 2020 we converted the predictor contribution measures to percent contribution such that all values for a single repetition summed to one automated predictors represented predictors with greater than 5 mean contribution across all training sets per algorithm and pseudo absence level we demonstrated expert predictors by considering only the driving predictors of annual mean temperature precipitation of the wettest month and elevation fig 1e therefore we generated and compared 30 000 sdms 25 algorithms x 4 pseudo absence levels x 3 predictor selections x 100 training sets we trained sdms with an 80 random subset of training sets algorithms included in ensembles achieved a sensitivity of 95 see model evaluation of omitted training presence records 2 4 model evaluation we evaluated centroid explanation ability by identifying expected important predictors and response curve estimation fig 1f g we evaluated predictive ability by the accuracy of the predicted probability of occurrence and binary discrimination fig 1h i each algorithm provided a different range of probabilities for interpretation consequently we normalized all predictions before evaluation details of all evaluations are available in supplementary methods 2 4 1 identification of ecologically important predictors the jaccard index j quantified the ability to identify ecologically important predictors fig 1f j is a measure of similarity between two datasets j ranges from zero to one such that one and zero indicate identical and no similarities respectively jaccard 1908 we determined j between automated and expert predictors for each training set and sdm we determined how many of the three predictors used to create the virtual species were selected during automated selection and divided by the total number of unique automated and expert predictors e g inman et al 2021 fig 1f 2 4 2 response curve estimation we calculated response curves for each predictor used to create the virtual species by extracting the predicted probability and corresponding aggregated predictor values we smoothed the resulting responses by generalized additive smoothing to ensure a single probability per environmental value expected responses were calculated for each environmental value and compared by root mean square error rmse and spearman s correlation ρ fig 1 g rmse provided a measure of variation between the expected and estimated response values larger rmse values indicated a greater error in estimated responses ρ indicated if the estimated response curve determined the appropriate pattern relative to the expected one ρ ranged from 1 to 1 with negative values indicating negative correlation zero no association and positive values indicating a positive correlation 2 4 3 probability of occurrence we evaluated the predicted probability of occurrences by a full diagnostic verification by calibration bias skill accuracy refinement and resolution of training and testing regions murphy and winkler 1992 calibration described the degree to which relative suitability of a presence correlated with predicted probability bias indicated the degree to which the predicted probability differed from the known probability of occurrence skill measured the accuracy of the predicted probability relative to an expected binary prediction forecast accuracy reflected the overall degree to which binned predicted probability corresponded to the expected binned probability of occurrence refinement indicated the mean square difference of binned predicted and expected probability values resolution described the ability of sdms could separate different probabilities relative to expected separation murphy and winkler 1992 training evaluations represented comparisons of the predicted and expected probability of occurrence within the contiguous u s and mexico and testing evaluation was within canada and alaska unless otherwise stated we assessed calibration by the continuous boyce index cbi in the ecospat r package broennimann et al 2020 cbi measures the prediction accuracy of occurrence events by determining the spearman rank correlation coefficient of the predicted to expected ratio cbi values of one zero and negative indicated predictions consistent with occurrences equal to random and inconsistent with occurrences respectively boyce et al 2002 hirzel et al 2006 training cbi was determined by 20 of withheld occurrences testing cbi was evaluated against 2000 generated unique spatially thinned by 1 km and corrected by suitability presence absence records within canada and alaska fig 1c we determined the unconditional bias and skill by mean absolute error mae and the associated skill score ss respectively murphy 1988 roebber 1998 mae was the mean difference between predicted and expected probability values an mae value of zero indicated accurate predictions and greater values indicated a higher error in predictions ss was a mean square error measure between predicted probabilities and expected binary outcomes a ss value of one indicated perfect skill with greater than zero indicating better than random and less than zero indicated worse than random mae and ss were determined by extracting corresponding predicted and expected probability values into the appropriate formulas supplementary methods brier score bs represented forecast accuracy murphy and winkler 1992 bs assessed the mean squared error between predicted and expected binned probabilities a value of zero indicated accurate predictions 0 25 indicated predictions are equal to random and greater than 0 25 indicated predictions are inaccurate and worse than random brier 1950 refinement and resolution were quantified as part of bs and examined qualitatively by attribute figures hsu and murphy 1986 higher refinement indicated a greater difference in predicted and expected binned probabilities and zero indicated no difference higher resolution values indicated a greater ability to separate different probabilities with a minimum of zero which indicated no separation murphy and winkler 1992 we interpreted attribute diagrams according to the categorization of reliability based on the slope of the resulting reliability line perfect useful marginally useful not useful or dangerously useless predictions weisheimer and palmer 2014 bs refinement and resolution values were determined through the verification r package ncar 2015 2 4 4 presence absence map we evaluated the binary presence absence predictions by discrimination discrimination determined the threshold dependent ability of an sdm to classify presence or absence fielding and bell 1997 we used a minimal presence threshold of omitted training centroids to create binary maps we defined discrimination by sensitivity specificity precision f1 score and correct classification rate ccr fielding and bell 1997 sensitivity and specificity were the probability that known presences or absences were predicted correctly respectively precision was the probability that a predicted occurrence was an observed occurrence f1 score was the harmonic means of sensitivity and precision ccr is the conditional probability that presence and absences were correctly classified fielding and bell 1997 all discrimination metrics ranged from zero to one such that one indicated perfect discrimination while those 0 5 indicated random discrimination this range of discrimination metrics provided a complete perspective of sdms ability to classify presence and absences training discrimination was evaluated against the 20 of presence and pseudo absences withheld meanwhile discrimination was tested against the 2000 presence absences within canada and alaska described previously fig 1c accounting for the black box nature of biomod2 sdms were trained and projected with a pre determined 80 presence and pseudo absence subset subsequent thresholds were determined by evaluating prediction against the 80 training data by threshold and evaluation functions in dismo r package hijmans et al 2017 lastly the fit of each probability and binary evaluation was assessed by the minimum difference between training and testing evaluations the minimal difference is based on the logic that overfit models will predict the training data well but poorly on test data positive values indicate over fit while negative values indicate under fit models warren and seifert 2011 2 5 analysis variation in reliability among model building choices was determined through type ii wald χ2 tests fit by linear mixed effects models in the car and lmertest r packages kuznetsova et al 2017 fox and weisberg 2019 mixed effects models allowed for the examination of each model building consideration while accounting for repeated measures on training sets we determined a single mixed effect model for each validation and evaluation metric mixed effects models for j included fixed effects of algorithm and pseudo absences interaction with random effects of the training set we considered algorithm pseudo absence number and predictor selection method as fixed effects and training set as a random effect in the mixed effects model for response curve estimation and prediction evaluations we transformed all evaluations by order quantile normalization before statistical analysis to normalize mixed effect model residuals peterson and cavanaugh 2020 we examined minimal differences according to their absolute value to demonstrate deviation from fit we determined the mean relative performances of all associated evaluations to determine which methodology was best suited to identify ecologically important predictors estimate species environment response curves predict probability of occurrence and classify presence absence maps first posthoc comparisons by estimated marginal means with dunn šidák correction for pairwise comparisons were conducted for each validation and evaluation length 2020 we conducted posthoc tests on pseudo absences and predictor selection variation per algorithm and between algorithms pseudo absence levels and predictor selections to determine algorithm specific and overall performance patterns respectively second we assigned the resulting marginal means a normalized score from zero to one based on their significance group classification for each posthoc test such that sdms with the same statistical group classification received the same score we assigned the relative performance of one to the highest or lowest mean if the target value was one highest or zero respectively table s4 we interpreted these ranks to represent poor fair average good or excellent relative performance fig 5 third the relative performance of each model building consideration combination was determined by calculating the relative performance mean across each evaluation per objective we determined the relative performance of response curve estimation by the normalized mean of rmse and ρ relative performances for annual mean temperature precipitation of the wettest month and elevation similarly we calculated the relative performance of overall predictive ability by determining the normalized mean across all measures of training testing and predictive performance fit for probability of occurrence and presence absence map classification overall explanation or prediction relative performance was determined by the normalized mean across each respective group of evaluation metrics lastly total relative performance was determined by the normalized mean of explanation and prediction scores table s8 all sdm computations and analysis were completed in r v 3 6 0 r core team 2019 3 results the ability of model building considerations to account for the effects of centroids varied for identification of ecologically important predictors estimation species environment response curves predicting probability of occurrence and classification presence absence maps objectives p 0 05 table s6 evaluating the relative performance per objective indicated that at least one sdm successfully limited centroid effects to provide appropriate sdm conclusions table s7 however model building considerations to optimize each evaluation and objective were inconsistent between evaluations objectives model type software and within algorithms fig s3 4 only two algorithms multiple adaptive regression splines and surface range envelopes optimized all objectives under a single methodology 3 1 identification of ecologically important predictors the ability to identify ecologically important predictors from centroids was poor j 0 56 0 25 mean standard deviation sd fig 2 only 15 of sdms identified the ecologically important predictors instead sdms typically identified ecologically important and non important predictors 57 or identified two of three ecologically important predictors with 26 or without 2 non important predictors gdd ndvi and precipitation of the driest month were among the most misidentified by 62 39 and 32 of sdms respectively fig s1 the effect of pseudo absences was algorithm dependent and not consistent within model classes except envelope methods pseudo absences did not affect predictor identification for 12 of 25 algorithms we observed that eight algorithms improved identification with equal numbers of pseudo absences four for 10 000 pseudo absences and one improved at double pseudo absences fig 2 overall original generalized additive models with 10 000 pseudo absences provided the best identification generalized linear models from biomod2 with balanced datasets and ensemble methods excluding committee average across pseudo absences identified all ecologically important predictors but less consistently poor identification was exhibited by envelope and machine learning methods fig s3a 3 2 response curve estimation estimated response curves determined appropriate positive or negative trends ρ 0 71 0 17 mean sd but corresponding probabilities were miscalculated rmse 0 42 0 15 fig 3 across ecologically important predictors only 1 of response trends were poorly estimated ρ 0 on the other hand only 1 of responses closely approximated the appropriate response rmse 0 1 and 28 exhibited high miscalculation rmse 0 5 table s7 altogether only 0 1 of sdms resulted in poor trend and response estimation particularly by artificial neural networks and committee average ensembles estimated response patterns varied between ecologically important predictors and based on the platform used fig 3 annual temperature response estimates did not capture the expected β function but indicated a monotonic increase or a negative unimodal response which overpredicted at freezing temperatures by biomod2 and original algorithms respectively fig 3a conversely precipitation response estimates captured the expected logistic curve but were accurate only at minimal and maximal thresholds intermediate precipitation values generally over estimated corresponding probability specifically by biomod2 algorithms fig 3b responses of annual temperature and precipitation of the wettest month were further limited by the loss of conditions greater than 27 c and 700 mm respectively causing truncation fig 3a b lastly elevation exhibited the most consistent estimates of approximately linear monotonic decrease though trends varied fig 3c original algorithms under predicted occurrence probability at low to moderate elevations and over probability at high elevations algorithms from biomod2 only slightly under predicted occurrence at low elevation while over predicting occurrence at moderate to higher elevations table s7 relative performance evaluations indicated that 72 of algorithms required training with only the ecologically important predictors and triple or 10 000 pseudo absences to improve response estimates fig s3b however five algorithms achieved the highest response estimation when considered with equal centroids and pseudo absences and automated predictor selection these five algorithms included the overall best responses estimated by original generalized boosting regression methods with balanced training and automated predictor selection excellent response estimation was also exhibited by generalized linear models from biomod2 with automated and 10 000 pseudo absences table 3 the most inaccurate responses were estimated by envelope and committee average ensembles models table s7 fig s3b 3 3 probability of occurrence centroids generally reflected expected presence or absences but introduced high amounts of error into occurrence probability predictions owing to an inability to differentiate probabilities fig 4 most predictions exhibited little variation with higher than expected proportions of low probable areas supported by training and testing resolutions of 0 04 0 01 and 0 02 0 01 mean sd respectively fig 4c e fig s2 alternatively areas of high probability were overpredicted across most of north america suggesting low probability only within non coastal areas of western u s and canada fig 4 g low variability of probabilities provided good calibration and skill probabilities were consistent cbi 0 with centroids and testing occurrences for 88 and 82 of sdms respectively table s7 further 58 and 62 of predicted probabilities reflected expected presence or absences in the training and testing region respectively ss 0 lower skill compared to calibration resulted from overprediction of occurrence in expected low probability areas fig 4a g observed probability trends resulted in the overall bias of 0 19 0 09 and 0 22 0 10 mean sd in training and testing regions respectively this observed error was comparable to that indicated by forecast accuracy and refinement table s7 overall probability predictions were marginally useful at best fig s2 probability predictions were overfit to the training data with minimal differences exhibiting improved calibration less error and improved separation of values in the training region however the testing region indicated more skill owing to a higher proportion of species absence table s7 probability of occurrences was best estimated from centroids with equal or double pseudo absences by 76 of algorithms fig s4a predictor selection required to account for centroids was less consistent with 40 36 and 24 of algorithms requiring automated a priori and expert predictors respectively across all sdms occurrence probability was best estimated by original generalized regression boosting methods with equal pseudo absences and automated predictors table 3 excellent occurrence probabilities were also generated by mean and weighted mean ensembles with double pseudo absences and automated predictors the least reliable probabilities were provided by neural networks and envelope models fig s4a 3 4 presence absence map discrimination of presence absence from centroids exhibited over and under prediction of species presence depending on region and model building considerations fig 4b d f h for example boundaries with a high density of species presence were predominantly correctly classified but also overpredicted within mexico and along the u s mexico border precision 0 5 0 22 f1 0 62 0 18 mean sd fig 4d f extending classification outside of the training area observed either low detection of species presence or high overprediction precision 0 19 0 13 f1 0 21 0 1 mean sd fig 4f h boundaries with a low density of species presence were under predicted and misclassified as absent within both regions fig 4d f unless presence was vastly over predicted across arctic and coastal boundaries fig 4h as a result extrapolation of centroid trained sdms generally observed improved classification of species absence specificity 0 69 0 14 mean sd over presence sensitivity 0 55 0 12 mean sd overall sdms could only provide moderately accurate discriminations of presence or absence within both training and testing regions ccr 0 68 0 15 and 0 69 0 14 respectively mean sd further 86 of sdms provided better than random discrimination accordingly minimal difference between regions indicated sdms were overfitted to the centroids with lower discrimination of presences in the testing region compared to absences table s7 discrimination from centroids improved when considering equal or double pseudo absences to centroids for 87 of algorithms fig s4b prediction selection considerations were less consistent with 37 34 and 29 of algorithms requiring automated a priori and expert predictors respectively the relative performance indicated the most reliable discrimination was obtained with weighted mean ensembles with equal pseudo absences to centroids and automated predictors table 3 non weighted mean ensembles and original generalized additive models under the same model building considerations also provided excellent discrimination poorest discrimination ability was provided by envelope committee average ensembles and neural networks models fig s4b 3 5 explanation and prediction the ability of centroids to reliably provide explanations was best achieved by generalized linear models from biomod2 with equal pseudo absences to centroids to identify predictors and then estimate response curves envelope and machine learning methods tended to provide the least reliable explanations fig s3c overall predictive ability improved relative to other methodologies when boosting or non committee average ensemble methods with automated predictors and equal pseudo absences were considered neural networks and envelope models provided the poorest predictions fig s4c overall optimization of all sdm objectives from centroids required automated predictor selection regardless of pseudo absences for 44 of algorithms fig 5 alternatively application of expert predictors or a priori with triple or fewer pseudo absences to centroids was required for 38 and 10 of algorithms respectively fig s5 relative performance across all metrics indicated that original generalized boosting regression methods followed by mean median or weighted mean ensembles with equal centroids and pseudo absences and automated predictor selection provided the most reliable conclusions to explain and predict a distribution fig 5 meanwhile remaining regression methods provided excellent or good relative performance machine learning methods exhibited average to poor relative performance finally poor performance was provided by both envelope methods and committee average ensembles fig s5 4 discussion sdms are the most common method to aid management of specific species models can be built from different algorithms predictors and quantities of response variables whose conclusions vary in reliability depending on the objective and precision of the response variable in this study we observed that it is possible to determine appropriate conclusions from centroids if one constructs an sdm carefully considering the methods used particularly algorithms specifically generalized boosting regression methods gbms followed by mean or weighted mean ensembles provided the most accurate conclusions across objectives previous research highlighted gbms as high performing elith et al 2006 wisz et al 2008 heikkinen et al 2012 or moderately performing aguirre gutiérrez et al 2013 breiner et al 2018 choices their strength comes from using an iterative mean ensemble of the boosting and regression tree algorithms to emphasize previously misidentified training responses elith et al 2008 shirley et al 2013 consequently gbms are adept at interpreting non linear responses removing of non contributing predictors fitting multiple interactions accounting for interactions outliers and collinearity and analyzing and interpreting complex responses elith et al 2008 yu et al 2020 notably gbms can interpret imprecise occurrences graham et al 2008 naimi et al 2011 bombi and d amen 2012 and are less affected by coarsening of scale aguirre gutiérrez et al 2013 though gbms have been criticized for their tendency to overfit and produce an unreasonable probability of occurrences becker et al 2020 we did not observe that here table s7 similarly mean or weighted mean ensembles also tended to provide high relative performance across all objectives fig 5 these methods could predict appropriate presence absence maps while also identifying ecologically important predictors and maintaining excellent probability of occurrence predictions ensembles benefit from considering multiple algorithms to highlight areas of agreement the exceptional predictive ability of ensembles stems from presence predictions that are strictly limited to cells for which the majority of sdms agree aguirre gutiérrez et al 2013 additionally as all sdms were able to identify at least two of three ecologically important predictors ensembles were able to assign lower contributions to non ecologically important predictors ensemble methods have risen in popularity to account for variation among algorithms araújo and new 2007 hao et al 2019 compared ensemble to singular methods and found the former were the best or nearly best performing in most studies though ensemble methods can be improved with more careful fine tuning and consideration of algorithms included as opposed to a sensitivity threshold applied here the recommended use of gbms or ensembles contrasts previous sdm mosquito comparisons which suggested that maxent generalized linear models glms or random forests provided the highest performance in the bermuda islands and global predictions khatchikian et al 2011 ding et al 2018 however khatchikian et al 2011 evaluated against precise occurrences and did not consider gbms or ensembles meanwhile ding et al 2018 considered gbms but evaluated sdms without independent data more mosquito distribution publications to date have relied on maxent owing to its perceived flexibility and high performance merow et al 2013 however we observed only average relative performance of maxent overall fig 5 maxent estimates the probability of occurrence by determining the stable equilibrium state of parameters with the highest entropy phillips et al 2006 phillips and dudík 2008 booth et al 2014 maxent s consideration of centroids reduced environmental heterogeneity and thus incorrectly indicated stable equilibrium from maup and degraded performance bombi and d amen 2012 as a result the performance of maxent was reduced at coarser scales while the gbms were not gbms have consistently indicated comparable or better performance than maxent with coarse scales guisan et al 2007b graham et al 2008 bombi and d amen 2012 indicated no hindrance to gbm predictive performance until a 24 fold change from the suspected true ecological scale guisan et al 2007a demonstrated maxent performance decreased compared to gbm at a minimal 10 fold scale increase further other machine learning sdms are generally considered to provide more reliable results elith et al 2006 lawler et al 2006 the assumption of machine learning superiority may be driven by interpolative evaluation instead of the full diagnostic evaluation conducted here machine learning methods may require more attention to fine tuning hyper parameterizations to ensure reliable conclusions than was considered here araújo et al 2019 this suggests that despite maxent and other machine learning methods hold on the sdm literature its use in applications where coarse scales and maup are of concern is ill advised without fine tuning and independent evaluation further model building considerations indicated algorithm and objective specific effects with no pattern observed across algorithms which is consistent with previous studies synes and osborne 2011 barbet massin et al 2012 heikkinen et al 2012 these results further support the need to determine sdm methodology for the available data and objective instead of on commonly applied algorithms aguirre gutiérrez et al 2013 4 1 identification of ecologically important predictors overall predictor identification was poor these results corroborate the findings of inman et al 2021 they tested maxent s ability to identify the ecologically important predictors and observed correct identification by only 3 of sdms with aggregation corrected bias inman et al 2021 the scale changing inhibited predictor identification as drivers of distribution change with scale hortal et al 2010 the difference in scale alters the spatial autocorrelation and heterogeneity within each predictor accordingly sdms appeared to only select predictors with higher spatial autocorrelation or heterogeneity fig s6 increased heterogeneity and spatial autocorrelation inflate predictor importance particularly when a distribution is driven by multiple predictors connor et al 2018 smith and santos 2020 this suggests ecologically important predictors identified by sdms trained with centroids can approximate appropriate ecologically important predictors by indicating predictors demonstrating spatial autocorrelation and heterogeneity at the provided scale these findings may be limited to the predictor identification method applied harisena et al 2021 detailed the predictor importance assessment used here which is sensitive to spatial autocorrelation pseudo replication and truncated responses another predictor importance assessment or selection threshold may improve predictor identification with centroids synes and osborne 2011 harisena et al 2021 consistent predictor identification required generalized additive models gams with 10 000 pseudo absences predictor identification was driven more by the algorithm than the pseudo absence level smith and santos 2020 evaluated the effects of sample size scale and collinearity on gams and maxent to determine predictor contribution they concluded that small sample sizes and coarse scales inhibited predictor identification but the algorithm was the greater indicator of identification success specifically large sample sizes provided the best identification but maxent was more affected by coarse scales smith and santos 2020 therefore our findings partially agree with smith and santos 2020 the smallest sample size considered here was larger than smith and santos 2020 s largest thus potentially explaining the variation in the pseudo absence number effect this suggests that though larger sample sizes are better some algorithms have upper and lower sample size thresholds for predictor identification fig 2 further aguirre gutiérrez et al 2013 indicated only high variability of gam s variable contribution measures this is further supported by a decreased predictor selection ability of gam at lower pseudo absence levels fig 2 therefore gam s predictor identification may not be reflected when fewer centroids are available smith and santos 2020 4 2 response curve estimation aggregation caused truncated species response curves thus increasing niche width only capturing general trends this finding supports previous observations that mismatched scales inhibit species response detection azaele et al 2012 araújo and rozenfeld 2014 change in scale is known to alter the shape of responses from linear to asymmetric or skewed curves owing to maup rydgren et al 2003 lechner et al 2012 as the scale coarsens heterogeneity is increasingly masked thus limited the estimated response wiens 1989 however regardless of response imprecision guisan and zimmermann 2000 described that sdms are not expected to provide realistic responses nor to inform about their underlying mechanisms instead one should consider if the response curve trend was biologically possible and not overly complex jarnevich et al 2015 accordingly correlative sdms should only be expected to capture the general positive or negative response validated against physiological studies here sdms captured the expected positive or negative trends indicating appropriate realism for an sdm however overestimating niche breadth suggests that centroids are unsuitable for transfering beyond the training extent thuiller et al 2004 manzoor et al 2018 future studies may improve niche estimation by considering accounting for uncertainty within predictors such as standard error or considering additional aggregates i e min max median considering pseudo absences from a more restrictive range or only investigating univariate model responses thuiller et al 2004 winters et al 2008 santika and hutchinson 2009 stoklosa et al 2015 across sdms we identified glms with expert or successful automated identification and equal pseudo absences to centroids provided the best explanation this finding is contrary to previous studies which suggested that glms were inferior to other algorithms such as gam or gbm for response estimation santika and hutchinson 2009 this inconsistency may be due to previous glms considering only linear responses while we considered a higher order approach higher order approaches are recommended to provide increased flexibility to fit complex responses segurado et al 2006 dormann et al 2007 further explanation was best estimated for most algorithms when considering expert predictors and high numbers of pseudo absences the requirement of expert predictors for proper explanation re enforces the recommendation building sdms with only predictors that are well supported araújo et al 2019 4 3 probability of occurrence predictions of virtual species generally improved when considered with equal pseudo absences and automated predictor selection coarse scales increase the probability of false absences thus more pseudo absences bias sdms to consider more potentially suitable habitats as unsuitable mcpherson et al 2006 in this study the 1414 centroids limited pseudo absences to a maximum of 1761 unique environmental conditions therefore consideration of equal pseudo absences to centroids provided the least bias training relative to other pseudo absence levels investigated supported by previous studies moffett et al 2007 phillips and dudík 2008 liu et al 2018 for example johnson et al 2017 indicated that discrimination of a albopictus centroids improved when considering equal background points to centroids however a aegypti which had fewer occurrence records improved with double pseudo absences johnson et al 2017 this suggests the number of pseudo absences required varies based on the number of responses available and unique environmental conditions automated selection of predictors generally allowed for more accurate spatial conclusions accounting for the imprecision of centroids fundamentally alters how the responses and resulting distributions are interpreted levin 1992 while the effect of one factor may be prominent at a fine scale its effect may be negligible at another schweiger and beierkuhnlein 2016 hortal et al 2010 described how as scale coarsens the impact of biotic factors on insect distribution decreases and abiotic factors effects increase mouton et al 2009 suggested that data driven sdms such as automated predictors outperformed expert models as predictors were selected based on the available scale thus providing a more reliable interpretation therefore automated predictor selection estimates ecologically important predictors at the provided scale to better represent the responses at the observed over expected responses the overall probability of occurrence predictions was only moderately accurate with low generality suggesting marginal usefulness in application some studies suggest that lower degrees of scale coarsening preserved environmental characteristics guisan et al 2007b trivedi et al 2008 bombi and d amen 2012 but generally scale coarsening decreased sdm predictive performance rahbek and graves 2001 thompson and mcgarigal 2002 guisan et al 2007a seo et al 2009 mertes and jetz 2018 the degree of scale coarsening observed in this study table s2 did not reflect those of the lower degree previously described 10 km2 and therefore supported decreased performance at coarse scales our observed performance reflected a greater decrease in predictive ability than in previous centroid applications johnson et al 2017 applied centroids of a aegypti and a albopictus across the contiguous u s counties and observed good area under the receiver operating characteristic curve scores but without independent validation similarly collins et al 2017 compared sdms trained with precise or centroids occurrences to investigate the degree of bias introduced for butterfly dragonfly and damselfly species in the contiguous u s counties niche similarity metrics indicated centroids only somewhat compromised predictions with the effect more pronounced in larger and environmentally heterogenous counties which could not be accounted for by boundary scale collins et al 2017 one possible explanation for decreased degradation in our study is that all previous studies investigated administrative regions within a single country in contrast we applied centroid occurrences across administrative regions of three countries consequently across country considerations resulted in a more considerable variation in size and shape of boundaries thereby leading to greater uncertainty and instability of predictors by maup openshaw 1984 specifically larger and more heterogeneous administrative regions introduced greater predictor uncertainty namely boundaries in the western u s or canada collins et al 2017 cheng et al 2021 4 4 presence absence map prediction of species presence or absence tended to over predict presence with some cases of under prediction depending on the methodology methodology considerations for species presence or absence predictions followed the patterns described previously presence absence maps require further review of the threshold considered threshold selection is one of many possible sources of bias in sdms bean et al 2012 in this study we applied a minimum presence threshold fig 4b yet in practice threshold selection should be considered relative to the desired sdm application and the importance of omission and commission errors liu et al 2013 alternatively thresholds derived from the maximization of the sum between sensitivity and specificity or minimization of the difference between sensitivity and specificity are generally seen as superior to others or authors may examine an overlay of different thresholds to determine suitable areas liu et al 2005 jiménez valverde and lobo 2007 to our knowledge no studies have investigated the effect of binary threshold choice associated with maup or administrative geopolitical boundary centroids 4 5 implications management of mosquito populations often focuses on chemical or biological agents to limit of reproduction and spread yet these management practices require fine scale and precise predictions to be effective which are not captured using centroids fouet and kamdem 2019 pascoe et al 2019 our results indicated the prediction of only administrative regions at the highest risk of establishment while misclassifying lower density of true occurrence sites this suggested that with very careful consideration of sdm methods centroids can be used to predict boundaries at the highest risk of arthropod vector establishment if sufficient propagules are introduced in new boundaries these corresponding boundaries would be encouraged to enact public education campaigns and increase vector surveillance however sdms consistently missed lower risk areas which may indicate early detection this highlighted the loss of environmental detail with the use of centroids therefore the corresponding sdms are unsuitable for estimating regions with isolated risks such as micro niches further investigations on a local scale or with more precise requirements would be required to provide management applications additional or alternative methods may accomplish this may be necessary to provide reliable conclusions from centroids by applying mixed effect models hamil et al 2016 bayesian velásquez tibatá et al 2016 integration methods collins et al 2017 pacifici et al 2019 or considering movement and biotic factors in addition to abiotic soberón and peterson 2005 centroid responses and resulting ecologically insignificant scales in sdms are not limited to a aegypti and a albopictus approximately half of the occurrences from species of all major taxonomic groups are limited to centroids in occurrence repositories in the u s park and davis 2017 the results of this study provide guidance to improve centroid application in sdms but not conclusive guidelines virtual species ensure sdm assumptions are met including that occurrence records are precise entire geographic and environmental extent are sampled without bias species are at equilibrium and they provide a known truth for evaluation guisan and zimmermann 2000 conversely using a virtual species may bias the results as it gives a simplified distribution based on limited environmental conditions without movement or biotic impacts the results here reflect the ability of sdms to determine appropriate ecologically important predictors estimate responses predict probability and presence only if the species responses are based on a combination of β logistic and linear responses we selected these responses to ensure ecological realism given ecological and physiological studies of a aegypti and a albopictus considering linear and non linear responses limited potentially bias towards a particular analysis hirzel et al 2001 other responses may not observe the same results thus re enforcing the need to test models for the given data and objective for example many regression and tree based sdms poorly model linear responses as the logit link and grouping strategies are non linear and represent a threshold response meynard and quinn 2007 additionally we defined the virtual species from a multiplicative formula yet we trained sdms with additive formulas this allowed for the interaction of environmental conditions on species occurrence while maintaining common practice in sdms as shown by the default settings of an additive formula for most sdms elith et al 2006 meynard and quinn 2007 meynard and quinn 2007 examined sdm discrimination ability of virtual species determined by additive and multiplicative habitat suitability indexes they found that additive and multiplicative training followed similar performance patterns but varied depending on the evaluation metric future sdm investigations of centroids may contrast our findings if trained with multiplicative rather than additive formulas therefore one major limitation was considering a single virtual species across sdms as additional virtual species would allow more variation in the known habitat suitability additionally it is important to note we examined all sdms under default settings default settings may have improved the performance of one sdm over another for example the default interaction depth of gbms and multiple adaptive regression splines have a default interaction depth of seven and zero respectively further default settings allowed gbms to have greater maximum number of trees and minimal number of observations per node than random forest and classification tree table s3 these would allow gbms to resemble the original multiplicative suitability index more closely as well as a greater ability to determine the differentiate between environmental condition importance presence and absence if all algorithms were fine tuned to the provided data we may have observed different results merow et al 2013 araújo et al 2019 future work is required to determine if our results hold across taxonomic groups credit authorship contribution statement justin r barker conceived the study collected analyzed the data and drafted the manuscript hugh j macisaac conceived the study revised and approved the manuscript declaration of competing interest the authors declare that they have no conflict of interest acknowledgments funding was provided by nserc discovery grant and canada research chair to hjm supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2022 110107 appendix supplementary materials image application 1 image application 2 image application 3 
24383,describing and understanding species distributions and the factors driving them is fundamental to ecology and biogeography species distribution models sdms allow one to investigate objectives of identifying ecologically important factors to the distribution estimating species environment responses predicting the probability of species occurrence and predicting species presence or absence mosquito occurrence records used in sdms are often imprecise and represented as a centroid of a geopolitical administrative boundary using a virtual species we investigated the effect of centroids on sdms and determined which methodology was best suited to provide accurate and applicable conclusions for each of the objectives we compared 12 distinct algorithms four levels of pseudo absences and three predictor sets to determine the optimal sdm methodology for each objective the ability of methodology considerations to account for the effects of centroids varied for each objective ecologically important predictors were misidentified but could be best approximated by generalized additive models with 10 000 pseudo absences response curves only captured the expected positive or negative trends centroids limited sdms ability to differentiate expected probabilities resulting in overprediction of high probability areas response curves and occurrence probabilities were best estimated by generalized boosting regression models species presence was largely over estimated within southern regions but underpredicted in northern regions and was best estimated by weighted mean ensembles overall generalized boosting regression methods and weighted mean ensembles provided the most reliable conclusions across all four objectives further the most reliable conclusions were consistently observed with equal pseudo absences when considered with the removal of low contributing predictors except for predictor identification keywords aedes centroid ecological niche modelling imprecise response scale species distribution modelling data availability data will be made available on request 1 introduction species distribution models sdms also known as ecological niche models are powerful tools to correlate the occurrence of a species with environmental predictors to explain and or predict a distribution guisan and zimmermann 2000 explanations of distributions include testing hypotheses related to identifying ecologically important conditions which determine the distribution bradie and leung 2017 and or estimating species environment response curves e g ikegami and jenkins 2018 meanwhile sdms predict the probability of occurrence e g jarnevich and reynolds 2011 and or the expected presence or absence of a species e g johnson et al 2017 in geographic and temporal space the ability of sdms to explain and or predict a distribution depends on but not limited to the algorithm number and quality of response and predictor variables considered wisz et al 2008 synes and osborne 2011 heikkinen et al 2012 previous comparisons have indicated that different algorithms are better suited for other objectives and input data heikkinen et al 2012 aguirre gutiérrez et al 2013 the response variable consists of presences absences abundance or species richness of target species or subjects elith et al 2006 wisz et al 2008 absence records are rarely available or reliable with pseudo absences applied instead barbet massin et al 2012 pseudo absences represent a location where the species has not been observed whether sampled or not and is presumed to be absent without a validating absence record grimmett et al 2020 predictors reflect the abiotic or biotic conditions for which responses are considered guisan and zimmermann 2000 though only predictors with solid evidence indicating a causal relationship with the species distribution should be considered when possible and generally higher number of response variables is recommended austin 2002 wisz et al 2008 but see boria and blois 2018 scale is one of the qualities of response and predictor variables that affects sdm performance lechner et al 2012 lecours et al 2015 depending on the context scale relates to the spatial relationship at which a species interacts with the environmental influences i e dispersal range jackson and fahrig 2015 the spatial characteristics of the occurrence records i e sampling unit area of observation positional accuracy or predictors i e cell size grain resolution or the spatial and temporal accuracy applied to the sdm to analyze the distribution lecours et al 2015 for this paper we use scale to describe the level of spatial detail for each form of data failure to explicitly consider the scale can limit sdms ability to provide reliable conclusions which are applicable and accurate to aid management actions are directly affected moudrý et al 2019 the applied scale must satisfy sdms assumptions of i the occurrence records contain no error and ii the provided environmental predictors are representative of the physiological tolerances or resource requirements of the species niche austin 2002 osborne and leitão 2009 however response quality and predictor variable availability limit the choice of scale specifically irregular lattice occurrence records i e administrative regions centroids with high geographic uncertainty cheng et al 2021 connor et al 2018 response quality limits the geographic precision while predictor scale limits the level of environmental and temporal detail available connor et al 2018 lawler et al 2006 previous investigations suggested that half or more of repository occurrence records i e presence absence within the united states and select species in europe are geographically inaccurate and represent centroids of administrative geopolitical boundaries hereafter centroids collins et al 2017 park and davis 2017 cheng et al 2021 consideration of centroids in sdms alters variable contribution assessment interpretation of responses and an overall decrease in predictive ability johnson and gillingham 2008 osborne and leitão 2009 naimi et al 2011 many methodological approaches have been suggested but cannot entirely correct the imprecision of centroids e g araújo and new 2007 pacifici et al 2019 considering the mean predictor value within each boundary may limit the effect of centroids park and davis 2017 however aggregation causes a loss of fine scale variation which may be an important determinant of species distributions therefore is not practical for large boundaries collins et al 2017 cheng et al 2021 additionally aggregation increases potential artifact effects through the modifiable areal unit problem maup openshaw 1984 maup is a source of statistical bias where correlations can vary from positive to negative depending on the aggregation scale i e county state goodchild 2011 accordingly the resulting aggregated scale satisfies assumption i but potentially violates ii through obscuring fine scale variation and maup effects pearson and dawson 2003 moudrý and šímová 2012 manzoor et al 2018 further sdms calibrated with centroids are often misleading nelson 2001 lecours et al 2015 sdm applications are limited owing to the abundance of centroids for some species and geographic regions to produce sophisticated sdms duputié et al 2014 reliable sdms conclusions can only be established if the applied scale captures important environmental characteristics of the species distribution vergara et al 2016 issues related to centroids remain impossible to solve without accurate occurrence data josselin and louvet 2019 regardless the application of centroids is common practice in sdms of epidemiologically relevant species in north america e g escobar et al 2013 johnson et al 2017 for example occurrence records of the arbovirus vector mosquitoes aedes aegypti and aedes albopictus are predominately available as county centroids within the u s hahn et al 2017 a aegeypti and a albopictus can transmit over 20 pathogens including zika chikungunya dengue and yellow fever viruses leta et al 2018 aided by human mediated dispersal and high eco plasticity both species have rapidly expanded their range in recent years causing increased introduction and incidence of pathogens within novel regions weaver 2014 ibañez justicia 2020 johnson et al 2017 predicted the distribution of a aegpyti and a albopictus within the contiguous u s from county centroids they indicated the unlikely occurrence of both species within wayne county mi johnson et al 2017 however both species were recorded across the border in the windsor essex region of south western ontario canada from 2017 to 2019 giordano et al 2019 with a albopictus continuing to be present through june 2021 windsor essex health unit 2021 therefore concern exists that sdms trained with centroids may not provide reliable conclusions there is increasing awareness that sdms must be tested and designed for the desired objective using available data aguirre gutiérrez et al 2013 guillera arroita et al 2015 araújo et al 2019 the effect of centroids on different sdm algorithms quantity of response and predictor variables is unknown previous investigations of sdms calibrated with centroids are limited to the probability of occurrence predictions by maximum entropy maxent collins et al 2017 park and davis 2017 cheng et al 2021 given the availability of multiple algorithms it is therefore vital to assess the effect of administrative centroids on different algorithms to achieve common sdm objectives common sdm objectives include identifying ecologically important predictors estimating species environment response curves predicting the probability of occurrence and classifying presence absence maps aguirre gutiérrez et al 2013 araújo et al 2019 here we provide an in depth analysis of sdms ability to achieve these common objectives for epidemiologically relevant species of mosquitoes based on centroid occurrences of a virtual species in north america to simulate reality we created a virtual species to resemble epidemiologically relevant species with known administrative region centroid occurrences a aegypti and a albopictus we focus on assessing sdm s ability to explain a species niche by identifying the correct ecologically important predictors and estimating appropriate species environment responses additionally we determine the ability of sdms to predict the probability of occurrence and binary presence absence maps from centroids lastly we investigated which sdm methodology is best suited to interpret centroids across all described objectives this work will guide the use of centroids in sdms to improve the reliability of conclusions for public health applications 2 methods we constructed a realistic virtual species to simulate real world application of centroids with the environmental suitability traits based on a aegypti and a albopictus environmental suitability of both species has been primarily related to temperature for development and survival brady et al 2013 eisen et al 2014 additionally both species are container breeding species that rely on precipitation for suitable reproduction conditions in natural or human made containers i e tires flower plots gama and islamiyah 2013 dhimal et al 2015 a albopictus has successfully established in more northern areas attributed to its ability to diapause and survive cold winters denlinger and armbruster 2014 a aegypti has only demonstrated diapause in some populations lima et al 2016 both species occur beyond environmentally suitable areas by employing micro niches as refugia when the macro climate is unsuitable hayden et al 2010 murdock et al 2017 a aegypti is mainly found in urban areas and has an anthropophilic feeding habit a albopictus inhabits urban peri urban rural or forested habitats and is an opportunistic feeder yang et al 2021 when species distributions overlap a albopictus is a superior larval competitor and a albopictus males will cross mate with a aegypti females causing reproductive losses braks et al 2004 lounibos et al 2016 2 1 predictor variables based on the literature we considered predictors that have direct and indirect effects on a albopictus and a aegypti including climate topography land cover and use vegetation indices and socioeconomic predictors larson et al 2010 mughini gras et al 2014 alahmed et al 2015 we calculated the aggregate means of each predictor to represent mean administrative boundary predictor values with zonal statistics in arcgis 10 6 esri 2008 boundary land cover and use categories were represented by the mean percent land cover and use per category within a boundary we assessed multi collinearity using pearson s correlation matrix followed by the variance inflation factor vif leroy et al 2016 naimi et al 2014 multi collinearity was evaluated at the original 1 km2 and aggregated scale to address all potential collinearity we excluded highly correlated variables r 0 7 vif 10 to prevent analysis errors dormann et al 2013 we manually selected a single predictor from each highly correlated group table 1 s1 we calculated some predictors before aggregation growing degree days gdd represented the magnitude of mean monthly temperatures above a baseline temperature of 5 c below which development or survival cannot occur mcmaster and wilhelm 1997 we calculated the selected bioclimatic variables annual mean temperature bio1 mean diurnal temperature bio2 precipitation of the wettest month bio13 and precipitation of the driest month bio14 and gdd from daymet version 4 monthly climate summaries thornton et al 1997 2017 in dismo and envirem r packages respectively hijmans et al 2017 bemmels 2018 additionally we estimated human population density from the most recent census data for each administrative boundary as a proxy for rural and urban areas as well as anthropophilic nature of a aegpyti national institute of statistics and geography 2018 statistics canada 2018 u s census bureau 2017 yang et al 2021 we applied the normalized difference vegetation index ndvi to quantify vegetation greenness and provide an understanding of vegetation density pettorelli et al 2005 we restricted the geographic extent to north america with administrative regions represented by canadian health regions u s counties and mexican states resulting in a mean scale of 6424 km2 table s2 2 2 virtual species design we designed a virtual species through the virtualspecies r package leroy et al 2016 we designed the habitat suitability to reflect common characteristics of a aegypti and a albopictus based on annual mean temperature precipitation of the wettest month and elevation at the most detailed available scale of 1 km2 this scale was appropriate as both species have mean flight ranges of 1 km verdonschot and besse lototskaya 2014 however this scale would not reflect appropriate micro niches or refugia annual mean temperature related to survival and development reinhold et al 2018 precipitation of the wettest month indicated the availability and quality of oviposition sites for reproduction becker et al 2010 lower elevation related to increased human disturbance creating more breeding habitats through artificial water holding containers gama and islamiyah 2013 dhimal et al 2015 accordingly we determined the virtual species habitat suitability from defined responses of each predictor within north america fig 1a we modeled the virtual species habitat suitability by a multiplicative suitability index of annual mean temperature precipitation of the wettest month and elevation as β function logistic and linear responses respectively fig 1a c supplementary methods a β function pattern allowed for specific upper and lower thresholds with different slopes representing temperature thresholds for survival and development cunze et al 2016 koch et al 2016 the logistic function represented a gradual increase in suitability to a maximum asymptote reflecting the availability of oviposition sites as precipitation increased alaniz et al 2017 we expressed elevation as a piecewise linear decrease representing lower host population and pooling water availability at higher elevations alaniz et al 2017 santos and meneses 2017 we interpreted habitat suitability as the probability of occurrence for comparison of sdms the final probability map was visually examined to ensure similarity to published predictions of a aegypti and a albopictus for ecological realism fig 1b 2 3 modeling building to train sdms we created a geographically structured response by converting the suitability index into presence absence records fig 1b c we randomly generated 3500 unique 1 km spatially thinned and corrected by suitability presence only records within the contiguous u s and mexico these records were then converted into centroids such that all occurrences within a boundary were represented by one centroid resulting in 1414 centroids to assess sdm methodology for centroid occurrences we investigated common model building choices of the algorithm the number of pseudo absences generated and predictor variable selection fig 1d e these choices represent how the species environment relationship is interpreted characterized and assessed and predicted against elith et al 2006 wisz et al 2008 aguirre gutiérrez et al 2013 2 3 1 algorithms we applied twelve different distinct algorithms in either their original software denoted by o or as part of ensemble sdm software biomod2 thuiller et al 2020 denoted by b table 2 the software or platform applied potentially impacts sdm performance as each has its unique features and considerations aguirre gutiérrez et al 2013 guillera arroita et al 2015 the ensemble sdm framework provided by biomod2 is the most widely used within the sdm literature hao et al 2019 however the black box nature of the biomod2 framework results in only rough model calibrations it inflates model evaluations by rescaling predictions by a binomial generalized linear model thuiller et al 2009 not present in the original software thus a comparison of original and biomod2 methods assesses the consideration of software selection on model reliability we constructed the original regression and random forest models using additive formulas also we calibrated the original generalized linear models with first and second order polynomial variables of all predictors to reflect corresponding biomod2 formulas otherwise all algorithms were run with default settings for simplicity and comparison table s3 for descriptions of each algorithm see elith et al 2006 araújo and new 2007 reiss et al 2011 and fitzpatrick et al 2013 2 3 2 pseudo absences we considered pseudo absences for model training to simulate common practice instead of known absence pseudo absences must be derived from areas accessible to the species barve et al 2011 a aegypti and a albopictus are primarily distributed by human activity eritja et al 2017 thus all administrative boundaries were considered accessible accordingly we generated 100 000 pseudo absences at least 1 km apart within the 1761 boundaries without a centroid occurrence in the contiguous u s and mexico we considered pseudo absence numbers equal double or triple the number of centroids 1 1 1 2 1 3 respectively e g tiffin et al 2019 or a total of 10 000 we determined 100 unique training sets per pseudo absence level consisting of all centroid occurrences and a random subset without replacement of all pseudo absences to ensure consistent training fig 1d 2 3 3 predictor selection we considered predictor selection by a priori automated and expert selection a priori represented all predictors with suspected direct indirect or resource effects e g low et al 2021 alternatively ecologically important predictors are estimated from a priori by the percent reduction in model fit when each predictor is randomly permuted hereafter automated harisena et al 2021 to demonstrate each predictor selection we first trained sdms with all predictors to represent a priori table 1 for each a priori training set we calculated predictor importance per algorithm and pseudo absence level predictor importance was assessed by randomizing a single predictor variable position then making a new prediction with the new randomized predictor variables predictor importance reflects the difference between pearson s correlation of the original and randomized predictors prediction from one thuiller et al 2020 we repeated this process 1500 times per predictor to allow for adequate convergence predictor importance was determined by functions in biomod2 or equivalent functions in caret r packages for original algorithms kuhn 2020 liaw et al 2019 thuiller et al 2020 we converted the predictor contribution measures to percent contribution such that all values for a single repetition summed to one automated predictors represented predictors with greater than 5 mean contribution across all training sets per algorithm and pseudo absence level we demonstrated expert predictors by considering only the driving predictors of annual mean temperature precipitation of the wettest month and elevation fig 1e therefore we generated and compared 30 000 sdms 25 algorithms x 4 pseudo absence levels x 3 predictor selections x 100 training sets we trained sdms with an 80 random subset of training sets algorithms included in ensembles achieved a sensitivity of 95 see model evaluation of omitted training presence records 2 4 model evaluation we evaluated centroid explanation ability by identifying expected important predictors and response curve estimation fig 1f g we evaluated predictive ability by the accuracy of the predicted probability of occurrence and binary discrimination fig 1h i each algorithm provided a different range of probabilities for interpretation consequently we normalized all predictions before evaluation details of all evaluations are available in supplementary methods 2 4 1 identification of ecologically important predictors the jaccard index j quantified the ability to identify ecologically important predictors fig 1f j is a measure of similarity between two datasets j ranges from zero to one such that one and zero indicate identical and no similarities respectively jaccard 1908 we determined j between automated and expert predictors for each training set and sdm we determined how many of the three predictors used to create the virtual species were selected during automated selection and divided by the total number of unique automated and expert predictors e g inman et al 2021 fig 1f 2 4 2 response curve estimation we calculated response curves for each predictor used to create the virtual species by extracting the predicted probability and corresponding aggregated predictor values we smoothed the resulting responses by generalized additive smoothing to ensure a single probability per environmental value expected responses were calculated for each environmental value and compared by root mean square error rmse and spearman s correlation ρ fig 1 g rmse provided a measure of variation between the expected and estimated response values larger rmse values indicated a greater error in estimated responses ρ indicated if the estimated response curve determined the appropriate pattern relative to the expected one ρ ranged from 1 to 1 with negative values indicating negative correlation zero no association and positive values indicating a positive correlation 2 4 3 probability of occurrence we evaluated the predicted probability of occurrences by a full diagnostic verification by calibration bias skill accuracy refinement and resolution of training and testing regions murphy and winkler 1992 calibration described the degree to which relative suitability of a presence correlated with predicted probability bias indicated the degree to which the predicted probability differed from the known probability of occurrence skill measured the accuracy of the predicted probability relative to an expected binary prediction forecast accuracy reflected the overall degree to which binned predicted probability corresponded to the expected binned probability of occurrence refinement indicated the mean square difference of binned predicted and expected probability values resolution described the ability of sdms could separate different probabilities relative to expected separation murphy and winkler 1992 training evaluations represented comparisons of the predicted and expected probability of occurrence within the contiguous u s and mexico and testing evaluation was within canada and alaska unless otherwise stated we assessed calibration by the continuous boyce index cbi in the ecospat r package broennimann et al 2020 cbi measures the prediction accuracy of occurrence events by determining the spearman rank correlation coefficient of the predicted to expected ratio cbi values of one zero and negative indicated predictions consistent with occurrences equal to random and inconsistent with occurrences respectively boyce et al 2002 hirzel et al 2006 training cbi was determined by 20 of withheld occurrences testing cbi was evaluated against 2000 generated unique spatially thinned by 1 km and corrected by suitability presence absence records within canada and alaska fig 1c we determined the unconditional bias and skill by mean absolute error mae and the associated skill score ss respectively murphy 1988 roebber 1998 mae was the mean difference between predicted and expected probability values an mae value of zero indicated accurate predictions and greater values indicated a higher error in predictions ss was a mean square error measure between predicted probabilities and expected binary outcomes a ss value of one indicated perfect skill with greater than zero indicating better than random and less than zero indicated worse than random mae and ss were determined by extracting corresponding predicted and expected probability values into the appropriate formulas supplementary methods brier score bs represented forecast accuracy murphy and winkler 1992 bs assessed the mean squared error between predicted and expected binned probabilities a value of zero indicated accurate predictions 0 25 indicated predictions are equal to random and greater than 0 25 indicated predictions are inaccurate and worse than random brier 1950 refinement and resolution were quantified as part of bs and examined qualitatively by attribute figures hsu and murphy 1986 higher refinement indicated a greater difference in predicted and expected binned probabilities and zero indicated no difference higher resolution values indicated a greater ability to separate different probabilities with a minimum of zero which indicated no separation murphy and winkler 1992 we interpreted attribute diagrams according to the categorization of reliability based on the slope of the resulting reliability line perfect useful marginally useful not useful or dangerously useless predictions weisheimer and palmer 2014 bs refinement and resolution values were determined through the verification r package ncar 2015 2 4 4 presence absence map we evaluated the binary presence absence predictions by discrimination discrimination determined the threshold dependent ability of an sdm to classify presence or absence fielding and bell 1997 we used a minimal presence threshold of omitted training centroids to create binary maps we defined discrimination by sensitivity specificity precision f1 score and correct classification rate ccr fielding and bell 1997 sensitivity and specificity were the probability that known presences or absences were predicted correctly respectively precision was the probability that a predicted occurrence was an observed occurrence f1 score was the harmonic means of sensitivity and precision ccr is the conditional probability that presence and absences were correctly classified fielding and bell 1997 all discrimination metrics ranged from zero to one such that one indicated perfect discrimination while those 0 5 indicated random discrimination this range of discrimination metrics provided a complete perspective of sdms ability to classify presence and absences training discrimination was evaluated against the 20 of presence and pseudo absences withheld meanwhile discrimination was tested against the 2000 presence absences within canada and alaska described previously fig 1c accounting for the black box nature of biomod2 sdms were trained and projected with a pre determined 80 presence and pseudo absence subset subsequent thresholds were determined by evaluating prediction against the 80 training data by threshold and evaluation functions in dismo r package hijmans et al 2017 lastly the fit of each probability and binary evaluation was assessed by the minimum difference between training and testing evaluations the minimal difference is based on the logic that overfit models will predict the training data well but poorly on test data positive values indicate over fit while negative values indicate under fit models warren and seifert 2011 2 5 analysis variation in reliability among model building choices was determined through type ii wald χ2 tests fit by linear mixed effects models in the car and lmertest r packages kuznetsova et al 2017 fox and weisberg 2019 mixed effects models allowed for the examination of each model building consideration while accounting for repeated measures on training sets we determined a single mixed effect model for each validation and evaluation metric mixed effects models for j included fixed effects of algorithm and pseudo absences interaction with random effects of the training set we considered algorithm pseudo absence number and predictor selection method as fixed effects and training set as a random effect in the mixed effects model for response curve estimation and prediction evaluations we transformed all evaluations by order quantile normalization before statistical analysis to normalize mixed effect model residuals peterson and cavanaugh 2020 we examined minimal differences according to their absolute value to demonstrate deviation from fit we determined the mean relative performances of all associated evaluations to determine which methodology was best suited to identify ecologically important predictors estimate species environment response curves predict probability of occurrence and classify presence absence maps first posthoc comparisons by estimated marginal means with dunn šidák correction for pairwise comparisons were conducted for each validation and evaluation length 2020 we conducted posthoc tests on pseudo absences and predictor selection variation per algorithm and between algorithms pseudo absence levels and predictor selections to determine algorithm specific and overall performance patterns respectively second we assigned the resulting marginal means a normalized score from zero to one based on their significance group classification for each posthoc test such that sdms with the same statistical group classification received the same score we assigned the relative performance of one to the highest or lowest mean if the target value was one highest or zero respectively table s4 we interpreted these ranks to represent poor fair average good or excellent relative performance fig 5 third the relative performance of each model building consideration combination was determined by calculating the relative performance mean across each evaluation per objective we determined the relative performance of response curve estimation by the normalized mean of rmse and ρ relative performances for annual mean temperature precipitation of the wettest month and elevation similarly we calculated the relative performance of overall predictive ability by determining the normalized mean across all measures of training testing and predictive performance fit for probability of occurrence and presence absence map classification overall explanation or prediction relative performance was determined by the normalized mean across each respective group of evaluation metrics lastly total relative performance was determined by the normalized mean of explanation and prediction scores table s8 all sdm computations and analysis were completed in r v 3 6 0 r core team 2019 3 results the ability of model building considerations to account for the effects of centroids varied for identification of ecologically important predictors estimation species environment response curves predicting probability of occurrence and classification presence absence maps objectives p 0 05 table s6 evaluating the relative performance per objective indicated that at least one sdm successfully limited centroid effects to provide appropriate sdm conclusions table s7 however model building considerations to optimize each evaluation and objective were inconsistent between evaluations objectives model type software and within algorithms fig s3 4 only two algorithms multiple adaptive regression splines and surface range envelopes optimized all objectives under a single methodology 3 1 identification of ecologically important predictors the ability to identify ecologically important predictors from centroids was poor j 0 56 0 25 mean standard deviation sd fig 2 only 15 of sdms identified the ecologically important predictors instead sdms typically identified ecologically important and non important predictors 57 or identified two of three ecologically important predictors with 26 or without 2 non important predictors gdd ndvi and precipitation of the driest month were among the most misidentified by 62 39 and 32 of sdms respectively fig s1 the effect of pseudo absences was algorithm dependent and not consistent within model classes except envelope methods pseudo absences did not affect predictor identification for 12 of 25 algorithms we observed that eight algorithms improved identification with equal numbers of pseudo absences four for 10 000 pseudo absences and one improved at double pseudo absences fig 2 overall original generalized additive models with 10 000 pseudo absences provided the best identification generalized linear models from biomod2 with balanced datasets and ensemble methods excluding committee average across pseudo absences identified all ecologically important predictors but less consistently poor identification was exhibited by envelope and machine learning methods fig s3a 3 2 response curve estimation estimated response curves determined appropriate positive or negative trends ρ 0 71 0 17 mean sd but corresponding probabilities were miscalculated rmse 0 42 0 15 fig 3 across ecologically important predictors only 1 of response trends were poorly estimated ρ 0 on the other hand only 1 of responses closely approximated the appropriate response rmse 0 1 and 28 exhibited high miscalculation rmse 0 5 table s7 altogether only 0 1 of sdms resulted in poor trend and response estimation particularly by artificial neural networks and committee average ensembles estimated response patterns varied between ecologically important predictors and based on the platform used fig 3 annual temperature response estimates did not capture the expected β function but indicated a monotonic increase or a negative unimodal response which overpredicted at freezing temperatures by biomod2 and original algorithms respectively fig 3a conversely precipitation response estimates captured the expected logistic curve but were accurate only at minimal and maximal thresholds intermediate precipitation values generally over estimated corresponding probability specifically by biomod2 algorithms fig 3b responses of annual temperature and precipitation of the wettest month were further limited by the loss of conditions greater than 27 c and 700 mm respectively causing truncation fig 3a b lastly elevation exhibited the most consistent estimates of approximately linear monotonic decrease though trends varied fig 3c original algorithms under predicted occurrence probability at low to moderate elevations and over probability at high elevations algorithms from biomod2 only slightly under predicted occurrence at low elevation while over predicting occurrence at moderate to higher elevations table s7 relative performance evaluations indicated that 72 of algorithms required training with only the ecologically important predictors and triple or 10 000 pseudo absences to improve response estimates fig s3b however five algorithms achieved the highest response estimation when considered with equal centroids and pseudo absences and automated predictor selection these five algorithms included the overall best responses estimated by original generalized boosting regression methods with balanced training and automated predictor selection excellent response estimation was also exhibited by generalized linear models from biomod2 with automated and 10 000 pseudo absences table 3 the most inaccurate responses were estimated by envelope and committee average ensembles models table s7 fig s3b 3 3 probability of occurrence centroids generally reflected expected presence or absences but introduced high amounts of error into occurrence probability predictions owing to an inability to differentiate probabilities fig 4 most predictions exhibited little variation with higher than expected proportions of low probable areas supported by training and testing resolutions of 0 04 0 01 and 0 02 0 01 mean sd respectively fig 4c e fig s2 alternatively areas of high probability were overpredicted across most of north america suggesting low probability only within non coastal areas of western u s and canada fig 4 g low variability of probabilities provided good calibration and skill probabilities were consistent cbi 0 with centroids and testing occurrences for 88 and 82 of sdms respectively table s7 further 58 and 62 of predicted probabilities reflected expected presence or absences in the training and testing region respectively ss 0 lower skill compared to calibration resulted from overprediction of occurrence in expected low probability areas fig 4a g observed probability trends resulted in the overall bias of 0 19 0 09 and 0 22 0 10 mean sd in training and testing regions respectively this observed error was comparable to that indicated by forecast accuracy and refinement table s7 overall probability predictions were marginally useful at best fig s2 probability predictions were overfit to the training data with minimal differences exhibiting improved calibration less error and improved separation of values in the training region however the testing region indicated more skill owing to a higher proportion of species absence table s7 probability of occurrences was best estimated from centroids with equal or double pseudo absences by 76 of algorithms fig s4a predictor selection required to account for centroids was less consistent with 40 36 and 24 of algorithms requiring automated a priori and expert predictors respectively across all sdms occurrence probability was best estimated by original generalized regression boosting methods with equal pseudo absences and automated predictors table 3 excellent occurrence probabilities were also generated by mean and weighted mean ensembles with double pseudo absences and automated predictors the least reliable probabilities were provided by neural networks and envelope models fig s4a 3 4 presence absence map discrimination of presence absence from centroids exhibited over and under prediction of species presence depending on region and model building considerations fig 4b d f h for example boundaries with a high density of species presence were predominantly correctly classified but also overpredicted within mexico and along the u s mexico border precision 0 5 0 22 f1 0 62 0 18 mean sd fig 4d f extending classification outside of the training area observed either low detection of species presence or high overprediction precision 0 19 0 13 f1 0 21 0 1 mean sd fig 4f h boundaries with a low density of species presence were under predicted and misclassified as absent within both regions fig 4d f unless presence was vastly over predicted across arctic and coastal boundaries fig 4h as a result extrapolation of centroid trained sdms generally observed improved classification of species absence specificity 0 69 0 14 mean sd over presence sensitivity 0 55 0 12 mean sd overall sdms could only provide moderately accurate discriminations of presence or absence within both training and testing regions ccr 0 68 0 15 and 0 69 0 14 respectively mean sd further 86 of sdms provided better than random discrimination accordingly minimal difference between regions indicated sdms were overfitted to the centroids with lower discrimination of presences in the testing region compared to absences table s7 discrimination from centroids improved when considering equal or double pseudo absences to centroids for 87 of algorithms fig s4b prediction selection considerations were less consistent with 37 34 and 29 of algorithms requiring automated a priori and expert predictors respectively the relative performance indicated the most reliable discrimination was obtained with weighted mean ensembles with equal pseudo absences to centroids and automated predictors table 3 non weighted mean ensembles and original generalized additive models under the same model building considerations also provided excellent discrimination poorest discrimination ability was provided by envelope committee average ensembles and neural networks models fig s4b 3 5 explanation and prediction the ability of centroids to reliably provide explanations was best achieved by generalized linear models from biomod2 with equal pseudo absences to centroids to identify predictors and then estimate response curves envelope and machine learning methods tended to provide the least reliable explanations fig s3c overall predictive ability improved relative to other methodologies when boosting or non committee average ensemble methods with automated predictors and equal pseudo absences were considered neural networks and envelope models provided the poorest predictions fig s4c overall optimization of all sdm objectives from centroids required automated predictor selection regardless of pseudo absences for 44 of algorithms fig 5 alternatively application of expert predictors or a priori with triple or fewer pseudo absences to centroids was required for 38 and 10 of algorithms respectively fig s5 relative performance across all metrics indicated that original generalized boosting regression methods followed by mean median or weighted mean ensembles with equal centroids and pseudo absences and automated predictor selection provided the most reliable conclusions to explain and predict a distribution fig 5 meanwhile remaining regression methods provided excellent or good relative performance machine learning methods exhibited average to poor relative performance finally poor performance was provided by both envelope methods and committee average ensembles fig s5 4 discussion sdms are the most common method to aid management of specific species models can be built from different algorithms predictors and quantities of response variables whose conclusions vary in reliability depending on the objective and precision of the response variable in this study we observed that it is possible to determine appropriate conclusions from centroids if one constructs an sdm carefully considering the methods used particularly algorithms specifically generalized boosting regression methods gbms followed by mean or weighted mean ensembles provided the most accurate conclusions across objectives previous research highlighted gbms as high performing elith et al 2006 wisz et al 2008 heikkinen et al 2012 or moderately performing aguirre gutiérrez et al 2013 breiner et al 2018 choices their strength comes from using an iterative mean ensemble of the boosting and regression tree algorithms to emphasize previously misidentified training responses elith et al 2008 shirley et al 2013 consequently gbms are adept at interpreting non linear responses removing of non contributing predictors fitting multiple interactions accounting for interactions outliers and collinearity and analyzing and interpreting complex responses elith et al 2008 yu et al 2020 notably gbms can interpret imprecise occurrences graham et al 2008 naimi et al 2011 bombi and d amen 2012 and are less affected by coarsening of scale aguirre gutiérrez et al 2013 though gbms have been criticized for their tendency to overfit and produce an unreasonable probability of occurrences becker et al 2020 we did not observe that here table s7 similarly mean or weighted mean ensembles also tended to provide high relative performance across all objectives fig 5 these methods could predict appropriate presence absence maps while also identifying ecologically important predictors and maintaining excellent probability of occurrence predictions ensembles benefit from considering multiple algorithms to highlight areas of agreement the exceptional predictive ability of ensembles stems from presence predictions that are strictly limited to cells for which the majority of sdms agree aguirre gutiérrez et al 2013 additionally as all sdms were able to identify at least two of three ecologically important predictors ensembles were able to assign lower contributions to non ecologically important predictors ensemble methods have risen in popularity to account for variation among algorithms araújo and new 2007 hao et al 2019 compared ensemble to singular methods and found the former were the best or nearly best performing in most studies though ensemble methods can be improved with more careful fine tuning and consideration of algorithms included as opposed to a sensitivity threshold applied here the recommended use of gbms or ensembles contrasts previous sdm mosquito comparisons which suggested that maxent generalized linear models glms or random forests provided the highest performance in the bermuda islands and global predictions khatchikian et al 2011 ding et al 2018 however khatchikian et al 2011 evaluated against precise occurrences and did not consider gbms or ensembles meanwhile ding et al 2018 considered gbms but evaluated sdms without independent data more mosquito distribution publications to date have relied on maxent owing to its perceived flexibility and high performance merow et al 2013 however we observed only average relative performance of maxent overall fig 5 maxent estimates the probability of occurrence by determining the stable equilibrium state of parameters with the highest entropy phillips et al 2006 phillips and dudík 2008 booth et al 2014 maxent s consideration of centroids reduced environmental heterogeneity and thus incorrectly indicated stable equilibrium from maup and degraded performance bombi and d amen 2012 as a result the performance of maxent was reduced at coarser scales while the gbms were not gbms have consistently indicated comparable or better performance than maxent with coarse scales guisan et al 2007b graham et al 2008 bombi and d amen 2012 indicated no hindrance to gbm predictive performance until a 24 fold change from the suspected true ecological scale guisan et al 2007a demonstrated maxent performance decreased compared to gbm at a minimal 10 fold scale increase further other machine learning sdms are generally considered to provide more reliable results elith et al 2006 lawler et al 2006 the assumption of machine learning superiority may be driven by interpolative evaluation instead of the full diagnostic evaluation conducted here machine learning methods may require more attention to fine tuning hyper parameterizations to ensure reliable conclusions than was considered here araújo et al 2019 this suggests that despite maxent and other machine learning methods hold on the sdm literature its use in applications where coarse scales and maup are of concern is ill advised without fine tuning and independent evaluation further model building considerations indicated algorithm and objective specific effects with no pattern observed across algorithms which is consistent with previous studies synes and osborne 2011 barbet massin et al 2012 heikkinen et al 2012 these results further support the need to determine sdm methodology for the available data and objective instead of on commonly applied algorithms aguirre gutiérrez et al 2013 4 1 identification of ecologically important predictors overall predictor identification was poor these results corroborate the findings of inman et al 2021 they tested maxent s ability to identify the ecologically important predictors and observed correct identification by only 3 of sdms with aggregation corrected bias inman et al 2021 the scale changing inhibited predictor identification as drivers of distribution change with scale hortal et al 2010 the difference in scale alters the spatial autocorrelation and heterogeneity within each predictor accordingly sdms appeared to only select predictors with higher spatial autocorrelation or heterogeneity fig s6 increased heterogeneity and spatial autocorrelation inflate predictor importance particularly when a distribution is driven by multiple predictors connor et al 2018 smith and santos 2020 this suggests ecologically important predictors identified by sdms trained with centroids can approximate appropriate ecologically important predictors by indicating predictors demonstrating spatial autocorrelation and heterogeneity at the provided scale these findings may be limited to the predictor identification method applied harisena et al 2021 detailed the predictor importance assessment used here which is sensitive to spatial autocorrelation pseudo replication and truncated responses another predictor importance assessment or selection threshold may improve predictor identification with centroids synes and osborne 2011 harisena et al 2021 consistent predictor identification required generalized additive models gams with 10 000 pseudo absences predictor identification was driven more by the algorithm than the pseudo absence level smith and santos 2020 evaluated the effects of sample size scale and collinearity on gams and maxent to determine predictor contribution they concluded that small sample sizes and coarse scales inhibited predictor identification but the algorithm was the greater indicator of identification success specifically large sample sizes provided the best identification but maxent was more affected by coarse scales smith and santos 2020 therefore our findings partially agree with smith and santos 2020 the smallest sample size considered here was larger than smith and santos 2020 s largest thus potentially explaining the variation in the pseudo absence number effect this suggests that though larger sample sizes are better some algorithms have upper and lower sample size thresholds for predictor identification fig 2 further aguirre gutiérrez et al 2013 indicated only high variability of gam s variable contribution measures this is further supported by a decreased predictor selection ability of gam at lower pseudo absence levels fig 2 therefore gam s predictor identification may not be reflected when fewer centroids are available smith and santos 2020 4 2 response curve estimation aggregation caused truncated species response curves thus increasing niche width only capturing general trends this finding supports previous observations that mismatched scales inhibit species response detection azaele et al 2012 araújo and rozenfeld 2014 change in scale is known to alter the shape of responses from linear to asymmetric or skewed curves owing to maup rydgren et al 2003 lechner et al 2012 as the scale coarsens heterogeneity is increasingly masked thus limited the estimated response wiens 1989 however regardless of response imprecision guisan and zimmermann 2000 described that sdms are not expected to provide realistic responses nor to inform about their underlying mechanisms instead one should consider if the response curve trend was biologically possible and not overly complex jarnevich et al 2015 accordingly correlative sdms should only be expected to capture the general positive or negative response validated against physiological studies here sdms captured the expected positive or negative trends indicating appropriate realism for an sdm however overestimating niche breadth suggests that centroids are unsuitable for transfering beyond the training extent thuiller et al 2004 manzoor et al 2018 future studies may improve niche estimation by considering accounting for uncertainty within predictors such as standard error or considering additional aggregates i e min max median considering pseudo absences from a more restrictive range or only investigating univariate model responses thuiller et al 2004 winters et al 2008 santika and hutchinson 2009 stoklosa et al 2015 across sdms we identified glms with expert or successful automated identification and equal pseudo absences to centroids provided the best explanation this finding is contrary to previous studies which suggested that glms were inferior to other algorithms such as gam or gbm for response estimation santika and hutchinson 2009 this inconsistency may be due to previous glms considering only linear responses while we considered a higher order approach higher order approaches are recommended to provide increased flexibility to fit complex responses segurado et al 2006 dormann et al 2007 further explanation was best estimated for most algorithms when considering expert predictors and high numbers of pseudo absences the requirement of expert predictors for proper explanation re enforces the recommendation building sdms with only predictors that are well supported araújo et al 2019 4 3 probability of occurrence predictions of virtual species generally improved when considered with equal pseudo absences and automated predictor selection coarse scales increase the probability of false absences thus more pseudo absences bias sdms to consider more potentially suitable habitats as unsuitable mcpherson et al 2006 in this study the 1414 centroids limited pseudo absences to a maximum of 1761 unique environmental conditions therefore consideration of equal pseudo absences to centroids provided the least bias training relative to other pseudo absence levels investigated supported by previous studies moffett et al 2007 phillips and dudík 2008 liu et al 2018 for example johnson et al 2017 indicated that discrimination of a albopictus centroids improved when considering equal background points to centroids however a aegypti which had fewer occurrence records improved with double pseudo absences johnson et al 2017 this suggests the number of pseudo absences required varies based on the number of responses available and unique environmental conditions automated selection of predictors generally allowed for more accurate spatial conclusions accounting for the imprecision of centroids fundamentally alters how the responses and resulting distributions are interpreted levin 1992 while the effect of one factor may be prominent at a fine scale its effect may be negligible at another schweiger and beierkuhnlein 2016 hortal et al 2010 described how as scale coarsens the impact of biotic factors on insect distribution decreases and abiotic factors effects increase mouton et al 2009 suggested that data driven sdms such as automated predictors outperformed expert models as predictors were selected based on the available scale thus providing a more reliable interpretation therefore automated predictor selection estimates ecologically important predictors at the provided scale to better represent the responses at the observed over expected responses the overall probability of occurrence predictions was only moderately accurate with low generality suggesting marginal usefulness in application some studies suggest that lower degrees of scale coarsening preserved environmental characteristics guisan et al 2007b trivedi et al 2008 bombi and d amen 2012 but generally scale coarsening decreased sdm predictive performance rahbek and graves 2001 thompson and mcgarigal 2002 guisan et al 2007a seo et al 2009 mertes and jetz 2018 the degree of scale coarsening observed in this study table s2 did not reflect those of the lower degree previously described 10 km2 and therefore supported decreased performance at coarse scales our observed performance reflected a greater decrease in predictive ability than in previous centroid applications johnson et al 2017 applied centroids of a aegypti and a albopictus across the contiguous u s counties and observed good area under the receiver operating characteristic curve scores but without independent validation similarly collins et al 2017 compared sdms trained with precise or centroids occurrences to investigate the degree of bias introduced for butterfly dragonfly and damselfly species in the contiguous u s counties niche similarity metrics indicated centroids only somewhat compromised predictions with the effect more pronounced in larger and environmentally heterogenous counties which could not be accounted for by boundary scale collins et al 2017 one possible explanation for decreased degradation in our study is that all previous studies investigated administrative regions within a single country in contrast we applied centroid occurrences across administrative regions of three countries consequently across country considerations resulted in a more considerable variation in size and shape of boundaries thereby leading to greater uncertainty and instability of predictors by maup openshaw 1984 specifically larger and more heterogeneous administrative regions introduced greater predictor uncertainty namely boundaries in the western u s or canada collins et al 2017 cheng et al 2021 4 4 presence absence map prediction of species presence or absence tended to over predict presence with some cases of under prediction depending on the methodology methodology considerations for species presence or absence predictions followed the patterns described previously presence absence maps require further review of the threshold considered threshold selection is one of many possible sources of bias in sdms bean et al 2012 in this study we applied a minimum presence threshold fig 4b yet in practice threshold selection should be considered relative to the desired sdm application and the importance of omission and commission errors liu et al 2013 alternatively thresholds derived from the maximization of the sum between sensitivity and specificity or minimization of the difference between sensitivity and specificity are generally seen as superior to others or authors may examine an overlay of different thresholds to determine suitable areas liu et al 2005 jiménez valverde and lobo 2007 to our knowledge no studies have investigated the effect of binary threshold choice associated with maup or administrative geopolitical boundary centroids 4 5 implications management of mosquito populations often focuses on chemical or biological agents to limit of reproduction and spread yet these management practices require fine scale and precise predictions to be effective which are not captured using centroids fouet and kamdem 2019 pascoe et al 2019 our results indicated the prediction of only administrative regions at the highest risk of establishment while misclassifying lower density of true occurrence sites this suggested that with very careful consideration of sdm methods centroids can be used to predict boundaries at the highest risk of arthropod vector establishment if sufficient propagules are introduced in new boundaries these corresponding boundaries would be encouraged to enact public education campaigns and increase vector surveillance however sdms consistently missed lower risk areas which may indicate early detection this highlighted the loss of environmental detail with the use of centroids therefore the corresponding sdms are unsuitable for estimating regions with isolated risks such as micro niches further investigations on a local scale or with more precise requirements would be required to provide management applications additional or alternative methods may accomplish this may be necessary to provide reliable conclusions from centroids by applying mixed effect models hamil et al 2016 bayesian velásquez tibatá et al 2016 integration methods collins et al 2017 pacifici et al 2019 or considering movement and biotic factors in addition to abiotic soberón and peterson 2005 centroid responses and resulting ecologically insignificant scales in sdms are not limited to a aegypti and a albopictus approximately half of the occurrences from species of all major taxonomic groups are limited to centroids in occurrence repositories in the u s park and davis 2017 the results of this study provide guidance to improve centroid application in sdms but not conclusive guidelines virtual species ensure sdm assumptions are met including that occurrence records are precise entire geographic and environmental extent are sampled without bias species are at equilibrium and they provide a known truth for evaluation guisan and zimmermann 2000 conversely using a virtual species may bias the results as it gives a simplified distribution based on limited environmental conditions without movement or biotic impacts the results here reflect the ability of sdms to determine appropriate ecologically important predictors estimate responses predict probability and presence only if the species responses are based on a combination of β logistic and linear responses we selected these responses to ensure ecological realism given ecological and physiological studies of a aegypti and a albopictus considering linear and non linear responses limited potentially bias towards a particular analysis hirzel et al 2001 other responses may not observe the same results thus re enforcing the need to test models for the given data and objective for example many regression and tree based sdms poorly model linear responses as the logit link and grouping strategies are non linear and represent a threshold response meynard and quinn 2007 additionally we defined the virtual species from a multiplicative formula yet we trained sdms with additive formulas this allowed for the interaction of environmental conditions on species occurrence while maintaining common practice in sdms as shown by the default settings of an additive formula for most sdms elith et al 2006 meynard and quinn 2007 meynard and quinn 2007 examined sdm discrimination ability of virtual species determined by additive and multiplicative habitat suitability indexes they found that additive and multiplicative training followed similar performance patterns but varied depending on the evaluation metric future sdm investigations of centroids may contrast our findings if trained with multiplicative rather than additive formulas therefore one major limitation was considering a single virtual species across sdms as additional virtual species would allow more variation in the known habitat suitability additionally it is important to note we examined all sdms under default settings default settings may have improved the performance of one sdm over another for example the default interaction depth of gbms and multiple adaptive regression splines have a default interaction depth of seven and zero respectively further default settings allowed gbms to have greater maximum number of trees and minimal number of observations per node than random forest and classification tree table s3 these would allow gbms to resemble the original multiplicative suitability index more closely as well as a greater ability to determine the differentiate between environmental condition importance presence and absence if all algorithms were fine tuned to the provided data we may have observed different results merow et al 2013 araújo et al 2019 future work is required to determine if our results hold across taxonomic groups credit authorship contribution statement justin r barker conceived the study collected analyzed the data and drafted the manuscript hugh j macisaac conceived the study revised and approved the manuscript declaration of competing interest the authors declare that they have no conflict of interest acknowledgments funding was provided by nserc discovery grant and canada research chair to hjm supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2022 110107 appendix supplementary materials image application 1 image application 2 image application 3 
24384,the northern humboldt current system is the most productive eastern boundary upwelling system generating about 10 of the global fish production mainly coming from small pelagic fish it is bottom up and top down affected by environmental and anthropogenic variability such as el niño southern oscillation and fishing pressure respectively the high variability of small pelagic fish in this system as well as their economic importance call for a careful management aided by the use of end to end models this type of models represent the ecosystem as a whole from the physics through plankton up to fish dynamics in this study we utilised an end to end model consisting of a physical biogeochemical model croco bioebus coupled one way with an individual based fish model osmose we investigated how time variability in plankton food production affects fish populations in osmose and contrasted it against the sensitivity of the model to two parameters with high uncertainty the plankton accessibility to fish and fish larval mortality relative interannual variability in the modelled fish is similar to plankton variability it is however small compared with the high variability seen in fish observations in this productive ecosystem in contrast changes in larval mortality have a strong effect on anchovies in osmose it is a common practice to scale plankton food for fish accounting for processes that may make part of the total plankton in the water column unavailable we suggest that this scaling should be done constant across all plankton groups when previous knowledge on the different availabilities is lacking in addition end to end modelling systems should consider environmental impacts on other biological processes such as larval mortality in order to better capture the interactions between environmental processes plankton and fish keywords ecosystem modelling osmose end to end model croco bioebus northern humboldt current system eastern boundary upwelling system fisheries higher trophic levels trophic interactions physical biogeochemical model data availability the model code and output are available on request for requests regarding the observational data used to calibrate the model we refer to imarpe which provided this data 1 introduction the northern humboldt current system nhcs located in the eastern tropical south pacific etsp ocean is the most productive eastern boundary upwelling system generating about up to 10 of the global fish production chavez et al 2008 fao 2020 it hosts the largest single species fishery of the planet the peruvian anchovy engraulis ringens chavez et al 2003 aranda 2009 along with the pacific sardine sardinops sagax these small pelagic fish feed on plankton and build up huge biomasses that support a large industry of fishmeal production they are also valued by the local communities culturally lópez de la lama et al 2021 and economically christensen et al 2014 and are consumed by many marine predators such as seabirds muck 1987 jahncke et al 2004 marine mammals majluf and reyes 1989 and larger predatory fish pauly et al 1987 however they have shown to be prone to collapses related to environmental variability along with overfishing boerema and gulland 1973 putting at risk the fishing industry paredes and gutierrez 2008 the drivers behind the disproportionately large fish production of the nhcs compared to other eastern boundary upwelling systems are not fully understood carr 2002 possible explanations include the reset of the system succession to small pelagic fish during the el niño periods bakun and broad 2003 the compression of zooplankton prey for small pelagic fish at the surface by a shallow oxygen minimum zone and increased trophic transfer efficiency caused by relatively weak winds in combination to high primary production chavez and messié 2009 the etsp is affected by strong interannual variability in addition to the el niño and la niña events the etsp is subjected to regimes of cold ocean temperature named la vieja and warm temperature called el viejo chavez et al 2003 anchovies and sardines also fluctuate interannually with regimes of high anchovy abundance alternating with regimes of high sardine abundance schwartzlose et al 1999 chavez et al 2003 causes for these fluctuations are not completely clear and have been related to interannual variability in water temperature chavez et al 2003 between the 1970s and 1990s the ecosystem was under a regime of abundant sardines the regime shifted during the 1990s towards an anchovy dominated ecosystem anchovy collapsed during the el niño of 1998 but managed to recover while sardines continued declining to almost no presence by 2000 chavez et al 2003 alheit and niquen 2004 in addition red squat lobsters pleuroncodes monodon a generally benthic species off central chile but mostly pelagic off peru gutiérrez et al 2008 became particularly abundant in the pelagic system after this event gutiérrez et al 2008 finally the system is both bottom up and top down affected by environmental and anthropogenic drivers such as changes in temperature and productivity due to el niño southern oscillation and fishing pressure respectively boerema and gulland 1973 barrett et al 1985 barber and chavez 1983 the high and poorly understood temporal variability of fishes in the nhcs as well as their importance for the economy food security and the rest of the ecosystem call for a careful and sustainable fisheries management using an ecosystem based management approach supported by end to end models pikitch et al 2004 end to end models aim at representing the marine ecosystems as a whole by including environmental components as well as lower plankton and higher trophic levels htl such as fish and their utilisation by humans common ecosystem models represent functional groups or individual species interacting in a trophic web see fulton 2010 tittensor et al 2018 for reviews end to end models also include primary producers such as plankton which are affected by the environment either already included in the model e g atlantis fulton et al 2004 or provided by physical biogeochemical models e g pisces apecosm maury 2010 among other types of ecosystem models the multispecies individual based models are as detailed as simulating the single individuals or schools of fish e g rose et al 2015 belonging to such type of models the object oriented simulator of marine ecosystems osmose simulates the whole life cycle of fish shin and cury 2001 2004 www osmose model org accessed 2021 10 28 it is usually one way coupled with biogeochemical models which provide lower trophic levels or plankton as food for some of the fish in the ecosystem e g halouani et al 2016 moullec et al 2019b in this study we simulated the etsp ecosystem with a one way coupled model system including a physical biogeochemical model coastal and regional ocean community model croco biogeochemical model developed for the eastern boundary upwelling systems bioebus shchepetkin and mcwilliams 2005 gutknecht et al 2013 and osmose as htl model to improve the model fit to observations models have to be calibrated by adjusting model parameters for which no values are available easily or unambiguously from literature using optimisation algorithms here in particular evolutionary algorithms provides an automated and objective way for calibration and can converge to solutions that may not be reached manually or analytically when handling complex models duboz et al 2010 oliveros ramos and shin 2016 yet the strong variability in physical forcing and in fish abundance observed in the nhcs makes the calibration of osmose for this specific ecosystem challenging osmose has been implemented in several ecosystems using time constant parameters to represent a steady ecosystem state travers et al 2006 fu et al 2012 grüss et al 2015 halouani et al 2016 xing et al 2017 bănaru et al 2019 moullec et al 2019b which can serve as a starting point for evaluating the ecosystem response under changing conditions e g fu et al 2012 moullec et al 2019a diaz et al 2019 travers trolet et al 2014b marzloff et al 2009 developed a configuration of osmose with time constant parameters for the pelagic ecosystem off peru using years 2000 to 2006 as reference for the calibration just after the regime shift of 1998 on the other hand oliveros ramos et al 2017 addressed the interannual variability of the nhcs by calibrating time varying parameters the resulting configuration matched the seasonal and interannual fluctuations in observations this approach implicitly assumes that the observed variability in fish may be caused by processes that need to be accounted for by temporally varying parameter values and it provides an estimation for such parameters however it might dampen any variability caused bottom up by fluctuations in physical forcing and its propagation to plankton biomass on the other hand using constant parameters allows to isolate the impact of time variability in the forcings the aim of this study is to understand the sensitivity of osmose to temporal variability in plankton food estimated by a physical biogeochemical model and whether this replicates the temporal variability that has historically been observed in fish to do so we first calibrated osmose against biomass and landings data of nine fish and invertebrate species from the post el niño low sardine regime between 2000 and 2008 period in which no strong el niño event occurred to investigate the potential relevance of bottom up causes of fluctuations of fish biomass we decided here to apply a configuration of osmose for the etsp with calibrated temporally constant parameters such a set up allows to systematically probe the ecosystem regarding its response to variability of food for calibration osmose was forced with a plankton climatology that we obtained from the biogeochemical model croco bioebus hindcast over the time period from 2000 to 2008 we then forced the calibrated osmose configuration with an interannually varying biogeochemical hindcast from 1990 to 2010 to assess whether or not the plankton forcing alone could generate the regime shift after the el niño of 1998 in osmose to put the effects of interannual forcing into perspective we also carried out sensitivity experiments varying two different parameters of the osmose model which are either directly related to the food availability of the biogeochemical model or address the larval mortality of fish species these parameters have high uncertainty and in previous studies have often been adjusted to calibrate osmose we also evaluated both croco bioebus and osmose since this is a pre condition for performing the experiments the results of this study provide insight on advisable improvements for the connection of osmose with biogeochemical models for a better representation of the effect of environmental variability in end to end models 2 methods 2 1 the lower trophic levels model croco bioebus we used the coastal and regional ocean community model croco shchepetkin and mcwilliams 2005 coupled online with a biogeochemical model developed for eastern boundary upwelling systems bioebus gutknecht et al 2013 the model domain spans from 10 n to 33 s and from 69 to 118 w with a horizontal resolution of 1 12 and 32 sigma layers bioebus consists of 12 prognostic variables oxygen ammonium nitrate nitrite nitrous oxide dissolved organic nitrogen small and large detritus small and large phytoplankton and small and large zooplankton initial and boundary conditions for croco bioebus are from simple ocean data assimilation soda carton et al 2018 and monthly climatology cars csiro commonwealth scientific and industrial research organisation atlas of regional seas observations ridgway et al 2002 croco bioebus is spun up for 30 years repeating the forcing of year 1990 afterwards it is simulated from 1990 to 2010 with interannually varying forcing the configuration used in this study is described in detail by josé et al 2019 and a list of the parameters that were adjusted for this configuration is available in xue et al 2022 for coupling with osmose the four plankton groups small and large phyto and zooplankton were integrated above the oxygen minimum zone omz here defined by an oxygen threshold of 90 μ m ol o2 kg 1 karstensen et al 2008 and integrated biomasses were transformed from nitrogen to wet weight ww main currency in osmose by multiplying them by the conversion factors 720 720 675 and 1000 mg ww mmol n 1 respectively travers trolet et al 2014a their tab 4 regridded from 1 12 to 1 6 resolution and then provided as food forcing for the fish in osmose see section 2 2 since croco bioebus provides daily plankton food output we averaged the plankton food to produce bi weekly forcing for osmose 2 2 the higher trophic levels model osmose osmose is an object oriented individual based model that simulates the whole life cycle of fish from eggs to adults individual fish are grouped in schools of the same size and age these are distributed over a 2 dimensional grid and within species and life stage specific distribution maps that are produced by statistical climate niche models oliveros ramos et al 2017 on every time step each school moves randomly to one adjacent grid cell within its distribution map predation is opportunistic based on the spatial overlap of predator and prey every species or group feeds on prey that falls within certain minimum and maximum predator prey size ratios the predator feeds until either being satiated or until the available prey runs out satiation depends on the biomass of the predator the number of mortality sub steps and a constant maximum ingestion rate which in our configuration is the same for all groups see appendix a 2 in consequence predatory interactions are not set a priori by the model user but these emerge from the size structure of the populations a full description of the model is available in shin and cury 2001 2004 and travers et al 2009 2 2 1 configuration overview the configuration in this project uses osmose version 3 3 3 and was derived from the configuration by oliveros ramos et al 2017 which covers the same region from 20 s to 6 n and from 93 to 70 w see fig 1 bottom spans from 1992 to 2008 and was calibrated against interannually varying observations for our configuration we averaged the observations from 2000 to 2008 to produce a configuration representative of this period of time after the strong el niño of 1998 observations were available for all groups simulated in the model for this period of time we also averaged the plankton simulated by croco bioebus from 2000 to 2008 to produce a plankton climatology as forcing for osmose this time period is dominated by anchovies while sardines were dominant through the 1980s and decreased during the 1990s until their final collapse after the el niño event of 1997 1998 chavez et al 2003 although for the period that we used to calibrate the model 2000 to 2008 sardines play a minor role they are an important component of the ecosystem in the long term so we included them in the configuration we set up a configuration with constant parameters to generate a mechanistic model that can be used to understand the ecosystem response to certain forcings such as fishing pressure and environmental changes in sensitivity studies the configuration for the northern humboldt current system nhcs consists of peruvian anchovy engraulis ringens peruvian hake merluccius gayi pacific sardine sardinops sagax chilean jack mackerel trachurus murphyi pacific chub mackerel scomber japonicus mesopelagic fish squat lobster pleurocondes monodon humboldt squid dosidicus gigas and euphausiids parameters as well as distribution maps for all groups are provided in appendix a 2 and in the supplement the parameters in our configuration are the same as in oliveros ramos et al 2017 with the exceptions mentioned in section 2 2 2 we applied constant annual fishing rates for each species in our climatological set up because anchovies are only fished during certain seasons their landings show a marked seasonality therefore a seasonality of fishing rate was derived from the anchovy landings observations see fig 7 in the appendix a 2 the fishing rate of all other species was assumed to be constant over the year the model is initialised through a seeding process that generates schools of fish at the egg and larval stages during several years at the beginning of the model run after the first 12 years of the spin up the seeding is stopped and all further eggs are only produced by adult fish therefore egg production depends on the amount of adults biomass in osmose the spatial distribution of fish is constrained by maps defining their habitat the maps define the probability of a school to occur on each of the grid cells of the domain with the sum of all wet grid cells equalling 1 in our study the distribution maps of each species vary for every season at the beginning of the season the schools are randomly located over the new map taking into account the probability given by each grid cell we averaged the distribution maps of the configuration mentioned above provided by oliveros ramos and lujan paredes personal communication from 2000 to 2008 to produce a seasonal climatology as part of the analysis performed in section 3 3 we isolated the region where most of anchovies occur to do so we utilised a probability map calculated by averaging all temporally varying maps based on this map first we excluded all cells with a chance of anchovy occurrence equal to 0 as well as the dry cells out of the remaining cells we calculated the mean and then selected those cells with higher probability than the mean there is a probability of around 90 of finding any of the anchovy schools within the region consisting of all selected cells 2 2 2 model calibration the model was calibrated using the evolutionary algorithm developed by oliveros ramos et al 2017 detailed instructions on the calibration are available in the osmose documentation http documentation osmose model org index html the calibration ran for 400 hundred generations using a population size of 75 individuals an individual is a vector of parameter values in this calibration framework per generation for the evolutionary algorithm in every iteration the model was run for 50 years consisting of 25 years of spin up and evaluating against observations the last 25 years of the simulation available observations included biomasses from acoustic surveys integrated over the exclusive economic zone of peru eez and averaged from 2000 to 2008 and monthly landings of exploited species anchovy hake sardine jack mackerel chub mackerel and humboldt squid also averaged from 2000 to 2008 because the acoustic indices only cover the eez of peru we scaled the model output by dividing it by a factor q see table 4 which represents the proportion of the averaged distribution map of each group that falls within the peruvian eez in their configuration oliveros ramos et al 2017 calibrated a time varying larval mortality lm constant natural additional mortality time and size class varying fishing rate time varying plankton accessibility coefficient ac and time varying incoming flux of squat lobster in our climatology no incoming flux of squat lobster is included because the squat lobster is present since the beginning of the simulation and we only calibrated time constant lm and plankton ac time constant natural additional mortalities and fishing rates with a seasonality for anchovies see section 2 2 1 were obtained from the literature see table 4 in addition we manually adjusted the fishing rate of humboldt squid before the calibration process since our configuration had a tendency to overestimate the landings of this species the ac is the fraction of the total plankton that is provided as food for the fish it parameterises a range of processes that affect the availability of plankton for the fish such as turbulence stratification and vertical migrations and distribution see travers trolet et al 2014a literature values of this parameter for osmose vary strongly from very low values of 10 5 marzloff et al 2009 up to 69 grüss et al 2015 our calibration suggested optimal values ac of 3 0 5 0 2 0 and 0 4 for small and large phytoplankton and zooplankton respectively the larval mortality rate lm ts 1 is applied to the first stage of fish in osmose eggs and larvae during its first time step ts of life this parameter is typically calibrated for osmose e g travers et al 2009 marzloff et al 2009 halouani et al 2016 bănaru et al 2019 since field observations are scarce the optimal parameter values are available in table 4 in appendix a 2 after calibrating the model we simulated the configuration for 300 years to evaluate its stability with the calibrated parameters the sardine population collapses after the initial 50 years of simulation see supplement to avoid this decrease we adjusted by hand the natural mortality of juvenile and adult sardine as well as its lm see table 4 in appendix a 2 2 3 model evaluation we evaluated croco bioebus by comparing chlorophyll concentration and large zooplankton against observations see section 3 1 1 simulated phytoplankton concentration was converted to chlorophyll using function get chla m of the croco tools package penven 2019 and compared against modis remotely sensed chlorophyll concentration nasa 2018 a previous version of the model josé et al 2017 strongly overestimated zooplankton in comparison to observations hill cruz et al 2021 therefore for the present study we tuned the model to better match observed concentrations after tuning the model large zooplankton model concentrations were compared against mesozooplankton observations by moriarty and o brien 2013 and o brien and moriarty 2012 which are provided in carbon units for model comparison we transformed the observations to nitrogen dividing by a carbon to nitrogen ratio of 4 9 gc gn kiørboe 2013 and by the nitrogen molar mass of 14 g mol because the model does not parameterise diel vertical migrations simulated zooplankton is only present where food is available within the upper 100 m we therefore compared only the averaged zooplankton in the model and observations over the upper 100 m of the water column further model evaluations of sea surface temperature and mixed layer depth are provided in appendix a 1 simulated oxygen evaluation is available in josé et al 2019 we also evaluated the performance of osmose by comparing trophic levels with literature values section 3 1 2 2 4 experimental design to evaluate the effect and relative importance of an interannual versus a climatological plankton forcing on the simulated biomass of fish and macroinvertebrates we carried out six simulations all simulations ran for 25 years of spin up followed by 21 years of simulation our starting point was the calibrated climatological set up described in section 2 2 2 experiment 1 climatological in this experiment the 46 years run 25 years of spin up and then 21 simulation years have the same climatological plankton forcing with the second and third experiments we explored how interannually varying plankton affects the fish both experiments have an interannual plankton hindcast from 1990 to 2010 as forcing for the 21 years of simulation the spin up however differs in the two experiments to test whether variability in the spin up approach has any impact on the sensitivity of fish to plankton forcing for the second experiment called interannual the spin up consists of four years with climatological plankton forcing and then 21 years of interannual forcing the third experiment hybrid has climatological forcing over the entire 25 years of spin up we also put the impact of interannual plankton forcing into perspective by comparing it against the effect of changing two parameters we modified the plankton accessibility coefficient ac and the larval mortality lm by 10 these parameters were calibrated in the original climatological set up to optimise the model and their uncertainty is high in experiment 4 hybrid ac we evaluated the effect of a reduction in the ac by 10 which translates into less plankton being available as potential food in reality this can be interpreted as for example zooplankton hiding in a shallower oxygen minimum zone or a deeper mixed layer that dilutes phytoplankton in our original climatological osmose configuration we calibrated a different ac for each of the four plankton groups this adds an additional source of variability by changing the relative contribution of each group to the diet of fish we removed this variability in experiment 5 hybrid eqac by setting the ac to a constant value of 10 for all plankton groups we note that this represents a strong increase in the ac which makes the resulting fish biomass of this experiment not directly comparable to the other scenarios therefore for this specific experiment we only analysed the relative fluctuations in biomass with all of the above experiments we investigated the effect of changing food i e the gains of fish biomass either through the forcing or through the ac in a final sixth experiment hybrid alm we investigated how these changes in the gain or food side compare to changes in loss terms of fish by increasing the lm of anchovies by 10 we only manipulated the lm of anchovy in order to avoid an effect obscured by trophic interactions when manipulating the lms of the other groups to make the hybrid alm and hybrid ac experiments comparable we increased the lm and decreased the ac so that both experiments would have a negative impact on the anchovy biomass the six experiments are summarised below 1 climatological 25 years spin up with climatological plankton followed by 21 years of simulation using the same plankton climatology 2 interannual the spin up consisted of 4 years with climatological plankton forcing and then 21 years with interannual forcing after the spin up we simulated an additional 21 years applying the interannual hindcast of plankton from 1990 to 2010 3 hybrid 25 years of spin up time with climatological plankton followed by 21 years of simulation using the interannual hindcast of plankton from 1990 to 2010 4 hybrid ac hybrid set up with ac reduced by 10 5 hybrid eqac hybrid set up with ac of all four plankton groups equal to 10 6 hybrid alm hybrid set up with anchovy lm increased by 10 because osmose is a stochastic model random movement of schools and ordering of mortality events in a time step the output varies slightly among simulations therefore we analysed the average of 20 model runs for each experiment this study explores the effect of plankton variability on osmose therefore we removed other sources of interannual variability for instance habitat by keeping climatological distribution maps in all configurations appendix a 5 provides the results of an alternative set up where interannually varying distribution maps were applied from 1992 to 2008 in the hybrid configuration 3 results 3 1 model evaluation 3 1 1 croco bioebus the model reproduces the temporal variability in chlorophyll observations generally well replicating the seasonal pattern with higher chlorophyll concentrations in austral summer fig 1 top however from 2006 on wards it tends to overestimate chlorophyll especially during the austral summer large zooplankton is generally of the same order of magnitude as mesozooplankton observations fig 1 bottom this is a considerable improvement compared to the older version of the model by josé et al 2017 which was evaluated by hill cruz et al 2021 both model and observations show a high concentration of mesozooplankton in the region near the equator as well as towards the coast of peru within 50 km from the coast large zooplankton declines in the model this is not evident in the observations however this might be due to the low spatial resolution of observational samples further observations show a hotspot of high mesozooplankton concentrations around the galapagos islands which is not visible in the model this could be either a weakness of the model or it could also be an artefact in the observations due to averaging over very few samples for the whole water column an extensive discussion on the possible causes of mismatch between simulated large zooplankton and mesozooplankton observations observed in an earlier version of bioebus is provided by hill cruz et al 2021 3 1 2 osmose after calibrating and hand adjusting the parameters simulated biomass and landings show a good fit to observed estimates for most of the groups and are stable for at least 300 years fig 9 in the appendix a we evaluated the model performance by comparing the trophic levels simulated by osmose fig 2 with literature values table 1 the trophic structure in osmose agrees with the trophic structure of ecopath after plankton euphausiids are the lowest trophic level in the simulation followed by the small pelagic fish humboldt squid and hake are the top predators fig 2 and table 1 for anchovy pizarro et al 2019 observed a trophic level of 3 23 while in our model the trophic level of anchovies lies between 3 1 and 3 4 pizarro et al 2019 point out the presence of two groups of anchovies with different diet preferences one of them with a mean trophic level of 2 91 prefers to graze on phytoplankton and another carnivorous group has a mean trophic level as high as 3 79 pizarro et al 2019 the smaller trophic level range of anchovy in our study is likely due to having a single feeding preference predator prey size ratio range for all schools of the same age class we could not find trophic level estimations for squat lobster however given that it occupies a similar niche to anchovy gutiérrez et al 2008 we may also expect a trophic level around 3 in osmose we observe that it lies between about 2 5 and 3 fig 2 3 2 effect of plankton temporal variability accessibility coefficient and larval mortality on fish biomass the climatological calibration replicates well the time averaged biomass of fish and macroinvertebrates for the averaged time period 2000 2008 fig 9 for most scenarios and groups simulated biomass lies within the large variability in the observations fig 3 the hybrid and the interannual configurations show similar results fig 3 pointing out that the different spin ups do not have a considerable impact on the simulation this is especially evident for the euphausiids fig 4 right where both simulations converge after exhibiting different trajectories during the spin up this may suggest that the initial conditions are also not so important in osmose once it reaches steady state when comparing these two experiments with the climatological simulation the effect of introducing interannual variability in food is evidenced by the appearance of clear interannual fluctuations in euphausiids biomass and an increase in their mean biomass fig 4 right when introducing interannual variability in the plankton most of the simulated higher trophic levels exhibit interannual fluctuations of about 5 to 10 in their running mean with respect to the climatological set up see appendix a 5 in the hybrid configuration anchovy and euphausiids exhibit a maximum relative interannual variability of 8 8 and 14 6 of the mean value respectively however in the climatological run they also exhibit an interannual variability of about 4 1 and 1 1 respectively here we are referring to interannual variability as the difference between the maximum and the minimum of the 12 months running mean therefore about half of the interannual variability in anchovies comes from the internal dynamics of osmose rather than from the change in plankton forcing in the case of euphausiids most of the variability can be directly related to the change in plankton forcing this is also evident when comparing the hybrid and interannual configuration both experiments exhibit almost the same results for the euphausiids but they differ in the case of anchovies fig 4 such difference does not come from the plankton input but rather from the stochasticity and trophic interactions through the foodchain in osmose while the hybrid and interannual runs do show a different pattern than the climatological run their interannual fluctuations tend to be small compared to the high temporal variability in the observations other groups show almost no difference between the climatological and the interannual and hybrid configurations two important changes in the ecosystem were observed after the el niño of 1998 an increase in pelagic squat lobster and a complete collapse of sardines these are not replicated by the model which keeps all groups relatively constant before and after the el niño fig 3 and highlights the importance of including other sources of temporal variability in end to end models such as species spatial distribution in addition to food see appendix a 5 we also investigated the importance of total food concentration on fish biomass by reducing the plankton accessibility coefficient ac by 10 the reduction leads to a small decrease in fish biomass fig 3 both decreasing ac and increasing the lm of anchovy by 10 have a negative impact on anchovy however the impact of the lm is much larger than the impact of the ac fig 3 increasing anchovy lm also affects other species and in some cases the impact is also larger than the impact of the decreased ac therefore in this configuration the lm plays a greater role in controlling the biomass of fish an extreme case is the squat lobster whose biomass presents little change with decreased ac but almost doubles in the scenario with high anchovy lm fig 3 this evidences the same niche utilisation of the two species 3 3 further assessment of plankton accessibility coefficient effect on model temporal variability the plankton accessibility coefficient ac is a parameter that scales the plankton available for fish to eat because the ac was calibrated for each plankton group individually its differences across plankton groups low for large zooplankton and higher for the other groups might mask the impact of seasonal or temporal variability of plankton on fish to further investigate this issue in fig 5 we examined the total amount of plankton i e without multiplication by ac and the variation of plankton as food after multiplication by ac for this specific analysis we focused on the anchovy habitat therefore we isolated the region inhabited by about 90 of the anchovies fig 5 right as explained in section 2 2 1 the maximum interannual variability of total plankton in this region is 21 and 18 with and without the calibrated plankton accessibility coefficient respectively and the maximum seasonal variability is 18 and 19 fig 5 left and middle thus the interannual variability of total plankton in this region as food is increased by the ac as much as 3 furthermore applying a plankton ac shifts the seasonal peak of highest food availability from october to may fig 5 middle finally we assessed the effect of applying the same ac to all plankton groups in osmose in addition to the ac the food availability to each fish group is also affected by the predator prey size ratio and not all plankton groups are preyed by all planktivorous fish for example sardines prey on small particles such as plankton while anchovies prefer euphausiids the temporal variability of plankton comes directly from the biogeochemical model while euphausiids are explicitly represented in osmose and affected by the variability of their main plankton prey but also the trophic interactions with their predators therefore interspecies competition and predation between species of osmose may also play a role possibly causing non linear effects to further investigate this in a final experiment hybrid eqac we set the ac parameter to a constant value of 10 for every plankton group thereby omitting any effects caused by the different ac values for analysis we focused on the impact of this change on the diet of euphausiids which are the main planktivorous group in osmose and constitute about 85 of the anchovies diet the large homogenous ac of 10 increases the contribution of large zooplankton to the diet of euphausiids six times from only 3 to 18 6 table 2 furthermore setting up an equal ac for all groups also decreases the direct consumption of large phytoplankton by euphausiids by almost half table 2 this group is replaced by small zooplankton as the main prey of euphausiids this implies that the temporal variability of zooplankton has a greater impact on euphausiids as well as their subsequent predators 4 discussion 4 1 modelling temporal variability in the nhcs our study shows an effect of temporal variability in the biogeochemical model on higher trophic levels htl this variability is similar to the plankton forcing coming from the biogeochemical model the interannual variability in htl in osmose is however weak compared to the variability in observations and it does not replicate the regime shift after the el niño event of 1998 this discrepancy between model and observations may be attributed to several reasons first it is possible that the plankton temporal variability in the croco bioebus model is in fact too weak the plankton interannual variability observed in our plankton forcing which is close to 20 of the mean section 3 3 is much lower than the variability in anchovy observations however compared to satellite data see section 3 1 1 the surface chlorophyll in the model displays a similar variability around 20 of the mean see section 3 1 1 a second reason may be that the link between the biogeochemical model croco bioebus and the htl model osmose is too weak this link is done only through plankton food forcing for juvenile and adult fish other possible links may include the effect of oxygen temperature and food availability on larval survival and through interannually varying distribution maps temperature and oxygen are some of the variables that were considered when developing the distribution maps for constraining the habitat of the fish see oliveros ramos 2014 in appendix a 5 we provide an alternative configuration where additional interannual variability is introduced by applying interannual distribution maps instead of climatological ones however the direct impact of temperature on the physiology of the fish is not considered in osmose this may be relevant for future developments especially considering increasing temperatures due to climate change see penn and deutsch 2022 metabolic needs of swimming against currents and non random movement of individual schools such as searching for food and avoiding predators are also not considered in the model this proved to be relevant in the modelling study by watson et al 2015 it may also be that in the real ocean there is not a straightforward bottom up control of htl as supported by ayón et al 2004 they found no significant correlation between zooplankton and anchovy observations off peru between the period of 1984 to 2001 pointing to other potential drivers than food production therefore the main driver of the interannual variability in the nhcs might not be as simple as adult fish following the trends in plankton food this may be a peculiarity of the nhcs that makes the modelling of this ecosystem so challenging simulating environmental variability in osmose only through changes in plankton food for juvenile and adult fish has in fact produced stronger impacts in other ecosystems fu et al 2012 evaluated the effects of interannual variability in plankton input on their osmose model configuration for the strait of georgia in british columbia canada in their study interannual variability in phytoplankton produced strong effects of more than 50 on their small forage fish herring fu et al 2012 their figure 5a this is much larger than the response observed in our study in contrast interannually varying plankton in our study produces a change of about 5 to 10 in the biomass of most of the simulated htl groups see appendix a fourthly the period simulated in the nhcs is rather than a steady state el niño new steady state setting a part of a longer trend of interannual and multidecadal fluctuations in the ecosystem anchovy and sardine have been the two small pelagic fish fisheries with the highest catches since the 1960s these fishes fluctuate over the years with periods dominated by anchovies and others by sardines chavez et al 2003 the period from 1990 to 2010 corresponds to a progressive decrease of sardines and an overtake by anchovies to simulate these fluctuations a longer timeseries would be necessary this however is limited by the availability of data furthermore while our configuration includes the biggest pelagic macroinvertebrate and demersal fisheries off peru produce 2013 it may require other ecosystem components to account for the main drivers affecting these fisheries as a demersal species hake feeds on both pelagic and benthic fish species as well as euphausiids ware 1992 however in our configuration we only accounted for pelagic prey hence the variability in this species is missing the effects of its benthic prey in addition a possible explanation for the high production of the nhcs is the resetting of the system every few years by el niño events that impact both forage fish and their predators since higher trophic levels usually have longer generation times and take longer to recover this opens a loophole for forage fish to dominate the succession bakun and broad 2003 bertrand et al 2004 however we are missing apex predators in osmose the top predators in our configuration are the humboldt squid and the demersal fish hake but we are missing other groups such as marine mammals and sharks taylor et al 2008 achieved some level of interannual variability in an ecopath with ecosim configuration of the nhcs utilising a fit to time series routine that evaluated different predator prey interactions emphasising the importance of trophic dynamics their configuration included among other animals seabirds chondrichthyans cetaceans and pinnipeds while not containing as many groups as ecopath osmose in contrast allows for a detailed spatial representation of species with explicit life cycles and can take input from a biogeochemical model with finely resolved nutrient cycles finally the representation of survival of larvae may be of fundamental importance to our knowledge the study by oliveros ramos et al 2017 is the only modelling project with osmose that has successfully replicated the regime shift after the el niño event of 1998 they achieved this in addition to including interannual distribution maps by calibrating time varying parameters while such an approach successfully replicates the interannual variability in the system it masks the interactions between the biogeochemistry and htl because the temporally varying model parameters account for all temporal variability which is not necessarily justified not allowing to pinpoint processes for instance in oliveros ramos et al 2017 their figure 10 anchovy larval mortalities lm fluctuated more than 2 fold around the central value in our study we found that osmose is very sensitive to the value of lm with only a 10 change decreasing the biomass of anchovy by more than half the impact is much stronger than the effect caused by a 10 decrease in available food this suggests that the key to reproduce the interannual variability of the fisheries in the nhcs may not be in the food provided to adults but rather on the survival of larvae 4 2 towards a better parameterisation of larval mortality understanding the drivers of recruitment is essential to assess the growth of a population and in turn its maximum sustainable yield the maximum sustainable yield is the maximum amount of fish that can be taken from the system while keeping the population growth at sustainable levels past studies emphasise the importance of recruitment and mortality on the growth rate of fish populations tsikliras and froese 2019 in osmose recruitment is affected by the mortality of larvae therefore in this section we discuss the larval mortality in osmose and how to improve its parameterisation sources of larval mortality can be divided in four categories 1 mortality related to parents condition and variability among eggs 2 abiotic factors such as temperature 3 starvation and 4 predation predation 4 is already explicitly included in osmose the other factors are represented by the larval mortality parameter lm which accounts for mortality during the first 15 days of life of eggs and larvae it intends to account for processes that happen during the earliest life stages of fish when mortality is very high but hard to estimate from empirical studies for instance spatio temporal match between larvae and plankton allows fish recruitment cushing 1990 in upwelling regions this occurs at an optimal wind stress cury and roy 1989 cushing 1990 in this way the lm parameter in osmose also accounts for the impact of environmental processes on larvae such as wind dependence mixing our osmose configuration proved to be highly sensitive to the lm parameter following the setting up of other osmose configurations e g vergnon et al 2008 marzloff et al 2009 travers et al 2009 fu et al 2012 grüss et al 2015 halouani et al 2016 we estimated this parameter during the calibration process of the model therefore it was used in combination with the plankton accessibility coefficient ac to adjust the fish biomass to observed levels alternatives to calibrating this parameter may include to find a mechanistic representation of the fine scale larvae dynamics in relation to the physical environment and food availability this could resolve starvation 3 and abiotic causes of mortality 2 leaving only causes related to individual variability 1 to be calibrated in table 3 we compare survival derived from larval mortalities of sardine jack mackerel and anchovy against values provided by dahlberg 1979 the daily survival rates in osmose are smaller than in dahlberg 1979 table 3 however this comparison has to be taken with caution since the egg and first feeding larvae period in osmose 15 days is shorter than the periods reported by dahlberg 1979 table 3 therefore the high mortality of the initial days of life of fish is concentrated over a shorter timeframe and it is not surprising that the survival rates are lower finding a mechanistic link between the lm and the environmental drivers will be a crucial step in the development of end to end models roy 1993 found a relationship between wind speed and recruitment of anchovy and sardine populations in several eastern boundary upwelling systems this is based on the hypothesis that low wind and upwelling is linked to low primary productivity and recruitment high wind speeds on the other hand generates strong mixing that disperses larvae away from the food therefore there is an optimal environmental window cury and roy 1989 where the wind is neither too strong nor too weak and maximum recruitment is achieved roy 1993 from a modelling perspective lett et al 2008 proposed an explicit simulation of the larval stages of fish as a lagrangian individual based model with salinity temperature and velocity inputs a simple experiment to increase the effect of food availability on fish in osmose is to link the lm to the food availability through a linear relationship other potential improvements for the larval parameterisation in osmose may include to either link the lm parameter to environmental conditions for instance through the relationship found by roy 1993 or to include a whole new larval sub model in osmose similar to the one proposed by lett et al 2008 brochier et al 2008 simulated anchovy larval survival off the coast of peru based on a hydrodynamic model simulating larval drift and also considering lethal temperature egg buoyancy and active vertical swimming of the larvae the temporal dynamics of their results roughly resemble the seasonality in observations while no interannual variability was taken into account this approach shows potential for resolving larval dynamics in a mechanistic way the time series of estimated larval mortalities by oliveros ramos et al 2017 provides a good fitting hindcast a statistical relationship with the physical parameters and traces of the biogeochemical model could then be derived to produce estimates for future projections this may not only reduce the uncertainty in the lm but because lm and ac act in opposite directions it would potentially also provide insights into better estimations of the ac during the calibration process by reducing the number of parameters to be optimised there is no model that fits all purposes but models are useful tools to investigate certain questions every question however poses specific requirements for the model osmose was originally developed to investigate trophic interactions among htl such as fish shin and cury 2001 2004 at this time fish schools were divided into piscivorous and non piscivorous fish and their maximum populations were regulated by a carrying capacity shin and cury 2001 2004 later on it was modified to also include explicit food forcing from plankton groups travers 2009 which could be derived from satellite and surveys data marzloff et al 2009 or biogeochemical models travers et al 2009 at this point a carrying capacity parameter was not necessary anymore since limited resources were explicitly modelled however the ac was implemented to scale the biomass of plankton that is available to the fish the reasoning behind is that not all plankton in the water column is available for the fish to feed travers et al 2009 this parameter is however poorly understood and it is usually calibrated a blind calibration of the ac may however obscure the interactions between higher and lower trophic levels in the end to end model the study by travers trolet et al 2014b a looked at the combined effects of top down and bottom up pressures on a two way coupled n 2 p 2 z 2 d 2 osmose model system the fish to plankton feedback was achieved by calculating a mortality map of plankton based on the consumption by fish the maximum consumption of every plankton group was given by the ac which came from a calibration since in a two way coupling system fish consumption has a direct impact on zooplankton mortality the ac might also affect the biogeochemistry of the model therefore special attention has to be taken for the choice of this parameter 5 conclusion we set up a climatological configuration for the northern humboldt current system coupling the higher trophic levels model osmose with the physical biogeochemical model croco bioebus the calibrated model replicates well the mean biomass between 2000 and 2008 of most of the groups in a steady state changing the climatological plankton forcing to an interannual time series introduces temporal variability in the ecosystem however it does not replicate the strong fluctuations in fish especially sardine and anchovy observed before and after the el niño event of 1998 the inability of our model to replicate the regime shift may arise from the period between 1990 and 2010 not being in a steady state like our configuration but being a transitionary state from a sardine to an anchovy dominated regime covering a longer time series might help to capture longer term fluctuations in addition other processes should be assessed as potential major drivers of variability temporal changes in the habitat of fish may be an additional source of interannual variability these were included by oliveros ramos et al 2017 as interannually varying distribution maps based on statistical methods in climate projections these could be directly linked to the variables in the ocean circulation biogeochemical model linking other environmental drivers for instance temperature and oxygen with life stages of higher trophic levels for instance larvae may shed light into the main causes of the strong fluctuations of small pelagic fish in the northern humboldt current system this in turn may reduce the uncertainty in the plankton accessibility coefficient which is the most poorly constrained parameter in osmose when the main goal of using osmose is to explore the interactions between higher trophic levels and biogeochemistry including plankton we recommend a thoughtful consideration of what the plankton accessibility coefficient represents in the model for example some of the large zooplankton may perform vertical migrations and hide in the oxygen minimum zone in this case it would not be available for the fish during part of the day and it would require a different accessibility coefficient however if this information is missing while parameters need to be calibrated for evaluating the link between the biogeochemical processes and osmose we recommend to calibrate the same accessibility coefficient for all plankton groups credit authorship contribution statement mariana hill cruz conceptualization methodology formal analysis writing ivy frenger supervision writing julia getzlaff conceptualization supervision writing iris kriest conceptualization supervision writing tianfei xue methodology writing yunne jai shin supervision writing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was funded by the bundesministerium für bildung und forschung bmbf germany through the projects coastal upwelling system in a changing ocean cusco 03f0813 a and humboldt tipping 01lc1823b in addition jg received funancial support by the bmbf funded project co2meso 03f0876a and tx by the china scholarship council 201808460055 simulations and model calibration were carried out using the computing facilities of the norddeutscher verbund zur förderung des hoch und höchstleistungsrechnens hlrn we thank ricardo oliveros ramos and criscely luján paredes for providing the osmose humboldt interannual configuration and distribution maps we also thank ricardo oliveros ramos for providing scientific advice and technical support to this project we thank nicolas barrier for his technical support to the project we thank the instituto del mar del perú imarpe for providing the data to calibrate the model and we thank dimitri gutierrez for facilitating this data finally we thank andreas oschlies for his helpful contribution to the discussion and two anonymous reviewers for their valuable comments to improve the manuscript appendix a a 1 croco sea surface temperature and mixed layer depth the model sea surface temperature sst resembles well satellite observations from 2002 to 2010 fig 6 top the sst increases during el niño event of 1997 1998 in comparison to the rest of the time series fig 6 top the mixed layer depth becomes deeper during el niño event of 1997 1998 fig 6 bottom a 2 higher trophic levels model parameters table 4 provides the parameters used to run osmose the original name of each parameter as it is read by the model is provided fig 7 provides the seasonality of the anchovy landings additional parameters and the distribution maps are provided in the supplement a 3 calibration evolution the calibration ran for 400 generations using 75 individuals the global fitness function evolved from an original global fitness of 521 59 on the first generation to 0 29 on generation 200 from here it only decreased to 0 26 at generation 400 fig 8 shows the evolution of the parameter sets over the first half of the calibration a 4 climatological configuration fig 9 shows biomass and landings in the climatological configuration of osmose over a 300 years run the model resembles well averaged observations against which it was optimised a 5 configuration with interannual distribution maps in this section we provide the relative variability with respect to the climatological configuration see section 2 4 we also examine the hybrid configuration see section 2 4 running with interannually varying distribution maps from 1992 to 2008 instead of climatological distribution maps the initialisation food forcing and parameters are the same as in the hybrid configuration the interannual distribution maps are the same as used by oliveros ramos et al 2017 for most groups introducing interannual variability in plankton produces a relative change of around 5 to 10 fig 10 changing the larval mortality of anchovy in addition to the interannual variability in plankton has a larger impact in all groups except for the humboldt squid than only introducing interannual variability in the plankton fig 10 applying interannual variability to the distribution maps has a visible impact on the fish when compared to using climatological maps fig 10 compared to the hybrid configuration in the configuration with interannual maps some of the groups for instance humboldt squid exhibit a stronger interannual variability fig 10 in all experiments but the climatological set up sardines get destabilised and exhibit a continuous decline throughout the time series fig 10 a 6 plankton interannual and seasonal variability plankton has interannual and seasonal variability these are highly affected by the accessibility coefficient intv 13 and 9 1 and seasv 19 and 27 fig 11 in the full domain on the other hand the accessibility coefficient has a smaller effect when considering only the anchovy habitat see section 3 for a description of the anchovy habitat intv and seasv differences are only 3 and 1 respectively fig 11 appendix b supplementary data supplementary material related to this article can be found online at https doi org 10 1016 j ecolmodel 2022 110097 appendix b supplementary data the following is the supplementary material related to this article mmc s1 understanding the drivers of fish variability in an end to end model of the northern humboldt current system supplement 
24384,the northern humboldt current system is the most productive eastern boundary upwelling system generating about 10 of the global fish production mainly coming from small pelagic fish it is bottom up and top down affected by environmental and anthropogenic variability such as el niño southern oscillation and fishing pressure respectively the high variability of small pelagic fish in this system as well as their economic importance call for a careful management aided by the use of end to end models this type of models represent the ecosystem as a whole from the physics through plankton up to fish dynamics in this study we utilised an end to end model consisting of a physical biogeochemical model croco bioebus coupled one way with an individual based fish model osmose we investigated how time variability in plankton food production affects fish populations in osmose and contrasted it against the sensitivity of the model to two parameters with high uncertainty the plankton accessibility to fish and fish larval mortality relative interannual variability in the modelled fish is similar to plankton variability it is however small compared with the high variability seen in fish observations in this productive ecosystem in contrast changes in larval mortality have a strong effect on anchovies in osmose it is a common practice to scale plankton food for fish accounting for processes that may make part of the total plankton in the water column unavailable we suggest that this scaling should be done constant across all plankton groups when previous knowledge on the different availabilities is lacking in addition end to end modelling systems should consider environmental impacts on other biological processes such as larval mortality in order to better capture the interactions between environmental processes plankton and fish keywords ecosystem modelling osmose end to end model croco bioebus northern humboldt current system eastern boundary upwelling system fisheries higher trophic levels trophic interactions physical biogeochemical model data availability the model code and output are available on request for requests regarding the observational data used to calibrate the model we refer to imarpe which provided this data 1 introduction the northern humboldt current system nhcs located in the eastern tropical south pacific etsp ocean is the most productive eastern boundary upwelling system generating about up to 10 of the global fish production chavez et al 2008 fao 2020 it hosts the largest single species fishery of the planet the peruvian anchovy engraulis ringens chavez et al 2003 aranda 2009 along with the pacific sardine sardinops sagax these small pelagic fish feed on plankton and build up huge biomasses that support a large industry of fishmeal production they are also valued by the local communities culturally lópez de la lama et al 2021 and economically christensen et al 2014 and are consumed by many marine predators such as seabirds muck 1987 jahncke et al 2004 marine mammals majluf and reyes 1989 and larger predatory fish pauly et al 1987 however they have shown to be prone to collapses related to environmental variability along with overfishing boerema and gulland 1973 putting at risk the fishing industry paredes and gutierrez 2008 the drivers behind the disproportionately large fish production of the nhcs compared to other eastern boundary upwelling systems are not fully understood carr 2002 possible explanations include the reset of the system succession to small pelagic fish during the el niño periods bakun and broad 2003 the compression of zooplankton prey for small pelagic fish at the surface by a shallow oxygen minimum zone and increased trophic transfer efficiency caused by relatively weak winds in combination to high primary production chavez and messié 2009 the etsp is affected by strong interannual variability in addition to the el niño and la niña events the etsp is subjected to regimes of cold ocean temperature named la vieja and warm temperature called el viejo chavez et al 2003 anchovies and sardines also fluctuate interannually with regimes of high anchovy abundance alternating with regimes of high sardine abundance schwartzlose et al 1999 chavez et al 2003 causes for these fluctuations are not completely clear and have been related to interannual variability in water temperature chavez et al 2003 between the 1970s and 1990s the ecosystem was under a regime of abundant sardines the regime shifted during the 1990s towards an anchovy dominated ecosystem anchovy collapsed during the el niño of 1998 but managed to recover while sardines continued declining to almost no presence by 2000 chavez et al 2003 alheit and niquen 2004 in addition red squat lobsters pleuroncodes monodon a generally benthic species off central chile but mostly pelagic off peru gutiérrez et al 2008 became particularly abundant in the pelagic system after this event gutiérrez et al 2008 finally the system is both bottom up and top down affected by environmental and anthropogenic drivers such as changes in temperature and productivity due to el niño southern oscillation and fishing pressure respectively boerema and gulland 1973 barrett et al 1985 barber and chavez 1983 the high and poorly understood temporal variability of fishes in the nhcs as well as their importance for the economy food security and the rest of the ecosystem call for a careful and sustainable fisheries management using an ecosystem based management approach supported by end to end models pikitch et al 2004 end to end models aim at representing the marine ecosystems as a whole by including environmental components as well as lower plankton and higher trophic levels htl such as fish and their utilisation by humans common ecosystem models represent functional groups or individual species interacting in a trophic web see fulton 2010 tittensor et al 2018 for reviews end to end models also include primary producers such as plankton which are affected by the environment either already included in the model e g atlantis fulton et al 2004 or provided by physical biogeochemical models e g pisces apecosm maury 2010 among other types of ecosystem models the multispecies individual based models are as detailed as simulating the single individuals or schools of fish e g rose et al 2015 belonging to such type of models the object oriented simulator of marine ecosystems osmose simulates the whole life cycle of fish shin and cury 2001 2004 www osmose model org accessed 2021 10 28 it is usually one way coupled with biogeochemical models which provide lower trophic levels or plankton as food for some of the fish in the ecosystem e g halouani et al 2016 moullec et al 2019b in this study we simulated the etsp ecosystem with a one way coupled model system including a physical biogeochemical model coastal and regional ocean community model croco biogeochemical model developed for the eastern boundary upwelling systems bioebus shchepetkin and mcwilliams 2005 gutknecht et al 2013 and osmose as htl model to improve the model fit to observations models have to be calibrated by adjusting model parameters for which no values are available easily or unambiguously from literature using optimisation algorithms here in particular evolutionary algorithms provides an automated and objective way for calibration and can converge to solutions that may not be reached manually or analytically when handling complex models duboz et al 2010 oliveros ramos and shin 2016 yet the strong variability in physical forcing and in fish abundance observed in the nhcs makes the calibration of osmose for this specific ecosystem challenging osmose has been implemented in several ecosystems using time constant parameters to represent a steady ecosystem state travers et al 2006 fu et al 2012 grüss et al 2015 halouani et al 2016 xing et al 2017 bănaru et al 2019 moullec et al 2019b which can serve as a starting point for evaluating the ecosystem response under changing conditions e g fu et al 2012 moullec et al 2019a diaz et al 2019 travers trolet et al 2014b marzloff et al 2009 developed a configuration of osmose with time constant parameters for the pelagic ecosystem off peru using years 2000 to 2006 as reference for the calibration just after the regime shift of 1998 on the other hand oliveros ramos et al 2017 addressed the interannual variability of the nhcs by calibrating time varying parameters the resulting configuration matched the seasonal and interannual fluctuations in observations this approach implicitly assumes that the observed variability in fish may be caused by processes that need to be accounted for by temporally varying parameter values and it provides an estimation for such parameters however it might dampen any variability caused bottom up by fluctuations in physical forcing and its propagation to plankton biomass on the other hand using constant parameters allows to isolate the impact of time variability in the forcings the aim of this study is to understand the sensitivity of osmose to temporal variability in plankton food estimated by a physical biogeochemical model and whether this replicates the temporal variability that has historically been observed in fish to do so we first calibrated osmose against biomass and landings data of nine fish and invertebrate species from the post el niño low sardine regime between 2000 and 2008 period in which no strong el niño event occurred to investigate the potential relevance of bottom up causes of fluctuations of fish biomass we decided here to apply a configuration of osmose for the etsp with calibrated temporally constant parameters such a set up allows to systematically probe the ecosystem regarding its response to variability of food for calibration osmose was forced with a plankton climatology that we obtained from the biogeochemical model croco bioebus hindcast over the time period from 2000 to 2008 we then forced the calibrated osmose configuration with an interannually varying biogeochemical hindcast from 1990 to 2010 to assess whether or not the plankton forcing alone could generate the regime shift after the el niño of 1998 in osmose to put the effects of interannual forcing into perspective we also carried out sensitivity experiments varying two different parameters of the osmose model which are either directly related to the food availability of the biogeochemical model or address the larval mortality of fish species these parameters have high uncertainty and in previous studies have often been adjusted to calibrate osmose we also evaluated both croco bioebus and osmose since this is a pre condition for performing the experiments the results of this study provide insight on advisable improvements for the connection of osmose with biogeochemical models for a better representation of the effect of environmental variability in end to end models 2 methods 2 1 the lower trophic levels model croco bioebus we used the coastal and regional ocean community model croco shchepetkin and mcwilliams 2005 coupled online with a biogeochemical model developed for eastern boundary upwelling systems bioebus gutknecht et al 2013 the model domain spans from 10 n to 33 s and from 69 to 118 w with a horizontal resolution of 1 12 and 32 sigma layers bioebus consists of 12 prognostic variables oxygen ammonium nitrate nitrite nitrous oxide dissolved organic nitrogen small and large detritus small and large phytoplankton and small and large zooplankton initial and boundary conditions for croco bioebus are from simple ocean data assimilation soda carton et al 2018 and monthly climatology cars csiro commonwealth scientific and industrial research organisation atlas of regional seas observations ridgway et al 2002 croco bioebus is spun up for 30 years repeating the forcing of year 1990 afterwards it is simulated from 1990 to 2010 with interannually varying forcing the configuration used in this study is described in detail by josé et al 2019 and a list of the parameters that were adjusted for this configuration is available in xue et al 2022 for coupling with osmose the four plankton groups small and large phyto and zooplankton were integrated above the oxygen minimum zone omz here defined by an oxygen threshold of 90 μ m ol o2 kg 1 karstensen et al 2008 and integrated biomasses were transformed from nitrogen to wet weight ww main currency in osmose by multiplying them by the conversion factors 720 720 675 and 1000 mg ww mmol n 1 respectively travers trolet et al 2014a their tab 4 regridded from 1 12 to 1 6 resolution and then provided as food forcing for the fish in osmose see section 2 2 since croco bioebus provides daily plankton food output we averaged the plankton food to produce bi weekly forcing for osmose 2 2 the higher trophic levels model osmose osmose is an object oriented individual based model that simulates the whole life cycle of fish from eggs to adults individual fish are grouped in schools of the same size and age these are distributed over a 2 dimensional grid and within species and life stage specific distribution maps that are produced by statistical climate niche models oliveros ramos et al 2017 on every time step each school moves randomly to one adjacent grid cell within its distribution map predation is opportunistic based on the spatial overlap of predator and prey every species or group feeds on prey that falls within certain minimum and maximum predator prey size ratios the predator feeds until either being satiated or until the available prey runs out satiation depends on the biomass of the predator the number of mortality sub steps and a constant maximum ingestion rate which in our configuration is the same for all groups see appendix a 2 in consequence predatory interactions are not set a priori by the model user but these emerge from the size structure of the populations a full description of the model is available in shin and cury 2001 2004 and travers et al 2009 2 2 1 configuration overview the configuration in this project uses osmose version 3 3 3 and was derived from the configuration by oliveros ramos et al 2017 which covers the same region from 20 s to 6 n and from 93 to 70 w see fig 1 bottom spans from 1992 to 2008 and was calibrated against interannually varying observations for our configuration we averaged the observations from 2000 to 2008 to produce a configuration representative of this period of time after the strong el niño of 1998 observations were available for all groups simulated in the model for this period of time we also averaged the plankton simulated by croco bioebus from 2000 to 2008 to produce a plankton climatology as forcing for osmose this time period is dominated by anchovies while sardines were dominant through the 1980s and decreased during the 1990s until their final collapse after the el niño event of 1997 1998 chavez et al 2003 although for the period that we used to calibrate the model 2000 to 2008 sardines play a minor role they are an important component of the ecosystem in the long term so we included them in the configuration we set up a configuration with constant parameters to generate a mechanistic model that can be used to understand the ecosystem response to certain forcings such as fishing pressure and environmental changes in sensitivity studies the configuration for the northern humboldt current system nhcs consists of peruvian anchovy engraulis ringens peruvian hake merluccius gayi pacific sardine sardinops sagax chilean jack mackerel trachurus murphyi pacific chub mackerel scomber japonicus mesopelagic fish squat lobster pleurocondes monodon humboldt squid dosidicus gigas and euphausiids parameters as well as distribution maps for all groups are provided in appendix a 2 and in the supplement the parameters in our configuration are the same as in oliveros ramos et al 2017 with the exceptions mentioned in section 2 2 2 we applied constant annual fishing rates for each species in our climatological set up because anchovies are only fished during certain seasons their landings show a marked seasonality therefore a seasonality of fishing rate was derived from the anchovy landings observations see fig 7 in the appendix a 2 the fishing rate of all other species was assumed to be constant over the year the model is initialised through a seeding process that generates schools of fish at the egg and larval stages during several years at the beginning of the model run after the first 12 years of the spin up the seeding is stopped and all further eggs are only produced by adult fish therefore egg production depends on the amount of adults biomass in osmose the spatial distribution of fish is constrained by maps defining their habitat the maps define the probability of a school to occur on each of the grid cells of the domain with the sum of all wet grid cells equalling 1 in our study the distribution maps of each species vary for every season at the beginning of the season the schools are randomly located over the new map taking into account the probability given by each grid cell we averaged the distribution maps of the configuration mentioned above provided by oliveros ramos and lujan paredes personal communication from 2000 to 2008 to produce a seasonal climatology as part of the analysis performed in section 3 3 we isolated the region where most of anchovies occur to do so we utilised a probability map calculated by averaging all temporally varying maps based on this map first we excluded all cells with a chance of anchovy occurrence equal to 0 as well as the dry cells out of the remaining cells we calculated the mean and then selected those cells with higher probability than the mean there is a probability of around 90 of finding any of the anchovy schools within the region consisting of all selected cells 2 2 2 model calibration the model was calibrated using the evolutionary algorithm developed by oliveros ramos et al 2017 detailed instructions on the calibration are available in the osmose documentation http documentation osmose model org index html the calibration ran for 400 hundred generations using a population size of 75 individuals an individual is a vector of parameter values in this calibration framework per generation for the evolutionary algorithm in every iteration the model was run for 50 years consisting of 25 years of spin up and evaluating against observations the last 25 years of the simulation available observations included biomasses from acoustic surveys integrated over the exclusive economic zone of peru eez and averaged from 2000 to 2008 and monthly landings of exploited species anchovy hake sardine jack mackerel chub mackerel and humboldt squid also averaged from 2000 to 2008 because the acoustic indices only cover the eez of peru we scaled the model output by dividing it by a factor q see table 4 which represents the proportion of the averaged distribution map of each group that falls within the peruvian eez in their configuration oliveros ramos et al 2017 calibrated a time varying larval mortality lm constant natural additional mortality time and size class varying fishing rate time varying plankton accessibility coefficient ac and time varying incoming flux of squat lobster in our climatology no incoming flux of squat lobster is included because the squat lobster is present since the beginning of the simulation and we only calibrated time constant lm and plankton ac time constant natural additional mortalities and fishing rates with a seasonality for anchovies see section 2 2 1 were obtained from the literature see table 4 in addition we manually adjusted the fishing rate of humboldt squid before the calibration process since our configuration had a tendency to overestimate the landings of this species the ac is the fraction of the total plankton that is provided as food for the fish it parameterises a range of processes that affect the availability of plankton for the fish such as turbulence stratification and vertical migrations and distribution see travers trolet et al 2014a literature values of this parameter for osmose vary strongly from very low values of 10 5 marzloff et al 2009 up to 69 grüss et al 2015 our calibration suggested optimal values ac of 3 0 5 0 2 0 and 0 4 for small and large phytoplankton and zooplankton respectively the larval mortality rate lm ts 1 is applied to the first stage of fish in osmose eggs and larvae during its first time step ts of life this parameter is typically calibrated for osmose e g travers et al 2009 marzloff et al 2009 halouani et al 2016 bănaru et al 2019 since field observations are scarce the optimal parameter values are available in table 4 in appendix a 2 after calibrating the model we simulated the configuration for 300 years to evaluate its stability with the calibrated parameters the sardine population collapses after the initial 50 years of simulation see supplement to avoid this decrease we adjusted by hand the natural mortality of juvenile and adult sardine as well as its lm see table 4 in appendix a 2 2 3 model evaluation we evaluated croco bioebus by comparing chlorophyll concentration and large zooplankton against observations see section 3 1 1 simulated phytoplankton concentration was converted to chlorophyll using function get chla m of the croco tools package penven 2019 and compared against modis remotely sensed chlorophyll concentration nasa 2018 a previous version of the model josé et al 2017 strongly overestimated zooplankton in comparison to observations hill cruz et al 2021 therefore for the present study we tuned the model to better match observed concentrations after tuning the model large zooplankton model concentrations were compared against mesozooplankton observations by moriarty and o brien 2013 and o brien and moriarty 2012 which are provided in carbon units for model comparison we transformed the observations to nitrogen dividing by a carbon to nitrogen ratio of 4 9 gc gn kiørboe 2013 and by the nitrogen molar mass of 14 g mol because the model does not parameterise diel vertical migrations simulated zooplankton is only present where food is available within the upper 100 m we therefore compared only the averaged zooplankton in the model and observations over the upper 100 m of the water column further model evaluations of sea surface temperature and mixed layer depth are provided in appendix a 1 simulated oxygen evaluation is available in josé et al 2019 we also evaluated the performance of osmose by comparing trophic levels with literature values section 3 1 2 2 4 experimental design to evaluate the effect and relative importance of an interannual versus a climatological plankton forcing on the simulated biomass of fish and macroinvertebrates we carried out six simulations all simulations ran for 25 years of spin up followed by 21 years of simulation our starting point was the calibrated climatological set up described in section 2 2 2 experiment 1 climatological in this experiment the 46 years run 25 years of spin up and then 21 simulation years have the same climatological plankton forcing with the second and third experiments we explored how interannually varying plankton affects the fish both experiments have an interannual plankton hindcast from 1990 to 2010 as forcing for the 21 years of simulation the spin up however differs in the two experiments to test whether variability in the spin up approach has any impact on the sensitivity of fish to plankton forcing for the second experiment called interannual the spin up consists of four years with climatological plankton forcing and then 21 years of interannual forcing the third experiment hybrid has climatological forcing over the entire 25 years of spin up we also put the impact of interannual plankton forcing into perspective by comparing it against the effect of changing two parameters we modified the plankton accessibility coefficient ac and the larval mortality lm by 10 these parameters were calibrated in the original climatological set up to optimise the model and their uncertainty is high in experiment 4 hybrid ac we evaluated the effect of a reduction in the ac by 10 which translates into less plankton being available as potential food in reality this can be interpreted as for example zooplankton hiding in a shallower oxygen minimum zone or a deeper mixed layer that dilutes phytoplankton in our original climatological osmose configuration we calibrated a different ac for each of the four plankton groups this adds an additional source of variability by changing the relative contribution of each group to the diet of fish we removed this variability in experiment 5 hybrid eqac by setting the ac to a constant value of 10 for all plankton groups we note that this represents a strong increase in the ac which makes the resulting fish biomass of this experiment not directly comparable to the other scenarios therefore for this specific experiment we only analysed the relative fluctuations in biomass with all of the above experiments we investigated the effect of changing food i e the gains of fish biomass either through the forcing or through the ac in a final sixth experiment hybrid alm we investigated how these changes in the gain or food side compare to changes in loss terms of fish by increasing the lm of anchovies by 10 we only manipulated the lm of anchovy in order to avoid an effect obscured by trophic interactions when manipulating the lms of the other groups to make the hybrid alm and hybrid ac experiments comparable we increased the lm and decreased the ac so that both experiments would have a negative impact on the anchovy biomass the six experiments are summarised below 1 climatological 25 years spin up with climatological plankton followed by 21 years of simulation using the same plankton climatology 2 interannual the spin up consisted of 4 years with climatological plankton forcing and then 21 years with interannual forcing after the spin up we simulated an additional 21 years applying the interannual hindcast of plankton from 1990 to 2010 3 hybrid 25 years of spin up time with climatological plankton followed by 21 years of simulation using the interannual hindcast of plankton from 1990 to 2010 4 hybrid ac hybrid set up with ac reduced by 10 5 hybrid eqac hybrid set up with ac of all four plankton groups equal to 10 6 hybrid alm hybrid set up with anchovy lm increased by 10 because osmose is a stochastic model random movement of schools and ordering of mortality events in a time step the output varies slightly among simulations therefore we analysed the average of 20 model runs for each experiment this study explores the effect of plankton variability on osmose therefore we removed other sources of interannual variability for instance habitat by keeping climatological distribution maps in all configurations appendix a 5 provides the results of an alternative set up where interannually varying distribution maps were applied from 1992 to 2008 in the hybrid configuration 3 results 3 1 model evaluation 3 1 1 croco bioebus the model reproduces the temporal variability in chlorophyll observations generally well replicating the seasonal pattern with higher chlorophyll concentrations in austral summer fig 1 top however from 2006 on wards it tends to overestimate chlorophyll especially during the austral summer large zooplankton is generally of the same order of magnitude as mesozooplankton observations fig 1 bottom this is a considerable improvement compared to the older version of the model by josé et al 2017 which was evaluated by hill cruz et al 2021 both model and observations show a high concentration of mesozooplankton in the region near the equator as well as towards the coast of peru within 50 km from the coast large zooplankton declines in the model this is not evident in the observations however this might be due to the low spatial resolution of observational samples further observations show a hotspot of high mesozooplankton concentrations around the galapagos islands which is not visible in the model this could be either a weakness of the model or it could also be an artefact in the observations due to averaging over very few samples for the whole water column an extensive discussion on the possible causes of mismatch between simulated large zooplankton and mesozooplankton observations observed in an earlier version of bioebus is provided by hill cruz et al 2021 3 1 2 osmose after calibrating and hand adjusting the parameters simulated biomass and landings show a good fit to observed estimates for most of the groups and are stable for at least 300 years fig 9 in the appendix a we evaluated the model performance by comparing the trophic levels simulated by osmose fig 2 with literature values table 1 the trophic structure in osmose agrees with the trophic structure of ecopath after plankton euphausiids are the lowest trophic level in the simulation followed by the small pelagic fish humboldt squid and hake are the top predators fig 2 and table 1 for anchovy pizarro et al 2019 observed a trophic level of 3 23 while in our model the trophic level of anchovies lies between 3 1 and 3 4 pizarro et al 2019 point out the presence of two groups of anchovies with different diet preferences one of them with a mean trophic level of 2 91 prefers to graze on phytoplankton and another carnivorous group has a mean trophic level as high as 3 79 pizarro et al 2019 the smaller trophic level range of anchovy in our study is likely due to having a single feeding preference predator prey size ratio range for all schools of the same age class we could not find trophic level estimations for squat lobster however given that it occupies a similar niche to anchovy gutiérrez et al 2008 we may also expect a trophic level around 3 in osmose we observe that it lies between about 2 5 and 3 fig 2 3 2 effect of plankton temporal variability accessibility coefficient and larval mortality on fish biomass the climatological calibration replicates well the time averaged biomass of fish and macroinvertebrates for the averaged time period 2000 2008 fig 9 for most scenarios and groups simulated biomass lies within the large variability in the observations fig 3 the hybrid and the interannual configurations show similar results fig 3 pointing out that the different spin ups do not have a considerable impact on the simulation this is especially evident for the euphausiids fig 4 right where both simulations converge after exhibiting different trajectories during the spin up this may suggest that the initial conditions are also not so important in osmose once it reaches steady state when comparing these two experiments with the climatological simulation the effect of introducing interannual variability in food is evidenced by the appearance of clear interannual fluctuations in euphausiids biomass and an increase in their mean biomass fig 4 right when introducing interannual variability in the plankton most of the simulated higher trophic levels exhibit interannual fluctuations of about 5 to 10 in their running mean with respect to the climatological set up see appendix a 5 in the hybrid configuration anchovy and euphausiids exhibit a maximum relative interannual variability of 8 8 and 14 6 of the mean value respectively however in the climatological run they also exhibit an interannual variability of about 4 1 and 1 1 respectively here we are referring to interannual variability as the difference between the maximum and the minimum of the 12 months running mean therefore about half of the interannual variability in anchovies comes from the internal dynamics of osmose rather than from the change in plankton forcing in the case of euphausiids most of the variability can be directly related to the change in plankton forcing this is also evident when comparing the hybrid and interannual configuration both experiments exhibit almost the same results for the euphausiids but they differ in the case of anchovies fig 4 such difference does not come from the plankton input but rather from the stochasticity and trophic interactions through the foodchain in osmose while the hybrid and interannual runs do show a different pattern than the climatological run their interannual fluctuations tend to be small compared to the high temporal variability in the observations other groups show almost no difference between the climatological and the interannual and hybrid configurations two important changes in the ecosystem were observed after the el niño of 1998 an increase in pelagic squat lobster and a complete collapse of sardines these are not replicated by the model which keeps all groups relatively constant before and after the el niño fig 3 and highlights the importance of including other sources of temporal variability in end to end models such as species spatial distribution in addition to food see appendix a 5 we also investigated the importance of total food concentration on fish biomass by reducing the plankton accessibility coefficient ac by 10 the reduction leads to a small decrease in fish biomass fig 3 both decreasing ac and increasing the lm of anchovy by 10 have a negative impact on anchovy however the impact of the lm is much larger than the impact of the ac fig 3 increasing anchovy lm also affects other species and in some cases the impact is also larger than the impact of the decreased ac therefore in this configuration the lm plays a greater role in controlling the biomass of fish an extreme case is the squat lobster whose biomass presents little change with decreased ac but almost doubles in the scenario with high anchovy lm fig 3 this evidences the same niche utilisation of the two species 3 3 further assessment of plankton accessibility coefficient effect on model temporal variability the plankton accessibility coefficient ac is a parameter that scales the plankton available for fish to eat because the ac was calibrated for each plankton group individually its differences across plankton groups low for large zooplankton and higher for the other groups might mask the impact of seasonal or temporal variability of plankton on fish to further investigate this issue in fig 5 we examined the total amount of plankton i e without multiplication by ac and the variation of plankton as food after multiplication by ac for this specific analysis we focused on the anchovy habitat therefore we isolated the region inhabited by about 90 of the anchovies fig 5 right as explained in section 2 2 1 the maximum interannual variability of total plankton in this region is 21 and 18 with and without the calibrated plankton accessibility coefficient respectively and the maximum seasonal variability is 18 and 19 fig 5 left and middle thus the interannual variability of total plankton in this region as food is increased by the ac as much as 3 furthermore applying a plankton ac shifts the seasonal peak of highest food availability from october to may fig 5 middle finally we assessed the effect of applying the same ac to all plankton groups in osmose in addition to the ac the food availability to each fish group is also affected by the predator prey size ratio and not all plankton groups are preyed by all planktivorous fish for example sardines prey on small particles such as plankton while anchovies prefer euphausiids the temporal variability of plankton comes directly from the biogeochemical model while euphausiids are explicitly represented in osmose and affected by the variability of their main plankton prey but also the trophic interactions with their predators therefore interspecies competition and predation between species of osmose may also play a role possibly causing non linear effects to further investigate this in a final experiment hybrid eqac we set the ac parameter to a constant value of 10 for every plankton group thereby omitting any effects caused by the different ac values for analysis we focused on the impact of this change on the diet of euphausiids which are the main planktivorous group in osmose and constitute about 85 of the anchovies diet the large homogenous ac of 10 increases the contribution of large zooplankton to the diet of euphausiids six times from only 3 to 18 6 table 2 furthermore setting up an equal ac for all groups also decreases the direct consumption of large phytoplankton by euphausiids by almost half table 2 this group is replaced by small zooplankton as the main prey of euphausiids this implies that the temporal variability of zooplankton has a greater impact on euphausiids as well as their subsequent predators 4 discussion 4 1 modelling temporal variability in the nhcs our study shows an effect of temporal variability in the biogeochemical model on higher trophic levels htl this variability is similar to the plankton forcing coming from the biogeochemical model the interannual variability in htl in osmose is however weak compared to the variability in observations and it does not replicate the regime shift after the el niño event of 1998 this discrepancy between model and observations may be attributed to several reasons first it is possible that the plankton temporal variability in the croco bioebus model is in fact too weak the plankton interannual variability observed in our plankton forcing which is close to 20 of the mean section 3 3 is much lower than the variability in anchovy observations however compared to satellite data see section 3 1 1 the surface chlorophyll in the model displays a similar variability around 20 of the mean see section 3 1 1 a second reason may be that the link between the biogeochemical model croco bioebus and the htl model osmose is too weak this link is done only through plankton food forcing for juvenile and adult fish other possible links may include the effect of oxygen temperature and food availability on larval survival and through interannually varying distribution maps temperature and oxygen are some of the variables that were considered when developing the distribution maps for constraining the habitat of the fish see oliveros ramos 2014 in appendix a 5 we provide an alternative configuration where additional interannual variability is introduced by applying interannual distribution maps instead of climatological ones however the direct impact of temperature on the physiology of the fish is not considered in osmose this may be relevant for future developments especially considering increasing temperatures due to climate change see penn and deutsch 2022 metabolic needs of swimming against currents and non random movement of individual schools such as searching for food and avoiding predators are also not considered in the model this proved to be relevant in the modelling study by watson et al 2015 it may also be that in the real ocean there is not a straightforward bottom up control of htl as supported by ayón et al 2004 they found no significant correlation between zooplankton and anchovy observations off peru between the period of 1984 to 2001 pointing to other potential drivers than food production therefore the main driver of the interannual variability in the nhcs might not be as simple as adult fish following the trends in plankton food this may be a peculiarity of the nhcs that makes the modelling of this ecosystem so challenging simulating environmental variability in osmose only through changes in plankton food for juvenile and adult fish has in fact produced stronger impacts in other ecosystems fu et al 2012 evaluated the effects of interannual variability in plankton input on their osmose model configuration for the strait of georgia in british columbia canada in their study interannual variability in phytoplankton produced strong effects of more than 50 on their small forage fish herring fu et al 2012 their figure 5a this is much larger than the response observed in our study in contrast interannually varying plankton in our study produces a change of about 5 to 10 in the biomass of most of the simulated htl groups see appendix a fourthly the period simulated in the nhcs is rather than a steady state el niño new steady state setting a part of a longer trend of interannual and multidecadal fluctuations in the ecosystem anchovy and sardine have been the two small pelagic fish fisheries with the highest catches since the 1960s these fishes fluctuate over the years with periods dominated by anchovies and others by sardines chavez et al 2003 the period from 1990 to 2010 corresponds to a progressive decrease of sardines and an overtake by anchovies to simulate these fluctuations a longer timeseries would be necessary this however is limited by the availability of data furthermore while our configuration includes the biggest pelagic macroinvertebrate and demersal fisheries off peru produce 2013 it may require other ecosystem components to account for the main drivers affecting these fisheries as a demersal species hake feeds on both pelagic and benthic fish species as well as euphausiids ware 1992 however in our configuration we only accounted for pelagic prey hence the variability in this species is missing the effects of its benthic prey in addition a possible explanation for the high production of the nhcs is the resetting of the system every few years by el niño events that impact both forage fish and their predators since higher trophic levels usually have longer generation times and take longer to recover this opens a loophole for forage fish to dominate the succession bakun and broad 2003 bertrand et al 2004 however we are missing apex predators in osmose the top predators in our configuration are the humboldt squid and the demersal fish hake but we are missing other groups such as marine mammals and sharks taylor et al 2008 achieved some level of interannual variability in an ecopath with ecosim configuration of the nhcs utilising a fit to time series routine that evaluated different predator prey interactions emphasising the importance of trophic dynamics their configuration included among other animals seabirds chondrichthyans cetaceans and pinnipeds while not containing as many groups as ecopath osmose in contrast allows for a detailed spatial representation of species with explicit life cycles and can take input from a biogeochemical model with finely resolved nutrient cycles finally the representation of survival of larvae may be of fundamental importance to our knowledge the study by oliveros ramos et al 2017 is the only modelling project with osmose that has successfully replicated the regime shift after the el niño event of 1998 they achieved this in addition to including interannual distribution maps by calibrating time varying parameters while such an approach successfully replicates the interannual variability in the system it masks the interactions between the biogeochemistry and htl because the temporally varying model parameters account for all temporal variability which is not necessarily justified not allowing to pinpoint processes for instance in oliveros ramos et al 2017 their figure 10 anchovy larval mortalities lm fluctuated more than 2 fold around the central value in our study we found that osmose is very sensitive to the value of lm with only a 10 change decreasing the biomass of anchovy by more than half the impact is much stronger than the effect caused by a 10 decrease in available food this suggests that the key to reproduce the interannual variability of the fisheries in the nhcs may not be in the food provided to adults but rather on the survival of larvae 4 2 towards a better parameterisation of larval mortality understanding the drivers of recruitment is essential to assess the growth of a population and in turn its maximum sustainable yield the maximum sustainable yield is the maximum amount of fish that can be taken from the system while keeping the population growth at sustainable levels past studies emphasise the importance of recruitment and mortality on the growth rate of fish populations tsikliras and froese 2019 in osmose recruitment is affected by the mortality of larvae therefore in this section we discuss the larval mortality in osmose and how to improve its parameterisation sources of larval mortality can be divided in four categories 1 mortality related to parents condition and variability among eggs 2 abiotic factors such as temperature 3 starvation and 4 predation predation 4 is already explicitly included in osmose the other factors are represented by the larval mortality parameter lm which accounts for mortality during the first 15 days of life of eggs and larvae it intends to account for processes that happen during the earliest life stages of fish when mortality is very high but hard to estimate from empirical studies for instance spatio temporal match between larvae and plankton allows fish recruitment cushing 1990 in upwelling regions this occurs at an optimal wind stress cury and roy 1989 cushing 1990 in this way the lm parameter in osmose also accounts for the impact of environmental processes on larvae such as wind dependence mixing our osmose configuration proved to be highly sensitive to the lm parameter following the setting up of other osmose configurations e g vergnon et al 2008 marzloff et al 2009 travers et al 2009 fu et al 2012 grüss et al 2015 halouani et al 2016 we estimated this parameter during the calibration process of the model therefore it was used in combination with the plankton accessibility coefficient ac to adjust the fish biomass to observed levels alternatives to calibrating this parameter may include to find a mechanistic representation of the fine scale larvae dynamics in relation to the physical environment and food availability this could resolve starvation 3 and abiotic causes of mortality 2 leaving only causes related to individual variability 1 to be calibrated in table 3 we compare survival derived from larval mortalities of sardine jack mackerel and anchovy against values provided by dahlberg 1979 the daily survival rates in osmose are smaller than in dahlberg 1979 table 3 however this comparison has to be taken with caution since the egg and first feeding larvae period in osmose 15 days is shorter than the periods reported by dahlberg 1979 table 3 therefore the high mortality of the initial days of life of fish is concentrated over a shorter timeframe and it is not surprising that the survival rates are lower finding a mechanistic link between the lm and the environmental drivers will be a crucial step in the development of end to end models roy 1993 found a relationship between wind speed and recruitment of anchovy and sardine populations in several eastern boundary upwelling systems this is based on the hypothesis that low wind and upwelling is linked to low primary productivity and recruitment high wind speeds on the other hand generates strong mixing that disperses larvae away from the food therefore there is an optimal environmental window cury and roy 1989 where the wind is neither too strong nor too weak and maximum recruitment is achieved roy 1993 from a modelling perspective lett et al 2008 proposed an explicit simulation of the larval stages of fish as a lagrangian individual based model with salinity temperature and velocity inputs a simple experiment to increase the effect of food availability on fish in osmose is to link the lm to the food availability through a linear relationship other potential improvements for the larval parameterisation in osmose may include to either link the lm parameter to environmental conditions for instance through the relationship found by roy 1993 or to include a whole new larval sub model in osmose similar to the one proposed by lett et al 2008 brochier et al 2008 simulated anchovy larval survival off the coast of peru based on a hydrodynamic model simulating larval drift and also considering lethal temperature egg buoyancy and active vertical swimming of the larvae the temporal dynamics of their results roughly resemble the seasonality in observations while no interannual variability was taken into account this approach shows potential for resolving larval dynamics in a mechanistic way the time series of estimated larval mortalities by oliveros ramos et al 2017 provides a good fitting hindcast a statistical relationship with the physical parameters and traces of the biogeochemical model could then be derived to produce estimates for future projections this may not only reduce the uncertainty in the lm but because lm and ac act in opposite directions it would potentially also provide insights into better estimations of the ac during the calibration process by reducing the number of parameters to be optimised there is no model that fits all purposes but models are useful tools to investigate certain questions every question however poses specific requirements for the model osmose was originally developed to investigate trophic interactions among htl such as fish shin and cury 2001 2004 at this time fish schools were divided into piscivorous and non piscivorous fish and their maximum populations were regulated by a carrying capacity shin and cury 2001 2004 later on it was modified to also include explicit food forcing from plankton groups travers 2009 which could be derived from satellite and surveys data marzloff et al 2009 or biogeochemical models travers et al 2009 at this point a carrying capacity parameter was not necessary anymore since limited resources were explicitly modelled however the ac was implemented to scale the biomass of plankton that is available to the fish the reasoning behind is that not all plankton in the water column is available for the fish to feed travers et al 2009 this parameter is however poorly understood and it is usually calibrated a blind calibration of the ac may however obscure the interactions between higher and lower trophic levels in the end to end model the study by travers trolet et al 2014b a looked at the combined effects of top down and bottom up pressures on a two way coupled n 2 p 2 z 2 d 2 osmose model system the fish to plankton feedback was achieved by calculating a mortality map of plankton based on the consumption by fish the maximum consumption of every plankton group was given by the ac which came from a calibration since in a two way coupling system fish consumption has a direct impact on zooplankton mortality the ac might also affect the biogeochemistry of the model therefore special attention has to be taken for the choice of this parameter 5 conclusion we set up a climatological configuration for the northern humboldt current system coupling the higher trophic levels model osmose with the physical biogeochemical model croco bioebus the calibrated model replicates well the mean biomass between 2000 and 2008 of most of the groups in a steady state changing the climatological plankton forcing to an interannual time series introduces temporal variability in the ecosystem however it does not replicate the strong fluctuations in fish especially sardine and anchovy observed before and after the el niño event of 1998 the inability of our model to replicate the regime shift may arise from the period between 1990 and 2010 not being in a steady state like our configuration but being a transitionary state from a sardine to an anchovy dominated regime covering a longer time series might help to capture longer term fluctuations in addition other processes should be assessed as potential major drivers of variability temporal changes in the habitat of fish may be an additional source of interannual variability these were included by oliveros ramos et al 2017 as interannually varying distribution maps based on statistical methods in climate projections these could be directly linked to the variables in the ocean circulation biogeochemical model linking other environmental drivers for instance temperature and oxygen with life stages of higher trophic levels for instance larvae may shed light into the main causes of the strong fluctuations of small pelagic fish in the northern humboldt current system this in turn may reduce the uncertainty in the plankton accessibility coefficient which is the most poorly constrained parameter in osmose when the main goal of using osmose is to explore the interactions between higher trophic levels and biogeochemistry including plankton we recommend a thoughtful consideration of what the plankton accessibility coefficient represents in the model for example some of the large zooplankton may perform vertical migrations and hide in the oxygen minimum zone in this case it would not be available for the fish during part of the day and it would require a different accessibility coefficient however if this information is missing while parameters need to be calibrated for evaluating the link between the biogeochemical processes and osmose we recommend to calibrate the same accessibility coefficient for all plankton groups credit authorship contribution statement mariana hill cruz conceptualization methodology formal analysis writing ivy frenger supervision writing julia getzlaff conceptualization supervision writing iris kriest conceptualization supervision writing tianfei xue methodology writing yunne jai shin supervision writing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was funded by the bundesministerium für bildung und forschung bmbf germany through the projects coastal upwelling system in a changing ocean cusco 03f0813 a and humboldt tipping 01lc1823b in addition jg received funancial support by the bmbf funded project co2meso 03f0876a and tx by the china scholarship council 201808460055 simulations and model calibration were carried out using the computing facilities of the norddeutscher verbund zur förderung des hoch und höchstleistungsrechnens hlrn we thank ricardo oliveros ramos and criscely luján paredes for providing the osmose humboldt interannual configuration and distribution maps we also thank ricardo oliveros ramos for providing scientific advice and technical support to this project we thank nicolas barrier for his technical support to the project we thank the instituto del mar del perú imarpe for providing the data to calibrate the model and we thank dimitri gutierrez for facilitating this data finally we thank andreas oschlies for his helpful contribution to the discussion and two anonymous reviewers for their valuable comments to improve the manuscript appendix a a 1 croco sea surface temperature and mixed layer depth the model sea surface temperature sst resembles well satellite observations from 2002 to 2010 fig 6 top the sst increases during el niño event of 1997 1998 in comparison to the rest of the time series fig 6 top the mixed layer depth becomes deeper during el niño event of 1997 1998 fig 6 bottom a 2 higher trophic levels model parameters table 4 provides the parameters used to run osmose the original name of each parameter as it is read by the model is provided fig 7 provides the seasonality of the anchovy landings additional parameters and the distribution maps are provided in the supplement a 3 calibration evolution the calibration ran for 400 generations using 75 individuals the global fitness function evolved from an original global fitness of 521 59 on the first generation to 0 29 on generation 200 from here it only decreased to 0 26 at generation 400 fig 8 shows the evolution of the parameter sets over the first half of the calibration a 4 climatological configuration fig 9 shows biomass and landings in the climatological configuration of osmose over a 300 years run the model resembles well averaged observations against which it was optimised a 5 configuration with interannual distribution maps in this section we provide the relative variability with respect to the climatological configuration see section 2 4 we also examine the hybrid configuration see section 2 4 running with interannually varying distribution maps from 1992 to 2008 instead of climatological distribution maps the initialisation food forcing and parameters are the same as in the hybrid configuration the interannual distribution maps are the same as used by oliveros ramos et al 2017 for most groups introducing interannual variability in plankton produces a relative change of around 5 to 10 fig 10 changing the larval mortality of anchovy in addition to the interannual variability in plankton has a larger impact in all groups except for the humboldt squid than only introducing interannual variability in the plankton fig 10 applying interannual variability to the distribution maps has a visible impact on the fish when compared to using climatological maps fig 10 compared to the hybrid configuration in the configuration with interannual maps some of the groups for instance humboldt squid exhibit a stronger interannual variability fig 10 in all experiments but the climatological set up sardines get destabilised and exhibit a continuous decline throughout the time series fig 10 a 6 plankton interannual and seasonal variability plankton has interannual and seasonal variability these are highly affected by the accessibility coefficient intv 13 and 9 1 and seasv 19 and 27 fig 11 in the full domain on the other hand the accessibility coefficient has a smaller effect when considering only the anchovy habitat see section 3 for a description of the anchovy habitat intv and seasv differences are only 3 and 1 respectively fig 11 appendix b supplementary data supplementary material related to this article can be found online at https doi org 10 1016 j ecolmodel 2022 110097 appendix b supplementary data the following is the supplementary material related to this article mmc s1 understanding the drivers of fish variability in an end to end model of the northern humboldt current system supplement 
