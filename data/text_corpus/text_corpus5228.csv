index,text
26140,generating quality meshes for hydrological modeling is challenging this article demonstrates using mesh workflows to incorporate national stream networks into very large dynamic meshes for distributed high performance computing hpc a multilevel quadtree is used to partition watersheds and merge stream networks ranging from hill slope to four level 4 hydrological unit code huc scales generating mesh sizes from hundreds to tens of millions of triangles by using a mesh workflow it is demonstrated how users control mesh quality including triangle sizes and the removal of small triangles and slivers four watersheds are studied ranging in scale from shale hills hill slope to the chesapeake bay 177 968 sq km and are used to compare mesh characteristics with user parameters and different elevation sources to generate a spectrum of multilevel quadtree meshes by using triangles to represent land surface and stream networks stream curvature is lost and the mesh workflow is used to demonstrate what parameters are important to maintain stream characteristics to meet hpc constraints the multilevel quadtree is demonstrated by picking quadtree tiles along a storm path to show how users can combine quadtree tiles at multiple levels to concentrate hpc resources for hydrological science research graphical abstract image 1 1 introduction meshes representing elevation surfaces or the ground are a critical component of many environmental models and this paper presents a mesh workflow a set of repeatable software components and processes to aid modelers to create quality surface meshes using national elevation ned usgs 2011 and national hydrography datasets nhd nhd 2013 for hydrological modelling anywhere in the continental united states conus the mesh workflow is a software component extension of the hydroterre end to end workflows leonard and duffy 2013 leonard and duffy 2014b leonard 2015b leonard and duffy 2016 hydroterre has been designed to prepare essential terrestrial variables etv for individual united states geological survey usgs level 12 hydrological unit code huc anywhere in the conus the mesh workflow has been designed to consume multiple level 12 hucs using a corrected large graph to collate etvs a corrected large graph contains validated stream flow network geometry and adjacent huc selections using a graph based visual analytics workflow designed for large scale hydrological modeling leonard et al 2015 leonard et al 2017 that validates streamflow directions this article focuses on the processes needed to create multilevel simplification meshes using ned and merging nhd stream networks into the mesh geometry to be used in hydrological modeling with distributed high performance computing hpc mesh workflows are essential to handle the complexity of merging these datasets to create and refine geometry with 10s 100s of millions of triangles appropriate for hydrological science research with the long term goal of generating triangles smaller and smaller as when the mesh is refined the computed hydrological solution will approach the true solution this article is structured as follows section 1 introduces the study locations and the reasons why multilevel mesh workflows are necessary for large scale hydrological modeling section 2 explains details about the software components used to process the national datasets and generate quality meshes for hydrological modeling section 3 describes the user parameters that control the mesh workflow the methods used to predict and evaluate mesh qualities the mesh characteristics and hpc results at the study locations section 4 demonstrates the mesh workflows describes differences found with inputs and the resultant stream networks how users can improve results by examining mesh qualities at the study watershed locations is discussed followed by a demonstration at one study site location as to why a multilevel mesh is required for hydrological modeling 1 1 why use multilevel mesh workflows before modeling any large scale watersheds predicting mesh sizes and compute requirements is necessary to determine if available hpc resources are adequate and the resultant mesh is suitable for the modelers objective this article demonstrates a mesh workflow that provides users these features for watershed sizes ranging from hill slope to conus scales by generating multilevel quadtree meshes quadtree is a tree data structure where each node has exactly four children finkel and bentley 1974 here quadtrees are used to partition the elevation model of the watershed in two dimensions by recursively subdividing the elevation model into four quadrants each quadtree depth or level represents the elevation surface at a different resolution tile size or simplification method each quadtree level has multiple nodes with each node containing a triangulated irregular network tin based on delaunay triangulation cheng et al 2012 therefore each quadtree tile at a level is an individual mesh suitable for distributed parallel computing however for most hydrological models the stream network is a critical data input and elevation models do not delineate the stream network from the elevation raster surface software tools such as taudem tesfa et al 2011 extract the stream network from elevation models yet at places throughout the conus these data products do not match the stream network delineated by nhd nor seen with aerial photography leonard 2015a leonard et al 2015 furthermore additional datasets such as road networks and other urban infrastructure are needed for hydrological modeling that affect mesh characteristics combining these datasets is challenging due to data quality differences and the likelihood of generating a poor mesh is high as will be demonstrated throughout this article the hpc requirements for large scale mesh workflows are demanding hence one way to constrain hpc requirements is to mix tiles from multiple quadtree levels to create a multiresolution mesh mixing quadtree level tiles provide users more options with mesh sizes and is suitable for hpc load balancing as an example for floodplain analysis the user could select quadtree tiles with small triangle sizes that spatially intersect a storm path while further away from the storm path triangle sizes are large therefore dataset networks need to match at quadtree tile edges at the same level but at the other mesh levels as well consequently a mesh workflow is important to aid users in managing and creating quality meshes for hydrological models that require hpc distributed computing to demonstrate the multilevel mesh workflows four study locations were selected table 1 using the etv and large graph case studies leonard and duffy 2013 leonard et al 2015 the largest watershed studied is the chesapeake bay watershed containing four level 4 hucs located on the east coast of the united states of america the remaining watersheds in descending size are the susquehanna juniata and shale hills each watershed is a sub watershed of its predecessor with the two smallest watersheds lidar elevation datasets from pennsylvania spatial data access pasda 2016 are used to compare stream geometry and mesh characteristics from the workflow to further demonstrate why mesh workflows are needed the next subsection describes common issues with meshes that affect hydrological modeling 1 2 what are common mesh issues for hydrological modeling there is an art in creating suitable meshes for hydrological modeling and common issues are discussed here that explain the need for a mesh workflow the penn state integrated hydrologic model pihm is used to demonstrate issues with meshes found amongst other hydrological models using polygon meshes as input datasets pihm is a physics based fully distributed hydrological model for simulating hydrologic state variables in space and time supported by national climate land use topographic and hydrogeological data products qu and duffy 2007 pihmgis bhatt et al 2014 and hydroterre toolsets provide functionality to generate stream networks using taudem users specify tolerances to simplify catchment boundaries and the stream networks by removing unnecessary nodes using the douglas peucker algorithm douglas and peucker 1973 with a user supplied elevation dataset pihmgis generates delaunay triangulations using triangle shewchuk 1996 that are refined by shape and size using a delaunay refinement algorithm by ruppert 1995 the tin is constrained by the stream network and catchment boundary with generated triangles conforming to these line networks also known as breaklines these methods have been implemented at numerous individual watersheds for pihm and require fine tuning by users to generate a mesh that is uniform in size users often are required to over simplify the stream network and specify a large area threshold to generate uniform triangles to reduce the number of skinny triangles needle cap slivers cheng et al 2012 and small triangles adjacent to streams leonard 2015b slivers are undesirable because they have dihedral angles close to both zero and 180 that corrupts the stiffness matrix in the finite element method cheng et al 2012 used by the sundials solver hindmarsh et al 2005 within pihm over simplifying the stream network causes elevation sampling issues the first example is stream segments that dissect through hills rather than following the stream curvature geometry often the stream vertices sample the elevation values on the hill not the stream location by assigning downstream vertices with erroneous high elevation values values higher than the upstream vertices along the stream segment leonard 2015a the second common example is similar to the first stream segments located within valley floors sample the valley walls or above creating stream segments that resemble zigzag shapes leonard 2015b from the millions of data model pihm workflows executed from hydroterre using national datasets 26 91 failed due to a poor stream network leonard and duffy 2014b furthermore poor quality meshes were generated due to how the stream network and elevation model were merged accounting for 71 17 pihm model workflow failures leonard and duffy 2014b leonard 2015b to resolve these erroneous elevation values required manual search and editing using gis that may be reasonable for an individual level 12 huc based on the number of stream segments however manual editing is often too time consuming for multiple level 12 hucs and does not encourage reproducibility and provenance the large graph used to validate huc and stream networks workflow has automated tools to identify these stream segments using a graphical user interface with suggested elevation values based on slope and nearby elevation values nevertheless for the juniata watershed with 97 level 12 hucs addressing these stream issues is also a time consuming process taking approximately two hours to assign elevation values and correct stream flow directions both strategies require a more robust way to retain stream curvature and stream vertex placement to sample correct elevation values from the digital elevation model dem furthermore to simulate large watersheds there are two common strategies the first is to model the entire watershed on a distributed shared memory compute environment encouraging modelers to use larger triangles and over simplified stream networks to reduce triangle counts as previously described this strategy is also problematic as the tin mesh is not decomposed into subdomains so that each central processing unit cpu has about the same amount of computation and minimized communication cost between processors hager and wellein 2010 the mesh is not load balanced and will affect the hydrological model hpc performance the second strategy is to model level 12 hucs individually with a huc per compute node and manually connect stream inlets and outlets with other hucs to constitute a larger watershed this method discourages using the same parameters that control the watershed meshes with all hucs as the modeler tries to optimize each huc individually assigning different parameters per huc creates mesh problems as catchment edges are not consistent with adjacent hucs stream inlets and outlets do not match and triangle sizes do not align with neighboring hucs using this strategy ignores flux exchange such as groundwater along watershed boundaries in addition each huc has different sizes and combined with different parameters to generate tins the triangle counts per huc vary therefore the watershed is poorly load balanced and cpu idle times will be high waiting for other watershed models to resolve per simulation time step from the above mesh issues affecting hydrological modeling a mesh structure is required that creates uniform triangle sizes is capable of decomposing large scale watersheds into subdomains is suitable for load balancing and computing hydrological models with distributed hpc hence a quadtree has been used here to decompose the watersheds with each tile containing a tin with similar triangle counts consequently small area skinny and sliver triangles will be inserted into the mesh predominately from the stream network therefore this article focuses on how the mesh workflow merges elevation ned and lidar and nhd stream networks followed by how sliver and small triangles are removed to create quality meshes for hydrological modeling then the mesh and stream characteristic results at the four watershed locations with various complexities are discussed to demonstrate the performance of the mesh workflow 1 3 related work the most common technique to join stream networks and elevation models is to etch burn or surface reconditioning the streams into the elevation models to enforce mapped drainage patterns stream burning saunders 1999 maidment and djokic 2000 lindsay 2016 techniques adjust elevation grid cells within the dem to enforce or create a local drainage pattern within large watersheds such as the chesapeake bay baker et al 2006 and is often required with flat landscapes callow et al 2007 and low resolution dems these techniques are beneficial for hydrological models that derive stream networks using the dem without a polyline supplied stream network although stream burning may improve the derived stream network errors in calculated stream distances are not avoided paz et al 2008 by using raster datasets to take measurements of stream lengths paz et al 2008 reported errors as high as 7 depending on dem resolution the algorithm used to calculate stream distances and raster data structures de smith 2004 as summarized earlier pihm and other models require both elevation and stream datasets to derive the tin with the polyline stream network serving as a tin breakline the advantage of this strategy is to provide users more control of the data inputs however more control is also a disadvantage with streams being over simplified to reduce triangle counts as previously discussed here this research focuses on what type of mesh characteristics are required to replicate the user supplied bad or good stream network using a mesh workflow that generates meshes that are suitable for distributed hpc modeling mesh generation is an extensively studied field and used by many disciplines with techniques such as the quadtree and delaunay that date back to the 1970s and continue to be studied by many here this article focus is on delaunay tins quadtrees mesh reduction and sliver removal to generate quality mesh and stream networks at multiple levels for a description on delaunay mesh generation algorithms the readers are directed to research by shewchuk 2008 and cheng cheng et al 2012 with research on quadtree data structures readers are directed to samet 1984 for combining quadtrees and tins in mesh generation pajarola et al 2002 yang et al 2005 using quadtrees within terrain simplification for large terrain surfaces cignoni et al 1998 lindstrom and pascucci 2002 example research with identifying and removing slivers from meshes include cheng et al 2000 edelsbrunner and guoy 2002 research with multilevel meshes and tins include the following de berg and dobrindt 1998 walshaw and cross 2000 for related research in integrating large terrain models and stream networks in hydrological modeling readers are referred to merwade et al 2008 on flood inundation mapping tesfa et al 2011 with the extraction of hydrological proximity measures from dems the prediction of soil properties using dems florinsky et al 2002 and evaluating shuttle radar and interpolated dems for elevation gradient and soil erosion kinsey henderson and wilkinson 2013 for delineating streambanks pai and saraswat 2013 estimating stream channel geometry ames et al 2009 and the effect of lidar derived dem resolution on large scale watershed models yang et al 2014 2 creating multilevel quadtree meshes and stream networks for hydrological modeling this section describes the software and methods used to create quadtree meshes and stream networks for hydrological modeling section 2 1 summarizes the hydroterre workflows used by the mesh workflow to retrieve etvs for individual level 12 hucs to retrieve multiple level 12 hucs for larger watersheds a large graph workflow section 2 2 is used to select and retrieve etv data bundles these data bundles are combined and used as inputs to the mesh workflow as summarized in section 2 3 the last section steps through the main software components of the mesh workflow describing user inputs how the quadtree meshes are generated and merged with the stream network the steps taken to remove slivers and small triangles and output datasets used for hydrological modeling 2 1 hydroterre workflow overview hydroterre workflows are initiated via the web application by selecting a level 12 huc hydroterre consists of four workflows fig 1 a forming an end to end workflow system for hydrological modeling in a distributed computing environment leonard 2015b leonard and duffy 2016 the first is the etv data workflow fig 1b responsible for selecting projecting clipping and extracting national datasets within the level 12 huc watershed leonard and duffy 2013 creating a level 12 huc data bundle with standard geographic information system gis datasets typically takes about two minutes to create leonard and duffy 2014b the etv data workflow operates as an independent service using file formats common for many models conversely the data model workflow fig 1c is dependent and employs the etv workflow service as data inputs four parameters control the watershed level 12 huc boundary and stream topology that in turn controls unstructured mesh details for hydrological modeling leonard and duffy 2014b the data model workflow assigns land use initial conditions and other parameters using the national datasets as a priori values the pihm model workflow fig 1d consumes the data model workflow as data inputs using the web application calibration initialization and hpc model parameters are controlled by the expert user default values are assigned automatically by using data mining strategies from the previous workflow results the etv data model and model workflows have been executed millions of times to investigate the main reasons for failure within the national datasets or within the models leonard and duffy 2014b leonard 2015b the last hydroterre workflow is the visualization workflow fig 1e to encourage iterative and investigative processes by the expert user to rapidly change data model and model parameters leonard and duffy 2016 the visualization workflow consumes the data data model and model workflow services as data inputs this workflow provides maps and data visualizations for the expert user to drill down interrogate model results and rapidly test and re submit hydrological models for further analysis 2 2 large graph workflow overview the hydroterre end to end workflow described earlier considers a single level huc 12 the next step is to model connecting level 12 hucs or a graph of watersheds to achieve this goal requires a conus scale graph of all level 12 hucs unfortunately the implied graph from current nhd have issues that require expert intervention leonard and duffy 2014a leonard et al 2015 leonard 2015b the most common reasons for intervention to correct watershed graphs include conflicting edge directions edges that pass back and forth along huc boundaries and edges within flat sloped elevations leonard et al 2017 for hydrological models like pihm conflicting edge directions will cause simulations to either not converge or be inefficient in solving physics automation to correct conflicting edge directions is currently not feasible due to elevation resolution ned with 10 or 30 m and flat sloped regions leonard 2015b leonard et al 2016 for example when multiple streams edges share the same elevation raster values it is not clear whether the edge directions are valid with automated detection furthermore the conus nhd graph scale is large with 33 338 895 streams 851 265 305 unique edges and 683 298 991 unique nodes leonard et al 2016 inserting ned and lidar elevation nodes into the existing nhd network will further increase the graph size requiring significant hpc resources to automate edge directions leonard et al 2017 hence expert intervention is necessary to validate stream graphs with large graph workflows and visual analytics the large graph workflow fig 1f generates two types of graphs the first is a corrected graph of level 12 hucs that is used to retrieve data bundles from hydroterre the expert user is required to validate level 12 huc connections that have flat sloped elevation at adjoining hucs the second graph is a consistent flow direction stream network based on the nhd stream network with this graph the user is required to validate flat slope stream reaches inlets and outlets for the juniata watershed a depth first search dfs graph was generated by selecting upstream level 12 hucs from root node identification 020503041204 that creates a graph size of 97 nodes level 12 hucs validation is a time consuming and iterative process taking two hours for the juniata watershed study to validate 745 issues identified with flow edge directions leonard et al 2017 hence due to time constraints the juniata watershed is the largest watershed studied with a validated stream network with the mesh workflow in this article an in consistent stream flow direction stream network does not alter the mesh workflow results although there is an impact on performance for models such as pihm 2 3 mesh workflow overview the purpose of the mesh workflow fig 1g is to generate a land surface mesh that is suitable for hydrological modeling using parallel distributed hpc for spatial decomposition a quadtree data structure was used to partition the land surface by recursively subdividing the space into four quadrants finkel and bentley 1974 samet 1984 each quadrant or mesh tile is a standalone model input containing a land surface mesh and a stream network for a hpc compute node to resolve hydrological physics for computation messaging between tiles mesh and stream connection files are generated to communicate exchange of data between tile edges each mesh tile is rectangular for load balancing and to minimize the surface to volume ratio size of data exchanged between tiles consequently the bounding box of the entire huc graph generated from the large graph workflow is first created and then this box extent is used to recursively subdivide the elevation dataset into tiles hence rectangular tile extents are used to execute data workflows fig 1b rather than using level 12 huc boundaries not rectangular to access etv data bundles for the mesh workflow to maintain huc boundaries assigning boundary conditions are necessary at triangle edges after executing the mesh workflow the quadtree dataset is consumed by the data model workflow to generate hydrological model input files additionally as discussed in sections 3 and 4 executing the mesh workflow is computational rigorous and time consuming therefore the mesh workflow is an offline software and data service the next section discusses the mesh workflow software components 2 4 mesh workflow software components fig 2 summarizes the six main components of the mesh workflow section 2 4 1 discusses the workflow data inputs and user parameters to control the mesh quality the second and third components section 2 4 2 demonstrate how the quadtree mesh is prepared to incorporate stream network geometry section 2 4 3 the fourth component reveals the steps taken to remove slivers and small triangles from the quadtree meshes section 2 4 4 the fifth and sixth components discuss the steps taken to transform the meshes into datasets appropriate for hydrological modeling using distributed hpc resources section 2 4 5 2 4 1 input requirements the mesh workflow requires two data inputs the first input is a dem and the second is a stream network a user supplies a list of dems and stream network shapefiles that are re projected to a specified projection coordinated system in this article both datasets are generated with the large graph workflow for the smaller watersheds shale hills and juniata the large graph workflow generates a list of huc 12s that are used to create a bounding box to select and merge adjoining raster datasets with the same projection system and to provide a corrected stream network there are number of user parameters that control the mesh workflow summarized in table 2 for example users can specify the projection type table 2a by specifying the epsg code european petroleum survey group 2016 with the default type being usgs albers hydroterre default configuration code 5070 the remaining parameters are explained in further detail within the following subsections 2 4 2 validate parameters and create quadtree mesh the root region quadtree is based on the rectangular extent of the dems representing level zero or the root graph node fig 3 a based on the merged dem dataset a delaunay tin is generated by specifying the elevation tile size table 2b that controls minimum elevation sampling the next level level one is generated by decomposing level zero region into four quadrants fig 3b the merged dem is clipped into four elevation datasets a delaunay tin mesh is created for each quadrant tile using the clipped dem decomposing each level of quadrants is repeated until the user specified maximum quadtree level table 2c has been reached or decomposing stops when the triangle sizes near the elevation resolution for example in fig 3 recursion stopped at level five specified by the user however by using equation one the maximum level can be pre determined by elevation size resolution and tile size by using equation two a user can pre calculate triangle sizes without etched streams to determine if the triangle dimensions meet their modeling requirements and if the user has access too appropriate hpc resources for example to model the juniata shown in fig 3 the same watershed could be partitioned from one to 1024 hpc compute nodes with a wide range of triangle sizes furthermore equation three is used to determine whether the triangles are uniform to avoid elongated triangles by subdividing the longest edge section 3 2 demonstrates these techniques in further detail with the study watersheds therefore if the user has specified a maximum level that is not supported the workflow does not continue and the user is notified of this issue after generating the quadrant tiles leaf nodes for all levels or depths each quadrant tile is converted into a node point shapefile representing the unique nodes of all delaunay triangle meshes additionally a triangle mesh shapefile is created with neighbor identifications for each triangle edge these conversions are necessary to merge river geometry within the quadtree lw floor log2 elevwidth elevcellwidth tilesize lh floor log2 elevheight elevcellheight tilesize maxlevel max lw lh equation 1 how to pre calculate maximum quadtree level elevwidth width of elevation dataset elevheight height of elevation dataset tilesize specifies minimum number of times to sample elevation dataset triw elevwidth tilesize 1 tilewidthmultipler 2ˆlevel trih elevheight tilesize 1 tileheightmultipler 2ˆlevel equation 2 how to pre determine triangle sizes without stream network triw triangle width of delaney tin trih triangle height of delaney tin tilewidthmultipler how many times to split extent width tileheightmultipler how many times to split extent height level quadtree level ar elevwidth elevheightif ar 1 swap truetile rows 1lar floor ar uar ceil ar if ar sqrt lar uar tile columns larelsetile columns uarif swap tile rows tile columnstile columns 1 equation 3 by using aspect ratio of elevation extent the number of quadtree rows and columns are determined 2 4 3 merge stream geometry with quadtree at level zero the stream geometry is clipped to the entire extent of the dems from levels one to the maximum level the stream network is clipped by the extent of each quadrant tile at each tile the inlets and outlets are identified these nodes are considered valuable points and are not altered within the mesh workflow that way the position of inlets and outlets per quadrant tiles do not change and connection files between tiles and all levels section 2 4 5 share identical locations as demonstrated in section 4 4 the next step is to insert mesh vertices that intersect the stream network to maintain the regular spacing of the mesh triangulated grid if the user specified a densify stream value table 2d more vertices are inserted into the stream network at a regular distance to create more triangles along streams each mesh node is buffered with a maximum distance table 2e at level zero with the distance decreasing using equation 4 per quadtree level to maintain the mesh regularity i e to avoid a buffer size greater than triangle sizes any mesh and stream nodes within the buffer geometry is considered the same location therefore multiple nodes are purged aiding in the reduction of slivers and small triangles as further discussed in sub section 2 4 4 if triw trih bd 0 35 triwelse bd 0 35 trihif bd ub bd ub equation 4 method to determine buffer size to select and purge nodes bd buffer distanceub user supplied maximum buffer distancetriw triangle widthtrih triangle height the modified stream network is merged into the quadtree by treating the network as a hardline constraint within a delaunay tin to enforce the stream height values cheng et al 2012 esri 2016a the tin is converted to a triangle mesh shapefile that is nearly identical to the inputs analysis of the geometry generated incurs numerical precision differences between vertices of the tin and stream network therefore triangle vertices adjacent to the stream network are selected and repositioned using the snap distance value table 2f to align the triangle and stream network fig 4 a using this strategy has eliminated many slivers often found along the stream networks as further discussed in the next section 2 4 4 removing slivers and small triangles one of the main reasons for creating quadtrees with a minimum elevation sample was to ensure slivers are not generated hence slivers and small triangles created will occur near stream networks that clearly do not have a regular uniform geometry the user can specify thresholds to remove slivers and small triangles that may affect their hydrological modeling which in turn control how well the stream shape is preserved demonstrated in sections 3 4 4 2 and 4 3 as previously mentioned strategies to reduce slivers include consolidating vertices within a buffer polygon table 2e that occur due to numerical precision differences with stored xyz values in shapefiles as well as snapping table 2f triangle edge vertices near stream networks fig 4a to identify and remove slivers from tins the thinness ratio equation 5 davis 1990 was assigned to each triangle per quadtree tile the default thinness ratio value is 0 3 and users can modify this value as a user input parameter table 2g to remove different types of slivers i e dagger blade cheng et al 2000 edelsbrunner and guoy 2002 cheng et al 2012 to identify small triangles the user specifies the level zero small area threshold table 2h which is reduced per level using equation six thinness 4 pi triangle area triangle length ˆ2 equation 5 thinness ratio davis 1990 area 0 5 trih triwif ua area remove triangle nodes equation 6 small area threshold bd buffer distanceua user supplied maximum areatriw triangle widthtrih triangle height once slivers and small triangles are identified per quadtree tile the strategy to remove these issues summarized in fig 4 while preserving steam geometry meant identifying and to weight the location of triangle vertices if one of the three vertices fig 4b is not located on the stream network only this vertex is removed if there are two vertices on the stream edge within the delete node threshold table 2i the downstream vertex is removed if the location is not on the tile edge fig 4c then the upstream vertex is removed fig 4d however if this upstream vertex has been identified as a stream inlet the vertex will not be removed fig 4e unfortunately this is one circumstance when small triangles will remain if this triangle is identified as a sliver a vertex is inserted in the center of the longest edge fig 4f if two of the three triangle vertices are not on the stream network the edge with the smallest distance is examined the vertex not on the stream is marked for removal fig 4g unless the vertex is on the tile edge in these circumstances then the other edge is examined and the end vertex not on the stream is removed fig 4h again if this vertex is on the tile edge then no vertices are removed and this scenario is another situation when small triangles remain in the quadtree fig 4i as before if the triangle is a sliver another vertex is inserted that may create small triangles fig 4j and k additionally if this small triangle is equilateral the edge with vertices not on the network are removed if not on the tile edge after modifying vertices that cause slivers and small triangles the tile tin is recreated and converted to a triangle shapefile these steps to remove slivers and small triangles are repeated per individual quadtree tile to the user specified maximum number of attempts table 2j when issues are still identified within the tile as mentioned above there are circumstances when these mesh issues are necessary to maintain the quadtree data structure section 3 2 discusses the methods to predict and evaluate mesh quality and section 3 3 demonstrates the removal of slivers and small triangles from mesh workflow results at the study watershed locations the next mesh workflow step is to create mesh files appropriate for hydrological models 2 4 5 generating mesh and connection files triangles modified along tile edges to remove slivers and small triangles require adjacent tiles to match these changes at the same quadtree level there are two actions as summarized in fig 4k and l the default action is to add vertices along tile edges table 2k with the cost of inserting more triangles most often small triangles i e tile 2 will have two small triangles inserted in fig 4k users concerned about triangle counts can override this action by deleting vertices that were inserted with the adjacent tile i e tile 1 in fig 4l in other words the user chooses to accept slivers and or small triangles however the recommended action is to add triangles since inserting a small number of triangles are not significant compared to the large number of triangles per individual quadtree tile as shown in section 3 3 after validation each quadtree is converted into multiple files for modeling purposes the first file generated is a summary of the quadtree tiles table 3 a with properties about the mesh stream network connecting tiles and the bounding box of individual tiles for the quadtree level these properties are used to select tiles by triangle count and identify tiles that intersect storm paths as demonstrated in section 4 4 each tile tin is converted from a shapefile to text files with mesh table 3b and stream properties table 3c for interoperability the remaining files generated are grouped into connection file types there are two spatial scales of connection files fig 5 the first scale fig 5a is how triangles and stream networks located on tile edges are connected to adjacent tiles at the same quadtree level at this scale a mesh connection file is created identifying which triangles and edges connect between the two tiles table 4 a a stream connection file identifies the stream segment keys and the vertex fig 5b they share in common at the tile edge table 4b at the second scale connection files are used to connect mesh and river datasets with other levels as demonstrated in fig 5c a tile edge at level one level containing four tiles will share the edges of two tiles at level two level with 16 tiles the data structure of this file table 4c contains the same properties as the mesh connection file with the addition of a ratio that represents the proportion of the smaller edge overlaps with the larger edge fig 5d that way models like pihm can use this ratio to partition fluxes between triangles at different quadtree levels this section has focused on the main components of the mesh workflow that creates a quadtree based on a list of dems the workflow then merges a stream network with the quadtree tiles that handles the removal of slivers and small triangles from the meshes based on user parameters once the quadtree is complete the tin tiles are converted and connections between multiple quadtree levels are generated for hpc hydrological model usage each component is executed in parallel with the maximum number of threads specified by the user table 2l the next section discusses the results of the mesh workflow with hydrological model examples at the watershed study locations 3 quadtree meshes and stream networks at watershed study locations section 2 discussed how the mesh workflow components generate quadtree meshes with stream networks for hydrological modeling each quadtree level contains a set of tiles with each tile containing a tin with an embedded stream network section 3 describes the mesh workflow results at the four watershed study locations table 1 first described is the workflow parameters used at the watershed locations followed by the methods to predict and evaluate mesh qualities generated by the mesh workflows section 3 2 section 3 3 summarizes the mesh characteristic results for each watershed study location the last section reviews and evaluates the hpc performance of the mesh workflows to aid in predicting workflow requirements 3 1 mesh workflow parameter exceptions the mesh workflow was performed at the study location watersheds table 1 with the parameters outlined in table 2 and discussed in section 2 this section focuses on parameter exceptions used by the mesh workflows with the smaller watersheds shale hills and juniata both ned and pasda lidar elevation datasets were used to compare differences with mesh workflow results pasda 2016 however ned used the default projection code and lidar used code 3651 the remaining large watersheds used ned as the elevation data source as there is no access to a national lidar dataset usgs 2016 additionally smaller sub watersheds with high resolution elevation datasets were inserted into larger watersheds low elevation resolution to demonstrate how users can mix different types of elevation datasets and define mesh workflow parameters to create consistent quality meshes for hydrological modeling mixing elevation datasets within watershed boundaries table 1b were demonstrated by inserting shale hills pasda lidar tile into the juniata ned and inserting the juniata pasda lidar tiles into the susquehanna ned watershed the nhd stream network was used for all watersheds except at shale hills at shale hills the critical zone observatory stream network neal 2013 was used as nhd stream coverage does not reach this hill slope watershed additionally stream densification has been performed with the shale hills stream network to increase triangle density at multiple quadtree levels section 3 3 1 to demonstrate how users control triangle density by tile sizes four tile sizes 16 32 64 and 128 were used for levels zero to five when the elevation resolution was sufficient for this research level five was selected as the maximum level studied to produce tiles ranges from 1024 to 2048 manageable with common hpc cluster environments 3 2 methods to predict and evaluate mesh quality to predict and evaluate the mesh qualities produced by the workflow for each of the watershed study locations the mesh sizes were first predicted without stream networks section 3 2 1 before executing the workflows during and after the mesh generation three mesh qualities were used to measure the meshes as described in section 3 2 2 3 2 1 predict mesh sizes using the techniques described in section 2 4 the mesh characteristics width height were first predicted for each of the watershed locations table 1 without streams for quadtree levels 0 to the maximum supported level and elevation resolution table 5 summarizes appendix a with mesh properties at levels zero five selected maximum and the maximum quadtree level recall one goal of the mesh workflow is to provide user control of triangle sizes and the total number of tiles for hpc hydrological modeling the maximum triangle width and height occurs at level zero and the minimum size dimensions occur at the largest mesh level supported by tile size and elevation resolution this equates to generating triangles that are close to or identical to the pixel elevation dimensions 3 2 2 measuring mesh qualities to evaluate the mesh workflow results three qualities are measured the first quality is comparing the stream length generated by the mesh workflow with the supplied nhd stream inputs table 1 has the nhd stream lengths for each watershed ideally the workflow will generate an identical stream length 100 match stream length comparisons under 100 indicate under sampling or the number of vertices along the stream does not capture the stream curvature over simplifying stream edges within triangle area and is undesired while over 100 indicates oversampling and or aliasing effects i e staircase effect hearn and baker 1997 when triangle sizes are smaller than stream curvature the second metric is calculating the perimeter ratio hydrological models like pihm exchange data along triangle edges with adjacent triangles ideally the triangle edges follow the path of the stream network as well as capture the topography with sufficient detail as the quadtree meshes recursively subdivide the triangles become smaller until reaching the elevation resolution in other words the mesh has reached the maximum triangle perimeter possible table 6 records the total triangle perimeters without stream networks for each watershed using the predicted mesh sizes section 3 2 1 each mesh workflow perimeter is calculated and compared to the total triangle perimeter possible within the chosen quadtree level and tile size a ratio of one indicates the mesh workflow has produced a mesh identical to a mesh at the elevation resolution and is the mesh workflow objective therefore the mesh is sufficiently small and representing the stream network with uniform triangle sizes a high perimeter ratio indicates the triangle sizes vary to capture the stream network and indicate to the user the chosen quadtree level and tile size is generating triangles that are not uniform may not be a concern for the user a perimeter ratio less than one indicates the workflow has generated a mesh smaller than the elevation resolution along the stream network by additional vertices inserted in the stream network over sampling to capture stream curvature the last calculation of mesh quality is the thinness ratio equation four all triangles have their thinness ratio calculated to identify slivers and are filtered by the user defined value table 2g this research article has treated all watershed studies with the same constant value of 0 3 before removing any slivers by the mesh workflow fig 2 group 4 the number of triangles with thinness ratios between 0 05 and 0 5 with increments of 0 05 were recorded to compare and contrast how efficient the workflow removed slivers and small areas these three mesh quality measurements are presented for each of the watersheds in the following section 3 3 mesh characteristic results the following sub sections summarize the mesh characteristics and data properties for each of the four watershed study locations the goal of each mesh workflow is to generate a stream network that matches the stream length inputs 100 result and a perimeter factor of one to achieve these goals the mesh workflow should create a triangle mesh that is uniform and sufficiently small that does not reduce the stream length and generates no slivers 3 3 1 shale hills watershed using ned at shale hills table 7 a watershed is the smallest article example in terms of elevation resolution 21 by 17 pixels and area 0 2 sq km the ned elevation resolution at shale hills supports tile sizes 16 and 32 from the four tile sizes used in these experiments 16 32 64 and 128 at tile size 16 quadtree levels of zero and one the mesh workflow generated triangle counts of 478 and 670 respectively appendix b1 at level one the average triangle count per tile was 168 triangles additionally both perimeter ratios are close to one when compared to a triangle mesh with no streams the total number of river segments are similar between the two levels with 13 level zero and 14 segments level one comparing the generated stream lengths with the provided stream input both levels produced nearly identical lengths at 99 in other words differences are in centimeters a value of 0 3 was selected as the thinness ratio threshold to identify slivers with 2 of the triangles at level zero and 1 4 at level one appendix c1 identified as slivers before the mesh workflow successfully removed all slivers and small triangles the mesh workflow results are similar between tile sizes 16 and 32 at shale hills using the ned elevation dataset tile size 32 at level zero produced 598 triangles in total with 14 river segments that represent 99 of the input length and a perimeter ratio of 1 02 again the given thinness ratio identified 2 of the triangles as slivers appendix c1 before the mesh workflow successfully removed all slivers and small triangles by using lidar at the shale hills watershed it is possible to examine all four tile sizes as summarized in table 7b at tile size 16 quadtree level zero generated the smallest triangle total count of 944 triangles as well as the largest triangle count of 532 427 at level five appendix b1 the total triangle count ranges from 3916 level zero to 532 388 at level four using tile size 32 with a tile size of 64 level zero has 15 984 triangles and at tile size 128 level zero generated 64 698 triangles examining the triangle totals per maximum level at each tile size the triangle counts are very similar for example at tile size 64 the triangle count is 522 327 triangles at the maximum level of three while at tile size 128 the triangle count is 515 556 triangles at level two maximum quadtree level when comparing average triangle counts per tile for each tile size the reader can approximate triangle counts for larger tile sizes by multiplying with a ratio of four for example to estimate the average count at tile size 32 multiplying tile size 16 average triangle count of 472 by four produces 1888 triangles a value close to the 1929 triangles produced with tile size 32 these values are not identical due to inserting stream networks that modify the regular mesh sampling as discussed in sections 2 4 3 and 4 3 at tile size 16 the average triangle count is 457 per tile between levels zero to four at level five the average triangle count reduces to 260 triangles a decrease of 42 22 this behavior also happens with the remaining tile sizes with a reduction of 45 29 at tile size 32 48 48 at tile size 64 and 50 at tile size 128 these reductions occur when the mesh generation process has reached the elevation resolution preventing any further elevation sampling using lidar at shale hills watershed generates perimeter ratios close to the goal of one for all tile sizes and quadtree levels tile sizes 16 32 and 64 are slightly less than 1 0 due to oversampling along the stream network creating the staircase or stairstep effect hearn and baker 1997 with tile sizes 32 and 64 the stairstep effect generated stream lengths of 104 46 and 103 65 respectively larger than the supplied inputs at tile size 128 the generated stream length is 104 25 larger 15 cm difference although the perimeter ratio was not affected 1 0 by oversampling conversely at tile size 16 the stream length is 99 65 or a one centimeter difference with a perimeter ratio of 0 98 both the ned and lidar shale hills watershed mesh workflows used the same stream input with ned workflows generating a maximum of 14 stream segments while using lidar elevation the workflow generated stream segment counts ranging from 21 a 61 increase to 323 a 2207 increase compared to ned workflow as the mesh workflow generates more stream segments and triangles the sliver count increases as well at tile size 16 the sliver ratio ranges from 0 006 to 1 38 tile size 32 from 0 009 to 0 61 tile size 64 from 0 017 to 0 19 and the range is from 0 016 to 0 023 at tile size 128 appendix c1 the success rate of removing slivers and small areas from lidar generated meshes varies compared to the ned generated mesh at tile size 16 the removal of slivers and small areas was 100 successful at levels zero and one 55 56 at level two and 0 at levels three to five with tile size 32 the success rates ranged from 0 to 87 50 tile size 64 from 0 to 40 and at tile size 64 no slivers and small areas were removed the main reason for these low success rates was using the add option with edge minimum stream threshold table 2k that encourages the insertion of small triangles as discussed in section 2 4 4 3 3 2 juniata watershed the ned elevation resolution at the juniata watershed supports all four tile sizes 16 32 64 and 128 as shown in table 8 a at tile size 16 the lowest number of triangles 26 894 occurs at level zero as well as the least number of stream segments 13 611 appendix b2 these relatively low numbers at the juniata watershed reflect with the lowest stream length comparison of 89 29 and the highest perimeter ratio of 5 92 both measurements indicate the generation of irregular larger triangles along the stream network losing stream curvature features however as the quadtree level increases at tile size 16 the increase in triangle and stream counts improves both measurements with a high stream length of 94 66 and low perimeter ratio of 1 1 at level five as the workflow measured stream lengths a pattern formed with low stream length comparisons at level zero and then high stream length comparisons objective of workflow towards quadtree level five that was repeated with the remaining tile sizes the mesh workflow produced stream comparisons at level five of 96 59 at tile size 32 97 66 with tile size 64 and 98 82 at tile size 128 however the juniata stream network is approximately eleven thousand kilometers in length table 1 resulting with large stream length differences between the mesh workflow result and the nhd input at tile size 16 the difference in length between the nhd inputs varies from 582 km to 1166 km from 371 km to 1108 km at tile size 32 255 km 1019 km at tile size 64 and 143 km 864 km at tile size 128 to reduce these stream length differences the user will have to increase the quadtree level and or increase the tile size with consequences discussed in section 3 4 additionally the pattern of high perimeter ratios at level zero towards the goal of a perimeter ratio of one towards level five are repeated with all tile sizes although there is a substantial increase in the total triangle counts to achieve perimeter ratio of one level five the largest quadtree explored here generated 571 958 triangles perimeter ratio of 1 10 at tile size 16 2 171 827 perimeter ratio of 1 05 at tile size 32 8 512 948 perimeter ratio of 1 02 at tile size 64 and 32 513 133 perimeter ratio of 0 99 triangles at tile size 128 removing slivers and small areas for all tile sizes and quadtree levels at the ned juniata watershed were effective ranging from 99 46 to 100 success rates the number of slivers identified ranged from 7095 tile size 32 level 0 up to 297 135 triangles tile size 128 level 5 appendix c2 the mesh workflow resulted with no slivers and small areas at levels zero and one with tile size 32 with all tile sizes level five produced and retained the most slivers approximately 0 005 of the total produced triangle count with 37 remaining at tile size 16 109 at tile size 32 429 at tile size 64 and 1611 triangles at tile size 128 appendix c2 most of these sliver and small area triangles occur near stream inlets and outlets identified as critical locations to preserve see sections 2 4 4 and 4 3 the results of juniata ned mesh workflow contrasts with the shale hills lidar watershed with consistently high stream comparisons similar perimeter ratios and similar triangle counts of half a million the reason for these differences is due to the complexity of the stream network at juniata watershed under sampling or inadequate tile sizes and the mesh workflow not reaching the maximum quadtree level elevation resolution appendix a table 8b reveals the results of using lidar at the juniata watershed to retain near square sampling the number of tiles produced is twice the size of the ned version although more tiles does not equate to twice the number of triangles for all quadtree levels at tile size 16 the range of triangle counts are from 28 454 level zero to 1 168 016 level five an increase of 5 8 104 21 respectively between ned and lidar elevation sources appendix b2 by increasing the tile sizes the difference in triangle counts between ned and lidar does increase at lower levels faster than higher quadtree levels at tile size 32 the range of triangle counts are from 36 176 level zero increase by 14 61 to 4 215 139 level five increase by 94 at tile size 64 the range is from 57 434 level zero increase by 29 55 to 16 794 503 level five increase by 97 28 with tile size 128 the triangle count range is from 124 454 level zero increase by 52 90 to 67 815 622 level five increase by 108 58 additionally twice the number of quadtree tiles does not double the number of stream segments with all levels and tile sizes the increase of stream segments at tile size 16 is from 4 05 13 611 versus 14 162 stream segments at level zero to 32 41 55 874 versus 73 985 stream segments at level five while at tile size 32 the increase in stream counts range from 8 81 to 36 12 13 89 39 57 at tile size 64 and from 21 61 24 949 versus 30 341 segments at level zero to 43 24 368 354 versus 527 617 segments at level five at tile size 128 comparing stream lengths between the nhd input and lidar mesh workflow generated streams the lidar performs slightly better than ned does with these tile sizes and quadtree levels at tile size 16 the stream length differences are between 20 level 0 to 100 level 4 kilometers with tile size 32 the differences range from 30 level 5 to 99 level 2 kilometers tile size 64 the smallest difference of 66 km occurs at level five the largest difference of 100 37 km at level one at tile size 128 the stream length differences range from 13 level 5 to 98 km level 0 with tile sizes above 16 the largest stream differences occur at lower quadtree levels with smaller differences at higher levels while at tile size 16 it is the reverse with a smaller difference at level zero and stream difference increases at high levels removing slivers and small areas for all tile sizes and quadtree levels at the lidar juniata watershed were effective ranging from 97 71 to 100 success rates the number of slivers identified ranged from 6516 tile size 16 level 0 up to 443 242 triangles tile size 128 level 5 appendix c2 the mesh workflow resulted with no slivers and small areas at tile size 16 level zero with all tile sizes level five produced and retained the most slivers approximately 0 012 of the total produced triangle count with 141 remaining at tile size 16 449 at tile size 32 1811 at tile size 64 and 10 140 triangles at tile size 128 appendix c2 most of these sliver and small area triangles occur near stream inlets and outlets identified as critical see section 2 4 4 although more slivers were retained at larger tile sizes and quadtree levels as discussed in section 4 3 3 3 3 susquehanna watershed the ned elevation resolution at the susquehanna watershed supports all four tile sizes as shown in table 9 quadtree level zero has the smallest number of triangle counts for each tile size with 54 760 triangles at tile size 16 62 200 at tile size 32 80 170 at tile size 64 and 128 190 at tile size 128 appendix b3 in contrast the highest triangle counts occur at level five 669 256 at tile size 16 2 345 198 at tile size 32 8 840 635 at tile size 64 34 401 352 at tile size 128 at tile size 16 the lowest number of triangles 54 760 occurs at level zero as well as the least number of stream segments 28 154 these relatively low numbers at the susquehanna watershed reflect with the lowest stream length comparison of 85 91 and the highest perimeter ratio of 8 97 both measurements indicate the generation of irregular larger triangles along the stream network losing stream curvature features however as the quadtree level increases at tile size 16 the increase in triangle and stream counts improves both measurements with a high stream length of 92 28 and low perimeter ratio of 1 19 at level five as with the juniata a pattern of low stream length comparisons at level zero and then high stream length comparisons objective of workflow towards quadtree level five was repeated with the remaining tile sizes the mesh workflow produced stream comparisons at level five of 94 99 at tile size 32 97 11 with tile size 64 and 98 44 at tile size 128 however the susquehanna stream network is approximately fifty two thousand kilometers in length table 1 resulting with large stream length differences between the mesh workflow result and the nhd input at tile size 16 the difference in total stream length between the nhd inputs varies from 3997 km to 7293 km from 2591 km to 7062 km at tile size 32 1498 km 6614 km at tile size 64 and 808 km 5872 km at tile size 128 to reduce these stream length differences the user will have to increase the quadtree level and or increase the tile size with consequences discussed in sections 3 4 and 4 3 1 the sequence of high perimeter ratios at level zero towards the goal of a perimeter ratio of one towards level five are repeated with all tile sizes again there is a substantial increase in the total triangle counts to achieve perimeter ratio of one by increasing tile size the perimeter ratio at level zero improves rapidly from 8 97 tile size 16 4 72 tile size 32 2 74 tile size 64 and 1 82 tile size 128 towards the goal of one at quadtree level five the perimeter ratio is 1 19 at tile size 16 1 09 at tile size 32 1 04 at tile size 64 and the best perimeter ratio result at the susquehanna watershed was 1 02 at tile size 128 removing slivers and small areas for all tile sizes and quadtree levels at the ned susquehanna watershed were effective ranging from 99 79 to 100 success rates the number of slivers identified ranged from 13 448 tile size 16 level 0 up to 584 257 triangles tile size 128 level 5 see appendix c3 the mesh workflow resulted with no slivers and small areas at level one with tile sizes 16 and 32 level five at all tile sizes produced and retained the most slivers approximately 0 003 of the total produced triangle count with 15 remaining at tile size 16 70 at tile size 32 283 at tile size 64 and 1245 triangles at tile size 128 appendix c3 3 3 4 chesapeake bay watershed the ned elevation resolution at the chesapeake bay watershed supports all four tile sizes as shown in table 10 to retain near square sampling the number of tiles produced is twice the size of a quadtree structure equation 3 quadtree level zero has the smallest number of triangle counts for each tile size with 144 404 triangles at tile size 16 160 370 at tile size 32 200 290 at tile size 64 and 303 724 at tile size 128 appendix b4 these relatively low number of triangle counts is why all the quadtree level zero tile sizes had the highest perimeter ratio with a ratio of 10 1 at tile size 16 5 22 at tile size 32 2 99 at tile size 64 and a ratio of 1 95 at tile size 128 the highest triangle counts occur at level five 1 407 418 at tile size 16 4 767 525 at tile size 32 17 709 853 at tile size 64 and 68 501 899 triangles at tile size 128 with more triangles at level five the mesh workflow generates perimeter ratios closer to one as tile sizes increase with a ratio of 1 21 at tile size 16 1 09 at tile size 32 1 04 at tile size 64 and a ratio of 1 01 at tile size 128 quadtree level zero also has the smallest number of stream segments ranging from 74 145 segments at tile size 16 up to 121 828 segments at tile size 128 smaller numbers of segments indicate the generated stream geometry is not capturing the stream curvature inputs hence level zero stream comparisons are the lowest with 84 95 at tile size 16 85 34 tile size 32 86 21 tile size 64 and 87 63 at tile size 128 the largest numbers of stream segments occur at quadtree level five for each tile size with 251 383 at tile size 16 446 150 at tile size 32 832 608 at tile size 64 and 1 591 544 at tile size 128 therefore level five has the highest stream length comparisons of 91 62 at tile size 16 94 37 tile size 32 96 66 tile size 64 and the highest comparison of 98 21 with tile size 128 however the chesapeake bay stream network is approximately 132 thousand kilometers in length table 1 resulting in substantial stream length differences between the mesh workflow result and the nhd input at tile size 16 the difference in length between the nhd inputs varies from 11 038 km to 19 826 km from 7417 km to 19 315 km at tile size 32 4400 km to 18 173 km at tile size 64 and 2362 km to 16 306 km at tile size 128 removing slivers and small areas for all tile sizes and quadtree levels at the ned chesapeake bay watershed were effective ranging from 99 82 to 100 success rates the number of slivers identified ranged from 191 664 tile size 16 level 0 up to 1 326 502 triangles tile size 128 level 5 appendix c4 the mesh workflow resulted in the least number of slivers at levels zero and one with all tile sizes level five produced and retained the most slivers approximately 0 003 of the total produced triangle count with 53 remaining at tile size 16 167 at tile size 32 599 at tile size 64 and 2354 triangles at tile size 128 appendix c4 the majority of these sliver and small area triangles occur near stream inlets and outlets identified as critical see section 2 4 4 and how to decrease these counts are discussed in section 4 3 3 3 5 mixing ned and lidar two tile sizes 32 and 64 quadtree level five experiments table 1b were conducted with shale hills lidar overlaid on top of juniata ned as summarized in table 8c a third experiment was superimposing the juniata lidar elevation dataset over the susquehanna ned watershed with a tile size of 64 shown in table 9b inspecting mesh workflow triangle count results the susquehanna test produced identical results appendix b3 and the juniata tests generated 8 and 14 less triangles appendix b2 with these minor differences the perimeter ratios are identical by examining the stream segment results 214 tile size 32 and 830 tile size 64 were added by the mesh workflow at the juniata watershed equating to the stream length increasing by 21 0 19 increase and 47 0 43 increase kilometers respectively in contrast there were six less stream segments generated at the susquehanna watershed the stream length was reduced by 500 m the stream length comparison percentage was not affected removing slivers and small areas for all three experiments were effective ranging from 99 73 to 99 91 success rates the number of slivers identified were 82 808 juniata tile size 32 level 5 159 081 juniata tile size 64 level 5 and 298 885 susquehanna tile size 64 level 5 triangles appendix c5 at the juniata watershed experiments 0 005 slivers remained tile size 32 had 109 and tile size 64 had 429 and 0 003 remained 283 slivers at the susquehanna watershed with tile size 64 at quadtree level five additionally there is an impact on hpc performance by mixing elevation data sets with these workflows requiring more time than the ned versions appendix c with only minor differences generated in lengths of the stream network therefore the remaining sections will consider the mixing of elevation sources as the same with ned or lidar mesh workflow results however the addition of multiple lidar datasets covering larger areas within the larger catchments would create larger differences in the generated stream network results not explored here 3 4 mesh workflow hpc results this section summarizes the hpc performance of the mesh workflows by first comparing the generated data sizes for each of the different scale watersheds understanding the disk usage requirements assists in predicting mesh workflow requirements and ways to improve performance the second evaluation is comparing total wall times versus cpu times for each of the watersheds ideally wall times will be low and the differences between wall and cpu times are high with no cpu idle times equating too efficient parallel hpc the last comparison is investigating the wall and cpu times per quadtree tile looking for trends in how long it takes to process and generate data and to identify if the cpu is idle three servers were used to perform these mesh workflows and the server features are summarized in appendix d appendices d1 to d4 summarize the hpc results for each watershed and the following subsections contrast the hpc results with all watershed study locations 3 4 1 disk usage the tree map shneiderman 1992 for disk storage with all the mesh workflows is summarized in fig 6 each watershed spatial scale and elevation source has a separate color for example the juniata lidar workflows are shaded in green and the juniata ned workflows are shaded in yellow the larger uniform shaded areas represent more disk storage and file counts than the smaller areas thus the chesapeake bay brown rectangles requires the most disk storage ranging from 924 megabytes at tile size 16 quadtree level zero brown rectangle located in bottom right corner up to 290 gigabytes at tile size 128 quadtree level five brown rectangle located in top left corner shale hills orange requires the least amount of disk storage furthermore the sequence of watershed disk storage requirements is revealed in fig 6 that do not match the spatial scales table 1 the total disk storage for all chesapeake mesh workflows required 711 gigabytes susquehanna 337 gigabytes juniata lidar 470 gigabytes juniata ned 264 gigabytes and shale hills lidar required 20 gigabytes based on spatial scale the susquehanna catchment would be the second largest disk user but follows the juniata lidar mesh workflow results using lidar elevation generates more triangles and stream segments than ned the juniata lidar tile size 128 at level five generated 67 815 622 triangles nearly twice the amount at the susquehanna 34 401 352 triangles watershed appendix b additionally quadtree levels three to five dominate fig 6 as these generate the most number of tiles and represent the largest triangle and stream counts for all mesh workflows 3 4 2 wall versus cpu time for all chesapeake mesh workflows brown rectangles in fig 7 the total wall time was 44 days and total cpu time was 170 5 days at the susquehanna watershed the total wall time was 11 5 days and 47 35 cpu days the juniata lidar mesh workflow took 21 5 days wall time and 90 cpu days nearly twice the amount of time as the susquehanna workflows the juniata ned mesh workflow a sub watershed of the susquehanna was slightly faster than the susquehanna results requiring 9 8 wall time days and 39 45 cpu days the shale hills workflows took 1 75 wall time days and 7 5 cpu days the wall and cpu times of the ned juniata and susquehanna mesh workflows were similar as the triangle counts are also comparable for example at tile size 128 quadtree level five there are 32 513 133 and 34 401 352 triangles respectively appendix b2 and b4 indicating that the triangle dimensions are smaller at the juniata catchment than those of the susquehanna watershed however both watersheds have been constrained by the maximum quadtree level of five as discussed in section 3 1 the juniata lidar workflow generated 67 815 622 triangles about twice the number of triangles at both ned juniata and susquehanna mesh workflows and required twice the amount of time however when comparing similar total triangle count workflows between the juniata lidar workflow and the chesapeake bay ned workflow 68 501 899 triangles at tile size 128 level five the chesapeake workflow took twice as long this discrepancy occurred as the workflows used different servers appendix d with different hard disk properties the chesapeake bay workflow cpus were idle due to the cpu waiting on the slower disks to respond the workflows were disk bounded as revealed in fig 7 the largest rectangles wall times occur with quadtree levels four and five amongst all mesh workflows tile size 128 at quadtree level five took the most amount of wall and cpu times for all watersheds a total of 20 64 wall days and 87 35 cpu days at the chesapeake bay 12 57 days and 54 cpu days at the juniata using lidar 6 26 days and 26 81 cpu days at the susquehanna watershed 5 73 days and 23 63 cpu days at the juniata with ned elevation at shale hills with lidar tile size 16 took the longest amount of time 21 39 h and 3 79 cpu days 3 4 3 wall versus cpu time per tile total cpu and wall times for quadtree level five required the most amount of time as the mesh workflows are generating either 1024 or 2048 tiles significantly more tiles than lower quadtree levels as explained in section 2 4 another way to understand the performance of the mesh workflows is to analyze the wall and cpu times per individual quadtree tile to predict workflow performance on large distributed hpc environments as reflected in fig 8 individual wall times per tile for the chesapeake bay requires more than the other watersheds combined as the watershed size increases so too does the number of triangles and stream segments per tile and at small quadtree levels levels 0 and 1 there is more work for an individual tile to perform fig 6 and the mesh workflow is not efficient at small watershed scales shale hills and the juniata the wall time is relatively low but at the susquehanna watershed level 0 took 90 min and the chesapeake bay took 10 h at level zero having these benchmarks against watershed sizes helps predict mesh workflow completion times and inform end users in contrast quadtree levels three and higher are ideal for distributed computing with smaller numbers of triangles per individual tile appendices d1 to d4 shows the wall and cpu times per tiles for example the juniata ned workflow took about 18 wall time hours at tile size 64 with quadtree level five the wall time per tile was 1 05 min and 4 24 cpu minutes per tile it is reasonable to expect the same mesh workflow to take a few minutes on a 1024 node hpc cluster 4 demonstration of mesh workflow the previous sections have discussed the mesh workflow software components the hpc performance and the generated mesh characteristic results at the four watershed study locations this section focuses on demonstrating the mesh workflow results in particular the performance of replicating the user defined stream inputs section 4 1 describes the impact of elevation resolution with quadtree levels and user defined tile sizes to empower the user with choices on creating different types of meshes for their hydrological modeling purpose section 4 2 compares the stream differences between the user supplied stream network and the mesh workflow generated stream networks at the four watershed study location extents section 4 3 examines the mesh qualities of stream length perimeter ratio and thinness ratio at the stream extent to demonstrate the impact of user inputs with the juniata mesh workflow the last section demonstrates using the quadtree data structures to provide the user multiple options to create dynamic meshes that are suitable for the users hydrological modeling requirements and hpc constraints 4 1 understanding the impact of elevation resolution with tile sizes and quadtree levels when users have access to fine resolution elevation datasets the user has more control on how she or he can generate a mesh model for example at shale hills using the ned product provides little variance between the total number of tiles 1 4 and triangle sizes 32 23 m 40 83 m hence at this spatial scale hpc environments are not necessary when one tile can capture the elevation resolution to represent the shale hills watershed however using the pasda lidar elevation product there are more options for the user with a tile count range of 2 2048 and triangle sizes of 0 97 m up to 26 33 m users interested in modeling the shale hills watershed at 0 96 m by 0 95 m triangle resolutions elevation resolution will require access to a minimum 32 node hpc cluster tile size 128 at level 2 128 nodes with tile size 64 at level three 512 nodes with tile size 32 at level four and 2048 nodes with tile size 16 at level five by assigning one tile mesh per compute node as the watershed extent increases the user has more hpc options for their modeling goals for example the juniata watershed has maximum quadtree levels ranging from five tile size 128 to eight tile size 16 with the ned data product that could be modeled on a large hpc cluster size 1024 nodes at level 5 to the largest hpc clusters 65 536 nodes at level 8 assuming one tile per core rather than one compute node however to model the juniata watershed with the pasda lidar elevation product treating each tile as a compute node is not currently feasible with existing hpc resources to model the juniata watershed at the maximum quadtree level requires hpc resources ranging from 524 288 tile size 128 at level 5 to 33 554 432 tile size 16 at level 12 compute nodes instead of assigning one tile per compute node one tile will need to be assigned per compute core requiring access to the largest hpc resources of 10 million cores top 500 2016 at the juniata watershed furthermore as the watershed scale increases susquehanna and chesapeake bay using the ned product the number of compute nodes required exceed current hpc resources with tile sizes ranging from 16 to 128 users will be required to increase the tile size above 128 to decrease the maximum quadtree level for users to compute one tile per compute node however increasing tile sizes has a performance impact with mesh workflows for example at the juniata watershed ned mesh workflow at quadtree level five cpu time per tile was 2 45 min at tile size 16 2 82 min at tile size 32 4 24 min at tile size 64 and 33 23 min at tile size 128 a similar decrease in performance was observed with the juniata lidar meshwork and the other watershed workflows after tile size 64 the cpu idle times increase as the mesh workflows are disk bounded therefore users will need to determine what strategy is ideal for their compute requirements by either assigning one tile per core versus one tile per compute node dependent on their model physics computation requirements and their desired triangle size furthermore there is an impact on the generated stream networks which are first demonstrated at the entire watershed extent 4 2 where are the stream differences at watershed extent as discussed in sections 2 and 3 mesh workflows were performed at four watershed scales table 1 at quadtree levels 0 to 5 with tile sizes 16 32 64 and 128 at shale hills the ned elevation dataset supported two tile sizes and a maximum quadtree level of one while the lidar elevation dataset supported all tile sizes the maximum number of levels ranged from 2 to 5 fig 9a visualizes shale hills lidar mesh at tile size 16 level zero triangles not adjacent to the stream are uniform and those near the stream are comparable size without losing the stream curvature as reflected with stream length differences in centimeters table 7 with streams generated by the mesh workflow and the stream input dataset however the shale hills stream network is not complex and all the mesh workflow results are similar this is not the case with the remaining watershed studies this section focuses at quadtree level 5 with the best matching stream lengths and supplied data and distinguishes where the stream network is not identical to the supplied nhd dataset to visualize the differences between the nhd and mesh workflow generated stream network the symmetrical difference esri 2016b between the two datasets were calculated in figs 9 15 the blue lines represent identical nhd and mesh workflow generated stream segments and white dots and lines highlight locations where the two datasets are different at figs 12 15 these matrices are zoomed spatially close to the stream geometry and the white dots become apparent as missing stream segments the generated triangles are only shown in figs 14 and 15 as it is not feasible to distinguish from the millions of triangles generated at full watershed extent scales these millions of triangles that are not near stream networks are uniform in size as the mesh workflows alter triangles near stream networks as discussed in section 2 4 hence it is not necessary to visualize these triangles additionally the grid of thin grey lines shows the quadtree tile locations the larger watersheds delineate the location of smaller sub watersheds performed by the mesh workflows to aid in visualizing scale at the juniata watershed with a tile size of 128 at quadtree level 5 the ned mesh workflow stream length comparison was 98 69 a stream length difference of 143 km between the generated stream and nhd network these stream differences white segments are shown in fig 9b the lidar mesh workflow stream results at the juniata are shown in fig 9c the lidar results produced a stream comparison of 98 80 or a stream length difference of 130 km between the nhd network although the stream differences are relatively small between the elevation sources as fig 9 demonstrates the spatial distribution between the two elevation workflow results are not similar with the ned workflow results having 4544 missing stream segments ranging from 10 24 to 222 m in length and a mean of 27 78 m while the lidar mesh workflow had 6735 missing stream segments with segment lengths ranging from 7 31 to 105 46 m and a mean of 20 36 m with the susquehanna watershed fig 10 the ned mesh workflow produced a stream comparison of 98 44 a stream length difference of 808 km between the nhd and generated stream network the ned workflow generated 5303 stream segments that did not match the nhd stream network the segment lengths ranged from 36 71 to 574 21 m with a mean of 161 32 m at the chesapeake bay watershed fig 11 the ned workflow produced a stream comparison of 98 21 a stream length difference of 2362 km between the nhd and generated stream network the ned workflow generated 12 532 stream segments that did not match the nhd stream network the segment lengths ranged from 35 29 to 834 31 m with a mean of 173 92 m visually examining where the stream differences occur within the larger watershed extents the spatial patterns do not concentrate at any particular locations and appear at first random at the larger catchment scales the stream differences are significant for example the chesapeake bay watershed difference represents 21 of the juniata stream network to understand where these stream differences occur the next subsection compares the mesh qualities between ned and lidar with the juniata watershed at the stream segment extent understanding where the stream differences occur is important to help users choose parameters to control the mesh workflow 4 3 examining mesh qualities at stream extent recall the main objective of the mesh workflow is to replicate the stream inputs using a quadtree data structure that can be used to dynamically select tiles for distribution in a hpc environment this subsection discusses the impact on stream geometry quality by the choices made by the user on tile sizes quadtree levels and the elevation data source this section focused on the juniata watershed where both ned and lidar elevation mesh workflows were studied that generated different mesh qualities section 4 2 examined both juniata mesh workflows at the full extent of the watershed this section focuses on two locations the first is the stream network identified in fig 9e with the ned results shown in fig 12 and the lidar results in fig 13 the second location is the stream intersection marked at fig 9f within the first location extent with figs 14 and 15 revealing the ned and lidar mesh workflow results respectively 4 3 1 how user choices affect stream lengths the stream length results for the juniata mesh workflows are described in section 3 3 2 that provide total lengths for tile sizes 16 32 64 and 128 between quadtree levels 0 to 5 here the focus is on examining how user choices affect stream lengths as well as where the differences between generated stream networks and inputs occur for each of the tile sizes examined quadtree level zero stream lengths generated the largest differences and level five generated the smallest differences this occurs as tile sizes control the number of samples per tile with level zero having the least number of samples as the juniata has one tile using ned and two tiles with lidar at tile size 16 level zero the mesh generated stream network blue lines is only using the start and end vertices of a stream segment with both elevation sources as shown in figs 12 and 13 increasing tile sizes slightly improves the stream network at level zero by generating longer stream segments with each quadtree level increase more stream segments are inserted by visually inspecting the differences between the blue mesh workflow generated and white nhd user input lines with the objective of not seeing white lines it is not until reaching level three tile size 128 does the stream network resemble the user input datasets with both elevation sources tile sizes 16 and 32 consistently do not capture the stream curvatures as shown in figs 12 and 13 tile size 64 replicates more of the stream curvatures than tile sizes 16 and 32 although using lidar reproduces the stream curvatures at an earlier quadtree level than the ned mesh workflows due to higher elevation resolution it is clear that tile size 128 performs better at replicating the stream network with both data sources however the computational costs disk cpu memory are significant appendix d compared to the other tile sizes the main reason for higher costs are the larger number of triangles appendix d generated by the mesh workflows as shown in figs 14 and 15 at tile size 128 quadtree level 3 the density of triangles is large compared to the other tile sizes and at each level the triangle sizes become smaller and capture the stream curvature comparing tile size 128 at level 5 between ned fig 14 and lidar fig 15 elevation sources it is evident that the mesh workflow can generate more uniform triangles with lidar and capture the stream curvature thus the user has a choice between longer compute times to generate stream networks that match the supplied inputs versus shorter compute times that over simplifies the stream network users interested in shorter compute times not only loose stream curvature but will be required to handle stream segments that cut through hills as highlighted in figs 12a and 13a to manage these occurrences the user will need to validate the stream network in the large graph workflow section 2 2 to confirm elevation values at stream vertices depending on the user elevation resolution and mesh workflow parameters this process may require numerous iterations and be time consuming therefore the user would shorten these processes by choosing a tile size and quadtree level that resembles the stream network as close to the hpc constraints as possible for example as a minimum use tile size 128 at level 3 fig 12 for the ned mesh workflow and tile size 128 at level 2 using lidar elevation fig 13 4 3 2 obtaining a perimeter ratio of one ideally the mesh workflows would generate a perimeter ratio of one indicating that the mesh triangles are uniform and capture the stream network that is identical to a mesh at the elevation resolution the shale hills lidar mesh workflows generated a perimeter ratio of one and the juniata ned and lidar mesh workflows nearly achieved a ratio of one as with the stream length comparisons tile size 128 performed better than the other tile sizes at all quadtree levels with values of 0 99 1 02 with the ned mesh workflow at level 5 the 0 99 perimeter ratio indicates there are more triangles along the stream network to capture stream curvature however this was not enough to generate a perfect stream comparison as shown in figs 9 12 and 14 poor curvature occurs as stream bends are often less than the elevation resolution of 10 or 30 m more triangles will be necessary to improve the stream curvature generating smaller triangles than the supported ned elevation resolution appendix a the lidar mesh workflows at levels four and five generated a perimeter ratio of 1 01 and this mesh workflow is more likely to generate a ratio of 1 0 as occurred at shale hills watershed with larger quadtree levels as most stream curvature diameters are measured larger than the 1 m elevation resolution however the lidar elevation at the juniata watershed supports up to nine levels at tile size 128 requiring a total of 524 288 tiles assuming ten minutes per quadtree tile the mesh workflow would take nearly ten years to finish on the systems listed in appendix d evidently a large hpc system is required to complete the mesh workflows at these scales 4 3 3 how user choices impact the creation of slivers and small triangles as described in section 3 3 2 the removal of slivers and small triangles were effective from 97 71 to 100 success rates at the juniata mesh workflows as identified in section 2 4 4 there are situations when slivers and small triangles remain controlled by user inputs table 2 for example figs 14a and 15a shows where small triangles were not removed as all three vertices are on the stream network and fig 14b and fig 15b identify where small triangles occur with two vertices on the stream network to remove these small triangles users will be required to modify the maximum buffer distance table 2e and the small area threshold table 2h the removal of slivers was also constrained by multiple vertices located on the stream network for example at fig 14c and fig 15c additionally as the tile sizes and number of levels increase the total number of triangles increase appendix b and so too does the number of slivers appendix c as indicated in fig 14d and fig 15d to remove these slivers users will be required to use the delete option table 2k rather than the add option used in these figures and modify the delete node threshold table 2i the goal of the mesh workflow is to support users to generate multiple tests to remove slivers and small triangles however without hpc support dense meshes with tile sizes of 128 and above it is difficult to do multiple tests new algorithms are required to improve the removal process since more triangles equates to higher sliver counts and small triangles furthermore additional research is required to find ways of improving the user options outlined in table 2 by automating these values based on the user supplied datasets to accommodate stream curvature below elevation resolution as an alternative solution to using one quadtree level section 4 4 mixes tile sizes and levels to generate different meshes for hydrological modelling 4 4 picking quadtree tiles along storm path recall one of the main objectives of the mesh workflow is to provide user flexibility and control on generating different types of meshes for hydrological modeling as the previous sections have demonstrated the user can generate meshes consisting of many millions of triangles for models like pihm more triangles are computationally expensive leonard 2015b therefore strategies are necessary to maximize where triangles are required and to minimize where triangles are not essential using the quadtree data structure provides the user multiple options to select tiles based on desired level and triangle counts rather than generating all tiles for a complete quadtree level for example fig 16 demonstrates choosing quadtree tiles following a storm path for both ned fig 16 a and lidar fig 16 b elevation sources at the juniata watershed by using the techniques discussed in section 2 4 2 the user can estimate the number of triangles generated for each quadtree tile per level for a watershed domain he or she supplies a storm path and specify buffer distances to select quadtree tiles i e levels 4 and 5 that require dense triangles for potential flooding locations while tiles that are located the furthest away from the storm path use lower quadtree levels 0 to 2 to reduce triangle count totals with the ned storm path example fig 16 a 352 tiles were selected with 22 tiles at levels 2 3 82 tiles at level 4 and 248 at level 5 triangle counts ranged from 225 453 at tile size 16 up to 11 432 584 at tile size 128 using lidar elevation fig 16 b 348 tiles were selected with 54 tiles at levels 1 3 140 tiles at level 4 and 154 tiles at level 5 lidar triangle counts ranged from 231 368 at tile size 16 up to 11 770 812 at tile size 128 both workflows produced comparable triangle counts and assuming one tile per compute node both storm path examples require less compute nodes needed at level 5 appendix b to accommodate more hpc cluster environments however using a quadtree does constrain the user selecting tiles must match the tile edge at the adjacent tile level for example the single level 2 tile requires two level 3 tiles at the northern and western edge at fig 16c location to generate connection files as described in section 2 4 5 to further demonstrate mesh quality and mixing quadtree level tiles the meshes were rendered from a camera perspective following the arrow direction at fig 16d fig 16e shows the triangle mesh lidar quality with tile size 128 in the foreground and fig 16f representing the same perspective using points to reveal stream locations to contrast mesh quality differences between tile sizes and elevation source fig 16g shows the triangle mesh using ned clearly lidar retains more topographic features and retains hill slope features fig 16h represents the ned triangle mesh as lines to show the contrast of mesh tile qualities there is an art in generating quality meshes suitable for environmental modeling here using quadtrees to select suitable meshes for hydrological science has been demonstrated quadtrees enable users to choose a wide range of mesh qualities within available hpc resources to create multilevel meshes that are scalable and dynamic for watersheds ranging from hill slope to conus scales 5 limitations and constraints hydrologic models such as le pihm zhang et al 2016 where streams are dynamically changing both spatially and with time are not considered here other hydrological features such as lakes and dams were not included in the mesh workflow process stream flow directions were validated with the two smaller watersheds only shale hills and juniata watersheds there is no impact on the mesh workflow performance with inconsistent flow directions however with models like pihm there is an impact on model performance as computational solvers will unlikely resolve physics equations the non production servers appendix d used to record times presented in the appendices and sections 3 and 4 are slightly different the larger watersheds used a server with slower disk speeds and results would be improved on faster disks as the mesh workflows were disk bounded furthermore the meshes were not simplified during delaney triangulation this strategy was used to record the worst case time scenario of very detailed triangle counts that are uniform in size levels 3 and higher within the complete tile triangle counts could be reduced but future work will include additional datasets that will require these triangles the results presented here serve as a benchmark to understand the impact on these datasets for hydrological modeling 6 conclusion providing the ability to incorporate large stream networks into very large dynamic mesh models coupled with etvs is important to improve hydrological science the challenges of working with four watershed scales ranging from hill slope to four level 4 hucs using nhd and ned were demonstrated using mesh workflows the main software components of the mesh workflow were described including user parameters that control mesh and stream geometry how quadtree meshes were generated and merged with the stream network steps taken to remove slivers and small triangles and the output datasets used for hydrological modeling to evaluate mesh and stream geometry from the mesh workflow three metrics were used the first was comparing the user supplied stream network lengths with those generated by the workflow stream length comparisons ranged from 84 95 to identical matches 100 at the four watershed scales however depending on the chosen tile size and quadtree level the stream length differences can be quite large due to the workflow not capturing all stream curvature features the second metric was comparing the triangle perimeter ratio between a mesh with no embedded streams with the quadtree generated mesh and stream network a sufficiently small and uniform triangle mesh will closely match the user supplied stream network a ratio near one mesh workflow results varied from 0 98 to 10 01 with high ratios occurring at low quadtree levels ratios near one at quadtree levels 3 and more the last metric used was the thinness ratio to identify sliver triangles many millions of triangles were created by the mesh workflows generating many thousands of slivers the success rate ranged from no slivers removed due to inappropriate workflow parameters to all slivers and small triangles removed at the chesapeake bay watershed 0 003 slivers were retained with a similar performance at the other watersheds the user has access to various strategies to remove slivers and small triangles with the mesh workflow tool presented here although there are circumstances when these issues cannot be removed hence iteration by the user is required to modify parameters to generate alternative meshes suitable for their modeling requirements at low quadtree levels and tile sizes mesh workflow iteration is rapid however at large quadtree levels and tile sizes large hpc resources are necessary to improve compute performance i e minutes not days with large hpc clusters stream length comparison and the removal of slivers the mesh workflow is scalable and the majority of workflow steps are pleasingly parallel furthermore the quadtree structure is suitable for multilevel tiles to provide the user multiple options to create dynamic meshes that are suitable for the users hydrological modeling requirements and hpc constraints 7 future direction this research focused on generating quality meshes with embedded stream networks using workflows for automation and rapid prototyping by using a quadtree data structure with multiple levels it has been demonstrated how a dynamic selection process can be used to select tiles for hydrological science purposes for example to select tiles with a dense number of triangles along stream networks that intersect a storm path for floodplain analysis here it has been demonstrated that counts per individual tile ranged from 260 to 303 724 triangles however it is unclear what an optimal number of triangles per quadtree tile is and how many triangles along tile edges is efficient for hydrological modeling for example models like pihm that exchange flux information along triangle edges how many triangles can a hpc cluster node efficiently compute pihm physics further research is required to optimize the mesh workflow to not only load balance the mesh size and connections but also consider the model physics data sizes and network constraints for efficient hpc future research will implement different spatial decomposition techniques for example by extending the quadtree implemented here to an octree data structure to incorporate bedrock depth and wells exploring other algorithms including the k d tree and the iterative wavefront edge expansion cell decomposition hale 2011 rather than generating the entire quadtree mesh levels as implemented here the next version of the mesh workflow will focus on weighting regions and using hot spot analysis techniques to prioritize regions that require fine resolution meshes doing so will not only improve the mesh generation process but will improve the hydrological science objectives the next mesh workflow generation will serve a national mesh dataset for multiple hydrological models and research objectives finally the removal of slivers and small triangles requires further advancement future mesh workflows will incorporate dams lakes bridges road networks i e culvert locations and buildings that will increase the mesh complexity and the generation of slivers users will require more control to fine tune and identify slivers interactively with multiple strategies for different datasets visual analytic tools will be necessary to guide users with identifying and prioritizing user attention to select appropriate parameters to control the mesh quality pertaining to their modeling requirements software availability name quadtree mesh workflow developer lorne leonard department of civil engineering department of computer science and engineering department of landscape architecture and institutes of energy and theenvironment the pennsylvania state university contact information lorne leonard department of civil environmental engineering the pennsylvania state university 406 sackett building university park pa 16802 usa software required internet browser later versions are recommended program language c c python arcgis availability and cost any user can access hydroterre web applications at no cost at http www hydroterre psu edu contact developer availability with mesh workflow appendix a supplementary data the following is the supplementary data related to this article appendices leonard appendices leonard appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2017 11 036 
26140,generating quality meshes for hydrological modeling is challenging this article demonstrates using mesh workflows to incorporate national stream networks into very large dynamic meshes for distributed high performance computing hpc a multilevel quadtree is used to partition watersheds and merge stream networks ranging from hill slope to four level 4 hydrological unit code huc scales generating mesh sizes from hundreds to tens of millions of triangles by using a mesh workflow it is demonstrated how users control mesh quality including triangle sizes and the removal of small triangles and slivers four watersheds are studied ranging in scale from shale hills hill slope to the chesapeake bay 177 968 sq km and are used to compare mesh characteristics with user parameters and different elevation sources to generate a spectrum of multilevel quadtree meshes by using triangles to represent land surface and stream networks stream curvature is lost and the mesh workflow is used to demonstrate what parameters are important to maintain stream characteristics to meet hpc constraints the multilevel quadtree is demonstrated by picking quadtree tiles along a storm path to show how users can combine quadtree tiles at multiple levels to concentrate hpc resources for hydrological science research graphical abstract image 1 1 introduction meshes representing elevation surfaces or the ground are a critical component of many environmental models and this paper presents a mesh workflow a set of repeatable software components and processes to aid modelers to create quality surface meshes using national elevation ned usgs 2011 and national hydrography datasets nhd nhd 2013 for hydrological modelling anywhere in the continental united states conus the mesh workflow is a software component extension of the hydroterre end to end workflows leonard and duffy 2013 leonard and duffy 2014b leonard 2015b leonard and duffy 2016 hydroterre has been designed to prepare essential terrestrial variables etv for individual united states geological survey usgs level 12 hydrological unit code huc anywhere in the conus the mesh workflow has been designed to consume multiple level 12 hucs using a corrected large graph to collate etvs a corrected large graph contains validated stream flow network geometry and adjacent huc selections using a graph based visual analytics workflow designed for large scale hydrological modeling leonard et al 2015 leonard et al 2017 that validates streamflow directions this article focuses on the processes needed to create multilevel simplification meshes using ned and merging nhd stream networks into the mesh geometry to be used in hydrological modeling with distributed high performance computing hpc mesh workflows are essential to handle the complexity of merging these datasets to create and refine geometry with 10s 100s of millions of triangles appropriate for hydrological science research with the long term goal of generating triangles smaller and smaller as when the mesh is refined the computed hydrological solution will approach the true solution this article is structured as follows section 1 introduces the study locations and the reasons why multilevel mesh workflows are necessary for large scale hydrological modeling section 2 explains details about the software components used to process the national datasets and generate quality meshes for hydrological modeling section 3 describes the user parameters that control the mesh workflow the methods used to predict and evaluate mesh qualities the mesh characteristics and hpc results at the study locations section 4 demonstrates the mesh workflows describes differences found with inputs and the resultant stream networks how users can improve results by examining mesh qualities at the study watershed locations is discussed followed by a demonstration at one study site location as to why a multilevel mesh is required for hydrological modeling 1 1 why use multilevel mesh workflows before modeling any large scale watersheds predicting mesh sizes and compute requirements is necessary to determine if available hpc resources are adequate and the resultant mesh is suitable for the modelers objective this article demonstrates a mesh workflow that provides users these features for watershed sizes ranging from hill slope to conus scales by generating multilevel quadtree meshes quadtree is a tree data structure where each node has exactly four children finkel and bentley 1974 here quadtrees are used to partition the elevation model of the watershed in two dimensions by recursively subdividing the elevation model into four quadrants each quadtree depth or level represents the elevation surface at a different resolution tile size or simplification method each quadtree level has multiple nodes with each node containing a triangulated irregular network tin based on delaunay triangulation cheng et al 2012 therefore each quadtree tile at a level is an individual mesh suitable for distributed parallel computing however for most hydrological models the stream network is a critical data input and elevation models do not delineate the stream network from the elevation raster surface software tools such as taudem tesfa et al 2011 extract the stream network from elevation models yet at places throughout the conus these data products do not match the stream network delineated by nhd nor seen with aerial photography leonard 2015a leonard et al 2015 furthermore additional datasets such as road networks and other urban infrastructure are needed for hydrological modeling that affect mesh characteristics combining these datasets is challenging due to data quality differences and the likelihood of generating a poor mesh is high as will be demonstrated throughout this article the hpc requirements for large scale mesh workflows are demanding hence one way to constrain hpc requirements is to mix tiles from multiple quadtree levels to create a multiresolution mesh mixing quadtree level tiles provide users more options with mesh sizes and is suitable for hpc load balancing as an example for floodplain analysis the user could select quadtree tiles with small triangle sizes that spatially intersect a storm path while further away from the storm path triangle sizes are large therefore dataset networks need to match at quadtree tile edges at the same level but at the other mesh levels as well consequently a mesh workflow is important to aid users in managing and creating quality meshes for hydrological models that require hpc distributed computing to demonstrate the multilevel mesh workflows four study locations were selected table 1 using the etv and large graph case studies leonard and duffy 2013 leonard et al 2015 the largest watershed studied is the chesapeake bay watershed containing four level 4 hucs located on the east coast of the united states of america the remaining watersheds in descending size are the susquehanna juniata and shale hills each watershed is a sub watershed of its predecessor with the two smallest watersheds lidar elevation datasets from pennsylvania spatial data access pasda 2016 are used to compare stream geometry and mesh characteristics from the workflow to further demonstrate why mesh workflows are needed the next subsection describes common issues with meshes that affect hydrological modeling 1 2 what are common mesh issues for hydrological modeling there is an art in creating suitable meshes for hydrological modeling and common issues are discussed here that explain the need for a mesh workflow the penn state integrated hydrologic model pihm is used to demonstrate issues with meshes found amongst other hydrological models using polygon meshes as input datasets pihm is a physics based fully distributed hydrological model for simulating hydrologic state variables in space and time supported by national climate land use topographic and hydrogeological data products qu and duffy 2007 pihmgis bhatt et al 2014 and hydroterre toolsets provide functionality to generate stream networks using taudem users specify tolerances to simplify catchment boundaries and the stream networks by removing unnecessary nodes using the douglas peucker algorithm douglas and peucker 1973 with a user supplied elevation dataset pihmgis generates delaunay triangulations using triangle shewchuk 1996 that are refined by shape and size using a delaunay refinement algorithm by ruppert 1995 the tin is constrained by the stream network and catchment boundary with generated triangles conforming to these line networks also known as breaklines these methods have been implemented at numerous individual watersheds for pihm and require fine tuning by users to generate a mesh that is uniform in size users often are required to over simplify the stream network and specify a large area threshold to generate uniform triangles to reduce the number of skinny triangles needle cap slivers cheng et al 2012 and small triangles adjacent to streams leonard 2015b slivers are undesirable because they have dihedral angles close to both zero and 180 that corrupts the stiffness matrix in the finite element method cheng et al 2012 used by the sundials solver hindmarsh et al 2005 within pihm over simplifying the stream network causes elevation sampling issues the first example is stream segments that dissect through hills rather than following the stream curvature geometry often the stream vertices sample the elevation values on the hill not the stream location by assigning downstream vertices with erroneous high elevation values values higher than the upstream vertices along the stream segment leonard 2015a the second common example is similar to the first stream segments located within valley floors sample the valley walls or above creating stream segments that resemble zigzag shapes leonard 2015b from the millions of data model pihm workflows executed from hydroterre using national datasets 26 91 failed due to a poor stream network leonard and duffy 2014b furthermore poor quality meshes were generated due to how the stream network and elevation model were merged accounting for 71 17 pihm model workflow failures leonard and duffy 2014b leonard 2015b to resolve these erroneous elevation values required manual search and editing using gis that may be reasonable for an individual level 12 huc based on the number of stream segments however manual editing is often too time consuming for multiple level 12 hucs and does not encourage reproducibility and provenance the large graph used to validate huc and stream networks workflow has automated tools to identify these stream segments using a graphical user interface with suggested elevation values based on slope and nearby elevation values nevertheless for the juniata watershed with 97 level 12 hucs addressing these stream issues is also a time consuming process taking approximately two hours to assign elevation values and correct stream flow directions both strategies require a more robust way to retain stream curvature and stream vertex placement to sample correct elevation values from the digital elevation model dem furthermore to simulate large watersheds there are two common strategies the first is to model the entire watershed on a distributed shared memory compute environment encouraging modelers to use larger triangles and over simplified stream networks to reduce triangle counts as previously described this strategy is also problematic as the tin mesh is not decomposed into subdomains so that each central processing unit cpu has about the same amount of computation and minimized communication cost between processors hager and wellein 2010 the mesh is not load balanced and will affect the hydrological model hpc performance the second strategy is to model level 12 hucs individually with a huc per compute node and manually connect stream inlets and outlets with other hucs to constitute a larger watershed this method discourages using the same parameters that control the watershed meshes with all hucs as the modeler tries to optimize each huc individually assigning different parameters per huc creates mesh problems as catchment edges are not consistent with adjacent hucs stream inlets and outlets do not match and triangle sizes do not align with neighboring hucs using this strategy ignores flux exchange such as groundwater along watershed boundaries in addition each huc has different sizes and combined with different parameters to generate tins the triangle counts per huc vary therefore the watershed is poorly load balanced and cpu idle times will be high waiting for other watershed models to resolve per simulation time step from the above mesh issues affecting hydrological modeling a mesh structure is required that creates uniform triangle sizes is capable of decomposing large scale watersheds into subdomains is suitable for load balancing and computing hydrological models with distributed hpc hence a quadtree has been used here to decompose the watersheds with each tile containing a tin with similar triangle counts consequently small area skinny and sliver triangles will be inserted into the mesh predominately from the stream network therefore this article focuses on how the mesh workflow merges elevation ned and lidar and nhd stream networks followed by how sliver and small triangles are removed to create quality meshes for hydrological modeling then the mesh and stream characteristic results at the four watershed locations with various complexities are discussed to demonstrate the performance of the mesh workflow 1 3 related work the most common technique to join stream networks and elevation models is to etch burn or surface reconditioning the streams into the elevation models to enforce mapped drainage patterns stream burning saunders 1999 maidment and djokic 2000 lindsay 2016 techniques adjust elevation grid cells within the dem to enforce or create a local drainage pattern within large watersheds such as the chesapeake bay baker et al 2006 and is often required with flat landscapes callow et al 2007 and low resolution dems these techniques are beneficial for hydrological models that derive stream networks using the dem without a polyline supplied stream network although stream burning may improve the derived stream network errors in calculated stream distances are not avoided paz et al 2008 by using raster datasets to take measurements of stream lengths paz et al 2008 reported errors as high as 7 depending on dem resolution the algorithm used to calculate stream distances and raster data structures de smith 2004 as summarized earlier pihm and other models require both elevation and stream datasets to derive the tin with the polyline stream network serving as a tin breakline the advantage of this strategy is to provide users more control of the data inputs however more control is also a disadvantage with streams being over simplified to reduce triangle counts as previously discussed here this research focuses on what type of mesh characteristics are required to replicate the user supplied bad or good stream network using a mesh workflow that generates meshes that are suitable for distributed hpc modeling mesh generation is an extensively studied field and used by many disciplines with techniques such as the quadtree and delaunay that date back to the 1970s and continue to be studied by many here this article focus is on delaunay tins quadtrees mesh reduction and sliver removal to generate quality mesh and stream networks at multiple levels for a description on delaunay mesh generation algorithms the readers are directed to research by shewchuk 2008 and cheng cheng et al 2012 with research on quadtree data structures readers are directed to samet 1984 for combining quadtrees and tins in mesh generation pajarola et al 2002 yang et al 2005 using quadtrees within terrain simplification for large terrain surfaces cignoni et al 1998 lindstrom and pascucci 2002 example research with identifying and removing slivers from meshes include cheng et al 2000 edelsbrunner and guoy 2002 research with multilevel meshes and tins include the following de berg and dobrindt 1998 walshaw and cross 2000 for related research in integrating large terrain models and stream networks in hydrological modeling readers are referred to merwade et al 2008 on flood inundation mapping tesfa et al 2011 with the extraction of hydrological proximity measures from dems the prediction of soil properties using dems florinsky et al 2002 and evaluating shuttle radar and interpolated dems for elevation gradient and soil erosion kinsey henderson and wilkinson 2013 for delineating streambanks pai and saraswat 2013 estimating stream channel geometry ames et al 2009 and the effect of lidar derived dem resolution on large scale watershed models yang et al 2014 2 creating multilevel quadtree meshes and stream networks for hydrological modeling this section describes the software and methods used to create quadtree meshes and stream networks for hydrological modeling section 2 1 summarizes the hydroterre workflows used by the mesh workflow to retrieve etvs for individual level 12 hucs to retrieve multiple level 12 hucs for larger watersheds a large graph workflow section 2 2 is used to select and retrieve etv data bundles these data bundles are combined and used as inputs to the mesh workflow as summarized in section 2 3 the last section steps through the main software components of the mesh workflow describing user inputs how the quadtree meshes are generated and merged with the stream network the steps taken to remove slivers and small triangles and output datasets used for hydrological modeling 2 1 hydroterre workflow overview hydroterre workflows are initiated via the web application by selecting a level 12 huc hydroterre consists of four workflows fig 1 a forming an end to end workflow system for hydrological modeling in a distributed computing environment leonard 2015b leonard and duffy 2016 the first is the etv data workflow fig 1b responsible for selecting projecting clipping and extracting national datasets within the level 12 huc watershed leonard and duffy 2013 creating a level 12 huc data bundle with standard geographic information system gis datasets typically takes about two minutes to create leonard and duffy 2014b the etv data workflow operates as an independent service using file formats common for many models conversely the data model workflow fig 1c is dependent and employs the etv workflow service as data inputs four parameters control the watershed level 12 huc boundary and stream topology that in turn controls unstructured mesh details for hydrological modeling leonard and duffy 2014b the data model workflow assigns land use initial conditions and other parameters using the national datasets as a priori values the pihm model workflow fig 1d consumes the data model workflow as data inputs using the web application calibration initialization and hpc model parameters are controlled by the expert user default values are assigned automatically by using data mining strategies from the previous workflow results the etv data model and model workflows have been executed millions of times to investigate the main reasons for failure within the national datasets or within the models leonard and duffy 2014b leonard 2015b the last hydroterre workflow is the visualization workflow fig 1e to encourage iterative and investigative processes by the expert user to rapidly change data model and model parameters leonard and duffy 2016 the visualization workflow consumes the data data model and model workflow services as data inputs this workflow provides maps and data visualizations for the expert user to drill down interrogate model results and rapidly test and re submit hydrological models for further analysis 2 2 large graph workflow overview the hydroterre end to end workflow described earlier considers a single level huc 12 the next step is to model connecting level 12 hucs or a graph of watersheds to achieve this goal requires a conus scale graph of all level 12 hucs unfortunately the implied graph from current nhd have issues that require expert intervention leonard and duffy 2014a leonard et al 2015 leonard 2015b the most common reasons for intervention to correct watershed graphs include conflicting edge directions edges that pass back and forth along huc boundaries and edges within flat sloped elevations leonard et al 2017 for hydrological models like pihm conflicting edge directions will cause simulations to either not converge or be inefficient in solving physics automation to correct conflicting edge directions is currently not feasible due to elevation resolution ned with 10 or 30 m and flat sloped regions leonard 2015b leonard et al 2016 for example when multiple streams edges share the same elevation raster values it is not clear whether the edge directions are valid with automated detection furthermore the conus nhd graph scale is large with 33 338 895 streams 851 265 305 unique edges and 683 298 991 unique nodes leonard et al 2016 inserting ned and lidar elevation nodes into the existing nhd network will further increase the graph size requiring significant hpc resources to automate edge directions leonard et al 2017 hence expert intervention is necessary to validate stream graphs with large graph workflows and visual analytics the large graph workflow fig 1f generates two types of graphs the first is a corrected graph of level 12 hucs that is used to retrieve data bundles from hydroterre the expert user is required to validate level 12 huc connections that have flat sloped elevation at adjoining hucs the second graph is a consistent flow direction stream network based on the nhd stream network with this graph the user is required to validate flat slope stream reaches inlets and outlets for the juniata watershed a depth first search dfs graph was generated by selecting upstream level 12 hucs from root node identification 020503041204 that creates a graph size of 97 nodes level 12 hucs validation is a time consuming and iterative process taking two hours for the juniata watershed study to validate 745 issues identified with flow edge directions leonard et al 2017 hence due to time constraints the juniata watershed is the largest watershed studied with a validated stream network with the mesh workflow in this article an in consistent stream flow direction stream network does not alter the mesh workflow results although there is an impact on performance for models such as pihm 2 3 mesh workflow overview the purpose of the mesh workflow fig 1g is to generate a land surface mesh that is suitable for hydrological modeling using parallel distributed hpc for spatial decomposition a quadtree data structure was used to partition the land surface by recursively subdividing the space into four quadrants finkel and bentley 1974 samet 1984 each quadrant or mesh tile is a standalone model input containing a land surface mesh and a stream network for a hpc compute node to resolve hydrological physics for computation messaging between tiles mesh and stream connection files are generated to communicate exchange of data between tile edges each mesh tile is rectangular for load balancing and to minimize the surface to volume ratio size of data exchanged between tiles consequently the bounding box of the entire huc graph generated from the large graph workflow is first created and then this box extent is used to recursively subdivide the elevation dataset into tiles hence rectangular tile extents are used to execute data workflows fig 1b rather than using level 12 huc boundaries not rectangular to access etv data bundles for the mesh workflow to maintain huc boundaries assigning boundary conditions are necessary at triangle edges after executing the mesh workflow the quadtree dataset is consumed by the data model workflow to generate hydrological model input files additionally as discussed in sections 3 and 4 executing the mesh workflow is computational rigorous and time consuming therefore the mesh workflow is an offline software and data service the next section discusses the mesh workflow software components 2 4 mesh workflow software components fig 2 summarizes the six main components of the mesh workflow section 2 4 1 discusses the workflow data inputs and user parameters to control the mesh quality the second and third components section 2 4 2 demonstrate how the quadtree mesh is prepared to incorporate stream network geometry section 2 4 3 the fourth component reveals the steps taken to remove slivers and small triangles from the quadtree meshes section 2 4 4 the fifth and sixth components discuss the steps taken to transform the meshes into datasets appropriate for hydrological modeling using distributed hpc resources section 2 4 5 2 4 1 input requirements the mesh workflow requires two data inputs the first input is a dem and the second is a stream network a user supplies a list of dems and stream network shapefiles that are re projected to a specified projection coordinated system in this article both datasets are generated with the large graph workflow for the smaller watersheds shale hills and juniata the large graph workflow generates a list of huc 12s that are used to create a bounding box to select and merge adjoining raster datasets with the same projection system and to provide a corrected stream network there are number of user parameters that control the mesh workflow summarized in table 2 for example users can specify the projection type table 2a by specifying the epsg code european petroleum survey group 2016 with the default type being usgs albers hydroterre default configuration code 5070 the remaining parameters are explained in further detail within the following subsections 2 4 2 validate parameters and create quadtree mesh the root region quadtree is based on the rectangular extent of the dems representing level zero or the root graph node fig 3 a based on the merged dem dataset a delaunay tin is generated by specifying the elevation tile size table 2b that controls minimum elevation sampling the next level level one is generated by decomposing level zero region into four quadrants fig 3b the merged dem is clipped into four elevation datasets a delaunay tin mesh is created for each quadrant tile using the clipped dem decomposing each level of quadrants is repeated until the user specified maximum quadtree level table 2c has been reached or decomposing stops when the triangle sizes near the elevation resolution for example in fig 3 recursion stopped at level five specified by the user however by using equation one the maximum level can be pre determined by elevation size resolution and tile size by using equation two a user can pre calculate triangle sizes without etched streams to determine if the triangle dimensions meet their modeling requirements and if the user has access too appropriate hpc resources for example to model the juniata shown in fig 3 the same watershed could be partitioned from one to 1024 hpc compute nodes with a wide range of triangle sizes furthermore equation three is used to determine whether the triangles are uniform to avoid elongated triangles by subdividing the longest edge section 3 2 demonstrates these techniques in further detail with the study watersheds therefore if the user has specified a maximum level that is not supported the workflow does not continue and the user is notified of this issue after generating the quadrant tiles leaf nodes for all levels or depths each quadrant tile is converted into a node point shapefile representing the unique nodes of all delaunay triangle meshes additionally a triangle mesh shapefile is created with neighbor identifications for each triangle edge these conversions are necessary to merge river geometry within the quadtree lw floor log2 elevwidth elevcellwidth tilesize lh floor log2 elevheight elevcellheight tilesize maxlevel max lw lh equation 1 how to pre calculate maximum quadtree level elevwidth width of elevation dataset elevheight height of elevation dataset tilesize specifies minimum number of times to sample elevation dataset triw elevwidth tilesize 1 tilewidthmultipler 2ˆlevel trih elevheight tilesize 1 tileheightmultipler 2ˆlevel equation 2 how to pre determine triangle sizes without stream network triw triangle width of delaney tin trih triangle height of delaney tin tilewidthmultipler how many times to split extent width tileheightmultipler how many times to split extent height level quadtree level ar elevwidth elevheightif ar 1 swap truetile rows 1lar floor ar uar ceil ar if ar sqrt lar uar tile columns larelsetile columns uarif swap tile rows tile columnstile columns 1 equation 3 by using aspect ratio of elevation extent the number of quadtree rows and columns are determined 2 4 3 merge stream geometry with quadtree at level zero the stream geometry is clipped to the entire extent of the dems from levels one to the maximum level the stream network is clipped by the extent of each quadrant tile at each tile the inlets and outlets are identified these nodes are considered valuable points and are not altered within the mesh workflow that way the position of inlets and outlets per quadrant tiles do not change and connection files between tiles and all levels section 2 4 5 share identical locations as demonstrated in section 4 4 the next step is to insert mesh vertices that intersect the stream network to maintain the regular spacing of the mesh triangulated grid if the user specified a densify stream value table 2d more vertices are inserted into the stream network at a regular distance to create more triangles along streams each mesh node is buffered with a maximum distance table 2e at level zero with the distance decreasing using equation 4 per quadtree level to maintain the mesh regularity i e to avoid a buffer size greater than triangle sizes any mesh and stream nodes within the buffer geometry is considered the same location therefore multiple nodes are purged aiding in the reduction of slivers and small triangles as further discussed in sub section 2 4 4 if triw trih bd 0 35 triwelse bd 0 35 trihif bd ub bd ub equation 4 method to determine buffer size to select and purge nodes bd buffer distanceub user supplied maximum buffer distancetriw triangle widthtrih triangle height the modified stream network is merged into the quadtree by treating the network as a hardline constraint within a delaunay tin to enforce the stream height values cheng et al 2012 esri 2016a the tin is converted to a triangle mesh shapefile that is nearly identical to the inputs analysis of the geometry generated incurs numerical precision differences between vertices of the tin and stream network therefore triangle vertices adjacent to the stream network are selected and repositioned using the snap distance value table 2f to align the triangle and stream network fig 4 a using this strategy has eliminated many slivers often found along the stream networks as further discussed in the next section 2 4 4 removing slivers and small triangles one of the main reasons for creating quadtrees with a minimum elevation sample was to ensure slivers are not generated hence slivers and small triangles created will occur near stream networks that clearly do not have a regular uniform geometry the user can specify thresholds to remove slivers and small triangles that may affect their hydrological modeling which in turn control how well the stream shape is preserved demonstrated in sections 3 4 4 2 and 4 3 as previously mentioned strategies to reduce slivers include consolidating vertices within a buffer polygon table 2e that occur due to numerical precision differences with stored xyz values in shapefiles as well as snapping table 2f triangle edge vertices near stream networks fig 4a to identify and remove slivers from tins the thinness ratio equation 5 davis 1990 was assigned to each triangle per quadtree tile the default thinness ratio value is 0 3 and users can modify this value as a user input parameter table 2g to remove different types of slivers i e dagger blade cheng et al 2000 edelsbrunner and guoy 2002 cheng et al 2012 to identify small triangles the user specifies the level zero small area threshold table 2h which is reduced per level using equation six thinness 4 pi triangle area triangle length ˆ2 equation 5 thinness ratio davis 1990 area 0 5 trih triwif ua area remove triangle nodes equation 6 small area threshold bd buffer distanceua user supplied maximum areatriw triangle widthtrih triangle height once slivers and small triangles are identified per quadtree tile the strategy to remove these issues summarized in fig 4 while preserving steam geometry meant identifying and to weight the location of triangle vertices if one of the three vertices fig 4b is not located on the stream network only this vertex is removed if there are two vertices on the stream edge within the delete node threshold table 2i the downstream vertex is removed if the location is not on the tile edge fig 4c then the upstream vertex is removed fig 4d however if this upstream vertex has been identified as a stream inlet the vertex will not be removed fig 4e unfortunately this is one circumstance when small triangles will remain if this triangle is identified as a sliver a vertex is inserted in the center of the longest edge fig 4f if two of the three triangle vertices are not on the stream network the edge with the smallest distance is examined the vertex not on the stream is marked for removal fig 4g unless the vertex is on the tile edge in these circumstances then the other edge is examined and the end vertex not on the stream is removed fig 4h again if this vertex is on the tile edge then no vertices are removed and this scenario is another situation when small triangles remain in the quadtree fig 4i as before if the triangle is a sliver another vertex is inserted that may create small triangles fig 4j and k additionally if this small triangle is equilateral the edge with vertices not on the network are removed if not on the tile edge after modifying vertices that cause slivers and small triangles the tile tin is recreated and converted to a triangle shapefile these steps to remove slivers and small triangles are repeated per individual quadtree tile to the user specified maximum number of attempts table 2j when issues are still identified within the tile as mentioned above there are circumstances when these mesh issues are necessary to maintain the quadtree data structure section 3 2 discusses the methods to predict and evaluate mesh quality and section 3 3 demonstrates the removal of slivers and small triangles from mesh workflow results at the study watershed locations the next mesh workflow step is to create mesh files appropriate for hydrological models 2 4 5 generating mesh and connection files triangles modified along tile edges to remove slivers and small triangles require adjacent tiles to match these changes at the same quadtree level there are two actions as summarized in fig 4k and l the default action is to add vertices along tile edges table 2k with the cost of inserting more triangles most often small triangles i e tile 2 will have two small triangles inserted in fig 4k users concerned about triangle counts can override this action by deleting vertices that were inserted with the adjacent tile i e tile 1 in fig 4l in other words the user chooses to accept slivers and or small triangles however the recommended action is to add triangles since inserting a small number of triangles are not significant compared to the large number of triangles per individual quadtree tile as shown in section 3 3 after validation each quadtree is converted into multiple files for modeling purposes the first file generated is a summary of the quadtree tiles table 3 a with properties about the mesh stream network connecting tiles and the bounding box of individual tiles for the quadtree level these properties are used to select tiles by triangle count and identify tiles that intersect storm paths as demonstrated in section 4 4 each tile tin is converted from a shapefile to text files with mesh table 3b and stream properties table 3c for interoperability the remaining files generated are grouped into connection file types there are two spatial scales of connection files fig 5 the first scale fig 5a is how triangles and stream networks located on tile edges are connected to adjacent tiles at the same quadtree level at this scale a mesh connection file is created identifying which triangles and edges connect between the two tiles table 4 a a stream connection file identifies the stream segment keys and the vertex fig 5b they share in common at the tile edge table 4b at the second scale connection files are used to connect mesh and river datasets with other levels as demonstrated in fig 5c a tile edge at level one level containing four tiles will share the edges of two tiles at level two level with 16 tiles the data structure of this file table 4c contains the same properties as the mesh connection file with the addition of a ratio that represents the proportion of the smaller edge overlaps with the larger edge fig 5d that way models like pihm can use this ratio to partition fluxes between triangles at different quadtree levels this section has focused on the main components of the mesh workflow that creates a quadtree based on a list of dems the workflow then merges a stream network with the quadtree tiles that handles the removal of slivers and small triangles from the meshes based on user parameters once the quadtree is complete the tin tiles are converted and connections between multiple quadtree levels are generated for hpc hydrological model usage each component is executed in parallel with the maximum number of threads specified by the user table 2l the next section discusses the results of the mesh workflow with hydrological model examples at the watershed study locations 3 quadtree meshes and stream networks at watershed study locations section 2 discussed how the mesh workflow components generate quadtree meshes with stream networks for hydrological modeling each quadtree level contains a set of tiles with each tile containing a tin with an embedded stream network section 3 describes the mesh workflow results at the four watershed study locations table 1 first described is the workflow parameters used at the watershed locations followed by the methods to predict and evaluate mesh qualities generated by the mesh workflows section 3 2 section 3 3 summarizes the mesh characteristic results for each watershed study location the last section reviews and evaluates the hpc performance of the mesh workflows to aid in predicting workflow requirements 3 1 mesh workflow parameter exceptions the mesh workflow was performed at the study location watersheds table 1 with the parameters outlined in table 2 and discussed in section 2 this section focuses on parameter exceptions used by the mesh workflows with the smaller watersheds shale hills and juniata both ned and pasda lidar elevation datasets were used to compare differences with mesh workflow results pasda 2016 however ned used the default projection code and lidar used code 3651 the remaining large watersheds used ned as the elevation data source as there is no access to a national lidar dataset usgs 2016 additionally smaller sub watersheds with high resolution elevation datasets were inserted into larger watersheds low elevation resolution to demonstrate how users can mix different types of elevation datasets and define mesh workflow parameters to create consistent quality meshes for hydrological modeling mixing elevation datasets within watershed boundaries table 1b were demonstrated by inserting shale hills pasda lidar tile into the juniata ned and inserting the juniata pasda lidar tiles into the susquehanna ned watershed the nhd stream network was used for all watersheds except at shale hills at shale hills the critical zone observatory stream network neal 2013 was used as nhd stream coverage does not reach this hill slope watershed additionally stream densification has been performed with the shale hills stream network to increase triangle density at multiple quadtree levels section 3 3 1 to demonstrate how users control triangle density by tile sizes four tile sizes 16 32 64 and 128 were used for levels zero to five when the elevation resolution was sufficient for this research level five was selected as the maximum level studied to produce tiles ranges from 1024 to 2048 manageable with common hpc cluster environments 3 2 methods to predict and evaluate mesh quality to predict and evaluate the mesh qualities produced by the workflow for each of the watershed study locations the mesh sizes were first predicted without stream networks section 3 2 1 before executing the workflows during and after the mesh generation three mesh qualities were used to measure the meshes as described in section 3 2 2 3 2 1 predict mesh sizes using the techniques described in section 2 4 the mesh characteristics width height were first predicted for each of the watershed locations table 1 without streams for quadtree levels 0 to the maximum supported level and elevation resolution table 5 summarizes appendix a with mesh properties at levels zero five selected maximum and the maximum quadtree level recall one goal of the mesh workflow is to provide user control of triangle sizes and the total number of tiles for hpc hydrological modeling the maximum triangle width and height occurs at level zero and the minimum size dimensions occur at the largest mesh level supported by tile size and elevation resolution this equates to generating triangles that are close to or identical to the pixel elevation dimensions 3 2 2 measuring mesh qualities to evaluate the mesh workflow results three qualities are measured the first quality is comparing the stream length generated by the mesh workflow with the supplied nhd stream inputs table 1 has the nhd stream lengths for each watershed ideally the workflow will generate an identical stream length 100 match stream length comparisons under 100 indicate under sampling or the number of vertices along the stream does not capture the stream curvature over simplifying stream edges within triangle area and is undesired while over 100 indicates oversampling and or aliasing effects i e staircase effect hearn and baker 1997 when triangle sizes are smaller than stream curvature the second metric is calculating the perimeter ratio hydrological models like pihm exchange data along triangle edges with adjacent triangles ideally the triangle edges follow the path of the stream network as well as capture the topography with sufficient detail as the quadtree meshes recursively subdivide the triangles become smaller until reaching the elevation resolution in other words the mesh has reached the maximum triangle perimeter possible table 6 records the total triangle perimeters without stream networks for each watershed using the predicted mesh sizes section 3 2 1 each mesh workflow perimeter is calculated and compared to the total triangle perimeter possible within the chosen quadtree level and tile size a ratio of one indicates the mesh workflow has produced a mesh identical to a mesh at the elevation resolution and is the mesh workflow objective therefore the mesh is sufficiently small and representing the stream network with uniform triangle sizes a high perimeter ratio indicates the triangle sizes vary to capture the stream network and indicate to the user the chosen quadtree level and tile size is generating triangles that are not uniform may not be a concern for the user a perimeter ratio less than one indicates the workflow has generated a mesh smaller than the elevation resolution along the stream network by additional vertices inserted in the stream network over sampling to capture stream curvature the last calculation of mesh quality is the thinness ratio equation four all triangles have their thinness ratio calculated to identify slivers and are filtered by the user defined value table 2g this research article has treated all watershed studies with the same constant value of 0 3 before removing any slivers by the mesh workflow fig 2 group 4 the number of triangles with thinness ratios between 0 05 and 0 5 with increments of 0 05 were recorded to compare and contrast how efficient the workflow removed slivers and small areas these three mesh quality measurements are presented for each of the watersheds in the following section 3 3 mesh characteristic results the following sub sections summarize the mesh characteristics and data properties for each of the four watershed study locations the goal of each mesh workflow is to generate a stream network that matches the stream length inputs 100 result and a perimeter factor of one to achieve these goals the mesh workflow should create a triangle mesh that is uniform and sufficiently small that does not reduce the stream length and generates no slivers 3 3 1 shale hills watershed using ned at shale hills table 7 a watershed is the smallest article example in terms of elevation resolution 21 by 17 pixels and area 0 2 sq km the ned elevation resolution at shale hills supports tile sizes 16 and 32 from the four tile sizes used in these experiments 16 32 64 and 128 at tile size 16 quadtree levels of zero and one the mesh workflow generated triangle counts of 478 and 670 respectively appendix b1 at level one the average triangle count per tile was 168 triangles additionally both perimeter ratios are close to one when compared to a triangle mesh with no streams the total number of river segments are similar between the two levels with 13 level zero and 14 segments level one comparing the generated stream lengths with the provided stream input both levels produced nearly identical lengths at 99 in other words differences are in centimeters a value of 0 3 was selected as the thinness ratio threshold to identify slivers with 2 of the triangles at level zero and 1 4 at level one appendix c1 identified as slivers before the mesh workflow successfully removed all slivers and small triangles the mesh workflow results are similar between tile sizes 16 and 32 at shale hills using the ned elevation dataset tile size 32 at level zero produced 598 triangles in total with 14 river segments that represent 99 of the input length and a perimeter ratio of 1 02 again the given thinness ratio identified 2 of the triangles as slivers appendix c1 before the mesh workflow successfully removed all slivers and small triangles by using lidar at the shale hills watershed it is possible to examine all four tile sizes as summarized in table 7b at tile size 16 quadtree level zero generated the smallest triangle total count of 944 triangles as well as the largest triangle count of 532 427 at level five appendix b1 the total triangle count ranges from 3916 level zero to 532 388 at level four using tile size 32 with a tile size of 64 level zero has 15 984 triangles and at tile size 128 level zero generated 64 698 triangles examining the triangle totals per maximum level at each tile size the triangle counts are very similar for example at tile size 64 the triangle count is 522 327 triangles at the maximum level of three while at tile size 128 the triangle count is 515 556 triangles at level two maximum quadtree level when comparing average triangle counts per tile for each tile size the reader can approximate triangle counts for larger tile sizes by multiplying with a ratio of four for example to estimate the average count at tile size 32 multiplying tile size 16 average triangle count of 472 by four produces 1888 triangles a value close to the 1929 triangles produced with tile size 32 these values are not identical due to inserting stream networks that modify the regular mesh sampling as discussed in sections 2 4 3 and 4 3 at tile size 16 the average triangle count is 457 per tile between levels zero to four at level five the average triangle count reduces to 260 triangles a decrease of 42 22 this behavior also happens with the remaining tile sizes with a reduction of 45 29 at tile size 32 48 48 at tile size 64 and 50 at tile size 128 these reductions occur when the mesh generation process has reached the elevation resolution preventing any further elevation sampling using lidar at shale hills watershed generates perimeter ratios close to the goal of one for all tile sizes and quadtree levels tile sizes 16 32 and 64 are slightly less than 1 0 due to oversampling along the stream network creating the staircase or stairstep effect hearn and baker 1997 with tile sizes 32 and 64 the stairstep effect generated stream lengths of 104 46 and 103 65 respectively larger than the supplied inputs at tile size 128 the generated stream length is 104 25 larger 15 cm difference although the perimeter ratio was not affected 1 0 by oversampling conversely at tile size 16 the stream length is 99 65 or a one centimeter difference with a perimeter ratio of 0 98 both the ned and lidar shale hills watershed mesh workflows used the same stream input with ned workflows generating a maximum of 14 stream segments while using lidar elevation the workflow generated stream segment counts ranging from 21 a 61 increase to 323 a 2207 increase compared to ned workflow as the mesh workflow generates more stream segments and triangles the sliver count increases as well at tile size 16 the sliver ratio ranges from 0 006 to 1 38 tile size 32 from 0 009 to 0 61 tile size 64 from 0 017 to 0 19 and the range is from 0 016 to 0 023 at tile size 128 appendix c1 the success rate of removing slivers and small areas from lidar generated meshes varies compared to the ned generated mesh at tile size 16 the removal of slivers and small areas was 100 successful at levels zero and one 55 56 at level two and 0 at levels three to five with tile size 32 the success rates ranged from 0 to 87 50 tile size 64 from 0 to 40 and at tile size 64 no slivers and small areas were removed the main reason for these low success rates was using the add option with edge minimum stream threshold table 2k that encourages the insertion of small triangles as discussed in section 2 4 4 3 3 2 juniata watershed the ned elevation resolution at the juniata watershed supports all four tile sizes 16 32 64 and 128 as shown in table 8 a at tile size 16 the lowest number of triangles 26 894 occurs at level zero as well as the least number of stream segments 13 611 appendix b2 these relatively low numbers at the juniata watershed reflect with the lowest stream length comparison of 89 29 and the highest perimeter ratio of 5 92 both measurements indicate the generation of irregular larger triangles along the stream network losing stream curvature features however as the quadtree level increases at tile size 16 the increase in triangle and stream counts improves both measurements with a high stream length of 94 66 and low perimeter ratio of 1 1 at level five as the workflow measured stream lengths a pattern formed with low stream length comparisons at level zero and then high stream length comparisons objective of workflow towards quadtree level five that was repeated with the remaining tile sizes the mesh workflow produced stream comparisons at level five of 96 59 at tile size 32 97 66 with tile size 64 and 98 82 at tile size 128 however the juniata stream network is approximately eleven thousand kilometers in length table 1 resulting with large stream length differences between the mesh workflow result and the nhd input at tile size 16 the difference in length between the nhd inputs varies from 582 km to 1166 km from 371 km to 1108 km at tile size 32 255 km 1019 km at tile size 64 and 143 km 864 km at tile size 128 to reduce these stream length differences the user will have to increase the quadtree level and or increase the tile size with consequences discussed in section 3 4 additionally the pattern of high perimeter ratios at level zero towards the goal of a perimeter ratio of one towards level five are repeated with all tile sizes although there is a substantial increase in the total triangle counts to achieve perimeter ratio of one level five the largest quadtree explored here generated 571 958 triangles perimeter ratio of 1 10 at tile size 16 2 171 827 perimeter ratio of 1 05 at tile size 32 8 512 948 perimeter ratio of 1 02 at tile size 64 and 32 513 133 perimeter ratio of 0 99 triangles at tile size 128 removing slivers and small areas for all tile sizes and quadtree levels at the ned juniata watershed were effective ranging from 99 46 to 100 success rates the number of slivers identified ranged from 7095 tile size 32 level 0 up to 297 135 triangles tile size 128 level 5 appendix c2 the mesh workflow resulted with no slivers and small areas at levels zero and one with tile size 32 with all tile sizes level five produced and retained the most slivers approximately 0 005 of the total produced triangle count with 37 remaining at tile size 16 109 at tile size 32 429 at tile size 64 and 1611 triangles at tile size 128 appendix c2 most of these sliver and small area triangles occur near stream inlets and outlets identified as critical locations to preserve see sections 2 4 4 and 4 3 the results of juniata ned mesh workflow contrasts with the shale hills lidar watershed with consistently high stream comparisons similar perimeter ratios and similar triangle counts of half a million the reason for these differences is due to the complexity of the stream network at juniata watershed under sampling or inadequate tile sizes and the mesh workflow not reaching the maximum quadtree level elevation resolution appendix a table 8b reveals the results of using lidar at the juniata watershed to retain near square sampling the number of tiles produced is twice the size of the ned version although more tiles does not equate to twice the number of triangles for all quadtree levels at tile size 16 the range of triangle counts are from 28 454 level zero to 1 168 016 level five an increase of 5 8 104 21 respectively between ned and lidar elevation sources appendix b2 by increasing the tile sizes the difference in triangle counts between ned and lidar does increase at lower levels faster than higher quadtree levels at tile size 32 the range of triangle counts are from 36 176 level zero increase by 14 61 to 4 215 139 level five increase by 94 at tile size 64 the range is from 57 434 level zero increase by 29 55 to 16 794 503 level five increase by 97 28 with tile size 128 the triangle count range is from 124 454 level zero increase by 52 90 to 67 815 622 level five increase by 108 58 additionally twice the number of quadtree tiles does not double the number of stream segments with all levels and tile sizes the increase of stream segments at tile size 16 is from 4 05 13 611 versus 14 162 stream segments at level zero to 32 41 55 874 versus 73 985 stream segments at level five while at tile size 32 the increase in stream counts range from 8 81 to 36 12 13 89 39 57 at tile size 64 and from 21 61 24 949 versus 30 341 segments at level zero to 43 24 368 354 versus 527 617 segments at level five at tile size 128 comparing stream lengths between the nhd input and lidar mesh workflow generated streams the lidar performs slightly better than ned does with these tile sizes and quadtree levels at tile size 16 the stream length differences are between 20 level 0 to 100 level 4 kilometers with tile size 32 the differences range from 30 level 5 to 99 level 2 kilometers tile size 64 the smallest difference of 66 km occurs at level five the largest difference of 100 37 km at level one at tile size 128 the stream length differences range from 13 level 5 to 98 km level 0 with tile sizes above 16 the largest stream differences occur at lower quadtree levels with smaller differences at higher levels while at tile size 16 it is the reverse with a smaller difference at level zero and stream difference increases at high levels removing slivers and small areas for all tile sizes and quadtree levels at the lidar juniata watershed were effective ranging from 97 71 to 100 success rates the number of slivers identified ranged from 6516 tile size 16 level 0 up to 443 242 triangles tile size 128 level 5 appendix c2 the mesh workflow resulted with no slivers and small areas at tile size 16 level zero with all tile sizes level five produced and retained the most slivers approximately 0 012 of the total produced triangle count with 141 remaining at tile size 16 449 at tile size 32 1811 at tile size 64 and 10 140 triangles at tile size 128 appendix c2 most of these sliver and small area triangles occur near stream inlets and outlets identified as critical see section 2 4 4 although more slivers were retained at larger tile sizes and quadtree levels as discussed in section 4 3 3 3 3 susquehanna watershed the ned elevation resolution at the susquehanna watershed supports all four tile sizes as shown in table 9 quadtree level zero has the smallest number of triangle counts for each tile size with 54 760 triangles at tile size 16 62 200 at tile size 32 80 170 at tile size 64 and 128 190 at tile size 128 appendix b3 in contrast the highest triangle counts occur at level five 669 256 at tile size 16 2 345 198 at tile size 32 8 840 635 at tile size 64 34 401 352 at tile size 128 at tile size 16 the lowest number of triangles 54 760 occurs at level zero as well as the least number of stream segments 28 154 these relatively low numbers at the susquehanna watershed reflect with the lowest stream length comparison of 85 91 and the highest perimeter ratio of 8 97 both measurements indicate the generation of irregular larger triangles along the stream network losing stream curvature features however as the quadtree level increases at tile size 16 the increase in triangle and stream counts improves both measurements with a high stream length of 92 28 and low perimeter ratio of 1 19 at level five as with the juniata a pattern of low stream length comparisons at level zero and then high stream length comparisons objective of workflow towards quadtree level five was repeated with the remaining tile sizes the mesh workflow produced stream comparisons at level five of 94 99 at tile size 32 97 11 with tile size 64 and 98 44 at tile size 128 however the susquehanna stream network is approximately fifty two thousand kilometers in length table 1 resulting with large stream length differences between the mesh workflow result and the nhd input at tile size 16 the difference in total stream length between the nhd inputs varies from 3997 km to 7293 km from 2591 km to 7062 km at tile size 32 1498 km 6614 km at tile size 64 and 808 km 5872 km at tile size 128 to reduce these stream length differences the user will have to increase the quadtree level and or increase the tile size with consequences discussed in sections 3 4 and 4 3 1 the sequence of high perimeter ratios at level zero towards the goal of a perimeter ratio of one towards level five are repeated with all tile sizes again there is a substantial increase in the total triangle counts to achieve perimeter ratio of one by increasing tile size the perimeter ratio at level zero improves rapidly from 8 97 tile size 16 4 72 tile size 32 2 74 tile size 64 and 1 82 tile size 128 towards the goal of one at quadtree level five the perimeter ratio is 1 19 at tile size 16 1 09 at tile size 32 1 04 at tile size 64 and the best perimeter ratio result at the susquehanna watershed was 1 02 at tile size 128 removing slivers and small areas for all tile sizes and quadtree levels at the ned susquehanna watershed were effective ranging from 99 79 to 100 success rates the number of slivers identified ranged from 13 448 tile size 16 level 0 up to 584 257 triangles tile size 128 level 5 see appendix c3 the mesh workflow resulted with no slivers and small areas at level one with tile sizes 16 and 32 level five at all tile sizes produced and retained the most slivers approximately 0 003 of the total produced triangle count with 15 remaining at tile size 16 70 at tile size 32 283 at tile size 64 and 1245 triangles at tile size 128 appendix c3 3 3 4 chesapeake bay watershed the ned elevation resolution at the chesapeake bay watershed supports all four tile sizes as shown in table 10 to retain near square sampling the number of tiles produced is twice the size of a quadtree structure equation 3 quadtree level zero has the smallest number of triangle counts for each tile size with 144 404 triangles at tile size 16 160 370 at tile size 32 200 290 at tile size 64 and 303 724 at tile size 128 appendix b4 these relatively low number of triangle counts is why all the quadtree level zero tile sizes had the highest perimeter ratio with a ratio of 10 1 at tile size 16 5 22 at tile size 32 2 99 at tile size 64 and a ratio of 1 95 at tile size 128 the highest triangle counts occur at level five 1 407 418 at tile size 16 4 767 525 at tile size 32 17 709 853 at tile size 64 and 68 501 899 triangles at tile size 128 with more triangles at level five the mesh workflow generates perimeter ratios closer to one as tile sizes increase with a ratio of 1 21 at tile size 16 1 09 at tile size 32 1 04 at tile size 64 and a ratio of 1 01 at tile size 128 quadtree level zero also has the smallest number of stream segments ranging from 74 145 segments at tile size 16 up to 121 828 segments at tile size 128 smaller numbers of segments indicate the generated stream geometry is not capturing the stream curvature inputs hence level zero stream comparisons are the lowest with 84 95 at tile size 16 85 34 tile size 32 86 21 tile size 64 and 87 63 at tile size 128 the largest numbers of stream segments occur at quadtree level five for each tile size with 251 383 at tile size 16 446 150 at tile size 32 832 608 at tile size 64 and 1 591 544 at tile size 128 therefore level five has the highest stream length comparisons of 91 62 at tile size 16 94 37 tile size 32 96 66 tile size 64 and the highest comparison of 98 21 with tile size 128 however the chesapeake bay stream network is approximately 132 thousand kilometers in length table 1 resulting in substantial stream length differences between the mesh workflow result and the nhd input at tile size 16 the difference in length between the nhd inputs varies from 11 038 km to 19 826 km from 7417 km to 19 315 km at tile size 32 4400 km to 18 173 km at tile size 64 and 2362 km to 16 306 km at tile size 128 removing slivers and small areas for all tile sizes and quadtree levels at the ned chesapeake bay watershed were effective ranging from 99 82 to 100 success rates the number of slivers identified ranged from 191 664 tile size 16 level 0 up to 1 326 502 triangles tile size 128 level 5 appendix c4 the mesh workflow resulted in the least number of slivers at levels zero and one with all tile sizes level five produced and retained the most slivers approximately 0 003 of the total produced triangle count with 53 remaining at tile size 16 167 at tile size 32 599 at tile size 64 and 2354 triangles at tile size 128 appendix c4 the majority of these sliver and small area triangles occur near stream inlets and outlets identified as critical see section 2 4 4 and how to decrease these counts are discussed in section 4 3 3 3 5 mixing ned and lidar two tile sizes 32 and 64 quadtree level five experiments table 1b were conducted with shale hills lidar overlaid on top of juniata ned as summarized in table 8c a third experiment was superimposing the juniata lidar elevation dataset over the susquehanna ned watershed with a tile size of 64 shown in table 9b inspecting mesh workflow triangle count results the susquehanna test produced identical results appendix b3 and the juniata tests generated 8 and 14 less triangles appendix b2 with these minor differences the perimeter ratios are identical by examining the stream segment results 214 tile size 32 and 830 tile size 64 were added by the mesh workflow at the juniata watershed equating to the stream length increasing by 21 0 19 increase and 47 0 43 increase kilometers respectively in contrast there were six less stream segments generated at the susquehanna watershed the stream length was reduced by 500 m the stream length comparison percentage was not affected removing slivers and small areas for all three experiments were effective ranging from 99 73 to 99 91 success rates the number of slivers identified were 82 808 juniata tile size 32 level 5 159 081 juniata tile size 64 level 5 and 298 885 susquehanna tile size 64 level 5 triangles appendix c5 at the juniata watershed experiments 0 005 slivers remained tile size 32 had 109 and tile size 64 had 429 and 0 003 remained 283 slivers at the susquehanna watershed with tile size 64 at quadtree level five additionally there is an impact on hpc performance by mixing elevation data sets with these workflows requiring more time than the ned versions appendix c with only minor differences generated in lengths of the stream network therefore the remaining sections will consider the mixing of elevation sources as the same with ned or lidar mesh workflow results however the addition of multiple lidar datasets covering larger areas within the larger catchments would create larger differences in the generated stream network results not explored here 3 4 mesh workflow hpc results this section summarizes the hpc performance of the mesh workflows by first comparing the generated data sizes for each of the different scale watersheds understanding the disk usage requirements assists in predicting mesh workflow requirements and ways to improve performance the second evaluation is comparing total wall times versus cpu times for each of the watersheds ideally wall times will be low and the differences between wall and cpu times are high with no cpu idle times equating too efficient parallel hpc the last comparison is investigating the wall and cpu times per quadtree tile looking for trends in how long it takes to process and generate data and to identify if the cpu is idle three servers were used to perform these mesh workflows and the server features are summarized in appendix d appendices d1 to d4 summarize the hpc results for each watershed and the following subsections contrast the hpc results with all watershed study locations 3 4 1 disk usage the tree map shneiderman 1992 for disk storage with all the mesh workflows is summarized in fig 6 each watershed spatial scale and elevation source has a separate color for example the juniata lidar workflows are shaded in green and the juniata ned workflows are shaded in yellow the larger uniform shaded areas represent more disk storage and file counts than the smaller areas thus the chesapeake bay brown rectangles requires the most disk storage ranging from 924 megabytes at tile size 16 quadtree level zero brown rectangle located in bottom right corner up to 290 gigabytes at tile size 128 quadtree level five brown rectangle located in top left corner shale hills orange requires the least amount of disk storage furthermore the sequence of watershed disk storage requirements is revealed in fig 6 that do not match the spatial scales table 1 the total disk storage for all chesapeake mesh workflows required 711 gigabytes susquehanna 337 gigabytes juniata lidar 470 gigabytes juniata ned 264 gigabytes and shale hills lidar required 20 gigabytes based on spatial scale the susquehanna catchment would be the second largest disk user but follows the juniata lidar mesh workflow results using lidar elevation generates more triangles and stream segments than ned the juniata lidar tile size 128 at level five generated 67 815 622 triangles nearly twice the amount at the susquehanna 34 401 352 triangles watershed appendix b additionally quadtree levels three to five dominate fig 6 as these generate the most number of tiles and represent the largest triangle and stream counts for all mesh workflows 3 4 2 wall versus cpu time for all chesapeake mesh workflows brown rectangles in fig 7 the total wall time was 44 days and total cpu time was 170 5 days at the susquehanna watershed the total wall time was 11 5 days and 47 35 cpu days the juniata lidar mesh workflow took 21 5 days wall time and 90 cpu days nearly twice the amount of time as the susquehanna workflows the juniata ned mesh workflow a sub watershed of the susquehanna was slightly faster than the susquehanna results requiring 9 8 wall time days and 39 45 cpu days the shale hills workflows took 1 75 wall time days and 7 5 cpu days the wall and cpu times of the ned juniata and susquehanna mesh workflows were similar as the triangle counts are also comparable for example at tile size 128 quadtree level five there are 32 513 133 and 34 401 352 triangles respectively appendix b2 and b4 indicating that the triangle dimensions are smaller at the juniata catchment than those of the susquehanna watershed however both watersheds have been constrained by the maximum quadtree level of five as discussed in section 3 1 the juniata lidar workflow generated 67 815 622 triangles about twice the number of triangles at both ned juniata and susquehanna mesh workflows and required twice the amount of time however when comparing similar total triangle count workflows between the juniata lidar workflow and the chesapeake bay ned workflow 68 501 899 triangles at tile size 128 level five the chesapeake workflow took twice as long this discrepancy occurred as the workflows used different servers appendix d with different hard disk properties the chesapeake bay workflow cpus were idle due to the cpu waiting on the slower disks to respond the workflows were disk bounded as revealed in fig 7 the largest rectangles wall times occur with quadtree levels four and five amongst all mesh workflows tile size 128 at quadtree level five took the most amount of wall and cpu times for all watersheds a total of 20 64 wall days and 87 35 cpu days at the chesapeake bay 12 57 days and 54 cpu days at the juniata using lidar 6 26 days and 26 81 cpu days at the susquehanna watershed 5 73 days and 23 63 cpu days at the juniata with ned elevation at shale hills with lidar tile size 16 took the longest amount of time 21 39 h and 3 79 cpu days 3 4 3 wall versus cpu time per tile total cpu and wall times for quadtree level five required the most amount of time as the mesh workflows are generating either 1024 or 2048 tiles significantly more tiles than lower quadtree levels as explained in section 2 4 another way to understand the performance of the mesh workflows is to analyze the wall and cpu times per individual quadtree tile to predict workflow performance on large distributed hpc environments as reflected in fig 8 individual wall times per tile for the chesapeake bay requires more than the other watersheds combined as the watershed size increases so too does the number of triangles and stream segments per tile and at small quadtree levels levels 0 and 1 there is more work for an individual tile to perform fig 6 and the mesh workflow is not efficient at small watershed scales shale hills and the juniata the wall time is relatively low but at the susquehanna watershed level 0 took 90 min and the chesapeake bay took 10 h at level zero having these benchmarks against watershed sizes helps predict mesh workflow completion times and inform end users in contrast quadtree levels three and higher are ideal for distributed computing with smaller numbers of triangles per individual tile appendices d1 to d4 shows the wall and cpu times per tiles for example the juniata ned workflow took about 18 wall time hours at tile size 64 with quadtree level five the wall time per tile was 1 05 min and 4 24 cpu minutes per tile it is reasonable to expect the same mesh workflow to take a few minutes on a 1024 node hpc cluster 4 demonstration of mesh workflow the previous sections have discussed the mesh workflow software components the hpc performance and the generated mesh characteristic results at the four watershed study locations this section focuses on demonstrating the mesh workflow results in particular the performance of replicating the user defined stream inputs section 4 1 describes the impact of elevation resolution with quadtree levels and user defined tile sizes to empower the user with choices on creating different types of meshes for their hydrological modeling purpose section 4 2 compares the stream differences between the user supplied stream network and the mesh workflow generated stream networks at the four watershed study location extents section 4 3 examines the mesh qualities of stream length perimeter ratio and thinness ratio at the stream extent to demonstrate the impact of user inputs with the juniata mesh workflow the last section demonstrates using the quadtree data structures to provide the user multiple options to create dynamic meshes that are suitable for the users hydrological modeling requirements and hpc constraints 4 1 understanding the impact of elevation resolution with tile sizes and quadtree levels when users have access to fine resolution elevation datasets the user has more control on how she or he can generate a mesh model for example at shale hills using the ned product provides little variance between the total number of tiles 1 4 and triangle sizes 32 23 m 40 83 m hence at this spatial scale hpc environments are not necessary when one tile can capture the elevation resolution to represent the shale hills watershed however using the pasda lidar elevation product there are more options for the user with a tile count range of 2 2048 and triangle sizes of 0 97 m up to 26 33 m users interested in modeling the shale hills watershed at 0 96 m by 0 95 m triangle resolutions elevation resolution will require access to a minimum 32 node hpc cluster tile size 128 at level 2 128 nodes with tile size 64 at level three 512 nodes with tile size 32 at level four and 2048 nodes with tile size 16 at level five by assigning one tile mesh per compute node as the watershed extent increases the user has more hpc options for their modeling goals for example the juniata watershed has maximum quadtree levels ranging from five tile size 128 to eight tile size 16 with the ned data product that could be modeled on a large hpc cluster size 1024 nodes at level 5 to the largest hpc clusters 65 536 nodes at level 8 assuming one tile per core rather than one compute node however to model the juniata watershed with the pasda lidar elevation product treating each tile as a compute node is not currently feasible with existing hpc resources to model the juniata watershed at the maximum quadtree level requires hpc resources ranging from 524 288 tile size 128 at level 5 to 33 554 432 tile size 16 at level 12 compute nodes instead of assigning one tile per compute node one tile will need to be assigned per compute core requiring access to the largest hpc resources of 10 million cores top 500 2016 at the juniata watershed furthermore as the watershed scale increases susquehanna and chesapeake bay using the ned product the number of compute nodes required exceed current hpc resources with tile sizes ranging from 16 to 128 users will be required to increase the tile size above 128 to decrease the maximum quadtree level for users to compute one tile per compute node however increasing tile sizes has a performance impact with mesh workflows for example at the juniata watershed ned mesh workflow at quadtree level five cpu time per tile was 2 45 min at tile size 16 2 82 min at tile size 32 4 24 min at tile size 64 and 33 23 min at tile size 128 a similar decrease in performance was observed with the juniata lidar meshwork and the other watershed workflows after tile size 64 the cpu idle times increase as the mesh workflows are disk bounded therefore users will need to determine what strategy is ideal for their compute requirements by either assigning one tile per core versus one tile per compute node dependent on their model physics computation requirements and their desired triangle size furthermore there is an impact on the generated stream networks which are first demonstrated at the entire watershed extent 4 2 where are the stream differences at watershed extent as discussed in sections 2 and 3 mesh workflows were performed at four watershed scales table 1 at quadtree levels 0 to 5 with tile sizes 16 32 64 and 128 at shale hills the ned elevation dataset supported two tile sizes and a maximum quadtree level of one while the lidar elevation dataset supported all tile sizes the maximum number of levels ranged from 2 to 5 fig 9a visualizes shale hills lidar mesh at tile size 16 level zero triangles not adjacent to the stream are uniform and those near the stream are comparable size without losing the stream curvature as reflected with stream length differences in centimeters table 7 with streams generated by the mesh workflow and the stream input dataset however the shale hills stream network is not complex and all the mesh workflow results are similar this is not the case with the remaining watershed studies this section focuses at quadtree level 5 with the best matching stream lengths and supplied data and distinguishes where the stream network is not identical to the supplied nhd dataset to visualize the differences between the nhd and mesh workflow generated stream network the symmetrical difference esri 2016b between the two datasets were calculated in figs 9 15 the blue lines represent identical nhd and mesh workflow generated stream segments and white dots and lines highlight locations where the two datasets are different at figs 12 15 these matrices are zoomed spatially close to the stream geometry and the white dots become apparent as missing stream segments the generated triangles are only shown in figs 14 and 15 as it is not feasible to distinguish from the millions of triangles generated at full watershed extent scales these millions of triangles that are not near stream networks are uniform in size as the mesh workflows alter triangles near stream networks as discussed in section 2 4 hence it is not necessary to visualize these triangles additionally the grid of thin grey lines shows the quadtree tile locations the larger watersheds delineate the location of smaller sub watersheds performed by the mesh workflows to aid in visualizing scale at the juniata watershed with a tile size of 128 at quadtree level 5 the ned mesh workflow stream length comparison was 98 69 a stream length difference of 143 km between the generated stream and nhd network these stream differences white segments are shown in fig 9b the lidar mesh workflow stream results at the juniata are shown in fig 9c the lidar results produced a stream comparison of 98 80 or a stream length difference of 130 km between the nhd network although the stream differences are relatively small between the elevation sources as fig 9 demonstrates the spatial distribution between the two elevation workflow results are not similar with the ned workflow results having 4544 missing stream segments ranging from 10 24 to 222 m in length and a mean of 27 78 m while the lidar mesh workflow had 6735 missing stream segments with segment lengths ranging from 7 31 to 105 46 m and a mean of 20 36 m with the susquehanna watershed fig 10 the ned mesh workflow produced a stream comparison of 98 44 a stream length difference of 808 km between the nhd and generated stream network the ned workflow generated 5303 stream segments that did not match the nhd stream network the segment lengths ranged from 36 71 to 574 21 m with a mean of 161 32 m at the chesapeake bay watershed fig 11 the ned workflow produced a stream comparison of 98 21 a stream length difference of 2362 km between the nhd and generated stream network the ned workflow generated 12 532 stream segments that did not match the nhd stream network the segment lengths ranged from 35 29 to 834 31 m with a mean of 173 92 m visually examining where the stream differences occur within the larger watershed extents the spatial patterns do not concentrate at any particular locations and appear at first random at the larger catchment scales the stream differences are significant for example the chesapeake bay watershed difference represents 21 of the juniata stream network to understand where these stream differences occur the next subsection compares the mesh qualities between ned and lidar with the juniata watershed at the stream segment extent understanding where the stream differences occur is important to help users choose parameters to control the mesh workflow 4 3 examining mesh qualities at stream extent recall the main objective of the mesh workflow is to replicate the stream inputs using a quadtree data structure that can be used to dynamically select tiles for distribution in a hpc environment this subsection discusses the impact on stream geometry quality by the choices made by the user on tile sizes quadtree levels and the elevation data source this section focused on the juniata watershed where both ned and lidar elevation mesh workflows were studied that generated different mesh qualities section 4 2 examined both juniata mesh workflows at the full extent of the watershed this section focuses on two locations the first is the stream network identified in fig 9e with the ned results shown in fig 12 and the lidar results in fig 13 the second location is the stream intersection marked at fig 9f within the first location extent with figs 14 and 15 revealing the ned and lidar mesh workflow results respectively 4 3 1 how user choices affect stream lengths the stream length results for the juniata mesh workflows are described in section 3 3 2 that provide total lengths for tile sizes 16 32 64 and 128 between quadtree levels 0 to 5 here the focus is on examining how user choices affect stream lengths as well as where the differences between generated stream networks and inputs occur for each of the tile sizes examined quadtree level zero stream lengths generated the largest differences and level five generated the smallest differences this occurs as tile sizes control the number of samples per tile with level zero having the least number of samples as the juniata has one tile using ned and two tiles with lidar at tile size 16 level zero the mesh generated stream network blue lines is only using the start and end vertices of a stream segment with both elevation sources as shown in figs 12 and 13 increasing tile sizes slightly improves the stream network at level zero by generating longer stream segments with each quadtree level increase more stream segments are inserted by visually inspecting the differences between the blue mesh workflow generated and white nhd user input lines with the objective of not seeing white lines it is not until reaching level three tile size 128 does the stream network resemble the user input datasets with both elevation sources tile sizes 16 and 32 consistently do not capture the stream curvatures as shown in figs 12 and 13 tile size 64 replicates more of the stream curvatures than tile sizes 16 and 32 although using lidar reproduces the stream curvatures at an earlier quadtree level than the ned mesh workflows due to higher elevation resolution it is clear that tile size 128 performs better at replicating the stream network with both data sources however the computational costs disk cpu memory are significant appendix d compared to the other tile sizes the main reason for higher costs are the larger number of triangles appendix d generated by the mesh workflows as shown in figs 14 and 15 at tile size 128 quadtree level 3 the density of triangles is large compared to the other tile sizes and at each level the triangle sizes become smaller and capture the stream curvature comparing tile size 128 at level 5 between ned fig 14 and lidar fig 15 elevation sources it is evident that the mesh workflow can generate more uniform triangles with lidar and capture the stream curvature thus the user has a choice between longer compute times to generate stream networks that match the supplied inputs versus shorter compute times that over simplifies the stream network users interested in shorter compute times not only loose stream curvature but will be required to handle stream segments that cut through hills as highlighted in figs 12a and 13a to manage these occurrences the user will need to validate the stream network in the large graph workflow section 2 2 to confirm elevation values at stream vertices depending on the user elevation resolution and mesh workflow parameters this process may require numerous iterations and be time consuming therefore the user would shorten these processes by choosing a tile size and quadtree level that resembles the stream network as close to the hpc constraints as possible for example as a minimum use tile size 128 at level 3 fig 12 for the ned mesh workflow and tile size 128 at level 2 using lidar elevation fig 13 4 3 2 obtaining a perimeter ratio of one ideally the mesh workflows would generate a perimeter ratio of one indicating that the mesh triangles are uniform and capture the stream network that is identical to a mesh at the elevation resolution the shale hills lidar mesh workflows generated a perimeter ratio of one and the juniata ned and lidar mesh workflows nearly achieved a ratio of one as with the stream length comparisons tile size 128 performed better than the other tile sizes at all quadtree levels with values of 0 99 1 02 with the ned mesh workflow at level 5 the 0 99 perimeter ratio indicates there are more triangles along the stream network to capture stream curvature however this was not enough to generate a perfect stream comparison as shown in figs 9 12 and 14 poor curvature occurs as stream bends are often less than the elevation resolution of 10 or 30 m more triangles will be necessary to improve the stream curvature generating smaller triangles than the supported ned elevation resolution appendix a the lidar mesh workflows at levels four and five generated a perimeter ratio of 1 01 and this mesh workflow is more likely to generate a ratio of 1 0 as occurred at shale hills watershed with larger quadtree levels as most stream curvature diameters are measured larger than the 1 m elevation resolution however the lidar elevation at the juniata watershed supports up to nine levels at tile size 128 requiring a total of 524 288 tiles assuming ten minutes per quadtree tile the mesh workflow would take nearly ten years to finish on the systems listed in appendix d evidently a large hpc system is required to complete the mesh workflows at these scales 4 3 3 how user choices impact the creation of slivers and small triangles as described in section 3 3 2 the removal of slivers and small triangles were effective from 97 71 to 100 success rates at the juniata mesh workflows as identified in section 2 4 4 there are situations when slivers and small triangles remain controlled by user inputs table 2 for example figs 14a and 15a shows where small triangles were not removed as all three vertices are on the stream network and fig 14b and fig 15b identify where small triangles occur with two vertices on the stream network to remove these small triangles users will be required to modify the maximum buffer distance table 2e and the small area threshold table 2h the removal of slivers was also constrained by multiple vertices located on the stream network for example at fig 14c and fig 15c additionally as the tile sizes and number of levels increase the total number of triangles increase appendix b and so too does the number of slivers appendix c as indicated in fig 14d and fig 15d to remove these slivers users will be required to use the delete option table 2k rather than the add option used in these figures and modify the delete node threshold table 2i the goal of the mesh workflow is to support users to generate multiple tests to remove slivers and small triangles however without hpc support dense meshes with tile sizes of 128 and above it is difficult to do multiple tests new algorithms are required to improve the removal process since more triangles equates to higher sliver counts and small triangles furthermore additional research is required to find ways of improving the user options outlined in table 2 by automating these values based on the user supplied datasets to accommodate stream curvature below elevation resolution as an alternative solution to using one quadtree level section 4 4 mixes tile sizes and levels to generate different meshes for hydrological modelling 4 4 picking quadtree tiles along storm path recall one of the main objectives of the mesh workflow is to provide user flexibility and control on generating different types of meshes for hydrological modeling as the previous sections have demonstrated the user can generate meshes consisting of many millions of triangles for models like pihm more triangles are computationally expensive leonard 2015b therefore strategies are necessary to maximize where triangles are required and to minimize where triangles are not essential using the quadtree data structure provides the user multiple options to select tiles based on desired level and triangle counts rather than generating all tiles for a complete quadtree level for example fig 16 demonstrates choosing quadtree tiles following a storm path for both ned fig 16 a and lidar fig 16 b elevation sources at the juniata watershed by using the techniques discussed in section 2 4 2 the user can estimate the number of triangles generated for each quadtree tile per level for a watershed domain he or she supplies a storm path and specify buffer distances to select quadtree tiles i e levels 4 and 5 that require dense triangles for potential flooding locations while tiles that are located the furthest away from the storm path use lower quadtree levels 0 to 2 to reduce triangle count totals with the ned storm path example fig 16 a 352 tiles were selected with 22 tiles at levels 2 3 82 tiles at level 4 and 248 at level 5 triangle counts ranged from 225 453 at tile size 16 up to 11 432 584 at tile size 128 using lidar elevation fig 16 b 348 tiles were selected with 54 tiles at levels 1 3 140 tiles at level 4 and 154 tiles at level 5 lidar triangle counts ranged from 231 368 at tile size 16 up to 11 770 812 at tile size 128 both workflows produced comparable triangle counts and assuming one tile per compute node both storm path examples require less compute nodes needed at level 5 appendix b to accommodate more hpc cluster environments however using a quadtree does constrain the user selecting tiles must match the tile edge at the adjacent tile level for example the single level 2 tile requires two level 3 tiles at the northern and western edge at fig 16c location to generate connection files as described in section 2 4 5 to further demonstrate mesh quality and mixing quadtree level tiles the meshes were rendered from a camera perspective following the arrow direction at fig 16d fig 16e shows the triangle mesh lidar quality with tile size 128 in the foreground and fig 16f representing the same perspective using points to reveal stream locations to contrast mesh quality differences between tile sizes and elevation source fig 16g shows the triangle mesh using ned clearly lidar retains more topographic features and retains hill slope features fig 16h represents the ned triangle mesh as lines to show the contrast of mesh tile qualities there is an art in generating quality meshes suitable for environmental modeling here using quadtrees to select suitable meshes for hydrological science has been demonstrated quadtrees enable users to choose a wide range of mesh qualities within available hpc resources to create multilevel meshes that are scalable and dynamic for watersheds ranging from hill slope to conus scales 5 limitations and constraints hydrologic models such as le pihm zhang et al 2016 where streams are dynamically changing both spatially and with time are not considered here other hydrological features such as lakes and dams were not included in the mesh workflow process stream flow directions were validated with the two smaller watersheds only shale hills and juniata watersheds there is no impact on the mesh workflow performance with inconsistent flow directions however with models like pihm there is an impact on model performance as computational solvers will unlikely resolve physics equations the non production servers appendix d used to record times presented in the appendices and sections 3 and 4 are slightly different the larger watersheds used a server with slower disk speeds and results would be improved on faster disks as the mesh workflows were disk bounded furthermore the meshes were not simplified during delaney triangulation this strategy was used to record the worst case time scenario of very detailed triangle counts that are uniform in size levels 3 and higher within the complete tile triangle counts could be reduced but future work will include additional datasets that will require these triangles the results presented here serve as a benchmark to understand the impact on these datasets for hydrological modeling 6 conclusion providing the ability to incorporate large stream networks into very large dynamic mesh models coupled with etvs is important to improve hydrological science the challenges of working with four watershed scales ranging from hill slope to four level 4 hucs using nhd and ned were demonstrated using mesh workflows the main software components of the mesh workflow were described including user parameters that control mesh and stream geometry how quadtree meshes were generated and merged with the stream network steps taken to remove slivers and small triangles and the output datasets used for hydrological modeling to evaluate mesh and stream geometry from the mesh workflow three metrics were used the first was comparing the user supplied stream network lengths with those generated by the workflow stream length comparisons ranged from 84 95 to identical matches 100 at the four watershed scales however depending on the chosen tile size and quadtree level the stream length differences can be quite large due to the workflow not capturing all stream curvature features the second metric was comparing the triangle perimeter ratio between a mesh with no embedded streams with the quadtree generated mesh and stream network a sufficiently small and uniform triangle mesh will closely match the user supplied stream network a ratio near one mesh workflow results varied from 0 98 to 10 01 with high ratios occurring at low quadtree levels ratios near one at quadtree levels 3 and more the last metric used was the thinness ratio to identify sliver triangles many millions of triangles were created by the mesh workflows generating many thousands of slivers the success rate ranged from no slivers removed due to inappropriate workflow parameters to all slivers and small triangles removed at the chesapeake bay watershed 0 003 slivers were retained with a similar performance at the other watersheds the user has access to various strategies to remove slivers and small triangles with the mesh workflow tool presented here although there are circumstances when these issues cannot be removed hence iteration by the user is required to modify parameters to generate alternative meshes suitable for their modeling requirements at low quadtree levels and tile sizes mesh workflow iteration is rapid however at large quadtree levels and tile sizes large hpc resources are necessary to improve compute performance i e minutes not days with large hpc clusters stream length comparison and the removal of slivers the mesh workflow is scalable and the majority of workflow steps are pleasingly parallel furthermore the quadtree structure is suitable for multilevel tiles to provide the user multiple options to create dynamic meshes that are suitable for the users hydrological modeling requirements and hpc constraints 7 future direction this research focused on generating quality meshes with embedded stream networks using workflows for automation and rapid prototyping by using a quadtree data structure with multiple levels it has been demonstrated how a dynamic selection process can be used to select tiles for hydrological science purposes for example to select tiles with a dense number of triangles along stream networks that intersect a storm path for floodplain analysis here it has been demonstrated that counts per individual tile ranged from 260 to 303 724 triangles however it is unclear what an optimal number of triangles per quadtree tile is and how many triangles along tile edges is efficient for hydrological modeling for example models like pihm that exchange flux information along triangle edges how many triangles can a hpc cluster node efficiently compute pihm physics further research is required to optimize the mesh workflow to not only load balance the mesh size and connections but also consider the model physics data sizes and network constraints for efficient hpc future research will implement different spatial decomposition techniques for example by extending the quadtree implemented here to an octree data structure to incorporate bedrock depth and wells exploring other algorithms including the k d tree and the iterative wavefront edge expansion cell decomposition hale 2011 rather than generating the entire quadtree mesh levels as implemented here the next version of the mesh workflow will focus on weighting regions and using hot spot analysis techniques to prioritize regions that require fine resolution meshes doing so will not only improve the mesh generation process but will improve the hydrological science objectives the next mesh workflow generation will serve a national mesh dataset for multiple hydrological models and research objectives finally the removal of slivers and small triangles requires further advancement future mesh workflows will incorporate dams lakes bridges road networks i e culvert locations and buildings that will increase the mesh complexity and the generation of slivers users will require more control to fine tune and identify slivers interactively with multiple strategies for different datasets visual analytic tools will be necessary to guide users with identifying and prioritizing user attention to select appropriate parameters to control the mesh quality pertaining to their modeling requirements software availability name quadtree mesh workflow developer lorne leonard department of civil engineering department of computer science and engineering department of landscape architecture and institutes of energy and theenvironment the pennsylvania state university contact information lorne leonard department of civil environmental engineering the pennsylvania state university 406 sackett building university park pa 16802 usa software required internet browser later versions are recommended program language c c python arcgis availability and cost any user can access hydroterre web applications at no cost at http www hydroterre psu edu contact developer availability with mesh workflow appendix a supplementary data the following is the supplementary data related to this article appendices leonard appendices leonard appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2017 11 036 
26141,this paper presents swat modflow rt3d a model that couples the semi distributed watershed model swat soil and water assessment tool with the groundwater flow model modflow and the groundwater solute reactive transport model rt3d to simulate nitrate no3 fate and transport in a watershed system the model is based on a recently developed swat modflow model with rt3d now called as a subroutine within the modflow code to provide a single stand alone model code rt3d uses no3 concentration of deep percolation water from swat and groundwater heads and flows from modflow to simulate spatially varying groundwater no3 concentration and no3 loading to from streams with the latter used by swat to route no3 mass through the network model use is demonstrated through an application to the sprague river watershed 4100 km2 in oregon other chemical species of interest can be included in the rt3d reaction module in applications of the model to other watersheds keywords nitrate groundwater swat modflow rt3d integrated modelling management 1 introduction due to the requirement for increased production of food and energy the application of fertilizers has increased augmenting nitrogen n pollution in the environment erisman et al 2013 nitrate no3 has been one of the dominant forms of increased n loading since the 1970s dise and wright 1995 smith et al 1999 high concentration of no3 dissolved in surface water can lead to eutrophication of water bodies puckett 1994 nolan et al 1997 vidon et al 2010 and also can cause health problems such as methemoglobinemia in infants and stomach cancer in adults carpenter et al 1998 the presence of no3 in groundwater systems also can contribute to the oxidative dissolution and inhibition of chemical reduction of other dissolved environmental pollutants such as selenite seo4 and sulfate so4 e g wright 1999 bailey et al 2012a as such the us environmental protection agency us epa has established a maximum contaminant level mcl of 10 mg l no3 n us epa 1995 for drinking water no3 is very mobile in soil water and groundwater systems with a low sorption capacity but can undergo chemical reduction denitrification if the following conditions are met the presence of microbial populations possessing the appropriate metabolic capacity the presence of an electron e donor such as organic carbon and restricted availability of dissolved oxygen o2 and near saturation conditions korom 1992 under rainfall or irrigated conditions high levels of soluble no3 can occur in groundwater due to leaching through the soil profile randall and iragavarapu 1995 no3 then is transported through the saturated zone according to advection dispersion processes and finally delivered to streams and rivers via groundwater discharge duff and triska 2000 approaches to assess no3 contamination fate and reactive transport at the watershed and river basin scale are needed to investigate remediation strategies under scenarios of changes in land use and climatic patterns models can be useful assessment tools for the quantification of pollution pressures by nutrients refsgaard et al 1999 conan et al 2003 over the last decades several empirical lumped models of nutrient transport retention and loss in river basins have been developed based on the export coefficient approach hetling et al 1999 small scale lysimeter based processes wriedt et al 2007 kaufmann et al 2014 gis based mass balance method pieterse et al 2003 and statistical regressions seitzinger et al 2002 each model was initially developed for a different region and goal and differed from other models in its complexity spatial and temporal resolution and data requirements often however individual hydrological and chemical processes need to be simulated in space and time to relate plant growth and root uptake land use and cropping patterns and climate change to the corresponding responses these responses include surface runoff root soil zone processes and nutrient cycling soil moisture flow and chemical transport groundwater flow and chemical transport and groundwater surface water interactions examples of models that incorporate many of these processes include the nitrogen modelling system nms lunn et al 1996 which accounts for no3 transport at the catchment scale the integrated nitrogen model in catchments inca model whitehead et al 1998 which simulates n surface and subsurface pathways undergoing reaction kinetics and the soil and water assessment tool swat arnold et al 1998 neitsch et al 2011 which simulates plant growth surface and subsurface flow and in stream flow and nutrient transport processes another subset of existing groundwater solute reactive transport models e g reactive transport in 3 dimensions rt3d clement 1997 and modular 3 d multi species transport model mt3dms zheng and wang 1999 has been modified to include nitrogen chemical kinetics molenat and gascuel odoux 2002 wriedt and rode 2006 bailey et al 2014 at the regional scale these models receive groundwater head and flow output from the 3d groundwater flow model modflow harbaugh 2005 to simulate solute transport in a heterogeneous aquifer system however these studies lack the appropriate land surface and soil plant hydrological processes to analyze no3 at the watershed scale and in the pathways groundwater runoff in stream of concern in attempts to account for the main hydrological processes in both the land surface system and the groundwater system several researchers in the past two decades have linked swat with modflow at varying levels of complexity sophocleous and perkins 2000 conan et al 2003 kim et al 2008 guzman et al 2015 most recently bailey et al 2016 provided an enhanced swat modflow modelling framework which uses an internal mapping scheme to pass simulated data between swat hydrologic response units hrus i e unique combinations of land use soil and slope that comprise swat s main computational unit and modflow finite difference grid cells on a time step defined by the model user the modelling system also allows the swat and modflow models to be of difference spatial extents to incorporate nitrate fate and transport three specific studies have linked mt3dms to swat modflow modelling systems conan et al 2003 for a 12 km2 catchment in brittany france galbiati et al 2006 for the 20 km2 bonello watershed in italy and narula and gosain 2013 for the 11 600 km2 upper yamuna watershed in the ganga river basin india each modelling systems consisted of the three separate models swat modflow mt3dms that are loosely coupled i e outputs from the swat are provided to modflow and mt3dms but modflow and mt3dms outputs are not provided to swat on the following time step therefore groundwater flow and solute transport processes are dependent on land surface processes but land surface processes such as streamflow and stream solute transport are not dependent on groundwater processes a direct integration is required particularly in watersheds wherein groundwater is close to the ground surface each study also used month averaged rates and loads adequate if water tables are deep but not appropriate for watersheds wherein groundwater is a significant component of streamflow in this study the recently developed swat modflow model bailey et al 2016 that includes internal mapping of hru data to grid cell format is modified to include rt3d to improve the assessment of reactive transport of no3 in both surface and groundwater systems at the watershed scale rt3d is included as a subroutine within the modflow code thus providing a single stand alone swat modflow rt3d model executable with surface subsurface coupling occurring on a daily time step this integration allows spatio temporal characterization of groundwater no3 n concentration groundwater no3 n loading to from the stream network and in stream no3 n loading to demonstrate model capabilities the swat modflow rt3d model is applied to the sprague river watershed 4100 km2 within the upper klamath basin in southern oregon this watershed was chosen due to observed groundwater driven streamflow in several catchments model results are tested against groundwater no3 n concentration groundwater no3 n loading to from the stream network and in stream no3 n loading observation data also are compared against a calibrated stand alone swat model to demonstrate the advantages of using the coupled swat modflow rt3d model 2 model overview this section summarizes the base models that are used in the swat modflow rt3d framework section 3 provides the details of linking the base models to provide the stand alone fully coupled model 2 1 the soil and water assessment tool swat the swat model arnold et al 1998 neitsch et al 2005 2011 gassman et al 2007 is a physically based semi distributed parameter basin scale continuous time hydrologic model that operates on a daily time step it is designed to predict the influence of land management practices on water sediment and nutrient yields at the watershed scale the lumped model emphasizes land surface hydrologic sediment and nutrient processes and is computationally efficient for long term simulation the watershed is divided into multiple sub basins with each sub basin containing one stream within each sub basin mass balance equations for water sediment and nutrients are computed at the level of hydrologic response units hrus which are areal regions that have a unique combination of land use soil properties and slope hrus can be spatially disconnected and do not have a designated geographic location water nutrient and sediment output from each hru are routed directly the outlet of the corresponding sub basin with the connectivity used to route to downstream sub basin in terms of groundwater flow and solute transport swat employs one dimensional analytical lagging routines to route groundwater and nutrient mass from each hru to the sub basin outlet through the stream network these routines therefore neglect heterogeneity in aquifer parameters e g hydraulic conductivity porosity specific yield and specific storage and regional flow gradients and do not consider the subsurface spatial interactions between hrus swat therefore is not capable of expressing the spatial distribution of groundwater levels and groundwater interactions with surface water i e groundwater discharge and stream seepage 2 2 modflow modflow harbaugh 2005 is a physically based three dimensional groundwater model used in confined unconfined or mixed aquifer systems both steady state and transient conditions can be simulated modflow solves the groundwater flow equation based on the finite difference approach that requires the aquifer to be discretized into grid cells laterally and vertically with aquifer properties assumed to be uniform within each cell model output includes groundwater hydraulic head at the center of each cell and if using boundary condition packages such as the river riv package or the streamflow routing sfr package groundwater flow rates to from each stream segment to obtain spatially varying recharge rates modflow often is linked with land surface models such as the precipitation runoff modelling system prms markstrom et al 2015 such as in the integrated gsflow model markstrom et al 2008 or swat as is done in the model presented in this paper modflow simulation results hydraulic head groundwater flow rates sources sinks flow rates can be used by groundwater solute transport models such as mt3dms prommer et al 2003 mao et al 2006 rt3d huang et al 2008 bailey et al 2013a 2014 and pht3d prommer et al 2003 appelo and rolle 2010 among all these solute transport models rt3d allows the use of predefined e g sequential decay reactions microbial growth and transport or user defined sets of kinetically controlled reactions with the option of monod and dual monod kinetics e g lee et al 2006 wriedt and rode 2006 an ordinary differential equation ode solver is used to solve multiple chemical reaction rate laws simultaneously thereby allowing species concentrations to affect each other e g limiting the chemical reduction of an electron acceptor if microbially preferred acceptors are present in the groundwater due to the capability of interactive multi species transport for any number of solutes we therefore have selected rt3d to include in the swat modflow modelling framework in this study section 2 4 2 3 swat modflow model the swat modflow bailey et al 2016 modelling code used in this study uses the modflow nwt niswonger et al 2011 version of modflow and employs an internal mapping scheme that passes data between swat computational units hrus sub basins and modflow grid cells the hydrological processes simulated by swat and by modflow in the coupled swat modflow model are shown in fig 1 with swat processes labeled in green and modflow processes labeled in blue the rt3d processes are labeled in red and will be discussed in section 3 the river package within modflow is used to simulate volumetric exchange flow rates i e either groundwater discharge rates or stream seepage rates between the aquifer and the stream network using streambed hydraulic conductivity and darcy s law with groundwater discharge occurring when water table elevation is higher than the stream stage deep percolation from the bottom of the soil profile as calculated for each hru in the watershed is passed to modflow grid cells as recharge and the depth of each sub basin stream is passed to the modflow river cells modflow then solves the groundwater flow equation and then passes water table elevation to each swat hru and volumetric exchange flow rates to each swat sub basin with the latter added to the water routed through the watershed s stream network using swat s routing algorithms hence swat provides surface water runoff and soil lateral flow to the stream network where modflow provides groundwater discharge and also seepage from the stream to the aquifer the mapping scheme between swat computational units and the modflow finite difference grid cells is based on geo processing routines performed during model construction due to the difference in the spatial discretization between the models each hru must be geographically located which then can be intersected with the modflow grid cells to provide connectivity between the two the hrus typically constructed using arcswat winchell et al 2013 are first split into individual polygons to provide geographical locations to the original hrus these individual polygons are termed disaggregated hrus dhrus bailey et al 2016 which are used to pass hru based values to the modflow grid cells based on the percentage of the dhru area that contributes to the grid cell area according to this definition the separated dhrus share the same variable information with the original hru calculation e g soil deep percolation the modflow river cells are identified by intersecting the watershed stream network with the modflow grid and since the river cells in modflow contribute groundwater surface water interaction to each sub basin stream the group of river cells that reside in each sub basin must also be identified four swat modflow input text files are generated to store the mapping information for hrus to dhrus file 1 dhrus to modflow grid cells file 2 modflow grid cells to dhrus file 3 and swat sub basin to modflow river cells file 4 the information in these four text files is read at the beginning of the swat modflow simulation and stored in memory for use when modflow is called by swat these files can convert information back and forth between these models by running an executable file through a fortran code fig 2 shows a schematic diagram of the coupling and spatial interaction between swat hrus dhrus river and grid cells lateral groundwater flow from adjacent subbasins or from other parts of the regional aquifer system that is beyond the boundaries of the swat model can be represented by specified head or time varying head boundary conditions these boundary conditions will bring groundwater into out of the model domain based on the difference in simulated head and the boundary conditions at the boundary also a larger modflow model that encompasses the regional aquifer system can be used with the swat model linked only for the area within the swat watershed boundary the theoretical documentation for swat modflow and tutorials for preparing swat modflow simulations are available on the main swat model website http swat tamu edu software swat modflow the model has recently been applied to the sprague river watershed bailey et al 2016 the same study watershed for this study model results were compared against groundwater elevation stream discharge and groundwater discharge to stream reaches within the watershed 2 4 rt3d reactive transport in 3 dimensions model rt3d is a three dimensional groundwater contaminant and solute transport model that can simulate advection dispersion and chemical reactions of dissolved constituents in groundwater clement 1997 clement et al 1998 rt3d uses the groundwater hydraulic head cell by cell flow data in all aquifer dimensions and groundwater sources and sinks e g groundwater pumping recharge groundwater surface water exchange flow rates outputs computed by a companion modflow model to establish the groundwater flow field rt3d was chosen due to its ability to simulate chemical kinetics of multiple interacting species assuming rigid porous media linear equilibrium sorption and saturated conditions the system of advection dispersion reaction adr equations describing the fate and transport of contaminants of species k can be written as follows clement 1997 1 ϕ c k t x i ϕ v i c k x i ϕ d i j c k x j q s c s k ρ b c k t ϕ r k 1 2 m where m is the total number of aqueous phase species c k is the concentration of the kth species m f l f 3 where f denotes the fluid phase d ij is the hydrodynamic dispersion coefficient l 2 t 1 v is the average seepage velocity l b t 1 where b denotes the bulk phase ϕ is the soil porosity l f 3 l b 3 q s is the volumetric flux of water representing sources and sinks of the species l f 3 t 1 l b 3 c s k is the concentration of the source or sink m f l f 3 r represents the rate of all reactions that occur in the aqueous phase for the kth species m f l f 3 t 1 ρ b is the bulk density of the porous media m b l b 3 and c k is the concentration of the kth species sorbed on solids m f m b 1 the system of adr equations with one equation for each chemical species is solved for the spatially variable change in c k using the operator split os numerical scheme yeh and tripathy 1989 using the same finite difference grid as the accompanying modflow model with the os method an iterative solver is used to simulate the change in concentration implicitly simultaneously using linear algebra techniques due to advection dispersion and sources and sinks with results provided to the chemical reaction subroutine to solve for the change in concentration due to chemical reactions using an ordinary differential equation ode solver the chemical reaction subroutine within the rt3d fortran can be modified to incorporate any number of interacting chemical species and rate laws for r can describe decay or production of species according to first order chemical kinetics with monod terms for example lee et al 2006 developed a nitrogen transformation module for rt3d that accounted for nitrification and denitrification whereas bailey et al 2015 develop a nitrogen module that accounted for the full nitrogen cycle in the crop soil water system in agricultural areas bailey et al 2013a also developed a selenium cycling module for rt3d 3 swat modflow rt3d modelling framework the swat modflow rt3d modelling code uses the swat modflow model as the base code and incorporates rt3d as a subroutine within the modflow fortran code thus the developed modelling code is a single model that produces a single fortran executable the chemical transport processes simulated by rt3d within the coupled model are summarized in fig 1 with red labels and the data flow of the coupled model is presented in fig 3 the coupled model has the ability to use swat and modflow models of different spatial extent which means one of the models can be extend beyond the boundaries of the other beyond the overlap area the original functionality of each model is retained if the swat model does not have a full hru map i e hrus that cover the entire watershed domain then recharge and nitrate leaching in those areas will not be provided to the underlying modflow rt3d grid cells the current version of swat modflow rt3d includes only no3 n reactive transport in groundwater since it is also simulated by swat and thus can be routed through the stream network using the current in stream nitrogen algorithms of swat based on user needs other reactive chemical species could be implemented into the rt3d reaction module as with swat modflow the computed recharge from each swat hru is passed to modflow grid cells and river stage is passed to modflow river cells when modflow finishes solving the groundwater flow equation the rt3d subroutine is called with the modified rt3d model receiving groundwater fluxes across cell interfaces in each aquifer dimension flow rates of the various sources and sinks from the modflow model and also receives no3 n concentration in recharge water and no3 n concentration in each sub basin stream from the swat model the process of passing data between swat units and modflow rt3d grid cells is demonstrated in the schematic of fig 2 rt3d simulates the change in no3 n concentration for each grid cell and the no3 n mass loading to from to from each stream with the latter passed to swat for in stream water quality modelling and routine through the stream network of the watershed model results can be tested against groundwater no3 n concentration in stream no3 n mass loading rates and if available no3 n groundwater mass loading rates to stream reaches the default time step for coupling between swat modflow and rt3d is one day although the code allows users to specify the frequency of swat calls to modflow rt3d allowing for example a daily surface simulation and monthly subsurface if desired 4 model application sprague river watershed 4 1 study area the integrated swat modflow rt3d framework is tested in the sprague river watershed 4000 km2 for the 1970 to 2003 time period the sprague river watershed is located in upper klamath river basin fig 4 a of southern oregon usa with the annual average precipitation ranging from 340 to 950 mm yr and the elevation ranging from 1270 m to 2600 m above sea level usgs 2009 high elevations occur in the northeast region of the sycan and north fork rivers and low elevations occur in the southwest region along the sprague river corridor fig 5 a the watershed is comprised mostly of coniferous forest rabe and calonje 2009 with minor land cover of herbaceous 14 7 shrubland 14 depressional wetlands 3 4 and cultivated area 2 5 fig 5b the primary land use is grazing of beef cattle in irrigated bottom land u s department of agriculture natural resources conservation service 2009 the sprague river is supplied by three major tributaries the south and north forks which join to form the sprague river main stem and the larger sycan river which reaches the main stem about 20 km downstream of this confluence fig 4c the sprague and williamson rivers are two of the three largest tributaries to the large shallow upper klamath lake see fig 4b and contribute over half of the lake s inflow the third main tributary is the wood river which lies to the east of the sprague and williamson rivers records et al 2014 outflow from upper klamath lake also supplies the u s bureau of reclamation s klamath irrigation project which provides water for more than 1000 farms thorsteinson et al 2011 the sprague river watershed has complex interactions between groundwater and river network groundwater supplies a large percentage of annual stream in the upper klamath basin especially in the north fork of the sprague river where groundwater discharges into streams are approximately 3 4 m3 s however the groundwater influence is relatively low in the sycan river and south fork of the sprague river with only about a groundwater discharge rate of 1 m3 s groundwater to the streams gannett et al 2007 much of the cascade mountains region is highly nitrogen limited which means these aquifers can be recognized as sensitive to no3 inputs anderson 2002 korom 1992 showed that once no3 is leached below the root zone denitrification is a particularly important process for chemical reaction that affects nitrate concentration in the aquifer the low levels of dissolved oxygen along the deep groundwater flow path and the presence of nitrite in the water samples from the deep wells demonstrate that denitrification occurs in the aquifer available data for model testing include no3 n concentration in groundwater and surface water stream flow and water table elevation see section 4 2 4 2 nitrate data for model testing in stream no 3 n loading approximately biweekly stream no3 n grab samples collected by the klamath tribes research station following standard protocol klamath tribes 2008 are available at a stream gage site from march 2001 to december 2010 along the north fork river in the sprague watershed see fig 4c these concentration values were combined with daily flow rates to compute monthly in stream no3 n loads using the program load estimator loadest runkel and cohn 2004 while loadest assumes long term daily flow datasets are collocated with water quality samples the flow data from the closest gage oregon water resources department gage 11495900 were available only after september 2008 while water quality data collection began in approximately march 2001 this flow gage is located less than 0 6 km downstream of the water quality sample location with no intervening tributaries however long term daily flow data for the entire period of water quality data collection were available at us geological survey gage 11495800 approximately 1 7 km upstream of the water quality sample location but with an intervening ungaged tributary therefore a scatter plot was derived using the flow data at one gage against another during the period of overlapping data availability for both gages september 2008 september 2011 the slope of the linear regression line between the two flow points is treated as the scaling factor and is used to estimate a time series of daily flows at the downstream oregon water resources department gage for flow inputs to the loadest program from 2001 to 2010 the resulting simulated in stream loading time series at the north fork stream gage was compared to the loadest data without any further calibration groundwater no 3 n concentrations available no3 n groundwater data in the sprague river watershed in recent decades are entirely from drinking water quality compliance monitoring for domestic and small commercial wells groundwater no3 n data for klamath county was retrieved from the oregon public health drinking water data online inventory https yourwater oregon gov countyinventory php accessed 26 august 2015 including all agencies and well status active and inactive from the query results all well logs containing the name of any towns known to occur in or near the sprague river watershed e g beatty bly sprague river chiloquin were selected well log locations were provided only in the public land system survey grid to quarter quarter section or coarser spatial resolution depending on the coarseness of the resolution well location grids were then matched in arcgis from one to 16 intersecting modflow grid cells there are 16 observation wells with a total of 602 measurements of groundwater no3 n concentration that are available for model testing the average groundwater no3 n concentration is 0 34 mg l with a standard deviation of 0 77 mg l the locations of the observation wells are shown in fig 4c they are situated principally along the south fork and sprague rivers 4 3 model construction the swat modflow model for the sprague river watershed was developed by bailey et al 2016 by linking a calibrated swat model for the sprague river watershed records et al 2014 with a calibrated modflow model for upper klamath basin gannett et al 2012 the swat model was developed to study the influence of climate change and wetland loss on water quality whereas the modflow model was used to quantitative evaluate the regional groundwater system within the basin the modflow model was developed by the us geological survey although the modflow model included the entire upper klamath basin only the portion covered by the sprague river watershed was coupled with the swat model since the main stem and tributaries have different hydrologic characteristics the developed swat model was separated into four swat models the sprague river main stem sycan river south fork and north fork records et al 2014 for more details of swat setup refer to records 2013 the swat model was calibrated and tested using monthly stream flow during the 2001 2010 period it was auto calibrated with dynamically dimensioned search dds algorithms employing manual calibration where necessary to fine tune model performance using tools developed by tolson and shoemaker 2007 model performance was generally acceptable for streamflow with a monthly nash sutcliff efficiency coefficient nsec greater than 0 7 at the outlet of the sprague river records et al 2014 however monthly streamflow percent bias was 31 overestimated for the north fork a groundwater driven tributary as such the four swat models were merged and the parameters for north fork model were applied to the entire watershed the model domain of the modflow model encompasses the entire upper klamath basin see fig 4b which drains an area of about 20 000 km2 this region was divided into cells with a cell size of 762 m within modflow the aquifers are represented as three variable thickness layers discretized into a grid of 285 rows and 210 columns the original model was set to simulate 3 month quarterly stress periods from 1970 through 2003 with each stress period subdivided into 5 flow time steps to evaluate the timing of the hydrologic response to changes in stresses the model was calibrated for the 1989 to 2003 time period gannett et al 2012 for the swat modflow model simulation bailey et al 2016 model results were compared against groundwater head data stream discharge rates at the north fork gage site and groundwater discharge rates to 6 stream reaches throughout the sprague river watershed for the swat modflow rt3d model the rt3d component used the same grid as the modflow model with the following adr equation used to simulate reactive transport of no3 in the aquifer system 2 c n o 3 t r n o 3 x i v i c n o 3 x i d i j c n o 3 x j q s ϕ c s n o 3 r since no3 has a very low sorption capacity the retardation factor r n o 3 is set to 1 0 for each grid cell indicating no sorption the rate law for denitrification is specified using a single monod expression wherein the rate of the reaction depends only on the presence of no3 3 r no 3 μ n o 3 c n o 3 c n o 3 k n o 3 c n o 3 where μ n o 3 is the first order rate constant d 1 for denitrification and k n o 3 is the monod half saturation constant m f l f 3 for no3 since spatially varying information on denitrification activity is not available for the watershed constant values for both μ n o 3 and k n o 3 are provided to each grid cell μ n o 3 was assigned a value of 0 07 day 1 which corresponds to a half life of 10 days this value is approximately the average of most published denitrification first order rates in soils and aquifers throughout the world heatwole and mccray 2007 bailey et al 2012b and similar to the half life value of 11 days and 8 days found in aquifer studies presented in conan et al 2003 and pauwels et al 1998 respectively the coupled swat modflow rt3d was simulated from 1970 to 2003 with daily time steps although the modflow model simulates the entire upper klamath basin it is still capable of coupling with the swat model in only the sprague river watershed area the coupled model contains 142 swat sub basins and 763 river cells in the sprague river watershed according to the principles described in model coupling section 1940 hru polygons used in the construction of the swat model were spatially disaggregated to create 207 804 dhrus 5 results and discussion 5 1 groundwater no3 n concentrations typical results of the swat modflow rt3d simulation in regards to groundwater head and no3 n groundwater concentration are shown in figs 6 11 simulated cell wise groundwater hydraulic head m at the end of the coupled model simulation 2003 is shown in fig 6a with the water table elevation ranging from 1268 m to 2025 m above msl the spatial pattern of the head field is similar to the ground surface elevation with high head and low head occurring in regions of high and low surface elevation respectively the lowest water table elevation occurs along the main corridor of the sprague river the depth to water table for the north fork catchment where the stream and water quality gage is located is shown in fig 6b showing the areas of high water table along the stream network fig 7a shows the spatial distribution of simulated annual averaged no3 n concentration mg l in groundwater of the sprague river watershed with no3 n values ranging from 0 to 1 2 mg l the highest concentrations occur along the main sprague river corridor and in the northwest region of the watershed an increasing trend of concentration was found from the watershed boundary toward the stream site due to the distribution of land use types fig 5b fig 7b and c d show the time series of simulated and observed no3 n concentration at the location of three groundwater monitoring wells for the time period 1985 to 2003 with the location of the wells shown in fig 7a these three wells are selected due to multiple samples available for each site the simulated values correspond to rt3d grid cells within which the monitoring wells are located wells 136 142 and 135 129 are located in cultivated areas in general the model captures well the within season and long term trend of no3 n magnitude in particular for well 136 142 the seasonal pattern of rapid concentration increase due to fertilizer and then slow concentration decrease due to denitrification during the fall and winter months is replicated and corresponds well to observed values fig 8 shows boxplots of average annual simulated groundwater no3 n concentrations for different land use types both the spatial distribution and boxplots demonstrate that higher no3 n concentrations occur in the cultivated filed areas and herbaceous regions with low no3 n concentrations in the upland forested areas and along the main corridor of the south fork catchment when comparing the average of the measured no3 n values in the observation wells 0 33 mg l with the average simulated values from all grid cells 0 08 mg l the model seems to under predict no3 n concentration however the majority of observation wells are located along the river corridors see fig 4c which are cultivated fields and herbaceous land use types with higher no3 n concentration than natural background concentrations anderson 2002 see also boxplots in fig 8 especially for the cultivated field area the averaged simulated no3 n concentration is 0 52 mg l therefore annually averaged no3 n concentrations from grid cells along the rivers are selected to evaluate the model performance close to the observation wells four different sets of spatial analysis were performed using four different buffer zones all grid cells within a 500 m 1000 m and 2000 m buffer from the entire sprague river watershed stream network and finally all grid cells in the sprague river watershed model domain this resulted in 2 278 3 220 4 685 and 7060 grid cells for the four scenarios respectively frequency distributions are used to compare the 602 observed values with model results fig 9 frequency distributions analyzes the ability of the coupled model to represent accurately the range of the concentration values as compared to observed values and the relative frequency of concentration values within a given concentration interval to verify if the model captures the regional spatio temporal statistics of solute concentration as can be seen from fig 9 the shape and the magnitude of frequency for each concentration interval produced by the model is similar to the frequency from the observed data particularly for the 500 m buffer zone as the observation wells are located close to the river network the swat modflow rt3d model slightly overestimates the low range to mid range concentrations 0 0 4 mg l according to fig 9 a b c or 0 0 3 mg l according to fig 9d and slightly underestimates the mid range to high range concentrations 0 4 mg l for all buffer zones for example for the 500 m buffer zone simulated relative frequencies for 0 1 0 2 mg l and over 1 0 mg l concentration ranges are 20 9 and 0 7 whereas the observed data indicated that relative frequencies are 12 9 and 6 4 of the ranges respectively as can be seen from fig 7 that high no3 n concentrations can be captured by the model however even for the 500 m buffer zone scenario it still includes a large amount of simulated low concentration grid cells located along the upstream of the river corridors fig 7a whereas the observed wells are located at outlets of the sycan river the north fork the south fork and downstream of the sprague river fig 4 which contain high values of no3 n fig 7a when generating the pdf graph the relative frequency of the high values is not as much as the observed values in brief the large discrepancy between the simulated and observed frequency over low range and high range concentration values could be an artifact of not having samples in areas of low no3 n concentration i e observation well placement is biased towards areas of probable high no3 n concentration due to cultivated areas and animal grazing 5 2 no3 n in stream loading simulated and measured no3 n in stream loading for the north fork gage see location in fig 4c are shown in fig 10a the unit for the in stream loading is kg ha which is calculated by kg of in stream no3 n divided by the watershed area as seen in the figure the swat modflow rt3d model is able to track the measured in stream loading quite well with simulated results matching measured results for peak flow periods and base flow periods with peaks occurring after the precipitation season shaded areas in fig 10a as compared to the original swat model records 2013 there is a marked improvement in performance statistics nash sutcliff efficiency coefficient nsec root mean square error rmse mean average error mae and coefficient of determination r2 for the coupled swat modflow rt3d model nsec 0 42 rmse 0 001 kg ha mae 0 278 kg ha r2 0 77 as compared to swat nsec 0 26 rmse 0 002 kg ha mae 0 491 kg ha r2 0 70 the uncoupled swat model consistently underestimates the in stream loading particularly during the periods of low baseflow i e groundwater discharge likely due to the lack of physically based groundwater and solute transport modelling fig 10b shows the scatterplot of the observed versus simulated monthly no3 n in stream concentration for the gage site on the north fork river see fig 4c from the swat model and the swat modflow rt3d model respectively error bounds were calculated by adding and subtracting the percentage of error to the simulated and observed values and then drawing the corresponding upper and lower lines that go through as can be seen in the figure the average measured no3 n in stream concentration is 0 00359 kg ha for 2001 2003 period and the simulated value from the swat and the coupled model is 0 00239 kg ha and 0 00361 kg ha respectively the rmse and mae from the coupled model provide low relative errors during the simulation period moriasi et al 2015 summarized that model performance can be judged as very good if monthly r2 0 7 indicating along with the visual inspection of the time series plots in fig 10 that the model out performs the swat model based on the swat modflow rt3d results there are a few outliers below the error range which demonstrates the model underestimates the loads at these receptors nevertheless 80 of the simulated in stream loading values fall within an error margin of 30 whereas the majority of the points from the swat model are below 30 error bound overall the coupled model shows a substantial improvement and yields good similarity with the observed values 5 3 groundwater no3 n mass loading to the sprague river simulated no3 n mass loading kg year from the aquifer to the stream network during the 1970 2003 period is shown in fig 11a which is important to quantify spatio temporal patterns of groundwater and surface water interaction in the watershed values are plotted for average annual mass loading for each of the 763 river cells within the sprague river watershed red bars represent no3 n loading from the aquifer to the stream whereas green bars indicate no3 n loading from the stream into the aquifer via stream seepage as can be seen in fig 11a the magnitude of no3 n loading is highly spatially variable based on different local hydrologic conditions and groundwater no3 n concentration the main sites for groundwater mass loading are located in the north fork catchment and the downstream portion of the sprague river average annual no3 n mass loading during the 1970 2003 time period for the entire sprague river watershed is shown in fig 11b loading varies from year to year with the estimated values changing from 4843 kg year 1983 to 6318 kg year 2001 with a standard deviation of 354 kg year for the entire 34 years the average mass of no3 n discharge into stream was approximately 5711 kg year further analysis shows that the average no3 n discharge loading for each kilometer length of the stream network is approximately 14 kg year this rate is similar to the loading of 26 kg year km estimated by morgan et al 2007 for the la pine oregon area a region located approximately 100 km north of the sprague river watershed during the year 1999 the higher loading rate in the la pine area likely is due to septic tank effluent being the primary source of no3 n hinkle et al 2007 which results in higher no3 n groundwater concentrations than in the sprague river watershed 5 4 model capabilities and limitations the integrated swat modflow rt3d model can be a useful tool to explore the fate and transport of no3 in coupled surface and subsurface systems and to identify plausible best management practices for controlling contaminant pollution in agricultural watersheds for now only no3 is included but other nitrogen species e g nh4 no2 could be simulated as well as other chemical species or contaminants for a given watershed the model provides the advantage of accounting for spatial variability in nutrient loadings and allows the realistic long term allocation of different nutrient sources with the existing land use practices present in the watershed the coupled model can provide maps of spatially varying groundwater nutrient concentration and nutrient mass fluxes between surface and groundwater which can help to assess possible hot spot nutrient areas in the aquifer and sensitive locations of nutrient loading from the aquifer to the river network these areas can be targeted for future remediation and fulfill the potential requirement for removal changes of drinking water sources under a given management alternative to satisfy groundwater quality currently the model does not account for no3 transport in the vadose zone for areas of high water tables this type of model is ideal since it captures the spatial interaction between groundwater in a heterogeneous aquifer and a stream network the vadose zone therefore may not impact significantly the travel time of no3 between the bottom of the soil profile and the water table however the uzf unsaturated zone flow package for modflow niswonger et al 2006 can be employed to simulate one dimensional groundwater flow in the vadose zone and can be coupled with a recent version of rt3d uzf rt3d bailey et al 2013b that can simulate reactive solute transport in the vadose zone this option will be included in future versions of swat modflow rt3d 6 summary and conclusions in this study the recently developed swat modflow model is extended to simulate the fate and transport of solute species in variably saturated subsurface systems by including the reactive transport model rt3d as a subroutine within the modflow code the resulting model is a single fortran code that provides a single model executable which greatly facilitates the modelling process and saves potential input output reading errors from single models the framework provides a valuable simulation tool for watersheds in which groundwater processes and groundwater nutrient concentrations significantly impact stream flow and in stream nutrient loading or wherein groundwater sources and sinks can impact land surface hydrologic processes model source code and a tutorial outlining the preparation of swat modflow rt3d simulations are available on the main swat model website http swat tamu edu software swat modflow applicability of this model was tested in the sprague river watershed 4100 km2 in the upper klamath basin during the 1970 2003 time period model results are tested against spatio temporal averages of no3 n groundwater concentrations and in stream no3 n loading at a stream gage site annual average mass loadings of no3 n from the aquifer to the stream network also are presented to demonstrate the capabilities of the model in providing spatially varying nutrient loading information the integrated model can be further applied to identify plausible best management practices for controlling contaminant pollution in agricultural watershed for now only no3 is included but other nitrogen species e g nh4 no2 could be simulated as well as other chemical species or contaminants for a given watershed areas that need improvements include 1 incorporating uzf rt3d with the unsaturated zone flow uzf package of modflow to better represent the solute transport in both the unsaturated and saturated zones and for agricultural irrigated areas 2 modification of swat hru to better represent cultivated field for irrigation requirements and 3 incorporation of new algorithms to simulate the impact of earthen canals on aquifer systems 7 software availability the swat modflow rt3d model is a fortran code developed using the intel fortran compiler for microsoft visual studio 10 microsoft corporation the program executable swat modflow rt3d exe was made available july 2016 and is available for download at no cost on the main webpage for the swat model http swat tamu edu software swat modflow the size of the executable is 28 5 mb the fortran source code also is available 7 mb for download from the same webpage with instructions for compiling in the intel visual fortran environment the program executable can run on any personal computer a workshop tutorial and example dataset for constructing a swat modflow rt3d model for the little river watershed georgia also is available on the webpage the modelling code is based on the original modelling codes of swat modflow and rt3d and was developed by ryan bailey and tyler wible ryan bailey can be contacted at department of civil and environmental engineering colorado state university 1372 campus delivery fort collins co 80523 1372 united states telephone 970 491 5045 fax 970 491 7727 e mail rtbailey colostate edu acknowledgements this work was supported by a grant from the agriculture and food research initiative of the usda national institute of food and agriculture grant number 2012 67003 19904 we thank two anonymous reviewers for providing very helpful comments and suggestions that improved the content of this paper 
26141,this paper presents swat modflow rt3d a model that couples the semi distributed watershed model swat soil and water assessment tool with the groundwater flow model modflow and the groundwater solute reactive transport model rt3d to simulate nitrate no3 fate and transport in a watershed system the model is based on a recently developed swat modflow model with rt3d now called as a subroutine within the modflow code to provide a single stand alone model code rt3d uses no3 concentration of deep percolation water from swat and groundwater heads and flows from modflow to simulate spatially varying groundwater no3 concentration and no3 loading to from streams with the latter used by swat to route no3 mass through the network model use is demonstrated through an application to the sprague river watershed 4100 km2 in oregon other chemical species of interest can be included in the rt3d reaction module in applications of the model to other watersheds keywords nitrate groundwater swat modflow rt3d integrated modelling management 1 introduction due to the requirement for increased production of food and energy the application of fertilizers has increased augmenting nitrogen n pollution in the environment erisman et al 2013 nitrate no3 has been one of the dominant forms of increased n loading since the 1970s dise and wright 1995 smith et al 1999 high concentration of no3 dissolved in surface water can lead to eutrophication of water bodies puckett 1994 nolan et al 1997 vidon et al 2010 and also can cause health problems such as methemoglobinemia in infants and stomach cancer in adults carpenter et al 1998 the presence of no3 in groundwater systems also can contribute to the oxidative dissolution and inhibition of chemical reduction of other dissolved environmental pollutants such as selenite seo4 and sulfate so4 e g wright 1999 bailey et al 2012a as such the us environmental protection agency us epa has established a maximum contaminant level mcl of 10 mg l no3 n us epa 1995 for drinking water no3 is very mobile in soil water and groundwater systems with a low sorption capacity but can undergo chemical reduction denitrification if the following conditions are met the presence of microbial populations possessing the appropriate metabolic capacity the presence of an electron e donor such as organic carbon and restricted availability of dissolved oxygen o2 and near saturation conditions korom 1992 under rainfall or irrigated conditions high levels of soluble no3 can occur in groundwater due to leaching through the soil profile randall and iragavarapu 1995 no3 then is transported through the saturated zone according to advection dispersion processes and finally delivered to streams and rivers via groundwater discharge duff and triska 2000 approaches to assess no3 contamination fate and reactive transport at the watershed and river basin scale are needed to investigate remediation strategies under scenarios of changes in land use and climatic patterns models can be useful assessment tools for the quantification of pollution pressures by nutrients refsgaard et al 1999 conan et al 2003 over the last decades several empirical lumped models of nutrient transport retention and loss in river basins have been developed based on the export coefficient approach hetling et al 1999 small scale lysimeter based processes wriedt et al 2007 kaufmann et al 2014 gis based mass balance method pieterse et al 2003 and statistical regressions seitzinger et al 2002 each model was initially developed for a different region and goal and differed from other models in its complexity spatial and temporal resolution and data requirements often however individual hydrological and chemical processes need to be simulated in space and time to relate plant growth and root uptake land use and cropping patterns and climate change to the corresponding responses these responses include surface runoff root soil zone processes and nutrient cycling soil moisture flow and chemical transport groundwater flow and chemical transport and groundwater surface water interactions examples of models that incorporate many of these processes include the nitrogen modelling system nms lunn et al 1996 which accounts for no3 transport at the catchment scale the integrated nitrogen model in catchments inca model whitehead et al 1998 which simulates n surface and subsurface pathways undergoing reaction kinetics and the soil and water assessment tool swat arnold et al 1998 neitsch et al 2011 which simulates plant growth surface and subsurface flow and in stream flow and nutrient transport processes another subset of existing groundwater solute reactive transport models e g reactive transport in 3 dimensions rt3d clement 1997 and modular 3 d multi species transport model mt3dms zheng and wang 1999 has been modified to include nitrogen chemical kinetics molenat and gascuel odoux 2002 wriedt and rode 2006 bailey et al 2014 at the regional scale these models receive groundwater head and flow output from the 3d groundwater flow model modflow harbaugh 2005 to simulate solute transport in a heterogeneous aquifer system however these studies lack the appropriate land surface and soil plant hydrological processes to analyze no3 at the watershed scale and in the pathways groundwater runoff in stream of concern in attempts to account for the main hydrological processes in both the land surface system and the groundwater system several researchers in the past two decades have linked swat with modflow at varying levels of complexity sophocleous and perkins 2000 conan et al 2003 kim et al 2008 guzman et al 2015 most recently bailey et al 2016 provided an enhanced swat modflow modelling framework which uses an internal mapping scheme to pass simulated data between swat hydrologic response units hrus i e unique combinations of land use soil and slope that comprise swat s main computational unit and modflow finite difference grid cells on a time step defined by the model user the modelling system also allows the swat and modflow models to be of difference spatial extents to incorporate nitrate fate and transport three specific studies have linked mt3dms to swat modflow modelling systems conan et al 2003 for a 12 km2 catchment in brittany france galbiati et al 2006 for the 20 km2 bonello watershed in italy and narula and gosain 2013 for the 11 600 km2 upper yamuna watershed in the ganga river basin india each modelling systems consisted of the three separate models swat modflow mt3dms that are loosely coupled i e outputs from the swat are provided to modflow and mt3dms but modflow and mt3dms outputs are not provided to swat on the following time step therefore groundwater flow and solute transport processes are dependent on land surface processes but land surface processes such as streamflow and stream solute transport are not dependent on groundwater processes a direct integration is required particularly in watersheds wherein groundwater is close to the ground surface each study also used month averaged rates and loads adequate if water tables are deep but not appropriate for watersheds wherein groundwater is a significant component of streamflow in this study the recently developed swat modflow model bailey et al 2016 that includes internal mapping of hru data to grid cell format is modified to include rt3d to improve the assessment of reactive transport of no3 in both surface and groundwater systems at the watershed scale rt3d is included as a subroutine within the modflow code thus providing a single stand alone swat modflow rt3d model executable with surface subsurface coupling occurring on a daily time step this integration allows spatio temporal characterization of groundwater no3 n concentration groundwater no3 n loading to from the stream network and in stream no3 n loading to demonstrate model capabilities the swat modflow rt3d model is applied to the sprague river watershed 4100 km2 within the upper klamath basin in southern oregon this watershed was chosen due to observed groundwater driven streamflow in several catchments model results are tested against groundwater no3 n concentration groundwater no3 n loading to from the stream network and in stream no3 n loading observation data also are compared against a calibrated stand alone swat model to demonstrate the advantages of using the coupled swat modflow rt3d model 2 model overview this section summarizes the base models that are used in the swat modflow rt3d framework section 3 provides the details of linking the base models to provide the stand alone fully coupled model 2 1 the soil and water assessment tool swat the swat model arnold et al 1998 neitsch et al 2005 2011 gassman et al 2007 is a physically based semi distributed parameter basin scale continuous time hydrologic model that operates on a daily time step it is designed to predict the influence of land management practices on water sediment and nutrient yields at the watershed scale the lumped model emphasizes land surface hydrologic sediment and nutrient processes and is computationally efficient for long term simulation the watershed is divided into multiple sub basins with each sub basin containing one stream within each sub basin mass balance equations for water sediment and nutrients are computed at the level of hydrologic response units hrus which are areal regions that have a unique combination of land use soil properties and slope hrus can be spatially disconnected and do not have a designated geographic location water nutrient and sediment output from each hru are routed directly the outlet of the corresponding sub basin with the connectivity used to route to downstream sub basin in terms of groundwater flow and solute transport swat employs one dimensional analytical lagging routines to route groundwater and nutrient mass from each hru to the sub basin outlet through the stream network these routines therefore neglect heterogeneity in aquifer parameters e g hydraulic conductivity porosity specific yield and specific storage and regional flow gradients and do not consider the subsurface spatial interactions between hrus swat therefore is not capable of expressing the spatial distribution of groundwater levels and groundwater interactions with surface water i e groundwater discharge and stream seepage 2 2 modflow modflow harbaugh 2005 is a physically based three dimensional groundwater model used in confined unconfined or mixed aquifer systems both steady state and transient conditions can be simulated modflow solves the groundwater flow equation based on the finite difference approach that requires the aquifer to be discretized into grid cells laterally and vertically with aquifer properties assumed to be uniform within each cell model output includes groundwater hydraulic head at the center of each cell and if using boundary condition packages such as the river riv package or the streamflow routing sfr package groundwater flow rates to from each stream segment to obtain spatially varying recharge rates modflow often is linked with land surface models such as the precipitation runoff modelling system prms markstrom et al 2015 such as in the integrated gsflow model markstrom et al 2008 or swat as is done in the model presented in this paper modflow simulation results hydraulic head groundwater flow rates sources sinks flow rates can be used by groundwater solute transport models such as mt3dms prommer et al 2003 mao et al 2006 rt3d huang et al 2008 bailey et al 2013a 2014 and pht3d prommer et al 2003 appelo and rolle 2010 among all these solute transport models rt3d allows the use of predefined e g sequential decay reactions microbial growth and transport or user defined sets of kinetically controlled reactions with the option of monod and dual monod kinetics e g lee et al 2006 wriedt and rode 2006 an ordinary differential equation ode solver is used to solve multiple chemical reaction rate laws simultaneously thereby allowing species concentrations to affect each other e g limiting the chemical reduction of an electron acceptor if microbially preferred acceptors are present in the groundwater due to the capability of interactive multi species transport for any number of solutes we therefore have selected rt3d to include in the swat modflow modelling framework in this study section 2 4 2 3 swat modflow model the swat modflow bailey et al 2016 modelling code used in this study uses the modflow nwt niswonger et al 2011 version of modflow and employs an internal mapping scheme that passes data between swat computational units hrus sub basins and modflow grid cells the hydrological processes simulated by swat and by modflow in the coupled swat modflow model are shown in fig 1 with swat processes labeled in green and modflow processes labeled in blue the rt3d processes are labeled in red and will be discussed in section 3 the river package within modflow is used to simulate volumetric exchange flow rates i e either groundwater discharge rates or stream seepage rates between the aquifer and the stream network using streambed hydraulic conductivity and darcy s law with groundwater discharge occurring when water table elevation is higher than the stream stage deep percolation from the bottom of the soil profile as calculated for each hru in the watershed is passed to modflow grid cells as recharge and the depth of each sub basin stream is passed to the modflow river cells modflow then solves the groundwater flow equation and then passes water table elevation to each swat hru and volumetric exchange flow rates to each swat sub basin with the latter added to the water routed through the watershed s stream network using swat s routing algorithms hence swat provides surface water runoff and soil lateral flow to the stream network where modflow provides groundwater discharge and also seepage from the stream to the aquifer the mapping scheme between swat computational units and the modflow finite difference grid cells is based on geo processing routines performed during model construction due to the difference in the spatial discretization between the models each hru must be geographically located which then can be intersected with the modflow grid cells to provide connectivity between the two the hrus typically constructed using arcswat winchell et al 2013 are first split into individual polygons to provide geographical locations to the original hrus these individual polygons are termed disaggregated hrus dhrus bailey et al 2016 which are used to pass hru based values to the modflow grid cells based on the percentage of the dhru area that contributes to the grid cell area according to this definition the separated dhrus share the same variable information with the original hru calculation e g soil deep percolation the modflow river cells are identified by intersecting the watershed stream network with the modflow grid and since the river cells in modflow contribute groundwater surface water interaction to each sub basin stream the group of river cells that reside in each sub basin must also be identified four swat modflow input text files are generated to store the mapping information for hrus to dhrus file 1 dhrus to modflow grid cells file 2 modflow grid cells to dhrus file 3 and swat sub basin to modflow river cells file 4 the information in these four text files is read at the beginning of the swat modflow simulation and stored in memory for use when modflow is called by swat these files can convert information back and forth between these models by running an executable file through a fortran code fig 2 shows a schematic diagram of the coupling and spatial interaction between swat hrus dhrus river and grid cells lateral groundwater flow from adjacent subbasins or from other parts of the regional aquifer system that is beyond the boundaries of the swat model can be represented by specified head or time varying head boundary conditions these boundary conditions will bring groundwater into out of the model domain based on the difference in simulated head and the boundary conditions at the boundary also a larger modflow model that encompasses the regional aquifer system can be used with the swat model linked only for the area within the swat watershed boundary the theoretical documentation for swat modflow and tutorials for preparing swat modflow simulations are available on the main swat model website http swat tamu edu software swat modflow the model has recently been applied to the sprague river watershed bailey et al 2016 the same study watershed for this study model results were compared against groundwater elevation stream discharge and groundwater discharge to stream reaches within the watershed 2 4 rt3d reactive transport in 3 dimensions model rt3d is a three dimensional groundwater contaminant and solute transport model that can simulate advection dispersion and chemical reactions of dissolved constituents in groundwater clement 1997 clement et al 1998 rt3d uses the groundwater hydraulic head cell by cell flow data in all aquifer dimensions and groundwater sources and sinks e g groundwater pumping recharge groundwater surface water exchange flow rates outputs computed by a companion modflow model to establish the groundwater flow field rt3d was chosen due to its ability to simulate chemical kinetics of multiple interacting species assuming rigid porous media linear equilibrium sorption and saturated conditions the system of advection dispersion reaction adr equations describing the fate and transport of contaminants of species k can be written as follows clement 1997 1 ϕ c k t x i ϕ v i c k x i ϕ d i j c k x j q s c s k ρ b c k t ϕ r k 1 2 m where m is the total number of aqueous phase species c k is the concentration of the kth species m f l f 3 where f denotes the fluid phase d ij is the hydrodynamic dispersion coefficient l 2 t 1 v is the average seepage velocity l b t 1 where b denotes the bulk phase ϕ is the soil porosity l f 3 l b 3 q s is the volumetric flux of water representing sources and sinks of the species l f 3 t 1 l b 3 c s k is the concentration of the source or sink m f l f 3 r represents the rate of all reactions that occur in the aqueous phase for the kth species m f l f 3 t 1 ρ b is the bulk density of the porous media m b l b 3 and c k is the concentration of the kth species sorbed on solids m f m b 1 the system of adr equations with one equation for each chemical species is solved for the spatially variable change in c k using the operator split os numerical scheme yeh and tripathy 1989 using the same finite difference grid as the accompanying modflow model with the os method an iterative solver is used to simulate the change in concentration implicitly simultaneously using linear algebra techniques due to advection dispersion and sources and sinks with results provided to the chemical reaction subroutine to solve for the change in concentration due to chemical reactions using an ordinary differential equation ode solver the chemical reaction subroutine within the rt3d fortran can be modified to incorporate any number of interacting chemical species and rate laws for r can describe decay or production of species according to first order chemical kinetics with monod terms for example lee et al 2006 developed a nitrogen transformation module for rt3d that accounted for nitrification and denitrification whereas bailey et al 2015 develop a nitrogen module that accounted for the full nitrogen cycle in the crop soil water system in agricultural areas bailey et al 2013a also developed a selenium cycling module for rt3d 3 swat modflow rt3d modelling framework the swat modflow rt3d modelling code uses the swat modflow model as the base code and incorporates rt3d as a subroutine within the modflow fortran code thus the developed modelling code is a single model that produces a single fortran executable the chemical transport processes simulated by rt3d within the coupled model are summarized in fig 1 with red labels and the data flow of the coupled model is presented in fig 3 the coupled model has the ability to use swat and modflow models of different spatial extent which means one of the models can be extend beyond the boundaries of the other beyond the overlap area the original functionality of each model is retained if the swat model does not have a full hru map i e hrus that cover the entire watershed domain then recharge and nitrate leaching in those areas will not be provided to the underlying modflow rt3d grid cells the current version of swat modflow rt3d includes only no3 n reactive transport in groundwater since it is also simulated by swat and thus can be routed through the stream network using the current in stream nitrogen algorithms of swat based on user needs other reactive chemical species could be implemented into the rt3d reaction module as with swat modflow the computed recharge from each swat hru is passed to modflow grid cells and river stage is passed to modflow river cells when modflow finishes solving the groundwater flow equation the rt3d subroutine is called with the modified rt3d model receiving groundwater fluxes across cell interfaces in each aquifer dimension flow rates of the various sources and sinks from the modflow model and also receives no3 n concentration in recharge water and no3 n concentration in each sub basin stream from the swat model the process of passing data between swat units and modflow rt3d grid cells is demonstrated in the schematic of fig 2 rt3d simulates the change in no3 n concentration for each grid cell and the no3 n mass loading to from to from each stream with the latter passed to swat for in stream water quality modelling and routine through the stream network of the watershed model results can be tested against groundwater no3 n concentration in stream no3 n mass loading rates and if available no3 n groundwater mass loading rates to stream reaches the default time step for coupling between swat modflow and rt3d is one day although the code allows users to specify the frequency of swat calls to modflow rt3d allowing for example a daily surface simulation and monthly subsurface if desired 4 model application sprague river watershed 4 1 study area the integrated swat modflow rt3d framework is tested in the sprague river watershed 4000 km2 for the 1970 to 2003 time period the sprague river watershed is located in upper klamath river basin fig 4 a of southern oregon usa with the annual average precipitation ranging from 340 to 950 mm yr and the elevation ranging from 1270 m to 2600 m above sea level usgs 2009 high elevations occur in the northeast region of the sycan and north fork rivers and low elevations occur in the southwest region along the sprague river corridor fig 5 a the watershed is comprised mostly of coniferous forest rabe and calonje 2009 with minor land cover of herbaceous 14 7 shrubland 14 depressional wetlands 3 4 and cultivated area 2 5 fig 5b the primary land use is grazing of beef cattle in irrigated bottom land u s department of agriculture natural resources conservation service 2009 the sprague river is supplied by three major tributaries the south and north forks which join to form the sprague river main stem and the larger sycan river which reaches the main stem about 20 km downstream of this confluence fig 4c the sprague and williamson rivers are two of the three largest tributaries to the large shallow upper klamath lake see fig 4b and contribute over half of the lake s inflow the third main tributary is the wood river which lies to the east of the sprague and williamson rivers records et al 2014 outflow from upper klamath lake also supplies the u s bureau of reclamation s klamath irrigation project which provides water for more than 1000 farms thorsteinson et al 2011 the sprague river watershed has complex interactions between groundwater and river network groundwater supplies a large percentage of annual stream in the upper klamath basin especially in the north fork of the sprague river where groundwater discharges into streams are approximately 3 4 m3 s however the groundwater influence is relatively low in the sycan river and south fork of the sprague river with only about a groundwater discharge rate of 1 m3 s groundwater to the streams gannett et al 2007 much of the cascade mountains region is highly nitrogen limited which means these aquifers can be recognized as sensitive to no3 inputs anderson 2002 korom 1992 showed that once no3 is leached below the root zone denitrification is a particularly important process for chemical reaction that affects nitrate concentration in the aquifer the low levels of dissolved oxygen along the deep groundwater flow path and the presence of nitrite in the water samples from the deep wells demonstrate that denitrification occurs in the aquifer available data for model testing include no3 n concentration in groundwater and surface water stream flow and water table elevation see section 4 2 4 2 nitrate data for model testing in stream no 3 n loading approximately biweekly stream no3 n grab samples collected by the klamath tribes research station following standard protocol klamath tribes 2008 are available at a stream gage site from march 2001 to december 2010 along the north fork river in the sprague watershed see fig 4c these concentration values were combined with daily flow rates to compute monthly in stream no3 n loads using the program load estimator loadest runkel and cohn 2004 while loadest assumes long term daily flow datasets are collocated with water quality samples the flow data from the closest gage oregon water resources department gage 11495900 were available only after september 2008 while water quality data collection began in approximately march 2001 this flow gage is located less than 0 6 km downstream of the water quality sample location with no intervening tributaries however long term daily flow data for the entire period of water quality data collection were available at us geological survey gage 11495800 approximately 1 7 km upstream of the water quality sample location but with an intervening ungaged tributary therefore a scatter plot was derived using the flow data at one gage against another during the period of overlapping data availability for both gages september 2008 september 2011 the slope of the linear regression line between the two flow points is treated as the scaling factor and is used to estimate a time series of daily flows at the downstream oregon water resources department gage for flow inputs to the loadest program from 2001 to 2010 the resulting simulated in stream loading time series at the north fork stream gage was compared to the loadest data without any further calibration groundwater no 3 n concentrations available no3 n groundwater data in the sprague river watershed in recent decades are entirely from drinking water quality compliance monitoring for domestic and small commercial wells groundwater no3 n data for klamath county was retrieved from the oregon public health drinking water data online inventory https yourwater oregon gov countyinventory php accessed 26 august 2015 including all agencies and well status active and inactive from the query results all well logs containing the name of any towns known to occur in or near the sprague river watershed e g beatty bly sprague river chiloquin were selected well log locations were provided only in the public land system survey grid to quarter quarter section or coarser spatial resolution depending on the coarseness of the resolution well location grids were then matched in arcgis from one to 16 intersecting modflow grid cells there are 16 observation wells with a total of 602 measurements of groundwater no3 n concentration that are available for model testing the average groundwater no3 n concentration is 0 34 mg l with a standard deviation of 0 77 mg l the locations of the observation wells are shown in fig 4c they are situated principally along the south fork and sprague rivers 4 3 model construction the swat modflow model for the sprague river watershed was developed by bailey et al 2016 by linking a calibrated swat model for the sprague river watershed records et al 2014 with a calibrated modflow model for upper klamath basin gannett et al 2012 the swat model was developed to study the influence of climate change and wetland loss on water quality whereas the modflow model was used to quantitative evaluate the regional groundwater system within the basin the modflow model was developed by the us geological survey although the modflow model included the entire upper klamath basin only the portion covered by the sprague river watershed was coupled with the swat model since the main stem and tributaries have different hydrologic characteristics the developed swat model was separated into four swat models the sprague river main stem sycan river south fork and north fork records et al 2014 for more details of swat setup refer to records 2013 the swat model was calibrated and tested using monthly stream flow during the 2001 2010 period it was auto calibrated with dynamically dimensioned search dds algorithms employing manual calibration where necessary to fine tune model performance using tools developed by tolson and shoemaker 2007 model performance was generally acceptable for streamflow with a monthly nash sutcliff efficiency coefficient nsec greater than 0 7 at the outlet of the sprague river records et al 2014 however monthly streamflow percent bias was 31 overestimated for the north fork a groundwater driven tributary as such the four swat models were merged and the parameters for north fork model were applied to the entire watershed the model domain of the modflow model encompasses the entire upper klamath basin see fig 4b which drains an area of about 20 000 km2 this region was divided into cells with a cell size of 762 m within modflow the aquifers are represented as three variable thickness layers discretized into a grid of 285 rows and 210 columns the original model was set to simulate 3 month quarterly stress periods from 1970 through 2003 with each stress period subdivided into 5 flow time steps to evaluate the timing of the hydrologic response to changes in stresses the model was calibrated for the 1989 to 2003 time period gannett et al 2012 for the swat modflow model simulation bailey et al 2016 model results were compared against groundwater head data stream discharge rates at the north fork gage site and groundwater discharge rates to 6 stream reaches throughout the sprague river watershed for the swat modflow rt3d model the rt3d component used the same grid as the modflow model with the following adr equation used to simulate reactive transport of no3 in the aquifer system 2 c n o 3 t r n o 3 x i v i c n o 3 x i d i j c n o 3 x j q s ϕ c s n o 3 r since no3 has a very low sorption capacity the retardation factor r n o 3 is set to 1 0 for each grid cell indicating no sorption the rate law for denitrification is specified using a single monod expression wherein the rate of the reaction depends only on the presence of no3 3 r no 3 μ n o 3 c n o 3 c n o 3 k n o 3 c n o 3 where μ n o 3 is the first order rate constant d 1 for denitrification and k n o 3 is the monod half saturation constant m f l f 3 for no3 since spatially varying information on denitrification activity is not available for the watershed constant values for both μ n o 3 and k n o 3 are provided to each grid cell μ n o 3 was assigned a value of 0 07 day 1 which corresponds to a half life of 10 days this value is approximately the average of most published denitrification first order rates in soils and aquifers throughout the world heatwole and mccray 2007 bailey et al 2012b and similar to the half life value of 11 days and 8 days found in aquifer studies presented in conan et al 2003 and pauwels et al 1998 respectively the coupled swat modflow rt3d was simulated from 1970 to 2003 with daily time steps although the modflow model simulates the entire upper klamath basin it is still capable of coupling with the swat model in only the sprague river watershed area the coupled model contains 142 swat sub basins and 763 river cells in the sprague river watershed according to the principles described in model coupling section 1940 hru polygons used in the construction of the swat model were spatially disaggregated to create 207 804 dhrus 5 results and discussion 5 1 groundwater no3 n concentrations typical results of the swat modflow rt3d simulation in regards to groundwater head and no3 n groundwater concentration are shown in figs 6 11 simulated cell wise groundwater hydraulic head m at the end of the coupled model simulation 2003 is shown in fig 6a with the water table elevation ranging from 1268 m to 2025 m above msl the spatial pattern of the head field is similar to the ground surface elevation with high head and low head occurring in regions of high and low surface elevation respectively the lowest water table elevation occurs along the main corridor of the sprague river the depth to water table for the north fork catchment where the stream and water quality gage is located is shown in fig 6b showing the areas of high water table along the stream network fig 7a shows the spatial distribution of simulated annual averaged no3 n concentration mg l in groundwater of the sprague river watershed with no3 n values ranging from 0 to 1 2 mg l the highest concentrations occur along the main sprague river corridor and in the northwest region of the watershed an increasing trend of concentration was found from the watershed boundary toward the stream site due to the distribution of land use types fig 5b fig 7b and c d show the time series of simulated and observed no3 n concentration at the location of three groundwater monitoring wells for the time period 1985 to 2003 with the location of the wells shown in fig 7a these three wells are selected due to multiple samples available for each site the simulated values correspond to rt3d grid cells within which the monitoring wells are located wells 136 142 and 135 129 are located in cultivated areas in general the model captures well the within season and long term trend of no3 n magnitude in particular for well 136 142 the seasonal pattern of rapid concentration increase due to fertilizer and then slow concentration decrease due to denitrification during the fall and winter months is replicated and corresponds well to observed values fig 8 shows boxplots of average annual simulated groundwater no3 n concentrations for different land use types both the spatial distribution and boxplots demonstrate that higher no3 n concentrations occur in the cultivated filed areas and herbaceous regions with low no3 n concentrations in the upland forested areas and along the main corridor of the south fork catchment when comparing the average of the measured no3 n values in the observation wells 0 33 mg l with the average simulated values from all grid cells 0 08 mg l the model seems to under predict no3 n concentration however the majority of observation wells are located along the river corridors see fig 4c which are cultivated fields and herbaceous land use types with higher no3 n concentration than natural background concentrations anderson 2002 see also boxplots in fig 8 especially for the cultivated field area the averaged simulated no3 n concentration is 0 52 mg l therefore annually averaged no3 n concentrations from grid cells along the rivers are selected to evaluate the model performance close to the observation wells four different sets of spatial analysis were performed using four different buffer zones all grid cells within a 500 m 1000 m and 2000 m buffer from the entire sprague river watershed stream network and finally all grid cells in the sprague river watershed model domain this resulted in 2 278 3 220 4 685 and 7060 grid cells for the four scenarios respectively frequency distributions are used to compare the 602 observed values with model results fig 9 frequency distributions analyzes the ability of the coupled model to represent accurately the range of the concentration values as compared to observed values and the relative frequency of concentration values within a given concentration interval to verify if the model captures the regional spatio temporal statistics of solute concentration as can be seen from fig 9 the shape and the magnitude of frequency for each concentration interval produced by the model is similar to the frequency from the observed data particularly for the 500 m buffer zone as the observation wells are located close to the river network the swat modflow rt3d model slightly overestimates the low range to mid range concentrations 0 0 4 mg l according to fig 9 a b c or 0 0 3 mg l according to fig 9d and slightly underestimates the mid range to high range concentrations 0 4 mg l for all buffer zones for example for the 500 m buffer zone simulated relative frequencies for 0 1 0 2 mg l and over 1 0 mg l concentration ranges are 20 9 and 0 7 whereas the observed data indicated that relative frequencies are 12 9 and 6 4 of the ranges respectively as can be seen from fig 7 that high no3 n concentrations can be captured by the model however even for the 500 m buffer zone scenario it still includes a large amount of simulated low concentration grid cells located along the upstream of the river corridors fig 7a whereas the observed wells are located at outlets of the sycan river the north fork the south fork and downstream of the sprague river fig 4 which contain high values of no3 n fig 7a when generating the pdf graph the relative frequency of the high values is not as much as the observed values in brief the large discrepancy between the simulated and observed frequency over low range and high range concentration values could be an artifact of not having samples in areas of low no3 n concentration i e observation well placement is biased towards areas of probable high no3 n concentration due to cultivated areas and animal grazing 5 2 no3 n in stream loading simulated and measured no3 n in stream loading for the north fork gage see location in fig 4c are shown in fig 10a the unit for the in stream loading is kg ha which is calculated by kg of in stream no3 n divided by the watershed area as seen in the figure the swat modflow rt3d model is able to track the measured in stream loading quite well with simulated results matching measured results for peak flow periods and base flow periods with peaks occurring after the precipitation season shaded areas in fig 10a as compared to the original swat model records 2013 there is a marked improvement in performance statistics nash sutcliff efficiency coefficient nsec root mean square error rmse mean average error mae and coefficient of determination r2 for the coupled swat modflow rt3d model nsec 0 42 rmse 0 001 kg ha mae 0 278 kg ha r2 0 77 as compared to swat nsec 0 26 rmse 0 002 kg ha mae 0 491 kg ha r2 0 70 the uncoupled swat model consistently underestimates the in stream loading particularly during the periods of low baseflow i e groundwater discharge likely due to the lack of physically based groundwater and solute transport modelling fig 10b shows the scatterplot of the observed versus simulated monthly no3 n in stream concentration for the gage site on the north fork river see fig 4c from the swat model and the swat modflow rt3d model respectively error bounds were calculated by adding and subtracting the percentage of error to the simulated and observed values and then drawing the corresponding upper and lower lines that go through as can be seen in the figure the average measured no3 n in stream concentration is 0 00359 kg ha for 2001 2003 period and the simulated value from the swat and the coupled model is 0 00239 kg ha and 0 00361 kg ha respectively the rmse and mae from the coupled model provide low relative errors during the simulation period moriasi et al 2015 summarized that model performance can be judged as very good if monthly r2 0 7 indicating along with the visual inspection of the time series plots in fig 10 that the model out performs the swat model based on the swat modflow rt3d results there are a few outliers below the error range which demonstrates the model underestimates the loads at these receptors nevertheless 80 of the simulated in stream loading values fall within an error margin of 30 whereas the majority of the points from the swat model are below 30 error bound overall the coupled model shows a substantial improvement and yields good similarity with the observed values 5 3 groundwater no3 n mass loading to the sprague river simulated no3 n mass loading kg year from the aquifer to the stream network during the 1970 2003 period is shown in fig 11a which is important to quantify spatio temporal patterns of groundwater and surface water interaction in the watershed values are plotted for average annual mass loading for each of the 763 river cells within the sprague river watershed red bars represent no3 n loading from the aquifer to the stream whereas green bars indicate no3 n loading from the stream into the aquifer via stream seepage as can be seen in fig 11a the magnitude of no3 n loading is highly spatially variable based on different local hydrologic conditions and groundwater no3 n concentration the main sites for groundwater mass loading are located in the north fork catchment and the downstream portion of the sprague river average annual no3 n mass loading during the 1970 2003 time period for the entire sprague river watershed is shown in fig 11b loading varies from year to year with the estimated values changing from 4843 kg year 1983 to 6318 kg year 2001 with a standard deviation of 354 kg year for the entire 34 years the average mass of no3 n discharge into stream was approximately 5711 kg year further analysis shows that the average no3 n discharge loading for each kilometer length of the stream network is approximately 14 kg year this rate is similar to the loading of 26 kg year km estimated by morgan et al 2007 for the la pine oregon area a region located approximately 100 km north of the sprague river watershed during the year 1999 the higher loading rate in the la pine area likely is due to septic tank effluent being the primary source of no3 n hinkle et al 2007 which results in higher no3 n groundwater concentrations than in the sprague river watershed 5 4 model capabilities and limitations the integrated swat modflow rt3d model can be a useful tool to explore the fate and transport of no3 in coupled surface and subsurface systems and to identify plausible best management practices for controlling contaminant pollution in agricultural watersheds for now only no3 is included but other nitrogen species e g nh4 no2 could be simulated as well as other chemical species or contaminants for a given watershed the model provides the advantage of accounting for spatial variability in nutrient loadings and allows the realistic long term allocation of different nutrient sources with the existing land use practices present in the watershed the coupled model can provide maps of spatially varying groundwater nutrient concentration and nutrient mass fluxes between surface and groundwater which can help to assess possible hot spot nutrient areas in the aquifer and sensitive locations of nutrient loading from the aquifer to the river network these areas can be targeted for future remediation and fulfill the potential requirement for removal changes of drinking water sources under a given management alternative to satisfy groundwater quality currently the model does not account for no3 transport in the vadose zone for areas of high water tables this type of model is ideal since it captures the spatial interaction between groundwater in a heterogeneous aquifer and a stream network the vadose zone therefore may not impact significantly the travel time of no3 between the bottom of the soil profile and the water table however the uzf unsaturated zone flow package for modflow niswonger et al 2006 can be employed to simulate one dimensional groundwater flow in the vadose zone and can be coupled with a recent version of rt3d uzf rt3d bailey et al 2013b that can simulate reactive solute transport in the vadose zone this option will be included in future versions of swat modflow rt3d 6 summary and conclusions in this study the recently developed swat modflow model is extended to simulate the fate and transport of solute species in variably saturated subsurface systems by including the reactive transport model rt3d as a subroutine within the modflow code the resulting model is a single fortran code that provides a single model executable which greatly facilitates the modelling process and saves potential input output reading errors from single models the framework provides a valuable simulation tool for watersheds in which groundwater processes and groundwater nutrient concentrations significantly impact stream flow and in stream nutrient loading or wherein groundwater sources and sinks can impact land surface hydrologic processes model source code and a tutorial outlining the preparation of swat modflow rt3d simulations are available on the main swat model website http swat tamu edu software swat modflow applicability of this model was tested in the sprague river watershed 4100 km2 in the upper klamath basin during the 1970 2003 time period model results are tested against spatio temporal averages of no3 n groundwater concentrations and in stream no3 n loading at a stream gage site annual average mass loadings of no3 n from the aquifer to the stream network also are presented to demonstrate the capabilities of the model in providing spatially varying nutrient loading information the integrated model can be further applied to identify plausible best management practices for controlling contaminant pollution in agricultural watershed for now only no3 is included but other nitrogen species e g nh4 no2 could be simulated as well as other chemical species or contaminants for a given watershed areas that need improvements include 1 incorporating uzf rt3d with the unsaturated zone flow uzf package of modflow to better represent the solute transport in both the unsaturated and saturated zones and for agricultural irrigated areas 2 modification of swat hru to better represent cultivated field for irrigation requirements and 3 incorporation of new algorithms to simulate the impact of earthen canals on aquifer systems 7 software availability the swat modflow rt3d model is a fortran code developed using the intel fortran compiler for microsoft visual studio 10 microsoft corporation the program executable swat modflow rt3d exe was made available july 2016 and is available for download at no cost on the main webpage for the swat model http swat tamu edu software swat modflow the size of the executable is 28 5 mb the fortran source code also is available 7 mb for download from the same webpage with instructions for compiling in the intel visual fortran environment the program executable can run on any personal computer a workshop tutorial and example dataset for constructing a swat modflow rt3d model for the little river watershed georgia also is available on the webpage the modelling code is based on the original modelling codes of swat modflow and rt3d and was developed by ryan bailey and tyler wible ryan bailey can be contacted at department of civil and environmental engineering colorado state university 1372 campus delivery fort collins co 80523 1372 united states telephone 970 491 5045 fax 970 491 7727 e mail rtbailey colostate edu acknowledgements this work was supported by a grant from the agriculture and food research initiative of the usda national institute of food and agriculture grant number 2012 67003 19904 we thank two anonymous reviewers for providing very helpful comments and suggestions that improved the content of this paper 
26142,quantifying populus growth and the impacts on hydrology and water quality are important should it be widely planted soil and water assessment tool swat tree growth algorithms and parameters for hybrid poplar in midwestern us and cottonwood in southern us were improved tree growth representation led to swat2012 code changes including a new leaf area parameter treed new leaf area index algorithm and leaf biomass algorithm simulated hybrid poplar lai and aboveground woody biomass pbias 34 5 nse 0 51 0 99 and r2 0 72 0 99 and cottonwood aboveground biomass runoff sediment and nitrate n pbias 39 11 nse 0 86 0 99 and r2 0 93 0 99 from the modified swat were satisfactory improved algorithms and parameter values and potential ranges for populus were reasonable thus the modified swat can be used for populus biofeedstock production modeling and hydrologic and water quality response to its growth keywords biomass yields populus short rotation woody crops swat model hydrology water quality 1 introduction sustainability energy independence and security and other social and environmental concerns have prompted an increasing interest in bioenergy as renewable energy sources liu et al 2014 love and nejadhashemi 2011 sarkar and miller 2014 sarkar et al 2011 wu et al 2012 wu and liu 2012 in particular cellulosic perennial crops and short rotation intensive culture sric of trees are potential sources of biofeedstock for bioenergy production anderson et al 1983 fege et al 1979 guo et al 2015 hansen and baker 1979 u s department of agriculture 1980 zavitkovski 1978 populus is highly productive under sric because of its rapid growth and coppice regeneration hansen 1983 and it could serve as a predominant temperate zone crop with the worldwide improvement of woody biomass fuel crop species haissig et al 1987 tree biomass production often increases with the decrease of tree spacing in sric plantations and tree spacing could influence the time needed to reach the maximum mean annual biomass increment mabi cannell and smith 1980 hansen and baker 1979 strong and hansen 1993 populus under sric systems has environmental impacts sixto et al 2014 including changes in nutrient cycle soil quality and water and sediment movement sediment loss from a cottonwood site 2 3 mg ha was lower than that from a conventional tilled cotton site 16 2 mg ha over 14 months in mississippi thornton et al 1998 nutrient movement from woody crops was less than agricultural crops in the years after the establishment year thornton et al 1998 tolbert et al 1997 aditya and william 2010 demonstrated that planting fast growing poplar trees could decrease total nitrogen n and phosphorus p loading in the millsboro pond watershed populus growth prediction is essential for managers and policy makers to establish and manage populus under sric plantations guo et al 2015 numerous tree growth models have been used for populus growth simulation to assist with establishment and management of populus under sric systems for example ek 1979 applied a regression model to estimate populus branch mass which was more accurate than models based on branch diameter isebrands et al 1982 used forest an individual tree based stand simulation model originally designed for conventional forests to simulate hybrid poplar growth based on tree size and survival tree survival estimation in the forest was based on a competition index which was a function of tree height and density radius and projection overlap of crown and area of tree horizontal crown projection isebrands et al 1982 rennolls and blackwell 1988 the competition index in the forest model was modified to be a function of tree density and crown radius and the differences between measured and simulated values of hybrid poplar biomass yields were reduced meldahl 1979 rennolls and blackwell 1988 there is a long history of bottom up modeling for poplar populus based on tree inventory and field data ceulemans 1990 hansen 1983 liski et al 2014 stettler and bradshaw 1994 host et al 1990 linked an ecophysiologic growth process model ecophys with the environmental policy integrated model epic williams et al 1989 to estimate poplar growth and management impacts on site productivity and erosion a harmonized equation was used for predicting hybrid poplar woody biomass in the pacific northwest clendenen 1996 stand to ecosystem carbon and evapotranspiration simulator secrets deckmyn et al 2004 and physiological principles to predict growth 3 pg amichev et al 2010 2011 were used for simulating field scale effects of soil irrigation n fertilization and rotation cycle on biomass yields for poplar and aspen wang et al 2013 predicted yield potential of poplar plantations using the ecosystem demography 2 ed2 model and demonstrated that simulated poplar yield matched observed data well biomass is assumed proportional to the radiant energy absorbed by the plant canopy in an energy conversion model which has been used for simulation of biomass yields of populus landsberg and wright 1989 the energy conversion equation landsberg and wright 1989 was also used in soil and water assessment tool swat agricultural land management alternative with numerical assessment criteria almanac epic and agricultural policy environmental extender apex models guo et al 2015 simulation models have been enhanced and updated in various ways in recent years for example the epic williams et al 1984 1989 crop growth model was added in swat to account for growth annual variation auto fertilization and auto irrigation as management options neitsch et al 2011 swat has been used for simulating impacts of bioenergy crops on hydrology and water quality at a wide range of scales around the world boles 2013 love and nejadhashemi 2011 nair et al 2011 parajuli and duffy 2013 powers et al 2011 raj 2013 the fundamental concepts of plant algorithms used in swat arnold et al 2012 are identical to those used in the almanac model kiniry et al 1992 plant growth simulation processes of both almanac and swat include light interception leaf area development and conversion of intercepted light into biomass kiniry et al 2008 2012 neitsch et al 2011 biomass is calculated based on light interception using beer s law with species specific radiation use efficiency bio e amount of dry biomass produced per unit of intercepted light values guo et al 2015 kiniry et al 1999 2007 a summary of algorithms for estimation of lai and weight of dropping leaves and swat parameters are included in data a 1 swat and similar process based models such as agricultural policy environmental extender apex have been used to assess the influence of land use management and requires various input parameters for plants arnold et al 2012 elobeid et al 2013 feng et al 2015 singh and saraswat 2016 tian et al 2016 some researchers have investigated parameterization and improvement of the plant dataset in the swat model for example raj 2013 developed and improved the parameters of switchgrass panicum virgatum l and giant miscanthus miscanthus giganteus in the swat plant dataset and validated and analyzed the range of parameters for these two grasses the parameters representing perennial rhizomatous grasses switchgrass and miscanthus were used for simulating bioenergy crop growth and hydrologic impact in swat boles 2013 cibin and chaubey 2015 raj 2013 the parameters representing tree growth in the swat plant dataset were developed based on personal communication and could be improved by tree growth data from the scientific literature arnold et al 2012 forest management was incorporated and modified in swat to better model water quantity and quality in watersheds in forested ecosystems li et al 2008 however the modification of forest management in the model was for mixed forest systems rather than a specific species li et al 2008 leaf area development in the model is a function of the growing season for mature plants which can attain the stand maximum leaf area index lai during the growing season arnold et al 2011 the leaf area algorithm in the model was not applicable for tree growth before maturity since lai of young regenerations cannot reach stand maximum lai before canopy closure guo et al 2015 thus swat2012 revision 635 and prior versions can only be used for growth simulation for mature plants and the ability to simulate tree biomass yields before maturity is limited arnold et al 2011 woody crops under sric systems are generally harvested before maturity or once they reach maturity hansen 1983 therefore it is necessary to improve simulation of tree growth in swat this study focused on the improvement of the swat model to better estimate populus biomass yields and effects of populus on water quantity and quality this study is the first to improve populus growth algorithms and parameters in swat with published populus growth and water quantity and quality data the objectives of this study were to 1 improve the plant growth subroutine of swat based on new algorithms and growth parameters of hybrid poplar tristis 1 populus balsamifera l p tristis fisch and eastern cottonwood populus deltoides bartr that were created in a prior study with almanac 2 perform sensitivity analysis and calculate relative sensitivity coefficients of plant growth parameters to model outputs to quantify the effect of populus growth parameters on biomass yield water yield and plant uptake of n and p 3 calibrate the model to match lai and woody biomass of hybrid poplar in wisconsin and aboveground biomass of cottonwood in mississippi and 4 test the modified model based on comparison of simulated lai biomass runoff sediment and nitrate n results of populus with published values 2 materials and methods 2 1 hybrid poplar site in wisconsin and cottonwood site in mississippi populus growth and water quantity and quality data used in this study were obtained from studies conducted in two sites a hybrid poplar site in wisconsin and cottonwood site in mississippi fig 1 the selected hybrid poplar study site was a sric system at the usda forest service harshaw experimental farm near rhinelander wisconsin usa 45 6 n 89 5 w hansen and baker 1979 on a padus series loam soil with slope steepness less than 1 to provide a venue for experiments with planted populus plantation nelson and michael 1982 eight inch hybrid poplar cuttings were planted in early june 1970 on a site in the hugo sauer nursery near rhinelander wisconsin ek and dawson 1976a the site was sowed to rye plowed and rototilled before planting the nutrients in the stand were maintained as ph 6 7 7 0 and p 213 224 kg ha n was maintained at 3 2 in new leaf tissue soil moisture at 16 30 levels by irrigation weeds were controlled using linuron ek and dawson 1976a michael et al 1988 the tennessee valley authority tva region a 276 county area including all of tennessee and portions of 10 contiguous states in the southeastern us was shown to be viable for cost effective production of short rotation woody crops based on economic analyses downing and graham 1993 the delta research and extension center at stoneville mississippi 33 34 n 90 85 w in the tennessee valley region was selected for cottonwood planting joslin and schoenholtz 1997 the cottonwood site was on agricultural land dominated by a bostket silt loam soil the site has a slope of 0 2 0 3 and parent material of riverine sediments soil physical property changes were determined at the site in 1995 prior to tree establishment and again in 1997 the end of growing season the site included six small 0 25 2 ha 0 0025 0 02 km2 replicated watersheds with the same soil type slope and land use joslin and schoenholtz 1997 the establishment of replicated watersheds was essential for the quantity quality and timing of surface runoff comparison eastern cottonwood 3 year rotation is a frequently recommended woody species for sric systems in the southeastern u s downing and graham 1993 cottonwood cuttings 20 30 cm long were planted with spacing of 1 2 3 6 m population 23 trees 100 m2 on february 3 1995 thornton et al 1998 the artificial watersheds were formed using 0 5 m high berms to surround land areas joslin and schoenholtz 1997 each outlet had a 0 5 m h shaped flume with a flow meter and an automated flow proportional sampler and a 2 m flume section joslin and schoenholtz 1997 four 91 cm length 61 cm width 8 cm depth pan lysimeters were installed in each plot at 80 cm depth to measure water flux and nutrients water samples were collected by the flow proportional sampler for sediment and nutrient concentration in runoff from may 1995 to june 1997 joslin and schoenholtz 1997 2 2 tree growth modification and related code changes in swat the almanac model was previously modified to simulate lai and biomass yield of hybrid poplar in wisconsin and cottonwood in mississippi guo et al 2015 the functional components and parameter values of hybrid poplar were determined and related algorithms were changed in the model since swat and almanac use similar plant algorithms arnold et al 2012 kiniry et al 1992 tree growth modification in almanac can also be used in swat thus related source code on lai and mass of dropping leaves algorithms guo et al 2015 were changed in swat2012 revision 628 a new leaf area algorithm was added in swat and used for maximum seasonal lai calculation equation 1 and 2 which was useful for simulating tree growth prior to maturity guo et al 2015 a new tree leaf area parameter treed was added in the plant database to describe how lai increases to the maximum potential lai blai with varying densities an algorithm used for calculating dropping leaves weight was added to estimate leaf dropping as a user defined fraction of annual accumulated tree biomass instead of total aboveground biomass equation 3 guo et al 2015 the tree growth algorithm and parameter to simulate leaf area development and leaf biomass were improved and related code was changed in the subroutines table a1 1 lai current year lai current year 1 10 ratetree 2 ratetree log 10 current year claiyr treed where claiyr is number of years until maximum lai is attained for any species and treed is a tree parameter defining how lai increases up to blai 3 falf bio leaf treebioini where falf is weight of dropping leaves treebioini is annual accumulated tree biomass and bio leaf is a user defined fraction in plant dat the modified swat code and executable file are available for downloading data a 2 the swat2012 model with tree growth modification was called modified swat in this study 2 3 the modified swat model setup and management practices the modified swat model was applied using data for crescent creek wisconsin river watershed in wisconsin and big sunflower river watershed in mississippi using arcswat in arcgis 10 1 hydrologic response units hrus were used to represent the hybrid poplar and cottonwood sites hrus were defined for the hybrid poplar and cottonwood sites using the following thresholds 0 land use 0 soil and 0 elevation daily precipitation and maximum and minimum temperatures data from 01 01 1965 to 12 31 1995 at the rhinelander wi us weather station ghcnd usc00477113 latitude 45 63 longitude 89 42 elevation 476 m close to the hybrid poplar site were downloaded from the national climatic data center ncdc daily precipitation and maximum and minimum temperature data from 01 01 1992 to 12 31 1997 at the stoneville experimental station ms us ghcnd usc00228445 latitude 33 4 longitude 90 92 elevation 39 m close to the cottonwood site were also obtained from the ncdc these data were added into arcswat for model setup other weather data including solar radiation relative humidity and wind speed were generated by the weather geodatabase wgen us coop 1960 2010 within swat the primary data required for swat model setup and simulation for these two sites came from a variety of sources table 1 the management operation schedules in swat include planting and end of schedule dates tillage nutrient and pesticide application rates and auto irrigation management practices during the establishment year for each site included tillage and nutrient application data tables a2 and a3 hybrid poplar growth from 1971 to 1980 also included the same n and p application as that in 1970 table a2 planting of hybrid poplar was on 1 june 1970 and harvest and kill were on 1 may 1980 ek 1979 hansen 1983 cottonwood growth from 1996 to 1997 included the same n and p application as that in the establishment year table a3 planting of cottonwood was on 3 feb 1995 and harvest and kill were on 30 nov 1997 joslin and schoenholtz 1997 the management data from the field site did not include exact values for all the input data in swat thus n p and auto irrigation application included in model management practices were used to simulate an idealized condition under which populus growth has little water or nutrient stress ek 1979 guo et al 2015 hansen 1983 2 4 sensitivity analysis for the modified swat model sensitivity analysis for tree growth parameters was performed based on the one at a time oat and global approach james and burges 1982 to identify the effect of hybrid poplar growth parameters on biomass yield water yield and plant uptake of n and p the latin hypercube sampling lhs method was used to generate a sample of plausible collections 200 equally distributed samples of parameter values helton and davis 2003 leta et al 2016 the partial effect of each sample for each tree growth parameter were also calculated van griensven et al 2006 to mathematically compare each parameter influence on a predicted output and obtain the rank of sensitivity to different model outputs based on the average partial effects of 200 samples equation 4 higher rank represented higher sensitivity and lower rank meant lower sensitivity leta et al 2016 van griensven et al 2006 the results of sensitivity analysis can provide guidance for determination of realistic values or potential ranges for parameters and model calibration 4 se n s i t i v i t y i j 100 y i j y 0 y i j y 0 2 x i j x i 0 x i 0 where se n s i t i v i t y i j is the partial effect of parameter i and sample j x i 0 is the initial value of parameter i y 0 is the value of the model output based on the initial value for all parameters x i j is the value of parameter i for sample j and y i j is the value of the model output based on x i j 2 5 data used for model calibration and validation the model was run for a total of 16 years 1965 1980 at the hybrid poplar site and 6 years 1992 1997 at the cottonwood site the first 5 years 1965 1969 at the hybrid poplar site and the first 3 years 1992 1994 at the cottonwood site were used for model warm up simulated lai and biomass yield data from 1970 to 1980 at the hybrid poplar site were compared with the observed data for model calibration and validation simulated biomass yield data from 1995 to 1997 and simulated water quantity and quality data from 1995 to 1997 at the cottonwood site were compared with the observed data for model calibration three observed data sets of hybrid poplar growth cottonwood growth water quantity and water quality sets 1 2 and 3 were used for model calibration and validation table 2 in this study the lai and biomass yield data for hybrid poplar in wisconsin were separated into two datasets sets 1 and 2 which were used for model calibration and validation respectively table 2 we used hybrid poplar data with high medium and low densities for both of model calibration and validation which were similar with guo et al 2015 s study set 1 data lai and aboveground woody biomass data for hybrid poplar with high density population 278 trees 100 m2 and low density population 17 trees 100 m2 and aboveground woody biomass data of hybrid poplar with medium density population 69 trees 100 m2 were used for hybrid poplar model calibration table 2 set 2 data aboveground woody biomass and lai of hybrid poplar with high density population 83 trees 100 m2 and medium density population 25 trees 100 m2 and aboveground woody biomass data of hybrid poplar with high density population 1111 trees 100 m2 and low density population 8 trees 100 m2 were used for hybrid poplar model validation table 2 set 3 data were all observed data in the cottonwood site in mississippi including aboveground biomass seasonal mean runoff per runoff event seasonal mean sediment per runoff event seasonal total sediment seasonal mean nitrate n in runoff and seasonal total nitrate n in runoff only model calibration was performed with the set 3 data at this site since only one tree population of 23 trees 100 m2 medium density was available for the cottonwood plot table 2 2 6 calibration of the modified swat and parameterization before calibrating the modified swat values and ranges of some tree growth parameters were obtained from a previous study on populus growth simulation by almanac data a 3 guo et al 2015 for hybrid poplar model calibration in wisconsin hybrid poplar growth parameters were adjusted manually and lai and aboveground woody biomass data for hybrid poplar from the modified swat were compared with the hybrid poplar calibration data set 1 hansen 1983 table 2 phu bio e ext coef blai alai min frgrw1 frgrw2 cnyld and cpyld were modified manually by increasing decreasing default values by 20 within reasonable ranges arnold et al 2012 to obtain acceptable lai and aboveground woody biomass results for hybrid poplar with various populations which matched well with published values during calibration of the modified swat hansen 1983 for cottonwood model calibration in mississippi aboveground biomass seasonal mean runoff per runoff event seasonal mean sediment per runoff event seasonal total sediment seasonal mean nitrate n in runoff and seasonal total nitrate n in runoff for cottonwood from the modified swat were compared with the cottonwood calibration set 3 initial scs cn ii value cn2 soil erodibility k factor usle k and minimum value of c factor for water erosion usle c were modified manually by increasing decreasing default values by 20 within reasonable ranges arnold et al 2011 to obtain acceptable runoff sediment and nitrate n in runoff which matched well with observed values joslin and schoenholtz 1997 simulated outputs of the modified swat model for the cottonwood site in mississippi were then compared to observed values 2 7 validation of the modified swat after calibration and model comparison for hybrid poplar model validation in wisconsin aboveground woody biomass and lai for hybrid poplar from the modified swat after calibration were compared with the hybrid poplar validation data set 2 hansen 1983 table 2 r2 nse and percent bias percent error pbias were used to evaluate model performance kumar and merwade 2009 the r2 value can represent the strength of the linear relationship between simulated and measured data the nse value nash and sutcliffe 1970 can indicate how well the measured data versus simulated data fits the 1 1 line an r2 or nse value of greater than 0 5 is considered reasonable model performance moriasi et al 2007 percent bias gupta et al 1999 measures the tendency of the simulated data to be larger or smaller than the measured data negative values represent model overestimation bias if pbias 25 for streamflow 55 for sediment and 70 for n and p model simulation results can be considered satisfactory moriasi et al 2007 to compare the performance of models in simulating biomass yields the simulated aboveground woody biomass of hybrid poplar with populations of 17 low density and 278 high density trees 100 m2 from the modified swat were selected to compared with those simulated from the original swat the observed mabi values for hybrid poplar in wisconsin and the simulated values from forest and modified forest models from previous studies were used to evaluate the performance of models in simulating mabi isebrands et al 1982 meldahl 1979 simulated mabi from the modified swat were compared with the simulated values from the original swat in the current research and the published observed and simulated data from forest and modified forest models isebrands et al 1982 meldahl 1979 3 results and discussion 3 1 sensitivity analysis of hybrid poplar growth parameters to selected outputs by the modified swat model of hybrid poplar site in wisconsin the effects of hybrid poplar growth parameters on the selected swat model outputs annual biomass yield water yield plant uptake of n and p were analyzed the water yield is the water leaving the hru representing the hybrid poplar site and entering the main channel a relative sensitivity coefficient was calculated for each tree growth parameter to obtain the rank of sensitivity to different model outputs table 3 hybrid poplar biomass yield was most sensitive to bio e t base t opt light extinction coefficient ext coef treed number of years required for tree species to reach full development mat yrs and other leaf area development parameters minimum lai for plant during dormancy alai min blai fraction of blai corresponding to the second point on optimal leaf development curve laimx2 and fraction of growing season coinciding with laimx2 frgrw2 bio e 10 times radiant use efficiency was the most sensitive parameter for biomass yield of hybrid poplar plant biomass was calculated based on light interception and radiant use efficiency which was the slope of the relationship between cumulative intercepted photosynthetically active radiation par and biomass distributed during the growing season trybula et al 2015 besides bio e ext coef and alai min were also important parameters to quantify the fraction of light intercepted by leaves and potential plant growth kiniry 1998 ext coef controlled estimation of the amount of intercepted par and minimum lai during dormancy alai min affected leaf area development arnold et al 2012 t base and t opt were also sensitive to biomass yield since they both affected temperature stress and timing of peak biomass yield and t base also controlled emergence threshold and potential heat units to reach maturity arnold et al 2012 trybula et al 2015 annual water yield and surface runoff were sensitive to bio e t opt and t base sediment loss in surface runoff was only sensitive to minimum crop factor for water erosion usle c nitrate n loss was sensitive to bio e plant n fraction at maturity pltnfr3 hybrid poplar biomass yield water yield surface runoff and plant uptake of n and p were highly sensitive to bio e and t opt table 3 which was consistent with sensitivity analysis of switchgrass growth parameters in swat trybula et al 2015 3 2 values and potential parameter range for populus growth in the modified swat the calibrated modified swat reasonably simulated annual lai and aboveground woody biomass yield of hybrid poplar with various spacings during calibration values and potential parameter ranges for populus were determined table 4 arnold et al 2011 black et al 2002 guo et al 2015 hansen 1983 kiniry et al 1999 landsberg and wright 1989 macdonald et al 2008 mclaughlin et al 1987 michael et al 1988 zavitkovski 1981 the default values for parameters pltpfr1 pltpfr2 pltpfr3 pltnfr1 pltnfr3 pltnfr2 frgmax vpdfr rsdco pl rdmx wavp co2hi biohi bmx trees and bm dieoff in the plant database were considered reasonable for populus growth simulation arnold et al 2012 kiniry et al 1999 macdonald et al 2008 since obtaining enough detailed data about the phenological and physiological characteristics of the vegetation is difficult and time consuming globally approximated plant parameter ranges are often used in ecological models arnold et al 2012 neitsch et al 2011 values and potential parameter ranges of hybrid poplar and cottonwood table 4 can be adjusted when applied to specific regions these values and ranges also provide guidance for determination of growth parameters for other populus clones or other woody species in process based models the modified swat with the calibrated values for hybrid poplar growth parameters have been used to model biomass yields of hybrid poplar and the impacts on hydrology and sediment and nutrient losses in the midwestern watersheds cibin et al 2016 guo 2016 guo et al 2018a 3 3 calibration of the modified swat 3 3 1 calibration of the modified swat for hybrid poplar growth in wisconsin the calibrated annual lai and aboveground woody biomass values by the modified swat were compared with the set 1 data figs 2 and 3 overall performance of the calibrated lai and aboveground woody biomass for the set 1 data were satisfactory nse 0 5 and r2 0 5 table 5 pbias values of the calibrated lai and aboveground woody biomass of hybrid poplar ranged from 9 to 2 representing accurate model simulation table 5 projected annual lai for the set 1 data by the modified swat fit the measured values reasonably well except that the projected lai values at years 8 and 9 1978 and 1979 were slightly higher than the measured values population of 17 trees 100 m2 fig 2b projected annual aboveground woody biomass for the set 1 data by the modified swat model reasonably matched measured values except that projected annual aboveground woody biomass values at years 2 and 3 1972 and 1973 were higher than observed values population of 278 trees 100 m2 fig 3a projected aboveground woody biomass values from years 8 10 were slightly higher than measured values population of 17 trees 100 m2 fig 3c moreover the calibrated daily streamflow from the outlet of tom doyle creek wisconsin river watershed in wisconsin reasonably fit the observed data from the usgs wisconsin river at rainbow lake station 05391000 latitude 45 83 longitude 89 55 data a 4 table a4 and fig a1 overall performance of the calibrated daily streamflow from 1970 to 1980 was satisfactory pbias 12 nse 0 53 and r2 0 67 from the modified swat fig a1 generally simulated annual flow partitioning from 1970 to 1980 for the modified swat in wisconsin was also reasonable data a 4 and fig a2 similar to those for a forest dominated watershed in northern wisconsin vano et al 2006 3 3 2 calibration of the modified swat for cottonwood growth and hydrologic and water quality responses in mississippi overall performance of the modeled annual aboveground biomass seasonal mean runoff per runoff event seasonal mean sediment per runoff event seasonal mean nitrate n in runoff per runoff event and seasonal total nitrate n in runoff for the set 3 data were satisfactory nse 0 5 and r2 0 5 the calibrated results of annual aboveground biomass fig 4 a seasonal mean runoff per runoff event fig 4b seasonal mean sediment per runoff event fig 4c seasonal mean nitrate n in runoff per runoff event fig 4e and seasonal total nitrate n in runoff fig 4f of cottonwood growth from the modified swat model was similar to observed values nse r2 values for modeled annual aboveground biomass seasonal mean runoff per runoff event seasonal mean sediment per runoff event seasonal mean nitrate n in runoff per runoff event and seasonal total nitrate n in runoff for the set 3 data were 0 99 0 99 0 91 0 93 0 98 0 99 0 86 0 98 and 0 97 0 98 respectively table 5 additionally pbias 0 8 close to 0 for the modeled annual aboveground biomass and seasonal total nitrate n in runoff table 5 indicated that simulated biomass yield and seasonal total nitrate n in runoff values by the modified swat were accurate pbias values of the modeled seasonal mean runoff per runoff event seasonal mean sediment per runoff event and seasonal mean nitrate n in runoff per runoff event of cottonwood growth were 12 pbias 25 11 pbias 55 39 pbias 70 pbias values of 12 and 39 indicate modeled results were overestimated generally and modeled mean runoff during the fall and winter of 1995 fig 4b and mean nitrate n in runoff during the winter of 1995 and the spring of 1996 fig 4e were higher than the observed values pbias 11 indicated seasonal mean sediment per runoff event was slightly underestimated and simulated mean sediment during the spring of 1996 was slightly lower than the observed value fig 4c simulated seasonal total sediment by modified swat did not fit observed values well except that modeled total sediment during the fall of 1995 was close to the observed value fig 4d simulated total sediment values during the winter of 1995 and the spring of 1996 were lower than the observed values as shown in fig 4d nse and r2 values of modeled seasonal total sediment were 0 15 and 0 42 nse 0 5 r2 0 5 which were not satisfactory table 5 nse and r2 were slightly lower than acceptable limits pbias 60 pbias 55 indicating simulated seasonal total sediment was underestimated however simulated seasonal total sediment can still be considered reasonable since it is challenging to accurately simulate sediment load and capture peaks of sediment load from a mildly sloped plot with low surface runoff and sediment load fig 4b and d guo et al 2018b 3 4 the modified swat model validation for hybrid poplar growth in wisconsin and model comparison overall performance of the validated lai for the set 2 data was satisfactory nse 0 5 and r2 0 5 simulated annual lai for the set 2 data by the modified swat model fit measured values well fig 5 a and b except that simulated lai value was slightly lower than the observed value at year 4 1974 and slightly higher than the observed value at year 5 1975 population of 83 trees 100 m2 fig 5a pbias values of simulated lai for the set 2 data were 2 and 8 respectively indicating accurate model simulation nse r2 values for simulated lai of hybrid poplar with populations of 83 and 25 trees 100 m2 were 0 51 0 72 and 0 94 0 95 respectively table 6 overall performance of the validated aboveground woody biomass yields for the set 2 data was acceptable nse 0 5 and r2 0 5 simulated annual aboveground woody biomass for the set 2 data by the modified swat model was similar to measured values fig 6 pbias values were 31 1111 trees 100 m2 and 34 83 trees 100 m2 indicating that modeled annual aboveground woody biomass results by the modified swat were overestimated aboveground woody biomass values were calculated based on simulated total biomass and fraction of total biomass partitioned to tree stems and branches overestimation of percentage of hybrid poplar aboveground biomass partitioned to woody biomass would result in larger than observed aboveground woody biomass values for aboveground woody biomass from year 2 5 of 1111 trees 100 m2 hybrid poplar fig 6a from year 2 4 of 83 trees 100 m2 hybrid poplar fig 6b and years 3 and 4 of 25 trees 100 m2 hybrid poplar fig 6c simulated values by the modified swat were higher than observed values pbias values were 3 25 trees 100 m2 and 5 8 trees 100 m2 representing accurate model simulation fig 6d nse r2 values for modeled aboveground woody biomass of hybrid poplar with populations of 1111 83 25 and 8 trees 100 m2 were 0 55 0 97 0 73 0 97 0 91 0 97 and 0 99 0 99 respectively table 6 besides nse r2 and pbias values the nonparametric wilcoxon rank sum test and cohen s effect size were used for annual lai and aboveground woody biomass of hybrid poplar with all populations both the set 1 and set 2 data to test the equality of the medians and means for the observed and simulated results respectively cohen 1977 guo et al 2018c the wilcoxon rank sum test was two tailed with a significance level of p 0 05 the wilcoxon rank sum test results for annual lai and aboveground woody biomass both showed that there is no significant differences between the medians of the observed and simulated results p 0 05 cohen s effect size for both annual lai and aboveground woody biomass were small 0 2 representing small differences between the means of the observed and simulated results cohen 1977 guo et al 2018c 3 5 evaluation of the modified swat in simulating seasonal hybrid poplar growth in wisconsin and model comparison to evaluate model performance in simulating seasonal variability of hybrid poplar growth simulated lai and total biomass was also compared with the observed data for hybrid poplar in wisconsin with a population of 278 trees 100 m2 during the first growing season in 1979 from michael et al 1988 s previous research data a 5 and fig a3 generally the simulated seasonal lai and total biomass for hybrid poplar reasonably fit the observed data data a 5 and fig a3 seasonal changes of simulated lai and total biomass for 8 trees 100 m2 hybrid poplar from 2003 to 2017 were reasonable and consistent with seasonal leaf area development and changes of biomass for hybrid poplar in the region cibin et al 2016 michael et al 1988 data a 5 and fig a4 the simulated aboveground woody biomass of hybrid poplar with populations of 17 and 278 trees 100 m2 from the modified swat were better than those from the original swat which did not follow the trend of the observed values fig a5 the original swat simulated aboveground woody biomass hybrid poplar with populations of 17 and 278 trees 100 m2 were unsatisfactory pbias values were 59 17 trees 100 m2 and 53 278 trees 100 m2 representing overestimated model simulation fig a5 nse r2 values for modeled aboveground woody biomass of hybrid poplar with populations of 17 and 278 trees 100 m2 were 0 32 0 78 and 0 29 0 93 respectively projected woody biomass by the modified swat model was improved relative to simulations by the original swat forest and modified forest models table 7 observed mean annual biomass increment mabi of 5 year old 69 trees 100 m2 hybrid poplar was 7 6 mg ha yr isebrands et al 1979 table 7 simulated values by forest swat and the modified swat models were 42 higher ek and dawson 1976a b 34 higher and 4 lower than the observed value respectively table 7 additionally the observed mabi value of 10 year old 17 trees 100 m2 hybrid poplar was 10 4 mg ha yr hansen 1983 table 7 projected values by the forest modified forest swat and modified swat models were 96 higher ek and dawson 1976a b 81 higher meldahl 1979 86 lower and 12 lower than the observed value respectively table 7 observed mabi value of 9 year old 8 trees 100 m2 hybrid poplar was 6 2 mg ha yr hansen 1983 table 7 modeled values by the forest swat and modified swat were 182 higher 76 lower ek and dawson 1976a b and 19 higher than the observed value respectively table 7 in the original swat tree density was governed using blai rather than a lai factor that could represent the changes of seasonal lai with different densities fraction of tree biomass converted to residue during the winter bio leaf was invariable in the original swat the original swat had difficulty in simulating how lai increases to the maximum lai and thus could not accurately simulate biomass yields for juvenile hybrid poplar trees biomass yield simulation from forest and modified forest was based on estimated tree height diameter and survival which were higher than the observed values thus projected biomass was much higher than the observed biomass ek and dawson 1976a b biomass yield simulation in swat was assumed proportional to the radiant energy absorbed by the plant canopy in an energy conversion model and accurate biomass simulation was based on accurate lai simulation arnold et al 2012 the modified swat improved lai simulation and thus improved biomass yield simulation for populus trees guo et al 2015 especially for populus tree growth under sric systems which usually reached maturity in several years forest modified forest and swat could reasonably simulate biomass yield for mature trees modified swat could simulate acceptable lai and biomass yield results for both juvenile and mature trees and a further evaluation of its performance in simulating biomass yield for older stands and stands with various populations and from various soils is needed only three or four yearly seasonal data observations were available for some tree populations more continuous populus growth hydrology and water quality field data have the potential to improve determination of values and ranges for tree growth parameters in process based models and thus improve biomass yields and water quantity and quality response modeling of short rotation woody crops additionally the current swat outputs only include plant total biomass but aboveground woody biomass stem and branch is used as biofeedstock thus it is desirable to improve the model to include root biomass aboveground biomass and aboveground woody biomass in model outputs 4 conclusions populus has the potential to provide large quantities of biofeedstock for energy production and it is important to quantify water quantity and water quality responses to populus growth when it is planted in large areas as a biomass feedstock tree growth algorithms and parameters were previously improved in almanac and reasonably simulated lai and biomass yield of juvenile and mature populus the functional components and parameters of populus are also useful for swat in this study swat was modified and used to simulate populus growth and its impacts on runoff sediment and nitrate n losses sensitivity analysis was used to determine ranges and values of growth parameters of populus the modified swat with tree growth modification was used to simulate lai and biomass yield of hybrid poplar with various populations in wisconsin and biomass yield of cottonwood and runoff sediment and nutrient loading to cottonwood growth in mississippi for model calibration the calibrated model was used to simulate lai and biomass yield of hybrid poplar with other populations in wisconsin for model validation populus biomass yield was sensitive to 10 of 35 plant growth parameters bio e t opt t base ext coef treed mat yrs and other leaf area development parameters alai min blai laimx2 and frgrw2 in the swat plant dataset the results of sensitivity analysis can provide guidance for determination of values or potential ranges for parameters and model calibration modeled aboveground woody biomass and lai values from the modified swat for hybrid poplar in wisconsin were satisfactory pbias 57 7 nse 0 94 0 99 and r2 0 74 0 99 performance of aboveground woody biomass simulation from the modified swat was superior to swat forest and modified forest models forest modified forest and swat could reasonably simulate biomass yield for mature trees and modified swat could accurately simulate lai and biomass yield results for both juvenile and mature trees additionally modeled aboveground biomass seasonal mean runoff seasonal mean sediment seasonal mean nitrate n in runoff and seasonal total nitrate n in runoff results from the modified swat model for the cottonwood site in mississippi were good pbias 39 11 nse 0 86 0 99 and r2 0 93 0 99 thus tree growth algorithms and parameters added in the modified swat and related changes in source code were acceptable values and potential ranges for hybrid poplar and cottonwood growth parameters were reasonable the modified swat model can be used for biofeedstock production modeling for populus before and after maturity and hydrologic and water quality response to its production at landscape scales the improved algorithms and parameters for tree growth and values and ranges for populus should also be useful for other process based models such as epic and apex more continuous populus growth hydrology and water quality field data at monthly seasonal levels have the potential to improve tree growth simulation in process based models incorporating root biomass aboveground biomass and aboveground woody biomass in model outputs could enable simulation results to be more usable for biofeedstock study in further study it is also important to evaluate the performance of modified swat in simulating biomass yield water quantity and quality impacts of older stands stands in various soils and with different densities acknowledgements we thank ms lynn wright with wrightlink consulting inc and oak ridge national laboratory for providing data and suggestions to this manuscript we thank dr cibin raj with purdue university for his insights on modeling appendix a supplementary data the following are the supplementary data related to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 multimedia component 3 multimedia component 3 multimedia component 4 multimedia component 4 multimedia component 5 multimedia component 5 multimedia component 6 multimedia component 6 multimedia component 7 multimedia component 7 multimedia component 8 multimedia component 8 multimedia component 9 multimedia component 9 multimedia component 10 multimedia component 10 multimedia component 11 multimedia component 11 multimedia component 12 multimedia component 12 multimedia component 13 multimedia component 13 multimedia component 14 multimedia component 14 multimedia component 15 multimedia component 15 multimedia component 16 multimedia component 16 multimedia component 17 multimedia component 17 multimedia component 18 multimedia component 18 appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 08 030 
26142,quantifying populus growth and the impacts on hydrology and water quality are important should it be widely planted soil and water assessment tool swat tree growth algorithms and parameters for hybrid poplar in midwestern us and cottonwood in southern us were improved tree growth representation led to swat2012 code changes including a new leaf area parameter treed new leaf area index algorithm and leaf biomass algorithm simulated hybrid poplar lai and aboveground woody biomass pbias 34 5 nse 0 51 0 99 and r2 0 72 0 99 and cottonwood aboveground biomass runoff sediment and nitrate n pbias 39 11 nse 0 86 0 99 and r2 0 93 0 99 from the modified swat were satisfactory improved algorithms and parameter values and potential ranges for populus were reasonable thus the modified swat can be used for populus biofeedstock production modeling and hydrologic and water quality response to its growth keywords biomass yields populus short rotation woody crops swat model hydrology water quality 1 introduction sustainability energy independence and security and other social and environmental concerns have prompted an increasing interest in bioenergy as renewable energy sources liu et al 2014 love and nejadhashemi 2011 sarkar and miller 2014 sarkar et al 2011 wu et al 2012 wu and liu 2012 in particular cellulosic perennial crops and short rotation intensive culture sric of trees are potential sources of biofeedstock for bioenergy production anderson et al 1983 fege et al 1979 guo et al 2015 hansen and baker 1979 u s department of agriculture 1980 zavitkovski 1978 populus is highly productive under sric because of its rapid growth and coppice regeneration hansen 1983 and it could serve as a predominant temperate zone crop with the worldwide improvement of woody biomass fuel crop species haissig et al 1987 tree biomass production often increases with the decrease of tree spacing in sric plantations and tree spacing could influence the time needed to reach the maximum mean annual biomass increment mabi cannell and smith 1980 hansen and baker 1979 strong and hansen 1993 populus under sric systems has environmental impacts sixto et al 2014 including changes in nutrient cycle soil quality and water and sediment movement sediment loss from a cottonwood site 2 3 mg ha was lower than that from a conventional tilled cotton site 16 2 mg ha over 14 months in mississippi thornton et al 1998 nutrient movement from woody crops was less than agricultural crops in the years after the establishment year thornton et al 1998 tolbert et al 1997 aditya and william 2010 demonstrated that planting fast growing poplar trees could decrease total nitrogen n and phosphorus p loading in the millsboro pond watershed populus growth prediction is essential for managers and policy makers to establish and manage populus under sric plantations guo et al 2015 numerous tree growth models have been used for populus growth simulation to assist with establishment and management of populus under sric systems for example ek 1979 applied a regression model to estimate populus branch mass which was more accurate than models based on branch diameter isebrands et al 1982 used forest an individual tree based stand simulation model originally designed for conventional forests to simulate hybrid poplar growth based on tree size and survival tree survival estimation in the forest was based on a competition index which was a function of tree height and density radius and projection overlap of crown and area of tree horizontal crown projection isebrands et al 1982 rennolls and blackwell 1988 the competition index in the forest model was modified to be a function of tree density and crown radius and the differences between measured and simulated values of hybrid poplar biomass yields were reduced meldahl 1979 rennolls and blackwell 1988 there is a long history of bottom up modeling for poplar populus based on tree inventory and field data ceulemans 1990 hansen 1983 liski et al 2014 stettler and bradshaw 1994 host et al 1990 linked an ecophysiologic growth process model ecophys with the environmental policy integrated model epic williams et al 1989 to estimate poplar growth and management impacts on site productivity and erosion a harmonized equation was used for predicting hybrid poplar woody biomass in the pacific northwest clendenen 1996 stand to ecosystem carbon and evapotranspiration simulator secrets deckmyn et al 2004 and physiological principles to predict growth 3 pg amichev et al 2010 2011 were used for simulating field scale effects of soil irrigation n fertilization and rotation cycle on biomass yields for poplar and aspen wang et al 2013 predicted yield potential of poplar plantations using the ecosystem demography 2 ed2 model and demonstrated that simulated poplar yield matched observed data well biomass is assumed proportional to the radiant energy absorbed by the plant canopy in an energy conversion model which has been used for simulation of biomass yields of populus landsberg and wright 1989 the energy conversion equation landsberg and wright 1989 was also used in soil and water assessment tool swat agricultural land management alternative with numerical assessment criteria almanac epic and agricultural policy environmental extender apex models guo et al 2015 simulation models have been enhanced and updated in various ways in recent years for example the epic williams et al 1984 1989 crop growth model was added in swat to account for growth annual variation auto fertilization and auto irrigation as management options neitsch et al 2011 swat has been used for simulating impacts of bioenergy crops on hydrology and water quality at a wide range of scales around the world boles 2013 love and nejadhashemi 2011 nair et al 2011 parajuli and duffy 2013 powers et al 2011 raj 2013 the fundamental concepts of plant algorithms used in swat arnold et al 2012 are identical to those used in the almanac model kiniry et al 1992 plant growth simulation processes of both almanac and swat include light interception leaf area development and conversion of intercepted light into biomass kiniry et al 2008 2012 neitsch et al 2011 biomass is calculated based on light interception using beer s law with species specific radiation use efficiency bio e amount of dry biomass produced per unit of intercepted light values guo et al 2015 kiniry et al 1999 2007 a summary of algorithms for estimation of lai and weight of dropping leaves and swat parameters are included in data a 1 swat and similar process based models such as agricultural policy environmental extender apex have been used to assess the influence of land use management and requires various input parameters for plants arnold et al 2012 elobeid et al 2013 feng et al 2015 singh and saraswat 2016 tian et al 2016 some researchers have investigated parameterization and improvement of the plant dataset in the swat model for example raj 2013 developed and improved the parameters of switchgrass panicum virgatum l and giant miscanthus miscanthus giganteus in the swat plant dataset and validated and analyzed the range of parameters for these two grasses the parameters representing perennial rhizomatous grasses switchgrass and miscanthus were used for simulating bioenergy crop growth and hydrologic impact in swat boles 2013 cibin and chaubey 2015 raj 2013 the parameters representing tree growth in the swat plant dataset were developed based on personal communication and could be improved by tree growth data from the scientific literature arnold et al 2012 forest management was incorporated and modified in swat to better model water quantity and quality in watersheds in forested ecosystems li et al 2008 however the modification of forest management in the model was for mixed forest systems rather than a specific species li et al 2008 leaf area development in the model is a function of the growing season for mature plants which can attain the stand maximum leaf area index lai during the growing season arnold et al 2011 the leaf area algorithm in the model was not applicable for tree growth before maturity since lai of young regenerations cannot reach stand maximum lai before canopy closure guo et al 2015 thus swat2012 revision 635 and prior versions can only be used for growth simulation for mature plants and the ability to simulate tree biomass yields before maturity is limited arnold et al 2011 woody crops under sric systems are generally harvested before maturity or once they reach maturity hansen 1983 therefore it is necessary to improve simulation of tree growth in swat this study focused on the improvement of the swat model to better estimate populus biomass yields and effects of populus on water quantity and quality this study is the first to improve populus growth algorithms and parameters in swat with published populus growth and water quantity and quality data the objectives of this study were to 1 improve the plant growth subroutine of swat based on new algorithms and growth parameters of hybrid poplar tristis 1 populus balsamifera l p tristis fisch and eastern cottonwood populus deltoides bartr that were created in a prior study with almanac 2 perform sensitivity analysis and calculate relative sensitivity coefficients of plant growth parameters to model outputs to quantify the effect of populus growth parameters on biomass yield water yield and plant uptake of n and p 3 calibrate the model to match lai and woody biomass of hybrid poplar in wisconsin and aboveground biomass of cottonwood in mississippi and 4 test the modified model based on comparison of simulated lai biomass runoff sediment and nitrate n results of populus with published values 2 materials and methods 2 1 hybrid poplar site in wisconsin and cottonwood site in mississippi populus growth and water quantity and quality data used in this study were obtained from studies conducted in two sites a hybrid poplar site in wisconsin and cottonwood site in mississippi fig 1 the selected hybrid poplar study site was a sric system at the usda forest service harshaw experimental farm near rhinelander wisconsin usa 45 6 n 89 5 w hansen and baker 1979 on a padus series loam soil with slope steepness less than 1 to provide a venue for experiments with planted populus plantation nelson and michael 1982 eight inch hybrid poplar cuttings were planted in early june 1970 on a site in the hugo sauer nursery near rhinelander wisconsin ek and dawson 1976a the site was sowed to rye plowed and rototilled before planting the nutrients in the stand were maintained as ph 6 7 7 0 and p 213 224 kg ha n was maintained at 3 2 in new leaf tissue soil moisture at 16 30 levels by irrigation weeds were controlled using linuron ek and dawson 1976a michael et al 1988 the tennessee valley authority tva region a 276 county area including all of tennessee and portions of 10 contiguous states in the southeastern us was shown to be viable for cost effective production of short rotation woody crops based on economic analyses downing and graham 1993 the delta research and extension center at stoneville mississippi 33 34 n 90 85 w in the tennessee valley region was selected for cottonwood planting joslin and schoenholtz 1997 the cottonwood site was on agricultural land dominated by a bostket silt loam soil the site has a slope of 0 2 0 3 and parent material of riverine sediments soil physical property changes were determined at the site in 1995 prior to tree establishment and again in 1997 the end of growing season the site included six small 0 25 2 ha 0 0025 0 02 km2 replicated watersheds with the same soil type slope and land use joslin and schoenholtz 1997 the establishment of replicated watersheds was essential for the quantity quality and timing of surface runoff comparison eastern cottonwood 3 year rotation is a frequently recommended woody species for sric systems in the southeastern u s downing and graham 1993 cottonwood cuttings 20 30 cm long were planted with spacing of 1 2 3 6 m population 23 trees 100 m2 on february 3 1995 thornton et al 1998 the artificial watersheds were formed using 0 5 m high berms to surround land areas joslin and schoenholtz 1997 each outlet had a 0 5 m h shaped flume with a flow meter and an automated flow proportional sampler and a 2 m flume section joslin and schoenholtz 1997 four 91 cm length 61 cm width 8 cm depth pan lysimeters were installed in each plot at 80 cm depth to measure water flux and nutrients water samples were collected by the flow proportional sampler for sediment and nutrient concentration in runoff from may 1995 to june 1997 joslin and schoenholtz 1997 2 2 tree growth modification and related code changes in swat the almanac model was previously modified to simulate lai and biomass yield of hybrid poplar in wisconsin and cottonwood in mississippi guo et al 2015 the functional components and parameter values of hybrid poplar were determined and related algorithms were changed in the model since swat and almanac use similar plant algorithms arnold et al 2012 kiniry et al 1992 tree growth modification in almanac can also be used in swat thus related source code on lai and mass of dropping leaves algorithms guo et al 2015 were changed in swat2012 revision 628 a new leaf area algorithm was added in swat and used for maximum seasonal lai calculation equation 1 and 2 which was useful for simulating tree growth prior to maturity guo et al 2015 a new tree leaf area parameter treed was added in the plant database to describe how lai increases to the maximum potential lai blai with varying densities an algorithm used for calculating dropping leaves weight was added to estimate leaf dropping as a user defined fraction of annual accumulated tree biomass instead of total aboveground biomass equation 3 guo et al 2015 the tree growth algorithm and parameter to simulate leaf area development and leaf biomass were improved and related code was changed in the subroutines table a1 1 lai current year lai current year 1 10 ratetree 2 ratetree log 10 current year claiyr treed where claiyr is number of years until maximum lai is attained for any species and treed is a tree parameter defining how lai increases up to blai 3 falf bio leaf treebioini where falf is weight of dropping leaves treebioini is annual accumulated tree biomass and bio leaf is a user defined fraction in plant dat the modified swat code and executable file are available for downloading data a 2 the swat2012 model with tree growth modification was called modified swat in this study 2 3 the modified swat model setup and management practices the modified swat model was applied using data for crescent creek wisconsin river watershed in wisconsin and big sunflower river watershed in mississippi using arcswat in arcgis 10 1 hydrologic response units hrus were used to represent the hybrid poplar and cottonwood sites hrus were defined for the hybrid poplar and cottonwood sites using the following thresholds 0 land use 0 soil and 0 elevation daily precipitation and maximum and minimum temperatures data from 01 01 1965 to 12 31 1995 at the rhinelander wi us weather station ghcnd usc00477113 latitude 45 63 longitude 89 42 elevation 476 m close to the hybrid poplar site were downloaded from the national climatic data center ncdc daily precipitation and maximum and minimum temperature data from 01 01 1992 to 12 31 1997 at the stoneville experimental station ms us ghcnd usc00228445 latitude 33 4 longitude 90 92 elevation 39 m close to the cottonwood site were also obtained from the ncdc these data were added into arcswat for model setup other weather data including solar radiation relative humidity and wind speed were generated by the weather geodatabase wgen us coop 1960 2010 within swat the primary data required for swat model setup and simulation for these two sites came from a variety of sources table 1 the management operation schedules in swat include planting and end of schedule dates tillage nutrient and pesticide application rates and auto irrigation management practices during the establishment year for each site included tillage and nutrient application data tables a2 and a3 hybrid poplar growth from 1971 to 1980 also included the same n and p application as that in 1970 table a2 planting of hybrid poplar was on 1 june 1970 and harvest and kill were on 1 may 1980 ek 1979 hansen 1983 cottonwood growth from 1996 to 1997 included the same n and p application as that in the establishment year table a3 planting of cottonwood was on 3 feb 1995 and harvest and kill were on 30 nov 1997 joslin and schoenholtz 1997 the management data from the field site did not include exact values for all the input data in swat thus n p and auto irrigation application included in model management practices were used to simulate an idealized condition under which populus growth has little water or nutrient stress ek 1979 guo et al 2015 hansen 1983 2 4 sensitivity analysis for the modified swat model sensitivity analysis for tree growth parameters was performed based on the one at a time oat and global approach james and burges 1982 to identify the effect of hybrid poplar growth parameters on biomass yield water yield and plant uptake of n and p the latin hypercube sampling lhs method was used to generate a sample of plausible collections 200 equally distributed samples of parameter values helton and davis 2003 leta et al 2016 the partial effect of each sample for each tree growth parameter were also calculated van griensven et al 2006 to mathematically compare each parameter influence on a predicted output and obtain the rank of sensitivity to different model outputs based on the average partial effects of 200 samples equation 4 higher rank represented higher sensitivity and lower rank meant lower sensitivity leta et al 2016 van griensven et al 2006 the results of sensitivity analysis can provide guidance for determination of realistic values or potential ranges for parameters and model calibration 4 se n s i t i v i t y i j 100 y i j y 0 y i j y 0 2 x i j x i 0 x i 0 where se n s i t i v i t y i j is the partial effect of parameter i and sample j x i 0 is the initial value of parameter i y 0 is the value of the model output based on the initial value for all parameters x i j is the value of parameter i for sample j and y i j is the value of the model output based on x i j 2 5 data used for model calibration and validation the model was run for a total of 16 years 1965 1980 at the hybrid poplar site and 6 years 1992 1997 at the cottonwood site the first 5 years 1965 1969 at the hybrid poplar site and the first 3 years 1992 1994 at the cottonwood site were used for model warm up simulated lai and biomass yield data from 1970 to 1980 at the hybrid poplar site were compared with the observed data for model calibration and validation simulated biomass yield data from 1995 to 1997 and simulated water quantity and quality data from 1995 to 1997 at the cottonwood site were compared with the observed data for model calibration three observed data sets of hybrid poplar growth cottonwood growth water quantity and water quality sets 1 2 and 3 were used for model calibration and validation table 2 in this study the lai and biomass yield data for hybrid poplar in wisconsin were separated into two datasets sets 1 and 2 which were used for model calibration and validation respectively table 2 we used hybrid poplar data with high medium and low densities for both of model calibration and validation which were similar with guo et al 2015 s study set 1 data lai and aboveground woody biomass data for hybrid poplar with high density population 278 trees 100 m2 and low density population 17 trees 100 m2 and aboveground woody biomass data of hybrid poplar with medium density population 69 trees 100 m2 were used for hybrid poplar model calibration table 2 set 2 data aboveground woody biomass and lai of hybrid poplar with high density population 83 trees 100 m2 and medium density population 25 trees 100 m2 and aboveground woody biomass data of hybrid poplar with high density population 1111 trees 100 m2 and low density population 8 trees 100 m2 were used for hybrid poplar model validation table 2 set 3 data were all observed data in the cottonwood site in mississippi including aboveground biomass seasonal mean runoff per runoff event seasonal mean sediment per runoff event seasonal total sediment seasonal mean nitrate n in runoff and seasonal total nitrate n in runoff only model calibration was performed with the set 3 data at this site since only one tree population of 23 trees 100 m2 medium density was available for the cottonwood plot table 2 2 6 calibration of the modified swat and parameterization before calibrating the modified swat values and ranges of some tree growth parameters were obtained from a previous study on populus growth simulation by almanac data a 3 guo et al 2015 for hybrid poplar model calibration in wisconsin hybrid poplar growth parameters were adjusted manually and lai and aboveground woody biomass data for hybrid poplar from the modified swat were compared with the hybrid poplar calibration data set 1 hansen 1983 table 2 phu bio e ext coef blai alai min frgrw1 frgrw2 cnyld and cpyld were modified manually by increasing decreasing default values by 20 within reasonable ranges arnold et al 2012 to obtain acceptable lai and aboveground woody biomass results for hybrid poplar with various populations which matched well with published values during calibration of the modified swat hansen 1983 for cottonwood model calibration in mississippi aboveground biomass seasonal mean runoff per runoff event seasonal mean sediment per runoff event seasonal total sediment seasonal mean nitrate n in runoff and seasonal total nitrate n in runoff for cottonwood from the modified swat were compared with the cottonwood calibration set 3 initial scs cn ii value cn2 soil erodibility k factor usle k and minimum value of c factor for water erosion usle c were modified manually by increasing decreasing default values by 20 within reasonable ranges arnold et al 2011 to obtain acceptable runoff sediment and nitrate n in runoff which matched well with observed values joslin and schoenholtz 1997 simulated outputs of the modified swat model for the cottonwood site in mississippi were then compared to observed values 2 7 validation of the modified swat after calibration and model comparison for hybrid poplar model validation in wisconsin aboveground woody biomass and lai for hybrid poplar from the modified swat after calibration were compared with the hybrid poplar validation data set 2 hansen 1983 table 2 r2 nse and percent bias percent error pbias were used to evaluate model performance kumar and merwade 2009 the r2 value can represent the strength of the linear relationship between simulated and measured data the nse value nash and sutcliffe 1970 can indicate how well the measured data versus simulated data fits the 1 1 line an r2 or nse value of greater than 0 5 is considered reasonable model performance moriasi et al 2007 percent bias gupta et al 1999 measures the tendency of the simulated data to be larger or smaller than the measured data negative values represent model overestimation bias if pbias 25 for streamflow 55 for sediment and 70 for n and p model simulation results can be considered satisfactory moriasi et al 2007 to compare the performance of models in simulating biomass yields the simulated aboveground woody biomass of hybrid poplar with populations of 17 low density and 278 high density trees 100 m2 from the modified swat were selected to compared with those simulated from the original swat the observed mabi values for hybrid poplar in wisconsin and the simulated values from forest and modified forest models from previous studies were used to evaluate the performance of models in simulating mabi isebrands et al 1982 meldahl 1979 simulated mabi from the modified swat were compared with the simulated values from the original swat in the current research and the published observed and simulated data from forest and modified forest models isebrands et al 1982 meldahl 1979 3 results and discussion 3 1 sensitivity analysis of hybrid poplar growth parameters to selected outputs by the modified swat model of hybrid poplar site in wisconsin the effects of hybrid poplar growth parameters on the selected swat model outputs annual biomass yield water yield plant uptake of n and p were analyzed the water yield is the water leaving the hru representing the hybrid poplar site and entering the main channel a relative sensitivity coefficient was calculated for each tree growth parameter to obtain the rank of sensitivity to different model outputs table 3 hybrid poplar biomass yield was most sensitive to bio e t base t opt light extinction coefficient ext coef treed number of years required for tree species to reach full development mat yrs and other leaf area development parameters minimum lai for plant during dormancy alai min blai fraction of blai corresponding to the second point on optimal leaf development curve laimx2 and fraction of growing season coinciding with laimx2 frgrw2 bio e 10 times radiant use efficiency was the most sensitive parameter for biomass yield of hybrid poplar plant biomass was calculated based on light interception and radiant use efficiency which was the slope of the relationship between cumulative intercepted photosynthetically active radiation par and biomass distributed during the growing season trybula et al 2015 besides bio e ext coef and alai min were also important parameters to quantify the fraction of light intercepted by leaves and potential plant growth kiniry 1998 ext coef controlled estimation of the amount of intercepted par and minimum lai during dormancy alai min affected leaf area development arnold et al 2012 t base and t opt were also sensitive to biomass yield since they both affected temperature stress and timing of peak biomass yield and t base also controlled emergence threshold and potential heat units to reach maturity arnold et al 2012 trybula et al 2015 annual water yield and surface runoff were sensitive to bio e t opt and t base sediment loss in surface runoff was only sensitive to minimum crop factor for water erosion usle c nitrate n loss was sensitive to bio e plant n fraction at maturity pltnfr3 hybrid poplar biomass yield water yield surface runoff and plant uptake of n and p were highly sensitive to bio e and t opt table 3 which was consistent with sensitivity analysis of switchgrass growth parameters in swat trybula et al 2015 3 2 values and potential parameter range for populus growth in the modified swat the calibrated modified swat reasonably simulated annual lai and aboveground woody biomass yield of hybrid poplar with various spacings during calibration values and potential parameter ranges for populus were determined table 4 arnold et al 2011 black et al 2002 guo et al 2015 hansen 1983 kiniry et al 1999 landsberg and wright 1989 macdonald et al 2008 mclaughlin et al 1987 michael et al 1988 zavitkovski 1981 the default values for parameters pltpfr1 pltpfr2 pltpfr3 pltnfr1 pltnfr3 pltnfr2 frgmax vpdfr rsdco pl rdmx wavp co2hi biohi bmx trees and bm dieoff in the plant database were considered reasonable for populus growth simulation arnold et al 2012 kiniry et al 1999 macdonald et al 2008 since obtaining enough detailed data about the phenological and physiological characteristics of the vegetation is difficult and time consuming globally approximated plant parameter ranges are often used in ecological models arnold et al 2012 neitsch et al 2011 values and potential parameter ranges of hybrid poplar and cottonwood table 4 can be adjusted when applied to specific regions these values and ranges also provide guidance for determination of growth parameters for other populus clones or other woody species in process based models the modified swat with the calibrated values for hybrid poplar growth parameters have been used to model biomass yields of hybrid poplar and the impacts on hydrology and sediment and nutrient losses in the midwestern watersheds cibin et al 2016 guo 2016 guo et al 2018a 3 3 calibration of the modified swat 3 3 1 calibration of the modified swat for hybrid poplar growth in wisconsin the calibrated annual lai and aboveground woody biomass values by the modified swat were compared with the set 1 data figs 2 and 3 overall performance of the calibrated lai and aboveground woody biomass for the set 1 data were satisfactory nse 0 5 and r2 0 5 table 5 pbias values of the calibrated lai and aboveground woody biomass of hybrid poplar ranged from 9 to 2 representing accurate model simulation table 5 projected annual lai for the set 1 data by the modified swat fit the measured values reasonably well except that the projected lai values at years 8 and 9 1978 and 1979 were slightly higher than the measured values population of 17 trees 100 m2 fig 2b projected annual aboveground woody biomass for the set 1 data by the modified swat model reasonably matched measured values except that projected annual aboveground woody biomass values at years 2 and 3 1972 and 1973 were higher than observed values population of 278 trees 100 m2 fig 3a projected aboveground woody biomass values from years 8 10 were slightly higher than measured values population of 17 trees 100 m2 fig 3c moreover the calibrated daily streamflow from the outlet of tom doyle creek wisconsin river watershed in wisconsin reasonably fit the observed data from the usgs wisconsin river at rainbow lake station 05391000 latitude 45 83 longitude 89 55 data a 4 table a4 and fig a1 overall performance of the calibrated daily streamflow from 1970 to 1980 was satisfactory pbias 12 nse 0 53 and r2 0 67 from the modified swat fig a1 generally simulated annual flow partitioning from 1970 to 1980 for the modified swat in wisconsin was also reasonable data a 4 and fig a2 similar to those for a forest dominated watershed in northern wisconsin vano et al 2006 3 3 2 calibration of the modified swat for cottonwood growth and hydrologic and water quality responses in mississippi overall performance of the modeled annual aboveground biomass seasonal mean runoff per runoff event seasonal mean sediment per runoff event seasonal mean nitrate n in runoff per runoff event and seasonal total nitrate n in runoff for the set 3 data were satisfactory nse 0 5 and r2 0 5 the calibrated results of annual aboveground biomass fig 4 a seasonal mean runoff per runoff event fig 4b seasonal mean sediment per runoff event fig 4c seasonal mean nitrate n in runoff per runoff event fig 4e and seasonal total nitrate n in runoff fig 4f of cottonwood growth from the modified swat model was similar to observed values nse r2 values for modeled annual aboveground biomass seasonal mean runoff per runoff event seasonal mean sediment per runoff event seasonal mean nitrate n in runoff per runoff event and seasonal total nitrate n in runoff for the set 3 data were 0 99 0 99 0 91 0 93 0 98 0 99 0 86 0 98 and 0 97 0 98 respectively table 5 additionally pbias 0 8 close to 0 for the modeled annual aboveground biomass and seasonal total nitrate n in runoff table 5 indicated that simulated biomass yield and seasonal total nitrate n in runoff values by the modified swat were accurate pbias values of the modeled seasonal mean runoff per runoff event seasonal mean sediment per runoff event and seasonal mean nitrate n in runoff per runoff event of cottonwood growth were 12 pbias 25 11 pbias 55 39 pbias 70 pbias values of 12 and 39 indicate modeled results were overestimated generally and modeled mean runoff during the fall and winter of 1995 fig 4b and mean nitrate n in runoff during the winter of 1995 and the spring of 1996 fig 4e were higher than the observed values pbias 11 indicated seasonal mean sediment per runoff event was slightly underestimated and simulated mean sediment during the spring of 1996 was slightly lower than the observed value fig 4c simulated seasonal total sediment by modified swat did not fit observed values well except that modeled total sediment during the fall of 1995 was close to the observed value fig 4d simulated total sediment values during the winter of 1995 and the spring of 1996 were lower than the observed values as shown in fig 4d nse and r2 values of modeled seasonal total sediment were 0 15 and 0 42 nse 0 5 r2 0 5 which were not satisfactory table 5 nse and r2 were slightly lower than acceptable limits pbias 60 pbias 55 indicating simulated seasonal total sediment was underestimated however simulated seasonal total sediment can still be considered reasonable since it is challenging to accurately simulate sediment load and capture peaks of sediment load from a mildly sloped plot with low surface runoff and sediment load fig 4b and d guo et al 2018b 3 4 the modified swat model validation for hybrid poplar growth in wisconsin and model comparison overall performance of the validated lai for the set 2 data was satisfactory nse 0 5 and r2 0 5 simulated annual lai for the set 2 data by the modified swat model fit measured values well fig 5 a and b except that simulated lai value was slightly lower than the observed value at year 4 1974 and slightly higher than the observed value at year 5 1975 population of 83 trees 100 m2 fig 5a pbias values of simulated lai for the set 2 data were 2 and 8 respectively indicating accurate model simulation nse r2 values for simulated lai of hybrid poplar with populations of 83 and 25 trees 100 m2 were 0 51 0 72 and 0 94 0 95 respectively table 6 overall performance of the validated aboveground woody biomass yields for the set 2 data was acceptable nse 0 5 and r2 0 5 simulated annual aboveground woody biomass for the set 2 data by the modified swat model was similar to measured values fig 6 pbias values were 31 1111 trees 100 m2 and 34 83 trees 100 m2 indicating that modeled annual aboveground woody biomass results by the modified swat were overestimated aboveground woody biomass values were calculated based on simulated total biomass and fraction of total biomass partitioned to tree stems and branches overestimation of percentage of hybrid poplar aboveground biomass partitioned to woody biomass would result in larger than observed aboveground woody biomass values for aboveground woody biomass from year 2 5 of 1111 trees 100 m2 hybrid poplar fig 6a from year 2 4 of 83 trees 100 m2 hybrid poplar fig 6b and years 3 and 4 of 25 trees 100 m2 hybrid poplar fig 6c simulated values by the modified swat were higher than observed values pbias values were 3 25 trees 100 m2 and 5 8 trees 100 m2 representing accurate model simulation fig 6d nse r2 values for modeled aboveground woody biomass of hybrid poplar with populations of 1111 83 25 and 8 trees 100 m2 were 0 55 0 97 0 73 0 97 0 91 0 97 and 0 99 0 99 respectively table 6 besides nse r2 and pbias values the nonparametric wilcoxon rank sum test and cohen s effect size were used for annual lai and aboveground woody biomass of hybrid poplar with all populations both the set 1 and set 2 data to test the equality of the medians and means for the observed and simulated results respectively cohen 1977 guo et al 2018c the wilcoxon rank sum test was two tailed with a significance level of p 0 05 the wilcoxon rank sum test results for annual lai and aboveground woody biomass both showed that there is no significant differences between the medians of the observed and simulated results p 0 05 cohen s effect size for both annual lai and aboveground woody biomass were small 0 2 representing small differences between the means of the observed and simulated results cohen 1977 guo et al 2018c 3 5 evaluation of the modified swat in simulating seasonal hybrid poplar growth in wisconsin and model comparison to evaluate model performance in simulating seasonal variability of hybrid poplar growth simulated lai and total biomass was also compared with the observed data for hybrid poplar in wisconsin with a population of 278 trees 100 m2 during the first growing season in 1979 from michael et al 1988 s previous research data a 5 and fig a3 generally the simulated seasonal lai and total biomass for hybrid poplar reasonably fit the observed data data a 5 and fig a3 seasonal changes of simulated lai and total biomass for 8 trees 100 m2 hybrid poplar from 2003 to 2017 were reasonable and consistent with seasonal leaf area development and changes of biomass for hybrid poplar in the region cibin et al 2016 michael et al 1988 data a 5 and fig a4 the simulated aboveground woody biomass of hybrid poplar with populations of 17 and 278 trees 100 m2 from the modified swat were better than those from the original swat which did not follow the trend of the observed values fig a5 the original swat simulated aboveground woody biomass hybrid poplar with populations of 17 and 278 trees 100 m2 were unsatisfactory pbias values were 59 17 trees 100 m2 and 53 278 trees 100 m2 representing overestimated model simulation fig a5 nse r2 values for modeled aboveground woody biomass of hybrid poplar with populations of 17 and 278 trees 100 m2 were 0 32 0 78 and 0 29 0 93 respectively projected woody biomass by the modified swat model was improved relative to simulations by the original swat forest and modified forest models table 7 observed mean annual biomass increment mabi of 5 year old 69 trees 100 m2 hybrid poplar was 7 6 mg ha yr isebrands et al 1979 table 7 simulated values by forest swat and the modified swat models were 42 higher ek and dawson 1976a b 34 higher and 4 lower than the observed value respectively table 7 additionally the observed mabi value of 10 year old 17 trees 100 m2 hybrid poplar was 10 4 mg ha yr hansen 1983 table 7 projected values by the forest modified forest swat and modified swat models were 96 higher ek and dawson 1976a b 81 higher meldahl 1979 86 lower and 12 lower than the observed value respectively table 7 observed mabi value of 9 year old 8 trees 100 m2 hybrid poplar was 6 2 mg ha yr hansen 1983 table 7 modeled values by the forest swat and modified swat were 182 higher 76 lower ek and dawson 1976a b and 19 higher than the observed value respectively table 7 in the original swat tree density was governed using blai rather than a lai factor that could represent the changes of seasonal lai with different densities fraction of tree biomass converted to residue during the winter bio leaf was invariable in the original swat the original swat had difficulty in simulating how lai increases to the maximum lai and thus could not accurately simulate biomass yields for juvenile hybrid poplar trees biomass yield simulation from forest and modified forest was based on estimated tree height diameter and survival which were higher than the observed values thus projected biomass was much higher than the observed biomass ek and dawson 1976a b biomass yield simulation in swat was assumed proportional to the radiant energy absorbed by the plant canopy in an energy conversion model and accurate biomass simulation was based on accurate lai simulation arnold et al 2012 the modified swat improved lai simulation and thus improved biomass yield simulation for populus trees guo et al 2015 especially for populus tree growth under sric systems which usually reached maturity in several years forest modified forest and swat could reasonably simulate biomass yield for mature trees modified swat could simulate acceptable lai and biomass yield results for both juvenile and mature trees and a further evaluation of its performance in simulating biomass yield for older stands and stands with various populations and from various soils is needed only three or four yearly seasonal data observations were available for some tree populations more continuous populus growth hydrology and water quality field data have the potential to improve determination of values and ranges for tree growth parameters in process based models and thus improve biomass yields and water quantity and quality response modeling of short rotation woody crops additionally the current swat outputs only include plant total biomass but aboveground woody biomass stem and branch is used as biofeedstock thus it is desirable to improve the model to include root biomass aboveground biomass and aboveground woody biomass in model outputs 4 conclusions populus has the potential to provide large quantities of biofeedstock for energy production and it is important to quantify water quantity and water quality responses to populus growth when it is planted in large areas as a biomass feedstock tree growth algorithms and parameters were previously improved in almanac and reasonably simulated lai and biomass yield of juvenile and mature populus the functional components and parameters of populus are also useful for swat in this study swat was modified and used to simulate populus growth and its impacts on runoff sediment and nitrate n losses sensitivity analysis was used to determine ranges and values of growth parameters of populus the modified swat with tree growth modification was used to simulate lai and biomass yield of hybrid poplar with various populations in wisconsin and biomass yield of cottonwood and runoff sediment and nutrient loading to cottonwood growth in mississippi for model calibration the calibrated model was used to simulate lai and biomass yield of hybrid poplar with other populations in wisconsin for model validation populus biomass yield was sensitive to 10 of 35 plant growth parameters bio e t opt t base ext coef treed mat yrs and other leaf area development parameters alai min blai laimx2 and frgrw2 in the swat plant dataset the results of sensitivity analysis can provide guidance for determination of values or potential ranges for parameters and model calibration modeled aboveground woody biomass and lai values from the modified swat for hybrid poplar in wisconsin were satisfactory pbias 57 7 nse 0 94 0 99 and r2 0 74 0 99 performance of aboveground woody biomass simulation from the modified swat was superior to swat forest and modified forest models forest modified forest and swat could reasonably simulate biomass yield for mature trees and modified swat could accurately simulate lai and biomass yield results for both juvenile and mature trees additionally modeled aboveground biomass seasonal mean runoff seasonal mean sediment seasonal mean nitrate n in runoff and seasonal total nitrate n in runoff results from the modified swat model for the cottonwood site in mississippi were good pbias 39 11 nse 0 86 0 99 and r2 0 93 0 99 thus tree growth algorithms and parameters added in the modified swat and related changes in source code were acceptable values and potential ranges for hybrid poplar and cottonwood growth parameters were reasonable the modified swat model can be used for biofeedstock production modeling for populus before and after maturity and hydrologic and water quality response to its production at landscape scales the improved algorithms and parameters for tree growth and values and ranges for populus should also be useful for other process based models such as epic and apex more continuous populus growth hydrology and water quality field data at monthly seasonal levels have the potential to improve tree growth simulation in process based models incorporating root biomass aboveground biomass and aboveground woody biomass in model outputs could enable simulation results to be more usable for biofeedstock study in further study it is also important to evaluate the performance of modified swat in simulating biomass yield water quantity and quality impacts of older stands stands in various soils and with different densities acknowledgements we thank ms lynn wright with wrightlink consulting inc and oak ridge national laboratory for providing data and suggestions to this manuscript we thank dr cibin raj with purdue university for his insights on modeling appendix a supplementary data the following are the supplementary data related to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 multimedia component 3 multimedia component 3 multimedia component 4 multimedia component 4 multimedia component 5 multimedia component 5 multimedia component 6 multimedia component 6 multimedia component 7 multimedia component 7 multimedia component 8 multimedia component 8 multimedia component 9 multimedia component 9 multimedia component 10 multimedia component 10 multimedia component 11 multimedia component 11 multimedia component 12 multimedia component 12 multimedia component 13 multimedia component 13 multimedia component 14 multimedia component 14 multimedia component 15 multimedia component 15 multimedia component 16 multimedia component 16 multimedia component 17 multimedia component 17 multimedia component 18 multimedia component 18 appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 08 030 
26143,many environmental time series measurements are characterised by irregular sampling a significant improvement of the dynamic harmonic regression dhr modelling technique to accommodate irregular sampled time series without the need for data pre processing has been developed taylor s series is used to obtain the time step state increments modifying the transition equation matrices this allows the user to avoid artefacts arising and insertion of assumptions from interpolation and regularisation of the data to a regular time base and makes dhr more consistent with the data based mechanistic approach to modelling environmental systems the new technique implemented as a matlab package has been tested on demanding simulated data sets and demonstrated on various environmental time series data with significantly varying sampling times the results have been compared with standard dhr where possible and the method reduces analysis time and produces unambiguous results by removing the need for pre processing always based on assumptions based only on the observed environmental data 1 introduction in analysing environmental data and modelling environmental processes there is a significant need to identify and estimate trends cycles and seasonal components dynamic harmonic regression dhr provides a cogent analytical tool to generate such results it is however firmly based in the classical time series analysis domain and relies on the data being sampled at specific intervals however in many disciplines dealing with the natural environment data sets are not sampled at regular intervals presented here is a significant update to dhr allowing direct use of irregularly sampled time series data in estimation of trends cycles and seasonal components in addition there is a distinct need for such a method to be accompanied by software that is easy to use and with results directly interpretable in the terms of the specific discipline be it climatology hydrology or environmental chemistry to cite a few of the disciplines where these methods have been successfully applied by the authors dynamic harmonic regression is a nonstationary time series analysis approach used to identify trends seasonal cyclical and irregular components within a state space framework young and ng 1989 the dhr method is implemented in the captain toolbox for matlab and has been used extensively by many researchers young et al 1999 taylor et al 2007 the dhr methodology has a wide range of applications and is particularly useful in analysing environmental data such as atmospheric pollutants becker et al 2006 venier et al 2012 where importantly it is cited as a recommended method in the 2011 unep air report in the persistent organic pollutants section unep 2011 other significant applications include paleoclimatology data based on isotope dating smith et al 2016 impacts on catchment water balance chappell and tych 2012 groundwater surface water fluxes keery et al 2007 geomorphology carling et al 2005 water quality cycles halliday et al 2013 or solar irradiation forecasting trapero et al 2015 but also in forecasting of phone call numbers within the call centre context tych et al 2002 medicine sofianopoulou et al 2017 and finance bhar 2010 however when data are irregularly sampled the existing dhr and related methods cannot be applied directly for instance paleoclimatic data series from core samples and speleothems are interpolated onto a fixed time base prior to analysis e g smith et al 2016 historic water quality data geomorphological data and atmospheric chemistry data e g becker et al 2006 carling et al 2005 are treated in the same way using prior processing the problem is that the original state space filtering based dhr cannot handle irregular sampling without applying resampling techniques making the time sampling uniform prior to the analysis as useful as resampling is it is still manipulation of the observed data and leads to increased uncertainties in model outputs and to potential artefacts resulting from the interpolation techniques applied such as aliasing chappell et al 2017 or spectral features of the approximation functional base applied in the interpolation process importantly where the actual samples become sparser it can lead to false certainty introducing interpolated samples where there are no data available the uncertainty estimates then become tainted usually unduly lower conversely where samples are denser it can lead to a removal of information also leading to increasing uncertainty fewer samples less averaging and potentially losing information in the upper part of the signal spectrum common anti aliasing methods for down sampling such as low pass filtering will have the latter problem with interpolation resampling is a step away from the data based mechanistic approach dbm young 1999 to modelling and data analysis which dhr is designed to be consistent allowing the observed data to tell us about the systems prior to process interpretation this is because interpolation always has an underlying model or assumptions which may form an introject affecting the data it has to be pointed out that the developed algorithm is not aimed purely at dealing with irregular sampling but at augmenting the existing dhr model which has proven to be highly effective and widely used in environmental science due to the natural interpretation of its object and of the model components as well as the inherent stochastic information provided by it analysing irregularly sampled time series data has a large body of literature addressing it irregularly sampled auto regression is one of them broersen et al 2004 derive a method for handling ar models with missing samples a very specific and limited form of irregular sampling with missing samples the sampling is regular in general ar and other methods relying on solving stochastic equations such as brockwell s 2001 levy process driven approach are not directly comparable with the proposed technique because they are usually much more general and so rely on additional mathematical analysis and assumptions in every specific application other approaches to irregularly sampled time series address whole spectrum estimation such as irregularly spaced approaches to fourier estimation such as o toole et al 2007 or wavelet based approaches of e g mathias et al 2004 which is exactly what is avoided here in order to reduce the uncertainty of results the reduction of uncertainty in the presented approach is achieved through minimising the number of spectral components that are estimated to only the dominant periodicities various machine learning approaches tend to require high data volumes and suffer from difficulty with obtaining justified uncertainty estimates we work with often expensive to obtain environmental data sets of necessarily limited length and normally address univariate time series so direct comparison with most published machine learning approaches is not easily achieved the term arbitrary sampling is introduced in the specific dhr context and used to describe how the irregular sampled time series is used within the irregular sampled dhr technique the temporal distance between each sample in the irregularly sampled time series is stored as a 1x n 1 vector complementing the irregularly sampled time series itself the term temporal distance is used here deliberately to highlight the possibility of using this technique in analysis of spatial series as for example in carling et al 2005 where dhr was used on regularised spatial data to analyse the pool riffle sequence in river geomorphology the arbitrary sampling processing uses both series the measured values and their sample times this approach can be used also for sparse regularly sampled series with many missing values where the time index for the missing values are removed creating an irregular sampled time series the creation of the temporal distance vector is the only pre processing required for the updated dhr and for the purposes of differentiating between the current dhr methodology and the proposed updated methodology the latter will be referred to as arbitrary sampled dynamic harmonic regression asdhr the update implements an arbitrary sampling technique in the kalman filter kf and fixed interval smoother fis algorithms while the irregular sampling has been previously used with kalman filtering e g li and shah 2008 the fis algorithm implementation here is a novel element not used elsewhere except for mindham et al 2018 and necessary for the use of asdhr overall the arbitrary sampling technique eliminates the need for any pre analysis or resampling and puts dhr back in line with the dbm approach by not inserting any assumptions or artefacts into the observed data the aim of this paper is to introduce the arbitrary sampling technique and to demonstrate the benefits of asdhr for analysis of environmental data sets which so often are irregularly sampled or contain numerous missing values this is achieved by providing a brief background to dhr and then introduce the arbitrary sampling methodology section 2 demonstrating the capability benefits and necessity of asdhr when using environmental data o paleo climatology smith et al 2016 comparing asdhr and dhr outputs to demonstrate the arbitrary sampling capability section 3 1 o persistent organic pollutants becker et al 2006 demonstrating the necessity for extending dhr to accommodate irregular sampled time series section 3 2 3 3 especially for noisy data series o forecasting atmospheric co2 introducing and demonstrating arbitrary forecasting the ability to forecast at arbitrary points into the future with different sampling times to the observed data section 3 4 evaluation of asdhr robustness to data sparseness and observational noise section 4 2 dynamic harmonic regression the dhr model assumes that the observable variable of a system is composed of four components 1 trend t sustained cyclical c with period different to the seasonality seasonal s and white noise e young et al 1999 1 y t t t c t s t e t the measured values of y are the output observations series of a system of stochastic state space equations which can then be broken down to allow for estimation of the four components t t is the trend component which can be considered a stochastic time varying intercept parameter and is interpreted spectrally as a zero frequency term i 0 where ω 0 or f 0 0 in practice occupying the lowest part of the spectrum and modelled as integrated or smoothed random walk see young et al 1999 with states termed level and slope of the trend the seasonal component s t is defined as 2 s t i 1 r s a i t cos ω i t b i t sin ω i t where a i t and b i t are stochastic time varying parameters tvp and ω i are the fundamental and harmonic frequencies associated with the seasonality in the series i 1 2 r s 3 c t i 1 r c α i t cos f i t β i t sin f i t where α i t and β i t are stochastic tvp and f i are the frequencies associated with the longer cyclical component i 1 2 r c the cyclic component c t has an identical definition to the seasonal and is isolated here to allow for a different physical interpretation whereas the white noise component e t is the remaining information after the other 3 components have been removed from y i e model residuals note that the full unobserved components model young et al 1999 also incorporates the irregular component here omitted for simplicity typically the tvp a i t b i t α i t β i t and both t t states are defined by a two dimensional state vector x i t l i t d i t t where l i t and d i t are respectively the changing level and slope of the associated tvp the stochastic evolution of each x i t is assumed to be described by a generalised random walk process 4 4 x i t f i x i t 1 g i η i t 1 i 1 2 r where r 1 r c r s and f and g defined in their time varying form in 7a and 7b respectively see also young et al 1999 for fixed form 2 1 state space and observation equations the state space model is constructed by aggregation of the subsystem matrices defined in 2 and is defined in young et al 1999 however both the state transition and noise input matrices are fixed and thus can only work for uniformly sampled data hence the need to apply regularisation techniques on irregularly sampled data the method proposed here replaces these fixed matrices with time step dependent ones where the values depend on the time between each sample thus allowing them to work for irregularly sampled data for the rest of the paper the temporal positioning of samples t at regular intervals δ t is replaced with the arbitrary positioning of samples δ t k where k the sample number keeps the temporal order if y v y k is the vth derivative of y y k and the form of the function y is not specified a data point distant from y k provides very little information about y y k using the local polynomial modelling reasoning e g fan and gijbels 1996 only the local data points in the vicinity of y k are used assuming y y k has the q 1 th derivative at the point y k then following taylor s expansion for y in the local neighbourhood of y k we have 5 y y y y k y y k y y k y y k 2 y y k 2 y q y k q y y k q if the value of y and its derivatives are known at the tth point as x k y ς k y ς k y ς k y q ς k t and the highest derivative of y y with respect to y with y k y ς k and y q 1 ς k η k where η k n 0 σ η 2 and ς k is the approximation point knot at sample k then taylor s expansion 3 can be applied in the local neighbourhood of ς k for all derivatives of y resulting in the grw model with state space 6a and observation 6b equations with the now time varying state transition in 7a and system noise input in 7b matrices 6a x k f k x k 1 g k η k 1 6b y k h k t x k e k where h k is the observation matrix dimension of nxr for rw trend and rw harmonics amplitudes observation equation 6b implements the regressive structure of dhr with x k being the estimated amplitudes of harmonics or trend levels for each k and their corresponding elements of h k contain the i th s harmonic values cos ω i t k or sin ω i t k or ones for the trend level 7a f k α δ k δ k 2 2 δ k q q 0 1 δ k δ k q 1 q 1 0 0 1 δ k q 2 q 2 0 0 0 1 7b g k δ k q 1 q 1 δ k q q δ k q 1 q 1 δ k t where δ k ς k ς k 1 is the temporal distance between the temporal samples number k and k 1 time difference between the knots ς k and ς k 1 when α 1 and q 0 1 2 this equation describes respectively random walk integrated random walk double integrated random walk etc when α ranges between 0 and 1 referring to smoothed random walk with orders q as above the choice of random walk order depends on the application where variation is expected q of 1 or higher is used naturally depending on the shape of the trend where no assumptions are made and suspicion of stationarity needs to be evaluated the simple rw model q 0 is usually more appropriate in practice the analysis starts with q of 0 for the harmonic components and 1 for the trend 2 2 algorithmic considerations to reiterate the term arbitrary sampling is used because the new state space equations section 2 1 do not constrain the time between each sample to be fixed as long as they are in temporal order the regularity or amount of irregularity in the sampling process does not impact the modelling process so long as the temporal positions of each sample are known and the finite taylor expansion 5 is a satisfactory approximant of y to keep the algorithm numerically well defined keeping the spectrum of the transition matrix sensible as its inverse is used in the smoothing algorithm the temporal distances between each sample δ k may need scaling to keep the majority or average sampling rate close to one this is equivalent to choosing the time unit suitable for the analysis e g if the sampling process is typically once a week then δ k provided in days needs to be divided by seven in formal terms as δ k affects the spectrum of the transition matrix f k and its invertibility condition the time must be expressed in the units that will not cause poorly conditioned f k for any or at least for very few steps k in the state space matrices section 2 1 a δ k of 1 for all k implies regular sampling as a special case 2 3 variance intervention amongst the numerous algorithmic advantages of the stochastic state space techniques such as the ease of forecasting smoothing and interpolation including arbitrary times between the existing samples the variance intervention technique seems particularly well suited to environmental data analysis and modelling very often the researcher is looking for confirmation or detection of a discrete change in the system variance intervention technique has been introduced by box and tiao 1975 and in the context of stochastic state space models it was developed and evaluated by young and ng 1989 with regular dhr intervention points are used to account for abrupt changes in the data such as a sharp calibration change or a shift in environmental system behaviour e g chappell and tych 2012 it can be used to model and evaluate the potential for specific breaks in the time series whether background level slope changes or sudden amplitude changes of the harmonic components in the dynamic harmonic regression context without intervention points any abrupt changes are smoothed in the model estimate and give poorer models that are not true to the system not reflecting the mechanisms governing the observed processes and so not consistent with the dbm approach in bayesian terms interventions amount to introducing diffused priors at the intervention a priori step causing the recursive estimator to doubt the current estimate by increasing the covariance matrix significantly introducing intervention points requires either assumptions or knowledge of the time of the change alternatively a search for a significant parametric change may be made using a sliding intervention technique as applied in chappell and tych 2012 to detect discrete changes in streamflow and evaporation records due to forest cover change or to other such interventions this advantage is not lost with the introduction of the arbitrary sampling technique as one of the examples below demonstrates 2 4 period identification in many environmental data series there is a need for identification of dominant periodicities as these are likely to indicate the phenomena active or dominant in the processes generating the time series spectral estimators such as fft and the various families of parametric spectral estimators from burg s to wavelets while commonly used are a sensitive to noise especially coloured noise and b their uncertainty is very high as fisher 1929 has shown the uncertainty of spectral estimators is of the same order as their magnitude these issues are aggravated for noisy processes within time varying spectra for the simple reason of the number of estimated values of the spectral characteristics being of a similar magnitude to that of the number of data points so while using the standard methods we are getting a picture for a range of frequencies this picture is highly uncertain for spectral estimators with dhr and asdhr one periodicity a handful of harmonic frequencies is analysed in each step of the periodicity sweep as we show below the powerful handling of uncertainty by the kalman filter and fixed interval smoother allows for a significant improvement of detection and estimation process and in addition importantly and nearly uniquely provides an uncertainty estimate of the identified periodicities the periodicity identification method used for asdhr involves scanning through a predetermined selection of periods and selecting the most statistically likely period s this is relatively time consuming for wider sweeps but the search could be optimised using variations of common search algorithms computation time is arguably not such a critical issue as a this is an off line process and b with high speed modern computers it is not significant the question of identification criterion for spectral peaks is quite critical the standard r2 being the proportion of variance of observed data explained by the model 8 8 r 2 1 e k 2 y k 2 with e k being the model residuals could be used as the statistical measure but this was found to be less reliable as many periods were found to have similar r2 values leading to poor sensitivity especially in trend dominated series and so the statistically best period was hard to distinguish from other significant periods the same approach will apply to multi periodic signals thanks to the orthogonality of the harmonic components introduced here is an analogue of the standard r2 a new measure easily described as the proportion of data explained by the seasonal or cyclic component 9 9 r s 2 s k 2 y k t k 2 where s k is the estimated seasonal component section 2 its quadratic norm variance is compared with that of the detrended data term in the denominator of 9 environmental data often have a significant slow or trend component which dominates the standard r2 while rs 2 focuses on the detrended data and seasonal component note that in the process of identification the trend is estimated together with the seasonal component for each case so there is no danger of introducing artefacts due to this procedure effectively a spectral decomposition in addition 9 provides a standardised measure of a relative strength of periodicity comparable across different time series 2 5 noise variance ratio nvr the introduction of taylor s expansion to the grw models indirectly influences the selection of hyperparameters by introducing the sampling rate directly into the state transition equation for the original dhr spectral model fit was used as it was relatively easy to formulaically express the dhr spectrum and compare it to the ar spectrum of the data this becomes more complex and ambiguous for irregularly sampled data however nvrs also carry the interpretation of time scaling of the model spectral boundary of the low pass filter interpretation of the process as explained in young et al 1999 in this case with the challenging application examples we found that choosing the nvrs needs to reflect the time scale of the modelled process rather than the best fit in any particular sense the latter would have been arbitrary and would introduce additional assumptions into the modelling process 3 demonstrating asdhr on environmental time series the examples compare where possible the proposed asdhr methodology with the original dhr methodology direct comparison is often difficult as both methods operate on different data sets dhr works with regularised and sometimes pre filtered data whereas asdhr works with the raw or unedited observed data in terms of the dbm approach or philosophy it should already be apparent that asdhr is a more appropriate tool for analysing environmental systems the first example 3 1 has more comparable data sets interpolated and raw data and is a good demonstration of a working asdhr methodology that is comparable to dhr the second example 3 2 demonstrates the need for asdhr to achieve data analysis that is in line with the dbm philosophy i e the data tells the story and not the assumptions used to manipulate the data for dhr analysis the third example 3 3 introduces a new type of forecasting termed arbitrary forecasting that allows predictions to occur at chosen points in the future not just from the end of the observed time series and at different sampling rates and points to that of the observed time series 3 1 paleo climatology example analysing patterns such as trends and cycles in paleoclimatic data is a common theme in this discipline the example we used was a typical one and previously published in nature scientific reports indicating the importance of the problem for the community a carbonate oxygen isotope δ18o record derived from speleothems contained within cueva de asiul situated in the matienzo depression cantabria north spain was used to reconstruct the precipitation delivery to northern spain during the last 12100 years using dhr analysis to find the trends and periods for full details and the analysis see smith et al 2016 here the dhr analysis in terms of trend and harmonic amplitudes is compared with the proposed asdhr similar results are expected as both methods are operating on the same data but the result specifics should be different due to the differences in the data pre processing and analysis algorithms 3 1 2 data pre processing with current dhr the data needs pre processing to make uniform the sampling rate and this involves linear interpolation followed by removing the interpolated samples where there are gaps in the observed data to avoid introduction of artefacts in this case analysed in smith et al 2016 by the corresponding author a highly irregularly sampled data series of 1919 values is reduced to a uniformly sampled data series of 815 62 of which are missing values mainly due to a single large gap in the data series which is a significant data loss even if the key characteristics of the data are preserved fig 1 with current dhr the large gap 872 years in the data series needs to be interpolated and due to its size any interpolation across it is meaningless in terms of physical interpretation and could affect the immediate estimates either side of it with the proposed asdhr procedure all that is required is to provide the temporal distance between each pair of samples this means asdhr has the full range of data 1919 values to utilise and ignores the effect of the large gap there is no interpolation 3 1 3 period identification the periodicities of the data were identified by scanning across a range of periods to find the two that fit the data best as in smith et al 2016 although as noted above the current dhr method only uses 815 resampled values while asdhr has the original 1919 values to use current dhr method 1290 and 1490 years asdhr 1320 and 1540 years well within the accuracy of the age estimate based on 18o isotope levels this new result confirms the findings of smith et al 2016 only providing a small adjustment when compared to the samples timing error 3 1 4 comparing current dhr with proposed asdhr to compare the model fit of the two methods the fit from dhr was rescaled back to the original time base and this showed that the arbitrary sampling procedure yielded slightly better results fig 2 the estimated trends and amplitudes were similar between the two methods figs 3 and 4 respectively with the main difference with the behaviour over the gaps the grey shaded area highlights the large gap in the data and a period of suspect data immediately before it the distributions of residual errors were also similar between the two methods with both being approximately gaussian and very close to symmetric fig 5 this demonstrates how the introduction of the arbitrary sampling technique does not affect the fundamentals of the dhr method using asdhr for paleo climatic series not only simplifies the analysis procedure no prior data manipulation and preserves the data i e no data loss artefacts introduced but also returns slightly better models in this case a more pronounced seasonal component 3 2 persistent organic pollutant example identifying patterns and trends in atmospheric concentrations of persistent organic pollutants pops is an important part of monitoring and understanding how anthropogenic activities affect them weekly air samples have been collected since january 1992 at the high arctic station of alert in canada and are filtered for various pops and have a high signal to noise ratio 3 1 for further background and dhr analysis see becker et al 2006 two examples are taken from the data collected at alert benzo a pyrene reported in becker et al 2006 and α hexachlorocyclohexane α hch not reported and both are members of the polycyclic aromatic hydrocarbons subset of pops prior to dhr analysis the data were pre processed missing values due to data below the instrumental detection limits were replaced by values 2 3 of the detection limits and data points situated outside 3x the standard deviation of any fitted trend where considered outliers and removed from the data set the data were then resampled to fortnightly due to the weekly data having significant irregularity and finally ran through a low pass filter to reduce aliasing in the first example the observed data with missing values and outliers were used with asdhr and compared to pre processed data with dhr in the second example both use the pre processed data but without the resampling or pre filtering for asdhr both model fit and trend were compared between the two techniques as that was the aim of dhr in the original paper 3 2 1 benzo a pyrene in becker et al 2006 an annual cycle was identified and using the highly irregularly sampled raw data this same annual cycle was identified using the asdhr identification procedure the subsequent estimated fit fig 6 and trend fig 7 show that data pre processing unless required for a specific analysis question is no longer necessary for dhr analysis if the arbitrary sampling technique is used where a good model fit and trend estimate were obtained from the raw unfiltered data the uncertainty estimate is higher for asdhr which can be attributed mainly to the prefiltering used necessarily prior to dhr application where data were brought onto fortnightly time base this pre filtering reduced the variance of the irregular component which is clearly visible in fig 6 in addition in asdhr as expected uncertainty grows when data are absent so the less frequent sampling between 1995 and 1999 as visible in fig 7 leads to the increase of estimated uncertainty 3 2 2 α hexachlorocyclohexane here both dhr and asdhr used the pre processed data where values under detection limits were set to 2 3 of the instrumental detection limits but for dhr the data were then resampled and pre filtered an annual cycle was identified again and the subsequent estimation of trend shows how pre filtering the data can lead to bias in its analysis in this case fig 8 the trend estimated by asdhr is pulled down by the observed data data that are missing in the resampled and pre filtered time series 3 3 arbitrary forecasting atmospheric co2 example below we present a simple example of forecasting of the well known keeling mauna loa co2 series see acknowledgments in this example we do not aim at perfect forecasts but rather at showing the flexibility and versatility of even the basic version asdhr in this application better forecasts could be achieved with more assumptions being included in the model such as a model of the business cycle or the industrial growth projections the mauna loa co2 monthly mean data set was used to demonstrate arbitrary forecasting that is forecasting from any point in the future and not just from the end of the data set additionally the time base of the forecasting period is not limited to that of the observed data something that the original dhr cannot do this is easily implemented by extending vector δ k by the values corresponding to the arbitrary points chosen in this example fig 9 the monthly mauna loa data are used to forecast the year 2018 on a weekly basis for five different periods of data 1960 to 1970 to 1980 to 1990 to 2000 and to 2010 as shown by the increasingly darker line thus the lighest grey forecast is based solely on the data upto 1970 and the darkest shading is based on all the data upto 2010 this fig 9 demonstrates how the rate of change of co2 grows with time as the knowledge is increasing e g the 1960 1970 based predictions for 2018 have levels observed in 2000 except during the 1990s where the 1960 2000 based predictions are lower than that of the 1960 1990 clearly relating to the visible dip during the 1990s the size of the uncertainty shown here as a single standard error estimate band increases as the forecasting horizon increases lighest grey for 48 years darkest grey for 8 years testing on this data set and on simulated data sets indicates that the forecasts are largely unaffected by data sparseness or the forecasting horizon magnitude only the observation noise level impacts the predictions in the past the dhr technique was successfully used for forecasting various processes in both broadly environmental and industrial applications from demand for electricity young and pedregal 1998 to numbers of calls to a banking call centre tych et al 2002 to anecdotally demand for beer unpublished lancaster university thesis asdhr naturally broadens the application area of this robust method 4 robustness and reliability evaluation before the methodology was applied to real data it was tested on a variety of challenging simulated data sets with known unobserved components to test the robustness and sensitivity to data sparseness size of temporal distancing and observational noise the methodology was found to be very robust with very sparse data sets it also produces meaningful estimates for a very wide range of temporal distances between the samples limited by the taylor expansion 3 and condition of the recursive estimate of the covariance matrix within the fixed interval smoother algorithm applied subject to these constraints the technique can be used to estimate the observed values and components no matter how irregularly sampled the time series is sensitivity to observation noise is similar between the time tested and commonly used dhr with about 300 citations and asdhr in terms of physical interpretation the extent of data sparseness needs to be considered when interpreting the estimated components as very sparse data may effectively under sample higher frequency components 5 conclusions presented here is a technique to improve the dhr analysis of irregularly sampled time series that removes the need for data pre processing regularisation decimation interpolation etc the technique also does not involve estimation of missing values and so any subsequent analysis is free from assumptions and bias and only uses the available observed data this brings dhr closer to the dbm philosophy of allowing the data to inform us of the processes and mechanisms that result in the observed time series it also makes it uniquely suitable for analysis of environmental irregularly sampled observational data data pre processing was a necessary step to allow dhr to work on irregularly sampled data sets but it comes with artefacts bias and increased uncertainties in the model estimates however with the arbitrary sampling technique this step can be avoided and provides model estimates with lower uncertainties and no bias the technique has been tested on challenging simulated data and is robust enough to work on extremely sparse data however in terms of physical interpretation there is a limit to how sparse the data can be due to e g under sampling chappell et al 2017 additionally the technique was found to have similar observation noise sensitivity to that found in standard dhr method the technique has been demonstrated here on three different types of observed environmental time series data and has yielded slightly better model outputs than the standard dhr method without data pre processing there will be no introduction of any assumptions artefacts or bias into the data prior to analysis and thus these results should be closer to observed reality the technique also allows for forecasting at arbitrary points and at different sampling rates than in the observed data this means the frequency of the forecast is not limited to the frequency of the observations and with a non stationary forecast horizon may allow forecasting to yield more insights into environmental processes finally while it may not be apparent from the equations asdhr is easily and inherently generalised so that all aspects of estimation are either time varying or state dependent from periodicity to dynamics of random walk model to nvrs for each sample k the periodicity random walk model and nvr can be set so for example one section of observed data could be analysed for one set of periodicities and another section analysed for another set or the random walk model could be changed to match a significant change in the data or the nvrs can be varied to suit the smoothness of the data software format and availability the method has been implemented within the matlab computing environment the input arguments specify the time series variable the state space format meta parameters for the trend and for harmonics amplitudes which essentially specify the time scale of the trend and amplitude variability additional arguments control variance interventions initial conditions etc with sensible default values provided the output arguments have also been constructed with ease of use in mind and include model fit estimated trend harmonic components and their amplitudes with their respective uncertainty estimates so are immediately interpretable in terms of the modelled environmental process matlab functions and example scripts are available from the corresponding author upon request the functions will be included in the captain toolbox for matlab in due course acknowledgements paleo climatic data smith et al 2016 have been kindly provided by dr andi smith of british geological survey the authors acknowledge dr hayley hung environment canada for access to the northern contaminants program ncp and the integrated atmospheric deposition network iadn datasets for persistent organic pollutants pops dr pieter tans noaa esrl www esrl noaa gov gmd ccgg trends and dr ralph keeling scripps institution of oceanography scrippsco2 ucsd edu appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 104503 
26143,many environmental time series measurements are characterised by irregular sampling a significant improvement of the dynamic harmonic regression dhr modelling technique to accommodate irregular sampled time series without the need for data pre processing has been developed taylor s series is used to obtain the time step state increments modifying the transition equation matrices this allows the user to avoid artefacts arising and insertion of assumptions from interpolation and regularisation of the data to a regular time base and makes dhr more consistent with the data based mechanistic approach to modelling environmental systems the new technique implemented as a matlab package has been tested on demanding simulated data sets and demonstrated on various environmental time series data with significantly varying sampling times the results have been compared with standard dhr where possible and the method reduces analysis time and produces unambiguous results by removing the need for pre processing always based on assumptions based only on the observed environmental data 1 introduction in analysing environmental data and modelling environmental processes there is a significant need to identify and estimate trends cycles and seasonal components dynamic harmonic regression dhr provides a cogent analytical tool to generate such results it is however firmly based in the classical time series analysis domain and relies on the data being sampled at specific intervals however in many disciplines dealing with the natural environment data sets are not sampled at regular intervals presented here is a significant update to dhr allowing direct use of irregularly sampled time series data in estimation of trends cycles and seasonal components in addition there is a distinct need for such a method to be accompanied by software that is easy to use and with results directly interpretable in the terms of the specific discipline be it climatology hydrology or environmental chemistry to cite a few of the disciplines where these methods have been successfully applied by the authors dynamic harmonic regression is a nonstationary time series analysis approach used to identify trends seasonal cyclical and irregular components within a state space framework young and ng 1989 the dhr method is implemented in the captain toolbox for matlab and has been used extensively by many researchers young et al 1999 taylor et al 2007 the dhr methodology has a wide range of applications and is particularly useful in analysing environmental data such as atmospheric pollutants becker et al 2006 venier et al 2012 where importantly it is cited as a recommended method in the 2011 unep air report in the persistent organic pollutants section unep 2011 other significant applications include paleoclimatology data based on isotope dating smith et al 2016 impacts on catchment water balance chappell and tych 2012 groundwater surface water fluxes keery et al 2007 geomorphology carling et al 2005 water quality cycles halliday et al 2013 or solar irradiation forecasting trapero et al 2015 but also in forecasting of phone call numbers within the call centre context tych et al 2002 medicine sofianopoulou et al 2017 and finance bhar 2010 however when data are irregularly sampled the existing dhr and related methods cannot be applied directly for instance paleoclimatic data series from core samples and speleothems are interpolated onto a fixed time base prior to analysis e g smith et al 2016 historic water quality data geomorphological data and atmospheric chemistry data e g becker et al 2006 carling et al 2005 are treated in the same way using prior processing the problem is that the original state space filtering based dhr cannot handle irregular sampling without applying resampling techniques making the time sampling uniform prior to the analysis as useful as resampling is it is still manipulation of the observed data and leads to increased uncertainties in model outputs and to potential artefacts resulting from the interpolation techniques applied such as aliasing chappell et al 2017 or spectral features of the approximation functional base applied in the interpolation process importantly where the actual samples become sparser it can lead to false certainty introducing interpolated samples where there are no data available the uncertainty estimates then become tainted usually unduly lower conversely where samples are denser it can lead to a removal of information also leading to increasing uncertainty fewer samples less averaging and potentially losing information in the upper part of the signal spectrum common anti aliasing methods for down sampling such as low pass filtering will have the latter problem with interpolation resampling is a step away from the data based mechanistic approach dbm young 1999 to modelling and data analysis which dhr is designed to be consistent allowing the observed data to tell us about the systems prior to process interpretation this is because interpolation always has an underlying model or assumptions which may form an introject affecting the data it has to be pointed out that the developed algorithm is not aimed purely at dealing with irregular sampling but at augmenting the existing dhr model which has proven to be highly effective and widely used in environmental science due to the natural interpretation of its object and of the model components as well as the inherent stochastic information provided by it analysing irregularly sampled time series data has a large body of literature addressing it irregularly sampled auto regression is one of them broersen et al 2004 derive a method for handling ar models with missing samples a very specific and limited form of irregular sampling with missing samples the sampling is regular in general ar and other methods relying on solving stochastic equations such as brockwell s 2001 levy process driven approach are not directly comparable with the proposed technique because they are usually much more general and so rely on additional mathematical analysis and assumptions in every specific application other approaches to irregularly sampled time series address whole spectrum estimation such as irregularly spaced approaches to fourier estimation such as o toole et al 2007 or wavelet based approaches of e g mathias et al 2004 which is exactly what is avoided here in order to reduce the uncertainty of results the reduction of uncertainty in the presented approach is achieved through minimising the number of spectral components that are estimated to only the dominant periodicities various machine learning approaches tend to require high data volumes and suffer from difficulty with obtaining justified uncertainty estimates we work with often expensive to obtain environmental data sets of necessarily limited length and normally address univariate time series so direct comparison with most published machine learning approaches is not easily achieved the term arbitrary sampling is introduced in the specific dhr context and used to describe how the irregular sampled time series is used within the irregular sampled dhr technique the temporal distance between each sample in the irregularly sampled time series is stored as a 1x n 1 vector complementing the irregularly sampled time series itself the term temporal distance is used here deliberately to highlight the possibility of using this technique in analysis of spatial series as for example in carling et al 2005 where dhr was used on regularised spatial data to analyse the pool riffle sequence in river geomorphology the arbitrary sampling processing uses both series the measured values and their sample times this approach can be used also for sparse regularly sampled series with many missing values where the time index for the missing values are removed creating an irregular sampled time series the creation of the temporal distance vector is the only pre processing required for the updated dhr and for the purposes of differentiating between the current dhr methodology and the proposed updated methodology the latter will be referred to as arbitrary sampled dynamic harmonic regression asdhr the update implements an arbitrary sampling technique in the kalman filter kf and fixed interval smoother fis algorithms while the irregular sampling has been previously used with kalman filtering e g li and shah 2008 the fis algorithm implementation here is a novel element not used elsewhere except for mindham et al 2018 and necessary for the use of asdhr overall the arbitrary sampling technique eliminates the need for any pre analysis or resampling and puts dhr back in line with the dbm approach by not inserting any assumptions or artefacts into the observed data the aim of this paper is to introduce the arbitrary sampling technique and to demonstrate the benefits of asdhr for analysis of environmental data sets which so often are irregularly sampled or contain numerous missing values this is achieved by providing a brief background to dhr and then introduce the arbitrary sampling methodology section 2 demonstrating the capability benefits and necessity of asdhr when using environmental data o paleo climatology smith et al 2016 comparing asdhr and dhr outputs to demonstrate the arbitrary sampling capability section 3 1 o persistent organic pollutants becker et al 2006 demonstrating the necessity for extending dhr to accommodate irregular sampled time series section 3 2 3 3 especially for noisy data series o forecasting atmospheric co2 introducing and demonstrating arbitrary forecasting the ability to forecast at arbitrary points into the future with different sampling times to the observed data section 3 4 evaluation of asdhr robustness to data sparseness and observational noise section 4 2 dynamic harmonic regression the dhr model assumes that the observable variable of a system is composed of four components 1 trend t sustained cyclical c with period different to the seasonality seasonal s and white noise e young et al 1999 1 y t t t c t s t e t the measured values of y are the output observations series of a system of stochastic state space equations which can then be broken down to allow for estimation of the four components t t is the trend component which can be considered a stochastic time varying intercept parameter and is interpreted spectrally as a zero frequency term i 0 where ω 0 or f 0 0 in practice occupying the lowest part of the spectrum and modelled as integrated or smoothed random walk see young et al 1999 with states termed level and slope of the trend the seasonal component s t is defined as 2 s t i 1 r s a i t cos ω i t b i t sin ω i t where a i t and b i t are stochastic time varying parameters tvp and ω i are the fundamental and harmonic frequencies associated with the seasonality in the series i 1 2 r s 3 c t i 1 r c α i t cos f i t β i t sin f i t where α i t and β i t are stochastic tvp and f i are the frequencies associated with the longer cyclical component i 1 2 r c the cyclic component c t has an identical definition to the seasonal and is isolated here to allow for a different physical interpretation whereas the white noise component e t is the remaining information after the other 3 components have been removed from y i e model residuals note that the full unobserved components model young et al 1999 also incorporates the irregular component here omitted for simplicity typically the tvp a i t b i t α i t β i t and both t t states are defined by a two dimensional state vector x i t l i t d i t t where l i t and d i t are respectively the changing level and slope of the associated tvp the stochastic evolution of each x i t is assumed to be described by a generalised random walk process 4 4 x i t f i x i t 1 g i η i t 1 i 1 2 r where r 1 r c r s and f and g defined in their time varying form in 7a and 7b respectively see also young et al 1999 for fixed form 2 1 state space and observation equations the state space model is constructed by aggregation of the subsystem matrices defined in 2 and is defined in young et al 1999 however both the state transition and noise input matrices are fixed and thus can only work for uniformly sampled data hence the need to apply regularisation techniques on irregularly sampled data the method proposed here replaces these fixed matrices with time step dependent ones where the values depend on the time between each sample thus allowing them to work for irregularly sampled data for the rest of the paper the temporal positioning of samples t at regular intervals δ t is replaced with the arbitrary positioning of samples δ t k where k the sample number keeps the temporal order if y v y k is the vth derivative of y y k and the form of the function y is not specified a data point distant from y k provides very little information about y y k using the local polynomial modelling reasoning e g fan and gijbels 1996 only the local data points in the vicinity of y k are used assuming y y k has the q 1 th derivative at the point y k then following taylor s expansion for y in the local neighbourhood of y k we have 5 y y y y k y y k y y k y y k 2 y y k 2 y q y k q y y k q if the value of y and its derivatives are known at the tth point as x k y ς k y ς k y ς k y q ς k t and the highest derivative of y y with respect to y with y k y ς k and y q 1 ς k η k where η k n 0 σ η 2 and ς k is the approximation point knot at sample k then taylor s expansion 3 can be applied in the local neighbourhood of ς k for all derivatives of y resulting in the grw model with state space 6a and observation 6b equations with the now time varying state transition in 7a and system noise input in 7b matrices 6a x k f k x k 1 g k η k 1 6b y k h k t x k e k where h k is the observation matrix dimension of nxr for rw trend and rw harmonics amplitudes observation equation 6b implements the regressive structure of dhr with x k being the estimated amplitudes of harmonics or trend levels for each k and their corresponding elements of h k contain the i th s harmonic values cos ω i t k or sin ω i t k or ones for the trend level 7a f k α δ k δ k 2 2 δ k q q 0 1 δ k δ k q 1 q 1 0 0 1 δ k q 2 q 2 0 0 0 1 7b g k δ k q 1 q 1 δ k q q δ k q 1 q 1 δ k t where δ k ς k ς k 1 is the temporal distance between the temporal samples number k and k 1 time difference between the knots ς k and ς k 1 when α 1 and q 0 1 2 this equation describes respectively random walk integrated random walk double integrated random walk etc when α ranges between 0 and 1 referring to smoothed random walk with orders q as above the choice of random walk order depends on the application where variation is expected q of 1 or higher is used naturally depending on the shape of the trend where no assumptions are made and suspicion of stationarity needs to be evaluated the simple rw model q 0 is usually more appropriate in practice the analysis starts with q of 0 for the harmonic components and 1 for the trend 2 2 algorithmic considerations to reiterate the term arbitrary sampling is used because the new state space equations section 2 1 do not constrain the time between each sample to be fixed as long as they are in temporal order the regularity or amount of irregularity in the sampling process does not impact the modelling process so long as the temporal positions of each sample are known and the finite taylor expansion 5 is a satisfactory approximant of y to keep the algorithm numerically well defined keeping the spectrum of the transition matrix sensible as its inverse is used in the smoothing algorithm the temporal distances between each sample δ k may need scaling to keep the majority or average sampling rate close to one this is equivalent to choosing the time unit suitable for the analysis e g if the sampling process is typically once a week then δ k provided in days needs to be divided by seven in formal terms as δ k affects the spectrum of the transition matrix f k and its invertibility condition the time must be expressed in the units that will not cause poorly conditioned f k for any or at least for very few steps k in the state space matrices section 2 1 a δ k of 1 for all k implies regular sampling as a special case 2 3 variance intervention amongst the numerous algorithmic advantages of the stochastic state space techniques such as the ease of forecasting smoothing and interpolation including arbitrary times between the existing samples the variance intervention technique seems particularly well suited to environmental data analysis and modelling very often the researcher is looking for confirmation or detection of a discrete change in the system variance intervention technique has been introduced by box and tiao 1975 and in the context of stochastic state space models it was developed and evaluated by young and ng 1989 with regular dhr intervention points are used to account for abrupt changes in the data such as a sharp calibration change or a shift in environmental system behaviour e g chappell and tych 2012 it can be used to model and evaluate the potential for specific breaks in the time series whether background level slope changes or sudden amplitude changes of the harmonic components in the dynamic harmonic regression context without intervention points any abrupt changes are smoothed in the model estimate and give poorer models that are not true to the system not reflecting the mechanisms governing the observed processes and so not consistent with the dbm approach in bayesian terms interventions amount to introducing diffused priors at the intervention a priori step causing the recursive estimator to doubt the current estimate by increasing the covariance matrix significantly introducing intervention points requires either assumptions or knowledge of the time of the change alternatively a search for a significant parametric change may be made using a sliding intervention technique as applied in chappell and tych 2012 to detect discrete changes in streamflow and evaporation records due to forest cover change or to other such interventions this advantage is not lost with the introduction of the arbitrary sampling technique as one of the examples below demonstrates 2 4 period identification in many environmental data series there is a need for identification of dominant periodicities as these are likely to indicate the phenomena active or dominant in the processes generating the time series spectral estimators such as fft and the various families of parametric spectral estimators from burg s to wavelets while commonly used are a sensitive to noise especially coloured noise and b their uncertainty is very high as fisher 1929 has shown the uncertainty of spectral estimators is of the same order as their magnitude these issues are aggravated for noisy processes within time varying spectra for the simple reason of the number of estimated values of the spectral characteristics being of a similar magnitude to that of the number of data points so while using the standard methods we are getting a picture for a range of frequencies this picture is highly uncertain for spectral estimators with dhr and asdhr one periodicity a handful of harmonic frequencies is analysed in each step of the periodicity sweep as we show below the powerful handling of uncertainty by the kalman filter and fixed interval smoother allows for a significant improvement of detection and estimation process and in addition importantly and nearly uniquely provides an uncertainty estimate of the identified periodicities the periodicity identification method used for asdhr involves scanning through a predetermined selection of periods and selecting the most statistically likely period s this is relatively time consuming for wider sweeps but the search could be optimised using variations of common search algorithms computation time is arguably not such a critical issue as a this is an off line process and b with high speed modern computers it is not significant the question of identification criterion for spectral peaks is quite critical the standard r2 being the proportion of variance of observed data explained by the model 8 8 r 2 1 e k 2 y k 2 with e k being the model residuals could be used as the statistical measure but this was found to be less reliable as many periods were found to have similar r2 values leading to poor sensitivity especially in trend dominated series and so the statistically best period was hard to distinguish from other significant periods the same approach will apply to multi periodic signals thanks to the orthogonality of the harmonic components introduced here is an analogue of the standard r2 a new measure easily described as the proportion of data explained by the seasonal or cyclic component 9 9 r s 2 s k 2 y k t k 2 where s k is the estimated seasonal component section 2 its quadratic norm variance is compared with that of the detrended data term in the denominator of 9 environmental data often have a significant slow or trend component which dominates the standard r2 while rs 2 focuses on the detrended data and seasonal component note that in the process of identification the trend is estimated together with the seasonal component for each case so there is no danger of introducing artefacts due to this procedure effectively a spectral decomposition in addition 9 provides a standardised measure of a relative strength of periodicity comparable across different time series 2 5 noise variance ratio nvr the introduction of taylor s expansion to the grw models indirectly influences the selection of hyperparameters by introducing the sampling rate directly into the state transition equation for the original dhr spectral model fit was used as it was relatively easy to formulaically express the dhr spectrum and compare it to the ar spectrum of the data this becomes more complex and ambiguous for irregularly sampled data however nvrs also carry the interpretation of time scaling of the model spectral boundary of the low pass filter interpretation of the process as explained in young et al 1999 in this case with the challenging application examples we found that choosing the nvrs needs to reflect the time scale of the modelled process rather than the best fit in any particular sense the latter would have been arbitrary and would introduce additional assumptions into the modelling process 3 demonstrating asdhr on environmental time series the examples compare where possible the proposed asdhr methodology with the original dhr methodology direct comparison is often difficult as both methods operate on different data sets dhr works with regularised and sometimes pre filtered data whereas asdhr works with the raw or unedited observed data in terms of the dbm approach or philosophy it should already be apparent that asdhr is a more appropriate tool for analysing environmental systems the first example 3 1 has more comparable data sets interpolated and raw data and is a good demonstration of a working asdhr methodology that is comparable to dhr the second example 3 2 demonstrates the need for asdhr to achieve data analysis that is in line with the dbm philosophy i e the data tells the story and not the assumptions used to manipulate the data for dhr analysis the third example 3 3 introduces a new type of forecasting termed arbitrary forecasting that allows predictions to occur at chosen points in the future not just from the end of the observed time series and at different sampling rates and points to that of the observed time series 3 1 paleo climatology example analysing patterns such as trends and cycles in paleoclimatic data is a common theme in this discipline the example we used was a typical one and previously published in nature scientific reports indicating the importance of the problem for the community a carbonate oxygen isotope δ18o record derived from speleothems contained within cueva de asiul situated in the matienzo depression cantabria north spain was used to reconstruct the precipitation delivery to northern spain during the last 12100 years using dhr analysis to find the trends and periods for full details and the analysis see smith et al 2016 here the dhr analysis in terms of trend and harmonic amplitudes is compared with the proposed asdhr similar results are expected as both methods are operating on the same data but the result specifics should be different due to the differences in the data pre processing and analysis algorithms 3 1 2 data pre processing with current dhr the data needs pre processing to make uniform the sampling rate and this involves linear interpolation followed by removing the interpolated samples where there are gaps in the observed data to avoid introduction of artefacts in this case analysed in smith et al 2016 by the corresponding author a highly irregularly sampled data series of 1919 values is reduced to a uniformly sampled data series of 815 62 of which are missing values mainly due to a single large gap in the data series which is a significant data loss even if the key characteristics of the data are preserved fig 1 with current dhr the large gap 872 years in the data series needs to be interpolated and due to its size any interpolation across it is meaningless in terms of physical interpretation and could affect the immediate estimates either side of it with the proposed asdhr procedure all that is required is to provide the temporal distance between each pair of samples this means asdhr has the full range of data 1919 values to utilise and ignores the effect of the large gap there is no interpolation 3 1 3 period identification the periodicities of the data were identified by scanning across a range of periods to find the two that fit the data best as in smith et al 2016 although as noted above the current dhr method only uses 815 resampled values while asdhr has the original 1919 values to use current dhr method 1290 and 1490 years asdhr 1320 and 1540 years well within the accuracy of the age estimate based on 18o isotope levels this new result confirms the findings of smith et al 2016 only providing a small adjustment when compared to the samples timing error 3 1 4 comparing current dhr with proposed asdhr to compare the model fit of the two methods the fit from dhr was rescaled back to the original time base and this showed that the arbitrary sampling procedure yielded slightly better results fig 2 the estimated trends and amplitudes were similar between the two methods figs 3 and 4 respectively with the main difference with the behaviour over the gaps the grey shaded area highlights the large gap in the data and a period of suspect data immediately before it the distributions of residual errors were also similar between the two methods with both being approximately gaussian and very close to symmetric fig 5 this demonstrates how the introduction of the arbitrary sampling technique does not affect the fundamentals of the dhr method using asdhr for paleo climatic series not only simplifies the analysis procedure no prior data manipulation and preserves the data i e no data loss artefacts introduced but also returns slightly better models in this case a more pronounced seasonal component 3 2 persistent organic pollutant example identifying patterns and trends in atmospheric concentrations of persistent organic pollutants pops is an important part of monitoring and understanding how anthropogenic activities affect them weekly air samples have been collected since january 1992 at the high arctic station of alert in canada and are filtered for various pops and have a high signal to noise ratio 3 1 for further background and dhr analysis see becker et al 2006 two examples are taken from the data collected at alert benzo a pyrene reported in becker et al 2006 and α hexachlorocyclohexane α hch not reported and both are members of the polycyclic aromatic hydrocarbons subset of pops prior to dhr analysis the data were pre processed missing values due to data below the instrumental detection limits were replaced by values 2 3 of the detection limits and data points situated outside 3x the standard deviation of any fitted trend where considered outliers and removed from the data set the data were then resampled to fortnightly due to the weekly data having significant irregularity and finally ran through a low pass filter to reduce aliasing in the first example the observed data with missing values and outliers were used with asdhr and compared to pre processed data with dhr in the second example both use the pre processed data but without the resampling or pre filtering for asdhr both model fit and trend were compared between the two techniques as that was the aim of dhr in the original paper 3 2 1 benzo a pyrene in becker et al 2006 an annual cycle was identified and using the highly irregularly sampled raw data this same annual cycle was identified using the asdhr identification procedure the subsequent estimated fit fig 6 and trend fig 7 show that data pre processing unless required for a specific analysis question is no longer necessary for dhr analysis if the arbitrary sampling technique is used where a good model fit and trend estimate were obtained from the raw unfiltered data the uncertainty estimate is higher for asdhr which can be attributed mainly to the prefiltering used necessarily prior to dhr application where data were brought onto fortnightly time base this pre filtering reduced the variance of the irregular component which is clearly visible in fig 6 in addition in asdhr as expected uncertainty grows when data are absent so the less frequent sampling between 1995 and 1999 as visible in fig 7 leads to the increase of estimated uncertainty 3 2 2 α hexachlorocyclohexane here both dhr and asdhr used the pre processed data where values under detection limits were set to 2 3 of the instrumental detection limits but for dhr the data were then resampled and pre filtered an annual cycle was identified again and the subsequent estimation of trend shows how pre filtering the data can lead to bias in its analysis in this case fig 8 the trend estimated by asdhr is pulled down by the observed data data that are missing in the resampled and pre filtered time series 3 3 arbitrary forecasting atmospheric co2 example below we present a simple example of forecasting of the well known keeling mauna loa co2 series see acknowledgments in this example we do not aim at perfect forecasts but rather at showing the flexibility and versatility of even the basic version asdhr in this application better forecasts could be achieved with more assumptions being included in the model such as a model of the business cycle or the industrial growth projections the mauna loa co2 monthly mean data set was used to demonstrate arbitrary forecasting that is forecasting from any point in the future and not just from the end of the data set additionally the time base of the forecasting period is not limited to that of the observed data something that the original dhr cannot do this is easily implemented by extending vector δ k by the values corresponding to the arbitrary points chosen in this example fig 9 the monthly mauna loa data are used to forecast the year 2018 on a weekly basis for five different periods of data 1960 to 1970 to 1980 to 1990 to 2000 and to 2010 as shown by the increasingly darker line thus the lighest grey forecast is based solely on the data upto 1970 and the darkest shading is based on all the data upto 2010 this fig 9 demonstrates how the rate of change of co2 grows with time as the knowledge is increasing e g the 1960 1970 based predictions for 2018 have levels observed in 2000 except during the 1990s where the 1960 2000 based predictions are lower than that of the 1960 1990 clearly relating to the visible dip during the 1990s the size of the uncertainty shown here as a single standard error estimate band increases as the forecasting horizon increases lighest grey for 48 years darkest grey for 8 years testing on this data set and on simulated data sets indicates that the forecasts are largely unaffected by data sparseness or the forecasting horizon magnitude only the observation noise level impacts the predictions in the past the dhr technique was successfully used for forecasting various processes in both broadly environmental and industrial applications from demand for electricity young and pedregal 1998 to numbers of calls to a banking call centre tych et al 2002 to anecdotally demand for beer unpublished lancaster university thesis asdhr naturally broadens the application area of this robust method 4 robustness and reliability evaluation before the methodology was applied to real data it was tested on a variety of challenging simulated data sets with known unobserved components to test the robustness and sensitivity to data sparseness size of temporal distancing and observational noise the methodology was found to be very robust with very sparse data sets it also produces meaningful estimates for a very wide range of temporal distances between the samples limited by the taylor expansion 3 and condition of the recursive estimate of the covariance matrix within the fixed interval smoother algorithm applied subject to these constraints the technique can be used to estimate the observed values and components no matter how irregularly sampled the time series is sensitivity to observation noise is similar between the time tested and commonly used dhr with about 300 citations and asdhr in terms of physical interpretation the extent of data sparseness needs to be considered when interpreting the estimated components as very sparse data may effectively under sample higher frequency components 5 conclusions presented here is a technique to improve the dhr analysis of irregularly sampled time series that removes the need for data pre processing regularisation decimation interpolation etc the technique also does not involve estimation of missing values and so any subsequent analysis is free from assumptions and bias and only uses the available observed data this brings dhr closer to the dbm philosophy of allowing the data to inform us of the processes and mechanisms that result in the observed time series it also makes it uniquely suitable for analysis of environmental irregularly sampled observational data data pre processing was a necessary step to allow dhr to work on irregularly sampled data sets but it comes with artefacts bias and increased uncertainties in the model estimates however with the arbitrary sampling technique this step can be avoided and provides model estimates with lower uncertainties and no bias the technique has been tested on challenging simulated data and is robust enough to work on extremely sparse data however in terms of physical interpretation there is a limit to how sparse the data can be due to e g under sampling chappell et al 2017 additionally the technique was found to have similar observation noise sensitivity to that found in standard dhr method the technique has been demonstrated here on three different types of observed environmental time series data and has yielded slightly better model outputs than the standard dhr method without data pre processing there will be no introduction of any assumptions artefacts or bias into the data prior to analysis and thus these results should be closer to observed reality the technique also allows for forecasting at arbitrary points and at different sampling rates than in the observed data this means the frequency of the forecast is not limited to the frequency of the observations and with a non stationary forecast horizon may allow forecasting to yield more insights into environmental processes finally while it may not be apparent from the equations asdhr is easily and inherently generalised so that all aspects of estimation are either time varying or state dependent from periodicity to dynamics of random walk model to nvrs for each sample k the periodicity random walk model and nvr can be set so for example one section of observed data could be analysed for one set of periodicities and another section analysed for another set or the random walk model could be changed to match a significant change in the data or the nvrs can be varied to suit the smoothness of the data software format and availability the method has been implemented within the matlab computing environment the input arguments specify the time series variable the state space format meta parameters for the trend and for harmonics amplitudes which essentially specify the time scale of the trend and amplitude variability additional arguments control variance interventions initial conditions etc with sensible default values provided the output arguments have also been constructed with ease of use in mind and include model fit estimated trend harmonic components and their amplitudes with their respective uncertainty estimates so are immediately interpretable in terms of the modelled environmental process matlab functions and example scripts are available from the corresponding author upon request the functions will be included in the captain toolbox for matlab in due course acknowledgements paleo climatic data smith et al 2016 have been kindly provided by dr andi smith of british geological survey the authors acknowledge dr hayley hung environment canada for access to the northern contaminants program ncp and the integrated atmospheric deposition network iadn datasets for persistent organic pollutants pops dr pieter tans noaa esrl www esrl noaa gov gmd ccgg trends and dr ralph keeling scripps institution of oceanography scrippsco2 ucsd edu appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 104503 
26144,intercropping switchgrass panicum virgatum with pine can increase bioenergy feedstock production without land opportunity costs but can potentially alter water budgets measuring evapotranspiration et and its parameters stomatal conductance gs leaf area index lai canopy temperature tc and soil moisture sm across cropping systems is costly and time consuming however interpretation of remotely sensed data can facilitate the effective assessment of relative et demands among competing forest landuses this study develops and tests geospatial models informed by a normalized difference vegetation index ndvi soil adjusted vegetation index savi vegetation vigor index vvi and other spectral information to estimate et and its parameters which are measured on experimental watersheds with young pines and natural understory yp switchgrass only sg and young pine intercropped with switchgrass ic the treatment watersheds were replicated on three sites located across the southeastern u s in carteret nc calhoun ms and greene al despite the growth inconsistency for the sg only treatment remote modeling estimation of et parameters yielded an acceptable r2 0 70 and the et model yielded r2 of 0 50 and a standard error of prediction of 0 94 however et and et parameter model estimation for the ic performed somewhat less satisfactorily with an r2 of 0 47 0 59 0 56 0 81 and 0 57 for et lai gs tc and sm respectively potentially due to inconsistencies in landsat image pixel size and landuse homogeneity moreover et parameter models for the yp site performed rather poorly with r2 0 28 0 63 and 0 76 for lai gs and tc respectively additionally image analysis automation was created with python scripting and geospatial models the findings from this study suggest that inclusion of more spatial variability sound data mining ultra high resolution imagery and advanced image processing approaches to account for potential modeling uncertainties can enhance the predictive capability of models to remotely estimate environmental parameters including et radial basis function network rbfn based models provided promising results for estimating et and et parameters using remotely sensed digital information when they are prepared with advanced data mining but it is likely that laypersons may find these models difficult to use however forest managers with access to neural network software can use our devised rbfn training models for estimating those forest hydrologic parameters with better accuracy keywords arcgis modelbuilder canopy temperature data mining evapotranspiration landsat orthoimagery python script rbfn software development soil moisture spot stomatal conductance visual basics studios 1 introduction the u s department of energy and the scientific community have a goal of producing biofuel from energy crops such as switchgrass panicum virgatum a cheaper alternative to row crops or other agricultural commodities like corn sweet sorghum sugarcane sugar beet crop residues and other woody biomass although crop residues and other woody biomass are abundantly available and much cheaper to procure than switchgrass they have their own downsides crop residues one source of soil organic carbon are essential for soil fertility enhancement and useful for soil erosion control increased water infiltration and evapotranspiration et reduction but need to be left in the field and tilled to provide a positive effect on crop production lal 2004 jarecki and lal 2003 in their review of next generation biomass feedstock for biofuel production simmons et al 2008 discussed the constraints of biofuel production from woody biomass and other agricultural products they suggested that the use of dedicated herbaceous perennial crops such as switchgrass perrin et al 2008 parrish and fike 2005 miscanthus sahoo et al 2018 and sorghum paterson et al 2008 would be better alternatives these herbaceous species can be grown in various regions of the united states u s fig 1 simmons et al 2008 recommended switchgrass cultivation as an understory in the row crop pine forests that are abundant in the southeastern united states pine plantations which constitute the plurality of croplands in vast areas across the southeastern united states from mississippi to north carolina are managed to produce lumber fiber for pulp paper cardboard and bioenergy feedstocks on a traditional pine plantation the space between rows has no economic value grasses that can serve as bioenergy feedstocks such as switchgrass could be intercropped between rows in pine plantations and grown until the closing canopy of the pines shades them out however such intercropping raises environmental and ecological questions regarding the water budgets of forest plantations is the evapotranspiration et of intercropped stands additive such that total et can be estimated based on pine and switchgrass et rates based on their relative coverage or does intercropping cause competition for water between the two crops such that the total et is less than the sum of et expected from the individual crops these questions have implications for regional water budgets under potential bioenergy development scenarios and for decisions about managing forestlands this study is part of a larger study examining how the establishment of these cropping systems affects stream flows surface and soil water quality and water budgets as discussed the addition of switchgrass understories in forest plantations like row pine would have ecological consequences especially if the switchgrass competes for soil water with the main forest crop using a soil plant atmosphere model parameterized with site specific data albaugh et al 2014 found increased et in the intercropped sites when compared to the mature pine or switchgrass only plots however the watershed scale et comparison data are lacking for switchgrass intercropping versus natural understory intercropping in pine forests therefore it is essential to quantify the amount of soil water used by switchgrass compared to row pine understories on a watershed scale plant and soil understory litter evaporation and transpiration or evapotranspiration et are major components of the hydrological cycle jaramillo and destouni 2015 studied 100 basins for actual et aet p variation with respect to flow regulation and irrigation impact and found a relatively large aet p increase in water limited basins including for a major portion of those basins in the united states global land cover changes impact the terrestrial water cycle et has a direct impact on hydrology crop growth and biomass production forest cover alteration including intercropping to accommodate switchgrass may change the et and water balance of these forest ecosystems sterling et al 2013 through their extensive study of 1500 estimates of annual evapotranspiration and corresponding global land cover change database projected a 5 percent decrease of global scale terrestrial evapotranspiration tet from the current anthropogenic land cover change mostly deforestation and an increase in tet with forest cover intensification an accurate estimation of et and its spatial and temporal distribution is of key importance for hydrological and meteorological applications including regional scale water balance sun et al 2011 the et rate of any ecosystem depends upon soil moisture and vegetation factors as well as climatic variables like air and canopy temperature radiation vapor pressure wind speed and the physical characteristics of the evaporating surface viessman and lewis 2003 while plant evaporation occurs mostly from above canopy interception as a function of canopy storage capacity and density amatya et al 1996 understory litter transpiration occurs by uptake and transport of water from the soil aquifer system by plant roots branches stems and eventually diffusing from plant leaves into the atmosphere senay et al 2013 et estimation from the forest cover would provide insight to the soil water use by different crops but it is a very cumbersome in situ based approach rapid accurate and cost effective estimation of et and its supporting parameters such as stomatal conductance gs leaf area index lai canopy temperature canopy albedo tc soil moisture sm and estimation of wind speed using remote sensing technology has become increasingly popular panda et al 2016 lai is defined as the single sided surface area of leaves per unit area of soil m2 m 2 and is a key parameter implicit in a variety of forest ecosystem processes including light and rain interception transpiration photosynthesis and soil heterotrophic respiration le maire et al 2006 lai is a seasonal parameter and is an indicator of crop growth thus et and lai correlate very well sun et al 2011 lai was also one of the hydrologic parameters recently discussed in parameterization guidelines and considerations for hydrologic models by malone et al 2015 optical indirect methods e g model lai 2200 plant canopy analyzer li cor lincoln ne or hemispherical photographs and semi direct methods using litter collection and allometric methods are used for local estimation of lai brauman et al 2012 le maire et al 2006 malone et al 2015 panda et al 2016 but these methods are time consuming cumbersome and costly according to hilker et al 2013 transpiration is directly linked to stomatal conductance gs local measurement of stomatal conductance is conducted by an indirect optical measurement malone et al 2015 or by a semi direct method using a vapor pressure deficit algorithm pearcy et al 1989 sampson et al 2011 but these methods are also costly and time consuming stomatal conductance of pine needles has been measured and used for estimating and modeling transpiration of pine forests amatya et al 1996 sack and scoffoni 2012 hilker et al 2013 suggested that satellite retrievals of photosynthesis or gross primary production gpp could be used to quantify transpiration rates through gs amatya and skaggs 2001 canopy conductance gc is generally approximated as a product of gs and lai amatya and harrison 2016 amatya et al 1996 brauman et al 2012 amatya and skaggs 2001 jensen et al 1990 nghi et al 2008 panda et al 2014 tian et al 2012 although the maximum stomatal conductance also may be estimated as a function of measured et vapor pressure deficit and other environmental variables morris et al 1998 as will be shown below canopy temperature can serve as a surrogate for the amount of evaporation and transpiration through the plant canopy and can be estimated with direct measurement using thermometers bastiaanssen et al 1998 forest soil moisture is generally estimated through instrumentation using a tensiometer and lysimeter olivera guerra et al 2015 van der ploeg and de rooij 2014 vasquez et al 2015 routine in situ measurement of plant hydrologic parameters is time consuming and expensive panda et al 2014 sampson et al 2011 majasalmi et al 2017 have a detailed review of the comparison of optical and allometric field instrumentation for forest hydrologic parameter estimation and are in favor of optical remote sensing approaches estimating forest et using remote sensing data is not a new concept there are many successful examples of using remotely sensed images to model et and water budgets for grasslands and crop lands chen et al 1997 feddema and eggbert 2005 johnson 2016 noori and panda 2016 panda et al 2009 rao et al 2006 schellberg et al 2008 tian et al 2013 turner et al 1999 wang and jia 2013 but such models have limitations for forests especially for understory in between forest rows as the satellites cannot see the ground or the understory in closed canopy forests and thus cannot sense either soil moisture or the spectral characteristics of the understory panda et al 2002 pisek et al 2015 2016 yang et al 2014a b 45 47 li and lyons 2002 used 1 1 km resolution noaa 14 avhrr remote sensing data to derive surface temperature which was combined with limited routine meteorological data like soil moisture to estimate the et rates in central australia with limited success cristobal and poystos 2011 tested the reliability of remote sensing data of terra and landsat to estimate forest vegetation et in the vallcebre research catchment in spain from 2003 to 2005 using 27 aqua modis images 11 landsat 7 and 10 landsat 5 images in comparison with stand transpiration obtained from sap flow measurements however even the best estimations of forest et obtained from landsat images had 30 percent uncertainty cristobal and poystos 2011 panda et al 2018 used cloud free landsat images from 2006 to 2014 and an advanced data mining approach to obtain principal component bands to correlate with et data they obtained a strong correlation between the remote digital information and the et of pine forest with a model r2 of 0 58 they panda et al 2018 used backpropagation neural network bpnn and radial basis function network rbfn models and obtained a testing validation average absolute error of 0 18 and 0 15 wm 2 and an average accuracy of 81 and 85 percent respectively the thermal band of landsat satellite imagery can be used to estimate canopy temperature lee 1994 panda et al 2016 senay et al 2013 satellite imagery approaches are generally based on the principles of the surface energy balance exploiting the remotely derived land surface temperature as a proxy indicator of surface water status cammalleri et al 2013 a review article by wang and qu 2009 explains how numerous studies have been conducted on the remote estimation of soil volumetric water content by using satellite aerial or simple digital photographic image analysis recent studies show that remotely sensed data especially freely available 30 m spatial resolution 16 day temporal resolution landsat thematic mapper tm images can be used to efficiently estimate gs canopy temperature lai and et of forest vegetation carter 1998 curran 1980 hafeez et al 2002 justice et al 1998 le maire et al 2006 moran et al 1994 north 2002 nouri et al 2012 olioso et al 1999 panda et al 2016 provoost et al 2005 rouse et al 1973 senay et al 2013 according to liou and kar 2014 and panda et al 2016 2018 traditional approaches for et estimation such as weighing lysimeter surface energy balance seb energy balance bowen ratio ebbr eddy covariance techniques pan measurement sap flow scintillometer water balance etc are mainly complex models and can estimate et on local field and landscape scales only over a homogeneous vegetation cover with high accuracy however such approaches cannot be directly extended to estimate the et rate of large areas of forest cover that contains natural heterogeneity and involves complex hydrologic processes due to costly and time consuming instrumentation processes idso et al 1975 panda et al 2016 zhang et al 2016 remotely sensed image data is being used for mapping regional and meso scale patterns of et and surface temperature which is helpful in establishing a direct link between surface radiances and energy balance components caselles et al 1992 glenn et al 2007 idso et al 1975 kustas and norman 1996 li et al 2009 long and singh 2013 moran et al 1989 panda et al 2016 2018 weigand and bartholic 1970 yang and shang 2013 zhang et al 2016 information embedded in satellite visible near infrared middle infrared and thermal infrared bands can be used to retrieve the land surface temperature lst vegetation index and atmospheric temperature and in turn supports et estimation for large spatial extents and with higher temporal frequencies liou and kar 2014 panda et al 2016 2018 zhang et al 2016 these studies clearly show that the remote sensing approach for estimating forest et and its contributing parameters has strong appeal since it eliminates laborious time consuming costly field methods which also have limitations in covering large areas and land cover heterogeneity majasalmi et al 2017 panda et al 2016 2018 the use of freely available moderate spatial resolution 30 m landsat data albaugh et al 2014 senay et al 2013 and five other even lower resolution global fractions of absorbed photosynthetically active radiation fpar in the wavelength region of 400 700 nm products like modis misr meris seawifs geov1 250 m 1 1 km has merit in estimating forest hydrologic parameters majasalmi et al 2015 tao et al 2015 verger et al 2015 yang et al 2014a b covering large spatial extents however one problem that has not yet been documented is that pine switchgrass intercropping widths 3 m cover areas smaller than the pixel scale 30 m of landsat 7 and 8 images this study addresses the methodological question of whether remotely sensed spectral bands can be useful for modeling evapotranspiration and its components for young loblolly pine with a recruited understory switchgrass and its intercropping between young pine beds and explain the amount of water use by landuse types 1 pine plantations intercropped with switchgrass and pine plantations intercropped with understories the goal of this study was to develop and test object oriented software to estimate the gs tc sm lai and et values of pine switchgrass and pine intercropped with switchgrass as well as understory the specific objectives of the study were to develop 1 multivariate regression models using remotely sensed imagery based digital information as predictor variable to estimate the gs tc sm lai and et respectively as outcome variables 2 artificial neural networks ann models using remotely sensed imagery based digital information rbfn algorithms to predict homogenous pine and switchgrass et and the et of pine intercropped with switchgrass as well as understory respectively 3 executable software using the multivariate regression analyses based algorithms automated geospatial models and python scripts for endusers to apply for their application and usage 2 materials and methods 2 1 study sites description the sites included in this research are environmentally diverse i carteret nc a topographically flat well managed coastal forest fig 2 a ii calhoun ms an upland inland forest with microtopography fig 2b and iii greene al a moderate to steep sloped inland old forest ecosystem fig 2c all three sites were established to investigate the environmental sustainability of intercropping switchgrass as a cellulosic biofuel between pine tree rows without using the land for food inside a managed pine forest owned and managed by weyerhaeuser to produce timber wood fiber and biofuel feedstock bennett et al 2013 muwamba et al 2015 each site has a minimum of four watersheds with four distinct vegetation treatments i mature row crop pine only ii young pine and switchgrass intercropping 6 m spacing between pine beds with 3m for switchgrass iii pine and understory intercropping 6 m spacing between pine beds with 3m for switchgrass and iv switchgrass only fig 3 each of the sites in greene county al and calhoun county ms has an additional reference watershed with a mid rotation pine forest not shown in fig 2 the experimental watersheds d0 d1 d2 and d3 in carteret county nc 34 49 n 76 40 w are 26 0 26 3 25 9 and 27 1 ha respectively fig 2 d0 is the watershed with young pine mixed with understory d1 is a watershed with pine intercropped with switchgrass d2 has mid rotation thinned pine with a natural understory as a reference and the fourth watershed d3 is switchgrass only the northern southern and western sides of the study site are fully covered by forest and the east side is dominated by agricultural land the carteret site topography is characterized by flat coastal plain at a 0 1 percent gradient and is at 3 m elevation above mean sea level mccarthy et al 1991 deloss fine sandy loam soil a fine loamy mixed thermic typic umbraquult that has poor drainage with shallow water tables and a ph range of 3 5 4 5 acidic represents the soil of the carteret study site amatya et al 1998 beltran et al 2010 the long term mean annual precipitation and penman monteith grass reference evapotranspiration at the study site are 1517 mm and 1010 mm respectively amatya and skaggs 2011 in greene county northwest alabama there are five watersheds fig 2c labeled gr1 gr stands for greene county gr2 gr3 and gr4 with areas of 11 6 26 7 25 9 and 16 5 respectively and a reference site grref that measures 6 8 ha bennett et al 2013 by 2014 6 year old matured pine stands with understories were established in gr1 that same year gr2 also had a 6 year old young pine stand with understory and gr3 had 8 yr old pine and switchgrass intercropping only switchgrass was grown in the gr4 watershed and grref not used in the study contained 20 yr old mid rotation matured pine the soils in the watersheds are a combination of falaya fine sandy loam thermic aeric fluvaquent somewhat poorly drained with a water table within 20 inches slopes from 0 to 2 percent magnolia fine sandy loam mesic typic pleudalf well drained with slopes from 0 to 25 percent and shatuba fine sandy loam thermic typic paleudult well drained with slopes from 1 to 12 percent bennett et al 2013 the erosion risk on the watersheds varied from high on gr1 to low on gr3 and gr4 the slope of the site watersheds varies from 9 9 to 12 7 percent the drainage at the outlets was measured using a flow meter located within a flume structure designed using the winflume design program the average pet of the watersheds varies from 1322 to 1471 mm while the pet of the grref reference watershed was 1600 mm bennett et al 2013 average annual precipitation of the greene county site was 1361 mm in calhoun county ms there are also five watersheds fig 2b labeled bf1 bf stands for befontaine bf2 bf3 bf4 and bfref not shown in the figure and not used in the study with areas of 14 1 12 8 10 9 15 2 and 12 6 ha respectively by 2014 bf1 was a 7 yr old young pine stand with natural understory bf2 was a pine stand thinned in 2007 with switchgrass intercropping bf4 was a 8 yr old pine also intercropped with switchgrass and bf3 was switchgrass only bf5 was a mid rotation pine stand planted in 1995 the soils at the site are a combination of cuthbert fine sandy loam thermic typic hapludult well drained with a water table at or below 2 m slopes 8 to 25 percent dulac silt loam thermic oxyaquic fragiudalf well drained with a water table at or below 2 m slopes 0 to 12 percent ruston fine sandy loam thermic typic paleudults well drained with a water table at or below 2 m slopes 0 to 8 percent providence silt loam thermic oxyaquic fragiudalf moderately well drained with a water table around 0 5 m slopes 0 to 15 percent waverly silt loam thermic fluvaquentic poorly drained with a water table from the surface to 0 4 m slopes 0 to 2 percent and gullied land half of the soils are classified as severely eroded drainage at the outlets was measured using a flow meter located within a flume structure designed using the winflume design program the site has an annual average temperature precipitation and potential evapotranspiration of 16 5 c 1405 mm and 1350 mm respectively 2 2 instrumentation and field data collection 2 2 1 field et calculation procedure at all of the study sites weather data were collected every 15 min by weather stations fitted with hobo u30 cellular data logger onset cape cod ma usa which were located in the proximity of the switchgrass only watersheds the weather data collected for analyses in this study included precipitation mm atmospheric pressure kpa solar radiation w m 2 wind speed m s 1 gust speed m s 1 wind direction temperature c and relative humidity each watershed was equipped with decagon soil moisture probes model 5tm connected to a campbell scientific data logger model cr200 at four depths 15 cm 30 cm 60 cm and 80 cm on the beds in tree rows and in between beds on furrows at two specific spatial locations fig 4 for real time monitoring of soil moisture daily weather data with field measured vegetation parameters on lai and maximum stomatal conductance gs were used to compute the pet with the penman monteith p m method however p m pet for a standard grass reference was used for switchgrass as there was only a limited data on its conductance actual et aet on each treatment watershed was estimated following the method developed by fisher et al 2005 as shown in equation 1 1 aet f pet where f is a soil moisture factor and pet is daily p m based potential evapotranspiration the factor f limited by soil moisture in the root zone was calculated as sm sm100 where sm daily average soil moisture measured at each treatment watershed and sm100 soil moisture content at 100 cm pressure head or 10 kpa which was estimated based on soil water characteristic data soil moisture characteristics were derived at the north carolina state university soil and water laboratory using undisturbed field soil core samples taken at each of the treatment watersheds during the study period this component of aet limited by energy component pet was assumed to represent only soil evaporation and vegetation transpiration evaporation from canopy interception was estimated separately for the mature pine stand and was assumed negligible for other treatment watersheds the detailed field hydro meteorological measurements and data analysis procedures for the study site in north carolina have been recently reported by ssegane et al 2017 and by bennett et al 2013 for the alabama site the mississippi site has a similar measurement protocol as that of the al site 2 2 2 field et parameters data collection methods field data lai gs tc and sm were collected from 2012 to 2014 which coincided with the satellite and aerial image acquisition periods a licor 2000 instrument was used in the field for in situ lai measurement of individual forest species such as pine young and matured switchgrass and understories a licor 1600 porometer field instrument was used to collect gs values for each species of vegetation a decagon portable volumetric water content measuring instrument was used to collect spatial soil moisture data in each watershed to supplement the soil moisture data recorded at specific locations in the watersheds as described above fig 4 the air temperature measured at the site weather station was assumed as a proxy for the tc data as the sensor height mostly coincided with the height of young pine switchgrass and understories the above field measured data and estimated daily aet as described earlier were used as output parameters for validation of the remote sensing digital information based et and et parameter estimation model development 2 3 image acquisition and processing 2 3 1 image selection digital information from free remotely sensed images like the landsat 7 etm and landsat 8 30m along with acquired spot 10m multispectral mss and ultra high resolution 4 band orthoimagery 0 15m images were used in the study to extract spectral band information as input model parameters to estimate the et and et parameters for the four types of vegetation landsat images were chosen as the source of spectral bands for analysis as they are free easily downloadable and can be easily processed due to the fact that the geometric and radiometric correction https earthexplorer usgs gov has already been completed the landsat images have a moderate spatial resolution of 30m and they cover the homogenous pine and switchgrass vegetation spatial area uniformly landsat imageries have a temporal resolution of 16 days as both landsat 7 etm and landsat 8 images were acquired in the same year part of 2013 and 2014 the temporal resolution period was reduced to eight days thus the et variation in the vegetation could be determined approximately twice monthly and in some cases four times a month capturing seasonal variation landsat images have complete required spectral resolution for et estimation have individual bands suitable to estimate the eco hydrologic parameters related to et and et parameters fig 5 landsat images also have simple radiometric resolution i e 8 bit for landsat 7 etm and 16 bit for landsat 8 which both require extra processing to make the imagery data compatible for model development along with the freely available cloud free landsat images spot images were acquired table 1 through astrium services richmond va usa to analyze the intercropped vegetation young pine understory and young pine switchgrass spot imageries were acquired at a cheaper cost when compared to other similar or slightly better higher spatial resolution imageries another advantage of using the spot imagery was the availability of spectral bands fig 5 that are suitable to estimate the eco hydrologic parameters related to et and et parameters under study the biggest advantage of using the astrium services images is that they radiometrically corrected the spot images before providing them to their users processed enhancing spatial resolution to explain a 6 m spaced intercropping of pine and switchgrass understory rows spot imageries were suitable for intercropped switchgrass eco hydrologic parameter estimation through model development ultra high 0 15m resolution orthoimages were collected for all three sites table 1 through quantum geospatial inc atlanta norcross usa to correlate with the localized et and et parameter lai and gs data that were collected on a transect basis coinciding with the date of image acquisition 2 3 2 image processing 2 3 2 1 geometric and radiometric correction geometric correction of the spot images was completed using the georeferencing tools available with arcgis 10 5 software redlands ca usa ground control points gcp road cross sections river bends and some monument locations were obtained from the referenced naip imageries of the study area to help in the geometric correction however geometrical correction of the orthoimages was completed using the gcps set up in the field before the image acquisition colored plates with known reflectance values were placed in the field as ground control points with known coordinates colored plates image reflectance values were correlated with the actual values to develop an algorithm which in turn was applied to the orthoimages through raster calculator for radiometric correction we followed the procedure developed by panda 2002 and panda et al 2010 it is to be noted that landsat imageries were geometrically and radiometrically corrected before being disseminated to the public and the spot images were acquired with completed radiometric correction 2 3 2 2 image fusion approach for spatial resolution set up spot mss images have a 10m resolution while spot panchromatic images have 5m resolution pansharpening erdas imagine with a modified intensity hue saturation resolution merge algorithm and resample arcgis 10 5 tools were used to have 5m resolution spot mss available to us for our study the spot mss 5m matched well to the 6 m spacing between the pine trees in the intercropped site orthoimageries used in the study to increase the acquired data numbers acquisition was completed during the time different from landsat and spot were of 15 cm resolution for et and et parameter estimation modeling they were resampled pansharpened to 5m resolution resampled spot and orthoimageries digital data were used for pine switchgrass and pine understory intercropped model development this image fusion technique helped in enhancing data numbers for effective model and subsequent algorithm development in studied landuses et and et parameter estimation using remotely sensed data 2 3 2 3 scanlines correction image masking image index development and digital ascii value extraction automation scanlines exists with raw landsat 7 etm images therefore a python script appendix a was written to remove them scanlines are nodata values inside images the python script took a 15 15 neighborhood of pixels specified using the focal statistics tool of arcgis and calculated the mean value of these 225 pixels and added inserted them in place of the nodata values of the image the script also did the batch processing for all landsat 7 etm image scanline corrections all processed images landsat 7 etm and 8 spot and orthoimagery were clipped to individual watersheds as the initial models were developed with the entire spatial extent for each of the watershed s prescribed vegetation covers fig 2 individual bands were separated from the composite image for spot and orthoimagery landsat bands were individually stacked when downloaded from the earth explorer https earthexplorer usgs gov site using the arccatalog band separation tool vegetation indices were developed using equation 2 for the normalized difference vegetation index ndvi equation 3 for the soil adjusted vegetation index savi and equation 4 for the vegetation vigor index vvi 2 ndvi ρ ir ρ r ρ ir ρ r 3 s a v i ρ i r ρ r ρ i r ρ r l 1 l 4 vvi ρ ir ρ g ρ ir ρ g where ρr ρg and ρir are spectral reflectance from the red green and nir band images as shown in fig 4 respectively and the l is a constant that represents the vegetation density huete 1988 defined the optimal adjustment factor of l 0 25 for higher vegetation density in the field l 0 5 for intermediate vegetation density and l 1 for low vegetation density automated geospatial models were developed in the arcgis modelbuilder platform to automate the spectral vegetation image development it is to be noted that image rasters in arcgis software are considered as integer data type rasters and therefore indices development using equations 2 4 using direct raster bands would not yield correct index images with decimal data type pixel asciis therefore during the model building in arcgis modelbuilder each of the image raster bands were converted to float data type rasters and the float data type rasters were used in the raster calculator tool to generate the index rasters all of the input band and index images were extracted to the watershed sizes using scripts written in python and the script helped in batch processing too a python script was written to automate and batch process the processed images to obtain watershed average digital ascii values through zonal statistics and use them as input parameters in the model development for estimated et and et parameters some data gaps were there due to possible field instrument malfunction during data collection weather anomalies and other human error in field measurements a detailed data mining approach was followed as shown in below subsection to prepare appropriate data for the modeling development with statistical and ann approaches panda et al 2018 2 4 data mining approaches for model data preparation preprocessing of input data was completed with the following methods generally missing values in a dataset are filled in through the use of the attribute mean of the dataset han and kamber 2001 most probable value han and kamber 2001 or a global constant han and kamber 2001 though for a few the mean of the group was used to fill the missing numbers for our datasets few outliers in our datasets were observed with initial visual interpretation however they were ascertained by a separability function a higher separability value suggested a great degree of distinctness in groups the separability equation used was represented as follows 5 v μ i μ j δ i δ j where μi is the mean of the group i μj is the mean of the group j δi is the standard deviation of the data in group i and δj is the standard deviation of the data in group j group i was the digital values obtained through image fusion and other analyses approaches described earlier and group j included the corresponding et and other et parameter values the authors did not envision any data volatility due to drastic weather changes during the three year study because data was collected in favorable weather conditions testing for data integration was essential for our datasets as the imagery data were collected from four different sources landsat 7 etm landsat 8 spot and aerial along with et and et parameters data with instrumentation thus proper integration of these various datasets was needed in order for the data to work as a single entity which assisted in bringing the digital data into a similar range as the landsat 7 dn reflectance percentage values of 0 255 8 bit data and the landsat 8 digital values of 0 65535 16 bit data panda et al 2018 thus the correlation between attributes a image data and b et and et parameters data was obtained by the following formulae 6 r a b a a b b n 1 σ a σ b where n is the number of data points a and b are means of two different attribute values and σ a and σ b are standard deviations of the respective attribute values when the value of r a b was greater than 0 and a and b were positively correlated the formula resulted in a high value and thus implied redundancy in the attributes we also completed data transformation for our study due to data volatility as described above therefore to enable the dataset to be ann model friendly data normalization was completed with our dataset to bring the image digital values and et and et parameter values into similar ranges in the neural networks literatures data normalizing also often refers to rescaling the vector by the minimum and the range to make all elements lie between 0 and 1 panda et al 2018 explained in their study that data normalization is generally completed by subtracting a measure of location and dividing by a measure of scale e g if the vector contains random values with a gaussian distribution subtract the mean and divide by the standard deviation to obtain a standard normal variable with a mean of 0 and a standard deviation of 1 equation 3 7 x n x i μ δ where n is the number of training cases x i is the value of the raw input variable x for the ith training case x n is the normalized value of x μ is the mean of data points and δ is the standard deviation of data points after data outliers were determined and data volatility reduction with normalization was conducted new datasets were created for both statistical and neural network model development the entire work process is shown as a cartographic model in fig 6 2 4 1 et and et parameter estimation model development 2 4 1 1 statistical modeling approach the ascii format of data from developed ndvi savi and vvi were used as input parameters for the lai output multivariate model development the gs linear regression model was developed using the band 4 spot band 5 landsat 7 etm and band 6 landsat 8 digital image information band 6 landsat 7 etm and band 10 landsat 8 digital image information were used for the canopy temperature estimation model development band 7 landsat 7 etm and band 7 landsat 8 were used for the development of sm remote estimation model table 2 shows the detailed image based parameters combination as input parameters for the et and et parameter estimation multivariate model development initial et estimation modeling was carried out using all of the digital image information discussed above simple regression analyses were conducted for the models using a single image factor ascii value the analyses were completed using the ms excel statistical tool pack the best fit trend line curves were developed along with the provision for the correlation algorithm equation and the coefficient of determination r2 value for the best fit models as described in table 2 initially all image based parameters were used as input parameters for et estimation model development for each watershed different vegetation covers backward step wise regression was used to obtain the best model input combination for each of the different watershed vegetation covers as there were a small number of variables to work with multicollinearity tests of the input parameters were completed separately for et estimation model development the analysis explained that red and nir near infrared bands are very similar and vvi is similar to ndvi which was supported by step wise regression modeling it should be noted that all of the digital image information and et and et parameter multivariate models were developed in the ms excel statistical tool pack s multivariate regression analysis tool using the appropriate parameters established through the multicollinearity analysis and step wise regression for the lai estimation models all three vegetation indices were used as input parameters to develop multiple regression models the p value statistics were used to test the null hypothesis that the coefficient is equal to zero no effect with low p value 0 05 it was understood that a predictor was meaningful to our models because changes in the predictor s value are related to changes in the response variable the model regression coefficients represent the mean change in the response variable for one unit of change in the predictor variable while holding other predictors as constant which is important in the analyses as it isolates the role of one variable from all of the others using regression coefficients we were able to develop the et parameters and et prediction algorithms that were useful in software development to predict et parameters and et with appropriate remotely sensed digital information when feasible when more data points were available the models that were developed with the 2012 and 2014 data were validated with the data from 2013 in some cases the model validations were completed with an extra mix of data from other years as enough data was not available from 2013 average absolute prediction accuracy aapa was computed for the validation models using equation 5 8 aapa 1 n 1 n a b s actual predicted a c t u a l 100 where n number of observations 2 5 artificial neural network modeling approach artificial neural network ann modeling techniques were adapted to enhance the remote estimation of et in pine switchgrass pine switchgrass intercropping and pine understory intercropping vegetation as statistical models for such et estimation proved to be inferior the rbfn modeling approach was used to develop such models a typical rbfn consists of three different layers with successive layers fully connected by feed forward arcs as shown in the rbfn model architecture pertaining to our research and in fig 7 there is no provision of weight between the input layer and the hidden layer prototype while a nonlinear transfer function i e radial basis function is used at the hidden layer fig 7 this study presents two input parameters landsat pc1 and 2 band digital information in the input layer as opposed to the rbfn model which includes just one hidden layer generally in the rbfn model the output layer is linear haykin 1999 but in this study the rbfn model was nonlinear due to the application of the gaussian transfer function in the network a step by step model optimization procedure was developed for this study following the procedural flow chart shown in panda et al 2010 to obtain the best correlation between input and output parameters in rbfn the learning rate momentum term and iteration rates were changed alternately to optimize the rbfn models so that optimal prediction accuracies were obtained the datasets for individual landuse based et and et parameters models were divided as a training and testing dataset with a random 70 30 percent ratio where feasible as in a few cases less than five data points available first the models were optimally trained then the testing data was used in both models to validate the optimal training model s estimation efficacy as discussed below also known as the rbfn model evaluation process the rbfn model performances were evaluated based on root mean square error rmse prediction accuracy and standard error of prediction sep moreover the correlation coefficient r between the actual and predicted output along with the slope and intercept of the linear regression model was used in model performance evaluations the equation for rmse is 9 r m s e m s e s s e n p where n is the number of observations p is the number of the parameter to be estimated and sse and mse are sum of squared errors and mean square error respectively average test prediction accuracy is calculated based on equation 10 where n is the total number of observations and opa and opp are actual and predicted output respectively 10 a v e r a g e t e s t a c c u r a c y 1 1 n i 1 n o p a o p p o p a 100 an executable file developed in the biolab of north dakota state university fargo nd using visual c microsoft corporation bellevue wa was used to determine the predicted et accuracy and the subsequent actual and predicted correlation coefficient r between the measured and predicted et and intercept a slope β and sep from the back propagation neural network result the predicted and actual output regression analysis was completed using the following linear equation 11 y βx a where x and y are predicted and actual output respectively β is slope and a is the intercept the sep of the predictive model is calculated by using the following equation by kramer et al 2001 12 i 1 n y i x i d m 2 n 1 where d m is the mean of the difference between actual and predicted values y and x of ith individual respectively and n is the total number of observations 2 5 1 software development the relationship between input and output data i e the statistical multiple regression correlation algorithms were used to develop executable files software in the object oriented programming language visual basics studios microsoft bellevue wa the executable files were created as forms so that they can be used by laypersons to estimate the pine pine switchgrass intercropped vegetation switchgrass and pine natural understory vegetation et and et parameters from image digital information by entering the input values in to designated text boxes and clicking on the calculate button 3 results and discussion 3 1 multicollinearity analysis on image bands for model development when one predictor variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy it creates a situation where the coefficient estimates may change erratically in response to small changes in the model or the data is the multicollinearity phenomenon pottel 2003 pottel 94 in his study on problems of using microsoft excel for statistics mentioned the advantage of performing multicollinearity analysis before performing multivariate regression the lai and et estimation models used multiple digital image parameters as explanatory variables therefore to ascertain the efficiency of each parameter in model development multicollinearity analyses were completed in ms excel statistical tool pack software results of a multicollinear analysis in table 3 revealed that savi and ndvi are essential pieces of information although similar for the model building in this study and have 96 percent collinearity therefore we have alternately used the information savi and ndvi in model development vvi image information has some degree of multicollinearity coefficient of 0 42 with both ndvi and savi multicollinearity analysis helped us determine the best bands to use in multivariate model development for lai and et estimation model development table 4 3 2 image information based et and et parameter lai gs tc and sm models 3 2 1 switchgrass only for remote estimation of the switchgrass only et parameters model development that uses landsat spot and orthoimagery digital information with an acceptable coefficient of determination lai r2 0 77 n 14 gs r2 0 70 n 18 tc r2 0 77 n 34 and sm r2 0 68 n 12 were obtained average prediction accuracies of 70 05 94 88 89 93 and 90 61 percent were obtained with the gs tc sm and lai models respectively table 4 the model result is based on the analyses of the validation dataset the model data were randomly separated as training data and testing data once the multivariate regression models were developed the algorithm using the input parameter coefficient and intercept coefficient for et or et parameter estimation was developed and the same algorithm was used to estimate the et or et parameter values a correlation analysis was created using the actual field data and the model based predicted data as the results of the validation model data the low correlation among the actual field data and the model based predicted data could be attributed to the inconsistent growth of switchgrass in the homogenous research plots and in the research plots where it was grown as an intercrop with young pine during the study period 2012 2014 the multivariate et estimation model provided r2 0 50 standard error of prediction sep 0 94 18 percent of the observed et average and an average prediction accuracy of 82 09 percent with n 55 for the estimation of et in switchgrass only plots the relatively poor performance could be attributed to the inconsistent spatial and temporal growth of switchgrass in those plots 3 2 2 switchgrass intercropped with pine remotely sensed image information that uses landsat spot and orthoimagery digital information for pine and switchgrass intercropped pine forest et parameter estimation models provided somewhat inferior model input output correlation i e coefficient of determination lai r2 0 59 n 24 gs r2 0 56 n 22 tc r2 0 81 n 36 and sm r2 0 10 n 4 values soil moisture remote estimation could not draw any statistical conclusion due to very small the sample size of only four average prediction accuracies of 54 55 85 28 70 64 and 88 07 percent were obtained with the gs tc and lai models respectively table 4 however a multivariate regression analysis to estimate the soil moisture amount in pine and switchgrass intercropping plots was completed using red nir ndvi and savi digital information instead of the natural band 7 landsat 7 etm and band 11 landsat 8 which yielded an significant improvement in sm estimation accuracy with an increase of r2 from 0 10 to 0 57 the et estimation model for switchgrass intercropping provided an r2 of 0 47 standard error of prediction sep 0 99 19 percent of observed et average and an average prediction accuracy of 81 44 percent with n 20 when using red nir and ndvi image information as input parameters the low correlation between the image input information and the et and et parameter values field measured data is due to the introduction of landsat image information to the model along with spot and orthoimages the pixel size 30 m of the landsat data and the field row spacing of the pine and switchgrass intercropping 6m did not match for intercropping spot mss images pan sharpened to 5m using the panchromatic image were useful to clearly differentiate the switchgrass row vegetation from the pine vegetation along with the orthoimagery spatial resolution 15 cm therefore landsat data should not be used in the model although it would decrease the number of input image variables in the study however we have included landsat based image information in the study thus obtained reduced model correlation furthermore it was concluded that landsat data should not be included in the switchgrass et or et parameter estimation in an intercropping perspective as the spacing of 6m is much lower than the 30m spatial resolution of landsat 3 2 3 pine and understory intercropping pine and understory intercropped et parameter remote estimation models that use landsat spot and orthoimagery digital information provided poor input output correlation with coefficients of determination values of i lai r2 0 28 n 27 ii gs r2 0 63 n 26 and iii tc r2 0 76 n 45 there was no soil moisture model developed for pine and understory intercropping the poor model correlation is attributed to the same factors previously discussed regarding switchgrass intercropped with pine the et estimation model developed for the young pine with natural understory watersheds provided an r2 of 0 48 and an average prediction accuracy of 81 41 percent with n 17 using red nir ndvi and savi image information as input parameters the multivariate model underpredicted in the majority of cases and 17 data points the low coefficient of determination obtained with this model for estimating et could be attributed to the heterogeneity of understory forest shrub species present in all pine with understory intercropping watersheds average prediction accuracy of et parameters exceeded 80 percent except for the gs and sm table 4 in this study the authors did not develop any et and et parameter estimation models for plots containing matured pine only however in another companion study the main authors of this study 15 have developed remote sensing based et and et parameter estimation models for plots containing matured pine only and have obtained significant input output correlations gs r2 0 61 n 37 tc r2 0 89 n 55 sm r2 0 33 n 39 and et r2 0 61 n 35 the authors attributed this to the homogeneity of the vegetation cover and the ability of the landsat 30 m images to comprehend the vegetation characteristics however in the intercropped sites the et parameter estimation input output correlations obtained were relatively satisfactory suggesting that remotely sensed digital information seems like a cost effective and efficient way of estimating et parameters for larger spatial coverage quickly through the et and et parameter models the authors address the methodological question of whether remotely sensed spectral bands can be useful for modeling evapotranspiration and its components for young pine with a recruited understory switchgrass and its intercropping between young pine beds the authors have concluded that for homogenous vegetation except the sm parameters all other et parameters discussed in this study and et itself can be estimated with algorithms developed using freely available medium resolution landsat images for intercropping vegetation high resolution images are required 3 3 rbfn models as discussed in the artificial neural network modeling approach section of the manuscript proper training and testing validation datasets were created for the rbfn model development the model parameters were set to optimum levels following the neural network optimization step by step approach in most modeling cases a learning coefficient of 0 5 a momentum term of 0 9 and 50 000 epochs were found to be optimum for the rbfn model architectures along with the learning rule of the delta rule algorithm and transfer function of sigmoid with few model optimizations completed the authors concluded that a learning coefficient of 0 5 a momentum term of 0 9 and epochs of 50 000 the learning rule of delta rule algorithm and a transfer function of sigmoid are optimal for this study s rbfn model development and thus used them for all of the models table 4 details the rbfn model architecture and its optimal functionality used while modeling along with model training and testing validation results for each landuses et and et parameter prediction table 4 contains the training and testing rmse data correlation rate actual versus desired classification rate value model prediction testing absolute error average accuracy and testing models actual versus predicted correlation coefficient r and sep values it was observed from the results with rbfn modeling pine and switchgrass only et canopy temperature lai and stomatal conductance could be estimated predicted well using the remotely sensed image information obviously with proper data mining table 4 more than 80 percent average testing model based prediction accuracies were obtained in those cases however the intermix landuses provided somewhat poorer testing prediction accuracies ranging from 60 to 80 percent the soil moisture prediction models like the statistical models did not provide any remarkable results attributed to the litter cover in the study area and the difficulty of satellite aerial platform based sensor data collection through the dense canopy in pine and pine intermix landuse sites it was also concluded that more data inclusion in a few of the models might enhance their ability to predict et and its parameters this procedure was developed as an alternative to the less complex simple and user friendly automated geospatial model and statistical model result supported executable file development approach to estimate et and its related parameters using remote sensing digital information as shown below however the ann model is not simple for lay users but forest managers with access to neural network software would likely be able to apply them for et and et parameter estimation from described landuses by using remotely sensed data 3 4 software development table 5 represents the multivariate model algorithms obtained to estimate et and et parameters for various vegetation treatment scenarios the equations algorithm in table 5 were used to develop executable files software to estimate daily et lai gs tc and sm parameters using the proper digital information the software will be available for public use as required in the github site https github com drsudhanshupanda software 3 5 uncertainty and limitations in this study use of daily et values for the watershed sites were obtained using an approximate method that used pet sm and field capacity as explained above unlike other similar studies 15 50 that compared the remote imagery based et with more accurate directly measured et by eddy covariance based methods this may have introduced some errors some other uncertainties might have arisen from the measurement of field et parameter data lai and gs including their estimates as watershed average from sample measurements which was acquired at approximately noon amatya et al 2016 in an attempt to coincide with the satellite or aerial image acquisition period sometimes there was a lag of as many as 2 3 days because of the field weather conditions authors in their laboratory conducted radiometric corrections for orthoimages whereas nasa completed corrections for the landsat images in house and astrium services inc completed corrections for the spot images with their own system this may have also introduced some errors the vegetation growth in the watersheds especially the switchgrass growth was uneven over the three years of research 2012 2014 switchgrass plots had sporadic coverage and therefore the image pixels were essentially mixed pixels mixels switchgrass and bare soil as described previously landsat images 30m resolution could not discern the vegetation in the intercropped plots therefore tools statistical models automated geospatial models and executable files may not be able to predict the daily average et and et parameters for various types of vegetation accurately however we attempted to produce estimations for et and et parameter values from remotely sensed image based digital information by combining different resolution images from three differing sites with topographic climate and environmental conditions it is likely that some errors were introduced due to the use of specific only bands in the analysis as well as our use of image processing software and instrumentation in the field 4 summary and conclusions intercropping switchgrass between tree rows in young pine plantations can increase bioenergy feedstock production without land opportunity costs however intercropping could have ecological consequences including altered water budgets due to the different et rates from different forest crops measurement of evapotranspiration et a significant component of any forest water budget across cropping systems is costly and time consuming so techniques for estimating et and its parameters from remotely sensed spectral bands could facilitate the assessment of relative et demands among competing forest land uses field and corresponding image data of various spatial and spectral resolutions were used within three environmentally diverse sites over a period of three years 2012 2014 to create robust multivariate models the models were trained with years 2012 and 2014 and validated tested with year 2013 data wherever feasible if enough data samples were available if enough data was not available the validation or testing data were picked randomly from the full dataset to ascertain the model efficiencies as shown in the results section it was observed from the study that canopy temperature of any vegetation could be accurately estimated with the tir bands of the images which is consistent with previous studies stomatal conductance and lai values even for the complex intercropped sites could be estimated with moderate accuracy using appropriate digital information evapotranspiration of switchgrass and its intercropping with pine could be reasonably well estimated using green red and nir band digital information along with ndvi and savi data the software developed using the obtained algorithm would help lay users to approximately estimate these ecohydrologic parameters of pine switchgrass and intercropping for appropriate management decisions in plantation forests with ease our study findings suggest that when more spatial variability sound data mining ultra high resolution imagery and advanced image processing approaches are included to account for potential modeling uncertainties they will enhance these environmental parameters remote estimation accuracy that said future studies using these remote sensing based et models should be further tested at multiple sites for quantifying the water use from switchgrass and or other similar cellulosic biofuels intercropped in pine forests separately by each vegetation and or in combination as a part of the regional water balance and resource assessment rbfn based models provided promising results for estimating et and et parameters using remotely sensed digital information prepared with data mining but it is assessed that lay persons may find it difficult to use however forest managers with access to neural network software can use our devised rbfn training models for estimating those forest hydrologic parameters with better accuracy acknowledgments the authors would like to express their sincere thanks to the united states department of energy for grant support of this study we acknowledge the support of numerous field crews weyerhaeuser personnel and undergraduate student assistants to complete the fieldwork and supporting in the image analyses we also sincerely acknowledge dr jami e nettles at weyerhaeuser company for her great support at various levels for completing this study and dr rhett jackson at university of georgia for support with some field data analysis for groundtruthing at ms and al study sites appendix b supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix b supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 07 012 appendix a python code for landsat 7 scanline correction image 1 
26144,intercropping switchgrass panicum virgatum with pine can increase bioenergy feedstock production without land opportunity costs but can potentially alter water budgets measuring evapotranspiration et and its parameters stomatal conductance gs leaf area index lai canopy temperature tc and soil moisture sm across cropping systems is costly and time consuming however interpretation of remotely sensed data can facilitate the effective assessment of relative et demands among competing forest landuses this study develops and tests geospatial models informed by a normalized difference vegetation index ndvi soil adjusted vegetation index savi vegetation vigor index vvi and other spectral information to estimate et and its parameters which are measured on experimental watersheds with young pines and natural understory yp switchgrass only sg and young pine intercropped with switchgrass ic the treatment watersheds were replicated on three sites located across the southeastern u s in carteret nc calhoun ms and greene al despite the growth inconsistency for the sg only treatment remote modeling estimation of et parameters yielded an acceptable r2 0 70 and the et model yielded r2 of 0 50 and a standard error of prediction of 0 94 however et and et parameter model estimation for the ic performed somewhat less satisfactorily with an r2 of 0 47 0 59 0 56 0 81 and 0 57 for et lai gs tc and sm respectively potentially due to inconsistencies in landsat image pixel size and landuse homogeneity moreover et parameter models for the yp site performed rather poorly with r2 0 28 0 63 and 0 76 for lai gs and tc respectively additionally image analysis automation was created with python scripting and geospatial models the findings from this study suggest that inclusion of more spatial variability sound data mining ultra high resolution imagery and advanced image processing approaches to account for potential modeling uncertainties can enhance the predictive capability of models to remotely estimate environmental parameters including et radial basis function network rbfn based models provided promising results for estimating et and et parameters using remotely sensed digital information when they are prepared with advanced data mining but it is likely that laypersons may find these models difficult to use however forest managers with access to neural network software can use our devised rbfn training models for estimating those forest hydrologic parameters with better accuracy keywords arcgis modelbuilder canopy temperature data mining evapotranspiration landsat orthoimagery python script rbfn software development soil moisture spot stomatal conductance visual basics studios 1 introduction the u s department of energy and the scientific community have a goal of producing biofuel from energy crops such as switchgrass panicum virgatum a cheaper alternative to row crops or other agricultural commodities like corn sweet sorghum sugarcane sugar beet crop residues and other woody biomass although crop residues and other woody biomass are abundantly available and much cheaper to procure than switchgrass they have their own downsides crop residues one source of soil organic carbon are essential for soil fertility enhancement and useful for soil erosion control increased water infiltration and evapotranspiration et reduction but need to be left in the field and tilled to provide a positive effect on crop production lal 2004 jarecki and lal 2003 in their review of next generation biomass feedstock for biofuel production simmons et al 2008 discussed the constraints of biofuel production from woody biomass and other agricultural products they suggested that the use of dedicated herbaceous perennial crops such as switchgrass perrin et al 2008 parrish and fike 2005 miscanthus sahoo et al 2018 and sorghum paterson et al 2008 would be better alternatives these herbaceous species can be grown in various regions of the united states u s fig 1 simmons et al 2008 recommended switchgrass cultivation as an understory in the row crop pine forests that are abundant in the southeastern united states pine plantations which constitute the plurality of croplands in vast areas across the southeastern united states from mississippi to north carolina are managed to produce lumber fiber for pulp paper cardboard and bioenergy feedstocks on a traditional pine plantation the space between rows has no economic value grasses that can serve as bioenergy feedstocks such as switchgrass could be intercropped between rows in pine plantations and grown until the closing canopy of the pines shades them out however such intercropping raises environmental and ecological questions regarding the water budgets of forest plantations is the evapotranspiration et of intercropped stands additive such that total et can be estimated based on pine and switchgrass et rates based on their relative coverage or does intercropping cause competition for water between the two crops such that the total et is less than the sum of et expected from the individual crops these questions have implications for regional water budgets under potential bioenergy development scenarios and for decisions about managing forestlands this study is part of a larger study examining how the establishment of these cropping systems affects stream flows surface and soil water quality and water budgets as discussed the addition of switchgrass understories in forest plantations like row pine would have ecological consequences especially if the switchgrass competes for soil water with the main forest crop using a soil plant atmosphere model parameterized with site specific data albaugh et al 2014 found increased et in the intercropped sites when compared to the mature pine or switchgrass only plots however the watershed scale et comparison data are lacking for switchgrass intercropping versus natural understory intercropping in pine forests therefore it is essential to quantify the amount of soil water used by switchgrass compared to row pine understories on a watershed scale plant and soil understory litter evaporation and transpiration or evapotranspiration et are major components of the hydrological cycle jaramillo and destouni 2015 studied 100 basins for actual et aet p variation with respect to flow regulation and irrigation impact and found a relatively large aet p increase in water limited basins including for a major portion of those basins in the united states global land cover changes impact the terrestrial water cycle et has a direct impact on hydrology crop growth and biomass production forest cover alteration including intercropping to accommodate switchgrass may change the et and water balance of these forest ecosystems sterling et al 2013 through their extensive study of 1500 estimates of annual evapotranspiration and corresponding global land cover change database projected a 5 percent decrease of global scale terrestrial evapotranspiration tet from the current anthropogenic land cover change mostly deforestation and an increase in tet with forest cover intensification an accurate estimation of et and its spatial and temporal distribution is of key importance for hydrological and meteorological applications including regional scale water balance sun et al 2011 the et rate of any ecosystem depends upon soil moisture and vegetation factors as well as climatic variables like air and canopy temperature radiation vapor pressure wind speed and the physical characteristics of the evaporating surface viessman and lewis 2003 while plant evaporation occurs mostly from above canopy interception as a function of canopy storage capacity and density amatya et al 1996 understory litter transpiration occurs by uptake and transport of water from the soil aquifer system by plant roots branches stems and eventually diffusing from plant leaves into the atmosphere senay et al 2013 et estimation from the forest cover would provide insight to the soil water use by different crops but it is a very cumbersome in situ based approach rapid accurate and cost effective estimation of et and its supporting parameters such as stomatal conductance gs leaf area index lai canopy temperature canopy albedo tc soil moisture sm and estimation of wind speed using remote sensing technology has become increasingly popular panda et al 2016 lai is defined as the single sided surface area of leaves per unit area of soil m2 m 2 and is a key parameter implicit in a variety of forest ecosystem processes including light and rain interception transpiration photosynthesis and soil heterotrophic respiration le maire et al 2006 lai is a seasonal parameter and is an indicator of crop growth thus et and lai correlate very well sun et al 2011 lai was also one of the hydrologic parameters recently discussed in parameterization guidelines and considerations for hydrologic models by malone et al 2015 optical indirect methods e g model lai 2200 plant canopy analyzer li cor lincoln ne or hemispherical photographs and semi direct methods using litter collection and allometric methods are used for local estimation of lai brauman et al 2012 le maire et al 2006 malone et al 2015 panda et al 2016 but these methods are time consuming cumbersome and costly according to hilker et al 2013 transpiration is directly linked to stomatal conductance gs local measurement of stomatal conductance is conducted by an indirect optical measurement malone et al 2015 or by a semi direct method using a vapor pressure deficit algorithm pearcy et al 1989 sampson et al 2011 but these methods are also costly and time consuming stomatal conductance of pine needles has been measured and used for estimating and modeling transpiration of pine forests amatya et al 1996 sack and scoffoni 2012 hilker et al 2013 suggested that satellite retrievals of photosynthesis or gross primary production gpp could be used to quantify transpiration rates through gs amatya and skaggs 2001 canopy conductance gc is generally approximated as a product of gs and lai amatya and harrison 2016 amatya et al 1996 brauman et al 2012 amatya and skaggs 2001 jensen et al 1990 nghi et al 2008 panda et al 2014 tian et al 2012 although the maximum stomatal conductance also may be estimated as a function of measured et vapor pressure deficit and other environmental variables morris et al 1998 as will be shown below canopy temperature can serve as a surrogate for the amount of evaporation and transpiration through the plant canopy and can be estimated with direct measurement using thermometers bastiaanssen et al 1998 forest soil moisture is generally estimated through instrumentation using a tensiometer and lysimeter olivera guerra et al 2015 van der ploeg and de rooij 2014 vasquez et al 2015 routine in situ measurement of plant hydrologic parameters is time consuming and expensive panda et al 2014 sampson et al 2011 majasalmi et al 2017 have a detailed review of the comparison of optical and allometric field instrumentation for forest hydrologic parameter estimation and are in favor of optical remote sensing approaches estimating forest et using remote sensing data is not a new concept there are many successful examples of using remotely sensed images to model et and water budgets for grasslands and crop lands chen et al 1997 feddema and eggbert 2005 johnson 2016 noori and panda 2016 panda et al 2009 rao et al 2006 schellberg et al 2008 tian et al 2013 turner et al 1999 wang and jia 2013 but such models have limitations for forests especially for understory in between forest rows as the satellites cannot see the ground or the understory in closed canopy forests and thus cannot sense either soil moisture or the spectral characteristics of the understory panda et al 2002 pisek et al 2015 2016 yang et al 2014a b 45 47 li and lyons 2002 used 1 1 km resolution noaa 14 avhrr remote sensing data to derive surface temperature which was combined with limited routine meteorological data like soil moisture to estimate the et rates in central australia with limited success cristobal and poystos 2011 tested the reliability of remote sensing data of terra and landsat to estimate forest vegetation et in the vallcebre research catchment in spain from 2003 to 2005 using 27 aqua modis images 11 landsat 7 and 10 landsat 5 images in comparison with stand transpiration obtained from sap flow measurements however even the best estimations of forest et obtained from landsat images had 30 percent uncertainty cristobal and poystos 2011 panda et al 2018 used cloud free landsat images from 2006 to 2014 and an advanced data mining approach to obtain principal component bands to correlate with et data they obtained a strong correlation between the remote digital information and the et of pine forest with a model r2 of 0 58 they panda et al 2018 used backpropagation neural network bpnn and radial basis function network rbfn models and obtained a testing validation average absolute error of 0 18 and 0 15 wm 2 and an average accuracy of 81 and 85 percent respectively the thermal band of landsat satellite imagery can be used to estimate canopy temperature lee 1994 panda et al 2016 senay et al 2013 satellite imagery approaches are generally based on the principles of the surface energy balance exploiting the remotely derived land surface temperature as a proxy indicator of surface water status cammalleri et al 2013 a review article by wang and qu 2009 explains how numerous studies have been conducted on the remote estimation of soil volumetric water content by using satellite aerial or simple digital photographic image analysis recent studies show that remotely sensed data especially freely available 30 m spatial resolution 16 day temporal resolution landsat thematic mapper tm images can be used to efficiently estimate gs canopy temperature lai and et of forest vegetation carter 1998 curran 1980 hafeez et al 2002 justice et al 1998 le maire et al 2006 moran et al 1994 north 2002 nouri et al 2012 olioso et al 1999 panda et al 2016 provoost et al 2005 rouse et al 1973 senay et al 2013 according to liou and kar 2014 and panda et al 2016 2018 traditional approaches for et estimation such as weighing lysimeter surface energy balance seb energy balance bowen ratio ebbr eddy covariance techniques pan measurement sap flow scintillometer water balance etc are mainly complex models and can estimate et on local field and landscape scales only over a homogeneous vegetation cover with high accuracy however such approaches cannot be directly extended to estimate the et rate of large areas of forest cover that contains natural heterogeneity and involves complex hydrologic processes due to costly and time consuming instrumentation processes idso et al 1975 panda et al 2016 zhang et al 2016 remotely sensed image data is being used for mapping regional and meso scale patterns of et and surface temperature which is helpful in establishing a direct link between surface radiances and energy balance components caselles et al 1992 glenn et al 2007 idso et al 1975 kustas and norman 1996 li et al 2009 long and singh 2013 moran et al 1989 panda et al 2016 2018 weigand and bartholic 1970 yang and shang 2013 zhang et al 2016 information embedded in satellite visible near infrared middle infrared and thermal infrared bands can be used to retrieve the land surface temperature lst vegetation index and atmospheric temperature and in turn supports et estimation for large spatial extents and with higher temporal frequencies liou and kar 2014 panda et al 2016 2018 zhang et al 2016 these studies clearly show that the remote sensing approach for estimating forest et and its contributing parameters has strong appeal since it eliminates laborious time consuming costly field methods which also have limitations in covering large areas and land cover heterogeneity majasalmi et al 2017 panda et al 2016 2018 the use of freely available moderate spatial resolution 30 m landsat data albaugh et al 2014 senay et al 2013 and five other even lower resolution global fractions of absorbed photosynthetically active radiation fpar in the wavelength region of 400 700 nm products like modis misr meris seawifs geov1 250 m 1 1 km has merit in estimating forest hydrologic parameters majasalmi et al 2015 tao et al 2015 verger et al 2015 yang et al 2014a b covering large spatial extents however one problem that has not yet been documented is that pine switchgrass intercropping widths 3 m cover areas smaller than the pixel scale 30 m of landsat 7 and 8 images this study addresses the methodological question of whether remotely sensed spectral bands can be useful for modeling evapotranspiration and its components for young loblolly pine with a recruited understory switchgrass and its intercropping between young pine beds and explain the amount of water use by landuse types 1 pine plantations intercropped with switchgrass and pine plantations intercropped with understories the goal of this study was to develop and test object oriented software to estimate the gs tc sm lai and et values of pine switchgrass and pine intercropped with switchgrass as well as understory the specific objectives of the study were to develop 1 multivariate regression models using remotely sensed imagery based digital information as predictor variable to estimate the gs tc sm lai and et respectively as outcome variables 2 artificial neural networks ann models using remotely sensed imagery based digital information rbfn algorithms to predict homogenous pine and switchgrass et and the et of pine intercropped with switchgrass as well as understory respectively 3 executable software using the multivariate regression analyses based algorithms automated geospatial models and python scripts for endusers to apply for their application and usage 2 materials and methods 2 1 study sites description the sites included in this research are environmentally diverse i carteret nc a topographically flat well managed coastal forest fig 2 a ii calhoun ms an upland inland forest with microtopography fig 2b and iii greene al a moderate to steep sloped inland old forest ecosystem fig 2c all three sites were established to investigate the environmental sustainability of intercropping switchgrass as a cellulosic biofuel between pine tree rows without using the land for food inside a managed pine forest owned and managed by weyerhaeuser to produce timber wood fiber and biofuel feedstock bennett et al 2013 muwamba et al 2015 each site has a minimum of four watersheds with four distinct vegetation treatments i mature row crop pine only ii young pine and switchgrass intercropping 6 m spacing between pine beds with 3m for switchgrass iii pine and understory intercropping 6 m spacing between pine beds with 3m for switchgrass and iv switchgrass only fig 3 each of the sites in greene county al and calhoun county ms has an additional reference watershed with a mid rotation pine forest not shown in fig 2 the experimental watersheds d0 d1 d2 and d3 in carteret county nc 34 49 n 76 40 w are 26 0 26 3 25 9 and 27 1 ha respectively fig 2 d0 is the watershed with young pine mixed with understory d1 is a watershed with pine intercropped with switchgrass d2 has mid rotation thinned pine with a natural understory as a reference and the fourth watershed d3 is switchgrass only the northern southern and western sides of the study site are fully covered by forest and the east side is dominated by agricultural land the carteret site topography is characterized by flat coastal plain at a 0 1 percent gradient and is at 3 m elevation above mean sea level mccarthy et al 1991 deloss fine sandy loam soil a fine loamy mixed thermic typic umbraquult that has poor drainage with shallow water tables and a ph range of 3 5 4 5 acidic represents the soil of the carteret study site amatya et al 1998 beltran et al 2010 the long term mean annual precipitation and penman monteith grass reference evapotranspiration at the study site are 1517 mm and 1010 mm respectively amatya and skaggs 2011 in greene county northwest alabama there are five watersheds fig 2c labeled gr1 gr stands for greene county gr2 gr3 and gr4 with areas of 11 6 26 7 25 9 and 16 5 respectively and a reference site grref that measures 6 8 ha bennett et al 2013 by 2014 6 year old matured pine stands with understories were established in gr1 that same year gr2 also had a 6 year old young pine stand with understory and gr3 had 8 yr old pine and switchgrass intercropping only switchgrass was grown in the gr4 watershed and grref not used in the study contained 20 yr old mid rotation matured pine the soils in the watersheds are a combination of falaya fine sandy loam thermic aeric fluvaquent somewhat poorly drained with a water table within 20 inches slopes from 0 to 2 percent magnolia fine sandy loam mesic typic pleudalf well drained with slopes from 0 to 25 percent and shatuba fine sandy loam thermic typic paleudult well drained with slopes from 1 to 12 percent bennett et al 2013 the erosion risk on the watersheds varied from high on gr1 to low on gr3 and gr4 the slope of the site watersheds varies from 9 9 to 12 7 percent the drainage at the outlets was measured using a flow meter located within a flume structure designed using the winflume design program the average pet of the watersheds varies from 1322 to 1471 mm while the pet of the grref reference watershed was 1600 mm bennett et al 2013 average annual precipitation of the greene county site was 1361 mm in calhoun county ms there are also five watersheds fig 2b labeled bf1 bf stands for befontaine bf2 bf3 bf4 and bfref not shown in the figure and not used in the study with areas of 14 1 12 8 10 9 15 2 and 12 6 ha respectively by 2014 bf1 was a 7 yr old young pine stand with natural understory bf2 was a pine stand thinned in 2007 with switchgrass intercropping bf4 was a 8 yr old pine also intercropped with switchgrass and bf3 was switchgrass only bf5 was a mid rotation pine stand planted in 1995 the soils at the site are a combination of cuthbert fine sandy loam thermic typic hapludult well drained with a water table at or below 2 m slopes 8 to 25 percent dulac silt loam thermic oxyaquic fragiudalf well drained with a water table at or below 2 m slopes 0 to 12 percent ruston fine sandy loam thermic typic paleudults well drained with a water table at or below 2 m slopes 0 to 8 percent providence silt loam thermic oxyaquic fragiudalf moderately well drained with a water table around 0 5 m slopes 0 to 15 percent waverly silt loam thermic fluvaquentic poorly drained with a water table from the surface to 0 4 m slopes 0 to 2 percent and gullied land half of the soils are classified as severely eroded drainage at the outlets was measured using a flow meter located within a flume structure designed using the winflume design program the site has an annual average temperature precipitation and potential evapotranspiration of 16 5 c 1405 mm and 1350 mm respectively 2 2 instrumentation and field data collection 2 2 1 field et calculation procedure at all of the study sites weather data were collected every 15 min by weather stations fitted with hobo u30 cellular data logger onset cape cod ma usa which were located in the proximity of the switchgrass only watersheds the weather data collected for analyses in this study included precipitation mm atmospheric pressure kpa solar radiation w m 2 wind speed m s 1 gust speed m s 1 wind direction temperature c and relative humidity each watershed was equipped with decagon soil moisture probes model 5tm connected to a campbell scientific data logger model cr200 at four depths 15 cm 30 cm 60 cm and 80 cm on the beds in tree rows and in between beds on furrows at two specific spatial locations fig 4 for real time monitoring of soil moisture daily weather data with field measured vegetation parameters on lai and maximum stomatal conductance gs were used to compute the pet with the penman monteith p m method however p m pet for a standard grass reference was used for switchgrass as there was only a limited data on its conductance actual et aet on each treatment watershed was estimated following the method developed by fisher et al 2005 as shown in equation 1 1 aet f pet where f is a soil moisture factor and pet is daily p m based potential evapotranspiration the factor f limited by soil moisture in the root zone was calculated as sm sm100 where sm daily average soil moisture measured at each treatment watershed and sm100 soil moisture content at 100 cm pressure head or 10 kpa which was estimated based on soil water characteristic data soil moisture characteristics were derived at the north carolina state university soil and water laboratory using undisturbed field soil core samples taken at each of the treatment watersheds during the study period this component of aet limited by energy component pet was assumed to represent only soil evaporation and vegetation transpiration evaporation from canopy interception was estimated separately for the mature pine stand and was assumed negligible for other treatment watersheds the detailed field hydro meteorological measurements and data analysis procedures for the study site in north carolina have been recently reported by ssegane et al 2017 and by bennett et al 2013 for the alabama site the mississippi site has a similar measurement protocol as that of the al site 2 2 2 field et parameters data collection methods field data lai gs tc and sm were collected from 2012 to 2014 which coincided with the satellite and aerial image acquisition periods a licor 2000 instrument was used in the field for in situ lai measurement of individual forest species such as pine young and matured switchgrass and understories a licor 1600 porometer field instrument was used to collect gs values for each species of vegetation a decagon portable volumetric water content measuring instrument was used to collect spatial soil moisture data in each watershed to supplement the soil moisture data recorded at specific locations in the watersheds as described above fig 4 the air temperature measured at the site weather station was assumed as a proxy for the tc data as the sensor height mostly coincided with the height of young pine switchgrass and understories the above field measured data and estimated daily aet as described earlier were used as output parameters for validation of the remote sensing digital information based et and et parameter estimation model development 2 3 image acquisition and processing 2 3 1 image selection digital information from free remotely sensed images like the landsat 7 etm and landsat 8 30m along with acquired spot 10m multispectral mss and ultra high resolution 4 band orthoimagery 0 15m images were used in the study to extract spectral band information as input model parameters to estimate the et and et parameters for the four types of vegetation landsat images were chosen as the source of spectral bands for analysis as they are free easily downloadable and can be easily processed due to the fact that the geometric and radiometric correction https earthexplorer usgs gov has already been completed the landsat images have a moderate spatial resolution of 30m and they cover the homogenous pine and switchgrass vegetation spatial area uniformly landsat imageries have a temporal resolution of 16 days as both landsat 7 etm and landsat 8 images were acquired in the same year part of 2013 and 2014 the temporal resolution period was reduced to eight days thus the et variation in the vegetation could be determined approximately twice monthly and in some cases four times a month capturing seasonal variation landsat images have complete required spectral resolution for et estimation have individual bands suitable to estimate the eco hydrologic parameters related to et and et parameters fig 5 landsat images also have simple radiometric resolution i e 8 bit for landsat 7 etm and 16 bit for landsat 8 which both require extra processing to make the imagery data compatible for model development along with the freely available cloud free landsat images spot images were acquired table 1 through astrium services richmond va usa to analyze the intercropped vegetation young pine understory and young pine switchgrass spot imageries were acquired at a cheaper cost when compared to other similar or slightly better higher spatial resolution imageries another advantage of using the spot imagery was the availability of spectral bands fig 5 that are suitable to estimate the eco hydrologic parameters related to et and et parameters under study the biggest advantage of using the astrium services images is that they radiometrically corrected the spot images before providing them to their users processed enhancing spatial resolution to explain a 6 m spaced intercropping of pine and switchgrass understory rows spot imageries were suitable for intercropped switchgrass eco hydrologic parameter estimation through model development ultra high 0 15m resolution orthoimages were collected for all three sites table 1 through quantum geospatial inc atlanta norcross usa to correlate with the localized et and et parameter lai and gs data that were collected on a transect basis coinciding with the date of image acquisition 2 3 2 image processing 2 3 2 1 geometric and radiometric correction geometric correction of the spot images was completed using the georeferencing tools available with arcgis 10 5 software redlands ca usa ground control points gcp road cross sections river bends and some monument locations were obtained from the referenced naip imageries of the study area to help in the geometric correction however geometrical correction of the orthoimages was completed using the gcps set up in the field before the image acquisition colored plates with known reflectance values were placed in the field as ground control points with known coordinates colored plates image reflectance values were correlated with the actual values to develop an algorithm which in turn was applied to the orthoimages through raster calculator for radiometric correction we followed the procedure developed by panda 2002 and panda et al 2010 it is to be noted that landsat imageries were geometrically and radiometrically corrected before being disseminated to the public and the spot images were acquired with completed radiometric correction 2 3 2 2 image fusion approach for spatial resolution set up spot mss images have a 10m resolution while spot panchromatic images have 5m resolution pansharpening erdas imagine with a modified intensity hue saturation resolution merge algorithm and resample arcgis 10 5 tools were used to have 5m resolution spot mss available to us for our study the spot mss 5m matched well to the 6 m spacing between the pine trees in the intercropped site orthoimageries used in the study to increase the acquired data numbers acquisition was completed during the time different from landsat and spot were of 15 cm resolution for et and et parameter estimation modeling they were resampled pansharpened to 5m resolution resampled spot and orthoimageries digital data were used for pine switchgrass and pine understory intercropped model development this image fusion technique helped in enhancing data numbers for effective model and subsequent algorithm development in studied landuses et and et parameter estimation using remotely sensed data 2 3 2 3 scanlines correction image masking image index development and digital ascii value extraction automation scanlines exists with raw landsat 7 etm images therefore a python script appendix a was written to remove them scanlines are nodata values inside images the python script took a 15 15 neighborhood of pixels specified using the focal statistics tool of arcgis and calculated the mean value of these 225 pixels and added inserted them in place of the nodata values of the image the script also did the batch processing for all landsat 7 etm image scanline corrections all processed images landsat 7 etm and 8 spot and orthoimagery were clipped to individual watersheds as the initial models were developed with the entire spatial extent for each of the watershed s prescribed vegetation covers fig 2 individual bands were separated from the composite image for spot and orthoimagery landsat bands were individually stacked when downloaded from the earth explorer https earthexplorer usgs gov site using the arccatalog band separation tool vegetation indices were developed using equation 2 for the normalized difference vegetation index ndvi equation 3 for the soil adjusted vegetation index savi and equation 4 for the vegetation vigor index vvi 2 ndvi ρ ir ρ r ρ ir ρ r 3 s a v i ρ i r ρ r ρ i r ρ r l 1 l 4 vvi ρ ir ρ g ρ ir ρ g where ρr ρg and ρir are spectral reflectance from the red green and nir band images as shown in fig 4 respectively and the l is a constant that represents the vegetation density huete 1988 defined the optimal adjustment factor of l 0 25 for higher vegetation density in the field l 0 5 for intermediate vegetation density and l 1 for low vegetation density automated geospatial models were developed in the arcgis modelbuilder platform to automate the spectral vegetation image development it is to be noted that image rasters in arcgis software are considered as integer data type rasters and therefore indices development using equations 2 4 using direct raster bands would not yield correct index images with decimal data type pixel asciis therefore during the model building in arcgis modelbuilder each of the image raster bands were converted to float data type rasters and the float data type rasters were used in the raster calculator tool to generate the index rasters all of the input band and index images were extracted to the watershed sizes using scripts written in python and the script helped in batch processing too a python script was written to automate and batch process the processed images to obtain watershed average digital ascii values through zonal statistics and use them as input parameters in the model development for estimated et and et parameters some data gaps were there due to possible field instrument malfunction during data collection weather anomalies and other human error in field measurements a detailed data mining approach was followed as shown in below subsection to prepare appropriate data for the modeling development with statistical and ann approaches panda et al 2018 2 4 data mining approaches for model data preparation preprocessing of input data was completed with the following methods generally missing values in a dataset are filled in through the use of the attribute mean of the dataset han and kamber 2001 most probable value han and kamber 2001 or a global constant han and kamber 2001 though for a few the mean of the group was used to fill the missing numbers for our datasets few outliers in our datasets were observed with initial visual interpretation however they were ascertained by a separability function a higher separability value suggested a great degree of distinctness in groups the separability equation used was represented as follows 5 v μ i μ j δ i δ j where μi is the mean of the group i μj is the mean of the group j δi is the standard deviation of the data in group i and δj is the standard deviation of the data in group j group i was the digital values obtained through image fusion and other analyses approaches described earlier and group j included the corresponding et and other et parameter values the authors did not envision any data volatility due to drastic weather changes during the three year study because data was collected in favorable weather conditions testing for data integration was essential for our datasets as the imagery data were collected from four different sources landsat 7 etm landsat 8 spot and aerial along with et and et parameters data with instrumentation thus proper integration of these various datasets was needed in order for the data to work as a single entity which assisted in bringing the digital data into a similar range as the landsat 7 dn reflectance percentage values of 0 255 8 bit data and the landsat 8 digital values of 0 65535 16 bit data panda et al 2018 thus the correlation between attributes a image data and b et and et parameters data was obtained by the following formulae 6 r a b a a b b n 1 σ a σ b where n is the number of data points a and b are means of two different attribute values and σ a and σ b are standard deviations of the respective attribute values when the value of r a b was greater than 0 and a and b were positively correlated the formula resulted in a high value and thus implied redundancy in the attributes we also completed data transformation for our study due to data volatility as described above therefore to enable the dataset to be ann model friendly data normalization was completed with our dataset to bring the image digital values and et and et parameter values into similar ranges in the neural networks literatures data normalizing also often refers to rescaling the vector by the minimum and the range to make all elements lie between 0 and 1 panda et al 2018 explained in their study that data normalization is generally completed by subtracting a measure of location and dividing by a measure of scale e g if the vector contains random values with a gaussian distribution subtract the mean and divide by the standard deviation to obtain a standard normal variable with a mean of 0 and a standard deviation of 1 equation 3 7 x n x i μ δ where n is the number of training cases x i is the value of the raw input variable x for the ith training case x n is the normalized value of x μ is the mean of data points and δ is the standard deviation of data points after data outliers were determined and data volatility reduction with normalization was conducted new datasets were created for both statistical and neural network model development the entire work process is shown as a cartographic model in fig 6 2 4 1 et and et parameter estimation model development 2 4 1 1 statistical modeling approach the ascii format of data from developed ndvi savi and vvi were used as input parameters for the lai output multivariate model development the gs linear regression model was developed using the band 4 spot band 5 landsat 7 etm and band 6 landsat 8 digital image information band 6 landsat 7 etm and band 10 landsat 8 digital image information were used for the canopy temperature estimation model development band 7 landsat 7 etm and band 7 landsat 8 were used for the development of sm remote estimation model table 2 shows the detailed image based parameters combination as input parameters for the et and et parameter estimation multivariate model development initial et estimation modeling was carried out using all of the digital image information discussed above simple regression analyses were conducted for the models using a single image factor ascii value the analyses were completed using the ms excel statistical tool pack the best fit trend line curves were developed along with the provision for the correlation algorithm equation and the coefficient of determination r2 value for the best fit models as described in table 2 initially all image based parameters were used as input parameters for et estimation model development for each watershed different vegetation covers backward step wise regression was used to obtain the best model input combination for each of the different watershed vegetation covers as there were a small number of variables to work with multicollinearity tests of the input parameters were completed separately for et estimation model development the analysis explained that red and nir near infrared bands are very similar and vvi is similar to ndvi which was supported by step wise regression modeling it should be noted that all of the digital image information and et and et parameter multivariate models were developed in the ms excel statistical tool pack s multivariate regression analysis tool using the appropriate parameters established through the multicollinearity analysis and step wise regression for the lai estimation models all three vegetation indices were used as input parameters to develop multiple regression models the p value statistics were used to test the null hypothesis that the coefficient is equal to zero no effect with low p value 0 05 it was understood that a predictor was meaningful to our models because changes in the predictor s value are related to changes in the response variable the model regression coefficients represent the mean change in the response variable for one unit of change in the predictor variable while holding other predictors as constant which is important in the analyses as it isolates the role of one variable from all of the others using regression coefficients we were able to develop the et parameters and et prediction algorithms that were useful in software development to predict et parameters and et with appropriate remotely sensed digital information when feasible when more data points were available the models that were developed with the 2012 and 2014 data were validated with the data from 2013 in some cases the model validations were completed with an extra mix of data from other years as enough data was not available from 2013 average absolute prediction accuracy aapa was computed for the validation models using equation 5 8 aapa 1 n 1 n a b s actual predicted a c t u a l 100 where n number of observations 2 5 artificial neural network modeling approach artificial neural network ann modeling techniques were adapted to enhance the remote estimation of et in pine switchgrass pine switchgrass intercropping and pine understory intercropping vegetation as statistical models for such et estimation proved to be inferior the rbfn modeling approach was used to develop such models a typical rbfn consists of three different layers with successive layers fully connected by feed forward arcs as shown in the rbfn model architecture pertaining to our research and in fig 7 there is no provision of weight between the input layer and the hidden layer prototype while a nonlinear transfer function i e radial basis function is used at the hidden layer fig 7 this study presents two input parameters landsat pc1 and 2 band digital information in the input layer as opposed to the rbfn model which includes just one hidden layer generally in the rbfn model the output layer is linear haykin 1999 but in this study the rbfn model was nonlinear due to the application of the gaussian transfer function in the network a step by step model optimization procedure was developed for this study following the procedural flow chart shown in panda et al 2010 to obtain the best correlation between input and output parameters in rbfn the learning rate momentum term and iteration rates were changed alternately to optimize the rbfn models so that optimal prediction accuracies were obtained the datasets for individual landuse based et and et parameters models were divided as a training and testing dataset with a random 70 30 percent ratio where feasible as in a few cases less than five data points available first the models were optimally trained then the testing data was used in both models to validate the optimal training model s estimation efficacy as discussed below also known as the rbfn model evaluation process the rbfn model performances were evaluated based on root mean square error rmse prediction accuracy and standard error of prediction sep moreover the correlation coefficient r between the actual and predicted output along with the slope and intercept of the linear regression model was used in model performance evaluations the equation for rmse is 9 r m s e m s e s s e n p where n is the number of observations p is the number of the parameter to be estimated and sse and mse are sum of squared errors and mean square error respectively average test prediction accuracy is calculated based on equation 10 where n is the total number of observations and opa and opp are actual and predicted output respectively 10 a v e r a g e t e s t a c c u r a c y 1 1 n i 1 n o p a o p p o p a 100 an executable file developed in the biolab of north dakota state university fargo nd using visual c microsoft corporation bellevue wa was used to determine the predicted et accuracy and the subsequent actual and predicted correlation coefficient r between the measured and predicted et and intercept a slope β and sep from the back propagation neural network result the predicted and actual output regression analysis was completed using the following linear equation 11 y βx a where x and y are predicted and actual output respectively β is slope and a is the intercept the sep of the predictive model is calculated by using the following equation by kramer et al 2001 12 i 1 n y i x i d m 2 n 1 where d m is the mean of the difference between actual and predicted values y and x of ith individual respectively and n is the total number of observations 2 5 1 software development the relationship between input and output data i e the statistical multiple regression correlation algorithms were used to develop executable files software in the object oriented programming language visual basics studios microsoft bellevue wa the executable files were created as forms so that they can be used by laypersons to estimate the pine pine switchgrass intercropped vegetation switchgrass and pine natural understory vegetation et and et parameters from image digital information by entering the input values in to designated text boxes and clicking on the calculate button 3 results and discussion 3 1 multicollinearity analysis on image bands for model development when one predictor variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy it creates a situation where the coefficient estimates may change erratically in response to small changes in the model or the data is the multicollinearity phenomenon pottel 2003 pottel 94 in his study on problems of using microsoft excel for statistics mentioned the advantage of performing multicollinearity analysis before performing multivariate regression the lai and et estimation models used multiple digital image parameters as explanatory variables therefore to ascertain the efficiency of each parameter in model development multicollinearity analyses were completed in ms excel statistical tool pack software results of a multicollinear analysis in table 3 revealed that savi and ndvi are essential pieces of information although similar for the model building in this study and have 96 percent collinearity therefore we have alternately used the information savi and ndvi in model development vvi image information has some degree of multicollinearity coefficient of 0 42 with both ndvi and savi multicollinearity analysis helped us determine the best bands to use in multivariate model development for lai and et estimation model development table 4 3 2 image information based et and et parameter lai gs tc and sm models 3 2 1 switchgrass only for remote estimation of the switchgrass only et parameters model development that uses landsat spot and orthoimagery digital information with an acceptable coefficient of determination lai r2 0 77 n 14 gs r2 0 70 n 18 tc r2 0 77 n 34 and sm r2 0 68 n 12 were obtained average prediction accuracies of 70 05 94 88 89 93 and 90 61 percent were obtained with the gs tc sm and lai models respectively table 4 the model result is based on the analyses of the validation dataset the model data were randomly separated as training data and testing data once the multivariate regression models were developed the algorithm using the input parameter coefficient and intercept coefficient for et or et parameter estimation was developed and the same algorithm was used to estimate the et or et parameter values a correlation analysis was created using the actual field data and the model based predicted data as the results of the validation model data the low correlation among the actual field data and the model based predicted data could be attributed to the inconsistent growth of switchgrass in the homogenous research plots and in the research plots where it was grown as an intercrop with young pine during the study period 2012 2014 the multivariate et estimation model provided r2 0 50 standard error of prediction sep 0 94 18 percent of the observed et average and an average prediction accuracy of 82 09 percent with n 55 for the estimation of et in switchgrass only plots the relatively poor performance could be attributed to the inconsistent spatial and temporal growth of switchgrass in those plots 3 2 2 switchgrass intercropped with pine remotely sensed image information that uses landsat spot and orthoimagery digital information for pine and switchgrass intercropped pine forest et parameter estimation models provided somewhat inferior model input output correlation i e coefficient of determination lai r2 0 59 n 24 gs r2 0 56 n 22 tc r2 0 81 n 36 and sm r2 0 10 n 4 values soil moisture remote estimation could not draw any statistical conclusion due to very small the sample size of only four average prediction accuracies of 54 55 85 28 70 64 and 88 07 percent were obtained with the gs tc and lai models respectively table 4 however a multivariate regression analysis to estimate the soil moisture amount in pine and switchgrass intercropping plots was completed using red nir ndvi and savi digital information instead of the natural band 7 landsat 7 etm and band 11 landsat 8 which yielded an significant improvement in sm estimation accuracy with an increase of r2 from 0 10 to 0 57 the et estimation model for switchgrass intercropping provided an r2 of 0 47 standard error of prediction sep 0 99 19 percent of observed et average and an average prediction accuracy of 81 44 percent with n 20 when using red nir and ndvi image information as input parameters the low correlation between the image input information and the et and et parameter values field measured data is due to the introduction of landsat image information to the model along with spot and orthoimages the pixel size 30 m of the landsat data and the field row spacing of the pine and switchgrass intercropping 6m did not match for intercropping spot mss images pan sharpened to 5m using the panchromatic image were useful to clearly differentiate the switchgrass row vegetation from the pine vegetation along with the orthoimagery spatial resolution 15 cm therefore landsat data should not be used in the model although it would decrease the number of input image variables in the study however we have included landsat based image information in the study thus obtained reduced model correlation furthermore it was concluded that landsat data should not be included in the switchgrass et or et parameter estimation in an intercropping perspective as the spacing of 6m is much lower than the 30m spatial resolution of landsat 3 2 3 pine and understory intercropping pine and understory intercropped et parameter remote estimation models that use landsat spot and orthoimagery digital information provided poor input output correlation with coefficients of determination values of i lai r2 0 28 n 27 ii gs r2 0 63 n 26 and iii tc r2 0 76 n 45 there was no soil moisture model developed for pine and understory intercropping the poor model correlation is attributed to the same factors previously discussed regarding switchgrass intercropped with pine the et estimation model developed for the young pine with natural understory watersheds provided an r2 of 0 48 and an average prediction accuracy of 81 41 percent with n 17 using red nir ndvi and savi image information as input parameters the multivariate model underpredicted in the majority of cases and 17 data points the low coefficient of determination obtained with this model for estimating et could be attributed to the heterogeneity of understory forest shrub species present in all pine with understory intercropping watersheds average prediction accuracy of et parameters exceeded 80 percent except for the gs and sm table 4 in this study the authors did not develop any et and et parameter estimation models for plots containing matured pine only however in another companion study the main authors of this study 15 have developed remote sensing based et and et parameter estimation models for plots containing matured pine only and have obtained significant input output correlations gs r2 0 61 n 37 tc r2 0 89 n 55 sm r2 0 33 n 39 and et r2 0 61 n 35 the authors attributed this to the homogeneity of the vegetation cover and the ability of the landsat 30 m images to comprehend the vegetation characteristics however in the intercropped sites the et parameter estimation input output correlations obtained were relatively satisfactory suggesting that remotely sensed digital information seems like a cost effective and efficient way of estimating et parameters for larger spatial coverage quickly through the et and et parameter models the authors address the methodological question of whether remotely sensed spectral bands can be useful for modeling evapotranspiration and its components for young pine with a recruited understory switchgrass and its intercropping between young pine beds the authors have concluded that for homogenous vegetation except the sm parameters all other et parameters discussed in this study and et itself can be estimated with algorithms developed using freely available medium resolution landsat images for intercropping vegetation high resolution images are required 3 3 rbfn models as discussed in the artificial neural network modeling approach section of the manuscript proper training and testing validation datasets were created for the rbfn model development the model parameters were set to optimum levels following the neural network optimization step by step approach in most modeling cases a learning coefficient of 0 5 a momentum term of 0 9 and 50 000 epochs were found to be optimum for the rbfn model architectures along with the learning rule of the delta rule algorithm and transfer function of sigmoid with few model optimizations completed the authors concluded that a learning coefficient of 0 5 a momentum term of 0 9 and epochs of 50 000 the learning rule of delta rule algorithm and a transfer function of sigmoid are optimal for this study s rbfn model development and thus used them for all of the models table 4 details the rbfn model architecture and its optimal functionality used while modeling along with model training and testing validation results for each landuses et and et parameter prediction table 4 contains the training and testing rmse data correlation rate actual versus desired classification rate value model prediction testing absolute error average accuracy and testing models actual versus predicted correlation coefficient r and sep values it was observed from the results with rbfn modeling pine and switchgrass only et canopy temperature lai and stomatal conductance could be estimated predicted well using the remotely sensed image information obviously with proper data mining table 4 more than 80 percent average testing model based prediction accuracies were obtained in those cases however the intermix landuses provided somewhat poorer testing prediction accuracies ranging from 60 to 80 percent the soil moisture prediction models like the statistical models did not provide any remarkable results attributed to the litter cover in the study area and the difficulty of satellite aerial platform based sensor data collection through the dense canopy in pine and pine intermix landuse sites it was also concluded that more data inclusion in a few of the models might enhance their ability to predict et and its parameters this procedure was developed as an alternative to the less complex simple and user friendly automated geospatial model and statistical model result supported executable file development approach to estimate et and its related parameters using remote sensing digital information as shown below however the ann model is not simple for lay users but forest managers with access to neural network software would likely be able to apply them for et and et parameter estimation from described landuses by using remotely sensed data 3 4 software development table 5 represents the multivariate model algorithms obtained to estimate et and et parameters for various vegetation treatment scenarios the equations algorithm in table 5 were used to develop executable files software to estimate daily et lai gs tc and sm parameters using the proper digital information the software will be available for public use as required in the github site https github com drsudhanshupanda software 3 5 uncertainty and limitations in this study use of daily et values for the watershed sites were obtained using an approximate method that used pet sm and field capacity as explained above unlike other similar studies 15 50 that compared the remote imagery based et with more accurate directly measured et by eddy covariance based methods this may have introduced some errors some other uncertainties might have arisen from the measurement of field et parameter data lai and gs including their estimates as watershed average from sample measurements which was acquired at approximately noon amatya et al 2016 in an attempt to coincide with the satellite or aerial image acquisition period sometimes there was a lag of as many as 2 3 days because of the field weather conditions authors in their laboratory conducted radiometric corrections for orthoimages whereas nasa completed corrections for the landsat images in house and astrium services inc completed corrections for the spot images with their own system this may have also introduced some errors the vegetation growth in the watersheds especially the switchgrass growth was uneven over the three years of research 2012 2014 switchgrass plots had sporadic coverage and therefore the image pixels were essentially mixed pixels mixels switchgrass and bare soil as described previously landsat images 30m resolution could not discern the vegetation in the intercropped plots therefore tools statistical models automated geospatial models and executable files may not be able to predict the daily average et and et parameters for various types of vegetation accurately however we attempted to produce estimations for et and et parameter values from remotely sensed image based digital information by combining different resolution images from three differing sites with topographic climate and environmental conditions it is likely that some errors were introduced due to the use of specific only bands in the analysis as well as our use of image processing software and instrumentation in the field 4 summary and conclusions intercropping switchgrass between tree rows in young pine plantations can increase bioenergy feedstock production without land opportunity costs however intercropping could have ecological consequences including altered water budgets due to the different et rates from different forest crops measurement of evapotranspiration et a significant component of any forest water budget across cropping systems is costly and time consuming so techniques for estimating et and its parameters from remotely sensed spectral bands could facilitate the assessment of relative et demands among competing forest land uses field and corresponding image data of various spatial and spectral resolutions were used within three environmentally diverse sites over a period of three years 2012 2014 to create robust multivariate models the models were trained with years 2012 and 2014 and validated tested with year 2013 data wherever feasible if enough data samples were available if enough data was not available the validation or testing data were picked randomly from the full dataset to ascertain the model efficiencies as shown in the results section it was observed from the study that canopy temperature of any vegetation could be accurately estimated with the tir bands of the images which is consistent with previous studies stomatal conductance and lai values even for the complex intercropped sites could be estimated with moderate accuracy using appropriate digital information evapotranspiration of switchgrass and its intercropping with pine could be reasonably well estimated using green red and nir band digital information along with ndvi and savi data the software developed using the obtained algorithm would help lay users to approximately estimate these ecohydrologic parameters of pine switchgrass and intercropping for appropriate management decisions in plantation forests with ease our study findings suggest that when more spatial variability sound data mining ultra high resolution imagery and advanced image processing approaches are included to account for potential modeling uncertainties they will enhance these environmental parameters remote estimation accuracy that said future studies using these remote sensing based et models should be further tested at multiple sites for quantifying the water use from switchgrass and or other similar cellulosic biofuels intercropped in pine forests separately by each vegetation and or in combination as a part of the regional water balance and resource assessment rbfn based models provided promising results for estimating et and et parameters using remotely sensed digital information prepared with data mining but it is assessed that lay persons may find it difficult to use however forest managers with access to neural network software can use our devised rbfn training models for estimating those forest hydrologic parameters with better accuracy acknowledgments the authors would like to express their sincere thanks to the united states department of energy for grant support of this study we acknowledge the support of numerous field crews weyerhaeuser personnel and undergraduate student assistants to complete the fieldwork and supporting in the image analyses we also sincerely acknowledge dr jami e nettles at weyerhaeuser company for her great support at various levels for completing this study and dr rhett jackson at university of georgia for support with some field data analysis for groundtruthing at ms and al study sites appendix b supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix b supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 07 012 appendix a python code for landsat 7 scanline correction image 1 
