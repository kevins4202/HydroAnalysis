index,text
23355,a thirty seven year wave hindcast 1979 2015 in chesapeake bay using ncep s climate forecast system reanalysis cfsr wind is presented the long term significant wave heights are generated by the third generation nearshore wave model swan which is validated using the wave height measurements at buoy stations in the bay the simulated wave heights are analyzed to characterize their temporal and spatial variabilities as well as long term changing trends by using an empirical orthogonal function eof analysis and an empirical cumulative distribution function approach seasonal variability as well as extreme storm effects on significant wave heights are revealed in the first mode of principle component then an extreme value analysis based on generalized extreme value and generalized pareto distribution functions is applied to evaluate design wave heights with different return periods the effects of key parameters including threshold value time span and data length on the design wave heights are extensively studied through the comparisons of different distribution functions evaluated by bayesian information criterion and akaike information criterion it is found that gamma distribution function and generalized extreme value analysis provide the best fit for annual and monthly data while generalized pareto distribution function gives the best fit when peak over threshold analysis is conducted keywords chesapeake bay design wave height generalized extreme value distribution generalized pareto distribution empirical orthogonal function 1 introduction coastal planners and engineers increasingly require information about wave climate to make better planning decisions and minimize future coastal hazards and economic loss because coastal waves play a significant role in coastal flooding and damage of coastal infrastructure wave studies in the field of ocean and coastal engineering have usually focused on characterizing the spatial and temporal variabilities of characteristic wave height typically the significant wave height and determining the design wave heights for structure design purposes to study spatial and temporal variabilities of significant wave height statistical analysis of long term wave climate data could be performed for example empirical orthogonal function eof analysis provides useful information regarding possible spatial patterns of variability within the data and how they change with time eof analysis has been widely used in oceanography to study major modes of climate variability such as the el nino southern oscillation enso roundy 2015 lian and chen 2012 messie and chavez 2011 and in coastal engineering to identify spreading and seasonal variability in shoreline and slope data lemke and miller 2017 the long term changing trends of wave height can be revealed by means of a regression analysis and an empirical cumulative distribution function approach which have been applied in a number of recent studies on extreme wave height in different ocean and coastal regions komar and allan 2007 2008 ruggiero et al 2010 long term trend of extreme wave height is of considerable interest in recent wave studies because significant changes in wave heights have been found in many coastal and ocean regions for instance mendez et al 2006 and menendez et al 2008 revealed significant long term variability of extreme wave height in the northeast pacific ocean using buoy measurements and a time dependent peak over threshold pot model in the north atlantic ocean near the coast of england carter and draper 1988 bacon and carter 1991 and east coast of u s komar and allan 2007 2008 researchers have found significant increases in wave height generated by extreme storms during the past decades similar results have also been reported in other locations such as west coast of u s using measurements from noaa buoy stations komar et al 2009 allan and komar 2000 2006 ruggiero et al 2010 and by analysis of storm intensities and hindcasted wave heights graham and diaz 2001 to determine the design wave heights extreme value analysis of significant wave height is always performed extreme value analysis eva has broad applications in many disciplines such as coastal engineering weather and climate finance and traffic prediction the theory of eva has been presented by a number of researchers gumbel 2012 coles et al 2001 kotz and nadarajah 2000 katz et al 2002 hawkes et al 2008 cooley 2009 2013 cooley et al 2007 its applications on extreme wave height analysis were presented by goda 1992 mathiesen et al 1994 and menendez et al 2008 the central idea of extreme wave height analysis is to determine the long term variability of significant wave height through implementations of distribution functions and quantile functions as well as extrapolation of historical data goda 1992 muir and el shaarawi 1986 muraleedharan et al 2012 the unknown parameters of the distribution functions are determined by a fitting method the common fitting methods include maximum likelihood estimate mle generalized maximum likelihood estimate gmle the method of moments mom probability weighted moment pwm least square method lsm bayesian and l moments coles et al 2001 each of these methods has its own merits and demerits for example for small sample data mle might not give good estimate of parameters and l moment could be used instead mom quantile estimators have smaller root mean square errors for specific range of shape parameter values than l moment and mle martins et al 2000 more detailed information regarding the estimators can be referred to martins et al 2000 after the determinations of distribution functions and quantile functions the extreme wave height data is organized in a way that is feasible for extrapolation the design wave heights can be finally determined given different return periods and probabilities of occurrence this paper is dedicated to investigating wave climate in chesapeake bay due to the lack of reliable long term wave data limited studies on wave climate in chesapeake bay have been carried out however significant advances in satellite altimeters have made it possible for researchers to use wave models to reproduce the historical wave height using reanalysis technique this technique has been utilized in many earlier studies on wave climate analysis for example stopa et al 2013 stopa and cheung 2014 chawla et al 2013 rascle and ardhuin 2013 tolman et al 2013 mentaschi et al 2015 anderson et al 2015 in this study the third generation nearshore wave model swan is applied to reconstruct long term significant wave height in the entire chesapeake bay the objectives of this study are 1 to hindcast significant wave height in the bay during 1979 2015 2 to investigate spatial and temporal variabilities of significant wave height in the bay 3 to determine and compare design wave heights by extreme value analysis the paper is organized as follows the data and methodology are introduced in section 2 in section 3 the simulated significant wave heights are analyzed statistically to reveal their spatial and temporal variabilities in the past decades extreme value analysis of the significant wave heights are presented in section 4 sensitivity of extreme wave height analysis to key parameters is discussed in section 5 and finally conclusions are presented in section 6 2 wave model although understanding of wave characteristics is essential in many aspects including navigational and design purposes this knowledge has been limited in chesapeake bay mostly because of scarcity of reliable observational data farnsworth 1997 recently a number of buoy systems were deployed by the national oceanic and atmospheric administrations noaa chesapeake bay interpretive buoy system cbibs to gather meteorological oceanographic and water quality data the program was launched in 2007 and the total number of buoys deployed so far is ten the locations of these buoys are shown in fig 1 these buoys are capable of collecting information on a variety of parameters including significant wave height and period maximum wave height and mean wave direction data is collected every 10 60 min depending on the parameter and is accessible through their website http buoybay noaa gov cbibs provide valuable short term wave height data for wave model validation to hindcast long term significant wave height in chesapeake bay 37 years wind data 1979 2015 were collected through the national centers for environmental prediction ncep climate forecast system reanalysis cfsr saha et al 2010 2014 the cfsr uses a coupled atmosphere ocean land surface sea ice system with advanced data assimilation techniques and an extensive database of meteorological observations to create its products the original cfsr dataset spans from 1979 to 2010 and the second version of the climate forecast system cfsv2 provides products from 2011 up until now with several improvements over cfsr such as a higher spatial resolution saha et al 2014 temporal resolution for both models is 6 h however spatial resolution of the cfsv2 is approximately 20 km compared to 38 km for cfsr which is a significant improvement in this study the third generation swan wave model rusu et al 2009 is employed to obtain 3 hourly significant wave heights for the past 37 years the computational domain encompasses the full chesapeake bay and a portion of the nearby coastal region the computational grid is curvilinear and includes 129 65 mesh cells fig 2 the bathymetry data is from ncei estuarine bathymetric digital elevation model for the swan simulations wave energy dissipation mechanisms including white capping wave breaking and bottom friction are triggered as an example the simulated significant wave heights swhs for 37 years at stingray point are depicted in fig 3 seasonal variability of the wave heights can be clearly seen because the hindcasted wave height data set is huge the model data comparisons in selected time periods are shown in order to demonstrate the model performance the simulated and measured swhs at buoy stations potomac and stingray point in year 2011 and 2012 are compared in figs 4 and 6 the reason of choosing year 2012 for demonstration is because wave climate in chesapeake bay was affected by hurricane sandy in this year it can be seen that the simulations match reasonably well with the measurements particularly the wave height variations during hurricane sandy were captured by the model to quantify the model performance the correlations between simulations and measurements at potomac and stingray point during 2011 and 2012 are presented in figs 5 and 7 particularly the bias 1 n i 1 n m i o i rmse and correlation coefficients are evaluated and shown in the figures the coefficients of determination r 2 are above 0 62 and the bias and rmse are reasonably small indicating that the swan model is capable of simulating temporal variations of swhs with reasonable accuracy 3 spatial and temporal variabilities of swhs the reconstructed swhs exhibit temporal and spatial variabilities in order to reveal their patterns an empirical orthogonal function eof analysis on daily averaged swhs is performed like fourier analysis the eof provides an expansion of the original data in a series of functions that separate the spatial and temporal variations these functions are determined by the correlations within the data set and may suggest certain processes or time scales of change the idea of eof analysis is to express the time series data as 1 z x y t k 1 n p c t e o f x y where z x y t is the original time series as a function of time t and space x y e o f x y is the eigenfunctions or vectors of the correlation matrix of the data which shows the spatial structures of the major factors that account for the spatial variations of the data and pc t is the principal component describing the temporal variation of each eof the eofs can be obtained by computing the eigenvalues and eigenvectors of a spatially weighted anomaly covariance matrix of a field and the resulting eigenvalues provide a measure of the percentage variance explained by each mode the lower mode eofs represent large scale variability and higher mode eofs show smaller scales or even sometimes random noises in this study eof analysis is performed using a matlab package and results for the first three modes are presented in figs 8 and 9 respectively fig 8 demonstrates the spatial distributions of the first three dominant eof modes for the entire chesapeake bay the corresponding pcs are presented in fig 9 in which the values are scaled to the range between 1 and 1 by dividing their maximum values from the calculated eigenvalues it can be determined that the mode 1 accounts for 91 2 of spatial variability of swhs the other modes only contribute to a small part of the signal variance clearly the pc of mode 1 demonstrates a seasonal variability of swhs with positive pc in winter season october march and negative pc in summer season the first eof mode describes deviation from the mean swh combined with the first pc mode it can be interpreted that in winter season when pc is positive the wave heights are generally greater than the mean swh while in summer season when pc is negative the wave heights are generally smaller than the mean swh the seasonal variation of wave climate is typical in coastal regions from fig 8 it is also found that the first eof has the largest value in the lower chesapeake bay and the smallest value in the upper bay it is because the lower bay is more exposed and wave height variations are more significant in this region since the other pc modes do not show clear variation patterns they are not discussed herein in the first pc mode in fig 9 several spikes with large positive pc values can be detected these anomalies are generally linked with hurricane or tropical storm events table 1 shows the names of tropical storms and times of occurrence in the past decade largest pc values are spotted when storms hit the bay as shown in fig 10 there is a close correlation between occurrence of storms and mode 1 eigenvalues the changing trend of significant wave height at a representative site is analyzed using a regression analysis stingray point is selected for this purpose since this point is not far from the mouth of the bay so it can capture extreme wave heights entering the bay regression analysis is performed on winter averaged and annual maxima data derived from swan results which are depicted in fig 11 a it is found that extreme wave heights at this station were generally increasing the increasing rate of annual maximum wave heights is much higher than that of winter average 4 1 m m y r versus 1 4 m m y r to examine the robustness of the regression analysis sensitivity of the calculated trends are tested with respect to the amount of data included in the analysis regression analysis is firstly performed using data from 1979 to 2008 and then rate of increase is computed by adding data annually this process is repeated until all years are included in the analysis the computed increasing rates for annual maxima and winter average are presented in fig 11b results show that except year 2011 in which there is a decrease in winter average and a sudden increase in annual maxima rates of wave height increase are fairly stable regardless of the amount of data used the decrease in winter average and increase in annual maxima in 2011 can be associated with hurricane irene which passed through chesapeake bay in august statistical significance test has been used widely in hydrology and coastal engineering tasdighi et al 2017 ruggiero et al 2010 to examine the significance of the slope of a regression model in this study the statistical significance test is performed on each subset of data to examine whether or not the rates of swh increases derived from regression analysis are statistically significant the significance test results in a p value 0 05 meaning that for both winter average and annual maxima rate of increases are not statistically significant in order to further examine the progressive increases of waves more detailed analysis of swhs is provided using probability distributions of all independent storms independent storm is defined by mendez et al 2006 in this definition minimum time span between 2 consecutive storms should be selected such that poisson process is assumed to be valid fig 12 a shows the number of independent storms occurred for a range of swhs during two time periods the first period is defined from 1979 to 1997 and the second one is from 1998 to 2015 results show that although total number of independent storms are higher during 1979 1997 by about 12 the number of extreme storms with swh larger than 1 5m exceeds by 33 during period 1998 2015 more explicit explanation of progressive increases of extreme storms is presented in fig 12b in which the empirical cumulative distribution functions for the two periods are depicted although medians for the two periods are almost the same 0 79m and 0 80m for periods 1979 1997 and 1998 2015 respectively a 9 increase is observed in 99 5 percentile in the period of 1998 2015 confirming the findings from the regression analysis presented in fig 11 and demonstrating a slight shift towards higher values of extreme wave heights in the past decades it is also shown that there is a consistency between the annual increasing rates of swhs based on regression analysis and cumulative distribution function analysis a more comprehensive study of progressive increases of waves in chesapeake bay is performed by obtaining 99 5 percentile of independent storms during periods 1979 1997 and 1998 2015 for the entire bay which are presented in fig 13 except lower bay where a maximum decrease of 0 27m in extreme wave height is observed fig 13c the rest of the bay experiences an average increase of 0 1 m and the maximum increase is found to be 0 36 m in the central bay although these changes are small in terms of intensity they confirm a slight increase in wave heights during the past decades 4 extreme value analysis in this section extreme value analysis will be performed to obtain design wave heights corresponding to different return periods using various extreme value assessment models to examine applicability of these models and to perform sensitivity analysis on extracted data to determine the uncertainty that comes along with extreme value models in extreme value theory it has been shown that for sufficiently long sequences of independent and identically distributed random variables the maxima of samples of size n can be fitted into the generalize extreme value gev family of distributions which has the following cumulative distribution function coles et al 2001 2 g z μ σ ξ e x p 1 ξ z μ σ 1 ξ ξ 0 e x p e x p z μ σ ξ 0 where μ σ and ξ are the location scale and shape parameters respectively the three classes of gev distribution functions are gumbel distribution type i ξ 0 frechet distribution type ii ξ 0 and weibull distribution type iii ξ 0 the return level corresponding to return period t can be obtained using the following equation 3 r t μ σ ξ 1 l n 1 1 t ξ ξ 0 μ σ l n l n 1 1 t ξ 0 one major concern with gev approach is that gev is often applied to annual maxima data hence ignores other significant extreme events in each year other approaches that can be used to reduce this limitation are block maxima and peak over threshold pot method in block maxima approach the entire data is divided into non overlap periods of equal size called block and maximum value in each block is selected for analysis an example of block maxima approach is monthly maxima which is also included in this study in the pot method a high threshold is selected and extreme value analysis is performed on all the data above the given threshold it can be shown that for sufficiently high threshold the data can be fitted into the so called generalized pareto gp distribution function given by 4 f z σ ξ 1 1 ξ z σ 1 ξ ξ 0 1 e x p z σ ξ 0 where σ 0 is the scale parameter and ξ is the shape parameter of the gp distribution function two important concerns with pot approach are the selection of the threshold and the minimum time span δ t which could affect the results in terms of frequency and exceedance estimates mendez et al 2006 regarding the time span δ t should be chosen sufficiently long to guarantee the independency between consecutive storms and to satisfy the validity of poisson process a wide range of δ t can be found in the literature luceno et al 2006 mendez et al 2006 in this section δ t 3 days is selected results for δ t 4 5 and 6 days are presented in the discussion section to investigate the sensitivity of time interval on the results the choice of threshold is also important in the pot analysis the threshold u should be taken sufficiently high for the distribution function to provide a reasonable estimate nevertheless it cannot be too high to produce large variance on the estimated parameters common approaches for selecting threshold include parameter stability plot and mean residual life plot in the first approach the parameter estimates from gp distribution function are plotted against a range of values of u the parameter estimates should be stable above the threshold at which the gp model becomes valid in the second approach u is plotted against the mean excess which is defined as the mean of the exceedances of u minus u the plot should be linear above the threshold at which the gp model becomes valid in this study both approaches are employed to determine the threshold results are depicted in fig 14 which suggests that both scale and shape parameters show stable behavior around 1 m therefore a threshold of 1 m can be considered as a suitable choice for pot analysis the interpretation of a mean residual life plot is not always easy as can be seen from fig 14b the plots are almost linear around u 1 m and then appear to decrease sharply from u 1 1 m therefore a threshold of 1 m is chosen to perform pot analysis mazas and hamm 2011 showed that along with gev and gp distribution functions the gamma distribution function often behaves well in terms of fitting the data therefore performance of gamma distribution function is also examined the cumulative distribution function of gamma is given by 5 f z σ ξ γ ξ z σ γ ξ where γ is the gamma function and γ is the lower incomplete gamma function to demonstrate and assess the performance of different extreme value analysis models the simulated wave heights at stingray point are used in this section both gev and pot analysis are performed for gev analysis annual and monthly maxima are extracted from simulated wave height data the parameter estimation is performed by mle and l moments the results of mle are shown in fig 15 the density plots fig 15a d show good agreement between the empirical density red line and that of the fitted gev distribution function dashed blue line for both annual and monthly maxima fig 15b e show q q plots of the empirical data quantiles against those derived from the fitted gev distribution function the plots are reasonably straight indicating that the utilization of the gev distribution function is fulfilled by good approximation for annual maxima fig 15b a slight deviation from the straight line can be observed however this deviation is typical for extreme value analysis because of uncertainties associated with extreme value problems finally fig 15c f show the return levels corresponding to different return periods of extreme wave heights for annual and monthly maxima respectively the points on the graphs fig 15c f are the estimated return levels from annual and monthly maxima data respectively the solid blue lines are the estimated return levels based on the fitted gev model and the dashed red lines are 95 confidence intervals for both models the empirical values fall within the 95 confidence intervals and close to the estimated return level especially for the monthly maxima model showing that both models can provide acceptable values for return levels more detailed information regarding the return levels using different parameter estimators are presented in table 2 and table 3 respectively both the plots and tables show that return levels extracted from annual maxima data have higher values compared to those extracted from monthly maxima data for example return levels for 10 25 50 and 100 years return periods from annual maxima data are 26 19 14 and 10 higher than those from monthly maxima data it can be also seen from the tables that there are minor changes in return levels in terms of using different parameter estimators the variation of return level is less than 0 6 indicating that both estimators can be used for extreme value analysis of wave height for pot analysis a threshold of 1 m and a time span of 3 days are selected which results in 386 independent storms the yearly distribution of storm events is presented in fig 16 it can be seen from fig 16a that more than 75 of storm events occur in the winter season fig 16b shows the distribution of independent storms above 1 m in year day in which extreme storm events annual maxima and 5 largest storms in each year are presented with different symbols the largest wave heights appear in the later hurricane season sep and oct as detected by eof analysis seasonal variation of extreme wave heights is observed the results using mle estimator is presented in fig 17 density plot fig 17a shows a good agreement between the empirical density function red line and the fitted gp distribution function dashed blue line similar to gev model q q plot fig 17b from gp model is straight indicating that gp distribution function can be used for eva with good approximation the empirical points fig 17c are very close to the estimated return levels from gp distribution function showing that it provides good approximation for return levels comparisons of return levels using different estimators are shown in table 4 slight differences on return levels are observed using mle and l moments estimators comparison of return levels obtained from gev and pot show that pot and gev produce almost the same results especially for higher return periods for example for 100 year return period pot and annual maxima gev produce the same results while for monthly maxima gev model the difference is only 10 from the above analyses it can be concluded that both gev and pot are reliable approaches for estimating design wave heights more detailed comparisons of these three approaches are presented in fig 18 in which return levels or design wave heights are plotted against return periods using mle estimator the conclusions are the same as what are observed in tables 2 4 5 discussions the choice of distribution functions the selection of threshold and time span as well as data length included in the analysis are important in extreme value assessment therefore this section is devoted to perform sensitivity analyses of these parameters to understand the effects of each parameter on the estimation of design wave height 5 1 threshold and time span in order to investigate the impacts of threshold wave height and time span on design wave heights a sensitivity analysis is performed by choosing values of 0 8 0 9 1 0 1 1 and 1 2 m for threshold wave height and 3 4 5 and 6 days for time spans the return levels are calculated using mle estimator and results for different time spans are shown in tables 5 8 it is shown that design wave height generally increases for different return periods with increasing time span another interesting result is that for a specific time span higher threshold wave height results in higher return level although the variation rates of return levels are very small especially for higher return periods 5 2 distribution functions in order to evaluate the performance of gev and gp distribution functions in terms of fitting the data a comparison is made between gev distribution functions and weibull gumbel gamma and log normal distribution functions by calculating bayesian information criterion bic also known as the schwarz criterion schwarz 1978 and akaike information criterion aic akaike 1974 bic minimizes the bias between the fitted model and the unknown true model which is given by 6 b i c 2 l n l k p l n n where l is the likelihood of the fit n is the sample size number of storm peaks above threshold and k p is the number of parameters of the distribution the aic which can be inferred as the best compromise between bias and variance is given by 7 a i c 2 l n l 2 k p a lower value of aic or bic indicates a better fit it is worth noting that the best fit does not necessarily provide the desirable result for design purposes as selecting a conservative return level seems more reasonable the goodness of fit test is firstly performed on gev weibull gumbel gamma and log normal using annual maxima data table 9 shows the summary of aic and bic values calculated for different models using mle it can be seen from table 9 that there is a slight difference between aic and bic calculated from the models showing that nearly all models are capable of fitting the annual maxima data however gamma distribution function gives the best fit and gev provides a better fit than weibull and gumbel distribution functions q q plot is employed to qualitatively compare the performance of all models and to check whether or not the actual and model data sets come from a population with the same distribution fig 19 for gumbel and weibull distribution functions q q plots confirm aic and bic tests shown in table 9 as some points deviate from the straight line however for gev log normal and gamma distribution functions the points fall approximately along the reference line indicating that these models provide better fits analyses are also performed on monthly maxima data to evaluate the performance of all models the results are presented in table 10 clearly weibull distribution function fails to give a good fit since aic and bic values of this model are much higher compared to others and gamma distribution function still provides the best fit q q plots fig 20 show graphically that weibull and gumbel distribution functions are not good options for eva on extreme wave heights and gev and gamma distribution functions provide the best fits among all models the log normal distribution function is not able to capture the tail of distribution function with deviations from the central line for pot analysis gp distribution function is compared with gamma and log normal distribution functions and the results of aic and bic tests are shown in table 11 in this analysis threshold wave height of 0 8 m and time span of 3 days are chosen q q plots fig 21 are also drawn to verify results obtained from aic and bic tests it shows that none of distribution functions are suitable for pot analysis except gp distribution function which can be considered as a suitable tool for pot analysis of the data 5 3 length of data used in the analysis the length of data included in the analysis can also play a significant role in obtaining the proper design wave height therefore a sensitivity analysis is performed in terms of sample duration by using 10 19 28 and 37 years datasets corresponding to the datasets during 1979 88 1979 97 1979 2006 and 1979 2015 respectively the design wave heights with a return period of 100 years are obtained using gev gamma and gp distribution functions it can be seen from table 12 that longer dataset results in higher design wave height which contradicts the findings of mazas and hamm 2011 that shorter dataset produced higher design wave height this contradiction is mostly due to the property of data being analyzed since extreme events are unpredictable higher design wave height can be obtained in smaller datasets if extreme storm events happen during that time period in addition a minor difference 2 maximum difference between design wave heights obtained from 28 and 37 year dataset is obtained suggesting that 28 years might be sufficiently long for extreme wave height analysis the maximum difference intensifies for 10 and 19 year dataset compared to 37 year dataset by 18 and 14 respectively therefore these datasets can not provide good estimates of design wave height for 100 year return period based on the analyses performed in this study gamma gev and gp distribution functions are selected to draw contours of design wave heights with 100 year return period for the entire chesapeake bay the results are shown in fig 22 the design wave height generally decreases from lower bay to the upper bay with design wave height between 1 5 and 2 m in the upper bay it increases substantially in the lower bay and reaches up to 3 25 m gamma distribution function gives a more conservative estimate of design wave height fig 22a compared to gev and gp distribution functions fig 22b c gp distribution function fails to provide design wave height in shallow areas since its analysis is based on a threshold value that might be greater than largest waves in those areas 6 conclusions in this paper swan wave model was applied to reconstruct the wave climate in chesapeake bay during 1979 2015 the spatial and temporal variabilities of the simulated wave heights in the bay were firstly analyzed using eof analysis regression analysis as well as cumulative distribution function analysis eof analysis performed on daily averaged swhs showed seasonal variability of wave heights in chesapeake bay with larger wave heights in winter season it also revealed that the lower bay experienced more significant variations in wave height extreme storm events such as hurricanes and tropical storms could be detected from the first mode of pc regression analysis on swhs at stingray point suggested that there was a steady increase of extreme wave heights in the chesapeake bay however the long term change was not significant the continuous increase of extreme waves was further verified by empirical cumulative distribution function analysis for two separate periods 1979 1997 and 1998 2015 in which a 9 increase in extreme wave height was observed in 99 5 percentile these findings were confirmed by obtaining 99 5 percentile for the entire bay results suggested that except lower bay where there was a maximum of 0 27m decrease in wave height the rest of the bay received an average wave height increase of 0 1 m in the extreme value analysis both gev and pot methods were applied to estimate design wave heights the reliability of these methods was extensively studied the effects of key parameters such as threshold value time span as well as data length on the design wave heights were evaluated the gev and pot analyses performed on annual and monthly maxima and independent extreme waves with threshold of 1 0 m and time span of 3 days showed that design wave heights with 100 year return period evaluated from gev for annual maxima data and gp model were higher than those from monthly maxima data by 10 therefore annual maxima and pot approaches provided a more conservative estimate of design wave height for design purposes the effects of time span and threshold on design wave height were examined by tests on different time spans 3 4 5 and 6 days and various thresholds 0 8 0 9 1 1 1 and 1 2 m it was found that increasing time span leaded to larger design wave height and higher threshold resulted in higher design wave height moreover sensitivity analysis on data duration showed that a 28 year dataset could provide an acceptable estimate of design wave height in the bay the performance of gev and gp was also evaluated in terms of fitting the data against various distribution functions including weibull gumbel gamma log normal distribution functions using aic bic test and q q plots results indicated that gamma and gev provided the best fit for annual and monthly data while gp distribution function gave the best fit when pot analysis was conducted acknowledgments ma acknowledges the financial support from padi foundation lou thanks for the support from the national natural science foundation of china nsfc 41602244 
23355,a thirty seven year wave hindcast 1979 2015 in chesapeake bay using ncep s climate forecast system reanalysis cfsr wind is presented the long term significant wave heights are generated by the third generation nearshore wave model swan which is validated using the wave height measurements at buoy stations in the bay the simulated wave heights are analyzed to characterize their temporal and spatial variabilities as well as long term changing trends by using an empirical orthogonal function eof analysis and an empirical cumulative distribution function approach seasonal variability as well as extreme storm effects on significant wave heights are revealed in the first mode of principle component then an extreme value analysis based on generalized extreme value and generalized pareto distribution functions is applied to evaluate design wave heights with different return periods the effects of key parameters including threshold value time span and data length on the design wave heights are extensively studied through the comparisons of different distribution functions evaluated by bayesian information criterion and akaike information criterion it is found that gamma distribution function and generalized extreme value analysis provide the best fit for annual and monthly data while generalized pareto distribution function gives the best fit when peak over threshold analysis is conducted keywords chesapeake bay design wave height generalized extreme value distribution generalized pareto distribution empirical orthogonal function 1 introduction coastal planners and engineers increasingly require information about wave climate to make better planning decisions and minimize future coastal hazards and economic loss because coastal waves play a significant role in coastal flooding and damage of coastal infrastructure wave studies in the field of ocean and coastal engineering have usually focused on characterizing the spatial and temporal variabilities of characteristic wave height typically the significant wave height and determining the design wave heights for structure design purposes to study spatial and temporal variabilities of significant wave height statistical analysis of long term wave climate data could be performed for example empirical orthogonal function eof analysis provides useful information regarding possible spatial patterns of variability within the data and how they change with time eof analysis has been widely used in oceanography to study major modes of climate variability such as the el nino southern oscillation enso roundy 2015 lian and chen 2012 messie and chavez 2011 and in coastal engineering to identify spreading and seasonal variability in shoreline and slope data lemke and miller 2017 the long term changing trends of wave height can be revealed by means of a regression analysis and an empirical cumulative distribution function approach which have been applied in a number of recent studies on extreme wave height in different ocean and coastal regions komar and allan 2007 2008 ruggiero et al 2010 long term trend of extreme wave height is of considerable interest in recent wave studies because significant changes in wave heights have been found in many coastal and ocean regions for instance mendez et al 2006 and menendez et al 2008 revealed significant long term variability of extreme wave height in the northeast pacific ocean using buoy measurements and a time dependent peak over threshold pot model in the north atlantic ocean near the coast of england carter and draper 1988 bacon and carter 1991 and east coast of u s komar and allan 2007 2008 researchers have found significant increases in wave height generated by extreme storms during the past decades similar results have also been reported in other locations such as west coast of u s using measurements from noaa buoy stations komar et al 2009 allan and komar 2000 2006 ruggiero et al 2010 and by analysis of storm intensities and hindcasted wave heights graham and diaz 2001 to determine the design wave heights extreme value analysis of significant wave height is always performed extreme value analysis eva has broad applications in many disciplines such as coastal engineering weather and climate finance and traffic prediction the theory of eva has been presented by a number of researchers gumbel 2012 coles et al 2001 kotz and nadarajah 2000 katz et al 2002 hawkes et al 2008 cooley 2009 2013 cooley et al 2007 its applications on extreme wave height analysis were presented by goda 1992 mathiesen et al 1994 and menendez et al 2008 the central idea of extreme wave height analysis is to determine the long term variability of significant wave height through implementations of distribution functions and quantile functions as well as extrapolation of historical data goda 1992 muir and el shaarawi 1986 muraleedharan et al 2012 the unknown parameters of the distribution functions are determined by a fitting method the common fitting methods include maximum likelihood estimate mle generalized maximum likelihood estimate gmle the method of moments mom probability weighted moment pwm least square method lsm bayesian and l moments coles et al 2001 each of these methods has its own merits and demerits for example for small sample data mle might not give good estimate of parameters and l moment could be used instead mom quantile estimators have smaller root mean square errors for specific range of shape parameter values than l moment and mle martins et al 2000 more detailed information regarding the estimators can be referred to martins et al 2000 after the determinations of distribution functions and quantile functions the extreme wave height data is organized in a way that is feasible for extrapolation the design wave heights can be finally determined given different return periods and probabilities of occurrence this paper is dedicated to investigating wave climate in chesapeake bay due to the lack of reliable long term wave data limited studies on wave climate in chesapeake bay have been carried out however significant advances in satellite altimeters have made it possible for researchers to use wave models to reproduce the historical wave height using reanalysis technique this technique has been utilized in many earlier studies on wave climate analysis for example stopa et al 2013 stopa and cheung 2014 chawla et al 2013 rascle and ardhuin 2013 tolman et al 2013 mentaschi et al 2015 anderson et al 2015 in this study the third generation nearshore wave model swan is applied to reconstruct long term significant wave height in the entire chesapeake bay the objectives of this study are 1 to hindcast significant wave height in the bay during 1979 2015 2 to investigate spatial and temporal variabilities of significant wave height in the bay 3 to determine and compare design wave heights by extreme value analysis the paper is organized as follows the data and methodology are introduced in section 2 in section 3 the simulated significant wave heights are analyzed statistically to reveal their spatial and temporal variabilities in the past decades extreme value analysis of the significant wave heights are presented in section 4 sensitivity of extreme wave height analysis to key parameters is discussed in section 5 and finally conclusions are presented in section 6 2 wave model although understanding of wave characteristics is essential in many aspects including navigational and design purposes this knowledge has been limited in chesapeake bay mostly because of scarcity of reliable observational data farnsworth 1997 recently a number of buoy systems were deployed by the national oceanic and atmospheric administrations noaa chesapeake bay interpretive buoy system cbibs to gather meteorological oceanographic and water quality data the program was launched in 2007 and the total number of buoys deployed so far is ten the locations of these buoys are shown in fig 1 these buoys are capable of collecting information on a variety of parameters including significant wave height and period maximum wave height and mean wave direction data is collected every 10 60 min depending on the parameter and is accessible through their website http buoybay noaa gov cbibs provide valuable short term wave height data for wave model validation to hindcast long term significant wave height in chesapeake bay 37 years wind data 1979 2015 were collected through the national centers for environmental prediction ncep climate forecast system reanalysis cfsr saha et al 2010 2014 the cfsr uses a coupled atmosphere ocean land surface sea ice system with advanced data assimilation techniques and an extensive database of meteorological observations to create its products the original cfsr dataset spans from 1979 to 2010 and the second version of the climate forecast system cfsv2 provides products from 2011 up until now with several improvements over cfsr such as a higher spatial resolution saha et al 2014 temporal resolution for both models is 6 h however spatial resolution of the cfsv2 is approximately 20 km compared to 38 km for cfsr which is a significant improvement in this study the third generation swan wave model rusu et al 2009 is employed to obtain 3 hourly significant wave heights for the past 37 years the computational domain encompasses the full chesapeake bay and a portion of the nearby coastal region the computational grid is curvilinear and includes 129 65 mesh cells fig 2 the bathymetry data is from ncei estuarine bathymetric digital elevation model for the swan simulations wave energy dissipation mechanisms including white capping wave breaking and bottom friction are triggered as an example the simulated significant wave heights swhs for 37 years at stingray point are depicted in fig 3 seasonal variability of the wave heights can be clearly seen because the hindcasted wave height data set is huge the model data comparisons in selected time periods are shown in order to demonstrate the model performance the simulated and measured swhs at buoy stations potomac and stingray point in year 2011 and 2012 are compared in figs 4 and 6 the reason of choosing year 2012 for demonstration is because wave climate in chesapeake bay was affected by hurricane sandy in this year it can be seen that the simulations match reasonably well with the measurements particularly the wave height variations during hurricane sandy were captured by the model to quantify the model performance the correlations between simulations and measurements at potomac and stingray point during 2011 and 2012 are presented in figs 5 and 7 particularly the bias 1 n i 1 n m i o i rmse and correlation coefficients are evaluated and shown in the figures the coefficients of determination r 2 are above 0 62 and the bias and rmse are reasonably small indicating that the swan model is capable of simulating temporal variations of swhs with reasonable accuracy 3 spatial and temporal variabilities of swhs the reconstructed swhs exhibit temporal and spatial variabilities in order to reveal their patterns an empirical orthogonal function eof analysis on daily averaged swhs is performed like fourier analysis the eof provides an expansion of the original data in a series of functions that separate the spatial and temporal variations these functions are determined by the correlations within the data set and may suggest certain processes or time scales of change the idea of eof analysis is to express the time series data as 1 z x y t k 1 n p c t e o f x y where z x y t is the original time series as a function of time t and space x y e o f x y is the eigenfunctions or vectors of the correlation matrix of the data which shows the spatial structures of the major factors that account for the spatial variations of the data and pc t is the principal component describing the temporal variation of each eof the eofs can be obtained by computing the eigenvalues and eigenvectors of a spatially weighted anomaly covariance matrix of a field and the resulting eigenvalues provide a measure of the percentage variance explained by each mode the lower mode eofs represent large scale variability and higher mode eofs show smaller scales or even sometimes random noises in this study eof analysis is performed using a matlab package and results for the first three modes are presented in figs 8 and 9 respectively fig 8 demonstrates the spatial distributions of the first three dominant eof modes for the entire chesapeake bay the corresponding pcs are presented in fig 9 in which the values are scaled to the range between 1 and 1 by dividing their maximum values from the calculated eigenvalues it can be determined that the mode 1 accounts for 91 2 of spatial variability of swhs the other modes only contribute to a small part of the signal variance clearly the pc of mode 1 demonstrates a seasonal variability of swhs with positive pc in winter season october march and negative pc in summer season the first eof mode describes deviation from the mean swh combined with the first pc mode it can be interpreted that in winter season when pc is positive the wave heights are generally greater than the mean swh while in summer season when pc is negative the wave heights are generally smaller than the mean swh the seasonal variation of wave climate is typical in coastal regions from fig 8 it is also found that the first eof has the largest value in the lower chesapeake bay and the smallest value in the upper bay it is because the lower bay is more exposed and wave height variations are more significant in this region since the other pc modes do not show clear variation patterns they are not discussed herein in the first pc mode in fig 9 several spikes with large positive pc values can be detected these anomalies are generally linked with hurricane or tropical storm events table 1 shows the names of tropical storms and times of occurrence in the past decade largest pc values are spotted when storms hit the bay as shown in fig 10 there is a close correlation between occurrence of storms and mode 1 eigenvalues the changing trend of significant wave height at a representative site is analyzed using a regression analysis stingray point is selected for this purpose since this point is not far from the mouth of the bay so it can capture extreme wave heights entering the bay regression analysis is performed on winter averaged and annual maxima data derived from swan results which are depicted in fig 11 a it is found that extreme wave heights at this station were generally increasing the increasing rate of annual maximum wave heights is much higher than that of winter average 4 1 m m y r versus 1 4 m m y r to examine the robustness of the regression analysis sensitivity of the calculated trends are tested with respect to the amount of data included in the analysis regression analysis is firstly performed using data from 1979 to 2008 and then rate of increase is computed by adding data annually this process is repeated until all years are included in the analysis the computed increasing rates for annual maxima and winter average are presented in fig 11b results show that except year 2011 in which there is a decrease in winter average and a sudden increase in annual maxima rates of wave height increase are fairly stable regardless of the amount of data used the decrease in winter average and increase in annual maxima in 2011 can be associated with hurricane irene which passed through chesapeake bay in august statistical significance test has been used widely in hydrology and coastal engineering tasdighi et al 2017 ruggiero et al 2010 to examine the significance of the slope of a regression model in this study the statistical significance test is performed on each subset of data to examine whether or not the rates of swh increases derived from regression analysis are statistically significant the significance test results in a p value 0 05 meaning that for both winter average and annual maxima rate of increases are not statistically significant in order to further examine the progressive increases of waves more detailed analysis of swhs is provided using probability distributions of all independent storms independent storm is defined by mendez et al 2006 in this definition minimum time span between 2 consecutive storms should be selected such that poisson process is assumed to be valid fig 12 a shows the number of independent storms occurred for a range of swhs during two time periods the first period is defined from 1979 to 1997 and the second one is from 1998 to 2015 results show that although total number of independent storms are higher during 1979 1997 by about 12 the number of extreme storms with swh larger than 1 5m exceeds by 33 during period 1998 2015 more explicit explanation of progressive increases of extreme storms is presented in fig 12b in which the empirical cumulative distribution functions for the two periods are depicted although medians for the two periods are almost the same 0 79m and 0 80m for periods 1979 1997 and 1998 2015 respectively a 9 increase is observed in 99 5 percentile in the period of 1998 2015 confirming the findings from the regression analysis presented in fig 11 and demonstrating a slight shift towards higher values of extreme wave heights in the past decades it is also shown that there is a consistency between the annual increasing rates of swhs based on regression analysis and cumulative distribution function analysis a more comprehensive study of progressive increases of waves in chesapeake bay is performed by obtaining 99 5 percentile of independent storms during periods 1979 1997 and 1998 2015 for the entire bay which are presented in fig 13 except lower bay where a maximum decrease of 0 27m in extreme wave height is observed fig 13c the rest of the bay experiences an average increase of 0 1 m and the maximum increase is found to be 0 36 m in the central bay although these changes are small in terms of intensity they confirm a slight increase in wave heights during the past decades 4 extreme value analysis in this section extreme value analysis will be performed to obtain design wave heights corresponding to different return periods using various extreme value assessment models to examine applicability of these models and to perform sensitivity analysis on extracted data to determine the uncertainty that comes along with extreme value models in extreme value theory it has been shown that for sufficiently long sequences of independent and identically distributed random variables the maxima of samples of size n can be fitted into the generalize extreme value gev family of distributions which has the following cumulative distribution function coles et al 2001 2 g z μ σ ξ e x p 1 ξ z μ σ 1 ξ ξ 0 e x p e x p z μ σ ξ 0 where μ σ and ξ are the location scale and shape parameters respectively the three classes of gev distribution functions are gumbel distribution type i ξ 0 frechet distribution type ii ξ 0 and weibull distribution type iii ξ 0 the return level corresponding to return period t can be obtained using the following equation 3 r t μ σ ξ 1 l n 1 1 t ξ ξ 0 μ σ l n l n 1 1 t ξ 0 one major concern with gev approach is that gev is often applied to annual maxima data hence ignores other significant extreme events in each year other approaches that can be used to reduce this limitation are block maxima and peak over threshold pot method in block maxima approach the entire data is divided into non overlap periods of equal size called block and maximum value in each block is selected for analysis an example of block maxima approach is monthly maxima which is also included in this study in the pot method a high threshold is selected and extreme value analysis is performed on all the data above the given threshold it can be shown that for sufficiently high threshold the data can be fitted into the so called generalized pareto gp distribution function given by 4 f z σ ξ 1 1 ξ z σ 1 ξ ξ 0 1 e x p z σ ξ 0 where σ 0 is the scale parameter and ξ is the shape parameter of the gp distribution function two important concerns with pot approach are the selection of the threshold and the minimum time span δ t which could affect the results in terms of frequency and exceedance estimates mendez et al 2006 regarding the time span δ t should be chosen sufficiently long to guarantee the independency between consecutive storms and to satisfy the validity of poisson process a wide range of δ t can be found in the literature luceno et al 2006 mendez et al 2006 in this section δ t 3 days is selected results for δ t 4 5 and 6 days are presented in the discussion section to investigate the sensitivity of time interval on the results the choice of threshold is also important in the pot analysis the threshold u should be taken sufficiently high for the distribution function to provide a reasonable estimate nevertheless it cannot be too high to produce large variance on the estimated parameters common approaches for selecting threshold include parameter stability plot and mean residual life plot in the first approach the parameter estimates from gp distribution function are plotted against a range of values of u the parameter estimates should be stable above the threshold at which the gp model becomes valid in the second approach u is plotted against the mean excess which is defined as the mean of the exceedances of u minus u the plot should be linear above the threshold at which the gp model becomes valid in this study both approaches are employed to determine the threshold results are depicted in fig 14 which suggests that both scale and shape parameters show stable behavior around 1 m therefore a threshold of 1 m can be considered as a suitable choice for pot analysis the interpretation of a mean residual life plot is not always easy as can be seen from fig 14b the plots are almost linear around u 1 m and then appear to decrease sharply from u 1 1 m therefore a threshold of 1 m is chosen to perform pot analysis mazas and hamm 2011 showed that along with gev and gp distribution functions the gamma distribution function often behaves well in terms of fitting the data therefore performance of gamma distribution function is also examined the cumulative distribution function of gamma is given by 5 f z σ ξ γ ξ z σ γ ξ where γ is the gamma function and γ is the lower incomplete gamma function to demonstrate and assess the performance of different extreme value analysis models the simulated wave heights at stingray point are used in this section both gev and pot analysis are performed for gev analysis annual and monthly maxima are extracted from simulated wave height data the parameter estimation is performed by mle and l moments the results of mle are shown in fig 15 the density plots fig 15a d show good agreement between the empirical density red line and that of the fitted gev distribution function dashed blue line for both annual and monthly maxima fig 15b e show q q plots of the empirical data quantiles against those derived from the fitted gev distribution function the plots are reasonably straight indicating that the utilization of the gev distribution function is fulfilled by good approximation for annual maxima fig 15b a slight deviation from the straight line can be observed however this deviation is typical for extreme value analysis because of uncertainties associated with extreme value problems finally fig 15c f show the return levels corresponding to different return periods of extreme wave heights for annual and monthly maxima respectively the points on the graphs fig 15c f are the estimated return levels from annual and monthly maxima data respectively the solid blue lines are the estimated return levels based on the fitted gev model and the dashed red lines are 95 confidence intervals for both models the empirical values fall within the 95 confidence intervals and close to the estimated return level especially for the monthly maxima model showing that both models can provide acceptable values for return levels more detailed information regarding the return levels using different parameter estimators are presented in table 2 and table 3 respectively both the plots and tables show that return levels extracted from annual maxima data have higher values compared to those extracted from monthly maxima data for example return levels for 10 25 50 and 100 years return periods from annual maxima data are 26 19 14 and 10 higher than those from monthly maxima data it can be also seen from the tables that there are minor changes in return levels in terms of using different parameter estimators the variation of return level is less than 0 6 indicating that both estimators can be used for extreme value analysis of wave height for pot analysis a threshold of 1 m and a time span of 3 days are selected which results in 386 independent storms the yearly distribution of storm events is presented in fig 16 it can be seen from fig 16a that more than 75 of storm events occur in the winter season fig 16b shows the distribution of independent storms above 1 m in year day in which extreme storm events annual maxima and 5 largest storms in each year are presented with different symbols the largest wave heights appear in the later hurricane season sep and oct as detected by eof analysis seasonal variation of extreme wave heights is observed the results using mle estimator is presented in fig 17 density plot fig 17a shows a good agreement between the empirical density function red line and the fitted gp distribution function dashed blue line similar to gev model q q plot fig 17b from gp model is straight indicating that gp distribution function can be used for eva with good approximation the empirical points fig 17c are very close to the estimated return levels from gp distribution function showing that it provides good approximation for return levels comparisons of return levels using different estimators are shown in table 4 slight differences on return levels are observed using mle and l moments estimators comparison of return levels obtained from gev and pot show that pot and gev produce almost the same results especially for higher return periods for example for 100 year return period pot and annual maxima gev produce the same results while for monthly maxima gev model the difference is only 10 from the above analyses it can be concluded that both gev and pot are reliable approaches for estimating design wave heights more detailed comparisons of these three approaches are presented in fig 18 in which return levels or design wave heights are plotted against return periods using mle estimator the conclusions are the same as what are observed in tables 2 4 5 discussions the choice of distribution functions the selection of threshold and time span as well as data length included in the analysis are important in extreme value assessment therefore this section is devoted to perform sensitivity analyses of these parameters to understand the effects of each parameter on the estimation of design wave height 5 1 threshold and time span in order to investigate the impacts of threshold wave height and time span on design wave heights a sensitivity analysis is performed by choosing values of 0 8 0 9 1 0 1 1 and 1 2 m for threshold wave height and 3 4 5 and 6 days for time spans the return levels are calculated using mle estimator and results for different time spans are shown in tables 5 8 it is shown that design wave height generally increases for different return periods with increasing time span another interesting result is that for a specific time span higher threshold wave height results in higher return level although the variation rates of return levels are very small especially for higher return periods 5 2 distribution functions in order to evaluate the performance of gev and gp distribution functions in terms of fitting the data a comparison is made between gev distribution functions and weibull gumbel gamma and log normal distribution functions by calculating bayesian information criterion bic also known as the schwarz criterion schwarz 1978 and akaike information criterion aic akaike 1974 bic minimizes the bias between the fitted model and the unknown true model which is given by 6 b i c 2 l n l k p l n n where l is the likelihood of the fit n is the sample size number of storm peaks above threshold and k p is the number of parameters of the distribution the aic which can be inferred as the best compromise between bias and variance is given by 7 a i c 2 l n l 2 k p a lower value of aic or bic indicates a better fit it is worth noting that the best fit does not necessarily provide the desirable result for design purposes as selecting a conservative return level seems more reasonable the goodness of fit test is firstly performed on gev weibull gumbel gamma and log normal using annual maxima data table 9 shows the summary of aic and bic values calculated for different models using mle it can be seen from table 9 that there is a slight difference between aic and bic calculated from the models showing that nearly all models are capable of fitting the annual maxima data however gamma distribution function gives the best fit and gev provides a better fit than weibull and gumbel distribution functions q q plot is employed to qualitatively compare the performance of all models and to check whether or not the actual and model data sets come from a population with the same distribution fig 19 for gumbel and weibull distribution functions q q plots confirm aic and bic tests shown in table 9 as some points deviate from the straight line however for gev log normal and gamma distribution functions the points fall approximately along the reference line indicating that these models provide better fits analyses are also performed on monthly maxima data to evaluate the performance of all models the results are presented in table 10 clearly weibull distribution function fails to give a good fit since aic and bic values of this model are much higher compared to others and gamma distribution function still provides the best fit q q plots fig 20 show graphically that weibull and gumbel distribution functions are not good options for eva on extreme wave heights and gev and gamma distribution functions provide the best fits among all models the log normal distribution function is not able to capture the tail of distribution function with deviations from the central line for pot analysis gp distribution function is compared with gamma and log normal distribution functions and the results of aic and bic tests are shown in table 11 in this analysis threshold wave height of 0 8 m and time span of 3 days are chosen q q plots fig 21 are also drawn to verify results obtained from aic and bic tests it shows that none of distribution functions are suitable for pot analysis except gp distribution function which can be considered as a suitable tool for pot analysis of the data 5 3 length of data used in the analysis the length of data included in the analysis can also play a significant role in obtaining the proper design wave height therefore a sensitivity analysis is performed in terms of sample duration by using 10 19 28 and 37 years datasets corresponding to the datasets during 1979 88 1979 97 1979 2006 and 1979 2015 respectively the design wave heights with a return period of 100 years are obtained using gev gamma and gp distribution functions it can be seen from table 12 that longer dataset results in higher design wave height which contradicts the findings of mazas and hamm 2011 that shorter dataset produced higher design wave height this contradiction is mostly due to the property of data being analyzed since extreme events are unpredictable higher design wave height can be obtained in smaller datasets if extreme storm events happen during that time period in addition a minor difference 2 maximum difference between design wave heights obtained from 28 and 37 year dataset is obtained suggesting that 28 years might be sufficiently long for extreme wave height analysis the maximum difference intensifies for 10 and 19 year dataset compared to 37 year dataset by 18 and 14 respectively therefore these datasets can not provide good estimates of design wave height for 100 year return period based on the analyses performed in this study gamma gev and gp distribution functions are selected to draw contours of design wave heights with 100 year return period for the entire chesapeake bay the results are shown in fig 22 the design wave height generally decreases from lower bay to the upper bay with design wave height between 1 5 and 2 m in the upper bay it increases substantially in the lower bay and reaches up to 3 25 m gamma distribution function gives a more conservative estimate of design wave height fig 22a compared to gev and gp distribution functions fig 22b c gp distribution function fails to provide design wave height in shallow areas since its analysis is based on a threshold value that might be greater than largest waves in those areas 6 conclusions in this paper swan wave model was applied to reconstruct the wave climate in chesapeake bay during 1979 2015 the spatial and temporal variabilities of the simulated wave heights in the bay were firstly analyzed using eof analysis regression analysis as well as cumulative distribution function analysis eof analysis performed on daily averaged swhs showed seasonal variability of wave heights in chesapeake bay with larger wave heights in winter season it also revealed that the lower bay experienced more significant variations in wave height extreme storm events such as hurricanes and tropical storms could be detected from the first mode of pc regression analysis on swhs at stingray point suggested that there was a steady increase of extreme wave heights in the chesapeake bay however the long term change was not significant the continuous increase of extreme waves was further verified by empirical cumulative distribution function analysis for two separate periods 1979 1997 and 1998 2015 in which a 9 increase in extreme wave height was observed in 99 5 percentile these findings were confirmed by obtaining 99 5 percentile for the entire bay results suggested that except lower bay where there was a maximum of 0 27m decrease in wave height the rest of the bay received an average wave height increase of 0 1 m in the extreme value analysis both gev and pot methods were applied to estimate design wave heights the reliability of these methods was extensively studied the effects of key parameters such as threshold value time span as well as data length on the design wave heights were evaluated the gev and pot analyses performed on annual and monthly maxima and independent extreme waves with threshold of 1 0 m and time span of 3 days showed that design wave heights with 100 year return period evaluated from gev for annual maxima data and gp model were higher than those from monthly maxima data by 10 therefore annual maxima and pot approaches provided a more conservative estimate of design wave height for design purposes the effects of time span and threshold on design wave height were examined by tests on different time spans 3 4 5 and 6 days and various thresholds 0 8 0 9 1 1 1 and 1 2 m it was found that increasing time span leaded to larger design wave height and higher threshold resulted in higher design wave height moreover sensitivity analysis on data duration showed that a 28 year dataset could provide an acceptable estimate of design wave height in the bay the performance of gev and gp was also evaluated in terms of fitting the data against various distribution functions including weibull gumbel gamma log normal distribution functions using aic bic test and q q plots results indicated that gamma and gev provided the best fit for annual and monthly data while gp distribution function gave the best fit when pot analysis was conducted acknowledgments ma acknowledges the financial support from padi foundation lou thanks for the support from the national natural science foundation of china nsfc 41602244 
23356,this study concerns fluid structure interaction analysis by using a solid acoustic finite element model letting an acoustic medium represent the fluid this is a promising methodology to obtain computationally affordable advanced models of fluid structure interaction problems were the deformations can be assumed relatively small and the added mass effects dominate the dynamic characteristics the work presents an extensive study of 19 plate specimens with material properties corresponding to carbon fibre reinforced plastics glass fibre reinforced plastics as well as steel and aluminium and a range of different panel aspect ratios in particular the effects of added mass on fibre reinforced plastic materials are highlighted in comparison to how these typically are treated in the industry today based on a systematic isolation of the added mass effects this paper enables a precise evaluation of the solid acoustic fsi modelling approach the modelling technique is also compared with previously published experiments the results show good agreement less than 3 difference between numerical and experimental results for the first natural frequency the results indicate that this is a very promising modelling technique that can serve as a refined analysis method for design work performed within the maritime industry keywords fluid structure interaction added mass wet natural frequencies submerged cantilever plates composites 1 introduction polymer composite materials play a crucial role in designing optimised structures for the maritime environment composite materials have a wide range of applicability as they have high stiffness to weight ratio are corrosion resistant and can be taylor designed for very attuned purposes and needs may it be lighter over all weight and thereby increased speed and or range which typically is the case or some very specific capabilities such as bend twist coupling or taylor designed acoustic impedance or simply aesthetics with complex shapes and high requirements on surface finish as the tension on the worlds resources grows and the need for environmentally sound solutions increases there is also an ever increasing need for more energy efficient and optimised structures this concerns both military and civilian applications ranging from entire hull structures to cantilevered structural components such as hydrofoils fins keels turbines and propeller blades e g lönnö 2003 marsh 2006 young et al 2016 mouritz et al 2001 regardless of part however to design an optimised component it is essential that the dynamic loading situation is understood properly and that the dynamic characteristics of the part can be predicted with enough accuracy for the situation at hand for structures submerged in water a complicating factor is the accentuated effect of added mass from the surrounding water that lowers the natural frequencies and thereby changes the dynamic characteristics of the component the dynamics of submerged cantilevered beams and plates has indeed been studied extensively within the research community since the mid 1960s e g lindholm et al 1965 muthuveerappan et al 1979 zheng ming 1992 liang et al 2001 fluid et al 2003 kramer et al 2013 sedlar et al 2011 however the main focus has been on metallic structures and hence the knowledge about the behaviour of composite materials in sub sea applications is more limited the focus on steel structures by the research community naturally also influences the typical design methods or rule of thumb used in the industry today typically steel or brass weight is simply doubled and no concern is taken for geometrical aspects when estimating the added mass effect on the natural frequencies there is hence a lack of knowledge and design methods for complex composite structures which is limiting the designers from utilising the full potential of composite materials and developing optimised structures in previous studies it is also shown that lighter composite materials with high specific stiffness are more susceptible to the influence of the surrounding water hence the added mass effect can have an even greater influence on the natural frequencies of composite materials than for the heavier steel or aluminium structures e g kramer et al 2013 stenius et al 2016 kwon et al 2013 presents an experimental study on the effect of water on vibrating cantilever beams the tested beams are slender plates with a narrow width and the results are in line with those presented in stenius et al 2016 with the dry to wet eigenfrequency ratio of 70 for aluminium 60 for cfrp and 50 for gfrp kwon et al 2013 used two test setups one where the beam was clamped in one end and another test where it was free free in the first test the displacement was monitored using digital image correlation dic techniques and in the latter ten accelerometers where assembled along the length of the beam in both test set ups the beams where initially disturbed either released from a pre stressed state or impinged by an impact hammer and the response was thereafter monitored further resent research on the fluid structure interaction also demonstrates the effect of the fluid compressibility e g canales and mantari 2018 and how to account for these effects in the design by analytical expressions traditional approaches of addressing fluid structure interaction problems can for instance be found in the review by young et al 2016 describing the current state of the art in modelling adaptive composites propellers young et al 2016 describes the progress and challenges of the simulation topic very well the review includes composite propellers but is equally applicable to all submerged and flexible bodies young et al 2016 describes different simulation techniques for both inviscid and viscous fluid structure interaction modelling and also includes a comprehensive reference list to the research field to fully resolve the flow around a vehicle in air or water using viscous flow computational fluid dynamics cfd with large eddy simulations les the grid must be highly resolved around the boundaries of the structures and this in turn also requires a very fine mesh and time step spalart 2000 predicts that a fully resolved les modelled flow around an airliner or car will include 10 11 grid points and be possible to perform in 2045 the model discussed in spalart 2000 is intended to resolve the flow around the object and not only the pressure acoustics but still the size of the model and computational power needed is overwhelming the topic of this paper concerns development and evaluation of more computationally efficient methods but still precise enough to predict the dynamic characteristics of submerged structural components the focus is to study more complex geometries than simple cylinders or rectangular plates with an interior consisting of internal stiffening with varying non isotropic material properties with for example local modes or bend twisting coupling which often is the case in real engineering problems the added mass then no longer depends only on a rigid outer geometry e g cylinder and the fluid properties a very promising approach is to utilise acoustic fluid structure interaction modelling techniques which are simple and straightforward with modern modelling techniques eliminating the need for deriving separate added mass properties yet fast enough for optimisation considerations large finite element models of the design can hereby be analysed and solved within fractions of the computational cost of fully coupled cfd fem or similar e g kwon and plessas 2014 motley et al 2013 the acoustic fluid structure modelling technique is not new in it self the finite element approach has been used in the car industry when predicting internal noise since the 1970 s hambric et al 2016 kim et al 1999 it is also possible to include the effect of a surrounding acoustic domain using a wave formulations hambric et al 2016 zhang 2002 normally when airborne sound is predicted a one sided coupling is sufficient coupling the movements of the structure to the pressure sound waves in the air in the application with slender structures submerged in water a two way coupling is necessary since the surrounding acoustic domain affects the eigenfrequencies of the submerged structure however there is a lack of well described and rigorous acoustic fluid structure finite element simulations in the literature which are compared to physical experiments therefore the accuracy of the modelling technique depending on the inherent simplification of modelling water as an acoustic medium is difficult to assess kwon and plessas 2014 introduces a technique for modelling the fluid domain in one far field and one close field sub domain in order to further reduce the computational cost although this seems to be a reasonable approach it is not clear from kwon and plessas 2014 whether the authors have studied mesh convergence and the sensitivity of the location of the boundary between the far field and the close field fluid domains and to what extent this might affect the results and conclusions drawn in the paper motley et al 2013 also use a similar modelling technique i e coupling rectangular cantilevered plates using shell elements with a fluid represented by an acoustic medium to simulate the boundary effect in the proximity of a rigid wall or free surface to the natural frequencies of the plates motley et al 2013 compare their simulations with experiments by lindholm et al 1965 showing good agreement further their results give wet dry frequency ratio of 40 60 for studied steel plates and 20 30 for the cfrp plates which is also in line with the experimental results presented in stenius et al 2016 in this study the hypothesis is that fluid structure interaction problems where added mass effects dominate can be very efficiently simulated by using an acoustic medium for the fluid and studying the problem in the frequency domain instead of running full time domain simulations this reduces the problem to 1 degree of freedom for each grid point in the fluid domain and hence simplifies the calculations this paper presents an extensive parameter study on simulating the dry and wet natural frequencies for a large number of rectangular test specimens with different materials and dimensions the simulations are compared with experimental results presented in a previous study by the authors stenius et al 2016 the fsi simulations are systematically isolated with respect to material properties dry eigenfrequncies and boundary conditions in order to be able to single out the effect of using an acoustic medium as fluid and assess how well the problem can be modelled with this assumption 2 acoustic finite element fsi model all simulations presented in this paper are based on the commercial finite element modelling package comsol multiphysics 4 4 all parts both solid and acoustic are discretized using elements with second order shape functions and a lagrangian formulation each solid mechanics node has three translational degrees of freedom while there is only one degree of freedom pressure p in the acoustic domain a continuous mesh is used where the solid mechanics and acoustic domains share nodes at the interface boundaries thereby forcing a constant contact between the fluid and the solid this results in four degrees of freedom for the nodes on the interface surfaces separating the acoustic and solid mechanics domains the eigenfrequency problem is then solved using a full two way coupling between the solid and the acoustic nodes the modelling approach in this paper is similar to kwon and plessas 2014 but differs in how the solid mechanics domain is discretized in this paper all solid elements are second order and full 3d elements while kwon and plessas 2014 use an eight node solid shell approach with reduced integration the approach in kwon and plessas 2014 is typically limited to shell like structures as in their paper however the aim in this paper is to evaluate a modelling technique for more general submerged bodies and hence a slightly more computationally costly modelling of the solid elements is motivated further in kwon and plessas 2014 a cellular automata ca is used to reduce the size of the acoustic domain that needs to be solved using finite elements in this study the complete tank is modelled the computational cost is naturally increased with a larger acoustic domain but as long as the studied frequencies are of reasonable magnitude the size of the acoustic mesh elements can be increased and still solve the problem with acceptable accuracy 3 simulation the simulation setup in this paper is designed in order to enable a detailed comparison to the results obtained from a test series performed by the authors and presented in a previous paper stenius et al 2016 the experimental setup is illustrated in fig 1 forced vibrations are imposed on clamped cantilever test specimens around a hinged rotation point the tests are repeated with the test specimens submerged under water wet and in air dry the dimensions densities and materials of the test specimens are presented in table 1 in this section the details of the simulation configuration are outlined including evaluation of the test specimen properties the structure of this work is outlined in the flow chart in fig 2 in this chart the left hand side represents the experiments and the right hand side represents the simulations performed to obtain the results for comparison on the experimental side left the majority of the work has been performed and presented in a previous paper see stenius et al 2016 the focus of this paper right side of the flow chart in fig 2 is to present a methodology for efficient numerical analysis of this type of fluid structure interaction problems and to make a detailed comparison to the results from the aforementioned experimental study the chart in fig 2 also shows the outline of how the test specimen properties from the experiments are obtained for the numerical modelling the work can be divided into four distinct steps enumerated below for each step the details are explained further in the subsequent sections 1 the first step is to evaluate the stiffness modulus for the individual specimens this is done through free vibration tests as well as by using the fe models of the plates fig 3 to ensure that the bending stiffness of the plates are correct in the subsequent steps 2 the second step involves calibration of the fe model to account for the simplified modelling of the specimen clamping fixture the fe model of the clamping fixture can be seen in fig 4 while the real clamping fixture can be seen in fig 5 the main difference is that holes gaps and bolts are not fully included in the fe model however through the calibration procedure their effect on the moment of inertia is accounted for 3 the third step is to run all simulations in the test series for the in air conditions to obtain the dry eigenfrequencies 4 in the fourth and final step an acoustic medium is added to the fe model to represent the surrounding water fig 6 in this step the specimens are simulated with the surrounding acoustic water medium in accordance with the wet experimental test series stenius et al 2016 finally the results in terms of dry and wet eigenfrequencies are compared from both simulations and experiments 3 1 fe model setup the solid model setup is schematically illustrated in fig 7 the solid model is constrained by pinning the axis of rotation restricting displacement u and w of the test rig see fig 8 and also restricting movement along this axis of rotation by locking displacement in the y direction v at two nodes see fig 9 close to the centreline of the test rig the simulated test rig hence has one free rigid body mode rotating around its axis of rotation but is restrained to move in all translational degrees of freedom the structural model is meshed using 3d solid tetrahedral elements the purpose with using 3d solid elements is to evaluate a generic approach that can be applied to any geometrical shape and not be limited to shell applications only 3 2 step 1 evaluation of young s modulus to determine stiffnesses i e the young s modulus e for the individual test specimens a free vibration impulse hammer test is performed impulse hammer tests are a commonly used procedure in the industry where standards exist e g iso 12680 1 2005 to evaluate the eigenfrequencies of a structure e g fagerberg and strömberg 2007 the test results are then typically used together with a model of the component analytical or numerical to calibrate or verify the properties of the model in a free vibration impulse hammer test the plates are typically suspended from two lightweight strings whereby the boundary conditions of free boundaries are approximated the test specimens are instrumented with accelerometers and pinged with an impulse hammer with an incorporated load cell the plates response to the impulse can be recorded as a function of time from which the free natural frequencies of the specimens are obtained an example recording of specimen 15 table 1 is illustrated in fig 10 the plate vibrations will be dominated by the natural frequencies transferring the measured time signal from the impulse test to the frequency plane gives the natural frequencies for the given specimen see fig 11 specimen 15 in table 1 the measured frequencies are used for further evaluation of the specimens stiffness and thereby derive the equivalent bending young s modulus the equivalent bending young s modulus is the young s modulus which will give the correct bending stiffness for the plates the term stiffness modulus e mod will be used in this paper to refer to that equivalent bending young s modulus it should be noted that for the metallic specimens the equivalent bending young s modulus is the same as the normal young s modulus while for the composite specimens this is not the same however as the focus in this paper is on the first bending modes for the specimens the equivalent bending modulus is adequate for this study 3 2 1 analytical evaluation if the plate is approximated as a beam the following expression can be used to calculate the natural frequency harris and piersol 2002 1 ω n a e i μ l 4 in eq 1 ω n is the n t h angular frequency e is the equivalent bending young s modulus i is the area moment of inertia l is the length of the beam μ is the mass per unit length of the beam and a is a factor that depends on the boundary conditions and mode number for free free conditions a can be seen in table 2 harris and piersol 2002 from eq 1 a preliminary stiffness modulus for the individual plate specimens is calculated the results from these calculations table 4 column e mod analytic are then used in the next step as a starting value for the fem evaluation there are similar equations for plates see e g guyader 2013 or leissa 1969 for example but since the boundary constraints one short side clamped in this case are equivalent to a cantilever beam and the obtained value is only used as a starting point for calculating the equivalent young s modulus in the fe model the beam equation can readily be used 3 2 2 evaluation using fem to refine the value from the analytical calculation in the previous step and to take into account the presence of the drilled holes the full fe model of the plate is used here the model see fig 3 consists of a linear elastic material and the geometrical properties and the material density of the individual specimens are taken from the reference study stenius et al 2016 for this calculation only solid mechanics are considered no acoustic medium present the material is assumed to be isotropic homogenous and linear elastic for all test specimens even the composites assuming a reasonable poisson s ratio of 0 3 gives that the material if fully described by the young s modulus and that the shear modulus can be calculated using g e 2 1 ν this is a simplification especially for the composite plates but since all tested composite lay ups are symmetrical there is no bend twisting coupling the first eigenmode is therefore pure bending for the tested plates and the chosen material model is sufficient to find the sought after stiffness modulus an optimisation is performed the objective is to minimise the difference between measured frequency f i m p u l s e from the free vibration test and the frequency calculated by the model f m o d e l the objective function is written as 2 m i n i m i s e f i m p u l s e f m o d e l 2 with respect to the stiffness modulus this is done by varying the normalised stiffness modulus of the material profile the initial stiffness modulus which is obtained from the analytical evaluation is multiplied with a factor n which has a starting value of 1 varying the stiffness is done by varying the factor n the normalisation of the modulus serves to prevent the algorithm from exiting the optimisation loop prematurely for numerical reasons to solve the optimisation the bobyqa algorithm is used with a convergence criteria of 0 01 bobyqa stands for bound optimisation by quadratic aproximation and is a derivative free algorithm see e g powell 2009 the resulting stiffness modulus from these calculations for the individual specimens are listed in table 4 column e mod fem from the results in table 4 it can be seen that for the cfrp plates there is a thickness dependence for the modulus this is due to the stacking sequence of the laminate in bending there is a sequence dependence for the stiffness if the zero degree layers are placed in the outer surfaces of the laminate the bending stiffness will be higher than if they are placed at the centre to clarify for the composite test specimens the derived stiffness modulus is the equivalent bending young s modulus as discussed above the plates used in the benchmark study stenius et al 2016 are made of carbon fibre mats with a surface weight of 1000 g m 2 these mats consists of a number of layers in 0 45 90 45 directions with 400 g m 2 in the 0 direction and 200 g m 2 in each of the other directions each layer or quad builds approximately 1 m m in thickness i e the 4 m m plates consists of four layers the 6 m m of six and so on all these mats are stacked so that the 0 layers are closest to the centre of the plate see table 3 for the thicker plates more quads as they are referred to in table 3 are added on the positive and negative side respectively with the same orientation thicker plate means more layers which means more 0 layers further from the neutral axis resulting in a higher stiffness modulus table 4 column e mod fem 3 2 3 mesh sensitivity study to determine that the fe mesh is refined enough to model the frequencies for the plates accurately a mesh convergence study is performed this convergence study is done using the baseline aluminium test id 15 in table 1 the mesh density is stepwise taken from a coarser to a finer mesh the number of elements and output frequencies are recorded and plotted for the first frequency fig 12 illustrates the results of the convergence study for the free free supported specimen setup which simulates the impulse hammer tests as seen in fig 12 it can be observed that the solution for the first eigenfrequency converges rapidly for the first frequency there is a difference of 1 4 between the first and the second calculation going from 295 to 659 elements after that the difference between the data points falls under 0 25 for the first frequency for the stiffness calculations in this paper the finest mesh density is selected i e 17142 elements the highest number of elements in fig 12 a mesh convergence study is further also performed on the solid test specimens including the clamping fixture this is as for the free free supported specimen setup above done by increasing the mesh refinement from coarse to extremely fine see example of mesh refinemen in fig 14 where fig 14a represents a normal mesh setting and fig 14b represents an extra fine mesh setting the results are presented in fig 13 as can be seen the results converge well the final selection of mesh refinement is the second most fine mesh represented by a green dot in fig 13 extra fine in fig 14b the mesh of the specimens is governed by the thickness of the plates i e 4 10 mm and there is only one tetrahedral element through its thickness with the chosen mesh density the aspect ratio and quality of these elements are sufficient and with the second order shape function lagrange formulation the bending stiffness and bending modes of the plates are well resolved typically there is 20 30 elements per quarter of the first bending mode the modelling and the calibration is performed for all the 19 plate specimens with the mesh density marked in green in fig 13 resulting in 12323 elements for the clamp and plate all 19 plate specimens are meshed with the acoustic domain present this is done so that the model is evaluated using the same mesh that is used for the acoustic solid fsi modelling in the subsequent steps 3 3 step 2 effective clamp fixture density in the experimental study the clamping fixture consists of two aluminium profiles between which the end of the plate specimen is clamped see fig 5 these are held together by a number of steel bolts a varying number of washers are used to align the test specimen so that the central plane of the plate aligns with the axis of rotation for all test specimen thicknesses in the fe model the clamp is a simplified geometry that has similar dimensions as the actual clamp as the clamping fixture is simplified in the fe model the effective density will be slightly different from the raw material density of aluminium from the previous step an accurate representation of the stiffness modulus for the test specimens is obtained hence by varying the clamping fixture density of the fe model so that the simulated eigenfrequencies match the measured dry eigenfrequencies an accurate representation of the effective density of the clamping fixture is obtained the calibration is done through an optimisation procedure described below where the clamp material is given a starting value of 2700 k g m 3 for this optimisation the objective function is written as 3 f t e s t f m o d e l 2 the resulting density of this optimisation represents the effective density of the specimen clamping fixture the bobyqa algorithm powell 2009 is used with a convergence criteria of 0 01 to perform this optimisation the resulting clamp densities from this optimisation are presented in table 4 column clamp dens 3 4 step 3 dry eigenfrequencies with the calibrated fe model from the previous steps the dry eigenfrequencies for all test specimens table 1 are calculated through the simulations the results are tabulated in in table 4 labeled dry simulations 3 5 step 4 wet natural frequency the model depicted in fig 6 contain the same clamp plate model as in the dry case but now the acoustic domain is also activated representing the surrounding water tank this is a multi physics model with solid mechanics acoustics interaction the density for the acoustic medium is 1002 k g m 3 and the speed of sound is 1481 m s which corresponds to the real conditions during the experiments stenius et al 2016 3 5 1 boundary conditions the boundary conditions for the specimen and clamp part of the model are largely the same as in the dry case except for the free boundaries these are now replaced by an acoustic structure boundary which connects the solid mechanics to the pressure acoustics domain in the surrounding tank the boundary conditions of the acoustic domain are modelled using five sound hard surfaces and one soft surface where p 0 the sound hard surfaces corresponds to the sides of the tank grey sides in fig 16 and the soft surface to the water surface blue in fig 16 3 5 2 convergence with acoustic fluid domain similarly as for the dry conditions a convergence study is performed with the acoustic domain modelling the water the mesh density is stepwise taken from a coarse to a finer mesh for the acoustic domain while keeping the mesh density of the clamp plate domain constant the number of elements and resulting frequencies are recorded for each step and the results are shown in fig 15 this shows very small variations in calculated frequency 0 1 these small variations are due to the fact size of the elements in the acoustic domain are governed by the mesh density of the clamp plate domain which is kept constant the calculations leading to the results presented in table 4 are performed at the fine mesh density marked green in fig 15 a minimum of 6 elements per wavelength is also preferable to accurately model the frequencies in the acoustic domain this can be evaluated using equation 4 4 f v λ where f is the frequency v is the wave speed and λ is the wave length the maximum element length in the fine setting used for the calculation of the wet frequency is 0 48 m using equation 4 shows that with this setting the model should be able to accurately calculate frequencies up to 514 h z as can be seen in table 4 this is higher than all the calculated frequencies 4 results results from the modelling of the wet natural frequencies in section 3 5 are presented in table 4 and figs 17 19 in fig 17 wet frequencies are plotted versus dry frequencies with colour coding of the different material groups fig 18 is depicting the ratio wet to dry frequencies versus dry frequencies fig 19 illustrates the relative error between simulations and experiments to start with the results from the simulations agree very well with the tests and the effect of the surrounding water is captured with surprisingly good accuracy considering the simplifications made assuming an acoustic medium it can be seen that both the effect of material and geometry is in line with the results obtained from experiments stenius et al 2016 it is shown that a stiffer and heavier plate with smaller area subjected to water is less affected by the surrounding fluid than a lightweight and less stiff plate with a large area projected in the direction of movement the ratio between wet and a dry eigenfrequencies fig 18 vary from 80 for the stiffest shortest and narrowest cfrp plate to 30 for the longest thinnest and widest cfrp plate see fig 18 the wet to dry ratio is highly coupled to geometry and it is a larger variation within the range of cfrp plates alone than between the different tested materials this is however as expected since the group of cfrp plates has the largest geometrical variation and the applied stacking sequence results in a proportionally lower bending stiffness for the thinner plates all figures show a very good agreement between modelled and tested results for the first natural frequency fig 19 shows that the difference between simulations and experiments is less than 3 for most of the specimens the error is positive i e the prediction is overestimating the eigenfrequencies this is interesting and in line with using the assumption of an acoustic medium instead of a fluid as this approach is neglecting viscous damping from large displacements flows and edge vortices intuitively it would have been assumed that the viscous effects from water would have been more pronounced for the long and flexible plates that have larger deformations with corresponding tip and edge vortices both being neglected in the acoustic simplification of the fluid hence the error between measurements and simulations could be suspected to be larger for specimens 4 9 12 and 19 than for 5 8 and 11 table 4 this is also true for most specimens except specimen 9 which is long wide and thin but still shows a negative but small error of 1 1 the only specimen showing a larger negative error is specimen 8 which is the stiffest cfrp plate being shortest narrowest and thickest and presenting an error of 3 1 this discrepancy could possibly be attributed to the fact that measuring the dry eigenfrequencies is more difficult for the higher frequency plates than for those with lower frequencies comparing the error obtained in the submerged simulation with the accuracy in the experimental set up can be performed by looking at the variation in estimated young s modulus of specimen of the same material for cfrp of medium thickness the variation is 4 8 for thin cfrp 0 8 and thick cfrp 2 1 gfrp shows a variation in young s modulus of 5 1 aluminium 1 9 and steel 1 it is not surprising that there is a larger variation in the composites and the larger percentage is mostly due to a lower young s modulus for example in the gfrp the predicted young s modulus varies about 1 g p a but since the average young s modulus of the gfrp plates is about 21 g p a the variation expressed in percent appears large hence the error in predicted submerged natural frequency using the proposed method is in the same order of magnitude or better than the accuracy of the experimental setup used in the performed experiments in summary the results show that the proposed method can predict the submerged eigenfrequencies with good accuracy from the performed work it is likely that the prediction is within a few percent and that it is most likely that the predicted eigenfrequency is a little higher than the real experimental natural frequency hence if the dry natural frequency can be predicted accurately using structural finite element simulations it is likely that the submerged natural frequency can be predicted with good accuracy using fsi by combining structural and acoustic finite element simulations these simulations are fast and can be recommended as a design method for engineers working with submerged structures where the submerged dynamic properties are of interest 5 discussion conclusions the paper presents a systematic study of the accuracy in modelling added mass effects in fluid structure interaction problems by using an acoustic medium for the fluid material properties as well as aspect ratio and thicknesses of 19 specimens are analysed and compared with experimental results the contribution from this paper is that great efforts are made to systematically isolate the errors in the modelling to only be attributed to the modelling of the fluid as an acoustic medium the presented results show that predicting the submerged natural frequencies using finite element simulation where the fluid is represented by an acoustic medium is fast and reasonably accurate method the presented approach is fully adoptable to complex shapes since normal 3d solid elements can be used to achieve predictions with the same accuracy that has been presented in the paper the fe model must be modelled with enough detail and meshed fine enough to capture the stiffness of the components and surrounding fluid accurately this implies that the solid must be modelled to correctly capture the stiffness properties of the component hence no refined mesh details needed to resolve stress concentrations or gradients in fillets or other small details are required such details can of course be included without reducing the accuracy of the model but with an additional involved cost in more dofs and longer associated computational time the mesh of the acoustic domain must be fine enough to capture the acoustic pressure waves which is a function of the speed of sound and highest frequency of interest normally the recommendation is to use at least 6 s order acoustic elements per wavelength but it is often convenient to use a continuous mesh and then the element size of the acoustic domain is often governed by the element size of the solid the results from this study shows excellent agreement between measured and modelled results the quality of the result depends on how well the geometry and the material properties are represented in the simulation i e if the dry frequency can be modelled with accuracy then so can the wet frequency there is still a geometrical difference between modelled and actual clamp this is a source of error but since the dimensions of the modelled clamp are from measurements of the actual clamp the difference in affected area is very small compared to the area of the plate specimens when other sources of error are systematically isolated the simulated results are very close to the experiments for the first natural frequency the difference between experimental and simulated frequencies are within a few percent this means that fluid structure interaction can be modelled using an acoustic solid interaction model and that this can serve as a analysis method for the designers within the maritime industry the simplified geometry is compensated for using the calculation of the equivalent clamp density the large variations in wet dry ratio between plates with different material and geometry showed in the experimental study stenius et al 2016 and confirmed in this study also shows that not only can this method do the work it can also be a more refined tool than the rule of thumb method of reducing the frequency to 70 of the frequency in air by taking into account the effects of geometry and the directional dependence of the material properties in anisotropic materials the presented method is hence not limited to simplified structures such as beams plates and cylinders but can be expected to offer an efficient and accurate method suitable for engineering design optimisation acknowledgements this research has been financially supported by the swedish defence materiel administration fmv 
23356,this study concerns fluid structure interaction analysis by using a solid acoustic finite element model letting an acoustic medium represent the fluid this is a promising methodology to obtain computationally affordable advanced models of fluid structure interaction problems were the deformations can be assumed relatively small and the added mass effects dominate the dynamic characteristics the work presents an extensive study of 19 plate specimens with material properties corresponding to carbon fibre reinforced plastics glass fibre reinforced plastics as well as steel and aluminium and a range of different panel aspect ratios in particular the effects of added mass on fibre reinforced plastic materials are highlighted in comparison to how these typically are treated in the industry today based on a systematic isolation of the added mass effects this paper enables a precise evaluation of the solid acoustic fsi modelling approach the modelling technique is also compared with previously published experiments the results show good agreement less than 3 difference between numerical and experimental results for the first natural frequency the results indicate that this is a very promising modelling technique that can serve as a refined analysis method for design work performed within the maritime industry keywords fluid structure interaction added mass wet natural frequencies submerged cantilever plates composites 1 introduction polymer composite materials play a crucial role in designing optimised structures for the maritime environment composite materials have a wide range of applicability as they have high stiffness to weight ratio are corrosion resistant and can be taylor designed for very attuned purposes and needs may it be lighter over all weight and thereby increased speed and or range which typically is the case or some very specific capabilities such as bend twist coupling or taylor designed acoustic impedance or simply aesthetics with complex shapes and high requirements on surface finish as the tension on the worlds resources grows and the need for environmentally sound solutions increases there is also an ever increasing need for more energy efficient and optimised structures this concerns both military and civilian applications ranging from entire hull structures to cantilevered structural components such as hydrofoils fins keels turbines and propeller blades e g lönnö 2003 marsh 2006 young et al 2016 mouritz et al 2001 regardless of part however to design an optimised component it is essential that the dynamic loading situation is understood properly and that the dynamic characteristics of the part can be predicted with enough accuracy for the situation at hand for structures submerged in water a complicating factor is the accentuated effect of added mass from the surrounding water that lowers the natural frequencies and thereby changes the dynamic characteristics of the component the dynamics of submerged cantilevered beams and plates has indeed been studied extensively within the research community since the mid 1960s e g lindholm et al 1965 muthuveerappan et al 1979 zheng ming 1992 liang et al 2001 fluid et al 2003 kramer et al 2013 sedlar et al 2011 however the main focus has been on metallic structures and hence the knowledge about the behaviour of composite materials in sub sea applications is more limited the focus on steel structures by the research community naturally also influences the typical design methods or rule of thumb used in the industry today typically steel or brass weight is simply doubled and no concern is taken for geometrical aspects when estimating the added mass effect on the natural frequencies there is hence a lack of knowledge and design methods for complex composite structures which is limiting the designers from utilising the full potential of composite materials and developing optimised structures in previous studies it is also shown that lighter composite materials with high specific stiffness are more susceptible to the influence of the surrounding water hence the added mass effect can have an even greater influence on the natural frequencies of composite materials than for the heavier steel or aluminium structures e g kramer et al 2013 stenius et al 2016 kwon et al 2013 presents an experimental study on the effect of water on vibrating cantilever beams the tested beams are slender plates with a narrow width and the results are in line with those presented in stenius et al 2016 with the dry to wet eigenfrequency ratio of 70 for aluminium 60 for cfrp and 50 for gfrp kwon et al 2013 used two test setups one where the beam was clamped in one end and another test where it was free free in the first test the displacement was monitored using digital image correlation dic techniques and in the latter ten accelerometers where assembled along the length of the beam in both test set ups the beams where initially disturbed either released from a pre stressed state or impinged by an impact hammer and the response was thereafter monitored further resent research on the fluid structure interaction also demonstrates the effect of the fluid compressibility e g canales and mantari 2018 and how to account for these effects in the design by analytical expressions traditional approaches of addressing fluid structure interaction problems can for instance be found in the review by young et al 2016 describing the current state of the art in modelling adaptive composites propellers young et al 2016 describes the progress and challenges of the simulation topic very well the review includes composite propellers but is equally applicable to all submerged and flexible bodies young et al 2016 describes different simulation techniques for both inviscid and viscous fluid structure interaction modelling and also includes a comprehensive reference list to the research field to fully resolve the flow around a vehicle in air or water using viscous flow computational fluid dynamics cfd with large eddy simulations les the grid must be highly resolved around the boundaries of the structures and this in turn also requires a very fine mesh and time step spalart 2000 predicts that a fully resolved les modelled flow around an airliner or car will include 10 11 grid points and be possible to perform in 2045 the model discussed in spalart 2000 is intended to resolve the flow around the object and not only the pressure acoustics but still the size of the model and computational power needed is overwhelming the topic of this paper concerns development and evaluation of more computationally efficient methods but still precise enough to predict the dynamic characteristics of submerged structural components the focus is to study more complex geometries than simple cylinders or rectangular plates with an interior consisting of internal stiffening with varying non isotropic material properties with for example local modes or bend twisting coupling which often is the case in real engineering problems the added mass then no longer depends only on a rigid outer geometry e g cylinder and the fluid properties a very promising approach is to utilise acoustic fluid structure interaction modelling techniques which are simple and straightforward with modern modelling techniques eliminating the need for deriving separate added mass properties yet fast enough for optimisation considerations large finite element models of the design can hereby be analysed and solved within fractions of the computational cost of fully coupled cfd fem or similar e g kwon and plessas 2014 motley et al 2013 the acoustic fluid structure modelling technique is not new in it self the finite element approach has been used in the car industry when predicting internal noise since the 1970 s hambric et al 2016 kim et al 1999 it is also possible to include the effect of a surrounding acoustic domain using a wave formulations hambric et al 2016 zhang 2002 normally when airborne sound is predicted a one sided coupling is sufficient coupling the movements of the structure to the pressure sound waves in the air in the application with slender structures submerged in water a two way coupling is necessary since the surrounding acoustic domain affects the eigenfrequencies of the submerged structure however there is a lack of well described and rigorous acoustic fluid structure finite element simulations in the literature which are compared to physical experiments therefore the accuracy of the modelling technique depending on the inherent simplification of modelling water as an acoustic medium is difficult to assess kwon and plessas 2014 introduces a technique for modelling the fluid domain in one far field and one close field sub domain in order to further reduce the computational cost although this seems to be a reasonable approach it is not clear from kwon and plessas 2014 whether the authors have studied mesh convergence and the sensitivity of the location of the boundary between the far field and the close field fluid domains and to what extent this might affect the results and conclusions drawn in the paper motley et al 2013 also use a similar modelling technique i e coupling rectangular cantilevered plates using shell elements with a fluid represented by an acoustic medium to simulate the boundary effect in the proximity of a rigid wall or free surface to the natural frequencies of the plates motley et al 2013 compare their simulations with experiments by lindholm et al 1965 showing good agreement further their results give wet dry frequency ratio of 40 60 for studied steel plates and 20 30 for the cfrp plates which is also in line with the experimental results presented in stenius et al 2016 in this study the hypothesis is that fluid structure interaction problems where added mass effects dominate can be very efficiently simulated by using an acoustic medium for the fluid and studying the problem in the frequency domain instead of running full time domain simulations this reduces the problem to 1 degree of freedom for each grid point in the fluid domain and hence simplifies the calculations this paper presents an extensive parameter study on simulating the dry and wet natural frequencies for a large number of rectangular test specimens with different materials and dimensions the simulations are compared with experimental results presented in a previous study by the authors stenius et al 2016 the fsi simulations are systematically isolated with respect to material properties dry eigenfrequncies and boundary conditions in order to be able to single out the effect of using an acoustic medium as fluid and assess how well the problem can be modelled with this assumption 2 acoustic finite element fsi model all simulations presented in this paper are based on the commercial finite element modelling package comsol multiphysics 4 4 all parts both solid and acoustic are discretized using elements with second order shape functions and a lagrangian formulation each solid mechanics node has three translational degrees of freedom while there is only one degree of freedom pressure p in the acoustic domain a continuous mesh is used where the solid mechanics and acoustic domains share nodes at the interface boundaries thereby forcing a constant contact between the fluid and the solid this results in four degrees of freedom for the nodes on the interface surfaces separating the acoustic and solid mechanics domains the eigenfrequency problem is then solved using a full two way coupling between the solid and the acoustic nodes the modelling approach in this paper is similar to kwon and plessas 2014 but differs in how the solid mechanics domain is discretized in this paper all solid elements are second order and full 3d elements while kwon and plessas 2014 use an eight node solid shell approach with reduced integration the approach in kwon and plessas 2014 is typically limited to shell like structures as in their paper however the aim in this paper is to evaluate a modelling technique for more general submerged bodies and hence a slightly more computationally costly modelling of the solid elements is motivated further in kwon and plessas 2014 a cellular automata ca is used to reduce the size of the acoustic domain that needs to be solved using finite elements in this study the complete tank is modelled the computational cost is naturally increased with a larger acoustic domain but as long as the studied frequencies are of reasonable magnitude the size of the acoustic mesh elements can be increased and still solve the problem with acceptable accuracy 3 simulation the simulation setup in this paper is designed in order to enable a detailed comparison to the results obtained from a test series performed by the authors and presented in a previous paper stenius et al 2016 the experimental setup is illustrated in fig 1 forced vibrations are imposed on clamped cantilever test specimens around a hinged rotation point the tests are repeated with the test specimens submerged under water wet and in air dry the dimensions densities and materials of the test specimens are presented in table 1 in this section the details of the simulation configuration are outlined including evaluation of the test specimen properties the structure of this work is outlined in the flow chart in fig 2 in this chart the left hand side represents the experiments and the right hand side represents the simulations performed to obtain the results for comparison on the experimental side left the majority of the work has been performed and presented in a previous paper see stenius et al 2016 the focus of this paper right side of the flow chart in fig 2 is to present a methodology for efficient numerical analysis of this type of fluid structure interaction problems and to make a detailed comparison to the results from the aforementioned experimental study the chart in fig 2 also shows the outline of how the test specimen properties from the experiments are obtained for the numerical modelling the work can be divided into four distinct steps enumerated below for each step the details are explained further in the subsequent sections 1 the first step is to evaluate the stiffness modulus for the individual specimens this is done through free vibration tests as well as by using the fe models of the plates fig 3 to ensure that the bending stiffness of the plates are correct in the subsequent steps 2 the second step involves calibration of the fe model to account for the simplified modelling of the specimen clamping fixture the fe model of the clamping fixture can be seen in fig 4 while the real clamping fixture can be seen in fig 5 the main difference is that holes gaps and bolts are not fully included in the fe model however through the calibration procedure their effect on the moment of inertia is accounted for 3 the third step is to run all simulations in the test series for the in air conditions to obtain the dry eigenfrequencies 4 in the fourth and final step an acoustic medium is added to the fe model to represent the surrounding water fig 6 in this step the specimens are simulated with the surrounding acoustic water medium in accordance with the wet experimental test series stenius et al 2016 finally the results in terms of dry and wet eigenfrequencies are compared from both simulations and experiments 3 1 fe model setup the solid model setup is schematically illustrated in fig 7 the solid model is constrained by pinning the axis of rotation restricting displacement u and w of the test rig see fig 8 and also restricting movement along this axis of rotation by locking displacement in the y direction v at two nodes see fig 9 close to the centreline of the test rig the simulated test rig hence has one free rigid body mode rotating around its axis of rotation but is restrained to move in all translational degrees of freedom the structural model is meshed using 3d solid tetrahedral elements the purpose with using 3d solid elements is to evaluate a generic approach that can be applied to any geometrical shape and not be limited to shell applications only 3 2 step 1 evaluation of young s modulus to determine stiffnesses i e the young s modulus e for the individual test specimens a free vibration impulse hammer test is performed impulse hammer tests are a commonly used procedure in the industry where standards exist e g iso 12680 1 2005 to evaluate the eigenfrequencies of a structure e g fagerberg and strömberg 2007 the test results are then typically used together with a model of the component analytical or numerical to calibrate or verify the properties of the model in a free vibration impulse hammer test the plates are typically suspended from two lightweight strings whereby the boundary conditions of free boundaries are approximated the test specimens are instrumented with accelerometers and pinged with an impulse hammer with an incorporated load cell the plates response to the impulse can be recorded as a function of time from which the free natural frequencies of the specimens are obtained an example recording of specimen 15 table 1 is illustrated in fig 10 the plate vibrations will be dominated by the natural frequencies transferring the measured time signal from the impulse test to the frequency plane gives the natural frequencies for the given specimen see fig 11 specimen 15 in table 1 the measured frequencies are used for further evaluation of the specimens stiffness and thereby derive the equivalent bending young s modulus the equivalent bending young s modulus is the young s modulus which will give the correct bending stiffness for the plates the term stiffness modulus e mod will be used in this paper to refer to that equivalent bending young s modulus it should be noted that for the metallic specimens the equivalent bending young s modulus is the same as the normal young s modulus while for the composite specimens this is not the same however as the focus in this paper is on the first bending modes for the specimens the equivalent bending modulus is adequate for this study 3 2 1 analytical evaluation if the plate is approximated as a beam the following expression can be used to calculate the natural frequency harris and piersol 2002 1 ω n a e i μ l 4 in eq 1 ω n is the n t h angular frequency e is the equivalent bending young s modulus i is the area moment of inertia l is the length of the beam μ is the mass per unit length of the beam and a is a factor that depends on the boundary conditions and mode number for free free conditions a can be seen in table 2 harris and piersol 2002 from eq 1 a preliminary stiffness modulus for the individual plate specimens is calculated the results from these calculations table 4 column e mod analytic are then used in the next step as a starting value for the fem evaluation there are similar equations for plates see e g guyader 2013 or leissa 1969 for example but since the boundary constraints one short side clamped in this case are equivalent to a cantilever beam and the obtained value is only used as a starting point for calculating the equivalent young s modulus in the fe model the beam equation can readily be used 3 2 2 evaluation using fem to refine the value from the analytical calculation in the previous step and to take into account the presence of the drilled holes the full fe model of the plate is used here the model see fig 3 consists of a linear elastic material and the geometrical properties and the material density of the individual specimens are taken from the reference study stenius et al 2016 for this calculation only solid mechanics are considered no acoustic medium present the material is assumed to be isotropic homogenous and linear elastic for all test specimens even the composites assuming a reasonable poisson s ratio of 0 3 gives that the material if fully described by the young s modulus and that the shear modulus can be calculated using g e 2 1 ν this is a simplification especially for the composite plates but since all tested composite lay ups are symmetrical there is no bend twisting coupling the first eigenmode is therefore pure bending for the tested plates and the chosen material model is sufficient to find the sought after stiffness modulus an optimisation is performed the objective is to minimise the difference between measured frequency f i m p u l s e from the free vibration test and the frequency calculated by the model f m o d e l the objective function is written as 2 m i n i m i s e f i m p u l s e f m o d e l 2 with respect to the stiffness modulus this is done by varying the normalised stiffness modulus of the material profile the initial stiffness modulus which is obtained from the analytical evaluation is multiplied with a factor n which has a starting value of 1 varying the stiffness is done by varying the factor n the normalisation of the modulus serves to prevent the algorithm from exiting the optimisation loop prematurely for numerical reasons to solve the optimisation the bobyqa algorithm is used with a convergence criteria of 0 01 bobyqa stands for bound optimisation by quadratic aproximation and is a derivative free algorithm see e g powell 2009 the resulting stiffness modulus from these calculations for the individual specimens are listed in table 4 column e mod fem from the results in table 4 it can be seen that for the cfrp plates there is a thickness dependence for the modulus this is due to the stacking sequence of the laminate in bending there is a sequence dependence for the stiffness if the zero degree layers are placed in the outer surfaces of the laminate the bending stiffness will be higher than if they are placed at the centre to clarify for the composite test specimens the derived stiffness modulus is the equivalent bending young s modulus as discussed above the plates used in the benchmark study stenius et al 2016 are made of carbon fibre mats with a surface weight of 1000 g m 2 these mats consists of a number of layers in 0 45 90 45 directions with 400 g m 2 in the 0 direction and 200 g m 2 in each of the other directions each layer or quad builds approximately 1 m m in thickness i e the 4 m m plates consists of four layers the 6 m m of six and so on all these mats are stacked so that the 0 layers are closest to the centre of the plate see table 3 for the thicker plates more quads as they are referred to in table 3 are added on the positive and negative side respectively with the same orientation thicker plate means more layers which means more 0 layers further from the neutral axis resulting in a higher stiffness modulus table 4 column e mod fem 3 2 3 mesh sensitivity study to determine that the fe mesh is refined enough to model the frequencies for the plates accurately a mesh convergence study is performed this convergence study is done using the baseline aluminium test id 15 in table 1 the mesh density is stepwise taken from a coarser to a finer mesh the number of elements and output frequencies are recorded and plotted for the first frequency fig 12 illustrates the results of the convergence study for the free free supported specimen setup which simulates the impulse hammer tests as seen in fig 12 it can be observed that the solution for the first eigenfrequency converges rapidly for the first frequency there is a difference of 1 4 between the first and the second calculation going from 295 to 659 elements after that the difference between the data points falls under 0 25 for the first frequency for the stiffness calculations in this paper the finest mesh density is selected i e 17142 elements the highest number of elements in fig 12 a mesh convergence study is further also performed on the solid test specimens including the clamping fixture this is as for the free free supported specimen setup above done by increasing the mesh refinement from coarse to extremely fine see example of mesh refinemen in fig 14 where fig 14a represents a normal mesh setting and fig 14b represents an extra fine mesh setting the results are presented in fig 13 as can be seen the results converge well the final selection of mesh refinement is the second most fine mesh represented by a green dot in fig 13 extra fine in fig 14b the mesh of the specimens is governed by the thickness of the plates i e 4 10 mm and there is only one tetrahedral element through its thickness with the chosen mesh density the aspect ratio and quality of these elements are sufficient and with the second order shape function lagrange formulation the bending stiffness and bending modes of the plates are well resolved typically there is 20 30 elements per quarter of the first bending mode the modelling and the calibration is performed for all the 19 plate specimens with the mesh density marked in green in fig 13 resulting in 12323 elements for the clamp and plate all 19 plate specimens are meshed with the acoustic domain present this is done so that the model is evaluated using the same mesh that is used for the acoustic solid fsi modelling in the subsequent steps 3 3 step 2 effective clamp fixture density in the experimental study the clamping fixture consists of two aluminium profiles between which the end of the plate specimen is clamped see fig 5 these are held together by a number of steel bolts a varying number of washers are used to align the test specimen so that the central plane of the plate aligns with the axis of rotation for all test specimen thicknesses in the fe model the clamp is a simplified geometry that has similar dimensions as the actual clamp as the clamping fixture is simplified in the fe model the effective density will be slightly different from the raw material density of aluminium from the previous step an accurate representation of the stiffness modulus for the test specimens is obtained hence by varying the clamping fixture density of the fe model so that the simulated eigenfrequencies match the measured dry eigenfrequencies an accurate representation of the effective density of the clamping fixture is obtained the calibration is done through an optimisation procedure described below where the clamp material is given a starting value of 2700 k g m 3 for this optimisation the objective function is written as 3 f t e s t f m o d e l 2 the resulting density of this optimisation represents the effective density of the specimen clamping fixture the bobyqa algorithm powell 2009 is used with a convergence criteria of 0 01 to perform this optimisation the resulting clamp densities from this optimisation are presented in table 4 column clamp dens 3 4 step 3 dry eigenfrequencies with the calibrated fe model from the previous steps the dry eigenfrequencies for all test specimens table 1 are calculated through the simulations the results are tabulated in in table 4 labeled dry simulations 3 5 step 4 wet natural frequency the model depicted in fig 6 contain the same clamp plate model as in the dry case but now the acoustic domain is also activated representing the surrounding water tank this is a multi physics model with solid mechanics acoustics interaction the density for the acoustic medium is 1002 k g m 3 and the speed of sound is 1481 m s which corresponds to the real conditions during the experiments stenius et al 2016 3 5 1 boundary conditions the boundary conditions for the specimen and clamp part of the model are largely the same as in the dry case except for the free boundaries these are now replaced by an acoustic structure boundary which connects the solid mechanics to the pressure acoustics domain in the surrounding tank the boundary conditions of the acoustic domain are modelled using five sound hard surfaces and one soft surface where p 0 the sound hard surfaces corresponds to the sides of the tank grey sides in fig 16 and the soft surface to the water surface blue in fig 16 3 5 2 convergence with acoustic fluid domain similarly as for the dry conditions a convergence study is performed with the acoustic domain modelling the water the mesh density is stepwise taken from a coarse to a finer mesh for the acoustic domain while keeping the mesh density of the clamp plate domain constant the number of elements and resulting frequencies are recorded for each step and the results are shown in fig 15 this shows very small variations in calculated frequency 0 1 these small variations are due to the fact size of the elements in the acoustic domain are governed by the mesh density of the clamp plate domain which is kept constant the calculations leading to the results presented in table 4 are performed at the fine mesh density marked green in fig 15 a minimum of 6 elements per wavelength is also preferable to accurately model the frequencies in the acoustic domain this can be evaluated using equation 4 4 f v λ where f is the frequency v is the wave speed and λ is the wave length the maximum element length in the fine setting used for the calculation of the wet frequency is 0 48 m using equation 4 shows that with this setting the model should be able to accurately calculate frequencies up to 514 h z as can be seen in table 4 this is higher than all the calculated frequencies 4 results results from the modelling of the wet natural frequencies in section 3 5 are presented in table 4 and figs 17 19 in fig 17 wet frequencies are plotted versus dry frequencies with colour coding of the different material groups fig 18 is depicting the ratio wet to dry frequencies versus dry frequencies fig 19 illustrates the relative error between simulations and experiments to start with the results from the simulations agree very well with the tests and the effect of the surrounding water is captured with surprisingly good accuracy considering the simplifications made assuming an acoustic medium it can be seen that both the effect of material and geometry is in line with the results obtained from experiments stenius et al 2016 it is shown that a stiffer and heavier plate with smaller area subjected to water is less affected by the surrounding fluid than a lightweight and less stiff plate with a large area projected in the direction of movement the ratio between wet and a dry eigenfrequencies fig 18 vary from 80 for the stiffest shortest and narrowest cfrp plate to 30 for the longest thinnest and widest cfrp plate see fig 18 the wet to dry ratio is highly coupled to geometry and it is a larger variation within the range of cfrp plates alone than between the different tested materials this is however as expected since the group of cfrp plates has the largest geometrical variation and the applied stacking sequence results in a proportionally lower bending stiffness for the thinner plates all figures show a very good agreement between modelled and tested results for the first natural frequency fig 19 shows that the difference between simulations and experiments is less than 3 for most of the specimens the error is positive i e the prediction is overestimating the eigenfrequencies this is interesting and in line with using the assumption of an acoustic medium instead of a fluid as this approach is neglecting viscous damping from large displacements flows and edge vortices intuitively it would have been assumed that the viscous effects from water would have been more pronounced for the long and flexible plates that have larger deformations with corresponding tip and edge vortices both being neglected in the acoustic simplification of the fluid hence the error between measurements and simulations could be suspected to be larger for specimens 4 9 12 and 19 than for 5 8 and 11 table 4 this is also true for most specimens except specimen 9 which is long wide and thin but still shows a negative but small error of 1 1 the only specimen showing a larger negative error is specimen 8 which is the stiffest cfrp plate being shortest narrowest and thickest and presenting an error of 3 1 this discrepancy could possibly be attributed to the fact that measuring the dry eigenfrequencies is more difficult for the higher frequency plates than for those with lower frequencies comparing the error obtained in the submerged simulation with the accuracy in the experimental set up can be performed by looking at the variation in estimated young s modulus of specimen of the same material for cfrp of medium thickness the variation is 4 8 for thin cfrp 0 8 and thick cfrp 2 1 gfrp shows a variation in young s modulus of 5 1 aluminium 1 9 and steel 1 it is not surprising that there is a larger variation in the composites and the larger percentage is mostly due to a lower young s modulus for example in the gfrp the predicted young s modulus varies about 1 g p a but since the average young s modulus of the gfrp plates is about 21 g p a the variation expressed in percent appears large hence the error in predicted submerged natural frequency using the proposed method is in the same order of magnitude or better than the accuracy of the experimental setup used in the performed experiments in summary the results show that the proposed method can predict the submerged eigenfrequencies with good accuracy from the performed work it is likely that the prediction is within a few percent and that it is most likely that the predicted eigenfrequency is a little higher than the real experimental natural frequency hence if the dry natural frequency can be predicted accurately using structural finite element simulations it is likely that the submerged natural frequency can be predicted with good accuracy using fsi by combining structural and acoustic finite element simulations these simulations are fast and can be recommended as a design method for engineers working with submerged structures where the submerged dynamic properties are of interest 5 discussion conclusions the paper presents a systematic study of the accuracy in modelling added mass effects in fluid structure interaction problems by using an acoustic medium for the fluid material properties as well as aspect ratio and thicknesses of 19 specimens are analysed and compared with experimental results the contribution from this paper is that great efforts are made to systematically isolate the errors in the modelling to only be attributed to the modelling of the fluid as an acoustic medium the presented results show that predicting the submerged natural frequencies using finite element simulation where the fluid is represented by an acoustic medium is fast and reasonably accurate method the presented approach is fully adoptable to complex shapes since normal 3d solid elements can be used to achieve predictions with the same accuracy that has been presented in the paper the fe model must be modelled with enough detail and meshed fine enough to capture the stiffness of the components and surrounding fluid accurately this implies that the solid must be modelled to correctly capture the stiffness properties of the component hence no refined mesh details needed to resolve stress concentrations or gradients in fillets or other small details are required such details can of course be included without reducing the accuracy of the model but with an additional involved cost in more dofs and longer associated computational time the mesh of the acoustic domain must be fine enough to capture the acoustic pressure waves which is a function of the speed of sound and highest frequency of interest normally the recommendation is to use at least 6 s order acoustic elements per wavelength but it is often convenient to use a continuous mesh and then the element size of the acoustic domain is often governed by the element size of the solid the results from this study shows excellent agreement between measured and modelled results the quality of the result depends on how well the geometry and the material properties are represented in the simulation i e if the dry frequency can be modelled with accuracy then so can the wet frequency there is still a geometrical difference between modelled and actual clamp this is a source of error but since the dimensions of the modelled clamp are from measurements of the actual clamp the difference in affected area is very small compared to the area of the plate specimens when other sources of error are systematically isolated the simulated results are very close to the experiments for the first natural frequency the difference between experimental and simulated frequencies are within a few percent this means that fluid structure interaction can be modelled using an acoustic solid interaction model and that this can serve as a analysis method for the designers within the maritime industry the simplified geometry is compensated for using the calculation of the equivalent clamp density the large variations in wet dry ratio between plates with different material and geometry showed in the experimental study stenius et al 2016 and confirmed in this study also shows that not only can this method do the work it can also be a more refined tool than the rule of thumb method of reducing the frequency to 70 of the frequency in air by taking into account the effects of geometry and the directional dependence of the material properties in anisotropic materials the presented method is hence not limited to simplified structures such as beams plates and cylinders but can be expected to offer an efficient and accurate method suitable for engineering design optimisation acknowledgements this research has been financially supported by the swedish defence materiel administration fmv 
23357,the significant increase in the demand for shipping transportation using large vessels in restricted waters such as cruising cargo vessels in channels draws worldwide maritime industries attention to mitigating potential grounding risks safer ship navigation requires a more accurate prediction tool to estimate the likelihood of a ship striking the seabed this study presents a safety framework for under keel clearance failure analysis of vessels crossing shallow waters the developed methodology can be applied by the designers operators and port managers to maintain their shipping fleets operating at an acceptable level of grounding safety a hierarchical bayesian analysis is applied to estimate the probability of touching the seabed based on the results of dynamic under keel clearance obtained from time domain hydrodynamic simulations to illustrate the application of the proposed method the performance of a large vessel is assessed when entering the queensland coastal zone with maximum water depth of 12 m the framework suggests that for a safe navigation with maximum failure probability of 3 10 5 the vessel should cross the passage at a speed lower than 3 m s where the maximum tolerable incident wave height is 0 5 m keywords ship safety grounding under keel clearance hierarchical bayesian analysis nomenclature subscripts duck dynamic under keel clearance ukc under keel clearance swl still water level scz safe clearance zone sl safe limit ucz unsafe clearance zone nhpp nonhomogeneous poisson process h water depth m t static draft m z dynamic squad r position vector m e i direction of the force excreted in ith direction φ generic distribution function v far field particle s velocity p pressure t i time of ith observation ρ water density α shape parameter λ failure rate β scale parameter v s ship speed m s h s significant wave height m l overall length of ship m b breadth of ship m t time sec m mass kg n normal vector t i travelling time of the vessel f probability density function 1 introduction by increasing the capacity of a shipping fleet both in size and quantity industries are more attracted to minimizing the grounding risk of shipping operations particularly in restricted waters ship grounding phenomenon accounts for one third of commercial ship accidents highlighted as a major risk in marine transportation by previous researchers brown et al 1997 jebsen and papakonstantinou 1997 mazaheri et al 2014 about 20 of all tanker losses between 1987 and 1991 brown et al 1997 and 47 of all accidents of large greek vessels from 1992 to 2005 were due to grounding samuelides et al 2009 proposing a reliable framework is essential for increasing the level of safety for ship navigation in shallow waters without compromising the loading capacity of the fleet that is developing a methodology is essential to determine the minimum under keel clearance ukc of the ship that will avoid leading to a grounding accident in the literature several concepts and predefined formulae are proposed for determining the squat of a ship that sails in restricted or open water amongst them three main approaches are singled out including theoretical gates and herbich 1977 t p gourlay 2000 t gourlay 2008 empirical barrass and derrett 2011 mazaheri et al 2014 moustafa and yehia and numerical methods europe 2006 t p gourlay 2000 sergent et al 2015 most of these researches are deterministic and do not consider the uncertainty associated with the parameters involved in predicting the ukc of the vessel as a function of time the dynamic ukc can in turn assist in the assessment of touching bottom probability tbp and provide the potential for risk assessment of very large ships vls moving along a shallow passage the factors that influence the dukc of the ship such as the speed should be statistically analysed a great deal of research has been conducted to develop risk based methods for minimizing the probability of failure during ship voyaging time however these methods assume that the stochastic process is observed as a renewal process hence poisson assumption is adopted for modelling the ship tbp gucma 2004 n quy et al 2006 n m quy et al 2007 gucma and schoeneich 2008 n quy et al 2006 and n m quy et al 2007 provide a parametric modelling method for safety policy improvement of ships entering shallow waters assuming that the grounding accidents follow a poisson process gucma and schoeneich 2008 applied a monte carlo approach to assess the probability that a ferry passes its safe zone in regards to ukc their statistical method uses a large number of trial tests on the manoeuvring performance of various vessel types in different navigation conditions however based on the assumption of a renewal process the intervals between each failure event inter arrival times are independently and identically distributed iid while this can make the analysis questionable it is not a true assumption to accept that the failure rate will be independent of time in reality the dukc record of the ship for the ith time step is dependent on the value in time step t i 1 which conflicts with the assumption of a constant failure rate for the homogeneous poisson process moreover considering time dependency of the simulation data in a stochastic process is not a straightforward procedure for constructing a probabilistic model recent advances in bayesian statistical methods namely hierarchical bayesian modelling hbm that can be carried out using open source markov chain monte carlo mcmc software packages such as openbugs lunn et al 2000 have brought them to a wider audience for solving complex engineering problems kelly and smith 2009 these methods are widely used in probabilistic risk assessment pra because of their ability to provide useful estimation of model parameters when either data are sparse or the correlation between them is difficult to perceive abbassi et al 2017 el gheriani et al 2017a b kelly and smith 2009 friis hansen 2000 siu and kelly 1998 in risk analysis there is a need to adopt data from different sources with varying levels of detail and incorporating the uncertainty that accompanies the data hbm can address uncertainty among the aggregated data for each event through generating an informative prior distribution and possible observations for the event s parameter of interest el gheriani et al 2017a b there have been many applications of bayesian inference that demonstrate the advantages of this method in pra examples include risk based maintenance planning deterioration process and component failure analysis arzaghi et al 2017 bhandari et al 2016 khakzad et al 2014 straub 2009 reliability assessment of marine structures and multi criteria decision making abaei et al 2017 luque et al 2014 this paper aims at developing a methodology for reliability analysis of the vessels transiting a shallow waterway while considering the time dependency of the stochastic motion responses the results derived from this study provide the necessary information for any risk mitigation strategies and decision support tools that are concerned with improving the safety of marine transportation in a port area a number of time domain simulations are carried out to evaluate the hydrodynamic performance of the vessel at different speeds and in random sea waves nonhomogeneous poisson process nhpp is adopted to quantify the number of times that the vessel passes its safety limits of safe ground touching mcmc is then applied to predict the tbp using bayesian inference to demonstrate the application of the proposed methodology a vls approaching the northern coast of queensland is considered as a case study 1 1 dynamic under keel clearance the motion of a vessel in shallow water causes a mass of fluid to be pushed away at the front of the hull this amount of water must flow back under the vessel and along the sides of the hull resulting in the acceleration of flow particles and in turn a significant pressure drop this phenomenon leads to a reduction in keel clearance of the vessel compared with the neutral position of the stationary vessel represented in figure 1 the motion causes the hull to sink deeper into the water with a slight trimming the algebraic sum of both sinking and trimming is known as squat dynamic under keel clearance dukc of a vessel is described as the clearance left from the static draft after subtraction of squat caused by the forward motion of the ship galor 2008 1 d u k c r t h t z r t where z r t is the dynamic squat of the vessel h is the water depth and t is the static draft these parameters can be driven either from theoretical empirical or numerical approaches as recommended by sergent et al 2015 however an empirical formula will not be applicable for all types of vessels and operational conditions briggs et al 2013 and theoretical approaches cannot provide a realistic estimation of dukc due to a number of assumptions needed for developing the model t p gourlay 2000 sergent et al 2015 therefore a numerical model is essential to evaluate the hydrodynamic responses of the vessel in every degree of freedom and finding the absolute local sinkage shown as a blue circle in figure 1 to understand the dynamic behaviour of a ship s ukc the following equation developed and based on newton s second law will be considered sergent et al 2015 2 m d 2 r d t 2 m g h u l l p n e i d s i 1 2 6 where m is the mass of ship g is gravity acceleration ds is a surface element of the ship hull p is the pressure of the flow n is the normal vector on the wetted surface of the ship e i is the direction of the forces exerted in the ith degree of freedom the continuity equation yields the velocity of the flow under the keel as 3 v r t v h dukc r t where v is the far field flow velocity and r is the position vector of x y z the pressure of the flow p will be estimated using bernoulli equation sergent et al 2015 4 p r t ρ g h dukc r t ρ 2 v 2 1 h 2 dukc r t therefore a time domain numerical model needs to be employed to simulate ship squat different models are available for simulating the scenario for instance gourlay 2000 and debaillon 2005 developed a finite difference and finite element model respectively for evaluating dynamic behaviour of the vessel n m quy et al 2007 developed a 3d diffraction model using harap software to estimate the response amplitude operator of the vessel operating in random sea waves among them 3d diffraction is suggested for hydrodynamic analysis of large structures as the inertia force is dominant compared to the drag force and the computational cost is more efficient karimirad 2011 hence in this study a time domain 3d diffraction model is adopted from abaiee et al 2016 for predicting response of the vessel under random sea waves for this purpose aqwa program manual 2009 was used for processing the time domain 3d diffraction simulation and evaluating performance of dukc of the vessel in different environment conditions this approach is appropriate for large volume structures where the incident waves tend to be affected by the structure and where part of the encountering waves will be diffracted by the structure and part of them will be radiated abaiee et al 2016 1 2 hierarchical bayesian modelling performing any kind of statistical inference starts with data data is defined as the observation values of a stochastic process that may incorporate various sources of uncertainty whatever is obtained from the evaluation manipulating or organizing data is referred to as information which leads to improving our knowledge while knowledge is what is known from gathered information finally the process of obtaining a conclusion based on what one knows is regarded as inference kelly and smith 2009 hbm is a probabilistic approach that allows the organisation of inference based on real world observations into information kelly and smith 2009 siu and kelly 1998 in the present paper bayes theorem is considered for carrying out inference kelly and smith 2009 5 π 1 θ x f x θ π 0 θ θ f x θ π 0 θ d θ where θ is the unknown parameter of interest f x θ is the likelihood function and π 1 θ x is the posterior distribution in the hierarchical baysian framework multistage prior distributions defined for parameter of interest denoted by π 0 θ kelly and smith 2009 can be calculated by 6 π 0 θ φ π 1 θ φ π 2 θ where π 1 θ φ is the first stage prior representing the population variability in θ π 2 φ is the hyper prior distribution representing the uncertainty in φ φ is a vector of hyper parameters e g φ α β while α and β are the shape and scale parameters respectively of a weibul distribution the prior is developed using generic data collected from different sources numerical simulations experiments or collected from different industrial sectors these result in an informative prior distribution π 0 φ for estimating the posterior distribution hbms are found to be more reliable in comparison to classical statistical methods as they are able to incorporate various types of information each having some sources of uncertainty in the estimation process siu and kelly 1998 as a subjective based probability framework it can assist in pra by propagating uncertainties through complex models siu and kelly 1998 recently studies were conducted to bring the application of hbm in pra kelly and smith 2009 niu et al 2015 yang et al 2013 mostly they generally proved the advantages of hbm for risk and reliability assessment of process engineering such as oil spill assessment and component failure analysis in the present study a methodology is developed using hbm for predicting the likelihood of ship grounding in restricted water 2 methodology ship grounding assessment this paper aims at developing a practical safety assessment framework for estimating the tbp of vessels operating in restricted waters this framework will assist the operators to maintain the ukc of a vessel out of its critical zone the outcome of the proposed approach is the lessening of ship grounding risk and improving the safety of navigation in the port area the proposed methodology consists of two steps as presented in figure 2 and discussed in the following sections 2 1 hydrodynamic modelling in order to develop a framework for safety assessment of ship navigation in shallow water it is necessary to estimate the stochastic dynamic responses of the vessel in a random sea environment this part of the methodology will assist in evaluating time varying ukc along the entire voyage route from entering to leaving a shallow water area the results will generate essential observation data for analysing the time and number of ship grounding events as the input to the second part of study which is failure assessment for this purpose a time domain hydrodynamic simulation is employed for developing the stochastic dukc function and the maximum local sinkage of the vessel illustrated with blue points in figure 3 given by eq 7 7 dukc i j f r t v s i h s j h l b t i 1 2 n j 1 2 m where t is time r is the location of local sinkage v s is ship speed h s is the encountered random wave heights h is water depth and l and b are the length and breadth of the vessel this function should be generated for the entire range of operational ship speed v s i and significant wave height h s i to enable the evaluation of all possible manoeuvring conditions of the vessel in shallow water a safe clearance zone is defined to preserve ship s ukc in a safe condition during the voyage that is for each dukc i j an allowable safe limit sl is considered and observations of the time that the vessel enters the unsafe clearance zone ucz is recorded these observations are required as the input for the next step of the study which predicts the likelihood of ship grounding the limits of ucz are dependent on several factors related to under keel clearance such as underwater obstructions unclear layers of mud and the uncertainties associated with charted depth parker and huff 2015 in most cases the allowable ucz is defined based on ukc management system for each port for arriving and departing vessels for instance the australian maritime safety authority amsa recommends an ucz equal to 10 of the actual water depth in the region h tull 2006 in the present study this recommendation by amsa is adopted for determining the safe limit of each dukc i j record 2 2 grounding failure assessment upon obtaining the dukc responses a failure model is developed to estimate the likelihood of the vessel touching the seabed the model is based on the assumption that for any inter arrival time t i t i 1 the number of ukc points passing the sl are not identically independently distributed iid therefore the i th passage failure known as the event where the vessel passes its sl for the ith time in t i is dependent upon t i 1 in which the previous event has occurred based on this assumption the failure rate λ t is dependent on time and the simulation yields stochastic results that represent a nonhomogeneous poisson process nhpp accordingly the expected number of failures in any given time interval t i 1 t i is given by eq 8 8 λ t t i 1 t i λ t d t where nf is the number of failures that the vessel touches the seabed subsequently an appropriate function must be specified for λ t representing the nhpp some of the common forms for λ t recommended in previous studies are power law log linear and linear models chang 2001 kelly and smith 2009 for the proposed method the power law function is considered for the failure assessment of dukc due to its ability to predict the nonlinearity of random process more accurately when compared to the linear models kelly and smith 2009 this function is given by eq 9 9 λ t α β t β α 1 this model can also subsume a constant failure rate assumption in the specific state where α 1 therefore the time to observe the first passage failure event given the power law function for failure rate follows a weibull distribution with shape parameter α and scale parameter β ross 1976 stated in eq 10 10 f t 1 α β t 1 β α 1 exp t 1 β α to estimate the parameters of α and β hbm is employed for sampling the i th passage failure observations represented by the blue points located below the sl in figure 3 for each time interval t i t i 1 a conditional probability function must be defined to reflect the dependency of observation points on the previous failure events in each simulation ross 1976 as given by eq 11 11 f t i t i 1 f t i t i t i 1 f t i pr t i t i 1 i 2 n where t i is the observation time of grounding event for the vessel with a specific voyage distance s and a ship speed v s eq 11 is a truncated weibulll distribution and the recommended likelihood function by kelly and smith 2009 is defined as f t 1 t 2 t n α β in which α and β are the hyper parameters openbugs software is utilized to perform the mcmc sampling from the joint distribution of α and β to obtain the marginal posterior distribution of the hyper parameters spiegelhalter et al 2007 although the aforementioned likelihood function is not pre programmed into openbugs an aleatory model can be developed using a generic distribution function termed as dlogik as suggested by kelly and smith 2009 by defining parameter φ log likelihood eq 11 allows openbugs to update the parameters in the likelihood function phi with a vector size of n with the samples of α and β from the prior distribution in eq 13 12 φ log α α log β α 1 log t i t n β α n where t n is the last observation of the grounding event in the simulation the independent diffusive gamma distribution is used for the prior distribution of hyper parameters as suggested by kelly and smith 2009 and given by 13 α g a m m a 0 0001 0 0001 β g a m m a 0 0001 0 0001 in eq 12 t i is the ith observation of the vessel keel passing scz shown in figure 3 the mcmc sampling must be performed for i 1 n to estimate the updated posterior distribution of hyper parameters α β these distributions are then adopted to predict the probability of grounding based on a weibull function this process is repeated for each dukc i j record each simulation to investigate various failure conditions for the vessel to pass its scz during the voyage in restricted waters this results in a failure probability distribution function for each operational condition enabling the improvement of safety in ship navigation 3 methodology application case study of a vls in queensland waterway to demonstrate the application of the developed methodology the safety assessment of a vls navigating in queensland s coastal zones is considered as the case study approximately 80 of the queensland population live in the coastal region which makes for a significant demand for shipping transportation using large vessels in this area caton and harvey 2015 according to hemer et al 2007 the maximum observable significant wave height in the queensland coastal zone is 1 0 m therefore the dukc i j simulations in this study are carried out for two levels of significant wave height h s h s i 0 5 1 0 m and four levels of ship speed v s v s i 2 3 4 5 m s this results in a total of 8 simulations all performed for the maximum travel time tmax the geometry details of the vls model with a figure of the ship hull used for hydrodynamic simulations in aqwa ansys software are listed in table 1 the heave response and dukc for the first simulation for vs 2 0 m s and hs 0 5 m predicted for a voyage time of tmax 2500 s is illustrated in figure 4 in this figure the static under keel clearance sukc is computed as z 4 0 m based on the amsa recommendations regarding the safety of navigation in restricted waters a safety limit of s l 10 80 m is specified for detecting the events where the vessel keel enters ucz these detections are adopted as the observations for the assessment of ship grounding as described in section 2 2 the observations from the dukc records of simulations carried out for hs 0 5 m and the entire range of ship speed vs are illustrated in figure 5 it is clearly shown in the figure that by increasing the ship speed the number of observation points entering ucz dramatically increases from 5 points for vs 2 m s to 49 points for vs 5 m s also the range between the first and the last observation time t1 tn becomes smaller for lower ship speeds for instance at vs 2 m s the range is 985 2111 sec while it extends to 196 2485 sec when the vessel cruises at vs 5 m s the observations are then entered into the hbm for developing the likelihood functions and estimating the posterior distribution of weibull parameters α and β the model for estimating the weibull parameters α β considered two chains in the mcmc modelling approach each simulation is performed with a total of 600 e 03 iterations to predict the posterior distributions figure 6 shows the estimated posterior distribution of the shape parameter α as well as the correlation between weibull parameters α β for ship speed of vs 3 m s and significant wave height of hs 0 5 m in figure 6 the values of shape parameter for 2 5 and 97 5 percentile are α 1 375 and α 4 949 respectively the expected value of alpha is estimated as e α 2 989 stands for 2 989 which is significantly higher than α 1 highlighting the importance of time dependent assumption for failure rate of ship grounding see eq 9 the expected value of weibull parameters for all vessel speeds and wave heights are listed in table 2 it is found that shape parameter approaches α 1 as the sea environment becomes more extreme the estimated probability of ship grounding for different ship speeds and significant wave heights are computed over a voyage time of tmax 2500 s this time corresponds to a minimum voyage distance of 5 km for the ship transiting queensland restricted waterway caton and harvey 2015 and the results are presented in figures 7 and 8 it is found from these figures that any increase in the cruising speed of the vessel results in a lower expected time of grounding failure for instance in the sea states with hs 0 5 m the expected time of grounding failure for vs 2 m s and 5 m s are 0 217 e 03s and 1 015 e 03s respectively these parameters are predicted as 0 067 e 03s for vs 2 m s and 0 295 e 03s for vs 5 m s when the significant wave height is hs 1 0 m it is also observed that the variation in the grounding likelihood for different ship speeds will be decreased as the sea environment faces higher wave heights in order to examine the probability of first time to failure fttf of the vessel in a particular passage six voyage distances s are considered from the simulation results a summary of the travelling time t for different voyage distances and the ship speeds are listed in table 3 and the predicted probability of fttf of each case is illustrated as presented in figures 9 and 10 a comparison between the results in figures 9 and 10 confirms that the ship is expected to have higher probability in shorter ranges of passage distance for higher ship speeds compared to the events observed at lower speeds that is for a vessel with a higher speed the fttf is predicted to be observed more in the earlier part of the voyage with a greater probability of touching the bottom while this probability will decrease drastically by increasing the voyage distance as an example for a voyage distance of 500 m at a significant wave height of 0 5 m the probability of fttf is estimated as 3 35e 03 and 1 04e 05 for ship speed of vs 5 m s and 2 m s while these probabilities change to 3 23e 03 and 1 58e 03 correspondingly for hs 1 0 m it is observed from figure 9 that at hs 0 5 m at a cruising speed of 2 m s the maximum probability of fttf is estimated as pmax 1 68e 03 that is it is expected to occur at the voyage distance of 2000m while this probability is decreased to 0 95e 03 for vs 5 m s the results also highlight that the variation of probability of fttf between different ship speeds dramatically decreases at longer distances if it is considered that the allowable probability of grounding is 3 10 5 3 per 100 000 ship movements as recommended by vrijling 1995 the results of the case study suggest that an acceptable level of safety can be achieved while navigating at ship speeds less that 3 m s and significant wave heights of lower than 0 5 m given the geometry details of the vessel as well as the water depth of 12 m the presented results highlight that the proposed framework can model the grounding of the vessel more accurately in comparison to previous methods due to relaxing the assumption of a constant failure rate and considering the time dependency of the observed data the method can be readily used by the operators and port management systems to improve the safety of the port operations as well as developing more effective risk mitigation policies for transitioning in restricted waters 4 conclusion the present paper proposes a methodology for predicting the grounding likelihood of ships cruising in shallow waters such as coastal areas the developed framework integrates the hydrodynamic analysis of dukc with a bayesian predictive tool to achieve its objective the hydrodynamic responses of a vls are numerically analysed for different ship speeds and incident wave heights where the estimated dukc results are adopted to develop the hbm as a case study the performance of the vessel was assessed when entering the coastal zones in north east queensland with a water depth of 12 m it is observed that the predictions are highly dependent on ship speeds and sea states highlighting the need for an nhpp model in ship grounding assessment the results suggest that a vessel can safely operate in maximum incident wave heights of 0 5 m with speeds lower than 3 m s while the probability of fttf is maintained at less than 3 10 5 which is recommended by the literature as the acceptable safety limit the proposed framework can predict the grounding likelihood of a vessel more accurately by considering the time dependency in the observation data and can be applied by operators and port managers to improve the reliability of ship navigation in shallow waters and coastal areas acknowledgment the first author would like to thank the national centre for maritime engineering and hydrodynamics of the australian maritime college amc for the scholarship support 
23357,the significant increase in the demand for shipping transportation using large vessels in restricted waters such as cruising cargo vessels in channels draws worldwide maritime industries attention to mitigating potential grounding risks safer ship navigation requires a more accurate prediction tool to estimate the likelihood of a ship striking the seabed this study presents a safety framework for under keel clearance failure analysis of vessels crossing shallow waters the developed methodology can be applied by the designers operators and port managers to maintain their shipping fleets operating at an acceptable level of grounding safety a hierarchical bayesian analysis is applied to estimate the probability of touching the seabed based on the results of dynamic under keel clearance obtained from time domain hydrodynamic simulations to illustrate the application of the proposed method the performance of a large vessel is assessed when entering the queensland coastal zone with maximum water depth of 12 m the framework suggests that for a safe navigation with maximum failure probability of 3 10 5 the vessel should cross the passage at a speed lower than 3 m s where the maximum tolerable incident wave height is 0 5 m keywords ship safety grounding under keel clearance hierarchical bayesian analysis nomenclature subscripts duck dynamic under keel clearance ukc under keel clearance swl still water level scz safe clearance zone sl safe limit ucz unsafe clearance zone nhpp nonhomogeneous poisson process h water depth m t static draft m z dynamic squad r position vector m e i direction of the force excreted in ith direction φ generic distribution function v far field particle s velocity p pressure t i time of ith observation ρ water density α shape parameter λ failure rate β scale parameter v s ship speed m s h s significant wave height m l overall length of ship m b breadth of ship m t time sec m mass kg n normal vector t i travelling time of the vessel f probability density function 1 introduction by increasing the capacity of a shipping fleet both in size and quantity industries are more attracted to minimizing the grounding risk of shipping operations particularly in restricted waters ship grounding phenomenon accounts for one third of commercial ship accidents highlighted as a major risk in marine transportation by previous researchers brown et al 1997 jebsen and papakonstantinou 1997 mazaheri et al 2014 about 20 of all tanker losses between 1987 and 1991 brown et al 1997 and 47 of all accidents of large greek vessels from 1992 to 2005 were due to grounding samuelides et al 2009 proposing a reliable framework is essential for increasing the level of safety for ship navigation in shallow waters without compromising the loading capacity of the fleet that is developing a methodology is essential to determine the minimum under keel clearance ukc of the ship that will avoid leading to a grounding accident in the literature several concepts and predefined formulae are proposed for determining the squat of a ship that sails in restricted or open water amongst them three main approaches are singled out including theoretical gates and herbich 1977 t p gourlay 2000 t gourlay 2008 empirical barrass and derrett 2011 mazaheri et al 2014 moustafa and yehia and numerical methods europe 2006 t p gourlay 2000 sergent et al 2015 most of these researches are deterministic and do not consider the uncertainty associated with the parameters involved in predicting the ukc of the vessel as a function of time the dynamic ukc can in turn assist in the assessment of touching bottom probability tbp and provide the potential for risk assessment of very large ships vls moving along a shallow passage the factors that influence the dukc of the ship such as the speed should be statistically analysed a great deal of research has been conducted to develop risk based methods for minimizing the probability of failure during ship voyaging time however these methods assume that the stochastic process is observed as a renewal process hence poisson assumption is adopted for modelling the ship tbp gucma 2004 n quy et al 2006 n m quy et al 2007 gucma and schoeneich 2008 n quy et al 2006 and n m quy et al 2007 provide a parametric modelling method for safety policy improvement of ships entering shallow waters assuming that the grounding accidents follow a poisson process gucma and schoeneich 2008 applied a monte carlo approach to assess the probability that a ferry passes its safe zone in regards to ukc their statistical method uses a large number of trial tests on the manoeuvring performance of various vessel types in different navigation conditions however based on the assumption of a renewal process the intervals between each failure event inter arrival times are independently and identically distributed iid while this can make the analysis questionable it is not a true assumption to accept that the failure rate will be independent of time in reality the dukc record of the ship for the ith time step is dependent on the value in time step t i 1 which conflicts with the assumption of a constant failure rate for the homogeneous poisson process moreover considering time dependency of the simulation data in a stochastic process is not a straightforward procedure for constructing a probabilistic model recent advances in bayesian statistical methods namely hierarchical bayesian modelling hbm that can be carried out using open source markov chain monte carlo mcmc software packages such as openbugs lunn et al 2000 have brought them to a wider audience for solving complex engineering problems kelly and smith 2009 these methods are widely used in probabilistic risk assessment pra because of their ability to provide useful estimation of model parameters when either data are sparse or the correlation between them is difficult to perceive abbassi et al 2017 el gheriani et al 2017a b kelly and smith 2009 friis hansen 2000 siu and kelly 1998 in risk analysis there is a need to adopt data from different sources with varying levels of detail and incorporating the uncertainty that accompanies the data hbm can address uncertainty among the aggregated data for each event through generating an informative prior distribution and possible observations for the event s parameter of interest el gheriani et al 2017a b there have been many applications of bayesian inference that demonstrate the advantages of this method in pra examples include risk based maintenance planning deterioration process and component failure analysis arzaghi et al 2017 bhandari et al 2016 khakzad et al 2014 straub 2009 reliability assessment of marine structures and multi criteria decision making abaei et al 2017 luque et al 2014 this paper aims at developing a methodology for reliability analysis of the vessels transiting a shallow waterway while considering the time dependency of the stochastic motion responses the results derived from this study provide the necessary information for any risk mitigation strategies and decision support tools that are concerned with improving the safety of marine transportation in a port area a number of time domain simulations are carried out to evaluate the hydrodynamic performance of the vessel at different speeds and in random sea waves nonhomogeneous poisson process nhpp is adopted to quantify the number of times that the vessel passes its safety limits of safe ground touching mcmc is then applied to predict the tbp using bayesian inference to demonstrate the application of the proposed methodology a vls approaching the northern coast of queensland is considered as a case study 1 1 dynamic under keel clearance the motion of a vessel in shallow water causes a mass of fluid to be pushed away at the front of the hull this amount of water must flow back under the vessel and along the sides of the hull resulting in the acceleration of flow particles and in turn a significant pressure drop this phenomenon leads to a reduction in keel clearance of the vessel compared with the neutral position of the stationary vessel represented in figure 1 the motion causes the hull to sink deeper into the water with a slight trimming the algebraic sum of both sinking and trimming is known as squat dynamic under keel clearance dukc of a vessel is described as the clearance left from the static draft after subtraction of squat caused by the forward motion of the ship galor 2008 1 d u k c r t h t z r t where z r t is the dynamic squat of the vessel h is the water depth and t is the static draft these parameters can be driven either from theoretical empirical or numerical approaches as recommended by sergent et al 2015 however an empirical formula will not be applicable for all types of vessels and operational conditions briggs et al 2013 and theoretical approaches cannot provide a realistic estimation of dukc due to a number of assumptions needed for developing the model t p gourlay 2000 sergent et al 2015 therefore a numerical model is essential to evaluate the hydrodynamic responses of the vessel in every degree of freedom and finding the absolute local sinkage shown as a blue circle in figure 1 to understand the dynamic behaviour of a ship s ukc the following equation developed and based on newton s second law will be considered sergent et al 2015 2 m d 2 r d t 2 m g h u l l p n e i d s i 1 2 6 where m is the mass of ship g is gravity acceleration ds is a surface element of the ship hull p is the pressure of the flow n is the normal vector on the wetted surface of the ship e i is the direction of the forces exerted in the ith degree of freedom the continuity equation yields the velocity of the flow under the keel as 3 v r t v h dukc r t where v is the far field flow velocity and r is the position vector of x y z the pressure of the flow p will be estimated using bernoulli equation sergent et al 2015 4 p r t ρ g h dukc r t ρ 2 v 2 1 h 2 dukc r t therefore a time domain numerical model needs to be employed to simulate ship squat different models are available for simulating the scenario for instance gourlay 2000 and debaillon 2005 developed a finite difference and finite element model respectively for evaluating dynamic behaviour of the vessel n m quy et al 2007 developed a 3d diffraction model using harap software to estimate the response amplitude operator of the vessel operating in random sea waves among them 3d diffraction is suggested for hydrodynamic analysis of large structures as the inertia force is dominant compared to the drag force and the computational cost is more efficient karimirad 2011 hence in this study a time domain 3d diffraction model is adopted from abaiee et al 2016 for predicting response of the vessel under random sea waves for this purpose aqwa program manual 2009 was used for processing the time domain 3d diffraction simulation and evaluating performance of dukc of the vessel in different environment conditions this approach is appropriate for large volume structures where the incident waves tend to be affected by the structure and where part of the encountering waves will be diffracted by the structure and part of them will be radiated abaiee et al 2016 1 2 hierarchical bayesian modelling performing any kind of statistical inference starts with data data is defined as the observation values of a stochastic process that may incorporate various sources of uncertainty whatever is obtained from the evaluation manipulating or organizing data is referred to as information which leads to improving our knowledge while knowledge is what is known from gathered information finally the process of obtaining a conclusion based on what one knows is regarded as inference kelly and smith 2009 hbm is a probabilistic approach that allows the organisation of inference based on real world observations into information kelly and smith 2009 siu and kelly 1998 in the present paper bayes theorem is considered for carrying out inference kelly and smith 2009 5 π 1 θ x f x θ π 0 θ θ f x θ π 0 θ d θ where θ is the unknown parameter of interest f x θ is the likelihood function and π 1 θ x is the posterior distribution in the hierarchical baysian framework multistage prior distributions defined for parameter of interest denoted by π 0 θ kelly and smith 2009 can be calculated by 6 π 0 θ φ π 1 θ φ π 2 θ where π 1 θ φ is the first stage prior representing the population variability in θ π 2 φ is the hyper prior distribution representing the uncertainty in φ φ is a vector of hyper parameters e g φ α β while α and β are the shape and scale parameters respectively of a weibul distribution the prior is developed using generic data collected from different sources numerical simulations experiments or collected from different industrial sectors these result in an informative prior distribution π 0 φ for estimating the posterior distribution hbms are found to be more reliable in comparison to classical statistical methods as they are able to incorporate various types of information each having some sources of uncertainty in the estimation process siu and kelly 1998 as a subjective based probability framework it can assist in pra by propagating uncertainties through complex models siu and kelly 1998 recently studies were conducted to bring the application of hbm in pra kelly and smith 2009 niu et al 2015 yang et al 2013 mostly they generally proved the advantages of hbm for risk and reliability assessment of process engineering such as oil spill assessment and component failure analysis in the present study a methodology is developed using hbm for predicting the likelihood of ship grounding in restricted water 2 methodology ship grounding assessment this paper aims at developing a practical safety assessment framework for estimating the tbp of vessels operating in restricted waters this framework will assist the operators to maintain the ukc of a vessel out of its critical zone the outcome of the proposed approach is the lessening of ship grounding risk and improving the safety of navigation in the port area the proposed methodology consists of two steps as presented in figure 2 and discussed in the following sections 2 1 hydrodynamic modelling in order to develop a framework for safety assessment of ship navigation in shallow water it is necessary to estimate the stochastic dynamic responses of the vessel in a random sea environment this part of the methodology will assist in evaluating time varying ukc along the entire voyage route from entering to leaving a shallow water area the results will generate essential observation data for analysing the time and number of ship grounding events as the input to the second part of study which is failure assessment for this purpose a time domain hydrodynamic simulation is employed for developing the stochastic dukc function and the maximum local sinkage of the vessel illustrated with blue points in figure 3 given by eq 7 7 dukc i j f r t v s i h s j h l b t i 1 2 n j 1 2 m where t is time r is the location of local sinkage v s is ship speed h s is the encountered random wave heights h is water depth and l and b are the length and breadth of the vessel this function should be generated for the entire range of operational ship speed v s i and significant wave height h s i to enable the evaluation of all possible manoeuvring conditions of the vessel in shallow water a safe clearance zone is defined to preserve ship s ukc in a safe condition during the voyage that is for each dukc i j an allowable safe limit sl is considered and observations of the time that the vessel enters the unsafe clearance zone ucz is recorded these observations are required as the input for the next step of the study which predicts the likelihood of ship grounding the limits of ucz are dependent on several factors related to under keel clearance such as underwater obstructions unclear layers of mud and the uncertainties associated with charted depth parker and huff 2015 in most cases the allowable ucz is defined based on ukc management system for each port for arriving and departing vessels for instance the australian maritime safety authority amsa recommends an ucz equal to 10 of the actual water depth in the region h tull 2006 in the present study this recommendation by amsa is adopted for determining the safe limit of each dukc i j record 2 2 grounding failure assessment upon obtaining the dukc responses a failure model is developed to estimate the likelihood of the vessel touching the seabed the model is based on the assumption that for any inter arrival time t i t i 1 the number of ukc points passing the sl are not identically independently distributed iid therefore the i th passage failure known as the event where the vessel passes its sl for the ith time in t i is dependent upon t i 1 in which the previous event has occurred based on this assumption the failure rate λ t is dependent on time and the simulation yields stochastic results that represent a nonhomogeneous poisson process nhpp accordingly the expected number of failures in any given time interval t i 1 t i is given by eq 8 8 λ t t i 1 t i λ t d t where nf is the number of failures that the vessel touches the seabed subsequently an appropriate function must be specified for λ t representing the nhpp some of the common forms for λ t recommended in previous studies are power law log linear and linear models chang 2001 kelly and smith 2009 for the proposed method the power law function is considered for the failure assessment of dukc due to its ability to predict the nonlinearity of random process more accurately when compared to the linear models kelly and smith 2009 this function is given by eq 9 9 λ t α β t β α 1 this model can also subsume a constant failure rate assumption in the specific state where α 1 therefore the time to observe the first passage failure event given the power law function for failure rate follows a weibull distribution with shape parameter α and scale parameter β ross 1976 stated in eq 10 10 f t 1 α β t 1 β α 1 exp t 1 β α to estimate the parameters of α and β hbm is employed for sampling the i th passage failure observations represented by the blue points located below the sl in figure 3 for each time interval t i t i 1 a conditional probability function must be defined to reflect the dependency of observation points on the previous failure events in each simulation ross 1976 as given by eq 11 11 f t i t i 1 f t i t i t i 1 f t i pr t i t i 1 i 2 n where t i is the observation time of grounding event for the vessel with a specific voyage distance s and a ship speed v s eq 11 is a truncated weibulll distribution and the recommended likelihood function by kelly and smith 2009 is defined as f t 1 t 2 t n α β in which α and β are the hyper parameters openbugs software is utilized to perform the mcmc sampling from the joint distribution of α and β to obtain the marginal posterior distribution of the hyper parameters spiegelhalter et al 2007 although the aforementioned likelihood function is not pre programmed into openbugs an aleatory model can be developed using a generic distribution function termed as dlogik as suggested by kelly and smith 2009 by defining parameter φ log likelihood eq 11 allows openbugs to update the parameters in the likelihood function phi with a vector size of n with the samples of α and β from the prior distribution in eq 13 12 φ log α α log β α 1 log t i t n β α n where t n is the last observation of the grounding event in the simulation the independent diffusive gamma distribution is used for the prior distribution of hyper parameters as suggested by kelly and smith 2009 and given by 13 α g a m m a 0 0001 0 0001 β g a m m a 0 0001 0 0001 in eq 12 t i is the ith observation of the vessel keel passing scz shown in figure 3 the mcmc sampling must be performed for i 1 n to estimate the updated posterior distribution of hyper parameters α β these distributions are then adopted to predict the probability of grounding based on a weibull function this process is repeated for each dukc i j record each simulation to investigate various failure conditions for the vessel to pass its scz during the voyage in restricted waters this results in a failure probability distribution function for each operational condition enabling the improvement of safety in ship navigation 3 methodology application case study of a vls in queensland waterway to demonstrate the application of the developed methodology the safety assessment of a vls navigating in queensland s coastal zones is considered as the case study approximately 80 of the queensland population live in the coastal region which makes for a significant demand for shipping transportation using large vessels in this area caton and harvey 2015 according to hemer et al 2007 the maximum observable significant wave height in the queensland coastal zone is 1 0 m therefore the dukc i j simulations in this study are carried out for two levels of significant wave height h s h s i 0 5 1 0 m and four levels of ship speed v s v s i 2 3 4 5 m s this results in a total of 8 simulations all performed for the maximum travel time tmax the geometry details of the vls model with a figure of the ship hull used for hydrodynamic simulations in aqwa ansys software are listed in table 1 the heave response and dukc for the first simulation for vs 2 0 m s and hs 0 5 m predicted for a voyage time of tmax 2500 s is illustrated in figure 4 in this figure the static under keel clearance sukc is computed as z 4 0 m based on the amsa recommendations regarding the safety of navigation in restricted waters a safety limit of s l 10 80 m is specified for detecting the events where the vessel keel enters ucz these detections are adopted as the observations for the assessment of ship grounding as described in section 2 2 the observations from the dukc records of simulations carried out for hs 0 5 m and the entire range of ship speed vs are illustrated in figure 5 it is clearly shown in the figure that by increasing the ship speed the number of observation points entering ucz dramatically increases from 5 points for vs 2 m s to 49 points for vs 5 m s also the range between the first and the last observation time t1 tn becomes smaller for lower ship speeds for instance at vs 2 m s the range is 985 2111 sec while it extends to 196 2485 sec when the vessel cruises at vs 5 m s the observations are then entered into the hbm for developing the likelihood functions and estimating the posterior distribution of weibull parameters α and β the model for estimating the weibull parameters α β considered two chains in the mcmc modelling approach each simulation is performed with a total of 600 e 03 iterations to predict the posterior distributions figure 6 shows the estimated posterior distribution of the shape parameter α as well as the correlation between weibull parameters α β for ship speed of vs 3 m s and significant wave height of hs 0 5 m in figure 6 the values of shape parameter for 2 5 and 97 5 percentile are α 1 375 and α 4 949 respectively the expected value of alpha is estimated as e α 2 989 stands for 2 989 which is significantly higher than α 1 highlighting the importance of time dependent assumption for failure rate of ship grounding see eq 9 the expected value of weibull parameters for all vessel speeds and wave heights are listed in table 2 it is found that shape parameter approaches α 1 as the sea environment becomes more extreme the estimated probability of ship grounding for different ship speeds and significant wave heights are computed over a voyage time of tmax 2500 s this time corresponds to a minimum voyage distance of 5 km for the ship transiting queensland restricted waterway caton and harvey 2015 and the results are presented in figures 7 and 8 it is found from these figures that any increase in the cruising speed of the vessel results in a lower expected time of grounding failure for instance in the sea states with hs 0 5 m the expected time of grounding failure for vs 2 m s and 5 m s are 0 217 e 03s and 1 015 e 03s respectively these parameters are predicted as 0 067 e 03s for vs 2 m s and 0 295 e 03s for vs 5 m s when the significant wave height is hs 1 0 m it is also observed that the variation in the grounding likelihood for different ship speeds will be decreased as the sea environment faces higher wave heights in order to examine the probability of first time to failure fttf of the vessel in a particular passage six voyage distances s are considered from the simulation results a summary of the travelling time t for different voyage distances and the ship speeds are listed in table 3 and the predicted probability of fttf of each case is illustrated as presented in figures 9 and 10 a comparison between the results in figures 9 and 10 confirms that the ship is expected to have higher probability in shorter ranges of passage distance for higher ship speeds compared to the events observed at lower speeds that is for a vessel with a higher speed the fttf is predicted to be observed more in the earlier part of the voyage with a greater probability of touching the bottom while this probability will decrease drastically by increasing the voyage distance as an example for a voyage distance of 500 m at a significant wave height of 0 5 m the probability of fttf is estimated as 3 35e 03 and 1 04e 05 for ship speed of vs 5 m s and 2 m s while these probabilities change to 3 23e 03 and 1 58e 03 correspondingly for hs 1 0 m it is observed from figure 9 that at hs 0 5 m at a cruising speed of 2 m s the maximum probability of fttf is estimated as pmax 1 68e 03 that is it is expected to occur at the voyage distance of 2000m while this probability is decreased to 0 95e 03 for vs 5 m s the results also highlight that the variation of probability of fttf between different ship speeds dramatically decreases at longer distances if it is considered that the allowable probability of grounding is 3 10 5 3 per 100 000 ship movements as recommended by vrijling 1995 the results of the case study suggest that an acceptable level of safety can be achieved while navigating at ship speeds less that 3 m s and significant wave heights of lower than 0 5 m given the geometry details of the vessel as well as the water depth of 12 m the presented results highlight that the proposed framework can model the grounding of the vessel more accurately in comparison to previous methods due to relaxing the assumption of a constant failure rate and considering the time dependency of the observed data the method can be readily used by the operators and port management systems to improve the safety of the port operations as well as developing more effective risk mitigation policies for transitioning in restricted waters 4 conclusion the present paper proposes a methodology for predicting the grounding likelihood of ships cruising in shallow waters such as coastal areas the developed framework integrates the hydrodynamic analysis of dukc with a bayesian predictive tool to achieve its objective the hydrodynamic responses of a vls are numerically analysed for different ship speeds and incident wave heights where the estimated dukc results are adopted to develop the hbm as a case study the performance of the vessel was assessed when entering the coastal zones in north east queensland with a water depth of 12 m it is observed that the predictions are highly dependent on ship speeds and sea states highlighting the need for an nhpp model in ship grounding assessment the results suggest that a vessel can safely operate in maximum incident wave heights of 0 5 m with speeds lower than 3 m s while the probability of fttf is maintained at less than 3 10 5 which is recommended by the literature as the acceptable safety limit the proposed framework can predict the grounding likelihood of a vessel more accurately by considering the time dependency in the observation data and can be applied by operators and port managers to improve the reliability of ship navigation in shallow waters and coastal areas acknowledgment the first author would like to thank the national centre for maritime engineering and hydrodynamics of the australian maritime college amc for the scholarship support 
23358,many usvs are equipped with navigation guidance and control ngc algorithms due to human errors that is present in manual navigation of surface vehicles the morvarid a catamaran shaped boat is designed and developed for plotting hydrography map of harbours to control it autonomously a fusion algorithm based on ekf search ball and potential field concept is developed some main parameters of dynamic model is derived based on experimental tests and the algorithm is evaluated using hardware in the loop concept the obstacle avoidance algorithm is assessed for different obstacles in size and position it is concluded that although the developed algorithm is robust and precise even in the presence of environmental disturbances however installing powerful thrusters would boost maneuverability more than that is keywords navigation obstacle avoidance kalman filter search ball thrust 1 introduction many researches have been performed and some are under study for surface vehicles automation since manual navigation system for vessels in supervising data acquisition and processing are always subject to human errors eydgahi et al 2007 in this text automatically controlled surface vehicles are called unmanned surface vehicle usv as it is common in many references while autonomous surface vehicle asv is used in another texts usv technology is rather new in contrast to autonomous underwater vehicles auvs which has already reached its maturity the accuracy of usvs is far better than that of the auvs since the gps fixes are generally available at all time in open waters naeem et al 2007 usvs are robots for operation at lakes canals harbors and even open sea that are characterized by small size good hiding capability high mobility and low price tang et al 2015 this surface vehicles are subjected to many objectives either alone or as part of a sensor network some well known applications for usvs include marine environment monitoring bathymetry inspection mine countermeasure and port protection oil and gas exploration deep sea pipeline monitoring coastal security search and rescue campbell et al 2012 pêtrès et al 2012 selection of a suitable marine craft platform for automation is the first step of work considering potential candidates classical hull shape single hull or twin hull catamaran shaped vessels exploits favourable hydrodynamic properties to obtain long range operation with low energy consumption nađ et al 2015 between small boats the catamaran is for stability with respect to roll capability of payload transport with respect to the hydrodynamic drag and redundancy in hull buoyancy caccia et al 2005 from view of reaction force applied to surface vehicles marine crafts can be classified according to their maximum operating speed u and length of the submerged portion l using the froude number fr u l g where g is the acceleration due to gravity the weight of a vessel operating with a froude number less than about 0 4 0 5 is almost completely supported by the hydrostatic force of buoyancy that is proportional to the volume of fluid displaced displacement mode in froude numbers greater than about 1 0 1 2 the weight is almost completely supported by a hydrodynamic force that is roughly proportional to the square of the speed planning mode for intermediate values of the froude number the vessel s weight is supported by both the hydrostatic and hydrodynamic force semi displacement vessel fossen 2011 in usvs the navigation guidance and control ngc system intelligently controls the vehicle to go from origin to destination avoiding the obstacles in its path depending on the anticipated danger of the obstacles the vehicle chooses an angle of divergence which avoids the obstacles and keeps the speed of the vehicle eydgahi et al 2007 during navigation the sensors for detecting the obstacles would be a radar lidar binocular vision stereo vision monocular vision infrared cameras laser range finders and ultrasonic sensors or combination some of these sensors in this field usually detecting distance is limited to a few hundred meters the maximum detecting distance of sensors would be under 200 m e g for lidar tang et al 2015 while ultrasonic sensors difficultly could detect up to 10 m some researches use high accuracy and expensive positioning systems such as rtk dgps despite to high accuracy and expensive positioning systems some experiments demonstrated the effectiveness of extended kalman filter ekf and simple pid guidance and control laws to perform basic control tasks such as auto heading auto speed and straight line following with a usv equipped only with gps and compass caccia et al 2008 different algorithms have been developed and were used for ngc as well as obstacle avoidance in reviewed texts each with some pros and cons some main methods that have been proposed for navigation and obstacle avoidance in robot boats are raytracing techniques the use of a state machine dynamic programming modified a algorithm fuzzy logic interval analysis voronoi diagrams optimization of the time derivative of the distance between boat and target and potential field framework pêtrès et al 2012 generally speaking the problems related to motion control and guidance of usvs are classified in the literature into three basic groups a point stabilization the goal is to stabilize the vehicle zeroing the position and orientation error with respect to a given target point with a desired orientation bibuli et al 2009 b path following more specifically the full path might be known to the experimenter prior starting the experiment and communicated to the vehicle in full or just a piece at the time i e the vehicle has to follow a planar path without temporal constraints this control compute and reduce to zero the distance between the vehicle and the path as well as the angle between the vessel speed and the tangent to the path bibuli et al 2009 caccia 2006 c path tracking trajectory tracking the vehicle might need to learn segments of the path to track sequentially just seconds ahead of setting on each one requiring the vessel to follow a time parameterised reference curve i e to be in specific points at specific instants of time bibuli et al 2009 sagginia et al 2015 caccia 2006 except to these three main groups two different methods are added in some texts d control in the horizontal plane where a simple p i d heading controller is sufficient for guaranteeing satisfactory performance and e cooperative motion control a leader and a follower vehicle following two parallel paths master slave caccia 2006 1 1 literature review some papers about guidance navigation and obstacle avoidance in usvs are reviewed and finally some useful information from different articles are given in a table for comparison praczyk 2015 presented application of evolutionary neural networks to the collision avoidance task and the navigation problem in a complex multi object rapidly changing environment which do not behave according to any widely accepted regulations praczyk 2015 liu et al 2015 introduced a path planning algorithm for the usv formation navigation based on the fast marching fm method which has features of fast computation speed and low computation complexity this algorithm covers two areas i e ship domain area and collision avoidance area to ensure the planned trajectory to not violate any forbidden area liu and bucknall 2015 zereik et al 2015 simulated three different control tasks namely path following obstacle avoidance and speed regulation as an algorithm named priority task approach the main objective of this approach was to correctly execute a path following task while guaranteeing also obstacle avoidance and vehicle speed regulation zereik et al 2015 ma 2015 developed a modified unscented kalman filter as an online estimation algorithm with higher precision and lower calculation complexity for usv state estimation it is concluded that the proposed algorithms to be superiority to the general ukf motwani et al 2013 evaluated potential application of interval kalman filter ikf algorithms for estimating the heading angle of the vessel under erroneous modeling assumptions the simulations reveal several characteristics of the ikf motwani et al 2013 onunka et al 2013 combined the ultrasonic sensor and radar to reduce the uncertainties present in the guidance and control of the usv while improving the obstacle detection and avoidance capacity of the usv especially in the near field region up to 5 m from the usv onunka et al 2013 finally for straightforward comparison some useful information from reviewed texts are given in table 1 some design characteristics thrust force maximum speed application field and navigation algorithms are selected information that is extracted from some published papers considering different algorithms are equipped to different usvs each with some drawbacks and since for faultless navigation and obstacle avoidance each platform would have its own correct and effective parameters the main objectives of this research is as a determining the dynamic model parameters based on experimental tests for the usv that is designed and constructed in this project b state estimation using ekf predictor c giving a complex path following algorithm for navigation control and obstacle avoidance based on research ball and potential field methods 2 materials and methods this section first considers the designed and constructed usv platform the derived rigid body model based on experimental results are described next then it is followed by extended kalman filter ekf application and developing a complex algorithm for ngc finally it is terminated with explanation of obstacle avoidance algorithm 2 1 the evaluated platform this manuscript explains a part of a complete scientific project morvarid 1 1 emorvarid ut ac ir that is pending for tracing the hydrography map of a harbour in the bureau using an usv considering common platforms the twin hulled catamaran design is selected due to its stability and simplicity of steering mechanism which is steered using differential thrust the morvarid is a plug in hybrid solar powered usv equipped with two thrusting motors each with 445 n 100 lbs thrust force this 24 v motors are controlled as variable speed in forward and backward the boat length width and height approximately are 3 8 2 4 and 1 5 m respectively it s overall weight is about 700 kg an 8 kwh high technology li ion battery pack can extend its stability for more than three continues cloudy days to perform the defined duty it is equipped with some local perception and global monitoring sensors as a simple gps pack of state sensor imu compass and air pressure range finder lidar a set of ultrasonic sensors stereoscopic vision system and three single beam echo sounders an outboard waterproof ipc is a central processing and decision making unit that receives all data and information analysis data and activate the port and starboard motors in the proper manner communication between morvarid and bureau is based on an ethernet network that capable for data sending to maximum 300 mbps in distances to 10 km the 3d cad model of the morvarid is shown in fig 1 a and its first test in the persian gulf lack suburban of tehran is illustrated in fig 1 b this usv can operate in four modes by a priority as a manual operation by a joystick on the vehicle b remote control by a handheld unit c control from office using a gui and d fully automatic path following 2 2 rigid body model this section discuss deriving the dynamic model of the marine vehicle in six degrees of freedom dof since six independent coordinates are necessary to determine the position and orientation of a rigid body according to fossen 1996 fossen 1994 it is assumed two coordinate frames the moving coordinate frame that is fixed to the vehicle and is called body fixed reference and an earth fixed reference frame as shown in fig 1 the origin of the body fixed frame is usually chosen to coincide with the center of gravity cg the kinematic equation for transforming body fixed reference to earth fixed one can be expressed as fossen 1994 1 η j η ν where η x y z φ θ ψ t denotes the position and orientation vector with coordinates in the earth fixed frame ν u v w p q r t is the generalized linear and angular velocity vector in body frame coordinate and j η is transformation matrix that for details the reader is referred to fossen 1994 fossen 1994 here x y and z are vehicle position and φ θ and ψ are orientation in earth fixed frame also u v and w are velocity respectively in surge sway and heave and p q and r are angular velocity respectively around roll pitch and yaw for surface vehicles the depth z and pitch θ variables are not applicable also the roll φ variation is found to be negligible during experimental evaluations naeem et al 2012 for simplicity ignoring the swing z cons and w 0 pitch θ 0 and q 0 and roll φ 0 and p 0 the kinematic model in eq 1 which describes the geometrical relationship between the earth fixed and the vehicle fixed motion is given as 2 x y ψ c o s ψ s i n ψ 0 s i n ψ c o s ψ 0 0 0 1 u υ r according to newtonian and lagrangian mechanics nonlinear dynamic equation of motion can be conventionally expressed as fossen 1994 3 m r b υ c r b υ υ d r b υ υ g η τ where mrb denotes the rigid body inertia matrix including added mass and mrb mrb t 0 and m r b 0 crb ν is denotes the matrix of coriolis and centripetal terms including added mass and crb ν crb ν t drb ν is damping matrix g η is vector of gravitational forces and moments and τ x y z k m n t is the vector of control input including force and moments in three directions in this case since the inputs are only from two port and starboard motors the usv is deal as underactuated surface ship fewer numbers of actuators than the to be controlled degrees of freedom considering tport as portside thrusting force and tstbd as starboard thrusting force each in surge direction the control input vector become as 5 τ τ u τ ν τ r t t p o r t t s t b d 0 t p o r t t s t b d b 2 t where b is the distance between two thrusting power sources 1 2 m in this case differential steering imposes a moment about the vehicle that causes it to turn there are distinct advantages to this type of system primarily the turning radius for the vehicle is substantially reduced as well as the additional capability to steer without the requirement of a forward speed bertaska et al 2015 the mathematical model of an underactuated ship moving in surge sway and yaw is obtained from the motion equation of the ship moving in six degrees of freedom under disturbances induced by wave wind and ocean current furthermore it is assumed that the inertia added mass and damping matrices are diagonal this assumption holds when the vessels have three planes of symmetry for which the axes of the body fixed reference frame are chosen to be parallel to the principal axis of the displaced fluid which are equal to the principal axis of the vessel most ships have port starboard symmetry moreover bottom top symmetry is not required for horizontal motion ship fore aft nonsymmetry implies that the off diagonal terms of the inertia and damping matrices are nonzero however these terms are small compared to the main diagonal terms so the underactuated ship moving in surge sway and yaw can be described as doa et al 2004 6 x u cos ψ v sin ψ y u sin ψ v cos ψ ψ r u m 22 m 11 v r d u m 11 u i 2 3 d u i m 11 u i 1 u 1 m 11 τ u 1 m 11 τ w u t v m 11 m 22 u r d υ m 22 v i 2 3 d υ i m 22 v i 1 v 1 m 22 τ w υ t r m 11 m 22 m 33 u r d υ m 22 v i 2 3 d r i m 33 r i 1 r 1 m 33 τ r 1 m 33 τ w r t the positive constant terms mjj where 1 j 3 denote the ship inertia including added mass and is derived according to equ 7 the positive constant terms du dv dr dui dvi and dri where i 2 3 represent the hydrodynamic damping in surge sway and yaw for simplicity the higher nonlinear damping terms are ignored muske and ashrafiuon 2008 doa et al 2004 and reyhanoglu 1996 the time varying terms τwu t τwv t and τwr t are the environmental disturbances induced by wave wind and ocean current with τwu t τwu max τwv t τwv max and τwr t τwr max finally the available controls are the surge force τu and the yaw moment τr that are calculated as equ 5 the parameters added mass and damping coefficients are the unknown variables that would be derived mass parameters include added mass contributions that represent hydraulic pressure forces and torque due to forced harmonic motion of the vessel which are proportional to acceleration using the estimate of the added mass terms presented in fossen 1994 for the experimental model boat it would be derived as muske and ashrafiuon 2008 7 m 11 m 0 05 m m 22 m 0 5 ρ π d 2 l m 33 m l 2 w 2 1 2 0 1 m b 2 ρ π d 2 l 3 12 where m 700 kg is the actual mass of the usv l 3 m is the effective length w 0 8 m is the width d 0 5 m is the mean submerged depth and ρ is the density of water about damping coefficients according to ma 2015 8 d u 2 0 2 d u d v 2 0 2 d v d r 2 0 2 d r d u 3 0 1 d u d v 3 0 1 d v d r 3 0 1 d r for defining du dv and dr combination of experimental results simulation and conformance with some references are used considering that the damping parameters are dependent on boat shape and dimension main related parameters of some usvs as well as morvarid are given as table 2 according to table 2 the ratio of m11 du m22 dv and m33 dr for all given usvs are in specific range inserting maximum values of these ratios in the simulation model and tuning their values till the surge and yaw speeds for predefined thrusting force and moments become stable is continued the predefined thrusting force is achieved from experimental results and is the minimum thrust force that could move the boat in the steady state for this case is 0 2 of maximum thrust finally these ratios for morvarid is defined as m11 du 10 m22 dv 5 and m33 dr 2 2 3 ekf algorithm and its parameters to best estimate the statues of the vehicle application an estimator filter is common in estimation theory the extended kalman filter ekf is the nonlinear version of the kalman filter which linearizes about an estimate of the current mean and covariance as it is the case in this study the state transition and observation models do not need to be linear functions of the state but may instead be differentiable functions the ekf can be formulated as model x k f x k 1 u k w k i n t h i s c a s e x k x k 1 t f x k 1 u k w k z k h x k v k i n t h i s c a s e z k h x k v k predict 9 x ˆ k f x ˆ k 1 u k i n t h i s c a s e x ˆ k x ˆ k 1 f x ˆ k 1 u k p k f k 1 p k 1 f k 1 t q k 1 update k k p k h k t h k p k h k t r 1 x ˆ k x ˆ k k k z k h x ˆ k p k i k k h k p k since three degree of freedom dof motion composed of surge sway and yaw was considered for the filter dynamics the usv s motion was estimated using position and attitude measurements provided by the gps compass and imu here xk x y ψ u ν r t is state vector in the step of kth zk x y ψ u ν r t is measurement vector that the first and second parameters are measured bys gps the 3rd parameter is measured by compass and the last three are measured by imu the state estimation function f xk 1 uk is a function of state parameters and control signal uk and is given according to equ 6 t is time step and h is jacobian of h xk that here would be a function of t as given below also fk 1 is jacobian of f xk 1 uk the jacobian matrix j for an arbitrary function f is an m n matrix that is given as equ 10 10 j d f d x f x 1 f x n f 1 x 1 f 1 x n f m x 1 f m x 1 the wk and vk in equ 9 are white noise for process and measurement respectively which are the characterization of system modeling errors and sensors uncertainty furthermore the following conditions are simultaneously satisfied rodríguez and gómez 2009 11 e w k 0 e v k 0 e w k w i t δ k i q k υ k υ i t δ k i r k where δ n 1 n 0 0 n 0 is the kronecker delta function qk is the covariance matrix of the system noise and rk is the covariance matrix of the observation noise that all of these are positive parameters the adjustment of qk and rk is critical in the development of kalman filter although estimating of rk is not very sophisticated about qk there are some methods for these parameters definition e g monte carlo gomez gil et al 2013 however in this research rk estimated as r σ x g p s 2 0 0 0 0 0 0 σ y g p s 2 0 0 0 0 0 0 σ ψ c o m p 2 0 0 0 0 0 0 σ u i m u 2 0 0 0 0 0 0 σ υ i m u 2 0 0 0 0 0 0 σ r i m u 2 h 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 t 0 0 0 0 0 0 1 t 0 0 0 0 0 0 1 2 4 path following and obstacle avoidance algorithm between path following algorithms potential field method is one of the most well known algorithm that operates according to magnetic potential field i e attractive or repulsive force are inversely proportional to distance from destination point this algorithm have been widely and successfully employed for control and motion planning of mobile robots for decades the potential field based algorithms are fast reliable and easy to tune once implemented on real platforms pêtrès et al 2012 in artificial potential field method movements of the robot represented as a particle are governed by a field which is usually composed of two components an attractive potential drawing the robot towards the goal and a repulsive potential pushing the robot away from obstacles approximately in all developed algorithms the destination point is a single point that attract the vehicle due to this the main drawback with potential field techniques is their susceptibility to local minima to dissolve this problem an algorithm is developed based on the combination of potential field and research ball algorithms más et al 2010 this concept is illustrated in fig 2 as ngc algorithm for each point on the navigation course a search is conducted to find two nearest goal points on the reference path the algorithm first finds the nearest path line in whole area and then searches on that line to complete the search ball once determined the distance of these points from the usv represents the greatness of the attractive force the process continues for all of the components in the examined trajectory the search is spatially bounded by the user defined search ball that here it is selected as equal as 2 l l is boat length fossen 1994 naeem et al 2008 actually a line of sight los maneuvering system was used to control usv position and transition between waypoints in a trajectory as in fossen 2011 this system used the vehicle s current position and desired positions to determine a desired heading the radius of the search ball br allows a certain level of flexibility on the user side however a well adjusted magnitude makes the algorithm more computationally efficient the search ball algorithm can be mathematically formulated as follows assuming points p xj yj to be the position of usv estimated by ekf and t 1 n as a set of indices for reference path points inside the search ball if e and n represent the east and north coordinates respectively for each j a new set bj i ε t dij br can be defined where distances dij are calculated with equ 12 12 d i j e i e j 2 n i n j 2 the members in the set of bj is sorted from min to max to obtain the minimum distance and its number actually the algorithm determines two nearest goal points to usv it is necessary to mention that as shown in fig 3 searching is done only inside a semicircle i e the algorithm seeks only ahead of the boat also the deflection angle of usv from each point is calculated using equ 13 13 α i a r c t a n n i n j e i e j to attract the usv toward the goals a linear potential pot is built for every path points as follows pêtrès et al 2012 14 p o t i k 2 d i j h e r e i 1 t o 4 where k2 is the desired attractive gradient and dij is the euclidean distance between p xj yj and ith goal finally the real destination point and the required orientation of usv that is shown by red vector in fig 3 is calculated from the result of calculated vectors using the equ 15 15 δ a r c t a n i p o t i s i n α i i p o t i c o s α i to set the motors thrusting force the algorithm first defines if the boat is in the right hand or left hand of the pass by comparing latitude of the boat and desired path then it sets the desired thrusting force according to equ 16 16 i n r i g h t t s t b d p r i m f o r c e z 1 δ 3 ψ p a t h a n g l e t p o r t p r i m f o r c e z 1 δ 3 ψ p a t h a n g l e i n l e f t t s t b d p r i m f o r c e z 1 δ 3 ψ p a t h a n g l e t p o r t p r i m f o r c e z 1 δ 3 ψ p a t h a n g l e according to fig 3 the z1 is minimum distance between usv and path that is calculated using triangulation relations actually increasing distance between the boat and the desired path as well as increasing δ causes more differences between two motors more turning torque also according to this equation the boat forced in a way that differences of heading and path angle is decreased the prime force is a variable defining the thrusting force when the usv is on the non curved path without any bias equ 17 17 p r i m f o r c e k 1 y n e a r g o a l 1 g o a l 2 5 z 1 where k1 is a constant number for example 30 of motors thrust it is assumed that thrust of motors t tmax rpm rpmmax bertaska et al 2015 variables ynear goal1 and ynear goal2 are component of goal positions in y direction for two nearest goals and difference of these two cause to reduce the speed at curved paths e g at head of the path also drift is causes to reduce speed obstacle avoidance to detect obstacles three set of sensors were used according to fig 4 a lidar hokuyo s uxm series was used in front of the boat that covers 190 to cover the rear area a stereoscopic system is under development using two ccd cameras and finally a set of ultrasonic sensors using 10 waterproof modules jsn sr04t were used that detect near obstacles approximately all around the vehicle considering the operation environment of usv two type of obstacles would be categorized as static obstacles and dynamic obstacles when an obstacle is detected inside the sight of any three mentioned sensors the obstacle function is activated and using clustering methods four parameters would be extracted include width of obstacle central point speed vector value and direction if the detected obstacle was static considering the near goal point to usv and distance between obstacle and usv the two near goal points to the obstacle is defined according to fig 3 if the obstacle is located in the right hand of the path the algorithm steers to left and vice versa using equ 18 with some alteration from pêtrès et al 2012 18 o b s t a c l e i n r i g h t t p o r t t p o r t k o b s d i s t o b s 1 k o b s d i s t o b s 1 o b s t a c l e i n l e f t t p o r t t p o r t k o b s d i s t o b s 1 t s t b d t s t b d k o b s d i s t o b s 1 where 19 k o b s k 1 o b s w i d t h k 2 here k1 and k2 are tunable scalars that are defined by trial and error in this case k2 is set as 50 the k1 is a variable that changes between 0 and 35 if distance between obstacle and usv decrease in each step k1 increases and vice versa the variable obs width is the width of detected obstacle and distobs is distance between usv and obstacle according to equ 18 when the boat gets closer to an obstacle it steers with more differential force although when an obstacle is very near the motors thrust is going to be a very large number but it is limited to 445 n all calculations for obstacle position was based on its cg point however considering the dimension of obstacle and according to equ 19 distance from obstacle is kept based on k1 and k2 values about the dynamic obstacles some potential scenarios would be considered i the obstacle is detected by lidar considering the speed vectors of usv and obstacle and extension of these vectors if these two trajectories are intersect inside the sight of the sensor some actions are required first the algorithm calculates all mentioned steps above to reduce the speed one gear below of the usv and this is repeated until the forward speed of usv becomes zero if the algorithm predicts a collision even with stopping the usv this means that the obstacle is coming directly toward the usv so it goes backward in 45 to right or left however if trajectories of two speed vectors are not intersect in special speed the usv runs with that speed ii the obstacle is detected by 3d vision in this case only obstacles are required attention that come toward and faster than usv however if it is estimated that collision is probable the usv steer to right or left with 45 iii the obstacle is detected by ultrasonic this means that usv is very close to obstacle the boat activates emergency cut off switch and all warning lights and signals are activated for morvarid usv the first test is performed in real situation and useful experimental data is obtained from some sensors however to evaluate the robustness and confidantes of the developed ngc algorithm before second test it was simulated as hardware in the loop by using lidar gps imu compass and ultrasonic sensors as a real data acquisition sources the algorithm was programmed and developed using visual c in microsoft visual studio software 3 results and discussions to plot the hydrography map of the purposed port all area was divided to straight lines that were connected by u turns at the ends many points on the lines were regarded and 2d position of points were defined in earth fixed frame fig 5 illustrates three of these lines with two end turns as shown in the figure the lines were 800 m in length and 150 m distance between them the predefined path was drawn by blue line and gps data was pointed by green while the estimated positions were shown by red line for careful illustration the gps data was drawn by multiplying data to 10 in y direction for border conditions in starting of the algorithm the state vector x0 was assumed as x0 p0 0 10 0 1 0 0 according to fig 5 the developed algorithm followed the straight paths very precisely while some errors were present for u turns at the end of the path since there was no more goal point the usv started to fluctuate inserting some disturbing forces in the algorithm had no effect on the navigation however if this force increased very much the usv lost its paths according to the simulation results disturbance forces in sway was acceptable when its approximated value was less than the thrusting force in surge fig 6 shows some main evaluated parameters versus time steps in this figure a is the surge velocity curve versus time this speed set to be 1 m s in the start up in the straight path speed was increased a little and continued approximately constantly as it was expected the speed decreased at the turning so the boat could navigate precisely since in fig 6 evaluated parameters were traced versus time steps and because of decreasing speed in the turning according to a the time that usv spend in the straight path seems to be equal to that of turning fig 6 b shows the yaw angle rate of usv the maximum value of r was approximately 12 s fig 6 c illustrates the orientation of boat based on east direction according to this chart in the first straight line the ψ is zero in the first u turning it was increased till to 180 and continued to second turning then it was decreased to zero for third straight path fig 6 d and e are propellers thrusting force for starboard and port respectively for straight path they were adjusted equally to 60 n that was approximately fit to second gear of motors this result approximately confirms the experimental results that forward velocity of 1 m s was obtained from second gear at the first turning since the boat turns to left side the starboard thrust was increased while the port was decreased and in the second turning this occurred vice versa according to these figures the maximum value of thrusting force was limited to 150 n finally fig 6 f shows turning torque that was derived from equ 5 result of obstacle avoidance algorithm is shown in fig 7 two different obstacles in two different positions were regarded the first obstacle s width was 70 m and the second was 100 m the algorithm was evaluated by changing the position and size of the obstacle in different cases distance of usv from obstacle was simply controlled with variable kobs equ 19 in the algorithm if distance between usv and obstacle was incremental the kobs was decreased and vice versa during navigation between lines when the usv lost its former path for any reason such as a wide obstacle and reached to a new line it started a new navigation and kept going forward fig 8 shows surge velocity angular velocity about yaw orientation thrust force in port thrust force in starboard and turning torque respectively in a to f in presence of obstacles illustrated in fig 7 according to a the surge velocity was decreased when the boat got close to turnings and obstacles the angular velocity about yaw was maximum to 15 and depends on the boat body characteristics as well as thrusting motors capabilities in the c orientation angle is illustrated while its maximum value goes approximately up to 200 figure 8 d and e shows the thrusting force from starboard and port motors it was desirable to obtain even changes in motors speed since uneven changes in revolution of motors is not favorite and sometimes impossible finally f shows the thrusting force that causes steering according to fig 6 the developed algorithm navigated and controlled the usv in a reasonable manner although using powerful propellers would increase maneuverability and provide more precise navigation especially in presence of obstacles 4 conclusion it has been proven that multiple motion sensors play a vital role in autonomous navigation the morvarid an autonomous usv was equipped with multiple sensors to plot the hydrography map in shallow waters dynamic model of the boat was derived and some main parameters of rigid body model was defined based on experimental evaluations for the best estimation of position and states the ekf estimator was used in navigation algorithm while for navigation and obstacle avoidance in path following algorithm combination of search ball and potential field methods were applied real data was provided for algorithm simulation based on hardware in the loop concept connecting gps imu compass lidar and ultrasonic sensors to a developed application in visual c the algorithm was evaluated in different circumstances with different values of environmental disturbances wind wave and current as well as different obstacles the traced curves from main evaluated parameters were illustrated the robustness and precision of the developed algorithm however installing powerful thrusters would boost maneuverability which in turn would smooth the curves acknowledgment authors would like to acknowledge the ports and maritime organization for funding the morvarid project no 20s 7509 2015 
23358,many usvs are equipped with navigation guidance and control ngc algorithms due to human errors that is present in manual navigation of surface vehicles the morvarid a catamaran shaped boat is designed and developed for plotting hydrography map of harbours to control it autonomously a fusion algorithm based on ekf search ball and potential field concept is developed some main parameters of dynamic model is derived based on experimental tests and the algorithm is evaluated using hardware in the loop concept the obstacle avoidance algorithm is assessed for different obstacles in size and position it is concluded that although the developed algorithm is robust and precise even in the presence of environmental disturbances however installing powerful thrusters would boost maneuverability more than that is keywords navigation obstacle avoidance kalman filter search ball thrust 1 introduction many researches have been performed and some are under study for surface vehicles automation since manual navigation system for vessels in supervising data acquisition and processing are always subject to human errors eydgahi et al 2007 in this text automatically controlled surface vehicles are called unmanned surface vehicle usv as it is common in many references while autonomous surface vehicle asv is used in another texts usv technology is rather new in contrast to autonomous underwater vehicles auvs which has already reached its maturity the accuracy of usvs is far better than that of the auvs since the gps fixes are generally available at all time in open waters naeem et al 2007 usvs are robots for operation at lakes canals harbors and even open sea that are characterized by small size good hiding capability high mobility and low price tang et al 2015 this surface vehicles are subjected to many objectives either alone or as part of a sensor network some well known applications for usvs include marine environment monitoring bathymetry inspection mine countermeasure and port protection oil and gas exploration deep sea pipeline monitoring coastal security search and rescue campbell et al 2012 pêtrès et al 2012 selection of a suitable marine craft platform for automation is the first step of work considering potential candidates classical hull shape single hull or twin hull catamaran shaped vessels exploits favourable hydrodynamic properties to obtain long range operation with low energy consumption nađ et al 2015 between small boats the catamaran is for stability with respect to roll capability of payload transport with respect to the hydrodynamic drag and redundancy in hull buoyancy caccia et al 2005 from view of reaction force applied to surface vehicles marine crafts can be classified according to their maximum operating speed u and length of the submerged portion l using the froude number fr u l g where g is the acceleration due to gravity the weight of a vessel operating with a froude number less than about 0 4 0 5 is almost completely supported by the hydrostatic force of buoyancy that is proportional to the volume of fluid displaced displacement mode in froude numbers greater than about 1 0 1 2 the weight is almost completely supported by a hydrodynamic force that is roughly proportional to the square of the speed planning mode for intermediate values of the froude number the vessel s weight is supported by both the hydrostatic and hydrodynamic force semi displacement vessel fossen 2011 in usvs the navigation guidance and control ngc system intelligently controls the vehicle to go from origin to destination avoiding the obstacles in its path depending on the anticipated danger of the obstacles the vehicle chooses an angle of divergence which avoids the obstacles and keeps the speed of the vehicle eydgahi et al 2007 during navigation the sensors for detecting the obstacles would be a radar lidar binocular vision stereo vision monocular vision infrared cameras laser range finders and ultrasonic sensors or combination some of these sensors in this field usually detecting distance is limited to a few hundred meters the maximum detecting distance of sensors would be under 200 m e g for lidar tang et al 2015 while ultrasonic sensors difficultly could detect up to 10 m some researches use high accuracy and expensive positioning systems such as rtk dgps despite to high accuracy and expensive positioning systems some experiments demonstrated the effectiveness of extended kalman filter ekf and simple pid guidance and control laws to perform basic control tasks such as auto heading auto speed and straight line following with a usv equipped only with gps and compass caccia et al 2008 different algorithms have been developed and were used for ngc as well as obstacle avoidance in reviewed texts each with some pros and cons some main methods that have been proposed for navigation and obstacle avoidance in robot boats are raytracing techniques the use of a state machine dynamic programming modified a algorithm fuzzy logic interval analysis voronoi diagrams optimization of the time derivative of the distance between boat and target and potential field framework pêtrès et al 2012 generally speaking the problems related to motion control and guidance of usvs are classified in the literature into three basic groups a point stabilization the goal is to stabilize the vehicle zeroing the position and orientation error with respect to a given target point with a desired orientation bibuli et al 2009 b path following more specifically the full path might be known to the experimenter prior starting the experiment and communicated to the vehicle in full or just a piece at the time i e the vehicle has to follow a planar path without temporal constraints this control compute and reduce to zero the distance between the vehicle and the path as well as the angle between the vessel speed and the tangent to the path bibuli et al 2009 caccia 2006 c path tracking trajectory tracking the vehicle might need to learn segments of the path to track sequentially just seconds ahead of setting on each one requiring the vessel to follow a time parameterised reference curve i e to be in specific points at specific instants of time bibuli et al 2009 sagginia et al 2015 caccia 2006 except to these three main groups two different methods are added in some texts d control in the horizontal plane where a simple p i d heading controller is sufficient for guaranteeing satisfactory performance and e cooperative motion control a leader and a follower vehicle following two parallel paths master slave caccia 2006 1 1 literature review some papers about guidance navigation and obstacle avoidance in usvs are reviewed and finally some useful information from different articles are given in a table for comparison praczyk 2015 presented application of evolutionary neural networks to the collision avoidance task and the navigation problem in a complex multi object rapidly changing environment which do not behave according to any widely accepted regulations praczyk 2015 liu et al 2015 introduced a path planning algorithm for the usv formation navigation based on the fast marching fm method which has features of fast computation speed and low computation complexity this algorithm covers two areas i e ship domain area and collision avoidance area to ensure the planned trajectory to not violate any forbidden area liu and bucknall 2015 zereik et al 2015 simulated three different control tasks namely path following obstacle avoidance and speed regulation as an algorithm named priority task approach the main objective of this approach was to correctly execute a path following task while guaranteeing also obstacle avoidance and vehicle speed regulation zereik et al 2015 ma 2015 developed a modified unscented kalman filter as an online estimation algorithm with higher precision and lower calculation complexity for usv state estimation it is concluded that the proposed algorithms to be superiority to the general ukf motwani et al 2013 evaluated potential application of interval kalman filter ikf algorithms for estimating the heading angle of the vessel under erroneous modeling assumptions the simulations reveal several characteristics of the ikf motwani et al 2013 onunka et al 2013 combined the ultrasonic sensor and radar to reduce the uncertainties present in the guidance and control of the usv while improving the obstacle detection and avoidance capacity of the usv especially in the near field region up to 5 m from the usv onunka et al 2013 finally for straightforward comparison some useful information from reviewed texts are given in table 1 some design characteristics thrust force maximum speed application field and navigation algorithms are selected information that is extracted from some published papers considering different algorithms are equipped to different usvs each with some drawbacks and since for faultless navigation and obstacle avoidance each platform would have its own correct and effective parameters the main objectives of this research is as a determining the dynamic model parameters based on experimental tests for the usv that is designed and constructed in this project b state estimation using ekf predictor c giving a complex path following algorithm for navigation control and obstacle avoidance based on research ball and potential field methods 2 materials and methods this section first considers the designed and constructed usv platform the derived rigid body model based on experimental results are described next then it is followed by extended kalman filter ekf application and developing a complex algorithm for ngc finally it is terminated with explanation of obstacle avoidance algorithm 2 1 the evaluated platform this manuscript explains a part of a complete scientific project morvarid 1 1 emorvarid ut ac ir that is pending for tracing the hydrography map of a harbour in the bureau using an usv considering common platforms the twin hulled catamaran design is selected due to its stability and simplicity of steering mechanism which is steered using differential thrust the morvarid is a plug in hybrid solar powered usv equipped with two thrusting motors each with 445 n 100 lbs thrust force this 24 v motors are controlled as variable speed in forward and backward the boat length width and height approximately are 3 8 2 4 and 1 5 m respectively it s overall weight is about 700 kg an 8 kwh high technology li ion battery pack can extend its stability for more than three continues cloudy days to perform the defined duty it is equipped with some local perception and global monitoring sensors as a simple gps pack of state sensor imu compass and air pressure range finder lidar a set of ultrasonic sensors stereoscopic vision system and three single beam echo sounders an outboard waterproof ipc is a central processing and decision making unit that receives all data and information analysis data and activate the port and starboard motors in the proper manner communication between morvarid and bureau is based on an ethernet network that capable for data sending to maximum 300 mbps in distances to 10 km the 3d cad model of the morvarid is shown in fig 1 a and its first test in the persian gulf lack suburban of tehran is illustrated in fig 1 b this usv can operate in four modes by a priority as a manual operation by a joystick on the vehicle b remote control by a handheld unit c control from office using a gui and d fully automatic path following 2 2 rigid body model this section discuss deriving the dynamic model of the marine vehicle in six degrees of freedom dof since six independent coordinates are necessary to determine the position and orientation of a rigid body according to fossen 1996 fossen 1994 it is assumed two coordinate frames the moving coordinate frame that is fixed to the vehicle and is called body fixed reference and an earth fixed reference frame as shown in fig 1 the origin of the body fixed frame is usually chosen to coincide with the center of gravity cg the kinematic equation for transforming body fixed reference to earth fixed one can be expressed as fossen 1994 1 η j η ν where η x y z φ θ ψ t denotes the position and orientation vector with coordinates in the earth fixed frame ν u v w p q r t is the generalized linear and angular velocity vector in body frame coordinate and j η is transformation matrix that for details the reader is referred to fossen 1994 fossen 1994 here x y and z are vehicle position and φ θ and ψ are orientation in earth fixed frame also u v and w are velocity respectively in surge sway and heave and p q and r are angular velocity respectively around roll pitch and yaw for surface vehicles the depth z and pitch θ variables are not applicable also the roll φ variation is found to be negligible during experimental evaluations naeem et al 2012 for simplicity ignoring the swing z cons and w 0 pitch θ 0 and q 0 and roll φ 0 and p 0 the kinematic model in eq 1 which describes the geometrical relationship between the earth fixed and the vehicle fixed motion is given as 2 x y ψ c o s ψ s i n ψ 0 s i n ψ c o s ψ 0 0 0 1 u υ r according to newtonian and lagrangian mechanics nonlinear dynamic equation of motion can be conventionally expressed as fossen 1994 3 m r b υ c r b υ υ d r b υ υ g η τ where mrb denotes the rigid body inertia matrix including added mass and mrb mrb t 0 and m r b 0 crb ν is denotes the matrix of coriolis and centripetal terms including added mass and crb ν crb ν t drb ν is damping matrix g η is vector of gravitational forces and moments and τ x y z k m n t is the vector of control input including force and moments in three directions in this case since the inputs are only from two port and starboard motors the usv is deal as underactuated surface ship fewer numbers of actuators than the to be controlled degrees of freedom considering tport as portside thrusting force and tstbd as starboard thrusting force each in surge direction the control input vector become as 5 τ τ u τ ν τ r t t p o r t t s t b d 0 t p o r t t s t b d b 2 t where b is the distance between two thrusting power sources 1 2 m in this case differential steering imposes a moment about the vehicle that causes it to turn there are distinct advantages to this type of system primarily the turning radius for the vehicle is substantially reduced as well as the additional capability to steer without the requirement of a forward speed bertaska et al 2015 the mathematical model of an underactuated ship moving in surge sway and yaw is obtained from the motion equation of the ship moving in six degrees of freedom under disturbances induced by wave wind and ocean current furthermore it is assumed that the inertia added mass and damping matrices are diagonal this assumption holds when the vessels have three planes of symmetry for which the axes of the body fixed reference frame are chosen to be parallel to the principal axis of the displaced fluid which are equal to the principal axis of the vessel most ships have port starboard symmetry moreover bottom top symmetry is not required for horizontal motion ship fore aft nonsymmetry implies that the off diagonal terms of the inertia and damping matrices are nonzero however these terms are small compared to the main diagonal terms so the underactuated ship moving in surge sway and yaw can be described as doa et al 2004 6 x u cos ψ v sin ψ y u sin ψ v cos ψ ψ r u m 22 m 11 v r d u m 11 u i 2 3 d u i m 11 u i 1 u 1 m 11 τ u 1 m 11 τ w u t v m 11 m 22 u r d υ m 22 v i 2 3 d υ i m 22 v i 1 v 1 m 22 τ w υ t r m 11 m 22 m 33 u r d υ m 22 v i 2 3 d r i m 33 r i 1 r 1 m 33 τ r 1 m 33 τ w r t the positive constant terms mjj where 1 j 3 denote the ship inertia including added mass and is derived according to equ 7 the positive constant terms du dv dr dui dvi and dri where i 2 3 represent the hydrodynamic damping in surge sway and yaw for simplicity the higher nonlinear damping terms are ignored muske and ashrafiuon 2008 doa et al 2004 and reyhanoglu 1996 the time varying terms τwu t τwv t and τwr t are the environmental disturbances induced by wave wind and ocean current with τwu t τwu max τwv t τwv max and τwr t τwr max finally the available controls are the surge force τu and the yaw moment τr that are calculated as equ 5 the parameters added mass and damping coefficients are the unknown variables that would be derived mass parameters include added mass contributions that represent hydraulic pressure forces and torque due to forced harmonic motion of the vessel which are proportional to acceleration using the estimate of the added mass terms presented in fossen 1994 for the experimental model boat it would be derived as muske and ashrafiuon 2008 7 m 11 m 0 05 m m 22 m 0 5 ρ π d 2 l m 33 m l 2 w 2 1 2 0 1 m b 2 ρ π d 2 l 3 12 where m 700 kg is the actual mass of the usv l 3 m is the effective length w 0 8 m is the width d 0 5 m is the mean submerged depth and ρ is the density of water about damping coefficients according to ma 2015 8 d u 2 0 2 d u d v 2 0 2 d v d r 2 0 2 d r d u 3 0 1 d u d v 3 0 1 d v d r 3 0 1 d r for defining du dv and dr combination of experimental results simulation and conformance with some references are used considering that the damping parameters are dependent on boat shape and dimension main related parameters of some usvs as well as morvarid are given as table 2 according to table 2 the ratio of m11 du m22 dv and m33 dr for all given usvs are in specific range inserting maximum values of these ratios in the simulation model and tuning their values till the surge and yaw speeds for predefined thrusting force and moments become stable is continued the predefined thrusting force is achieved from experimental results and is the minimum thrust force that could move the boat in the steady state for this case is 0 2 of maximum thrust finally these ratios for morvarid is defined as m11 du 10 m22 dv 5 and m33 dr 2 2 3 ekf algorithm and its parameters to best estimate the statues of the vehicle application an estimator filter is common in estimation theory the extended kalman filter ekf is the nonlinear version of the kalman filter which linearizes about an estimate of the current mean and covariance as it is the case in this study the state transition and observation models do not need to be linear functions of the state but may instead be differentiable functions the ekf can be formulated as model x k f x k 1 u k w k i n t h i s c a s e x k x k 1 t f x k 1 u k w k z k h x k v k i n t h i s c a s e z k h x k v k predict 9 x ˆ k f x ˆ k 1 u k i n t h i s c a s e x ˆ k x ˆ k 1 f x ˆ k 1 u k p k f k 1 p k 1 f k 1 t q k 1 update k k p k h k t h k p k h k t r 1 x ˆ k x ˆ k k k z k h x ˆ k p k i k k h k p k since three degree of freedom dof motion composed of surge sway and yaw was considered for the filter dynamics the usv s motion was estimated using position and attitude measurements provided by the gps compass and imu here xk x y ψ u ν r t is state vector in the step of kth zk x y ψ u ν r t is measurement vector that the first and second parameters are measured bys gps the 3rd parameter is measured by compass and the last three are measured by imu the state estimation function f xk 1 uk is a function of state parameters and control signal uk and is given according to equ 6 t is time step and h is jacobian of h xk that here would be a function of t as given below also fk 1 is jacobian of f xk 1 uk the jacobian matrix j for an arbitrary function f is an m n matrix that is given as equ 10 10 j d f d x f x 1 f x n f 1 x 1 f 1 x n f m x 1 f m x 1 the wk and vk in equ 9 are white noise for process and measurement respectively which are the characterization of system modeling errors and sensors uncertainty furthermore the following conditions are simultaneously satisfied rodríguez and gómez 2009 11 e w k 0 e v k 0 e w k w i t δ k i q k υ k υ i t δ k i r k where δ n 1 n 0 0 n 0 is the kronecker delta function qk is the covariance matrix of the system noise and rk is the covariance matrix of the observation noise that all of these are positive parameters the adjustment of qk and rk is critical in the development of kalman filter although estimating of rk is not very sophisticated about qk there are some methods for these parameters definition e g monte carlo gomez gil et al 2013 however in this research rk estimated as r σ x g p s 2 0 0 0 0 0 0 σ y g p s 2 0 0 0 0 0 0 σ ψ c o m p 2 0 0 0 0 0 0 σ u i m u 2 0 0 0 0 0 0 σ υ i m u 2 0 0 0 0 0 0 σ r i m u 2 h 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 t 0 0 0 0 0 0 1 t 0 0 0 0 0 0 1 2 4 path following and obstacle avoidance algorithm between path following algorithms potential field method is one of the most well known algorithm that operates according to magnetic potential field i e attractive or repulsive force are inversely proportional to distance from destination point this algorithm have been widely and successfully employed for control and motion planning of mobile robots for decades the potential field based algorithms are fast reliable and easy to tune once implemented on real platforms pêtrès et al 2012 in artificial potential field method movements of the robot represented as a particle are governed by a field which is usually composed of two components an attractive potential drawing the robot towards the goal and a repulsive potential pushing the robot away from obstacles approximately in all developed algorithms the destination point is a single point that attract the vehicle due to this the main drawback with potential field techniques is their susceptibility to local minima to dissolve this problem an algorithm is developed based on the combination of potential field and research ball algorithms más et al 2010 this concept is illustrated in fig 2 as ngc algorithm for each point on the navigation course a search is conducted to find two nearest goal points on the reference path the algorithm first finds the nearest path line in whole area and then searches on that line to complete the search ball once determined the distance of these points from the usv represents the greatness of the attractive force the process continues for all of the components in the examined trajectory the search is spatially bounded by the user defined search ball that here it is selected as equal as 2 l l is boat length fossen 1994 naeem et al 2008 actually a line of sight los maneuvering system was used to control usv position and transition between waypoints in a trajectory as in fossen 2011 this system used the vehicle s current position and desired positions to determine a desired heading the radius of the search ball br allows a certain level of flexibility on the user side however a well adjusted magnitude makes the algorithm more computationally efficient the search ball algorithm can be mathematically formulated as follows assuming points p xj yj to be the position of usv estimated by ekf and t 1 n as a set of indices for reference path points inside the search ball if e and n represent the east and north coordinates respectively for each j a new set bj i ε t dij br can be defined where distances dij are calculated with equ 12 12 d i j e i e j 2 n i n j 2 the members in the set of bj is sorted from min to max to obtain the minimum distance and its number actually the algorithm determines two nearest goal points to usv it is necessary to mention that as shown in fig 3 searching is done only inside a semicircle i e the algorithm seeks only ahead of the boat also the deflection angle of usv from each point is calculated using equ 13 13 α i a r c t a n n i n j e i e j to attract the usv toward the goals a linear potential pot is built for every path points as follows pêtrès et al 2012 14 p o t i k 2 d i j h e r e i 1 t o 4 where k2 is the desired attractive gradient and dij is the euclidean distance between p xj yj and ith goal finally the real destination point and the required orientation of usv that is shown by red vector in fig 3 is calculated from the result of calculated vectors using the equ 15 15 δ a r c t a n i p o t i s i n α i i p o t i c o s α i to set the motors thrusting force the algorithm first defines if the boat is in the right hand or left hand of the pass by comparing latitude of the boat and desired path then it sets the desired thrusting force according to equ 16 16 i n r i g h t t s t b d p r i m f o r c e z 1 δ 3 ψ p a t h a n g l e t p o r t p r i m f o r c e z 1 δ 3 ψ p a t h a n g l e i n l e f t t s t b d p r i m f o r c e z 1 δ 3 ψ p a t h a n g l e t p o r t p r i m f o r c e z 1 δ 3 ψ p a t h a n g l e according to fig 3 the z1 is minimum distance between usv and path that is calculated using triangulation relations actually increasing distance between the boat and the desired path as well as increasing δ causes more differences between two motors more turning torque also according to this equation the boat forced in a way that differences of heading and path angle is decreased the prime force is a variable defining the thrusting force when the usv is on the non curved path without any bias equ 17 17 p r i m f o r c e k 1 y n e a r g o a l 1 g o a l 2 5 z 1 where k1 is a constant number for example 30 of motors thrust it is assumed that thrust of motors t tmax rpm rpmmax bertaska et al 2015 variables ynear goal1 and ynear goal2 are component of goal positions in y direction for two nearest goals and difference of these two cause to reduce the speed at curved paths e g at head of the path also drift is causes to reduce speed obstacle avoidance to detect obstacles three set of sensors were used according to fig 4 a lidar hokuyo s uxm series was used in front of the boat that covers 190 to cover the rear area a stereoscopic system is under development using two ccd cameras and finally a set of ultrasonic sensors using 10 waterproof modules jsn sr04t were used that detect near obstacles approximately all around the vehicle considering the operation environment of usv two type of obstacles would be categorized as static obstacles and dynamic obstacles when an obstacle is detected inside the sight of any three mentioned sensors the obstacle function is activated and using clustering methods four parameters would be extracted include width of obstacle central point speed vector value and direction if the detected obstacle was static considering the near goal point to usv and distance between obstacle and usv the two near goal points to the obstacle is defined according to fig 3 if the obstacle is located in the right hand of the path the algorithm steers to left and vice versa using equ 18 with some alteration from pêtrès et al 2012 18 o b s t a c l e i n r i g h t t p o r t t p o r t k o b s d i s t o b s 1 k o b s d i s t o b s 1 o b s t a c l e i n l e f t t p o r t t p o r t k o b s d i s t o b s 1 t s t b d t s t b d k o b s d i s t o b s 1 where 19 k o b s k 1 o b s w i d t h k 2 here k1 and k2 are tunable scalars that are defined by trial and error in this case k2 is set as 50 the k1 is a variable that changes between 0 and 35 if distance between obstacle and usv decrease in each step k1 increases and vice versa the variable obs width is the width of detected obstacle and distobs is distance between usv and obstacle according to equ 18 when the boat gets closer to an obstacle it steers with more differential force although when an obstacle is very near the motors thrust is going to be a very large number but it is limited to 445 n all calculations for obstacle position was based on its cg point however considering the dimension of obstacle and according to equ 19 distance from obstacle is kept based on k1 and k2 values about the dynamic obstacles some potential scenarios would be considered i the obstacle is detected by lidar considering the speed vectors of usv and obstacle and extension of these vectors if these two trajectories are intersect inside the sight of the sensor some actions are required first the algorithm calculates all mentioned steps above to reduce the speed one gear below of the usv and this is repeated until the forward speed of usv becomes zero if the algorithm predicts a collision even with stopping the usv this means that the obstacle is coming directly toward the usv so it goes backward in 45 to right or left however if trajectories of two speed vectors are not intersect in special speed the usv runs with that speed ii the obstacle is detected by 3d vision in this case only obstacles are required attention that come toward and faster than usv however if it is estimated that collision is probable the usv steer to right or left with 45 iii the obstacle is detected by ultrasonic this means that usv is very close to obstacle the boat activates emergency cut off switch and all warning lights and signals are activated for morvarid usv the first test is performed in real situation and useful experimental data is obtained from some sensors however to evaluate the robustness and confidantes of the developed ngc algorithm before second test it was simulated as hardware in the loop by using lidar gps imu compass and ultrasonic sensors as a real data acquisition sources the algorithm was programmed and developed using visual c in microsoft visual studio software 3 results and discussions to plot the hydrography map of the purposed port all area was divided to straight lines that were connected by u turns at the ends many points on the lines were regarded and 2d position of points were defined in earth fixed frame fig 5 illustrates three of these lines with two end turns as shown in the figure the lines were 800 m in length and 150 m distance between them the predefined path was drawn by blue line and gps data was pointed by green while the estimated positions were shown by red line for careful illustration the gps data was drawn by multiplying data to 10 in y direction for border conditions in starting of the algorithm the state vector x0 was assumed as x0 p0 0 10 0 1 0 0 according to fig 5 the developed algorithm followed the straight paths very precisely while some errors were present for u turns at the end of the path since there was no more goal point the usv started to fluctuate inserting some disturbing forces in the algorithm had no effect on the navigation however if this force increased very much the usv lost its paths according to the simulation results disturbance forces in sway was acceptable when its approximated value was less than the thrusting force in surge fig 6 shows some main evaluated parameters versus time steps in this figure a is the surge velocity curve versus time this speed set to be 1 m s in the start up in the straight path speed was increased a little and continued approximately constantly as it was expected the speed decreased at the turning so the boat could navigate precisely since in fig 6 evaluated parameters were traced versus time steps and because of decreasing speed in the turning according to a the time that usv spend in the straight path seems to be equal to that of turning fig 6 b shows the yaw angle rate of usv the maximum value of r was approximately 12 s fig 6 c illustrates the orientation of boat based on east direction according to this chart in the first straight line the ψ is zero in the first u turning it was increased till to 180 and continued to second turning then it was decreased to zero for third straight path fig 6 d and e are propellers thrusting force for starboard and port respectively for straight path they were adjusted equally to 60 n that was approximately fit to second gear of motors this result approximately confirms the experimental results that forward velocity of 1 m s was obtained from second gear at the first turning since the boat turns to left side the starboard thrust was increased while the port was decreased and in the second turning this occurred vice versa according to these figures the maximum value of thrusting force was limited to 150 n finally fig 6 f shows turning torque that was derived from equ 5 result of obstacle avoidance algorithm is shown in fig 7 two different obstacles in two different positions were regarded the first obstacle s width was 70 m and the second was 100 m the algorithm was evaluated by changing the position and size of the obstacle in different cases distance of usv from obstacle was simply controlled with variable kobs equ 19 in the algorithm if distance between usv and obstacle was incremental the kobs was decreased and vice versa during navigation between lines when the usv lost its former path for any reason such as a wide obstacle and reached to a new line it started a new navigation and kept going forward fig 8 shows surge velocity angular velocity about yaw orientation thrust force in port thrust force in starboard and turning torque respectively in a to f in presence of obstacles illustrated in fig 7 according to a the surge velocity was decreased when the boat got close to turnings and obstacles the angular velocity about yaw was maximum to 15 and depends on the boat body characteristics as well as thrusting motors capabilities in the c orientation angle is illustrated while its maximum value goes approximately up to 200 figure 8 d and e shows the thrusting force from starboard and port motors it was desirable to obtain even changes in motors speed since uneven changes in revolution of motors is not favorite and sometimes impossible finally f shows the thrusting force that causes steering according to fig 6 the developed algorithm navigated and controlled the usv in a reasonable manner although using powerful propellers would increase maneuverability and provide more precise navigation especially in presence of obstacles 4 conclusion it has been proven that multiple motion sensors play a vital role in autonomous navigation the morvarid an autonomous usv was equipped with multiple sensors to plot the hydrography map in shallow waters dynamic model of the boat was derived and some main parameters of rigid body model was defined based on experimental evaluations for the best estimation of position and states the ekf estimator was used in navigation algorithm while for navigation and obstacle avoidance in path following algorithm combination of search ball and potential field methods were applied real data was provided for algorithm simulation based on hardware in the loop concept connecting gps imu compass lidar and ultrasonic sensors to a developed application in visual c the algorithm was evaluated in different circumstances with different values of environmental disturbances wind wave and current as well as different obstacles the traced curves from main evaluated parameters were illustrated the robustness and precision of the developed algorithm however installing powerful thrusters would boost maneuverability which in turn would smooth the curves acknowledgment authors would like to acknowledge the ports and maritime organization for funding the morvarid project no 20s 7509 2015 
23359,this paper examines the effect of the drag and inertia coefficients used in morison s equation as predicted by some calibration approaches on the short term wave induced force acting on a fixed vertical cylinder the four published irregular wave tests considered in this study are all highly inertia dominated the average peak and troughs approach is implemented to extract the significant wave height and the peak period from the wave elevation records linear random wave theory is adopted since it is the most appropriate theory to numerically estimate the water kinematics in deep water the calibration approaches considered to investigate the constant drag and inertia coefficients are the least squares fit to the force time domain the least squares fit to the force spectrum the conventional method of moments and the lower method of moments the variability of the coefficients is then examined by adopting the wave by wave method thereafter morison s wave force is estimated and compared to the experiments in the time and frequency domain the probability of exceedance of the extreme wave force values is estimated for each test individually in order to acquire a more comprehensive overview on the problem most results show a good agreement between the predicted and experimental wave induced force however the probability of exceedance for the extreme wave force obtained by the wave by wave method converge well with the experiments extreme force keywords morison equation vertical cylinder drag coefficient inertia coefficient load variability 1 introduction most of the floating support structure of offshore wind turbines owt consists of cylindrical member s either one vertical cylinder or a number of cylinders connected to each other s forming a truss uzunoglu et al 2016 the accurate prediction of wave load acting on those structures has a vital importance it is estimated by applying sequential steps in order to get accurate design load there is no doubt that morison et al 1950 has introduced the simplest most efficient and widely used method to predict the wave force on a submerged vertical cylinder with a diameter less than half of the wave length morison s equation consists of two components drag force f d due to the water particle velocity u and inertia force f i due to the water particle acceleration a sarpkaya 2010 has presented a comprehensive review of morison s equation and its dependence on various factors the estimation of the drag c d and the inertia coefficient c m plays an important role in the numerical prediction of the wave force in this regard a series of experiments has been carried out by troesch and kim 1991 and sarpkaya 1986 to estimate the c d and c m from these laboratory works many results have been published and are still used in many researches other studies have been performed in this area such as the work of wolfram and naghipour 1999 that examined the widely used approaches to estimate the coefficients on a heavily roughened circular cylinder the pioneering works of sarpkaya 1975 bearman et al 1985 dummer et al 1986 and chakrabarti 1988 have proposed different methods to estimate the c d and c m used in morison s equation based on laboratory and field experiments the concept of these methods is to provide values that give the best fit between the measured and the predicted force signal however shankar et al 1987 found that even by using the same wave record but by applying two different techniques the coefficients values might be significantly different isaacson et al 1991 summarized some techniques to estimate these coefficients for a wave force record his study has been conducted on a series of simulated wave record for a random sea based on two parameter pierson moskowitz spectrum raed et al 2016 adopted some of these techniques in two regular and two irregular wave tests a number of calibration approaches is available to deal with the experimental wave tests isaacson et al 1991 adopted the least squares fit to force time domain the least squares method to the force spectrum and the method of moments applied to the force probability distribution to estimate a constant value for the c d and c m further the variability of the coefficients along the time record has also been examined by isaacson et al 1991 by incorporating the wave by wave method other methods that consider the variability of the coefficients are also available for instance the work presented by dean et al 1981 regarding the applicability of these methods dean 1976 found the force measured in the drag regime is suitable in investigating the c d and not the c m and vice versa in the force measured in the inertia regime recently the conventional methods of moments as reported by najafian 2007 represents an effective calibration approach especially in case of phase shift existence between the measured forces and the measured water particle however the resultant coefficients by this method still suffer from a considerable scatter when it is compared to other methods so najafian 2007 proposed an efficient method called the lower method of moments that led to a more accurate estimate of the morison s coefficients in case of drag dominated forces in more specific studies mohd zaki et al 2016 compared the sampling variability of the drag and inertia coefficients from the conventional method of moments with those derived from the lower method of moments and another method called method of linear moments by using a simulated wave force data in particularly drag dominated force in the last decade many attempts concerning the probabilistic models of the morison loading and the effect of the non linearity due to the drag component had been developed najafian et al 1995 presented a review of the probabilistic description of morison wave loading and response of fixed offshore structures the uncertainties in the morison s equation could not be neglected and had also gained attention for instance guedes soares and moan 1983 have applied the first order second moment method fosm to estimate the uncertainties associated with the morison s force on cylindrical pipe thereafter raed et al 2015 adopted such method to study the uncertainties associated with the morison loads acting on semi submersible floating support structure for offshore wind turbine the international energy agency iea has been promoting several benchmark studies to help standardizing the calculation methods used within the offshore wind energy industry e g robertson et al 2014 which can also be used to assess the model uncertainty uzunoglu and guedes soares 2016 2018 due to its importance they are presently validating methods to determine morison s coefficients from experiments robertson et al 2015 the purpose of this work is to examine the effect of the drag and inertia coefficients used in morison s equation as predicted by some calibration approaches on the short term wave induced force acting on a fixed vertical cylinder four irregular wave tests selected from the ones published by robertson et al 2015 are considered these tests are all strongly inertia dominated four calibration approaches are used to estimate the constant coefficients namely least squares fit to the force time domain lstd the least squares fit to the force spectrum lsfs the conventional method of moments and the lower method of moments the variability of the coefficients along the time series is also examined by adopting the wave by wave method wbw based on dividing the wave according to the zero down crossing periods t z the wave force was predicted by implementing the obtained coefficients values into morison s equation thereafter for each test the probability of exceedance of the extreme values of the resultant force were compared with their corresponding experimental values 2 wave load calculation 2 1 wave force morison et al 1950 proposed that the force exerted by surface waves on a vertical cylinder pile which extends from the bottom through the free surface to be composed of inertia f i and drag f d components 1 f f d f i the drag and inertia forces are then represented in the time domain by 2 f t 1 2 ρ d c d u t u t π d 2 4 ρ c m a t where f is the wave force per unit length in n m c d is the drag coefficient c m is the inertia coefficient u is the water particle velocity in m s a is the water particle acceleration in m s 2 ρ is the water density in kg mass m 3 n s 2 m 4 while the d is the diameter of the cylinder in m the drag and inertia force could also be represented in the frequency domain directly based on the linearization of the drag term by borgman 1972 3 s f ω 8 π c d 2 k d 2 σ u 2 s u ω c m 2 k m 2 s a ω where s f is the force spectral density k d 0 5ρd k m 0 25ρπd 2 σ u is the standard deviation of the water particle velocity ω is the frequency in rad s while s u and s a are the water particle velocity and acceleration spectral density respectively 2 2 kinematics second order theory or higher are the best theories to be used in the prediction of wave kinematics due to its good analytical validity in deep water nevertheless the linear wave theory gives to some extent good results when compared to those obtained from the higher order theories but still the selection of the theory used need a complete knowledge about the prevailing environmental conditions surrounding the structure in this study the linear random wave theory is used to estimate the water kinematics later the estimated kinematics will be used to investigate the wave force 2 2 1 linear random wave theory linear random wave theory is considered the most convenient theory to calculate the water kinematics in deep and transitional water furthermore this wave is applicable only in case of non breaking waves dnv 2007 in this theory the fluid is assumed to be incompressible inviscid and irrotational and the irregular wave elevation can be expressed as a sum of a number of sinusoidal waves with different frequencies ɷ and heights h so the irregular wave time varying amplitude ζ is obtained by 4 ζ ζ a sin k x ω t in this equation ζa is the amplitude of each wavelet in m ω is wave frequency in rad s k is wave number in rad m once applying the boundary conditions and getting the velocity potential the horizontal velocity u and acceleration a could be obtained as follows e g guedes soares 1998 5 u ω h 2 cosh k z h sinh k h sin k x ω t 6 a ω 2 h 2 cosh k z h sinh k h cos k x ω t where u is horizontal water velocity in m s a is horizontal water acceleration in m s 2 ω is wave frequency in rad s h is wave height in m k is wave number in rad m h is water depth in m z is the downward draft below water level in m x is the distance of propagation and t is time in s also according to the linear theory the water particle velocity and acceleration spectra can be estimated directly from the water surface elevation density spectrum as follow isaacson et al 1991 7 s u ω ω 2 g z ω 2 s η ω 8 s a ω ω 4 g z ω 2 s η ω where 9 g z ω cosh k z h sinh k h 2 3 experimental data and setup the experimental data studied in this work was published in robertson et al 2015 two cylinders of different diameters and a draft of 1 44 m were tested in regular and irregular waves the cylinders were attached to a stiff framework with eigen frequencies of 10 hz and greater therefore their excitation does coincide with the natural frequencies of the cylinder as shown in fig 1 there are two force transducers located at the still water level swl and 0 7 m below swl the transducers record the horizontal wave force in the wave propagation direction the total wave force so called surge force is the sum of the forces recorded by t1 and t2 four tests are evaluated and described in table 1 and numbered according to robertson et al 2015 each one of the irregular wave tests considers a different cylinder diameter tests 17 and 18 evaluate a diameter of 0 2 m and tests 19 and 20 examine the diameter 0 327 m fig 2 tests 17 and 18 are for an irregular wave with a significant wave height h s of 0 279 m and a peak period t p of 2 4s acting on the two cylinders tests 19 and 20 are for h s equal to 0 357 m and t p equal to 2 76s the irregular wave tests contain 1710s of data with sampling frequency 50 hz 3 calibration methods several calibration approaches are available to obtain the appropriate drag and inertia coefficients used in morison s equation fig 1 shows the approaches incorporated in this study the coefficients could be either constant or variable along the time series regarding the constant coefficients four methods are adopted two methods are on the least squares basis and the other two are on the moment s basis the variability of the coefficients will be examined by incorporating the wave by wave method 3 1 constant coefficients estimating constant coefficients from the experiments is the most straightforward way several methods are presented throughout the last decade the least squares method and the method of moments are the two basis approaches that are incorporated in this study to predict those coefficients from the experimental data the idea of the former method is to minimize the residual error between the measured and the calculated force 3 1 1 least squares the least squares method can be divided into 1 least squares fit to the force time domain lstd and 2 least squares fit to the force spectrum lsfs both approaches could be applied to estimate the drag and inertia coefficients used in morison s equation 3 1 1 1 least squares fit to the force time domain lstd isaacson et al 1991 has introduced the following equations to estimate the coefficients directly from the kinematics and force record the drag c d and inertia c m coefficient are estimated by 10 c d 2 ρ d s 1 s 2 s 3 s 4 s 2 s 5 s 4 2 11 c m 4 π ρ d 2 s 3 s 5 s 1 s 4 s 2 s 5 s 4 2 where s 1 t f m t u t u t s 2 t a t 2 s 3 t f m t a t s 4 t u t u t a t s 5 t u t 4 while u and a are the water particle velocity in m s and acceleration in m s 2 respectively at each time step t in the time series and f m is the measured wave force 3 1 1 2 least squares fit to the force spectrum lsfs the least squares fit to the force spectrum can also be used to minimize the error between the measured and the predicted force from the frequency domain perspective as mentioned by isaacson et al 1991 the coefficients are given by 12 c d 2 ρ d q 3 q 4 q 1 q 6 q 3 q 5 q 6 2 1 2 13 c m 2 π ρ d 2 q 1 q 5 q 2 q 4 q 3 q 5 q 2 q 6 1 2 where q 1 i s f m ω i s u ω i q 2 i 8 π σ u 2 s u 2 ω i q 3 i s u ω i s a ω i q 4 i s f m ω i s a ω i q 5 i 8 π σ u 2 s u ω i s a ω i q 6 i s a 2 ω i where s fm is the measured force spectral density σ u is the standard deviation of the water particle velocity s u is the velocity spectral density s a is the acceleration spectrum and ɷ is the frequency in rad s 3 1 2 methods of moments the method of moments is suitable for cases when there is a phase shift between measured force and measured water particle kinematics i e when there is some distance between the locations of the wave probe and the transducers that measure the forces two approaches are considered in this study as described below in detail 3 1 2 1 conventional method of moments all the odd order statistical moments of the morison s wave force are equal to zero due to their symmetrical probability density function about the mean value of zero in the absence of current so the second and fourth moments are given by 14 m 2 e f 2 k d 2 c d 2 e u 4 k m 2 c m 2 e a 2 2 k d k m c d c m e u u a 15 m 4 e f 4 k d 4 c d 4 e u 8 k m 4 c m 4 e a 4 4 k d 3 k m c d 3 c m e u 5 u a 4 k d k m 3 c d c m 3 e u u a 3 6 k d 2 c d 2 k m 2 c m 2 e a 2 u 4 solving eqs 14 and 15 the drag and inertia coefficients are given by 16 c d 1 k d m 4 3 m 2 2 e u 8 3 e u 4 2 1 4 a n d c m 1 k m m 2 e u 4 c d 2 k d 2 e a 2 in the absence of current the expectations used in eq 16 are given by miller 1964 17 e u 4 3 σ u 4 e a 4 3 σ a 4 e u 8 105 σ u 8 since the force kurtosis is defined to be the ratio between the 4th moment and the square of its variance β f is written as 18 β f m 4 m 2 2 e f m 4 e f m 2 2 e f m 4 σ f m 4 by substituting eqs 16 18 the drag and inertia coefficients are determined by 19 c d 1 k d σ f σ u 2 β f 3 78 1 4 20 c m 1 k m σ f σ a 1 3 β f 3 78 where k d 0 5ρd k m 0 25ρπd 2 σ u and σ f are the standard deviation of the water particle velocity and the force respectively while σ a 2 is the variance of the water particle acceleration 3 1 2 2 method of lower order moments due to the scattering results in the coefficients when implementing the conventional method of moments the low order method of moments has been introduced by najafian 2007 to estimate the coefficients in morison s equation this method has been considered as a more efficient form of the method of moments the calculation procedures are identical to the conventional method except using the 1st order absolute moment rather than the 4th moment the first absolute moment is given by 21 e f e c d k d u u c m k m a where k d 0 5ρd k m 0 25ρπd 2 c d and c m is the drag and inertia coefficient respectively u and a are the water particle velocity and acceleration respectively mohd zaki et al 2016 summarized the calculation procedures as follow 1 develop a relationship between the force kurtosis β f and the r where r is the ratio between the expected value of the absolute value of force and the standard deviation of the experimental force record σ f that are simply extracted from the experiments 22 r e f σ f e c d k d u u c m k m a σ f 2 using the value of r obtained from eq 22 to indirectly investigate the value of β f 3 thereafter by substitute β f obtained from step 2 in eqs 19 and 20 the drag and inertia coefficients are obtained the establishment of the relationship between β f and r is well established in najafian 2010 the value of r and β f will not be affected if the force f is divided by a constant since they are dimensionless so the modified force f is given by 23 f f c d k d σ u 2 x 1 x 1 α x 2 where x 1 and x 2 are two independent standardized and jointly gaussian random variables and are given by x 1 u σ u x 2 a σ a and α c m k m σ a c d k d σ u 2 so x 1 and x 2 can be simply investigated from the values extracted from the time series of the velocity and acceleration whereas the value of α is assumed to be from 0 to 20 in steps of 0 1 so we obtain a vector of the modified force as a function of α in a similar way the value of the force kurtosis β f corresponding to each α is given by 24 β f m 4 m 2 2 β f m 4 m 2 2 105 18 α 2 3 α 4 3 α 2 2 25 r e f σ f e f σ f g α 3 α 2 therefore the g α can be estimated by evaluating the following integral 26 g α x 1 x 1 α x 2 p x 1 x 2 d x 1 d x 2 where p x 1 x 2 is the joint probability function of the two independent random variables a relationship was developed between β f and r using eqs 24 and 25 this relation was fitted by a 3rd degree polynomial equation 3 2 wave by wave method wbw from its name wave by wave analysis is based on incorporating the variability of the force coefficients within a given wave record this was done by assuming that c d and c m are constant for individual waves and that their variability can be examined by separately analyzing individual waves within a given wave record the applicability of this approach is based on dividing the water surface elevation η record into a number of waves depending on the zero up crossing or down crossing periods t z and solving each wave individually with its corresponding measured force when the kinematics are consistent with an irregular wave theory or are measured directly then a least squares fit of the measured wave force is applied for each portion of the time series corresponding to an individual wave 4 results and discussion in this study four wave records are considered as previously mentioned each one is calibrated by using the average peaks and troughs approach to estimate the wave characteristics the four experimental wave records are then classified into two groups groups a and b according to the resultant significant wave height h s and peak period t p as shown in table 2 group a consists of a reported h s rep equal to 0 279 m and t p rep equal to 2 4s while group b consists of h s rep equal to 0 357 m and t p rep 2 76s each group has two wave records corresponding to each of the two different cylinder s diameters d the calibrated wave properties reported by robertson et al 2015 are in good agreement with the results obtained in this study as the average percentage of error is 3 and 0 2 for h s and t p respectively as shown in table 2 the wave surface elevation ƞ and the total wave force measured f exp for each test considered in this study are shown in fig 3 the plots on the left hand side are for tests 17 and 18 group a and the plots on the right hand side are for tests 19 and 20 group b the wave elevation records of both tests in each group are identical however the total wave force for each of the two tests differs from each other since the diameters d are not equal the water particle velocity u and acceleration a are numerically simulated in the frequency domain as given in eqs 7 and 8 the cylinder depth was divided into 10 elements and the kinematics were calculated at each element then the total kinematics were derived and used to evaluate the total wave force in fig 4 the total water particle velocity s u and acceleration spectrum s a for group a and b are shown plots a and b are the velocity and acceleration spectrum for tests 17 and 18 respectively while plots c and d are for tests 19 and 20 since the wave elevation in each group is identical for both tests by consequence the water particle velocity and acceleration are identical as well as shown in the figure since some of the calibration methods mentioned in section 3 are relevant to the time domain it had been necessary to generate 1710s water kinematics time series numerically using the same phase angles of the wave elevation records that consist of 75000 data points with a time step of 0 02s the validation of the kinematics obtained by adopting the linear random wave theory is limited to the wave elevation since the experimental records are available only for the elevation and the wave force afterwards the estimated water kinematics u a in conjunction with the measured total wave force for each test are used to calibrate the drag c d and inertia coefficients c m used in morison s equation four methods are used in this study to estimate these coefficients namely the least squares fit to the force time series lstd the least squares fit to the force spectrum lsfs the conventional method of moments and the lower method of moments each method has been applied simultaneously on the four tests and the results are summarized in table 3 and fig 5 regarding the least squares based approaches the c d in all the tests are adjusted to 1 since the values obtained are too small and not realistic due to the predominance of the inertia components which plays an important role in the c d results and this agree well with dean 1976 moreover the behavior of the c d obtained by the least squares based approach cannot be determinately judged due to the possibility of 1 uncertainties in the experiments or 2 a small phase shift between the kinematics and the force or 3 the inconvenience of using this calibration method under certain circumstances however regardless the least squares based methods the conventional method of moments always gives a lower c d values than the lower method of moments in all the tests this invariable behavior gives to some extent strength for using the moments based approaches under certain circumstances which shows agreement with previous studies adopting the conventional method of moments in tests 17 and 18 results in 24 3 and 39 1 lower c d respectively when compared to the results obtained by the lower method of moments while using the conventional method of moments results in a 25 1 and 31 9 lower c d than the lower method of moments in tests 19 and 20 respectively regarding c m the lstd delivers 7 94 on average lower c m in all the tests than those obtained by lsfs while the conventional method delivers 4 65 on average higher c m than those obtained from the lower method of moments the exact percentage of deviation between the coefficients values resulting by incorporating the four different methods are summarized in fig 5 as shown in fig 5 the deviation between the c m values for each individual test is relatively small table 4 shows the force kurtosis β f which is considered as a measure of the importance of the nonlinear drag component in morison s wave loading all β f values approach 3 0 which means the loading is strongly inertia dominated furthermore the drag coefficients could be set to 1 in all least squares basis approaches as shown before in table 3 and only the inertia coefficient is investigated nevertheless the foregoing calculations will not be affected thereafter the drag and inertia coefficient estimated are used to calculate the total wave force acting on the fixed vertical cylinder using morison s equation moreover the effect of increasing the cylinder s diameter under the same sea state condition is also examined it was found that increasing the diameter by 38 in group a and adopting the conventional method and the lower method of moments results in 34 3 and 47 1 higher c d respectively whereas results in 3 4 and 6 7 lower c m respectively regarding group b increasing the diameter and adopting the same two approaches results in 36 3 and 42 higher c d while results in lowering the c m values by 2 1 and 4 3 respectively these results enhance on the importance of the viscous drag effect while the diameter increases fig 6 summarizes a comparison between the experimental wave force record and morison s wave force investigated by using the coefficients obtained using the aforementioned approaches the figure shows a sample of 15 s of comparison between the predicted and the experimental wave force despite the large deviation in the c d value reaching 39 1 in test 18 as shown in fig 5 the results in time domain agree well with the experiments except some minor deviations in the peaks and troughs values that could be due to adopting the linear random wave theory formulation in estimating the kinematics the variation on the drag and inertia coefficients along the time series is examined by incorporating the least squares fit to the force time domain lstd in the wave by wave basis this approach is based on breaking up the wave record into a number of individual waves based on the zero crossing periods t z and estimating the c d and c m for each individual wave fig 7 shows a set of plots composed from the c d and c m variability with the time and a comparison between the predicted and the experimental wave force since c d values exhibits a high degree of scattering due to the dominance of inertia components and the results was not realistic due to the reasons mentioned before so the c d for all waves is set to 1 as shown in plot a nevertheless the simulated wave force in plot c shows a good agreement with the experiments table 5 shows the mean μ and standard deviation σ of the inertia coefficient obtained for each test under consideration adopting the lstd in predicting the c m under the wave by wave basis results in a mean value 1 5 1 1 0 and 0 5 lower than the constant value obtained in table 3 for tests 17 18 19 and 20 respectively fig 8 and fig 9 show a comparison between the power spectrum density s f of the estimated wave force by using the coefficients in table 3 and the experimental force for tests 17 and 19 respectively in test 17 the lower method of moments delivers maximum power at 0 4 hz among the predicted results however this power is 2 4 lower than the maximum power delivered by the experiments at 0 43 hz whereas in test 19 the conventional method of moments delivers 0 3 lower power value than the one obtained from the experiments on the other hand the wave by wave method results in 10 6 and 12 4 lower power value than the experiments in test 17 and 19 respectively the small deviation in the natural frequency between the experiments and the simulations in both tests could be due to some uncertainties as mentioned before in the context moreover the time series was divided into a number of short signals with 20s length to explore the probability of exceedance of the extreme values on each test fig 10 presents a comparison between the probability of exceedance of the predicted extreme wave force and the experimental force the figure is composed of 4 plots which represent the four irregular wave tests regarding group a the extreme values predicted by all the foregoing approaches converge with the experimental results in probability level between 0 5 and 1 whereas the difference start to be notable below 0 5 regarding group b deviation is notable in the probability level below 0 65 between the predicted and experimental values eventually the extreme values obtained by the wave by wave method agree well with the experiments in all the range in both groups despite the deviation in the power obtained by this method 5 conclusion this work investigates the impact of some calibration approaches used for the prediction of morison s force coefficients for fixed vertical cylinder these approaches are applied to four irregular wave tests which are classified into two groups where two diameters are considered in each the constant coefficients are estimated by adopting lstd lsfs conventional method of moments and lower method of moments the coefficients variability on the foregoing tests is examined by implementing lstd under wbw approach the reflection on the total force is discussed through comparing a the predicated and experimental forces in the time domain b the frequency spectra of predicted and experimental forces and c probability distributions of the extreme values of the predicted and experimental forces in all tests the fluctuation on constant drag coefficient is remarkable compared to the inertia coefficient nevertheless this high fluctuation doesn t affect the prediction of the wave force due to the predominance of the inertia component moreover the c d is assumed to be 1 in case of the least squares based approaches and the results show a good agreement with the experiments the results of this study agree well with zaki et al 2016 since the inertia dominated wave force with kurtosis 3 5 is well predicted by applying the conventional method of moments however including the coefficient s variability is still more efficient as shown by isaacson et al 1991 as it gives the most accurate results for the probability of exceedance for the extreme force values however the least squares fit to the force spectrum lsfs give results almost identical to the obtained by adopting the moments based approaches which give strength to this method the deviation obtained in the results when applying the lstd approaches is due to the probability of a phase shift presence between the kinematics and the force signal in summary this work emphasizes the inaccurate results of the c d due the presence of the vertical cylinder in high inertia regime in the experiments incorporating the variability of coefficients using wbw approach gives the minimum deviation between the experimental and the predicted wave extreme values eventually using either the moments based approaches or the lsfs methods doesn t have a remarkable effect on the final results acknowledgements this work was performed within the scope of the strategic research plan of the centre for marine technology and ocean engineering centec which is financed by the portuguese foundation for science and technology fundação para a ciência e tecnologia fct 
23359,this paper examines the effect of the drag and inertia coefficients used in morison s equation as predicted by some calibration approaches on the short term wave induced force acting on a fixed vertical cylinder the four published irregular wave tests considered in this study are all highly inertia dominated the average peak and troughs approach is implemented to extract the significant wave height and the peak period from the wave elevation records linear random wave theory is adopted since it is the most appropriate theory to numerically estimate the water kinematics in deep water the calibration approaches considered to investigate the constant drag and inertia coefficients are the least squares fit to the force time domain the least squares fit to the force spectrum the conventional method of moments and the lower method of moments the variability of the coefficients is then examined by adopting the wave by wave method thereafter morison s wave force is estimated and compared to the experiments in the time and frequency domain the probability of exceedance of the extreme wave force values is estimated for each test individually in order to acquire a more comprehensive overview on the problem most results show a good agreement between the predicted and experimental wave induced force however the probability of exceedance for the extreme wave force obtained by the wave by wave method converge well with the experiments extreme force keywords morison equation vertical cylinder drag coefficient inertia coefficient load variability 1 introduction most of the floating support structure of offshore wind turbines owt consists of cylindrical member s either one vertical cylinder or a number of cylinders connected to each other s forming a truss uzunoglu et al 2016 the accurate prediction of wave load acting on those structures has a vital importance it is estimated by applying sequential steps in order to get accurate design load there is no doubt that morison et al 1950 has introduced the simplest most efficient and widely used method to predict the wave force on a submerged vertical cylinder with a diameter less than half of the wave length morison s equation consists of two components drag force f d due to the water particle velocity u and inertia force f i due to the water particle acceleration a sarpkaya 2010 has presented a comprehensive review of morison s equation and its dependence on various factors the estimation of the drag c d and the inertia coefficient c m plays an important role in the numerical prediction of the wave force in this regard a series of experiments has been carried out by troesch and kim 1991 and sarpkaya 1986 to estimate the c d and c m from these laboratory works many results have been published and are still used in many researches other studies have been performed in this area such as the work of wolfram and naghipour 1999 that examined the widely used approaches to estimate the coefficients on a heavily roughened circular cylinder the pioneering works of sarpkaya 1975 bearman et al 1985 dummer et al 1986 and chakrabarti 1988 have proposed different methods to estimate the c d and c m used in morison s equation based on laboratory and field experiments the concept of these methods is to provide values that give the best fit between the measured and the predicted force signal however shankar et al 1987 found that even by using the same wave record but by applying two different techniques the coefficients values might be significantly different isaacson et al 1991 summarized some techniques to estimate these coefficients for a wave force record his study has been conducted on a series of simulated wave record for a random sea based on two parameter pierson moskowitz spectrum raed et al 2016 adopted some of these techniques in two regular and two irregular wave tests a number of calibration approaches is available to deal with the experimental wave tests isaacson et al 1991 adopted the least squares fit to force time domain the least squares method to the force spectrum and the method of moments applied to the force probability distribution to estimate a constant value for the c d and c m further the variability of the coefficients along the time record has also been examined by isaacson et al 1991 by incorporating the wave by wave method other methods that consider the variability of the coefficients are also available for instance the work presented by dean et al 1981 regarding the applicability of these methods dean 1976 found the force measured in the drag regime is suitable in investigating the c d and not the c m and vice versa in the force measured in the inertia regime recently the conventional methods of moments as reported by najafian 2007 represents an effective calibration approach especially in case of phase shift existence between the measured forces and the measured water particle however the resultant coefficients by this method still suffer from a considerable scatter when it is compared to other methods so najafian 2007 proposed an efficient method called the lower method of moments that led to a more accurate estimate of the morison s coefficients in case of drag dominated forces in more specific studies mohd zaki et al 2016 compared the sampling variability of the drag and inertia coefficients from the conventional method of moments with those derived from the lower method of moments and another method called method of linear moments by using a simulated wave force data in particularly drag dominated force in the last decade many attempts concerning the probabilistic models of the morison loading and the effect of the non linearity due to the drag component had been developed najafian et al 1995 presented a review of the probabilistic description of morison wave loading and response of fixed offshore structures the uncertainties in the morison s equation could not be neglected and had also gained attention for instance guedes soares and moan 1983 have applied the first order second moment method fosm to estimate the uncertainties associated with the morison s force on cylindrical pipe thereafter raed et al 2015 adopted such method to study the uncertainties associated with the morison loads acting on semi submersible floating support structure for offshore wind turbine the international energy agency iea has been promoting several benchmark studies to help standardizing the calculation methods used within the offshore wind energy industry e g robertson et al 2014 which can also be used to assess the model uncertainty uzunoglu and guedes soares 2016 2018 due to its importance they are presently validating methods to determine morison s coefficients from experiments robertson et al 2015 the purpose of this work is to examine the effect of the drag and inertia coefficients used in morison s equation as predicted by some calibration approaches on the short term wave induced force acting on a fixed vertical cylinder four irregular wave tests selected from the ones published by robertson et al 2015 are considered these tests are all strongly inertia dominated four calibration approaches are used to estimate the constant coefficients namely least squares fit to the force time domain lstd the least squares fit to the force spectrum lsfs the conventional method of moments and the lower method of moments the variability of the coefficients along the time series is also examined by adopting the wave by wave method wbw based on dividing the wave according to the zero down crossing periods t z the wave force was predicted by implementing the obtained coefficients values into morison s equation thereafter for each test the probability of exceedance of the extreme values of the resultant force were compared with their corresponding experimental values 2 wave load calculation 2 1 wave force morison et al 1950 proposed that the force exerted by surface waves on a vertical cylinder pile which extends from the bottom through the free surface to be composed of inertia f i and drag f d components 1 f f d f i the drag and inertia forces are then represented in the time domain by 2 f t 1 2 ρ d c d u t u t π d 2 4 ρ c m a t where f is the wave force per unit length in n m c d is the drag coefficient c m is the inertia coefficient u is the water particle velocity in m s a is the water particle acceleration in m s 2 ρ is the water density in kg mass m 3 n s 2 m 4 while the d is the diameter of the cylinder in m the drag and inertia force could also be represented in the frequency domain directly based on the linearization of the drag term by borgman 1972 3 s f ω 8 π c d 2 k d 2 σ u 2 s u ω c m 2 k m 2 s a ω where s f is the force spectral density k d 0 5ρd k m 0 25ρπd 2 σ u is the standard deviation of the water particle velocity ω is the frequency in rad s while s u and s a are the water particle velocity and acceleration spectral density respectively 2 2 kinematics second order theory or higher are the best theories to be used in the prediction of wave kinematics due to its good analytical validity in deep water nevertheless the linear wave theory gives to some extent good results when compared to those obtained from the higher order theories but still the selection of the theory used need a complete knowledge about the prevailing environmental conditions surrounding the structure in this study the linear random wave theory is used to estimate the water kinematics later the estimated kinematics will be used to investigate the wave force 2 2 1 linear random wave theory linear random wave theory is considered the most convenient theory to calculate the water kinematics in deep and transitional water furthermore this wave is applicable only in case of non breaking waves dnv 2007 in this theory the fluid is assumed to be incompressible inviscid and irrotational and the irregular wave elevation can be expressed as a sum of a number of sinusoidal waves with different frequencies ɷ and heights h so the irregular wave time varying amplitude ζ is obtained by 4 ζ ζ a sin k x ω t in this equation ζa is the amplitude of each wavelet in m ω is wave frequency in rad s k is wave number in rad m once applying the boundary conditions and getting the velocity potential the horizontal velocity u and acceleration a could be obtained as follows e g guedes soares 1998 5 u ω h 2 cosh k z h sinh k h sin k x ω t 6 a ω 2 h 2 cosh k z h sinh k h cos k x ω t where u is horizontal water velocity in m s a is horizontal water acceleration in m s 2 ω is wave frequency in rad s h is wave height in m k is wave number in rad m h is water depth in m z is the downward draft below water level in m x is the distance of propagation and t is time in s also according to the linear theory the water particle velocity and acceleration spectra can be estimated directly from the water surface elevation density spectrum as follow isaacson et al 1991 7 s u ω ω 2 g z ω 2 s η ω 8 s a ω ω 4 g z ω 2 s η ω where 9 g z ω cosh k z h sinh k h 2 3 experimental data and setup the experimental data studied in this work was published in robertson et al 2015 two cylinders of different diameters and a draft of 1 44 m were tested in regular and irregular waves the cylinders were attached to a stiff framework with eigen frequencies of 10 hz and greater therefore their excitation does coincide with the natural frequencies of the cylinder as shown in fig 1 there are two force transducers located at the still water level swl and 0 7 m below swl the transducers record the horizontal wave force in the wave propagation direction the total wave force so called surge force is the sum of the forces recorded by t1 and t2 four tests are evaluated and described in table 1 and numbered according to robertson et al 2015 each one of the irregular wave tests considers a different cylinder diameter tests 17 and 18 evaluate a diameter of 0 2 m and tests 19 and 20 examine the diameter 0 327 m fig 2 tests 17 and 18 are for an irregular wave with a significant wave height h s of 0 279 m and a peak period t p of 2 4s acting on the two cylinders tests 19 and 20 are for h s equal to 0 357 m and t p equal to 2 76s the irregular wave tests contain 1710s of data with sampling frequency 50 hz 3 calibration methods several calibration approaches are available to obtain the appropriate drag and inertia coefficients used in morison s equation fig 1 shows the approaches incorporated in this study the coefficients could be either constant or variable along the time series regarding the constant coefficients four methods are adopted two methods are on the least squares basis and the other two are on the moment s basis the variability of the coefficients will be examined by incorporating the wave by wave method 3 1 constant coefficients estimating constant coefficients from the experiments is the most straightforward way several methods are presented throughout the last decade the least squares method and the method of moments are the two basis approaches that are incorporated in this study to predict those coefficients from the experimental data the idea of the former method is to minimize the residual error between the measured and the calculated force 3 1 1 least squares the least squares method can be divided into 1 least squares fit to the force time domain lstd and 2 least squares fit to the force spectrum lsfs both approaches could be applied to estimate the drag and inertia coefficients used in morison s equation 3 1 1 1 least squares fit to the force time domain lstd isaacson et al 1991 has introduced the following equations to estimate the coefficients directly from the kinematics and force record the drag c d and inertia c m coefficient are estimated by 10 c d 2 ρ d s 1 s 2 s 3 s 4 s 2 s 5 s 4 2 11 c m 4 π ρ d 2 s 3 s 5 s 1 s 4 s 2 s 5 s 4 2 where s 1 t f m t u t u t s 2 t a t 2 s 3 t f m t a t s 4 t u t u t a t s 5 t u t 4 while u and a are the water particle velocity in m s and acceleration in m s 2 respectively at each time step t in the time series and f m is the measured wave force 3 1 1 2 least squares fit to the force spectrum lsfs the least squares fit to the force spectrum can also be used to minimize the error between the measured and the predicted force from the frequency domain perspective as mentioned by isaacson et al 1991 the coefficients are given by 12 c d 2 ρ d q 3 q 4 q 1 q 6 q 3 q 5 q 6 2 1 2 13 c m 2 π ρ d 2 q 1 q 5 q 2 q 4 q 3 q 5 q 2 q 6 1 2 where q 1 i s f m ω i s u ω i q 2 i 8 π σ u 2 s u 2 ω i q 3 i s u ω i s a ω i q 4 i s f m ω i s a ω i q 5 i 8 π σ u 2 s u ω i s a ω i q 6 i s a 2 ω i where s fm is the measured force spectral density σ u is the standard deviation of the water particle velocity s u is the velocity spectral density s a is the acceleration spectrum and ɷ is the frequency in rad s 3 1 2 methods of moments the method of moments is suitable for cases when there is a phase shift between measured force and measured water particle kinematics i e when there is some distance between the locations of the wave probe and the transducers that measure the forces two approaches are considered in this study as described below in detail 3 1 2 1 conventional method of moments all the odd order statistical moments of the morison s wave force are equal to zero due to their symmetrical probability density function about the mean value of zero in the absence of current so the second and fourth moments are given by 14 m 2 e f 2 k d 2 c d 2 e u 4 k m 2 c m 2 e a 2 2 k d k m c d c m e u u a 15 m 4 e f 4 k d 4 c d 4 e u 8 k m 4 c m 4 e a 4 4 k d 3 k m c d 3 c m e u 5 u a 4 k d k m 3 c d c m 3 e u u a 3 6 k d 2 c d 2 k m 2 c m 2 e a 2 u 4 solving eqs 14 and 15 the drag and inertia coefficients are given by 16 c d 1 k d m 4 3 m 2 2 e u 8 3 e u 4 2 1 4 a n d c m 1 k m m 2 e u 4 c d 2 k d 2 e a 2 in the absence of current the expectations used in eq 16 are given by miller 1964 17 e u 4 3 σ u 4 e a 4 3 σ a 4 e u 8 105 σ u 8 since the force kurtosis is defined to be the ratio between the 4th moment and the square of its variance β f is written as 18 β f m 4 m 2 2 e f m 4 e f m 2 2 e f m 4 σ f m 4 by substituting eqs 16 18 the drag and inertia coefficients are determined by 19 c d 1 k d σ f σ u 2 β f 3 78 1 4 20 c m 1 k m σ f σ a 1 3 β f 3 78 where k d 0 5ρd k m 0 25ρπd 2 σ u and σ f are the standard deviation of the water particle velocity and the force respectively while σ a 2 is the variance of the water particle acceleration 3 1 2 2 method of lower order moments due to the scattering results in the coefficients when implementing the conventional method of moments the low order method of moments has been introduced by najafian 2007 to estimate the coefficients in morison s equation this method has been considered as a more efficient form of the method of moments the calculation procedures are identical to the conventional method except using the 1st order absolute moment rather than the 4th moment the first absolute moment is given by 21 e f e c d k d u u c m k m a where k d 0 5ρd k m 0 25ρπd 2 c d and c m is the drag and inertia coefficient respectively u and a are the water particle velocity and acceleration respectively mohd zaki et al 2016 summarized the calculation procedures as follow 1 develop a relationship between the force kurtosis β f and the r where r is the ratio between the expected value of the absolute value of force and the standard deviation of the experimental force record σ f that are simply extracted from the experiments 22 r e f σ f e c d k d u u c m k m a σ f 2 using the value of r obtained from eq 22 to indirectly investigate the value of β f 3 thereafter by substitute β f obtained from step 2 in eqs 19 and 20 the drag and inertia coefficients are obtained the establishment of the relationship between β f and r is well established in najafian 2010 the value of r and β f will not be affected if the force f is divided by a constant since they are dimensionless so the modified force f is given by 23 f f c d k d σ u 2 x 1 x 1 α x 2 where x 1 and x 2 are two independent standardized and jointly gaussian random variables and are given by x 1 u σ u x 2 a σ a and α c m k m σ a c d k d σ u 2 so x 1 and x 2 can be simply investigated from the values extracted from the time series of the velocity and acceleration whereas the value of α is assumed to be from 0 to 20 in steps of 0 1 so we obtain a vector of the modified force as a function of α in a similar way the value of the force kurtosis β f corresponding to each α is given by 24 β f m 4 m 2 2 β f m 4 m 2 2 105 18 α 2 3 α 4 3 α 2 2 25 r e f σ f e f σ f g α 3 α 2 therefore the g α can be estimated by evaluating the following integral 26 g α x 1 x 1 α x 2 p x 1 x 2 d x 1 d x 2 where p x 1 x 2 is the joint probability function of the two independent random variables a relationship was developed between β f and r using eqs 24 and 25 this relation was fitted by a 3rd degree polynomial equation 3 2 wave by wave method wbw from its name wave by wave analysis is based on incorporating the variability of the force coefficients within a given wave record this was done by assuming that c d and c m are constant for individual waves and that their variability can be examined by separately analyzing individual waves within a given wave record the applicability of this approach is based on dividing the water surface elevation η record into a number of waves depending on the zero up crossing or down crossing periods t z and solving each wave individually with its corresponding measured force when the kinematics are consistent with an irregular wave theory or are measured directly then a least squares fit of the measured wave force is applied for each portion of the time series corresponding to an individual wave 4 results and discussion in this study four wave records are considered as previously mentioned each one is calibrated by using the average peaks and troughs approach to estimate the wave characteristics the four experimental wave records are then classified into two groups groups a and b according to the resultant significant wave height h s and peak period t p as shown in table 2 group a consists of a reported h s rep equal to 0 279 m and t p rep equal to 2 4s while group b consists of h s rep equal to 0 357 m and t p rep 2 76s each group has two wave records corresponding to each of the two different cylinder s diameters d the calibrated wave properties reported by robertson et al 2015 are in good agreement with the results obtained in this study as the average percentage of error is 3 and 0 2 for h s and t p respectively as shown in table 2 the wave surface elevation ƞ and the total wave force measured f exp for each test considered in this study are shown in fig 3 the plots on the left hand side are for tests 17 and 18 group a and the plots on the right hand side are for tests 19 and 20 group b the wave elevation records of both tests in each group are identical however the total wave force for each of the two tests differs from each other since the diameters d are not equal the water particle velocity u and acceleration a are numerically simulated in the frequency domain as given in eqs 7 and 8 the cylinder depth was divided into 10 elements and the kinematics were calculated at each element then the total kinematics were derived and used to evaluate the total wave force in fig 4 the total water particle velocity s u and acceleration spectrum s a for group a and b are shown plots a and b are the velocity and acceleration spectrum for tests 17 and 18 respectively while plots c and d are for tests 19 and 20 since the wave elevation in each group is identical for both tests by consequence the water particle velocity and acceleration are identical as well as shown in the figure since some of the calibration methods mentioned in section 3 are relevant to the time domain it had been necessary to generate 1710s water kinematics time series numerically using the same phase angles of the wave elevation records that consist of 75000 data points with a time step of 0 02s the validation of the kinematics obtained by adopting the linear random wave theory is limited to the wave elevation since the experimental records are available only for the elevation and the wave force afterwards the estimated water kinematics u a in conjunction with the measured total wave force for each test are used to calibrate the drag c d and inertia coefficients c m used in morison s equation four methods are used in this study to estimate these coefficients namely the least squares fit to the force time series lstd the least squares fit to the force spectrum lsfs the conventional method of moments and the lower method of moments each method has been applied simultaneously on the four tests and the results are summarized in table 3 and fig 5 regarding the least squares based approaches the c d in all the tests are adjusted to 1 since the values obtained are too small and not realistic due to the predominance of the inertia components which plays an important role in the c d results and this agree well with dean 1976 moreover the behavior of the c d obtained by the least squares based approach cannot be determinately judged due to the possibility of 1 uncertainties in the experiments or 2 a small phase shift between the kinematics and the force or 3 the inconvenience of using this calibration method under certain circumstances however regardless the least squares based methods the conventional method of moments always gives a lower c d values than the lower method of moments in all the tests this invariable behavior gives to some extent strength for using the moments based approaches under certain circumstances which shows agreement with previous studies adopting the conventional method of moments in tests 17 and 18 results in 24 3 and 39 1 lower c d respectively when compared to the results obtained by the lower method of moments while using the conventional method of moments results in a 25 1 and 31 9 lower c d than the lower method of moments in tests 19 and 20 respectively regarding c m the lstd delivers 7 94 on average lower c m in all the tests than those obtained by lsfs while the conventional method delivers 4 65 on average higher c m than those obtained from the lower method of moments the exact percentage of deviation between the coefficients values resulting by incorporating the four different methods are summarized in fig 5 as shown in fig 5 the deviation between the c m values for each individual test is relatively small table 4 shows the force kurtosis β f which is considered as a measure of the importance of the nonlinear drag component in morison s wave loading all β f values approach 3 0 which means the loading is strongly inertia dominated furthermore the drag coefficients could be set to 1 in all least squares basis approaches as shown before in table 3 and only the inertia coefficient is investigated nevertheless the foregoing calculations will not be affected thereafter the drag and inertia coefficient estimated are used to calculate the total wave force acting on the fixed vertical cylinder using morison s equation moreover the effect of increasing the cylinder s diameter under the same sea state condition is also examined it was found that increasing the diameter by 38 in group a and adopting the conventional method and the lower method of moments results in 34 3 and 47 1 higher c d respectively whereas results in 3 4 and 6 7 lower c m respectively regarding group b increasing the diameter and adopting the same two approaches results in 36 3 and 42 higher c d while results in lowering the c m values by 2 1 and 4 3 respectively these results enhance on the importance of the viscous drag effect while the diameter increases fig 6 summarizes a comparison between the experimental wave force record and morison s wave force investigated by using the coefficients obtained using the aforementioned approaches the figure shows a sample of 15 s of comparison between the predicted and the experimental wave force despite the large deviation in the c d value reaching 39 1 in test 18 as shown in fig 5 the results in time domain agree well with the experiments except some minor deviations in the peaks and troughs values that could be due to adopting the linear random wave theory formulation in estimating the kinematics the variation on the drag and inertia coefficients along the time series is examined by incorporating the least squares fit to the force time domain lstd in the wave by wave basis this approach is based on breaking up the wave record into a number of individual waves based on the zero crossing periods t z and estimating the c d and c m for each individual wave fig 7 shows a set of plots composed from the c d and c m variability with the time and a comparison between the predicted and the experimental wave force since c d values exhibits a high degree of scattering due to the dominance of inertia components and the results was not realistic due to the reasons mentioned before so the c d for all waves is set to 1 as shown in plot a nevertheless the simulated wave force in plot c shows a good agreement with the experiments table 5 shows the mean μ and standard deviation σ of the inertia coefficient obtained for each test under consideration adopting the lstd in predicting the c m under the wave by wave basis results in a mean value 1 5 1 1 0 and 0 5 lower than the constant value obtained in table 3 for tests 17 18 19 and 20 respectively fig 8 and fig 9 show a comparison between the power spectrum density s f of the estimated wave force by using the coefficients in table 3 and the experimental force for tests 17 and 19 respectively in test 17 the lower method of moments delivers maximum power at 0 4 hz among the predicted results however this power is 2 4 lower than the maximum power delivered by the experiments at 0 43 hz whereas in test 19 the conventional method of moments delivers 0 3 lower power value than the one obtained from the experiments on the other hand the wave by wave method results in 10 6 and 12 4 lower power value than the experiments in test 17 and 19 respectively the small deviation in the natural frequency between the experiments and the simulations in both tests could be due to some uncertainties as mentioned before in the context moreover the time series was divided into a number of short signals with 20s length to explore the probability of exceedance of the extreme values on each test fig 10 presents a comparison between the probability of exceedance of the predicted extreme wave force and the experimental force the figure is composed of 4 plots which represent the four irregular wave tests regarding group a the extreme values predicted by all the foregoing approaches converge with the experimental results in probability level between 0 5 and 1 whereas the difference start to be notable below 0 5 regarding group b deviation is notable in the probability level below 0 65 between the predicted and experimental values eventually the extreme values obtained by the wave by wave method agree well with the experiments in all the range in both groups despite the deviation in the power obtained by this method 5 conclusion this work investigates the impact of some calibration approaches used for the prediction of morison s force coefficients for fixed vertical cylinder these approaches are applied to four irregular wave tests which are classified into two groups where two diameters are considered in each the constant coefficients are estimated by adopting lstd lsfs conventional method of moments and lower method of moments the coefficients variability on the foregoing tests is examined by implementing lstd under wbw approach the reflection on the total force is discussed through comparing a the predicated and experimental forces in the time domain b the frequency spectra of predicted and experimental forces and c probability distributions of the extreme values of the predicted and experimental forces in all tests the fluctuation on constant drag coefficient is remarkable compared to the inertia coefficient nevertheless this high fluctuation doesn t affect the prediction of the wave force due to the predominance of the inertia component moreover the c d is assumed to be 1 in case of the least squares based approaches and the results show a good agreement with the experiments the results of this study agree well with zaki et al 2016 since the inertia dominated wave force with kurtosis 3 5 is well predicted by applying the conventional method of moments however including the coefficient s variability is still more efficient as shown by isaacson et al 1991 as it gives the most accurate results for the probability of exceedance for the extreme force values however the least squares fit to the force spectrum lsfs give results almost identical to the obtained by adopting the moments based approaches which give strength to this method the deviation obtained in the results when applying the lstd approaches is due to the probability of a phase shift presence between the kinematics and the force signal in summary this work emphasizes the inaccurate results of the c d due the presence of the vertical cylinder in high inertia regime in the experiments incorporating the variability of coefficients using wbw approach gives the minimum deviation between the experimental and the predicted wave extreme values eventually using either the moments based approaches or the lsfs methods doesn t have a remarkable effect on the final results acknowledgements this work was performed within the scope of the strategic research plan of the centre for marine technology and ocean engineering centec which is financed by the portuguese foundation for science and technology fundação para a ciência e tecnologia fct 
