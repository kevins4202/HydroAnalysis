index,text
23025,this study proposed and applied a three dimensional 3 d numerical model based on existing 1 d and 2 d numerical models to investigate residual soil response in a homogeneous sandy seabed with a rocking mono pile subjected to a cyclic lateral load and waves the wave motion is governed by the reynolds averaged navier stokes rans equations compared to previous studies in the literature this research analyzed the pore pressure accumulation due to wave pile seabed interaction considering the pile rocking effect the proposed 3 d model is validated against existing experimental and numerical data subsequently the 3 d model is used to investigate the residual response of a seabed with a mono pile in which pile rocking caused by a lateral cyclic load is considered the results indicate that the existence of a rocking mono pile greatly affects the residual response of the seabed due to pile seabed interaction the rate of residual pore pressure buildup was significantly faster near the mono pile surface due to the impermeable interface and stiffness difference of the pile and seabed soil in addition the effect of pile rocking leads to the variation in shear stress in various parts of the seabed resulting in different residual pore pressure variations at various positions around the mono pile keywords residual pore pressure mono pile foundation pile seabed interaction pile rocking effect 1 introduction biot s consolidation equations are based on the assumption of an elastic body when adopted to describe the motion of pore fluid in a porous seabed where the response of the seabed changes according to the variation in external load lin et al 2016 in such seabed soil deformation and pore pressure can return to their initial states when external loading is removed liao et al 2018a b however many field and laboratory studies have shown that a component of seabed pore pressure accumulates over time in addition to the oscillatory pore pressure that is directly related to cyclic external loading this mechanism reflects the elastoplastic soil behavior of marine sediments and is important in the assessment of seabed pore pressure accumulation and effective stress reduction in the vicinity of marine structures subjected to external loads many studies have been conducted in recent years on the problem of pore pressure accumulation for example experimental results have shown that residual pore pressure and residual liquefaction can be caused by wave loads sumer 2014 tzang 1998 sumer et al 1999 2012 proposed three major measures of pore pressure accumulation the cyclic shear stress ratio the cyclic load period and the number of cycles to residual liquefaction seed and rahman 1978 set up a 1 d model to analyze pore pressure accumulation under propagating waves and the liquefaction caused by earthquake effects in a later study this model was extended to analyze residual responses in seabed soil under wave loading by analytical and numerical methods mcdougal et al 1989 obtained an analytical solution for the residual pore pressure in seabed soil caused by a series of waves cheng et al 2001 re examined and revised the analytical solution proposed by mcdougal et al 1989 their results showed that large errors in the simulation of residual pore pressure may occur with relatively small errors in shear stress sumer and fredsøe 2002 proposed an analytical solution for residual pore pressure using the fourier transform method and analyzed pore pressure accumulation based on biot s consolidation equations jeng et al 2007 proposed approximate analytical and numerical solutions to estimate residual pore pressure response in seabed which provided more accurate prediction than previous studies it is worth noting that the models proposed by sumer and fredsøe 2002 and jeng et al 2007 stem from the same principle although the two models have different forms in practical application with the development of residual pore pressure models studies on residual pore pressure response around marine structures are carried out jeng et al 2013 ye et al 2013a b and liao et al 2018a b developed a series of numerical models to study the seabed response around breakwater considering the porous flow inside the rubble however omitting the residual seabed response then zhao and jeng 2015 and zhao et al 2016 integrated the formulation of jeng and zhao 2015 to study the residual response around breakwater trunk besides li and jeng 2008 presented a 3 d analytical solution considering both oscillatory and residual mechanisms of pore pressure to analyze the seabed response around a breakwater head in more recent research jeng and ou 2010 adopted a more complex elasto plastic model of soil to analyze dynamic seabed and residual liquefaction responses in the vicinity of a breakwater recently elsafti and oumeraci 2016 developed a hydro geotechnical model and studied the residual seabed response around a gravity structure which could reflect the plastic soil behavior such as cyclic mobility in the recent years many efforts are devoted to study the wave induced seabed response around the mono pile foundation as it is widely used to support the offshore wind turbine negro et al 2017 li et al 2011 firstly explored the residual pore pressure buildup around a rigid impermeable mono pile with second order stokes wave applied on the seabed surface which neglected the wave pile interaction to include the effect of wave pile interaction sui et al 2016 adopted the fully non linear boussinesq equations to simulate the wave pile interaction and found that the existence of the mono pile presents significant effect on wave motion and pore pressure response in this study the wave model and seabed model are built separately in different codes to simplify the simulation lin et al 2017 incorporated the navier stokes equations and biot s consolidation equation in openfoam to examine the transient seabed response subjected to wave loading in the above studies the soil behavior is assumed to be elastic zhu et al 2018 then introduced a kinematic hardening constitutive model to simulate the cyclic mobility and pore pressure accumulation of the seabed beside the numerical studies cuéllar et al 2012b performed a physical test to explore the seabed densification around a monopile under lateral cyclic loading recently zhao et al 2017 employed the formulation of sassa et al 2001 to numerically study the oscillatory and residual seabed response around a monopile foundation however all the aforementioned studies except those by cuéllar et al 2012a 2012b are focus on non rocking mono pile structure which cannot reflect the influence of pile rocking effect on the pore pressure response the purpose of this study is to investigate the residual response of a sandy seabed soil around an embedded mono pile using extended 3 d model which can consider pile rocking effect the advantage of the proposed model is its simplicity and efficiency in the pore pressure accumulation calculation when treating the pile seabed interaction the wave motion is modeled by rans equations within the framework of the finite difference method the seabed is treated as an isotropic medium governed by biot s equations and the mono pile is solved based on elastic theory implemented in a finite element method program the proposed 3 d model is validated against available experimental data and numerical results under various loading finally the new 3 d model is applied to analyze residual pore pressure in 3 d seabed models with 1 a non rocking mono pile and 2 a rocking mono pile 2 description of the proposed 3 d numerical model for residual pore pressure in this section the proposed 3 d numerical model for residual pore pressure simulation is described in detail and compared with existing 1 d and 2 d numerical models 2 1 existing 1 d numerical model for the problem of wave seabed interaction biot s consolidation model is applied to simulate the elastic response of seabed soil the seabed pore pressure response to waves is composed of two main parts and can be expressed as 1 p p e p s where p is the total pore water pressure p e is the oscillatory excess pore pressure and p s is the average residual excess pore pressure over one wave period which can be defined as 2 p s 1 t t t t p d t where t is the wave period and t is the time the 1 d numerical model for residual pore pressure can be described as 3 p s t c v 2 p s z 2 f where c v is the coefficient of consolidation which can be defined as 4 c v g k γ 2 2 μ 1 2 μ 2 2 μ n g k in which g is the shear modulus of soil k is the soil permeability γ is the unit weight of water μ is the poisson s ratio of soil n is the soil porosity k 1 β k is the bulk modulus of pore fluid and β is the compressibility of pore fluid the source term of the 1 d numerical model can be expressed as 5 f u g t σ 0 t τ max α r σ 0 1 β r where u g denotes the generation of pore pressure τ max is the amplitude of the shear stress during simulation σ 0 represents the initial effective stress and the coefficients α r and β r are obtained according to the relative density of seabed soil sumer et al 2012 which can be described as 6 α r 0 34 d r 0 084 β r 0 37 d r 0 46 where d r is the relative density of the seabed soil which can be expressed as 7 d r e max e e max e min in which e is the void ratio e max is the maximum void ratio and e min is the minimum void ratio in order to solve eq 3 of the 1 d model the boundary conditions of the simulation should be set as follows 8 p s z 0 p s 0 t 0 9 p s h t z 0 or p s t 0 2 2 existing 2 d numerical model jeng and zhao 2015 extended the aforementioned 1 d model into a 2 d form and proposed a model for residual pore pressure in a 2 d situation which can be expressed as 10 p s t c v 2 p s x 2 2 p s z 2 f x z t where c v is the coefficient of consolidation in plane strain condition which can be defined as 11 c v g k γ w 1 2 μ for the 2 d numerical model the source term of residual pore pressure can be defined as 12 f x z t u g t σ o t τ i n s x z t α r σ o 1 β r where τ i n s x z t is the instantaneous shear stress in the calculation compared to the 1 d model the amplitude of shear stress in the source term is replaced with the instantaneous shear stress which reflects the effect of oscillatory shear stress on residual pore pressure within one wave period the results show that the modified 2 d model is more accurate and reflects the trend of residual pore pressure development more realistically than a 1 d model or a 2 d model based on maximum shear stress for the boundary conditions of residual pore pressure calculation the residual pore pressure p s should be defined on the top and bottom of the considered soil layer of the seabed with thickness h which can be expressed as 13 p s 0 at z 0 14 p s z 0 at z h in addition the lateral boundary conditions should have zero flux 2 3 the proposed 3 d numerical model this paper extends the previous 1 d and 2 d numerical models of residual pore pressure to a 3 d form and applies it to the current pile seabed model in order to analyze the residual pore pressure in the seabed soil around a mono pile subjected to wave loads the governing equation can be expressed as 15 p s t c v 2 p s x 2 2 p s y 2 2 p s z 2 f x y z t where c v is the coefficient of consolidation which can be defined as 16 c v g k γ w 2 1 μ 1 2 μ 2 1 μ n g k the source term of residual pore pressure in the 3 d model has a form similar to that of the 2 d case which can be expressed as f x y z t σ o t τ i n s x z t α r σ o 1 β r where τ i n s x z t is the instantaneous shear stress t is the wave period the coefficients α r and β r are determined by equation 6 and σ 0 is the initial effective stress which is expressed as 17 σ 0 1 2 k 0 3 γ z the proposed 3 d model is a model for the development of residual pore pressure in which the source term for residual pore pressure is mainly influenced by the instantaneous oscillatory shear stress that varies with time compared with the maximum model based on maximum shear stress the effect of external cyclic loads on the seabed can be fully considered in the proposed model which can better ensure the simultaneous generation of oscillatory and residual pore pressures for the boundary conditions of residual pore pressure calculation the residual pore pressure p s should be restricted on the seabed top and bottom which can be expressed as 18 p s 0 at z 0 19 p s z 0 at z h 3 theoretical methods and simulation conditions in order to illustrate the wave seabed monopile model more clearly the integrated model is sketched in fig 1 in addition the flowchart of the computational procedure of the integrated model is given in fig 2 the wave sub model set up in flow 3d and the seabed sub model with the mono pile established in comsol multiphysics are one way coupled at the seabed surface the oscillatory pore pressure response and some other results of seabed are obtained at step one in the simulation then the residual pore pressure response in seabed is iteratively solved by proposed residual model based on the mechanical response of seabed in this section the governing equations and boundary conditions of both the wave and seabed models adopted in the simulation are discussed in detail 3 1 wave model based on mass and momentum conservation equations rans equations are adopted to describe the motion of incompressible viscous fluid the governing equations can be expressed as 20 u f i x i 0 21 ρ f u f i t ρ f u f i u f j x j p f x i x j μ u f i x j u f j x i x j ρ f u f i u f j ρ f g i where x i is the cartesian coordinate ρ f is the fluid density u fi is the ensemble mean velocity p f is the fluid pressure μ is the dynamic viscosity t is the time and g i is the gravitational acceleration the reynolds stress term ρ f u fi u fj is modeled by the sophisticated 2 equation κ ε turbulence model launder and spalding 1974 and then the reynolds stress term can be estimated by 22 ρ f u f i u f j μ t u f i x j u f j x i 2 3 ρ f δ i j κ where μ t is the turbulence viscosity κ is the turbulence kinetic energy and δ ij is the kronecker delta based on eq 22 eq 21 can be rewritten as 23 ρ f u f i t ρ f u f i u f j x j x i ρ f 2 3 ρ f κ x j μ e f f u f i x j u f j x i ρ f g i in which μ eff μ μ t is the total effective viscosity 3 2 seabed model 3 2 1 governing equations according to previous research into seabed responses to wave pressure biot s quasi static qs model is suitable and accurate enough to simulate most seabed soil of low permeability under low frequency wave loading jeng and cha 2003 considering the wave and seabed parameters used in this research biot s qs model is adopted as the governing equation for the investigation of wave induced pore pressure in a porous seabed as it provides high simulation efficiency in this study the porous seabed is considered to be isotropic and homogenous with the same permeability k in all directions and the seepage in seabed follows the darcy s law the conservation of mass is expressed as 24 k 2 p e γ w n β p e t γ w ε s t where 2 2 x 2 2 y 2 2 z 2 is the laplace operator p e is the wave induced oscillatory pore water pressure in the seabed γ w is the unit weight of pore water n is the soil porosity and k is the soil permeability the volumetric strain of the soil matrix ε s and the compressibility of pore fluid β are defined as follows 25 ε s u s x v s y w s z 26 β 1 k 1 k w 1 s r p w 0 where u s v s and w s are the seabed soil displacements in the x y and z directions respectively k w is the true modulus of elasticity of pore water taken as 2 109 pa p w0 is absolute water pressure and s r is the seabed s degree of saturation 27 g s 2 u s g s 1 2 μ s ε s x p e x 28 g s 2 v s g s 1 2 μ s ε s y p e y 29 g s 2 w s g s 1 2 μ s ε s z p e z 3 2 2 boundary conditions appropriate boundary conditions are required to solve eqs 24 and 27 29 which govern the porous seabed response some of which are also displayed in fig 1 at the seabed surface the wave induced pore water pressure p is set to be equal to the dynamic wave pressure p w at the mudline which is obtained from the wave sub model and the vertical effective normal stresses and shear stresses are considered to be 0 30 σ z τ z x τ z y 0 p e p w at z 0 at the bottom of the seabed an impermeable rigid boundary condition is applied where the seabed displacement is zero and no vertical flow occurs 31 u s v s w s p e z 0 at z h the four lateral sides of the seabed model are considered to be impermeable as wall which means that there is zero seabed displacement and no flow occurs in the x direction at the left and right sides and in the y direction at the front and back sides 32 u p e x 0 at x 0 and x w 33 v p e y 0 at y 0 and y b where w and b are the length and width of the seabed sub model respectively 3 3 mono pile simulation 3 3 1 governing equations in order to simulate the displacement of the mono pile and its interaction with the seabed under dynamic wave loading more realistically the mono pile is adopted is considered to be an elastic body solved by finite element method instead of a rigid body since pore water pressure is not a considered factor inside the mono pile a modified biot s qs model based on elastic theory while neglecting the effect of pore water pressure is adopted to describe the motion of the mono pile which can be defined as 34 g p 2 u p g p 1 2 μ p ε p x 0 35 g p 2 v p g p 1 2 μ p ε p y 0 36 g p 2 w p g p 1 2 μ p ε p z 0 where u p v p and w p are the displacements of the mono pile in the x y and z directions respectively ε p u p x v p y w p z is the volume strain of the mono pile g p is the shear modulus and μ p is the poisson s ratio of the pile material 3 3 2 boundary conditions rocking motion of the mono pile is realized by imposing horizontal cyclic movement on the pile head applied as a displacement defined dirichlet boundary condition on the top surface of the mono pile the pile displacement used in the numerical model is expressed as follows 37 x p x p sin ω t where x p is the amplitude of the cyclic horizontal displacement of the pile head t denotes time and ω is the angular frequency of cyclic motion the interface between the mono pile and porous seabed is considered to be no slip and impermeable to study the coupled interaction effect this implies that the displacement of seabed soil at the mono pile interface is identical to the displacement of the mono pile which can be expressed as 38 u s u p v s v p and w s w p 39 p e n 0 where n is the normal vector to the interface 4 validation of the 3 d model in this section the proposed 3 d numerical model for residual pore pressure is validated against laboratory results and an existing numerical model in addition the response of residual pore pressure to the pile rocking effect is validated to ensure the accuracy of the new 3 d model in simulating residual pore pressure 4 1 results of pore pressure accumulation in the seabed without mono pile firstly the results of the proposed 3 d model are compared with the experimental data and 1 d numerical model presented in sumer et al 2012 the input data for the seabed and wave characteristics are listed in table 1 the model experiment was conducted by sumer et al 2012 in a wave flume that was 0 6 m wide and 26 5 m long the size of the soil pit in the experiment was 0 4 m 0 6 m 0 78 m and pore water pressure was measured at five different locations in the vertical direction of the soil pit comparisons of the numerical residual pore pressure model and the laboratory experiment results are shown in fig 3 variable p denotes the pore water pressure measured in the experiment of sumer et al 2012 and p s denotes the 1 d and 3 d numerical model results for residual pore pressure the peak values of p and p s have a relatively large difference fig 3 a shows the time series of residual pore pressure at a height of z 8 5 cm and fig 3 b shows it at a height of z 24 cm the relationship between residual pore pressure and mean pore pressure is also shown for the case of z 8 5 cm the mean pore pressures estimated by numerical simulation are in relatively good agreement with the laboratory experiment and the general trend in pore pressure is consistent for the height of z 24 cm the results of the 3 d numerical model and experimental data differ before t 10 s but become consistent afterwards in addition the 3 d modeled data are slightly lower than the test data while those of the 1 d numerical model are clearly larger this is because the 3 d model is calculated based on instantaneous shear stress rather than maximum shear stress which leads to a larger response of pore water pressure similar results for various numerical models have also been illustrated in jeng and zhao 2015 for the 1 d and 2 d model in which the residual response of 1 d and 2 d maximum model is larger than that of 2 d instant model as well therefore it can be seen that the residual response based on instantaneous shear stress is relatively more accurate than that of maximum shear stress in simulation by the comparisons above 4 2 results of pore pressure accumulation in a seabed with rocking mono pile it is worth noting that the validation of oscillatory response for the seabed under wave load with rocking and non rocking pile has been illustrated in zhang et al 2018 which shows the ability to simulate wave pile interaction accurately moreover the response of residual pore pressure in the seabed soil around a rocking mono pile is validated in this study as laboratory studies on the residual pore pressure of seabed soil with a mono pile are scarce currently the residual pore pressure of the 3 d model is compared with the pore pressure results while considering the pile rocking effect presented in cuéllar et al 2012a the numerical model focuses on the response of pore pressure accumulation under cyclic lateral loading without wave pressure acting on the seabed surface the simulation parameters adopted for validation are listed in table 2 fig 4 presents a comparison of pore pressure accumulation in the two 3 d numerical models under pile rocking in which pore water pressure p denotes the sum of both oscillatory pore pressure p e and residual pore pressure p s fig 4 a d show the time series of the pore pressure response at depths of 3 m 4 3 m 5 1 m and 7 m below the seabed surface respectively the horizontal distance from the mono pile surface is 0 5 m the solid line in fig 4 represents the results of the proposed 3 d model and the dash line represents the numerical results presented in cuéllar et al 2012a fig 4 clearly shows the periodic characteristic of oscillatory pore pressure and the increase of residual pore pressure with time the pore pressure variation of the two models has good consistency generally but differs at the maximum or minimum value as can be seen in fig 4 the main reason for this may be the different treatment of the pile seabed interface in two numerical models the results show good agreement in general which means the proposed 3 d model can accurately simulate the residual pore pressure response of a seabed with a mono pile based on the validation of the seabed residual pore pressure response considering a pile rocking effect the results of the proposed 3 d numerical model are considered acceptable and sufficient for analysis 5 application of the new 3 d model for residual pore pressure analysis in this section the proposed 3 d integrated model is used to simulate the pore pressure response of the seabed without mono pile with a non rocking mono pile and with a rocking mono pile in terms of seabed shear stress and variation of the residual pore pressure at different positions the total calculation time is 15t t is the wave period and the other input parameters are shown in table 3 5 1 analysis of the residual pore pressure in the seabed without mono pile fig 5 illustrates a contour plot of the residual pore pressure distribution in the seabed at t t 15 it can be seen that the maximum residual pore pressure appears at the front part of the seabed due to the effects of boundary conditions and residual pore pressure development with time in addition the residual pore pressure response is more obvious in the range of z 2 m to 17 m while it is less intense at the top and bottom of the seabed soil fig 6 shows the vertical distribution of residual pore pressure at the front position x 12 m and middle position x 50 m of the seabed at t t 15 in fig 5 the maximum residual pore pressure for both positions appears at z 7 m the maximum value at x 12 m is about 3 kpa and it is about 2 2 kpa at x 50 m the variations in the vertical distributions of the two positions are similar and the value of residual pore pressure decreases to less than 0 5 kpa at the seabed bottom fig 7 shows the development of residual pore pressure at position x 12 m z 7 m where the maximum pore pressure occurs the solid line in fig 7 denotes pore water pressure including that generated by both oscillatory and residual mechanisms and the dash line denotes residual pore pressure the value of pore water pressure is about 7 5 kpa at t t 15 and the residual pore pressure is around 3 kpa at this time it can be seen that the value of pore water pressure increases continuously with time due to the residual mechanism of pore pressure generation fig 8 presents the time series of residual pore pressure at seabed position x 12 m z 7 m the pore pressure value corresponds to the solid line in fig 6 the residual pore pressure increases quickly within the first few wave periods after which the increase becomes relatively slow after t t 7 and then gradually becomes stable in addition the variation in residual pore pressure presents an obvious oscillatory feature with a small amplitude which is caused by the periodic variation of instantaneous shear stress in the source term of the proposed 3 d model 5 2 analysis of the residual pore pressure in the seabed with non rocking mono pile in this section based on the 3 d seabed analysis the residual pore pressure response of the seabed with mono pile is explored in order to analyze the pore pressure response around the mono pile comprehensively four different positions at its waveward and lee sides were defined the input parameters for the waves seabed and mono pile are listed in table 3 the proposed 3 d model of residual pore pressure is directly related to the shear stress of the seabed soil fig 9 illustrates a contour plot of shear stress τ xz around the mono pile at three different times t 34 5 s 36 s 37 5 s corresponding to the moments when the wave crest wave midpoint and wave trough arrive at the centerline of the mono pile respectively the vertical displacement of the seabed soil and the slight horizontal deformation of the mono pile are also shown in fig 9 in order to illustrate the general trend of the soil monopile motion and there is a significant phase difference between the variations in shear stress and upper wave pressure subjected to the effect of wave crests and troughs the values of shear stress in fig 9 a and c are opposite while the distributions of stress are similar the maximum shear stress appears at the four angular points of the mono pile due to shear stress concentration caused by the obvious difference in the stiffness of the pile and soil in fig 9 b the maximum shear stress around the mono pile is smaller than that under the effect of wave crest and trough and the maximum shear stress appears at the waveward side of the mono pile in the upper seabed fig 10 shows a time series of pore water pressure accumulation at four different positions in the vicinity of the mono pile fig 10 a d show the results for positions x 46 m x 47 5 m and x 48 5 m at the waveward side of the pile and x 52 m at the back side respectively in which the distances from the pile surface r are 3 m r 1 5 d 1 5 m r 0 75 d 0 5 m r 0 25 d and 1 m r 0 5 d according to the different positions shown in fig 10 a d pore pressure accumulation begins after 0 5 1 t when the wave arrives in general the rate of pore pressure accumulation in fig 10 c and d is faster than that in fig 10 a and b the value of pore water pressure is largest in fig 10 c at the position closest to the pile surface in addition irregular fluctuation occurs at the point of minimum pore pressure in fig 10 b d this fluctuation is most obvious in fig 10 c and is very slight in fig 10 a the main reason for it is the varying wave pressure distribution caused by pile wave interaction the pile wave interaction may result in nonlinear effect such as wave reflection and cause irregular influences on the seabed around the mono pile moreover the fluctuation effect weakens gradually with increasing distance from the mono pile surface fig 11 shows a time series of residual pore pressure at position x 46 m z 0 5 m the rate of residual pore pressure increase is rapid before t t 2 and then becomes slower with time compared with fig 8 above the residual pore pressure in fig 11 is affected by the pile wave seabed interaction more significantly which results in the irregular fluctuation and nonlinear effect fig 12 presents a vertical distribution of residual pore pressure at four different positions around mono pile at t t 15 the pore pressure distributions are generally similar and pore pressure increases with decreasing distance from the pile surface due to the pile seabed soil interaction the increasing rate of residual pore pressure is the largest in fig 12 c and the maximum value appears at z 0 5 m because of the impermeable nature of the mono pile seabed interface at the position near the pile surface the dissipation of residual pore pressure is relatively slow in addition a shear stress concentration occurs near the pile seabed interface due to the obvious stiffness difference between the pile and the soil in fig 12 b and d the vertical distributions of residual pore pressure are very similar and the maximum value appears at the height of z 1 5 m in fig 12 a the influence of the pile soil interface is relatively low due to the long distance from the pile surface and the maximum value occurs at z 4 m 5 3 analysis of the residual pore pressure in the seabed with rocking mono pile this section focuses on the response of residual pore pressure in the seabed soil around the rocking mono pile this section investigates the residual pore pressure response of the seabed with a rocking mono pile fig 13 shows a contour plot of shear stress τ xz around the mono pile at three different times t 34 5 s 36 s 37 5 s in the rocking pile model in the seabed due to the joint influence of wave crests wave troughs and pile rocking the distribution of shear stress is antisymmetric in fig 13 a and c compared to the seabed with non rocking mono pile in section 5 2 the value of maximum shear stress is higher and the shear stress distribution around the pile is asymmetric due to the larger horizontal displacement of the mono pile in fig 13 b the value of shear stress around the mono pile is smaller than when wave crests and troughs are considered and the distribution of shear stress is similar to that in the seabed with non rocking mono pile at this moment fig 14 illustrates a time series of pore pressure accumulation at four positions around the mono pile in the rocking pile model fig 14 a d show the results for positions x 46 m x 47 5 m x 48 5 m at waveward side of the mono pile and x 52 m back side respectively due to the different distance from the mono pile the effect of pile rocking is relatively low and the pore pressure trend is similar to that in the seabed with non rocking mono pile while the pore pressure value is larger in addition large residual pore pressure occurs in fig 14 b and c due to the pile seabed interaction caused by forward pile displacement at the beginning of simulation while obvious dissipation occurs in both cases at t t 2 in fig 14 d the case at the back side of the mono pile there is no apparent pore pressure increase at first while the residual pore pressure increases quickly and is obviously larger than that in fig 14 c at t t 15 due to the joint effect of wave loads and pile rocking the reason for the difference between fig 14 c and d is that increased or decreased oscillatory shear stress occurs in part of the seabed due to the joint effect of wave and pile rocking which have the same period eventually leading to a difference in residual pore pressure variation at different positions moreover it can be seen that the influence of nonlinear fluctuation caused by the wave pile seabed interaction weakens with increasing distance from the pile surface fig 15 shows a time series of residual pore pressure at position x 46 m z 0 5 m in the seabed with rocking mono pile the residual pore pressure increases quickly before t t 2 and then more slowly with time compared to the non rocking pile model the value of residual pore pressure generally increases to some extent due to the effect of pile rocking the nonlinear influence of pile wave seabed interaction on residual pore pressure is more significant fig 16 presents a vertical distribution of residual pore pressure at four positions at t t 15 in the seabed with rocking mono pile the distribution of residual pore pressure and the vertical position of maximum pore pressure are similar to the results obtained for the non rocking pile model in addition the value of residual pore pressure increases to a certain degree which is apparent in fig 16 d 6 conclusions in this study detailed research has been conducted to explore the response of residual pore pressure considering mono pile seabed interaction by analyzing existing 1 d and 2 d numerical models of residual pore pressure and based on elastic soil assumption and studies on the source of residual pore pressure generation an existing 2 d numerical model was extended to a 3 d model in addition the results of the proposed 3 d residual pore pressure model were compared to experimental data for a seabed without mono pile and a numerical model for the seabed with a rocking mono pile without waves moreover the residual pore pressure responses in the seabed without mono pile with a non rocking mono pile and a rocking mono pile were analyzed allowing the following conclusions to be made 1 the proposed 3 d residual pore pressure model is developed based on the constitutive model of elastic soil and instantaneous shear stress the validation has shown the ability of the proposed model to simulate the residual pore pressure response under wave pile interaction accurately for general 3 d problem with an acceptable accuracy 2 in the seabed without mono pile the value of residual pore pressure increased gradually with time for the vertical distribution of residual pore pressure the maximum values appeared at the middle and upper parts of the seabed due to the oscillatory nature of instantaneous shear stress the buildup of residual pore pressure shows a corresponding characteristic of small amplitude oscillation 3 for the seabed with non rocking mono pile the maximum shear stress in the seabed appeared in the vicinity of the mono pile due to the impermeable interface between pile and soil and their different stiffness shear stress was concentrated near the mono pile surface in addition there was a nonlinear effect on the seabed soil around the mono pile caused by pile seabed wave interaction which is due to the out of phase between water waves and rocking pile the residual pore pressure fluctuated irregularly when subjected to this effect which weakened with distance from pile surface 4 in the seabed with rocking mono pile the residual pore pressure was larger than that in non rocking pile model due to the pile displacement the response of residual pore pressure was intense at the side of the rocking pile at the beginning of simulation in addition increased or decreased oscillatory shear stress occurred in part of the seabed this was caused by the joint effect of waves and pile rocking motion with the same period leading to differences in residual pore pressure variation at different positions furthermore the research on residual response for 3 d problem is preliminary and tentative it can provide qualitative analysis for the mono pile foundations in ocean engineering and it needs further studies especially on the governing equations for residual pore pressure generation the purpose of this paper is to investigate the possible effect of pile rocking motion on the pore pressure response as is known there exist many soil constitutive models that can reflect the residual characteristics of pore pressure response under pile rocking loads as a first approximation this study used a simple but workable way to analyze the wave seabed pile interaction considering pile rocking effect the soil model in presented study has a simple form and clear physical meaning which could help us to understand the pile seabed interaction in a much concise way in the future more advanced soil constitutive model and pile soil contact model such as model of elsafti and oumeraci 2016 should be applied and can give a deeper insight into the mechanism of wave seabed pile interaction acknowledgements this research project is financially supported by the national natural science foundation of china grant no 41602282 
23025,this study proposed and applied a three dimensional 3 d numerical model based on existing 1 d and 2 d numerical models to investigate residual soil response in a homogeneous sandy seabed with a rocking mono pile subjected to a cyclic lateral load and waves the wave motion is governed by the reynolds averaged navier stokes rans equations compared to previous studies in the literature this research analyzed the pore pressure accumulation due to wave pile seabed interaction considering the pile rocking effect the proposed 3 d model is validated against existing experimental and numerical data subsequently the 3 d model is used to investigate the residual response of a seabed with a mono pile in which pile rocking caused by a lateral cyclic load is considered the results indicate that the existence of a rocking mono pile greatly affects the residual response of the seabed due to pile seabed interaction the rate of residual pore pressure buildup was significantly faster near the mono pile surface due to the impermeable interface and stiffness difference of the pile and seabed soil in addition the effect of pile rocking leads to the variation in shear stress in various parts of the seabed resulting in different residual pore pressure variations at various positions around the mono pile keywords residual pore pressure mono pile foundation pile seabed interaction pile rocking effect 1 introduction biot s consolidation equations are based on the assumption of an elastic body when adopted to describe the motion of pore fluid in a porous seabed where the response of the seabed changes according to the variation in external load lin et al 2016 in such seabed soil deformation and pore pressure can return to their initial states when external loading is removed liao et al 2018a b however many field and laboratory studies have shown that a component of seabed pore pressure accumulates over time in addition to the oscillatory pore pressure that is directly related to cyclic external loading this mechanism reflects the elastoplastic soil behavior of marine sediments and is important in the assessment of seabed pore pressure accumulation and effective stress reduction in the vicinity of marine structures subjected to external loads many studies have been conducted in recent years on the problem of pore pressure accumulation for example experimental results have shown that residual pore pressure and residual liquefaction can be caused by wave loads sumer 2014 tzang 1998 sumer et al 1999 2012 proposed three major measures of pore pressure accumulation the cyclic shear stress ratio the cyclic load period and the number of cycles to residual liquefaction seed and rahman 1978 set up a 1 d model to analyze pore pressure accumulation under propagating waves and the liquefaction caused by earthquake effects in a later study this model was extended to analyze residual responses in seabed soil under wave loading by analytical and numerical methods mcdougal et al 1989 obtained an analytical solution for the residual pore pressure in seabed soil caused by a series of waves cheng et al 2001 re examined and revised the analytical solution proposed by mcdougal et al 1989 their results showed that large errors in the simulation of residual pore pressure may occur with relatively small errors in shear stress sumer and fredsøe 2002 proposed an analytical solution for residual pore pressure using the fourier transform method and analyzed pore pressure accumulation based on biot s consolidation equations jeng et al 2007 proposed approximate analytical and numerical solutions to estimate residual pore pressure response in seabed which provided more accurate prediction than previous studies it is worth noting that the models proposed by sumer and fredsøe 2002 and jeng et al 2007 stem from the same principle although the two models have different forms in practical application with the development of residual pore pressure models studies on residual pore pressure response around marine structures are carried out jeng et al 2013 ye et al 2013a b and liao et al 2018a b developed a series of numerical models to study the seabed response around breakwater considering the porous flow inside the rubble however omitting the residual seabed response then zhao and jeng 2015 and zhao et al 2016 integrated the formulation of jeng and zhao 2015 to study the residual response around breakwater trunk besides li and jeng 2008 presented a 3 d analytical solution considering both oscillatory and residual mechanisms of pore pressure to analyze the seabed response around a breakwater head in more recent research jeng and ou 2010 adopted a more complex elasto plastic model of soil to analyze dynamic seabed and residual liquefaction responses in the vicinity of a breakwater recently elsafti and oumeraci 2016 developed a hydro geotechnical model and studied the residual seabed response around a gravity structure which could reflect the plastic soil behavior such as cyclic mobility in the recent years many efforts are devoted to study the wave induced seabed response around the mono pile foundation as it is widely used to support the offshore wind turbine negro et al 2017 li et al 2011 firstly explored the residual pore pressure buildup around a rigid impermeable mono pile with second order stokes wave applied on the seabed surface which neglected the wave pile interaction to include the effect of wave pile interaction sui et al 2016 adopted the fully non linear boussinesq equations to simulate the wave pile interaction and found that the existence of the mono pile presents significant effect on wave motion and pore pressure response in this study the wave model and seabed model are built separately in different codes to simplify the simulation lin et al 2017 incorporated the navier stokes equations and biot s consolidation equation in openfoam to examine the transient seabed response subjected to wave loading in the above studies the soil behavior is assumed to be elastic zhu et al 2018 then introduced a kinematic hardening constitutive model to simulate the cyclic mobility and pore pressure accumulation of the seabed beside the numerical studies cuéllar et al 2012b performed a physical test to explore the seabed densification around a monopile under lateral cyclic loading recently zhao et al 2017 employed the formulation of sassa et al 2001 to numerically study the oscillatory and residual seabed response around a monopile foundation however all the aforementioned studies except those by cuéllar et al 2012a 2012b are focus on non rocking mono pile structure which cannot reflect the influence of pile rocking effect on the pore pressure response the purpose of this study is to investigate the residual response of a sandy seabed soil around an embedded mono pile using extended 3 d model which can consider pile rocking effect the advantage of the proposed model is its simplicity and efficiency in the pore pressure accumulation calculation when treating the pile seabed interaction the wave motion is modeled by rans equations within the framework of the finite difference method the seabed is treated as an isotropic medium governed by biot s equations and the mono pile is solved based on elastic theory implemented in a finite element method program the proposed 3 d model is validated against available experimental data and numerical results under various loading finally the new 3 d model is applied to analyze residual pore pressure in 3 d seabed models with 1 a non rocking mono pile and 2 a rocking mono pile 2 description of the proposed 3 d numerical model for residual pore pressure in this section the proposed 3 d numerical model for residual pore pressure simulation is described in detail and compared with existing 1 d and 2 d numerical models 2 1 existing 1 d numerical model for the problem of wave seabed interaction biot s consolidation model is applied to simulate the elastic response of seabed soil the seabed pore pressure response to waves is composed of two main parts and can be expressed as 1 p p e p s where p is the total pore water pressure p e is the oscillatory excess pore pressure and p s is the average residual excess pore pressure over one wave period which can be defined as 2 p s 1 t t t t p d t where t is the wave period and t is the time the 1 d numerical model for residual pore pressure can be described as 3 p s t c v 2 p s z 2 f where c v is the coefficient of consolidation which can be defined as 4 c v g k γ 2 2 μ 1 2 μ 2 2 μ n g k in which g is the shear modulus of soil k is the soil permeability γ is the unit weight of water μ is the poisson s ratio of soil n is the soil porosity k 1 β k is the bulk modulus of pore fluid and β is the compressibility of pore fluid the source term of the 1 d numerical model can be expressed as 5 f u g t σ 0 t τ max α r σ 0 1 β r where u g denotes the generation of pore pressure τ max is the amplitude of the shear stress during simulation σ 0 represents the initial effective stress and the coefficients α r and β r are obtained according to the relative density of seabed soil sumer et al 2012 which can be described as 6 α r 0 34 d r 0 084 β r 0 37 d r 0 46 where d r is the relative density of the seabed soil which can be expressed as 7 d r e max e e max e min in which e is the void ratio e max is the maximum void ratio and e min is the minimum void ratio in order to solve eq 3 of the 1 d model the boundary conditions of the simulation should be set as follows 8 p s z 0 p s 0 t 0 9 p s h t z 0 or p s t 0 2 2 existing 2 d numerical model jeng and zhao 2015 extended the aforementioned 1 d model into a 2 d form and proposed a model for residual pore pressure in a 2 d situation which can be expressed as 10 p s t c v 2 p s x 2 2 p s z 2 f x z t where c v is the coefficient of consolidation in plane strain condition which can be defined as 11 c v g k γ w 1 2 μ for the 2 d numerical model the source term of residual pore pressure can be defined as 12 f x z t u g t σ o t τ i n s x z t α r σ o 1 β r where τ i n s x z t is the instantaneous shear stress in the calculation compared to the 1 d model the amplitude of shear stress in the source term is replaced with the instantaneous shear stress which reflects the effect of oscillatory shear stress on residual pore pressure within one wave period the results show that the modified 2 d model is more accurate and reflects the trend of residual pore pressure development more realistically than a 1 d model or a 2 d model based on maximum shear stress for the boundary conditions of residual pore pressure calculation the residual pore pressure p s should be defined on the top and bottom of the considered soil layer of the seabed with thickness h which can be expressed as 13 p s 0 at z 0 14 p s z 0 at z h in addition the lateral boundary conditions should have zero flux 2 3 the proposed 3 d numerical model this paper extends the previous 1 d and 2 d numerical models of residual pore pressure to a 3 d form and applies it to the current pile seabed model in order to analyze the residual pore pressure in the seabed soil around a mono pile subjected to wave loads the governing equation can be expressed as 15 p s t c v 2 p s x 2 2 p s y 2 2 p s z 2 f x y z t where c v is the coefficient of consolidation which can be defined as 16 c v g k γ w 2 1 μ 1 2 μ 2 1 μ n g k the source term of residual pore pressure in the 3 d model has a form similar to that of the 2 d case which can be expressed as f x y z t σ o t τ i n s x z t α r σ o 1 β r where τ i n s x z t is the instantaneous shear stress t is the wave period the coefficients α r and β r are determined by equation 6 and σ 0 is the initial effective stress which is expressed as 17 σ 0 1 2 k 0 3 γ z the proposed 3 d model is a model for the development of residual pore pressure in which the source term for residual pore pressure is mainly influenced by the instantaneous oscillatory shear stress that varies with time compared with the maximum model based on maximum shear stress the effect of external cyclic loads on the seabed can be fully considered in the proposed model which can better ensure the simultaneous generation of oscillatory and residual pore pressures for the boundary conditions of residual pore pressure calculation the residual pore pressure p s should be restricted on the seabed top and bottom which can be expressed as 18 p s 0 at z 0 19 p s z 0 at z h 3 theoretical methods and simulation conditions in order to illustrate the wave seabed monopile model more clearly the integrated model is sketched in fig 1 in addition the flowchart of the computational procedure of the integrated model is given in fig 2 the wave sub model set up in flow 3d and the seabed sub model with the mono pile established in comsol multiphysics are one way coupled at the seabed surface the oscillatory pore pressure response and some other results of seabed are obtained at step one in the simulation then the residual pore pressure response in seabed is iteratively solved by proposed residual model based on the mechanical response of seabed in this section the governing equations and boundary conditions of both the wave and seabed models adopted in the simulation are discussed in detail 3 1 wave model based on mass and momentum conservation equations rans equations are adopted to describe the motion of incompressible viscous fluid the governing equations can be expressed as 20 u f i x i 0 21 ρ f u f i t ρ f u f i u f j x j p f x i x j μ u f i x j u f j x i x j ρ f u f i u f j ρ f g i where x i is the cartesian coordinate ρ f is the fluid density u fi is the ensemble mean velocity p f is the fluid pressure μ is the dynamic viscosity t is the time and g i is the gravitational acceleration the reynolds stress term ρ f u fi u fj is modeled by the sophisticated 2 equation κ ε turbulence model launder and spalding 1974 and then the reynolds stress term can be estimated by 22 ρ f u f i u f j μ t u f i x j u f j x i 2 3 ρ f δ i j κ where μ t is the turbulence viscosity κ is the turbulence kinetic energy and δ ij is the kronecker delta based on eq 22 eq 21 can be rewritten as 23 ρ f u f i t ρ f u f i u f j x j x i ρ f 2 3 ρ f κ x j μ e f f u f i x j u f j x i ρ f g i in which μ eff μ μ t is the total effective viscosity 3 2 seabed model 3 2 1 governing equations according to previous research into seabed responses to wave pressure biot s quasi static qs model is suitable and accurate enough to simulate most seabed soil of low permeability under low frequency wave loading jeng and cha 2003 considering the wave and seabed parameters used in this research biot s qs model is adopted as the governing equation for the investigation of wave induced pore pressure in a porous seabed as it provides high simulation efficiency in this study the porous seabed is considered to be isotropic and homogenous with the same permeability k in all directions and the seepage in seabed follows the darcy s law the conservation of mass is expressed as 24 k 2 p e γ w n β p e t γ w ε s t where 2 2 x 2 2 y 2 2 z 2 is the laplace operator p e is the wave induced oscillatory pore water pressure in the seabed γ w is the unit weight of pore water n is the soil porosity and k is the soil permeability the volumetric strain of the soil matrix ε s and the compressibility of pore fluid β are defined as follows 25 ε s u s x v s y w s z 26 β 1 k 1 k w 1 s r p w 0 where u s v s and w s are the seabed soil displacements in the x y and z directions respectively k w is the true modulus of elasticity of pore water taken as 2 109 pa p w0 is absolute water pressure and s r is the seabed s degree of saturation 27 g s 2 u s g s 1 2 μ s ε s x p e x 28 g s 2 v s g s 1 2 μ s ε s y p e y 29 g s 2 w s g s 1 2 μ s ε s z p e z 3 2 2 boundary conditions appropriate boundary conditions are required to solve eqs 24 and 27 29 which govern the porous seabed response some of which are also displayed in fig 1 at the seabed surface the wave induced pore water pressure p is set to be equal to the dynamic wave pressure p w at the mudline which is obtained from the wave sub model and the vertical effective normal stresses and shear stresses are considered to be 0 30 σ z τ z x τ z y 0 p e p w at z 0 at the bottom of the seabed an impermeable rigid boundary condition is applied where the seabed displacement is zero and no vertical flow occurs 31 u s v s w s p e z 0 at z h the four lateral sides of the seabed model are considered to be impermeable as wall which means that there is zero seabed displacement and no flow occurs in the x direction at the left and right sides and in the y direction at the front and back sides 32 u p e x 0 at x 0 and x w 33 v p e y 0 at y 0 and y b where w and b are the length and width of the seabed sub model respectively 3 3 mono pile simulation 3 3 1 governing equations in order to simulate the displacement of the mono pile and its interaction with the seabed under dynamic wave loading more realistically the mono pile is adopted is considered to be an elastic body solved by finite element method instead of a rigid body since pore water pressure is not a considered factor inside the mono pile a modified biot s qs model based on elastic theory while neglecting the effect of pore water pressure is adopted to describe the motion of the mono pile which can be defined as 34 g p 2 u p g p 1 2 μ p ε p x 0 35 g p 2 v p g p 1 2 μ p ε p y 0 36 g p 2 w p g p 1 2 μ p ε p z 0 where u p v p and w p are the displacements of the mono pile in the x y and z directions respectively ε p u p x v p y w p z is the volume strain of the mono pile g p is the shear modulus and μ p is the poisson s ratio of the pile material 3 3 2 boundary conditions rocking motion of the mono pile is realized by imposing horizontal cyclic movement on the pile head applied as a displacement defined dirichlet boundary condition on the top surface of the mono pile the pile displacement used in the numerical model is expressed as follows 37 x p x p sin ω t where x p is the amplitude of the cyclic horizontal displacement of the pile head t denotes time and ω is the angular frequency of cyclic motion the interface between the mono pile and porous seabed is considered to be no slip and impermeable to study the coupled interaction effect this implies that the displacement of seabed soil at the mono pile interface is identical to the displacement of the mono pile which can be expressed as 38 u s u p v s v p and w s w p 39 p e n 0 where n is the normal vector to the interface 4 validation of the 3 d model in this section the proposed 3 d numerical model for residual pore pressure is validated against laboratory results and an existing numerical model in addition the response of residual pore pressure to the pile rocking effect is validated to ensure the accuracy of the new 3 d model in simulating residual pore pressure 4 1 results of pore pressure accumulation in the seabed without mono pile firstly the results of the proposed 3 d model are compared with the experimental data and 1 d numerical model presented in sumer et al 2012 the input data for the seabed and wave characteristics are listed in table 1 the model experiment was conducted by sumer et al 2012 in a wave flume that was 0 6 m wide and 26 5 m long the size of the soil pit in the experiment was 0 4 m 0 6 m 0 78 m and pore water pressure was measured at five different locations in the vertical direction of the soil pit comparisons of the numerical residual pore pressure model and the laboratory experiment results are shown in fig 3 variable p denotes the pore water pressure measured in the experiment of sumer et al 2012 and p s denotes the 1 d and 3 d numerical model results for residual pore pressure the peak values of p and p s have a relatively large difference fig 3 a shows the time series of residual pore pressure at a height of z 8 5 cm and fig 3 b shows it at a height of z 24 cm the relationship between residual pore pressure and mean pore pressure is also shown for the case of z 8 5 cm the mean pore pressures estimated by numerical simulation are in relatively good agreement with the laboratory experiment and the general trend in pore pressure is consistent for the height of z 24 cm the results of the 3 d numerical model and experimental data differ before t 10 s but become consistent afterwards in addition the 3 d modeled data are slightly lower than the test data while those of the 1 d numerical model are clearly larger this is because the 3 d model is calculated based on instantaneous shear stress rather than maximum shear stress which leads to a larger response of pore water pressure similar results for various numerical models have also been illustrated in jeng and zhao 2015 for the 1 d and 2 d model in which the residual response of 1 d and 2 d maximum model is larger than that of 2 d instant model as well therefore it can be seen that the residual response based on instantaneous shear stress is relatively more accurate than that of maximum shear stress in simulation by the comparisons above 4 2 results of pore pressure accumulation in a seabed with rocking mono pile it is worth noting that the validation of oscillatory response for the seabed under wave load with rocking and non rocking pile has been illustrated in zhang et al 2018 which shows the ability to simulate wave pile interaction accurately moreover the response of residual pore pressure in the seabed soil around a rocking mono pile is validated in this study as laboratory studies on the residual pore pressure of seabed soil with a mono pile are scarce currently the residual pore pressure of the 3 d model is compared with the pore pressure results while considering the pile rocking effect presented in cuéllar et al 2012a the numerical model focuses on the response of pore pressure accumulation under cyclic lateral loading without wave pressure acting on the seabed surface the simulation parameters adopted for validation are listed in table 2 fig 4 presents a comparison of pore pressure accumulation in the two 3 d numerical models under pile rocking in which pore water pressure p denotes the sum of both oscillatory pore pressure p e and residual pore pressure p s fig 4 a d show the time series of the pore pressure response at depths of 3 m 4 3 m 5 1 m and 7 m below the seabed surface respectively the horizontal distance from the mono pile surface is 0 5 m the solid line in fig 4 represents the results of the proposed 3 d model and the dash line represents the numerical results presented in cuéllar et al 2012a fig 4 clearly shows the periodic characteristic of oscillatory pore pressure and the increase of residual pore pressure with time the pore pressure variation of the two models has good consistency generally but differs at the maximum or minimum value as can be seen in fig 4 the main reason for this may be the different treatment of the pile seabed interface in two numerical models the results show good agreement in general which means the proposed 3 d model can accurately simulate the residual pore pressure response of a seabed with a mono pile based on the validation of the seabed residual pore pressure response considering a pile rocking effect the results of the proposed 3 d numerical model are considered acceptable and sufficient for analysis 5 application of the new 3 d model for residual pore pressure analysis in this section the proposed 3 d integrated model is used to simulate the pore pressure response of the seabed without mono pile with a non rocking mono pile and with a rocking mono pile in terms of seabed shear stress and variation of the residual pore pressure at different positions the total calculation time is 15t t is the wave period and the other input parameters are shown in table 3 5 1 analysis of the residual pore pressure in the seabed without mono pile fig 5 illustrates a contour plot of the residual pore pressure distribution in the seabed at t t 15 it can be seen that the maximum residual pore pressure appears at the front part of the seabed due to the effects of boundary conditions and residual pore pressure development with time in addition the residual pore pressure response is more obvious in the range of z 2 m to 17 m while it is less intense at the top and bottom of the seabed soil fig 6 shows the vertical distribution of residual pore pressure at the front position x 12 m and middle position x 50 m of the seabed at t t 15 in fig 5 the maximum residual pore pressure for both positions appears at z 7 m the maximum value at x 12 m is about 3 kpa and it is about 2 2 kpa at x 50 m the variations in the vertical distributions of the two positions are similar and the value of residual pore pressure decreases to less than 0 5 kpa at the seabed bottom fig 7 shows the development of residual pore pressure at position x 12 m z 7 m where the maximum pore pressure occurs the solid line in fig 7 denotes pore water pressure including that generated by both oscillatory and residual mechanisms and the dash line denotes residual pore pressure the value of pore water pressure is about 7 5 kpa at t t 15 and the residual pore pressure is around 3 kpa at this time it can be seen that the value of pore water pressure increases continuously with time due to the residual mechanism of pore pressure generation fig 8 presents the time series of residual pore pressure at seabed position x 12 m z 7 m the pore pressure value corresponds to the solid line in fig 6 the residual pore pressure increases quickly within the first few wave periods after which the increase becomes relatively slow after t t 7 and then gradually becomes stable in addition the variation in residual pore pressure presents an obvious oscillatory feature with a small amplitude which is caused by the periodic variation of instantaneous shear stress in the source term of the proposed 3 d model 5 2 analysis of the residual pore pressure in the seabed with non rocking mono pile in this section based on the 3 d seabed analysis the residual pore pressure response of the seabed with mono pile is explored in order to analyze the pore pressure response around the mono pile comprehensively four different positions at its waveward and lee sides were defined the input parameters for the waves seabed and mono pile are listed in table 3 the proposed 3 d model of residual pore pressure is directly related to the shear stress of the seabed soil fig 9 illustrates a contour plot of shear stress τ xz around the mono pile at three different times t 34 5 s 36 s 37 5 s corresponding to the moments when the wave crest wave midpoint and wave trough arrive at the centerline of the mono pile respectively the vertical displacement of the seabed soil and the slight horizontal deformation of the mono pile are also shown in fig 9 in order to illustrate the general trend of the soil monopile motion and there is a significant phase difference between the variations in shear stress and upper wave pressure subjected to the effect of wave crests and troughs the values of shear stress in fig 9 a and c are opposite while the distributions of stress are similar the maximum shear stress appears at the four angular points of the mono pile due to shear stress concentration caused by the obvious difference in the stiffness of the pile and soil in fig 9 b the maximum shear stress around the mono pile is smaller than that under the effect of wave crest and trough and the maximum shear stress appears at the waveward side of the mono pile in the upper seabed fig 10 shows a time series of pore water pressure accumulation at four different positions in the vicinity of the mono pile fig 10 a d show the results for positions x 46 m x 47 5 m and x 48 5 m at the waveward side of the pile and x 52 m at the back side respectively in which the distances from the pile surface r are 3 m r 1 5 d 1 5 m r 0 75 d 0 5 m r 0 25 d and 1 m r 0 5 d according to the different positions shown in fig 10 a d pore pressure accumulation begins after 0 5 1 t when the wave arrives in general the rate of pore pressure accumulation in fig 10 c and d is faster than that in fig 10 a and b the value of pore water pressure is largest in fig 10 c at the position closest to the pile surface in addition irregular fluctuation occurs at the point of minimum pore pressure in fig 10 b d this fluctuation is most obvious in fig 10 c and is very slight in fig 10 a the main reason for it is the varying wave pressure distribution caused by pile wave interaction the pile wave interaction may result in nonlinear effect such as wave reflection and cause irregular influences on the seabed around the mono pile moreover the fluctuation effect weakens gradually with increasing distance from the mono pile surface fig 11 shows a time series of residual pore pressure at position x 46 m z 0 5 m the rate of residual pore pressure increase is rapid before t t 2 and then becomes slower with time compared with fig 8 above the residual pore pressure in fig 11 is affected by the pile wave seabed interaction more significantly which results in the irregular fluctuation and nonlinear effect fig 12 presents a vertical distribution of residual pore pressure at four different positions around mono pile at t t 15 the pore pressure distributions are generally similar and pore pressure increases with decreasing distance from the pile surface due to the pile seabed soil interaction the increasing rate of residual pore pressure is the largest in fig 12 c and the maximum value appears at z 0 5 m because of the impermeable nature of the mono pile seabed interface at the position near the pile surface the dissipation of residual pore pressure is relatively slow in addition a shear stress concentration occurs near the pile seabed interface due to the obvious stiffness difference between the pile and the soil in fig 12 b and d the vertical distributions of residual pore pressure are very similar and the maximum value appears at the height of z 1 5 m in fig 12 a the influence of the pile soil interface is relatively low due to the long distance from the pile surface and the maximum value occurs at z 4 m 5 3 analysis of the residual pore pressure in the seabed with rocking mono pile this section focuses on the response of residual pore pressure in the seabed soil around the rocking mono pile this section investigates the residual pore pressure response of the seabed with a rocking mono pile fig 13 shows a contour plot of shear stress τ xz around the mono pile at three different times t 34 5 s 36 s 37 5 s in the rocking pile model in the seabed due to the joint influence of wave crests wave troughs and pile rocking the distribution of shear stress is antisymmetric in fig 13 a and c compared to the seabed with non rocking mono pile in section 5 2 the value of maximum shear stress is higher and the shear stress distribution around the pile is asymmetric due to the larger horizontal displacement of the mono pile in fig 13 b the value of shear stress around the mono pile is smaller than when wave crests and troughs are considered and the distribution of shear stress is similar to that in the seabed with non rocking mono pile at this moment fig 14 illustrates a time series of pore pressure accumulation at four positions around the mono pile in the rocking pile model fig 14 a d show the results for positions x 46 m x 47 5 m x 48 5 m at waveward side of the mono pile and x 52 m back side respectively due to the different distance from the mono pile the effect of pile rocking is relatively low and the pore pressure trend is similar to that in the seabed with non rocking mono pile while the pore pressure value is larger in addition large residual pore pressure occurs in fig 14 b and c due to the pile seabed interaction caused by forward pile displacement at the beginning of simulation while obvious dissipation occurs in both cases at t t 2 in fig 14 d the case at the back side of the mono pile there is no apparent pore pressure increase at first while the residual pore pressure increases quickly and is obviously larger than that in fig 14 c at t t 15 due to the joint effect of wave loads and pile rocking the reason for the difference between fig 14 c and d is that increased or decreased oscillatory shear stress occurs in part of the seabed due to the joint effect of wave and pile rocking which have the same period eventually leading to a difference in residual pore pressure variation at different positions moreover it can be seen that the influence of nonlinear fluctuation caused by the wave pile seabed interaction weakens with increasing distance from the pile surface fig 15 shows a time series of residual pore pressure at position x 46 m z 0 5 m in the seabed with rocking mono pile the residual pore pressure increases quickly before t t 2 and then more slowly with time compared to the non rocking pile model the value of residual pore pressure generally increases to some extent due to the effect of pile rocking the nonlinear influence of pile wave seabed interaction on residual pore pressure is more significant fig 16 presents a vertical distribution of residual pore pressure at four positions at t t 15 in the seabed with rocking mono pile the distribution of residual pore pressure and the vertical position of maximum pore pressure are similar to the results obtained for the non rocking pile model in addition the value of residual pore pressure increases to a certain degree which is apparent in fig 16 d 6 conclusions in this study detailed research has been conducted to explore the response of residual pore pressure considering mono pile seabed interaction by analyzing existing 1 d and 2 d numerical models of residual pore pressure and based on elastic soil assumption and studies on the source of residual pore pressure generation an existing 2 d numerical model was extended to a 3 d model in addition the results of the proposed 3 d residual pore pressure model were compared to experimental data for a seabed without mono pile and a numerical model for the seabed with a rocking mono pile without waves moreover the residual pore pressure responses in the seabed without mono pile with a non rocking mono pile and a rocking mono pile were analyzed allowing the following conclusions to be made 1 the proposed 3 d residual pore pressure model is developed based on the constitutive model of elastic soil and instantaneous shear stress the validation has shown the ability of the proposed model to simulate the residual pore pressure response under wave pile interaction accurately for general 3 d problem with an acceptable accuracy 2 in the seabed without mono pile the value of residual pore pressure increased gradually with time for the vertical distribution of residual pore pressure the maximum values appeared at the middle and upper parts of the seabed due to the oscillatory nature of instantaneous shear stress the buildup of residual pore pressure shows a corresponding characteristic of small amplitude oscillation 3 for the seabed with non rocking mono pile the maximum shear stress in the seabed appeared in the vicinity of the mono pile due to the impermeable interface between pile and soil and their different stiffness shear stress was concentrated near the mono pile surface in addition there was a nonlinear effect on the seabed soil around the mono pile caused by pile seabed wave interaction which is due to the out of phase between water waves and rocking pile the residual pore pressure fluctuated irregularly when subjected to this effect which weakened with distance from pile surface 4 in the seabed with rocking mono pile the residual pore pressure was larger than that in non rocking pile model due to the pile displacement the response of residual pore pressure was intense at the side of the rocking pile at the beginning of simulation in addition increased or decreased oscillatory shear stress occurred in part of the seabed this was caused by the joint effect of waves and pile rocking motion with the same period leading to differences in residual pore pressure variation at different positions furthermore the research on residual response for 3 d problem is preliminary and tentative it can provide qualitative analysis for the mono pile foundations in ocean engineering and it needs further studies especially on the governing equations for residual pore pressure generation the purpose of this paper is to investigate the possible effect of pile rocking motion on the pore pressure response as is known there exist many soil constitutive models that can reflect the residual characteristics of pore pressure response under pile rocking loads as a first approximation this study used a simple but workable way to analyze the wave seabed pile interaction considering pile rocking effect the soil model in presented study has a simple form and clear physical meaning which could help us to understand the pile seabed interaction in a much concise way in the future more advanced soil constitutive model and pile soil contact model such as model of elsafti and oumeraci 2016 should be applied and can give a deeper insight into the mechanism of wave seabed pile interaction acknowledgements this research project is financially supported by the national natural science foundation of china grant no 41602282 
23026,this study was conducted to calculate and analyze the net cage volume of submergible single cage and double cage systems affected by currents waves waves in cocurrent flow and waves in countercurrent flow by using a 3 d imaging system to develop a more accurate method for estimating net cage deformations the results indicate that currents impose a significantly greater impact on net cage deformation than waves do the nets achieved maximal deformation when the trough passes through the net cages and waves in concurrent flow caused greater deformation compared with waves in countercurrent flow test results for the double cage system indicate that the upstream net cage provided a shielding effect to the downstream net cage alleviating the net cage deformation of the downstream cage under the test conditions of the present study the shielding effect reduced the net cage deformation resulting from waves by 50 an analysis of the mooring rope tension revealed that the mooring rope tension was greater under waves in cocurrent conditions than under waves in countercurrent conditions the double cage system consumed more energy and generated lower maximum mooring rope tension than the single cage system did the submersible net cage simultaneously reduced the net cage deformation and mooring rope tension with the lowest mooring rope tension observed under wave current interactions future researchers can adopt the proposed technique for measuring the 3 d deformation of net cages affected by waves and currents and use the results of the present study to verify relevant numerical models keywords net cage wave current interaction net cage volume reduction coefficient 3 d imaging technique 1 introduction advancements in fishery technologies and uncontrolled fishing practices have resulted in the gradual depletion of fish stocks coastal countries have exclusive fishing rights within a 200 nautical mile sea zone extending from their coastal baselines known as exclusive economic zones these zones are a major source of fish stocks and are off limits to foreign offshore fisheries furthermore international conservation commissions have formulated numerous policies limiting fishing in international waters such restrictions inevitably impel fisheries to adopt aquaculture as a means to increase fish stocks taiwanese onshore aquaculture farmers are facing the challenge of limited space and land subsidence caused by excessive groundwater withdrawal rendering aquaculture an ineffective form of fish stock development in taiwan hence nearshore net cage aquaculture which involves placing net cages in natural marine environments to cultivate fish is an alternative means for developing fish stocks this method requires no onshore land or water resource and therefore reduces the environmental impact of aquaculture net cage aquaculture is also an ideal method for developing taiwan s unique exclusive economic zones however long term net cage aquaculture degrades the quality of the surrounding seawater therefore the optimal locations for net cage aquaculture are deep open waters with dynamic water exchange and wave current movement in such environments the structural stress and deformation patterns of net cages are extremely complex and the dynamic forces imposed by the waves and currents cause net cage deformation because aquaculture net cages are composed of flexible water permeable components such as nets mooring ropes and rigid impermeable components e g floating frames bottom weights and floaters analyzing such cage structures by using theoretical approaches is impractical therefore most previous studies in this field have used simulations to analyze the stress patterns in net cages by first conducting model tests to obtain the semiempirical formulas of the various components and then incorporating these formulas into the morison equation regarding the semiempirical formulas for developing net cage components kawakami 1964 conducted a series of net cage tests to elucidate the influences that velocity and mesh size have on flow resistance and developed a semiempirical formula for calculating the stress exerted on submerged net cages milne 1972 and woods hole engineering associates 1984 have proposed flow resistance coefficients for submerged objects of various shapes aarsnes et al 1990 and loland 1991 further examined the different external forces that fluids exert on net cages from various angles they identified lift and drag as the main external forces exerted on the normal of the net cages while accounting for the shielding effect generated between the layers of net cages providing a sound basis for calculating the stress of net cages lader et al 2003 and lader and enerhaug 2005 have conducted a series of model tests to examine the influence of uniform currents on the deformation of net cages under various velocities and using different bottom weights subsequently the researchers developed numerical models for analyzing the stress levels of net cages tsukrov et al 2003 and tsukrov et al 2005 have adopted the finite element method fem to simulate the dynamic characteristics of submerged tension leg net cages fredriksson et al 2003 also employed the fem to simulate the floating collar dynamics and anchor system dynamics of disk shaped net cages affected by waves decew et al 2005 performed a series of model tests to examine the dynamic differences between cages affected by regular waves and those affected by irregular waves huang et al 2006 employed a lumped mass method to develop a numerical model that they used in combination with model tests to examine the stress and deformation conditions of net cages affected by uniform current in another study a numerical model and model tests were combined to determine and observe how adding tube sinkers alleviate net cage deformation huang et al 2007 subsequently huang et al 2008 adopted a numerical model to elucidate the anchor system stress and net cage deformation of single and double cage systems under various wave current conditions wave incidence angles and water depths huang et al 2009 adopted a numerical model to examine the anchor system tension and net cage deformation of single point mooring cages huang et al 2010 employed a lumped mass method to simulate the stress and dynamic characteristics of an anchor system in single point mooring cages subjected to irregular wave current interactions moreover a comparison between theoretical and in site results confirmed the exceptional accuracy of the calculation method dong et al 2010 and xu et al 2011 have adopted a lumped mass method to simulate several dynamic characteristic of net cage affected by irregular waves such as mooring rope tension net cage deformation and floating frame movement the researchers also conducted a series of hydraulic model tests to verify the accuracy of their method tang et al 2011 created a 2 d numerical wave tank nwt by using the boundary element method bem to simulate the mooring rope tension and dynamic characteristics of dual pontoon floating cages and subsequently conducted a series of hydraulic model tests to verify the accuracy of the 2 d nwt kristiansen and faltinsen 2012 developed a net truss model to simulate the deformation of net cages affected by currents and conducted a series of tests to verify the accuracy of the model xu et al 2012 adopted the lumped mass method to simulate the mooring rope tension dynamic characteristics and net cage deformation of multiple net cages affected by waves and currents and conducted a series of hydraulic model tests to verify the accuracy of the their method net cage volume reduction is closely associated with the health of fish stock in particular net cage deformation caused by typhoons can kill off large amounts of fish within net cages because of the compression forces that can form during such events although numerous studies have proposed numerical simulation models to calculate the dynamics of net cages such models require many hydraulic model tests to verify their accuracy and ensure their credibility net cage deformation is a 3 d phenomenon however most hydraulic model tests for assessing net cages have been involved using planar photography this method simplifies net cage deformation into 2 d model in which the changes in the projected area of the net cages were used to estimate the changes in volume consequently this method did not realistically represent the deformation of net cages affected by waves and currents our institution thl tainan hydraulics laboratory of national cheng kung university has developed the measurement technique yang et al 2008 and applied it on the interaction between flow current and cage this study employs this technique to account for the coexistence of wave and currents and mainly focus on the analysis of the deformation of net cages in a complete series of experiments some of the analysis has not been done before qualisys https www qualisys com provides the possibility to measure underwater by using specially adapted oqus motion capture cameras it is quite similar to the system developed by thl 2 the 3 d net cage deformation measurement technique this study used a noninvasive 3 d camera system comprising three charge coupled device ccd cameras a sufficient number of led lights were affixed to the net cage and the ccd cameras were used to capture 2 d images of the model the images were then overlapped to form 3 d images by performing a matrix conversion the 3 d images were analyzed to determine the deformation trends of net cages affected by waves and currents 2 1 theoretical methodology of 3 d image measurement and analysis techniques a central projection from a virtual camera focal point onto the image plane can be obtained through the transformation from 3 d physical coordinates to 2 d image coordinates for each of the 3 cameras one can then write the following relationship between known led coordinates x y z r and the corresponding image coordinates γ i ρ i i 1 2 3 tsai 1987 jain et al 1995 yang et al 2008 1 λ i γ i ρ i 1 a i x y z b i where λ i is a scalar parameter spinewine et al 2003 used the known physical and image coordinates of the calibration target to determine the values of matrices a i and vector b i the 3 d position vector r can be expressed using the following ray equation 2 r p i λ i q i where 3 p i a i 1 b i eq 3 is the projected values of observation position i after matrix p was established the researchers derived matrix q by using the following equation 4 q i a i 1 γ i ρ i 1 finally matrices p and q were incorporated into eq 2 where λ i is the unknown coefficient matrix of any observation position along the ray in theory when an led light point is obtained from two or three observation positions the 3 d position of the led light can be distinguished as the approximate intersecting point of the two or three rays fig 1 a linear equation was then employed to combine the unknown functions of the rays intersecting each observation position where λ i is determined using the generalized least squares method two cameras are required to determine the 3 d positions of led lights when using the aforementioned method the present study employed three cameras to enhance the accuracy of the measurement results 2 2 three dimensional net cage image measurement and analysis technique the proposed technique developed by thl yang et al 2008 can be used to analyze imaging data captured by ccd cameras by using equations 1 4 to determine the coordinates of led light points these light points can then be examined to determine the dynamics and deformation and calculate the volume reduction of the net cages the relevant procedures are described as follows 1 place three high resolution cameras outside of the glass window of the wave tank the cameras should be placed at the left side center and right side of a net cage at appropriate angles to concurrently monitor the displacement conditions of the led lights affixed to the net cages 2 prior to formal testing the coordinates of the calibration targets should first be established under static current conditions 3 affix numerous leds onto the net cages to create a deformable point grid structure the ideal net cage led grid structure established under static conditions serves as a control model against the deformation conditions of net cages affected by waves and currents 4 using analytical software developed by the thl the software uses equations 1 4 to determine the 3 d coordinates of the led light points the researchers employed the 3 d image analysis method to determine the x y and z coordinates of the led light points these points were then employed to dissect the net cage surface into an n number of small triangular elements subsequently the gauss divergence theory was employed to obtain volume v p 5 v p i 1 n f g i n i d a i where 6 f g i i 1 3 x i i y i j z i k 3 7 n i r 12 r 23 r 12 r 23 8 d a i s i s i a i s i b i s i c i 9 s i a i b i c i 2 where f g i is the location vector passing the center of gravity of a small triangle element n i represents the unit normal vector of a small triangular element d a i is the area of triangular plane element r i j represents the vector between positions i and j and a i b i and c i respectively represent the length of each side of the triangle fig 2 shows the relevant definitions therefore the net cage volume reduction coefficient can be expressed as follows 10 c v r v p v p o where v p o represents the original volume of the net cages under static conditions 3 experimental equipment and arrangement 3 1 experimental equipment tests were conducted in the wave current tank of the national sun yat sen university taiwan the main equipment and apparatuses are described in the following section 1 hydrodynamic wave current actuation system a wave tank the dimensions of the wave tank were 35 1 1 2 m l w h a front rear actuation wave generator is installed at the front of the tank stroke length 0 3 m the tank is 33 m in length after deducting the length of the wave generator and has 22 transparent windows for observation a wave absorbing construction was installed at the end of the tank the floor of the tank is a smooth stainless steel surface and a circumfluence system is installed below the tank floor fig 3 this study did not examine turbulence and the uniformity of current across the cross section the above should be error sources b wave generator the wave generator is a piston type wave generator that is controlled by an ad da card that transmits servo voltage information to the generator servo the generator servo controls the generator motor which actuates the piston wave plates the wave generator can be configured to produce regular and irregular waves for testing c current generator the wave tank comprises a circulation pipe opening on either side the circumfluence system is composed of a pump that circulates the water flow within the pipes this circulation actuates the flow of water in the tank to simulate the currents for testing the circulation motor operates within a range of 0 2000 rpm 2 wave gauge the researchers used the capacitive wave gauge developed by the thl this wave gauge achieves accuracy within 0 5 at the rated output test results have shown that the degree of influence imposed by potential environment noise and interferences is less than 0 05 cm indicating that the wave gauge is extremely accurate 3 current meter an alec acm250 a electromagnetic current meter was used in the present study this meter measures 2 d directions within a current range of 250 cm s and at a depth of 10 m the meter is accurate to within 2 of the selected measurement range the response frequency of the meter can be set to either 0 05 1 0 or 5 0 s at depth of 10 m 4 load cell a load cell developed by the japanese manufacturer ssk was employed in the present study the meter was 3 cm long with a diameter of 0 5 cm measurement could be taken within a range of 0 2 kg the meter is accurate to within 0 2 of the selected measurement range 5 camera system a 3 d imaging technique was adopted to analyze the deformation of the net cage the specifications of the camera system are tabulated in table 1 6 data recording system in hydraulic model testing most physical activity cannot be directly measured the aforementioned meters are required to electronically quantify such physical activity and convert them into voltage signals then the voltage signals are digitized using an a d converter which can then be stored on a computer for subsequent analysis and processing in the present study the data collected from the various meters were converted using the pcl 818 a d and d a cards manufactured by advantech corporation and stored in a computer 3 2 experimental setup 1 net cage model in the present study xiao liuqiu cage culture is the research subject based on the 1 30 model scale the researchers converted the prototype cage net system into model scale the specifications of the physical model are presented in table 2 37 leds affixed to the net cage were used to utilize 3 d net cage image measurement as shown in fig 4 the specifications of led system are listed in table 3 the main scaling effect is resulted from mesh size while the reduced mesh size will intensify viscous forces and cause scaling error the reference mesh size is 6 7 cm and shortens to about 0 2 cm after being reduced scale of 1 30 however this size 0 2 cm will cause excessive viscous forces therefore the mesh size used for this experiment is 0 76 cm the experimental results will be different from the actual phenomenon due to the scaling effect the same problem will be found in all net cage experiments except for the experiments conducted in large wave tanks 2 hydrodynamic conditions the net cage model was tested under the effects of currents waves waves in cocurrent flow and waves in countercurrent flow according to the field data of xiao liuqiu the hydrodynamic conditions were scaled to model dimensions using the froude scaling relationship table 4 provides experimental test cases for a net cage system and table 5 lists the designed hydrodynamic conditions on the laboratory and field the submersible net cage is used to reduce the impact of typhoon waves therefore only the cases including typhoon waves were considered 3 arrangement of the experimental test the experiments in a two dimensional wave tank were conducted in the present study the tank generates waves and uniform currents at the same time configuration of experimental setup for floating and submersible net cage is respectively indicated in fig 5 and fig 6 schematic diagrams of single and double cage system are shown in fig 7 and fig 8 since the directions of waves and currents in this experiment flow along the wave tank force exerting on the lateral sides of the net cages should be weak however the wall boundary effects are error source 4 experimental procedures preliminary tests were conducted to compare the mooring rope tension between the system with led system led lamps and wires and without led system formal tests would be performed when further confirmation of little effect on leds is verified fig 9 shows the diagram of the experimental procedures two waves are passed through the net cage before measurements are done 4 results and analysis 4 1 instrument calibration and preliminary testing the accuracy of the measurement instruments affects the integrity of the overall test results therefore relevant instruments must be calibrated prior to each test to ensure the applicability of the instruments calibration results revealed that the wave gauge and load cell achieved a correlation coefficient r 2 over 0 9998 and 0 9999 respectively suggesting that both the wave gauge and the load cell met test standards and were suitable for testing in this instance preliminary tests were conducted to elucidate the potential influences that the led system may impose on the tests 37 points are used to analyze the volume of net cages and the resulting error should be greater than the influence caused by the led system therefore we simply focus on the impact on the global mooring force in led system instead of analyzing its effect on the deformation of the net to get better understanding about the drag force caused by led system we use uniform flow with relative simple conditions for the test so that the experiment would be controlled easily and more precisely first a net cage system was constructed without affixing led system six uniform currents at varying velocities were applied to the system and the mooring rope tension of the net cage system was measured then the same test was conducted on a net cage system affixed with led system the preliminary test results are illustrated in fig 10 according to the figure the mooring rope tension of both systems were close to all six current types r 2 0 9994 suggesting that affixing led system to the net cage system posed minimal influence on net cage dynamics thereby verifying the feasibility of the test method adopted in the present study 4 2 analyzing the formal test results fig 11 shows the installation process of the test equipment and fig 12 shows the dynamics of the net cages affected by typhoon waves captured by the camera in the center the hydrodynamic conditions of all tests are tabulated in tables 6 and 7 for the floating single cage typhoon wave in cocurrent flow case fig 13 shows the 3 d net cage deformation calculated by analytical software that thl developed yang et al 2008 fig 13 a b and c illustrate the net cage located on the leftmost middle and rightmost position respectively leftmost means that upstream part of the cage moves to the leftmost position and rightmost means that downstream part of the cage moves to the rightmost position middle means the instant position which corresponds to the median of time interval during the cage moving to the leftmost position and to the rightmost position fig 14 shows the tension of the mooring rope in this case fig 15 shows a comparison of the volume reduction coefficient of the floating single cage system where t represents time t denotes the wave period 8 t t 0 represents the time of the wave crest passing through hitting the right part of the cage the net cage and 8 t t 4 represents the time of the wave trough passing through the net cage fig 15 indicates that currents imposed a significantly greater influence on the net cage deformation compared with waves under similar conditions in addition typhoon waves caused greater deformation than monsoon waves as anticipated when affected by waves the cage shifted and swayed repeatedly however the shape of the net cage changed only slightly deformation was comparatively more visible when the net cages were affected by currents for prolonged periods achieving maximal deformation the minimal volume reduction coefficient c v r approximately at the time when the wave troughs passed through the net cage table 6 shows the inconsistencies in the current velocities derived from various tests this irregularity occurred because the uniform current velocity in the wave tank was difficult to control the velocities of the waves in cocurrent flow were slightly weaker than that of the waves in countercurrent flow yet the deformation observed in the waves in cocurrent flow was greater than that in the waves in countercurrent flow based on these results the researchers inferred that under similar conditions waves in concurrent flow cause greater deformation than do waves in countercurrent flow fig 16 and fig 17 are diagrams for comparing the volume reduction coefficients of the floating net cages in the double cage system the net cage closest to the wave generator is cage 1 and the other net cage is cage 2 a comparison between figs 16 and 17 reveals that excluding the countercurrent tests cage 2 was less deformed because of the shielding effect provided by cage 1 this phenomenon was most apparent in the test without waves because the currents imposed a greater influence on the net cages than did the waves cage 2 shielded cage 1 during the countercurrent tests therefore cage 1 exhibited less deformation all other conditions were similar to those in the single cage system fig 18 is a diagram for comparing the volume reduction coefficients of the floating and submersible net cages in the single cage system in the figure the unfilled shapes represent the floating net cages and the filled shapes represent the submersible net cages the deformation trends of the submersible net cage were similar to those of the floating net cage the primary function of submersible net cages is to reduce the influence of the waves however because the test conditions in the present study resulted in the waves imposing less influence on deformation the effect that the submersible net cage had on improving the volume reduction coefficient was limited to approximately 5 in context of the typhoon wave tests although the increase in volume reduction was limited the submersible net cage reduced the deformation by up to 50 when considering only the deformation reduction ratio for example the deformation rate of the floating net cage 1 c v r was 4 whereas that of the submersible net cage was 2 where 8 t t 2 figs 19 and 20 are diagrams for comparing the volume reduction coefficients of the floating net cage and submersible net cage in the double cage system the trends of the double cage system were similar to those exhibited in the single cage system with the exception that a comparatively greater increase in net cage volume reduction was exhibited in the submersible net cage than the net cages in the single cage system fig 21 26 show the 3 d deformation of the floating cage in the typhoon wave tests in the figures above the waves propagate to the right the figures present the instant position of the led lamps at three different instants times which are from the wave trough passing through the net cage to the wave crest passing through the net cage at three instants times 8 t t 4 8 t t 6 and 8 t t 8 most figures show the greater displacement was obtained in the middle part of the net in a vertical direction the phenomenon became more obvious under typhoon waves in cocurrent flow fig 27 shows a diagram for comparing the maximum mooring rope tension between the submersible and floating net cages in the typhoon wave tests the figure indicates that the mooring rope tension was greater in the waves in cocurrent flow tests than in the waves in countercurrent flow tests subsequently the wave only tests yielded the lowest mooring rope tension the motion of net cages will decay wave energy and reduce mooring rope tension the double cage system attenuated more energy and exhibited a lower maximum mooring rope tension compared with the single cage system the submersible net cage not only reduced the net cage deformation but also reduced the mooring rope tension another reason could be that the two cages experiences counteracting waves which partly cancels out the resulting mooring force 5 conclusion this study used a 3 d imaging system to improve the planar photography method for calculating net cage volume reduction the system comprised three cameras that captured images of 37 led lights affixed to net cage the images were processed by an algorithm to determine the 3 d coordinates of the led lights and these were employed to determine the volume of the net cage compared with previous methods the proposed method can more accurately estimate the deformation conditions of net cages referencing the net cage system of xiao liuqiu and various current monsoon wave and typhoon wave data the researchers conducted a series of tests on single cage and double cage systems by establishing system models at a reduced scale of 1 30 in the wave tank of the national sun yat sen university taiwan subsequently the cage system models were tested under the effects of currents waves waves in cocurrent flow and waves in countercurrent flow to determine the mooring rope tension and net cage deformation for each system under similar test conditions the currents imposed a significantly greater impact on the net cages than did the waves the net cages achieved the maximal deformation when the troughs passed through the net cage and the waves in concurrent flow caused greater deformation compared with the waves in countercurrent flow the test results of the double cage system indicate that the upstream net cage shielded the downstream net cage alleviating the net cage deformation in the downstream cage this shielding effect was particularly evident during the current tests the primary function of submersible net cages is to reduce the impact of waves however because the test conditions in this study resulted in waves imposing a less influence in causing deformation the effect that the submersible net cage had on improving the volume reduction coefficient was limited to approximately 5 however the submersible net cage reduced the deformation by up to 50 when considering only the deformation reduction ratio to analyze the instant position of the led lamps all results show that greater displacement was obtained in the middle part of the net in a vertical direction the phenomenon became more obvious under typhoon waves in cocurrent flow an analysis of the maximum tension shows that the tension of the mooring ropes in the waves in cocurrent flow tests was greater than that in the waves in countercurrent flow tests and the wave only tests yielded the lowest mooring rope tension the double cage system attenuated more energy and generated a lower maximum mooring rope tension compared with the single cage system in which the submersible net cage reduced both the net cage deformation and mooring rope tension the dynamics of net cages affected by waves and currents are extremely complex therefore the test results are only applicable under the conditions in the presents study changing the structure or dimensions of the net cages or including different hydrodynamic conditions would inevitably alter the test results future studies should consider applying the proposed technique based on the research model adopted in the present study furthermore researchers attempting to conduct numerical simulations to determine the dynamics of net cages can reference the numerical model established herein and subsequently verify their numerical models by using the measurement results of this study acknowledgments the authors acknowledge the support from pingtung county government and ministry of science and technology taiwan under the grant 106 2911 i 006 301 
23026,this study was conducted to calculate and analyze the net cage volume of submergible single cage and double cage systems affected by currents waves waves in cocurrent flow and waves in countercurrent flow by using a 3 d imaging system to develop a more accurate method for estimating net cage deformations the results indicate that currents impose a significantly greater impact on net cage deformation than waves do the nets achieved maximal deformation when the trough passes through the net cages and waves in concurrent flow caused greater deformation compared with waves in countercurrent flow test results for the double cage system indicate that the upstream net cage provided a shielding effect to the downstream net cage alleviating the net cage deformation of the downstream cage under the test conditions of the present study the shielding effect reduced the net cage deformation resulting from waves by 50 an analysis of the mooring rope tension revealed that the mooring rope tension was greater under waves in cocurrent conditions than under waves in countercurrent conditions the double cage system consumed more energy and generated lower maximum mooring rope tension than the single cage system did the submersible net cage simultaneously reduced the net cage deformation and mooring rope tension with the lowest mooring rope tension observed under wave current interactions future researchers can adopt the proposed technique for measuring the 3 d deformation of net cages affected by waves and currents and use the results of the present study to verify relevant numerical models keywords net cage wave current interaction net cage volume reduction coefficient 3 d imaging technique 1 introduction advancements in fishery technologies and uncontrolled fishing practices have resulted in the gradual depletion of fish stocks coastal countries have exclusive fishing rights within a 200 nautical mile sea zone extending from their coastal baselines known as exclusive economic zones these zones are a major source of fish stocks and are off limits to foreign offshore fisheries furthermore international conservation commissions have formulated numerous policies limiting fishing in international waters such restrictions inevitably impel fisheries to adopt aquaculture as a means to increase fish stocks taiwanese onshore aquaculture farmers are facing the challenge of limited space and land subsidence caused by excessive groundwater withdrawal rendering aquaculture an ineffective form of fish stock development in taiwan hence nearshore net cage aquaculture which involves placing net cages in natural marine environments to cultivate fish is an alternative means for developing fish stocks this method requires no onshore land or water resource and therefore reduces the environmental impact of aquaculture net cage aquaculture is also an ideal method for developing taiwan s unique exclusive economic zones however long term net cage aquaculture degrades the quality of the surrounding seawater therefore the optimal locations for net cage aquaculture are deep open waters with dynamic water exchange and wave current movement in such environments the structural stress and deformation patterns of net cages are extremely complex and the dynamic forces imposed by the waves and currents cause net cage deformation because aquaculture net cages are composed of flexible water permeable components such as nets mooring ropes and rigid impermeable components e g floating frames bottom weights and floaters analyzing such cage structures by using theoretical approaches is impractical therefore most previous studies in this field have used simulations to analyze the stress patterns in net cages by first conducting model tests to obtain the semiempirical formulas of the various components and then incorporating these formulas into the morison equation regarding the semiempirical formulas for developing net cage components kawakami 1964 conducted a series of net cage tests to elucidate the influences that velocity and mesh size have on flow resistance and developed a semiempirical formula for calculating the stress exerted on submerged net cages milne 1972 and woods hole engineering associates 1984 have proposed flow resistance coefficients for submerged objects of various shapes aarsnes et al 1990 and loland 1991 further examined the different external forces that fluids exert on net cages from various angles they identified lift and drag as the main external forces exerted on the normal of the net cages while accounting for the shielding effect generated between the layers of net cages providing a sound basis for calculating the stress of net cages lader et al 2003 and lader and enerhaug 2005 have conducted a series of model tests to examine the influence of uniform currents on the deformation of net cages under various velocities and using different bottom weights subsequently the researchers developed numerical models for analyzing the stress levels of net cages tsukrov et al 2003 and tsukrov et al 2005 have adopted the finite element method fem to simulate the dynamic characteristics of submerged tension leg net cages fredriksson et al 2003 also employed the fem to simulate the floating collar dynamics and anchor system dynamics of disk shaped net cages affected by waves decew et al 2005 performed a series of model tests to examine the dynamic differences between cages affected by regular waves and those affected by irregular waves huang et al 2006 employed a lumped mass method to develop a numerical model that they used in combination with model tests to examine the stress and deformation conditions of net cages affected by uniform current in another study a numerical model and model tests were combined to determine and observe how adding tube sinkers alleviate net cage deformation huang et al 2007 subsequently huang et al 2008 adopted a numerical model to elucidate the anchor system stress and net cage deformation of single and double cage systems under various wave current conditions wave incidence angles and water depths huang et al 2009 adopted a numerical model to examine the anchor system tension and net cage deformation of single point mooring cages huang et al 2010 employed a lumped mass method to simulate the stress and dynamic characteristics of an anchor system in single point mooring cages subjected to irregular wave current interactions moreover a comparison between theoretical and in site results confirmed the exceptional accuracy of the calculation method dong et al 2010 and xu et al 2011 have adopted a lumped mass method to simulate several dynamic characteristic of net cage affected by irregular waves such as mooring rope tension net cage deformation and floating frame movement the researchers also conducted a series of hydraulic model tests to verify the accuracy of their method tang et al 2011 created a 2 d numerical wave tank nwt by using the boundary element method bem to simulate the mooring rope tension and dynamic characteristics of dual pontoon floating cages and subsequently conducted a series of hydraulic model tests to verify the accuracy of the 2 d nwt kristiansen and faltinsen 2012 developed a net truss model to simulate the deformation of net cages affected by currents and conducted a series of tests to verify the accuracy of the model xu et al 2012 adopted the lumped mass method to simulate the mooring rope tension dynamic characteristics and net cage deformation of multiple net cages affected by waves and currents and conducted a series of hydraulic model tests to verify the accuracy of the their method net cage volume reduction is closely associated with the health of fish stock in particular net cage deformation caused by typhoons can kill off large amounts of fish within net cages because of the compression forces that can form during such events although numerous studies have proposed numerical simulation models to calculate the dynamics of net cages such models require many hydraulic model tests to verify their accuracy and ensure their credibility net cage deformation is a 3 d phenomenon however most hydraulic model tests for assessing net cages have been involved using planar photography this method simplifies net cage deformation into 2 d model in which the changes in the projected area of the net cages were used to estimate the changes in volume consequently this method did not realistically represent the deformation of net cages affected by waves and currents our institution thl tainan hydraulics laboratory of national cheng kung university has developed the measurement technique yang et al 2008 and applied it on the interaction between flow current and cage this study employs this technique to account for the coexistence of wave and currents and mainly focus on the analysis of the deformation of net cages in a complete series of experiments some of the analysis has not been done before qualisys https www qualisys com provides the possibility to measure underwater by using specially adapted oqus motion capture cameras it is quite similar to the system developed by thl 2 the 3 d net cage deformation measurement technique this study used a noninvasive 3 d camera system comprising three charge coupled device ccd cameras a sufficient number of led lights were affixed to the net cage and the ccd cameras were used to capture 2 d images of the model the images were then overlapped to form 3 d images by performing a matrix conversion the 3 d images were analyzed to determine the deformation trends of net cages affected by waves and currents 2 1 theoretical methodology of 3 d image measurement and analysis techniques a central projection from a virtual camera focal point onto the image plane can be obtained through the transformation from 3 d physical coordinates to 2 d image coordinates for each of the 3 cameras one can then write the following relationship between known led coordinates x y z r and the corresponding image coordinates γ i ρ i i 1 2 3 tsai 1987 jain et al 1995 yang et al 2008 1 λ i γ i ρ i 1 a i x y z b i where λ i is a scalar parameter spinewine et al 2003 used the known physical and image coordinates of the calibration target to determine the values of matrices a i and vector b i the 3 d position vector r can be expressed using the following ray equation 2 r p i λ i q i where 3 p i a i 1 b i eq 3 is the projected values of observation position i after matrix p was established the researchers derived matrix q by using the following equation 4 q i a i 1 γ i ρ i 1 finally matrices p and q were incorporated into eq 2 where λ i is the unknown coefficient matrix of any observation position along the ray in theory when an led light point is obtained from two or three observation positions the 3 d position of the led light can be distinguished as the approximate intersecting point of the two or three rays fig 1 a linear equation was then employed to combine the unknown functions of the rays intersecting each observation position where λ i is determined using the generalized least squares method two cameras are required to determine the 3 d positions of led lights when using the aforementioned method the present study employed three cameras to enhance the accuracy of the measurement results 2 2 three dimensional net cage image measurement and analysis technique the proposed technique developed by thl yang et al 2008 can be used to analyze imaging data captured by ccd cameras by using equations 1 4 to determine the coordinates of led light points these light points can then be examined to determine the dynamics and deformation and calculate the volume reduction of the net cages the relevant procedures are described as follows 1 place three high resolution cameras outside of the glass window of the wave tank the cameras should be placed at the left side center and right side of a net cage at appropriate angles to concurrently monitor the displacement conditions of the led lights affixed to the net cages 2 prior to formal testing the coordinates of the calibration targets should first be established under static current conditions 3 affix numerous leds onto the net cages to create a deformable point grid structure the ideal net cage led grid structure established under static conditions serves as a control model against the deformation conditions of net cages affected by waves and currents 4 using analytical software developed by the thl the software uses equations 1 4 to determine the 3 d coordinates of the led light points the researchers employed the 3 d image analysis method to determine the x y and z coordinates of the led light points these points were then employed to dissect the net cage surface into an n number of small triangular elements subsequently the gauss divergence theory was employed to obtain volume v p 5 v p i 1 n f g i n i d a i where 6 f g i i 1 3 x i i y i j z i k 3 7 n i r 12 r 23 r 12 r 23 8 d a i s i s i a i s i b i s i c i 9 s i a i b i c i 2 where f g i is the location vector passing the center of gravity of a small triangle element n i represents the unit normal vector of a small triangular element d a i is the area of triangular plane element r i j represents the vector between positions i and j and a i b i and c i respectively represent the length of each side of the triangle fig 2 shows the relevant definitions therefore the net cage volume reduction coefficient can be expressed as follows 10 c v r v p v p o where v p o represents the original volume of the net cages under static conditions 3 experimental equipment and arrangement 3 1 experimental equipment tests were conducted in the wave current tank of the national sun yat sen university taiwan the main equipment and apparatuses are described in the following section 1 hydrodynamic wave current actuation system a wave tank the dimensions of the wave tank were 35 1 1 2 m l w h a front rear actuation wave generator is installed at the front of the tank stroke length 0 3 m the tank is 33 m in length after deducting the length of the wave generator and has 22 transparent windows for observation a wave absorbing construction was installed at the end of the tank the floor of the tank is a smooth stainless steel surface and a circumfluence system is installed below the tank floor fig 3 this study did not examine turbulence and the uniformity of current across the cross section the above should be error sources b wave generator the wave generator is a piston type wave generator that is controlled by an ad da card that transmits servo voltage information to the generator servo the generator servo controls the generator motor which actuates the piston wave plates the wave generator can be configured to produce regular and irregular waves for testing c current generator the wave tank comprises a circulation pipe opening on either side the circumfluence system is composed of a pump that circulates the water flow within the pipes this circulation actuates the flow of water in the tank to simulate the currents for testing the circulation motor operates within a range of 0 2000 rpm 2 wave gauge the researchers used the capacitive wave gauge developed by the thl this wave gauge achieves accuracy within 0 5 at the rated output test results have shown that the degree of influence imposed by potential environment noise and interferences is less than 0 05 cm indicating that the wave gauge is extremely accurate 3 current meter an alec acm250 a electromagnetic current meter was used in the present study this meter measures 2 d directions within a current range of 250 cm s and at a depth of 10 m the meter is accurate to within 2 of the selected measurement range the response frequency of the meter can be set to either 0 05 1 0 or 5 0 s at depth of 10 m 4 load cell a load cell developed by the japanese manufacturer ssk was employed in the present study the meter was 3 cm long with a diameter of 0 5 cm measurement could be taken within a range of 0 2 kg the meter is accurate to within 0 2 of the selected measurement range 5 camera system a 3 d imaging technique was adopted to analyze the deformation of the net cage the specifications of the camera system are tabulated in table 1 6 data recording system in hydraulic model testing most physical activity cannot be directly measured the aforementioned meters are required to electronically quantify such physical activity and convert them into voltage signals then the voltage signals are digitized using an a d converter which can then be stored on a computer for subsequent analysis and processing in the present study the data collected from the various meters were converted using the pcl 818 a d and d a cards manufactured by advantech corporation and stored in a computer 3 2 experimental setup 1 net cage model in the present study xiao liuqiu cage culture is the research subject based on the 1 30 model scale the researchers converted the prototype cage net system into model scale the specifications of the physical model are presented in table 2 37 leds affixed to the net cage were used to utilize 3 d net cage image measurement as shown in fig 4 the specifications of led system are listed in table 3 the main scaling effect is resulted from mesh size while the reduced mesh size will intensify viscous forces and cause scaling error the reference mesh size is 6 7 cm and shortens to about 0 2 cm after being reduced scale of 1 30 however this size 0 2 cm will cause excessive viscous forces therefore the mesh size used for this experiment is 0 76 cm the experimental results will be different from the actual phenomenon due to the scaling effect the same problem will be found in all net cage experiments except for the experiments conducted in large wave tanks 2 hydrodynamic conditions the net cage model was tested under the effects of currents waves waves in cocurrent flow and waves in countercurrent flow according to the field data of xiao liuqiu the hydrodynamic conditions were scaled to model dimensions using the froude scaling relationship table 4 provides experimental test cases for a net cage system and table 5 lists the designed hydrodynamic conditions on the laboratory and field the submersible net cage is used to reduce the impact of typhoon waves therefore only the cases including typhoon waves were considered 3 arrangement of the experimental test the experiments in a two dimensional wave tank were conducted in the present study the tank generates waves and uniform currents at the same time configuration of experimental setup for floating and submersible net cage is respectively indicated in fig 5 and fig 6 schematic diagrams of single and double cage system are shown in fig 7 and fig 8 since the directions of waves and currents in this experiment flow along the wave tank force exerting on the lateral sides of the net cages should be weak however the wall boundary effects are error source 4 experimental procedures preliminary tests were conducted to compare the mooring rope tension between the system with led system led lamps and wires and without led system formal tests would be performed when further confirmation of little effect on leds is verified fig 9 shows the diagram of the experimental procedures two waves are passed through the net cage before measurements are done 4 results and analysis 4 1 instrument calibration and preliminary testing the accuracy of the measurement instruments affects the integrity of the overall test results therefore relevant instruments must be calibrated prior to each test to ensure the applicability of the instruments calibration results revealed that the wave gauge and load cell achieved a correlation coefficient r 2 over 0 9998 and 0 9999 respectively suggesting that both the wave gauge and the load cell met test standards and were suitable for testing in this instance preliminary tests were conducted to elucidate the potential influences that the led system may impose on the tests 37 points are used to analyze the volume of net cages and the resulting error should be greater than the influence caused by the led system therefore we simply focus on the impact on the global mooring force in led system instead of analyzing its effect on the deformation of the net to get better understanding about the drag force caused by led system we use uniform flow with relative simple conditions for the test so that the experiment would be controlled easily and more precisely first a net cage system was constructed without affixing led system six uniform currents at varying velocities were applied to the system and the mooring rope tension of the net cage system was measured then the same test was conducted on a net cage system affixed with led system the preliminary test results are illustrated in fig 10 according to the figure the mooring rope tension of both systems were close to all six current types r 2 0 9994 suggesting that affixing led system to the net cage system posed minimal influence on net cage dynamics thereby verifying the feasibility of the test method adopted in the present study 4 2 analyzing the formal test results fig 11 shows the installation process of the test equipment and fig 12 shows the dynamics of the net cages affected by typhoon waves captured by the camera in the center the hydrodynamic conditions of all tests are tabulated in tables 6 and 7 for the floating single cage typhoon wave in cocurrent flow case fig 13 shows the 3 d net cage deformation calculated by analytical software that thl developed yang et al 2008 fig 13 a b and c illustrate the net cage located on the leftmost middle and rightmost position respectively leftmost means that upstream part of the cage moves to the leftmost position and rightmost means that downstream part of the cage moves to the rightmost position middle means the instant position which corresponds to the median of time interval during the cage moving to the leftmost position and to the rightmost position fig 14 shows the tension of the mooring rope in this case fig 15 shows a comparison of the volume reduction coefficient of the floating single cage system where t represents time t denotes the wave period 8 t t 0 represents the time of the wave crest passing through hitting the right part of the cage the net cage and 8 t t 4 represents the time of the wave trough passing through the net cage fig 15 indicates that currents imposed a significantly greater influence on the net cage deformation compared with waves under similar conditions in addition typhoon waves caused greater deformation than monsoon waves as anticipated when affected by waves the cage shifted and swayed repeatedly however the shape of the net cage changed only slightly deformation was comparatively more visible when the net cages were affected by currents for prolonged periods achieving maximal deformation the minimal volume reduction coefficient c v r approximately at the time when the wave troughs passed through the net cage table 6 shows the inconsistencies in the current velocities derived from various tests this irregularity occurred because the uniform current velocity in the wave tank was difficult to control the velocities of the waves in cocurrent flow were slightly weaker than that of the waves in countercurrent flow yet the deformation observed in the waves in cocurrent flow was greater than that in the waves in countercurrent flow based on these results the researchers inferred that under similar conditions waves in concurrent flow cause greater deformation than do waves in countercurrent flow fig 16 and fig 17 are diagrams for comparing the volume reduction coefficients of the floating net cages in the double cage system the net cage closest to the wave generator is cage 1 and the other net cage is cage 2 a comparison between figs 16 and 17 reveals that excluding the countercurrent tests cage 2 was less deformed because of the shielding effect provided by cage 1 this phenomenon was most apparent in the test without waves because the currents imposed a greater influence on the net cages than did the waves cage 2 shielded cage 1 during the countercurrent tests therefore cage 1 exhibited less deformation all other conditions were similar to those in the single cage system fig 18 is a diagram for comparing the volume reduction coefficients of the floating and submersible net cages in the single cage system in the figure the unfilled shapes represent the floating net cages and the filled shapes represent the submersible net cages the deformation trends of the submersible net cage were similar to those of the floating net cage the primary function of submersible net cages is to reduce the influence of the waves however because the test conditions in the present study resulted in the waves imposing less influence on deformation the effect that the submersible net cage had on improving the volume reduction coefficient was limited to approximately 5 in context of the typhoon wave tests although the increase in volume reduction was limited the submersible net cage reduced the deformation by up to 50 when considering only the deformation reduction ratio for example the deformation rate of the floating net cage 1 c v r was 4 whereas that of the submersible net cage was 2 where 8 t t 2 figs 19 and 20 are diagrams for comparing the volume reduction coefficients of the floating net cage and submersible net cage in the double cage system the trends of the double cage system were similar to those exhibited in the single cage system with the exception that a comparatively greater increase in net cage volume reduction was exhibited in the submersible net cage than the net cages in the single cage system fig 21 26 show the 3 d deformation of the floating cage in the typhoon wave tests in the figures above the waves propagate to the right the figures present the instant position of the led lamps at three different instants times which are from the wave trough passing through the net cage to the wave crest passing through the net cage at three instants times 8 t t 4 8 t t 6 and 8 t t 8 most figures show the greater displacement was obtained in the middle part of the net in a vertical direction the phenomenon became more obvious under typhoon waves in cocurrent flow fig 27 shows a diagram for comparing the maximum mooring rope tension between the submersible and floating net cages in the typhoon wave tests the figure indicates that the mooring rope tension was greater in the waves in cocurrent flow tests than in the waves in countercurrent flow tests subsequently the wave only tests yielded the lowest mooring rope tension the motion of net cages will decay wave energy and reduce mooring rope tension the double cage system attenuated more energy and exhibited a lower maximum mooring rope tension compared with the single cage system the submersible net cage not only reduced the net cage deformation but also reduced the mooring rope tension another reason could be that the two cages experiences counteracting waves which partly cancels out the resulting mooring force 5 conclusion this study used a 3 d imaging system to improve the planar photography method for calculating net cage volume reduction the system comprised three cameras that captured images of 37 led lights affixed to net cage the images were processed by an algorithm to determine the 3 d coordinates of the led lights and these were employed to determine the volume of the net cage compared with previous methods the proposed method can more accurately estimate the deformation conditions of net cages referencing the net cage system of xiao liuqiu and various current monsoon wave and typhoon wave data the researchers conducted a series of tests on single cage and double cage systems by establishing system models at a reduced scale of 1 30 in the wave tank of the national sun yat sen university taiwan subsequently the cage system models were tested under the effects of currents waves waves in cocurrent flow and waves in countercurrent flow to determine the mooring rope tension and net cage deformation for each system under similar test conditions the currents imposed a significantly greater impact on the net cages than did the waves the net cages achieved the maximal deformation when the troughs passed through the net cage and the waves in concurrent flow caused greater deformation compared with the waves in countercurrent flow the test results of the double cage system indicate that the upstream net cage shielded the downstream net cage alleviating the net cage deformation in the downstream cage this shielding effect was particularly evident during the current tests the primary function of submersible net cages is to reduce the impact of waves however because the test conditions in this study resulted in waves imposing a less influence in causing deformation the effect that the submersible net cage had on improving the volume reduction coefficient was limited to approximately 5 however the submersible net cage reduced the deformation by up to 50 when considering only the deformation reduction ratio to analyze the instant position of the led lamps all results show that greater displacement was obtained in the middle part of the net in a vertical direction the phenomenon became more obvious under typhoon waves in cocurrent flow an analysis of the maximum tension shows that the tension of the mooring ropes in the waves in cocurrent flow tests was greater than that in the waves in countercurrent flow tests and the wave only tests yielded the lowest mooring rope tension the double cage system attenuated more energy and generated a lower maximum mooring rope tension compared with the single cage system in which the submersible net cage reduced both the net cage deformation and mooring rope tension the dynamics of net cages affected by waves and currents are extremely complex therefore the test results are only applicable under the conditions in the presents study changing the structure or dimensions of the net cages or including different hydrodynamic conditions would inevitably alter the test results future studies should consider applying the proposed technique based on the research model adopted in the present study furthermore researchers attempting to conduct numerical simulations to determine the dynamics of net cages can reference the numerical model established herein and subsequently verify their numerical models by using the measurement results of this study acknowledgments the authors acknowledge the support from pingtung county government and ministry of science and technology taiwan under the grant 106 2911 i 006 301 
23027,this paper aims to construct an active control system using an interceptor and to verify the performance through towing tests to improve seakeeping performance of a high speed planing vessel the full scale vessel is an unmanned surface vessel with a length of 8 m and the model ship is made with the scale ratio of 1 5 333 the interceptor servo unit is designed using the rack and pinion type an embedded control system is developed based on a single board computer the motion control algorithm is designed based on the differential control the performance of the designed system and is verified by the calm water test and the seakeeping test in seoul national university snu the trim and the rise of center of gravity tend to decrease as the interceptor stroke increase an improvement in the resistance by the interceptor is seen at the speed of less than froude number 1 16 the pitch motion is decreased by 41 3 in the regular wave and 32 4 in the irregular wave by the controllable interceptor system keywords high speed planing vessel interceptor active control calm water test regular wave test irregular wave test 1 introduction a planing vessel is relatively simple in shape and easy to estimate the performance compared to high speed vessels such as multi hull hydrofoil craft and hovercraft planing vessels has been used as patrol boats service crafts pilot boats coast guard vessels and small naval vessels for operation in more exposed areas karimi et al 2015 the planing vessel supports most of its weight by the hydrodynamic lift in high speed so it is known to have excessive trim and poor seakeeping performance appendages such as interceptor trim tab and transom wedge are adopted to improve the seakeeping performance the interceptor is a blade attached perpendicular to the stern which reduces the trim by increasing the pressure of the stern by intercepting the flow with the blade the effect of the interceptor on the hydrodynamic characteristics of a planing vessel has been confirmed by model tests and numerical analysis methods tsai and hwang 2004 conducted model tests to determine the effect of stern flap interceptor and integrated interceptor with stern flap on the resistance performance of high speed planning vessel model tests for patrol boats were conducted at national taiwan university and hamburg ship model basin hsmb test results showed that the resistance reduction effect is greatest between froude number fn 2 0 2 5 the integrated interceptor with stern flap was found to be more effective in reducing resistance than when using each appendage alone brizzolara and molini 2005 calculated the lift change on the hull bottom by the interceptor using computational fluid dynamics cfd day and cooper 2011 studied the effect of interceptor on the drag reduction of high performance sailing yachts the interceptor exhibited 10 18 resistance reduction over the speed range of 8 20 knots and the resistance reduction was larger than those achievable through trim changes by moving ballast longitudinally de luca and pensa 2011 investigated the effect of interceptors on the v shaped prismatic hull using cfd and towing tests various types of deadrise angle longitudinal center of gravity lcg and interceptor dimension had been studied it was confirmed that the deadrise angle had a strong influence on interceptor effectiveness karimi et al 2013 performed model tests for monohull and catamaran with the interceptor model tests for the 11 m monohull were performed at the sharif university of technology and model tests for the 18 m catamaran were conducted at the krylov shipbuilding research institute monohull and catamaran showed resistance reduction of 15 and 12 with the interceptor seo et al 2013 conducted model tests of a deep v catamaran for a combination of trim tab interceptor transom wedge and integrated trim tab and transom wedge in the towing tank at newcastle university the interceptor showed the greatest efficiency and showed a fuel reduction of 5 and a trim reduction of 1 2 at design speed mansoori and fernandes 2016 showed that the interceptor can control the porposing instability in high speed craft using cfd calculation results and they conducted research to prevent the unfit effect of interceptors through a combination of interceptor and trim tab mansoori and fernandes 2017 recently active control using controllable appendages has been studied haywood et al 1995 performed the motion modeling and control of high speed vessels the vertical motion and roll motion were controlled by the stern flap and the fin respectively adaptive controller which changes the control law after system identification si according to each operating condition was used kim and yamato 2004 designed the longitudinal motion controller of fully submerged hydrofoil to mitigate the unstable vertical motion in following sea linear quadratic regulator and kalman filter were used to construct the longitudinal motion control system xi and sun 2006 developed a nonlinear controller to mitigate the porposing instability of high speed planning vessels using controllable transom flap the controller was designed based on the feedback linearization and the performance of the controller was validated in simulation rijkens et al 2011 conducted the vertical motion modeling based on the model test data and controlled the vertical motion using a stern flap and an interceptor the controller was designed using proportional integral derivative pid control and the controller performance was validated through simulation karimi et al 2015 designed a vertical motion controller of planning boats using an optimal control technique in simulation it was confirmed that the pitch motion of the vessel is reduced by active control in head sea condition ertogan et al 2017 performed the si for surge and pitch motion of high speed craft to utilize in the controller design si with sea trial test data was carried out using linear model and artificial neural network ann and it was confirmed that si using ann is more effective choi et al 2018 designed a controller to control attitude of the ship by controllable stern interceptor in calm water as mentioned above studies on the effect of the fixed interceptor on high speed vessels are actively carried out however studies on active control techniques using controllable interceptor have been performed by a few researchers experimental studies on the active control effect using interceptor have been rarely conducted in this paper the effectiveness of the active control using the controllable interceptor is validated through the model tests the full scale vessel is a high speed planning vessel with a length of 8 m and the model ship is manufactured with the scale ratio of 1 5 333 the interceptor used on the full scale vessel is humphree x300 the width and stroke length of the interceptor are 300 mm and 50 mm respectively the interceptor dimension applied to the model ship is determined by the scale ratio the interceptor is driven by a servomotor the servo unit for converting the rotational motion of the servomotor into the linear motion of the interceptor is designed by a rack and pinion type the embedded controller determines the control input through the control algorithm using the measured information of ship motions the motion control algorithm is designed based on the differential control that determines the interceptor stroke by feeding back the pitch rate the model test is carried out in the snu towing tank the model test consist of calm water test seakeeping test in regular wave and in irregular wave calm water test results are compared with the full scale trial data the seakeeping test in regular wave is performed in the range of non dimensionalized wavelength λ l 2 to 5 a total of 11 tests are performed on irregular wave condition seakeeping test results with and without the motion control are compared to validate the active control system the remainder of this paper is structured as follows section 2 provides general information for the model test the controllable interceptor system is described in section 3 the model test results are shown in section 4 finally conclusions are provided in section 5 2 model test outline 2 1 model ship for this study seven hulls are developed to be used as a platform for an autonomous unmanned surface vehicle usv three deep v hull forms are initially developed and the resistance and the seakeeping performance of the hulls are determined by kim et al 2013 the 4th and 5th hull forms are designed to improve the resistance and the seakeeping performance the full scale vessel using the 5th hull form is constructed under the name aragon 1 the 6th and 7th hull forms are developed to improve the straight line stability and the maneuvering performance the 6th hull form is modified and the full scale veseel aragon 2 is constructed using the hull form the turning characteristic of the vessel is investigated by free running test kim and kim 2017a based on the accumulated experience the final hull has been designed and is now being constructed in the full scale the hull form used in this study is a modified 6th hull a 1 5 m model ship is constructed to estimate the seakeeping performance of the full scale vessel the main dimensions and photographs of the vehicle are shown in table 1 and fig 1 kim and kim 2017b 2 2 high speed towing system the model tests are carried out at snu towing tank the towing tank is 110 m long 8 m wide and 3 5 m deep the facility is equipped with a high speed carriage designed in truss structure the carriage can tow a model ship up to 10m s fig 2 shows the high speed towing carriage the high speed towing carriage is equipped with a towing device the towing device is designed to measure the heave and pitch and it constrains the surge the heave and pitch are measured by potentiometers and the resistance is measured by the strain gauge fig 3 is a schematic representation of the towing device 2 3 coordinate system the coordinate system used in this paper is shown in fig 4 the trim angle is denoted as τ η 3 and η 5 are the heave and pitch respectively η 3 is positive upward and η 5 is positive bow up h means the interceptor stroke i e interceptor height 3 interceptor control system 3 1 interceptor driving module the interceptor driving module refers to the integrated system of the interceptor the servomotor and the servo unit for converting the rotational motion of the servomotor into the linear motion of the interceptor the interceptor applied to the full scale vessel is humphree x300 with 300 mm width and 50 mm maximum stroke the interceptor dimension of the model ship is determined by the scale ratio between the model ship and the full scale vessel the servomotor is an electric motor used to control the interceptor stroke in this study highest hs700 is used to control the interceptor generally either cam or rack and pinion is used to convert rotational motion into linear motion if servo unit is designed based on cam type the interceptor driving module could be too thick to be installed in the model scale in this paper the servo unit is designed by rack and pinion as shown in fig 5 fig 6 shows the interceptor driving module attached to the model ship 3 2 embedded controller an embedded controller refers to a system equipped with a microprocessor for an effective control of a machine or electronic device the embedded controller receives the measured signal and generates it to the motion data to be used in the control algorithm the control algorithm determines the interceptor stroke using the motion data the embedded controller converts the servo motor angle to the interceptor stroke the process is represented by a block diagram as shown in fig 7 the embedded controller is shown in fig 8 and the main features are listed as follows based on beaglebone black bbb one built in inertia measurement unit imu two pulse width modulation pwm channels are provided for independent control of the servo motors two analog to digital conversion adc channels are provided to measure the ship motion by the potentiometer the bbb is a single board computer developed by texas instrument table 2 summarizes the specifications of bbb the sampling rate of the control system is 50 hz the fastest encounter wave frequency in the seakeeping test is 2 32 hz so it is considered that the sampling rate is sufficient to control the ship motion 3 3 control algorithm it is necessary to determine the control algorithm and feedback parameter to control the ship motion effectively this study chose the control algorithm in practical and realistic way to reduce the ship motion in waves in the ideal case it is appropriate to apply the multi input single output control algorithm because the heave motion and pitch motion of the ship are coupled however it is difficult to measure the heave motion accurately in real world so we decided to feedback only the pitch motion in the towing test the pitch motion can be accurately measured by the potentiometer mounted on the towing device when performing a free running test the pitch motion is measured by the inertial measurement unit imu the imu consists of the gyro and the accelerometer the euler angles are estimated by integrating the angular velocity and the angular acceleration which are measured by the gyro and accelerometer so there is a bias in the measured pitch angle if the measured motion error is large a proportional controller may not be appropriate in this study the active control algorithm is constructed using a differential controller as shown in eq 1 1 h h 0 u k d η 5 where h 0 is the initial interceptor stroke u is the ship speed k d is the control gain and η 5 is the pitch rate the initial interceptor stroke h 0 means the optimal interceptor stroke which shows the optimal resistance performance at a certain ship speed is determined based on the calm water test results in this study the units of interceptor stroke and pitch rate are percentage and degree respectively the control gain k d is determined by trial and errors based on the seakeeping test results the gain tuning method is described in section 4 2 4 towing tests in calm water and in head waves 4 1 calm water test the full scale trials are conducted in deachung lake south korea the model scale tests are carried out in snu towing tank the photographs of the trials are shown in fig 9 the trim rise of center of gravity cg and resistance of the model ship are measured by the towing test in various towing speeds and interceptor stroke conditions the full scale trials are performed by changing the engine revolution per minute rpm and interceptor stroke the test conditions are listed in table 3 fig 10 shows the model test results the resistance and the rise of cg are non dimensionalized by the weight and the draft at after perpendicular respectively the model scale vessel is in semi planing speed region at fn 0 58 1 16 and it shows pure planing behaviors above fn 1 16 the semi planing speed region means the transient speed region between low speed and pure planing speed kim and kim 2017a as the interceptor stroke increases the trim and the rise of cg tend to decrease the optimal interceptor stroke which exhibits optimal resistance performance varies with towing speeds the optimal interceptor strokes of the model scale vessel are listed in table 4 in the semi planing region the interceptor stabilizes the trim and it improves the hull resistance performance the interceptor causes the resistance to increase in the pure planing region it is considered that the increase of the wetted surface area due to the interceptor and the increase of the drag of the interceptor itself deteriorate the resistance performance the running trims are compared in fig 11 the full scale vessel generally has a larger trim than that of the model ship and the tendency becomes larger as the speed increases the model scale vessel is placed in the relatively lower reynolds numbers rather than the full scale vessel thus has a larger frictional resistance since the resistance of the planing vessel mainly affects the afterbody the relatively large frictional resistance on the model scale may cause additional bow down moments and it reduce the trim the running trim difference between full scale and model scale vessels decreases as the interceptor stroke increases this is because the effect of the additional bow down moment is reduced as the trim becomes smaller due to the interceptor fig 12 shows the speed of the full scale vessel according to the engine rpm similar to the model test results the interceptor improves the resistance performance in the semi planing region in the pure planing region the interceptor causes an increase in resistance the interceptor increases the vessel speed by an average of 7 5 in the semi planing region as suggested in this study it will be efficient to make a look up table of the optimal interceptor stroke for each engine rpm and use it for the vessel operation 4 2 seakeeping tests in regular head waves the regular wave tests are performed at fn 1 16 with and without the active control when the active control is not applied the interceptor stroke is fixed to 0 or 40 respectively three different control gains are applied to the regular wave tests the interceptor initial stroke h 0 u is set to be 40 because it show the best resistance performance at fn 1 16 the control gains are determined based on the regular wave test results without the active control let η 5 m a x be the maximum value of the pitch rate in the wave test the control gain k d is determined for each test result so that the sum of h 0 u and k d η 5 m a x equals to be 100 at first the active control test is performed with the smallest control gain and then the control gain is gradually increased to obtain the optimal control gain table 5 summarizes the wave test conditions the analysis of the wave test is performed by the curve fitting to deduct the motion amplitude and the mean value the amplitude means the response amplitude operator rao an example of the curve fitting result is shown in fig 13 the motion amplitude and mean value are shown in fig 14 the heave motion is non dimensionalized by the wave amplitude a and the pitch motion is non dimensionalized by using the wave number k and the wave amplitude a from the test results the wavelength of 3 5 l is confirmed as the resonance frequency of the vessel when the interceptor stroke is fixed to 40 the heave and pitch at the resonance frequency are reduced by 20 7 and 21 6 respectively the control gain that minimizes the motion at the resonance frequency is gain3 the heave and pitch are reduced by 33 4 and 41 3 by the active control with gain3 respectively in the case of gain2 and gain3 the magnitude of the control gain differs by about 32 but there is no significant difference in the motion response on the basis of the resonance frequency the motion amplitude is decreased due to the active control in the long wave while the motion amplitude is similar or slightly increased in the short wave the mean values of the motions are larger when the interceptor height is fixed at 0 than that of the other conditions it can be seen that the mean value of the motion when the active control is applied and when the interceptor stroke is fixed to 40 is almost the same this is because the interceptor initial stroke is set to 40 when performing active control tests the time histories of test results at the wavelength of 2 l and 3 5 l where the active control is ineffective and most effective are compared in fig 15 when the control gain1 is applied the controllable interceptor is not fully utilized the interceptor stroke with control gain2 and gain3 is saturated its maximum value in the wavelength condition 2 l since the control algorithm does not show a great effect in short waves in the wavelength 3 5 l condition the active controller with gain3 makes more effort to control the ship motion than the controller with gain2 but there is little difference on seakeeping performance it is expected that there will be no significant change in the test result even if the test is performed with much larger control gain 4 3 seakeeping tests in irregular head waves the irregular wave tests are carried out at fn 1 16 with and without the active control when the active control is not performed the interceptor stroke is fixed to 0 the gain2 which has the best seakeeping performance in regular wave is applied to the irregular wave tests ittc wave spectrum is used to generate the irregular wave the significant wave height is set to 77 mm and the modal period is set to 2 08 s the wave condition corresponds to sea state 3 on full scale due to the limitation of the towing tank length the time range that can be measured at the constant velocity is about 9 s the model test are conducted 11 timesby changing the time history of the irregular waves so that the model vessel could meet enough waves the time history of the motions in irregular waves are shown in fig 16 it seems that almost the same wave is applied for the both cases the mean values of the motions are much smaller when the active control is applied due to the initial interceptor stroke root mean square rms is used to compare the irregular wave test results quantitatively the rms values are compared in fig 17 there is little difference in rms values of the wave elevation rather the wave elevation is slightly larger when the active control is performed when the active control is applied the rms value decreases by 32 4 for the pitch motion and by 12 1 for the heave motion as a result of the irregular wave test it is expected that the seakeeping performance will be improved by applying the active control system in real environment 5 conclusion in this paper an experimental study on the controllable interceptor is conducted to improve the seakeeping performance of the high speed vessel the model ship is constructed with the scale ratio of 1 5 333 the interceptor driving unit consists of an interceptor a servo motor and a servo unit the servo unit is designed by a rack and pinion type the embedded controller is designed to process measurement signals the control algorithm is designed based on the differential control the calm water tests and the seakeeping tests are conducted by a high speed towing system of snu the following conclusions can be drawn 5 1 calm water test as the interceptor stroke increases the trim and rise of cg tend to decrease the interceptor can improve the visibility of a ship the interceptor can improve the resistance performance in the semi planing region the interceptor can reduce the fuel consumption in calm water it is confirmed that the tendency of the trim and the rise of cg by interceptor between model scale and full scale is generally in good agreement 5 2 seakeeping test when active control is applied the pitch and heave at the resonance frequency are reduced by up to 41 3 and 33 4 respectively the change in the control efficiency of the differential controller is insignificant when the magnitude of the control gain is above the certain value when active control is applied the pitch motion rms is reduced by 32 4 and the heave motion rms is reduced by 12 1 in irregular wave the active control can improve the seakeeping performance of a ship this study has the following limitations first the seakeeping test is conducted only for the design speed instead of performing the test in various speed conditions we decided to conduct the experiment with various waves and control conditions at the design speed the active control performance in different speed conditions cannot be guaranteed because the performance of the derivative control algorithm will vary depending on the vessel speed in order to design more universal and sophisticated controller it remains a further study second the active controller performance in waves is verified only by the model scale test in the towing tank the irregular wave tests using the ittc wave spectrum are conducted to verify the control performance in the nearest condition to real sea however the performance can be deteriorated in the real environment for further research we plan to perform the motion control and the coordinate turning of the full scale vessel acknowledgements this research was carried out under a project titled development of multi purpose autonomous unmanned surface vehicle 8 8 pms3870 funded by the ministry of oceans and fisheries republic of korea and authors would like to thank prof key pyo rhee who is an emeritus professor in seoul national university has provided many guidance for this research 
23027,this paper aims to construct an active control system using an interceptor and to verify the performance through towing tests to improve seakeeping performance of a high speed planing vessel the full scale vessel is an unmanned surface vessel with a length of 8 m and the model ship is made with the scale ratio of 1 5 333 the interceptor servo unit is designed using the rack and pinion type an embedded control system is developed based on a single board computer the motion control algorithm is designed based on the differential control the performance of the designed system and is verified by the calm water test and the seakeeping test in seoul national university snu the trim and the rise of center of gravity tend to decrease as the interceptor stroke increase an improvement in the resistance by the interceptor is seen at the speed of less than froude number 1 16 the pitch motion is decreased by 41 3 in the regular wave and 32 4 in the irregular wave by the controllable interceptor system keywords high speed planing vessel interceptor active control calm water test regular wave test irregular wave test 1 introduction a planing vessel is relatively simple in shape and easy to estimate the performance compared to high speed vessels such as multi hull hydrofoil craft and hovercraft planing vessels has been used as patrol boats service crafts pilot boats coast guard vessels and small naval vessels for operation in more exposed areas karimi et al 2015 the planing vessel supports most of its weight by the hydrodynamic lift in high speed so it is known to have excessive trim and poor seakeeping performance appendages such as interceptor trim tab and transom wedge are adopted to improve the seakeeping performance the interceptor is a blade attached perpendicular to the stern which reduces the trim by increasing the pressure of the stern by intercepting the flow with the blade the effect of the interceptor on the hydrodynamic characteristics of a planing vessel has been confirmed by model tests and numerical analysis methods tsai and hwang 2004 conducted model tests to determine the effect of stern flap interceptor and integrated interceptor with stern flap on the resistance performance of high speed planning vessel model tests for patrol boats were conducted at national taiwan university and hamburg ship model basin hsmb test results showed that the resistance reduction effect is greatest between froude number fn 2 0 2 5 the integrated interceptor with stern flap was found to be more effective in reducing resistance than when using each appendage alone brizzolara and molini 2005 calculated the lift change on the hull bottom by the interceptor using computational fluid dynamics cfd day and cooper 2011 studied the effect of interceptor on the drag reduction of high performance sailing yachts the interceptor exhibited 10 18 resistance reduction over the speed range of 8 20 knots and the resistance reduction was larger than those achievable through trim changes by moving ballast longitudinally de luca and pensa 2011 investigated the effect of interceptors on the v shaped prismatic hull using cfd and towing tests various types of deadrise angle longitudinal center of gravity lcg and interceptor dimension had been studied it was confirmed that the deadrise angle had a strong influence on interceptor effectiveness karimi et al 2013 performed model tests for monohull and catamaran with the interceptor model tests for the 11 m monohull were performed at the sharif university of technology and model tests for the 18 m catamaran were conducted at the krylov shipbuilding research institute monohull and catamaran showed resistance reduction of 15 and 12 with the interceptor seo et al 2013 conducted model tests of a deep v catamaran for a combination of trim tab interceptor transom wedge and integrated trim tab and transom wedge in the towing tank at newcastle university the interceptor showed the greatest efficiency and showed a fuel reduction of 5 and a trim reduction of 1 2 at design speed mansoori and fernandes 2016 showed that the interceptor can control the porposing instability in high speed craft using cfd calculation results and they conducted research to prevent the unfit effect of interceptors through a combination of interceptor and trim tab mansoori and fernandes 2017 recently active control using controllable appendages has been studied haywood et al 1995 performed the motion modeling and control of high speed vessels the vertical motion and roll motion were controlled by the stern flap and the fin respectively adaptive controller which changes the control law after system identification si according to each operating condition was used kim and yamato 2004 designed the longitudinal motion controller of fully submerged hydrofoil to mitigate the unstable vertical motion in following sea linear quadratic regulator and kalman filter were used to construct the longitudinal motion control system xi and sun 2006 developed a nonlinear controller to mitigate the porposing instability of high speed planning vessels using controllable transom flap the controller was designed based on the feedback linearization and the performance of the controller was validated in simulation rijkens et al 2011 conducted the vertical motion modeling based on the model test data and controlled the vertical motion using a stern flap and an interceptor the controller was designed using proportional integral derivative pid control and the controller performance was validated through simulation karimi et al 2015 designed a vertical motion controller of planning boats using an optimal control technique in simulation it was confirmed that the pitch motion of the vessel is reduced by active control in head sea condition ertogan et al 2017 performed the si for surge and pitch motion of high speed craft to utilize in the controller design si with sea trial test data was carried out using linear model and artificial neural network ann and it was confirmed that si using ann is more effective choi et al 2018 designed a controller to control attitude of the ship by controllable stern interceptor in calm water as mentioned above studies on the effect of the fixed interceptor on high speed vessels are actively carried out however studies on active control techniques using controllable interceptor have been performed by a few researchers experimental studies on the active control effect using interceptor have been rarely conducted in this paper the effectiveness of the active control using the controllable interceptor is validated through the model tests the full scale vessel is a high speed planning vessel with a length of 8 m and the model ship is manufactured with the scale ratio of 1 5 333 the interceptor used on the full scale vessel is humphree x300 the width and stroke length of the interceptor are 300 mm and 50 mm respectively the interceptor dimension applied to the model ship is determined by the scale ratio the interceptor is driven by a servomotor the servo unit for converting the rotational motion of the servomotor into the linear motion of the interceptor is designed by a rack and pinion type the embedded controller determines the control input through the control algorithm using the measured information of ship motions the motion control algorithm is designed based on the differential control that determines the interceptor stroke by feeding back the pitch rate the model test is carried out in the snu towing tank the model test consist of calm water test seakeeping test in regular wave and in irregular wave calm water test results are compared with the full scale trial data the seakeeping test in regular wave is performed in the range of non dimensionalized wavelength λ l 2 to 5 a total of 11 tests are performed on irregular wave condition seakeeping test results with and without the motion control are compared to validate the active control system the remainder of this paper is structured as follows section 2 provides general information for the model test the controllable interceptor system is described in section 3 the model test results are shown in section 4 finally conclusions are provided in section 5 2 model test outline 2 1 model ship for this study seven hulls are developed to be used as a platform for an autonomous unmanned surface vehicle usv three deep v hull forms are initially developed and the resistance and the seakeeping performance of the hulls are determined by kim et al 2013 the 4th and 5th hull forms are designed to improve the resistance and the seakeeping performance the full scale vessel using the 5th hull form is constructed under the name aragon 1 the 6th and 7th hull forms are developed to improve the straight line stability and the maneuvering performance the 6th hull form is modified and the full scale veseel aragon 2 is constructed using the hull form the turning characteristic of the vessel is investigated by free running test kim and kim 2017a based on the accumulated experience the final hull has been designed and is now being constructed in the full scale the hull form used in this study is a modified 6th hull a 1 5 m model ship is constructed to estimate the seakeeping performance of the full scale vessel the main dimensions and photographs of the vehicle are shown in table 1 and fig 1 kim and kim 2017b 2 2 high speed towing system the model tests are carried out at snu towing tank the towing tank is 110 m long 8 m wide and 3 5 m deep the facility is equipped with a high speed carriage designed in truss structure the carriage can tow a model ship up to 10m s fig 2 shows the high speed towing carriage the high speed towing carriage is equipped with a towing device the towing device is designed to measure the heave and pitch and it constrains the surge the heave and pitch are measured by potentiometers and the resistance is measured by the strain gauge fig 3 is a schematic representation of the towing device 2 3 coordinate system the coordinate system used in this paper is shown in fig 4 the trim angle is denoted as τ η 3 and η 5 are the heave and pitch respectively η 3 is positive upward and η 5 is positive bow up h means the interceptor stroke i e interceptor height 3 interceptor control system 3 1 interceptor driving module the interceptor driving module refers to the integrated system of the interceptor the servomotor and the servo unit for converting the rotational motion of the servomotor into the linear motion of the interceptor the interceptor applied to the full scale vessel is humphree x300 with 300 mm width and 50 mm maximum stroke the interceptor dimension of the model ship is determined by the scale ratio between the model ship and the full scale vessel the servomotor is an electric motor used to control the interceptor stroke in this study highest hs700 is used to control the interceptor generally either cam or rack and pinion is used to convert rotational motion into linear motion if servo unit is designed based on cam type the interceptor driving module could be too thick to be installed in the model scale in this paper the servo unit is designed by rack and pinion as shown in fig 5 fig 6 shows the interceptor driving module attached to the model ship 3 2 embedded controller an embedded controller refers to a system equipped with a microprocessor for an effective control of a machine or electronic device the embedded controller receives the measured signal and generates it to the motion data to be used in the control algorithm the control algorithm determines the interceptor stroke using the motion data the embedded controller converts the servo motor angle to the interceptor stroke the process is represented by a block diagram as shown in fig 7 the embedded controller is shown in fig 8 and the main features are listed as follows based on beaglebone black bbb one built in inertia measurement unit imu two pulse width modulation pwm channels are provided for independent control of the servo motors two analog to digital conversion adc channels are provided to measure the ship motion by the potentiometer the bbb is a single board computer developed by texas instrument table 2 summarizes the specifications of bbb the sampling rate of the control system is 50 hz the fastest encounter wave frequency in the seakeeping test is 2 32 hz so it is considered that the sampling rate is sufficient to control the ship motion 3 3 control algorithm it is necessary to determine the control algorithm and feedback parameter to control the ship motion effectively this study chose the control algorithm in practical and realistic way to reduce the ship motion in waves in the ideal case it is appropriate to apply the multi input single output control algorithm because the heave motion and pitch motion of the ship are coupled however it is difficult to measure the heave motion accurately in real world so we decided to feedback only the pitch motion in the towing test the pitch motion can be accurately measured by the potentiometer mounted on the towing device when performing a free running test the pitch motion is measured by the inertial measurement unit imu the imu consists of the gyro and the accelerometer the euler angles are estimated by integrating the angular velocity and the angular acceleration which are measured by the gyro and accelerometer so there is a bias in the measured pitch angle if the measured motion error is large a proportional controller may not be appropriate in this study the active control algorithm is constructed using a differential controller as shown in eq 1 1 h h 0 u k d η 5 where h 0 is the initial interceptor stroke u is the ship speed k d is the control gain and η 5 is the pitch rate the initial interceptor stroke h 0 means the optimal interceptor stroke which shows the optimal resistance performance at a certain ship speed is determined based on the calm water test results in this study the units of interceptor stroke and pitch rate are percentage and degree respectively the control gain k d is determined by trial and errors based on the seakeeping test results the gain tuning method is described in section 4 2 4 towing tests in calm water and in head waves 4 1 calm water test the full scale trials are conducted in deachung lake south korea the model scale tests are carried out in snu towing tank the photographs of the trials are shown in fig 9 the trim rise of center of gravity cg and resistance of the model ship are measured by the towing test in various towing speeds and interceptor stroke conditions the full scale trials are performed by changing the engine revolution per minute rpm and interceptor stroke the test conditions are listed in table 3 fig 10 shows the model test results the resistance and the rise of cg are non dimensionalized by the weight and the draft at after perpendicular respectively the model scale vessel is in semi planing speed region at fn 0 58 1 16 and it shows pure planing behaviors above fn 1 16 the semi planing speed region means the transient speed region between low speed and pure planing speed kim and kim 2017a as the interceptor stroke increases the trim and the rise of cg tend to decrease the optimal interceptor stroke which exhibits optimal resistance performance varies with towing speeds the optimal interceptor strokes of the model scale vessel are listed in table 4 in the semi planing region the interceptor stabilizes the trim and it improves the hull resistance performance the interceptor causes the resistance to increase in the pure planing region it is considered that the increase of the wetted surface area due to the interceptor and the increase of the drag of the interceptor itself deteriorate the resistance performance the running trims are compared in fig 11 the full scale vessel generally has a larger trim than that of the model ship and the tendency becomes larger as the speed increases the model scale vessel is placed in the relatively lower reynolds numbers rather than the full scale vessel thus has a larger frictional resistance since the resistance of the planing vessel mainly affects the afterbody the relatively large frictional resistance on the model scale may cause additional bow down moments and it reduce the trim the running trim difference between full scale and model scale vessels decreases as the interceptor stroke increases this is because the effect of the additional bow down moment is reduced as the trim becomes smaller due to the interceptor fig 12 shows the speed of the full scale vessel according to the engine rpm similar to the model test results the interceptor improves the resistance performance in the semi planing region in the pure planing region the interceptor causes an increase in resistance the interceptor increases the vessel speed by an average of 7 5 in the semi planing region as suggested in this study it will be efficient to make a look up table of the optimal interceptor stroke for each engine rpm and use it for the vessel operation 4 2 seakeeping tests in regular head waves the regular wave tests are performed at fn 1 16 with and without the active control when the active control is not applied the interceptor stroke is fixed to 0 or 40 respectively three different control gains are applied to the regular wave tests the interceptor initial stroke h 0 u is set to be 40 because it show the best resistance performance at fn 1 16 the control gains are determined based on the regular wave test results without the active control let η 5 m a x be the maximum value of the pitch rate in the wave test the control gain k d is determined for each test result so that the sum of h 0 u and k d η 5 m a x equals to be 100 at first the active control test is performed with the smallest control gain and then the control gain is gradually increased to obtain the optimal control gain table 5 summarizes the wave test conditions the analysis of the wave test is performed by the curve fitting to deduct the motion amplitude and the mean value the amplitude means the response amplitude operator rao an example of the curve fitting result is shown in fig 13 the motion amplitude and mean value are shown in fig 14 the heave motion is non dimensionalized by the wave amplitude a and the pitch motion is non dimensionalized by using the wave number k and the wave amplitude a from the test results the wavelength of 3 5 l is confirmed as the resonance frequency of the vessel when the interceptor stroke is fixed to 40 the heave and pitch at the resonance frequency are reduced by 20 7 and 21 6 respectively the control gain that minimizes the motion at the resonance frequency is gain3 the heave and pitch are reduced by 33 4 and 41 3 by the active control with gain3 respectively in the case of gain2 and gain3 the magnitude of the control gain differs by about 32 but there is no significant difference in the motion response on the basis of the resonance frequency the motion amplitude is decreased due to the active control in the long wave while the motion amplitude is similar or slightly increased in the short wave the mean values of the motions are larger when the interceptor height is fixed at 0 than that of the other conditions it can be seen that the mean value of the motion when the active control is applied and when the interceptor stroke is fixed to 40 is almost the same this is because the interceptor initial stroke is set to 40 when performing active control tests the time histories of test results at the wavelength of 2 l and 3 5 l where the active control is ineffective and most effective are compared in fig 15 when the control gain1 is applied the controllable interceptor is not fully utilized the interceptor stroke with control gain2 and gain3 is saturated its maximum value in the wavelength condition 2 l since the control algorithm does not show a great effect in short waves in the wavelength 3 5 l condition the active controller with gain3 makes more effort to control the ship motion than the controller with gain2 but there is little difference on seakeeping performance it is expected that there will be no significant change in the test result even if the test is performed with much larger control gain 4 3 seakeeping tests in irregular head waves the irregular wave tests are carried out at fn 1 16 with and without the active control when the active control is not performed the interceptor stroke is fixed to 0 the gain2 which has the best seakeeping performance in regular wave is applied to the irregular wave tests ittc wave spectrum is used to generate the irregular wave the significant wave height is set to 77 mm and the modal period is set to 2 08 s the wave condition corresponds to sea state 3 on full scale due to the limitation of the towing tank length the time range that can be measured at the constant velocity is about 9 s the model test are conducted 11 timesby changing the time history of the irregular waves so that the model vessel could meet enough waves the time history of the motions in irregular waves are shown in fig 16 it seems that almost the same wave is applied for the both cases the mean values of the motions are much smaller when the active control is applied due to the initial interceptor stroke root mean square rms is used to compare the irregular wave test results quantitatively the rms values are compared in fig 17 there is little difference in rms values of the wave elevation rather the wave elevation is slightly larger when the active control is performed when the active control is applied the rms value decreases by 32 4 for the pitch motion and by 12 1 for the heave motion as a result of the irregular wave test it is expected that the seakeeping performance will be improved by applying the active control system in real environment 5 conclusion in this paper an experimental study on the controllable interceptor is conducted to improve the seakeeping performance of the high speed vessel the model ship is constructed with the scale ratio of 1 5 333 the interceptor driving unit consists of an interceptor a servo motor and a servo unit the servo unit is designed by a rack and pinion type the embedded controller is designed to process measurement signals the control algorithm is designed based on the differential control the calm water tests and the seakeeping tests are conducted by a high speed towing system of snu the following conclusions can be drawn 5 1 calm water test as the interceptor stroke increases the trim and rise of cg tend to decrease the interceptor can improve the visibility of a ship the interceptor can improve the resistance performance in the semi planing region the interceptor can reduce the fuel consumption in calm water it is confirmed that the tendency of the trim and the rise of cg by interceptor between model scale and full scale is generally in good agreement 5 2 seakeeping test when active control is applied the pitch and heave at the resonance frequency are reduced by up to 41 3 and 33 4 respectively the change in the control efficiency of the differential controller is insignificant when the magnitude of the control gain is above the certain value when active control is applied the pitch motion rms is reduced by 32 4 and the heave motion rms is reduced by 12 1 in irregular wave the active control can improve the seakeeping performance of a ship this study has the following limitations first the seakeeping test is conducted only for the design speed instead of performing the test in various speed conditions we decided to conduct the experiment with various waves and control conditions at the design speed the active control performance in different speed conditions cannot be guaranteed because the performance of the derivative control algorithm will vary depending on the vessel speed in order to design more universal and sophisticated controller it remains a further study second the active controller performance in waves is verified only by the model scale test in the towing tank the irregular wave tests using the ittc wave spectrum are conducted to verify the control performance in the nearest condition to real sea however the performance can be deteriorated in the real environment for further research we plan to perform the motion control and the coordinate turning of the full scale vessel acknowledgements this research was carried out under a project titled development of multi purpose autonomous unmanned surface vehicle 8 8 pms3870 funded by the ministry of oceans and fisheries republic of korea and authors would like to thank prof key pyo rhee who is an emeritus professor in seoul national university has provided many guidance for this research 
23028,this article presents a step by step procedure for estimation of the joint distribution of n year maximum significant wave height individual wave and crest heights and total water level accommodating the effects of directional and seasonal variation surge and tide the approach is based on non stationary extreme value analysis of peaks over threshold incorporating careful uncertainty quantification and is illustrated for a north sea location using hindcast data the article further provides a brief overview of the development of a regulatory framework for specification of design conditions for total water level over the past half century keywords metocean design extreme total extreme water level non stationary uncertainty 1 introduction extremes of wave height and total water level twl are key parameters for the design of fixed platforms in the offshore environment previous papers e g feld et al 2015 randell et al 2015 have described an approach to non stationary extreme value analysis henceforth called ceva abbreviating covariate extreme value analysis for estimating n year maxima of significant wave height individual wave and crest heights taking into account the variation in seasonal and directional covariates waves that impact the topsides and supporting beams of offshore structures are particularly significant since they result in a rapid increase in loading with inundation level extremes of twl namely the combination of wave crest and still water level swl itself the sum of tide and storm surge can cause bigger loads still and are often of greater importance to the structural engineer than crest height alone this paper builds on the approach described in previous papers to also include swl effects in a manner which is consistent with the wave modelling methodology and which preserves the relationships between waves storm surge and tidal levels that are observed within storms the underlying approach to the estimation of the wave component of twl is based upon modelling storm peak events on a directional seasonal covariate domain described in outline in section 4 whilst this approach captures the storm peaks appropriately in order to determine the maximum twl within each storm it is necessary to model more than just the peak sea state this is due to both the random nature of large individual wave crests within sea states near to the peak and also to the characteristics of the inter relationships between waves tide and surge both of these effects may result in the highest water level during a storm occurring at a time of lower significant wave height h s but higher tide and or surge in order to represent the total water level variability throughout a storm event therefore representative storm trajectories are derived which aim to capture the variability of all of the key wave section 5 and surge section 6 parameters as the storm develops both temporally and directionally these trajectories can then be appropriately re scaled in order to match the severity of storm peaks randomly selected from the fitted extremal model to estimate maximum twl in a storm all these modelling components i e storm peak modelling wave and surge storm trajectory selection and tidal variations need to be brought together and combined with the short term variability of individual crest heights in this way for each simulated sea state in each storm event individual maximum crests are randomly sampled and added to appropriately selected surge and tidal level this process explained in section 7 is then repeated for all randomly simulated storms over the return period of interest for each period of simulation the maximum twl for each direction and day of year are retained this allows extreme values of twl for any directional seasonal combination to be subsequently extracted and these can then further be aggregated to derive all year and omnidirectional extremes in a statistically consistent manner this final simulation is described in section 8 this modelling procedure allows all extremes that may be required for design and operational purposes to be derived in a single analysis for example seasonal criteria for installation activities are readily available or a re alignment of a structure during the design phase can be easily accommodated by simply aggregating across different sets of directional sectors throughout this whole process uncertainties are propagated into the estimated distribution of the n year maximum twl using the methods described these uncertainties are captured by using bootstrapping of the original storm peak data a range of wave and surge storm trajectory shapes different tidal phases a range of extreme value thresholds random sampling of h s and random sampling of individual crest heights 2 background for the offshore environment we assume that twl is defined as the sum of individual crest surge and tidal components the importance of twl has been explored particularly within two areas of study a coastal flooding and over topping and b wave impact on marine bottom founded structures in the first of these annual maxima from long time series were traditionally used as the basis for extrapolating to long return periods but based on swl i e combined tide and surge this approach means however that many significant surge events will be excluded if they happen to occur at low tide and it also does not make the best use of the available data since only a single event per year is included the combined effects of decoupled tide and surge were modelled in pugh and vassie 1978 by the joint probability method jpm where non parametric probability distributions for both were derived and assuming independence recombined statistically to obtain the statistics of overall swl in order to extrapolate to longer return periods an empirically selected log distribution was fitted to the tail of positive surges the approach made better use of the data by using all hourly samples but in so doing introduced a data set which consisted of dependent samples this introduced a bias into the estimate of the non exceedance probability associated with given return periods despite the shortcomings of the method it has been widely applied although the method was subsequently revised by tawn 1992 to de cluster the surge data into independent events to smooth the observed magnitudes and to fit a more statistically justified generalised pareto distribution gpd to the tail of the surge distribution an empirical approach for adjusting the surge distribution for different tidal levels was also presented for application to those shallow locations where this was relevant hawkes et al 2002 proposed a joint model for water level wave height wave steepness and their dependence an extension of the jpm for application to cases with more than two variables was described by liu et al 2010 in the direct jpm in which a multi dimensional histogram was set up to include wave run up in addition to tide and surge in this approach the characteristics of dependence between the three were explicitly captured by using an empirical non parametric method although the details used for extrapolation beyond the length of the data set are unclear shevchenko and ivelskaya 2015 broadened and generalised the original jpm to include a description of seasonal variability in mean sea level within the tidal harmonics and used the gumbel distribution to extrapolate both surge and tsunami levels to longer return periods however any joint probability characteristics between the parameters were not explicitly modelled in this approach more sophisticated modelling approaches to joint probability in general have been developed by heffernan and tawn 2004 which describe the relationship of variable y conditional on the value of another extreme variable x following transformation to a standard typically laplace marginal scale 1 y x x a x x b w where a 1 1 and b 1 are fitted parameters and w represents a residual process with unknown distribution assumed gaussian for fitting only typically a generalised pareto distribution gpd is used to fit each marginal distribution of peaks over threshold the approach can be extended to any number of variables in which each is conditional upon the value of a single conditioning variable that exceeds a certain extremal threshold gouldby et al 2014 applied this approach to the study of coastal over topping and overflow which included swl and wave components once the model was fitted a monte carlo approach was used in which a single parameter was sampled randomly and the relationship presented above was used including sampling from the distribution of residuals w to determine associated values of other parameters in order to model for long return periods in terms of setting the deck height of offshore structures and the determination of extreme twl in the north sea the design recipe in the 1970s and early 80s was based on a 1 5 m clearance over and above a combination of the 50 year crest height the 50 year surge and the mean high water spring mhws tide uk hmso 1974 during the 1980s the key return period was increased to 100 years and some simple allowance was given for joint probabilities between tide and surge on the assumption of two gaussian parameters between which a correlation coefficient could be defined uk department of energy 1990 by 1998 the uk health and safety executive dictated that a structure needed to withstand the 10 000 year twl with no additional air gap but no clear guidance was given as to how the twl should be derived at this time therefore certain approximate methods were developed within the industry based on empirically derived relationships founded on considerations such as storm length versus length of tidal cycle and rules of thumb relating crest heights from one return period to another one such method for the 10 000 year twl twl 10000 which was adopted by shell and bp in 2000 was the so called interim method 2 twl 10000 c 1000 3 4 mhw msl s 1 where mhw is the mean tidal high water s 1 is the 1 year positive surge c 1000 is the 1000 year crest height and msl is mean sea level a second approach was described in leggett et al 2007 for the central cns and southern sns north sea 3 cns twl 10000 c 10000 msl s 1 sns twl 10000 c 10000 msl s 3 where s 3 is the 3 year positive surge and where subscript 10000 refers to the 10 000 year value of the corresponding quantities however this approach based on consideration of only selected combinations of crest height tide and surge rather than a general investigation of the worst possible combinations was not generically applicable iso19902 2007 presented a range of twl values for an offshore location utilizing relationships between tide surge and crest and this was based on the approach set out by uk department of energy 1990 it provided limiting cases for twl based on either complete correlation between surge and crest and the completely uncorrelated case the range provided for twl was 4 a 2 s 2 t 2 a s 2 t 2 where a is the extreme crest height s is the extreme surge and t is the maximum elevation of tide relative to mean sea level iso19901 1 2005 adopted the tromans and vanderschuren 1995 storm based approach for the determination of individual wave and crest height return values based on the statistical combination of the long term distribution of storm maxima with the short term distribution of individual waves this correctly accounts for the fact that the largest waves in a storm do not necessarily come from the most severe sea state and that the largest waves in a given return period do not necessarily come from the storms with the largest h s however there was still no further guidance as to how to combine these crest heights with swl variations in uk health and satefy executive 2009 a monte carlo approach was described to combine the approach of tromans and vanderschuren 1995 for individual wave crests with a representation of the joint probabilities of waves and surge again though a simplistic approach was adopted in which once a randomly selected h s was selected the surge of the same percentile was associated with the sea state such that effectively a perfect correlation was assumed between waves and surge but a random tide was included an additional empirical correction factor was then derived from measured data to correct for the degree of correlation we note the work of callaghan et al 2008 serafin and ruggiero 2014 wahl et al 2017 and others on simulating wave environments for estimation of erosion and over topping previous papers by some of the current authors have developed the monte carlo approach e g ewans and jonathan 2008 feld et al 2015 in which the approach of tromans and vanderschuren 1995 was adopted for the crests but which allowed for varying characteristics by season and direction in order to better capture the changing statistical populations through the year and by direction in order to derive twl however a method for combining these crests with appropriate tides and surges is required and this is the substance of the current paper 3 example data set for illustrative purposes a data set from a location in the western half of the southern north sea in a water depth of around 20 m has been chosen the water level data consisted of hourly measurements at an offshore platform between october 2006 and december 2016 and the wave data came from the nora10 norwegian reanalysis 10 km wave hindcast model reistad et al 2011 wam third generation prognostic wave model wamdi 1988 hindcast grid point closest to the measurement location and covered the same period a representation of the distribution of h s by season and direction is shown in fig 1 showing the significance of the covariates in determining the severity of any particular directional seasonal combination in this plot all the data points are shown as grey dots and the storm peaks are shown as black dots direction is defined as the direction from which storms propagate measured clockwise from north tides were separated from storm surges by harmonic analysis using t tide software pawlowicz et al 2002 of hourly mean original water level data with residual level referred to as surge fig 2 a shows the variability of surge with season with black dots representing all the observed data points again the seasonality is obvious a similar plot is shown for tide in fig 2 b where the small equinoctial effect on tides can be seen the relationship between tide and surge is shown in fig 2 c in which the relationship appears to be random in nature in an overall sense although there appears to be a slight tendency for the highest surges to have occurred at the extremes of tide either high or low fig 2 d illustrates the overall relationship between h s and surge in this case the largest surge events are associated with higher h s values but the scatter indicates that a large h s does not necessarily imply that a large surge will occur simultaneously for definiteness wave height is defined as the difference between the maximum and minimum values of the ocean surface between consecutive down crossings of mean water level crest height is defined as the maximum value of the ocean surface between an up crossing and subsequent down crossing of the mean water level 4 storm peak modelling the details of this approach have been described in previous papers e g feld et al 2015 briefly 1 a set of directional seasonal covariate bins within which conditions are considered homogeneous is defined binning reduces the computational complexity of the covariate description and hence the complexity of the spline calculations to estimate extreme value ev models typically this is based on 32 directional bins 11 25 width and 24 seasonal bins approximately 2 weeks long giving a total of 768 across the covariate domain 2 a threshold q for isolation of storm event is defined using a quantile of sea state h s per directional seasonal sector this threshold is typically chosen to correspond to a quantile with constant non exceedance probability of between approximately 0 5 and 0 75 this produces a sufficient number of storm events whilst keeping the storm length to a manageable size a quantile is better than a fixed storm threshold since this ensures that calmer seasons and directions are adequately represented in the overall model and see e g northrop and jonathan 2011 the peak of the storm event is captured and characterised by the storm peak h s referred to as h s s p for definiteness where needed zero crossing wave period t z spectral mean period t 01 direction and day of year note that t 01 is defined as m 0 m 1 where m 0 is the zeroth moment and m 1 the first moment of the wave spectrum t 01 is a key parameter in the forristall crest height probability distribution 3 for each storm the whole period of exceedance of storm threshold q is also added to the set of historical storm trajectories which can then be associated with synthesized storm peaks see section 5 4 a set of viable ev thresholds ψ for storm peaks is chosen corresponding to quantiles with non exceedance probabilities per covariate bin within some reasonable interval above ψ occurrences of storm peaks are assumed to follow a poisson process with mean rate ρ and storm severity described by a generalised pareto model with scale parameter σ and shape parameter ξ 5 the variation of model parameters ψ ρ σ and ξ with covariates is described using linear combinations of cubic b spline functions or tensor products thereof defined on the covariate domain each spline function has a fixed width but can vary in height the extent to which spline function height is allowed to vary between adjacent splines is determined by penalty terms and an optimal smoothness chosen using cross validated penalised maximum likelihood estimation the intention is that spline smoothness is chosen so that the resulting variation in model parameters reflects the underlying natural variability present whilst preventing over fitting a conceptual illustration unrelated to the current application of the effect of high and low penalty cases is shown in fig 3 in the left hand case the variability of heights between adjacent splines is much more constrained than the right hand case a penalised likelihood approach is also used to estimate covariate dependent ev thresholds ψ in 4 above 6 the procedure for partitioning the covariate domain is explained in e g ross et al 2017 we choose to partition the domain into 32 directional bins of width 11 25 and 24 seasonal bins of width 15 seasonal days from a year with 360 seasonal days we judge this resolution to be sufficient to capture the main directional and seasonal variation of storm peak significant wave height the extreme value model therefore uses a total of 768 32 24 covariate combinations for extreme value analysis we assume that neighbouring covariate bins exhibit similar behaviour this is enforced by penalising the local variation of extreme value parameter estimates we choose the penalty so that the resulting extreme value model has optimal predictive performance in this sense if there was no predictive evidence in the data related to covariate variation the extreme value model would be extremely stiff corresponding effectively to one covariate bin in this case there would be one bin and 1156 peaks in it for the current application further the effective number of covariate degrees of freedom used in the analysis can vary from one stiff to 768 flexible the actual effective number is chosen to maximise predictive performance using cross validation the optimal choice of parameter roughness penality is discussed more fully in section 6 and illustrated in fig 6 all modelling is performed for 768 covariate combinations for presentation of results concerning the distribution of n year maxima we can combine covariate bins to present exactly the results that the engineer finds most useful in this work we present estimates e g fig 11 or fig 12 discussed in section 8 on 8 directional octants and 12 seasonal months however we can provide estimates of extreme environments using any combinations of covariate bins of interest to the engineer once the storm peak modelling has been completed a monte carlo approach can then be used to simulate a set of random storm peaks for any given return period that reflects the underlying statistical characteristics of the data to capture uncertainties in this process the original data can also be bootstrapped and the whole modelling process repeated 5 derivation of storm wave trajectory it is not sufficient to just base the analysis on storm peaks there are two main reasons for this a an extreme value of twl in a given directional sector will not necessarily correspond to an occurrence of storm peak h s in the same directional sector it may occur as the tail of a storm that peaks in a different directional sector and b when looking at large individual wave and crest values these may occur during sea states that are not at the peak of storms a consequence of this approach is that the largest observed values in each of the directional sectors are not and should not be statistically independent in practice however the data are used in the design process as if they were independent and this means that there is some level of conservatism in the directional extremes in general though the level of dependence is small for bins of size 45 or larger and the biggest effect is on the least severe sectors if only storm peaks were used to derive extremes though the results would be non conservative so on balance the approach described here is preferred note that the effect is not an issue for seasonal sectors since storm lengths are much shorter than the lengths of normal seasonal definitions we now assume that trajectories of storms within the database being analysed are representative of the range of storm shapes that may be seen clearly storms of different severities and in different seasons and directions may have different characteristics so the challenge is to identify storms that have peaks that are closest to each randomly simulated storm peak to identify these the observed storm histories are aggregated into a set of bins defined by the storm peak values of h s direction and day of year this is illustrated in fig 4 where bins populated with storm peaks from the observed data are indicated in blue for every randomly selected storm peak with characteristics h s s p drc s p ssn s p indicated by a red dot in the figure a distance d is defined to the centre of every bin with characteristics h s b i n s p drc b i n s p ssn b i n s p for which data is available namely 5 d 2 h s s p h s b i n s p 2 α h s 2 ssn s p ssn b i n s p 2 α ssn 2 drc s p drc b i n s p 2 α drc 2 where superscript s p indicates storm peak values h s is significant wave height ssn is the day of year drc is direction and the αs are scaling factors selected for each variable the bin that is closest for the selected scaling factors indicated by the green bin in the figure is then used as a source of archetype storms and corresponding trajectories for the storm peak in question the scaling factors α h s α ssn and α drc can be adjusted in order to fine tune the relative importance of the three dimensions for the data set under investigation the number of archetype storms in each bin can also be adjusted a large number of storms would produce a more varied array of potential storm shapes so capturing uncertainty in the storm trajectory but if the number is set too large then there will be storms that are less similar to the simulated storm peak that are also randomly selected suitable values of the α parameters are chosen by inspection of diagnostic plots illustrating the performance of storm trajectory matching using a cross validation procedure historical storms are withheld from the analysis in turn and then used as test cases we find values of α parameters yielding adequate matching to the storm trajectory for the withheld storms typical values of the α parameters are given in feld et al 2015 once the archetype populations have been established the trajectories will be randomly selected for association with randomly simulated storm peaks if the selected storm trajectory for some archetype labelled for definiteness has peak characteristics h s s p drc s p and ssn s p the storm trajectory is then adjusted for association with a storm peak with characteristics h s s p drc s p ssn s p such that a all h s values are scaled by the ratio of h s s p h s s p b the whole storm history of directions are rotated by drc s p drc s p so that the archetype storm peak direction matches that of the simulated storm peak and c wave periods are scaled such that after scaling the sea state steepness s 2 π h s g t 2 at every time step does not change for further discussion of the storm wave trajectory matching procedure please see feld et al 2015 6 still water level modelling for the determination of twl the joint relationship between wave crests tide and surge needs to be captured within the ceva methodology the same storm archetype approach that is used for storm wave trajectories is also used to describe the development of surge through storm histories as outlined in section 6 1 for locations where the water depth is sufficiently shallow that variations in the water depth can have an effect on the sea states it is important to also capture the tidal variation from that same storm for deeper water locations just the storm surge needs to be available and the tide can be randomly sampled these tidal approaches are described in section 6 2 6 1 surge modelling within the period of each storm as characterised by the exceedance of h s above storm threshold q the storm surge is characterised by its maximum minimum median and range i e the difference between the maximum and minimum storm surge as illustrated in fig 5 linear relationships are then developed between each of these characteristics and the storm peak h s within each of the directional and seasonal bin combinations giving a total of 768 different fits the relationship is defined in terms of a a selectable quantile of storm peak h s and the corresponding median value of surge characteristic together referred to as a lock point with value h s lock surgelock and b the slope of a linear least squares fit between the surge characteristic and storm peak h s with value slope the allowed rate of variability of slope with direction and season is set using a smoothing b spline optimised using cross validation for a given covariate bin the model takes the form 6 surge slope h s h s lock surgelock estimation of cross validation smoothness penalties for slope in the case of the surge maxima variable is illustrated in fig 6 the figure shows lack of fit from the regression model as a function of slope smoothness red lines illustrate how well the regression model describes variation present in the data as a function of slope smoothness as slope becomes smoother from left to right the quality of fit reduces the black line illustrates how well the regression model is able to predict unseen data at optimum smoothness the lack of predictive fit is a minimum this is a classic bias variance trade off to illustrate for the case of surge maxima fig 7 shows the variability of storm peak h s lock point slope and storm surge maximum lock point fig 8 shows 95 uncertainty intervals ui for the range of 96 linear fits within each of 8 aggregated directional sectors for the illustrative example for storm surge maximum surge median and surge minimum characteristics in these plots the grey dots represent all the observed combinations of h s and surge whilst the coloured dots represent the h s and surge maximum pairs blue h s and surge median pairs yellow and h s and surge minimum pairs red similar plots not shown were examined by month the plots show that in general there is a broadening of surge maximum and surge minimum as h s increases with surge median in general tending to increase more slowly this is apparent in plots split both by season and direction it is also evident that as expected there are more severe events that occur in the winter months and that the south east and east are calmer directions in order to capture the variability in the relationship between storm surge characteristics and h s the residuals of the linear regression relationships i e the differences between observed relationships and the line of best fit are also saved these are then sampled randomly during the final monte carlo analysis and applied to the regression relationship for each storm residuals from storm surge characteristics were inspected by direction and season and did not show obvious structure residuals are re sampled during simulation to ensure that the natural variability in relationships is captured rather than collapsing everything onto a single regression relationship fig 9 illustrates the overall performance of the regression model for the storm surge maximum characteristic for given simulated storm peak h s value we use equation 6 above to calculate a surge maximum surge median surge minimum and surge range for the simulated storm these values are dependent on the storm peak direction and season of the simulated storm peak event we refer to these as mxm mdn mnm and rng for clarity we next adjust the matched archetype surge trajectory s t say which originally has different values mxm mdn mnm and rng for the surge maximum median minimum and range such that the adjusted archetype surge trajectory s t has the desired values corresponding to the simulated storm peak event there are numerous possible approaches to achieve this here we outline a simple linear scaling approach based on matching surge median surge maximum and surge minimum only for s t mdn define s t such that 7 s t mdn mxm mdn s t mdn mxm mdn and when s t mdn define s t such that 8 mdn s t mdn mnm mdn s t mdn mnm 6 2 tidal modelling when a random storm is simulated the waves and surge are sampled from the same archetype storm so retaining the relationship between these components for shallower water locations the tidal component itself is sampled from the same storm as the waves and surge but the tidal component is not re scaled in most hindcasts that are available the effect of the variation in still water level on h s is not captured as they are run with a constant water depth for this reason it is often better to use measured wave and water level records to establish the relationships between h s and still water levels an example of the impact of water level on the h s time trace is shown in fig 10 7 simulation of twl and related variables to obtain a single realisation of maximum twl and its components for a single storm the following procedure is used we start by a simulating a storm peak direction and season from the poisson rate model and a storm peak h s from the extreme value model then b we select a historical archetype storm trajectory of sea state h s with direction and season in time and surge in time with similar storm peak characteristics to the simulated storm peak as described in section 5 and c rescale the storm trajectory sea state h s characteristics as described in section 5 so that they agree with the simulated storm peak then d we rescale the surge trajectory as described in section 6 next e we sample a random historical interval of tide to associate with the storm then f we estimate the water depth for every sea state using the swl components of tide and surge and the mean sea level above bed subsequently g we randomly sample maximum individual crest heights for each sea state using probability distributions based on the corresponding water depth typically the forristall distribution is used but this can be modified to fit water depth or swell characteristics where appropriate then h we add crest surge and tide components per sea state to obtain twl finally i the maximum value of twl per directional seasonal covariate bin is saved for the realisation to obtain a single realisation of maximum twl corresponding to a period of n years we simply simulate the appropriate random number of storm events for n years and retain the maximum value of twl per directional seasonal covariate bin over all events in this way the distribution of n year maximum twl can therefore be estimated from multiple n year simulations for any combination of directional seasonal covariate bins of interest including the combination of all covariate bins typically to estimate the distribution of n year maximum twl at least 200 realisations of n years of data are calculated so that the central characteristics e g mean median mode of the distribution of the n year maximum twl are estimated reliably in the current work 300 realisations of n years were evaluated to estimate extreme quantiles e g the 95 ile of the distribution of the n year maximum twl precisely a larger number of realisations would be required we note in passing that the computational efficiency of naive numerical simulation can often be considerably improved using e g numerical integration e g ross et al 2017 importance sampling or other more thoughtful smarter simulation 8 estimation of the distribution of the n year event to estimate the distribution of the n year maximum for quantities of interest ceva uses a monte carlo approach to simulate all storms in a return period of interest multiple times by a fitting the poisson and gp model to n b different bootstrap resamples of the original data and b making n r realisations of twl and its components the full return period of interest for each bootstrap this produces n b n r different realisations of the return period of interest where each version consists of multiple storms each of which are simulated as described in section 7 and from which just the largest values of h s individual wave height h individual crest height c and twl are stored for every bin this allows a probability distribution to be developed for the maximum of each of these variables for a return period of interest the distribution of the n year maximum for each bin can then be summarised by the quantile with non exceedance probability 1 e i e the 37th percentile which corresponds to the n year return value for that bin in the absence of parameter uncertainty other quantiles of the distribution can also be used e g to summarise the width of the distribution of the n year maximum aleatory natural inherent and epistemic data and modelling uncertainties are captured throughout the simulation process natural variability of storm peaks for a given environment of storm trajectories given storm peak of wave heights and crests given storm trajectory and of tide are all quantified modelling uncertainty due to a finite original sample and choice of ev threshold is also quantified the resulting probability distribution implicitly reflects these uncertainties typically for applications to estimation of extreme wave environments based on hindcasts or measurements the aleatory uncertainty is the major contributor to the width of the distribution of the n year maximum in the example used here only 15 realisations of 20 bootstraps of the original sample were taken that is 300 simulations overall have been used to illustrate the methodology using these simulations the overall fit of the h s model to the data as split by direction and season and overall are shown in fig 11 split by direction a similar plot split by season was also inspected this is quite a small number of realisations to estimate the whole distribution and is reflected in the jagged nature of the modelled median and 95 ui black lines fitted to the observed data red dots as noted earlier however 300 realisations is sufficient to estimate the central features e g median of the distribution the red dashed lines represent the 95 ui range from across all bootstrap resamples using more realisations would make the tails smoother or alternatively numerical integration can also be used the overall comparison is good with the tail corresponding to the original data being contained within the 95 ui for the tail simulated under the fitted model towards the top end of the data sets the 95 ui associated with the red bootstrap re sampled data narrows because the same data points are being re sampled each time similar plots are shown in fig 12 for all storm sea states as opposed to just the storm peaks split by direction plots split by month are also available again the overall comparison is good although the storm lengths seem to be under estimated by the approach since the number of modelled sea states indicated by the number to the right of mdl above each plot are lower than the actual act number of sea states nevertheless the overall comparison of the probability distributions is good from the 300 simulations the distributions of the maxima are shown in fig 13 in which larger overall widths of the curves indicate a higher level of variability the 37th percentile and median values are indicated by the dashed horizontal lines the overall curves for the 37th percentile of the distribution of the n year maxima for h s c and twl are shown in fig 14 and fig 15 fig 16 shows a comparison between the observed combinations of h s and surge that were observed overall and in each directional sector overlaid by median and 95 ui shown as red lines the equivalent modelled values are represented by the black lines agreement between observed red and simulated black curves is good in the body of the data becoming more uncertain for large h s where a there are fewer data and b there is greater spread in surge for given h s the differences in the relationships in each directional sector are quite clear with many sectors exhibiting an increasingly negative surge as storms become more severe particularly from the south east the north west and north on the other hand show a positive correlation between h s and surge these reflect the different storm tracks taken by storms which produce northerly as opposed to southerly or easterly winds at the site which will in turn affect the magnitude of the inverse barometric effect and the relative timing of the peak in surge and the h s peak in the different storm types estimates for the 37th percentile of the distribution of the n year maximum for splits by direction are shown in table 1 and table 2 for wave crest and twl respectively equivalent tables for results split by month are shown in table 3 and table 4 differences between twl and crest values in the tables are termed implied swl values and are given in table 5 and table 6 for values split by direction and season respectively we note that for any n year period the implied swl should be interpreted as the value of swl that when added to the 37th percentile of the distribution of n year maximum of individual crest provides the 37th percentile of the distribution of n year maximum twl the term implied swl is used since the largest twl will not necessarily occur at the time of maximum individual crest height this effect will become more significant at a location where the wave climate is not that severe and the tides are large these tables show the varying level of contribution by directional sector as reflected in fig 16 overall the implied swl values are larger for the north and north west sectors than for the other sectors albeit with some variability this could be associated with noise due to insufficient realisations in the analysis or it may indicate a varying degree of association between the timing of maximum surge and maximum wave conditions across the directional seasonal domain 9 discussion and conclusions in addition to the derivation of extreme h s and individual wave height the covariate extreme value approach ceva allows for the natural variability in waves and swl and their joint probabilities to be modelled over long periods of time this allows estimation of the joint distribution of n year maxima of wave crest storm surge and tide and hence twl the approach includes the capability of reflecting the variability of climate with direction and season and also the correlation between the various components being studied in a non parametric fashion which makes the approach very general there are some limitations to the approach however the main one being that sufficient storm events need to be available in the underlying data set in order to populate the many directional seasonal bins adequately at the start of the analysis where data sets are shorter or fewer events occur per year for example for tropical cyclones this can be a problem but the analysis can be carried out in with just one covariate in this case typically direction to increase the number of events per underlying bin however this still may result in poor model fits if the data set is too small a further difficulty of the approach is that in order to get statistically stable results a large number of realisations needs to be run and this can be time consuming even with good computing resources using parallel processing is a significant help in this regard but the end point of the development is smarter simulation incorporating clever sampling numerical integration and parallel processing rather than naive monte carlo analysis for long return periods a further enhancement that is under development ross et al 2018 for inclusion within ceva is the use of the approach of heffernan and tawn 2004 to determine the associated surge characteristics rather than using the linear regression and residuals approach described here it is also understood that the surge and wave trajectory re scaling approaches are relatively crude and more sophisticated statistical approaches e g tendijck et al 2018 are being developed to describe those more systematically despite the limitations described here the overall approach has been shown to produce good results in several of the major oil and gas basins and allows the complexity of the environment to be well captured within a single analysis appendix a supplementary data the following is the supplementary data to this article data profile data profile appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j oceaneng 2018 10 027 
23028,this article presents a step by step procedure for estimation of the joint distribution of n year maximum significant wave height individual wave and crest heights and total water level accommodating the effects of directional and seasonal variation surge and tide the approach is based on non stationary extreme value analysis of peaks over threshold incorporating careful uncertainty quantification and is illustrated for a north sea location using hindcast data the article further provides a brief overview of the development of a regulatory framework for specification of design conditions for total water level over the past half century keywords metocean design extreme total extreme water level non stationary uncertainty 1 introduction extremes of wave height and total water level twl are key parameters for the design of fixed platforms in the offshore environment previous papers e g feld et al 2015 randell et al 2015 have described an approach to non stationary extreme value analysis henceforth called ceva abbreviating covariate extreme value analysis for estimating n year maxima of significant wave height individual wave and crest heights taking into account the variation in seasonal and directional covariates waves that impact the topsides and supporting beams of offshore structures are particularly significant since they result in a rapid increase in loading with inundation level extremes of twl namely the combination of wave crest and still water level swl itself the sum of tide and storm surge can cause bigger loads still and are often of greater importance to the structural engineer than crest height alone this paper builds on the approach described in previous papers to also include swl effects in a manner which is consistent with the wave modelling methodology and which preserves the relationships between waves storm surge and tidal levels that are observed within storms the underlying approach to the estimation of the wave component of twl is based upon modelling storm peak events on a directional seasonal covariate domain described in outline in section 4 whilst this approach captures the storm peaks appropriately in order to determine the maximum twl within each storm it is necessary to model more than just the peak sea state this is due to both the random nature of large individual wave crests within sea states near to the peak and also to the characteristics of the inter relationships between waves tide and surge both of these effects may result in the highest water level during a storm occurring at a time of lower significant wave height h s but higher tide and or surge in order to represent the total water level variability throughout a storm event therefore representative storm trajectories are derived which aim to capture the variability of all of the key wave section 5 and surge section 6 parameters as the storm develops both temporally and directionally these trajectories can then be appropriately re scaled in order to match the severity of storm peaks randomly selected from the fitted extremal model to estimate maximum twl in a storm all these modelling components i e storm peak modelling wave and surge storm trajectory selection and tidal variations need to be brought together and combined with the short term variability of individual crest heights in this way for each simulated sea state in each storm event individual maximum crests are randomly sampled and added to appropriately selected surge and tidal level this process explained in section 7 is then repeated for all randomly simulated storms over the return period of interest for each period of simulation the maximum twl for each direction and day of year are retained this allows extreme values of twl for any directional seasonal combination to be subsequently extracted and these can then further be aggregated to derive all year and omnidirectional extremes in a statistically consistent manner this final simulation is described in section 8 this modelling procedure allows all extremes that may be required for design and operational purposes to be derived in a single analysis for example seasonal criteria for installation activities are readily available or a re alignment of a structure during the design phase can be easily accommodated by simply aggregating across different sets of directional sectors throughout this whole process uncertainties are propagated into the estimated distribution of the n year maximum twl using the methods described these uncertainties are captured by using bootstrapping of the original storm peak data a range of wave and surge storm trajectory shapes different tidal phases a range of extreme value thresholds random sampling of h s and random sampling of individual crest heights 2 background for the offshore environment we assume that twl is defined as the sum of individual crest surge and tidal components the importance of twl has been explored particularly within two areas of study a coastal flooding and over topping and b wave impact on marine bottom founded structures in the first of these annual maxima from long time series were traditionally used as the basis for extrapolating to long return periods but based on swl i e combined tide and surge this approach means however that many significant surge events will be excluded if they happen to occur at low tide and it also does not make the best use of the available data since only a single event per year is included the combined effects of decoupled tide and surge were modelled in pugh and vassie 1978 by the joint probability method jpm where non parametric probability distributions for both were derived and assuming independence recombined statistically to obtain the statistics of overall swl in order to extrapolate to longer return periods an empirically selected log distribution was fitted to the tail of positive surges the approach made better use of the data by using all hourly samples but in so doing introduced a data set which consisted of dependent samples this introduced a bias into the estimate of the non exceedance probability associated with given return periods despite the shortcomings of the method it has been widely applied although the method was subsequently revised by tawn 1992 to de cluster the surge data into independent events to smooth the observed magnitudes and to fit a more statistically justified generalised pareto distribution gpd to the tail of the surge distribution an empirical approach for adjusting the surge distribution for different tidal levels was also presented for application to those shallow locations where this was relevant hawkes et al 2002 proposed a joint model for water level wave height wave steepness and their dependence an extension of the jpm for application to cases with more than two variables was described by liu et al 2010 in the direct jpm in which a multi dimensional histogram was set up to include wave run up in addition to tide and surge in this approach the characteristics of dependence between the three were explicitly captured by using an empirical non parametric method although the details used for extrapolation beyond the length of the data set are unclear shevchenko and ivelskaya 2015 broadened and generalised the original jpm to include a description of seasonal variability in mean sea level within the tidal harmonics and used the gumbel distribution to extrapolate both surge and tsunami levels to longer return periods however any joint probability characteristics between the parameters were not explicitly modelled in this approach more sophisticated modelling approaches to joint probability in general have been developed by heffernan and tawn 2004 which describe the relationship of variable y conditional on the value of another extreme variable x following transformation to a standard typically laplace marginal scale 1 y x x a x x b w where a 1 1 and b 1 are fitted parameters and w represents a residual process with unknown distribution assumed gaussian for fitting only typically a generalised pareto distribution gpd is used to fit each marginal distribution of peaks over threshold the approach can be extended to any number of variables in which each is conditional upon the value of a single conditioning variable that exceeds a certain extremal threshold gouldby et al 2014 applied this approach to the study of coastal over topping and overflow which included swl and wave components once the model was fitted a monte carlo approach was used in which a single parameter was sampled randomly and the relationship presented above was used including sampling from the distribution of residuals w to determine associated values of other parameters in order to model for long return periods in terms of setting the deck height of offshore structures and the determination of extreme twl in the north sea the design recipe in the 1970s and early 80s was based on a 1 5 m clearance over and above a combination of the 50 year crest height the 50 year surge and the mean high water spring mhws tide uk hmso 1974 during the 1980s the key return period was increased to 100 years and some simple allowance was given for joint probabilities between tide and surge on the assumption of two gaussian parameters between which a correlation coefficient could be defined uk department of energy 1990 by 1998 the uk health and safety executive dictated that a structure needed to withstand the 10 000 year twl with no additional air gap but no clear guidance was given as to how the twl should be derived at this time therefore certain approximate methods were developed within the industry based on empirically derived relationships founded on considerations such as storm length versus length of tidal cycle and rules of thumb relating crest heights from one return period to another one such method for the 10 000 year twl twl 10000 which was adopted by shell and bp in 2000 was the so called interim method 2 twl 10000 c 1000 3 4 mhw msl s 1 where mhw is the mean tidal high water s 1 is the 1 year positive surge c 1000 is the 1000 year crest height and msl is mean sea level a second approach was described in leggett et al 2007 for the central cns and southern sns north sea 3 cns twl 10000 c 10000 msl s 1 sns twl 10000 c 10000 msl s 3 where s 3 is the 3 year positive surge and where subscript 10000 refers to the 10 000 year value of the corresponding quantities however this approach based on consideration of only selected combinations of crest height tide and surge rather than a general investigation of the worst possible combinations was not generically applicable iso19902 2007 presented a range of twl values for an offshore location utilizing relationships between tide surge and crest and this was based on the approach set out by uk department of energy 1990 it provided limiting cases for twl based on either complete correlation between surge and crest and the completely uncorrelated case the range provided for twl was 4 a 2 s 2 t 2 a s 2 t 2 where a is the extreme crest height s is the extreme surge and t is the maximum elevation of tide relative to mean sea level iso19901 1 2005 adopted the tromans and vanderschuren 1995 storm based approach for the determination of individual wave and crest height return values based on the statistical combination of the long term distribution of storm maxima with the short term distribution of individual waves this correctly accounts for the fact that the largest waves in a storm do not necessarily come from the most severe sea state and that the largest waves in a given return period do not necessarily come from the storms with the largest h s however there was still no further guidance as to how to combine these crest heights with swl variations in uk health and satefy executive 2009 a monte carlo approach was described to combine the approach of tromans and vanderschuren 1995 for individual wave crests with a representation of the joint probabilities of waves and surge again though a simplistic approach was adopted in which once a randomly selected h s was selected the surge of the same percentile was associated with the sea state such that effectively a perfect correlation was assumed between waves and surge but a random tide was included an additional empirical correction factor was then derived from measured data to correct for the degree of correlation we note the work of callaghan et al 2008 serafin and ruggiero 2014 wahl et al 2017 and others on simulating wave environments for estimation of erosion and over topping previous papers by some of the current authors have developed the monte carlo approach e g ewans and jonathan 2008 feld et al 2015 in which the approach of tromans and vanderschuren 1995 was adopted for the crests but which allowed for varying characteristics by season and direction in order to better capture the changing statistical populations through the year and by direction in order to derive twl however a method for combining these crests with appropriate tides and surges is required and this is the substance of the current paper 3 example data set for illustrative purposes a data set from a location in the western half of the southern north sea in a water depth of around 20 m has been chosen the water level data consisted of hourly measurements at an offshore platform between october 2006 and december 2016 and the wave data came from the nora10 norwegian reanalysis 10 km wave hindcast model reistad et al 2011 wam third generation prognostic wave model wamdi 1988 hindcast grid point closest to the measurement location and covered the same period a representation of the distribution of h s by season and direction is shown in fig 1 showing the significance of the covariates in determining the severity of any particular directional seasonal combination in this plot all the data points are shown as grey dots and the storm peaks are shown as black dots direction is defined as the direction from which storms propagate measured clockwise from north tides were separated from storm surges by harmonic analysis using t tide software pawlowicz et al 2002 of hourly mean original water level data with residual level referred to as surge fig 2 a shows the variability of surge with season with black dots representing all the observed data points again the seasonality is obvious a similar plot is shown for tide in fig 2 b where the small equinoctial effect on tides can be seen the relationship between tide and surge is shown in fig 2 c in which the relationship appears to be random in nature in an overall sense although there appears to be a slight tendency for the highest surges to have occurred at the extremes of tide either high or low fig 2 d illustrates the overall relationship between h s and surge in this case the largest surge events are associated with higher h s values but the scatter indicates that a large h s does not necessarily imply that a large surge will occur simultaneously for definiteness wave height is defined as the difference between the maximum and minimum values of the ocean surface between consecutive down crossings of mean water level crest height is defined as the maximum value of the ocean surface between an up crossing and subsequent down crossing of the mean water level 4 storm peak modelling the details of this approach have been described in previous papers e g feld et al 2015 briefly 1 a set of directional seasonal covariate bins within which conditions are considered homogeneous is defined binning reduces the computational complexity of the covariate description and hence the complexity of the spline calculations to estimate extreme value ev models typically this is based on 32 directional bins 11 25 width and 24 seasonal bins approximately 2 weeks long giving a total of 768 across the covariate domain 2 a threshold q for isolation of storm event is defined using a quantile of sea state h s per directional seasonal sector this threshold is typically chosen to correspond to a quantile with constant non exceedance probability of between approximately 0 5 and 0 75 this produces a sufficient number of storm events whilst keeping the storm length to a manageable size a quantile is better than a fixed storm threshold since this ensures that calmer seasons and directions are adequately represented in the overall model and see e g northrop and jonathan 2011 the peak of the storm event is captured and characterised by the storm peak h s referred to as h s s p for definiteness where needed zero crossing wave period t z spectral mean period t 01 direction and day of year note that t 01 is defined as m 0 m 1 where m 0 is the zeroth moment and m 1 the first moment of the wave spectrum t 01 is a key parameter in the forristall crest height probability distribution 3 for each storm the whole period of exceedance of storm threshold q is also added to the set of historical storm trajectories which can then be associated with synthesized storm peaks see section 5 4 a set of viable ev thresholds ψ for storm peaks is chosen corresponding to quantiles with non exceedance probabilities per covariate bin within some reasonable interval above ψ occurrences of storm peaks are assumed to follow a poisson process with mean rate ρ and storm severity described by a generalised pareto model with scale parameter σ and shape parameter ξ 5 the variation of model parameters ψ ρ σ and ξ with covariates is described using linear combinations of cubic b spline functions or tensor products thereof defined on the covariate domain each spline function has a fixed width but can vary in height the extent to which spline function height is allowed to vary between adjacent splines is determined by penalty terms and an optimal smoothness chosen using cross validated penalised maximum likelihood estimation the intention is that spline smoothness is chosen so that the resulting variation in model parameters reflects the underlying natural variability present whilst preventing over fitting a conceptual illustration unrelated to the current application of the effect of high and low penalty cases is shown in fig 3 in the left hand case the variability of heights between adjacent splines is much more constrained than the right hand case a penalised likelihood approach is also used to estimate covariate dependent ev thresholds ψ in 4 above 6 the procedure for partitioning the covariate domain is explained in e g ross et al 2017 we choose to partition the domain into 32 directional bins of width 11 25 and 24 seasonal bins of width 15 seasonal days from a year with 360 seasonal days we judge this resolution to be sufficient to capture the main directional and seasonal variation of storm peak significant wave height the extreme value model therefore uses a total of 768 32 24 covariate combinations for extreme value analysis we assume that neighbouring covariate bins exhibit similar behaviour this is enforced by penalising the local variation of extreme value parameter estimates we choose the penalty so that the resulting extreme value model has optimal predictive performance in this sense if there was no predictive evidence in the data related to covariate variation the extreme value model would be extremely stiff corresponding effectively to one covariate bin in this case there would be one bin and 1156 peaks in it for the current application further the effective number of covariate degrees of freedom used in the analysis can vary from one stiff to 768 flexible the actual effective number is chosen to maximise predictive performance using cross validation the optimal choice of parameter roughness penality is discussed more fully in section 6 and illustrated in fig 6 all modelling is performed for 768 covariate combinations for presentation of results concerning the distribution of n year maxima we can combine covariate bins to present exactly the results that the engineer finds most useful in this work we present estimates e g fig 11 or fig 12 discussed in section 8 on 8 directional octants and 12 seasonal months however we can provide estimates of extreme environments using any combinations of covariate bins of interest to the engineer once the storm peak modelling has been completed a monte carlo approach can then be used to simulate a set of random storm peaks for any given return period that reflects the underlying statistical characteristics of the data to capture uncertainties in this process the original data can also be bootstrapped and the whole modelling process repeated 5 derivation of storm wave trajectory it is not sufficient to just base the analysis on storm peaks there are two main reasons for this a an extreme value of twl in a given directional sector will not necessarily correspond to an occurrence of storm peak h s in the same directional sector it may occur as the tail of a storm that peaks in a different directional sector and b when looking at large individual wave and crest values these may occur during sea states that are not at the peak of storms a consequence of this approach is that the largest observed values in each of the directional sectors are not and should not be statistically independent in practice however the data are used in the design process as if they were independent and this means that there is some level of conservatism in the directional extremes in general though the level of dependence is small for bins of size 45 or larger and the biggest effect is on the least severe sectors if only storm peaks were used to derive extremes though the results would be non conservative so on balance the approach described here is preferred note that the effect is not an issue for seasonal sectors since storm lengths are much shorter than the lengths of normal seasonal definitions we now assume that trajectories of storms within the database being analysed are representative of the range of storm shapes that may be seen clearly storms of different severities and in different seasons and directions may have different characteristics so the challenge is to identify storms that have peaks that are closest to each randomly simulated storm peak to identify these the observed storm histories are aggregated into a set of bins defined by the storm peak values of h s direction and day of year this is illustrated in fig 4 where bins populated with storm peaks from the observed data are indicated in blue for every randomly selected storm peak with characteristics h s s p drc s p ssn s p indicated by a red dot in the figure a distance d is defined to the centre of every bin with characteristics h s b i n s p drc b i n s p ssn b i n s p for which data is available namely 5 d 2 h s s p h s b i n s p 2 α h s 2 ssn s p ssn b i n s p 2 α ssn 2 drc s p drc b i n s p 2 α drc 2 where superscript s p indicates storm peak values h s is significant wave height ssn is the day of year drc is direction and the αs are scaling factors selected for each variable the bin that is closest for the selected scaling factors indicated by the green bin in the figure is then used as a source of archetype storms and corresponding trajectories for the storm peak in question the scaling factors α h s α ssn and α drc can be adjusted in order to fine tune the relative importance of the three dimensions for the data set under investigation the number of archetype storms in each bin can also be adjusted a large number of storms would produce a more varied array of potential storm shapes so capturing uncertainty in the storm trajectory but if the number is set too large then there will be storms that are less similar to the simulated storm peak that are also randomly selected suitable values of the α parameters are chosen by inspection of diagnostic plots illustrating the performance of storm trajectory matching using a cross validation procedure historical storms are withheld from the analysis in turn and then used as test cases we find values of α parameters yielding adequate matching to the storm trajectory for the withheld storms typical values of the α parameters are given in feld et al 2015 once the archetype populations have been established the trajectories will be randomly selected for association with randomly simulated storm peaks if the selected storm trajectory for some archetype labelled for definiteness has peak characteristics h s s p drc s p and ssn s p the storm trajectory is then adjusted for association with a storm peak with characteristics h s s p drc s p ssn s p such that a all h s values are scaled by the ratio of h s s p h s s p b the whole storm history of directions are rotated by drc s p drc s p so that the archetype storm peak direction matches that of the simulated storm peak and c wave periods are scaled such that after scaling the sea state steepness s 2 π h s g t 2 at every time step does not change for further discussion of the storm wave trajectory matching procedure please see feld et al 2015 6 still water level modelling for the determination of twl the joint relationship between wave crests tide and surge needs to be captured within the ceva methodology the same storm archetype approach that is used for storm wave trajectories is also used to describe the development of surge through storm histories as outlined in section 6 1 for locations where the water depth is sufficiently shallow that variations in the water depth can have an effect on the sea states it is important to also capture the tidal variation from that same storm for deeper water locations just the storm surge needs to be available and the tide can be randomly sampled these tidal approaches are described in section 6 2 6 1 surge modelling within the period of each storm as characterised by the exceedance of h s above storm threshold q the storm surge is characterised by its maximum minimum median and range i e the difference between the maximum and minimum storm surge as illustrated in fig 5 linear relationships are then developed between each of these characteristics and the storm peak h s within each of the directional and seasonal bin combinations giving a total of 768 different fits the relationship is defined in terms of a a selectable quantile of storm peak h s and the corresponding median value of surge characteristic together referred to as a lock point with value h s lock surgelock and b the slope of a linear least squares fit between the surge characteristic and storm peak h s with value slope the allowed rate of variability of slope with direction and season is set using a smoothing b spline optimised using cross validation for a given covariate bin the model takes the form 6 surge slope h s h s lock surgelock estimation of cross validation smoothness penalties for slope in the case of the surge maxima variable is illustrated in fig 6 the figure shows lack of fit from the regression model as a function of slope smoothness red lines illustrate how well the regression model describes variation present in the data as a function of slope smoothness as slope becomes smoother from left to right the quality of fit reduces the black line illustrates how well the regression model is able to predict unseen data at optimum smoothness the lack of predictive fit is a minimum this is a classic bias variance trade off to illustrate for the case of surge maxima fig 7 shows the variability of storm peak h s lock point slope and storm surge maximum lock point fig 8 shows 95 uncertainty intervals ui for the range of 96 linear fits within each of 8 aggregated directional sectors for the illustrative example for storm surge maximum surge median and surge minimum characteristics in these plots the grey dots represent all the observed combinations of h s and surge whilst the coloured dots represent the h s and surge maximum pairs blue h s and surge median pairs yellow and h s and surge minimum pairs red similar plots not shown were examined by month the plots show that in general there is a broadening of surge maximum and surge minimum as h s increases with surge median in general tending to increase more slowly this is apparent in plots split both by season and direction it is also evident that as expected there are more severe events that occur in the winter months and that the south east and east are calmer directions in order to capture the variability in the relationship between storm surge characteristics and h s the residuals of the linear regression relationships i e the differences between observed relationships and the line of best fit are also saved these are then sampled randomly during the final monte carlo analysis and applied to the regression relationship for each storm residuals from storm surge characteristics were inspected by direction and season and did not show obvious structure residuals are re sampled during simulation to ensure that the natural variability in relationships is captured rather than collapsing everything onto a single regression relationship fig 9 illustrates the overall performance of the regression model for the storm surge maximum characteristic for given simulated storm peak h s value we use equation 6 above to calculate a surge maximum surge median surge minimum and surge range for the simulated storm these values are dependent on the storm peak direction and season of the simulated storm peak event we refer to these as mxm mdn mnm and rng for clarity we next adjust the matched archetype surge trajectory s t say which originally has different values mxm mdn mnm and rng for the surge maximum median minimum and range such that the adjusted archetype surge trajectory s t has the desired values corresponding to the simulated storm peak event there are numerous possible approaches to achieve this here we outline a simple linear scaling approach based on matching surge median surge maximum and surge minimum only for s t mdn define s t such that 7 s t mdn mxm mdn s t mdn mxm mdn and when s t mdn define s t such that 8 mdn s t mdn mnm mdn s t mdn mnm 6 2 tidal modelling when a random storm is simulated the waves and surge are sampled from the same archetype storm so retaining the relationship between these components for shallower water locations the tidal component itself is sampled from the same storm as the waves and surge but the tidal component is not re scaled in most hindcasts that are available the effect of the variation in still water level on h s is not captured as they are run with a constant water depth for this reason it is often better to use measured wave and water level records to establish the relationships between h s and still water levels an example of the impact of water level on the h s time trace is shown in fig 10 7 simulation of twl and related variables to obtain a single realisation of maximum twl and its components for a single storm the following procedure is used we start by a simulating a storm peak direction and season from the poisson rate model and a storm peak h s from the extreme value model then b we select a historical archetype storm trajectory of sea state h s with direction and season in time and surge in time with similar storm peak characteristics to the simulated storm peak as described in section 5 and c rescale the storm trajectory sea state h s characteristics as described in section 5 so that they agree with the simulated storm peak then d we rescale the surge trajectory as described in section 6 next e we sample a random historical interval of tide to associate with the storm then f we estimate the water depth for every sea state using the swl components of tide and surge and the mean sea level above bed subsequently g we randomly sample maximum individual crest heights for each sea state using probability distributions based on the corresponding water depth typically the forristall distribution is used but this can be modified to fit water depth or swell characteristics where appropriate then h we add crest surge and tide components per sea state to obtain twl finally i the maximum value of twl per directional seasonal covariate bin is saved for the realisation to obtain a single realisation of maximum twl corresponding to a period of n years we simply simulate the appropriate random number of storm events for n years and retain the maximum value of twl per directional seasonal covariate bin over all events in this way the distribution of n year maximum twl can therefore be estimated from multiple n year simulations for any combination of directional seasonal covariate bins of interest including the combination of all covariate bins typically to estimate the distribution of n year maximum twl at least 200 realisations of n years of data are calculated so that the central characteristics e g mean median mode of the distribution of the n year maximum twl are estimated reliably in the current work 300 realisations of n years were evaluated to estimate extreme quantiles e g the 95 ile of the distribution of the n year maximum twl precisely a larger number of realisations would be required we note in passing that the computational efficiency of naive numerical simulation can often be considerably improved using e g numerical integration e g ross et al 2017 importance sampling or other more thoughtful smarter simulation 8 estimation of the distribution of the n year event to estimate the distribution of the n year maximum for quantities of interest ceva uses a monte carlo approach to simulate all storms in a return period of interest multiple times by a fitting the poisson and gp model to n b different bootstrap resamples of the original data and b making n r realisations of twl and its components the full return period of interest for each bootstrap this produces n b n r different realisations of the return period of interest where each version consists of multiple storms each of which are simulated as described in section 7 and from which just the largest values of h s individual wave height h individual crest height c and twl are stored for every bin this allows a probability distribution to be developed for the maximum of each of these variables for a return period of interest the distribution of the n year maximum for each bin can then be summarised by the quantile with non exceedance probability 1 e i e the 37th percentile which corresponds to the n year return value for that bin in the absence of parameter uncertainty other quantiles of the distribution can also be used e g to summarise the width of the distribution of the n year maximum aleatory natural inherent and epistemic data and modelling uncertainties are captured throughout the simulation process natural variability of storm peaks for a given environment of storm trajectories given storm peak of wave heights and crests given storm trajectory and of tide are all quantified modelling uncertainty due to a finite original sample and choice of ev threshold is also quantified the resulting probability distribution implicitly reflects these uncertainties typically for applications to estimation of extreme wave environments based on hindcasts or measurements the aleatory uncertainty is the major contributor to the width of the distribution of the n year maximum in the example used here only 15 realisations of 20 bootstraps of the original sample were taken that is 300 simulations overall have been used to illustrate the methodology using these simulations the overall fit of the h s model to the data as split by direction and season and overall are shown in fig 11 split by direction a similar plot split by season was also inspected this is quite a small number of realisations to estimate the whole distribution and is reflected in the jagged nature of the modelled median and 95 ui black lines fitted to the observed data red dots as noted earlier however 300 realisations is sufficient to estimate the central features e g median of the distribution the red dashed lines represent the 95 ui range from across all bootstrap resamples using more realisations would make the tails smoother or alternatively numerical integration can also be used the overall comparison is good with the tail corresponding to the original data being contained within the 95 ui for the tail simulated under the fitted model towards the top end of the data sets the 95 ui associated with the red bootstrap re sampled data narrows because the same data points are being re sampled each time similar plots are shown in fig 12 for all storm sea states as opposed to just the storm peaks split by direction plots split by month are also available again the overall comparison is good although the storm lengths seem to be under estimated by the approach since the number of modelled sea states indicated by the number to the right of mdl above each plot are lower than the actual act number of sea states nevertheless the overall comparison of the probability distributions is good from the 300 simulations the distributions of the maxima are shown in fig 13 in which larger overall widths of the curves indicate a higher level of variability the 37th percentile and median values are indicated by the dashed horizontal lines the overall curves for the 37th percentile of the distribution of the n year maxima for h s c and twl are shown in fig 14 and fig 15 fig 16 shows a comparison between the observed combinations of h s and surge that were observed overall and in each directional sector overlaid by median and 95 ui shown as red lines the equivalent modelled values are represented by the black lines agreement between observed red and simulated black curves is good in the body of the data becoming more uncertain for large h s where a there are fewer data and b there is greater spread in surge for given h s the differences in the relationships in each directional sector are quite clear with many sectors exhibiting an increasingly negative surge as storms become more severe particularly from the south east the north west and north on the other hand show a positive correlation between h s and surge these reflect the different storm tracks taken by storms which produce northerly as opposed to southerly or easterly winds at the site which will in turn affect the magnitude of the inverse barometric effect and the relative timing of the peak in surge and the h s peak in the different storm types estimates for the 37th percentile of the distribution of the n year maximum for splits by direction are shown in table 1 and table 2 for wave crest and twl respectively equivalent tables for results split by month are shown in table 3 and table 4 differences between twl and crest values in the tables are termed implied swl values and are given in table 5 and table 6 for values split by direction and season respectively we note that for any n year period the implied swl should be interpreted as the value of swl that when added to the 37th percentile of the distribution of n year maximum of individual crest provides the 37th percentile of the distribution of n year maximum twl the term implied swl is used since the largest twl will not necessarily occur at the time of maximum individual crest height this effect will become more significant at a location where the wave climate is not that severe and the tides are large these tables show the varying level of contribution by directional sector as reflected in fig 16 overall the implied swl values are larger for the north and north west sectors than for the other sectors albeit with some variability this could be associated with noise due to insufficient realisations in the analysis or it may indicate a varying degree of association between the timing of maximum surge and maximum wave conditions across the directional seasonal domain 9 discussion and conclusions in addition to the derivation of extreme h s and individual wave height the covariate extreme value approach ceva allows for the natural variability in waves and swl and their joint probabilities to be modelled over long periods of time this allows estimation of the joint distribution of n year maxima of wave crest storm surge and tide and hence twl the approach includes the capability of reflecting the variability of climate with direction and season and also the correlation between the various components being studied in a non parametric fashion which makes the approach very general there are some limitations to the approach however the main one being that sufficient storm events need to be available in the underlying data set in order to populate the many directional seasonal bins adequately at the start of the analysis where data sets are shorter or fewer events occur per year for example for tropical cyclones this can be a problem but the analysis can be carried out in with just one covariate in this case typically direction to increase the number of events per underlying bin however this still may result in poor model fits if the data set is too small a further difficulty of the approach is that in order to get statistically stable results a large number of realisations needs to be run and this can be time consuming even with good computing resources using parallel processing is a significant help in this regard but the end point of the development is smarter simulation incorporating clever sampling numerical integration and parallel processing rather than naive monte carlo analysis for long return periods a further enhancement that is under development ross et al 2018 for inclusion within ceva is the use of the approach of heffernan and tawn 2004 to determine the associated surge characteristics rather than using the linear regression and residuals approach described here it is also understood that the surge and wave trajectory re scaling approaches are relatively crude and more sophisticated statistical approaches e g tendijck et al 2018 are being developed to describe those more systematically despite the limitations described here the overall approach has been shown to produce good results in several of the major oil and gas basins and allows the complexity of the environment to be well captured within a single analysis appendix a supplementary data the following is the supplementary data to this article data profile data profile appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j oceaneng 2018 10 027 
23029,structural health monitoring shm and condition monitoring cm systems are currently utilised to collect data from offshore wind turbines owts to enhance the accurate estimation of their operational performance however industry accepted practices for effectively managing the information that these systems provide have not been widely established yet this paper presents a four step methodological framework for the effective data management of shm systems of owts and illustrates its applicability in real time continuous data collected from three operational units with the aim of utilising more complete and accurate datasets for fatigue life assessment of support structures firstly a time efficient synchronisation method that enables the continuous monitoring of these systems is presented followed by a novel approach to noise cleansing and the posterior missing data imputation mdi by the implementation of these techniques those data points containing excessive noise are removed from the dataset step 2 advanced numerical tools are employed to regenerate missing data step 3 and fatigue is estimated for the results of these two methodologies step 4 results show that after cleansing missing data can be imputed with an average absolute error of 2 1 while this error is kept within the 15 2 11 0 range in 95 of cases furthermore only 0 15 of the imputed data fell outside the noise thresholds fatigue is found to be underestimated both when data cleansing does not take place and when it takes place but mdi does not this makes this novel methodology an enhancement to conventional structural integrity assessment techniques that do not employ continuous datasets in their analyses keywords structural health monitoring shm offshore wind data synchronisation noise cleansing missing data imputation artificial neural network ann acronyms ann artificial neural network owf offshore wind farm cm condition monitoring owt offshore wind turbine dels damage equivalent loads o m operation and maintenance fea finite element analysis r residuals lcoe levelized cost of energy scada supervisory control and data acquisition mdi missing data imputation shm structural health monitoring mse minimum squared error shms structural health monitoring systems oma operational modal analysis ss support structure ow offshore wind wts wind turbines 1 introduction structural health monitoring systems shms have become relevant in the last decade for the operational management of offshore wind turbines owts due to their damage detection and continuous fatigue life assessment capabilities operation and maintenance o m related costs are a significant contributor to the levelized cost of energy lcoe shafiee et al 2016 shafiee and sørensen 2018 while in the past shms were installed as a way to abide by the german regulations imposing a 10 of assets instrumented across an offshore wind farm owf and not exploited to their full potential nowadays operators have realized how these technologies could result in an increase in electricity production and thereby a reduction in lcoe ioannou et al 2018 myhr et al 2014 over the past decades many researchers from the shm community have developed an extensive amount of methods based on a variety of physically interpretable structural features hansen et al 2017 at this point in time there is no widely accepted practice with respect to the specification of monitoring systems as industry is still exploring wts potential making every wind farm different in terms of technologies implemented number and location of the sensors redundancies etc most of these fatigue assessment methods rely on collected data from either accelerometers strain gauges or the combination of both from selected instrumented units luengo and kolios 2015 martinez luengo et al 2016 numerous authors have carried out different ways of analysing shms data for example a vibration based damage localization and quantification method based on natural frequencies and mode shapes extracted by means of operational modal analysis oma combined with finite element analysis fea of the test structure hansen et al 2017 another approach to fatigue assessment is by the extrapolation of the dynamic behaviour of owts from a limited set of sensors existing monitoring strategies for monopiles are based on physical models or artificial intelligence ziegler et al 2017 model based time domain algorithms require accelerometers and sometimes strain gauges on the structure these try to reproduce the time history of dynamic response parameters such as acceleration or strain of the whole structure for different operational regimes this was carried out by employing kalman filters maes et al 2016a fallais et al 2016 joint input state estimation maes et al 2016b and modal expansion algorithms maes et al 2016b iliopoulos et al 2014 2016 even though accelerometers might be placed in the wt s nacelle for supervisory control and data acquisition scada or condition monitoring cm purposes they are not so often placed at different levels of the support structure ss unless there is a particular interest in its vibration monitoring however installing these accelerometers at different levels of the turbine is more expensive besides accelerometers alone do not cover all the necessary frequencies needed for modal expansion algorithms as maes et al 2016b explains making strain gauges also necessary furthermore sometimes wts are only instrumented with strain gauges especially those commissioned more than five years ago most fatigue sensitive spots called hot spots in owts are inaccessible for direct measurements i e at welds or mudline iliopoulos et al 2017 different methods have been utilised to accurately predict the structure s response at these important locations where strain gauges cannot be installed this is achieved by combining measurements from sub optimal locations with fea ziegler et al 2017 iliopoulos et al 2014 2017 martinez luengo et al 2017 gentils et al 2017 to extrapolate to the critical locations sometimes datasets at accessible locations are not complete due to failure in acquiring or recording the data full storage space high noise etc the issue of limited information due to limited availability of operational data could be mitigated by these feas this hypothesis has been supported in different articles where accurate load estimation is believed to be best carried out with data driven models requiring only a short period of mechanical strain measurements smolka and cheng 2013 however this approach of using incomplete shm datasets is questionable not only for deriving service life estimations from reduced time intervals but also for introducing uncertainty in the estimations and wasting costly shm data that could potentially be utilised for damage detection and quantification strategies as mentioned earlier oma introduces uncertainty in the estimations according to banfi and carassale the available mathematical oma techniques have the common feature that the unmeasured excitation is modelled as a random process specified by some probabilistic models banfi et al 2017 in practical applications the length of the measurement is limited and the probabilistic model adopted to represent the excitation does not necessarily apply this together with measurement errors leads to uncertainties of a different nature that affect the estimation of the modal parameters finally it seems impractical to install multiple sensors and dedicate resources to analysing their measurements without obtaining a long term view of how the system behaves and degrades noise is inherent to data acquisition signals in realistic applications are inevitably contaminated with measurement noise as well as other sorts of variabilities and uncertainties such as calibration issues transmission or de synchronisation between the real and the recorded time stamp as a result the shm features extracted from the contaminated data such as damage equivalent loads dels power spectrum and frequency response function are also noisy mao and todd 2012 2013 uncertainty could contaminate the extracted shm features dramatically if the data quality is poor and thereby causes ambiguity in interpreting the features sarrafi and mao 2017 usually the uncertainty will raise false alarms in the damage detection i e non damage induced feature deviation from the undamaged baseline therefore noise identification and quantification in shms data should not be ignored and ideally should take place before fatigue assessment besides a systematic approach to the effective data management of these shms installed in owts prior fatigue assessment has not been established yet either in the literature or by regulations this paper aims to develop a methodological framework for the effective data management of shms of owts by addressing the issues of missing data and noise in the acquired data which influence the effective fatigue assessment of offshore wind ow energy assets this is achieved through a four step process including synchronisation cleansing imputation and fatigue assessment that enables the continuous analysis of the unit s structural integrity and remaining service life throughout the years as highlighted in fig 1 this novel framework is implemented by utilising real and continuously monitored 50 hz strain data collected from three different owts currently in operation for over three years these turbines were instrumented with shms during their commissioning therefore it is assumed that no previous fatigue damage from the commissioning phase was undertaken by the turbine without being captured and that the noise calibration error present in the measurements used to derive the dynamic structural behaviour of the units is minimum this article highlights the importance of appropriate data handling of shms for the continuous fatigue assessment of an owt s ss the four stage methodology proposed in fig 1 is implemented in section 2 and its results discussed in section 3 after data synchronisation takes place noise cleansing and missing data imputation mdi are applied their efficiency for the better assessment of the structure s integrity is analysed in section 3 where the impact that noise cleansing has in the accuracy of mdi is shown during the noise cleansing stage the inherent dynamic relationships between different parts of the ss are derived and those dynamic responses significantly deviating from them are cleansed in the third stage missing data present in these datasets is imputed for both the non cleansed and the cleansed scenarios the accuracy of the imputation is shown by the comparison between the imputed and the exact data values finally fatigue is estimated for four different scenarios without cleansing without mdi without cleansing with mdi with cleansing without mdi and with cleansing with mdi results show that the proposed data management framework could help the ow industry to derive more accurate fatigue life estimations to help push the boundaries of current operational periods and make the technology more competitive by reducing its lcoe 2 data management framework for offshore wind applications 2 1 data synchronisation modern wts are equipped with sophisticated scada control systems spreading on a 10 min time basis a vast amount of information including details on the wind flow and meteorological conditions on turbine alignment to the wind on the conversion of wind kinetic energy into active power on the vibrational and mechanical status of the machine on thermal conditions at relevant parts of the turbines and so on castellani et al 2017 shms data are physically collected from time to time at the discretion of the operator from the owt as the local storage capacity is limited this often coincides with regular inspection activities once data have been collected environmental data from both scada and metmast are synchronised by having one measurement for each time step typically wind measurements are recorded every 10 min and metmast measurements every 30 min as a result two synchronisation approaches could be considered every 10 min by keeping wave measurements constant for the 30 min interval or every 30 min by averaging wind conditions in this analysis the 10 min interval dataset is chosen as wind is considered to be the environmental factor contributing most to the overall loading that the structure is subject to in comparison to wave s loading therefore by having 10 min intervals wind variability is more accurately captured strain data would typically need to be temperature normalized each strain gauge that required compensation has an associated temperature channel and set of apparent strain coefficients therefore the temperature compensated strain would be the actual measured strain minus the apparent strain which depends on the temperature and the sensor material properties the apparent strain ε a is calculated as 1 ε a c 0 c 1 t c 2 t 2 c 3 t 3 c 4 t 4 where t is the value of the temperature c and c 0 to c 4 are the coefficients for the gauge batch the length of the dataset also needs to be reduced as handling 50 hz strain data is neither time nor cost efficient furthermore its synchronisation with environmental conditions would be problematic as there would be 30 000 strain measurements per each 10 min measurement of environmental conditions a solution to this issue consists of the calculation of the damage equivalent loads dels for 10 min intervals schutz 1996 ziegler and muskulus 2016 cosack 2010 dels are equivalent to the single load that would cause the same damage than the cumulative effect of the loads for the established interval which in this case is 10 or 30 min the expression is calculated with the following formula schutz 1996 ziegler and muskulus 2016 cosack 2010 2 d e l i 1 n i σ i m n e q 1 m where n i is the current cycle σ i m is the stress range n eq is a fixed number of cycles and m is the slope of the s n curve values for n eq and m can be obtained from standards such as the volume dedicated to fatigue design of offshore steel structures from dnvgl rp c203 v det norske veritas a once the dels are calculated resulting in a single dataset containing 18 months of continuous data strain data can be synchronised with environmental data provided that environmental data was previously synchronised at the same frequency than the strain data the result is a single dataset containing scada environmental wind wave and generator s active power and strain data for every 10 min any redundant data will be identified and removed during this process reducing the length of the dataset and avoiding double counting fatigue cycles 2 2 data cleansing before these datasets can be used for fatigue analysis and following the statistical pattern recognition paradigm for more information see martinez luengo et al 2016 data cleansing must take place in the offshore wind energy context cleansing is understood as two phenomena the removal of abnormal data which are believed to be abnormal not due to damage but due to external conditions i e the malfunctioning of a sensor removal of noisy data this occurs when sensors record noisy measurements strain gauges generally record noisy measurements in the presence of electric and or magnetic fields which can superimpose electrical noise on the measurement signals if not controlled the noise can lead to inaccurate results and incorrect interpretation of the strain signals vishay precision group 2013 even though sensors for shm of owt support structures are placed way below the nacelle and therefore not exposed to their electric and magnetic fields interferences could occur if they are placed close to the j tube in the tp other noise sources that could potentially introduce noise in the train measurements are transformers relays generators rotating equipment radio transmitters electrical storms poor insulation of the sensor during installation transient vibrations etc in summary any electrical device that generates consumes or transmits power is a potential source for causing noise in strain gage circuits in general the higher the voltage or current level and the closer the strain gage circuit to the electrical device the greater will be the induced noise vishay precision group 2013 it is difficult to know if a sensor is recording noise and how much the magnitude of this noise is individually but due to the embedded redundancy in the shms the relative noise can be accounted for by comparing the readings of two correlated sensors at each time stamp the concept of correlating sensors lies in the premise that depending on wind direction different pairs of sensors will exhibit behaviour of a similar trend this is illustrated in figs 2 and 3 while in fig 2 for that particular day sensors a and c were correlated and therefore exhibit the same trend in dels measurements even though there is some offset between them fig 3 shows that these same two sensors a and c were not exhibiting the same trend on another day when the wind direction did not make them in correlation when two sensors are not in correlation at a particular moment it does not necessarily mean that there is noise in their measurements it only implies that the parts of the ss where these two sensors are placed are not experiencing physically the same trend of stress and therefore sensors are not measuring the same trend of strains for a particular direction this correlation between sensors allows us to understand the offset between dels measurements when two sensors are in correlation and therefore it can be employed to cleanse the dataset whenever the noise between a pair of sensors is higher than a particular level previously established in this paper we propose a novel approach for noise identification and removal for that approach analysis of the sensors that are in correlation for particular intervals depending on the wind direction is carried out the term correlation is understood to be two sensors following the same behaviour or trend in measurements even though there might be an offset between the two initially in order to determine which sensors are in correlation at different wind directions the dataset was divided into 20deg intervals 18 in total and dels were plotted for each wind direction angle see fig 4 where dels from different sensors are plotted as it can be appreciated in this figure sensors 1 and 3 seem to be following a similar uniform trend in orientation 2 between 20 and 40 deg of wind direction however for orientation 15 280 300 deg it seems that their measurements are much more distorted this procedure was repeated several times to find which sensors would correlate at each orientation nevertheless these graphs do not show precisely the differences between sensor readings and their evolution for this reason they are not an accurate way of determining whether a new point would be within reasonable limits of noise to solve that noise thresholds have to be defined in a way that when the noise level of a particular measurement happens to fall above a predefined threshold the data point is automatically excluded from the final dataset noise thresholds are determined by calculating the difference between two sensors measurements for all wind directions the value of this difference tends to be a stable value or offset which may be zero when the pair of sensors are in perfect correlation this means that even if the difference the offset is constant around a certain value statistical distribution s mean value the standard deviation would be significantly lower whenever the sensors are in correlation and higher when they are not in order to be exhaustive all possible sensor combinations for each one of the 18 orientations were analysed for each orientation there is a total possible number of combinations c of 3 c i 1 n n 1 28 n being the number of sensors which in this case is eight afterwards a normal distribution was fitted to all computed values of the 28 sensor combinations for every orientation the mean of the normal distribution determines the offset between the measurements this offset constitutes the difference between dynamic responses of the two sensors of the combination being analysed the best indicator of the correlation between two sensors is the standard deviation of the difference between their measurements the smaller this is the more correlated these measurements are as this means that these sensors measurements follow a more similar trend in order to automatize data cleansing throughout the life of a structure firstly the noise thresholds need to be set this would be achieved by analysing the correlation between sensors for small intervals of wind direction right at the beginning of the operation of the analysed asset five degree intervals were selected for this purpose for two reasons in order to not only to capture the slightest variability of these correlations with enough accuracy but also to have enough data points to posteriorly define the polynomials that will constitute the noise thresholds in order to define the noise thresholds the dataset is divided into intervals according to wind direction which results in a total of 72 intervals 360 5 72 also for each data point the 28 sensor combinations are computed if for each sensor combination among 28 possible combinations the mean and standard deviation at all orientations 72 are plotted into a graph and a polynomial is fitted into the points the boundaries of the admissible noise can be set this can be observed in fig 5 where the mean value blue line and mean value plus and minus the standard deviations black dashed lines of the difference between sensors readings every five degrees are plotted fifth order polynomials were fitted to the points the order of these polynomials was determined after the optimisation of the fitting error was carried out fig 5 shows the particular case of the sensor 2 6 combination furthermore the two red polynomials represent a 20 noise allowance this noise allowance is set to be 20 of the standard deviation at each orientation for each new measurement if the deviation of the difference between sensors measurements is higher or lower than the thresholds red lines the data point is considered to have excessive noise and is therefore excluded from the dataset in fig 5 the mean value of the difference in dels measured by sensors 2 and 6 is shown in blue this difference is 4 δ d e l s 2 6 d e l s 2 d e l s 6 this mean value represents the offset of the measurements due to both the measurement of different physical states of the structure and difference in calibration when these sensors are installed the closer that δ d e l s 2 6 for a particular data point gets to the mean for a given wind direction the less noise this sensor s readings will have a certain noise or variation in δ d e l s 2 6 will still be expected and its magnitude will be dependent upon the level of correlation these two sensors experience throughout the wind directions this is measured by the standard deviation which determines how spread the values are in a normal distribution and accounts for 95 of the values 99 7 within 3 standard deviations of the mean the closer that the m e a n s t d d e v i a t i o n is to zero the more correlated the sensors are and therefore the more similar trend of measurements these will record when a dataset is cleansed the 28 different sensor relationships at each time step are computed thus the wind direction is used to extract the upper and lower noise thresholds for each combination which will be compared to the computed values of the combinations a noise matrix will be filled for each data point of the set whenever the computed value is within the established thresholds a 1 would be filled in the noise matrix if the measured difference of values falls outside the thresholds the noise in the measurement is considered too high therefore a 0 would be placed in the noise matrix which is composed of the following relationships 5 δ d e l s 1 1 δ d e l s 1 2 δ d e l s 1 3 δ d e l s 1 4 δ d e l s 1 5 δ d e l s 1 6 δ d e l s 1 7 δ d e l s 1 8 δ d e l s 2 1 δ d e l s 2 2 δ d e l s 2 3 δ d e l s 2 4 δ d e l s 2 5 δ d e l s 2 6 δ d e l s 2 7 δ d e l s 2 8 δ d e l s 3 1 δ d e l s 3 2 δ d e l s 3 3 δ d e l s 3 4 δ d e l s 3 5 δ d e l s 3 6 δ d e l s 3 7 δ d e l s 3 8 δ d e l s 4 1 δ d e l s 4 2 δ d e l s 4 3 δ d e l s 4 4 δ d e l s 4 5 δ d e l s 4 6 δ d e l s 4 7 δ d e l s 4 8 δ d e l s 5 1 δ d e l s 5 2 δ d e l s 5 3 δ d e l s 5 4 δ d e l s 5 5 δ d e l s 5 6 δ d e l s 5 7 δ d e l s 5 8 δ d e l s 6 1 δ d e l s 6 2 δ d e l s 6 3 δ d e l s 6 4 δ d e l s 6 5 δ d e l s 6 6 δ d e l s 6 7 δ d e l s 6 8 δ d e l s 7 1 δ d e l s 7 2 δ d e l s 7 3 δ d e l s 7 4 δ d e l s 7 5 δ d e l s 7 6 δ d e l s 7 7 δ d e l s 7 8 δ d e l s 8 1 δ d e l s 8 2 δ d e l s 8 3 δ d e l s 8 4 δ d e l s 8 5 δ d e l s 8 6 δ d e l s 8 7 δ d e l s 8 8 where the relationships between the same sensor are not considered the difference is zero by definition therefore these are marked as nan not a number in the matrix below furthermore inverse relationships are considered as if the first sensor of the difference is always the lowest number i e δ d e l s 2 1 will never be computed because it has similar characteristics to δ d e l s 1 2 therefore δ d e l s 2 1 is substituted for δ d e l s 1 2 in the matrix this procedure makes the matrix symmetric which facilitates the procedure of determining which of the sensors for a particular combination is the one presenting noise or if both are equation 6 shows the resultant noise matrix 6 n a n 1 2 1 3 1 2 n a n 2 3 1 3 2 3 n a n 1 4 1 5 2 4 2 5 3 4 3 5 1 6 1 7 1 8 2 6 2 7 2 8 3 6 3 7 3 8 1 4 2 4 3 4 1 5 2 5 3 5 1 6 2 6 3 6 n a n 4 5 4 5 n a n 4 6 5 6 4 6 4 7 4 8 5 6 5 7 5 8 n a n 6 7 6 8 1 7 2 7 3 7 4 7 5 7 6 7 n a n 7 8 1 8 2 8 3 8 4 8 5 8 6 8 7 8 n a n note for clarity the matrix above only shows the sensors combinations when a dataset is being cleansed the 28 different sensors relationships at each time step are computed and compared to the noise thresholds to determine whether or not the noise they present is admissible or not admissible 1 inadmissible 0 for each time step the noise matrix will be filled in binary once the noise matrix is complete for a particular time step each sensor of the combination is checked whenever noise is detected for that particular combination for example if the combination 1 2 shown in red in fig 6 has noise either sensor 1 sensor 2 or even both of them could have noise the criteria used to decide which one or if both of the sensors have noise is to check the overall performance of the sensors at a given time step therefore for this case all the relationships involving sensor 1 first row and sensor 2 second column are checked with three potential outcomes majority of sensor 1 s combinations have noise but not sensor 2 s combinations sum noisematrix 1 4 therefore sensor 1 s value is deleted due to excessive noise but not sensor 2 s value majority of sensor 2 s combinations have noise but not sensor 1 s combinations sum noisematrix 2 4 therefore sensor 1 s value is deleted due to excessive noise but not sensor 2 s value both sensors combinations have noise sum noisematrix 1 4 sum noisematrix 2 4 therefore both sensors values are deleted 2 3 missing data imputation after noise is removed data is checked using the criterion of completeness making sure that information is not corrupted missing data is a challenge faced in almost every empirical analysis but especially in engineering applications employing sensing technologies these technologies are by no means infallible as they can present different types of failure modes in the data collection some of these are calibration noise transmission and data storing issues and also those related to the reliability and failure mechanisms of the data acquisition system composed of the sensing technologies transmission and storage of the measurements current practice in the ow industry would ignore the missing data and select reduced intervals of complete time series that are believed to be representative to carry out their analysis this approach is practical for time consuming studies however precious data are discarded in the process having complete datasets free of noise would without doubt enhance the confidence in the fatigue life analysis and allow more realistic remaining service life estimations an effective way of dealing with missing data from shms of owts is through employing artificial neural networks ann this method was chosen as the best approach due to its applicability accuracy and consistency with the analytic software used for other data management activities during this project gheyas and smith 2010 kolios et al 2018 lazakis et al 2018 other relevant methods for mdi are mean imputation hawthorne and elliott 2005 k nearest neighbour maximum likelihood dempster et al 1977 enders 2001 eason bond lozev n d and multiple imputation methods richman et al 2009 reilly and pepe 1997 fig 7 shows the methodology followed for mdi using ann in order to train the ann input and output matrices need to be specified this process might seem trivial but often one of the most recurrent issues with shm is the excess of non necessary data and how to determine which data should should not be analysed for this application the relevant input variables include wind speed wind direction generator active power significant wave height and wave direction output data is constituted by the eight sensors previously utilised for data cleansing these sensors are located at the transition piece of the turbines once the input matrices for each dataset are created the statistical distributions of each input are derived as can be appreciated from fig 8 normal rayleigh and kernel distributions were fitted to the inputs kernel distribution being the best fit among others to the available empirical data a kernel distribution is a nonparametric representation of the probability density function of a random variable matlab 2016 kernel distributions are used when a parametric distribution cannot properly describe the data also when assumptions about the distribution of the data are better to be avoided kernel distributions are defined by a smoothing function and a bandwidth value which control the smoothness of the resulting density curve furthermore from the initial dataset a similar percentage to the one of the data removed during the cleansing would be deleted from both the original and the cleansed datasets these removed data are imputed with the anns described later and their results compared to the originals in order to assess the level of confidence that can be given to these estimations further details are explained in section 3 2 2 4 fatigue assessment the ultimate aim of this framework is to develop a data management tool that supports fatigue calculations for ss of owts in order to do so data cleansing and mdi techniques were applied to real shm data from three wts obtained from a continuous monitoring campaign therefore the fatigue that these three turbines are subject to during the monitoring campaign is assessed for the four possible scenarios as summarised in fig 9 an initial dataset without any other manipulation than eliminating missing data is used for case a without cleansing without mdi scenario case a is utilised to train the ann mentioned in section 2 2 which imputes the missing data from the original dataset constituting case b without cleansing with mdi scenario on the other hand case c with cleansing without mdi scenario is made when data are cleansed and missing data removed from the dataset afterwards this has the implication that only high quality data without noise are used for the calculation however the length of the dataset is significantly reduced which also diminishes the confidence in the remaining service life estimations lastly case d with cleansing with mdi scenario is made by employing case c s dataset to train an ann which imputes the previously removed missing data after the cleansing took place the two most commonly used fatigue assessment techniques are the stress life s n approach and the fracture mechanics approach martinez luengo et al 2017 the s n curve approach is the one recommended by dnv and iec standards see v det norske veritas b due to its straightforward implementation a review of the currently used s n curves is provided in brennan and tavares 2014 furthermore the equivalent stress range δs is determined from the four different datasets previously mentioned by calculating the del of the whole dataset in the same way as in section 3 1 having obtained the equivalent stress range the number of loading cycles to crack initiation in equation 6 can then be determined from the s n curve expressed as 7 log n a log δ s where a is the intercept m in the slope of the s n curve in the log log plot v det norske veritas b the selection of the s n curve plays a massive role in the results obtained these are generally classified in air seawater with adequate cathodic protection or free corrosion conditions and are taken from dnv rp c203 fatigue strength analyses of offshore steel structures v det norske veritas 2005 offshore structures are prone to corrosion development due to the harsh marine environment which leads to significant levels of damage to the structures and hence a reduction in service life adedipe et al 2016 for that reason curve d in seawater with adequate cathodic protection is used in service life calculations with an intercept a 15 6 and a slope m 5 3 results and discussion in this section the results of the analyses described in section 3 are presented this analysis was performed on three wts from the same owf which from now on are called turbines 1 2 and 3 for clarity purposes metocean scada and strain data were available for the three turbines and synchronised as explained in the previous section before the data cleansing started also all the data points where the turbine should have been in operation wind speeds of 4 25 m s but according to scada was shut down were deleted from the dataset this deletion is carried out so these non operational intervals do not affect the data cleansing process fig 10 shows how this filtered dataset follows the power curve 3 1 data cleansing in order to capture the dynamic response of each turbine better the synchronised datasets are divided into five intervals of wind speed these intervals consist of three operational and two not operational regimes 0 4 m s and 25 m s being the intervals of the non operational regime and 4 11 m s 11 18 m s and 18 25 m s the intervals of the operational regime this approach was chosen as it provides a good compromise between capturing well the behaviour of the turbines and having enough data in each interval for the statistical analysis the interval corresponding to wind speed greater than 25 m s had to be discarded due to the lack of samples which made the statistical analysis of this interval not possible the only data point of this interval remained uncleansed in the final dataset as it was impossible to determine whether it had noise or not therefore the assumption of no noise present in this data point was made during the analysis the different polynomials which constitute the noise thresholds for each interval for each one of the 28 sensor combinations are extracted fig 11 a and b shows an example of how these different noise thresholds may look while fig 11 a shows the great level of physical correlation that sensors 1 2 have for low wind speeds 0 4 m s with a very steady mean and standard deviation values a constant mean value of difference between sensors implies that these sensors are physically exposed to the same type of physical excitations as the average offset between these sensors does not have significant variation across the different wind directions a constant value of the standard deviation implies that the pair of sensors is continuously correlated as the deviation of their sensor readings from the mean value definition of standard deviation is constant across wind directions fig 11b shows a different situation where the correlation of sensors 3 7 is strongly influenced by the wind direction in a pattern similar to a sinusoidal wave furthermore the standard deviation also exhibits a higher degree of variation than in fig 11a by reaching local maximums in the valleys of the mean distribution and local minimums at the hills of the mean value distribution the noise thresholds are set to be 20 of the standard deviation of the difference between sensors although this percentage might seem high it was set to be a reasonable trade off between cleansing excessive noise and capturing diversions from the expected behaviour of the asset that could potentially lead to an acceleration of fatigue damage excessive cleansing would result in the removal of expected phenomena such as vibrations and sudden excitations that could locally affect the turbine wind gusts local impact of waves propagation effects or even localized damage this percentage ensures that not too much data are discarded for further analysis however it may vary depending on the level of risk that each operator is willing to take fig 12 shows the percentage of deleted data for each sensor at the three turbines and for the different wind classes which correspond to the operational regimes previously mentioned 1 0 4 m s 2 4 11 m s 3 11 18 m s and 4 18 25 m s 3 2 missing data imputation after data cleansing has taken place the missing data from the reduced but more accurate datasets are imputed with the aim of obtaining more complete datasets for the fatigue assessment anns with different structures are developed to perform this imputation and to determine whether the imputation becomes more accurate due to the data cleansing therefore following the mdi framework the three filtered and cleansed datasets from turbines 1 2 and 3 were used as inputs and outputs to train the anns the ann employed was a two layer feedforward network with a sigmoid transfer function in the hidden layer and a linear transfer function in the output layer the number of hidden neurons was optimised for each turbine after the training was done a similar percentage to the one of previously cleansed data was randomly removed from each sensor of both the original and the already cleansed datasets a record of these randomly deleted data was kept for later on when computing the deviation of the prediction from the real value verification process three different algorithms for ann training were utilised scaled conjugate gradient levenberg marquardt and bayesian normalisation levenberg marquardt is recommended by matlab 2016 for most problems but for some noisy and small problems bayesian normalisation can take longer time but achieves a better solution foresee and hagan 1997 hagan and menhaj 1999 for large problems however scaled conjugate gradient is recommended as it uses gradient calculations which are more memory efficient than the jacobian calculations the other two algorithms use moller 1993 finally levenberg marquardt was chosen for outperforming the others in terms of error minimum squared error mse and residuals r training performance regression number of iterations and training time needed figs 13 and 14 show an example of the error histogram and regression chart missing data were imputed through a number of stochastic input values to the ann a problem often presented in ann is overfitting overfitting occurs when the network has memorized the training examples but has not learned to generalize to new situations this could be the case when the performance on the training set is good but the test set performance is significantly worse the solution in this case would be reducing the number of neurons an example of overfitting can be the ann employing 1000 neurons for turbine 2 where the error is considerably higher than that of the 400 neurons ann see fig 16 in order to avoid overfitting but optimise the results the best performing architectures were chosen for each turbine these were the 200 400 and 1000 neurons for turbines 1 2 and 3 respectively the following figures show the performance of the different ann architectures for both with and without cleansing cases see figs 15 16 and 17 another aspect noticed during the cleansing process of turbine 3 was that all measurements from sensor 8 were compromised as they appeared to be two orders of magnitude lower than the expected values therefore the level of mismatching in the mdi is not surprising furthermore the results of turbine 3 show that for no apparent reason axial sensors 1 3 5 and 7 present a higher challenge for the imputation which appears to be mitigated with the cleansing but is still noticeable fig 18 represents a comparison between the best performing anns trained with and without cleansed data for the three turbines this figure shows that mdi is performed more efficiently after data cleansing has taken place as this reduces not only the mean error of the imputation but also the standard deviation of this error thus for the few cases where the mean imputation error of the dataset with previous data cleansing exceeded the one without it turbine 1 sensors 6 7 and 8 turbine 2 sensors 7 and 8 the absolute error is still smaller with data cleansing when the comparison of the performance is made see fig 19 results show that the average absolute error is 2 1 furthermore in 95 of the cases i e 2 standard deviations the error is within the range 15 2 11 0 this estimation was carried out by averaging mean value and standard deviation errors across the eight sensors for the three turbines excluding sensor 8 from turbine 3 as mentioned before besides turbine 3 presents the highest challenge to input data to having standard deviations that exceed the 20 of error in the imputation furthermore the errors presented in this section were calculated from the difference between the imputation and the exact value of dels nevertheless errors reduce considerably by checking when the imputed values are within the noise thresholds previously defined these errors are presented in table 1 3 3 fatigue assessment fatigue assessment constitutes the last step of the proposed methodology and the fundamental reason for its development this section analyses the effect that data cleansing and mdi have on the current fatigue damage estimation fatigue assessment is normally based on uncomplete datasets hence being able to impute missing data enhances the confidence in residual fatigue life estimations as the number of samples increases and can become more accurate however this imputation needs to be precise by not introducing noise or amplifying biases in the estimations data cleansing is key in keeping noise away from the datasets figs 20 22 show for each of the three turbines under consideration the effect that the four different combinations of cleansing and mdi scenarios have in fatigue calculations this analysis takes case d as its baseline due to the positive results obtained in the previous section where missing data were proven to be imputed to the exact real value with an average absolute error of 2 1 and within the range of 15 2 11 0 for 95 of the times according to figs 20 and 22 fatigue is underestimated when data cleansing and mdi are not performed this can be appreciated especially in case a without cleansing without mdi and case b without cleansing with mdi the cause is believed to be an excess of noise which contributes to the collection of lower measurements and makes stress ranges lower for the rainflow counting algorithm when data cleansing is not carried out but the mdi is there is occasional overestimation of stresses see case b sensors 1 and 6 in fig 20 and sensors 3 and 5 in fig 21 the reason is that the noise is picked up in the algorithm and reproduced making the cumulative effect to considerably increase the overall fatigue of the structure on the opposite side case c where data cleansing is carried out but mdi is not is found to underestimate fatigue for the three turbines the explanation for this phenomenon is the dramatic reduction in the number of samples considered for the fatigue calculation see table 2 the underestimation of fatigue when data cleansing is not carried out is particularly concerning the implications of the underestimation of fatigue loads may seem small at this stage however these estimations have been made after two years of operation and at not critical locations this means that while the difference in fatigue damage is currently not an issue after ten years of operation it could make a difference to the remaining service life calculations when an underestimated stress range is introduced in the s n curve furthermore sensors are not installed at turbine s hot spots meaning that the measurements they collect are potentially 5 10 times smaller than they could be at hot spots martinez luengo et al 2017 the underestimation of fatigue could potentially make a big impact at these hot spots and in the remaining service life of the structure 4 conclusion and future work in this study a framework for the effective data management of shms was developed enabling the continuous analysis of offshore wind turbines structural integrity throughout the life cycle the synchronisation between environmental data scada and metocean and real continuously monitored 50 hz strain data collected from three different owts currently in operation in the irish sea led to datasets over three years long however these three datasets were incomplete noise cleansing and mdi were carried out with the purpose of determining their benefits in continuous fatigue assessment of offshore wind turbines two scenarios were considered for each wind turbine with and without noise cleansing our results confirmed that in those cases where data cleansing was carried out the average imputation error was about 2 1 furthermore in 95 of the cases the error was within the range 15 2 11 0 the results indicated that noise cleansing and mdi could successfully be employed together to produce more complete datasets containing real low disturbed strain data furthermore fatigue was estimated for the four different cases namely i without cleansing without mdi case a ii without cleansing with mdi case b iii with cleansing without mdi case c and iv with cleansing with mdi case d results showed that for the wind turbines 1 and 3 fatigue was underestimated when data cleansing had not been performed the cause is believed to be an excess of noise which contributes to the collection of more uniform cycles of fatigue in case c where data cleansing was carried out but mdi was not fatigue was found to be underestimated for all the three turbines also there was an overestimation of fatigue in some sensors when data cleansing was not carried out but mdi was the reason is that the noise is picked up in the mdi algorithm and reproduced making the cumulative effect to considerably increase the overall fatigue of the structure currently fatigue analyses are often performed based on uncomplete datasets the methodology presented in this research provides the possibility of enhancing the confidence in fatigue life estimations by increasing the length of the datasets through firstly data cleansing and secondly mdi the results obtained validate our two novel methodologies making it a suitable tool for better evaluation of offshore wind turbines structural integrity we are exploring some opportunities to implement the proposed approaches in the wind energy sector with the aim of deriving more accurate fatigue life estimations to help push the boundaries of current operational periods and make the technology more competitive by reducing its lcoe further work could potentially focus on accounting for the degradation in the accuracy of sensor readings increase in noise across the years comparing different periods across the life of a windfarm a comparison between the performance of the proposed ann method and some other techniques such as random forest support vector machine svm and gaussian process regression is in our research agenda acknowledgements this work was supported by grant ep l016303 1 for cranfield university centre for doctoral training in renewable energy marine structures rems http www rems cdt ac uk from the uk engineering and physical sciences research council epsrc and innogy se 
23029,structural health monitoring shm and condition monitoring cm systems are currently utilised to collect data from offshore wind turbines owts to enhance the accurate estimation of their operational performance however industry accepted practices for effectively managing the information that these systems provide have not been widely established yet this paper presents a four step methodological framework for the effective data management of shm systems of owts and illustrates its applicability in real time continuous data collected from three operational units with the aim of utilising more complete and accurate datasets for fatigue life assessment of support structures firstly a time efficient synchronisation method that enables the continuous monitoring of these systems is presented followed by a novel approach to noise cleansing and the posterior missing data imputation mdi by the implementation of these techniques those data points containing excessive noise are removed from the dataset step 2 advanced numerical tools are employed to regenerate missing data step 3 and fatigue is estimated for the results of these two methodologies step 4 results show that after cleansing missing data can be imputed with an average absolute error of 2 1 while this error is kept within the 15 2 11 0 range in 95 of cases furthermore only 0 15 of the imputed data fell outside the noise thresholds fatigue is found to be underestimated both when data cleansing does not take place and when it takes place but mdi does not this makes this novel methodology an enhancement to conventional structural integrity assessment techniques that do not employ continuous datasets in their analyses keywords structural health monitoring shm offshore wind data synchronisation noise cleansing missing data imputation artificial neural network ann acronyms ann artificial neural network owf offshore wind farm cm condition monitoring owt offshore wind turbine dels damage equivalent loads o m operation and maintenance fea finite element analysis r residuals lcoe levelized cost of energy scada supervisory control and data acquisition mdi missing data imputation shm structural health monitoring mse minimum squared error shms structural health monitoring systems oma operational modal analysis ss support structure ow offshore wind wts wind turbines 1 introduction structural health monitoring systems shms have become relevant in the last decade for the operational management of offshore wind turbines owts due to their damage detection and continuous fatigue life assessment capabilities operation and maintenance o m related costs are a significant contributor to the levelized cost of energy lcoe shafiee et al 2016 shafiee and sørensen 2018 while in the past shms were installed as a way to abide by the german regulations imposing a 10 of assets instrumented across an offshore wind farm owf and not exploited to their full potential nowadays operators have realized how these technologies could result in an increase in electricity production and thereby a reduction in lcoe ioannou et al 2018 myhr et al 2014 over the past decades many researchers from the shm community have developed an extensive amount of methods based on a variety of physically interpretable structural features hansen et al 2017 at this point in time there is no widely accepted practice with respect to the specification of monitoring systems as industry is still exploring wts potential making every wind farm different in terms of technologies implemented number and location of the sensors redundancies etc most of these fatigue assessment methods rely on collected data from either accelerometers strain gauges or the combination of both from selected instrumented units luengo and kolios 2015 martinez luengo et al 2016 numerous authors have carried out different ways of analysing shms data for example a vibration based damage localization and quantification method based on natural frequencies and mode shapes extracted by means of operational modal analysis oma combined with finite element analysis fea of the test structure hansen et al 2017 another approach to fatigue assessment is by the extrapolation of the dynamic behaviour of owts from a limited set of sensors existing monitoring strategies for monopiles are based on physical models or artificial intelligence ziegler et al 2017 model based time domain algorithms require accelerometers and sometimes strain gauges on the structure these try to reproduce the time history of dynamic response parameters such as acceleration or strain of the whole structure for different operational regimes this was carried out by employing kalman filters maes et al 2016a fallais et al 2016 joint input state estimation maes et al 2016b and modal expansion algorithms maes et al 2016b iliopoulos et al 2014 2016 even though accelerometers might be placed in the wt s nacelle for supervisory control and data acquisition scada or condition monitoring cm purposes they are not so often placed at different levels of the support structure ss unless there is a particular interest in its vibration monitoring however installing these accelerometers at different levels of the turbine is more expensive besides accelerometers alone do not cover all the necessary frequencies needed for modal expansion algorithms as maes et al 2016b explains making strain gauges also necessary furthermore sometimes wts are only instrumented with strain gauges especially those commissioned more than five years ago most fatigue sensitive spots called hot spots in owts are inaccessible for direct measurements i e at welds or mudline iliopoulos et al 2017 different methods have been utilised to accurately predict the structure s response at these important locations where strain gauges cannot be installed this is achieved by combining measurements from sub optimal locations with fea ziegler et al 2017 iliopoulos et al 2014 2017 martinez luengo et al 2017 gentils et al 2017 to extrapolate to the critical locations sometimes datasets at accessible locations are not complete due to failure in acquiring or recording the data full storage space high noise etc the issue of limited information due to limited availability of operational data could be mitigated by these feas this hypothesis has been supported in different articles where accurate load estimation is believed to be best carried out with data driven models requiring only a short period of mechanical strain measurements smolka and cheng 2013 however this approach of using incomplete shm datasets is questionable not only for deriving service life estimations from reduced time intervals but also for introducing uncertainty in the estimations and wasting costly shm data that could potentially be utilised for damage detection and quantification strategies as mentioned earlier oma introduces uncertainty in the estimations according to banfi and carassale the available mathematical oma techniques have the common feature that the unmeasured excitation is modelled as a random process specified by some probabilistic models banfi et al 2017 in practical applications the length of the measurement is limited and the probabilistic model adopted to represent the excitation does not necessarily apply this together with measurement errors leads to uncertainties of a different nature that affect the estimation of the modal parameters finally it seems impractical to install multiple sensors and dedicate resources to analysing their measurements without obtaining a long term view of how the system behaves and degrades noise is inherent to data acquisition signals in realistic applications are inevitably contaminated with measurement noise as well as other sorts of variabilities and uncertainties such as calibration issues transmission or de synchronisation between the real and the recorded time stamp as a result the shm features extracted from the contaminated data such as damage equivalent loads dels power spectrum and frequency response function are also noisy mao and todd 2012 2013 uncertainty could contaminate the extracted shm features dramatically if the data quality is poor and thereby causes ambiguity in interpreting the features sarrafi and mao 2017 usually the uncertainty will raise false alarms in the damage detection i e non damage induced feature deviation from the undamaged baseline therefore noise identification and quantification in shms data should not be ignored and ideally should take place before fatigue assessment besides a systematic approach to the effective data management of these shms installed in owts prior fatigue assessment has not been established yet either in the literature or by regulations this paper aims to develop a methodological framework for the effective data management of shms of owts by addressing the issues of missing data and noise in the acquired data which influence the effective fatigue assessment of offshore wind ow energy assets this is achieved through a four step process including synchronisation cleansing imputation and fatigue assessment that enables the continuous analysis of the unit s structural integrity and remaining service life throughout the years as highlighted in fig 1 this novel framework is implemented by utilising real and continuously monitored 50 hz strain data collected from three different owts currently in operation for over three years these turbines were instrumented with shms during their commissioning therefore it is assumed that no previous fatigue damage from the commissioning phase was undertaken by the turbine without being captured and that the noise calibration error present in the measurements used to derive the dynamic structural behaviour of the units is minimum this article highlights the importance of appropriate data handling of shms for the continuous fatigue assessment of an owt s ss the four stage methodology proposed in fig 1 is implemented in section 2 and its results discussed in section 3 after data synchronisation takes place noise cleansing and missing data imputation mdi are applied their efficiency for the better assessment of the structure s integrity is analysed in section 3 where the impact that noise cleansing has in the accuracy of mdi is shown during the noise cleansing stage the inherent dynamic relationships between different parts of the ss are derived and those dynamic responses significantly deviating from them are cleansed in the third stage missing data present in these datasets is imputed for both the non cleansed and the cleansed scenarios the accuracy of the imputation is shown by the comparison between the imputed and the exact data values finally fatigue is estimated for four different scenarios without cleansing without mdi without cleansing with mdi with cleansing without mdi and with cleansing with mdi results show that the proposed data management framework could help the ow industry to derive more accurate fatigue life estimations to help push the boundaries of current operational periods and make the technology more competitive by reducing its lcoe 2 data management framework for offshore wind applications 2 1 data synchronisation modern wts are equipped with sophisticated scada control systems spreading on a 10 min time basis a vast amount of information including details on the wind flow and meteorological conditions on turbine alignment to the wind on the conversion of wind kinetic energy into active power on the vibrational and mechanical status of the machine on thermal conditions at relevant parts of the turbines and so on castellani et al 2017 shms data are physically collected from time to time at the discretion of the operator from the owt as the local storage capacity is limited this often coincides with regular inspection activities once data have been collected environmental data from both scada and metmast are synchronised by having one measurement for each time step typically wind measurements are recorded every 10 min and metmast measurements every 30 min as a result two synchronisation approaches could be considered every 10 min by keeping wave measurements constant for the 30 min interval or every 30 min by averaging wind conditions in this analysis the 10 min interval dataset is chosen as wind is considered to be the environmental factor contributing most to the overall loading that the structure is subject to in comparison to wave s loading therefore by having 10 min intervals wind variability is more accurately captured strain data would typically need to be temperature normalized each strain gauge that required compensation has an associated temperature channel and set of apparent strain coefficients therefore the temperature compensated strain would be the actual measured strain minus the apparent strain which depends on the temperature and the sensor material properties the apparent strain ε a is calculated as 1 ε a c 0 c 1 t c 2 t 2 c 3 t 3 c 4 t 4 where t is the value of the temperature c and c 0 to c 4 are the coefficients for the gauge batch the length of the dataset also needs to be reduced as handling 50 hz strain data is neither time nor cost efficient furthermore its synchronisation with environmental conditions would be problematic as there would be 30 000 strain measurements per each 10 min measurement of environmental conditions a solution to this issue consists of the calculation of the damage equivalent loads dels for 10 min intervals schutz 1996 ziegler and muskulus 2016 cosack 2010 dels are equivalent to the single load that would cause the same damage than the cumulative effect of the loads for the established interval which in this case is 10 or 30 min the expression is calculated with the following formula schutz 1996 ziegler and muskulus 2016 cosack 2010 2 d e l i 1 n i σ i m n e q 1 m where n i is the current cycle σ i m is the stress range n eq is a fixed number of cycles and m is the slope of the s n curve values for n eq and m can be obtained from standards such as the volume dedicated to fatigue design of offshore steel structures from dnvgl rp c203 v det norske veritas a once the dels are calculated resulting in a single dataset containing 18 months of continuous data strain data can be synchronised with environmental data provided that environmental data was previously synchronised at the same frequency than the strain data the result is a single dataset containing scada environmental wind wave and generator s active power and strain data for every 10 min any redundant data will be identified and removed during this process reducing the length of the dataset and avoiding double counting fatigue cycles 2 2 data cleansing before these datasets can be used for fatigue analysis and following the statistical pattern recognition paradigm for more information see martinez luengo et al 2016 data cleansing must take place in the offshore wind energy context cleansing is understood as two phenomena the removal of abnormal data which are believed to be abnormal not due to damage but due to external conditions i e the malfunctioning of a sensor removal of noisy data this occurs when sensors record noisy measurements strain gauges generally record noisy measurements in the presence of electric and or magnetic fields which can superimpose electrical noise on the measurement signals if not controlled the noise can lead to inaccurate results and incorrect interpretation of the strain signals vishay precision group 2013 even though sensors for shm of owt support structures are placed way below the nacelle and therefore not exposed to their electric and magnetic fields interferences could occur if they are placed close to the j tube in the tp other noise sources that could potentially introduce noise in the train measurements are transformers relays generators rotating equipment radio transmitters electrical storms poor insulation of the sensor during installation transient vibrations etc in summary any electrical device that generates consumes or transmits power is a potential source for causing noise in strain gage circuits in general the higher the voltage or current level and the closer the strain gage circuit to the electrical device the greater will be the induced noise vishay precision group 2013 it is difficult to know if a sensor is recording noise and how much the magnitude of this noise is individually but due to the embedded redundancy in the shms the relative noise can be accounted for by comparing the readings of two correlated sensors at each time stamp the concept of correlating sensors lies in the premise that depending on wind direction different pairs of sensors will exhibit behaviour of a similar trend this is illustrated in figs 2 and 3 while in fig 2 for that particular day sensors a and c were correlated and therefore exhibit the same trend in dels measurements even though there is some offset between them fig 3 shows that these same two sensors a and c were not exhibiting the same trend on another day when the wind direction did not make them in correlation when two sensors are not in correlation at a particular moment it does not necessarily mean that there is noise in their measurements it only implies that the parts of the ss where these two sensors are placed are not experiencing physically the same trend of stress and therefore sensors are not measuring the same trend of strains for a particular direction this correlation between sensors allows us to understand the offset between dels measurements when two sensors are in correlation and therefore it can be employed to cleanse the dataset whenever the noise between a pair of sensors is higher than a particular level previously established in this paper we propose a novel approach for noise identification and removal for that approach analysis of the sensors that are in correlation for particular intervals depending on the wind direction is carried out the term correlation is understood to be two sensors following the same behaviour or trend in measurements even though there might be an offset between the two initially in order to determine which sensors are in correlation at different wind directions the dataset was divided into 20deg intervals 18 in total and dels were plotted for each wind direction angle see fig 4 where dels from different sensors are plotted as it can be appreciated in this figure sensors 1 and 3 seem to be following a similar uniform trend in orientation 2 between 20 and 40 deg of wind direction however for orientation 15 280 300 deg it seems that their measurements are much more distorted this procedure was repeated several times to find which sensors would correlate at each orientation nevertheless these graphs do not show precisely the differences between sensor readings and their evolution for this reason they are not an accurate way of determining whether a new point would be within reasonable limits of noise to solve that noise thresholds have to be defined in a way that when the noise level of a particular measurement happens to fall above a predefined threshold the data point is automatically excluded from the final dataset noise thresholds are determined by calculating the difference between two sensors measurements for all wind directions the value of this difference tends to be a stable value or offset which may be zero when the pair of sensors are in perfect correlation this means that even if the difference the offset is constant around a certain value statistical distribution s mean value the standard deviation would be significantly lower whenever the sensors are in correlation and higher when they are not in order to be exhaustive all possible sensor combinations for each one of the 18 orientations were analysed for each orientation there is a total possible number of combinations c of 3 c i 1 n n 1 28 n being the number of sensors which in this case is eight afterwards a normal distribution was fitted to all computed values of the 28 sensor combinations for every orientation the mean of the normal distribution determines the offset between the measurements this offset constitutes the difference between dynamic responses of the two sensors of the combination being analysed the best indicator of the correlation between two sensors is the standard deviation of the difference between their measurements the smaller this is the more correlated these measurements are as this means that these sensors measurements follow a more similar trend in order to automatize data cleansing throughout the life of a structure firstly the noise thresholds need to be set this would be achieved by analysing the correlation between sensors for small intervals of wind direction right at the beginning of the operation of the analysed asset five degree intervals were selected for this purpose for two reasons in order to not only to capture the slightest variability of these correlations with enough accuracy but also to have enough data points to posteriorly define the polynomials that will constitute the noise thresholds in order to define the noise thresholds the dataset is divided into intervals according to wind direction which results in a total of 72 intervals 360 5 72 also for each data point the 28 sensor combinations are computed if for each sensor combination among 28 possible combinations the mean and standard deviation at all orientations 72 are plotted into a graph and a polynomial is fitted into the points the boundaries of the admissible noise can be set this can be observed in fig 5 where the mean value blue line and mean value plus and minus the standard deviations black dashed lines of the difference between sensors readings every five degrees are plotted fifth order polynomials were fitted to the points the order of these polynomials was determined after the optimisation of the fitting error was carried out fig 5 shows the particular case of the sensor 2 6 combination furthermore the two red polynomials represent a 20 noise allowance this noise allowance is set to be 20 of the standard deviation at each orientation for each new measurement if the deviation of the difference between sensors measurements is higher or lower than the thresholds red lines the data point is considered to have excessive noise and is therefore excluded from the dataset in fig 5 the mean value of the difference in dels measured by sensors 2 and 6 is shown in blue this difference is 4 δ d e l s 2 6 d e l s 2 d e l s 6 this mean value represents the offset of the measurements due to both the measurement of different physical states of the structure and difference in calibration when these sensors are installed the closer that δ d e l s 2 6 for a particular data point gets to the mean for a given wind direction the less noise this sensor s readings will have a certain noise or variation in δ d e l s 2 6 will still be expected and its magnitude will be dependent upon the level of correlation these two sensors experience throughout the wind directions this is measured by the standard deviation which determines how spread the values are in a normal distribution and accounts for 95 of the values 99 7 within 3 standard deviations of the mean the closer that the m e a n s t d d e v i a t i o n is to zero the more correlated the sensors are and therefore the more similar trend of measurements these will record when a dataset is cleansed the 28 different sensor relationships at each time step are computed thus the wind direction is used to extract the upper and lower noise thresholds for each combination which will be compared to the computed values of the combinations a noise matrix will be filled for each data point of the set whenever the computed value is within the established thresholds a 1 would be filled in the noise matrix if the measured difference of values falls outside the thresholds the noise in the measurement is considered too high therefore a 0 would be placed in the noise matrix which is composed of the following relationships 5 δ d e l s 1 1 δ d e l s 1 2 δ d e l s 1 3 δ d e l s 1 4 δ d e l s 1 5 δ d e l s 1 6 δ d e l s 1 7 δ d e l s 1 8 δ d e l s 2 1 δ d e l s 2 2 δ d e l s 2 3 δ d e l s 2 4 δ d e l s 2 5 δ d e l s 2 6 δ d e l s 2 7 δ d e l s 2 8 δ d e l s 3 1 δ d e l s 3 2 δ d e l s 3 3 δ d e l s 3 4 δ d e l s 3 5 δ d e l s 3 6 δ d e l s 3 7 δ d e l s 3 8 δ d e l s 4 1 δ d e l s 4 2 δ d e l s 4 3 δ d e l s 4 4 δ d e l s 4 5 δ d e l s 4 6 δ d e l s 4 7 δ d e l s 4 8 δ d e l s 5 1 δ d e l s 5 2 δ d e l s 5 3 δ d e l s 5 4 δ d e l s 5 5 δ d e l s 5 6 δ d e l s 5 7 δ d e l s 5 8 δ d e l s 6 1 δ d e l s 6 2 δ d e l s 6 3 δ d e l s 6 4 δ d e l s 6 5 δ d e l s 6 6 δ d e l s 6 7 δ d e l s 6 8 δ d e l s 7 1 δ d e l s 7 2 δ d e l s 7 3 δ d e l s 7 4 δ d e l s 7 5 δ d e l s 7 6 δ d e l s 7 7 δ d e l s 7 8 δ d e l s 8 1 δ d e l s 8 2 δ d e l s 8 3 δ d e l s 8 4 δ d e l s 8 5 δ d e l s 8 6 δ d e l s 8 7 δ d e l s 8 8 where the relationships between the same sensor are not considered the difference is zero by definition therefore these are marked as nan not a number in the matrix below furthermore inverse relationships are considered as if the first sensor of the difference is always the lowest number i e δ d e l s 2 1 will never be computed because it has similar characteristics to δ d e l s 1 2 therefore δ d e l s 2 1 is substituted for δ d e l s 1 2 in the matrix this procedure makes the matrix symmetric which facilitates the procedure of determining which of the sensors for a particular combination is the one presenting noise or if both are equation 6 shows the resultant noise matrix 6 n a n 1 2 1 3 1 2 n a n 2 3 1 3 2 3 n a n 1 4 1 5 2 4 2 5 3 4 3 5 1 6 1 7 1 8 2 6 2 7 2 8 3 6 3 7 3 8 1 4 2 4 3 4 1 5 2 5 3 5 1 6 2 6 3 6 n a n 4 5 4 5 n a n 4 6 5 6 4 6 4 7 4 8 5 6 5 7 5 8 n a n 6 7 6 8 1 7 2 7 3 7 4 7 5 7 6 7 n a n 7 8 1 8 2 8 3 8 4 8 5 8 6 8 7 8 n a n note for clarity the matrix above only shows the sensors combinations when a dataset is being cleansed the 28 different sensors relationships at each time step are computed and compared to the noise thresholds to determine whether or not the noise they present is admissible or not admissible 1 inadmissible 0 for each time step the noise matrix will be filled in binary once the noise matrix is complete for a particular time step each sensor of the combination is checked whenever noise is detected for that particular combination for example if the combination 1 2 shown in red in fig 6 has noise either sensor 1 sensor 2 or even both of them could have noise the criteria used to decide which one or if both of the sensors have noise is to check the overall performance of the sensors at a given time step therefore for this case all the relationships involving sensor 1 first row and sensor 2 second column are checked with three potential outcomes majority of sensor 1 s combinations have noise but not sensor 2 s combinations sum noisematrix 1 4 therefore sensor 1 s value is deleted due to excessive noise but not sensor 2 s value majority of sensor 2 s combinations have noise but not sensor 1 s combinations sum noisematrix 2 4 therefore sensor 1 s value is deleted due to excessive noise but not sensor 2 s value both sensors combinations have noise sum noisematrix 1 4 sum noisematrix 2 4 therefore both sensors values are deleted 2 3 missing data imputation after noise is removed data is checked using the criterion of completeness making sure that information is not corrupted missing data is a challenge faced in almost every empirical analysis but especially in engineering applications employing sensing technologies these technologies are by no means infallible as they can present different types of failure modes in the data collection some of these are calibration noise transmission and data storing issues and also those related to the reliability and failure mechanisms of the data acquisition system composed of the sensing technologies transmission and storage of the measurements current practice in the ow industry would ignore the missing data and select reduced intervals of complete time series that are believed to be representative to carry out their analysis this approach is practical for time consuming studies however precious data are discarded in the process having complete datasets free of noise would without doubt enhance the confidence in the fatigue life analysis and allow more realistic remaining service life estimations an effective way of dealing with missing data from shms of owts is through employing artificial neural networks ann this method was chosen as the best approach due to its applicability accuracy and consistency with the analytic software used for other data management activities during this project gheyas and smith 2010 kolios et al 2018 lazakis et al 2018 other relevant methods for mdi are mean imputation hawthorne and elliott 2005 k nearest neighbour maximum likelihood dempster et al 1977 enders 2001 eason bond lozev n d and multiple imputation methods richman et al 2009 reilly and pepe 1997 fig 7 shows the methodology followed for mdi using ann in order to train the ann input and output matrices need to be specified this process might seem trivial but often one of the most recurrent issues with shm is the excess of non necessary data and how to determine which data should should not be analysed for this application the relevant input variables include wind speed wind direction generator active power significant wave height and wave direction output data is constituted by the eight sensors previously utilised for data cleansing these sensors are located at the transition piece of the turbines once the input matrices for each dataset are created the statistical distributions of each input are derived as can be appreciated from fig 8 normal rayleigh and kernel distributions were fitted to the inputs kernel distribution being the best fit among others to the available empirical data a kernel distribution is a nonparametric representation of the probability density function of a random variable matlab 2016 kernel distributions are used when a parametric distribution cannot properly describe the data also when assumptions about the distribution of the data are better to be avoided kernel distributions are defined by a smoothing function and a bandwidth value which control the smoothness of the resulting density curve furthermore from the initial dataset a similar percentage to the one of the data removed during the cleansing would be deleted from both the original and the cleansed datasets these removed data are imputed with the anns described later and their results compared to the originals in order to assess the level of confidence that can be given to these estimations further details are explained in section 3 2 2 4 fatigue assessment the ultimate aim of this framework is to develop a data management tool that supports fatigue calculations for ss of owts in order to do so data cleansing and mdi techniques were applied to real shm data from three wts obtained from a continuous monitoring campaign therefore the fatigue that these three turbines are subject to during the monitoring campaign is assessed for the four possible scenarios as summarised in fig 9 an initial dataset without any other manipulation than eliminating missing data is used for case a without cleansing without mdi scenario case a is utilised to train the ann mentioned in section 2 2 which imputes the missing data from the original dataset constituting case b without cleansing with mdi scenario on the other hand case c with cleansing without mdi scenario is made when data are cleansed and missing data removed from the dataset afterwards this has the implication that only high quality data without noise are used for the calculation however the length of the dataset is significantly reduced which also diminishes the confidence in the remaining service life estimations lastly case d with cleansing with mdi scenario is made by employing case c s dataset to train an ann which imputes the previously removed missing data after the cleansing took place the two most commonly used fatigue assessment techniques are the stress life s n approach and the fracture mechanics approach martinez luengo et al 2017 the s n curve approach is the one recommended by dnv and iec standards see v det norske veritas b due to its straightforward implementation a review of the currently used s n curves is provided in brennan and tavares 2014 furthermore the equivalent stress range δs is determined from the four different datasets previously mentioned by calculating the del of the whole dataset in the same way as in section 3 1 having obtained the equivalent stress range the number of loading cycles to crack initiation in equation 6 can then be determined from the s n curve expressed as 7 log n a log δ s where a is the intercept m in the slope of the s n curve in the log log plot v det norske veritas b the selection of the s n curve plays a massive role in the results obtained these are generally classified in air seawater with adequate cathodic protection or free corrosion conditions and are taken from dnv rp c203 fatigue strength analyses of offshore steel structures v det norske veritas 2005 offshore structures are prone to corrosion development due to the harsh marine environment which leads to significant levels of damage to the structures and hence a reduction in service life adedipe et al 2016 for that reason curve d in seawater with adequate cathodic protection is used in service life calculations with an intercept a 15 6 and a slope m 5 3 results and discussion in this section the results of the analyses described in section 3 are presented this analysis was performed on three wts from the same owf which from now on are called turbines 1 2 and 3 for clarity purposes metocean scada and strain data were available for the three turbines and synchronised as explained in the previous section before the data cleansing started also all the data points where the turbine should have been in operation wind speeds of 4 25 m s but according to scada was shut down were deleted from the dataset this deletion is carried out so these non operational intervals do not affect the data cleansing process fig 10 shows how this filtered dataset follows the power curve 3 1 data cleansing in order to capture the dynamic response of each turbine better the synchronised datasets are divided into five intervals of wind speed these intervals consist of three operational and two not operational regimes 0 4 m s and 25 m s being the intervals of the non operational regime and 4 11 m s 11 18 m s and 18 25 m s the intervals of the operational regime this approach was chosen as it provides a good compromise between capturing well the behaviour of the turbines and having enough data in each interval for the statistical analysis the interval corresponding to wind speed greater than 25 m s had to be discarded due to the lack of samples which made the statistical analysis of this interval not possible the only data point of this interval remained uncleansed in the final dataset as it was impossible to determine whether it had noise or not therefore the assumption of no noise present in this data point was made during the analysis the different polynomials which constitute the noise thresholds for each interval for each one of the 28 sensor combinations are extracted fig 11 a and b shows an example of how these different noise thresholds may look while fig 11 a shows the great level of physical correlation that sensors 1 2 have for low wind speeds 0 4 m s with a very steady mean and standard deviation values a constant mean value of difference between sensors implies that these sensors are physically exposed to the same type of physical excitations as the average offset between these sensors does not have significant variation across the different wind directions a constant value of the standard deviation implies that the pair of sensors is continuously correlated as the deviation of their sensor readings from the mean value definition of standard deviation is constant across wind directions fig 11b shows a different situation where the correlation of sensors 3 7 is strongly influenced by the wind direction in a pattern similar to a sinusoidal wave furthermore the standard deviation also exhibits a higher degree of variation than in fig 11a by reaching local maximums in the valleys of the mean distribution and local minimums at the hills of the mean value distribution the noise thresholds are set to be 20 of the standard deviation of the difference between sensors although this percentage might seem high it was set to be a reasonable trade off between cleansing excessive noise and capturing diversions from the expected behaviour of the asset that could potentially lead to an acceleration of fatigue damage excessive cleansing would result in the removal of expected phenomena such as vibrations and sudden excitations that could locally affect the turbine wind gusts local impact of waves propagation effects or even localized damage this percentage ensures that not too much data are discarded for further analysis however it may vary depending on the level of risk that each operator is willing to take fig 12 shows the percentage of deleted data for each sensor at the three turbines and for the different wind classes which correspond to the operational regimes previously mentioned 1 0 4 m s 2 4 11 m s 3 11 18 m s and 4 18 25 m s 3 2 missing data imputation after data cleansing has taken place the missing data from the reduced but more accurate datasets are imputed with the aim of obtaining more complete datasets for the fatigue assessment anns with different structures are developed to perform this imputation and to determine whether the imputation becomes more accurate due to the data cleansing therefore following the mdi framework the three filtered and cleansed datasets from turbines 1 2 and 3 were used as inputs and outputs to train the anns the ann employed was a two layer feedforward network with a sigmoid transfer function in the hidden layer and a linear transfer function in the output layer the number of hidden neurons was optimised for each turbine after the training was done a similar percentage to the one of previously cleansed data was randomly removed from each sensor of both the original and the already cleansed datasets a record of these randomly deleted data was kept for later on when computing the deviation of the prediction from the real value verification process three different algorithms for ann training were utilised scaled conjugate gradient levenberg marquardt and bayesian normalisation levenberg marquardt is recommended by matlab 2016 for most problems but for some noisy and small problems bayesian normalisation can take longer time but achieves a better solution foresee and hagan 1997 hagan and menhaj 1999 for large problems however scaled conjugate gradient is recommended as it uses gradient calculations which are more memory efficient than the jacobian calculations the other two algorithms use moller 1993 finally levenberg marquardt was chosen for outperforming the others in terms of error minimum squared error mse and residuals r training performance regression number of iterations and training time needed figs 13 and 14 show an example of the error histogram and regression chart missing data were imputed through a number of stochastic input values to the ann a problem often presented in ann is overfitting overfitting occurs when the network has memorized the training examples but has not learned to generalize to new situations this could be the case when the performance on the training set is good but the test set performance is significantly worse the solution in this case would be reducing the number of neurons an example of overfitting can be the ann employing 1000 neurons for turbine 2 where the error is considerably higher than that of the 400 neurons ann see fig 16 in order to avoid overfitting but optimise the results the best performing architectures were chosen for each turbine these were the 200 400 and 1000 neurons for turbines 1 2 and 3 respectively the following figures show the performance of the different ann architectures for both with and without cleansing cases see figs 15 16 and 17 another aspect noticed during the cleansing process of turbine 3 was that all measurements from sensor 8 were compromised as they appeared to be two orders of magnitude lower than the expected values therefore the level of mismatching in the mdi is not surprising furthermore the results of turbine 3 show that for no apparent reason axial sensors 1 3 5 and 7 present a higher challenge for the imputation which appears to be mitigated with the cleansing but is still noticeable fig 18 represents a comparison between the best performing anns trained with and without cleansed data for the three turbines this figure shows that mdi is performed more efficiently after data cleansing has taken place as this reduces not only the mean error of the imputation but also the standard deviation of this error thus for the few cases where the mean imputation error of the dataset with previous data cleansing exceeded the one without it turbine 1 sensors 6 7 and 8 turbine 2 sensors 7 and 8 the absolute error is still smaller with data cleansing when the comparison of the performance is made see fig 19 results show that the average absolute error is 2 1 furthermore in 95 of the cases i e 2 standard deviations the error is within the range 15 2 11 0 this estimation was carried out by averaging mean value and standard deviation errors across the eight sensors for the three turbines excluding sensor 8 from turbine 3 as mentioned before besides turbine 3 presents the highest challenge to input data to having standard deviations that exceed the 20 of error in the imputation furthermore the errors presented in this section were calculated from the difference between the imputation and the exact value of dels nevertheless errors reduce considerably by checking when the imputed values are within the noise thresholds previously defined these errors are presented in table 1 3 3 fatigue assessment fatigue assessment constitutes the last step of the proposed methodology and the fundamental reason for its development this section analyses the effect that data cleansing and mdi have on the current fatigue damage estimation fatigue assessment is normally based on uncomplete datasets hence being able to impute missing data enhances the confidence in residual fatigue life estimations as the number of samples increases and can become more accurate however this imputation needs to be precise by not introducing noise or amplifying biases in the estimations data cleansing is key in keeping noise away from the datasets figs 20 22 show for each of the three turbines under consideration the effect that the four different combinations of cleansing and mdi scenarios have in fatigue calculations this analysis takes case d as its baseline due to the positive results obtained in the previous section where missing data were proven to be imputed to the exact real value with an average absolute error of 2 1 and within the range of 15 2 11 0 for 95 of the times according to figs 20 and 22 fatigue is underestimated when data cleansing and mdi are not performed this can be appreciated especially in case a without cleansing without mdi and case b without cleansing with mdi the cause is believed to be an excess of noise which contributes to the collection of lower measurements and makes stress ranges lower for the rainflow counting algorithm when data cleansing is not carried out but the mdi is there is occasional overestimation of stresses see case b sensors 1 and 6 in fig 20 and sensors 3 and 5 in fig 21 the reason is that the noise is picked up in the algorithm and reproduced making the cumulative effect to considerably increase the overall fatigue of the structure on the opposite side case c where data cleansing is carried out but mdi is not is found to underestimate fatigue for the three turbines the explanation for this phenomenon is the dramatic reduction in the number of samples considered for the fatigue calculation see table 2 the underestimation of fatigue when data cleansing is not carried out is particularly concerning the implications of the underestimation of fatigue loads may seem small at this stage however these estimations have been made after two years of operation and at not critical locations this means that while the difference in fatigue damage is currently not an issue after ten years of operation it could make a difference to the remaining service life calculations when an underestimated stress range is introduced in the s n curve furthermore sensors are not installed at turbine s hot spots meaning that the measurements they collect are potentially 5 10 times smaller than they could be at hot spots martinez luengo et al 2017 the underestimation of fatigue could potentially make a big impact at these hot spots and in the remaining service life of the structure 4 conclusion and future work in this study a framework for the effective data management of shms was developed enabling the continuous analysis of offshore wind turbines structural integrity throughout the life cycle the synchronisation between environmental data scada and metocean and real continuously monitored 50 hz strain data collected from three different owts currently in operation in the irish sea led to datasets over three years long however these three datasets were incomplete noise cleansing and mdi were carried out with the purpose of determining their benefits in continuous fatigue assessment of offshore wind turbines two scenarios were considered for each wind turbine with and without noise cleansing our results confirmed that in those cases where data cleansing was carried out the average imputation error was about 2 1 furthermore in 95 of the cases the error was within the range 15 2 11 0 the results indicated that noise cleansing and mdi could successfully be employed together to produce more complete datasets containing real low disturbed strain data furthermore fatigue was estimated for the four different cases namely i without cleansing without mdi case a ii without cleansing with mdi case b iii with cleansing without mdi case c and iv with cleansing with mdi case d results showed that for the wind turbines 1 and 3 fatigue was underestimated when data cleansing had not been performed the cause is believed to be an excess of noise which contributes to the collection of more uniform cycles of fatigue in case c where data cleansing was carried out but mdi was not fatigue was found to be underestimated for all the three turbines also there was an overestimation of fatigue in some sensors when data cleansing was not carried out but mdi was the reason is that the noise is picked up in the mdi algorithm and reproduced making the cumulative effect to considerably increase the overall fatigue of the structure currently fatigue analyses are often performed based on uncomplete datasets the methodology presented in this research provides the possibility of enhancing the confidence in fatigue life estimations by increasing the length of the datasets through firstly data cleansing and secondly mdi the results obtained validate our two novel methodologies making it a suitable tool for better evaluation of offshore wind turbines structural integrity we are exploring some opportunities to implement the proposed approaches in the wind energy sector with the aim of deriving more accurate fatigue life estimations to help push the boundaries of current operational periods and make the technology more competitive by reducing its lcoe further work could potentially focus on accounting for the degradation in the accuracy of sensor readings increase in noise across the years comparing different periods across the life of a windfarm a comparison between the performance of the proposed ann method and some other techniques such as random forest support vector machine svm and gaussian process regression is in our research agenda acknowledgements this work was supported by grant ep l016303 1 for cranfield university centre for doctoral training in renewable energy marine structures rems http www rems cdt ac uk from the uk engineering and physical sciences research council epsrc and innogy se 
