index,text
24775,auxiliary information in the form of species abundance is frequently available as part of data collected for ecological investigations yet when modeling distributions of species over large regions species presence and sometimes absence are typically used incorporating abundances into species distribution models may greatly improve model predictive accuracy in practice boosted regression trees brt models have been widely used in species distribution modeling however no ecological study has been conducted to date that has assessed the predictive accuracy of brt models that incorporates species abundance weights we compared traditional unweighted brts with species abundance weighted brts for 55 fluvial fish species native to the northeastern u s overall model deviance explained and six diagnostic measures of predictive performance were compared between traditional brts and weighted brts these comparisons indicated that unweighted brts performed better for fluvial fish species considered common including those with greater numbers of presences and higher prevalence conversely weighted brts were better suited for modeling distributions of species that had fewer presences lower prevalence and higher rarity indicating the potential of species abundance weighted distribution modeling to improve results for species of high conservation importance last we offer insights into the applicability of using weighted approaches with other commonly used species distribution modeling methods keywords species distribution models boosted regression trees species abundance fluvial fishes 1 introduction species distribution models sdms also called ecological environmental niche models play an important role in quantifying species habitat relationships and predicting species distributions in ecological research conservation and environmental management guisan and zimmermann 2000 robinson et al 2017 sdms are used to predict the probability that a target species is present at a given location or to quantify habitat suitability as a function of multiple predictor variables representing key environmental conditions linked to species habitat usage and persistence sdms have been developed for many types of organisms residing in terrestrial freshwater and marine environments elith and leathwick 2009 in early stages of sdm use and development prior to 2000 regression based models e g general generalized linear models were frequently utilized guisan and zimmermann 2000 however based on improved methodology and ecological understanding more complex statistical approaches have been implemented for sdms increasing accuracy of model predictions these advances have provided a mechanism for understanding complex non linear relationships and interactions among environmental predictors providing gains in ecological understanding of species environment relationships in particular the application of machine learning techniques in sdms has increased dramatically over the past two decades with boosted regression trees brt models being one of the most widely used approaches elith et al 2008 brts are adept at handling nonlinearity selecting predictor variables accounting for interactions among predictors and quantifying predictor relative importance all of which can be difficult to address in regression based models in numerous studies brts have outperformed regression based models such as generalized linear models glms and generalized additive models gams in analyzing complex species habitat relationships elith et al 2008 but see shabani et al 2016 norberg et al 2019 despite the success of brts in developing sdms for a wide variety of organisms and environments potential still exists for improvements that could further bolster model accuracy for this modeling method data availability is critical for sdm development with characteristics of the data type method of collection spatial extent etc driving choices in sdm models and approaches a number of studies have focused on data deficiency warton and shepherd 2010 elith et al 2011 fithian and hastie 2013 yackulic et al 2013 radosavljevic and anderson 2014 renner et al 2015 for instance when only presence data are available presence only approaches can be used to model species distributions merow et al 2013 phillips et al 2017 while species information may be collected as presence only or presence absence data auxiliary information in the form of species counts or abundance is frequently available in ecology however this information is often reduced to presence only or presence absence prior to sdm development thus eliminating information that could further elucidate complex species habitat relationships in sdms in certain cases variability in species abundance could be linked to variation in habitat suitability with species being more abundant within highly suitable habitats for instance weber et al 2017 found a positive relationship between abundance of species from many taxonomic groups and environmental suitability additional studies used occurrence data or sdms to predict abundance distributions van couwenberghe 2013 yañez arenas et al 2014 or have used abundance data to improve the predictive abilities of sdms howard et al 2014 however other studies found this type of relationship between abundances and suitability to be weak or non existent dallas and hastings 2018 collectively these studies indicate that much still needs to be learned with respect to abundance habitat relationships in sdms providing a research opportunity to explore the conditions under which abundance informed sdms could improve model predictions modifications to existing sdm modeling methods have often been implemented in ecology for correcting imbalanced survey data commonly used sdms can be divided into regression based models and machine learning based models logistic regressions are widely used in species distribution modeling when the response variable is dichotomous however if the response variable in a logistic regression has many more absences than presences the accuracy and precision of parameters as well as predictive performance will be affected salas eljatib et al 2018 for instance king and zeng 2001 introduced a corrective approach to deal with this imbalanced data issue known as rare events logistic regression while warton and shepherd 2010 used poisson point process logistic regression models to solve the pseudo absence problem further stolar and nielsen 2015 improved model performance dealing with spatially biased sampling by adding a weighting term in the logistic regression machine learning based sdms e g brts maxent random forest artificial neural networks etc are more complex than regression based models and often treated as a black box with respect to species distribution modeling therefore modified versions are relatively rare compared to regression based models in ecology however just like regression based sdms machine learning based sdms can be improved once their black box properties are uncovered through the explanation of machine learning approaches such as brt elith et al 2008 these models have become more tangible to scientists and subsequently more frequently applied in ecological studies modifications to improve model fit and predictive abilities of these widely used machine learning methods such as brts have great potential in improving ecological research the goal of this study is to compare the predictive abilities of traditional unweighted presence absence species distribution models with those that are weighted by species abundance using a common robust species distribution modeling method boosted regression trees we develop weighted vs unweighted species distribution models for 55 fluvial fish species native to the northeastern u s using a standard 10 fold cross validation modeling approach weighted vs unweighted models are compared using model deviance explained to measure overall model fit six diagnostic measures of predictive performance evaluation of patterns in species presence prevalence and rarity and predictor variable importance and rankings we provide recommendations on the use of abundance weighted vs unweighted models and offer insights into the applicability of using abundance weighted approaches with other commonly used species distribution modeling methods 2 material and methods four primary steps were conducted to implement this study biological and environmental predictor data preparation development of abundance weightings for each species species distribution modeling using weighted and unweighted approaches and comparison of results among weighted and unweighted models for each species figure 2 2 1 biological and environmental data we developed species distribution models for 55 fluvial fish species native to 22 northeastern u s states figure 1 table a1 to compare the model performance and predictive capabilities of the weighted and unweighted brt approaches community wide fish data collected using single pass electrofishing methods spanning 1990 2013 were obtained from academic institutions and local state and federal agencies see daniel et al 2015 and used in model development species presence absence data locations were designated as falling within either native or non native portions of their overall range based on species level 8 digit usgs hydrologic unit code huc maps of native and introduced status provided by the usgs nonindigenous aquatic species program this step ensured that only presence absence locations considered native were used in modeled development and excluded non native presences for species outside of their native range which could represent novel conditions for model predictors and thus affect native species distribution model development fish survey site locations were spatially linked to stream reaches of the national hydrography dataset plus v1 nhdplusv1 usgs 2005 allowing for the use of an existing suite of 23 natural and anthropogenic landscape variables as predictors in modeling table a2 these include commonly utilized predictors known to influence the distribution and abundance of fluvial fishes cooper et al 2019 with natural factors representing catchment area climate elevation and groundwater contribution to stream flow and anthropogenic factors representing urban and agricultural land uses dams roads nutrient inputs and mines characterized over multiple spatial extents including catchments and riparian buffers table a2 daniel et al 2015 cooper et al 2017 2 2 description of the models 2 2 1 unweighted boosted regression trees brt boosted regression trees brt combine regression trees and a powerful boosting technique that iteratively fits tree models using binary splits of predictor variables elith et al 2008 boosting is an ensemble procedure for improving model prediction by reducing model deviance through linking successive tree models focused on weak learners i e the residuals from predictors performing poorly in previous steps in brt models three parameters must be considered learning rate tree complexity and bag fraction learning rate is used to control the contribution of each individual tree to the overall model tree complexity adjusts the number of nodes in a tree governing the interaction complexity in the model e g if tree complexity is 2 up to two way interactions can be fit finally bag fraction is the proportion of training data that is used in each iteration which controls the stochasticity of boosting imbalanced presence absence data very rare or very common species will often require differing learning rates elith et al 2008 during preliminary model runs we evaluated differing combinations of learning rate values number of trees and bag fraction values this process identified that larger learning rates might result in models for rare species that did not converge while smaller learning rate for common species might result in model overfitting as a result we used an initial learning rate of 0 05 for species with 100 presences and a learning rate 0 01 for species with 100 presences we iteratively reduced the learning rate by half to ensure a minimum of 1000 trees in the final model elith et al 2008 and capped the maximum number of trees at 10 000 to avoid overfitting for all models we used the default bag fraction of 0 75 and a tree complexity of 5 i e five nodes in each tree with models being developed with the dismo r package 2 2 2 weighted boosted regression trees wbrt a weighted boosted regression tree wbrt model is a modified brt that applies a weight wij to each species at each sampling site based on individual species abundance and overall species richness differing from a standard brt where all species presence absences are effectively weighted equally weighting sites based on numbers of species supported could account for potential differences in habitat suitability across sites as sites with higher individual species abundance may reflect greater overall habitat suitability weber et al 2017 and result in improved model fit in a logistic wbrt the loss function residual deviance of species j is l j 2 1 i 1 n j w i j i 1 n j w i j 1 y i j log 1 y i j y i j log y i j where nj is the number of sites in the model training data set of species j yij is the observed value 0 or 1 of species j at site i y i j is the predicted value of species j at site i and wij is the weight of species j at site i for the wbrt we set the weight wij equal to 1 for sites with species absences while wij is a scaled product ranging from 1 to 101 of relative abundance and species richness j at site i with presence of target species j w i j u w i j min u w i j max u w i j min u w i j 100 1 where uwij is the unscaled weight of species j at site i which is the product of the relative abundance of species j and richness at site i calculated using the following formulas r a i j a i j j 1 m a i j u w i j r a i j r i c h n e s s i where ra ij is the relative abundance of species j at site i a ij is the raw abundance of species j at site i and m is the species richness at site i here we use relative abundance as it is readily available form of abundance for fish data that can be calculated simply from community species count data as opposed to effort based abundance measures commonly referred to as catch per unit effort or cpue this is due to the fact that effort measures e g length time area etc are sometimes lacking for fish community data provided by various sources collected under differing sampling objectives in developing this weighting factor we account for the dual influences of both relative abundance and species richness for instance using the formula above a species with a relative abundance of 0 2 at a site with an overall species richness of 10 would have a weight of 2 however the same species would have a lower weight of 0 4 given a site species richness of 2 and the same relative abundance 0 2 in effect this weighting controls for both site level species abundance and species dominance resulting in higher weighting for sites with higher species abundance relative to higher overall species richness and providing a potential indicator of higher overall site specific habitat suitability brt and wbrt models were developed using a 10 fold cross validation with brt and wbrt being fitted using the same training set with the optimal number of trees in each model being estimated using 10 fold cross validation during this validation process the dataset was divided into 10 non overlapping groups with each unique group being withheld as a test dataset while remaining groups were used as a training dataset for model fitting 2 3 model comparison we compared results between the wbrt and brt approaches among the 55 fishes modeled using 1 overall model deviance explained as a measure of model fit 2 six diagnostic metrics evaluating model predictive performance 3 comparison of patterns in species presences prevalence and rarity between models and 4 relative importance of predictors and overall predictor rankings 2 3 1 model deviance explained we used deviance explained based on models developed from the overall initial dataset to compare model fitting where cross validation residual deviance is the mean of the residual deviance from each fold of the cross validation d e v i a n c e e x p l a i n e d t o t a l d e v i a n c e c r o s s v a l i d a t i o n r e s i d u a l d e v i a n c e t o t a l d e v i a n c e a t test was used to compare mean deviance explained between the wbrt and brt approaches 2 3 2 metrics comparing predictive performance model comparison is often a crucial aspect of evaluating potential improvements to an existing method the measures and methods to compare the accuracy or performance of sdms are diverse and controversial liu et al 2011 leroy et al 2018 an intuitive measure is overall accuracy defined as the proportion of sites predicted to support a species where a species is actually found however it has been repeatedly criticized as not being suitable for imbalanced data which includes data with many more absences than presences or vice versa fielding and bell 1997 manel et al 2001 two alternative measures are sensitivity proportion of presences correctly predicted and specificity proportion of absences correctly predicted swets 1988 both are calculated from a confusion matrix and are independent of prevalence the proportion of presences in the dataset allouche et al 2006 one of the most commonly used measures to compare sdm performance is the area under the receiver operating characteristic roc curve known as auc which is developed from a 2 dimensional plot with sensitivity as the vertical axis and 1 specificity as the horizontal axis auc is a threshold independent method avoiding the subjective selection of threshold values where a single presence absence cutoff is chosen to develop a confusion matrix for model evaluation auc ranges between 0 and 1 with an auc of 0 5 indicating that the prediction capability of the model is no better than random and values greater than 0 7 are considered adequate in modeling species distributions swets 1988 however auc has been criticized in several studies for giving misleading results for imbalanced data lobo et al 2008 peterson et al 2008 jimenez valverde 2012 frequently ecological sample data are imbalanced especially over large regions and therefore auc may not be appropriate to evaluate and or compare sdms alone an alternative evaluation metric is the area under the precision recall also called sensitivity curve auprc which is also a threshold independent metric this metric can evaluate sdms with imbalanced data as it is not dependent on model specificity davis and goadrich 2006 sofaer et al 2018 similarly auprc measures the area under a 2 dimensional curve in which the vertical axis is precision and the horizontal axis is sensitivity also called recall sofaer et al 2019 auprc can range between 0 and 1 however its minimum value increases with prevalence and there is no established cut off point for identifying adequate models with auprc though higher auprc indicates a better model prediction cohen s kappa is another commonly used metric to evaluate sdm performance however it depends on prevalence and therefore may result in statistical inaccuracies in estimating sdm accuracy allouche 2006 delgado and tibau 2019 cohen s kappa is calculated using three parameters prevalence sensitivity and specificity k a p p a p 0 p e 1 p e where p 0 p r e v a l e n c e s e n s i t i v i t y 1 p r e v a l e n c e s p e c i f i c i t y p e 2 s e n s i t i v i t y s p e c i f i c i t y 1 p r e v a l e n c e 1 p r e v a l e n c e p 0 kappa ranges between 1 and 1 cohen 1960 with higher kappa values indicating better model predictions a more appropriate alternative is the true skill statistic tss which is equal to the sum of sensitivity and specificity minus one fielding and bell 1997 tss retains all the advantages of kappa but is also largely immune to prevalence of the sample data allouche 2006 in this study predicted presences and absences were separated by a threshold value at which the tss is maximized manel et al 2001 hernandez et al 2006 use of a wide variety of diagnostic measures of model accuracy such as those described can provide a means to effectively compare models developed using alternative approaches including potential modification of an existing modeling method results for brt and wbrt models were compared using sensitivity specificity auc auprc cohen s kappa and tss to evaluate the models predictive capability table 1 values for these six diagnostic metrics were compared for each species for the wbrt and brt modeling approaches to determine the number of metrics that performed better using wbrt vs brt for subsequent analyses we identified species that performed better using wbrt if 4 metrics had higher values compared to brt conversely species identified as performing better using brt had 4 metrics with higher values compared to wbrt results for these two groups were evaluated using radar plots to identify which metrics corresponded to differing performance among the two modeling approaches 2 3 3 differences in species presences prevalence and rarity to test whether differences in model performance were related to species presence prevalence and multiple aspects of rarity empirical distribution functions were applied we used this approach to compare these factors for species performing better using wbrt with distributions from species better suited to brt modeling described above for this analysis we performed a two sample kolmogorov smirnov ks test and plotted results using empirical cumulative density functions the ks test is a non parametric method for comparing two samples to determine whether they follow the same distribution rohlf and sokal 1981 the ks test statistic is d sup x f n 1 x f n 2 x where f n 1 and f n 2 are the empirical cumulative distribution function of the first and second sample respectively when sample sizes are large n 1 50 and n 2 50 the critical value is d k n 1 n 2 n 1 n 2 where k l n 2 2 and is the level of significance when the ks test statistic d is greater than the critical value d these two samples distributions are significantly different to quantify species rarity we utilized an integrated rarity ir index leitao et al 2016 representing a continuous gradient of species rarity by combining measures of species range size habitat usage and mean species weights described in wbrt section above species native range areas km2 obtained from range maps described above were utilized as a measure of overall range size with species having smaller ranges being geographically rarer range in habitat usage was derived with the index of habitat specificity ihs pritt and frimpong 2010 which sums the number of unique freshwater habitat types e g substrate flow velocity etc attributed to individual freshwater fish species frimpong and angermeier 2009 the ihs has a theoretical maximum value of 25 i e 25 total habitat types assigned with species that have lower ihs scores indicating a lower range of habitat use and potentially greater rarity pritt and frimpong 2010 mean species weights utilized as the weighting factor in wbrt were used as a measure of species abundance with species that have lower mean weights representing those that have lower overall relative abundance normalized by species richness at occupied sites the integrated rarity ir i of species i was calculated by combining species native range size snri index of habitat specificity ihsi and mean species weights mswi i r i s n r i w s n r i h s i w i h s m s w i w m s w w s n r w i h s w m s w where wsnr wihs and wmsw are the weights of snri ihsi and mswi respectively in this study all three weights in this formula were equal to 1 3 reflecting equal weighting of these three respective factors snri ihsi and mswi were standardized to a 0 to 1 scale prior to calculation of iri values using the following formula s t a n d a r d i z e d i n d e x i i n d e x i min i n d e x i max i n d e x i min i n d e x i where min and max represent the minimum and maximum values respectively resulting ir values range from a theoretical minimum of 0 to a theoretical maximum of 1 with lower values for rare species and higher values from more common species in general species considered rare according to the ir index would have smaller ranges utilize fewer habitat types and have lower abundance relative to other species 2 3 4 predictor relative importance and overall predictor rankings the relative importance of predictor variables was calculated for each species using wbrt and brt model results in order to compare the relative contributions of predictor variables among approaches predictor variable importance is calculated as r i i 1 m m 1 m i i 2 t m where rii stands for the relative importance for the ith predictor variable m is the number of trees and i i 2 t m is the squared relevance of each predictor weighted by the number of times it was chosen as the splitting variable in tree m hastie et al 2009 in addition we assigned ranks to predictor variables based on their relative importance calculating an overall mean rank across species for each predictor m e a n r a n k i j 1 n r a n k i j n where rankij is the rank of predictor i for species j and n is the total number of species 55 in this study all analyses were conducted in r version 3 6 1 r core team vienna austria 3 results 3 1 comparing brt and wbrt model results 3 1 1 model deviance explained percentage of total deviance explained used to measure model fitting was higher for wbrt than brt for 49 of 55 species table a3 mean deviance explained for wbrt was 0 4769 se 0 0192 range 0 1924 0 8132 compared to 0 3743 se 0 0137 range 0 1429 0 6131 for brt and was significantly higher based on a paired t test p 0 01 fig 3 a differences in deviance explained between wbrt and brt models varied over the integrated rarity index in general these differences were positive indicating that wbrts had improved model fit compared to brts however when integrated rarity was larger than 0 4 indicating more common species differences among the wbrt and brt approaches decreased fig 3b 3 1 2 metrics comparing predictive performance for 50 of 55 species wbrt had a higher metric value indicating better predictive performance than brt for at least one metric when multiple metrics are considered 13 species have higher values for wbrt for four or more metrics fig 4 a table a3 while 24 species performed better with brt based on having higher values for four or more metrics generally kappa and tss led to the same model preferences and in particular results for sensitivity and tss matched both performed better for either wbrt or brt for 52 of 55 species in contrast sensitivity and specificity had differing model preferences being mismatched in 50 of 55 species auprc and auc had moderate congruence with only 15 out 55 species mismatched among the 13 species for which wbrt performed better results were mainly driven by higher metric values for sensitivity 13 kappa 13 tss 13 and auprc 12 fig 4b only two species showed a higher specificity value while eight species had higher auc values similar to wbrt results for the 24 species for which brt performed better included higher metric values for sensitivity 21 kappa 24 tss 24 and auc 23 fig 4c while eight species and 16 species had higher specificity and auprc values respectively 3 2 differences in species presences prevalence and rarity among the two groups of species performing better in either wbrt n 13 or brt n 24 table 2 the number of presences for species with better predictions in wbrt was significantly lower than those with better predictions in brt welch t test p 0 01 with a mean of 785 se 204 range 135 1970 for wbrt and mean of 3198 se 765 range 76 15 811 for brt the empirical cumulative density distribution of presences for these two groups of species was significantly different based on a ks test d 0 5417 p 0 01 fig 5 a the prevalence of the species with better predictions in wbrt with a mean of 0 07 se 0 02 range 0 01 0 19 was also significantly lower than those with better predictions in brt welch t test p 0 01 with a mean of 0 19 se 0 03 range 0 02 0 54 the empirical cumulative density distribution of wbrt species prevalence indicated that it was significantly different than the distribution of brt species prevalence based on a ks test d 0 4295 p 0 04 fig 5b the integrated rarity ir for species performing better in wbrt with a mean of 0 21 se 0 04 range 0 06 0 46 was significantly lower than the mean of those that performed better using brt with a mean of 0 31 se 0 03 range 0 12 0 69 welch t test p 0 02 the empirical cumulative density distribution of wbrt species ir was marginally different from the brt species ir based on a ks test d 0 3846 p 0 08 fig 5c 3 3 predictor relative importance and overall predictor rankings the importance of predictor variables varied primarily by species with differences among wbrt and brt models among species being minimal as indicated by similar mean relative importance and ranks of predictors table 3 the top predictor was catchment area accounting for 23 8 and 18 1 of relative importance for wbrt and brt respectively with mean annual air temperature 9 7 vs 9 3 and mean annual precipitation 7 7 vs 6 9 being the next two most important variables overall the order of predictors according to mean relative importance and mean rank was identical in wbrt and brt table 3 4 discussion to the best of our knowledge this is the first study focused on incorporating species abundance and richness into species distribution models sdms in stream ecology improving predictive accuracy is a primary goal in developing new methods for creating species distribution models sdms stevens and conway 2020 given that many of the species data utilized in sdm development originate from community based abundance sampling efforts particularly in fisheries research there is untapped potential in utilizing the inherent abundance and richness in these datasets in sdms as opposed to reducing community abundance data to binary presence absence data prior to modeling previous studies have suggested that species relative abundance and richness at the sampling locations can be a positive indicator of habitat suitability weber et al 2017 therefore incorporating these measures into a weighting factor applied to boosted regression trees brts species distribution models or other sdm methods more generally can improve model predictive accuracy as indicated by the current study 4 1 applying species abundance and richness based weights to sdms implications for improved modeling of less prevalent and rare species our results suggest that neither brts nor weighted brts wbrts as a whole were a better choice for all stream fish species modeled in this study for the northeastern u s however in general wbrts outperformed unweighted brts for stream fish species with fewer presences lower prevalence and higher rarity these are characteristics that can be shared by species of conservation importance thus this weighting approach has the potential to improve models for these types of species although species with low prevalence can result in imbalanced data causing biased predictions in sdms as has been indicated in a number of studies manel et al 2001 mcpherson and jetz 2007 santika 2011 this issue has seldom been discussed in the context of brt models this is perhaps due to the more powerful predictive ability of brts as issues related to low species prevalence and imbalanced data are not as apparent as regression based sdms identifying candidate species for use of weighting brts can be challenging given that the discrimination and definition of rare species have not been widely accepted by researchers pritt and frimpong 2010 the rarity index utilized in this study that combines species abundance weights habitat usage and native range size provides a reasonable measure of rarity that can be applied to other taxa to identify species best suited for weighted brts when prevalence data are not available the number of presences could be applied to substitute for prevalence as they are likely to be highly correlated in many cases for instance the number of presences and prevalence were highly correlated pearson s correlation coefficient 0 85 p 0 01 in the current study based on the results of this study wbrts should be considered for fluvial fish species with high rarity and low number of presences both species relative abundance and richness were used to calculate the weight of each observation in this study unweighted binary presence absence species models treat all presences the same when testing habitat suitability whether a single individual was observed or many potentially 1000 s of individuals were observed a more logical assumption is that species will be more abundant in more suitable habitats aguirre gutiérrez et al 2013 vanderwal et al 2009 there are however limits to the information that these weightings can provide in the context of sdms as wbrts may not be ideal for common species as they are usually widely distributed and have generalist adaptions to habitats pritt and frimpong 2010 given that common species tend to be widespread and generally of high abundance at locations where they are found it is unsurprising that weights for these species add little value to brts while a limited number of studies have concluded that habitat suitability and species abundance are unrelated e g dallas and hasting 2018 filz et al 2013 nielsen et al 2005 these studies have focused on different taxa groups e g trees mammals insects and vascular plants have not incorporated the effects of species richness and or had much coarser data spatial resolutions than the current study although we incorporated species richness in wbrt models the effect of species interactions on sdms needs to be further studied while the current study supports a positive linkage between species abundance and habitat suitability for less prevalent and rare species this relationship requires further research to aid in use of species weightings for other taxa groups beyond fluvial fishes in addition to prevalence and rarity there are other factors that may affect model performance for example fish sampling provides a snapshot of the relationship between fish communities and their habitats with fish presence and or abundance information being influenced by sampling effort season date time location and identification and or counting errors to differing degrees those biases and uncertainties can vary by species for instance rarer species can be more difficult to detect or may have more variability in abundance across sampling locations wenger and freeman 2008 steenweg et al 2019 which could result in less model certainty for these species in certain cases in addition fish species have differing physiological tolerances to habitat conditions or may undergo seasonal migrations in addition fish species have differing physiological tolerances to habitat conditions as a result locations with the highest species abundance may not always correspond to the most suitable habitats nevertheless weighted sdms still have a great potential in improving predictive ability of sdms 4 2 use of multiple diagnostic metrics to evaluate alternative models when applying the brt or wbrt approaches for other species model predictive performance should be evaluated on a species by species basis we implemented six metrics to compare the performance of the brts and wbrts and found differing results in model preference among metrics if only one metric was used to measure the performance of sdms biased conclusions in model performance would likely result for this reason model performance should not be measured using one single diagnostic metric further survey data for many species are imbalanced i e prevalence is much lower than 0 5 yet some commonly used diagnostic metrics are designed for balanced data auc in particular weights sensitivity and specificity equally when evaluating model performance in ecological surveys presences are usually more valuable in exploring habitat suitability than absences which can be incorrectly obtained for multiple reasons for instance all fish species may not have been captured due to sampling or gear problems additionally habitat may be suitable however individuals from a particular fish species may have vacated the area at the time when sampling was conducted due to seasonal or short term variation in habitat use based on environmental conditions e g stream flow temperature etc similarly correctly predicting presences for an sdm is often of greater importance than correctly predicting absences in most cases therefore sensitivity and auprc are better metrics than specificity and auc for imbalanced data in ecology allouche et al 2006 found that tss is a better metric of predictive accuracy than kappa for sdm evaluation as kappa is dependent on prevalence however in the present study kappa and tss exhibited high correlation pearson s correlation coefficient 0 98 p 0 01 one possible reason is that the prevalence for 53 of 55 fluvial fish species is this study is less than 0 5 and it is not possible to test the performance of kappa or tss across the whole prevalence range 0 1 when evaluating the performance of sdms developed using the brt and wbrt approaches we recommend the use of multiple diagnostic metrics that best represent a given study s objectives in use of sdm results 4 3 applicability of species weightings with other sdm approaches and additional weighting factors this study offers insights into the applicability of using abundance weighted approaches with other commonly used species distribution modeling methods such as logistic regression lr and random forest rf species abundance information can be added into logistic regression models by similarly adjusting the weights in the likelihood function however compared to brt models lr models have difficulties in dealing with multicollinearity interactions non linearity and predictor variable selection these disadvantages may affect the application of weighted lr models and therefore model comparison and validation is needed prior to implementation rf models use the gini index and entropy to grow trees an abundance index can be added into the gini index and entropy function by adjusting case weights of sample data however the performance of weighted rf and its corresponding influence on sdm predictive performance needs further examination species weightings have the potential to be implemented in other sdm approaches however this practice requires careful consideration of specific characteristics of each modeling approach nonetheless results of the current study suggest the potential of species weightings in brt and other model methods to improve predictive accuracy in modeling species distributions other types of data besides species abundance can be utilized as weighting factors in sdms or incorporated into analyses involving weighted sdms species abundances can vary due to numerous factors such as variability in habitat conditions sampling methods and sampling intensity for example other auxiliary information of target species such as biomass length structure and age structure at each location can be a significant indicator of habitat suitability in certain cases species presence absence and abundance data do not display similar distribution patterns therefore the predictions of species distribution ranges based solely on either presence absence or abundance data can be inaccurate with use of combined information critical for valid results mi et al 2017 propose a priority protection index pi that combines the prediction results of occurrence and abundance models to guide habitat management if sampling intensity is known the predicted probability of presence can be transformed to expected abundance changes in expected abundance in biological systems can be used as an early warning indicator for species range contraction or population declines ashcroft et al 2017 further exploration in the use of weightings in sdms for other modeling approaches and applicability of other weighting factors e g biomass etc is needed to provide a framework for developing weighted sdms into useful tools for policy makers and managers 4 4 conclusion in the present study we found that wbrt models outperformed brt models for fish species with lower prevalence and higher rarity in the northeastern u s while brt models performed better for common species with higher prevalence further use of a single model evaluation metric should be avoided in model comparison in favor of multiple diagnostic metrics as certain metrics may be less robust for evaluating and or comparing sdms developed with imbalanced data the approach to developing weighted sdms using species abundance and richness presented in this study can be applied to other commonly used sdms and is not limited solely to brts since sdms are inherently species specific and data dependent model evaluation should be applied for any new species taxa or datasets utilizing this approach credit authorship contribution statement hao yu conceptualization methodology formal analysis writing original draft arthur r cooper conceptualization data curation investigation writing review editing dana m infante supervision conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was funded by the usgs aquatic gap program we thank alexa mckerrow and daniel wieferich for providing feedback on this project we also thank kyle herreman and jared ross for gis and database assistance we are grateful to the numerous federal and state agencies academic institutions and non profit organizations that provided the fish data facilitating this study http assessment fishhabitat org 578a9a43e4b0c1aacab89763 578a9a47e4b0c1aacab8976a supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2020 109202 appendix supplementary materials image application 1 
24775,auxiliary information in the form of species abundance is frequently available as part of data collected for ecological investigations yet when modeling distributions of species over large regions species presence and sometimes absence are typically used incorporating abundances into species distribution models may greatly improve model predictive accuracy in practice boosted regression trees brt models have been widely used in species distribution modeling however no ecological study has been conducted to date that has assessed the predictive accuracy of brt models that incorporates species abundance weights we compared traditional unweighted brts with species abundance weighted brts for 55 fluvial fish species native to the northeastern u s overall model deviance explained and six diagnostic measures of predictive performance were compared between traditional brts and weighted brts these comparisons indicated that unweighted brts performed better for fluvial fish species considered common including those with greater numbers of presences and higher prevalence conversely weighted brts were better suited for modeling distributions of species that had fewer presences lower prevalence and higher rarity indicating the potential of species abundance weighted distribution modeling to improve results for species of high conservation importance last we offer insights into the applicability of using weighted approaches with other commonly used species distribution modeling methods keywords species distribution models boosted regression trees species abundance fluvial fishes 1 introduction species distribution models sdms also called ecological environmental niche models play an important role in quantifying species habitat relationships and predicting species distributions in ecological research conservation and environmental management guisan and zimmermann 2000 robinson et al 2017 sdms are used to predict the probability that a target species is present at a given location or to quantify habitat suitability as a function of multiple predictor variables representing key environmental conditions linked to species habitat usage and persistence sdms have been developed for many types of organisms residing in terrestrial freshwater and marine environments elith and leathwick 2009 in early stages of sdm use and development prior to 2000 regression based models e g general generalized linear models were frequently utilized guisan and zimmermann 2000 however based on improved methodology and ecological understanding more complex statistical approaches have been implemented for sdms increasing accuracy of model predictions these advances have provided a mechanism for understanding complex non linear relationships and interactions among environmental predictors providing gains in ecological understanding of species environment relationships in particular the application of machine learning techniques in sdms has increased dramatically over the past two decades with boosted regression trees brt models being one of the most widely used approaches elith et al 2008 brts are adept at handling nonlinearity selecting predictor variables accounting for interactions among predictors and quantifying predictor relative importance all of which can be difficult to address in regression based models in numerous studies brts have outperformed regression based models such as generalized linear models glms and generalized additive models gams in analyzing complex species habitat relationships elith et al 2008 but see shabani et al 2016 norberg et al 2019 despite the success of brts in developing sdms for a wide variety of organisms and environments potential still exists for improvements that could further bolster model accuracy for this modeling method data availability is critical for sdm development with characteristics of the data type method of collection spatial extent etc driving choices in sdm models and approaches a number of studies have focused on data deficiency warton and shepherd 2010 elith et al 2011 fithian and hastie 2013 yackulic et al 2013 radosavljevic and anderson 2014 renner et al 2015 for instance when only presence data are available presence only approaches can be used to model species distributions merow et al 2013 phillips et al 2017 while species information may be collected as presence only or presence absence data auxiliary information in the form of species counts or abundance is frequently available in ecology however this information is often reduced to presence only or presence absence prior to sdm development thus eliminating information that could further elucidate complex species habitat relationships in sdms in certain cases variability in species abundance could be linked to variation in habitat suitability with species being more abundant within highly suitable habitats for instance weber et al 2017 found a positive relationship between abundance of species from many taxonomic groups and environmental suitability additional studies used occurrence data or sdms to predict abundance distributions van couwenberghe 2013 yañez arenas et al 2014 or have used abundance data to improve the predictive abilities of sdms howard et al 2014 however other studies found this type of relationship between abundances and suitability to be weak or non existent dallas and hastings 2018 collectively these studies indicate that much still needs to be learned with respect to abundance habitat relationships in sdms providing a research opportunity to explore the conditions under which abundance informed sdms could improve model predictions modifications to existing sdm modeling methods have often been implemented in ecology for correcting imbalanced survey data commonly used sdms can be divided into regression based models and machine learning based models logistic regressions are widely used in species distribution modeling when the response variable is dichotomous however if the response variable in a logistic regression has many more absences than presences the accuracy and precision of parameters as well as predictive performance will be affected salas eljatib et al 2018 for instance king and zeng 2001 introduced a corrective approach to deal with this imbalanced data issue known as rare events logistic regression while warton and shepherd 2010 used poisson point process logistic regression models to solve the pseudo absence problem further stolar and nielsen 2015 improved model performance dealing with spatially biased sampling by adding a weighting term in the logistic regression machine learning based sdms e g brts maxent random forest artificial neural networks etc are more complex than regression based models and often treated as a black box with respect to species distribution modeling therefore modified versions are relatively rare compared to regression based models in ecology however just like regression based sdms machine learning based sdms can be improved once their black box properties are uncovered through the explanation of machine learning approaches such as brt elith et al 2008 these models have become more tangible to scientists and subsequently more frequently applied in ecological studies modifications to improve model fit and predictive abilities of these widely used machine learning methods such as brts have great potential in improving ecological research the goal of this study is to compare the predictive abilities of traditional unweighted presence absence species distribution models with those that are weighted by species abundance using a common robust species distribution modeling method boosted regression trees we develop weighted vs unweighted species distribution models for 55 fluvial fish species native to the northeastern u s using a standard 10 fold cross validation modeling approach weighted vs unweighted models are compared using model deviance explained to measure overall model fit six diagnostic measures of predictive performance evaluation of patterns in species presence prevalence and rarity and predictor variable importance and rankings we provide recommendations on the use of abundance weighted vs unweighted models and offer insights into the applicability of using abundance weighted approaches with other commonly used species distribution modeling methods 2 material and methods four primary steps were conducted to implement this study biological and environmental predictor data preparation development of abundance weightings for each species species distribution modeling using weighted and unweighted approaches and comparison of results among weighted and unweighted models for each species figure 2 2 1 biological and environmental data we developed species distribution models for 55 fluvial fish species native to 22 northeastern u s states figure 1 table a1 to compare the model performance and predictive capabilities of the weighted and unweighted brt approaches community wide fish data collected using single pass electrofishing methods spanning 1990 2013 were obtained from academic institutions and local state and federal agencies see daniel et al 2015 and used in model development species presence absence data locations were designated as falling within either native or non native portions of their overall range based on species level 8 digit usgs hydrologic unit code huc maps of native and introduced status provided by the usgs nonindigenous aquatic species program this step ensured that only presence absence locations considered native were used in modeled development and excluded non native presences for species outside of their native range which could represent novel conditions for model predictors and thus affect native species distribution model development fish survey site locations were spatially linked to stream reaches of the national hydrography dataset plus v1 nhdplusv1 usgs 2005 allowing for the use of an existing suite of 23 natural and anthropogenic landscape variables as predictors in modeling table a2 these include commonly utilized predictors known to influence the distribution and abundance of fluvial fishes cooper et al 2019 with natural factors representing catchment area climate elevation and groundwater contribution to stream flow and anthropogenic factors representing urban and agricultural land uses dams roads nutrient inputs and mines characterized over multiple spatial extents including catchments and riparian buffers table a2 daniel et al 2015 cooper et al 2017 2 2 description of the models 2 2 1 unweighted boosted regression trees brt boosted regression trees brt combine regression trees and a powerful boosting technique that iteratively fits tree models using binary splits of predictor variables elith et al 2008 boosting is an ensemble procedure for improving model prediction by reducing model deviance through linking successive tree models focused on weak learners i e the residuals from predictors performing poorly in previous steps in brt models three parameters must be considered learning rate tree complexity and bag fraction learning rate is used to control the contribution of each individual tree to the overall model tree complexity adjusts the number of nodes in a tree governing the interaction complexity in the model e g if tree complexity is 2 up to two way interactions can be fit finally bag fraction is the proportion of training data that is used in each iteration which controls the stochasticity of boosting imbalanced presence absence data very rare or very common species will often require differing learning rates elith et al 2008 during preliminary model runs we evaluated differing combinations of learning rate values number of trees and bag fraction values this process identified that larger learning rates might result in models for rare species that did not converge while smaller learning rate for common species might result in model overfitting as a result we used an initial learning rate of 0 05 for species with 100 presences and a learning rate 0 01 for species with 100 presences we iteratively reduced the learning rate by half to ensure a minimum of 1000 trees in the final model elith et al 2008 and capped the maximum number of trees at 10 000 to avoid overfitting for all models we used the default bag fraction of 0 75 and a tree complexity of 5 i e five nodes in each tree with models being developed with the dismo r package 2 2 2 weighted boosted regression trees wbrt a weighted boosted regression tree wbrt model is a modified brt that applies a weight wij to each species at each sampling site based on individual species abundance and overall species richness differing from a standard brt where all species presence absences are effectively weighted equally weighting sites based on numbers of species supported could account for potential differences in habitat suitability across sites as sites with higher individual species abundance may reflect greater overall habitat suitability weber et al 2017 and result in improved model fit in a logistic wbrt the loss function residual deviance of species j is l j 2 1 i 1 n j w i j i 1 n j w i j 1 y i j log 1 y i j y i j log y i j where nj is the number of sites in the model training data set of species j yij is the observed value 0 or 1 of species j at site i y i j is the predicted value of species j at site i and wij is the weight of species j at site i for the wbrt we set the weight wij equal to 1 for sites with species absences while wij is a scaled product ranging from 1 to 101 of relative abundance and species richness j at site i with presence of target species j w i j u w i j min u w i j max u w i j min u w i j 100 1 where uwij is the unscaled weight of species j at site i which is the product of the relative abundance of species j and richness at site i calculated using the following formulas r a i j a i j j 1 m a i j u w i j r a i j r i c h n e s s i where ra ij is the relative abundance of species j at site i a ij is the raw abundance of species j at site i and m is the species richness at site i here we use relative abundance as it is readily available form of abundance for fish data that can be calculated simply from community species count data as opposed to effort based abundance measures commonly referred to as catch per unit effort or cpue this is due to the fact that effort measures e g length time area etc are sometimes lacking for fish community data provided by various sources collected under differing sampling objectives in developing this weighting factor we account for the dual influences of both relative abundance and species richness for instance using the formula above a species with a relative abundance of 0 2 at a site with an overall species richness of 10 would have a weight of 2 however the same species would have a lower weight of 0 4 given a site species richness of 2 and the same relative abundance 0 2 in effect this weighting controls for both site level species abundance and species dominance resulting in higher weighting for sites with higher species abundance relative to higher overall species richness and providing a potential indicator of higher overall site specific habitat suitability brt and wbrt models were developed using a 10 fold cross validation with brt and wbrt being fitted using the same training set with the optimal number of trees in each model being estimated using 10 fold cross validation during this validation process the dataset was divided into 10 non overlapping groups with each unique group being withheld as a test dataset while remaining groups were used as a training dataset for model fitting 2 3 model comparison we compared results between the wbrt and brt approaches among the 55 fishes modeled using 1 overall model deviance explained as a measure of model fit 2 six diagnostic metrics evaluating model predictive performance 3 comparison of patterns in species presences prevalence and rarity between models and 4 relative importance of predictors and overall predictor rankings 2 3 1 model deviance explained we used deviance explained based on models developed from the overall initial dataset to compare model fitting where cross validation residual deviance is the mean of the residual deviance from each fold of the cross validation d e v i a n c e e x p l a i n e d t o t a l d e v i a n c e c r o s s v a l i d a t i o n r e s i d u a l d e v i a n c e t o t a l d e v i a n c e a t test was used to compare mean deviance explained between the wbrt and brt approaches 2 3 2 metrics comparing predictive performance model comparison is often a crucial aspect of evaluating potential improvements to an existing method the measures and methods to compare the accuracy or performance of sdms are diverse and controversial liu et al 2011 leroy et al 2018 an intuitive measure is overall accuracy defined as the proportion of sites predicted to support a species where a species is actually found however it has been repeatedly criticized as not being suitable for imbalanced data which includes data with many more absences than presences or vice versa fielding and bell 1997 manel et al 2001 two alternative measures are sensitivity proportion of presences correctly predicted and specificity proportion of absences correctly predicted swets 1988 both are calculated from a confusion matrix and are independent of prevalence the proportion of presences in the dataset allouche et al 2006 one of the most commonly used measures to compare sdm performance is the area under the receiver operating characteristic roc curve known as auc which is developed from a 2 dimensional plot with sensitivity as the vertical axis and 1 specificity as the horizontal axis auc is a threshold independent method avoiding the subjective selection of threshold values where a single presence absence cutoff is chosen to develop a confusion matrix for model evaluation auc ranges between 0 and 1 with an auc of 0 5 indicating that the prediction capability of the model is no better than random and values greater than 0 7 are considered adequate in modeling species distributions swets 1988 however auc has been criticized in several studies for giving misleading results for imbalanced data lobo et al 2008 peterson et al 2008 jimenez valverde 2012 frequently ecological sample data are imbalanced especially over large regions and therefore auc may not be appropriate to evaluate and or compare sdms alone an alternative evaluation metric is the area under the precision recall also called sensitivity curve auprc which is also a threshold independent metric this metric can evaluate sdms with imbalanced data as it is not dependent on model specificity davis and goadrich 2006 sofaer et al 2018 similarly auprc measures the area under a 2 dimensional curve in which the vertical axis is precision and the horizontal axis is sensitivity also called recall sofaer et al 2019 auprc can range between 0 and 1 however its minimum value increases with prevalence and there is no established cut off point for identifying adequate models with auprc though higher auprc indicates a better model prediction cohen s kappa is another commonly used metric to evaluate sdm performance however it depends on prevalence and therefore may result in statistical inaccuracies in estimating sdm accuracy allouche 2006 delgado and tibau 2019 cohen s kappa is calculated using three parameters prevalence sensitivity and specificity k a p p a p 0 p e 1 p e where p 0 p r e v a l e n c e s e n s i t i v i t y 1 p r e v a l e n c e s p e c i f i c i t y p e 2 s e n s i t i v i t y s p e c i f i c i t y 1 p r e v a l e n c e 1 p r e v a l e n c e p 0 kappa ranges between 1 and 1 cohen 1960 with higher kappa values indicating better model predictions a more appropriate alternative is the true skill statistic tss which is equal to the sum of sensitivity and specificity minus one fielding and bell 1997 tss retains all the advantages of kappa but is also largely immune to prevalence of the sample data allouche 2006 in this study predicted presences and absences were separated by a threshold value at which the tss is maximized manel et al 2001 hernandez et al 2006 use of a wide variety of diagnostic measures of model accuracy such as those described can provide a means to effectively compare models developed using alternative approaches including potential modification of an existing modeling method results for brt and wbrt models were compared using sensitivity specificity auc auprc cohen s kappa and tss to evaluate the models predictive capability table 1 values for these six diagnostic metrics were compared for each species for the wbrt and brt modeling approaches to determine the number of metrics that performed better using wbrt vs brt for subsequent analyses we identified species that performed better using wbrt if 4 metrics had higher values compared to brt conversely species identified as performing better using brt had 4 metrics with higher values compared to wbrt results for these two groups were evaluated using radar plots to identify which metrics corresponded to differing performance among the two modeling approaches 2 3 3 differences in species presences prevalence and rarity to test whether differences in model performance were related to species presence prevalence and multiple aspects of rarity empirical distribution functions were applied we used this approach to compare these factors for species performing better using wbrt with distributions from species better suited to brt modeling described above for this analysis we performed a two sample kolmogorov smirnov ks test and plotted results using empirical cumulative density functions the ks test is a non parametric method for comparing two samples to determine whether they follow the same distribution rohlf and sokal 1981 the ks test statistic is d sup x f n 1 x f n 2 x where f n 1 and f n 2 are the empirical cumulative distribution function of the first and second sample respectively when sample sizes are large n 1 50 and n 2 50 the critical value is d k n 1 n 2 n 1 n 2 where k l n 2 2 and is the level of significance when the ks test statistic d is greater than the critical value d these two samples distributions are significantly different to quantify species rarity we utilized an integrated rarity ir index leitao et al 2016 representing a continuous gradient of species rarity by combining measures of species range size habitat usage and mean species weights described in wbrt section above species native range areas km2 obtained from range maps described above were utilized as a measure of overall range size with species having smaller ranges being geographically rarer range in habitat usage was derived with the index of habitat specificity ihs pritt and frimpong 2010 which sums the number of unique freshwater habitat types e g substrate flow velocity etc attributed to individual freshwater fish species frimpong and angermeier 2009 the ihs has a theoretical maximum value of 25 i e 25 total habitat types assigned with species that have lower ihs scores indicating a lower range of habitat use and potentially greater rarity pritt and frimpong 2010 mean species weights utilized as the weighting factor in wbrt were used as a measure of species abundance with species that have lower mean weights representing those that have lower overall relative abundance normalized by species richness at occupied sites the integrated rarity ir i of species i was calculated by combining species native range size snri index of habitat specificity ihsi and mean species weights mswi i r i s n r i w s n r i h s i w i h s m s w i w m s w w s n r w i h s w m s w where wsnr wihs and wmsw are the weights of snri ihsi and mswi respectively in this study all three weights in this formula were equal to 1 3 reflecting equal weighting of these three respective factors snri ihsi and mswi were standardized to a 0 to 1 scale prior to calculation of iri values using the following formula s t a n d a r d i z e d i n d e x i i n d e x i min i n d e x i max i n d e x i min i n d e x i where min and max represent the minimum and maximum values respectively resulting ir values range from a theoretical minimum of 0 to a theoretical maximum of 1 with lower values for rare species and higher values from more common species in general species considered rare according to the ir index would have smaller ranges utilize fewer habitat types and have lower abundance relative to other species 2 3 4 predictor relative importance and overall predictor rankings the relative importance of predictor variables was calculated for each species using wbrt and brt model results in order to compare the relative contributions of predictor variables among approaches predictor variable importance is calculated as r i i 1 m m 1 m i i 2 t m where rii stands for the relative importance for the ith predictor variable m is the number of trees and i i 2 t m is the squared relevance of each predictor weighted by the number of times it was chosen as the splitting variable in tree m hastie et al 2009 in addition we assigned ranks to predictor variables based on their relative importance calculating an overall mean rank across species for each predictor m e a n r a n k i j 1 n r a n k i j n where rankij is the rank of predictor i for species j and n is the total number of species 55 in this study all analyses were conducted in r version 3 6 1 r core team vienna austria 3 results 3 1 comparing brt and wbrt model results 3 1 1 model deviance explained percentage of total deviance explained used to measure model fitting was higher for wbrt than brt for 49 of 55 species table a3 mean deviance explained for wbrt was 0 4769 se 0 0192 range 0 1924 0 8132 compared to 0 3743 se 0 0137 range 0 1429 0 6131 for brt and was significantly higher based on a paired t test p 0 01 fig 3 a differences in deviance explained between wbrt and brt models varied over the integrated rarity index in general these differences were positive indicating that wbrts had improved model fit compared to brts however when integrated rarity was larger than 0 4 indicating more common species differences among the wbrt and brt approaches decreased fig 3b 3 1 2 metrics comparing predictive performance for 50 of 55 species wbrt had a higher metric value indicating better predictive performance than brt for at least one metric when multiple metrics are considered 13 species have higher values for wbrt for four or more metrics fig 4 a table a3 while 24 species performed better with brt based on having higher values for four or more metrics generally kappa and tss led to the same model preferences and in particular results for sensitivity and tss matched both performed better for either wbrt or brt for 52 of 55 species in contrast sensitivity and specificity had differing model preferences being mismatched in 50 of 55 species auprc and auc had moderate congruence with only 15 out 55 species mismatched among the 13 species for which wbrt performed better results were mainly driven by higher metric values for sensitivity 13 kappa 13 tss 13 and auprc 12 fig 4b only two species showed a higher specificity value while eight species had higher auc values similar to wbrt results for the 24 species for which brt performed better included higher metric values for sensitivity 21 kappa 24 tss 24 and auc 23 fig 4c while eight species and 16 species had higher specificity and auprc values respectively 3 2 differences in species presences prevalence and rarity among the two groups of species performing better in either wbrt n 13 or brt n 24 table 2 the number of presences for species with better predictions in wbrt was significantly lower than those with better predictions in brt welch t test p 0 01 with a mean of 785 se 204 range 135 1970 for wbrt and mean of 3198 se 765 range 76 15 811 for brt the empirical cumulative density distribution of presences for these two groups of species was significantly different based on a ks test d 0 5417 p 0 01 fig 5 a the prevalence of the species with better predictions in wbrt with a mean of 0 07 se 0 02 range 0 01 0 19 was also significantly lower than those with better predictions in brt welch t test p 0 01 with a mean of 0 19 se 0 03 range 0 02 0 54 the empirical cumulative density distribution of wbrt species prevalence indicated that it was significantly different than the distribution of brt species prevalence based on a ks test d 0 4295 p 0 04 fig 5b the integrated rarity ir for species performing better in wbrt with a mean of 0 21 se 0 04 range 0 06 0 46 was significantly lower than the mean of those that performed better using brt with a mean of 0 31 se 0 03 range 0 12 0 69 welch t test p 0 02 the empirical cumulative density distribution of wbrt species ir was marginally different from the brt species ir based on a ks test d 0 3846 p 0 08 fig 5c 3 3 predictor relative importance and overall predictor rankings the importance of predictor variables varied primarily by species with differences among wbrt and brt models among species being minimal as indicated by similar mean relative importance and ranks of predictors table 3 the top predictor was catchment area accounting for 23 8 and 18 1 of relative importance for wbrt and brt respectively with mean annual air temperature 9 7 vs 9 3 and mean annual precipitation 7 7 vs 6 9 being the next two most important variables overall the order of predictors according to mean relative importance and mean rank was identical in wbrt and brt table 3 4 discussion to the best of our knowledge this is the first study focused on incorporating species abundance and richness into species distribution models sdms in stream ecology improving predictive accuracy is a primary goal in developing new methods for creating species distribution models sdms stevens and conway 2020 given that many of the species data utilized in sdm development originate from community based abundance sampling efforts particularly in fisheries research there is untapped potential in utilizing the inherent abundance and richness in these datasets in sdms as opposed to reducing community abundance data to binary presence absence data prior to modeling previous studies have suggested that species relative abundance and richness at the sampling locations can be a positive indicator of habitat suitability weber et al 2017 therefore incorporating these measures into a weighting factor applied to boosted regression trees brts species distribution models or other sdm methods more generally can improve model predictive accuracy as indicated by the current study 4 1 applying species abundance and richness based weights to sdms implications for improved modeling of less prevalent and rare species our results suggest that neither brts nor weighted brts wbrts as a whole were a better choice for all stream fish species modeled in this study for the northeastern u s however in general wbrts outperformed unweighted brts for stream fish species with fewer presences lower prevalence and higher rarity these are characteristics that can be shared by species of conservation importance thus this weighting approach has the potential to improve models for these types of species although species with low prevalence can result in imbalanced data causing biased predictions in sdms as has been indicated in a number of studies manel et al 2001 mcpherson and jetz 2007 santika 2011 this issue has seldom been discussed in the context of brt models this is perhaps due to the more powerful predictive ability of brts as issues related to low species prevalence and imbalanced data are not as apparent as regression based sdms identifying candidate species for use of weighting brts can be challenging given that the discrimination and definition of rare species have not been widely accepted by researchers pritt and frimpong 2010 the rarity index utilized in this study that combines species abundance weights habitat usage and native range size provides a reasonable measure of rarity that can be applied to other taxa to identify species best suited for weighted brts when prevalence data are not available the number of presences could be applied to substitute for prevalence as they are likely to be highly correlated in many cases for instance the number of presences and prevalence were highly correlated pearson s correlation coefficient 0 85 p 0 01 in the current study based on the results of this study wbrts should be considered for fluvial fish species with high rarity and low number of presences both species relative abundance and richness were used to calculate the weight of each observation in this study unweighted binary presence absence species models treat all presences the same when testing habitat suitability whether a single individual was observed or many potentially 1000 s of individuals were observed a more logical assumption is that species will be more abundant in more suitable habitats aguirre gutiérrez et al 2013 vanderwal et al 2009 there are however limits to the information that these weightings can provide in the context of sdms as wbrts may not be ideal for common species as they are usually widely distributed and have generalist adaptions to habitats pritt and frimpong 2010 given that common species tend to be widespread and generally of high abundance at locations where they are found it is unsurprising that weights for these species add little value to brts while a limited number of studies have concluded that habitat suitability and species abundance are unrelated e g dallas and hasting 2018 filz et al 2013 nielsen et al 2005 these studies have focused on different taxa groups e g trees mammals insects and vascular plants have not incorporated the effects of species richness and or had much coarser data spatial resolutions than the current study although we incorporated species richness in wbrt models the effect of species interactions on sdms needs to be further studied while the current study supports a positive linkage between species abundance and habitat suitability for less prevalent and rare species this relationship requires further research to aid in use of species weightings for other taxa groups beyond fluvial fishes in addition to prevalence and rarity there are other factors that may affect model performance for example fish sampling provides a snapshot of the relationship between fish communities and their habitats with fish presence and or abundance information being influenced by sampling effort season date time location and identification and or counting errors to differing degrees those biases and uncertainties can vary by species for instance rarer species can be more difficult to detect or may have more variability in abundance across sampling locations wenger and freeman 2008 steenweg et al 2019 which could result in less model certainty for these species in certain cases in addition fish species have differing physiological tolerances to habitat conditions or may undergo seasonal migrations in addition fish species have differing physiological tolerances to habitat conditions as a result locations with the highest species abundance may not always correspond to the most suitable habitats nevertheless weighted sdms still have a great potential in improving predictive ability of sdms 4 2 use of multiple diagnostic metrics to evaluate alternative models when applying the brt or wbrt approaches for other species model predictive performance should be evaluated on a species by species basis we implemented six metrics to compare the performance of the brts and wbrts and found differing results in model preference among metrics if only one metric was used to measure the performance of sdms biased conclusions in model performance would likely result for this reason model performance should not be measured using one single diagnostic metric further survey data for many species are imbalanced i e prevalence is much lower than 0 5 yet some commonly used diagnostic metrics are designed for balanced data auc in particular weights sensitivity and specificity equally when evaluating model performance in ecological surveys presences are usually more valuable in exploring habitat suitability than absences which can be incorrectly obtained for multiple reasons for instance all fish species may not have been captured due to sampling or gear problems additionally habitat may be suitable however individuals from a particular fish species may have vacated the area at the time when sampling was conducted due to seasonal or short term variation in habitat use based on environmental conditions e g stream flow temperature etc similarly correctly predicting presences for an sdm is often of greater importance than correctly predicting absences in most cases therefore sensitivity and auprc are better metrics than specificity and auc for imbalanced data in ecology allouche et al 2006 found that tss is a better metric of predictive accuracy than kappa for sdm evaluation as kappa is dependent on prevalence however in the present study kappa and tss exhibited high correlation pearson s correlation coefficient 0 98 p 0 01 one possible reason is that the prevalence for 53 of 55 fluvial fish species is this study is less than 0 5 and it is not possible to test the performance of kappa or tss across the whole prevalence range 0 1 when evaluating the performance of sdms developed using the brt and wbrt approaches we recommend the use of multiple diagnostic metrics that best represent a given study s objectives in use of sdm results 4 3 applicability of species weightings with other sdm approaches and additional weighting factors this study offers insights into the applicability of using abundance weighted approaches with other commonly used species distribution modeling methods such as logistic regression lr and random forest rf species abundance information can be added into logistic regression models by similarly adjusting the weights in the likelihood function however compared to brt models lr models have difficulties in dealing with multicollinearity interactions non linearity and predictor variable selection these disadvantages may affect the application of weighted lr models and therefore model comparison and validation is needed prior to implementation rf models use the gini index and entropy to grow trees an abundance index can be added into the gini index and entropy function by adjusting case weights of sample data however the performance of weighted rf and its corresponding influence on sdm predictive performance needs further examination species weightings have the potential to be implemented in other sdm approaches however this practice requires careful consideration of specific characteristics of each modeling approach nonetheless results of the current study suggest the potential of species weightings in brt and other model methods to improve predictive accuracy in modeling species distributions other types of data besides species abundance can be utilized as weighting factors in sdms or incorporated into analyses involving weighted sdms species abundances can vary due to numerous factors such as variability in habitat conditions sampling methods and sampling intensity for example other auxiliary information of target species such as biomass length structure and age structure at each location can be a significant indicator of habitat suitability in certain cases species presence absence and abundance data do not display similar distribution patterns therefore the predictions of species distribution ranges based solely on either presence absence or abundance data can be inaccurate with use of combined information critical for valid results mi et al 2017 propose a priority protection index pi that combines the prediction results of occurrence and abundance models to guide habitat management if sampling intensity is known the predicted probability of presence can be transformed to expected abundance changes in expected abundance in biological systems can be used as an early warning indicator for species range contraction or population declines ashcroft et al 2017 further exploration in the use of weightings in sdms for other modeling approaches and applicability of other weighting factors e g biomass etc is needed to provide a framework for developing weighted sdms into useful tools for policy makers and managers 4 4 conclusion in the present study we found that wbrt models outperformed brt models for fish species with lower prevalence and higher rarity in the northeastern u s while brt models performed better for common species with higher prevalence further use of a single model evaluation metric should be avoided in model comparison in favor of multiple diagnostic metrics as certain metrics may be less robust for evaluating and or comparing sdms developed with imbalanced data the approach to developing weighted sdms using species abundance and richness presented in this study can be applied to other commonly used sdms and is not limited solely to brts since sdms are inherently species specific and data dependent model evaluation should be applied for any new species taxa or datasets utilizing this approach credit authorship contribution statement hao yu conceptualization methodology formal analysis writing original draft arthur r cooper conceptualization data curation investigation writing review editing dana m infante supervision conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was funded by the usgs aquatic gap program we thank alexa mckerrow and daniel wieferich for providing feedback on this project we also thank kyle herreman and jared ross for gis and database assistance we are grateful to the numerous federal and state agencies academic institutions and non profit organizations that provided the fish data facilitating this study http assessment fishhabitat org 578a9a43e4b0c1aacab89763 578a9a47e4b0c1aacab8976a supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2020 109202 appendix supplementary materials image application 1 
24776,turbidity is one of the important indicators in water quality management of reservoir there are many factors affecting turbidity and its time series is non linear making prediction difficult therefore it is necessary to carry out research on reservoir turbidity prediction methods in this study the long short term memory lstm neural network was identified validated and tested for the computation of turbidity in the qingcaosha reservoir the model employed historical data of turbidity water level wind direction and wind speed over a period of 2 years at various monitoring points within 40 iterations of the model the mean square error converged to less than 0 05 steadily and the nash efficiency coefficient of the 24 h prediction was above 0 5 it showed that the model has the characteristics of fast convergence high stability and accurate prediction which meant this model can be well applied to prediction of reservoir turbidity this study also tried to use the forecasted wind field data to improve the actual turbidity prediction of the reservoir the results showed that the accuracy is slightly lower than the predicted result using the measured wind field data but it was significantly higher than the prediction result using the extended wind field data at the previous time point therefore using forecasted wind field data can effectively improve the accuracy of the actual reservoir turbidity forecast the results of this study indicate that the lstm neural network model is fast stable and highly accurate indicating that it is suitable for prediction of turbidity in reservoirs and can provide support for water quality management of reservoirs keywords turbidity prediction lstm neural network time series wind field 1 introduction with china s rapid economic development and population growth water shortages and worsening pollution have seriously affected residents water security xu et al 2003 according to relevant statistics as of 2017 of the 1940 surface water quality sections points in china the water quality of 67 9 of the sections was ⅰ ⅲ the water quality of 23 8 of sections was ⅳ ⅴ and the water quality of 8 3 of sections was inferior to ⅴ of the 112 important lakes reservoirs lakes reservoirs of class i water quality account for 5 4 lakes reservoirs of class ii water quality account for 24 1 and lakes reservoirs of class iii water quality account for 33 0 wu 2020 the intensification of water resources pollution has made the already tight water resources more tense which has led to a vicious circle between the two therefore the key to protecting water resources is to make a correct evaluation of the quality of water sources and to reasonably analyze and select water quality standards in order to evaluate the status of water quality a series of water quality standards and water quality parameters need to be specified among which turbidity is an important water quality indicator reflecting the physical characteristics of the water body it can reflect the transparency and purification effect of the water body and to some extent characterize the growth of algae wang et al 2012 stacey et al 2019 figueroa pico et al 2020 therefore accurate prediction of turbidity helps us better understand the quality of water bodies parametric statistics and deterministic models have been traditional methods for modeling turbidity and some studies have been conducted on turbidity prediction models boxall et al 2005 huang 2013 guo 2014 lu et al 2020 however due to the complex nonlinear relationship between many factors affecting turbidity and variables traditional data processing methods are no longer sufficient to solve the problem vreeburg et al 2004 wei 2017 on the other hand artificial neural networks ann capable of mimicking the basic characteristics of the human brain such as adaptive self organizing and fault tolerant have been widely used for model identification analysis and prediction system identification and design optimization niu et al 2006 shu 2006 over the past two decades artificial neural networks have developed explosively in almost all research areas rumelhart and mcclelland 1986 hochreiter and schmidhuber 1997 hinton and salakhutdinov 2006 messikh et al 2007 cabreta mercader 1995 hanbay et al 2008 unlike many statistics based water quality models the latter assumes a linear relationship between response and predictors and their normal distributions while artificial neural networks can map non linear relationships that characterize aquatic ecosystems and have been widely used in water quality problem marier and dandy 1997 demirdag et al 2000 huntingtong et al 2001 julie et al 2002 suen and eheat 2003 sahoo et al 2006 gurmeets et al 2011 qaderi and babanejad 2017 tian et al 2019 the long short term memory lstm neural network in the artificial neural network model selected in this study can better handle the spatiotemporal and non linear complex relationships between multiple parameters due to its own structure making it more favorable for turbidity prediction chen and huo 2016 wang et al 2018 liu et al 2019a the main purpose of this study is to construct a turbidity prediction model for qingcaosha reservoir using lstm neural network train and test the model with measured data and evaluate the feasibility of the model for turbidity prediction the effect of using forecast wind field to improve forecast accuracy in practical applications is also studied finally it can provide scientific support for the management of the reservoir 2 methodology 2 1 reservoir water quality data set the data set used in this study was generated by continuous automatic monitoring of the turbidity of qingcaosha reservoir which is located in the northwest of changxing island at the yangtze river estuary as shown in fig 1 a the effective storage capacity of the reservoir is 438 million cubic meters and the designed total storage capacity is 527 million cubic meters it is currently the largest drinking water source reservoir in shanghai with the largest number of beneficiaries serving more than 10 million people gu et al 2008 and is known as shanghai s century old strategic water source lu 2014 the turbidity monitoring station of this study is divided into three pontoon monitoring points y2 y5 y6 and three fixed pile points g2 g3 g4 fig 1 b shows the location of each turbidity monitoring point the water level monitoring point and wind direction monitoring point are at the water outlet of the reservoir during the two year period march october 2017 march october 2018 the turbidity data of the six stations and the wind field and water level data at the water outlet were collected every 3 h the specific time is 2 o clock 5 o clock 8 o clock 11 o clock 14 o clock 17 o clock 20 o clock and 23 o clock every day 2 2 lstm neural network lstm neural network is a special kind of recurrent neural network which is designed to solve the problem of long term dependence this network was introduced by hochreiter hochreiter and schmidhuber 1997 and many people have improved and popularized it the core of lstm neural network is the simplest feedforward neural network in the input layer to the output layer of the feed forward neural network each neuron receives the input from the previous level and outputs it to the next level and no feedback occurs in the entire network varun et al 2017 however many data processing problems such as voice signals video signals and natural language are difficult to solve through feedforward neural networks this is because these data are time series data and their time dependence makes feedforward neural networks unable to process them li et al 2015 a recurrent neural network rnn is a type of neural network used to process time series data through the recurrent structure of the hidden layer it can better process time series data jing et al 2016 compared with the traditional rnn lstm has a more sophisticated information transmission mechanism which can effectively solve timing problems and long term dependency problems graves and jurgen 2005 in recent years some researchers have applied lstm to the prediction of water quality indicators such as dissolved oxygen and chlorophyll a wang et al 2017 li et al 2018 tian et al 2019 and have also tried to make prediction on turbidity liu et al 2019 however these studies did not take environmental impact factors into account when predicting water quality in this paper the wind field which is an environmental factor that has a greater influence on turbidity is taken into account in the prediction of turbidity to improve the accuracy of the final prediction the experimental hardware used in this study is the windows 10 operating system and is based on python 3 5 programming the neural network model used in this article is based on the tenserflow deep learning framework developed by google tensorflow is a symbolic mathematical system based on data flow programming which is widely used in the programming implementation of various machine learning algorithms abadi et al 2016 2 2 1 input variables and data processing in this study turbidity data at six monitoring points in the reservoir and wind field and water level data at the reservoir water outlet were collected after analyzing the turbidity data it was found that there was some unreasonable noise in the original data from august to october and the distribution of the noise was relatively concentrated which may be caused by the failure of the monitoring equipment as shown in fig 2 a after removing the data from august to october the median distribution of turbidity is between 25 and 50 and the maximum value is below 200 according to the artificial monitoring data in the reservoir this turbidity range is more in line with the actual situation as shown in fig 2 b as shown in figure 3 after analyzing the wind field data it is found that when the wind direction values are 0 90 and 180 270 that is when the wind direction is southeast wind and northwest wind the probability of high turbidity is high these two wind directions are also in line with the mainstream direction of qingcaosha reservoir this shows that the influence of wind speed on turbidity in different wind directions is different therefore the wind speed needs to be converted into the wind speed in the main stream direction of the reservoir and the wind speed perpendicular to the main stream direction of the reservoir as variable inputs assuming that the wind direction is a the wind speed is s the wind speed in the main stream direction of the reservoir is u and the wind speed perpendicular to the main stream direction of the reservoir is v we get eqs 1 2 through these two formulas the wind speeds in different wind directions are projected onto this coordinate axis when the value of u is positive it means that the wind field at this time has a component of the northwest wind direction and on the contrary it has a component of the southeast wind direction when the value of v is positive it means that the wind field at this time has a component of the southwest wind direction and on the contrary it has a component of the northeast wind direction 1 u s sin a 45 2 v s cos a 45 therefore the variables that ultimately serve as the input set include turbidity data at six monitoring points water level data at the water inlet and wind speed in the mainstream direction of the reservoir and vertical wind speed in the reservoir due to the different nature of each variable with different dimensions and orders of magnitude the data needs to be standardized data normalization is to scale the data so that all data falls into a small specific interval the standardization of data can remove the unit limitation of the data and convert it into pure values there is no dimensional limit which facilitates comparison and weighting of indicators that could not be compared with each other due to different units or magnitudes in this paper the data normalization method is mainly used the specific algorithm and main flow of implementation are as follows min max normalization is also called dispersion standardization which results in a reasonable range of 0 to 1 the conversion function is defined as eq 3 3 y x x m i n x m a x x m i n x among them min x is the minimum value among all samples of sequence data max x is the maximum value among all samples of sequence data 2 2 2 lstm neural network and learning algorithm the first layer in the lstm neural network is called the input layer the last layer is the output layer and the middle is the hidden layer hidden layers can be one or more layers a loop structure is added to its hidden layer and the loop structure using sequence information can store the information of the previous time step graves and jurgen 2005 as shown in fig 2 there are four interacting gates in an lstm cell in fig 4 x is the input h and c are two memory vectors and c are cell activation vectors all of which are the same size as the hidden vector h σ is the logistic sigmoid function the task of tanh is to push the values to be between 1 and 1 the hidden layer of lstm contains forget gate input gate and output gate to protect and control the state of neurons these gates act on the hidden layers of the lstm model on the cells also known as blocks the input gate controls the strength of the new input into the memory unit the forget gate controls the memory unit to maintain the intensity of the previous time value and the output gate controls the intensity of the output memory unit their operating function is eqn 4 8 1 forget gate 4 f t σ w xf x t w hf x t 1 w cf x t 1 b f 2 input gate 5 i t σ w xi x t w hi x t 1 w ci x t 1 b i 3 final memory cell 6 c t f t c t 1 i t tanh w xc x t w hc x t 1 b c 4 output gate 7 o t σ w xo x t w ho x t 1 w co x t 1 b o 8 h t o t tanh c t among them it ft ot and ct respectively represent the vector values of the input gate forget gate output gate and memory unit w is the various input cycle weights b is the bias term σ is a sigmoid function which is used to control the unit flow weights ranging from 0 1 f is the intercellular activation vector tanh is the hyperbolic tangent function teng et al 2016 the ideal model generally requires the predicted value to fit the true value in the predicted sample better this requires the use of indicators to measure the gap between the predicted value and the true value and the closer the predicted value to the true value the better the result the value of the index is used to determine the closeness of the two and the weight of each layer is further updated to obtain the optimal model the loss function is used to evaluate the gap between the predicted value and the true value of the model and it is also the objective function of optimization in neural networks the training and optimization of the neural network is the process of minimizing the loss function if the loss function is smaller the model s predicted value will be closer to the true value the loss function is usually expressed by a specific set of equations usually the mean square error mse which is often used in regression tasks eq 9 is the definition of this loss function 9 l θ 1 n i 1 n y i f x i θ 2 where f x is the function to be fitted l θ is used to represent the difference between the true value and the predicted value that is the loss function and n is the number of training sets it can be seen that the higher the value of the loss function output the greater the difference between the predicted value and the true value and the less satisfactory the prediction effect 2 2 3 optimization of the lstm neural network structure the goal of the neural network is to find the minimum value of the loss function this does not mean that the minimum point of the non convex function can be searched but the value of the loss function can be significantly reduced during training and eventually converge to an acceptable minimum point therefore in the field of deep learning choosing an optimization algorithm is also the top priority of a model different optimization algorithms are likely to lead to different training effects this research uses the adam algorithm in the optimization algorithm adam algorithm is a first order optimization algorithm that can replace the traditional stochastic gradient descent process yang et al 2018 it can iteratively update the neural network weights based on the training data adam s algorithm is different from traditional stochastic gradient descent stochastic gradient descent maintains a single learning rate to update all weights the learning rate does not change during the training process the adam algorithm designs independent adaptive learning rates for different parameters by calculating the first and second moment estimates of the gradient this allows it to flexibly use different learning rates for different parameters eqs 10 and 11 are specific calculation formulas 10 w w α v d w c s d w c ε 11 b b α v d b c s d b c ε among them w is the weight and b is the offset α is the learning rate of the network which guides the adjustment of the hyperparameters of the network weights by changing the gradient of the loss function vdw and vdb are the gradient momentums accumulated by the loss function during the first t 1 iterations respectively ε is a small value to prevent the denominator from being zero the lstm neural network used in the model in this paper uses adam algorithm the algorithm is implemented on the tensorflow platform and can be used directly through packaged packages this model shows faster convergence by using the adam algorithm reducing the frequent modification of the initial parameters of the learning rate 2 2 4 modeling performance criteria in this study the prediction results were verified by root mean square error rmse and nash sutcliffe efficiency coefficient nse analysis methods rmse is very sensitive to the large or small errors that occur in a single set of measurements which can well reflect the accuracy of model measurements the nse value depends to a greater extent on the large value in the actual measurement simulation while the small value has less influence therefore nse tends to focus on peak simulation they are expressed as follows 12 r m s e i 1 n y i y 2 n 13 n s e 1 i 1 n x o b s i x m o d e l i 2 i 1 n x o b s i x o b s 2 among them yi is the output value of the neural network y is the real value xobs i is the actual value xmodel i is the predicted value xobs is the average of the actual value and n is the amount of data 2 2 5 parameter determination because it is a regression problem and there is only one predicted variable so there are 9 neurons in the input layer and 1 neuron in the output layer hidden size are first selected from 1 to 3 times the sum of input layer neurons and output layer neurons according to empirical formulas but the number of hidden size involved in lstm includes the 4 mentioned gates in section 2 2 2 therefore the number of hidden size will increase greatly finally after testing it is determined that the prediction effect is best when the number of hidden size is 50 after considering the computing resource limit and the size of the data set the model s batch size is chosen to be 1000 the number of iterations of the model is selected as 100 because according to experiments when the number of iterations is 100 the model has been able to fully converge the learning rate of the model will be changed automatically due to the influence of the adam optimizer so only the initial learning rate needs to be set the initial learning rate used in this model is 0 1 the time step the characteristic parameter of the lstm model represents the expansion step of back propagation that is the length of the time series required for prediction its determination requires changing the time step based on the set number of iterations and batch size and observing the error size of the test set due to the relative randomness of the neural network model the training is repeated ten times at each time step to obtain the root mean square error and the average is used as the error result table 1 shows the root mean square error results obtained when the forecast period is 3 h it can be seen that when the time step is less than 4 the error of several points basically decreases as the time step increases while when the time step is greater than 4 the error of several points shows an increase trend with time step therefore when the time step is 4 the prediction results of each point can achieve better results so the time step selected by the model is 4 when the forecast period is 3 h next the root mean square error of the turbidity at g4 at different time steps in different forecast periods within 24 h is analyzed table 2 it can be seen that when the forecast period is less than or equal to 9 h and the time step is 4 the model has the smallest root mean square error and the highest accuracy and when the forecast period is greater than 9 h the optimal time step is 1 therefore when choosing a time step the model chooses 4 when the forecast period is less than or equal to 9 h and 1 when it is greater than 9 h 2 2 6 workflow of lstm turbidity prediction model as an extended model with multiple hidden lstm layers each layer of the stacked lstm has numerous memory cells which makes the model earning the deep learning technique as shown in fig 5 we designed a water quality prediction model based on lstm deep neural networks 3 results and discussion 3 1 lstm turbidity prediction model first in order to analyze the impact of different data set sizes on prediction accuracy this study was conducted using different data volumes under different data set sizes the data set is divided into a training set and a test set and the division ratio is 0 8 0 2 that is 80 of the data is used as the training set input and 20 of the data is used as the test set for testing fig 6 shows the comparison between predicted results and actual values fig 6 shows that the simulated output of the lstm turbidity prediction model for the turbidity prediction of the water conveyance of qingcaosha reservoir is basically consistent with the overall output and the predicted value is very close to the actual value indicating that the model has a low degree of deviation it can be considered that the lstm model has a good effect in predicting the turbidity of the water conveyance of qingcaosha reservoir at the same time the amount of input training data of the lstm neural network will significantly affect the prediction effect of the model when the amount of input data is 630 sets of data the deviation between the predicted value curve and the true value curve is large and the gap is obvious as the amount of input training data for the neural network increases such as 1261 sets of data 1752 sets of data and 2448 sets of data the model prediction results improve the predicted value curve is closer to the true value curve and the degree of deviation decreases this is because when the size of the training set increases the data features will also increase and the data features that the model can train will also increase which will improve the training effect of the model and improve the prediction effect of the model further training is performed with the largest amount of input data that is 2448 sets of data and the convergence of the training error is observed it can be seen from fig 7 that during the training of the lstm turbidity prediction model the prediction error of the test set quickly converged to less than 0 05 within 40 iterations and the prediction error of the training set itself also converged to less than 0 05 within 40 iterations this shows that the lstm neural network model can quickly converge when training data the training error is small and the prediction result of the test set is relatively good the error of the training set and the test set during the lstm turbidity prediction model training decreases rapidly in the first 40 iterations indicating that the training of the lstm turbidity prediction is fast after 40 iterations the error of the training set and test set is stable at a low level and the fluctuation is small indicating that the prediction model has good stability the actual reservoir data is updated quickly and requires fast response time which makes prediction difficult therefore the fastness of the model in this paper is conducive to the rapid analysis of reservoir turbidity data and real time prediction effect in addition the prediction of the turbidity of the reservoir will greatly affect the decision of the management of the reservoir therefore whether the model results can maintain a robust prediction effect is of great significance to the manager therefore the stability of the lstm turbidity prediction model in this paper is also one of the advantages of the model which makes it suitable for reservoir turbidity prediction 3 2 optimization of actual turbidity prediction using weather forecast data in the actual turbidity forecast there is no turbidity data at the current time point for the model to calculate the turbidity at the next time point the common practice is to use the data from the previous time point for prediction therefore this study attempts to use the forecasted wind field data to make predictions to investigate whether the accuracy of the prediction can be improved the selected time period is july 2018 the forecast period of the weather forecast is one day the source is weather forecast data from china weather network the wind field forecast data are wind level and wind direction in order to apply the model they need to be converted into numbers the wind level conversion method refers to relevant regulations of the meteorological department the data is also preprocessed the wind speed is converted into the wind speed in the main direction of the reservoir and the wind speed perpendicular to the main direction of the reservoir then compare it with the actual data and the comparison result is shown in fig 8 it can be found that when the wind speed is in the mainstream direction of the reservoir the predicted value as a whole is higher than the actual value when the wind speed is perpendicular to the mainstream of the reservoir the overall trend is the same but the actual data fluctuates more than the forecast data in order to analyze the effect of forecasting using forecasted wind field data it is necessary to compare it with the forecast results using the measured wind field data and the previous time point wind field data it should be noted that the turbidity and water level of the remaining points when using the forecasted wind field data are used from the previous time point that is to say this forecast only changes the wind speed finally the prediction result errors root mean square error and nash efficiency coefficient using different data and different prediction intervals are shown in fig 9 due to the relative randomness of the neural network model the training result is repeated ten times at each prediction interval to obtain the prediction result error and the average is taken as the error result it can be seen that for the three prediction methods as the time interval of the prediction becomes larger the error of the prediction result will increase accordingly the magnitude and increase of the error within 24 h are within acceptable ranges so it can be said that it is more accurate to use the forecasted wind field data for prediction the rmse error obtained using the pre wind field report data is greater than the error obtained using the actual wind field data and is smaller than the error predicted from the previous time point wind field data the nse error obtained using the predicted wind field data is less than the actual wind field data the error is greater than the prediction error using wind field data from the previous time point this shows that although the use of weather forecast data is not as good as forecasting using actual wind field data but is better than using the wind field data from the previous point in time therefore the use of forecasted wind field data in turbidity forecasting can improve forecasting accuracy 4 conclusions in this study the lstm neural network was identified validated and tested for the computation of turbidity in the qingcaosha reservoir the model employed historical data of turbidity water level wind direction and wind speed over a period of 2 years at various monitoring points within 40 iterations of the model the mean square error converged to less than 0 05 steadily and the nash efficiency coefficient of the 24 h prediction was above 0 5 it showed that the model has the characteristics of fast convergence high stability and accurate prediction which meant this model can be well applied to prediction of reservoir turbidity this study also tried to use the forecasted wind field data to improve the actual turbidity prediction of the reservoir the results showed that the accuracy is slightly lower than the predicted result using the measured wind field data but it was significantly higher than the prediction result using the extended wind field data at the previous time point therefore using forecasted wind field data can effectively improve the accuracy of the actual reservoir turbidity forecast credit author statement i have made substantial contributions to the conception or design of the work or the acquisition analysis or interpretation of data for the work and i have drafted the work or revised it critically for important intellectual content and i have approved the final version to be published and i agree to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved all persons who have made substantial contributions to the work reported in the manuscript including those who provided editing and writing assistance but who are not authors are named in the acknowledgments section of the manuscript and have given their written permission to be named if the manuscript does not include acknowledgments it is because the authors have not received substantial contributions from nonauthors declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the major science and technology program for water pollution control and treatment no 2017zx07207003 02 funded by ministry of housing and urban rural development of the people s of china we are very grateful for the financial support of this program 
24776,turbidity is one of the important indicators in water quality management of reservoir there are many factors affecting turbidity and its time series is non linear making prediction difficult therefore it is necessary to carry out research on reservoir turbidity prediction methods in this study the long short term memory lstm neural network was identified validated and tested for the computation of turbidity in the qingcaosha reservoir the model employed historical data of turbidity water level wind direction and wind speed over a period of 2 years at various monitoring points within 40 iterations of the model the mean square error converged to less than 0 05 steadily and the nash efficiency coefficient of the 24 h prediction was above 0 5 it showed that the model has the characteristics of fast convergence high stability and accurate prediction which meant this model can be well applied to prediction of reservoir turbidity this study also tried to use the forecasted wind field data to improve the actual turbidity prediction of the reservoir the results showed that the accuracy is slightly lower than the predicted result using the measured wind field data but it was significantly higher than the prediction result using the extended wind field data at the previous time point therefore using forecasted wind field data can effectively improve the accuracy of the actual reservoir turbidity forecast the results of this study indicate that the lstm neural network model is fast stable and highly accurate indicating that it is suitable for prediction of turbidity in reservoirs and can provide support for water quality management of reservoirs keywords turbidity prediction lstm neural network time series wind field 1 introduction with china s rapid economic development and population growth water shortages and worsening pollution have seriously affected residents water security xu et al 2003 according to relevant statistics as of 2017 of the 1940 surface water quality sections points in china the water quality of 67 9 of the sections was ⅰ ⅲ the water quality of 23 8 of sections was ⅳ ⅴ and the water quality of 8 3 of sections was inferior to ⅴ of the 112 important lakes reservoirs lakes reservoirs of class i water quality account for 5 4 lakes reservoirs of class ii water quality account for 24 1 and lakes reservoirs of class iii water quality account for 33 0 wu 2020 the intensification of water resources pollution has made the already tight water resources more tense which has led to a vicious circle between the two therefore the key to protecting water resources is to make a correct evaluation of the quality of water sources and to reasonably analyze and select water quality standards in order to evaluate the status of water quality a series of water quality standards and water quality parameters need to be specified among which turbidity is an important water quality indicator reflecting the physical characteristics of the water body it can reflect the transparency and purification effect of the water body and to some extent characterize the growth of algae wang et al 2012 stacey et al 2019 figueroa pico et al 2020 therefore accurate prediction of turbidity helps us better understand the quality of water bodies parametric statistics and deterministic models have been traditional methods for modeling turbidity and some studies have been conducted on turbidity prediction models boxall et al 2005 huang 2013 guo 2014 lu et al 2020 however due to the complex nonlinear relationship between many factors affecting turbidity and variables traditional data processing methods are no longer sufficient to solve the problem vreeburg et al 2004 wei 2017 on the other hand artificial neural networks ann capable of mimicking the basic characteristics of the human brain such as adaptive self organizing and fault tolerant have been widely used for model identification analysis and prediction system identification and design optimization niu et al 2006 shu 2006 over the past two decades artificial neural networks have developed explosively in almost all research areas rumelhart and mcclelland 1986 hochreiter and schmidhuber 1997 hinton and salakhutdinov 2006 messikh et al 2007 cabreta mercader 1995 hanbay et al 2008 unlike many statistics based water quality models the latter assumes a linear relationship between response and predictors and their normal distributions while artificial neural networks can map non linear relationships that characterize aquatic ecosystems and have been widely used in water quality problem marier and dandy 1997 demirdag et al 2000 huntingtong et al 2001 julie et al 2002 suen and eheat 2003 sahoo et al 2006 gurmeets et al 2011 qaderi and babanejad 2017 tian et al 2019 the long short term memory lstm neural network in the artificial neural network model selected in this study can better handle the spatiotemporal and non linear complex relationships between multiple parameters due to its own structure making it more favorable for turbidity prediction chen and huo 2016 wang et al 2018 liu et al 2019a the main purpose of this study is to construct a turbidity prediction model for qingcaosha reservoir using lstm neural network train and test the model with measured data and evaluate the feasibility of the model for turbidity prediction the effect of using forecast wind field to improve forecast accuracy in practical applications is also studied finally it can provide scientific support for the management of the reservoir 2 methodology 2 1 reservoir water quality data set the data set used in this study was generated by continuous automatic monitoring of the turbidity of qingcaosha reservoir which is located in the northwest of changxing island at the yangtze river estuary as shown in fig 1 a the effective storage capacity of the reservoir is 438 million cubic meters and the designed total storage capacity is 527 million cubic meters it is currently the largest drinking water source reservoir in shanghai with the largest number of beneficiaries serving more than 10 million people gu et al 2008 and is known as shanghai s century old strategic water source lu 2014 the turbidity monitoring station of this study is divided into three pontoon monitoring points y2 y5 y6 and three fixed pile points g2 g3 g4 fig 1 b shows the location of each turbidity monitoring point the water level monitoring point and wind direction monitoring point are at the water outlet of the reservoir during the two year period march october 2017 march october 2018 the turbidity data of the six stations and the wind field and water level data at the water outlet were collected every 3 h the specific time is 2 o clock 5 o clock 8 o clock 11 o clock 14 o clock 17 o clock 20 o clock and 23 o clock every day 2 2 lstm neural network lstm neural network is a special kind of recurrent neural network which is designed to solve the problem of long term dependence this network was introduced by hochreiter hochreiter and schmidhuber 1997 and many people have improved and popularized it the core of lstm neural network is the simplest feedforward neural network in the input layer to the output layer of the feed forward neural network each neuron receives the input from the previous level and outputs it to the next level and no feedback occurs in the entire network varun et al 2017 however many data processing problems such as voice signals video signals and natural language are difficult to solve through feedforward neural networks this is because these data are time series data and their time dependence makes feedforward neural networks unable to process them li et al 2015 a recurrent neural network rnn is a type of neural network used to process time series data through the recurrent structure of the hidden layer it can better process time series data jing et al 2016 compared with the traditional rnn lstm has a more sophisticated information transmission mechanism which can effectively solve timing problems and long term dependency problems graves and jurgen 2005 in recent years some researchers have applied lstm to the prediction of water quality indicators such as dissolved oxygen and chlorophyll a wang et al 2017 li et al 2018 tian et al 2019 and have also tried to make prediction on turbidity liu et al 2019 however these studies did not take environmental impact factors into account when predicting water quality in this paper the wind field which is an environmental factor that has a greater influence on turbidity is taken into account in the prediction of turbidity to improve the accuracy of the final prediction the experimental hardware used in this study is the windows 10 operating system and is based on python 3 5 programming the neural network model used in this article is based on the tenserflow deep learning framework developed by google tensorflow is a symbolic mathematical system based on data flow programming which is widely used in the programming implementation of various machine learning algorithms abadi et al 2016 2 2 1 input variables and data processing in this study turbidity data at six monitoring points in the reservoir and wind field and water level data at the reservoir water outlet were collected after analyzing the turbidity data it was found that there was some unreasonable noise in the original data from august to october and the distribution of the noise was relatively concentrated which may be caused by the failure of the monitoring equipment as shown in fig 2 a after removing the data from august to october the median distribution of turbidity is between 25 and 50 and the maximum value is below 200 according to the artificial monitoring data in the reservoir this turbidity range is more in line with the actual situation as shown in fig 2 b as shown in figure 3 after analyzing the wind field data it is found that when the wind direction values are 0 90 and 180 270 that is when the wind direction is southeast wind and northwest wind the probability of high turbidity is high these two wind directions are also in line with the mainstream direction of qingcaosha reservoir this shows that the influence of wind speed on turbidity in different wind directions is different therefore the wind speed needs to be converted into the wind speed in the main stream direction of the reservoir and the wind speed perpendicular to the main stream direction of the reservoir as variable inputs assuming that the wind direction is a the wind speed is s the wind speed in the main stream direction of the reservoir is u and the wind speed perpendicular to the main stream direction of the reservoir is v we get eqs 1 2 through these two formulas the wind speeds in different wind directions are projected onto this coordinate axis when the value of u is positive it means that the wind field at this time has a component of the northwest wind direction and on the contrary it has a component of the southeast wind direction when the value of v is positive it means that the wind field at this time has a component of the southwest wind direction and on the contrary it has a component of the northeast wind direction 1 u s sin a 45 2 v s cos a 45 therefore the variables that ultimately serve as the input set include turbidity data at six monitoring points water level data at the water inlet and wind speed in the mainstream direction of the reservoir and vertical wind speed in the reservoir due to the different nature of each variable with different dimensions and orders of magnitude the data needs to be standardized data normalization is to scale the data so that all data falls into a small specific interval the standardization of data can remove the unit limitation of the data and convert it into pure values there is no dimensional limit which facilitates comparison and weighting of indicators that could not be compared with each other due to different units or magnitudes in this paper the data normalization method is mainly used the specific algorithm and main flow of implementation are as follows min max normalization is also called dispersion standardization which results in a reasonable range of 0 to 1 the conversion function is defined as eq 3 3 y x x m i n x m a x x m i n x among them min x is the minimum value among all samples of sequence data max x is the maximum value among all samples of sequence data 2 2 2 lstm neural network and learning algorithm the first layer in the lstm neural network is called the input layer the last layer is the output layer and the middle is the hidden layer hidden layers can be one or more layers a loop structure is added to its hidden layer and the loop structure using sequence information can store the information of the previous time step graves and jurgen 2005 as shown in fig 2 there are four interacting gates in an lstm cell in fig 4 x is the input h and c are two memory vectors and c are cell activation vectors all of which are the same size as the hidden vector h σ is the logistic sigmoid function the task of tanh is to push the values to be between 1 and 1 the hidden layer of lstm contains forget gate input gate and output gate to protect and control the state of neurons these gates act on the hidden layers of the lstm model on the cells also known as blocks the input gate controls the strength of the new input into the memory unit the forget gate controls the memory unit to maintain the intensity of the previous time value and the output gate controls the intensity of the output memory unit their operating function is eqn 4 8 1 forget gate 4 f t σ w xf x t w hf x t 1 w cf x t 1 b f 2 input gate 5 i t σ w xi x t w hi x t 1 w ci x t 1 b i 3 final memory cell 6 c t f t c t 1 i t tanh w xc x t w hc x t 1 b c 4 output gate 7 o t σ w xo x t w ho x t 1 w co x t 1 b o 8 h t o t tanh c t among them it ft ot and ct respectively represent the vector values of the input gate forget gate output gate and memory unit w is the various input cycle weights b is the bias term σ is a sigmoid function which is used to control the unit flow weights ranging from 0 1 f is the intercellular activation vector tanh is the hyperbolic tangent function teng et al 2016 the ideal model generally requires the predicted value to fit the true value in the predicted sample better this requires the use of indicators to measure the gap between the predicted value and the true value and the closer the predicted value to the true value the better the result the value of the index is used to determine the closeness of the two and the weight of each layer is further updated to obtain the optimal model the loss function is used to evaluate the gap between the predicted value and the true value of the model and it is also the objective function of optimization in neural networks the training and optimization of the neural network is the process of minimizing the loss function if the loss function is smaller the model s predicted value will be closer to the true value the loss function is usually expressed by a specific set of equations usually the mean square error mse which is often used in regression tasks eq 9 is the definition of this loss function 9 l θ 1 n i 1 n y i f x i θ 2 where f x is the function to be fitted l θ is used to represent the difference between the true value and the predicted value that is the loss function and n is the number of training sets it can be seen that the higher the value of the loss function output the greater the difference between the predicted value and the true value and the less satisfactory the prediction effect 2 2 3 optimization of the lstm neural network structure the goal of the neural network is to find the minimum value of the loss function this does not mean that the minimum point of the non convex function can be searched but the value of the loss function can be significantly reduced during training and eventually converge to an acceptable minimum point therefore in the field of deep learning choosing an optimization algorithm is also the top priority of a model different optimization algorithms are likely to lead to different training effects this research uses the adam algorithm in the optimization algorithm adam algorithm is a first order optimization algorithm that can replace the traditional stochastic gradient descent process yang et al 2018 it can iteratively update the neural network weights based on the training data adam s algorithm is different from traditional stochastic gradient descent stochastic gradient descent maintains a single learning rate to update all weights the learning rate does not change during the training process the adam algorithm designs independent adaptive learning rates for different parameters by calculating the first and second moment estimates of the gradient this allows it to flexibly use different learning rates for different parameters eqs 10 and 11 are specific calculation formulas 10 w w α v d w c s d w c ε 11 b b α v d b c s d b c ε among them w is the weight and b is the offset α is the learning rate of the network which guides the adjustment of the hyperparameters of the network weights by changing the gradient of the loss function vdw and vdb are the gradient momentums accumulated by the loss function during the first t 1 iterations respectively ε is a small value to prevent the denominator from being zero the lstm neural network used in the model in this paper uses adam algorithm the algorithm is implemented on the tensorflow platform and can be used directly through packaged packages this model shows faster convergence by using the adam algorithm reducing the frequent modification of the initial parameters of the learning rate 2 2 4 modeling performance criteria in this study the prediction results were verified by root mean square error rmse and nash sutcliffe efficiency coefficient nse analysis methods rmse is very sensitive to the large or small errors that occur in a single set of measurements which can well reflect the accuracy of model measurements the nse value depends to a greater extent on the large value in the actual measurement simulation while the small value has less influence therefore nse tends to focus on peak simulation they are expressed as follows 12 r m s e i 1 n y i y 2 n 13 n s e 1 i 1 n x o b s i x m o d e l i 2 i 1 n x o b s i x o b s 2 among them yi is the output value of the neural network y is the real value xobs i is the actual value xmodel i is the predicted value xobs is the average of the actual value and n is the amount of data 2 2 5 parameter determination because it is a regression problem and there is only one predicted variable so there are 9 neurons in the input layer and 1 neuron in the output layer hidden size are first selected from 1 to 3 times the sum of input layer neurons and output layer neurons according to empirical formulas but the number of hidden size involved in lstm includes the 4 mentioned gates in section 2 2 2 therefore the number of hidden size will increase greatly finally after testing it is determined that the prediction effect is best when the number of hidden size is 50 after considering the computing resource limit and the size of the data set the model s batch size is chosen to be 1000 the number of iterations of the model is selected as 100 because according to experiments when the number of iterations is 100 the model has been able to fully converge the learning rate of the model will be changed automatically due to the influence of the adam optimizer so only the initial learning rate needs to be set the initial learning rate used in this model is 0 1 the time step the characteristic parameter of the lstm model represents the expansion step of back propagation that is the length of the time series required for prediction its determination requires changing the time step based on the set number of iterations and batch size and observing the error size of the test set due to the relative randomness of the neural network model the training is repeated ten times at each time step to obtain the root mean square error and the average is used as the error result table 1 shows the root mean square error results obtained when the forecast period is 3 h it can be seen that when the time step is less than 4 the error of several points basically decreases as the time step increases while when the time step is greater than 4 the error of several points shows an increase trend with time step therefore when the time step is 4 the prediction results of each point can achieve better results so the time step selected by the model is 4 when the forecast period is 3 h next the root mean square error of the turbidity at g4 at different time steps in different forecast periods within 24 h is analyzed table 2 it can be seen that when the forecast period is less than or equal to 9 h and the time step is 4 the model has the smallest root mean square error and the highest accuracy and when the forecast period is greater than 9 h the optimal time step is 1 therefore when choosing a time step the model chooses 4 when the forecast period is less than or equal to 9 h and 1 when it is greater than 9 h 2 2 6 workflow of lstm turbidity prediction model as an extended model with multiple hidden lstm layers each layer of the stacked lstm has numerous memory cells which makes the model earning the deep learning technique as shown in fig 5 we designed a water quality prediction model based on lstm deep neural networks 3 results and discussion 3 1 lstm turbidity prediction model first in order to analyze the impact of different data set sizes on prediction accuracy this study was conducted using different data volumes under different data set sizes the data set is divided into a training set and a test set and the division ratio is 0 8 0 2 that is 80 of the data is used as the training set input and 20 of the data is used as the test set for testing fig 6 shows the comparison between predicted results and actual values fig 6 shows that the simulated output of the lstm turbidity prediction model for the turbidity prediction of the water conveyance of qingcaosha reservoir is basically consistent with the overall output and the predicted value is very close to the actual value indicating that the model has a low degree of deviation it can be considered that the lstm model has a good effect in predicting the turbidity of the water conveyance of qingcaosha reservoir at the same time the amount of input training data of the lstm neural network will significantly affect the prediction effect of the model when the amount of input data is 630 sets of data the deviation between the predicted value curve and the true value curve is large and the gap is obvious as the amount of input training data for the neural network increases such as 1261 sets of data 1752 sets of data and 2448 sets of data the model prediction results improve the predicted value curve is closer to the true value curve and the degree of deviation decreases this is because when the size of the training set increases the data features will also increase and the data features that the model can train will also increase which will improve the training effect of the model and improve the prediction effect of the model further training is performed with the largest amount of input data that is 2448 sets of data and the convergence of the training error is observed it can be seen from fig 7 that during the training of the lstm turbidity prediction model the prediction error of the test set quickly converged to less than 0 05 within 40 iterations and the prediction error of the training set itself also converged to less than 0 05 within 40 iterations this shows that the lstm neural network model can quickly converge when training data the training error is small and the prediction result of the test set is relatively good the error of the training set and the test set during the lstm turbidity prediction model training decreases rapidly in the first 40 iterations indicating that the training of the lstm turbidity prediction is fast after 40 iterations the error of the training set and test set is stable at a low level and the fluctuation is small indicating that the prediction model has good stability the actual reservoir data is updated quickly and requires fast response time which makes prediction difficult therefore the fastness of the model in this paper is conducive to the rapid analysis of reservoir turbidity data and real time prediction effect in addition the prediction of the turbidity of the reservoir will greatly affect the decision of the management of the reservoir therefore whether the model results can maintain a robust prediction effect is of great significance to the manager therefore the stability of the lstm turbidity prediction model in this paper is also one of the advantages of the model which makes it suitable for reservoir turbidity prediction 3 2 optimization of actual turbidity prediction using weather forecast data in the actual turbidity forecast there is no turbidity data at the current time point for the model to calculate the turbidity at the next time point the common practice is to use the data from the previous time point for prediction therefore this study attempts to use the forecasted wind field data to make predictions to investigate whether the accuracy of the prediction can be improved the selected time period is july 2018 the forecast period of the weather forecast is one day the source is weather forecast data from china weather network the wind field forecast data are wind level and wind direction in order to apply the model they need to be converted into numbers the wind level conversion method refers to relevant regulations of the meteorological department the data is also preprocessed the wind speed is converted into the wind speed in the main direction of the reservoir and the wind speed perpendicular to the main direction of the reservoir then compare it with the actual data and the comparison result is shown in fig 8 it can be found that when the wind speed is in the mainstream direction of the reservoir the predicted value as a whole is higher than the actual value when the wind speed is perpendicular to the mainstream of the reservoir the overall trend is the same but the actual data fluctuates more than the forecast data in order to analyze the effect of forecasting using forecasted wind field data it is necessary to compare it with the forecast results using the measured wind field data and the previous time point wind field data it should be noted that the turbidity and water level of the remaining points when using the forecasted wind field data are used from the previous time point that is to say this forecast only changes the wind speed finally the prediction result errors root mean square error and nash efficiency coefficient using different data and different prediction intervals are shown in fig 9 due to the relative randomness of the neural network model the training result is repeated ten times at each prediction interval to obtain the prediction result error and the average is taken as the error result it can be seen that for the three prediction methods as the time interval of the prediction becomes larger the error of the prediction result will increase accordingly the magnitude and increase of the error within 24 h are within acceptable ranges so it can be said that it is more accurate to use the forecasted wind field data for prediction the rmse error obtained using the pre wind field report data is greater than the error obtained using the actual wind field data and is smaller than the error predicted from the previous time point wind field data the nse error obtained using the predicted wind field data is less than the actual wind field data the error is greater than the prediction error using wind field data from the previous time point this shows that although the use of weather forecast data is not as good as forecasting using actual wind field data but is better than using the wind field data from the previous point in time therefore the use of forecasted wind field data in turbidity forecasting can improve forecasting accuracy 4 conclusions in this study the lstm neural network was identified validated and tested for the computation of turbidity in the qingcaosha reservoir the model employed historical data of turbidity water level wind direction and wind speed over a period of 2 years at various monitoring points within 40 iterations of the model the mean square error converged to less than 0 05 steadily and the nash efficiency coefficient of the 24 h prediction was above 0 5 it showed that the model has the characteristics of fast convergence high stability and accurate prediction which meant this model can be well applied to prediction of reservoir turbidity this study also tried to use the forecasted wind field data to improve the actual turbidity prediction of the reservoir the results showed that the accuracy is slightly lower than the predicted result using the measured wind field data but it was significantly higher than the prediction result using the extended wind field data at the previous time point therefore using forecasted wind field data can effectively improve the accuracy of the actual reservoir turbidity forecast credit author statement i have made substantial contributions to the conception or design of the work or the acquisition analysis or interpretation of data for the work and i have drafted the work or revised it critically for important intellectual content and i have approved the final version to be published and i agree to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved all persons who have made substantial contributions to the work reported in the manuscript including those who provided editing and writing assistance but who are not authors are named in the acknowledgments section of the manuscript and have given their written permission to be named if the manuscript does not include acknowledgments it is because the authors have not received substantial contributions from nonauthors declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the major science and technology program for water pollution control and treatment no 2017zx07207003 02 funded by ministry of housing and urban rural development of the people s of china we are very grateful for the financial support of this program 
24777,traditionally marine carbon monoxide co models assume that the microbial oxidation of co is only dependent on the concentration of co in the water column however co oxidation rates in the ocean have been reported to vary up to two orders of magnitude both spatially and temporally here we developed a new model assuming that co microbial oxidation is dependent on bacterial carbon biomass other than co concentration in addition to microbial oxidation the model also describes co photochemical production vertical mixing and air sea gas exchange the new co model has been embedded in the european regional seas ecosystem model ersem and coupled with the general ocean turbulence model gotm the co gotm ersem model was implemented at the bermuda atlantic time series bats station to simulate co concentrations observed in march 1993 by kettle 1994 the proposed second order function describing co microbial oxidation introduces a new parameter the bacteria biomass specific oxidation rate which was estimated to be 5 7 0 2 μg c m 3 1 h 1 statistical metrics indicates that the new co model performs better than a previously published model with a first order decay function to describe microbial oxidation acknowledging the dependence of microbial oxidation on bacterial abundance is realistic a long term 1992 1994 simulation carried out with co gotm ersem reproduced the spatial and seasonal variability of co reported in the literature our model provides a realistic description of the co dynamics and is potentially usable in different environmental contexts worldwide keywords marine carbon monoxide microbial oxidation marine ecosystem modelling second order kinetics 1 introduction carbon monoxide co plays two key roles in the atmosphere 1 it impacts on climate forcing by competing with the methane in the reaction with the hydroxyl radical daniel and solomon 1998 the main atmospheric oxidant and 2 it is involved in the production of ozone logan et al 1981 which in turn leads to the photochemical smog reducing atmospheric visibility therefore considering its impact on the chemical properties of the atmosphere co is regarded as one of the most important trace gasses stocker et al 2013 although most of the atmospheric co is emitted from the continent outgassing from the sea surface could be a significant source in the remote marine environments and in the southern hemisphere where the co in the surface ocean is supersaturated with respect to the overlying air bates et al 1995 conrad et al 1982 khalil and rasmussen 1990 logan et al 1981 rhee 2000 stubbins et al 2006 zafiriou et al 2003 understanding co dynamics in the marine upper layer is thereby crucial to assess the role played by this gas in the global climate regulation the concentration of dissolved co in the surface ocean results from the balance between photochemical production conrad et al 1982 redden 1982 zuo and jones 1995 microbial oxidation conrad et al 1982 jones and amador 1993 jones and morita 1984 air sea gas exchange bates et al 1995 conrad et al 1982 park and rhee 2016 zuo and jones 1995 and vertical mixing doney et al 1995 gnanadesikan 1996 johnson and bates 1996 kettle 1994 fig 1 among these processes photochemical production and microbial oxidation are the major processes contributing to the co budget in the ocean zafiriou et al 2003 indeed photolysis of chromophoric dissolved organic matter cdom in the euphotic zone is the only known source of co while microbial oxidation is by far the dominant sink destroying more than 80 of the co pool therefore an accurate parameterization of microbial oxidation is essential to estimate co flux from the upper ocean moran and miller 2007 microbial co oxidation is described conventionally as a first order kinetics conrad et al 1982 johnson and bates 1996 jones 1991 jones and amador 1993 xie et al 2005 zafiriou et al 2003 assuming that co oxidation rate increases linearly with the increase of dissolved co concentrations regardless of microbial abundance and community composition several modeling studies of marine co dynamics were carried out to understand the co budget in the ocean kettle 1994 developed a model to understand the surface diurnal pattern of dissolved co concentrations at the bermuda atlantic time series study bats station in the sargasso sea the model adopted the price weller pinkel pwp vertical mixing scheme price et al 1986 to simulate the physical mixing and transport in the surface mixed layer and subsurface layers co production was simulated by using a modified version of the photochemical production module previously developed for dissolved hydrogen peroxide h2o2 in the marine environments by sikorski and zika 1993 in subsequent studies kettle 2000 2005b an optimization technique was used to reduce the discrepancy between observed and simulated dissolved co concentrations based on the co observation by kettle 1994 gnanadesikan 1996 developed a simple model coupling co dynamics with a bulk mixed layer model to identify nine marine regimes corresponding to different interactions between physical mixing and photochemical productions the regimes were defined depending on the ratios between physical length scales i e the depths to which vertical mixing ventilation and photochemically active radiation penetration occur the critical difference between the models of gnanadesikan 1996 and kettle 1994 is the way they describe co photochemical production while kettle 1994 considered the variation of co photoproduction rate depending on the spectral irradiance gnanadesikan 1996 assumed that the photoproduction is proportional to a fraction of the total irradiance simple box models were also used to determine the ratio between photochemical production and microbial oxidation johnson and bates 1996 kitidis et al 2011 johnson and bates 1996 determined the photoproduction and oxidation rates using the exponential fits of their observed diurnal variations of co kitidis et al 2011 took the production and oxidation rates from their experimental measurements and considered the vertical gradient of co concentration due mainly to the light attenuation with depth all the above mentioned modeling studies used a first order kinetics to describe co microbial oxidation implicitly assuming that the co microbial oxidation rate is constant in the ocean however this assumption is not consistent with experimental studies reporting that the co oxidation rates k co varies dramatically 0 003 1 11 h 1 both temporally and spatially johnson and bates 1996 jones 1991 jones and amador 1993 kwon 2015 xie et al 2005 moreover xie et al 2005 2009 reported complex influences of various biotic and abiotic variables on this process showing that k co is dependent on temperature primary production and salinity these studies suggest that previously used formulations can only be reliable in specific conditions i e specific location and time of the year but cannot be used in modeling work dealing with large spatial e g global models and temporal scales from seasonal upward the aim of this paper is to provide a novel model formulation able to simulate the variability of co oxidation rate described in literature to this end we tested the hypothesis that microbial co oxidation is a function of not only dissolved co concentration but also bacterial biomass our co model was implemented in a widely used marine ecosystem model the european regional seas ecosystem model ersem butenschön et al 2016 since ersem only accounts for heterotrophic bacteria we assumed that the activity of co oxidizing bacteria is proportional to the biomass of the heterotrophic bacteria community this assumption is supported by the several studies gonzalez and moran 1997 gonzalez et al 2000 moran et al 2004 suzuki et al 2001 tolli et al 2006 which show that co oxidizing bacteria roseobacter associated clade are ubiquitous in the ocean and that account for a relatively constant fraction of the heterotrophic bacterial biomass 2 methods 2 1 co model with a new formulation of microbial oxidation temporal and spatial variability of dissolved co concentrations co in the water column was formulated as a function of depth z and time t associated with photochemical production j air sea gas exchange f z 0 vertical mixing v and microbial oxidation m 1 d co dt j z t f 0 t v z t m z t the detailed formulation of the four processes on the right hand side of eq 1 are described in the following sections 2 1 1 photochemical production j photolysis rate of gas species in the atmosphere is determined by the actinic flux of the sun absorption property of a reactant and the quantum yield representing the production efficiency analogous mechanisms have been applied to the photochemical production of the co in the ocean taking into account the attenuation of the irradiance in the water column kettle 1994 zafiriou et al 1984 2 j z t λ 2 λ 1 e λ z t a g λ φ λ d λ where e λ z t indicates solar spectral irradiance at the given wavelength λ depth z and time t a g λ and φ λ indicate the absorption coefficient of cdom and the apparent quantum yield of co at the given wavelength respectively in this study 280 and 800 nm were adopted as λ 1 and λ 2 respectively as most of co production occurs at the wavelength shorter than the visible wavelengths kettle 1994 valentine and zepp 1993 e λ z t can be replaced by a fraction of the total surface irradiance et z t therefore the right hand side of eq 2 becomes 3 j z t 0 51 e t z t 800 280 a g λ φ λ d λ where 0 51 is the solar irradiance penetrating the water surface and consists of 42 of visible light and 9 of ultraviolet uv light on average gibson 2003 a g λ can also be described as an exponential decrease of ag λ 0 with slope s where ag λ 0 is a reference absorption coefficient at λ 0 bricaud et al 1995 1981 green and blough 1994 4 a g λ a g λ 0 e s λ λ 0 while several experiments conducted in the coastal area anderson and stedmon 2007 asmala et al 2012 coble 2007 ferrari 2000 ferrari et al 1996 mannino et al 2008 rochelle newall and fisher 2002 stedmon et al 2000 vodacek et al 1997 showed a linear relationship between dissolved organic carbon concentrations doc and the absorption coefficient of cdom at a specific wavelength a g λ 0 nelson et al 1998 and nelson and siegel 2013 found no relationship in the open ocean and in the sargasso sea siegel et al 2002 at bermuda from 1996 to 1999 thereby regardless of doc we assumed a g λ 0 to be constant at the value of 0 2 m 1 as determined by kettle 1994 in the same area by using a reference wavelength of 300 nm λ 0 and the reference slope s of 0 020 nm 1 kettle 2005b kitidis et al 2011 we adopted the exponential fitting curve of φ λ developed by kettle 2005b based on experimental results at bats kettle 1994 5 φ λ 2 427 e 0 0302 λ 2 1 2 air sea flux f the air sea co flux was calculated by a mass transfer equation as follows 6 f 0 t k w co 0 t l p co where k w is the gas transfer velocity of co co 0 t and pco are the concentration of co at the sea surface at the given time and partial pressure of co in the overlying air respectively and l is the solubility of co wiesenburg and guinasso 1979 we assumed that the co is homogeneously distributed in the upper layer in the model previous findings support our assumption that dissolved co concentration is virtually constant in the first 5 m during the day johnson 1999 pco was calculated as a product of the mole fraction of atmospheric co and the atmospheric pressure at bats assuming that water vapor was saturated the mean co mole fraction 169 ppb observed in march 1993 by the atmospheric monitoring station bmw bermuda west run by noaa esrl national oceanic and atmospheric administration earth system research laboratory https www esrl noaa gov gmd dv data was used for our calculation k w was parameterized following nightingale et al 2000 because it is indifferent from the recently suggested parameterizations ho et al 2011 wanninkhof 2014 implying its reliability and it has already been used to model air sea co2 and o2 exchange with ersem butenschön et al 2016 accounting for the change in diffusivities of both co and momentum at different thermodynamic conditions of the seawater from the reference condition temperature 20 c and salinity 0 k w can be calculated as follows 7 k w 0 333 u 10 0 222 u 10 2 sc 600 0 5 where u 10 is the wind speed at 10 m high and sc is the schmidt number which is the ratio between the diffusivity wise and houghton 1968 of co and the kinematic viscosity korson et al 1969 millero 1974 of seawater the seawater temperature and salinity generated by a physical mixing model were used to calculate sc 2 1 3 vertical mixing v due to sunlight attenuation through the water column co concentration should be higher at the sea surface decreasing exponentially with depth assuming uniform cdom distribution however vertical mixing may redistribute the dissolved co molecules within the mixed layer in a one dimensional 1 d context the vertical mixing of co within water column is described by 8 v z t z d z ε z co where d z and ɛ are the eddy and molecular diffusivities respectively the turbulent fluxes in the marine boundary layer can be calculated by means of various different turbulence closure models e g kettle 2005 here we have used the k ɛ turbulence closure scheme in the general ocean turbulence model gotm www gotm net as previously done by kettle 2005a and burchard and petersen 1999 2 1 4 a new formulation of microbial oxidation m we assumed that microbial oxidation rate of co m is better represented by a second order decay function of co concentration and bacterial biomass 9 m k bio b co where k bio is a new microbial oxidation rate coefficient and b is a bacterial biomass concentration in carbon unit it is worthwhile to note that the k bio multiplied by b is the same to the conventional k co h 1 thus the unit of k bio is same to k co divided by b since the spatial and the temporal variabilities of k co are implicitly represented by those of b the new coefficient k bio can be assumed to be constant in any environment it should be noted that the co oxidized by bacteria is converted in the model to dissolved inorganic carbon dic since co is used for energy and not for carbon assimilation jones and amador 1993 moran and miller 2007 tolli and taylor 2005 2 2 implementation of the coupled co gotm ersem model and set up for bats the new formulation of microbial co oxidation requires the explicitly simulated bacteria biomass for this reason we have embedded the proposed co formulation in the european regional seas ecosystem model ersem butenschön et al 2016 which is one of the few marine ecosystem models that explicitly simulates bacterial biomass baretta bekker et al 1995 blackford et al 2004 butenschön et al 2016 polimene et al 2006 ersem has been coupled with gotm and implemented at bats as previously done to simulate bulk pelagic ecosystem properties and dms p dynamics butenschön et al 2016 polimene et al 2012 bats is the only site where dissolved co concentrations time series were measured along with physical and biological parameters allowing to put co dynamic in a wider ecosystem context since the maximum mixed layer depth mld at bats was not deeper than 190 m during the year in 1993 steinberg et al 2001 we confined the model depth to 210 meter consisting of 60 equidistant vertical layers it is assumed that there is no upward flux across the model s bottom boundary while the downward flux such as particle sinking is allowed model initial conditions and parameters were taken from butenschön et al 2016 atmospheric forcing data were obtained from the european centre for medium range weather forecast reanalysis data product era interim dee et al 2011 the model without the co module was run for 30 years to get semi steady state of ecosystem variables by assimilating the vertical profiles of temperature and salinity t s observed at bats constrained by the repeated atmospheric forcing in 1991 since the interval of observed t s profiles in 1991 varied between 1 and 3 months the relaxation time scale of t s was set at 30 days the surface boundary conditions of the model were forced by 6 hourly meteorology in 1991 using the final state of the 30 year spin up as initial conditions the model was further integrated until march 15 1993 with 6 hourly corresponding era interim forcing to generate the initial conditions for the ecosystem state variable used in the 9 day simulation described in the next section 2 3 nine day simulation for the determination of optimum k bio kettle 1994 measured the co concentrations in the surface waters at bats for 9 days in march 1993 these data have been used to test the new co model and to estimate the value of k bio to compensate for missing hydrodynamic impacts of lateral advection and diffusion simulated t and s were relaxed toward observed profiles for this short simulation we used the wind speed and irradiance observed by kettle 1994 which offered a higher temporal resolution less than 1 min with respect to era interim 6 h a constant co profile equal to the mean value observed on 15th march 1993 was given as initial condition to allow the model to redistribute co within the water column following its dynamics bayesian optimization snoek et al 2012 was employed to determine the most appropriate k bio using the 9 day co observations with each iterative calculation of the objective function root mean square error rmse of co in this study bounding the pre specified ranges of k bio the algorithm updates the k bio and incorporates the new k bio into the next estimate of rmse until it converges to minimum since the k co suggested by kettle 2005b divided by simulated bacteria biomass on 15 of march 1993 is order of 1e 03 we set the lower and upper limit for the search space of k bio as 1e 04 and 1e 02 mg c m 3 1 h 1 respectively the uncertainty of k bio was estimated by monte carlo method by generating 100 sets of the dissolved co concentrations in time series that are randomly varied within 5 of the co concentrations which is the analytical uncertainty kettle 1994 mean and standard deviation of the 100 simulations were adopted as the optimal k bio and its error respectively to investigate how k bio value responds to the source and sink terms of co budget sensitivity experiments were carried out with respect to the photochemical production j air sea gas exchange f and vertical mixing v rates because they can be variable depending on the different parameterizations simulation without perturbation of j f and v was assigned as control simulation below for the sensitivity runs the j f and v were individually perturbed by 20 and 10 of those of the control simulation sensitivity of k bio for each term is defined as 10 s n l δ k bio k bio δ t l t l where tl denotes the budget term l of control run and tl the perturbed tl l is one of j f and v and tl is one of 0 8tl 0 9tl 1 1tl and 1 2tl 2 4 multiyear simulation to investigate seasonal to inter annual variability of co 3 year simulation from 1992 to 1994 was carried out the bacterial biomasses observed for the same period at bats as part of us joint global ocean flux study steinberg et al 2001 were used to validate the model simulation and to see how the variation of bacterial biomass impacts the microbial oxidation to this purpose observed bacterial cell density cells kg 1 was converted to carbon mass unit by a conversion factor of 10 fg c cell 1 steinberg et al 2001 for this simulation we used the optimum k bio determined in section 2 3 co gotm ersem was restarted from the 30 year spin up state of gotm ersem coupled model the meteorology was forced by the 6 hourly era interim data and the model t s profiles were relaxed toward the observed profiles with the relaxation time scale of a month 2 5 model evaluation metrics we used three quantitative metrics root mean squared error rmse mean bias error mbe and pearson correlation coefficient r to assess our co model skill suggested by jolliff et al 2009 rmse is defined as the square root of the variance between simulated and observed values and mbe as the difference between the means of model and of observation fields rmse and mbe measure the degree of discrepancies between the model prediction and the observation thus the closer their values are to zero the better the model accuracy is the pearson correlation coefficient r defined here by the covariance of model and of observation fields divided by the product of their standard deviations is a measure of the degree of linear association between model and observations rmse mbe and r give quantitative information particularly when evaluating the sensitivity of a model to a specific parameter to minimize the magnitude of fitness between model and observation jolliff et al 2009 3 results 3 1 nine day simulation with optimum k bio the microbial oxidation rate coefficient k bio in the new co gotm ersem model determined by the procedure described in section 2 3 was 5 7 0 2 μg c m 3 1 h 1 we present here the model performance focusing on the surface co concentrations as well as their vertical distributions sensitivity results of the k bio to the perturbations of co sources and sinks are also presented 3 1 1 surface co concentration simulated and observed kettle 1994 surface co concentrations during the 9 days from mar 15 to 24 1993 are displayed in fig 2 the observed diel variations and the gradual increasing trend of surface co concentrations are well reproduced by the model the good performance of our new model was confirmed by a set of statistical metrics rmse mbe and r as shown in table 1 our model performs slightly better than a previously published model kettle 2005b regardless of applying the optimization technique however r values from both models are identical 3 1 2 vertical profiles of co concentration in fig 3 the simulated co profiles are compared with the observations by kettle 1994 overall the model underestimates the observed co especially below the mld where the simulated co concentrations are close to zero while the observations never fall below 0 2 nm however the high correlation between simulated and observed values average r 0 8 indicates that the model captures the general trend of the observations as for example the depth where concentrations rapidly decrease nevertheless the aforementioned underestimation of the observed values at depth reduces the overall performance of the model as highlighted by the relatively large rmse values mean rmse 0 53 0 26 3 1 3 sensitivity of k bio to co source and sinks our experiments indicate that the air sea gas exchange rate f has negligible effects on the determination of k bio overall k bio is more sensitive to the photochemical production rate j than to the physical mixing rate v fig 4 k bio is inversely related to v because it acts as a sink by dilution of dissolved co as shown in fig 4b the sn j was calculated as 1 32 sn f as 0 and sn v as 0 5 3 2 multiyear simulation from 1992 to 1994 3 2 1 bacterial biomass the bacterial biomass measured at bats varied between 3 and 8 mg c m 3 with a slight decreasing trend of 0 4 mg c m 3 a 1 fig 5 the simulated bacterial biomass exhibits a clear seasonality with high values in spring and a gradual decrease toward fall and winter which is consistent with the observations steinberg et al 2001 in addition the model reproduced the gradual decreasing trend of 0 4 mg c m 3 a 1 observed between 1992 and 1994 however simulated bacterial biomass overestimates the observed values by 30 on average while the vernal bloom of bacteria was captured by the model for 1992 and 1993 the low values observed in spring of 1994 were not reproduced in the simulations if we exclude this period from the comparison r and mbe values are 0 7 and 1 3 respectively confirming the general good performance of the model 3 2 2 seasonal cycles of bacterial biomass and co the simulated seasonal cycles of bacterial biomass and surface co concentration are illustrated in fig 6 a co concentrations display low values 1 nm in spring concomitantly with high bacterial biomass co starts to increase by the onset of stratification due to radiative heating and by the reduction of bacterial biomass 2 5 nm from may to august co remains high 4 5 nm with a peak concentration in july mid summer driven by the combination of strong photochemical production weak vertical mixing and reduced bacterial biomass from september early fall to january winter co concentration declines to below 1 nm in association with the decrease of photochemical production small increase of microbial oxidation and deepened mld since the co oxidation is a function of bacterial biomass its seasonality exactly follows bacterial biomass the corresponding conventional oxidation rate coefficient k co shows its seasonal maximum in march and minimum in august the mean vertical distributions of co and k co from the 3 year simulation are displayed in fig 6b the highest k co appears at subsurface between 30 m and 50 m depth just above the mld on the other hand the simulated co concentration maximum occurs at the surface because of the high irradiance and slightly lowered bacterial biomass 4 discussion 4 1 meaning of the second order loss kinetics microbial oxidation is the dominant sink of co in seawater overwhelming air sea gas exchange under normal turbulent conditions at the sea surface gnanadesikan 1996 zafiriou et al 2003 it is therefore crucial to accurately parameterize this process if we want to simulate dissolved co concentrations in a reliable way in this work we propose a new model including variable bacterial biomass in the formulation of co oxidation our model is supported by literature findings showing that the conventional k co is not constant in the ocean indeed k co is higher in the coastal areas than in the open ocean jones and amador 1993 xie et al 2005 in the subsurface layer than in the bottom and surface layers jones 1991 kettle 1994 kwon 2015 and during phytoplankton bloom than during non productive periods johnson and bates 1996 jones and amador 1993 zhang and xie 2012 all these studies suggest that it is unlikely that microbial oxidation of co is only dependent on co concentration as assumed in previously published models gnanadesikan 1996 kettle 2005b kitidis et al 2011 conte et al 2018 we argue that like other microbial processes the microbial co oxidation is affected by microbial density and community composition supply of organic and inorganic substrates and other conditions such as temperature and ph rivkin and anderson 1997 rivkin et al 1996 our new model allows k co to vary spatially and temporally reflecting the dependency of bacterial growth on environmental conditions and in this way connecting the marine co cycle to broader ecosystem functions the seasonal variability of co in our model is consistent with the observations reported by jones 1991 who described large co variability in the sargasso sea between june of 1986 and september of 1987 jones 1991 found that both co concentration and k co in june were higher than in september by 1 7 and 2 times respectively another observed k co value at the sargasso sea in summer aug 1999 was reported as 0 02 0 002 h 1 tolli and taylor 2005 showing a similarity with our summer value 0 03 0 003 h 1 fig 6a johnson and bates 1996 explained the almost 4 times higher co concentration observed in summer with respect to winter by the synergetic effect of high irradiance and lower oxidation rate due probably to low abundance of bacteria in addition to the temporal seasonal variation modelled k co also varies with depth following bacterial distribution fig 6b this is consistent with previous studies reporting that k co decreased gradually with depth reaching its maximum at about 40 m deep jones 1991 and that bacterial biomass at bats reaches its maximum between 30 and 80 meter depth steinberg et al 2001 since primary production is likely to be affected by the global climate change cavan et al 2019 moore et al 2018 further studies should be designed to assess how global warming driven alterations of the planktonic ecosystem might affect the global co budget and the role of co as a climate change driver 4 2 critical assessment of model assumptions inclusion of bacterial biomass in the new parameterization of co oxidation assumes that a constant fraction of the heterotrophic bacterial community is involved in co oxidation this assumption is supported by previous studies reporting that roseobacter associated clade cells responsible for the fastest co metabolism are ubiquitous in marine environments accounting for 36 2 4 of the total microbial assemblage tolli et al 2006 however since tolli et al 2006 only considered samples from coastal waters further studies are necessary to assess the validity of our assumption in wide range of marine environments our model reproduced at least qualitatively the maximal bacterial biomass in the subsurface layers fig 7 c and the consequent maximum of k co fig 6b however the model significantly overestimates both bacterial biomass and k co below 40 m indeed steinberg et al 2001 reported the bacterial biomass 2 0 mg c m 3 at depths less than 150 m regardless of the season while our model simulated circa 5 mg c m 3 at the same depth except for winter fig 7c fig 7 illustrates that bacterial biomass is coupled to dissolved organic carbon doc reaching their maxima at 80 m near the subsurface chl a maximum steinberg et al 2001 this is consistent with previous findings and theoretical modeling studies showing a correlation between phytoplankton or chl a and bacterial production underlining the dependence of bacterial growth on a pool of doc freshly produced by the primary producers dumont et al 2011 wiebinga and de baar 1998 polimene et al 2006 the overestimation of bacteria in the subsurface layer can be mainly explained by overestimation of doc which is the main source of carbon and energy for heterotrophic bacteria since total organic carbon toc observations in 1994 are available and it is dominated by doc in bats hansell and carlson 1998 we compared toc rather than doc fig 8 the simulated toc between 100 210 m depth was overestimated about 40 despite the overestimated bacterial biomass and doc our model reproduced a realistic relationship among primary production doc and bacteria indeed the simulated doc tends to concentrate at the subsurface layers since phytoplankton populates the subsurface layer to avoid nutrient limited surface waters the most salient feature of our model is to connect co dynamics and primary production this connection is established through bacterial abundance and distribution and doc production and fate another element to be considered is that we did not resolve the cdom dynamics explicitly assuming that the cdom absorbance is constant however siegel et al 2002 observed non homogeneous vertical distribution of cdom absorbance at bats with larger values observed at the depths between 50 and 100 m suggesting that the photochemical production of co may differ depending on the depth given that the k bio is highly sensitive to the change of photoproduction rate fig 4 additional studies are required to shed light on cdom absorbance variability and refine our model accordingly 5 conclusions a co model was developed with a new parameterization of microbial oxidation the dominant sink of co in the ocean we suggested a new parameterization implying a second order loss kinetics depending on bacterial biomass other than co concentration the new parameterization introduces a universal constant k bio which describes the bacterial biomass specific co oxidation rate by optimizing co simulations against the 9 day observations of surface co concentrations at bats kettle 1994 k bio was estimated to be 5 7 0 2 μg c m 3 1 h 1 using this k bio value our simulations carried out with co gotm ersem reproduced the observed temporal seasonal and inter annual and spatial vertical variability of co oxidation rate and co concentrations further studies assessing the dependency of co on bacterial biomass and doc would be required to evaluate if the k bio derived in this study is applicable in other oceanic contexts credit author statement young shin kwon conceptualization writing original draft preparation software data curation visualization formal analysis funding acquisition hyoun woo kang supervision methodology writing original draft preparation funding acquisition luca polimene writing reviewing and editing funding acquisition tae siek rhee writing reviewing and editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments samples and data the original data set from bats station can be accessed at the bios database http bats bios edu data this work was supported by the national research foundation of korea nrf grant funded by the korea government msit no nrf 2018h1a2a1060886 and by korea polar programs pm20050 and pe20150 hyoun woo kang was supported by the kiost in house project pe99811 luca polimene was funded through the uk nerc grants ne n001974 1 and ne r011087 1 
24777,traditionally marine carbon monoxide co models assume that the microbial oxidation of co is only dependent on the concentration of co in the water column however co oxidation rates in the ocean have been reported to vary up to two orders of magnitude both spatially and temporally here we developed a new model assuming that co microbial oxidation is dependent on bacterial carbon biomass other than co concentration in addition to microbial oxidation the model also describes co photochemical production vertical mixing and air sea gas exchange the new co model has been embedded in the european regional seas ecosystem model ersem and coupled with the general ocean turbulence model gotm the co gotm ersem model was implemented at the bermuda atlantic time series bats station to simulate co concentrations observed in march 1993 by kettle 1994 the proposed second order function describing co microbial oxidation introduces a new parameter the bacteria biomass specific oxidation rate which was estimated to be 5 7 0 2 μg c m 3 1 h 1 statistical metrics indicates that the new co model performs better than a previously published model with a first order decay function to describe microbial oxidation acknowledging the dependence of microbial oxidation on bacterial abundance is realistic a long term 1992 1994 simulation carried out with co gotm ersem reproduced the spatial and seasonal variability of co reported in the literature our model provides a realistic description of the co dynamics and is potentially usable in different environmental contexts worldwide keywords marine carbon monoxide microbial oxidation marine ecosystem modelling second order kinetics 1 introduction carbon monoxide co plays two key roles in the atmosphere 1 it impacts on climate forcing by competing with the methane in the reaction with the hydroxyl radical daniel and solomon 1998 the main atmospheric oxidant and 2 it is involved in the production of ozone logan et al 1981 which in turn leads to the photochemical smog reducing atmospheric visibility therefore considering its impact on the chemical properties of the atmosphere co is regarded as one of the most important trace gasses stocker et al 2013 although most of the atmospheric co is emitted from the continent outgassing from the sea surface could be a significant source in the remote marine environments and in the southern hemisphere where the co in the surface ocean is supersaturated with respect to the overlying air bates et al 1995 conrad et al 1982 khalil and rasmussen 1990 logan et al 1981 rhee 2000 stubbins et al 2006 zafiriou et al 2003 understanding co dynamics in the marine upper layer is thereby crucial to assess the role played by this gas in the global climate regulation the concentration of dissolved co in the surface ocean results from the balance between photochemical production conrad et al 1982 redden 1982 zuo and jones 1995 microbial oxidation conrad et al 1982 jones and amador 1993 jones and morita 1984 air sea gas exchange bates et al 1995 conrad et al 1982 park and rhee 2016 zuo and jones 1995 and vertical mixing doney et al 1995 gnanadesikan 1996 johnson and bates 1996 kettle 1994 fig 1 among these processes photochemical production and microbial oxidation are the major processes contributing to the co budget in the ocean zafiriou et al 2003 indeed photolysis of chromophoric dissolved organic matter cdom in the euphotic zone is the only known source of co while microbial oxidation is by far the dominant sink destroying more than 80 of the co pool therefore an accurate parameterization of microbial oxidation is essential to estimate co flux from the upper ocean moran and miller 2007 microbial co oxidation is described conventionally as a first order kinetics conrad et al 1982 johnson and bates 1996 jones 1991 jones and amador 1993 xie et al 2005 zafiriou et al 2003 assuming that co oxidation rate increases linearly with the increase of dissolved co concentrations regardless of microbial abundance and community composition several modeling studies of marine co dynamics were carried out to understand the co budget in the ocean kettle 1994 developed a model to understand the surface diurnal pattern of dissolved co concentrations at the bermuda atlantic time series study bats station in the sargasso sea the model adopted the price weller pinkel pwp vertical mixing scheme price et al 1986 to simulate the physical mixing and transport in the surface mixed layer and subsurface layers co production was simulated by using a modified version of the photochemical production module previously developed for dissolved hydrogen peroxide h2o2 in the marine environments by sikorski and zika 1993 in subsequent studies kettle 2000 2005b an optimization technique was used to reduce the discrepancy between observed and simulated dissolved co concentrations based on the co observation by kettle 1994 gnanadesikan 1996 developed a simple model coupling co dynamics with a bulk mixed layer model to identify nine marine regimes corresponding to different interactions between physical mixing and photochemical productions the regimes were defined depending on the ratios between physical length scales i e the depths to which vertical mixing ventilation and photochemically active radiation penetration occur the critical difference between the models of gnanadesikan 1996 and kettle 1994 is the way they describe co photochemical production while kettle 1994 considered the variation of co photoproduction rate depending on the spectral irradiance gnanadesikan 1996 assumed that the photoproduction is proportional to a fraction of the total irradiance simple box models were also used to determine the ratio between photochemical production and microbial oxidation johnson and bates 1996 kitidis et al 2011 johnson and bates 1996 determined the photoproduction and oxidation rates using the exponential fits of their observed diurnal variations of co kitidis et al 2011 took the production and oxidation rates from their experimental measurements and considered the vertical gradient of co concentration due mainly to the light attenuation with depth all the above mentioned modeling studies used a first order kinetics to describe co microbial oxidation implicitly assuming that the co microbial oxidation rate is constant in the ocean however this assumption is not consistent with experimental studies reporting that the co oxidation rates k co varies dramatically 0 003 1 11 h 1 both temporally and spatially johnson and bates 1996 jones 1991 jones and amador 1993 kwon 2015 xie et al 2005 moreover xie et al 2005 2009 reported complex influences of various biotic and abiotic variables on this process showing that k co is dependent on temperature primary production and salinity these studies suggest that previously used formulations can only be reliable in specific conditions i e specific location and time of the year but cannot be used in modeling work dealing with large spatial e g global models and temporal scales from seasonal upward the aim of this paper is to provide a novel model formulation able to simulate the variability of co oxidation rate described in literature to this end we tested the hypothesis that microbial co oxidation is a function of not only dissolved co concentration but also bacterial biomass our co model was implemented in a widely used marine ecosystem model the european regional seas ecosystem model ersem butenschön et al 2016 since ersem only accounts for heterotrophic bacteria we assumed that the activity of co oxidizing bacteria is proportional to the biomass of the heterotrophic bacteria community this assumption is supported by the several studies gonzalez and moran 1997 gonzalez et al 2000 moran et al 2004 suzuki et al 2001 tolli et al 2006 which show that co oxidizing bacteria roseobacter associated clade are ubiquitous in the ocean and that account for a relatively constant fraction of the heterotrophic bacterial biomass 2 methods 2 1 co model with a new formulation of microbial oxidation temporal and spatial variability of dissolved co concentrations co in the water column was formulated as a function of depth z and time t associated with photochemical production j air sea gas exchange f z 0 vertical mixing v and microbial oxidation m 1 d co dt j z t f 0 t v z t m z t the detailed formulation of the four processes on the right hand side of eq 1 are described in the following sections 2 1 1 photochemical production j photolysis rate of gas species in the atmosphere is determined by the actinic flux of the sun absorption property of a reactant and the quantum yield representing the production efficiency analogous mechanisms have been applied to the photochemical production of the co in the ocean taking into account the attenuation of the irradiance in the water column kettle 1994 zafiriou et al 1984 2 j z t λ 2 λ 1 e λ z t a g λ φ λ d λ where e λ z t indicates solar spectral irradiance at the given wavelength λ depth z and time t a g λ and φ λ indicate the absorption coefficient of cdom and the apparent quantum yield of co at the given wavelength respectively in this study 280 and 800 nm were adopted as λ 1 and λ 2 respectively as most of co production occurs at the wavelength shorter than the visible wavelengths kettle 1994 valentine and zepp 1993 e λ z t can be replaced by a fraction of the total surface irradiance et z t therefore the right hand side of eq 2 becomes 3 j z t 0 51 e t z t 800 280 a g λ φ λ d λ where 0 51 is the solar irradiance penetrating the water surface and consists of 42 of visible light and 9 of ultraviolet uv light on average gibson 2003 a g λ can also be described as an exponential decrease of ag λ 0 with slope s where ag λ 0 is a reference absorption coefficient at λ 0 bricaud et al 1995 1981 green and blough 1994 4 a g λ a g λ 0 e s λ λ 0 while several experiments conducted in the coastal area anderson and stedmon 2007 asmala et al 2012 coble 2007 ferrari 2000 ferrari et al 1996 mannino et al 2008 rochelle newall and fisher 2002 stedmon et al 2000 vodacek et al 1997 showed a linear relationship between dissolved organic carbon concentrations doc and the absorption coefficient of cdom at a specific wavelength a g λ 0 nelson et al 1998 and nelson and siegel 2013 found no relationship in the open ocean and in the sargasso sea siegel et al 2002 at bermuda from 1996 to 1999 thereby regardless of doc we assumed a g λ 0 to be constant at the value of 0 2 m 1 as determined by kettle 1994 in the same area by using a reference wavelength of 300 nm λ 0 and the reference slope s of 0 020 nm 1 kettle 2005b kitidis et al 2011 we adopted the exponential fitting curve of φ λ developed by kettle 2005b based on experimental results at bats kettle 1994 5 φ λ 2 427 e 0 0302 λ 2 1 2 air sea flux f the air sea co flux was calculated by a mass transfer equation as follows 6 f 0 t k w co 0 t l p co where k w is the gas transfer velocity of co co 0 t and pco are the concentration of co at the sea surface at the given time and partial pressure of co in the overlying air respectively and l is the solubility of co wiesenburg and guinasso 1979 we assumed that the co is homogeneously distributed in the upper layer in the model previous findings support our assumption that dissolved co concentration is virtually constant in the first 5 m during the day johnson 1999 pco was calculated as a product of the mole fraction of atmospheric co and the atmospheric pressure at bats assuming that water vapor was saturated the mean co mole fraction 169 ppb observed in march 1993 by the atmospheric monitoring station bmw bermuda west run by noaa esrl national oceanic and atmospheric administration earth system research laboratory https www esrl noaa gov gmd dv data was used for our calculation k w was parameterized following nightingale et al 2000 because it is indifferent from the recently suggested parameterizations ho et al 2011 wanninkhof 2014 implying its reliability and it has already been used to model air sea co2 and o2 exchange with ersem butenschön et al 2016 accounting for the change in diffusivities of both co and momentum at different thermodynamic conditions of the seawater from the reference condition temperature 20 c and salinity 0 k w can be calculated as follows 7 k w 0 333 u 10 0 222 u 10 2 sc 600 0 5 where u 10 is the wind speed at 10 m high and sc is the schmidt number which is the ratio between the diffusivity wise and houghton 1968 of co and the kinematic viscosity korson et al 1969 millero 1974 of seawater the seawater temperature and salinity generated by a physical mixing model were used to calculate sc 2 1 3 vertical mixing v due to sunlight attenuation through the water column co concentration should be higher at the sea surface decreasing exponentially with depth assuming uniform cdom distribution however vertical mixing may redistribute the dissolved co molecules within the mixed layer in a one dimensional 1 d context the vertical mixing of co within water column is described by 8 v z t z d z ε z co where d z and ɛ are the eddy and molecular diffusivities respectively the turbulent fluxes in the marine boundary layer can be calculated by means of various different turbulence closure models e g kettle 2005 here we have used the k ɛ turbulence closure scheme in the general ocean turbulence model gotm www gotm net as previously done by kettle 2005a and burchard and petersen 1999 2 1 4 a new formulation of microbial oxidation m we assumed that microbial oxidation rate of co m is better represented by a second order decay function of co concentration and bacterial biomass 9 m k bio b co where k bio is a new microbial oxidation rate coefficient and b is a bacterial biomass concentration in carbon unit it is worthwhile to note that the k bio multiplied by b is the same to the conventional k co h 1 thus the unit of k bio is same to k co divided by b since the spatial and the temporal variabilities of k co are implicitly represented by those of b the new coefficient k bio can be assumed to be constant in any environment it should be noted that the co oxidized by bacteria is converted in the model to dissolved inorganic carbon dic since co is used for energy and not for carbon assimilation jones and amador 1993 moran and miller 2007 tolli and taylor 2005 2 2 implementation of the coupled co gotm ersem model and set up for bats the new formulation of microbial co oxidation requires the explicitly simulated bacteria biomass for this reason we have embedded the proposed co formulation in the european regional seas ecosystem model ersem butenschön et al 2016 which is one of the few marine ecosystem models that explicitly simulates bacterial biomass baretta bekker et al 1995 blackford et al 2004 butenschön et al 2016 polimene et al 2006 ersem has been coupled with gotm and implemented at bats as previously done to simulate bulk pelagic ecosystem properties and dms p dynamics butenschön et al 2016 polimene et al 2012 bats is the only site where dissolved co concentrations time series were measured along with physical and biological parameters allowing to put co dynamic in a wider ecosystem context since the maximum mixed layer depth mld at bats was not deeper than 190 m during the year in 1993 steinberg et al 2001 we confined the model depth to 210 meter consisting of 60 equidistant vertical layers it is assumed that there is no upward flux across the model s bottom boundary while the downward flux such as particle sinking is allowed model initial conditions and parameters were taken from butenschön et al 2016 atmospheric forcing data were obtained from the european centre for medium range weather forecast reanalysis data product era interim dee et al 2011 the model without the co module was run for 30 years to get semi steady state of ecosystem variables by assimilating the vertical profiles of temperature and salinity t s observed at bats constrained by the repeated atmospheric forcing in 1991 since the interval of observed t s profiles in 1991 varied between 1 and 3 months the relaxation time scale of t s was set at 30 days the surface boundary conditions of the model were forced by 6 hourly meteorology in 1991 using the final state of the 30 year spin up as initial conditions the model was further integrated until march 15 1993 with 6 hourly corresponding era interim forcing to generate the initial conditions for the ecosystem state variable used in the 9 day simulation described in the next section 2 3 nine day simulation for the determination of optimum k bio kettle 1994 measured the co concentrations in the surface waters at bats for 9 days in march 1993 these data have been used to test the new co model and to estimate the value of k bio to compensate for missing hydrodynamic impacts of lateral advection and diffusion simulated t and s were relaxed toward observed profiles for this short simulation we used the wind speed and irradiance observed by kettle 1994 which offered a higher temporal resolution less than 1 min with respect to era interim 6 h a constant co profile equal to the mean value observed on 15th march 1993 was given as initial condition to allow the model to redistribute co within the water column following its dynamics bayesian optimization snoek et al 2012 was employed to determine the most appropriate k bio using the 9 day co observations with each iterative calculation of the objective function root mean square error rmse of co in this study bounding the pre specified ranges of k bio the algorithm updates the k bio and incorporates the new k bio into the next estimate of rmse until it converges to minimum since the k co suggested by kettle 2005b divided by simulated bacteria biomass on 15 of march 1993 is order of 1e 03 we set the lower and upper limit for the search space of k bio as 1e 04 and 1e 02 mg c m 3 1 h 1 respectively the uncertainty of k bio was estimated by monte carlo method by generating 100 sets of the dissolved co concentrations in time series that are randomly varied within 5 of the co concentrations which is the analytical uncertainty kettle 1994 mean and standard deviation of the 100 simulations were adopted as the optimal k bio and its error respectively to investigate how k bio value responds to the source and sink terms of co budget sensitivity experiments were carried out with respect to the photochemical production j air sea gas exchange f and vertical mixing v rates because they can be variable depending on the different parameterizations simulation without perturbation of j f and v was assigned as control simulation below for the sensitivity runs the j f and v were individually perturbed by 20 and 10 of those of the control simulation sensitivity of k bio for each term is defined as 10 s n l δ k bio k bio δ t l t l where tl denotes the budget term l of control run and tl the perturbed tl l is one of j f and v and tl is one of 0 8tl 0 9tl 1 1tl and 1 2tl 2 4 multiyear simulation to investigate seasonal to inter annual variability of co 3 year simulation from 1992 to 1994 was carried out the bacterial biomasses observed for the same period at bats as part of us joint global ocean flux study steinberg et al 2001 were used to validate the model simulation and to see how the variation of bacterial biomass impacts the microbial oxidation to this purpose observed bacterial cell density cells kg 1 was converted to carbon mass unit by a conversion factor of 10 fg c cell 1 steinberg et al 2001 for this simulation we used the optimum k bio determined in section 2 3 co gotm ersem was restarted from the 30 year spin up state of gotm ersem coupled model the meteorology was forced by the 6 hourly era interim data and the model t s profiles were relaxed toward the observed profiles with the relaxation time scale of a month 2 5 model evaluation metrics we used three quantitative metrics root mean squared error rmse mean bias error mbe and pearson correlation coefficient r to assess our co model skill suggested by jolliff et al 2009 rmse is defined as the square root of the variance between simulated and observed values and mbe as the difference between the means of model and of observation fields rmse and mbe measure the degree of discrepancies between the model prediction and the observation thus the closer their values are to zero the better the model accuracy is the pearson correlation coefficient r defined here by the covariance of model and of observation fields divided by the product of their standard deviations is a measure of the degree of linear association between model and observations rmse mbe and r give quantitative information particularly when evaluating the sensitivity of a model to a specific parameter to minimize the magnitude of fitness between model and observation jolliff et al 2009 3 results 3 1 nine day simulation with optimum k bio the microbial oxidation rate coefficient k bio in the new co gotm ersem model determined by the procedure described in section 2 3 was 5 7 0 2 μg c m 3 1 h 1 we present here the model performance focusing on the surface co concentrations as well as their vertical distributions sensitivity results of the k bio to the perturbations of co sources and sinks are also presented 3 1 1 surface co concentration simulated and observed kettle 1994 surface co concentrations during the 9 days from mar 15 to 24 1993 are displayed in fig 2 the observed diel variations and the gradual increasing trend of surface co concentrations are well reproduced by the model the good performance of our new model was confirmed by a set of statistical metrics rmse mbe and r as shown in table 1 our model performs slightly better than a previously published model kettle 2005b regardless of applying the optimization technique however r values from both models are identical 3 1 2 vertical profiles of co concentration in fig 3 the simulated co profiles are compared with the observations by kettle 1994 overall the model underestimates the observed co especially below the mld where the simulated co concentrations are close to zero while the observations never fall below 0 2 nm however the high correlation between simulated and observed values average r 0 8 indicates that the model captures the general trend of the observations as for example the depth where concentrations rapidly decrease nevertheless the aforementioned underestimation of the observed values at depth reduces the overall performance of the model as highlighted by the relatively large rmse values mean rmse 0 53 0 26 3 1 3 sensitivity of k bio to co source and sinks our experiments indicate that the air sea gas exchange rate f has negligible effects on the determination of k bio overall k bio is more sensitive to the photochemical production rate j than to the physical mixing rate v fig 4 k bio is inversely related to v because it acts as a sink by dilution of dissolved co as shown in fig 4b the sn j was calculated as 1 32 sn f as 0 and sn v as 0 5 3 2 multiyear simulation from 1992 to 1994 3 2 1 bacterial biomass the bacterial biomass measured at bats varied between 3 and 8 mg c m 3 with a slight decreasing trend of 0 4 mg c m 3 a 1 fig 5 the simulated bacterial biomass exhibits a clear seasonality with high values in spring and a gradual decrease toward fall and winter which is consistent with the observations steinberg et al 2001 in addition the model reproduced the gradual decreasing trend of 0 4 mg c m 3 a 1 observed between 1992 and 1994 however simulated bacterial biomass overestimates the observed values by 30 on average while the vernal bloom of bacteria was captured by the model for 1992 and 1993 the low values observed in spring of 1994 were not reproduced in the simulations if we exclude this period from the comparison r and mbe values are 0 7 and 1 3 respectively confirming the general good performance of the model 3 2 2 seasonal cycles of bacterial biomass and co the simulated seasonal cycles of bacterial biomass and surface co concentration are illustrated in fig 6 a co concentrations display low values 1 nm in spring concomitantly with high bacterial biomass co starts to increase by the onset of stratification due to radiative heating and by the reduction of bacterial biomass 2 5 nm from may to august co remains high 4 5 nm with a peak concentration in july mid summer driven by the combination of strong photochemical production weak vertical mixing and reduced bacterial biomass from september early fall to january winter co concentration declines to below 1 nm in association with the decrease of photochemical production small increase of microbial oxidation and deepened mld since the co oxidation is a function of bacterial biomass its seasonality exactly follows bacterial biomass the corresponding conventional oxidation rate coefficient k co shows its seasonal maximum in march and minimum in august the mean vertical distributions of co and k co from the 3 year simulation are displayed in fig 6b the highest k co appears at subsurface between 30 m and 50 m depth just above the mld on the other hand the simulated co concentration maximum occurs at the surface because of the high irradiance and slightly lowered bacterial biomass 4 discussion 4 1 meaning of the second order loss kinetics microbial oxidation is the dominant sink of co in seawater overwhelming air sea gas exchange under normal turbulent conditions at the sea surface gnanadesikan 1996 zafiriou et al 2003 it is therefore crucial to accurately parameterize this process if we want to simulate dissolved co concentrations in a reliable way in this work we propose a new model including variable bacterial biomass in the formulation of co oxidation our model is supported by literature findings showing that the conventional k co is not constant in the ocean indeed k co is higher in the coastal areas than in the open ocean jones and amador 1993 xie et al 2005 in the subsurface layer than in the bottom and surface layers jones 1991 kettle 1994 kwon 2015 and during phytoplankton bloom than during non productive periods johnson and bates 1996 jones and amador 1993 zhang and xie 2012 all these studies suggest that it is unlikely that microbial oxidation of co is only dependent on co concentration as assumed in previously published models gnanadesikan 1996 kettle 2005b kitidis et al 2011 conte et al 2018 we argue that like other microbial processes the microbial co oxidation is affected by microbial density and community composition supply of organic and inorganic substrates and other conditions such as temperature and ph rivkin and anderson 1997 rivkin et al 1996 our new model allows k co to vary spatially and temporally reflecting the dependency of bacterial growth on environmental conditions and in this way connecting the marine co cycle to broader ecosystem functions the seasonal variability of co in our model is consistent with the observations reported by jones 1991 who described large co variability in the sargasso sea between june of 1986 and september of 1987 jones 1991 found that both co concentration and k co in june were higher than in september by 1 7 and 2 times respectively another observed k co value at the sargasso sea in summer aug 1999 was reported as 0 02 0 002 h 1 tolli and taylor 2005 showing a similarity with our summer value 0 03 0 003 h 1 fig 6a johnson and bates 1996 explained the almost 4 times higher co concentration observed in summer with respect to winter by the synergetic effect of high irradiance and lower oxidation rate due probably to low abundance of bacteria in addition to the temporal seasonal variation modelled k co also varies with depth following bacterial distribution fig 6b this is consistent with previous studies reporting that k co decreased gradually with depth reaching its maximum at about 40 m deep jones 1991 and that bacterial biomass at bats reaches its maximum between 30 and 80 meter depth steinberg et al 2001 since primary production is likely to be affected by the global climate change cavan et al 2019 moore et al 2018 further studies should be designed to assess how global warming driven alterations of the planktonic ecosystem might affect the global co budget and the role of co as a climate change driver 4 2 critical assessment of model assumptions inclusion of bacterial biomass in the new parameterization of co oxidation assumes that a constant fraction of the heterotrophic bacterial community is involved in co oxidation this assumption is supported by previous studies reporting that roseobacter associated clade cells responsible for the fastest co metabolism are ubiquitous in marine environments accounting for 36 2 4 of the total microbial assemblage tolli et al 2006 however since tolli et al 2006 only considered samples from coastal waters further studies are necessary to assess the validity of our assumption in wide range of marine environments our model reproduced at least qualitatively the maximal bacterial biomass in the subsurface layers fig 7 c and the consequent maximum of k co fig 6b however the model significantly overestimates both bacterial biomass and k co below 40 m indeed steinberg et al 2001 reported the bacterial biomass 2 0 mg c m 3 at depths less than 150 m regardless of the season while our model simulated circa 5 mg c m 3 at the same depth except for winter fig 7c fig 7 illustrates that bacterial biomass is coupled to dissolved organic carbon doc reaching their maxima at 80 m near the subsurface chl a maximum steinberg et al 2001 this is consistent with previous findings and theoretical modeling studies showing a correlation between phytoplankton or chl a and bacterial production underlining the dependence of bacterial growth on a pool of doc freshly produced by the primary producers dumont et al 2011 wiebinga and de baar 1998 polimene et al 2006 the overestimation of bacteria in the subsurface layer can be mainly explained by overestimation of doc which is the main source of carbon and energy for heterotrophic bacteria since total organic carbon toc observations in 1994 are available and it is dominated by doc in bats hansell and carlson 1998 we compared toc rather than doc fig 8 the simulated toc between 100 210 m depth was overestimated about 40 despite the overestimated bacterial biomass and doc our model reproduced a realistic relationship among primary production doc and bacteria indeed the simulated doc tends to concentrate at the subsurface layers since phytoplankton populates the subsurface layer to avoid nutrient limited surface waters the most salient feature of our model is to connect co dynamics and primary production this connection is established through bacterial abundance and distribution and doc production and fate another element to be considered is that we did not resolve the cdom dynamics explicitly assuming that the cdom absorbance is constant however siegel et al 2002 observed non homogeneous vertical distribution of cdom absorbance at bats with larger values observed at the depths between 50 and 100 m suggesting that the photochemical production of co may differ depending on the depth given that the k bio is highly sensitive to the change of photoproduction rate fig 4 additional studies are required to shed light on cdom absorbance variability and refine our model accordingly 5 conclusions a co model was developed with a new parameterization of microbial oxidation the dominant sink of co in the ocean we suggested a new parameterization implying a second order loss kinetics depending on bacterial biomass other than co concentration the new parameterization introduces a universal constant k bio which describes the bacterial biomass specific co oxidation rate by optimizing co simulations against the 9 day observations of surface co concentrations at bats kettle 1994 k bio was estimated to be 5 7 0 2 μg c m 3 1 h 1 using this k bio value our simulations carried out with co gotm ersem reproduced the observed temporal seasonal and inter annual and spatial vertical variability of co oxidation rate and co concentrations further studies assessing the dependency of co on bacterial biomass and doc would be required to evaluate if the k bio derived in this study is applicable in other oceanic contexts credit author statement young shin kwon conceptualization writing original draft preparation software data curation visualization formal analysis funding acquisition hyoun woo kang supervision methodology writing original draft preparation funding acquisition luca polimene writing reviewing and editing funding acquisition tae siek rhee writing reviewing and editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments samples and data the original data set from bats station can be accessed at the bios database http bats bios edu data this work was supported by the national research foundation of korea nrf grant funded by the korea government msit no nrf 2018h1a2a1060886 and by korea polar programs pm20050 and pe20150 hyoun woo kang was supported by the kiost in house project pe99811 luca polimene was funded through the uk nerc grants ne n001974 1 and ne r011087 1 
24778,wood production from native tree species in brazil is primarily limited to exploitation of natural forests the identification of potential habitats for tree planting may provide new opportunities for natural forest conservation and management and increase the viability of native species plantations for highly valuable wood production this study aimed to identify potential habitats for native tree planting using a crop zoning model that combines environmental variables and wood demand modeling the target region for the study was minas gerais mg state southeast region brazil the maxent model was used to match environmental variables and the occurrence of 19 economically important tree species wood demand modeling was performed through the grouping analysis algorithm using brazilian consumption records by species the models generated with maxent were highly accurate area under the curve auc 0 77 apuleia leiocarpa vogel j f macbr hymenaea courbaril l micropholis venulosa mart e ex miq p p pouteria caimito ruiz pav radlk pouteria guianensis aubl simarouba amara aubl and tachigali paniculata aubl presented potential cultivation areas occupying 460 881 572 467 208 820 202 989 118 937 158 254 and 288 769 km2 respectively three classes of wood demand were identified r2 0 82 the belo horizonte juiz de fora montes claros and ubá micro regions showed high demand for most species studied the interaction between wood demand and areas with potential for planting each species allowed the specification of priority regions for reforestation regions with high demand and high cultivation potential occupied in km² 19 993 23 for a leiocarpa 4 193 8 for h courbaril 1 939 6 for m venulosa 16 356 3 for p caimito 1 623 6 for p guianensis 0 8 for s amara and 53 566 2 for t paniculata establishing these native tree species near wood based industries in regions that match the environmental variables of their occurrence area leads to natural forest conservation and economic growth of consumption centers graphical abstract image graphical abstract keywords maxent tropical wood demand environmental zoning native tree species 1 introduction the wood supply from native forests in brazil mainly from the amazon has decreased in recent years in response to prevailing environmental legislation and control by regulatory agencies nepstad et al 2009 rodrigues et al 2009 putz and romero 2014 brazilian institute of geography and statistics ibge 2017 the imbalance between native wood supply and demand can generate negative socioeconomic impacts both internationally and nationally especially in large brazilian consumption centers such as são paulo minas gerais paraná and santa catarina states this justifies the creation of specific policies to encourage legal production in order to mitigate the impacts of natural forest exploitation burkhard et al 2012 fao 2012 ibama 2014 oliver 2015 souza et al 2018 forest plantations are one option to meet the high demand for native wood in brazil asen et al 2012 to reduce pressure on natural forests buongiorno and zhu 2014 putz and romero 2015 and to generate income carle and holmgren 2008 putz and romero 2014 the likelihood of increased investment in all forestry enterprise types is higher if the commercial production of wood from native species is profitable profits may be substantial if one takes into account the environmental suitability for planting native trees wang et al 2014 falasca et al 2017 along with the economic and social implications of the investment brancalion et al 2012 shearman et al 2012 putz and romero 2014 however the use of native species of high commercial value in planted forests is still developing in brazil there are also few studies on the environmental requirements of these species and the economic and social aspects related to such plantations rolim and piotto 2019 for example to date there have been no silvicultural or economic studies related to manilkara elata allemão ex miq monach maçaranduba the second most utilized native tree species in brazil ibama 2014 the information available for this species is only related to its diversity and genetic structure azevedo et al 2007 pre and post exploration dynamics uhl and vieira 1989 wadsworth and zweede 2006 chagas et al 2012 castro and de carvalho 2014 avila et al 2017 and leaf and wood anatomy almeida jr et al 2013 nascimento et al 2017 such scarcity of information is common for the most economically important native species in brazil species distribution models sdms which allow the correlation between species and their biophysical environment help to identify potential areas for species cultivation elith and leathwick 2009 syfert et al 2013 qin et al 2017 there are many sdms available such as maxent bioclim garp glm gam and random forest which differ according to parameters and data entry criteria nix 1986 mccullagh and nelder 1989 hastie and tibshirani 1990 busby 1991 stockwell and noble 1992 hutchinson 1995 breiman 2001 phillips et al 2006 giannini et al 2012 the maxent model has been proven to be efficient and useful for species distribution modeling and unlike many sdms it requires only species presence data or occurrence combined with environmental layers phillips and dudík 2008 elith et al 2011 ma and sun 2018 the use of the maxent model in forestry is well documented for example it has been used to model the habitats of medicinal plants in india and china yang et al 2013 remya et al 2015 zhang et al 2016 bioenergetic and threatened plants in china wang et al 2014 qin et al 2017 and eucalyptus grandis garcia et al 2014 bambusa vulgaris and dendrocalamus giganteus santos et al 2019 in brazil the identification of potential habitats for native trees while considering the wood market may provide new options for forest conservation management and for increasing the viability of commercial plantations masera et al 2006 naidoo and ricketts 2006 egoh et al 2008 whether to invest in wood production is a decision often determined by profit estimates and should be aided by quantitative and qualitative indicators of demand for wood bacha 2003 kies et al 2009 in this sense choosing which wood to produce and where to produce it becomes safer when environmental data and market information are linked allowing the establishment of development areas that are based on the homogeneity of natural and social attributes naidoo and ricketts 2006 carvalho and scolforo 2008 such results can support the implementation of agri environmental policies as well as landscape sustainability assessments swetnam et al 2011 burkhard et al 2012 the objective of this study was to use the maxent model and spatial statistics techniques to identify potential regions of minas gerais mg state southeast region brazil suitable for planting economically important native tree species to meet this objective the environmental conditions of each species origin and cultivation regions were compared and the areas of greatest wood demand for each species were identified next priority areas with high potential for reforestation and high demand for wood were defined for the selected species 2 material and methods 2 1 study area the target region for the study was mg state southeast region brazil 13 94 22 50 s 41 73 52 87 w which occupies approximately 586 528 km2 and comprises 853 municipalities grouped into 66 micro regions fig 1 its economy is the third largest in brazil with primary sectors including agriculture livestock basso et al 2012 sá júnior et al 2012 and planted forestry primarily eucalyptus spp ibá 2017 this state is the second highest consumer of native wood in brazil ibama 2014 2 2 wood consumption database native wood consumption data specifically for solid wood products such as round wood and sawn wood were compiled from the forest origin document fod system which reports on trade and transportation of native forest resources in brazil ibama 2018 the states and municipalities of origin and destination of the wood not georeferenced species volume and types of products are contained in the fod system for volume only timber imported from other states was included since the volume of native timber produced by mg state is insignificant and not counted in the fod system this may be due to the history of forest exploitation and fragmentation in the state that makes legal management of native forests unfeasible today ief 2020 all information was georeferenced into a gis environment using arcgis 10 6 1 software creating a geospatial database with 387 891 information points fig 2 the species selection for this study was primarily based on consumption m3 by species and municipality of the 40 most consumed in the study area 19 brazilian tree species were selected these species accounted for approximately 2 5 million m3 of commercialized solid wood in the state between 2006 and 2016 55 of the total wood consumption in mg state table 1 2 3 potential habitats for cultivation native tree species in brazil 2 3 1 species occurrence data the georeferenced occurrence points of the 19 brazilian species were obtained from the global biodiversity information facility gbif database in https www gbif org the minas gerais state forest inventory carvalho and scolforo 2008 and specieslink http www splink org br data quality control was performed to ensure accurate information and georeferencing yesson et al 2007 giannini et al 2012 after refinement 3872 points of occurrence were used ranging from 28 points for hymenolobium petraeum to 727 points for hymenaea courbaril table 1 2 3 2 environmental variables to calculate the cultivation potential of the target species 21 edaphoclimatic variables were extracted for each occurrence point climatic variables were obtained from the worldclim global climate data version 2 0 database fick and hijmans 2017 the climatic variables were annual mean temperature c bio 1 mean diurnal range c bio 2 isothermality bio 3 temperature seasonality standard deviation 100 bio 4 maximum temperature of warmest month c bio 5 minimum temperature of coldest month c bio 6 temperature annual range bio 5 bio 6 bio 7 mean temperature of wettest quarter c bio 8 mean temperature of driest quarter c bio 9 mean temperature of warmest quarter c bio 10 mean temperature of coldest quarter c bio 11 annual precipitation mm bio 12 precipitation of wettest month mm bio 13 precipitation of driest month mm bio 14 precipitation seasonality mm bio 15 precipitation of wettest quarter mm bio 16 precipitation of driest quarter mm bio 17 precipitation of warmest quarter mm bio 18 and precipitation of coldest quarter mm bio 19 water deficits wd were obtained by calculating the water balance thornthwaite and mather 1957 with 300 mm of available water in the soil klippel et al 2013 data in the categorical variable soils was obtained from the brazilian soil map produced by embrapa santos et al 2011 which was grouped according to the dominant soil classes of the mapping units all environmental variables were obtained for 1 km spatial resolution 2 3 3 adjustment and evaluation of the predictive model the linear correlation r between the environmental variables was verified using the labgeo package fernandes filho 2018 in r software r core team 2018 variables with high correlation r 0 95 were eliminated to avoid multicollinearity in the modeling the maxent model version 4 4 1 phillips et al 2017 was used to estimate species aptitude probabilities based on the occurrence points and selected environmental variables this approach generated probability estimates ranging from 0 to 1 the algorithm was performed using default settings auto features with the exception that the random seed option was selected so that each replica would use a different set of test points the model was submitted to 10 repetitions and cross validation was performed for each repetition the number of test points was determined by the number of occurrence points divided by the number of replicates a convergence threshold of 0 00001 was used with 500 interactions and 10 000 background points results were based on an average of 10 repetitions accuracy was assessed by the area under the curve auc of the receiver operating characteristics spiers et al 2018 auc values ranged from 0 5 models with low predictive capacity to 1 0 models with high prediction the participation of each environmental variable in the modeling was quantified using the jackknife test elith et al 2006 the maxent model results were imported into arcgis software the final maps for species planting potential comprised values from 0 to 1 supplementary appendix a based on the classifications proposed by yang et al 2013 and qin et al 2017 the values were grouped into four classes of planting potential high potential 0 6 good potential 0 4 0 6 moderate potential 0 2 0 4 and low potential 0 2 for each species the optimal cultivation area high and good potential in mg state was calculated using albers conical projection with a central meridian at 45 45 and standard parallels at 15 68 and 21 47 2 4 wood demand modeling for minas gerais state wood demand modeling was performed based on the spatial distribution of wood consumption by species masera et al 2006 consumption records from 2006 to 2016 compiled from the fod system were grouped by micro region using the r base package from r programming language software division into micro regions proposed and implemented by the brazilian institute of geography and statistics ibge is based on the economic and social similarities between municipalities in a geographical area of a brazilian state aiming to capture the economic influences of a municipality over another production and articulation two basic indicators were used to identify micro regions the structure of production and spatial interaction the first involves the analysis of the structure of primary production land use agricultural orientation the dimensional structure of establishments production relations technological level and use of capital and degree of diversification of agricultural production the spatial interaction indicator is related to the area of influence of the sub regional centers which function as articulating elements of the production processing and distribution of agricultural and urban goods and services ibge 1990 we considered this grouping of municipalities in order to better deal with the existence of large wood consuming markets and their influence on surrounding municipalities for species presenting high or good cultivation potential in mg state three wood demand classes high moderate and low were determined using the grouping analysis algorithm with arcgis software this algorithm identifies the similarity or divergence between sampling units from distinct and spatially defined locations creating statistically different groups wu et al 2015 the grouping was performed based on the total volume of wood consumption analysis fields in arcgis tools by micro region input features three groups were created number of groups based on this information high moderate and low clustering was defined by euclidean distances distance method between records without spatial constraints no spatial constraint r2 was calculated to demonstrate variation in data and clustering accuracy using eq 1 where sst denotes the difference between groups and sse denotes similarity within the group 1 r 2 s s t s s e s s t 2 s s t i 1 n c j 1 n i k 1 n v v i j k v k 2 3 s s e i 1 n c j 1 n i k 1 n v v i j k v i k 2 in eqs 2 and 3 n is the resource number number of micro regions nc is the group number high moderate or low ni is the resource number in group i nv is the variable number volume of wood used to group resources v i j k is the k value variable of the j resource in group i v k is the mean value of the k variable and v i k is the mean value of the k variable in group i esri 2019a 2 5 identification of priority areas for planting native tree species in minas gerais state first the priority planting areas for selected species were obtained for the high and moderate wood demand regions a new layer in gis was created through the intersection of high and moderate wood demand and potential cultivation layers high good moderate or low esri 2019b in total nine production potential classes were defined high demand and high potential 1 high demand and good potential 2 high demand and moderate potential 3 high demand and low potential 4 moderate demand and high potential 5 moderate demand and good potential 6 moderate demand and moderate potential 7 moderate demand and low potential 8 and non priority areas 9 classes 1 2 5 and 6 were considered priority areas for planting the studied species in mg state these classes represent strategic areas for the planning and development of the forestry sector enabling the establishment of development regions that are based on favorable environmental and economic attributes carvalho and scolforo 2008 3 results 3 1 adjustment and evaluation of the predictive model five highly correlated environmental variables r 0 95 were excluded minimum temperature of the coldest month bio 6 mean temperature of the driest quarter bio 9 mean temperature of the coldest quarter bio 11 precipitation of the wettest quarter bio 16 and precipitation of the driest quarter bio 17 supplementary appendix b the maxent model presented an auc between 0 77 h courbaril and t paniculata and 0 91 for p venosa table 2 according to the jackknife test fig 3 the effect of temperature variables specifically bio 1 bio 2 bio 3 bio 4 and bio 7 was statistically greater than for precipitation and soil variables these variables had a greater predictive value training gains for modeling most species a leiocarpa b nítida c racemosa c guianensis e uncinatum h courbaril h petraeum m elata p paniculata p caimito p guianensis p venosa s amara and t paniculata temperature seasonality bio 4 was the main variable in the modeling of a leiocarpa b nitida e uncinatum h courbaril and s amara and strongly influenced the modeling of seven other species d excelsa d odorata g glabra m venulosa p paniculata q paraensis and t paniculata the suitable range for cultivation based on temperature seasonality varied from 0 g glabra to 310 a leiocarpa the average annual precipitation bio 12 was the most important precipitation variable for d excelsa d odorata g glabra and q parenesis and strongly influenced six other species b nítida c guianensis e uncinatum h courbaril m elata and p guianensis the appropriate interval for cultivation of bio 12 varied from 1750 mm d odorata and e uncinatum to 3400 mm g glabra response curves are provided in supplementary appendix a 3 2 potential habitats for cultivation native tree species the studied native tree species which are in high demand in brazil showed distinct distributions in relation to potential planting habitats figs 4 and 5 the optimal cultivation areas high and good potential for b nitida c guianensis d excelsa d odorata e uncinatum g glabra h petraeum p paniculata and q parenesis are located mainly in the north region and the northern part of mato grosso state central west region far from the native wood consumer centers in the southeast region the potential for planting these species in mg state is low 0 0 2 some areas around mg state have moderate and good potential for planting d odorata being more affordable than if transported from naturally occurring areas north and central west regions additionally optimal cultivation areas for the species c racemosa m elata and p venosa are present along the atlantic coast in areas very close to mg state in addition to the north region optimal cultivation areas for the species a leiocarpa h courbaril m venulosa p caimito p guianensis s amara and t paniculata occupy 460 881 572 467 208 820 202 988 118 937 158 254 and 288 769 km2 in mg state respectively these species exhibit a high potential for income generation and restoration of native forests in this state these species also have potential to be used in plantations in other states of the southeast and south regions where the largest consumption centers are located ibama 2014 3 3 native wood demand regions in minas gerais state three wood demand regions were identified r2 0 82 for species with high cultivation potential in mg state fig 6 high demand regions included between one h courbaril and m venulosa and nine a leiocarpa micro regions the belo horizonte micro region stood out for its high consumption of wood from six different species the juiz de fora montes claros and ubá micro regions also showed high demand for three of the seven species 3 4 priority areas for planting native tree species in minas gerais state combining wood demand and potential cultivation regions in mg state fig 7 the areas with high demand and high potential in km² were as follows 19 993 23 a leiocarpa 4193 79 h courbaril 1939 58 m venulosa 16 356 25 p caimito 1623 61 p guianensis 0 84 s amara and 53 566 24 t paniculata the areas with high demand and good potential average demand and high potential and average demand and good potential together totaled 154 657 22 a leiocarpa 64 372 46 h courbaril 47 682 58 m venulosa 74 587 35 p caimito 26 476 32 p guianensis 39 144 97 s amara and 42 971 56 t paniculata km2 4 discussion the high accuracy auc 0 77 of the models for evaluating cultivation areas using maxent suggests that the ability to discriminate between high and low potential sites for cultivation was satisfactory elith et al 2006 our models also indicate that areas with high cultivation potential were positively correlated with environmental conditions found in the natural habitats of these species wang et al 2014 the lower auc values for the h courbaril and t paniculata models are explained by these species wide geographic distributions decreasing the models predictive performances yang et al 2013 the small number of recorded occurrences of h petraeum did not affect modeling accuracy contrary to previous studies williams et al 2009 van gils et al 2012 spiers et al 2018 because it is endemic and restricted to the amazon h petraeum presents a smaller area of occurrence and small niche amplitude which likely simplified model predictions hernandez et al 2006 species with low cultivation potential in mg state only present adequate plantation areas in regions with predominant af and am climate types north region and part of the central west region such locations are characterized by average temperatures 18 c and high levels of precipitation alvares et al 2013 species with low cultivation potential were divided according to temperature related variables b nítida c racemosa c guianensis e uncinatum h petraeum m elata p paniculata and p venosa or precipitation related variables d excelsa d odorata g glabra and q parenesis specifically for c racemosa m elata and p venosa high consumption in mg state as well as potential cultivation areas along part of the brazilian coast justify their plantation in the southern bahia espírito santo and são paulo states which are close to areas of high wood consumption ibama 2014 species with high cultivation potential in mg state a leiocarpa h courbaril m venulosa p caimito p guianensis s amara and t paniculata presented adequate areas that were more evenly distributed across brazil these areas were delimited by af am aw as cwa and cwb climate types sá júnior et al 2012 alvares et al 2013 and were strongly influenced by temperature specifically bio 1 bio 2 bio 3 bio 4 and bio 7 and wd these patterns of species suitability relating to climate and soil differences between sites are particularly important for the cultivation and utilization of forest resources in potential plantation areas assisting in determining appropriate management and operation binkley et al 2017 these patterns can also support tree genetic improvement programs especially when based on temperature and precipitation variables garcia et al 2014 for most species the effect of temperature variables on cropland modeling was statistically greater than the effects of precipitation and soil variables as indicated by the jackknife test this indicates the preference of these species for warm regions and may represent an adaptation associated with genetic characteristics this adaptation has been reported for several families such as fabaceae and sapotaceae in this study which present high diversity and abundance in regions with higher temperatures punyasena et al 2008 specifically temperature seasonality was one of the major environmental variables in the cropland modeling of 12 studied species seasonal temperature variation has previously been relevant in predicting suitable cultivation areas kumarl and stohlgren 2009 wang et al 2014 zhang et al 2016 it also seems to condition plant growth since photosynthetic activity often appears to be influenced more by seasonality than extreme temperatures xu et al 2013 the intergovernmental panel on climate change ipcc warns of a likely 2 8 c increase in median temperature and a 20 decrease in precipitation ipcc 2007 around the world this climate change may alter the characteristics of bioclimatic regions garcia et al 2014 and affect species distributions changing the delimitation of potential areas for tree planting one strategy to evaluate these possible changes to crop areas without the need to produce new modeling is to analyze the response curves of environmental variables supplementary appendix a these response curves quantify the relationship between the probability of species occurrence and the most important environmental variables that control their distributions ma and sun 2018 they should be used to identify locations where the basic environmental requirements for species development and production occur for both the current climate and future climate scenarios trabuco et al 2010 if changes to temperature and precipitation are within an appropriate range for species cultivation potential planting areas may not change significantly for species with potential for planting in mg state a leiocarpa h courbaril m venulosa p caimito p guianensis s amara and t paniculata their grouping into wood demand regions was based on estimates of spatial variation in their consumption much of this variation expressed by r2 was identified after modeling indicating that clustering was effective in discriminating solid wood consumer groups in the state wu et al 2015 higher wood consumption in some micro regions such as belo horizonte juiz de fora montes claros and ubá can be explained by the fact that they are important distribution supply centers in mg state and brazil ibge 2008 as well as areas with industrial potential mainly in the furniture manufacturing sector bastos and almeida 2008 the formation of different groups reflects the variation in the level of social demand for wood and is mainly a market phenomenon burkhard et al 2012 this information should be understood in the light of current forest management as well as future trends in other words investment in planted forests must necessarily be based on quantitative and qualitative indicators of the timber market bacha 2003 kies et al 2009 zang et al 2015 in this sense demand maps for each type of wood are useful and should be considered in current enterprises and future forest planning indicating appropriate allocation of financial and human resources and strategic points for trade masera et al 2006 santos et al 2017 combining wood demand and cultivation areas allowed the establishment of areas with high and medium demand with the possibility of cultivation this type of zoning therefore considers the synergy between some environmental and social attributes related to forest production allowing forest entrepreneurs to understand particular silvicultural and market peculiarities along with the requirements for settling in a location carvalho and scolforo 2008 more specifically areas with high demand and high cultivation potential combine the optimal ecological and economic qualities in the two categories this initiative could stimulate the forestry sector increasing plantations in order to meet the demand for large volumes of native wood and allowing large consumption hubs to benefit from reduced wood transport costs santos et al 2017 the results may also assist the government in determining public policies aimed at regional development and maintenance of traditional markets galik and abt 2016 planted forests are a means of meeting increased demand for timber and environmental services thus achieving sustainable forest development from this perspective the environmental and wood demand analysis in this study was successful in mapping native tree planting regions for in mg state however some observations should be made first despite the availability of up to date and reliable data a small number of occurrence records can lead to underestimating the amount of suitable habitat for the cultivation of some species spiers et al 2018 second the results are drawn from an ecological perspective without considering the potential for silvicultural practices and genetic improvement to minimize environmental stress and thus expand suitable cultivation areas trabucco et al 2010 therefore highly economically important species such as m elata may show cultivation potential in mg state if specific silvicultural techniques were adopted although this would require field verification finally the prospecting of suitable areas for forestry projects involves a variety of factors such as availability of land inputs relief conditions the interconnection of highways expected storage prices the unit cost of forestry interest rates and local policies cambero and sowlati 2014 wolfsmayr and rauch 2014 zang et al 2015 santos et al 2017 santos et al 2019 therefore future studies with a higher level of detail are needed to build an ideal model for wood demand the identification of regions where the environmental requirements for the development of each of these species are met is perhaps the most relevant outcome from this study together with wood demand data this environmental information provides a basis for the adoption of suitable forest management that conserves these native tree species through reforestation in both their current range and outside it the results of this study when in the possession of groups including companies wood markets and public administrators could be used to guarantee the self sufficiency of brazilian states creating sufficient production of native wood to meet their own consumption demands 5 conclusions environmental modeling using the maxent algorithm made it possible to determine the potential cultivation areas for native tree species of high commercial value it can be applied as a planning tool for planting these species in brazil and around the world among the nineteen species evaluated seven had cultivation potential in mg state suggesting these species can generate income and increase the potential of native forest restoration in this location by looking at the interaction between wood demand and potential cultivation habitats we were able to specify priority areas for reforestation the identification of such priority areas located near industries based on native wood can reduce pressure on the naturally occurring range of these species this could lead to improved conservation outcomes while strengthening and diversifying the economy in important wood consumption centers funding this work was supported by the coordenação de aperfeiçoamento de pessoal de nível superior brazil capes finance code 001 credit authorship contribution statement thales g v martins conceptualization methodology writing original draft visualization geraldo g reis project administration supervision writing review editing maria g f reis project administration supervision writing review editing lucas a a telles methodology formal analysis mayara r lage methodology formal analysis writing original draft gleidson g c mendes formal analysis writing original draft dayane l pinto methodology visualization nero l m castro methodology formal analysis alexandre s lorenzon methodology writing review editing ricardo s silva methodology formal analysis writing review editing duberlí g e gonzáles formal analysis visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors gratefully acknowledge the universidade federal de viçosa ufv and coordenação de aperfeiçoamento de pessoal de nível superior brazil capes finance code 001 for funding the project we also acknowledge to the geographic information systems laboratory ufv for the methodological contribution supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2020 109211 appendix supplementary materials image application 1 image application 2 image application 3 
24778,wood production from native tree species in brazil is primarily limited to exploitation of natural forests the identification of potential habitats for tree planting may provide new opportunities for natural forest conservation and management and increase the viability of native species plantations for highly valuable wood production this study aimed to identify potential habitats for native tree planting using a crop zoning model that combines environmental variables and wood demand modeling the target region for the study was minas gerais mg state southeast region brazil the maxent model was used to match environmental variables and the occurrence of 19 economically important tree species wood demand modeling was performed through the grouping analysis algorithm using brazilian consumption records by species the models generated with maxent were highly accurate area under the curve auc 0 77 apuleia leiocarpa vogel j f macbr hymenaea courbaril l micropholis venulosa mart e ex miq p p pouteria caimito ruiz pav radlk pouteria guianensis aubl simarouba amara aubl and tachigali paniculata aubl presented potential cultivation areas occupying 460 881 572 467 208 820 202 989 118 937 158 254 and 288 769 km2 respectively three classes of wood demand were identified r2 0 82 the belo horizonte juiz de fora montes claros and ubá micro regions showed high demand for most species studied the interaction between wood demand and areas with potential for planting each species allowed the specification of priority regions for reforestation regions with high demand and high cultivation potential occupied in km² 19 993 23 for a leiocarpa 4 193 8 for h courbaril 1 939 6 for m venulosa 16 356 3 for p caimito 1 623 6 for p guianensis 0 8 for s amara and 53 566 2 for t paniculata establishing these native tree species near wood based industries in regions that match the environmental variables of their occurrence area leads to natural forest conservation and economic growth of consumption centers graphical abstract image graphical abstract keywords maxent tropical wood demand environmental zoning native tree species 1 introduction the wood supply from native forests in brazil mainly from the amazon has decreased in recent years in response to prevailing environmental legislation and control by regulatory agencies nepstad et al 2009 rodrigues et al 2009 putz and romero 2014 brazilian institute of geography and statistics ibge 2017 the imbalance between native wood supply and demand can generate negative socioeconomic impacts both internationally and nationally especially in large brazilian consumption centers such as são paulo minas gerais paraná and santa catarina states this justifies the creation of specific policies to encourage legal production in order to mitigate the impacts of natural forest exploitation burkhard et al 2012 fao 2012 ibama 2014 oliver 2015 souza et al 2018 forest plantations are one option to meet the high demand for native wood in brazil asen et al 2012 to reduce pressure on natural forests buongiorno and zhu 2014 putz and romero 2015 and to generate income carle and holmgren 2008 putz and romero 2014 the likelihood of increased investment in all forestry enterprise types is higher if the commercial production of wood from native species is profitable profits may be substantial if one takes into account the environmental suitability for planting native trees wang et al 2014 falasca et al 2017 along with the economic and social implications of the investment brancalion et al 2012 shearman et al 2012 putz and romero 2014 however the use of native species of high commercial value in planted forests is still developing in brazil there are also few studies on the environmental requirements of these species and the economic and social aspects related to such plantations rolim and piotto 2019 for example to date there have been no silvicultural or economic studies related to manilkara elata allemão ex miq monach maçaranduba the second most utilized native tree species in brazil ibama 2014 the information available for this species is only related to its diversity and genetic structure azevedo et al 2007 pre and post exploration dynamics uhl and vieira 1989 wadsworth and zweede 2006 chagas et al 2012 castro and de carvalho 2014 avila et al 2017 and leaf and wood anatomy almeida jr et al 2013 nascimento et al 2017 such scarcity of information is common for the most economically important native species in brazil species distribution models sdms which allow the correlation between species and their biophysical environment help to identify potential areas for species cultivation elith and leathwick 2009 syfert et al 2013 qin et al 2017 there are many sdms available such as maxent bioclim garp glm gam and random forest which differ according to parameters and data entry criteria nix 1986 mccullagh and nelder 1989 hastie and tibshirani 1990 busby 1991 stockwell and noble 1992 hutchinson 1995 breiman 2001 phillips et al 2006 giannini et al 2012 the maxent model has been proven to be efficient and useful for species distribution modeling and unlike many sdms it requires only species presence data or occurrence combined with environmental layers phillips and dudík 2008 elith et al 2011 ma and sun 2018 the use of the maxent model in forestry is well documented for example it has been used to model the habitats of medicinal plants in india and china yang et al 2013 remya et al 2015 zhang et al 2016 bioenergetic and threatened plants in china wang et al 2014 qin et al 2017 and eucalyptus grandis garcia et al 2014 bambusa vulgaris and dendrocalamus giganteus santos et al 2019 in brazil the identification of potential habitats for native trees while considering the wood market may provide new options for forest conservation management and for increasing the viability of commercial plantations masera et al 2006 naidoo and ricketts 2006 egoh et al 2008 whether to invest in wood production is a decision often determined by profit estimates and should be aided by quantitative and qualitative indicators of demand for wood bacha 2003 kies et al 2009 in this sense choosing which wood to produce and where to produce it becomes safer when environmental data and market information are linked allowing the establishment of development areas that are based on the homogeneity of natural and social attributes naidoo and ricketts 2006 carvalho and scolforo 2008 such results can support the implementation of agri environmental policies as well as landscape sustainability assessments swetnam et al 2011 burkhard et al 2012 the objective of this study was to use the maxent model and spatial statistics techniques to identify potential regions of minas gerais mg state southeast region brazil suitable for planting economically important native tree species to meet this objective the environmental conditions of each species origin and cultivation regions were compared and the areas of greatest wood demand for each species were identified next priority areas with high potential for reforestation and high demand for wood were defined for the selected species 2 material and methods 2 1 study area the target region for the study was mg state southeast region brazil 13 94 22 50 s 41 73 52 87 w which occupies approximately 586 528 km2 and comprises 853 municipalities grouped into 66 micro regions fig 1 its economy is the third largest in brazil with primary sectors including agriculture livestock basso et al 2012 sá júnior et al 2012 and planted forestry primarily eucalyptus spp ibá 2017 this state is the second highest consumer of native wood in brazil ibama 2014 2 2 wood consumption database native wood consumption data specifically for solid wood products such as round wood and sawn wood were compiled from the forest origin document fod system which reports on trade and transportation of native forest resources in brazil ibama 2018 the states and municipalities of origin and destination of the wood not georeferenced species volume and types of products are contained in the fod system for volume only timber imported from other states was included since the volume of native timber produced by mg state is insignificant and not counted in the fod system this may be due to the history of forest exploitation and fragmentation in the state that makes legal management of native forests unfeasible today ief 2020 all information was georeferenced into a gis environment using arcgis 10 6 1 software creating a geospatial database with 387 891 information points fig 2 the species selection for this study was primarily based on consumption m3 by species and municipality of the 40 most consumed in the study area 19 brazilian tree species were selected these species accounted for approximately 2 5 million m3 of commercialized solid wood in the state between 2006 and 2016 55 of the total wood consumption in mg state table 1 2 3 potential habitats for cultivation native tree species in brazil 2 3 1 species occurrence data the georeferenced occurrence points of the 19 brazilian species were obtained from the global biodiversity information facility gbif database in https www gbif org the minas gerais state forest inventory carvalho and scolforo 2008 and specieslink http www splink org br data quality control was performed to ensure accurate information and georeferencing yesson et al 2007 giannini et al 2012 after refinement 3872 points of occurrence were used ranging from 28 points for hymenolobium petraeum to 727 points for hymenaea courbaril table 1 2 3 2 environmental variables to calculate the cultivation potential of the target species 21 edaphoclimatic variables were extracted for each occurrence point climatic variables were obtained from the worldclim global climate data version 2 0 database fick and hijmans 2017 the climatic variables were annual mean temperature c bio 1 mean diurnal range c bio 2 isothermality bio 3 temperature seasonality standard deviation 100 bio 4 maximum temperature of warmest month c bio 5 minimum temperature of coldest month c bio 6 temperature annual range bio 5 bio 6 bio 7 mean temperature of wettest quarter c bio 8 mean temperature of driest quarter c bio 9 mean temperature of warmest quarter c bio 10 mean temperature of coldest quarter c bio 11 annual precipitation mm bio 12 precipitation of wettest month mm bio 13 precipitation of driest month mm bio 14 precipitation seasonality mm bio 15 precipitation of wettest quarter mm bio 16 precipitation of driest quarter mm bio 17 precipitation of warmest quarter mm bio 18 and precipitation of coldest quarter mm bio 19 water deficits wd were obtained by calculating the water balance thornthwaite and mather 1957 with 300 mm of available water in the soil klippel et al 2013 data in the categorical variable soils was obtained from the brazilian soil map produced by embrapa santos et al 2011 which was grouped according to the dominant soil classes of the mapping units all environmental variables were obtained for 1 km spatial resolution 2 3 3 adjustment and evaluation of the predictive model the linear correlation r between the environmental variables was verified using the labgeo package fernandes filho 2018 in r software r core team 2018 variables with high correlation r 0 95 were eliminated to avoid multicollinearity in the modeling the maxent model version 4 4 1 phillips et al 2017 was used to estimate species aptitude probabilities based on the occurrence points and selected environmental variables this approach generated probability estimates ranging from 0 to 1 the algorithm was performed using default settings auto features with the exception that the random seed option was selected so that each replica would use a different set of test points the model was submitted to 10 repetitions and cross validation was performed for each repetition the number of test points was determined by the number of occurrence points divided by the number of replicates a convergence threshold of 0 00001 was used with 500 interactions and 10 000 background points results were based on an average of 10 repetitions accuracy was assessed by the area under the curve auc of the receiver operating characteristics spiers et al 2018 auc values ranged from 0 5 models with low predictive capacity to 1 0 models with high prediction the participation of each environmental variable in the modeling was quantified using the jackknife test elith et al 2006 the maxent model results were imported into arcgis software the final maps for species planting potential comprised values from 0 to 1 supplementary appendix a based on the classifications proposed by yang et al 2013 and qin et al 2017 the values were grouped into four classes of planting potential high potential 0 6 good potential 0 4 0 6 moderate potential 0 2 0 4 and low potential 0 2 for each species the optimal cultivation area high and good potential in mg state was calculated using albers conical projection with a central meridian at 45 45 and standard parallels at 15 68 and 21 47 2 4 wood demand modeling for minas gerais state wood demand modeling was performed based on the spatial distribution of wood consumption by species masera et al 2006 consumption records from 2006 to 2016 compiled from the fod system were grouped by micro region using the r base package from r programming language software division into micro regions proposed and implemented by the brazilian institute of geography and statistics ibge is based on the economic and social similarities between municipalities in a geographical area of a brazilian state aiming to capture the economic influences of a municipality over another production and articulation two basic indicators were used to identify micro regions the structure of production and spatial interaction the first involves the analysis of the structure of primary production land use agricultural orientation the dimensional structure of establishments production relations technological level and use of capital and degree of diversification of agricultural production the spatial interaction indicator is related to the area of influence of the sub regional centers which function as articulating elements of the production processing and distribution of agricultural and urban goods and services ibge 1990 we considered this grouping of municipalities in order to better deal with the existence of large wood consuming markets and their influence on surrounding municipalities for species presenting high or good cultivation potential in mg state three wood demand classes high moderate and low were determined using the grouping analysis algorithm with arcgis software this algorithm identifies the similarity or divergence between sampling units from distinct and spatially defined locations creating statistically different groups wu et al 2015 the grouping was performed based on the total volume of wood consumption analysis fields in arcgis tools by micro region input features three groups were created number of groups based on this information high moderate and low clustering was defined by euclidean distances distance method between records without spatial constraints no spatial constraint r2 was calculated to demonstrate variation in data and clustering accuracy using eq 1 where sst denotes the difference between groups and sse denotes similarity within the group 1 r 2 s s t s s e s s t 2 s s t i 1 n c j 1 n i k 1 n v v i j k v k 2 3 s s e i 1 n c j 1 n i k 1 n v v i j k v i k 2 in eqs 2 and 3 n is the resource number number of micro regions nc is the group number high moderate or low ni is the resource number in group i nv is the variable number volume of wood used to group resources v i j k is the k value variable of the j resource in group i v k is the mean value of the k variable and v i k is the mean value of the k variable in group i esri 2019a 2 5 identification of priority areas for planting native tree species in minas gerais state first the priority planting areas for selected species were obtained for the high and moderate wood demand regions a new layer in gis was created through the intersection of high and moderate wood demand and potential cultivation layers high good moderate or low esri 2019b in total nine production potential classes were defined high demand and high potential 1 high demand and good potential 2 high demand and moderate potential 3 high demand and low potential 4 moderate demand and high potential 5 moderate demand and good potential 6 moderate demand and moderate potential 7 moderate demand and low potential 8 and non priority areas 9 classes 1 2 5 and 6 were considered priority areas for planting the studied species in mg state these classes represent strategic areas for the planning and development of the forestry sector enabling the establishment of development regions that are based on favorable environmental and economic attributes carvalho and scolforo 2008 3 results 3 1 adjustment and evaluation of the predictive model five highly correlated environmental variables r 0 95 were excluded minimum temperature of the coldest month bio 6 mean temperature of the driest quarter bio 9 mean temperature of the coldest quarter bio 11 precipitation of the wettest quarter bio 16 and precipitation of the driest quarter bio 17 supplementary appendix b the maxent model presented an auc between 0 77 h courbaril and t paniculata and 0 91 for p venosa table 2 according to the jackknife test fig 3 the effect of temperature variables specifically bio 1 bio 2 bio 3 bio 4 and bio 7 was statistically greater than for precipitation and soil variables these variables had a greater predictive value training gains for modeling most species a leiocarpa b nítida c racemosa c guianensis e uncinatum h courbaril h petraeum m elata p paniculata p caimito p guianensis p venosa s amara and t paniculata temperature seasonality bio 4 was the main variable in the modeling of a leiocarpa b nitida e uncinatum h courbaril and s amara and strongly influenced the modeling of seven other species d excelsa d odorata g glabra m venulosa p paniculata q paraensis and t paniculata the suitable range for cultivation based on temperature seasonality varied from 0 g glabra to 310 a leiocarpa the average annual precipitation bio 12 was the most important precipitation variable for d excelsa d odorata g glabra and q parenesis and strongly influenced six other species b nítida c guianensis e uncinatum h courbaril m elata and p guianensis the appropriate interval for cultivation of bio 12 varied from 1750 mm d odorata and e uncinatum to 3400 mm g glabra response curves are provided in supplementary appendix a 3 2 potential habitats for cultivation native tree species the studied native tree species which are in high demand in brazil showed distinct distributions in relation to potential planting habitats figs 4 and 5 the optimal cultivation areas high and good potential for b nitida c guianensis d excelsa d odorata e uncinatum g glabra h petraeum p paniculata and q parenesis are located mainly in the north region and the northern part of mato grosso state central west region far from the native wood consumer centers in the southeast region the potential for planting these species in mg state is low 0 0 2 some areas around mg state have moderate and good potential for planting d odorata being more affordable than if transported from naturally occurring areas north and central west regions additionally optimal cultivation areas for the species c racemosa m elata and p venosa are present along the atlantic coast in areas very close to mg state in addition to the north region optimal cultivation areas for the species a leiocarpa h courbaril m venulosa p caimito p guianensis s amara and t paniculata occupy 460 881 572 467 208 820 202 988 118 937 158 254 and 288 769 km2 in mg state respectively these species exhibit a high potential for income generation and restoration of native forests in this state these species also have potential to be used in plantations in other states of the southeast and south regions where the largest consumption centers are located ibama 2014 3 3 native wood demand regions in minas gerais state three wood demand regions were identified r2 0 82 for species with high cultivation potential in mg state fig 6 high demand regions included between one h courbaril and m venulosa and nine a leiocarpa micro regions the belo horizonte micro region stood out for its high consumption of wood from six different species the juiz de fora montes claros and ubá micro regions also showed high demand for three of the seven species 3 4 priority areas for planting native tree species in minas gerais state combining wood demand and potential cultivation regions in mg state fig 7 the areas with high demand and high potential in km² were as follows 19 993 23 a leiocarpa 4193 79 h courbaril 1939 58 m venulosa 16 356 25 p caimito 1623 61 p guianensis 0 84 s amara and 53 566 24 t paniculata the areas with high demand and good potential average demand and high potential and average demand and good potential together totaled 154 657 22 a leiocarpa 64 372 46 h courbaril 47 682 58 m venulosa 74 587 35 p caimito 26 476 32 p guianensis 39 144 97 s amara and 42 971 56 t paniculata km2 4 discussion the high accuracy auc 0 77 of the models for evaluating cultivation areas using maxent suggests that the ability to discriminate between high and low potential sites for cultivation was satisfactory elith et al 2006 our models also indicate that areas with high cultivation potential were positively correlated with environmental conditions found in the natural habitats of these species wang et al 2014 the lower auc values for the h courbaril and t paniculata models are explained by these species wide geographic distributions decreasing the models predictive performances yang et al 2013 the small number of recorded occurrences of h petraeum did not affect modeling accuracy contrary to previous studies williams et al 2009 van gils et al 2012 spiers et al 2018 because it is endemic and restricted to the amazon h petraeum presents a smaller area of occurrence and small niche amplitude which likely simplified model predictions hernandez et al 2006 species with low cultivation potential in mg state only present adequate plantation areas in regions with predominant af and am climate types north region and part of the central west region such locations are characterized by average temperatures 18 c and high levels of precipitation alvares et al 2013 species with low cultivation potential were divided according to temperature related variables b nítida c racemosa c guianensis e uncinatum h petraeum m elata p paniculata and p venosa or precipitation related variables d excelsa d odorata g glabra and q parenesis specifically for c racemosa m elata and p venosa high consumption in mg state as well as potential cultivation areas along part of the brazilian coast justify their plantation in the southern bahia espírito santo and são paulo states which are close to areas of high wood consumption ibama 2014 species with high cultivation potential in mg state a leiocarpa h courbaril m venulosa p caimito p guianensis s amara and t paniculata presented adequate areas that were more evenly distributed across brazil these areas were delimited by af am aw as cwa and cwb climate types sá júnior et al 2012 alvares et al 2013 and were strongly influenced by temperature specifically bio 1 bio 2 bio 3 bio 4 and bio 7 and wd these patterns of species suitability relating to climate and soil differences between sites are particularly important for the cultivation and utilization of forest resources in potential plantation areas assisting in determining appropriate management and operation binkley et al 2017 these patterns can also support tree genetic improvement programs especially when based on temperature and precipitation variables garcia et al 2014 for most species the effect of temperature variables on cropland modeling was statistically greater than the effects of precipitation and soil variables as indicated by the jackknife test this indicates the preference of these species for warm regions and may represent an adaptation associated with genetic characteristics this adaptation has been reported for several families such as fabaceae and sapotaceae in this study which present high diversity and abundance in regions with higher temperatures punyasena et al 2008 specifically temperature seasonality was one of the major environmental variables in the cropland modeling of 12 studied species seasonal temperature variation has previously been relevant in predicting suitable cultivation areas kumarl and stohlgren 2009 wang et al 2014 zhang et al 2016 it also seems to condition plant growth since photosynthetic activity often appears to be influenced more by seasonality than extreme temperatures xu et al 2013 the intergovernmental panel on climate change ipcc warns of a likely 2 8 c increase in median temperature and a 20 decrease in precipitation ipcc 2007 around the world this climate change may alter the characteristics of bioclimatic regions garcia et al 2014 and affect species distributions changing the delimitation of potential areas for tree planting one strategy to evaluate these possible changes to crop areas without the need to produce new modeling is to analyze the response curves of environmental variables supplementary appendix a these response curves quantify the relationship between the probability of species occurrence and the most important environmental variables that control their distributions ma and sun 2018 they should be used to identify locations where the basic environmental requirements for species development and production occur for both the current climate and future climate scenarios trabuco et al 2010 if changes to temperature and precipitation are within an appropriate range for species cultivation potential planting areas may not change significantly for species with potential for planting in mg state a leiocarpa h courbaril m venulosa p caimito p guianensis s amara and t paniculata their grouping into wood demand regions was based on estimates of spatial variation in their consumption much of this variation expressed by r2 was identified after modeling indicating that clustering was effective in discriminating solid wood consumer groups in the state wu et al 2015 higher wood consumption in some micro regions such as belo horizonte juiz de fora montes claros and ubá can be explained by the fact that they are important distribution supply centers in mg state and brazil ibge 2008 as well as areas with industrial potential mainly in the furniture manufacturing sector bastos and almeida 2008 the formation of different groups reflects the variation in the level of social demand for wood and is mainly a market phenomenon burkhard et al 2012 this information should be understood in the light of current forest management as well as future trends in other words investment in planted forests must necessarily be based on quantitative and qualitative indicators of the timber market bacha 2003 kies et al 2009 zang et al 2015 in this sense demand maps for each type of wood are useful and should be considered in current enterprises and future forest planning indicating appropriate allocation of financial and human resources and strategic points for trade masera et al 2006 santos et al 2017 combining wood demand and cultivation areas allowed the establishment of areas with high and medium demand with the possibility of cultivation this type of zoning therefore considers the synergy between some environmental and social attributes related to forest production allowing forest entrepreneurs to understand particular silvicultural and market peculiarities along with the requirements for settling in a location carvalho and scolforo 2008 more specifically areas with high demand and high cultivation potential combine the optimal ecological and economic qualities in the two categories this initiative could stimulate the forestry sector increasing plantations in order to meet the demand for large volumes of native wood and allowing large consumption hubs to benefit from reduced wood transport costs santos et al 2017 the results may also assist the government in determining public policies aimed at regional development and maintenance of traditional markets galik and abt 2016 planted forests are a means of meeting increased demand for timber and environmental services thus achieving sustainable forest development from this perspective the environmental and wood demand analysis in this study was successful in mapping native tree planting regions for in mg state however some observations should be made first despite the availability of up to date and reliable data a small number of occurrence records can lead to underestimating the amount of suitable habitat for the cultivation of some species spiers et al 2018 second the results are drawn from an ecological perspective without considering the potential for silvicultural practices and genetic improvement to minimize environmental stress and thus expand suitable cultivation areas trabucco et al 2010 therefore highly economically important species such as m elata may show cultivation potential in mg state if specific silvicultural techniques were adopted although this would require field verification finally the prospecting of suitable areas for forestry projects involves a variety of factors such as availability of land inputs relief conditions the interconnection of highways expected storage prices the unit cost of forestry interest rates and local policies cambero and sowlati 2014 wolfsmayr and rauch 2014 zang et al 2015 santos et al 2017 santos et al 2019 therefore future studies with a higher level of detail are needed to build an ideal model for wood demand the identification of regions where the environmental requirements for the development of each of these species are met is perhaps the most relevant outcome from this study together with wood demand data this environmental information provides a basis for the adoption of suitable forest management that conserves these native tree species through reforestation in both their current range and outside it the results of this study when in the possession of groups including companies wood markets and public administrators could be used to guarantee the self sufficiency of brazilian states creating sufficient production of native wood to meet their own consumption demands 5 conclusions environmental modeling using the maxent algorithm made it possible to determine the potential cultivation areas for native tree species of high commercial value it can be applied as a planning tool for planting these species in brazil and around the world among the nineteen species evaluated seven had cultivation potential in mg state suggesting these species can generate income and increase the potential of native forest restoration in this location by looking at the interaction between wood demand and potential cultivation habitats we were able to specify priority areas for reforestation the identification of such priority areas located near industries based on native wood can reduce pressure on the naturally occurring range of these species this could lead to improved conservation outcomes while strengthening and diversifying the economy in important wood consumption centers funding this work was supported by the coordenação de aperfeiçoamento de pessoal de nível superior brazil capes finance code 001 credit authorship contribution statement thales g v martins conceptualization methodology writing original draft visualization geraldo g reis project administration supervision writing review editing maria g f reis project administration supervision writing review editing lucas a a telles methodology formal analysis mayara r lage methodology formal analysis writing original draft gleidson g c mendes formal analysis writing original draft dayane l pinto methodology visualization nero l m castro methodology formal analysis alexandre s lorenzon methodology writing review editing ricardo s silva methodology formal analysis writing review editing duberlí g e gonzáles formal analysis visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors gratefully acknowledge the universidade federal de viçosa ufv and coordenação de aperfeiçoamento de pessoal de nível superior brazil capes finance code 001 for funding the project we also acknowledge to the geographic information systems laboratory ufv for the methodological contribution supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2020 109211 appendix supplementary materials image application 1 image application 2 image application 3 
24779,mathematical models represent essential tools allowing a quantitative analysis of an epidemic system with the consequent identification of possible strategies to control a disease outbreak or even to prevent it however to be used in decision making they must be carefully parametrized and validated with epidemiological data as well as biological information on the relevant players here benefitting of the olive quick decline syndrome oqds outbreak which has occurred in southern italy since 2013 an epidemiological model describing this epidemic is presented beside the bacterium xylella fastidiosa the oqds main players considered in the model are its insect vectors philaenus spumarius and the host plants olive trees and weeds of the insects and of the bacterium the model is based on a system of ordinary differential equations the analysis of which have provided interesting results about possible equilibria of the epidemic system and guidelines for its numerical simulations these under a variety of parameter scenarios have led to the model sensitivity analysis hence to understanding the parameters relative importance in the transmission of the disease although the model presented here is mathematically rather simplified its analysis has highlighted threshold parameters that could be the target of control strategies within the integrated pest management framework not requiring the removal of the productive resource represented by the olive trees indeed numerical simulations support the outcomes of the mathematical analysis according to which a removal of a suitable amount of weeds biomass reservoir of xylella fastidiosa from olive orchards and surrounding areas resulted the most efficient strategy to control the spread of the oqds in addition as expected the adoption of more resistant olive tree cultivars has been shown to be a good strategy though less cost effective in controlling the pathogen keywords xylella fastidiosa olive trees epidemics mathematical model numerical simulations control strategies 2010 msc 34 xx 34cxx 37n25 92dxx 92d30 92c80 1 introduction xylella fastidiosa wells et al 1987 the causative agent of numerous important plant diseases janse and obradovic 2010 is a quarantine gram negative bacterium efsa 2015 transmitted by xylem fluid feeding hemiptera cicadomorpha belonging to the families cicadellidae aphrophoridae and clastopteridae janse and obradovic 2010 redak et al 2004 until recent years this bacterial pathogen associated with about 50 insect vectors has been reported in the american continent india turkey taiwan iran and lebanon amanifar et al 2014 güldür et al 2005 janse and obradovic 2010 jindal and sharma 1987 leu and su 1993 temsah et al 2015 within europe even though the first report of pierce s disease symptoms in grapevines have been reported in the mid of 1980s berisha unpublished the presence of x fastidiosa in this area was confirmed almost ten years later on grapevine of kosovo berisha et al 1998 however the exact location of infected samples was unknown in 2011 the bacterium has been intercepted in france but all further surveys failed to detect its presence in the country anses 2012 until 2015 in 2013 x fastidiosa subsp pauca isolate ol g2 hereafter only xylella fastidiosa has resulted infesting a wide area of olive tree plantations oleander and almond in apulia italy causing the olive quick decline syndrome oqds saponari et al 2013 in this region x fastidiosa subsp pauca st53 was recorded in different insect vectors the meadow spittlebug philaenus spumarius linnaeus 1758 neophilaenus campestris falln 1805 hemiptera aphrophoridae euscelis lineolatus brull 1832 hemiptera cicadellidae cariddi et al 2014 carlucci et al 2013 elbeaino et al 2014 saponari et al 2014 the first species of the list represents the main insect vector of the bacterium in southern italy philaenus spumarius nymphs develop on herbaceous vegetation represented by weeds or ornamental plants confined in an own produced foam for protection from predators and maintenance of temperature and moisture adults soon after their appearance move to the tree canopies experiments have shown a larger infection prevalence of adults on olive trees than on weeds even if the possibility that weeds represent a reservoir of the bacterium cannot be excluded cornara 2017 xylella fastidiosa transmission can be summarized by four events see almeida et al 2005 redak et al 2004 and references therein a acquisition from a source plant b attachment and retention to vector s foregut c inoculation into a new host d development of the infection in a plant after inoculation once a plant is infected bacteria multiply within the xylem vessels resulting in the formation of microfilm which occludes the xylem vessels thus inhibiting the flux of water through the lymph vessels eventually blocking the nutrition of the plant typical symptoms are leaf scorch dieback of twigs branches and even of the whole plant carlucci et al 2013 the eradication of infected trees and uninfected trees in their neighborhood causes serious social and economic drawbacks so alternative management strategies are needed the mathematical modelling of vector plant pathogen dynamics within the agroecosystem of olive orchards such as those in apulian region may help in the identification of key points to formulate possible control strategies a recent study adopting a quantitative lattice model for the infection spreading has shown that the numbers of vectors and trees are the most relevant parameters controlling the infection fierro et al 2019 more specifically they have proposed an interesting simulation tool without performing analytical studies of its qualitative behaviour the choice of this work instead has been to adopt a dynamical model based on systems of ordinary differential equations ode s because of their convenience for the analysis of optimal control problems see e g capasso 2009 arnăutu et al 2011 aniţa et al 2019 and references therein here a mathematical model is presented that could be adopted in an integrated pest management framework to suggest eradication or optimal control strategies against x fastidiosa epidemics we propose and analyze an oversimplified ode system describing the evolution of the populations of the three key players involved in the epidemic process i e olive trees insects weeds for the time being we have adopted a model which ignores both the life cycle of the insects and the spatial structure of the system model reduction is anyhow a must considering that holistic models cannot be treated in a mathematically rigorous way because of analytical unaffordability still we have included the essential features of a real vector plant pathogen system the plan of the paper is the following one in section 2 1 the relevant variables are introduced in paragraphs 2 1 1 2 1 2 2 1 3 the mathematical model is proposed as a system of ordinary differential equations ode s in paragraph 3 2 the relevant parameter values are presented on which numerical simulations have been carried out section 3 1 is devoted to the qualitative analysis of the epidemic system it has driven in section 3 3 some numerical simulations of the system and the sensitivity analysis of the model to relevant parameters concluding remarks and future research plans are reported in section 4 2 materials and methods 2 1 background of the model a detailed model including all the insect stages and their sexual differences would lead to a rather complex model from the mathematical point of view hence a substantial model reduction has been adopted including what can be considered the most significant features of the dynamics of a real epidemic system with respect to possible optimal control strategies a remarkable representation of the concept of model reduction has been offered by picasso https www dailyartmagazine com pablo picasso bulls road simplicity accordingly only the following components have been considered first of all the feeding behaviours and metabolic processes are qualitatively similar for nymphs and adult insects with the only exception that the former feed on herbaceous plants weeds and the latter on shrubs and trees therefore both nymphs and adults are possible active vectors of the infection janse and obradovic 2010 the different developmental stages of the insect eggs nymphs adults should be considered but due to the ensuing mathematical complexity in this paper the whole insect life cycle has been considered as consisting of one metastage a recent study on modelling insect life cycles can be found in rossini et al 2019 we will also ignore the difference between males and females the individuals of the insect population will be denoted by a if healthy and by v if infected the populations of susceptible and infected trees will be respectively denoted by s and i see table 1 in the environment there are other herbaceous and arbustive plants here named as weeds that may constitute a reservoir for the bacterial pathogen x fastidiosa the number of healthy weeds will be denoted by p while q stands for the infected ones finally we might consider populations of natural predators of the x fastidiosa insect vector but for the time being this case will be ignored see e g bruzzone et al 2018 and bautista et al 2019 all the parameters in the model are non negative quantities 2 1 1 the mathematical model dynamics of insects the equation for the susceptible insects within the population will contain the reproduction term for which they are born healthy at rate r from the existing adult females of the population due to the fact that bacteria reside only in the foregut of an adult insect the latter generate only healthy offspring see e g almeida et al 2005 redak et al 2004 and references therein the development of nymphs and their molting on adults however require weeds in the environment either healthy or infected this has been expressed by the dependence here assumed to be linear of the birth rate upon the total weeds population by taking these facts into account the evolution equation of the two insect subpopulations are the following ones 1 d a d t r a v p q r χ a a v n p q s i a β i s i a γ q p q a d v d t n p q s i v r χ v a v β i s i a γ q p q a the production of healthy insects has been modeled as 2 r a v p q χ a where a logistic term p q χ a has been introduced this means that the total population of weeds p q acts as carrying capacity for the insects where χ is a tuning parameter in the second equation above concerning infected insects the logistic term is 3 r a v χ v insects experience a natural mortality n p q s i which depends on the availability of their resources represented by trees and plants both healthy and infected as an additional simplification we will consider a constant mortality rate n susceptible insects may become infected by feeding on infected trees or plants we assume that the insects infection rate is a linear function of the relative abundances with respect to their respective total populations of both trees and weeds via the parameters β and γ respectively see e g capasso 2009 i e 4 β i s i γ q p q a in the light of the aforementioned simplifications system 1 becomes 5 d a d t r a v p q r χ a a v n a β i s i a γ q p q a d v d t n v r χ v a v β i s i a γ q p q a 2 1 2 the mathematical model dynamics of olive trees for the olive trees it is better to refer to their canopies so that we may consider pruning and regrowth the dynamics of olive trees is described by the following two equations 6 d s d t q s i c s ℓ s λ v s b ℓ i i s s α i d i d t s i c i λ v s μ i ℓ i b ℓ i i s s α i healthy trees canopy s are produced by regrowth or additional planting the production of healthy trees has been described by a logistic growth model 7 q s i c s where q is the natural constant growth rate and the logistic term s i c takes into account a possible carrying capacity c correspondingly in the second equation concerning infected trees a logistic term s i c i has been included for trees in view of their long survival we can neglect natural mortality but we will consider a constant decay rate ℓ due to the regular pruning or possible elimination logging canopies of infected trees i experience a disease related extra mortality μ a possible recovery of trees might be considered at a constant rate α trees get infected by contact with infected adult insects or by human activities such as pruning budding and grafting as far as the incidence rate due to infected insects is concerned we have assumed the form see dietz 1982 8 λ g a v v a v s where g a v denotes the contact rate of trees with the total population of insects the parameter λ is strictly related to a specific cultivar this means that we are assuming that the probability for a tree to acquire the infection upon a contact with insects is proportional to the frequency of infected insects with respect to their total population we have assumed g a v a v which leads to the simplification 9 λ v s the incidence rate due to human activities has been considered proportional to the relative abundance of infected trees with respect to their total mass given ℓ the rate of contacts with tools employed for human activities we have 10 b ℓ i i s s 2 1 3 the mathematical model dynamics of weeds the dynamics of the weeds mass is described by the following two equations 11 d p d t a p c 2 p q η v p h p p q d q d t p q c 2 q η v p δ q h q p q as above logistic growth is assumed at net reproduction rate a and carrying capacity c 2 we assume that all weeds produce healthy ones for the infection rate of weeds we have made the same assumptions as for the olive trees so that the incidence rate for weeds is 12 η v p disease related mortality of weeds occurs at rate δ while hp and hq represent mass reduction due to human related activities later these terms will be used as control terms for the eventual eradication of the epidemic in the relevant habitat we may assume that they are linearly dependent on the size of the existing vegetation i e 13 h p p q h 1 p h q p q h 1 q the model presented above belongs to the so called class of ecoepidemic models see review venturino 2016 although predator prey or competing populations are not incorporated simulations were performed using an own code based on the ode23s routine 230 of matlab 2007b on a hp zbook 14 g2 mobile workstation 3 results and discussion 3 1 mathematical analysis for technical reasons we rephrase the system by introducing the following new variables see also table 1 the total number of insects f a v and the fractions of susceptibles u a f 1 and infectives z 1 u v f 1 the total canopy mass of olive trees n s i and the fractions of susceptibles x s n 1 and infectives y i n 1 we proceed similarly with the total weeds mass m p q and their susceptible w p m 1 and infective γ q m 1 fractions by observing that y 1 x and γ 1 w in terms of fractions our system becomes 14 d u d t r m 1 u β 1 x γ 1 w u d f d t f r m χ f n d x d t x q μ b ℓ 1 x λ 1 u f α 1 x d n d t n q x ℓ n c μ 1 x d w d t a 1 w w δ 1 w η 1 u f d m d t m a m c 2 δ 1 w h 1 system 14 incorporates different populations affected by disease two of them are interlinked since insects cannot reproduce without weeds we wish to explore the eventual behaviour of the relevant populations for large times first of all we may look for the possible existence of equilibria which can be obtained by solving the following system of equations 15 r m 1 u β 1 x γ 1 w u 0 16 f r m χ f n 0 17 x q μ b ℓ 1 x λ 1 u f α 1 x 0 18 n q x ℓ n c μ 1 x 0 19 a 1 w w δ 1 w η 1 u f 0 20 m a m c 2 δ 1 w h 1 0 now we explore some interesting features of the system which anticipate the outcomes of the numerical simulations and possibly lead to the identification of potentially weak points in the plant xylella insect system that could lead to the development of guidelines for the control of a xylella epidemic a more detailed analysis of the above system would have required nontrivial mathematical techniques that might have obscured relevant issues of practical interest a possible equilibrium is the trivial one 21 u f x n w m e q 0 u 0 0 1 0 1 0 which means absence of all populations a situation with no practical meaning we focus on the total populations i e on equations 16 18 and 20 equation 16 for the total populations of insects admits either the trivial solution f 1 e q 0 or the solution of 22 r m χ f n 0 if m m 1 e q 0 we have 23 r χ f n 0 which leads to an unfeasible value for f this shows that m e q 0 implies f e q 0 which is already an important consequence of the model on the other hand equation 20 admits either the trivial solution m 1 e q 0 or m 2 e q c 2 a h 1 δ 1 w c 2 a h 1 which can be feasible only for a h 1 for the parameters reported in table 3 c 2 10 c 1000 0 and h 1 0 0 i e no weeds cut we have m 2 e q a c 2 0 5 1000 0 500 0 instead with a weeds cutting h 1 a we may only have m 1 e q 0 and so only f 1 e q 0 equation 18 is self consistent it admits either the trivial solution n 1 e q 0 or the solution of q x 2 e q ℓ n 2 e q c μ 1 x 2 e q 0 i e 24 n 2 e q c q x 2 e q ℓ μ 1 x 2 e q from 24 we derive n 2 e q c q ℓ this is feasible only for q ℓ for the parameters reported in table 3 we have n 2 e q 49 0 altogether we have identified the following interesting results to possibly obtain a nontrivial steady state equilibrium for the olive trees we must have 25 q ℓ in order to eliminate the weeds and consequently to eradicate the insects we require 26 h 1 a unfortunately conditions 25 and 26 are only sufficient conditions they do not exclude the possible coexistence of insects and olive trees provided the insect population is not very large in this respect the numerical simulations elucidate the crucial role of the parameter χ let us anticipate that from equation 16 we may recognize the role of m χ as the effective carrying capacity of the insect population f for χ 1 χ 2 we have m χ 1 m χ 2 which implies for χ 1 a possibly larger population of insects hence a possibly larger infective insect population which may lead to a larger force of infection on olive trees thus making the possible coexistence of insects and trees unlikely it is more difficult to analyze the role of λ its magnitude is influenced by the resistance to infection of each olive tree cultivar i e by increasing the cultivar resistance to infection the value of λ decreases it appears in eq 17 which is indeed more difficult to analyze independently of the other equations in the system anyhow the numerical simulations highlight its role additional comments are postponed to section 3 3 3 2 parameter values the species p spumarius can be attributed to the r selection reproductive strategy with a one year life cycle so almost all the adults die during the winter season supported by weaver and king 1954 see also whittaker 1973 for this reason assuming that a really small proportion of the adults can survive to the next year a value of 0 98 0 95 0 99 is reasonable for the parameter n the weeds growth rate a is a highly variable parameter since within the weeds category are included both grass and shrubs that are characterized by different overwintering strategies and thus having different growth rates spanning from 100 renewal of epigeal apparatus e g convolvolus sp to only a small fraction of it e g nerium oleander for the previous reason several values in the range 0 1 1 0 have been tested regarding the infected trees recovery rate α no data are present in the literature concerning oqds in order to test the influence of this parameter on the results of the model two different scenarios have been hypothesized the first one α 0 1 is considered the more reliable corresponding to a recovery of 10 of the infected trees due to the application of phytosanitary practices the second one with α 0 5 is considered less realistic the pruning of the olive trees in the infected area is usually carried out every 2 3 years bollettino ufficiale della regione puglia 2016 and implies a removal of about 15 20 of the biomass mostly constituted by wood that cannot be used by the insect as a food resource so a loss of an average of 5 10 of the total biomass each year has been assumed as a reliable value as a consequence the biomass suitable to sustain the insect growth is reduced by about 1 ℓ 0 01 as carrying capacity of olive trees c a value of 100 has been assigned as a reference unitary value in order to obtain a reliable estimate of the weed s carrying capacity we have considered previous studies where by using the sweep net as collecting tool a range of 4 40 adults were collected on weeds weaver and king 1954 while only 0 4 0 7 adults were collected on olive trees cornara 2017 so the carrying capacity of weeds should be about 10 100 times the one of olive trees considering the difference between the environment studied in weaver and king 1954 with respect to the olive orchard we have adopted a more conservative ratio corresponding to c 2 10 c in all the cases in which different values of the parameters have been tested those highlighted above in the text as well as the insect intraspecific competition rate χ the output of the model resulted to be mostly unaffected the main aim of the numerical simulations has been to investigate the long term behavior of our system on the basis of the qualitative analysis carried out in section 3 1 as expected the numerical simulations show that the system tends to an eventual equilibrium for all species independently of the initial conditions since the life cycle of p spumarius from egg to adult has a duration of one year we have chosen the year as the symbolic time unit to assign the numerical values to the parameters listed in table 3 to pursue the aim of this study we focused on possible targets of agronomic management here they are represented by the following two parameters i the weeds elimination rate by human intervention h 1 and ii the trees infection rate by infected insects λ agronomic practice has shown a significant dependence of this parameter upon the olive cultivar for the previous reasons for fixed values of the other parameters as from table 3 we performed simulations for testing the behavior of the epidemic system with respect to these two parameters in fig 3 4 numerical results are plotted for the following selections λ 0 8 0 5 0 3 describing an increase of the resistance of the olive tree h 1 0 0 0 4 describing two possible control scenarios the first one with no weeds cut and the second one with a cut intensity above the value of the weeds reproduction parameter a 0 3 in fig 3 the value α 0 1 has been chosen while in fig 4 α 0 5 regarding χ in both figures the value of 0 001 has been adopted corresponding to a large carrying capacity of insects supported by the weeds population a couple of additional simulations have been reported in fig 5 for both α 0 1 and α 0 5 concerning values of λ and h 1 in the more confused region of the sensitivity surface in fig 6 a comparison of the sensitivity surfaces with respect to the two relevant parameters λ and h 1 has been carried out for α 0 1 and α 0 5 the value χ 0 001 has been kept sensitivity analysis has been carried out with respect to the same parameters in the whole intervals h 1 0 2 0 8 and λ 0 3 0 8 so to make evident the bifurcation of the qualitative behavior of the system with respect to these two parameters a more detailed description of the outcomes of the numerical simulations are reported in the paragraph below 3 3 numerical simulations simulations were performed using an own code based on the ode23s routine 230 of matlab 2007b on a hp zbook 14 g2 mobile workstation more specifically using the chosen set of parameter values the integration of the dynamical system 14 is performed for a long time until all the populations settle to a constant value so that a stable equilibrium is attained this allows the generation of the time series graphs of figs 3 4 5 further the final value of the integration is recorded for all the populations together with the combinations of h 1 and λ that have generated it the latter generate the grid that can be seen on the horizontal plane the population value is then used as the height of the surface corresponding while the parameter values are employed to identify the point in the domain on the horizontal plane with respect to which this height is assigned this process is repeated for all the values of the parameters h 1 and λ that appear in the range of the figure with a relatively small stepsize the matlab command surf allows to reconstruct the surface on the basis of the stored information giving the plots shown in fig 6 the results of the numerical simulations show that in the absence of any human intervention i e no weeds removal insects and weeds populations tends to a density level compatible with the assumed carrying capacity of the environment figs 3 and 4 cases b d f in this situation the canopy mass of olive trees experiences a dramatic decrease and seems to be doomed to extinction figs 3 and 4 cases b d with the exception of the case with highly resistant cultivar λ 0 3 where a coexistence of olive trees insects and weeds seems possible figs 3 and 4 case f the results of the performed numerical simulations clearly highlight that h 1 a is the threshold value for weeds removal independently of the resistance of the chosen cultivar if h 1 a the populations of insects and weeds rapidly decline while the olive tree population tends to a density level determined by the difference between the tree growth rate q and the tree pruning rate ℓ figs 3 and 4 cases a c e the resistance of the cultivar seems to have a lesser effect than the removal of the weeds if h 1 0 only highly resistant cultivars λ 0 3 allow the maintainance of the olive tree population figs 3 and 4 case f while combined with weeds removal an increase in the cultivar resistance allows a quicker recovery of the tree population figs 3 and 4 cases a c e the achieved results are compatible with the mathematical analysis performed in section 3 1 as a further support to the reliability of the qualitative behavior reported in figs 3 and 4 the numerical calculations of the jacobi matrices associated with system 14 are reported in the appendix for the two sample cases a and b of fig 4 showing that the equilibria emerged those cases have all negative eigenvalues which means the asymptotic stability of those equilibria under these circumstances the qualitative behavior of the system is independent of initial conditions in a suitable neighborhood of the relevant equilibria global stability requires further nontrivial analysis 3 4 sensitivity analysis sensitivity surfaces fig 6 highlight similar results the threshold effect for h 1 a is extremely apparent in the graph concerning the olive tree population n if h 1 a values of n tend to zero while if h 1 a values of n tend to a new carrying capacity of the olive tree plantations which is approximately half of the assumed carrying capacity 200 400 trees ha supporting the extensification of olive orchards sensitivity surfaces also show the effect of the resistance of the cultivar in particular a nontrivial equilibrium is possible even for less resistant cultivar in presence of a higher level of infected trees recovery rate α 0 5 fig 6 right column 4 conclusions our results although preliminary show that a couple of possible equilibria have been identified for the system studied here further nontrivial analysis would be required for finding additional feasible equilibria and for their stability analysis results of numerical simulations have identified the key components of this plants insect bacterium epidemic system that have to be considered as possible targets for farsighted biocontrol strategies moreover the most promising target for an effective and cost efficient control of the x fastidiosa epidemic is represented by agricultural management practices consisting of the partial removal of the weeds within and in the surroundings of olive orchards a further interesting strategy as expected is represented by the use of more resistant cultivar besides the economic effort required to replace olive trees this strategy has a severe impact on the farm productivity and economy due to the low production of new plantations during the first years although mathematically rather simplified the model presented here and the performed analyses have highlighted the crucial role of weeds removal and choice of the olive cultivar in the control of a x fastidiosa epidemic in a typical mediterranean agroecosystem such as southern apulia italy instead of destroying the productive resources by paraphrasing the case of a human disease anyone would agree that control strategies would not include the killing of human beings as we propose in this paper it should be preferable to act on the environment instead in order to control and possibly eradicate the disease see e g aniţa and capasso 2010 capasso and kunisch 1988 capasso 2009 and references therein our complete research plan includes the extension of our ordinary differential ode model to partial differential pde systems which take into account additional relevant features of the epidemic system such as a spatial structure and a time structure i e the insect life cycle and seasonality primary goal of the research will then be the analysis of possible control strategies such as weeds cut insect traps treated nets for optimal control problems relevant participating costs need to be included e g production losses and management costs validation of the model proposed here represents a key issue although we have tried to render explicit the assumptions underlying our model the latter has not yet been validated by comparison with experimental data therefore we caution that it is far from being conclusive for x fastidiosa subsp pauca p spumarius olive tree epidemics however it is desirable that with additional features that make it more realistic and combined with efficient numerical methods our model might provide the foundations for designing optimal control strategies by public authorities as an additional non trivial remark it has to be noticed that the mathematical quantitative approach has revealed the lack of adequate experimental data concerning the unknown parameters mainly related to the insect biology reported in table 3 for the reported simulations only some numerical values have been found for the parameters highlighting the need to perform in vivo experiments to obtain the unknown ones model driven experiments based on the current knowledge the above analysis and numerical simulations make it advisable that competent public authorities e g regional agriculture directorates and national phytosanitary service have to impose the implementation of good practices such as weeds control even the removal of a small proportion of weeds can have a dramatic effect in the collapse of p spumarius populations in all areas already invested by the disease and in those adjacent to them cleaning tools for human activities is recommended as an additional prevention strategy declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the research of e v has been partially supported by the project metodi numerici e computazionali per le scienze applicate of the dipartimento di matematica giuseppe peano ev is a member of the indam research group gncs vc and ev are members of cimab the italian national research network on mathematics for biology environment medicine etc part of the work of ev was carried out during a stay at the banff international research station whose support is kindly acknowledged in the framework of the program new mathematical methods for complex systems in ecology thanks are due to the editor of the journal and to the anonymous reviewers for their valuable comments and suggestions which have led to a significant improvement of the manuscript appendix a information about the stability of the equilibria detected by the numerical simulations can be obtained by the sign of the eigenvalues of the jacobi matrix associated with system 14 evaluated at the relevant equilibrium points if we denote by z the vector u f x n w m and the right hand side of system 14 by the vector function 27 f z m 1 u β 1 x γ 1 w u f r m χ f n x q μ b ℓ 1 x λ 1 u f α 1 x n q x ℓ n c μ 1 x a 1 w w δ 1 w η 1 u f m a m c 2 δ 1 w h 1 the jacobi matrix of f at a point z is given by 28 j f z f i z j 1 i j 6 below we report two sample cases concerning the equilibria detected in the numerical computations a0 1 figure 4 case a equilibrium values u 1 0 f 0 0 x 1 n 49 0 w 1 0 m 0 0 29 j f a z 2 98 10 11 0 0 75 0 0 10 0 01 0 0 98 0 0 0 0 0 3 36 10 5 1 90 0 0 0 0 0 68 60 0 49 0 0 0 4 20 10 6 0 0 0 5 0 0 0 0 0 0 0 1 eigenvalues 1 90 0 98 0 50 0 49 0 10 2 98 10 11 a0 2 figure 4 case b equilibrium values u 1 0 f 2 175196 10 05 x 0 27 n 0 w 0 59 m 217 52 30 j f b 43505 49 0 0 75 0 0 10 0 0 43503 92 0 0 0 43503926 79 47611 23 0 2 21 0 0 0 0 0 0 0 53 0 0 12781 95 0 0 0 0 63 0 0 0 0 0 43 50 0 22 eigenvalues 43506 34 43503 92 1 42 0 57 0 53 0 22 in both cases the computed eigenvalues are strictly less than zero so that we may claim that both equilibria are locally stable 
24779,mathematical models represent essential tools allowing a quantitative analysis of an epidemic system with the consequent identification of possible strategies to control a disease outbreak or even to prevent it however to be used in decision making they must be carefully parametrized and validated with epidemiological data as well as biological information on the relevant players here benefitting of the olive quick decline syndrome oqds outbreak which has occurred in southern italy since 2013 an epidemiological model describing this epidemic is presented beside the bacterium xylella fastidiosa the oqds main players considered in the model are its insect vectors philaenus spumarius and the host plants olive trees and weeds of the insects and of the bacterium the model is based on a system of ordinary differential equations the analysis of which have provided interesting results about possible equilibria of the epidemic system and guidelines for its numerical simulations these under a variety of parameter scenarios have led to the model sensitivity analysis hence to understanding the parameters relative importance in the transmission of the disease although the model presented here is mathematically rather simplified its analysis has highlighted threshold parameters that could be the target of control strategies within the integrated pest management framework not requiring the removal of the productive resource represented by the olive trees indeed numerical simulations support the outcomes of the mathematical analysis according to which a removal of a suitable amount of weeds biomass reservoir of xylella fastidiosa from olive orchards and surrounding areas resulted the most efficient strategy to control the spread of the oqds in addition as expected the adoption of more resistant olive tree cultivars has been shown to be a good strategy though less cost effective in controlling the pathogen keywords xylella fastidiosa olive trees epidemics mathematical model numerical simulations control strategies 2010 msc 34 xx 34cxx 37n25 92dxx 92d30 92c80 1 introduction xylella fastidiosa wells et al 1987 the causative agent of numerous important plant diseases janse and obradovic 2010 is a quarantine gram negative bacterium efsa 2015 transmitted by xylem fluid feeding hemiptera cicadomorpha belonging to the families cicadellidae aphrophoridae and clastopteridae janse and obradovic 2010 redak et al 2004 until recent years this bacterial pathogen associated with about 50 insect vectors has been reported in the american continent india turkey taiwan iran and lebanon amanifar et al 2014 güldür et al 2005 janse and obradovic 2010 jindal and sharma 1987 leu and su 1993 temsah et al 2015 within europe even though the first report of pierce s disease symptoms in grapevines have been reported in the mid of 1980s berisha unpublished the presence of x fastidiosa in this area was confirmed almost ten years later on grapevine of kosovo berisha et al 1998 however the exact location of infected samples was unknown in 2011 the bacterium has been intercepted in france but all further surveys failed to detect its presence in the country anses 2012 until 2015 in 2013 x fastidiosa subsp pauca isolate ol g2 hereafter only xylella fastidiosa has resulted infesting a wide area of olive tree plantations oleander and almond in apulia italy causing the olive quick decline syndrome oqds saponari et al 2013 in this region x fastidiosa subsp pauca st53 was recorded in different insect vectors the meadow spittlebug philaenus spumarius linnaeus 1758 neophilaenus campestris falln 1805 hemiptera aphrophoridae euscelis lineolatus brull 1832 hemiptera cicadellidae cariddi et al 2014 carlucci et al 2013 elbeaino et al 2014 saponari et al 2014 the first species of the list represents the main insect vector of the bacterium in southern italy philaenus spumarius nymphs develop on herbaceous vegetation represented by weeds or ornamental plants confined in an own produced foam for protection from predators and maintenance of temperature and moisture adults soon after their appearance move to the tree canopies experiments have shown a larger infection prevalence of adults on olive trees than on weeds even if the possibility that weeds represent a reservoir of the bacterium cannot be excluded cornara 2017 xylella fastidiosa transmission can be summarized by four events see almeida et al 2005 redak et al 2004 and references therein a acquisition from a source plant b attachment and retention to vector s foregut c inoculation into a new host d development of the infection in a plant after inoculation once a plant is infected bacteria multiply within the xylem vessels resulting in the formation of microfilm which occludes the xylem vessels thus inhibiting the flux of water through the lymph vessels eventually blocking the nutrition of the plant typical symptoms are leaf scorch dieback of twigs branches and even of the whole plant carlucci et al 2013 the eradication of infected trees and uninfected trees in their neighborhood causes serious social and economic drawbacks so alternative management strategies are needed the mathematical modelling of vector plant pathogen dynamics within the agroecosystem of olive orchards such as those in apulian region may help in the identification of key points to formulate possible control strategies a recent study adopting a quantitative lattice model for the infection spreading has shown that the numbers of vectors and trees are the most relevant parameters controlling the infection fierro et al 2019 more specifically they have proposed an interesting simulation tool without performing analytical studies of its qualitative behaviour the choice of this work instead has been to adopt a dynamical model based on systems of ordinary differential equations ode s because of their convenience for the analysis of optimal control problems see e g capasso 2009 arnăutu et al 2011 aniţa et al 2019 and references therein here a mathematical model is presented that could be adopted in an integrated pest management framework to suggest eradication or optimal control strategies against x fastidiosa epidemics we propose and analyze an oversimplified ode system describing the evolution of the populations of the three key players involved in the epidemic process i e olive trees insects weeds for the time being we have adopted a model which ignores both the life cycle of the insects and the spatial structure of the system model reduction is anyhow a must considering that holistic models cannot be treated in a mathematically rigorous way because of analytical unaffordability still we have included the essential features of a real vector plant pathogen system the plan of the paper is the following one in section 2 1 the relevant variables are introduced in paragraphs 2 1 1 2 1 2 2 1 3 the mathematical model is proposed as a system of ordinary differential equations ode s in paragraph 3 2 the relevant parameter values are presented on which numerical simulations have been carried out section 3 1 is devoted to the qualitative analysis of the epidemic system it has driven in section 3 3 some numerical simulations of the system and the sensitivity analysis of the model to relevant parameters concluding remarks and future research plans are reported in section 4 2 materials and methods 2 1 background of the model a detailed model including all the insect stages and their sexual differences would lead to a rather complex model from the mathematical point of view hence a substantial model reduction has been adopted including what can be considered the most significant features of the dynamics of a real epidemic system with respect to possible optimal control strategies a remarkable representation of the concept of model reduction has been offered by picasso https www dailyartmagazine com pablo picasso bulls road simplicity accordingly only the following components have been considered first of all the feeding behaviours and metabolic processes are qualitatively similar for nymphs and adult insects with the only exception that the former feed on herbaceous plants weeds and the latter on shrubs and trees therefore both nymphs and adults are possible active vectors of the infection janse and obradovic 2010 the different developmental stages of the insect eggs nymphs adults should be considered but due to the ensuing mathematical complexity in this paper the whole insect life cycle has been considered as consisting of one metastage a recent study on modelling insect life cycles can be found in rossini et al 2019 we will also ignore the difference between males and females the individuals of the insect population will be denoted by a if healthy and by v if infected the populations of susceptible and infected trees will be respectively denoted by s and i see table 1 in the environment there are other herbaceous and arbustive plants here named as weeds that may constitute a reservoir for the bacterial pathogen x fastidiosa the number of healthy weeds will be denoted by p while q stands for the infected ones finally we might consider populations of natural predators of the x fastidiosa insect vector but for the time being this case will be ignored see e g bruzzone et al 2018 and bautista et al 2019 all the parameters in the model are non negative quantities 2 1 1 the mathematical model dynamics of insects the equation for the susceptible insects within the population will contain the reproduction term for which they are born healthy at rate r from the existing adult females of the population due to the fact that bacteria reside only in the foregut of an adult insect the latter generate only healthy offspring see e g almeida et al 2005 redak et al 2004 and references therein the development of nymphs and their molting on adults however require weeds in the environment either healthy or infected this has been expressed by the dependence here assumed to be linear of the birth rate upon the total weeds population by taking these facts into account the evolution equation of the two insect subpopulations are the following ones 1 d a d t r a v p q r χ a a v n p q s i a β i s i a γ q p q a d v d t n p q s i v r χ v a v β i s i a γ q p q a the production of healthy insects has been modeled as 2 r a v p q χ a where a logistic term p q χ a has been introduced this means that the total population of weeds p q acts as carrying capacity for the insects where χ is a tuning parameter in the second equation above concerning infected insects the logistic term is 3 r a v χ v insects experience a natural mortality n p q s i which depends on the availability of their resources represented by trees and plants both healthy and infected as an additional simplification we will consider a constant mortality rate n susceptible insects may become infected by feeding on infected trees or plants we assume that the insects infection rate is a linear function of the relative abundances with respect to their respective total populations of both trees and weeds via the parameters β and γ respectively see e g capasso 2009 i e 4 β i s i γ q p q a in the light of the aforementioned simplifications system 1 becomes 5 d a d t r a v p q r χ a a v n a β i s i a γ q p q a d v d t n v r χ v a v β i s i a γ q p q a 2 1 2 the mathematical model dynamics of olive trees for the olive trees it is better to refer to their canopies so that we may consider pruning and regrowth the dynamics of olive trees is described by the following two equations 6 d s d t q s i c s ℓ s λ v s b ℓ i i s s α i d i d t s i c i λ v s μ i ℓ i b ℓ i i s s α i healthy trees canopy s are produced by regrowth or additional planting the production of healthy trees has been described by a logistic growth model 7 q s i c s where q is the natural constant growth rate and the logistic term s i c takes into account a possible carrying capacity c correspondingly in the second equation concerning infected trees a logistic term s i c i has been included for trees in view of their long survival we can neglect natural mortality but we will consider a constant decay rate ℓ due to the regular pruning or possible elimination logging canopies of infected trees i experience a disease related extra mortality μ a possible recovery of trees might be considered at a constant rate α trees get infected by contact with infected adult insects or by human activities such as pruning budding and grafting as far as the incidence rate due to infected insects is concerned we have assumed the form see dietz 1982 8 λ g a v v a v s where g a v denotes the contact rate of trees with the total population of insects the parameter λ is strictly related to a specific cultivar this means that we are assuming that the probability for a tree to acquire the infection upon a contact with insects is proportional to the frequency of infected insects with respect to their total population we have assumed g a v a v which leads to the simplification 9 λ v s the incidence rate due to human activities has been considered proportional to the relative abundance of infected trees with respect to their total mass given ℓ the rate of contacts with tools employed for human activities we have 10 b ℓ i i s s 2 1 3 the mathematical model dynamics of weeds the dynamics of the weeds mass is described by the following two equations 11 d p d t a p c 2 p q η v p h p p q d q d t p q c 2 q η v p δ q h q p q as above logistic growth is assumed at net reproduction rate a and carrying capacity c 2 we assume that all weeds produce healthy ones for the infection rate of weeds we have made the same assumptions as for the olive trees so that the incidence rate for weeds is 12 η v p disease related mortality of weeds occurs at rate δ while hp and hq represent mass reduction due to human related activities later these terms will be used as control terms for the eventual eradication of the epidemic in the relevant habitat we may assume that they are linearly dependent on the size of the existing vegetation i e 13 h p p q h 1 p h q p q h 1 q the model presented above belongs to the so called class of ecoepidemic models see review venturino 2016 although predator prey or competing populations are not incorporated simulations were performed using an own code based on the ode23s routine 230 of matlab 2007b on a hp zbook 14 g2 mobile workstation 3 results and discussion 3 1 mathematical analysis for technical reasons we rephrase the system by introducing the following new variables see also table 1 the total number of insects f a v and the fractions of susceptibles u a f 1 and infectives z 1 u v f 1 the total canopy mass of olive trees n s i and the fractions of susceptibles x s n 1 and infectives y i n 1 we proceed similarly with the total weeds mass m p q and their susceptible w p m 1 and infective γ q m 1 fractions by observing that y 1 x and γ 1 w in terms of fractions our system becomes 14 d u d t r m 1 u β 1 x γ 1 w u d f d t f r m χ f n d x d t x q μ b ℓ 1 x λ 1 u f α 1 x d n d t n q x ℓ n c μ 1 x d w d t a 1 w w δ 1 w η 1 u f d m d t m a m c 2 δ 1 w h 1 system 14 incorporates different populations affected by disease two of them are interlinked since insects cannot reproduce without weeds we wish to explore the eventual behaviour of the relevant populations for large times first of all we may look for the possible existence of equilibria which can be obtained by solving the following system of equations 15 r m 1 u β 1 x γ 1 w u 0 16 f r m χ f n 0 17 x q μ b ℓ 1 x λ 1 u f α 1 x 0 18 n q x ℓ n c μ 1 x 0 19 a 1 w w δ 1 w η 1 u f 0 20 m a m c 2 δ 1 w h 1 0 now we explore some interesting features of the system which anticipate the outcomes of the numerical simulations and possibly lead to the identification of potentially weak points in the plant xylella insect system that could lead to the development of guidelines for the control of a xylella epidemic a more detailed analysis of the above system would have required nontrivial mathematical techniques that might have obscured relevant issues of practical interest a possible equilibrium is the trivial one 21 u f x n w m e q 0 u 0 0 1 0 1 0 which means absence of all populations a situation with no practical meaning we focus on the total populations i e on equations 16 18 and 20 equation 16 for the total populations of insects admits either the trivial solution f 1 e q 0 or the solution of 22 r m χ f n 0 if m m 1 e q 0 we have 23 r χ f n 0 which leads to an unfeasible value for f this shows that m e q 0 implies f e q 0 which is already an important consequence of the model on the other hand equation 20 admits either the trivial solution m 1 e q 0 or m 2 e q c 2 a h 1 δ 1 w c 2 a h 1 which can be feasible only for a h 1 for the parameters reported in table 3 c 2 10 c 1000 0 and h 1 0 0 i e no weeds cut we have m 2 e q a c 2 0 5 1000 0 500 0 instead with a weeds cutting h 1 a we may only have m 1 e q 0 and so only f 1 e q 0 equation 18 is self consistent it admits either the trivial solution n 1 e q 0 or the solution of q x 2 e q ℓ n 2 e q c μ 1 x 2 e q 0 i e 24 n 2 e q c q x 2 e q ℓ μ 1 x 2 e q from 24 we derive n 2 e q c q ℓ this is feasible only for q ℓ for the parameters reported in table 3 we have n 2 e q 49 0 altogether we have identified the following interesting results to possibly obtain a nontrivial steady state equilibrium for the olive trees we must have 25 q ℓ in order to eliminate the weeds and consequently to eradicate the insects we require 26 h 1 a unfortunately conditions 25 and 26 are only sufficient conditions they do not exclude the possible coexistence of insects and olive trees provided the insect population is not very large in this respect the numerical simulations elucidate the crucial role of the parameter χ let us anticipate that from equation 16 we may recognize the role of m χ as the effective carrying capacity of the insect population f for χ 1 χ 2 we have m χ 1 m χ 2 which implies for χ 1 a possibly larger population of insects hence a possibly larger infective insect population which may lead to a larger force of infection on olive trees thus making the possible coexistence of insects and trees unlikely it is more difficult to analyze the role of λ its magnitude is influenced by the resistance to infection of each olive tree cultivar i e by increasing the cultivar resistance to infection the value of λ decreases it appears in eq 17 which is indeed more difficult to analyze independently of the other equations in the system anyhow the numerical simulations highlight its role additional comments are postponed to section 3 3 3 2 parameter values the species p spumarius can be attributed to the r selection reproductive strategy with a one year life cycle so almost all the adults die during the winter season supported by weaver and king 1954 see also whittaker 1973 for this reason assuming that a really small proportion of the adults can survive to the next year a value of 0 98 0 95 0 99 is reasonable for the parameter n the weeds growth rate a is a highly variable parameter since within the weeds category are included both grass and shrubs that are characterized by different overwintering strategies and thus having different growth rates spanning from 100 renewal of epigeal apparatus e g convolvolus sp to only a small fraction of it e g nerium oleander for the previous reason several values in the range 0 1 1 0 have been tested regarding the infected trees recovery rate α no data are present in the literature concerning oqds in order to test the influence of this parameter on the results of the model two different scenarios have been hypothesized the first one α 0 1 is considered the more reliable corresponding to a recovery of 10 of the infected trees due to the application of phytosanitary practices the second one with α 0 5 is considered less realistic the pruning of the olive trees in the infected area is usually carried out every 2 3 years bollettino ufficiale della regione puglia 2016 and implies a removal of about 15 20 of the biomass mostly constituted by wood that cannot be used by the insect as a food resource so a loss of an average of 5 10 of the total biomass each year has been assumed as a reliable value as a consequence the biomass suitable to sustain the insect growth is reduced by about 1 ℓ 0 01 as carrying capacity of olive trees c a value of 100 has been assigned as a reference unitary value in order to obtain a reliable estimate of the weed s carrying capacity we have considered previous studies where by using the sweep net as collecting tool a range of 4 40 adults were collected on weeds weaver and king 1954 while only 0 4 0 7 adults were collected on olive trees cornara 2017 so the carrying capacity of weeds should be about 10 100 times the one of olive trees considering the difference between the environment studied in weaver and king 1954 with respect to the olive orchard we have adopted a more conservative ratio corresponding to c 2 10 c in all the cases in which different values of the parameters have been tested those highlighted above in the text as well as the insect intraspecific competition rate χ the output of the model resulted to be mostly unaffected the main aim of the numerical simulations has been to investigate the long term behavior of our system on the basis of the qualitative analysis carried out in section 3 1 as expected the numerical simulations show that the system tends to an eventual equilibrium for all species independently of the initial conditions since the life cycle of p spumarius from egg to adult has a duration of one year we have chosen the year as the symbolic time unit to assign the numerical values to the parameters listed in table 3 to pursue the aim of this study we focused on possible targets of agronomic management here they are represented by the following two parameters i the weeds elimination rate by human intervention h 1 and ii the trees infection rate by infected insects λ agronomic practice has shown a significant dependence of this parameter upon the olive cultivar for the previous reasons for fixed values of the other parameters as from table 3 we performed simulations for testing the behavior of the epidemic system with respect to these two parameters in fig 3 4 numerical results are plotted for the following selections λ 0 8 0 5 0 3 describing an increase of the resistance of the olive tree h 1 0 0 0 4 describing two possible control scenarios the first one with no weeds cut and the second one with a cut intensity above the value of the weeds reproduction parameter a 0 3 in fig 3 the value α 0 1 has been chosen while in fig 4 α 0 5 regarding χ in both figures the value of 0 001 has been adopted corresponding to a large carrying capacity of insects supported by the weeds population a couple of additional simulations have been reported in fig 5 for both α 0 1 and α 0 5 concerning values of λ and h 1 in the more confused region of the sensitivity surface in fig 6 a comparison of the sensitivity surfaces with respect to the two relevant parameters λ and h 1 has been carried out for α 0 1 and α 0 5 the value χ 0 001 has been kept sensitivity analysis has been carried out with respect to the same parameters in the whole intervals h 1 0 2 0 8 and λ 0 3 0 8 so to make evident the bifurcation of the qualitative behavior of the system with respect to these two parameters a more detailed description of the outcomes of the numerical simulations are reported in the paragraph below 3 3 numerical simulations simulations were performed using an own code based on the ode23s routine 230 of matlab 2007b on a hp zbook 14 g2 mobile workstation more specifically using the chosen set of parameter values the integration of the dynamical system 14 is performed for a long time until all the populations settle to a constant value so that a stable equilibrium is attained this allows the generation of the time series graphs of figs 3 4 5 further the final value of the integration is recorded for all the populations together with the combinations of h 1 and λ that have generated it the latter generate the grid that can be seen on the horizontal plane the population value is then used as the height of the surface corresponding while the parameter values are employed to identify the point in the domain on the horizontal plane with respect to which this height is assigned this process is repeated for all the values of the parameters h 1 and λ that appear in the range of the figure with a relatively small stepsize the matlab command surf allows to reconstruct the surface on the basis of the stored information giving the plots shown in fig 6 the results of the numerical simulations show that in the absence of any human intervention i e no weeds removal insects and weeds populations tends to a density level compatible with the assumed carrying capacity of the environment figs 3 and 4 cases b d f in this situation the canopy mass of olive trees experiences a dramatic decrease and seems to be doomed to extinction figs 3 and 4 cases b d with the exception of the case with highly resistant cultivar λ 0 3 where a coexistence of olive trees insects and weeds seems possible figs 3 and 4 case f the results of the performed numerical simulations clearly highlight that h 1 a is the threshold value for weeds removal independently of the resistance of the chosen cultivar if h 1 a the populations of insects and weeds rapidly decline while the olive tree population tends to a density level determined by the difference between the tree growth rate q and the tree pruning rate ℓ figs 3 and 4 cases a c e the resistance of the cultivar seems to have a lesser effect than the removal of the weeds if h 1 0 only highly resistant cultivars λ 0 3 allow the maintainance of the olive tree population figs 3 and 4 case f while combined with weeds removal an increase in the cultivar resistance allows a quicker recovery of the tree population figs 3 and 4 cases a c e the achieved results are compatible with the mathematical analysis performed in section 3 1 as a further support to the reliability of the qualitative behavior reported in figs 3 and 4 the numerical calculations of the jacobi matrices associated with system 14 are reported in the appendix for the two sample cases a and b of fig 4 showing that the equilibria emerged those cases have all negative eigenvalues which means the asymptotic stability of those equilibria under these circumstances the qualitative behavior of the system is independent of initial conditions in a suitable neighborhood of the relevant equilibria global stability requires further nontrivial analysis 3 4 sensitivity analysis sensitivity surfaces fig 6 highlight similar results the threshold effect for h 1 a is extremely apparent in the graph concerning the olive tree population n if h 1 a values of n tend to zero while if h 1 a values of n tend to a new carrying capacity of the olive tree plantations which is approximately half of the assumed carrying capacity 200 400 trees ha supporting the extensification of olive orchards sensitivity surfaces also show the effect of the resistance of the cultivar in particular a nontrivial equilibrium is possible even for less resistant cultivar in presence of a higher level of infected trees recovery rate α 0 5 fig 6 right column 4 conclusions our results although preliminary show that a couple of possible equilibria have been identified for the system studied here further nontrivial analysis would be required for finding additional feasible equilibria and for their stability analysis results of numerical simulations have identified the key components of this plants insect bacterium epidemic system that have to be considered as possible targets for farsighted biocontrol strategies moreover the most promising target for an effective and cost efficient control of the x fastidiosa epidemic is represented by agricultural management practices consisting of the partial removal of the weeds within and in the surroundings of olive orchards a further interesting strategy as expected is represented by the use of more resistant cultivar besides the economic effort required to replace olive trees this strategy has a severe impact on the farm productivity and economy due to the low production of new plantations during the first years although mathematically rather simplified the model presented here and the performed analyses have highlighted the crucial role of weeds removal and choice of the olive cultivar in the control of a x fastidiosa epidemic in a typical mediterranean agroecosystem such as southern apulia italy instead of destroying the productive resources by paraphrasing the case of a human disease anyone would agree that control strategies would not include the killing of human beings as we propose in this paper it should be preferable to act on the environment instead in order to control and possibly eradicate the disease see e g aniţa and capasso 2010 capasso and kunisch 1988 capasso 2009 and references therein our complete research plan includes the extension of our ordinary differential ode model to partial differential pde systems which take into account additional relevant features of the epidemic system such as a spatial structure and a time structure i e the insect life cycle and seasonality primary goal of the research will then be the analysis of possible control strategies such as weeds cut insect traps treated nets for optimal control problems relevant participating costs need to be included e g production losses and management costs validation of the model proposed here represents a key issue although we have tried to render explicit the assumptions underlying our model the latter has not yet been validated by comparison with experimental data therefore we caution that it is far from being conclusive for x fastidiosa subsp pauca p spumarius olive tree epidemics however it is desirable that with additional features that make it more realistic and combined with efficient numerical methods our model might provide the foundations for designing optimal control strategies by public authorities as an additional non trivial remark it has to be noticed that the mathematical quantitative approach has revealed the lack of adequate experimental data concerning the unknown parameters mainly related to the insect biology reported in table 3 for the reported simulations only some numerical values have been found for the parameters highlighting the need to perform in vivo experiments to obtain the unknown ones model driven experiments based on the current knowledge the above analysis and numerical simulations make it advisable that competent public authorities e g regional agriculture directorates and national phytosanitary service have to impose the implementation of good practices such as weeds control even the removal of a small proportion of weeds can have a dramatic effect in the collapse of p spumarius populations in all areas already invested by the disease and in those adjacent to them cleaning tools for human activities is recommended as an additional prevention strategy declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the research of e v has been partially supported by the project metodi numerici e computazionali per le scienze applicate of the dipartimento di matematica giuseppe peano ev is a member of the indam research group gncs vc and ev are members of cimab the italian national research network on mathematics for biology environment medicine etc part of the work of ev was carried out during a stay at the banff international research station whose support is kindly acknowledged in the framework of the program new mathematical methods for complex systems in ecology thanks are due to the editor of the journal and to the anonymous reviewers for their valuable comments and suggestions which have led to a significant improvement of the manuscript appendix a information about the stability of the equilibria detected by the numerical simulations can be obtained by the sign of the eigenvalues of the jacobi matrix associated with system 14 evaluated at the relevant equilibrium points if we denote by z the vector u f x n w m and the right hand side of system 14 by the vector function 27 f z m 1 u β 1 x γ 1 w u f r m χ f n x q μ b ℓ 1 x λ 1 u f α 1 x n q x ℓ n c μ 1 x a 1 w w δ 1 w η 1 u f m a m c 2 δ 1 w h 1 the jacobi matrix of f at a point z is given by 28 j f z f i z j 1 i j 6 below we report two sample cases concerning the equilibria detected in the numerical computations a0 1 figure 4 case a equilibrium values u 1 0 f 0 0 x 1 n 49 0 w 1 0 m 0 0 29 j f a z 2 98 10 11 0 0 75 0 0 10 0 01 0 0 98 0 0 0 0 0 3 36 10 5 1 90 0 0 0 0 0 68 60 0 49 0 0 0 4 20 10 6 0 0 0 5 0 0 0 0 0 0 0 1 eigenvalues 1 90 0 98 0 50 0 49 0 10 2 98 10 11 a0 2 figure 4 case b equilibrium values u 1 0 f 2 175196 10 05 x 0 27 n 0 w 0 59 m 217 52 30 j f b 43505 49 0 0 75 0 0 10 0 0 43503 92 0 0 0 43503926 79 47611 23 0 2 21 0 0 0 0 0 0 0 53 0 0 12781 95 0 0 0 0 63 0 0 0 0 0 43 50 0 22 eigenvalues 43506 34 43503 92 1 42 0 57 0 53 0 22 in both cases the computed eigenvalues are strictly less than zero so that we may claim that both equilibria are locally stable 
