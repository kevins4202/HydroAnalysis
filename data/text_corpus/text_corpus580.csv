index,text
2900,data driven hydrological models are widely used for many practical purposes however the reliability of such models depend heavily on the strategy used to partition available observations into model calibration and evaluation subsets unfortunately available data splitting methods are poor at ensuring consistency of statistical properties between different subsets resulting in considerable bias and or inconsistency in evaluation performance as well as poor generalization ability to address this problem we propose and test two new data splitting methods applied to hydrological models that do not consider time dependent structure the somplex approach uses a self organizing map to analytically cluster the data based on its distributional properties after which a portion of each cluster is allocated to the calibration and evaluation subsets using the previously developed duplex method in the mduplex approach rather than clustering the data the duplex allocation strategy is modified to better maintain statistical similarity of the data subsets when tested using a data driven rainfall runoff modelling study applied to 754 catchments the new methods were significantly better at splitting the data into subsets with similar statistical properties however performance of different methods was found to depend strongly on the skewness of the streamflow data based on which we present practical recommendations regarding which method to use in different circumstances since the task of partitioning the data into mutually consistent statistically subsets is generic these concepts are broadly applicable to many hydrological models where time dependency of hydro climatic data can be ignored ranging from physics based to data driven including machine learning keywords hydrological models data splitting model calibration data driven models machine learning ann data availability data will be made available on request 1 introduction hydrological models are used for a wide range of purposes including to predict catchment runoff and water resource availability estimate the risks of floods and droughts and assess the impacts of climate change chilkoti et al 2017 kang sridhar 2017 luo et al 2018 najafi moradkhani 2015 osman et al 2017 partington et al 2022 yang et al 2019 when attempting to model the spatio temporal process complexity associated with hydrological systems it becomes necessary for the data to characterize catchment heterogeneity at progressively finer resolutions hrachowitz et al 2013 however the available data are rarely sufficient to suitably satisfy this demand due to which the more parsimonious conceptual approach is often used for practical applications meanwhile fully data driven modeling approaches have been consistently shown to provide superior predictive performance best et al 2015 yang et al 2019 due in part to the fact that data driven approaches are not necessarily required to explicitly satisfy physically based constraints they have even been successfully used for hydrological prediction at very large scales where a single model can be simultaneously applied to multiple and even ungaged catchments gudmundsson seneviratne 2015 kratzert et al 2019 regardless of model type key steps of the model development process are model calibration and evaluation mount et al 2016 the calibration step is used for model development while the evaluation step is used to assess the quality of the calibrated model essentially the purpose of evaluation is to ensure that the model has not been over fitted to any particular vagaries of the calibration data coron et al 2012 fowler et al 2016 vaze et al 2010 and can therefore be expected to generalize well to new as of yet unseen data shen 2018 jiang et al 2020 iten et al 2020 therefore it is recommended practice to split the observed dataset into two separate subsets with one subset used for model development and the other subset used to provide an independent assessment of model performance in addition the calibration subset is often further partitioned into a training subset used for parameter estimation and a model selection subset used variously for structure selection and or other related operations such as hyper parameter tuning and stop training maier et al 2010 unfortunately there is a general lack of consistency in terminology used by different modeling communities accordingly to promote clarity of communication this paper will adopt the terminology of calibration to refer to parameter estimation tuning selection to refer to all other aspects of model development such as model architecture selection hyper parameter tuning and stop training etc and evaluation to refer to the process of testing the performance of the model on an independent data subset the data used for these different aspects of model development can play critical roles in defining the performance of a data driven hydrological model typically model development consists mainly of determining values for the model parameters and these calibrated parameter values generally tend to be biased towards better reproducing the hydrologic behaviors seen in the data subset used for that purpose the consequence is that we typically observe a deterioration in performance when the model is tested on a different data subset used for independent evaluation seibert van meerveld 2016 thirel et al 2015 an important reason for this is a lack of hydrological and or statistical consistency kleme≈° 1986 martinez and gupta 2011 guo et al 2020 between the two data subsets i e in statistical terms the two data sets do not have the same distributional properties for example if the data subset used for model development primarily represents wet conditions the calibration process can result in parameters that are well suited to reproducing system behaviors under wet conditions but that provide significantly biased simulations under dry conditions fowler et al 2020 vaze et al 2010 for data driven models the model structures are often determined by testing numerous structural possibilities accordingly the key issues that determine differences in performance obtained on model development and evaluation subsets of the data are a whether there is sufficient information in the calibration and selection subsets to effectively learn an appropriate model structure and corresponding parameter values zheng et al 2018 and b whether the calibration selection and evaluation data subsets are mutually statistically consistent in this regard zheng et al 2018 have shown that when a larger number of extreme events are included in the calibration subset its evaluation performance tends to be rated optimistically as being better than it objectively actually is this is because metric values computed under more extreme conditions the calibration subset will tend to be worse in magnitude than when computed under more normal conditions the evaluation subset due to the fact that hydrological models generally tend to perform less well under extreme conditions conversely if a larger number of extreme data points are assigned to the evaluation subset the resulting model evaluation tends to be rated pessimistically as being worse than it objectively actually is in both cases the underlying problem is the challenge of ensuring that the data assigned to subsets used for different purposes have similar distributions in recognition of this problem studies have proposed a variety of good practices to be followed when splitting the data into subsets however recommendations on how to split the data tend to be rather general such as maintaining similar hydro climatic conditions between subsets gibbs et al 2018 li et al 2012 and using large enough model development subsets for the model to experience the full range of hydro climatic conditions during calibration coron et al 2012 typically data driven models treat the system memory as being effectively finite represented using several lagged time steps of data galelli et al 2014 this allows the use of approaches where blocks of data can be sampled from different parts of the overall data set and presented to the training algorithm in random order in practice it has been found that various structured random sampling methods give better results than a pure random sampling approach bowden et al 2002 may et al 2010 wu et al 2013 however such studies have usually been based on a limited number of catchments and systematic assessments of the utility of different data splitting strategies over a wide range of hydro geo climatic conditions have been lacking to fill the aforementioned gap zheng et al 2018 reported on an initial large sample study that was explicitly designed to explore the impacts of data splitting they compared four formal data splitting strategies applied to data driven artificial neural network ann hydrological models using data from 754 catchments across australia and the united states the systematic sampling ss approach the deterministic duplex approach the self organizing map based neyman sampling sbss n approach and the self organizing map based proportional sampling sbss p approach in ss the data are ordered along the output variable dimension in increasing order and the calibration subset is formed by selection of every k th sample from a random starting point of the entire dataset the remaining data are allocated to the evaluation subset wu et al 2013 in duplex samples are drawn based on euclidean distances between the data points where the two points with the largest euclidean distance are assigned to the calibration subset and the next pair of points that are farthest apart in the remaining list is assigned to the evaluation subset may et al 2010 implementation of the stochastic sbss n and sbss p data splitting methods involves two steps may et al 2010 first the data are partitioned into clusters using a self organizing map som kohonen 1995 which considers the distances between data points next data for the calibration and evaluation subsets are obtained by sampling from each of these clusters in sbss p the sampling is carried out in proportion to the number of samples in each cluster in sbss n the sample allocation is increased for the cluster that contains a larger number of data points or where the data points within a cluster have a larger variance may et al 2010 the comprehensive analysis conducted by zheng et al 2018 indicates that different data splitting methods can consistently produce significantly different evaluation performance for different catchments and that the differences can be as large as 100 in root mean squared error rmse notably these differences can be most pronounced in catchments where the streamflow data distributions are more strongly skewed the main findings of zheng et al 2018 regarding the relative performance of the four data splitting methods are a sbss p based models showed the overall best expected performance in predicting runoff but with significant variability for different randomly generated splits b the duplex based approach tended to be pessimistic i e evaluation performance was underestimated but with no variability being a deterministic method and c sbss n and ss both tend to result in moderate to large predictions bias and moderate performance variability across different runs 11 in this paper we develop and test two new data splitting methods entitled somplex and mduplex that are specifically designed to address limitations of the data splitting methods mentioned above somplex is motivated by the fact that sbss tends to provide very good i e low bias close to the benchmarking value mean performance over multiple runs but with high variability across runs to simultaneously achieve both low bias and low variability the self organizing map som feature of sbss is used to analytically cluster the data based on its distributional properties this is followed by allocating a portion of each cluster to the calibration selection and evaluation subsets using the deterministic duplex method the alternative approach mduplex is motivated by the fact that although duplex is deterministic which makes it attractive for practical applications it consistently results in pessimistic evaluation performance accordingly mduplex is a modified version of duplex in which the data splitting strategy of the latter is modified by assigning a larger number of extreme data points to the calibration set in order to improve its performance the key contributions of this study include i development of two new data splitting methods for the development of data driven hydrological models ii a large sample assessment of these methods by applying general regression neural network grnn data driven models developed with data splits obtained using the two new and three existing data splitting methods to 754 catchments iii practical guidance on the most appropriate data splitting method to be applied based on the data properties i e skewness of the runoff data we use the grnn model architecture for this study this is because it has the advantage of not requiring continuous temporal sequences of inputs a key advantage when testing data splitting strategies further it also enables the development of large numbers of model possibilities due to its relatively simple model architecture that achieves comparable performance to more complex ann type alternatives li et al 2014 it is highlighted that the data driven model considered in this study does not consider time dependent structure of the hydro climatic data which has been often the case for many previous modelling studies e g may et al 2010 zheng et al 2018 overall the findings can be expected to be generally transferable to other data driven hydrological models e g ones based in machine learning where time dependency of hydro climatic data can be ignored since they all share the same need for data to be partitioned into several statistically representative subsets 2 data splitting methods it should be clearly stated at the outset that the purpose of the evaluation process developed in this paper is to assess the in sample performance of the model humphrey et al 2017 in other words the ability of the model to perform reliably under conditions similar to that corresponding to the data used for model calibration and evaluation performing well robustly under such conditions is clearly a pre requisite to being able to perform well under other out of sample conditions assessing the potential out of sample performance of a model is a separate and arguably more complex issue that is not well understood and is not the focus of this study possible ways to enable such analysis include the use of stress testing on models beyond the historical data razavi 2021 comparing the outputs of different models under truly out of sample predictions gleeson et al 2021 or incorporating physical knowledge into data driven models more specifically the aim of this study is to improve the model s in sample performance by evaluating two proposed splitting strategies that ensure that the data allocated to the calibration and evaluation sets have similar statistical properties the assumption is that a model exhibiting good in sample performance is more likely to be successful at predicting future scenarios than a model that has poor in sample performance in the data splitting methods proposed in this study the training selection and evaluation data subsets share an overlapping time horizon i e the data are randomly sampled throughout the entire time horizon while the use of time continuous and non overlapping data for model calibration and evaluation might be common practice for many hydrological studies tongal and booij 2018 razavi 2021 li et al 2022 such is not the case necessarily for data driven modeling in general in fact it is a typical requirement in data driven modelling that the data can be properly randomized may et al 2010 maier et al 2010 wu et al 2013 lee et al 2020 kahloot and ekler 2021 and it is arguably mainly in hydrology where this practice is not rigorously followed since the different input output vectors used by data driven models are treated as being independent whether the data are time continuous or not makes no difference in real world applications one reason why hydrological modeling studies often separate out a particular time continuous part of the data shen et al 2022 to be used for model evaluation is that a major concern is whether a model can be credibly used for the prediction of future hydrological events e g under non stationary conditions however the problem of guaranteeing future prediction capability under yet unseen hydrological conditions based on development using historical data arguably requires a much more reasoned approach than simply separating out a particular time continuous portion of the data first it is necessary to establish credibility in the ability of the model when tested under previously seen historical conditions and to achieve this goal it is important and necessary to ensure that the data used in both model development and evaluation are as fully representative as possible next it is important to be clear that assessing a model s performance under conditions that have not been represented in the data used for model development requires that a rather than choosing a particular time continuous part of the data one must establish a defensible procedure for selecting a testing period that has distinctly different hydrological conditions and b a meaningful procedure needs to be established for assessing model performance under these different hydrological conditions one now runs into an interesting conundrum if we do not use a fully representative data set for model development i e if we hold out some unusual events we are not providing access to the information necessary to maximize inference of the best possible model in such a case the model may or may not perform well under those new conditions and we cannot know whether this is due to a model structural inadequacy or insufficiently informative data during model development while it would be interesting to assess the extent to which a model trained on less than fully representative data can perform under unusual novel conditions existing in the current data set it is arguable whether this actually provides any degree of demonstrably real as opposed to subjective confidence in the capability of the model under yet unseen conditions in the absence of a philosophically and practically defensible strategy for establishing model credibility in the face of changing hydrological conditions we argue that a rational model development approach is to ensure that model development has access to a fully representative set of events drawn from the available observations thereby maximizing the possibility of robust model performance under typically observed conditions the data splitting methods discussed in this paper including the two existing methods detailed in this section and the two novel methods introduced in section 3 seek to do just that meanwhile assessing a model s credibility in regards to changing future conditions remains an important topic for ongoing investigation 2 1 random methods stratified sampling stratified sampling involves identifying distinct but homogeneous regions within the data and forcing the sampled subsets to include data from every stratum cochran 1977 the self organizing map som kohonen 1995 achieves a typical form of stratified sampling used in several recent data driven modelling applications wu et al 2013 zheng et al 2018 the som is a set of codebook vectors an array or map of weights in p dimensional space that is trained to learn a representation that best describes the p dimensional distribution of the data the data are assigned according to their nearest codebook vector which can then be projected onto a 2 dimensional map to achieve data subsets with similar statistical properties and are therefore representative of the data as a whole data must be selected from each and every map unit the sbss method tested by zheng et al 2018 uses som based stratified sampling sbss while this would appear to be an attractive option for data splitting in practice one has to contend with the fact that the sampling procedure can be sensitive to choice of som algorithm parameters and map size and therefore to the partitioning that results bowden et al 2002 further the best approach to sample from within the som map is not clear daszykowski et al 2002 to address these issues may et al 2010 proposed methods for selecting the size of the som and for determining the numbers of samples drawn from each som partition so as to minimize sample bias and variance nonetheless stratified random sampling is inherently random and performance variability is still typically observed albeit reduced in comparison to uniform random sampling 2 2 deterministic methods duplex approach kennard and stone 1969 developed the cadex and duplex data splitting algorithms for split sample evaluation of regression models cadex proceeds by first allocating the datum that lies farthest from all others to the first subset and allocating the next farthest one to the next subset and so on subsequent data are iteratively sampled one by one by identifying the datum that lies farthest from any previously selected points in the target set where the target set alternates duplex is a modified form of cadex in which data are selected in a pair wise manner i e two data points are assigned to the subset at once which can improve the statistical consistency of the resulting subsets snee 1977 duplex sampling is fully deterministic and only one split is possible for any given database resulting in zero sample variance while it is typically used to generate two subsets with a 50 50 split it is possible to generate splits of arbitrary proportional size by first allocating data to the smaller set until it is filled and then allocating all remaining data to the larger set snee 1977 zheng et al 2018 conducted a comprehensive analysis of the performance of these four well known formal data splitting methods sbss p sbb n duplex and ss on the development of data driven artificial neural network ann models of streamflow i e rainfall runoff ann models application of these four data splitting methods to 754 catchments with different properties resulted in 902 483 ann models thereby enabling rigorous statistical analysis resulting in the findings outlined in table 1 in summary each method exhibited strengths and weakness as characterized in terms of bias and variance indicating that none of them provides a satisfactory solution in the context of developing data driven rainfall runoff models 3 the two proposed data splitting methods here we develop two new data splitting methods the first entitled somplex is designed to overcome the problem of large variability associated with the sbss p method while retaining its superior performance with respect to bias the second entitled mduplex is designed to reduce the bias associated with the duplex method which has no variance since it involves deterministic allocation 3 1 the somplex algorithm somplex is a multi stage algorithm that combines som based clustering with duplex sampling of map units som clustering is used to identify distinct regions of the data space that can include both typical classes and examples of unique input output cases however overlooked by many data splitting applications is that the clusters may cover varying proportions of the database data can be non uniformly distributed within each partition and data in some partitions can be more widely spread than in others may et al 2010 due to which random sampling from within each cluster can be less than ideal conversely given any distribution of data duplex can generate a sample that uniformly covers the full range of the data snee 1977 by applying duplex to each som based partition representative samples can be generated from each partition regardless of the distribution within the partition the result is both robust and relatively insensitive to the partitioning that results from the som algorithm and since duplex is fully deterministic the result is free from sample variability pseudo code for the somplex algorithm is shown in fig 1 given a database d the algorithm generates calibration c selection s and evaluation e subsets as follows parameterization of the algorithm is discussed later in section 4 4 3 2 the mduplex algorithm duplex section 2 2 provides a mechanism for splitting the data in a deterministic manner a property that is attractive for practical applications however as discussed in section 2 6 it can result in significant bias when used in the context of evaluating the performance of data driven rainfall runoff models where the size of the calibration subset is typically larger than that of the evaluation subset under such circumstances duplex allocates a substantially larger number of normal less extreme data points to the larger calibration subset this biases the calibration towards normal events and causes the model to have relatively poor performance on extreme events resulting in pessimistic assessment of model evaluation performance to overcome this problem we propose a modified version of duplex called mduplex in which a multiple sampling strategy is used to generate the calibration selection and evaluation data subsets instead of the sampling process being carried out only once to generate the selection and evaluation subsets with all of the remaining data with small distances being assigned to the calibration subset the data are simultaneously allocated into all three subsets as indicated in fig 2 the benefit of this approach is that a larger number of extreme points data pairs with large distances can be assigned to the calibration subset than when using duplex resulting in better statistical similarity between the calibration selection and evaluation subsets 4 the simulation experiments 4 1 large catchment samples the proposed data splitting methods were tested in the context of developing data driven rainfall runoff models for 754 catchments including 322 from australia zhang and chiew 2009 and 432 from the us duan et al 2006 these catchments represent a wide diversity of catchment properties such as precipitation evaporation and catchment area data consist of daily rainfall and runoff observations recorded in millimeters per day mm day with record lengths varying from 10 to 40 years following zheng et al 2018 we use the first 10 years of available data for each catchment for this study due to the fact that these years are less likely to be affected by urbanization this choice also enables a fair comparison with the results obtained by zheng et al 2018 see table 1 skewness of the runoff data over these 10 year periods varies over a wide range of values from 1 12 to 52 03 and is consistent with that of the original complete dataset indicating that the 10 year subsets are representative of the entire datasets at least in terms of skewness for more details regarding the dataset see zheng et al 2018 4 2 the data driven model consistent with zheng et al 2018 we selected the general regression neural network grnn specht 1991 as the data driven model for this study reasons for this are that i grnns have a simple fixed model structure with only one tunable parameter so that issues related to model structure selection can be avoided consequently variations in model performance are only due to the choice of data ii use of grnns enables a fair comparison with the methods tested by zheng et al 2018 where the same modelling approach was used iii the relative simplicity of grnns facilitates computational feasibility of this study where very large numbers of models must be developed and evaluated iv grnns have been shown to provide comparable performance to more complex ann model architectures li et al 2014 for each catchment model inputs are rainfall and runoff data at various lagged time steps wu et al 2013 the most appropriate lags have previously been shown to depend on catchment properties such as area and slope and were determined by zheng et al 2018 based on a partial mutual information pmi analysis may et al 2008 li et al 2015 in each case consistent with previous work 80 of the data were used for model development 60 for calibration and 20 for selection and 20 for evaluation zheng et al 2018 may et al 2010 wu et al 2013 brent s method was used for estimation of the grnn model parameter press et al 1992 and the root mean squared error rmse was used as the performance metric for all stages of the study for each data splitting approach to ensure consistency with zheng et al 2018 we generated 100 different splits of each dataset training therefore results in a total of 150 800 grnn models for the 754 catchments performance results from the 100 splits are used to compute the bias and variance statistics for each catchment model for each data splitting method for comparison results for the sbss p sbb n duplex and ss methods are taken directly from zheng et al 2018 4 3 benchmarking performance of the models the approach of wu et al 2013 was used to determine the expected benchmarking model performance for each catchment this approach is based on the premise that allocation of any particular fraction of the available data to each of the two calibration and evaluation subsets results in an expected model error which is estimated as the average model error over all possible splits of the data for the given fractional allocation here 80 for model development 20 for evaluation this expected model error is generally larger than zero due to model structural inadequacies gupta et al 2012 observational errors and insufficient informativeness of the data if the model evaluation error is found to be larger than this expected error the assessment of model performance can be considered pessimistic and can be traced to assigning too many extreme data points to the evaluation subset conversely if the model evaluation error is found to be smaller than this expected error the assessment of model performance can be considered optimistic and can be traced to assigning an insufficient number of extreme data points to the evaluation subset because computing the expected model error requires evaluation of the performance of models developed for every possible data split the associated computational burden can be very large to circumvent this problem wu et al 2013 showed how the expected model error can be estimated using a sufficiently large number of random samples rather than all possible splits to within a specified level of accuracy and precision zheng et al 2018 have previously used this approach to estimate the benchmarking performance expected rmse values for grnn models on each of the 754 catchments used for our current study we therefore use those benchmarking results here to analyze model performance bias and variance 4 4 algorithm parameters for implementation of the somplex method the som was trained using the conventional som learning algorithm which involves two stages a short ordering phase during which weight adjustments are large followed by a longer tuning phase where adjustments are fine kohonen 1995 the som learning parameters used in this study are summarized in table 2 for full details of the som algorithm see kohonen 2013 an important aspect is a conscience mechanism that avoids the generation of large clusters and ensures that the distribution of data is as even as possible in contrast note that the mduplex algorithm is parameter free which increases its attractiveness for practical application 4 5 metrics used for assessing model performance to evaluate performance we used relative bias rb relative variance rv and relative estimation efficiency ree following zheng et al 2018 these are defined as follows 1 rb e m m m 100 2 rv v a r m m m 100 3 ree r b 2 r v where m is the evaluation subset rmse value for a particular catchment model and m is the benchmark performance rmse value for that catchment rb represents the expected model bias computed over multiple data splits 100 in this study rv represents the corresponding variability of the evaluation performance and ree accounts for both bias and variance 5 results and discussion 5 1 data splitting results first we compare results of the new somplex method with those of the previous sbss p for a particular catchment fig 3 the figure shows two typical data splits generated with different random seeds here for easy visualization we plot one input rainfall observations against the corresponding output runoff observations only the large extreme rainfall and runoff events are shown as these are more likely to have a significant effect on the model performance the figures show larger variation in the assignment of extreme events to the two subsets by sbss p for instance using sbss p none of the extreme events with runoff greater than 400 mm d were assigned to the evaluation set blue squares in one sbss p run fig 3 a while three such extreme events were assigned to the evaluation set for another run fig 3 c in contrast the somplex results are less variable as shown in fig 3 b d overall the distribution of extreme events assigned to the c s and e subsets is more similar for somplex than for sbss p in fig 4 we compare the results of the new mduplex method with those of the previously used duplex for a typical catchment the runoff probability density plot shows that of the two methods mduplex has assigned a larger number of extreme events large runoff values to the training set which means that fewer extreme events have been allocated to the evaluation set this assignment gives the model an opportunity to overcome the pessimistic model performance associated with duplex table 1 note also that the c s and e subset probability density distributions are more similar for mduplex than for duplex while we have presented illustrative results for only one catchment similar results were obtained for other catchments overall these results suggest that somplex and mduplex provide superior approaches to ensuring statistical similarity of data splits when selecting the calibration selection and evaluation subsets particularly in regard to the representation of extreme events 5 2 performance comparison box graphs of relative bias rb and relative variance rb for the evaluation results of the grnn models applied to the 754 catchments are shown in fig 5 results are shown for somplex and muplex as well as for the previously used sbss p duplex and ss methods as mentioned previously each method was applied 100 times because zheng et al 2018 reported that sbss n consistently exhibited poor performance table 1 we omit showing the corresponding results here the figure shows that the different methods achieved significantly different evaluation performance in terms of both relative bias rb and relative variance rv this clearly illustrates how the performance of the model can be significantly affected by the assignment of data into model development and evaluation subsets overall sbss p consistently results in the smallest relative bias over the 100 runs followed by somplex and mduplex fig 5a however the relative variability associated with the sbss p method is high due to the stochasticities associated with the approach although somplex achieves slightly worse relative bias than sbss p its relative variance is significantly lower fig 5b due to the use of the deterministic duplex method for sampling from the som clusters meanwhile mduplex exhibits lower relative bias than duplex although the distribution of rb values is wider than for somplex fig 5a since both these two methods are deterministic they display no variance fig 5b probability distributions of relative estimation efficiency ree are shown in fig 6 note that ree accounts for both bias and variance and smaller values are better so the ideal situation would be a distribution that peaks at the origin and has zero dispersion a delta function the distribution for mduplex blue dashed line peaks closer to zero and has relatively smaller dispersion followed by somplex red solid line the sbss p green dashed line and duplex black dash dot line methods provided the worst performance with distributions shifted more to the right in fig 7 we show evaluation performance scatterplots of simulated versus observed runoff for models calibrated using different data splitting methods results are shown for a typical catchment with moderate runoff skewness 10 3 also reported are the kge metric values gupta et al 2009 computed on the calibration including both training and selection and evaluation subsets the results indicate that use of somplex and mduplex data splits results in runoff simulations that agree well with observations as evidenced by relatively high kge values on both the calibration and evaluation subsets interestingly for somplex the performance variation between the calibration and evaluation subsets is lower than for the other methods we also present the probability density of the kge differences between the calibration and evaluation sets i e kge calib kge eval for each grnn model with six data splitting methods applied to the catchments as shown in fig 8 it is consistently shown that the kge values from the calibration data set are more likely to be larger than those from the evaluation set for each data splitting method this is expected as the model calibration performance tends to be better than the evaluation performance relatively the somplex method performs the best in terms of maintaining similar performance between the calibration and evaluation data this suggests that somplex performs well at ensuring the consistency of statistical properties between the model development and evaluation subsets while the mduplex method exhibited a slightly worse performance than the somplex ss and the sbss p approaches it shows an improved ability compared with duplex in maintaining similarity between calibration and evaluation performance 5 3 performance as a function of runoff data skewness in figs 9 and 10 we show rb and rv results for catchments with different ranges of runoff skewness it is clear from these plots that sbss p green consistently results in the smallest relative bias rb regardless of skewness but that relative variance over different data split realizations progressively increases with runoff skewness in comparison somplex red bias tends to increase negatively with increasing skewness but variance remains smaller than for the sbss p approach for duplex grey the results proceed from optimistic positive bias to pessimistic negative bias as skewness increases being deterministic variance is zero and this tendency is reflected in the somplex and duplex results since both are also based on the duplex methodology meanwhile mduplex blue consistently has lower relative bias than duplex both are deterministic with no variance in figs 11 and 12 we show how the average ranking of each of the data splitting methods sbss n is excluded varies with runoff skewness ranges in terms of relative bias rb and relative estimation efficiency ree respectively 1 indicates the best ranking as before sbss p green is consistently ranked best in terms of rb and worst in terms of ree in contrast mduplex has the best ree rank due to its low variance while maintaining a consistent moderate average pb rank across all skewness ranges meanwhile somplex ranks second best in terms of both rb and ree for data skewness smaller than 25 but performance deteriorates at higher values of skewness 5 4 analysis of variability while sbss p sbss n and somplex are stochastic the other methods are either semi deterministic or fully deterministic here we compare spss p and somplex in terms of relative variance we omit sbss n since previous results indicate that it performs worse than sbss p in terms of the rb rv and ree metrics fig 13 shows violin plots of percent relative bias rb for sbss p and somplex when applied to two typical catchments with different runoff skewness 10 3 and 36 9 respectively these plots were generated as follows the number n d of data splits was progressively varied from 5 to 90 and the appropriate number of rb values was sampled from the total 100 available rb values without replacement the mean of these n d values was recorded and the procedure repeated 100 times for each case to generate the distributions shown comparing the plots on the right to those on the left we see that somplex converges to very small variability at a faster rate with fewer data split repetitions than spbb p for both catchments similar results were observed for other catchments this result is clearly attributable to the use of the deterministic duplex strategy within the somplex methodology the practical and computational benefits of this are obvious 5 5 practical guidelines for selecting an appropriate data splitting method based on our experience with the large catchment sample study reported above fig 14 provides some guidance for an appropriate data splitting method as shown if as is common only a very low number of model calibration repetitions 1 2 data splits is feasible we recommend the use of mduplex due to its moderate bias and lack of variance if time and computational ability permit a moderate number of model calibration repetitions 10 50 data splits we recommend somplex for skewness below 25 and duplex for skewness above 25 if time and computation are not constrained we recommend sbss p as the best approach due to its consistently low bias regardless of runoff skewness the data splitting study reported in this paper takes advantage of the fact that data driven models treat the system memory as being effectively finite represented using several lagged time steps of data so that different parts of the data can be presented to the training algorithm in random order as such these methods are broadly applicable to the field of machine learning where the model development methods typically share this same property to assess performance users will need to establish suitable benchmarks according to their specific application 6 summary and conclusions based on an analysis of the strengths and limitations of some pre existing methods we have proposed and tested two new data splitting methods namely somplex and mduplex the former somplex is a multi stage algorithm that exploits the ability of soms to generate statistically representative data clusters and the ability of duplex to select and allocate data from each cluster the latter mduplex improves on the duplex strategy in a manner that is tailored to rainfall runoff modeling by assigning larger numbers of extreme events to the calibration subset compared with four previously reported methods we find that somplex exhibits significantly reduced sampling variance compared to sbss p while maintaining relatively low expected bias which makes it attractive for practical applications provided a moderate number of calibration repetitions can be performed mduplex improves over duplex by reducing the tendency to generate pessimistic performance overall mduplex provides consistently low ree regardless of runoff skewness which makes it the most appropriate method if only a very few calibration repetitions can be performed which is typical in engineering practice if time and computation are not limited sbss p provides the best expected performance regardless of data skewness it should be noted that this study has focused only on the strategy used for generating data splits and has been tested only in the context of data driven rainfall runoff modeling further work needs to be done to assess the impacts of different calibration selection and evaluation subset size ratios and or of different total amounts of data used for model development further the methods have been developed and tested in the context of data driven models for which strictly maintaining continuous temporal sequencing of data presented to the algorithms used for model development is not required in general the development of physically based and conceptual hydrological models where temporal data continuity is required can also be expected to be sensitive to the manner in which data is assigned to calibration and evaluation subsets guo et al 2020 and therefore methods that achieve proper data subsetting for such cases while preserving proper representativeness and consistency of the calibration and evaluation subsets need to be investigated see zheng et al 2022 as always we encourage and invite discussion and collaboration on these and related aspects of model development declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work is funded by the national natural science foundation of china 51922096 52179080 and excellent youth natural science foundation of zhejiang province china lr19e080003 we also gratefully acknowledge data for the 432 us catchments provided by dr thibault mathevet which can be also accessed through ftp hydrology nws noaa gov pub gcip mopex us data with details of this dataset given in http www nws noaa gov ohd mopex mo datasets htm data for australian catchments are given as supporting information of zheng et al 2018 which can be found at https agupubs onlinelibrary wiley com doi 10 1002 2017wr021470 
2900,data driven hydrological models are widely used for many practical purposes however the reliability of such models depend heavily on the strategy used to partition available observations into model calibration and evaluation subsets unfortunately available data splitting methods are poor at ensuring consistency of statistical properties between different subsets resulting in considerable bias and or inconsistency in evaluation performance as well as poor generalization ability to address this problem we propose and test two new data splitting methods applied to hydrological models that do not consider time dependent structure the somplex approach uses a self organizing map to analytically cluster the data based on its distributional properties after which a portion of each cluster is allocated to the calibration and evaluation subsets using the previously developed duplex method in the mduplex approach rather than clustering the data the duplex allocation strategy is modified to better maintain statistical similarity of the data subsets when tested using a data driven rainfall runoff modelling study applied to 754 catchments the new methods were significantly better at splitting the data into subsets with similar statistical properties however performance of different methods was found to depend strongly on the skewness of the streamflow data based on which we present practical recommendations regarding which method to use in different circumstances since the task of partitioning the data into mutually consistent statistically subsets is generic these concepts are broadly applicable to many hydrological models where time dependency of hydro climatic data can be ignored ranging from physics based to data driven including machine learning keywords hydrological models data splitting model calibration data driven models machine learning ann data availability data will be made available on request 1 introduction hydrological models are used for a wide range of purposes including to predict catchment runoff and water resource availability estimate the risks of floods and droughts and assess the impacts of climate change chilkoti et al 2017 kang sridhar 2017 luo et al 2018 najafi moradkhani 2015 osman et al 2017 partington et al 2022 yang et al 2019 when attempting to model the spatio temporal process complexity associated with hydrological systems it becomes necessary for the data to characterize catchment heterogeneity at progressively finer resolutions hrachowitz et al 2013 however the available data are rarely sufficient to suitably satisfy this demand due to which the more parsimonious conceptual approach is often used for practical applications meanwhile fully data driven modeling approaches have been consistently shown to provide superior predictive performance best et al 2015 yang et al 2019 due in part to the fact that data driven approaches are not necessarily required to explicitly satisfy physically based constraints they have even been successfully used for hydrological prediction at very large scales where a single model can be simultaneously applied to multiple and even ungaged catchments gudmundsson seneviratne 2015 kratzert et al 2019 regardless of model type key steps of the model development process are model calibration and evaluation mount et al 2016 the calibration step is used for model development while the evaluation step is used to assess the quality of the calibrated model essentially the purpose of evaluation is to ensure that the model has not been over fitted to any particular vagaries of the calibration data coron et al 2012 fowler et al 2016 vaze et al 2010 and can therefore be expected to generalize well to new as of yet unseen data shen 2018 jiang et al 2020 iten et al 2020 therefore it is recommended practice to split the observed dataset into two separate subsets with one subset used for model development and the other subset used to provide an independent assessment of model performance in addition the calibration subset is often further partitioned into a training subset used for parameter estimation and a model selection subset used variously for structure selection and or other related operations such as hyper parameter tuning and stop training maier et al 2010 unfortunately there is a general lack of consistency in terminology used by different modeling communities accordingly to promote clarity of communication this paper will adopt the terminology of calibration to refer to parameter estimation tuning selection to refer to all other aspects of model development such as model architecture selection hyper parameter tuning and stop training etc and evaluation to refer to the process of testing the performance of the model on an independent data subset the data used for these different aspects of model development can play critical roles in defining the performance of a data driven hydrological model typically model development consists mainly of determining values for the model parameters and these calibrated parameter values generally tend to be biased towards better reproducing the hydrologic behaviors seen in the data subset used for that purpose the consequence is that we typically observe a deterioration in performance when the model is tested on a different data subset used for independent evaluation seibert van meerveld 2016 thirel et al 2015 an important reason for this is a lack of hydrological and or statistical consistency kleme≈° 1986 martinez and gupta 2011 guo et al 2020 between the two data subsets i e in statistical terms the two data sets do not have the same distributional properties for example if the data subset used for model development primarily represents wet conditions the calibration process can result in parameters that are well suited to reproducing system behaviors under wet conditions but that provide significantly biased simulations under dry conditions fowler et al 2020 vaze et al 2010 for data driven models the model structures are often determined by testing numerous structural possibilities accordingly the key issues that determine differences in performance obtained on model development and evaluation subsets of the data are a whether there is sufficient information in the calibration and selection subsets to effectively learn an appropriate model structure and corresponding parameter values zheng et al 2018 and b whether the calibration selection and evaluation data subsets are mutually statistically consistent in this regard zheng et al 2018 have shown that when a larger number of extreme events are included in the calibration subset its evaluation performance tends to be rated optimistically as being better than it objectively actually is this is because metric values computed under more extreme conditions the calibration subset will tend to be worse in magnitude than when computed under more normal conditions the evaluation subset due to the fact that hydrological models generally tend to perform less well under extreme conditions conversely if a larger number of extreme data points are assigned to the evaluation subset the resulting model evaluation tends to be rated pessimistically as being worse than it objectively actually is in both cases the underlying problem is the challenge of ensuring that the data assigned to subsets used for different purposes have similar distributions in recognition of this problem studies have proposed a variety of good practices to be followed when splitting the data into subsets however recommendations on how to split the data tend to be rather general such as maintaining similar hydro climatic conditions between subsets gibbs et al 2018 li et al 2012 and using large enough model development subsets for the model to experience the full range of hydro climatic conditions during calibration coron et al 2012 typically data driven models treat the system memory as being effectively finite represented using several lagged time steps of data galelli et al 2014 this allows the use of approaches where blocks of data can be sampled from different parts of the overall data set and presented to the training algorithm in random order in practice it has been found that various structured random sampling methods give better results than a pure random sampling approach bowden et al 2002 may et al 2010 wu et al 2013 however such studies have usually been based on a limited number of catchments and systematic assessments of the utility of different data splitting strategies over a wide range of hydro geo climatic conditions have been lacking to fill the aforementioned gap zheng et al 2018 reported on an initial large sample study that was explicitly designed to explore the impacts of data splitting they compared four formal data splitting strategies applied to data driven artificial neural network ann hydrological models using data from 754 catchments across australia and the united states the systematic sampling ss approach the deterministic duplex approach the self organizing map based neyman sampling sbss n approach and the self organizing map based proportional sampling sbss p approach in ss the data are ordered along the output variable dimension in increasing order and the calibration subset is formed by selection of every k th sample from a random starting point of the entire dataset the remaining data are allocated to the evaluation subset wu et al 2013 in duplex samples are drawn based on euclidean distances between the data points where the two points with the largest euclidean distance are assigned to the calibration subset and the next pair of points that are farthest apart in the remaining list is assigned to the evaluation subset may et al 2010 implementation of the stochastic sbss n and sbss p data splitting methods involves two steps may et al 2010 first the data are partitioned into clusters using a self organizing map som kohonen 1995 which considers the distances between data points next data for the calibration and evaluation subsets are obtained by sampling from each of these clusters in sbss p the sampling is carried out in proportion to the number of samples in each cluster in sbss n the sample allocation is increased for the cluster that contains a larger number of data points or where the data points within a cluster have a larger variance may et al 2010 the comprehensive analysis conducted by zheng et al 2018 indicates that different data splitting methods can consistently produce significantly different evaluation performance for different catchments and that the differences can be as large as 100 in root mean squared error rmse notably these differences can be most pronounced in catchments where the streamflow data distributions are more strongly skewed the main findings of zheng et al 2018 regarding the relative performance of the four data splitting methods are a sbss p based models showed the overall best expected performance in predicting runoff but with significant variability for different randomly generated splits b the duplex based approach tended to be pessimistic i e evaluation performance was underestimated but with no variability being a deterministic method and c sbss n and ss both tend to result in moderate to large predictions bias and moderate performance variability across different runs 11 in this paper we develop and test two new data splitting methods entitled somplex and mduplex that are specifically designed to address limitations of the data splitting methods mentioned above somplex is motivated by the fact that sbss tends to provide very good i e low bias close to the benchmarking value mean performance over multiple runs but with high variability across runs to simultaneously achieve both low bias and low variability the self organizing map som feature of sbss is used to analytically cluster the data based on its distributional properties this is followed by allocating a portion of each cluster to the calibration selection and evaluation subsets using the deterministic duplex method the alternative approach mduplex is motivated by the fact that although duplex is deterministic which makes it attractive for practical applications it consistently results in pessimistic evaluation performance accordingly mduplex is a modified version of duplex in which the data splitting strategy of the latter is modified by assigning a larger number of extreme data points to the calibration set in order to improve its performance the key contributions of this study include i development of two new data splitting methods for the development of data driven hydrological models ii a large sample assessment of these methods by applying general regression neural network grnn data driven models developed with data splits obtained using the two new and three existing data splitting methods to 754 catchments iii practical guidance on the most appropriate data splitting method to be applied based on the data properties i e skewness of the runoff data we use the grnn model architecture for this study this is because it has the advantage of not requiring continuous temporal sequences of inputs a key advantage when testing data splitting strategies further it also enables the development of large numbers of model possibilities due to its relatively simple model architecture that achieves comparable performance to more complex ann type alternatives li et al 2014 it is highlighted that the data driven model considered in this study does not consider time dependent structure of the hydro climatic data which has been often the case for many previous modelling studies e g may et al 2010 zheng et al 2018 overall the findings can be expected to be generally transferable to other data driven hydrological models e g ones based in machine learning where time dependency of hydro climatic data can be ignored since they all share the same need for data to be partitioned into several statistically representative subsets 2 data splitting methods it should be clearly stated at the outset that the purpose of the evaluation process developed in this paper is to assess the in sample performance of the model humphrey et al 2017 in other words the ability of the model to perform reliably under conditions similar to that corresponding to the data used for model calibration and evaluation performing well robustly under such conditions is clearly a pre requisite to being able to perform well under other out of sample conditions assessing the potential out of sample performance of a model is a separate and arguably more complex issue that is not well understood and is not the focus of this study possible ways to enable such analysis include the use of stress testing on models beyond the historical data razavi 2021 comparing the outputs of different models under truly out of sample predictions gleeson et al 2021 or incorporating physical knowledge into data driven models more specifically the aim of this study is to improve the model s in sample performance by evaluating two proposed splitting strategies that ensure that the data allocated to the calibration and evaluation sets have similar statistical properties the assumption is that a model exhibiting good in sample performance is more likely to be successful at predicting future scenarios than a model that has poor in sample performance in the data splitting methods proposed in this study the training selection and evaluation data subsets share an overlapping time horizon i e the data are randomly sampled throughout the entire time horizon while the use of time continuous and non overlapping data for model calibration and evaluation might be common practice for many hydrological studies tongal and booij 2018 razavi 2021 li et al 2022 such is not the case necessarily for data driven modeling in general in fact it is a typical requirement in data driven modelling that the data can be properly randomized may et al 2010 maier et al 2010 wu et al 2013 lee et al 2020 kahloot and ekler 2021 and it is arguably mainly in hydrology where this practice is not rigorously followed since the different input output vectors used by data driven models are treated as being independent whether the data are time continuous or not makes no difference in real world applications one reason why hydrological modeling studies often separate out a particular time continuous part of the data shen et al 2022 to be used for model evaluation is that a major concern is whether a model can be credibly used for the prediction of future hydrological events e g under non stationary conditions however the problem of guaranteeing future prediction capability under yet unseen hydrological conditions based on development using historical data arguably requires a much more reasoned approach than simply separating out a particular time continuous portion of the data first it is necessary to establish credibility in the ability of the model when tested under previously seen historical conditions and to achieve this goal it is important and necessary to ensure that the data used in both model development and evaluation are as fully representative as possible next it is important to be clear that assessing a model s performance under conditions that have not been represented in the data used for model development requires that a rather than choosing a particular time continuous part of the data one must establish a defensible procedure for selecting a testing period that has distinctly different hydrological conditions and b a meaningful procedure needs to be established for assessing model performance under these different hydrological conditions one now runs into an interesting conundrum if we do not use a fully representative data set for model development i e if we hold out some unusual events we are not providing access to the information necessary to maximize inference of the best possible model in such a case the model may or may not perform well under those new conditions and we cannot know whether this is due to a model structural inadequacy or insufficiently informative data during model development while it would be interesting to assess the extent to which a model trained on less than fully representative data can perform under unusual novel conditions existing in the current data set it is arguable whether this actually provides any degree of demonstrably real as opposed to subjective confidence in the capability of the model under yet unseen conditions in the absence of a philosophically and practically defensible strategy for establishing model credibility in the face of changing hydrological conditions we argue that a rational model development approach is to ensure that model development has access to a fully representative set of events drawn from the available observations thereby maximizing the possibility of robust model performance under typically observed conditions the data splitting methods discussed in this paper including the two existing methods detailed in this section and the two novel methods introduced in section 3 seek to do just that meanwhile assessing a model s credibility in regards to changing future conditions remains an important topic for ongoing investigation 2 1 random methods stratified sampling stratified sampling involves identifying distinct but homogeneous regions within the data and forcing the sampled subsets to include data from every stratum cochran 1977 the self organizing map som kohonen 1995 achieves a typical form of stratified sampling used in several recent data driven modelling applications wu et al 2013 zheng et al 2018 the som is a set of codebook vectors an array or map of weights in p dimensional space that is trained to learn a representation that best describes the p dimensional distribution of the data the data are assigned according to their nearest codebook vector which can then be projected onto a 2 dimensional map to achieve data subsets with similar statistical properties and are therefore representative of the data as a whole data must be selected from each and every map unit the sbss method tested by zheng et al 2018 uses som based stratified sampling sbss while this would appear to be an attractive option for data splitting in practice one has to contend with the fact that the sampling procedure can be sensitive to choice of som algorithm parameters and map size and therefore to the partitioning that results bowden et al 2002 further the best approach to sample from within the som map is not clear daszykowski et al 2002 to address these issues may et al 2010 proposed methods for selecting the size of the som and for determining the numbers of samples drawn from each som partition so as to minimize sample bias and variance nonetheless stratified random sampling is inherently random and performance variability is still typically observed albeit reduced in comparison to uniform random sampling 2 2 deterministic methods duplex approach kennard and stone 1969 developed the cadex and duplex data splitting algorithms for split sample evaluation of regression models cadex proceeds by first allocating the datum that lies farthest from all others to the first subset and allocating the next farthest one to the next subset and so on subsequent data are iteratively sampled one by one by identifying the datum that lies farthest from any previously selected points in the target set where the target set alternates duplex is a modified form of cadex in which data are selected in a pair wise manner i e two data points are assigned to the subset at once which can improve the statistical consistency of the resulting subsets snee 1977 duplex sampling is fully deterministic and only one split is possible for any given database resulting in zero sample variance while it is typically used to generate two subsets with a 50 50 split it is possible to generate splits of arbitrary proportional size by first allocating data to the smaller set until it is filled and then allocating all remaining data to the larger set snee 1977 zheng et al 2018 conducted a comprehensive analysis of the performance of these four well known formal data splitting methods sbss p sbb n duplex and ss on the development of data driven artificial neural network ann models of streamflow i e rainfall runoff ann models application of these four data splitting methods to 754 catchments with different properties resulted in 902 483 ann models thereby enabling rigorous statistical analysis resulting in the findings outlined in table 1 in summary each method exhibited strengths and weakness as characterized in terms of bias and variance indicating that none of them provides a satisfactory solution in the context of developing data driven rainfall runoff models 3 the two proposed data splitting methods here we develop two new data splitting methods the first entitled somplex is designed to overcome the problem of large variability associated with the sbss p method while retaining its superior performance with respect to bias the second entitled mduplex is designed to reduce the bias associated with the duplex method which has no variance since it involves deterministic allocation 3 1 the somplex algorithm somplex is a multi stage algorithm that combines som based clustering with duplex sampling of map units som clustering is used to identify distinct regions of the data space that can include both typical classes and examples of unique input output cases however overlooked by many data splitting applications is that the clusters may cover varying proportions of the database data can be non uniformly distributed within each partition and data in some partitions can be more widely spread than in others may et al 2010 due to which random sampling from within each cluster can be less than ideal conversely given any distribution of data duplex can generate a sample that uniformly covers the full range of the data snee 1977 by applying duplex to each som based partition representative samples can be generated from each partition regardless of the distribution within the partition the result is both robust and relatively insensitive to the partitioning that results from the som algorithm and since duplex is fully deterministic the result is free from sample variability pseudo code for the somplex algorithm is shown in fig 1 given a database d the algorithm generates calibration c selection s and evaluation e subsets as follows parameterization of the algorithm is discussed later in section 4 4 3 2 the mduplex algorithm duplex section 2 2 provides a mechanism for splitting the data in a deterministic manner a property that is attractive for practical applications however as discussed in section 2 6 it can result in significant bias when used in the context of evaluating the performance of data driven rainfall runoff models where the size of the calibration subset is typically larger than that of the evaluation subset under such circumstances duplex allocates a substantially larger number of normal less extreme data points to the larger calibration subset this biases the calibration towards normal events and causes the model to have relatively poor performance on extreme events resulting in pessimistic assessment of model evaluation performance to overcome this problem we propose a modified version of duplex called mduplex in which a multiple sampling strategy is used to generate the calibration selection and evaluation data subsets instead of the sampling process being carried out only once to generate the selection and evaluation subsets with all of the remaining data with small distances being assigned to the calibration subset the data are simultaneously allocated into all three subsets as indicated in fig 2 the benefit of this approach is that a larger number of extreme points data pairs with large distances can be assigned to the calibration subset than when using duplex resulting in better statistical similarity between the calibration selection and evaluation subsets 4 the simulation experiments 4 1 large catchment samples the proposed data splitting methods were tested in the context of developing data driven rainfall runoff models for 754 catchments including 322 from australia zhang and chiew 2009 and 432 from the us duan et al 2006 these catchments represent a wide diversity of catchment properties such as precipitation evaporation and catchment area data consist of daily rainfall and runoff observations recorded in millimeters per day mm day with record lengths varying from 10 to 40 years following zheng et al 2018 we use the first 10 years of available data for each catchment for this study due to the fact that these years are less likely to be affected by urbanization this choice also enables a fair comparison with the results obtained by zheng et al 2018 see table 1 skewness of the runoff data over these 10 year periods varies over a wide range of values from 1 12 to 52 03 and is consistent with that of the original complete dataset indicating that the 10 year subsets are representative of the entire datasets at least in terms of skewness for more details regarding the dataset see zheng et al 2018 4 2 the data driven model consistent with zheng et al 2018 we selected the general regression neural network grnn specht 1991 as the data driven model for this study reasons for this are that i grnns have a simple fixed model structure with only one tunable parameter so that issues related to model structure selection can be avoided consequently variations in model performance are only due to the choice of data ii use of grnns enables a fair comparison with the methods tested by zheng et al 2018 where the same modelling approach was used iii the relative simplicity of grnns facilitates computational feasibility of this study where very large numbers of models must be developed and evaluated iv grnns have been shown to provide comparable performance to more complex ann model architectures li et al 2014 for each catchment model inputs are rainfall and runoff data at various lagged time steps wu et al 2013 the most appropriate lags have previously been shown to depend on catchment properties such as area and slope and were determined by zheng et al 2018 based on a partial mutual information pmi analysis may et al 2008 li et al 2015 in each case consistent with previous work 80 of the data were used for model development 60 for calibration and 20 for selection and 20 for evaluation zheng et al 2018 may et al 2010 wu et al 2013 brent s method was used for estimation of the grnn model parameter press et al 1992 and the root mean squared error rmse was used as the performance metric for all stages of the study for each data splitting approach to ensure consistency with zheng et al 2018 we generated 100 different splits of each dataset training therefore results in a total of 150 800 grnn models for the 754 catchments performance results from the 100 splits are used to compute the bias and variance statistics for each catchment model for each data splitting method for comparison results for the sbss p sbb n duplex and ss methods are taken directly from zheng et al 2018 4 3 benchmarking performance of the models the approach of wu et al 2013 was used to determine the expected benchmarking model performance for each catchment this approach is based on the premise that allocation of any particular fraction of the available data to each of the two calibration and evaluation subsets results in an expected model error which is estimated as the average model error over all possible splits of the data for the given fractional allocation here 80 for model development 20 for evaluation this expected model error is generally larger than zero due to model structural inadequacies gupta et al 2012 observational errors and insufficient informativeness of the data if the model evaluation error is found to be larger than this expected error the assessment of model performance can be considered pessimistic and can be traced to assigning too many extreme data points to the evaluation subset conversely if the model evaluation error is found to be smaller than this expected error the assessment of model performance can be considered optimistic and can be traced to assigning an insufficient number of extreme data points to the evaluation subset because computing the expected model error requires evaluation of the performance of models developed for every possible data split the associated computational burden can be very large to circumvent this problem wu et al 2013 showed how the expected model error can be estimated using a sufficiently large number of random samples rather than all possible splits to within a specified level of accuracy and precision zheng et al 2018 have previously used this approach to estimate the benchmarking performance expected rmse values for grnn models on each of the 754 catchments used for our current study we therefore use those benchmarking results here to analyze model performance bias and variance 4 4 algorithm parameters for implementation of the somplex method the som was trained using the conventional som learning algorithm which involves two stages a short ordering phase during which weight adjustments are large followed by a longer tuning phase where adjustments are fine kohonen 1995 the som learning parameters used in this study are summarized in table 2 for full details of the som algorithm see kohonen 2013 an important aspect is a conscience mechanism that avoids the generation of large clusters and ensures that the distribution of data is as even as possible in contrast note that the mduplex algorithm is parameter free which increases its attractiveness for practical application 4 5 metrics used for assessing model performance to evaluate performance we used relative bias rb relative variance rv and relative estimation efficiency ree following zheng et al 2018 these are defined as follows 1 rb e m m m 100 2 rv v a r m m m 100 3 ree r b 2 r v where m is the evaluation subset rmse value for a particular catchment model and m is the benchmark performance rmse value for that catchment rb represents the expected model bias computed over multiple data splits 100 in this study rv represents the corresponding variability of the evaluation performance and ree accounts for both bias and variance 5 results and discussion 5 1 data splitting results first we compare results of the new somplex method with those of the previous sbss p for a particular catchment fig 3 the figure shows two typical data splits generated with different random seeds here for easy visualization we plot one input rainfall observations against the corresponding output runoff observations only the large extreme rainfall and runoff events are shown as these are more likely to have a significant effect on the model performance the figures show larger variation in the assignment of extreme events to the two subsets by sbss p for instance using sbss p none of the extreme events with runoff greater than 400 mm d were assigned to the evaluation set blue squares in one sbss p run fig 3 a while three such extreme events were assigned to the evaluation set for another run fig 3 c in contrast the somplex results are less variable as shown in fig 3 b d overall the distribution of extreme events assigned to the c s and e subsets is more similar for somplex than for sbss p in fig 4 we compare the results of the new mduplex method with those of the previously used duplex for a typical catchment the runoff probability density plot shows that of the two methods mduplex has assigned a larger number of extreme events large runoff values to the training set which means that fewer extreme events have been allocated to the evaluation set this assignment gives the model an opportunity to overcome the pessimistic model performance associated with duplex table 1 note also that the c s and e subset probability density distributions are more similar for mduplex than for duplex while we have presented illustrative results for only one catchment similar results were obtained for other catchments overall these results suggest that somplex and mduplex provide superior approaches to ensuring statistical similarity of data splits when selecting the calibration selection and evaluation subsets particularly in regard to the representation of extreme events 5 2 performance comparison box graphs of relative bias rb and relative variance rb for the evaluation results of the grnn models applied to the 754 catchments are shown in fig 5 results are shown for somplex and muplex as well as for the previously used sbss p duplex and ss methods as mentioned previously each method was applied 100 times because zheng et al 2018 reported that sbss n consistently exhibited poor performance table 1 we omit showing the corresponding results here the figure shows that the different methods achieved significantly different evaluation performance in terms of both relative bias rb and relative variance rv this clearly illustrates how the performance of the model can be significantly affected by the assignment of data into model development and evaluation subsets overall sbss p consistently results in the smallest relative bias over the 100 runs followed by somplex and mduplex fig 5a however the relative variability associated with the sbss p method is high due to the stochasticities associated with the approach although somplex achieves slightly worse relative bias than sbss p its relative variance is significantly lower fig 5b due to the use of the deterministic duplex method for sampling from the som clusters meanwhile mduplex exhibits lower relative bias than duplex although the distribution of rb values is wider than for somplex fig 5a since both these two methods are deterministic they display no variance fig 5b probability distributions of relative estimation efficiency ree are shown in fig 6 note that ree accounts for both bias and variance and smaller values are better so the ideal situation would be a distribution that peaks at the origin and has zero dispersion a delta function the distribution for mduplex blue dashed line peaks closer to zero and has relatively smaller dispersion followed by somplex red solid line the sbss p green dashed line and duplex black dash dot line methods provided the worst performance with distributions shifted more to the right in fig 7 we show evaluation performance scatterplots of simulated versus observed runoff for models calibrated using different data splitting methods results are shown for a typical catchment with moderate runoff skewness 10 3 also reported are the kge metric values gupta et al 2009 computed on the calibration including both training and selection and evaluation subsets the results indicate that use of somplex and mduplex data splits results in runoff simulations that agree well with observations as evidenced by relatively high kge values on both the calibration and evaluation subsets interestingly for somplex the performance variation between the calibration and evaluation subsets is lower than for the other methods we also present the probability density of the kge differences between the calibration and evaluation sets i e kge calib kge eval for each grnn model with six data splitting methods applied to the catchments as shown in fig 8 it is consistently shown that the kge values from the calibration data set are more likely to be larger than those from the evaluation set for each data splitting method this is expected as the model calibration performance tends to be better than the evaluation performance relatively the somplex method performs the best in terms of maintaining similar performance between the calibration and evaluation data this suggests that somplex performs well at ensuring the consistency of statistical properties between the model development and evaluation subsets while the mduplex method exhibited a slightly worse performance than the somplex ss and the sbss p approaches it shows an improved ability compared with duplex in maintaining similarity between calibration and evaluation performance 5 3 performance as a function of runoff data skewness in figs 9 and 10 we show rb and rv results for catchments with different ranges of runoff skewness it is clear from these plots that sbss p green consistently results in the smallest relative bias rb regardless of skewness but that relative variance over different data split realizations progressively increases with runoff skewness in comparison somplex red bias tends to increase negatively with increasing skewness but variance remains smaller than for the sbss p approach for duplex grey the results proceed from optimistic positive bias to pessimistic negative bias as skewness increases being deterministic variance is zero and this tendency is reflected in the somplex and duplex results since both are also based on the duplex methodology meanwhile mduplex blue consistently has lower relative bias than duplex both are deterministic with no variance in figs 11 and 12 we show how the average ranking of each of the data splitting methods sbss n is excluded varies with runoff skewness ranges in terms of relative bias rb and relative estimation efficiency ree respectively 1 indicates the best ranking as before sbss p green is consistently ranked best in terms of rb and worst in terms of ree in contrast mduplex has the best ree rank due to its low variance while maintaining a consistent moderate average pb rank across all skewness ranges meanwhile somplex ranks second best in terms of both rb and ree for data skewness smaller than 25 but performance deteriorates at higher values of skewness 5 4 analysis of variability while sbss p sbss n and somplex are stochastic the other methods are either semi deterministic or fully deterministic here we compare spss p and somplex in terms of relative variance we omit sbss n since previous results indicate that it performs worse than sbss p in terms of the rb rv and ree metrics fig 13 shows violin plots of percent relative bias rb for sbss p and somplex when applied to two typical catchments with different runoff skewness 10 3 and 36 9 respectively these plots were generated as follows the number n d of data splits was progressively varied from 5 to 90 and the appropriate number of rb values was sampled from the total 100 available rb values without replacement the mean of these n d values was recorded and the procedure repeated 100 times for each case to generate the distributions shown comparing the plots on the right to those on the left we see that somplex converges to very small variability at a faster rate with fewer data split repetitions than spbb p for both catchments similar results were observed for other catchments this result is clearly attributable to the use of the deterministic duplex strategy within the somplex methodology the practical and computational benefits of this are obvious 5 5 practical guidelines for selecting an appropriate data splitting method based on our experience with the large catchment sample study reported above fig 14 provides some guidance for an appropriate data splitting method as shown if as is common only a very low number of model calibration repetitions 1 2 data splits is feasible we recommend the use of mduplex due to its moderate bias and lack of variance if time and computational ability permit a moderate number of model calibration repetitions 10 50 data splits we recommend somplex for skewness below 25 and duplex for skewness above 25 if time and computation are not constrained we recommend sbss p as the best approach due to its consistently low bias regardless of runoff skewness the data splitting study reported in this paper takes advantage of the fact that data driven models treat the system memory as being effectively finite represented using several lagged time steps of data so that different parts of the data can be presented to the training algorithm in random order as such these methods are broadly applicable to the field of machine learning where the model development methods typically share this same property to assess performance users will need to establish suitable benchmarks according to their specific application 6 summary and conclusions based on an analysis of the strengths and limitations of some pre existing methods we have proposed and tested two new data splitting methods namely somplex and mduplex the former somplex is a multi stage algorithm that exploits the ability of soms to generate statistically representative data clusters and the ability of duplex to select and allocate data from each cluster the latter mduplex improves on the duplex strategy in a manner that is tailored to rainfall runoff modeling by assigning larger numbers of extreme events to the calibration subset compared with four previously reported methods we find that somplex exhibits significantly reduced sampling variance compared to sbss p while maintaining relatively low expected bias which makes it attractive for practical applications provided a moderate number of calibration repetitions can be performed mduplex improves over duplex by reducing the tendency to generate pessimistic performance overall mduplex provides consistently low ree regardless of runoff skewness which makes it the most appropriate method if only a very few calibration repetitions can be performed which is typical in engineering practice if time and computation are not limited sbss p provides the best expected performance regardless of data skewness it should be noted that this study has focused only on the strategy used for generating data splits and has been tested only in the context of data driven rainfall runoff modeling further work needs to be done to assess the impacts of different calibration selection and evaluation subset size ratios and or of different total amounts of data used for model development further the methods have been developed and tested in the context of data driven models for which strictly maintaining continuous temporal sequencing of data presented to the algorithms used for model development is not required in general the development of physically based and conceptual hydrological models where temporal data continuity is required can also be expected to be sensitive to the manner in which data is assigned to calibration and evaluation subsets guo et al 2020 and therefore methods that achieve proper data subsetting for such cases while preserving proper representativeness and consistency of the calibration and evaluation subsets need to be investigated see zheng et al 2022 as always we encourage and invite discussion and collaboration on these and related aspects of model development declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work is funded by the national natural science foundation of china 51922096 52179080 and excellent youth natural science foundation of zhejiang province china lr19e080003 we also gratefully acknowledge data for the 432 us catchments provided by dr thibault mathevet which can be also accessed through ftp hydrology nws noaa gov pub gcip mopex us data with details of this dataset given in http www nws noaa gov ohd mopex mo datasets htm data for australian catchments are given as supporting information of zheng et al 2018 which can be found at https agupubs onlinelibrary wiley com doi 10 1002 2017wr021470 
2901,a two layer model based on the integrated form of richards equation re was recently developed to simulate the soil water movement in the roots layer and the vadose zone with a relatively shallow and dynamic water table the model simulates thickness averaged volumetric water content and matric suction as opposed to point values and was numerically verified for three soil textures using hydrus as a benchmark however the strengths and limitations of the two layer model and its performance in stratified soils and under actual field conditions have not been tested this study further examined the two layer model using two numerical verification experiments and most importantly tested its performance at site level under actual highly variable hydroclimate conditions moreover model parameters were estimated and uncertainty and sources of errors were quantified using a bayesian framework first the two layer model was evaluated for 231 soil textures under varying soil layer thicknesses with a uniform soil profile second the two layer model was assessed for stratified conditions where the top and bottom soil layers have contrasting hydraulic conductivities the model was evaluated by comparing soil moisture and flux estimates to those from the hydrus model last a case study of model application using data from a soil climate analysis network scan site was presented bayesian monte carlo bmc method was implemented for model calibration and quantifying sources of uncertainty under real hydroclimate and soil conditions for a homogeneous soil profile the two layer model generally had excellent performance in estimating volumetric water content and fluxes while the model performance slightly declined with increasing layer thickness and coarser textured soils the model configurations regarding layer thicknesses and soil textures that generate accurate soil moisture and flux estimations were further suggested with the two layers of contrasting permeability model simulated soil moisture contents and fluxes agreed well with those computed by hydrus indicating that the two layer model accurately handles the water flow dynamics around the layer interface in the field application given the highly variable hydroclimate conditions the two layer model combined with the bmc method showed good agreement with the observed average soil moisture of the root zone and the vadose zone below rmse 0 021 during calibration and 0 023 during validation periods the contribution of parametric uncertainty to the total model uncertainty was too small compared to other sources the numerical tests and the site level application showed that the two layer model can reliably simulate thickness averaged soil moisture and estimate fluxes in the vadose zone under various soil and hydroclimate conditions results also indicated that the bmc method could be a robust framework for vadose zone hydraulic parameters identification and model uncertainty estimation keywords richards equation re soil moisture numerical solution hydrus bayesian monte carlo maximum likelihood estimation data availability data will be made available on request 1 introduction application of richards equation re to describe water movement in unsaturated soils can be very challenging at the field and watershed scales for many reasons including soil heterogeneity highly variable hydroclimate conditions and fluctuating shallow water table vereecken et al 2016 farthing and ogden 2017 integrated forms of point scale re allow numerically efficient coupling of land surface to shallow groundwater at larger scales by focusing the analysis on distinct soil zones such as soil horizons roots zone and vadose zone he et al 2021 recently the authors have developed a two layer integrated form of re to simulate one dimensional vertical unsaturated flow in the root zone and the vadose zone below he et al 2021 the purpose of developing the two layer model was to efficiently simulate vertically averaged soil moisture content in the two distinct soil zones and maintain continuity of water flux at the interface under various surficial and bottom flux and prescribed hydraulic head boundary conditions including a shallow water table the model was designed to simulate layer thickness averaged soil moisture as opposed to point values it is also numerically suitable for larger than point scale applications it can be used to couple land surface to groundwater in large scale hydrological models for which estimation of soil moisture and water fluxes at high vertical resolution might be unnecessary the two layer integrated form of re converted the partial differential equation pde of re to two coupled ordinary differential equations odes describing thickness averaged moisture content and interfacial water flux in two soil layers the coupled odes were solved by heun s method with the iterative corrector to reduce truncation error and improve stability the model handles variable precipitation plant transpiration soil evaporation and groundwater fluctuations details of the model can be found in he et al 2021 he et al 2021 evaluated their model for relatively simple atmospheric and bottom boundary conditions with only three homogeneous soil profiles by comparing their results to the one dimensional finite element model hydrus 1 d ≈°im≈Ønek et al 2008 as a benchmark the two layer model showed excellent accuracy and efficiency in estimating thickness averaged volumetric moisture content and water fluxes including plant transpiration in the roots layer however the authors did not examine the two layer model performance in stratified soils with contrasting permeabilities or different soil textures and most notably did not test the model with actual field data under real hydroclimate conditions further uncertainty of model predictions and sources of uncertainty were not examined nor quantified instability of numerical schemes at the interface of two different soil textures with contrasting permeabilities is well known miller et al 2013 zeng et al 2018 one of the proposed methodologies to deal with discontinuity in the hydraulic parameters is to properly average the hydraulic parameters at layers interfaces belfort et al 2013 lai and ogden 2015 the flux at the interface between two soil layers is conserved in the integrated form of re in the two layer model through properly derived expressions for the unsaturated hydraulic conductivity and matric potential at the interface he et al 2021 highly variable flux conditions at the surface and switching between prescribed head and flux boundary conditions abruptly can produce numerical instability and convergence problems in the solution of re equation zha et al 2019 this paper shows that the integrated form of re in the two layer model developed by he at al 2021 can handle numerical instability efficiently under highly variable hydroclimate conditions this paper further demonstrates 1 the integrated form of re can accurately simulate layer averaged soil moisture across all soil textures and efficiently maintain continuity of water fluxes in layers with contrasting permeabilities in the presence of shallow or deep water table 2 the model can reproduce observed data under actual field and hydroclimate conditions and 3 the model parameters are identifiable from a bayesian point of view and model uncertainty is dominated by structural and observational errors to test these hypotheses we conducted model verification and evaluation scenarios the model verification includes two numerical experiments varying soil textures and thicknesses and layers with contrasting permeability and model evaluation includes a site level application case study table 1 summarizes the model verification and evaluation scenarios the structure of the paper is as follows first the methodology used to evaluate model performance for homogeneous and heterogeneous soil scenarios is presented this is followed by the description of the scan site used in the field level application of the two layer model next the bmc method used in parameter and uncertainty estimation is described the results section provides a qualitative and quantitative comparison of the two layer model results to hydrus and field measured soil moisture estimates the strengths and weaknesses of the two layer model are scrutinized under discussion the manuscript ends with conclusions 2 methodology 2 1 data used in this study both synthetic and measured data were used in this study the synthetic data was utilized in the first numerical experiment of model verification which includes artificially created soil textures using pedotransfer functions with rosetta3 see section 2 4 1 and meteorological data with a cycle of prescribed rainfall intensities and potential transpiration rates in the second numerical experiment of model verification we collected data for two soil textures from hills et al 1989 who estimated the van genuchten soil hydraulic parameters from laboratory measurements the same synthetic meteorological data was also used in the second numerical experiment as to the model evaluation with site level application case study the measured data including soil texture soil moisture and meteorological data were obtained from the soil climate analysis network scan https www wcc nrcs usda gov scan see below sections for the detailed information of data being used the equipment used i e hardware and software are listed in supplementary material s4 2 2 the two layer model the two layer model is described by the following coupled ordinary differential equations refer to fig 1 on flow domain schematic illustration readers are referred to he et al 2021 for a detailed description of the model 1 h d Œ∏ 1 dt q 0 q 1 h s 2 h h d Œ∏ 2 dt Œ∏ 2 s dh dt q 1 q 2 in which 2a Œ∏ 1 t 1 h h 0 Œ∏ z t d z Œ∏ 2 t 1 h t h h t h Œ∏ z t d z 2b q 2 2 h Œ≤ k 1 1 Œ≤ k 2 œà 2 œà 1 Œ≤ k 1 1 Œ≤ k 2 where Œ∏ 1 and Œ∏ 2 are the first root zone and the second layer lower vadose soil average moisture contents respectively Œ∏ 2 s is the saturated water content of the second layer h is the thickness of the first layer l h is the depth to the water table l q 0 is the moisture flux at the soil atmosphere interface lt 1 positive downward q 1 is the moisture flux at the interface of the two layers lt 1 q 2 is the moisture flux at the bottom of the second layer and accounts for flux interactions between the vadose zone and the water table lt 1 s is the transpiration rate t 1 k 1 and k 2 are average unsaturated hydraulic conductivities of the first and the second layers respectively lt 1 œà 1 and œà 2 are average soil matric potential for the first and the second layer respectively lt 1 and Œ≤ h h h the coupled ordinary differential equations eqs 1 and 2 of the two layer model are solved by heun s method with the iterative corrector to reduce truncation error and improve stability actual plant transpiration rate s is calculated based on the moisture content of the root zone according to the method proposed by feddes 1982 the actual bare soil evaporation is estimated according to the average moisture content of the root zone layer 2 3 soil water retention curve the soil hydraulic characteristic relationships Œ∏ œà and k Œ∏ in this study were described by the van genuchten 1980 model 3 k Œ∏ k s s e 1 2 1 1 s e 1 m m 2 œà 0 k s œà 0 4 œà s e 1 Œ± se 1 m 1 1 m 5 se Œ∏ Œ∏ res Œ∏ sat Œ∏ res where s e is relative saturation k s is saturated hydraulic conductivity lt 1 Œ∏ res and Œ∏ sat are residual and saturated water content respectively n is pore size distribution index m is a fitting parameter defined as m 1 1 n and Œ± is the fitting parameter l 1 the parameters n Œª and Œ± are coefficients affecting the shape of the hydraulic functions 2 4 model verification experiments 2 4 1 soil texture and layers thicknesses in this test the two layer model was run with a homogeneous soil profile with 231 soil textures combined with 400 soil layer thickness scenarios under one prescribed upper boundary condition and two bottom boundary conditions the reference model hydrus ≈°im≈Ønek et al 2008 was run with the same soil layer thickness climate and boundary conditions in the numerical simulations each homogeneous soil profile was made up of soil texture identified by varying the percentage of soil separate of sand silt and clay during simulations the soil separates in each soil texture varied from 0 to 100 at 5 increments thus as shown in fig 2 231 soil textures were generated covering all possible textures on the usda soil texture triangle cosby et al 1984 the van genuchten soil hydraulic parameters including the water retention parameters and saturated hydraulic conductivity k s were estimated using rosetta3 rosetta3 is a python based open source pedotransfer functions model based on artificial neural networks ann developed by zhang and schaap 2017 this allowed us to generate the soil hydraulic parameters and saturated hydraulic conductivity for all 231 soil textures using sand silt and clay percentages as input the thickness of the first root zone and the second layer lower vadose soil varied from 10 to 200 cm at 10 cm increments thus the total soil depth varied from a minimum of 20 cm to a maximum of 400 cm this resulted in 400 soil layer thickness combinations for each soil texture the upper boundary condition involved an atmospheric scenario with a cycle of prescribed rainfall intensities and potential transpiration rates fig 3 the first 5 days had no rain but there was a 0 2 cm day potential transpiration days 5 10 had 2 cm day of constant rain but no transpiration demand this cycle was repeated until day 50 because hydrus and the two layer model calculate soil evaporation differently we only considered plant transpiration to allow for a consistent comparison of the two layer model with hydrus both the two layer model and hydrus adopt the root water uptake water stress response function proposed by feddes et al 1978 to calculate the actual plant transpiration rate the parameters for the stress reduction function were set to the values in wesseling 1991 for pasture values of root water uptake water stress response function parameters were œà 1 10 cm œà 2 25 cm œà 3 800 cm œà 4 8000 cm two bottom boundary conditions were applied 1 free drainage which refers to zero pressure gradient boundary at the bottom this boundary condition is suitable for situations where the water table is far below the domain of interest 2 zero pressure head boundary condition which describes the case where the water table is at the bottom of the soil column water table depth is equal to the total depth of the soil column h we set the initial moisture contents for all soil textures to the moisture content at 33 kpa field capacity simulations were carried out by the two layer model and hydrus for a 50 day period using a computational time step of 0 001 days in hydrus the soil domain was discretized using 101 equidistant nodes the soil moisture estimations for the first and the second layers were obtained by averaging the soil moisture contents of the nodes within each layer note that for fine textured soils with the genuchten water hydraulic parameter n less than 1 3 an air entry value of 2 cm is typically recommended in hydrus applications to overcome the convergence issue vogel and cislerova 1988 vogel et al 2000 this configuration significantly alters the hydraulic conductivity function however this modification in air entry pressure for fine textured soils was not necessary for the two layer model in order to make the two models comparable this option was not selected in hydrus instead the maximum number of iterations during any time step was changed from the default value of 10 to 100 this change sacrificed efficiency for accuracy in hydrus using the standard van genuchten model for fine textured soils model performance was evaluated using averaged rmse of soil moisture contents by averaging rmse values of moisture contents from the two soil layers there are 231 plots of rmse patterns each with different thicknesses of two soil layers and two bottom boundary conditions due to space limitations the results of only three soil textures are presented in this manuscript full results can be found in supplementary materials the three selected soil textures were coarse medium and fine textured soils sand loam and clay sand silt and clay fractions were selected to represent these three soil textures following the usda soil texture classification soil survey staff 1999 sandy soil was 90 sand 5 silt and 5 clay loamy soil was 40 sand 40 silt and 20 clay while clay soil was 10 sand 15 silt and 75 clay 2 4 2 layers with contrasting permeability we assessed the performance of the two layer model with coarse textured soil on top of fine textured soil and vice versa the coarse and fine textured soils used in this study were loamy fine sand and silty clay loam obtained from hills et al 1989 the van genuchten soil hydraulic parameter values of these two soil textures are shown in table 2 the thicknesses of the two soil layers were set to 30 cm the upper boundary condition was the same as the 5 day cycle weather pattern over 15 days as described earlier fig 3 again the free drainage and zero pressure head were the two bottom boundary conditions considered the initial moisture contents of both soil textures were set to the moisture content at 33 kpa 0 269 for loamy fine sand and 0 448 for silty clay loam results of soil moisture contents top and bottom flux terms and estimated transpiration rates were compared with those obtained from hydrus 2 5 model evaluation with a case study 2 5 1 site description the two layer model was applied to a scan site to assess its ability to predict soil moisture under highly variable hydroclimate conditions at the field scale site tuskegee scan site id 2115 from alabama usa was chosen as the study site which is located at 32 26 n and 85 45 w at an elevation of 122 m above mean sea level fig 4 the scan dataset provides site level soil moisture and meteorological data at daily time steps schaefer et al 2007 soil moisture was measured at five different soil depths which are 5 cm 2 in 10 cm 4 in 20 cm 8 in 50 cm 20 in and 100 cm 40 in to avoid days with subzero air temperature daily data were gathered from february 24th to october 31st for the years 2018 and 2019 data from 2018 were used for model calibration and data from 2019 were used for model validation our preliminary test showed that moisture redistribution always occurred within 2 days to minimize the uncertainty coming from the initial moisture content the first five days from february 24th to 28th made up the model warm up period results of the model simulated moisture contents were compared with field measurements from march 1st to october 31st to make the model outputs comparable with the observed soil moisture data the measured soil moisture contents at different depths were grouped into two soil layers by following the logic in the two layer model that the first layer represents the root zone where the plant water uptake occurs and the second layer is the lower vadose soil at the scan site the weather station and soil moisture sampling point were installed at the same location where the area was covered by short grass or natural fallow for most of the time albergel et al 2015 we consulted with the local usda service center in tuskegee for vegetation cover and rooting depth the dominant species for this scan site is bahiagrass paspalum notatum the depth where most of the root biomass is located is about 18 cm thus we assumed the top 20 cm of the soil to be the root zone layer and the next 30 cm below was the second layer based on the web soil survey soil survey staff natural resources conservation service 2019 the groundwater level at the site is below 200 cm however there is a small creek about 500 m southeast of the site the groundwater level in the area around the creek was about 110 cm inquired from web soil survey which could potentially influence soil moisture measurement in the deeper soil 100 cm the fifth sensor was excluded for model comparison due to the lack of groundwater level data thus we considered the total soil depth of interest to be 50 cm that includes the top four moisture sensors the first two moisture sensors belonged to the first layer and the fourth sensor belonged to the second layer the third sensor was located at the boundary between the two layers soil properties for four soil horizons within 50 cm soil profile were provided by the national cooperative soil survey survey 2017 including the percentage of sand silt clay and organic carbon bulk density moisture content at field capacity and moisture content at wilting point because the first and the second layer of the model domain contained several horizons the soil physical properties of each layer were calculated by weighted average according to the depth of the horizons within the layer percentage of sand silt clay and organic carbon and moisture contents at field capacity and wilting point were used as inputs to the rosetta3 model to estimate the van genuchten soil hydraulic parameters rosetta3 provided the prediction uncertainties of each van genuchten parameter as standard deviations meteorological data were available at daily time step for the simulation period including precipitation maximum and minimum air temperature relative humidity solar radiation and wind speed fao 56 penman monteith method allen et al 1998 was applied to calculate the daily potential evapotranspiration pet rate 2 5 2 model calibration for model calibration the two layer model was run from february 24th 2018 to oct 31st 2018 the upper boundary condition was atmospheric controlled which was described by precipitation and pet calculated pet and observed precipitation data for the model calibration period are shown in fig 5 potential evaporation for bare soil and potential transpiration rate for grass were calculated by partitioning pet using an area index f s the area index represents the fraction of bare soil and 1 f s is the fraction of vegetation cover at the study site the area of vegetation cover was unknown this area index can be calibrated in the model calibration process the bottom boundary condition was set to free drainage we ran the two layer model with Œ¥t 0 001 day 86 s during the calibration and validation periods 2 5 3 bayesian model parameter and uncertainty estimation the uncertainties introduced by input data and data used for calibration model parameters and imperfection in the model structure make the model output subject to errors the uncertainties of the two layer model in model applications stem mainly from the following specific sources 1 uncertainties may be introduced due to measurement errors limited soil moisture data and interpolation of observed data to obtain vertically averaged soil moisture contents for the two soil layers in the model domain 2 estimation of van genuchten parameter from basic soil texture data using rosetta3 3 averaging soil properties from different horizons to obtain averaged soil properties of two soil layers as inputs for rosetta3 and 4 model structural errors introduced by neglecting higher order terms in the derivation of equations 1 and 2 as well as not accounting for soil heterogeneity and other potentially important processes such as lateral flow and preferential pathways quantifying the uncertainties of the two layer model can provide a better idea of how the two layer model performs at the site level during the model calibration and uncertainty estimation we employed the bmc method for model calibration and uncertainty estimation the detailed methodology and procedure of bmc can be found in hantush and chaudhary 2014 and chaudhary and hantush 2017 in this study we considered the five van genuchten soil hydraulic parameters and the area index œâ Œ± n Œ∏ res Œ∏ sat k s f s as random variables uniform distributions of the values or their log transformations are commonly assumed as priors for the unknown parameters e g vrugt and bouten 2002 w√∂hling and vrugt 2008 huisman et al 2010 mboh et al 2012 k√∂pke et al 2019 the effect of priors diminishes with the size of the observed data and the choice of the prior distribution therefore becomes increasingly less important following scharnagl et al 2011 the prior distribution of van genuchten soil hydraulic parameters is defined as p x u a x b x where a x and b x are the lower and upper bounds respectively a x and b x are calculated as Œ≥ 4 œÉ where Œ≥ is rosetta3 predicted values and œÉ is the standard deviations of the predicted parameters the predicted values and corresponding standard deviations of Œ± n and k s from rosetta3 were given in log form the log values of these three parameters were assumed uniformly distributed based on their logarithmic standard deviations as prior distributions the values of these three parameters were sampled from the uniform distributions of the log10 values and then inverted to their original values the area index f s was assumed a uniformly distributed priori p f s u 0 1 the upper and lower bounds of prior distributions of model input parameters are shown in table 3 the relationship between the observed soil moisture at time t o t and the corresponding simulated output Œ∏ œâ t from the two layer model can be expressed as o t Œ∏ œâ t Œµ where Œµ Œµ 1 Œµ 2 Œµ m Œµ i n 0 œÉ Œµ 2 was assumed to be zero mean independent and normally distributed model residual error and m is the number of observations the error Œµ accounts for all sources of modeling errors described above observational parametric structural hydrometeorological inputs we generated 1 000 000 parameter sets by randomly drawing parameter values from their prior distributions fig 6 illustrates a brief portrayal of the bmc methodology applied in this study what follows is a summary description of the bmc methodology based on bayes theorem the posterior joint probability density function is given by 6 p œâ i o k l œâ i p œâ i where o o 1 o 2 o m is set of m observed moisture content values p œâ i o is the posterior probability mass of parameter set œâ i Œ± i n i Œ∏ res i Œ∏ sat i k s i f s i i 1 2 n where n is the number of randomly sampled parameter sets n 1 000 000 l œâ i p o œâ i is the likelihood of observations given œâ i p œâ i is the prior probability mass of the parameter set œâ i k is a normalizing factor such that i 1 n p œâ i o 1 that is k n i 1 n l œâ i where we have assumed equally likely parameter sets a prior p œâ i 1 n the objective function to optimize is the log likelihood function of model residual errors the joint log likelihood function given a set of m independent moisture content observations o 1 o 2 om and a parameter set œâ i is 7 ln l œâ i m 2 l n 2 œÄ m ln œÉ Œµ 1 2 k 1 m Œµ i œÉ Œµ 2 the likelihood of each generated parameter set œâ i can be obtained by maximizing eq 7 chaudhary and hantush 2017 7a l œâ i 2 œÄ e œÉ Œµ i 2 m 2 where l is the likelihood of œâ i in which 7b œÉ Œµ i 2 1 m k 1 m Œµ k œâ i 2 the posterior probability mass of œâ i is given by 8 p œâ i o l œâ i i 1 n l œâ i the bayesian estimate of layer averaged moisture content Œ∏ of the first and the second layer at any point in time is the conditional mean of Œ∏ given the observation 9 e Œ∏ o i 1 n e Œ∏ œâ i p œâ i o 1 i 1 n l x i i 1 n Œ∏ œâ i t l œâ i in which we made use of e Œ∏ œâ i Œ∏ œâ i t and eq 6 posterior probability distribution functions pdfs of the parameters œâ i Œ± i n i Œ∏ res i Œ∏ sat i k s i k c i can be obtained from the sampled values of each model parameter and corresponding posterior probability masses computed by eq 6 the confidence band for simulated posterior i e conditional on the observed data soil moisture content at time t can be generated from the following cumulative distribution function cdf hantush and chaudhary 2014 10 f y o 1 2 1 2 i 1 n e r f y Œ∏ œâ i t 2 œÉ Œµ i p œâ i o 1 2 1 2 i 1 n l œâ i i 1 n e r f y Œ∏ œâ i t 2 œÉ Œµ i l œâ i where y is the value of soil moisture content this equation can be inverted using any root finding techniques to obtain percentiles and construct a confidence band for moisture content at any point in time given the hydroclimate data model performance was evaluated by estimating rmse and nash sutcliffe efficiency e ns obtained from the bayesian estimates eq 9 and corresponding hydrus or layer averaged observed data of volumetric soil moisture content Œ∏ because soil moisture was measured at discrete spatial points linear interpolation was applied to field measurements to compare model outputs with measurements for the two simulated soil layers we first interpolated the soil moisture contents along the 50 cm soil column according to the observations at four depths and then calculated averaged moisture contents for the first and the second layer by averaging interpolated values from 1 cm to 20 cm and 20 cm to 50 cm respectively the model performance indices were calculated for each layer separately model predictive uncertainty of volumetric soil moisture content was obtained as follows random samples of Œ∏ at each day for each soil layer were drawn from eq 10 the variance of Œ∏ at each day was calculated from the randomly drawn values the sample average of the variances œÉ 2 over the simulation 245 days was taken as measures of total model prediction uncertainty for each layer the bayesian estimated values of residual error variance œÉ Œµ 2 is that part œÉ 2 which accounts for measurement model structural errors and uncertainty in the forcing input hydroclimate data an estimate of the error variance attributed to parameters uncertainty œÉ œâ 2 was obtained from the mc simulated moisture contents n 106 and their corresponding posterior probability masses calculated by eq 8 the calculated variances were then averaged over the simulation as a measure of the parametric uncertainty variance œÉ œâ 2 we note that œÉ 2 is not equal to œÉ Œµ 2 œÉ œâ 2 due to nonlinear interactions and dependence of œÉ Œµ 2 other sources of errors on parameter values the ratio œÉ œâ 2 œÉ 2 is an approximate estimate of the fraction of total error contributed by uncertainty in the parameters and œÉ Œµ 2 œÉ 2 is an approximate estimate of the fraction of total error contributed by other sources of errors measurement structural and hydroclimate forcing 3 results 3 1 soil textures and layers thicknesses fig 7 shows the rmse values obtained from the two layer model and hydrus simulated Œ∏ for three soil textures using free drainage a and zero pressure head b bottom boundary conditions the plots show the contour lines and heat maps of rmse with different thicknesses of the first root zone and the second layer fig 8 shows an example of the simulated moisture contents of two soil layers from the two layer model and hydrus using 50 cm thickness for both layers respectively as shown in fig 7 rmse has an increasing trend with increased layer thickness for both layers with the free drainage bottom boundary condition the rmse for three soil textures was always lower than 0 015 with a shallow root zone less than 30 cm rmse increased rapidly again never exceeding 0 015 with the increasing thickness of the second layer the same trend was observed with a thin second layer but this was less pronounced in the figures when considering the water table at the bottom of the soil profile zero pressure head the performance of the two layer model varied for different soil textures the model performance with the coarse textured soils dropped with increased layer thicknesses rmse was highest for sand and clay soil texture with the presence of a shallow water table in fig 7 for sand rmse was lower than 0 01 only when the first layer thickness was less than 60 cm and the second layer thickness was below 90 cm when soil texture became finer model performance improved rmse for loam dropped below 0 01 for all thickness scenarios whereas for clay the maximum rmse was 0 02 when all the 231 soil textures are pooled the minimum and maximum rmse were 0 and 0 018 respectively for the free drainage bottom boundary condition and 0 and 0 048 for the zero pressure head bottom boundary condition supplementary material s1 fig 7 summarizes model performances as a function of layer thicknesses for a given soil texture another way of assessing model performance is plotting rmse as a function of soil texture on the soil texture triangle for various soil layer thicknesses fig 9 shows one such example where the variation of rmse with soil texture is shown for 50 cm root zone depth combined with second layer thicknesses of 10 100 and 200 cm under the two bottom boundary conditions rmse heat maps for all other thickness combinations are available in the supplementary material s2 in fig 9 the two layer model performed better with the free drainage bottom boundary condition than the water table bottom boundary condition this was also the case with other thickness combinations supplementary material s2 the general pattern in each soil triangle is that rmse increases with increased sand fraction the model performance also generally increases with increased silt fraction which is more evident for deeper soils the maximum rmse for the case of free drainage at the bottom was 0 008 in fig 9 and it corresponds to the case with the second layer thickness being 200 cm and a very high sand fraction with the zero pressure head boundary condition the maximum error was 0 038 which happened with the same thickness and soil texture thus rmse values from the free drainage bottom boundary condition were lower than those from the zero pressure head bottom boundary condition with the increase of soil thickness rmse values often increased from the bottom left of the soil triangle high fraction of sand then rmse values increased in the top angle high fraction of clay cumulative top and bottom fluxes and actual plant transpiration obtained by the two layer model were also compared to hydrus counterparts the overall model performance for cumulative bottom flux decreased with the increasing soil profile thickness the full comparisons of cumulative bottom flux and actual transpiration estimation between the two models can be found in supplementary material s3 and s4 3 2 layers with contrasting permeability the results from simulations with the two layer model and hydrus for 30 cm of loamy fine sand high permeability overlaying 30 cm of silty clay loam low permeability and vice versa are shown in figs 10 and 11 both models simulated soil moisture contents of the low permeability layer were consistently higher than the high permeability layer as shown in figs 10 and 11 the soil moisture contents of the two soil layers and flux estimations from the two layer model matched those from hydrus moisture contents varied correspondingly with the atmospheric condition i e moisture contents in both layers declined in response to the transpiration demand which was followed by an increase over the next 5 days due to rain for the soil layer configuration with high permeability soil overlaying the low permeability soil fig 10 the two layer model showed excellent performance under the free drainage bottom boundary condition the rmse of both layers was lower than 0 01 the cumulative top and bottom flux from the two layer model were identical to those from hydrus while the cumulative transpiration was slightly higher than hydrus with the zero pressure head bottom boundary condition the moisture content in the first layer from the two layer model was higher than that from hydrus in the first 5 days with only transpiration while in the next 5 days with precipitation the moisture content of the first layer was lower than that from hydrus the rmse for the first layer was 0 02 while moisture contents of the second layer matched very well with that from the reference model with rmse equal to 0 002 the cumulative top flux and transpiration rate were identical to those from hydrus the cumulative bottom flux for the first 5 days was higher absolute value than that from hydrus but similar for the next 10 days when the low permeability soil overlaid the high permeability soil fig 11 soil moisture and cumulative fluxes estimated by the two layer model were almost identical to their counterparts generated by hydrus for both bottom boundary conditions the rmse values for the first and second layers average moisture contents in both bottom boundary conditions were consistently lower than 0 01 3 3 application of the two layer model to the scan site figures 12 a1 and a2 show the two layer model calibration results from march 1st 2018 to october 31st 2018 the bayesian estimates eq 9 95 confidence interval and observed soil moisture contents of the root zone and the soil layer below respectively the 95 confidence limits were obtained by inverting eq 10 using the bisection method the bayesian estimated vertically averaged soil moisture contents of both layers compare well with the corresponding aggregated observations given the uncertainty and errors in preprocessing of limited and discrete observed point data set and linear interpolation of what could actually be a nonlinear soil moisture distribution the rmse and e ns values are 0 016 and 0 73 for the first layer and 0 021 and 0 62 for the second layer respectively all the observed soil moisture values fell within the 95 confidence bands the 95 confidence intervals and the bayesian estimates a posteriori of model input parameters and œÉ Œµ 2 calculated by bmc are shown in table 4 figures 12 b1 and b2 show bmc predicted soil moisture contents along with 95 confidence bounds and observed soil moisture contents of both soil layers for the validation period march 1st october 31st 2019 the soil variability and magnitude of moisture contents are adequately captured by the bmc estimates as shown in figures 12 b1 and b2 although model performance dropped somewhat for the validation period it can still be considered good with rmse values equal to 0 023 and 0 023 and e ns values equal to 0 73 and 0 72 for the first and second layers respectively the prior and posterior distributions of the model input parameters are shown in fig 13 the two layer model appears robust in simulating hydrometeorological conditions outside the range used for model calibration 4 discussion 4 1 model verification with numerical experiments 4 1 1 soil textures and layer thicknesses the numerical simulations on homogeneous soil profiles revealed the performance of the two layer model on various soil textures and layer thickness conditions overall the two layer model performs better with the free drainage than the zero pressure head bottom boundary condition with the influence of the water table groundwater affects the soil moisture of the layer above mainly through capillary actions in the two layer model solution the suction force in the second layer is averaged over the layer corresponding to the thickness the truncation errors incurred by neglecting higher than first order terms leading to eqs 1 and 2 increase the error in deeper soil and can be more pronounced near the water table where capillary pressure gradient can be highly nonlinear except for coarse textured soil with the water table at the bottom fig 7 where the two layer model suffers from the increased thickness of both layers model performance deteriorates only with relatively thicker lower vadose soil the model still performed very well for a relatively thick roots layer 2 m except for sandy soil and water table at the bottom the highly nonlinear relationship between matric pressure head and moisture content in coarse soils near saturation amplifies the truncation errors in the computed matric pressure head gradient at the water table and consequently the average soil moisture computed by the model 4 1 2 layers with contrasting permeability solving re for layered soils has been challenging because of the discontinuity of moisture and hydraulic properties moving from one soil texture to another two phenomena are often related to this discontinuity the capillary barrier and the hydraulic barrier alfnes et al 2004 si et al 2011 one attempt to address or smooth the discontinuity is to find suitable values of hydraulic conductivity and matric potential at the interface of two different soil textures matthews et al 2004 szymkiewicz and helmig 2011 in the two layer model the interface flux term q 1 is expressed as a function of the hydraulic conductivity and vertically averaged matric potential of the first and second layer given by eq 2b he et al 2021 the two layer model appropriately handles the discontinuity of hydraulic properties with two extreme soil layering scenarios the results reflected these two types of barriers considering the free drainage bottom boundary condition when loamy fine sand is on top of silty clay loam and if flux from the upper layer at the interface is higher than the saturated conductivity of the lower layer the hydraulic barrier occurs in this case only part of the water flux is transmitted downward and the excess water is initially retained in the upper layer in figs 10 a1 during the first two days of the rainfall period day 6 to day 7 the moisture content of the upper layer started to increase at day 6 while the increase of the moisture content for the lower layer was observed at day 7 because of the hydraulic barrier the discontinuity created by the hydraulic barrier was gradually mitigated when both layers received rainfall resulting in increased hydraulic conductivities for both layers furthermore the capillary barrier can be observed in figs 11 a1 during the rainfall period from day 6 to day 10 the moisture content of the lower layer had slower rate of increase than that in the upper layer when figs 11 a1 is compared to figs 10 a1 the highest moisture contents of the loam textured layer were similar 0 428 in figs 11 a1 vs 0 438 in figs 10 a1 however the highest moisture content of the sandy soil layer in figs 11 a1 0 143 was lower than that in figs 10 a1 0 173 which indicates that the capillary barrier occurred during the rainfall period in figs 11 a1 our results suggest that the first order approximation of taylor expansion of conductivity and matric potential at the interface in the two layer model can be a solution to deal with heterogeneous soil profiles 4 1 3 on the model assumptions the simulated results of soil moisture and fluxes for homogeneous and heterogeneous soil profiles indicate the assumptions leading to the development of the two layer model are adequate these assumptions are 1 truncation of the higher order terms in the taylor series approximations of matric potential and unsaturated conductivity at the interface of the two soil layers eqs 11 and 19 in he et al 2021 and 2 œà i œà Œ∏ i and k i k Œ∏ i these assumptions likely contributed to the minor deviations of the two layer model results from hydrus results however it is impossible to identify each assumption s relative contribution further the errors contributed by the assumptions of œà i œà Œ∏ i and k i k Œ∏ i are likely to be more pronounced in coarse textured soils sand than in fine textured soils because of the highly nonlinear characteristic relationships near saturation e g figs 7 b1 for example when the water table is not too far below the root zone the distribution of soil moisture in a predominantly sandy soil becomes highly nonlinear thus the deviations between œà i and œà Œ∏ i and k i and k Œ∏ i are expected to be the highest these differences can be exacerbated further by a relatively thick vadose soil below the root zone second layer model performance is improved when layer thickness decreases because as moisture variations become smaller the assumption of œà i œà Œ∏ i and k i k Œ∏ i becomes more tenable in the case of a deep water table and free drainage bottom boundary condition the nonlinearity of moisture distribution is lower compared to zero pressure head bottom boundary condition which is more favorable for smaller truncation errors and the assumption of œà i œà Œ∏ i and k i k Œ∏ i thus the overall model performance for the free drainage bottom boundary condition is better than for a shallow water table zero pressure head bottom boundary condition nevertheless if the temporal variability of the atmospheric forcing is high soil moisture distribution can have higher spatial variability especially with fine textured soils supplementary material s2 in addition because of the highly nonlinear characteristic of water potential near saturation above the water table soil evaporation near the soil surface and heterogeneous root water uptake can also induce heterogeneity of moisture profile and eventually lead to deviations from the above assumptions thus higher order corrections are needed to explore improved model performance in the case of heterogeneous distribution of Œ∏ 4 2 case study application 4 2 1 model performance under highly variable hydroclimate conditions in model application at the site level the two layer model showed its skills in simulating layer averaged soil moisture at field scale the model predicted layer averaged volumetric soil moisture content matched well with the pre processed layer averaged observed values a noticeable increase was observed for both layers after the rainfall events precipitation was the only water input pathway while evapotranspiration and gravity drainage were the two pathways for water leaving the soil domain the actual transpiration was calculated based on soil water availability of the first soil layer which was assumed to be the root zone layer in the two layer model when soil moisture of the root zone was decreasing during dry conditions with little or no precipitation the two layer model calculated the actual transpiration and evaporation rate according to the soil moisture of the whole root zone layer in reality moisture content at the soil surface may differ from that in deeper soil these differences could lead to under or over estimating transpiration and evaporation for different weather conditions furthermore accurate estimation of potential evapotranspiration could improve overall model performance owing to detailed meteorology data provided by scan every term in the penman monteith method was addressed properly additional uncertainty could be introduced if other simplified potential evapotranspiration calculation methods are used 4 2 2 quantifying sources of uncertainty within the bayesian framework the bayesian framework proved simple and robust in the two layer model calibration and uncertainty estimation under real hydroclimate and soil conditions as stated in the methodology we assumed that Œµ n 0 œÉ Œµ 2 the bayesian estimated values of residual error variance œÉ Œµ 2 for the first layer and the second layer shown in table 4 were 2 77 10 4 and 4 39 10 4 respectively model prediction variances for the first and the second layer were œÉ 2 2 88 10 4 and 4 52 10 4 respectively as shown in figures 12 a1 and a2 the darker grey bands are attributed to model prediction error coming from all sources of errors parametric observational hydroclimate data and Œµ the ratio œÉ Œµ 2 œÉ 2 was 96 for the first layer and 97 for the second layer which indicates that after conditioning on the processed observed moisture content data bulk of the modeling errors were caused by deficiencies in the model structure and errors in the observed and hydroclimate data the contribution of parametric uncertainty to the total error appears very small up to 4 and 3 in layers 1 and 2 respectively we also calculated the error variance attributed to parameters uncertainty œÉ œâ 2 as described in subsection 2 5 3 the calculated œÉ œâ 2 were 7 50 10 6 and 7 81 10 6 for the first layer and the second layer respectively parametric uncertainty contributed very little about 2 61 and 1 73 for the first and the second layer respectively to the model prediction variance the uncertainty bands before a prior and after a posterior conditioning on the observation data are plotted as grey and blue bands in fig 12 respectively we note that the reduced posterior parametric uncertainty was obtained after conditioning on the sizable preprocessed observed moisture content data these findings indicate that much of the uncertainty is attributed to observational hydroclimate data and model structural errors while parametric uncertainty contributed very little to the overall model uncertainty 4 2 3 parameter estimation and posterior distributions the overall good match between bayesian estimates and observed soil moisture contents of two soil layers indicates that the parameters were informed appropriately by the observations and are identifiable we further analyzed the posterior distributions of model input parameters fig 13 shows the histograms of posterior distributions overlaying prior distributions along with bmc estimated values of model input parameters most of the posterior distributions of model input parameters clustered around their bmc estimated values as shown in fig 13 for the root zone layer the posterior distributions of n Œ∏ res and Œ∏ sat narrowed around a small region the posterior distributions of Œ± and k s were clustered in a range narrower than the prior range while f s had its posterior distributions extended over a wider region of the prior ranges for the second layer the posterior distributions of n Œ∏ res Œ∏ sat and k s clustered in a small region compared to their priors while the posterior distribution of Œ± showed a wider range clustered and peaked distributions are associated with well identifiable parameters and less parameter uncertainty while flat and scattered distributions indicate more parameter uncertainty from fig 13 n Œ∏ sat Œ∏ res and k s for the first layer and the second layer were identifiable for their posterior distributions however Œ± for the two layers and f s for the first layer seemed non identifiable we conducted a nonparametric statistical kolmogorov smirnov k s test massey 1951 to further evaluate the identifiability of the model parameters the k s test was applied to quantify the maximum distance d max between the prior and posterior cumulative distribution functions cdfs of each model parameter if d max is significant at a certain confidence level the parameter can be declared identifiable because the two distributions are statistically different the d max values from the k s test are shown in table 5 the p values that correspond to d max for all model parameters were smaller than 0 001 indicating that all model parameters were identifiable these findings indicate that all parameters in the first and the second layer can be well informed by the site level soil moisture observations however the observations did not provide enough information that can be used to fully estimate the values for a water retention parameter Œ± for the first and the second layer and area index f s for determining the fraction of bare soil and vegetation cover studies have reported that in situ measurements of soil moisture content sometimes do not contain sufficient information to constrain van genuchten soil hydraulic parameters due to the small variability of the observations to represent a whole range of soil water states w√∂hling and vrugt 2011 nevertheless bmc methodology constrained the parameters very well for almost all of the parameters besides estimations of parameters for prior distribution using the pedotransfer function take into account the correlations between soil hydraulic parameters which is better than uninformed prior distribution using the informed priors can produce good results in estimating parameter values scharnagl et al 2011 application of soil moisture models requires simplifications of what is otherwise a complex unsaturated flow phenomenon the two layer model and bayesian mc simulations show a robust framework to model vertically averaged soil moisture and estimate soil hydraulic parameters at the field scale fig 13 4 3 implications of the two layer model three hypotheses have been tested through the assessment scenarios performed in this study the results indicate that the two layer model can successfully simulate layer integrated soil moisture content and water fluxes in the root zone and vadose zone below for various soil textures under highly variable atmospheric conditions at the surface and the prescribed head and flux boundary conditions at the bottom the numerical simplicity of the two layer model allows efficient coupling of ground surface phenomena to relatively shallow groundwater in large scale hydrological models rather easily in cases where higher vertical resolution is not required and when emphases are on the root and vadose zones and continuity of water fluxes the two layer model can be a robust numerical solution for soil moisture and water flux estimations one such example of the potential application of the two layer model is that in a wetland environment soils at the outer fringes of the wetland often alternate between saturated and unsaturated flow conditions during and between the hydroperiods a stable numerical solution can be too difficult to obtain under such flow conditions and when percolating water encounters soil layers of contrasting permeabilities high resolution numerical evaluation of re can be very challenging and may not always converge to a unique solution sharifi et al 2017 while the two layer integrated from of re can be an efficient alternative to simulate average soil moisture and water fluxes in complex wetland ecosystems we emphasize that higher order corrections can be an option to improve model performance in relatively thick soil profiles an extension of the model to multi layer integrated solution of re for deep and stratified soils is rather straightforward and can be explored in a future work 5 conclusions this study evaluated the two layer model using two numerical verification experiments and a model evaluation cast study the uncertainty and sources of errors were quantified using a bayesian framework the major conclusions are as follows 1 the numerical experiment with homogeneous soil profiles showed that the two layer model had excellent performance in predicting volumetric soil moisture and water fluxes nevertheless there is a slight decrease in model performance with increasing layer thickness and coarser soil textures the model performed better for the free drainage bottom boundary condition than the zero pressure head i e water table bottom boundary condition 2 the two layer model successfully deals with interfacial water fluxes in soil layers with contrasting properties without having any numerical instability or convergence issues 3 the model can predict layer averaged soil moisture at field scale with appropriate input data under highly variable hydroclimate and real soil conditions 4 much of the predictive uncertainty was attributed to the model structural and observational errors including errors in hydroclimate data in contrast parametric uncertainty was found to be very small and the parameters were identifiable from a bayesian point of view after conditioning on the observed volumetric moisture content data 5 the good match between likelihood weighted estimates of layer averaged volumetric moisture content and the observed values along with the computed 95 confidence limits indicate that the bmc method can be a robust framework for vadose soil hydraulic parameter identification and uncertainty estimation under real hydroclimate and soil conditions it should be noted that the two layer approximate solution of richards equation was intended for simulating average moisture content in the root zone or biologically active sediment layer in the presence of free drainage or a relatively shallow water table the two layer numerical model is not designed to simulate average soil moisture and fluxes in deep soils and a thick vadose zone extension of the two layer model solution to multiple soil layers can address highly stratified and deep soil profiles credit authorship contribution statement junhao he software methodology formal analysis writing original draft mohamed m hantush conceptualization methodology writing review editing latif kalin investigation methodology project administration writing review editing supervision sabahattin isik methodology software data curation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the u s epa through its office of research and development partially funded and collaborated in the research reported in this paper under contract ep c 11 010 with auburn university college of forestry wildlife and environment this document has been reviewed in accordance with u s environmental protection agency policy and approved for publication the views expressed in this article are those of the authors and do not necessarily represent the views or the policies of the u s environmental protection agency appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128327 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 supplementary data 3 supplementary data 4 supplementary data 5 supplementary data 6 supplementary data 7 supplementary data 8 supplementary data 9 
2901,a two layer model based on the integrated form of richards equation re was recently developed to simulate the soil water movement in the roots layer and the vadose zone with a relatively shallow and dynamic water table the model simulates thickness averaged volumetric water content and matric suction as opposed to point values and was numerically verified for three soil textures using hydrus as a benchmark however the strengths and limitations of the two layer model and its performance in stratified soils and under actual field conditions have not been tested this study further examined the two layer model using two numerical verification experiments and most importantly tested its performance at site level under actual highly variable hydroclimate conditions moreover model parameters were estimated and uncertainty and sources of errors were quantified using a bayesian framework first the two layer model was evaluated for 231 soil textures under varying soil layer thicknesses with a uniform soil profile second the two layer model was assessed for stratified conditions where the top and bottom soil layers have contrasting hydraulic conductivities the model was evaluated by comparing soil moisture and flux estimates to those from the hydrus model last a case study of model application using data from a soil climate analysis network scan site was presented bayesian monte carlo bmc method was implemented for model calibration and quantifying sources of uncertainty under real hydroclimate and soil conditions for a homogeneous soil profile the two layer model generally had excellent performance in estimating volumetric water content and fluxes while the model performance slightly declined with increasing layer thickness and coarser textured soils the model configurations regarding layer thicknesses and soil textures that generate accurate soil moisture and flux estimations were further suggested with the two layers of contrasting permeability model simulated soil moisture contents and fluxes agreed well with those computed by hydrus indicating that the two layer model accurately handles the water flow dynamics around the layer interface in the field application given the highly variable hydroclimate conditions the two layer model combined with the bmc method showed good agreement with the observed average soil moisture of the root zone and the vadose zone below rmse 0 021 during calibration and 0 023 during validation periods the contribution of parametric uncertainty to the total model uncertainty was too small compared to other sources the numerical tests and the site level application showed that the two layer model can reliably simulate thickness averaged soil moisture and estimate fluxes in the vadose zone under various soil and hydroclimate conditions results also indicated that the bmc method could be a robust framework for vadose zone hydraulic parameters identification and model uncertainty estimation keywords richards equation re soil moisture numerical solution hydrus bayesian monte carlo maximum likelihood estimation data availability data will be made available on request 1 introduction application of richards equation re to describe water movement in unsaturated soils can be very challenging at the field and watershed scales for many reasons including soil heterogeneity highly variable hydroclimate conditions and fluctuating shallow water table vereecken et al 2016 farthing and ogden 2017 integrated forms of point scale re allow numerically efficient coupling of land surface to shallow groundwater at larger scales by focusing the analysis on distinct soil zones such as soil horizons roots zone and vadose zone he et al 2021 recently the authors have developed a two layer integrated form of re to simulate one dimensional vertical unsaturated flow in the root zone and the vadose zone below he et al 2021 the purpose of developing the two layer model was to efficiently simulate vertically averaged soil moisture content in the two distinct soil zones and maintain continuity of water flux at the interface under various surficial and bottom flux and prescribed hydraulic head boundary conditions including a shallow water table the model was designed to simulate layer thickness averaged soil moisture as opposed to point values it is also numerically suitable for larger than point scale applications it can be used to couple land surface to groundwater in large scale hydrological models for which estimation of soil moisture and water fluxes at high vertical resolution might be unnecessary the two layer integrated form of re converted the partial differential equation pde of re to two coupled ordinary differential equations odes describing thickness averaged moisture content and interfacial water flux in two soil layers the coupled odes were solved by heun s method with the iterative corrector to reduce truncation error and improve stability the model handles variable precipitation plant transpiration soil evaporation and groundwater fluctuations details of the model can be found in he et al 2021 he et al 2021 evaluated their model for relatively simple atmospheric and bottom boundary conditions with only three homogeneous soil profiles by comparing their results to the one dimensional finite element model hydrus 1 d ≈°im≈Ønek et al 2008 as a benchmark the two layer model showed excellent accuracy and efficiency in estimating thickness averaged volumetric moisture content and water fluxes including plant transpiration in the roots layer however the authors did not examine the two layer model performance in stratified soils with contrasting permeabilities or different soil textures and most notably did not test the model with actual field data under real hydroclimate conditions further uncertainty of model predictions and sources of uncertainty were not examined nor quantified instability of numerical schemes at the interface of two different soil textures with contrasting permeabilities is well known miller et al 2013 zeng et al 2018 one of the proposed methodologies to deal with discontinuity in the hydraulic parameters is to properly average the hydraulic parameters at layers interfaces belfort et al 2013 lai and ogden 2015 the flux at the interface between two soil layers is conserved in the integrated form of re in the two layer model through properly derived expressions for the unsaturated hydraulic conductivity and matric potential at the interface he et al 2021 highly variable flux conditions at the surface and switching between prescribed head and flux boundary conditions abruptly can produce numerical instability and convergence problems in the solution of re equation zha et al 2019 this paper shows that the integrated form of re in the two layer model developed by he at al 2021 can handle numerical instability efficiently under highly variable hydroclimate conditions this paper further demonstrates 1 the integrated form of re can accurately simulate layer averaged soil moisture across all soil textures and efficiently maintain continuity of water fluxes in layers with contrasting permeabilities in the presence of shallow or deep water table 2 the model can reproduce observed data under actual field and hydroclimate conditions and 3 the model parameters are identifiable from a bayesian point of view and model uncertainty is dominated by structural and observational errors to test these hypotheses we conducted model verification and evaluation scenarios the model verification includes two numerical experiments varying soil textures and thicknesses and layers with contrasting permeability and model evaluation includes a site level application case study table 1 summarizes the model verification and evaluation scenarios the structure of the paper is as follows first the methodology used to evaluate model performance for homogeneous and heterogeneous soil scenarios is presented this is followed by the description of the scan site used in the field level application of the two layer model next the bmc method used in parameter and uncertainty estimation is described the results section provides a qualitative and quantitative comparison of the two layer model results to hydrus and field measured soil moisture estimates the strengths and weaknesses of the two layer model are scrutinized under discussion the manuscript ends with conclusions 2 methodology 2 1 data used in this study both synthetic and measured data were used in this study the synthetic data was utilized in the first numerical experiment of model verification which includes artificially created soil textures using pedotransfer functions with rosetta3 see section 2 4 1 and meteorological data with a cycle of prescribed rainfall intensities and potential transpiration rates in the second numerical experiment of model verification we collected data for two soil textures from hills et al 1989 who estimated the van genuchten soil hydraulic parameters from laboratory measurements the same synthetic meteorological data was also used in the second numerical experiment as to the model evaluation with site level application case study the measured data including soil texture soil moisture and meteorological data were obtained from the soil climate analysis network scan https www wcc nrcs usda gov scan see below sections for the detailed information of data being used the equipment used i e hardware and software are listed in supplementary material s4 2 2 the two layer model the two layer model is described by the following coupled ordinary differential equations refer to fig 1 on flow domain schematic illustration readers are referred to he et al 2021 for a detailed description of the model 1 h d Œ∏ 1 dt q 0 q 1 h s 2 h h d Œ∏ 2 dt Œ∏ 2 s dh dt q 1 q 2 in which 2a Œ∏ 1 t 1 h h 0 Œ∏ z t d z Œ∏ 2 t 1 h t h h t h Œ∏ z t d z 2b q 2 2 h Œ≤ k 1 1 Œ≤ k 2 œà 2 œà 1 Œ≤ k 1 1 Œ≤ k 2 where Œ∏ 1 and Œ∏ 2 are the first root zone and the second layer lower vadose soil average moisture contents respectively Œ∏ 2 s is the saturated water content of the second layer h is the thickness of the first layer l h is the depth to the water table l q 0 is the moisture flux at the soil atmosphere interface lt 1 positive downward q 1 is the moisture flux at the interface of the two layers lt 1 q 2 is the moisture flux at the bottom of the second layer and accounts for flux interactions between the vadose zone and the water table lt 1 s is the transpiration rate t 1 k 1 and k 2 are average unsaturated hydraulic conductivities of the first and the second layers respectively lt 1 œà 1 and œà 2 are average soil matric potential for the first and the second layer respectively lt 1 and Œ≤ h h h the coupled ordinary differential equations eqs 1 and 2 of the two layer model are solved by heun s method with the iterative corrector to reduce truncation error and improve stability actual plant transpiration rate s is calculated based on the moisture content of the root zone according to the method proposed by feddes 1982 the actual bare soil evaporation is estimated according to the average moisture content of the root zone layer 2 3 soil water retention curve the soil hydraulic characteristic relationships Œ∏ œà and k Œ∏ in this study were described by the van genuchten 1980 model 3 k Œ∏ k s s e 1 2 1 1 s e 1 m m 2 œà 0 k s œà 0 4 œà s e 1 Œ± se 1 m 1 1 m 5 se Œ∏ Œ∏ res Œ∏ sat Œ∏ res where s e is relative saturation k s is saturated hydraulic conductivity lt 1 Œ∏ res and Œ∏ sat are residual and saturated water content respectively n is pore size distribution index m is a fitting parameter defined as m 1 1 n and Œ± is the fitting parameter l 1 the parameters n Œª and Œ± are coefficients affecting the shape of the hydraulic functions 2 4 model verification experiments 2 4 1 soil texture and layers thicknesses in this test the two layer model was run with a homogeneous soil profile with 231 soil textures combined with 400 soil layer thickness scenarios under one prescribed upper boundary condition and two bottom boundary conditions the reference model hydrus ≈°im≈Ønek et al 2008 was run with the same soil layer thickness climate and boundary conditions in the numerical simulations each homogeneous soil profile was made up of soil texture identified by varying the percentage of soil separate of sand silt and clay during simulations the soil separates in each soil texture varied from 0 to 100 at 5 increments thus as shown in fig 2 231 soil textures were generated covering all possible textures on the usda soil texture triangle cosby et al 1984 the van genuchten soil hydraulic parameters including the water retention parameters and saturated hydraulic conductivity k s were estimated using rosetta3 rosetta3 is a python based open source pedotransfer functions model based on artificial neural networks ann developed by zhang and schaap 2017 this allowed us to generate the soil hydraulic parameters and saturated hydraulic conductivity for all 231 soil textures using sand silt and clay percentages as input the thickness of the first root zone and the second layer lower vadose soil varied from 10 to 200 cm at 10 cm increments thus the total soil depth varied from a minimum of 20 cm to a maximum of 400 cm this resulted in 400 soil layer thickness combinations for each soil texture the upper boundary condition involved an atmospheric scenario with a cycle of prescribed rainfall intensities and potential transpiration rates fig 3 the first 5 days had no rain but there was a 0 2 cm day potential transpiration days 5 10 had 2 cm day of constant rain but no transpiration demand this cycle was repeated until day 50 because hydrus and the two layer model calculate soil evaporation differently we only considered plant transpiration to allow for a consistent comparison of the two layer model with hydrus both the two layer model and hydrus adopt the root water uptake water stress response function proposed by feddes et al 1978 to calculate the actual plant transpiration rate the parameters for the stress reduction function were set to the values in wesseling 1991 for pasture values of root water uptake water stress response function parameters were œà 1 10 cm œà 2 25 cm œà 3 800 cm œà 4 8000 cm two bottom boundary conditions were applied 1 free drainage which refers to zero pressure gradient boundary at the bottom this boundary condition is suitable for situations where the water table is far below the domain of interest 2 zero pressure head boundary condition which describes the case where the water table is at the bottom of the soil column water table depth is equal to the total depth of the soil column h we set the initial moisture contents for all soil textures to the moisture content at 33 kpa field capacity simulations were carried out by the two layer model and hydrus for a 50 day period using a computational time step of 0 001 days in hydrus the soil domain was discretized using 101 equidistant nodes the soil moisture estimations for the first and the second layers were obtained by averaging the soil moisture contents of the nodes within each layer note that for fine textured soils with the genuchten water hydraulic parameter n less than 1 3 an air entry value of 2 cm is typically recommended in hydrus applications to overcome the convergence issue vogel and cislerova 1988 vogel et al 2000 this configuration significantly alters the hydraulic conductivity function however this modification in air entry pressure for fine textured soils was not necessary for the two layer model in order to make the two models comparable this option was not selected in hydrus instead the maximum number of iterations during any time step was changed from the default value of 10 to 100 this change sacrificed efficiency for accuracy in hydrus using the standard van genuchten model for fine textured soils model performance was evaluated using averaged rmse of soil moisture contents by averaging rmse values of moisture contents from the two soil layers there are 231 plots of rmse patterns each with different thicknesses of two soil layers and two bottom boundary conditions due to space limitations the results of only three soil textures are presented in this manuscript full results can be found in supplementary materials the three selected soil textures were coarse medium and fine textured soils sand loam and clay sand silt and clay fractions were selected to represent these three soil textures following the usda soil texture classification soil survey staff 1999 sandy soil was 90 sand 5 silt and 5 clay loamy soil was 40 sand 40 silt and 20 clay while clay soil was 10 sand 15 silt and 75 clay 2 4 2 layers with contrasting permeability we assessed the performance of the two layer model with coarse textured soil on top of fine textured soil and vice versa the coarse and fine textured soils used in this study were loamy fine sand and silty clay loam obtained from hills et al 1989 the van genuchten soil hydraulic parameter values of these two soil textures are shown in table 2 the thicknesses of the two soil layers were set to 30 cm the upper boundary condition was the same as the 5 day cycle weather pattern over 15 days as described earlier fig 3 again the free drainage and zero pressure head were the two bottom boundary conditions considered the initial moisture contents of both soil textures were set to the moisture content at 33 kpa 0 269 for loamy fine sand and 0 448 for silty clay loam results of soil moisture contents top and bottom flux terms and estimated transpiration rates were compared with those obtained from hydrus 2 5 model evaluation with a case study 2 5 1 site description the two layer model was applied to a scan site to assess its ability to predict soil moisture under highly variable hydroclimate conditions at the field scale site tuskegee scan site id 2115 from alabama usa was chosen as the study site which is located at 32 26 n and 85 45 w at an elevation of 122 m above mean sea level fig 4 the scan dataset provides site level soil moisture and meteorological data at daily time steps schaefer et al 2007 soil moisture was measured at five different soil depths which are 5 cm 2 in 10 cm 4 in 20 cm 8 in 50 cm 20 in and 100 cm 40 in to avoid days with subzero air temperature daily data were gathered from february 24th to october 31st for the years 2018 and 2019 data from 2018 were used for model calibration and data from 2019 were used for model validation our preliminary test showed that moisture redistribution always occurred within 2 days to minimize the uncertainty coming from the initial moisture content the first five days from february 24th to 28th made up the model warm up period results of the model simulated moisture contents were compared with field measurements from march 1st to october 31st to make the model outputs comparable with the observed soil moisture data the measured soil moisture contents at different depths were grouped into two soil layers by following the logic in the two layer model that the first layer represents the root zone where the plant water uptake occurs and the second layer is the lower vadose soil at the scan site the weather station and soil moisture sampling point were installed at the same location where the area was covered by short grass or natural fallow for most of the time albergel et al 2015 we consulted with the local usda service center in tuskegee for vegetation cover and rooting depth the dominant species for this scan site is bahiagrass paspalum notatum the depth where most of the root biomass is located is about 18 cm thus we assumed the top 20 cm of the soil to be the root zone layer and the next 30 cm below was the second layer based on the web soil survey soil survey staff natural resources conservation service 2019 the groundwater level at the site is below 200 cm however there is a small creek about 500 m southeast of the site the groundwater level in the area around the creek was about 110 cm inquired from web soil survey which could potentially influence soil moisture measurement in the deeper soil 100 cm the fifth sensor was excluded for model comparison due to the lack of groundwater level data thus we considered the total soil depth of interest to be 50 cm that includes the top four moisture sensors the first two moisture sensors belonged to the first layer and the fourth sensor belonged to the second layer the third sensor was located at the boundary between the two layers soil properties for four soil horizons within 50 cm soil profile were provided by the national cooperative soil survey survey 2017 including the percentage of sand silt clay and organic carbon bulk density moisture content at field capacity and moisture content at wilting point because the first and the second layer of the model domain contained several horizons the soil physical properties of each layer were calculated by weighted average according to the depth of the horizons within the layer percentage of sand silt clay and organic carbon and moisture contents at field capacity and wilting point were used as inputs to the rosetta3 model to estimate the van genuchten soil hydraulic parameters rosetta3 provided the prediction uncertainties of each van genuchten parameter as standard deviations meteorological data were available at daily time step for the simulation period including precipitation maximum and minimum air temperature relative humidity solar radiation and wind speed fao 56 penman monteith method allen et al 1998 was applied to calculate the daily potential evapotranspiration pet rate 2 5 2 model calibration for model calibration the two layer model was run from february 24th 2018 to oct 31st 2018 the upper boundary condition was atmospheric controlled which was described by precipitation and pet calculated pet and observed precipitation data for the model calibration period are shown in fig 5 potential evaporation for bare soil and potential transpiration rate for grass were calculated by partitioning pet using an area index f s the area index represents the fraction of bare soil and 1 f s is the fraction of vegetation cover at the study site the area of vegetation cover was unknown this area index can be calibrated in the model calibration process the bottom boundary condition was set to free drainage we ran the two layer model with Œ¥t 0 001 day 86 s during the calibration and validation periods 2 5 3 bayesian model parameter and uncertainty estimation the uncertainties introduced by input data and data used for calibration model parameters and imperfection in the model structure make the model output subject to errors the uncertainties of the two layer model in model applications stem mainly from the following specific sources 1 uncertainties may be introduced due to measurement errors limited soil moisture data and interpolation of observed data to obtain vertically averaged soil moisture contents for the two soil layers in the model domain 2 estimation of van genuchten parameter from basic soil texture data using rosetta3 3 averaging soil properties from different horizons to obtain averaged soil properties of two soil layers as inputs for rosetta3 and 4 model structural errors introduced by neglecting higher order terms in the derivation of equations 1 and 2 as well as not accounting for soil heterogeneity and other potentially important processes such as lateral flow and preferential pathways quantifying the uncertainties of the two layer model can provide a better idea of how the two layer model performs at the site level during the model calibration and uncertainty estimation we employed the bmc method for model calibration and uncertainty estimation the detailed methodology and procedure of bmc can be found in hantush and chaudhary 2014 and chaudhary and hantush 2017 in this study we considered the five van genuchten soil hydraulic parameters and the area index œâ Œ± n Œ∏ res Œ∏ sat k s f s as random variables uniform distributions of the values or their log transformations are commonly assumed as priors for the unknown parameters e g vrugt and bouten 2002 w√∂hling and vrugt 2008 huisman et al 2010 mboh et al 2012 k√∂pke et al 2019 the effect of priors diminishes with the size of the observed data and the choice of the prior distribution therefore becomes increasingly less important following scharnagl et al 2011 the prior distribution of van genuchten soil hydraulic parameters is defined as p x u a x b x where a x and b x are the lower and upper bounds respectively a x and b x are calculated as Œ≥ 4 œÉ where Œ≥ is rosetta3 predicted values and œÉ is the standard deviations of the predicted parameters the predicted values and corresponding standard deviations of Œ± n and k s from rosetta3 were given in log form the log values of these three parameters were assumed uniformly distributed based on their logarithmic standard deviations as prior distributions the values of these three parameters were sampled from the uniform distributions of the log10 values and then inverted to their original values the area index f s was assumed a uniformly distributed priori p f s u 0 1 the upper and lower bounds of prior distributions of model input parameters are shown in table 3 the relationship between the observed soil moisture at time t o t and the corresponding simulated output Œ∏ œâ t from the two layer model can be expressed as o t Œ∏ œâ t Œµ where Œµ Œµ 1 Œµ 2 Œµ m Œµ i n 0 œÉ Œµ 2 was assumed to be zero mean independent and normally distributed model residual error and m is the number of observations the error Œµ accounts for all sources of modeling errors described above observational parametric structural hydrometeorological inputs we generated 1 000 000 parameter sets by randomly drawing parameter values from their prior distributions fig 6 illustrates a brief portrayal of the bmc methodology applied in this study what follows is a summary description of the bmc methodology based on bayes theorem the posterior joint probability density function is given by 6 p œâ i o k l œâ i p œâ i where o o 1 o 2 o m is set of m observed moisture content values p œâ i o is the posterior probability mass of parameter set œâ i Œ± i n i Œ∏ res i Œ∏ sat i k s i f s i i 1 2 n where n is the number of randomly sampled parameter sets n 1 000 000 l œâ i p o œâ i is the likelihood of observations given œâ i p œâ i is the prior probability mass of the parameter set œâ i k is a normalizing factor such that i 1 n p œâ i o 1 that is k n i 1 n l œâ i where we have assumed equally likely parameter sets a prior p œâ i 1 n the objective function to optimize is the log likelihood function of model residual errors the joint log likelihood function given a set of m independent moisture content observations o 1 o 2 om and a parameter set œâ i is 7 ln l œâ i m 2 l n 2 œÄ m ln œÉ Œµ 1 2 k 1 m Œµ i œÉ Œµ 2 the likelihood of each generated parameter set œâ i can be obtained by maximizing eq 7 chaudhary and hantush 2017 7a l œâ i 2 œÄ e œÉ Œµ i 2 m 2 where l is the likelihood of œâ i in which 7b œÉ Œµ i 2 1 m k 1 m Œµ k œâ i 2 the posterior probability mass of œâ i is given by 8 p œâ i o l œâ i i 1 n l œâ i the bayesian estimate of layer averaged moisture content Œ∏ of the first and the second layer at any point in time is the conditional mean of Œ∏ given the observation 9 e Œ∏ o i 1 n e Œ∏ œâ i p œâ i o 1 i 1 n l x i i 1 n Œ∏ œâ i t l œâ i in which we made use of e Œ∏ œâ i Œ∏ œâ i t and eq 6 posterior probability distribution functions pdfs of the parameters œâ i Œ± i n i Œ∏ res i Œ∏ sat i k s i k c i can be obtained from the sampled values of each model parameter and corresponding posterior probability masses computed by eq 6 the confidence band for simulated posterior i e conditional on the observed data soil moisture content at time t can be generated from the following cumulative distribution function cdf hantush and chaudhary 2014 10 f y o 1 2 1 2 i 1 n e r f y Œ∏ œâ i t 2 œÉ Œµ i p œâ i o 1 2 1 2 i 1 n l œâ i i 1 n e r f y Œ∏ œâ i t 2 œÉ Œµ i l œâ i where y is the value of soil moisture content this equation can be inverted using any root finding techniques to obtain percentiles and construct a confidence band for moisture content at any point in time given the hydroclimate data model performance was evaluated by estimating rmse and nash sutcliffe efficiency e ns obtained from the bayesian estimates eq 9 and corresponding hydrus or layer averaged observed data of volumetric soil moisture content Œ∏ because soil moisture was measured at discrete spatial points linear interpolation was applied to field measurements to compare model outputs with measurements for the two simulated soil layers we first interpolated the soil moisture contents along the 50 cm soil column according to the observations at four depths and then calculated averaged moisture contents for the first and the second layer by averaging interpolated values from 1 cm to 20 cm and 20 cm to 50 cm respectively the model performance indices were calculated for each layer separately model predictive uncertainty of volumetric soil moisture content was obtained as follows random samples of Œ∏ at each day for each soil layer were drawn from eq 10 the variance of Œ∏ at each day was calculated from the randomly drawn values the sample average of the variances œÉ 2 over the simulation 245 days was taken as measures of total model prediction uncertainty for each layer the bayesian estimated values of residual error variance œÉ Œµ 2 is that part œÉ 2 which accounts for measurement model structural errors and uncertainty in the forcing input hydroclimate data an estimate of the error variance attributed to parameters uncertainty œÉ œâ 2 was obtained from the mc simulated moisture contents n 106 and their corresponding posterior probability masses calculated by eq 8 the calculated variances were then averaged over the simulation as a measure of the parametric uncertainty variance œÉ œâ 2 we note that œÉ 2 is not equal to œÉ Œµ 2 œÉ œâ 2 due to nonlinear interactions and dependence of œÉ Œµ 2 other sources of errors on parameter values the ratio œÉ œâ 2 œÉ 2 is an approximate estimate of the fraction of total error contributed by uncertainty in the parameters and œÉ Œµ 2 œÉ 2 is an approximate estimate of the fraction of total error contributed by other sources of errors measurement structural and hydroclimate forcing 3 results 3 1 soil textures and layers thicknesses fig 7 shows the rmse values obtained from the two layer model and hydrus simulated Œ∏ for three soil textures using free drainage a and zero pressure head b bottom boundary conditions the plots show the contour lines and heat maps of rmse with different thicknesses of the first root zone and the second layer fig 8 shows an example of the simulated moisture contents of two soil layers from the two layer model and hydrus using 50 cm thickness for both layers respectively as shown in fig 7 rmse has an increasing trend with increased layer thickness for both layers with the free drainage bottom boundary condition the rmse for three soil textures was always lower than 0 015 with a shallow root zone less than 30 cm rmse increased rapidly again never exceeding 0 015 with the increasing thickness of the second layer the same trend was observed with a thin second layer but this was less pronounced in the figures when considering the water table at the bottom of the soil profile zero pressure head the performance of the two layer model varied for different soil textures the model performance with the coarse textured soils dropped with increased layer thicknesses rmse was highest for sand and clay soil texture with the presence of a shallow water table in fig 7 for sand rmse was lower than 0 01 only when the first layer thickness was less than 60 cm and the second layer thickness was below 90 cm when soil texture became finer model performance improved rmse for loam dropped below 0 01 for all thickness scenarios whereas for clay the maximum rmse was 0 02 when all the 231 soil textures are pooled the minimum and maximum rmse were 0 and 0 018 respectively for the free drainage bottom boundary condition and 0 and 0 048 for the zero pressure head bottom boundary condition supplementary material s1 fig 7 summarizes model performances as a function of layer thicknesses for a given soil texture another way of assessing model performance is plotting rmse as a function of soil texture on the soil texture triangle for various soil layer thicknesses fig 9 shows one such example where the variation of rmse with soil texture is shown for 50 cm root zone depth combined with second layer thicknesses of 10 100 and 200 cm under the two bottom boundary conditions rmse heat maps for all other thickness combinations are available in the supplementary material s2 in fig 9 the two layer model performed better with the free drainage bottom boundary condition than the water table bottom boundary condition this was also the case with other thickness combinations supplementary material s2 the general pattern in each soil triangle is that rmse increases with increased sand fraction the model performance also generally increases with increased silt fraction which is more evident for deeper soils the maximum rmse for the case of free drainage at the bottom was 0 008 in fig 9 and it corresponds to the case with the second layer thickness being 200 cm and a very high sand fraction with the zero pressure head boundary condition the maximum error was 0 038 which happened with the same thickness and soil texture thus rmse values from the free drainage bottom boundary condition were lower than those from the zero pressure head bottom boundary condition with the increase of soil thickness rmse values often increased from the bottom left of the soil triangle high fraction of sand then rmse values increased in the top angle high fraction of clay cumulative top and bottom fluxes and actual plant transpiration obtained by the two layer model were also compared to hydrus counterparts the overall model performance for cumulative bottom flux decreased with the increasing soil profile thickness the full comparisons of cumulative bottom flux and actual transpiration estimation between the two models can be found in supplementary material s3 and s4 3 2 layers with contrasting permeability the results from simulations with the two layer model and hydrus for 30 cm of loamy fine sand high permeability overlaying 30 cm of silty clay loam low permeability and vice versa are shown in figs 10 and 11 both models simulated soil moisture contents of the low permeability layer were consistently higher than the high permeability layer as shown in figs 10 and 11 the soil moisture contents of the two soil layers and flux estimations from the two layer model matched those from hydrus moisture contents varied correspondingly with the atmospheric condition i e moisture contents in both layers declined in response to the transpiration demand which was followed by an increase over the next 5 days due to rain for the soil layer configuration with high permeability soil overlaying the low permeability soil fig 10 the two layer model showed excellent performance under the free drainage bottom boundary condition the rmse of both layers was lower than 0 01 the cumulative top and bottom flux from the two layer model were identical to those from hydrus while the cumulative transpiration was slightly higher than hydrus with the zero pressure head bottom boundary condition the moisture content in the first layer from the two layer model was higher than that from hydrus in the first 5 days with only transpiration while in the next 5 days with precipitation the moisture content of the first layer was lower than that from hydrus the rmse for the first layer was 0 02 while moisture contents of the second layer matched very well with that from the reference model with rmse equal to 0 002 the cumulative top flux and transpiration rate were identical to those from hydrus the cumulative bottom flux for the first 5 days was higher absolute value than that from hydrus but similar for the next 10 days when the low permeability soil overlaid the high permeability soil fig 11 soil moisture and cumulative fluxes estimated by the two layer model were almost identical to their counterparts generated by hydrus for both bottom boundary conditions the rmse values for the first and second layers average moisture contents in both bottom boundary conditions were consistently lower than 0 01 3 3 application of the two layer model to the scan site figures 12 a1 and a2 show the two layer model calibration results from march 1st 2018 to october 31st 2018 the bayesian estimates eq 9 95 confidence interval and observed soil moisture contents of the root zone and the soil layer below respectively the 95 confidence limits were obtained by inverting eq 10 using the bisection method the bayesian estimated vertically averaged soil moisture contents of both layers compare well with the corresponding aggregated observations given the uncertainty and errors in preprocessing of limited and discrete observed point data set and linear interpolation of what could actually be a nonlinear soil moisture distribution the rmse and e ns values are 0 016 and 0 73 for the first layer and 0 021 and 0 62 for the second layer respectively all the observed soil moisture values fell within the 95 confidence bands the 95 confidence intervals and the bayesian estimates a posteriori of model input parameters and œÉ Œµ 2 calculated by bmc are shown in table 4 figures 12 b1 and b2 show bmc predicted soil moisture contents along with 95 confidence bounds and observed soil moisture contents of both soil layers for the validation period march 1st october 31st 2019 the soil variability and magnitude of moisture contents are adequately captured by the bmc estimates as shown in figures 12 b1 and b2 although model performance dropped somewhat for the validation period it can still be considered good with rmse values equal to 0 023 and 0 023 and e ns values equal to 0 73 and 0 72 for the first and second layers respectively the prior and posterior distributions of the model input parameters are shown in fig 13 the two layer model appears robust in simulating hydrometeorological conditions outside the range used for model calibration 4 discussion 4 1 model verification with numerical experiments 4 1 1 soil textures and layer thicknesses the numerical simulations on homogeneous soil profiles revealed the performance of the two layer model on various soil textures and layer thickness conditions overall the two layer model performs better with the free drainage than the zero pressure head bottom boundary condition with the influence of the water table groundwater affects the soil moisture of the layer above mainly through capillary actions in the two layer model solution the suction force in the second layer is averaged over the layer corresponding to the thickness the truncation errors incurred by neglecting higher than first order terms leading to eqs 1 and 2 increase the error in deeper soil and can be more pronounced near the water table where capillary pressure gradient can be highly nonlinear except for coarse textured soil with the water table at the bottom fig 7 where the two layer model suffers from the increased thickness of both layers model performance deteriorates only with relatively thicker lower vadose soil the model still performed very well for a relatively thick roots layer 2 m except for sandy soil and water table at the bottom the highly nonlinear relationship between matric pressure head and moisture content in coarse soils near saturation amplifies the truncation errors in the computed matric pressure head gradient at the water table and consequently the average soil moisture computed by the model 4 1 2 layers with contrasting permeability solving re for layered soils has been challenging because of the discontinuity of moisture and hydraulic properties moving from one soil texture to another two phenomena are often related to this discontinuity the capillary barrier and the hydraulic barrier alfnes et al 2004 si et al 2011 one attempt to address or smooth the discontinuity is to find suitable values of hydraulic conductivity and matric potential at the interface of two different soil textures matthews et al 2004 szymkiewicz and helmig 2011 in the two layer model the interface flux term q 1 is expressed as a function of the hydraulic conductivity and vertically averaged matric potential of the first and second layer given by eq 2b he et al 2021 the two layer model appropriately handles the discontinuity of hydraulic properties with two extreme soil layering scenarios the results reflected these two types of barriers considering the free drainage bottom boundary condition when loamy fine sand is on top of silty clay loam and if flux from the upper layer at the interface is higher than the saturated conductivity of the lower layer the hydraulic barrier occurs in this case only part of the water flux is transmitted downward and the excess water is initially retained in the upper layer in figs 10 a1 during the first two days of the rainfall period day 6 to day 7 the moisture content of the upper layer started to increase at day 6 while the increase of the moisture content for the lower layer was observed at day 7 because of the hydraulic barrier the discontinuity created by the hydraulic barrier was gradually mitigated when both layers received rainfall resulting in increased hydraulic conductivities for both layers furthermore the capillary barrier can be observed in figs 11 a1 during the rainfall period from day 6 to day 10 the moisture content of the lower layer had slower rate of increase than that in the upper layer when figs 11 a1 is compared to figs 10 a1 the highest moisture contents of the loam textured layer were similar 0 428 in figs 11 a1 vs 0 438 in figs 10 a1 however the highest moisture content of the sandy soil layer in figs 11 a1 0 143 was lower than that in figs 10 a1 0 173 which indicates that the capillary barrier occurred during the rainfall period in figs 11 a1 our results suggest that the first order approximation of taylor expansion of conductivity and matric potential at the interface in the two layer model can be a solution to deal with heterogeneous soil profiles 4 1 3 on the model assumptions the simulated results of soil moisture and fluxes for homogeneous and heterogeneous soil profiles indicate the assumptions leading to the development of the two layer model are adequate these assumptions are 1 truncation of the higher order terms in the taylor series approximations of matric potential and unsaturated conductivity at the interface of the two soil layers eqs 11 and 19 in he et al 2021 and 2 œà i œà Œ∏ i and k i k Œ∏ i these assumptions likely contributed to the minor deviations of the two layer model results from hydrus results however it is impossible to identify each assumption s relative contribution further the errors contributed by the assumptions of œà i œà Œ∏ i and k i k Œ∏ i are likely to be more pronounced in coarse textured soils sand than in fine textured soils because of the highly nonlinear characteristic relationships near saturation e g figs 7 b1 for example when the water table is not too far below the root zone the distribution of soil moisture in a predominantly sandy soil becomes highly nonlinear thus the deviations between œà i and œà Œ∏ i and k i and k Œ∏ i are expected to be the highest these differences can be exacerbated further by a relatively thick vadose soil below the root zone second layer model performance is improved when layer thickness decreases because as moisture variations become smaller the assumption of œà i œà Œ∏ i and k i k Œ∏ i becomes more tenable in the case of a deep water table and free drainage bottom boundary condition the nonlinearity of moisture distribution is lower compared to zero pressure head bottom boundary condition which is more favorable for smaller truncation errors and the assumption of œà i œà Œ∏ i and k i k Œ∏ i thus the overall model performance for the free drainage bottom boundary condition is better than for a shallow water table zero pressure head bottom boundary condition nevertheless if the temporal variability of the atmospheric forcing is high soil moisture distribution can have higher spatial variability especially with fine textured soils supplementary material s2 in addition because of the highly nonlinear characteristic of water potential near saturation above the water table soil evaporation near the soil surface and heterogeneous root water uptake can also induce heterogeneity of moisture profile and eventually lead to deviations from the above assumptions thus higher order corrections are needed to explore improved model performance in the case of heterogeneous distribution of Œ∏ 4 2 case study application 4 2 1 model performance under highly variable hydroclimate conditions in model application at the site level the two layer model showed its skills in simulating layer averaged soil moisture at field scale the model predicted layer averaged volumetric soil moisture content matched well with the pre processed layer averaged observed values a noticeable increase was observed for both layers after the rainfall events precipitation was the only water input pathway while evapotranspiration and gravity drainage were the two pathways for water leaving the soil domain the actual transpiration was calculated based on soil water availability of the first soil layer which was assumed to be the root zone layer in the two layer model when soil moisture of the root zone was decreasing during dry conditions with little or no precipitation the two layer model calculated the actual transpiration and evaporation rate according to the soil moisture of the whole root zone layer in reality moisture content at the soil surface may differ from that in deeper soil these differences could lead to under or over estimating transpiration and evaporation for different weather conditions furthermore accurate estimation of potential evapotranspiration could improve overall model performance owing to detailed meteorology data provided by scan every term in the penman monteith method was addressed properly additional uncertainty could be introduced if other simplified potential evapotranspiration calculation methods are used 4 2 2 quantifying sources of uncertainty within the bayesian framework the bayesian framework proved simple and robust in the two layer model calibration and uncertainty estimation under real hydroclimate and soil conditions as stated in the methodology we assumed that Œµ n 0 œÉ Œµ 2 the bayesian estimated values of residual error variance œÉ Œµ 2 for the first layer and the second layer shown in table 4 were 2 77 10 4 and 4 39 10 4 respectively model prediction variances for the first and the second layer were œÉ 2 2 88 10 4 and 4 52 10 4 respectively as shown in figures 12 a1 and a2 the darker grey bands are attributed to model prediction error coming from all sources of errors parametric observational hydroclimate data and Œµ the ratio œÉ Œµ 2 œÉ 2 was 96 for the first layer and 97 for the second layer which indicates that after conditioning on the processed observed moisture content data bulk of the modeling errors were caused by deficiencies in the model structure and errors in the observed and hydroclimate data the contribution of parametric uncertainty to the total error appears very small up to 4 and 3 in layers 1 and 2 respectively we also calculated the error variance attributed to parameters uncertainty œÉ œâ 2 as described in subsection 2 5 3 the calculated œÉ œâ 2 were 7 50 10 6 and 7 81 10 6 for the first layer and the second layer respectively parametric uncertainty contributed very little about 2 61 and 1 73 for the first and the second layer respectively to the model prediction variance the uncertainty bands before a prior and after a posterior conditioning on the observation data are plotted as grey and blue bands in fig 12 respectively we note that the reduced posterior parametric uncertainty was obtained after conditioning on the sizable preprocessed observed moisture content data these findings indicate that much of the uncertainty is attributed to observational hydroclimate data and model structural errors while parametric uncertainty contributed very little to the overall model uncertainty 4 2 3 parameter estimation and posterior distributions the overall good match between bayesian estimates and observed soil moisture contents of two soil layers indicates that the parameters were informed appropriately by the observations and are identifiable we further analyzed the posterior distributions of model input parameters fig 13 shows the histograms of posterior distributions overlaying prior distributions along with bmc estimated values of model input parameters most of the posterior distributions of model input parameters clustered around their bmc estimated values as shown in fig 13 for the root zone layer the posterior distributions of n Œ∏ res and Œ∏ sat narrowed around a small region the posterior distributions of Œ± and k s were clustered in a range narrower than the prior range while f s had its posterior distributions extended over a wider region of the prior ranges for the second layer the posterior distributions of n Œ∏ res Œ∏ sat and k s clustered in a small region compared to their priors while the posterior distribution of Œ± showed a wider range clustered and peaked distributions are associated with well identifiable parameters and less parameter uncertainty while flat and scattered distributions indicate more parameter uncertainty from fig 13 n Œ∏ sat Œ∏ res and k s for the first layer and the second layer were identifiable for their posterior distributions however Œ± for the two layers and f s for the first layer seemed non identifiable we conducted a nonparametric statistical kolmogorov smirnov k s test massey 1951 to further evaluate the identifiability of the model parameters the k s test was applied to quantify the maximum distance d max between the prior and posterior cumulative distribution functions cdfs of each model parameter if d max is significant at a certain confidence level the parameter can be declared identifiable because the two distributions are statistically different the d max values from the k s test are shown in table 5 the p values that correspond to d max for all model parameters were smaller than 0 001 indicating that all model parameters were identifiable these findings indicate that all parameters in the first and the second layer can be well informed by the site level soil moisture observations however the observations did not provide enough information that can be used to fully estimate the values for a water retention parameter Œ± for the first and the second layer and area index f s for determining the fraction of bare soil and vegetation cover studies have reported that in situ measurements of soil moisture content sometimes do not contain sufficient information to constrain van genuchten soil hydraulic parameters due to the small variability of the observations to represent a whole range of soil water states w√∂hling and vrugt 2011 nevertheless bmc methodology constrained the parameters very well for almost all of the parameters besides estimations of parameters for prior distribution using the pedotransfer function take into account the correlations between soil hydraulic parameters which is better than uninformed prior distribution using the informed priors can produce good results in estimating parameter values scharnagl et al 2011 application of soil moisture models requires simplifications of what is otherwise a complex unsaturated flow phenomenon the two layer model and bayesian mc simulations show a robust framework to model vertically averaged soil moisture and estimate soil hydraulic parameters at the field scale fig 13 4 3 implications of the two layer model three hypotheses have been tested through the assessment scenarios performed in this study the results indicate that the two layer model can successfully simulate layer integrated soil moisture content and water fluxes in the root zone and vadose zone below for various soil textures under highly variable atmospheric conditions at the surface and the prescribed head and flux boundary conditions at the bottom the numerical simplicity of the two layer model allows efficient coupling of ground surface phenomena to relatively shallow groundwater in large scale hydrological models rather easily in cases where higher vertical resolution is not required and when emphases are on the root and vadose zones and continuity of water fluxes the two layer model can be a robust numerical solution for soil moisture and water flux estimations one such example of the potential application of the two layer model is that in a wetland environment soils at the outer fringes of the wetland often alternate between saturated and unsaturated flow conditions during and between the hydroperiods a stable numerical solution can be too difficult to obtain under such flow conditions and when percolating water encounters soil layers of contrasting permeabilities high resolution numerical evaluation of re can be very challenging and may not always converge to a unique solution sharifi et al 2017 while the two layer integrated from of re can be an efficient alternative to simulate average soil moisture and water fluxes in complex wetland ecosystems we emphasize that higher order corrections can be an option to improve model performance in relatively thick soil profiles an extension of the model to multi layer integrated solution of re for deep and stratified soils is rather straightforward and can be explored in a future work 5 conclusions this study evaluated the two layer model using two numerical verification experiments and a model evaluation cast study the uncertainty and sources of errors were quantified using a bayesian framework the major conclusions are as follows 1 the numerical experiment with homogeneous soil profiles showed that the two layer model had excellent performance in predicting volumetric soil moisture and water fluxes nevertheless there is a slight decrease in model performance with increasing layer thickness and coarser soil textures the model performed better for the free drainage bottom boundary condition than the zero pressure head i e water table bottom boundary condition 2 the two layer model successfully deals with interfacial water fluxes in soil layers with contrasting properties without having any numerical instability or convergence issues 3 the model can predict layer averaged soil moisture at field scale with appropriate input data under highly variable hydroclimate and real soil conditions 4 much of the predictive uncertainty was attributed to the model structural and observational errors including errors in hydroclimate data in contrast parametric uncertainty was found to be very small and the parameters were identifiable from a bayesian point of view after conditioning on the observed volumetric moisture content data 5 the good match between likelihood weighted estimates of layer averaged volumetric moisture content and the observed values along with the computed 95 confidence limits indicate that the bmc method can be a robust framework for vadose soil hydraulic parameter identification and uncertainty estimation under real hydroclimate and soil conditions it should be noted that the two layer approximate solution of richards equation was intended for simulating average moisture content in the root zone or biologically active sediment layer in the presence of free drainage or a relatively shallow water table the two layer numerical model is not designed to simulate average soil moisture and fluxes in deep soils and a thick vadose zone extension of the two layer model solution to multiple soil layers can address highly stratified and deep soil profiles credit authorship contribution statement junhao he software methodology formal analysis writing original draft mohamed m hantush conceptualization methodology writing review editing latif kalin investigation methodology project administration writing review editing supervision sabahattin isik methodology software data curation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the u s epa through its office of research and development partially funded and collaborated in the research reported in this paper under contract ep c 11 010 with auburn university college of forestry wildlife and environment this document has been reviewed in accordance with u s environmental protection agency policy and approved for publication the views expressed in this article are those of the authors and do not necessarily represent the views or the policies of the u s environmental protection agency appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128327 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 supplementary data 3 supplementary data 4 supplementary data 5 supplementary data 6 supplementary data 7 supplementary data 8 supplementary data 9 
2902,traditional flood control projects such as dams and gates may disrupt river connectivity resulting in the fragmentation of river habitats leaky barriers as a new method of flood defense are gradually used in flood management especially in small rivers due to functions of the engineering in ecological and connecting rivers and regulating floods understanding the hydraulic effects and especially the backwater rise caused by leaky barriers is necessary to assess its impact and optimize the design this paper investigates the influence of the leaky barrier on hydrodynamics through a designed flume experiment a formula that reveals the backwater effects of the barrier was obtained by solving the momentum and continuity equations comparing the predicted and measured values of upstream water depth the difference was within a reasonable range based on the results the factors affecting the backwater rise are the froude number of the approaching flow downstream water depth and the longitudinal length drag coefficient the solid volume fraction of the leaky barriers among the characteristics of leaky barrier the solid volume fraction is the main factor affecting the backwater effect the findings are helpful to understand the hydraulic influence of leaky barriers and can provide references for practical project keywords flooding control natural flood management leaky barrier backwater effect flume experiment data availability data will be made available on request 1 introduction flooding is one of the most devastating natural disasters arnell and gosling 2016 dadson et al 2017 in order to resist the adverse effects of flooding human build various engineering measures to control flooding traditional projects such as dams flood walls flood gates and flood storage reservoirs alleviate flood risk to a certain extent but they may also block rivers and destroy the connection of the river system tockner and stanford 2002 mccartney and de la hera 2004 in addition they can also affect the normal reproduction and spread of species and have a part adverse impact on the environment poff et al 2007 to meet these threats there is an increasing interest in soft engineering in the form of natural flood management nfm nicholson et al 2012 nfm focuses on small scale intervention approaches and mimics or works with natural processes to achieve the purpose of reducing flood quinn et al 2013 lane 2017 leaky barriers bunds storage ponds ditches and swales and other sustainable drainage approaches are typical forms of nfm howarth 2017 studies show that nfm can offer ecological benefits such as improving water quality slowing down soil degradation and increasing biodiversity janes et al 2017 hankin et al 2018 in all forms of nfm the introduction of leaky barriers in the upper and middle catchments of rivers is a cost effective measure muhawenimana et al 2021 leaky barriers are constructed by spanning logs above and across the stream bed which are further secured in the banks with dowels or existing stakes usually leaky barriers leave a gap with the riverbed bottom to allow the normal river flow to pass underneath along with fish and other aquatic creatures and attenuate water by diverting flow onto floodplains only in high flows fig 1 such structures intercept part of the river and produce a certain backwater effect which leads to enhancing the floodplain storage and increasing the evaporation and infiltration of overflow water on the ground thus reducing river runoff and alleviating flood gippel 1995 thomas and nisbet 2012 early studies have also confirmed that wood debris and other floating trees in rivers affect navigation and excessive barrier blockage also increases the risk of flood young 1991 shields and gippel 1995 so many of these natural barriers in river systems have been removed gallisdorfer et al 2014 in recent years people have given rise to an interest in reintroducing leaky barriers in river catchments as realized that woody accumulations are beneficial to the restoration of river habitats leakey et al 2020 to achieve a trade off between creating suitable habitats and reducing flood risk the design of leaky barriers should be very careful but till now there are few design criteria available shields et al 2004 burgess gamble et al 2017 this could be due to the poor understanding of the effects of leaky barriers on river flow and the fluid forces acting on them bennett et al 2015 while such knowledge is crucial for supporting the evaluation of the flood hazard and optimization of the structural design mathematical modeling is an optional way to study the effects of leaky barriers some models have been presented by changing parameters such as hydraulic roughness coefficient manning s n and the channel geometry thomas and nisbet 2012 dixon et al 2016 rasche et al 2019 to model the flow obstructing nature of leaky barriers however those models can t accurately represent the hydraulic complexity of the flow generated by natural and engineered leaky barriers consisting of multiple dowels manners et al 2007 schalko et al 2018 2019 and it may not be appropriate to apply the same methods to other flow conditions or sites quinn et al 2013 flume experiments have also been conducted to study the backwater rise due to large woody debris researchers have worked out influencing factors for the backwater characteristics based on different experimental setups and the influencing factors included approach flow froude number loose large wood volume compactness of the large wood the cross sectional blockage ratio leaky barrier longitudinal length and so on schmocker and hager 2013 schalko et al 2018 2019 muhawenimana et al 2021 thus by conducting regression analysis they have derived empirical equations of different forms however none of these equations have shown wide applicability for varied hydraulic conditions and due to different considerations some of them even come to opposite conclusions the main reason is that the knowledge of detailed hydraulic characteristics of open channel flow affected by channel spanning leaky barriers is still limited so it is necessary to investigate the flow characteristics with leaky barriers and put forward a method with relatively wide adaptability to predict upstream water surface elevation or backwater water rise here we designed laboratory experiments to quantify the effect of leaky barriers on upstream and downstream hydrodynamic alterations by generalizing the leaky barrier as a porous structure we further combined the resistance law and the continuity equation to present a theoretical formula for the upstream water depth of open channel featured with a leaky barrier these analyses can increase our understanding of the flow impact of leaky barriers and propose suggestions for optimizing their performance 2 materials and methods 2 1 experimental setup laboratory experiments were performed in a circulating rectangular channel flume in the state key laboratory of water resources and hydropower engineering science at wuhan university china the experimental set up was presented in fig 2 a showing the 16 m long 0 6 m wide and 0 6 m deep recirculating flume with a flat bottom longitudinal flow direction was defined as positive in the downstream direction x while lateral and vertical flow direction were defined as y and z respectively and the origin of the axes was at the bottom of the flume downstream of the barrier test flow discharge was controlled by regulating valve set at the inlet of flume an electromagnetic flowmeter was used to record the discharge and the water depth was adjusted by a tailgate located at the flume outlet two rulers were fixed along the flume sidewall 1 5 m upstream and downstream of the model the preliminary experiment showed that the water level was nearly stable outside this range to measure the water depth of the upstream and downstream separately leaky barrier was installed in the channel at nearly 9 4 m downstream of the flume inlet with its main characteristics depicted in fig 2b leaky barrier was constructed using individual wooden dowels with a diameter d 0 025 m it comprised three dowel rows in the vertical and twelve dowels in the longitudinal direction featuring a height h s of 0 095 m a longitudinal length l s of 0 3 m and a lateral width b of 0 6 m all logs of the barrier were oriented perpendicular to the flow direction with a vertical gap b 0 of 0 055 m between the lowest dowel edge and flume bed and a vertical gap b of 0 01 m among other dowel rows to allow flow through the model was fixed by a plastic plate stuck on the channel walls and through the preliminary experiment the plate itself had a negligible effect on the approach flow conditions and its effect on backwater rise can be ignored a summary of the experimental set up is presented in table 1 with subscript 1 indicating upstream and subscript 2 indicating downstream of the barrier the solid volume fraction was defined by œï v s v l with v l b h 2 l s and vs is the volume occupied by the solid leaky barrier that was actually submerged hydraulic conditions included the discharge q and the mean flow depth h 1 and h 2 the bulk velocity u 1 and u 2 was defined as u q bh froude number was fr u gh with g denoting gravity acceleration and reynolds number was re u r œÖ with œÖ denoting the fluid kinematic viscosity and r denoting the channel hydraulic radius 2 2 velocity measurements flow velocities within the proximity of the completely submerged leaky barrier structure test 8 were measured using a sideways looking acoustic doppler velocimeter adv nortek vectrino velocity profiles were taken at 6 locations upstream and 15 locations downstream of the barrier as indicated in fig 3 between x 495 345 mm upstream and x 30 300 mm downstream of the barrier the longitudinal interval was set as 30 mm while between x 300 550 mm downstream of the structure the distance was increased to 50 mm the vertical interval of the sampling point was 5 mm fig 3 all measured points were on the channel midline y 0 3 m during measurements a sampling rate of 200 hz over a sampling period ranging from 5 to 20 min was adopted to capture representative high frequency turbulent fluctuations and to ensure adequate data quality velocity data were filtered using matlab r2016b by removing the data with an insufficient signal to noise ratio snr of 15 db and a correlation of 70 and then removing spikes using the method of goring et al goring and nikora 2002 2 3 theoretical analysis on backwater rise a leaky barrier was assumed to be dynamically similar to an array of rigid cylindrical elements then following the description used in canopy flows the drag per fluid volume within the structure d x n m3 can be represented by a quadratic drag law kaimal and finnigan 1994 1 d x œÅ c d a u 2 2 1 œï where œÅ kg m 3 is the fluid density cd is drag coefficient which is generally considered to be 0 9 to 1 0 gippel et al 1996 and in the present study the value of cd was set as 1 0 u m s is the temporally and spatially averaged longitudinal velocity a m 1 is denoted the frontal area per canopy volume œï is the solid volume fraction of the leaky barrier structure which is the ratio of barrier solid volume vs to control volume vl as described in section 2 1 and because of the leaky barrier consisting of circular cylinders with diameter d then œï œÄ a d 4 nepf 2012 flow within the barrier was assumed to be a steady one dimensional flow with hydrostatic pressure distribution the compressibility of fluid was not considered and the momentum correction factor equals 1 0 by neglecting the effect of bed slope and sidewalls shear stress the integrated conservation of momentum for the control volume between upstream and downstream was then presented 2 œÅ b h 2 u 2 u 2 u 1 1 2 œÅ g b 1 œï h 1 2 h 2 2 1 2 œÅ b l s c d a u 1 2 h 1 in which the left hand side of equation 2 shows the net change in momentum with u q bh while the first term on the right hand side of equation 2 represents the net hydrostatic pressure force and the second term is the drag within the barrier in which the water depth and velocity within the structure was approximated by the corresponding values at the upstream edge combining the continuity equation q u 1 bh 1 u 2 bh 2 then 3 h 1 h 2 h 2 3 3 h 1 h 2 h 2 2 2 h 1 h 2 h 2 2 f r 2 2 1 œï h 1 h 2 h 2 l s c d a 1 œï f r 2 2 0 in which f r 2 u 2 g h 2 is the froude number of the downstream channels and because of h 1 h 2 h 2 1 by neglecting h 1 h 2 h 2 3 thus h 1 the water depth upstream of the barrier can be obtained by 4 h 1 h 2 1 1 3 f r 2 2 1 œï 1 f r 2 2 1 œï 1 2 3 l s c d a 1 œï f r 2 2 3 results 3 1 mean flow and turbulent characteristics normalized time averaged streamwise velocity u u 2 on typical sections were presented in fig 4 as the control test without leaky barrier velocity was measured on a single vertical profile x 495 mm and the measured velocity profile represents typical open channel flow conditions following a logarithmic low then under the same discharge and downstream water depth leaky barrier was installed in the flume and the 3d velocity components were measured by adv at locations shown in fig 3 the leaky barrier obstructed the flow resulting in a significant change in the channel hydrodynamics fig 4a b upstream of the barriers fig 4a due to backwater effect of the barrier the streamwise velocity of the upper layer was decreasing while the bottom layer was increasing compared with the control test when approaching the barrier e g x 375 345 mm the velocity at the gap of the barrier z b 0 1 featured a tendency to increase significantly and the closer to the barrier the greater the flow velocity for areas located upper of the gap z b 0 1 the streamwise velocities tended to decrease with z and the velocity gets smaller when it is closer to the barrier specifically at x 345 mm the streamwise velocity near the free surface was only about 0 4 times the average flow velocity u 2 found in unobstructed flow condition at the positions further away from the barrier e g x 465 435 mm the velocity gradually recovered to the typical logarithmic law of open channel flows that is the velocity increased with the water depth immediately downstream of the barrier fig 4b measured velocity profiles were almost similar because of the barrier blockage the approaching flow diverted and featured high velocity at the bottom gap z b 0 1 thus there formed a high momentum flow region which expanded into the upper region of the barrier s wake z b 0 1 and downstream of the structure the velocity of the high momentum flow region reached its maximum value at about the middle of the bottom gap z b 0 0 5 which attained more than twice of u 2 in the control case in contrast in the region of the barrier 1 z b 0 2 73 the flow velocity tended to decrease firstly and the minimum velocity occurred at about z b 0 2 0 then the velocity increased with the increasing of water depth with the increase of the longitudinal distance the maximum velocity at the gap gradually decreased and at the upper layer z b 0 1 the minimum velocity increased gradually until x 180 mm as the distance increase the disturbance of the barrier gradually decreased and the vertical distribution of streamwise velocity was gradually becoming equilibrium for the profiles near the barrier x 30 90 mm there were fluctuations can be observed and this may be related to complex flow intersections such as the overtopping flow of the barrier jet flow between the dowel rows and high momentum flow in the gap area the presence of obvious eddies downstream of the barrier has proved that the longitudinal turbulence intensity u rms u 2 vertical turbulence intensity w rms w 2 and the reynolds stresses œÑ represented by u w were adopted to investigate the turbulent characteristics in which u u u and w w w where u w were the instantaneous flow velocity in the longitudinal and vertical direction and u w representing the time average velocity correspondingly and the normalized turbulence intensity profiles at six different longitudinal locations x 465 mm 435 mm 345 mm 60 mm 400 mm 550 mm were shown in fig 5 the turbulence intensity in the longitudinal direction was greater than that in the vertical direction meanwhile the urms and wrms were small upstream of the leaky barrier however at the downstream of the barrier the turbulence intensity increased significantly downstream of the barrier the maximum urms and wrms appeared near the dowels bottom z b 0 1 0 1 45 and the second peak of the turbulence occurred near the second vertical gap of the dowels z b 0 2 0 what s more at the gap urms decreased firstly and then increased with the height then there was also a peak value of urms near the middle of the gap upstream of the barrier the u w approached zero on the whole profiles however at locations downstream of the barrier the variation of reynolds stress can be divided into three regions i e the reynolds stresses increased with the increasing height under the gap z b 0 1 the value varied dramatically in the first row of dowels and the first vertical gap 1 z b 0 1 64 and above the first gap z b 0 1 64 the reynolds stresses approached zero 3 2 validation of water depth prediction the validity of equation 4 was demonstrated using the experimental results listed in table 1 combining the data series a20 a24 from muhawenimana et al 2021 the first series from young 1991 and the data from m√ºller et al 2021a 2021b since the leaky barrier structures were arranged in different ways in those literature the specific characteristics were collected and presented in fig 6 and the detailed data was listed in table 2 according to equation 4 only basic data of the downstream flow and barrier structure are required to know the backwater rise caused by the leaky barrier for the experiments the values of flow features h 2 fr 2 and leaky barrier s characteristics l s a œï assumed as inputs and the corresponding upstream water depth h 1 was calculated using the equation 4 the results of the calculated upstream water depth had been compared with the measured data and shown in fig 7 with the dotted line indicating that the calculated water depth error is in the range of 30 we chose the mean relative error mre and root mean square error rmse as the error metrics to evaluate the accuracy of formula 5 mre 1 n i 1 n h 1 cal h 1 mea h 1 mea 6 rmse 1 n i 1 n h 1 c a l h 1 m e a 2 a satisfying agreement between the calculated and measured values was obtained with the mre of 0 089 the rmse of 0 02 and fig 7 also shows that the equation 4 had good adaptability to different arrangements of leaky barriers there was a obvious deviation of one data 30 between the measured and the calculated value of upstream water depth from young s research this deviation may be closely related to the special setup of young s experiments first the cross section of open channel was blocked completely which resulted in large differences between upstream and downstream water depths this phenomenon increased the estimation errors since the equation simply ignored the influence of gravity second the weir controlling the downstream water depth became submerged which may in turn increase the upstream water depth 4 discussion our results showed that the presence of leaky barriers blocked the flow and resulted in a sharp change of vertical velocity distribution the high momentum exchange in the region of barrier s gap results in an increase in bed shear velocity u c f u and bed shear stress œÑ b œÅ u 2 yang and nepf 2018 follett et al 2020 on the one hand the high shear stress and velocity can prevent the bottom section from becoming blocked by the wood debris leaves needles and other sediment during the engineering operating on the other hand that may cause local scour and soil erosion at present the studies about leaky barriers were mainly conducted on a fixed bed resulting in neglecting the influence of local scour although the present study was conducted on a fixed bed the existence of the high momentum zone provided a new research direction for studying the scouring of channels caused by leaky barriers in further investigating maybe it is useful to know the details about the velocity variation in this area furthermore the low velocity region at the upper layer of the leaky barrier indicates a potential decrease in the sediment transport capacity and thus larger possibility of sediment siltation nevertheless the low velocity zone provides a concentrated source of food for fish and also plays an important role for fish in providing areas for resting and for refuge during floods bisson 1987 roni et al 2015 hence leaky barriers design should balance these two aspects well what s more it can also be seen from our experimental results that the leaky barrier produced strong turbulence and the affecting range was relatively wide it may because the interaction among the overtopping flow of the barrier the jet flow between the dowel rows and high momentum flow created a mixing region immediately downstream of the leaky barriers wang and tan 2007 m√ºller et al 2021b many studies proved that fish swimming performance transport of buoyant and suspended particles were related to the turbulent characteristics biggs et al 2005 markwith and leigh 2008 defina and peruzzo 2010 tritico and cotel 2010 muhawenimana et al 2019 hence fish behavior and plants hydrochory may be influenced by the complex flow characteristics in the mixing region more delicate experiments should be designed to investigate the turbulent structures formed in the near wake of these porous barriers and their potential ecological effects according to the backwater equation presented the upstream water depth h 1 is related to the porous engineered leaky barriers physical characteristics and flow characteristics overall the backwater effect increased with increasing longitudinal length drag coefficient the solid volume fraction and the spatially averaged frontal area per barrier volume as for the flow situation the backwater effect increased with increasing downstream water depth and the froude number of the approach flow some previous researcher s result can support this view they conducted flume and field experiments to explore the factors affecting backwater effect due to large wood debris gippel et al 1996 schmocker and hager 2013 schalko et al 2018 muhawenimana et al 2021 among the characteristisc of the leaky barrier the solid volume fraction is the main factor affecting the backwater effect here we presented a method to predict the backwater effect caused by leaky barrier and the result was acceptable but there are still several aspects can be improved firstly the influence of the non hydrostatic pressure was ignored because of the leaky barrier and the gap the flow changes dramatically that the pressure does not conform to the hydrostatic pressure distribution roth and hager 1999 suggested that the bottom pressure near the gate varied curvilinear with the location and the upstream water depth and the effect of non hydrostatic pressure was limited to twice the opening of the gate however the conclusion was obtained by neglecting the gate thickness for this study the barrier length may have a great influence on the non hydrostatic pressure hence it is difficult to obtain the real pressure variation that occurs along the structure secondly the average upstream flow velocity was used to represent the velocity inside the structure to calculate flow drag according to our velocity measurement the velocity changes dramatically upstream and downstream of the structure so simply using the upstream average speed representation may not really reflect the drag situation it is also difficult to accurately get the velocity in the leaky barrier by current experimental method in this work we did not consider the influence of gap height on the backwater effect because the main priority consideration in the design of the gap is the impact on fish passage and low flow passing nisbet et al 2011 dodd et al 2016 as for the arrangements of the dowels different patterns cause a change in the angle between the flow direction and the dowel s axes which affects the drag coefficient however in most cases the drag coefficient is maximum when the flow direction is perpendicular to the axis with the research from gippel et al 1996 so the backwater effect of the other arrangement structure like lattice arrangement will be weaker the experiment results from muhawenimana et al 2021 also proved this point one thing to note is that the above analysis considered the structure composed of only cylindrical logs so that œï œÄ a d 4 in contrast the engineered leaky barrier in the field is made of natural logs containing many branches and the surfaces are uneven what s more branches sediments and the leaves carried by the flow would accumulate among the log members and especially during floods the falling wood may also be accumulated in front of the structure manners et al 2007 these may lead to an increase of the longitudinal length and the structure became non cylindrical and less porous therefore the upstream water depth of the barrier may increase and thus the potential for flood hazards may also increase which may require regular maintenance of these barriers in the field and in this study we only considered the effect of a single barrier and obtained the key parameters of the backwater effect of the structure furthermore it is necessary to evaluate the cumulative effect of a series of multiple leaky barriers in the future 5 conclusions the recognition of the function of wood debris in ecology has led to increasing interest from removing wood debris to reintroducing wood engineered like leaky barriers the hydraulic effects generated by the barrier are key factors in determining the ecologic geomorphic and flood risk impact of a jam in this paper the influence of leaky barrier on channel hydrodynamics and the backwater effect of the barrier were investigated it found that the flow is mainly characterized by high velocity zone at the leaky barrier s gap a low velocity zone near the free water and a complex flow intersection in the middle region and it also found the variation characteristics of turbulence characteristics in upstream and downstream of the barrier what s more a new method based on hydraulic principles was proposed to determine the backwater effect of the leaky barrier and the equation was validated with experimental and collected data the results showed good agreement between calculated and measured upstream water depth implies the proposed equation has good adaptability our research will help to understand the impacts of leaky barriers and provide a certain reference for the design and operation of leaky barriers project credit authorship contribution statement rui huang data curation investigation writing original draft writing review editing yuhong zeng conceptualization funding acquisition methodology writing review editing wei zha data curation writing review editing fan yang data curation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this study was supported by the national natural science foundation of china grant no 51879197 and the fundamental research funds for the central universities grant no 2042021kf0221 
2902,traditional flood control projects such as dams and gates may disrupt river connectivity resulting in the fragmentation of river habitats leaky barriers as a new method of flood defense are gradually used in flood management especially in small rivers due to functions of the engineering in ecological and connecting rivers and regulating floods understanding the hydraulic effects and especially the backwater rise caused by leaky barriers is necessary to assess its impact and optimize the design this paper investigates the influence of the leaky barrier on hydrodynamics through a designed flume experiment a formula that reveals the backwater effects of the barrier was obtained by solving the momentum and continuity equations comparing the predicted and measured values of upstream water depth the difference was within a reasonable range based on the results the factors affecting the backwater rise are the froude number of the approaching flow downstream water depth and the longitudinal length drag coefficient the solid volume fraction of the leaky barriers among the characteristics of leaky barrier the solid volume fraction is the main factor affecting the backwater effect the findings are helpful to understand the hydraulic influence of leaky barriers and can provide references for practical project keywords flooding control natural flood management leaky barrier backwater effect flume experiment data availability data will be made available on request 1 introduction flooding is one of the most devastating natural disasters arnell and gosling 2016 dadson et al 2017 in order to resist the adverse effects of flooding human build various engineering measures to control flooding traditional projects such as dams flood walls flood gates and flood storage reservoirs alleviate flood risk to a certain extent but they may also block rivers and destroy the connection of the river system tockner and stanford 2002 mccartney and de la hera 2004 in addition they can also affect the normal reproduction and spread of species and have a part adverse impact on the environment poff et al 2007 to meet these threats there is an increasing interest in soft engineering in the form of natural flood management nfm nicholson et al 2012 nfm focuses on small scale intervention approaches and mimics or works with natural processes to achieve the purpose of reducing flood quinn et al 2013 lane 2017 leaky barriers bunds storage ponds ditches and swales and other sustainable drainage approaches are typical forms of nfm howarth 2017 studies show that nfm can offer ecological benefits such as improving water quality slowing down soil degradation and increasing biodiversity janes et al 2017 hankin et al 2018 in all forms of nfm the introduction of leaky barriers in the upper and middle catchments of rivers is a cost effective measure muhawenimana et al 2021 leaky barriers are constructed by spanning logs above and across the stream bed which are further secured in the banks with dowels or existing stakes usually leaky barriers leave a gap with the riverbed bottom to allow the normal river flow to pass underneath along with fish and other aquatic creatures and attenuate water by diverting flow onto floodplains only in high flows fig 1 such structures intercept part of the river and produce a certain backwater effect which leads to enhancing the floodplain storage and increasing the evaporation and infiltration of overflow water on the ground thus reducing river runoff and alleviating flood gippel 1995 thomas and nisbet 2012 early studies have also confirmed that wood debris and other floating trees in rivers affect navigation and excessive barrier blockage also increases the risk of flood young 1991 shields and gippel 1995 so many of these natural barriers in river systems have been removed gallisdorfer et al 2014 in recent years people have given rise to an interest in reintroducing leaky barriers in river catchments as realized that woody accumulations are beneficial to the restoration of river habitats leakey et al 2020 to achieve a trade off between creating suitable habitats and reducing flood risk the design of leaky barriers should be very careful but till now there are few design criteria available shields et al 2004 burgess gamble et al 2017 this could be due to the poor understanding of the effects of leaky barriers on river flow and the fluid forces acting on them bennett et al 2015 while such knowledge is crucial for supporting the evaluation of the flood hazard and optimization of the structural design mathematical modeling is an optional way to study the effects of leaky barriers some models have been presented by changing parameters such as hydraulic roughness coefficient manning s n and the channel geometry thomas and nisbet 2012 dixon et al 2016 rasche et al 2019 to model the flow obstructing nature of leaky barriers however those models can t accurately represent the hydraulic complexity of the flow generated by natural and engineered leaky barriers consisting of multiple dowels manners et al 2007 schalko et al 2018 2019 and it may not be appropriate to apply the same methods to other flow conditions or sites quinn et al 2013 flume experiments have also been conducted to study the backwater rise due to large woody debris researchers have worked out influencing factors for the backwater characteristics based on different experimental setups and the influencing factors included approach flow froude number loose large wood volume compactness of the large wood the cross sectional blockage ratio leaky barrier longitudinal length and so on schmocker and hager 2013 schalko et al 2018 2019 muhawenimana et al 2021 thus by conducting regression analysis they have derived empirical equations of different forms however none of these equations have shown wide applicability for varied hydraulic conditions and due to different considerations some of them even come to opposite conclusions the main reason is that the knowledge of detailed hydraulic characteristics of open channel flow affected by channel spanning leaky barriers is still limited so it is necessary to investigate the flow characteristics with leaky barriers and put forward a method with relatively wide adaptability to predict upstream water surface elevation or backwater water rise here we designed laboratory experiments to quantify the effect of leaky barriers on upstream and downstream hydrodynamic alterations by generalizing the leaky barrier as a porous structure we further combined the resistance law and the continuity equation to present a theoretical formula for the upstream water depth of open channel featured with a leaky barrier these analyses can increase our understanding of the flow impact of leaky barriers and propose suggestions for optimizing their performance 2 materials and methods 2 1 experimental setup laboratory experiments were performed in a circulating rectangular channel flume in the state key laboratory of water resources and hydropower engineering science at wuhan university china the experimental set up was presented in fig 2 a showing the 16 m long 0 6 m wide and 0 6 m deep recirculating flume with a flat bottom longitudinal flow direction was defined as positive in the downstream direction x while lateral and vertical flow direction were defined as y and z respectively and the origin of the axes was at the bottom of the flume downstream of the barrier test flow discharge was controlled by regulating valve set at the inlet of flume an electromagnetic flowmeter was used to record the discharge and the water depth was adjusted by a tailgate located at the flume outlet two rulers were fixed along the flume sidewall 1 5 m upstream and downstream of the model the preliminary experiment showed that the water level was nearly stable outside this range to measure the water depth of the upstream and downstream separately leaky barrier was installed in the channel at nearly 9 4 m downstream of the flume inlet with its main characteristics depicted in fig 2b leaky barrier was constructed using individual wooden dowels with a diameter d 0 025 m it comprised three dowel rows in the vertical and twelve dowels in the longitudinal direction featuring a height h s of 0 095 m a longitudinal length l s of 0 3 m and a lateral width b of 0 6 m all logs of the barrier were oriented perpendicular to the flow direction with a vertical gap b 0 of 0 055 m between the lowest dowel edge and flume bed and a vertical gap b of 0 01 m among other dowel rows to allow flow through the model was fixed by a plastic plate stuck on the channel walls and through the preliminary experiment the plate itself had a negligible effect on the approach flow conditions and its effect on backwater rise can be ignored a summary of the experimental set up is presented in table 1 with subscript 1 indicating upstream and subscript 2 indicating downstream of the barrier the solid volume fraction was defined by œï v s v l with v l b h 2 l s and vs is the volume occupied by the solid leaky barrier that was actually submerged hydraulic conditions included the discharge q and the mean flow depth h 1 and h 2 the bulk velocity u 1 and u 2 was defined as u q bh froude number was fr u gh with g denoting gravity acceleration and reynolds number was re u r œÖ with œÖ denoting the fluid kinematic viscosity and r denoting the channel hydraulic radius 2 2 velocity measurements flow velocities within the proximity of the completely submerged leaky barrier structure test 8 were measured using a sideways looking acoustic doppler velocimeter adv nortek vectrino velocity profiles were taken at 6 locations upstream and 15 locations downstream of the barrier as indicated in fig 3 between x 495 345 mm upstream and x 30 300 mm downstream of the barrier the longitudinal interval was set as 30 mm while between x 300 550 mm downstream of the structure the distance was increased to 50 mm the vertical interval of the sampling point was 5 mm fig 3 all measured points were on the channel midline y 0 3 m during measurements a sampling rate of 200 hz over a sampling period ranging from 5 to 20 min was adopted to capture representative high frequency turbulent fluctuations and to ensure adequate data quality velocity data were filtered using matlab r2016b by removing the data with an insufficient signal to noise ratio snr of 15 db and a correlation of 70 and then removing spikes using the method of goring et al goring and nikora 2002 2 3 theoretical analysis on backwater rise a leaky barrier was assumed to be dynamically similar to an array of rigid cylindrical elements then following the description used in canopy flows the drag per fluid volume within the structure d x n m3 can be represented by a quadratic drag law kaimal and finnigan 1994 1 d x œÅ c d a u 2 2 1 œï where œÅ kg m 3 is the fluid density cd is drag coefficient which is generally considered to be 0 9 to 1 0 gippel et al 1996 and in the present study the value of cd was set as 1 0 u m s is the temporally and spatially averaged longitudinal velocity a m 1 is denoted the frontal area per canopy volume œï is the solid volume fraction of the leaky barrier structure which is the ratio of barrier solid volume vs to control volume vl as described in section 2 1 and because of the leaky barrier consisting of circular cylinders with diameter d then œï œÄ a d 4 nepf 2012 flow within the barrier was assumed to be a steady one dimensional flow with hydrostatic pressure distribution the compressibility of fluid was not considered and the momentum correction factor equals 1 0 by neglecting the effect of bed slope and sidewalls shear stress the integrated conservation of momentum for the control volume between upstream and downstream was then presented 2 œÅ b h 2 u 2 u 2 u 1 1 2 œÅ g b 1 œï h 1 2 h 2 2 1 2 œÅ b l s c d a u 1 2 h 1 in which the left hand side of equation 2 shows the net change in momentum with u q bh while the first term on the right hand side of equation 2 represents the net hydrostatic pressure force and the second term is the drag within the barrier in which the water depth and velocity within the structure was approximated by the corresponding values at the upstream edge combining the continuity equation q u 1 bh 1 u 2 bh 2 then 3 h 1 h 2 h 2 3 3 h 1 h 2 h 2 2 2 h 1 h 2 h 2 2 f r 2 2 1 œï h 1 h 2 h 2 l s c d a 1 œï f r 2 2 0 in which f r 2 u 2 g h 2 is the froude number of the downstream channels and because of h 1 h 2 h 2 1 by neglecting h 1 h 2 h 2 3 thus h 1 the water depth upstream of the barrier can be obtained by 4 h 1 h 2 1 1 3 f r 2 2 1 œï 1 f r 2 2 1 œï 1 2 3 l s c d a 1 œï f r 2 2 3 results 3 1 mean flow and turbulent characteristics normalized time averaged streamwise velocity u u 2 on typical sections were presented in fig 4 as the control test without leaky barrier velocity was measured on a single vertical profile x 495 mm and the measured velocity profile represents typical open channel flow conditions following a logarithmic low then under the same discharge and downstream water depth leaky barrier was installed in the flume and the 3d velocity components were measured by adv at locations shown in fig 3 the leaky barrier obstructed the flow resulting in a significant change in the channel hydrodynamics fig 4a b upstream of the barriers fig 4a due to backwater effect of the barrier the streamwise velocity of the upper layer was decreasing while the bottom layer was increasing compared with the control test when approaching the barrier e g x 375 345 mm the velocity at the gap of the barrier z b 0 1 featured a tendency to increase significantly and the closer to the barrier the greater the flow velocity for areas located upper of the gap z b 0 1 the streamwise velocities tended to decrease with z and the velocity gets smaller when it is closer to the barrier specifically at x 345 mm the streamwise velocity near the free surface was only about 0 4 times the average flow velocity u 2 found in unobstructed flow condition at the positions further away from the barrier e g x 465 435 mm the velocity gradually recovered to the typical logarithmic law of open channel flows that is the velocity increased with the water depth immediately downstream of the barrier fig 4b measured velocity profiles were almost similar because of the barrier blockage the approaching flow diverted and featured high velocity at the bottom gap z b 0 1 thus there formed a high momentum flow region which expanded into the upper region of the barrier s wake z b 0 1 and downstream of the structure the velocity of the high momentum flow region reached its maximum value at about the middle of the bottom gap z b 0 0 5 which attained more than twice of u 2 in the control case in contrast in the region of the barrier 1 z b 0 2 73 the flow velocity tended to decrease firstly and the minimum velocity occurred at about z b 0 2 0 then the velocity increased with the increasing of water depth with the increase of the longitudinal distance the maximum velocity at the gap gradually decreased and at the upper layer z b 0 1 the minimum velocity increased gradually until x 180 mm as the distance increase the disturbance of the barrier gradually decreased and the vertical distribution of streamwise velocity was gradually becoming equilibrium for the profiles near the barrier x 30 90 mm there were fluctuations can be observed and this may be related to complex flow intersections such as the overtopping flow of the barrier jet flow between the dowel rows and high momentum flow in the gap area the presence of obvious eddies downstream of the barrier has proved that the longitudinal turbulence intensity u rms u 2 vertical turbulence intensity w rms w 2 and the reynolds stresses œÑ represented by u w were adopted to investigate the turbulent characteristics in which u u u and w w w where u w were the instantaneous flow velocity in the longitudinal and vertical direction and u w representing the time average velocity correspondingly and the normalized turbulence intensity profiles at six different longitudinal locations x 465 mm 435 mm 345 mm 60 mm 400 mm 550 mm were shown in fig 5 the turbulence intensity in the longitudinal direction was greater than that in the vertical direction meanwhile the urms and wrms were small upstream of the leaky barrier however at the downstream of the barrier the turbulence intensity increased significantly downstream of the barrier the maximum urms and wrms appeared near the dowels bottom z b 0 1 0 1 45 and the second peak of the turbulence occurred near the second vertical gap of the dowels z b 0 2 0 what s more at the gap urms decreased firstly and then increased with the height then there was also a peak value of urms near the middle of the gap upstream of the barrier the u w approached zero on the whole profiles however at locations downstream of the barrier the variation of reynolds stress can be divided into three regions i e the reynolds stresses increased with the increasing height under the gap z b 0 1 the value varied dramatically in the first row of dowels and the first vertical gap 1 z b 0 1 64 and above the first gap z b 0 1 64 the reynolds stresses approached zero 3 2 validation of water depth prediction the validity of equation 4 was demonstrated using the experimental results listed in table 1 combining the data series a20 a24 from muhawenimana et al 2021 the first series from young 1991 and the data from m√ºller et al 2021a 2021b since the leaky barrier structures were arranged in different ways in those literature the specific characteristics were collected and presented in fig 6 and the detailed data was listed in table 2 according to equation 4 only basic data of the downstream flow and barrier structure are required to know the backwater rise caused by the leaky barrier for the experiments the values of flow features h 2 fr 2 and leaky barrier s characteristics l s a œï assumed as inputs and the corresponding upstream water depth h 1 was calculated using the equation 4 the results of the calculated upstream water depth had been compared with the measured data and shown in fig 7 with the dotted line indicating that the calculated water depth error is in the range of 30 we chose the mean relative error mre and root mean square error rmse as the error metrics to evaluate the accuracy of formula 5 mre 1 n i 1 n h 1 cal h 1 mea h 1 mea 6 rmse 1 n i 1 n h 1 c a l h 1 m e a 2 a satisfying agreement between the calculated and measured values was obtained with the mre of 0 089 the rmse of 0 02 and fig 7 also shows that the equation 4 had good adaptability to different arrangements of leaky barriers there was a obvious deviation of one data 30 between the measured and the calculated value of upstream water depth from young s research this deviation may be closely related to the special setup of young s experiments first the cross section of open channel was blocked completely which resulted in large differences between upstream and downstream water depths this phenomenon increased the estimation errors since the equation simply ignored the influence of gravity second the weir controlling the downstream water depth became submerged which may in turn increase the upstream water depth 4 discussion our results showed that the presence of leaky barriers blocked the flow and resulted in a sharp change of vertical velocity distribution the high momentum exchange in the region of barrier s gap results in an increase in bed shear velocity u c f u and bed shear stress œÑ b œÅ u 2 yang and nepf 2018 follett et al 2020 on the one hand the high shear stress and velocity can prevent the bottom section from becoming blocked by the wood debris leaves needles and other sediment during the engineering operating on the other hand that may cause local scour and soil erosion at present the studies about leaky barriers were mainly conducted on a fixed bed resulting in neglecting the influence of local scour although the present study was conducted on a fixed bed the existence of the high momentum zone provided a new research direction for studying the scouring of channels caused by leaky barriers in further investigating maybe it is useful to know the details about the velocity variation in this area furthermore the low velocity region at the upper layer of the leaky barrier indicates a potential decrease in the sediment transport capacity and thus larger possibility of sediment siltation nevertheless the low velocity zone provides a concentrated source of food for fish and also plays an important role for fish in providing areas for resting and for refuge during floods bisson 1987 roni et al 2015 hence leaky barriers design should balance these two aspects well what s more it can also be seen from our experimental results that the leaky barrier produced strong turbulence and the affecting range was relatively wide it may because the interaction among the overtopping flow of the barrier the jet flow between the dowel rows and high momentum flow created a mixing region immediately downstream of the leaky barriers wang and tan 2007 m√ºller et al 2021b many studies proved that fish swimming performance transport of buoyant and suspended particles were related to the turbulent characteristics biggs et al 2005 markwith and leigh 2008 defina and peruzzo 2010 tritico and cotel 2010 muhawenimana et al 2019 hence fish behavior and plants hydrochory may be influenced by the complex flow characteristics in the mixing region more delicate experiments should be designed to investigate the turbulent structures formed in the near wake of these porous barriers and their potential ecological effects according to the backwater equation presented the upstream water depth h 1 is related to the porous engineered leaky barriers physical characteristics and flow characteristics overall the backwater effect increased with increasing longitudinal length drag coefficient the solid volume fraction and the spatially averaged frontal area per barrier volume as for the flow situation the backwater effect increased with increasing downstream water depth and the froude number of the approach flow some previous researcher s result can support this view they conducted flume and field experiments to explore the factors affecting backwater effect due to large wood debris gippel et al 1996 schmocker and hager 2013 schalko et al 2018 muhawenimana et al 2021 among the characteristisc of the leaky barrier the solid volume fraction is the main factor affecting the backwater effect here we presented a method to predict the backwater effect caused by leaky barrier and the result was acceptable but there are still several aspects can be improved firstly the influence of the non hydrostatic pressure was ignored because of the leaky barrier and the gap the flow changes dramatically that the pressure does not conform to the hydrostatic pressure distribution roth and hager 1999 suggested that the bottom pressure near the gate varied curvilinear with the location and the upstream water depth and the effect of non hydrostatic pressure was limited to twice the opening of the gate however the conclusion was obtained by neglecting the gate thickness for this study the barrier length may have a great influence on the non hydrostatic pressure hence it is difficult to obtain the real pressure variation that occurs along the structure secondly the average upstream flow velocity was used to represent the velocity inside the structure to calculate flow drag according to our velocity measurement the velocity changes dramatically upstream and downstream of the structure so simply using the upstream average speed representation may not really reflect the drag situation it is also difficult to accurately get the velocity in the leaky barrier by current experimental method in this work we did not consider the influence of gap height on the backwater effect because the main priority consideration in the design of the gap is the impact on fish passage and low flow passing nisbet et al 2011 dodd et al 2016 as for the arrangements of the dowels different patterns cause a change in the angle between the flow direction and the dowel s axes which affects the drag coefficient however in most cases the drag coefficient is maximum when the flow direction is perpendicular to the axis with the research from gippel et al 1996 so the backwater effect of the other arrangement structure like lattice arrangement will be weaker the experiment results from muhawenimana et al 2021 also proved this point one thing to note is that the above analysis considered the structure composed of only cylindrical logs so that œï œÄ a d 4 in contrast the engineered leaky barrier in the field is made of natural logs containing many branches and the surfaces are uneven what s more branches sediments and the leaves carried by the flow would accumulate among the log members and especially during floods the falling wood may also be accumulated in front of the structure manners et al 2007 these may lead to an increase of the longitudinal length and the structure became non cylindrical and less porous therefore the upstream water depth of the barrier may increase and thus the potential for flood hazards may also increase which may require regular maintenance of these barriers in the field and in this study we only considered the effect of a single barrier and obtained the key parameters of the backwater effect of the structure furthermore it is necessary to evaluate the cumulative effect of a series of multiple leaky barriers in the future 5 conclusions the recognition of the function of wood debris in ecology has led to increasing interest from removing wood debris to reintroducing wood engineered like leaky barriers the hydraulic effects generated by the barrier are key factors in determining the ecologic geomorphic and flood risk impact of a jam in this paper the influence of leaky barrier on channel hydrodynamics and the backwater effect of the barrier were investigated it found that the flow is mainly characterized by high velocity zone at the leaky barrier s gap a low velocity zone near the free water and a complex flow intersection in the middle region and it also found the variation characteristics of turbulence characteristics in upstream and downstream of the barrier what s more a new method based on hydraulic principles was proposed to determine the backwater effect of the leaky barrier and the equation was validated with experimental and collected data the results showed good agreement between calculated and measured upstream water depth implies the proposed equation has good adaptability our research will help to understand the impacts of leaky barriers and provide a certain reference for the design and operation of leaky barriers project credit authorship contribution statement rui huang data curation investigation writing original draft writing review editing yuhong zeng conceptualization funding acquisition methodology writing review editing wei zha data curation writing review editing fan yang data curation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this study was supported by the national natural science foundation of china grant no 51879197 and the fundamental research funds for the central universities grant no 2042021kf0221 
2903,baseflow originating primarily from groundwater is a critical streamflow component although its accurate estimation is fraught with significant difficulties this study estimates baseflow through existing graphical and digital filter methods using actual streamflow data from a gauging station at the alder creek watershed acw and synthetic streamflow data at ten study locations within the same watershed simulated with hydrogeosphere hgs aquanty inc 2018 there are four widely used graphical institute for hydrology 1980 sloto and crouse 1996 aksoy et al 2008 and six digital filtering lyne and hollick 1979 chapman and maxwell 1996 furey and gupta 2001 eckhardt 2005 tularam and ilahee 2008 aksoy et al 2009 baseflow separation approaches compared in this study to determine the most optimal approach baseflow estimates from real data are assessed based on the subjective concept of hydrologic plausibility while baseflow estimates obtained from a hgs streamflow record with graphical and digital filtering methods are compared to those computed directly by hgs overall results from this study indicate that baseflow hydrographs reveal a seasonal pattern at the acw during wintertime streamflow is composed almost entirely of baseflow whereas during summertime baseflow only consists approximately 20 to 60 of streamflow after comparing baseflow estimates with those computed by hgs the most optimal approaches at the ten study locations are assessed results show that the best approach at six study locations is the fukih aksoy et al 2009 approach while at three locations the chapman and maxwell 1996 approach and for one location the eckhardt 2005 approach performed the best in conclusion it is inferred that the most optimal approach within the acw varies spatially keywords baseflow estimates baseflow separation surface water groundwater interaction graphical methods digital filter methods hydrologic plausibility data availability data will be made available on request 1 introduction baseflow is an essential component of streamflow which originates primarily from groundwater discharging into streams e g hall 1968 freeze 1972 hayashi and rosenberry 2002 eckhardt 2005 brodie et al 2007 under certain situations baseflow can also result from delayed flow from surface water features such as wetlands and lakes as well as through flow regulation and wastewater discharge piggott et al 2005 as an important component of streamflow baseflow plays an essential role in sustaining riparian and aquatic ecosystems as well as influencing stream water chemistry in many streams streamflow is primarily composed of baseflow during dry periods and during wet seasons the ratio of baseflow to streamflow could decrease significantly depending on site conditions for example in a dry climate baseflow has been estimated to constitute approximately 80 percent of river flow within the upper colorado river basin miller et al 2016 in the baseflow and water use assessment report by toronto and region conservation 2008 baseflow has been estimated to be approximately 40 percent from the don river watershed in a humid climate during summertime due to the spatiotemporal variability of baseflow from one watershed to another predicting the contribution of baseflow relative to streamflow is essential for effective watershed management research on baseflow characteristics is vital for comprehending runoff generation processes and understanding interactions among streamflow groundwater and other components of the water cycle moreover investigations on spatial and temporal variability of baseflow could lead to better quantification of the significance of groundwater in streamflow processes tong et al 2021 baseflow recession has also been studied by researchers to estimate aquifer parameters from streamflow data e g brutsaert and nieber 1977 troch et al 2013 liang et al 2017 due to the importance of accurately estimating baseflow several studies based on various approaches have been conducted e g winter et al 1998 cey et al 1998 kalbus et al 2006 rosenberry and labaugh 2008 however it is difficult to obtain accurate baseflow hydrographs directly and continuously in the field therefore many different approaches have been developed to estimate baseflow based on disparate data available within a watershed baseflow estimation methods can be roughly divided into three groups direct measurements tracer based separation and non tracer based separation methods direct measurements rely on different instruments such as bag type or automated seepage meters mini piezometer heat pulse meter and ultrasonic meter to measure baseflow values at discrete points e g kalbus et al 2006 rosenberry and labaugh 2008 these instruments are installed to measure water fluxes across the groundwater surface water interface while direct measurements are very desirable they typically only provide point estimates in addition direct measurements are always time consuming and are not viable in making measurements at multiple locations within a watershed and over long time scales such point measurements are also logistically difficult to conduct in large rivers where access to measurement sites can be limited and the safety of workers can be a concern tracer based separation methods mainly rely on various isotopic and chemical tracers to explore the generation processes of each water cycle component e g yu and schwartz 1999 by separating streamflow into surface runoff and baseflow in previous studies these approaches have been widely used to determine baseflow values although they are always laborious have high data and sampling requirements and cannot be applied to past events due to the lack of required chemical data gonzales et al 2009 moreover the assumptions embedded in this approach may not be satisfied for example tracer based methods may contain relatively large uncertainties from chemical reactions during the mixing of components tracer measurements and elevation effects on the isotopic composition of precipitation gonzales et al 2009 these uncertainties in chemical reactions could result in tracer concentration changes during water movement through the watershed thus leading to less reliable baseflow estimation results therefore alternative non tracer based methods are needed non tracer based baseflow separation methods could be subdivided into several groups including graphical e g institute of hydrology 1980 sloto and crouse 1996 and digital filter methods e g lyne and hollick 1979 chapman and maxwell 1996 furey and gupta 2001 aksoy et al 2009 eckhardt 2005 tularam and ilahee 2008 in graphical methods different criteria are used to separate streamflow into baseflow and surface runoff through the analysis of a streamflow hydrograph in digital filter methods numerical approaches are utilized to filter streamflow into different portions of the hydrograph in previous research on baseflow estimation various approaches have been utilized and then compared to evaluate results e g nathan and mcmahon 1990 cey et al 1998 chapman 1999 arnold et al 2000 smakhtin 2001 conant 2004 schwartz 2007 gonzales et al 2009 indarto et al 2016 lott and stewart 2016 xie et al 2020 kissel and schmalz 2020 for example cey et al 1998 compared four field approaches to measure baseflow values at a small watershed in southern ontario canada approaches compared include the use of the velocity area technique mini piezometer measurements seepage meter measurements and analyses of electrical conductivity as well as isotope data among the first three techniques the velocity area technique resulted in best baseflow estimates from the analyses of isotope and electrical conductivity data it was shown that during storm events pre event water contributed approximately 64 to 80 of total stream discharge and antecedent moisture conditions of the catchment were found to largely affect the percentage of event and pre event water in streamflow gonzales et al 2009 compared various baseflow estimation methods including both tracer and non tracer based methods in a lowland area of netherlands the tracer approach revealed that groundwater responded quickly to rainfall events in this area and surface water contributed to most of measured discharge during flood events moreover estimated results were compared with baseflow values determined through the tracer based method in their study gonzales et al 2009 concluded that the rating curve method and the recursive filtering method proposed by eckhardt 2005 resulted in reliable baseflow values indarto et al 2016 reviewed earlier work on baseflow estimation and used seven recursive digital and two graphical methods to streamflow records from a watershed in east java indonesia to determine optimal parameter values baseflow index and the appropriate method for the investigated watershed results revealed that the exponentially weighted moving average ewma approach tularam and ilahee 2008 the lyne and hollick method 1979 and the local minimum method sloto and crouse 1996 performed better in this area xie et al 2020 estimated baseflow values with four graphical and five digital filter methods for 1 815 catchments in the united states an evaluation criterion was established to determine the true baseflow and this evaluation criterion was used together with performance metrics to analyze the accuracy of each separation method in this evaluation criterion they selected streamflow values during low flow conditions and treated these streamflow values strictly as baseflow values low flow conditions were defined as the condition when quick flow which includes interflow and overland flow has ceased in a catchment through this evaluation criterion xie et al 2020 concluded that the eckhardt 2005 method had the best performance across the contiguous united states based on the evaluation results for 1 815 catchments in these previous studies several baseflow separation methods were utilized and evaluated however as mentioned previously baseflow values are notoriously hard to quantify over long time scales especially over a large study area actual baseflow values from a watershed are always absent to help determine the best separation technique to circumvent this issue most studies have determined the optimal baseflow separation technique based on the qualitative concept of hydrologic plausibility in this study hydrologic plausibility means that features of a given baseflow hydrograph separated from a streamflow record should be consistent with anticipated natural conditions such as 1 its less variable nature compared to streamflow 2 its delayed response relative to interflow and overland flow and 3 that it does not exceed streamflow or exhibits unusually high increasing decreasing rates during rainfall events emphasis is made that the concept is subjective as there are no quantitative metrics that one can rely on thus could potentially lead to biased results some researchers have employed fully integrated three dimensional surface water groundwater physical models under varying hydrological conditions to simulate baseflow and the synthetic baseflow were assumed to be the true baseflow to test various baseflow separation techniques e g partington et al 2012 li et al 2014 su et al 2016 for example partington et al 2012 used four approaches to estimate baseflow including the hysep approach sloto and crouse 1996 the part program rutledge 1998 constructed based on a graphical approach the bflow program arnold and allen 1999 constructed based on the lyne and hollick 1979 approach and the eckhardt approach 2005 to test the performance of each approach hydrogeosphere hgs aquanty inc 2018 in conjunction with a hydraulic mixing cell hmc approach were used to obtain the synthetic true baseflow values for a simple monotonically sloping v shaped catchment partington et al 2012 found that the performance of different baseflow estimation approaches varied under eight different scenarios with different hydrological conditions but overall the hysep sliding interval approach showed the best results in most scenarios for this study similar to the work of partington et al 2012 li et al 2014 used synthetic results from hgs for a simple v shaped catchment to test the accuracies of several recursive digital filters lyne and hollick 1979 chapman and maxwell 1996 boughton 1993 chapman 1999 eckhardt 2005 results showed that baseflow estimates obtained through the lyne and hollick filter could better match the hgs synthetic baseflow under a wider range of catchment hydrological characteristics and optimal parameters varied based on hydrological conditions su et al 2016 investigated the utility of hydrological signatures to calibrate the eckhardt filter method eckhardt 2005 and tested seven possible hydrological signatures of baseflow comparing against the synthetic baseflow values simulated with hgs by li et al 2014 again for a tilted v shaped catchment results showed that the eckhardt filter had better performance after a hydrological signature based calibration in these previous studies partington et al 2012 li et al 2014 and su et al 2016 hgs was used to simulate baseflow with the hmc approach to help evaluate the performances of baseflow separation approaches although the use of synthetic baseflow from a model solved the problem of obtaining true baseflow estimates from an actual site synthetic baseflow used in these studies was not simulated for a real watershed instead the analysis was conducted based on a monotonically sloping v shaped catchment that simplified the intricate environmental conditions in actual watersheds subjected to seasonal hydrologic variations the primary purpose of this study is to assess baseflow estimates obtained from streamflow data at the alder creek watershed acw in southern ontario canada using various baseflow separation techniques baseflow separation is conducted through ten different approaches including four graphical and six digital filter approaches graphical methods include the 1 united kingdom institute of hydrology ukih method institute of hydrology 1980 aksoy et al 2008 2 three hydrograph separation hysep methods which are fixed interval hysep1 sliding interval hysep2 and local minimum hysep3 methods sloto and crouse 1996 digital filter methods include the 1 lyne and hollick 1979 2 filtered united kingdom institute of hydrology fukih aksoy et al 2009 3 chapman and maxwell 1996 4 eckhardt 2005 5 furey and gupta 2001 and the 6 ewma tularam and ilahee 2008 approaches details to each of these approaches are provided in the supplementary information si section baseflow estimates obtained through ten approaches using actual streamflow data from a real streamflow gauge installed within the acw are first compared and assessed utilizing the qualitative concept of hydrologic plausibility for a more quantitative comparison actual baseflow estimates are necessary however as actual baseflow estimates from the acw are not available to properly evaluate the performance of these ten baseflow separation techniques synthetic streamflow and baseflow data obtained from hgs are assumed to be true data and utilized for a more rigorous comparison to determine the most optimal approach for the acw unlike the simple v shape catchment models used by partington et al 2012 and li et al 2014 actual hydrological and geological conditions of the acw are simulated with hgs that rigorously considers the coupling of surface water groundwater flow and other hydrological conditions for the acw tong et al 2021 although numerical models may not be able to provide actual baseflow values for a given site a fully 3d integrated hydrological model should still generate good independent conceptualization of watershed flow dynamics under different conditions until better baseflow estimation tools or observation techniques are developed partington et al 2012 2 site description and data used for analysis 2 1 site description the study area is the alder creek watershed acw which is situated at the southwestern portion of the grand river watershed located in southern ontario canada fig 1 covering an area of approximately 79 km2 grca 2009 in the central portion of the grand river watershed where the acw is located surficial material is predominantly comprised of glacial deposits fig 2 shows that the acw is covered by a large variety of surficial materials including clay gravel sand and silt more specifically the middle and the southeastern portion of the acw is predominately covered by poorly to well sorted fine sand and gravel to coarse sand the western part is mainly covered by poorly to well sorted fine gravel and sand to coarse gravel and clay till is mostly distributed at the northern edge these surficial sediments have mainly formed during the most recent episode of pleistocene glaciation which is the wisconsinan glacial event that commenced 25 000 years ago and ended approximately 10 000 years ago the wisconsinan glaciation is subdivided into different phases thus the sediments deposited during different episodes are present within the acw specifically the bulk of glacial sediments found in this area contain pre michigan sub episode tills non glacial sediments michigan sub episode tills as well as stratified sediments deposited by a regionally thick ice and oscillating lobate ice formed due to the advance and retreat of the wisconsinan ice sheet grca 2018 beneath the surficial sediments the bedrock beneath the watershed constitutes a portion of the michigan and appalachian basins which were deposited on the ocean floor by devonian silurian and ordovician aged marine sediments that inundated this area between 345 and 370 million years ago moreover the sedimentary bedrock around this area is mainly interbedded limestone dolomite carbonate material and the shale of the oldest ordovician to the youngest devonian grca 2009 as for land use a total of seven categories have been classified fig 3 shows that the acw is predominately used for agriculture with fully 70 percent of which is used as agricultural land other than agricultural land land use within the watershed area consists also of urban built up forest open water grassland areas golf course area as well as aggregate extraction and roads in terms of hydrology the acw has a humid continental climate with an annual precipitation ranging from 800 to 1 000 mm year and an average daily temperature ranging from 12 2 c to 21 0 c chow et al 2016 during spring and fall the weather is wet with an average daily temperature of 5 0 c and the precipitation is in the range of 100 mm month whereas the weather is dry during the summer with an average daily temperature of 18 0 c and the precipitation ranges from 30 to 40 mm month during winter the average daily temperature is low which is 4 4 c and the precipitation is mainly in the form of snowfall government of canada 2020 the annual snowfall in this watershed is 150 200 cm and the average annual evapotranspiration is estimated to be 500 600 mm year grca 2009 2 2 research data this study investigates the performances of various baseflow separation approaches which mainly rely on streamflow data to estimate baseflow values in this study streamflow data used includes actual streamflow and synthetic streamflow data sets actual streamflow data is a three year daily streamflow record from may 1 2013 to december 31 2016 at the new dundee gauging station location 7 on fig 1 maintained by environment and natural resources of canada as actual baseflow estimates are not available at any location throughout the acw synthetic streamflow and baseflow hydrographs over a three year period from may 1 2013 to april 30 2016 are also generated with hydrogeosphere hgs aquanty inc 2018 a 3d fully integrated hydrological model that rigorously considers the coupling of surface water and groundwater flow processes tong et al 2021 the hgs model for the acw is composed of a surficial land use layer 30 m resolution dem data from the ontario ministry of natural resources and forestry a soil layer and stratigraphic units through a previously developed groundwater flow model fig 4 tong et al 2021 for the surficial land use layer a 25 m resolution land use data from the grand river conservation authority grca is utilized to describe plant functional types and surface roughness grca 2009 within the land use layer there are seven land use types defined agricultural land built up extraction roads forest golf courses open water and wetlands beneath the surficial layer there is a 1 m deep soil layer defined with soil data from soil landscapes of canada slc compiled by agricultural and agri food canada in this soil layer there are four soil types containing three kinds of loam and sandy loam identified based on soil texture the modeled stratigraphic units originate from the feflow model utilized for the regional municipality of waterloo tier three assessment matrix and sspa 2014a 2014b fig 4 shows that stratigraphic units contain aquifer a afa aquifer b afb aquifer c afc aquitard a ata aquitard b atb and aquitard c atc and these layers consist of different geological materials ata1 whittlesey clay afa1 whittlesey sand ata2 wentworth till atb1 upper maryhill till port stanley tavistock mornington and or stratford tills afb1 upper waterloo moraine stratified sediments and equivalents atb2 middle maryhill till and equivalents afb2 middle waterloo moraine stratified sediments and equivalents atb3 lower maryhill and stratified equivalents afb3 lower waterloo moraine stratified sediments or catfish creek till outwash atc1 upper main catfish creek till afc1 middle catfish creek stratified deposits and atc2 lower catfish creek till matrix and sspa 2014a 2014b ten layers were used in the study area including surficial geology layer 1 ata1 afa1 and ata2 layer 2 atb1 layer 3 afb1 layer 4 atb2 layer 5 afb2 layers 6 and 7 atb3 layer 8 afb3 layer 9 atc1 afc1 and atc2 layer 10 the constructed hgs model contains 43 829 triangular nodes with 86 798 elements for a single layer and 482 119 nodes with 867 980 elements for the entire domain for ten geological layers specified in the study various hydraulic conductivity k values were assigned to the subsurface domain ranging from 6 41 10 5 m day to 406 87 m day for horizontal k in x and y directions k x k y based on the regional hydrogeologic feflow model matrix and sspa 2014a 2014b while k in the vertical direction k z is ten times smaller than k x and k y a critical depth boundary condition was prescribed at the surface periphery to allow surface water flow out of the model domain a no flow boundary condition was applied at the bottom of the domain and model periphery to represent the groundwater flow divide based on topographic highs when synthetic baseflow and streamflow are generated through the hgs model winter processes are also considered snow precipitation and temperature data are utilized and applied to the model for transient simulations specifically precipitation data utilized in the model are from the roseville environment canada weather station located 2 km outside the watershed evapotranspiration was evaluated through the hargreaves evapotranspiration equation hargreaves and allen 2003 while the potential evapotranspiration pet was first estimated based on available weather data daily maximum and minimum air temperature and location of the study area latitude the actualevapotranspiration aet was then calculated based on pet and land cover data the winter november 1 2013 to april 30 2014 november 1 2014 to april 30 2015 november 1 2015 to april 30 2016 simulation is considered after the completion of the simulation from spring to fall may 1 2013 to october 31 2013 may 1 2014 to october 31 2014 may 1 2015 to october 31 2015 and during the winter simulation winter processes and parameters are added to the hgs model including 1 the freezing and thawing of porewater with lower k than summer that controls groundwater flow in the shallow subsurface schilling et al 2019 and 2 surface water flow with snowmelt and winter processes tong et al 2021 the exchange flux between surface water and groundwater in the model is positive when the water flows from the soil surface down through the shallow subsurface and into the underlying aquifers as groundwater recharge while the flow rate is negative when water moves out of the subsurface to the surface as groundwater discharge ten study locations along the tributaries and the main stem of alder creek are selected where synthetic streamflow and baseflow hydrographs are recorded during the three year simulation period the ten study locations were selected by considering various factors such as the relative position within the watershed i e tributary or main stem surficial geology exchange flux values land use and proximity to pumping wells the estimated baseflow from the hgs model at one location is simulated by summing the groundwater recharge and discharge values along the river upstream of the point during each timestep further details to the hgs model for the acw and the computed synthetic baseflow are provided in tong et al 2021 and key parameters are summarized in table 1 2 3 evaluation of baseflow separation methods with actual data fig 5 shows the baseflow estimated using actual streamflow data at the new dundee gauging station location 7 on fig 1 through four graphical estimation methods institute of hydrology 1980 aksoy et al 2008 sloto and crouse 1996 and six digital filter methods lyne and hollick 1979 aksoy et al 2009 chapman and maxwell 1996 eckhardt 2005 furey and gupta 2001 tularam and ilahee 2008 while table 2 summarizes the arithmetic mean maximum and minimum values of baseflow estimated through each approach table 2 shows that the arithmetic mean values range from 0 082 to 0 186 m3 s and the mean values from the ukih and fukih approaches are relatively lower than other approaches the maximum baseflow values range from 0 262 to 1 840 m3 s and the fukih approach generates the lowest maximum values as for the minimum values all baseflow separation approaches generate a same minimum value of 0 003 m3 s except for the furey and gupta approach the arithmetic mean maximum and minimum values from the furey and gupta approach are all largest amongst the ten separation approaches in contrast the fukih approach yielded the smallest baseflow estimates due to the lack of actual baseflow data estimated baseflow results can only be analyzed based on the concept of hydrologic plausibility from fig 5 it is shown that the baseflow hydrograph from the ukih approach fig 5a is flat and does not show an obvious change during precipitation events for the hysep fixed interval method fig 5b the change of baseflow is more distinct than that in the ukih approach during precipitation baseflow increases significantly over a short duration in particular the estimated baseflow hydrograph reveals a staircase pattern which does not correspond with natural conditions hence is not hydrologically plausible comparing between these three hysep approaches fig 5b d all these three approaches generate a large increase in baseflow during rainfall events and the changing trend of estimated baseflow in the hysep sliding interval approach is similar to that in the fixed interval approach for the hysep approaches large increases of baseflow and the staircase pattern could be observed during rainfall events which does not correspond with the delayed increase of baseflow expected under actual conditions furthermore due to the linear interpolation used in graphical approaches the hydrograph of the hysep local minimum approach fig 5d contains numerous shark peaks and stiff turns which appears to be abnormal and again is not hydrologically plausible for the digital filter approaches the overall changes of baseflow are much smoother than those from the graphical approaches for example in the lyne and hollick approach fig 5e although the increased amount of baseflow is not as large as that in the hysep sliding interval approach fig 5c it still shows a significant increase during some precipitation events which follows the results from the hysep local minimum approach fig 5d in the chapman and maxwell approach fig 5f the change in the estimated baseflow is smoother than that in lyne and hollick approach fig 5e and the increase during precipitation is also lower in the fukih approach fig 5g as mentioned before baseflow is first calculated by the ukih graphical approach and then filtered and smoothed by a digital filter thus leading to an extremely flat baseflow hydrograph without obvious changes throughout the year as for the eckhardt approach fig 5h large increases during precipitation are also observed and the amount of increase is similar to the lyne and hollick approach fig 5e for the furey and gupta approach fig 5i there is no constraint set for baseflow see si for details hence the baseflow values sometimes exceed streamflow in addition quick and large baseflow responses to precipitation are visible on fig 5i which is inconsistent with the anticipated slow response characteristic of baseflow to better quantify the change of baseflow with time and to further examine the hydrologic plausibility of various baseflow separation techniques the discharge derivative with respect to time dq dt is obtained by calculating the change of discharge within each day based on the baseflow and streamflow data obtained through ten different techniques the use of dq dt in conjunction with streamflow and baseflow hydrographs may be able to better identify rates of increase or decrease and assess the hydrologic plausibility of each baseflow separation technique thus helping to select the most optimal technique fig 6 shows the resulting dq dt estimates for these ten approaches to visualize the change in discharge of both streamflow and baseflow with time examination of results reveals that for the hysep fixed interval approach fig 6b the dq dt of baseflow is very large during precipitation and is almost the same as the dq dt of streamflow during some precipitation events this abnormally large dq dt of baseflow is not only observed in the hysep fixed interval approach fig 6b but also shown in the hysep sliding interval fig 6c and furey and gupta fig 6i approaches combining the baseflow derivative analyses with previous baseflow separation analyses baseflow values estimated through all these four graphical approaches fig 6a d show relatively large increases during precipitation events and the baseflow hydrographs are not smooth especially for the staircase patterns shown in the hydrographs of the hysep fixed fig 6b and sliding interval fig 6c approaches also the baseflow estimates from these approaches increase dramatically during precipitation events a large increase of baseflow during precipitation is observed not only in graphical approaches but also in the furey and gupta approach fig 6i for the results obtained from the lyne and hollick fig 6e and eckhardt approaches fig 6h the increases in baseflow estimates during precipitation are also obvious based on the derivative analysis baseflow separation results obtained from these approaches are not hydrologically plausible however although some of the baseflow separation approaches generate baseflow estimates that are not hydrologically plausible it is still difficult to determine the most optimal approach based on the analyses of hydrographs or its derivatives alone this is because data on actual baseflow from the acw is lacking and the criteria utilized to determine whether the given baseflow separation approach is hydrologically plausible or not is subjective therefore more rigorous assessment of baseflow separation techniques through simulated results from a 3d integrated hydrologic model is necessary that is baseflow values estimated through these ten baseflow separation techniques are compared with synthetic baseflow obtained from the hgs model to evaluate the performances of different approaches in the next section 3 evaluation of baseflow separation methods with synthetic data 3 1 synthetic baseflow from the hgs model in this study synthetic streamflow and baseflow at ten different study locations from may 1 2013 to april 30 2016 are obtained from the hgs model of the acw constructed by tong et al 2021 fig 7 shows the comparison between actual and synthetic streamflow from may 1 2013 to april 30 2016 from this figure it could be observed that although the actual and synthetic streamflow are not identical the values are generally close to each other and the rate of increase during precipitation is also similar for the time period considered therefore synthetic streamflow is utilized to estimate baseflow through the ten baseflow separation approaches utilized earlier and synthetic baseflow obtained from the model could be treated as actual baseflow to help determine the performance of different separation approaches fig 8 shows the comparison between synthetic streamflow and baseflow obtained from hgs as well as baseflow estimated from synthetic streamflow with the ten baseflow separation techniques at the new dundee gauging station location 7 figures si3 si11 show the results at the other nine locations the synthetic baseflow obtained from the hgs model is relatively low throughout the year and does not show an obvious increase during precipitation in general the synthetic baseflow hydrograph from hgs is smoother and there are no sharp peaks observed reflecting the diffusive exchange of groundwater with the stream compared with synthetic baseflow estimated baseflow calculated through the furey and gupta approach shows abnormally high values fig 8i baseflow estimated through the eckhardt fig 8h and lyne and hollick fig 8e approaches are also obviously higher than synthetic baseflow from hgs compared with the estimated baseflow through the three separation techniques baseflow from the remaining seven approaches fig 8a d 8f g 8j is lower and closer to synthetic baseflow however baseflow hydrographs estimated through three hysep approaches fig 8b d the chapman and maxwell approach fig 8f and the ewma approach fig 8j are not flat and show obvious increases during precipitation which does not correspond to the synthetic baseflow hydrographs from hgs overall the estimated baseflow hydrographs obtained through the ukih fig 8a and fukih fig 8g approaches are far lower and flatter than the baseflow hydrographs from the other baseflow separation approaches to quantitatively assess the results model performance statistics are computed and discussed next 3 2 performance assessment of baseflow estimation techniques fig 9 shows the scatterplots between synthetic and estimated baseflow for ten different baseflow separation techniques at the new dundee gauging station location 7 scatterplots for the other nine locations are provided in the si section as figures si12 si20 the red dashed regression lines and the corresponding equations show the relationship between synthetic and estimated baseflow the solid black 1 1 line indicates a perfect fit the coefficient of determination r2 shown in each graph represents how well the regression line approximates the original baseflow data the l1 norm is the mean absolute error which quantifies the absolute difference between synthetic and estimated baseflow while the l2 norm is the mean squared error which measures the average squared difference between synthetic and estimated baseflow the smaller the l1 and l2 norms the higher the correspondence of the synthetic and estimated baseflow and the better the performance of the baseflow separation approach the r2 value as well as l1 and l2 norms are calculated as 1 r 2 1 n i 1 n q m i Œº q m q 0 i Œº q 0 1 n i 1 n q m i Œº q m 2 1 n i 1 n q 0 i Œº q 0 2 2 2 l 1 q m q 0 1 n n i 1 q 0 i q m i 3 l 2 q m q 0 1 n n i 1 q 0 i q m i 2 where n is the total number of data q m i is the synthetic baseflow at i th time q 0 i is the estimated baseflow at i th time Œº q m is average synthetic baseflow and Œº q 0 is average estimated baseflow as mentioned previously synthetic baseflow obtained from hgs is relatively low throughout the year and the estimated baseflow is normally higher than synthetic baseflow resulting in a significant bias on fig 8 during dry seasons both estimated and synthetic baseflow are close to streamflow but during precipitation events estimated baseflow is obviously higher than its synthetic counterpart the scatterplots also reveal this feature fig 9 especially for the furey and gupta approach where the estimated baseflow is significantly higher than synthetic baseflow fig 9i from the regression lines in fig 9 the regression line slopes of the ukih fig 9a and the fukih fig 9g approaches are closer to the 1 1 line than the other approaches which indicates that the similarity of estimated and synthetic baseflow is higher when using the ukih fig 9a and fukih fig 9g approaches table 4 shows that the l1 and l2 norms of the ukih and the fukih approaches are also lower than the other approaches furthermore from the scatterplots of other study locations provided in the si section figures si12 si20 and the slope values provided in table 3 the estimated baseflow is still larger than synthetic baseflow for most cases and the furey and gupta approach always reveal lowest similarity as well as largest l1 and l2 norms tables 3 4 whereas the separation technique that gives the best approximation of baseflow estimates to synthetic baseflow is different from location 7 at some locations examination of figures si3 si11 that compare synthetic and estimated baseflow at the other nine locations and corresponding scatterplots figures si12 si20 reveal that overall estimated baseflow is consistently larger than simulated baseflow from hgs although at certain locations the correspondence is better such as the higher correspondence at location 1 figures si3 and si12 and lower correspondence at location 2 figures si4 and si13 these results collectively reveal that the most optimal approach varies with location for example figure si12 shows that the regression line for the chapman and maxwell approach figure si12f is closest to the 1 1 best fit line among the ten approaches at location 1 and l1 and l2 norms are also smallest table 4 to further assess the baseflow separation approach at each study location the correlation between synthetic and estimated baseflow is assessed through the nash sutcliffe nse number the nse number is calculated to quantify the goodness of fit between synthetic and estimated baseflow 4 nse 1 i 1 n q 0 i q m i 2 i 1 n q m i q m 2 where q m t and q 0 t were defined earlier and q m is the mean value of synthetic baseflow the nse number ranges from negative infinity to 1 0 the closer the nse number is to 1 0 the closer the estimated baseflow is to synthetic baseflow and the better the performance of the baseflow separation approach when the nse number is equal to 1 0 there is a perfect match of synthetic to estimated baseflow but when the nse number is equal to 0 0 the estimation error variance of that separation approach is equal to the variance of the synthetic baseflow which means that the predictions of the separation approach are accurate as the mean value of synthetic baseflow when the nse number is negative synthetic baseflow is a better predictor than the estimated value overall the larger the nse number the better is the performance of the baseflow separation approach table 5 summarizes the nse numbers for all the baseflow separation approaches at these ten study locations which measures the similarity of baseflow and dq dt between estimated and synthetic baseflow the largest nse numbers are marked with dark green and shown in bold while poor results are highlighted in red table 5 shows that the nse values between synthetic and estimated baseflow obtained through most of estimation approaches are negative and some of them are significantly small which represents an unsatisfactory fit with synthetic baseflow this is likely due to the differences in the physical and mathematical representation of baseflow by the hgs model and the various baseflow separation approaches for the hgs model detailed information about the catchment including the problem geometry soil type land use as well as surface water and groundwater flow parameters are utilized to build the model and to simulate baseflow values thus physical processes are more explicitly considered in hgs in contrast in graphical and filter approaches only the streamflow record is utilized to estimate baseflow and some separation approaches may not be suitable at a given location within the watershed leading to large differences between synthetic and estimated baseflow ultimately resulting in negative nse numbers some of which are unacceptably large in summary table 5 reveals that the best baseflow separation approach for locations 2 3 4 5 7 8 is the fukih approach while for locations 1 9 10 it is the chapman and maxwell approach and at location 6 it is the eckhardt approach fig 10 compares the synthetic and estimated baseflow calculated using the most optimal approach at all ten study locations showing good correspondence fig 11 shows the daily ratio of estimated baseflow through the fukih approach and synthetic baseflow to streamflow from hgs at location 8 as well as its yearly and monthly averages from may 1 2013 to april 30 2014 this figure reveals that the daily ratio of estimated baseflow to streamflow is approximately 0 80 1 00 when there is almost no precipitation during dry seasons when one examines the monthly average ratio of estimated baseflow to streamflow the ratio always becomes higher during periods of low precipitation for example the monthly average ratios for august 2013 and november 2013 are 0 82 and 0 96 higher than the monthly average ratios for the next few months with higher precipitation as precipitation events begin the daily ratio of estimated baseflow to streamflow begins to decrease specifically the daily ratio decreases from 0 90 1 00 to 0 20 0 60 and the monthly average ratio also becomes lower when precipitation is high during that month such as the monthly average ratio of 0 55 in october the yearly average ratio of estimated baseflow to streamflow is 0 78 from 2013 to 2014 moreover the monthly ratio of estimated baseflow to streamflow also changes with seasons specifically during the winter season from november 2013 to april 2014 the monthly average ratios of estimated baseflow to streamflow are approximately from 0 70 0 90 whereas in other seasons from may 2013 to october 2013 the monthly average ratios range between 0 60 0 80 fig 11 overall the ratio of estimated baseflow to streamflow during winter are generally higher than the ratio during other seasons in terms of synthetic baseflow computed with hgs values are generally lower than those obtained from various separation approaches thus the ratio of synthetic baseflow to streamflow is always lower than the ratio of estimated baseflow to streamflow fig 11 the daily ratio of synthetic baseflow to streamflow the monthly as well as yearly average ratios are all lower than equivalent ratios computed with estimated baseflow moreover the overall change of the ratio computed with synthetic baseflow shows similar features when compared to the ratio based on estimated baseflow during dry seasons the ratio of synthetic baseflow to streamflow is approximately 0 70 1 00 higher than that of the rainy season ranging approximately between 0 30 0 60 for example the monthly average ratio for august 2013 is 0 74 which is higher than the monthly average 0 46 in june and the monthly average ratio of 0 42 for october 2013 with higher precipitation in different seasons the daily ratio of synthetic baseflow to streamflow is also generally higher in winter and lower during other seasons as in the case for daily ratio of estimated baseflow to streamflow during the winter season which is from november to april monthly average ratios of synthetic baseflow to streamflow are approximately from 0 60 0 70 whereas in other seasons from may to october the monthly average ratios range from 0 40 0 60 fig 11 4 discussion 4 1 comparison of baseflow separation techniques with real data from the estimated baseflow calculated based on real streamflow data fig 5 it is observed that the baseflow hydrographs estimated through different baseflow separation approaches show different features for the graphical approaches fig 5a d as described in the si section linear interpolation is utilized leading to dramatically large increases of baseflow during precipitation events in addition the use of relative minimum streamflow values representing baseflow over certain time intervals results in staircase patterns which are abnormal features that are not observed under natural conditions hence are not hydrologically plausible for the digital filter approaches fig 5e j different filters and their determination of the most optimal parameters are dependent on environmental conditions of the watershed of interest fig 5 shows that the baseflow hydrographs obtained through filter approaches are generally smoother than their graphical counterparts as for the lyne and hollick fig 5e eckhardt fig 5h as well as furey and gupta fig 5i approaches baseflow significantly increases during precipitation events especially for the furey and gupta approach for the lyne and hollick approach the portion of baseflow relative to total streamflow is smaller than that in the furey and gupta approach which could be as high as 35 the computed baseflow relative to streamflow from the eckhardt approach is also around 35 fig 5i shows that baseflow could even take up to 50 of streamflow during rainfall periods when using the furey and gupta approach and the response of baseflow to precipitation events is rapid which is not consistent with the slow response features of baseflow for the chapman and maxwell fig 5f as well as the ewma fig 5j approaches there is no large increase during precipitation and baseflow accounts for approximately 15 of streamflow in general the baseflow hydrograph obtained with the fukih approach fig 5g is the flattest and smoothest which is also evident in corresponding dq dt values fig 6g this is because the fukih approach initially involves the ukih approach while a filter is then applied during the second stage resulting in a baseflow hydrograph that does not show any sudden increases during precipitation events and is relatively flat over the three year period over which the analysis is conducted however although some abnormal features could be observed from the analysis of these hydrographs obtained through different baseflow estimation techniques it is hard to directly determine which one is the most optimal estimation technique based on the subjective concept of hydrologic plausibility to assess the performance of each technique and to determine the optimal one true baseflow values are needed due to the lack of true baseflow measurements at the acw synthetic data generated with hgs are utilized in this study 4 2 comparison of baseflow separation techniques with synthetic data in this study hgs is utilized to generate synthetic streamflow and baseflow hydrographs at ten different monitoring locations within the acw so that they can be compared with those estimated with the ten baseflow separation techniques the hgs generated baseflow hydrograph is treated to be the true baseflow however one needs to acknowledge that sophisticated numerical models such as hgs used in this study could still produce errors during simulations this is so even if all known salient hydrological processes and large amounts of data are incorporated into the model to accurately simulate the conditions of the acw for example in the hgs model baseflow at one location is simulated by summing the exchange fluxes at all the streams nodes where the water flows to that location thus the resolution of the model grid could potentially impact simulation results therefore even if high resolution models are utilized one cannot ensure that simulated streamflow and baseflow hydrographs are free of numerical errors also the soil and underlying layers as well as land use in this model are divided into several categories but the distribution and division of different types of soil geological units as well as land use are far more intricate in the actual watershed likewise forcing functions i e initial and boundary conditions as well as source sink terms applied to the model are approximations to reality all these abovementioned factors could impact simulation results leading to potential errors in synthetic streamflow and baseflow computed with hgs despite these potential errors hgs results are instructive in assessing baseflow separation techniques given the most salient physical processes built into the model to capture the local hydrologic cycle including exchanges between surface water and groundwater for example fig 8 shows that synthetic baseflow is flat and smooth throughout the entire three year period the values of synthetic baseflow are relatively low and do not dramatically increase during rainfall compared with the synthetic baseflow hydrograph the estimated baseflow hydrograph calculated through the furey and gupta approach fig 8i shows large values that are several times larger than synthetic baseflow the baseflow hydrographs estimated through the eckhardt fig 8h as well as lyne and hollick fig 8e approaches are also considerably higher than the synthetic baseflow hydrograph as for the three graphical approaches when compared to the smooth synthetic baseflow hydrograph the estimated baseflow contains numerous shark peaks and staircase patterns that are not hydrologically plausible qualitatively speaking among all ten baseflow separation approaches the fukih approach fig 8g generates baseflow that is most similar to synthetic baseflow both in terms of their magnitude and features of the baseflow hydrographs to quantitatively assess which baseflow separation technique yields values that are closest to synthetic baseflow estimated with hgs model performance metrics such as the nse number as well as l1 and l2 norms are utilized results reveal that the most optimal baseflow estimation approach varies with the ten study locations for the acw according to previous research e g partington et al 2012 spatiotemporal variability in baseflow behavior might be due to heterogeneity in environmental factors such as land use topography geology slope and hydraulic parameters to name a few and different baseflow separation approaches result in baseflow hydrographs with different behavior and features for example the baseflow hydrograph estimated through the fukih approach is always relatively lower than other approaches and baseflow values do not significantly increase during precipitation events due to the second filtration by the digital approach thus this approach may be most suitable for catchments where the baseflow values are low and do not have dramatic variations in contrast other baseflow separation techniques examined in this study may be more suitable under different environmental conditions to better understand the influence of various environmental factors on baseflow additional research is needed moreover there is a clear need to obtain accurate baseflow estimates in the field to more directly compare against baseflow estimates obtained from streamflow records through various baseflow separation techniques the improved understanding of baseflow genesis mechanisms should lead to improved management of watersheds 5 summary and conclusions baseflow is a vital water cycle component to understand watershed hydrology and surface water groundwater interaction in this study baseflow is studied and estimated at the acw from may 2013 to december 2016 through several baseflow separation techniques including four graphical and six digital filter approaches to analyze features of baseflow and to evaluate the performances of each approach after estimating baseflow at a gauging station obtained through all ten approaches and analyzing results one can conclude that it is hard to determine the most optimal baseflow separation approach based on the concept of hydrologic plausibility alone this is because the concept of hydrologic plausibility is always subjective therefore reliable baseflow estimates along river reaches and their variations with seasons are needed to assess the performance of each baseflow separation technique although such records are not readily available given the absence of reliable baseflow estimates measured in the field and considering their uncertainty some researchers have relied on fully integrated three dimensional hydrological models to simulate baseflow values e g partington et al 2012 li et al 2014 su et al 2016 however the 3d integrated hydrologic model used in previous studies to conduct the analysis was based on monotonically sloping v shaped catchments which simplifies the actual intricate conditions in a natural environment in this study a high resolution hgs model of the acw is constructed and run by tong et al 2021 to simulate both surface water and baseflow hydrographs from 2013 to 2016 the simulated baseflow hydrograph from hgs is treated as the actual baseflow and utilized to investigate the performances of ten baseflow separation approaches our study resulted in the following conclusions 1 from the baseflow hydrograph estimated with actual streamflow data at a gauging station it could be inferred that the baseflow hydrographs obtained through graphical approaches always show abnormal patterns caused by the linear interpolation used in graphical approaches such as staircase patterns and shark peaks these features reflect sudden changes to estimated baseflow which is not in accordance with natural conditions also in graphical approaches baseflow hydrographs always show a large increase during significant precipitation events of longer durations this phenomenon has also been observed in the furey and gupta approach which is not hydrologically plausible 2 from the values of time derivatives dq dt computed from baseflow hydrograph it is observed that in graphical approaches the dq dt of baseflow is dramatically large during rainfall for the hysep fixed and sliding interval approaches and the dq dt of baseflow is even nearly the same as streamflow during the beginning of some precipitation events this is inconsistent with the anticipated delayed response of baseflow and this high increasing rate of baseflow is also not hydrologically plausible these large dq dt values are also observed when the furey and gupta approach is applied to the hydrographs based on the abnormal dq dt values these three baseflow estimation approaches are not considered to be good estimation approaches for the acw together with the examination of baseflow hydrographs the use of dq dt has been found to be very useful in assessing the hydrologic plausibility of baseflow separation techniques 3 as true baseflow hydrographs are not available at the acw synthetic baseflow hydrographs generated with hgs at ten study locations within the watershed are utilized as true baseflow to help assess the performances of baseflow separation techniques examination of synthetic baseflow at ten study locations revealed that they are in general flat and smooth throughout the year it does not show any significant increases between or during the precipitation events and generally the baseflow values are low which is only around 5 to 15 of streamflow during precipitation when precipitation values are large when precipitation values are low the proportion of synthetic baseflow in streamflow can reach 20 or higher compared with synthetic results the estimated baseflow hydrographs obtained through the eckhardt lyne and hollick as well as furey and gupta approaches are several times higher than synthetic baseflow during rainy seasons and this was especially the case for the furey and gupta approach the estimated baseflow hydrographs using the fukih approach is most similar with hgs results and they both exhibit low baseflow values and flat baseflow hydrographs for the acw 4 to quantitatively evaluate the goodness of fit of baseflow values computed from each baseflow separation approach with synthetic baseflow from hgs several model performance metrics are utilized from the scatterplots and regression lines it is inferred that synthetic baseflow from hgs is relatively low thus it is generally smaller than estimated baseflow in most cases in particular the nse number as well as l1 and l2 norms are also calculated for ten baseflow separation approaches at ten different monitoring locations within the acw and the results show that the most optimal approach at different locations are not consistent of the ten monitoring locations the fukih approach ranked the best at six locations the chapman and maxwell approach ranked to have the best performance at three locations while the eckhardt approach yielded the best results at one location 5 from the baseflow hydrographs at ten study locations seasonal patterns of changes to baseflow could be obviously observed during summertime baseflow becomes slightly higher corresponding to higher precipitation whereas during wintertime baseflow always decreases after comparing baseflow and streamflow hydrographs the increase in baseflow is much smaller than streamflow when there is a precipitation event corresponding with the feature of baseflow it almost always shows a muted and delayed response to precipitation events during rainy days the daily ratio of baseflow to streamflow varies from 0 20 to 0 60 whereas during dry seasons virtually all of streamflow constitutes baseflow underscoring the importance of groundwater to watershed fluxes the ratio of baseflow to streamflow also varies in different seasons during the winter season from november to april the ratio of baseflow to streamflow is generally higher than the ratio during other seasons from may to october 6 at different study locations within the acw the most optimal baseflow separation technique is not the same that is baseflow hydrographs at different location might be different caused through spatiotemporal variations in hydrological and geologic conditions therefore the baseflow separation technique that generates the most reasonable baseflow estimates may vary with environmental factors such as land use topography geology slope and hydraulic parameters to name a few further studies on how spatiotemporal variability in hydrological and geological conditions affect baseflow need to be investigated to better understand the factors that influence the genesis of baseflow and to also help the investigation of the selection of baseflow separation technique in a more rigorous fashion lastly while hgs simulation results are instructive in generating realistic baseflow estimates there is a clear need to obtain accurate baseflow estimates in the field more efficiently so that they can be compared to values estimated from baseflow separation techniques credit authorship contribution statement siyu cheng conceptualization methodology formal analysis investigation writing original draft visualization xin tong software methodology formal analysis investigation writing review editing walter a illman supervision conceptualization resources writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by a research grant from the canada first research excellence fund cfref and the discovery grant from natural sciences engineering research council of canada nserc awarded to walter a illman appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128279 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
2903,baseflow originating primarily from groundwater is a critical streamflow component although its accurate estimation is fraught with significant difficulties this study estimates baseflow through existing graphical and digital filter methods using actual streamflow data from a gauging station at the alder creek watershed acw and synthetic streamflow data at ten study locations within the same watershed simulated with hydrogeosphere hgs aquanty inc 2018 there are four widely used graphical institute for hydrology 1980 sloto and crouse 1996 aksoy et al 2008 and six digital filtering lyne and hollick 1979 chapman and maxwell 1996 furey and gupta 2001 eckhardt 2005 tularam and ilahee 2008 aksoy et al 2009 baseflow separation approaches compared in this study to determine the most optimal approach baseflow estimates from real data are assessed based on the subjective concept of hydrologic plausibility while baseflow estimates obtained from a hgs streamflow record with graphical and digital filtering methods are compared to those computed directly by hgs overall results from this study indicate that baseflow hydrographs reveal a seasonal pattern at the acw during wintertime streamflow is composed almost entirely of baseflow whereas during summertime baseflow only consists approximately 20 to 60 of streamflow after comparing baseflow estimates with those computed by hgs the most optimal approaches at the ten study locations are assessed results show that the best approach at six study locations is the fukih aksoy et al 2009 approach while at three locations the chapman and maxwell 1996 approach and for one location the eckhardt 2005 approach performed the best in conclusion it is inferred that the most optimal approach within the acw varies spatially keywords baseflow estimates baseflow separation surface water groundwater interaction graphical methods digital filter methods hydrologic plausibility data availability data will be made available on request 1 introduction baseflow is an essential component of streamflow which originates primarily from groundwater discharging into streams e g hall 1968 freeze 1972 hayashi and rosenberry 2002 eckhardt 2005 brodie et al 2007 under certain situations baseflow can also result from delayed flow from surface water features such as wetlands and lakes as well as through flow regulation and wastewater discharge piggott et al 2005 as an important component of streamflow baseflow plays an essential role in sustaining riparian and aquatic ecosystems as well as influencing stream water chemistry in many streams streamflow is primarily composed of baseflow during dry periods and during wet seasons the ratio of baseflow to streamflow could decrease significantly depending on site conditions for example in a dry climate baseflow has been estimated to constitute approximately 80 percent of river flow within the upper colorado river basin miller et al 2016 in the baseflow and water use assessment report by toronto and region conservation 2008 baseflow has been estimated to be approximately 40 percent from the don river watershed in a humid climate during summertime due to the spatiotemporal variability of baseflow from one watershed to another predicting the contribution of baseflow relative to streamflow is essential for effective watershed management research on baseflow characteristics is vital for comprehending runoff generation processes and understanding interactions among streamflow groundwater and other components of the water cycle moreover investigations on spatial and temporal variability of baseflow could lead to better quantification of the significance of groundwater in streamflow processes tong et al 2021 baseflow recession has also been studied by researchers to estimate aquifer parameters from streamflow data e g brutsaert and nieber 1977 troch et al 2013 liang et al 2017 due to the importance of accurately estimating baseflow several studies based on various approaches have been conducted e g winter et al 1998 cey et al 1998 kalbus et al 2006 rosenberry and labaugh 2008 however it is difficult to obtain accurate baseflow hydrographs directly and continuously in the field therefore many different approaches have been developed to estimate baseflow based on disparate data available within a watershed baseflow estimation methods can be roughly divided into three groups direct measurements tracer based separation and non tracer based separation methods direct measurements rely on different instruments such as bag type or automated seepage meters mini piezometer heat pulse meter and ultrasonic meter to measure baseflow values at discrete points e g kalbus et al 2006 rosenberry and labaugh 2008 these instruments are installed to measure water fluxes across the groundwater surface water interface while direct measurements are very desirable they typically only provide point estimates in addition direct measurements are always time consuming and are not viable in making measurements at multiple locations within a watershed and over long time scales such point measurements are also logistically difficult to conduct in large rivers where access to measurement sites can be limited and the safety of workers can be a concern tracer based separation methods mainly rely on various isotopic and chemical tracers to explore the generation processes of each water cycle component e g yu and schwartz 1999 by separating streamflow into surface runoff and baseflow in previous studies these approaches have been widely used to determine baseflow values although they are always laborious have high data and sampling requirements and cannot be applied to past events due to the lack of required chemical data gonzales et al 2009 moreover the assumptions embedded in this approach may not be satisfied for example tracer based methods may contain relatively large uncertainties from chemical reactions during the mixing of components tracer measurements and elevation effects on the isotopic composition of precipitation gonzales et al 2009 these uncertainties in chemical reactions could result in tracer concentration changes during water movement through the watershed thus leading to less reliable baseflow estimation results therefore alternative non tracer based methods are needed non tracer based baseflow separation methods could be subdivided into several groups including graphical e g institute of hydrology 1980 sloto and crouse 1996 and digital filter methods e g lyne and hollick 1979 chapman and maxwell 1996 furey and gupta 2001 aksoy et al 2009 eckhardt 2005 tularam and ilahee 2008 in graphical methods different criteria are used to separate streamflow into baseflow and surface runoff through the analysis of a streamflow hydrograph in digital filter methods numerical approaches are utilized to filter streamflow into different portions of the hydrograph in previous research on baseflow estimation various approaches have been utilized and then compared to evaluate results e g nathan and mcmahon 1990 cey et al 1998 chapman 1999 arnold et al 2000 smakhtin 2001 conant 2004 schwartz 2007 gonzales et al 2009 indarto et al 2016 lott and stewart 2016 xie et al 2020 kissel and schmalz 2020 for example cey et al 1998 compared four field approaches to measure baseflow values at a small watershed in southern ontario canada approaches compared include the use of the velocity area technique mini piezometer measurements seepage meter measurements and analyses of electrical conductivity as well as isotope data among the first three techniques the velocity area technique resulted in best baseflow estimates from the analyses of isotope and electrical conductivity data it was shown that during storm events pre event water contributed approximately 64 to 80 of total stream discharge and antecedent moisture conditions of the catchment were found to largely affect the percentage of event and pre event water in streamflow gonzales et al 2009 compared various baseflow estimation methods including both tracer and non tracer based methods in a lowland area of netherlands the tracer approach revealed that groundwater responded quickly to rainfall events in this area and surface water contributed to most of measured discharge during flood events moreover estimated results were compared with baseflow values determined through the tracer based method in their study gonzales et al 2009 concluded that the rating curve method and the recursive filtering method proposed by eckhardt 2005 resulted in reliable baseflow values indarto et al 2016 reviewed earlier work on baseflow estimation and used seven recursive digital and two graphical methods to streamflow records from a watershed in east java indonesia to determine optimal parameter values baseflow index and the appropriate method for the investigated watershed results revealed that the exponentially weighted moving average ewma approach tularam and ilahee 2008 the lyne and hollick method 1979 and the local minimum method sloto and crouse 1996 performed better in this area xie et al 2020 estimated baseflow values with four graphical and five digital filter methods for 1 815 catchments in the united states an evaluation criterion was established to determine the true baseflow and this evaluation criterion was used together with performance metrics to analyze the accuracy of each separation method in this evaluation criterion they selected streamflow values during low flow conditions and treated these streamflow values strictly as baseflow values low flow conditions were defined as the condition when quick flow which includes interflow and overland flow has ceased in a catchment through this evaluation criterion xie et al 2020 concluded that the eckhardt 2005 method had the best performance across the contiguous united states based on the evaluation results for 1 815 catchments in these previous studies several baseflow separation methods were utilized and evaluated however as mentioned previously baseflow values are notoriously hard to quantify over long time scales especially over a large study area actual baseflow values from a watershed are always absent to help determine the best separation technique to circumvent this issue most studies have determined the optimal baseflow separation technique based on the qualitative concept of hydrologic plausibility in this study hydrologic plausibility means that features of a given baseflow hydrograph separated from a streamflow record should be consistent with anticipated natural conditions such as 1 its less variable nature compared to streamflow 2 its delayed response relative to interflow and overland flow and 3 that it does not exceed streamflow or exhibits unusually high increasing decreasing rates during rainfall events emphasis is made that the concept is subjective as there are no quantitative metrics that one can rely on thus could potentially lead to biased results some researchers have employed fully integrated three dimensional surface water groundwater physical models under varying hydrological conditions to simulate baseflow and the synthetic baseflow were assumed to be the true baseflow to test various baseflow separation techniques e g partington et al 2012 li et al 2014 su et al 2016 for example partington et al 2012 used four approaches to estimate baseflow including the hysep approach sloto and crouse 1996 the part program rutledge 1998 constructed based on a graphical approach the bflow program arnold and allen 1999 constructed based on the lyne and hollick 1979 approach and the eckhardt approach 2005 to test the performance of each approach hydrogeosphere hgs aquanty inc 2018 in conjunction with a hydraulic mixing cell hmc approach were used to obtain the synthetic true baseflow values for a simple monotonically sloping v shaped catchment partington et al 2012 found that the performance of different baseflow estimation approaches varied under eight different scenarios with different hydrological conditions but overall the hysep sliding interval approach showed the best results in most scenarios for this study similar to the work of partington et al 2012 li et al 2014 used synthetic results from hgs for a simple v shaped catchment to test the accuracies of several recursive digital filters lyne and hollick 1979 chapman and maxwell 1996 boughton 1993 chapman 1999 eckhardt 2005 results showed that baseflow estimates obtained through the lyne and hollick filter could better match the hgs synthetic baseflow under a wider range of catchment hydrological characteristics and optimal parameters varied based on hydrological conditions su et al 2016 investigated the utility of hydrological signatures to calibrate the eckhardt filter method eckhardt 2005 and tested seven possible hydrological signatures of baseflow comparing against the synthetic baseflow values simulated with hgs by li et al 2014 again for a tilted v shaped catchment results showed that the eckhardt filter had better performance after a hydrological signature based calibration in these previous studies partington et al 2012 li et al 2014 and su et al 2016 hgs was used to simulate baseflow with the hmc approach to help evaluate the performances of baseflow separation approaches although the use of synthetic baseflow from a model solved the problem of obtaining true baseflow estimates from an actual site synthetic baseflow used in these studies was not simulated for a real watershed instead the analysis was conducted based on a monotonically sloping v shaped catchment that simplified the intricate environmental conditions in actual watersheds subjected to seasonal hydrologic variations the primary purpose of this study is to assess baseflow estimates obtained from streamflow data at the alder creek watershed acw in southern ontario canada using various baseflow separation techniques baseflow separation is conducted through ten different approaches including four graphical and six digital filter approaches graphical methods include the 1 united kingdom institute of hydrology ukih method institute of hydrology 1980 aksoy et al 2008 2 three hydrograph separation hysep methods which are fixed interval hysep1 sliding interval hysep2 and local minimum hysep3 methods sloto and crouse 1996 digital filter methods include the 1 lyne and hollick 1979 2 filtered united kingdom institute of hydrology fukih aksoy et al 2009 3 chapman and maxwell 1996 4 eckhardt 2005 5 furey and gupta 2001 and the 6 ewma tularam and ilahee 2008 approaches details to each of these approaches are provided in the supplementary information si section baseflow estimates obtained through ten approaches using actual streamflow data from a real streamflow gauge installed within the acw are first compared and assessed utilizing the qualitative concept of hydrologic plausibility for a more quantitative comparison actual baseflow estimates are necessary however as actual baseflow estimates from the acw are not available to properly evaluate the performance of these ten baseflow separation techniques synthetic streamflow and baseflow data obtained from hgs are assumed to be true data and utilized for a more rigorous comparison to determine the most optimal approach for the acw unlike the simple v shape catchment models used by partington et al 2012 and li et al 2014 actual hydrological and geological conditions of the acw are simulated with hgs that rigorously considers the coupling of surface water groundwater flow and other hydrological conditions for the acw tong et al 2021 although numerical models may not be able to provide actual baseflow values for a given site a fully 3d integrated hydrological model should still generate good independent conceptualization of watershed flow dynamics under different conditions until better baseflow estimation tools or observation techniques are developed partington et al 2012 2 site description and data used for analysis 2 1 site description the study area is the alder creek watershed acw which is situated at the southwestern portion of the grand river watershed located in southern ontario canada fig 1 covering an area of approximately 79 km2 grca 2009 in the central portion of the grand river watershed where the acw is located surficial material is predominantly comprised of glacial deposits fig 2 shows that the acw is covered by a large variety of surficial materials including clay gravel sand and silt more specifically the middle and the southeastern portion of the acw is predominately covered by poorly to well sorted fine sand and gravel to coarse sand the western part is mainly covered by poorly to well sorted fine gravel and sand to coarse gravel and clay till is mostly distributed at the northern edge these surficial sediments have mainly formed during the most recent episode of pleistocene glaciation which is the wisconsinan glacial event that commenced 25 000 years ago and ended approximately 10 000 years ago the wisconsinan glaciation is subdivided into different phases thus the sediments deposited during different episodes are present within the acw specifically the bulk of glacial sediments found in this area contain pre michigan sub episode tills non glacial sediments michigan sub episode tills as well as stratified sediments deposited by a regionally thick ice and oscillating lobate ice formed due to the advance and retreat of the wisconsinan ice sheet grca 2018 beneath the surficial sediments the bedrock beneath the watershed constitutes a portion of the michigan and appalachian basins which were deposited on the ocean floor by devonian silurian and ordovician aged marine sediments that inundated this area between 345 and 370 million years ago moreover the sedimentary bedrock around this area is mainly interbedded limestone dolomite carbonate material and the shale of the oldest ordovician to the youngest devonian grca 2009 as for land use a total of seven categories have been classified fig 3 shows that the acw is predominately used for agriculture with fully 70 percent of which is used as agricultural land other than agricultural land land use within the watershed area consists also of urban built up forest open water grassland areas golf course area as well as aggregate extraction and roads in terms of hydrology the acw has a humid continental climate with an annual precipitation ranging from 800 to 1 000 mm year and an average daily temperature ranging from 12 2 c to 21 0 c chow et al 2016 during spring and fall the weather is wet with an average daily temperature of 5 0 c and the precipitation is in the range of 100 mm month whereas the weather is dry during the summer with an average daily temperature of 18 0 c and the precipitation ranges from 30 to 40 mm month during winter the average daily temperature is low which is 4 4 c and the precipitation is mainly in the form of snowfall government of canada 2020 the annual snowfall in this watershed is 150 200 cm and the average annual evapotranspiration is estimated to be 500 600 mm year grca 2009 2 2 research data this study investigates the performances of various baseflow separation approaches which mainly rely on streamflow data to estimate baseflow values in this study streamflow data used includes actual streamflow and synthetic streamflow data sets actual streamflow data is a three year daily streamflow record from may 1 2013 to december 31 2016 at the new dundee gauging station location 7 on fig 1 maintained by environment and natural resources of canada as actual baseflow estimates are not available at any location throughout the acw synthetic streamflow and baseflow hydrographs over a three year period from may 1 2013 to april 30 2016 are also generated with hydrogeosphere hgs aquanty inc 2018 a 3d fully integrated hydrological model that rigorously considers the coupling of surface water and groundwater flow processes tong et al 2021 the hgs model for the acw is composed of a surficial land use layer 30 m resolution dem data from the ontario ministry of natural resources and forestry a soil layer and stratigraphic units through a previously developed groundwater flow model fig 4 tong et al 2021 for the surficial land use layer a 25 m resolution land use data from the grand river conservation authority grca is utilized to describe plant functional types and surface roughness grca 2009 within the land use layer there are seven land use types defined agricultural land built up extraction roads forest golf courses open water and wetlands beneath the surficial layer there is a 1 m deep soil layer defined with soil data from soil landscapes of canada slc compiled by agricultural and agri food canada in this soil layer there are four soil types containing three kinds of loam and sandy loam identified based on soil texture the modeled stratigraphic units originate from the feflow model utilized for the regional municipality of waterloo tier three assessment matrix and sspa 2014a 2014b fig 4 shows that stratigraphic units contain aquifer a afa aquifer b afb aquifer c afc aquitard a ata aquitard b atb and aquitard c atc and these layers consist of different geological materials ata1 whittlesey clay afa1 whittlesey sand ata2 wentworth till atb1 upper maryhill till port stanley tavistock mornington and or stratford tills afb1 upper waterloo moraine stratified sediments and equivalents atb2 middle maryhill till and equivalents afb2 middle waterloo moraine stratified sediments and equivalents atb3 lower maryhill and stratified equivalents afb3 lower waterloo moraine stratified sediments or catfish creek till outwash atc1 upper main catfish creek till afc1 middle catfish creek stratified deposits and atc2 lower catfish creek till matrix and sspa 2014a 2014b ten layers were used in the study area including surficial geology layer 1 ata1 afa1 and ata2 layer 2 atb1 layer 3 afb1 layer 4 atb2 layer 5 afb2 layers 6 and 7 atb3 layer 8 afb3 layer 9 atc1 afc1 and atc2 layer 10 the constructed hgs model contains 43 829 triangular nodes with 86 798 elements for a single layer and 482 119 nodes with 867 980 elements for the entire domain for ten geological layers specified in the study various hydraulic conductivity k values were assigned to the subsurface domain ranging from 6 41 10 5 m day to 406 87 m day for horizontal k in x and y directions k x k y based on the regional hydrogeologic feflow model matrix and sspa 2014a 2014b while k in the vertical direction k z is ten times smaller than k x and k y a critical depth boundary condition was prescribed at the surface periphery to allow surface water flow out of the model domain a no flow boundary condition was applied at the bottom of the domain and model periphery to represent the groundwater flow divide based on topographic highs when synthetic baseflow and streamflow are generated through the hgs model winter processes are also considered snow precipitation and temperature data are utilized and applied to the model for transient simulations specifically precipitation data utilized in the model are from the roseville environment canada weather station located 2 km outside the watershed evapotranspiration was evaluated through the hargreaves evapotranspiration equation hargreaves and allen 2003 while the potential evapotranspiration pet was first estimated based on available weather data daily maximum and minimum air temperature and location of the study area latitude the actualevapotranspiration aet was then calculated based on pet and land cover data the winter november 1 2013 to april 30 2014 november 1 2014 to april 30 2015 november 1 2015 to april 30 2016 simulation is considered after the completion of the simulation from spring to fall may 1 2013 to october 31 2013 may 1 2014 to october 31 2014 may 1 2015 to october 31 2015 and during the winter simulation winter processes and parameters are added to the hgs model including 1 the freezing and thawing of porewater with lower k than summer that controls groundwater flow in the shallow subsurface schilling et al 2019 and 2 surface water flow with snowmelt and winter processes tong et al 2021 the exchange flux between surface water and groundwater in the model is positive when the water flows from the soil surface down through the shallow subsurface and into the underlying aquifers as groundwater recharge while the flow rate is negative when water moves out of the subsurface to the surface as groundwater discharge ten study locations along the tributaries and the main stem of alder creek are selected where synthetic streamflow and baseflow hydrographs are recorded during the three year simulation period the ten study locations were selected by considering various factors such as the relative position within the watershed i e tributary or main stem surficial geology exchange flux values land use and proximity to pumping wells the estimated baseflow from the hgs model at one location is simulated by summing the groundwater recharge and discharge values along the river upstream of the point during each timestep further details to the hgs model for the acw and the computed synthetic baseflow are provided in tong et al 2021 and key parameters are summarized in table 1 2 3 evaluation of baseflow separation methods with actual data fig 5 shows the baseflow estimated using actual streamflow data at the new dundee gauging station location 7 on fig 1 through four graphical estimation methods institute of hydrology 1980 aksoy et al 2008 sloto and crouse 1996 and six digital filter methods lyne and hollick 1979 aksoy et al 2009 chapman and maxwell 1996 eckhardt 2005 furey and gupta 2001 tularam and ilahee 2008 while table 2 summarizes the arithmetic mean maximum and minimum values of baseflow estimated through each approach table 2 shows that the arithmetic mean values range from 0 082 to 0 186 m3 s and the mean values from the ukih and fukih approaches are relatively lower than other approaches the maximum baseflow values range from 0 262 to 1 840 m3 s and the fukih approach generates the lowest maximum values as for the minimum values all baseflow separation approaches generate a same minimum value of 0 003 m3 s except for the furey and gupta approach the arithmetic mean maximum and minimum values from the furey and gupta approach are all largest amongst the ten separation approaches in contrast the fukih approach yielded the smallest baseflow estimates due to the lack of actual baseflow data estimated baseflow results can only be analyzed based on the concept of hydrologic plausibility from fig 5 it is shown that the baseflow hydrograph from the ukih approach fig 5a is flat and does not show an obvious change during precipitation events for the hysep fixed interval method fig 5b the change of baseflow is more distinct than that in the ukih approach during precipitation baseflow increases significantly over a short duration in particular the estimated baseflow hydrograph reveals a staircase pattern which does not correspond with natural conditions hence is not hydrologically plausible comparing between these three hysep approaches fig 5b d all these three approaches generate a large increase in baseflow during rainfall events and the changing trend of estimated baseflow in the hysep sliding interval approach is similar to that in the fixed interval approach for the hysep approaches large increases of baseflow and the staircase pattern could be observed during rainfall events which does not correspond with the delayed increase of baseflow expected under actual conditions furthermore due to the linear interpolation used in graphical approaches the hydrograph of the hysep local minimum approach fig 5d contains numerous shark peaks and stiff turns which appears to be abnormal and again is not hydrologically plausible for the digital filter approaches the overall changes of baseflow are much smoother than those from the graphical approaches for example in the lyne and hollick approach fig 5e although the increased amount of baseflow is not as large as that in the hysep sliding interval approach fig 5c it still shows a significant increase during some precipitation events which follows the results from the hysep local minimum approach fig 5d in the chapman and maxwell approach fig 5f the change in the estimated baseflow is smoother than that in lyne and hollick approach fig 5e and the increase during precipitation is also lower in the fukih approach fig 5g as mentioned before baseflow is first calculated by the ukih graphical approach and then filtered and smoothed by a digital filter thus leading to an extremely flat baseflow hydrograph without obvious changes throughout the year as for the eckhardt approach fig 5h large increases during precipitation are also observed and the amount of increase is similar to the lyne and hollick approach fig 5e for the furey and gupta approach fig 5i there is no constraint set for baseflow see si for details hence the baseflow values sometimes exceed streamflow in addition quick and large baseflow responses to precipitation are visible on fig 5i which is inconsistent with the anticipated slow response characteristic of baseflow to better quantify the change of baseflow with time and to further examine the hydrologic plausibility of various baseflow separation techniques the discharge derivative with respect to time dq dt is obtained by calculating the change of discharge within each day based on the baseflow and streamflow data obtained through ten different techniques the use of dq dt in conjunction with streamflow and baseflow hydrographs may be able to better identify rates of increase or decrease and assess the hydrologic plausibility of each baseflow separation technique thus helping to select the most optimal technique fig 6 shows the resulting dq dt estimates for these ten approaches to visualize the change in discharge of both streamflow and baseflow with time examination of results reveals that for the hysep fixed interval approach fig 6b the dq dt of baseflow is very large during precipitation and is almost the same as the dq dt of streamflow during some precipitation events this abnormally large dq dt of baseflow is not only observed in the hysep fixed interval approach fig 6b but also shown in the hysep sliding interval fig 6c and furey and gupta fig 6i approaches combining the baseflow derivative analyses with previous baseflow separation analyses baseflow values estimated through all these four graphical approaches fig 6a d show relatively large increases during precipitation events and the baseflow hydrographs are not smooth especially for the staircase patterns shown in the hydrographs of the hysep fixed fig 6b and sliding interval fig 6c approaches also the baseflow estimates from these approaches increase dramatically during precipitation events a large increase of baseflow during precipitation is observed not only in graphical approaches but also in the furey and gupta approach fig 6i for the results obtained from the lyne and hollick fig 6e and eckhardt approaches fig 6h the increases in baseflow estimates during precipitation are also obvious based on the derivative analysis baseflow separation results obtained from these approaches are not hydrologically plausible however although some of the baseflow separation approaches generate baseflow estimates that are not hydrologically plausible it is still difficult to determine the most optimal approach based on the analyses of hydrographs or its derivatives alone this is because data on actual baseflow from the acw is lacking and the criteria utilized to determine whether the given baseflow separation approach is hydrologically plausible or not is subjective therefore more rigorous assessment of baseflow separation techniques through simulated results from a 3d integrated hydrologic model is necessary that is baseflow values estimated through these ten baseflow separation techniques are compared with synthetic baseflow obtained from the hgs model to evaluate the performances of different approaches in the next section 3 evaluation of baseflow separation methods with synthetic data 3 1 synthetic baseflow from the hgs model in this study synthetic streamflow and baseflow at ten different study locations from may 1 2013 to april 30 2016 are obtained from the hgs model of the acw constructed by tong et al 2021 fig 7 shows the comparison between actual and synthetic streamflow from may 1 2013 to april 30 2016 from this figure it could be observed that although the actual and synthetic streamflow are not identical the values are generally close to each other and the rate of increase during precipitation is also similar for the time period considered therefore synthetic streamflow is utilized to estimate baseflow through the ten baseflow separation approaches utilized earlier and synthetic baseflow obtained from the model could be treated as actual baseflow to help determine the performance of different separation approaches fig 8 shows the comparison between synthetic streamflow and baseflow obtained from hgs as well as baseflow estimated from synthetic streamflow with the ten baseflow separation techniques at the new dundee gauging station location 7 figures si3 si11 show the results at the other nine locations the synthetic baseflow obtained from the hgs model is relatively low throughout the year and does not show an obvious increase during precipitation in general the synthetic baseflow hydrograph from hgs is smoother and there are no sharp peaks observed reflecting the diffusive exchange of groundwater with the stream compared with synthetic baseflow estimated baseflow calculated through the furey and gupta approach shows abnormally high values fig 8i baseflow estimated through the eckhardt fig 8h and lyne and hollick fig 8e approaches are also obviously higher than synthetic baseflow from hgs compared with the estimated baseflow through the three separation techniques baseflow from the remaining seven approaches fig 8a d 8f g 8j is lower and closer to synthetic baseflow however baseflow hydrographs estimated through three hysep approaches fig 8b d the chapman and maxwell approach fig 8f and the ewma approach fig 8j are not flat and show obvious increases during precipitation which does not correspond to the synthetic baseflow hydrographs from hgs overall the estimated baseflow hydrographs obtained through the ukih fig 8a and fukih fig 8g approaches are far lower and flatter than the baseflow hydrographs from the other baseflow separation approaches to quantitatively assess the results model performance statistics are computed and discussed next 3 2 performance assessment of baseflow estimation techniques fig 9 shows the scatterplots between synthetic and estimated baseflow for ten different baseflow separation techniques at the new dundee gauging station location 7 scatterplots for the other nine locations are provided in the si section as figures si12 si20 the red dashed regression lines and the corresponding equations show the relationship between synthetic and estimated baseflow the solid black 1 1 line indicates a perfect fit the coefficient of determination r2 shown in each graph represents how well the regression line approximates the original baseflow data the l1 norm is the mean absolute error which quantifies the absolute difference between synthetic and estimated baseflow while the l2 norm is the mean squared error which measures the average squared difference between synthetic and estimated baseflow the smaller the l1 and l2 norms the higher the correspondence of the synthetic and estimated baseflow and the better the performance of the baseflow separation approach the r2 value as well as l1 and l2 norms are calculated as 1 r 2 1 n i 1 n q m i Œº q m q 0 i Œº q 0 1 n i 1 n q m i Œº q m 2 1 n i 1 n q 0 i Œº q 0 2 2 2 l 1 q m q 0 1 n n i 1 q 0 i q m i 3 l 2 q m q 0 1 n n i 1 q 0 i q m i 2 where n is the total number of data q m i is the synthetic baseflow at i th time q 0 i is the estimated baseflow at i th time Œº q m is average synthetic baseflow and Œº q 0 is average estimated baseflow as mentioned previously synthetic baseflow obtained from hgs is relatively low throughout the year and the estimated baseflow is normally higher than synthetic baseflow resulting in a significant bias on fig 8 during dry seasons both estimated and synthetic baseflow are close to streamflow but during precipitation events estimated baseflow is obviously higher than its synthetic counterpart the scatterplots also reveal this feature fig 9 especially for the furey and gupta approach where the estimated baseflow is significantly higher than synthetic baseflow fig 9i from the regression lines in fig 9 the regression line slopes of the ukih fig 9a and the fukih fig 9g approaches are closer to the 1 1 line than the other approaches which indicates that the similarity of estimated and synthetic baseflow is higher when using the ukih fig 9a and fukih fig 9g approaches table 4 shows that the l1 and l2 norms of the ukih and the fukih approaches are also lower than the other approaches furthermore from the scatterplots of other study locations provided in the si section figures si12 si20 and the slope values provided in table 3 the estimated baseflow is still larger than synthetic baseflow for most cases and the furey and gupta approach always reveal lowest similarity as well as largest l1 and l2 norms tables 3 4 whereas the separation technique that gives the best approximation of baseflow estimates to synthetic baseflow is different from location 7 at some locations examination of figures si3 si11 that compare synthetic and estimated baseflow at the other nine locations and corresponding scatterplots figures si12 si20 reveal that overall estimated baseflow is consistently larger than simulated baseflow from hgs although at certain locations the correspondence is better such as the higher correspondence at location 1 figures si3 and si12 and lower correspondence at location 2 figures si4 and si13 these results collectively reveal that the most optimal approach varies with location for example figure si12 shows that the regression line for the chapman and maxwell approach figure si12f is closest to the 1 1 best fit line among the ten approaches at location 1 and l1 and l2 norms are also smallest table 4 to further assess the baseflow separation approach at each study location the correlation between synthetic and estimated baseflow is assessed through the nash sutcliffe nse number the nse number is calculated to quantify the goodness of fit between synthetic and estimated baseflow 4 nse 1 i 1 n q 0 i q m i 2 i 1 n q m i q m 2 where q m t and q 0 t were defined earlier and q m is the mean value of synthetic baseflow the nse number ranges from negative infinity to 1 0 the closer the nse number is to 1 0 the closer the estimated baseflow is to synthetic baseflow and the better the performance of the baseflow separation approach when the nse number is equal to 1 0 there is a perfect match of synthetic to estimated baseflow but when the nse number is equal to 0 0 the estimation error variance of that separation approach is equal to the variance of the synthetic baseflow which means that the predictions of the separation approach are accurate as the mean value of synthetic baseflow when the nse number is negative synthetic baseflow is a better predictor than the estimated value overall the larger the nse number the better is the performance of the baseflow separation approach table 5 summarizes the nse numbers for all the baseflow separation approaches at these ten study locations which measures the similarity of baseflow and dq dt between estimated and synthetic baseflow the largest nse numbers are marked with dark green and shown in bold while poor results are highlighted in red table 5 shows that the nse values between synthetic and estimated baseflow obtained through most of estimation approaches are negative and some of them are significantly small which represents an unsatisfactory fit with synthetic baseflow this is likely due to the differences in the physical and mathematical representation of baseflow by the hgs model and the various baseflow separation approaches for the hgs model detailed information about the catchment including the problem geometry soil type land use as well as surface water and groundwater flow parameters are utilized to build the model and to simulate baseflow values thus physical processes are more explicitly considered in hgs in contrast in graphical and filter approaches only the streamflow record is utilized to estimate baseflow and some separation approaches may not be suitable at a given location within the watershed leading to large differences between synthetic and estimated baseflow ultimately resulting in negative nse numbers some of which are unacceptably large in summary table 5 reveals that the best baseflow separation approach for locations 2 3 4 5 7 8 is the fukih approach while for locations 1 9 10 it is the chapman and maxwell approach and at location 6 it is the eckhardt approach fig 10 compares the synthetic and estimated baseflow calculated using the most optimal approach at all ten study locations showing good correspondence fig 11 shows the daily ratio of estimated baseflow through the fukih approach and synthetic baseflow to streamflow from hgs at location 8 as well as its yearly and monthly averages from may 1 2013 to april 30 2014 this figure reveals that the daily ratio of estimated baseflow to streamflow is approximately 0 80 1 00 when there is almost no precipitation during dry seasons when one examines the monthly average ratio of estimated baseflow to streamflow the ratio always becomes higher during periods of low precipitation for example the monthly average ratios for august 2013 and november 2013 are 0 82 and 0 96 higher than the monthly average ratios for the next few months with higher precipitation as precipitation events begin the daily ratio of estimated baseflow to streamflow begins to decrease specifically the daily ratio decreases from 0 90 1 00 to 0 20 0 60 and the monthly average ratio also becomes lower when precipitation is high during that month such as the monthly average ratio of 0 55 in october the yearly average ratio of estimated baseflow to streamflow is 0 78 from 2013 to 2014 moreover the monthly ratio of estimated baseflow to streamflow also changes with seasons specifically during the winter season from november 2013 to april 2014 the monthly average ratios of estimated baseflow to streamflow are approximately from 0 70 0 90 whereas in other seasons from may 2013 to october 2013 the monthly average ratios range between 0 60 0 80 fig 11 overall the ratio of estimated baseflow to streamflow during winter are generally higher than the ratio during other seasons in terms of synthetic baseflow computed with hgs values are generally lower than those obtained from various separation approaches thus the ratio of synthetic baseflow to streamflow is always lower than the ratio of estimated baseflow to streamflow fig 11 the daily ratio of synthetic baseflow to streamflow the monthly as well as yearly average ratios are all lower than equivalent ratios computed with estimated baseflow moreover the overall change of the ratio computed with synthetic baseflow shows similar features when compared to the ratio based on estimated baseflow during dry seasons the ratio of synthetic baseflow to streamflow is approximately 0 70 1 00 higher than that of the rainy season ranging approximately between 0 30 0 60 for example the monthly average ratio for august 2013 is 0 74 which is higher than the monthly average 0 46 in june and the monthly average ratio of 0 42 for october 2013 with higher precipitation in different seasons the daily ratio of synthetic baseflow to streamflow is also generally higher in winter and lower during other seasons as in the case for daily ratio of estimated baseflow to streamflow during the winter season which is from november to april monthly average ratios of synthetic baseflow to streamflow are approximately from 0 60 0 70 whereas in other seasons from may to october the monthly average ratios range from 0 40 0 60 fig 11 4 discussion 4 1 comparison of baseflow separation techniques with real data from the estimated baseflow calculated based on real streamflow data fig 5 it is observed that the baseflow hydrographs estimated through different baseflow separation approaches show different features for the graphical approaches fig 5a d as described in the si section linear interpolation is utilized leading to dramatically large increases of baseflow during precipitation events in addition the use of relative minimum streamflow values representing baseflow over certain time intervals results in staircase patterns which are abnormal features that are not observed under natural conditions hence are not hydrologically plausible for the digital filter approaches fig 5e j different filters and their determination of the most optimal parameters are dependent on environmental conditions of the watershed of interest fig 5 shows that the baseflow hydrographs obtained through filter approaches are generally smoother than their graphical counterparts as for the lyne and hollick fig 5e eckhardt fig 5h as well as furey and gupta fig 5i approaches baseflow significantly increases during precipitation events especially for the furey and gupta approach for the lyne and hollick approach the portion of baseflow relative to total streamflow is smaller than that in the furey and gupta approach which could be as high as 35 the computed baseflow relative to streamflow from the eckhardt approach is also around 35 fig 5i shows that baseflow could even take up to 50 of streamflow during rainfall periods when using the furey and gupta approach and the response of baseflow to precipitation events is rapid which is not consistent with the slow response features of baseflow for the chapman and maxwell fig 5f as well as the ewma fig 5j approaches there is no large increase during precipitation and baseflow accounts for approximately 15 of streamflow in general the baseflow hydrograph obtained with the fukih approach fig 5g is the flattest and smoothest which is also evident in corresponding dq dt values fig 6g this is because the fukih approach initially involves the ukih approach while a filter is then applied during the second stage resulting in a baseflow hydrograph that does not show any sudden increases during precipitation events and is relatively flat over the three year period over which the analysis is conducted however although some abnormal features could be observed from the analysis of these hydrographs obtained through different baseflow estimation techniques it is hard to directly determine which one is the most optimal estimation technique based on the subjective concept of hydrologic plausibility to assess the performance of each technique and to determine the optimal one true baseflow values are needed due to the lack of true baseflow measurements at the acw synthetic data generated with hgs are utilized in this study 4 2 comparison of baseflow separation techniques with synthetic data in this study hgs is utilized to generate synthetic streamflow and baseflow hydrographs at ten different monitoring locations within the acw so that they can be compared with those estimated with the ten baseflow separation techniques the hgs generated baseflow hydrograph is treated to be the true baseflow however one needs to acknowledge that sophisticated numerical models such as hgs used in this study could still produce errors during simulations this is so even if all known salient hydrological processes and large amounts of data are incorporated into the model to accurately simulate the conditions of the acw for example in the hgs model baseflow at one location is simulated by summing the exchange fluxes at all the streams nodes where the water flows to that location thus the resolution of the model grid could potentially impact simulation results therefore even if high resolution models are utilized one cannot ensure that simulated streamflow and baseflow hydrographs are free of numerical errors also the soil and underlying layers as well as land use in this model are divided into several categories but the distribution and division of different types of soil geological units as well as land use are far more intricate in the actual watershed likewise forcing functions i e initial and boundary conditions as well as source sink terms applied to the model are approximations to reality all these abovementioned factors could impact simulation results leading to potential errors in synthetic streamflow and baseflow computed with hgs despite these potential errors hgs results are instructive in assessing baseflow separation techniques given the most salient physical processes built into the model to capture the local hydrologic cycle including exchanges between surface water and groundwater for example fig 8 shows that synthetic baseflow is flat and smooth throughout the entire three year period the values of synthetic baseflow are relatively low and do not dramatically increase during rainfall compared with the synthetic baseflow hydrograph the estimated baseflow hydrograph calculated through the furey and gupta approach fig 8i shows large values that are several times larger than synthetic baseflow the baseflow hydrographs estimated through the eckhardt fig 8h as well as lyne and hollick fig 8e approaches are also considerably higher than the synthetic baseflow hydrograph as for the three graphical approaches when compared to the smooth synthetic baseflow hydrograph the estimated baseflow contains numerous shark peaks and staircase patterns that are not hydrologically plausible qualitatively speaking among all ten baseflow separation approaches the fukih approach fig 8g generates baseflow that is most similar to synthetic baseflow both in terms of their magnitude and features of the baseflow hydrographs to quantitatively assess which baseflow separation technique yields values that are closest to synthetic baseflow estimated with hgs model performance metrics such as the nse number as well as l1 and l2 norms are utilized results reveal that the most optimal baseflow estimation approach varies with the ten study locations for the acw according to previous research e g partington et al 2012 spatiotemporal variability in baseflow behavior might be due to heterogeneity in environmental factors such as land use topography geology slope and hydraulic parameters to name a few and different baseflow separation approaches result in baseflow hydrographs with different behavior and features for example the baseflow hydrograph estimated through the fukih approach is always relatively lower than other approaches and baseflow values do not significantly increase during precipitation events due to the second filtration by the digital approach thus this approach may be most suitable for catchments where the baseflow values are low and do not have dramatic variations in contrast other baseflow separation techniques examined in this study may be more suitable under different environmental conditions to better understand the influence of various environmental factors on baseflow additional research is needed moreover there is a clear need to obtain accurate baseflow estimates in the field to more directly compare against baseflow estimates obtained from streamflow records through various baseflow separation techniques the improved understanding of baseflow genesis mechanisms should lead to improved management of watersheds 5 summary and conclusions baseflow is a vital water cycle component to understand watershed hydrology and surface water groundwater interaction in this study baseflow is studied and estimated at the acw from may 2013 to december 2016 through several baseflow separation techniques including four graphical and six digital filter approaches to analyze features of baseflow and to evaluate the performances of each approach after estimating baseflow at a gauging station obtained through all ten approaches and analyzing results one can conclude that it is hard to determine the most optimal baseflow separation approach based on the concept of hydrologic plausibility alone this is because the concept of hydrologic plausibility is always subjective therefore reliable baseflow estimates along river reaches and their variations with seasons are needed to assess the performance of each baseflow separation technique although such records are not readily available given the absence of reliable baseflow estimates measured in the field and considering their uncertainty some researchers have relied on fully integrated three dimensional hydrological models to simulate baseflow values e g partington et al 2012 li et al 2014 su et al 2016 however the 3d integrated hydrologic model used in previous studies to conduct the analysis was based on monotonically sloping v shaped catchments which simplifies the actual intricate conditions in a natural environment in this study a high resolution hgs model of the acw is constructed and run by tong et al 2021 to simulate both surface water and baseflow hydrographs from 2013 to 2016 the simulated baseflow hydrograph from hgs is treated as the actual baseflow and utilized to investigate the performances of ten baseflow separation approaches our study resulted in the following conclusions 1 from the baseflow hydrograph estimated with actual streamflow data at a gauging station it could be inferred that the baseflow hydrographs obtained through graphical approaches always show abnormal patterns caused by the linear interpolation used in graphical approaches such as staircase patterns and shark peaks these features reflect sudden changes to estimated baseflow which is not in accordance with natural conditions also in graphical approaches baseflow hydrographs always show a large increase during significant precipitation events of longer durations this phenomenon has also been observed in the furey and gupta approach which is not hydrologically plausible 2 from the values of time derivatives dq dt computed from baseflow hydrograph it is observed that in graphical approaches the dq dt of baseflow is dramatically large during rainfall for the hysep fixed and sliding interval approaches and the dq dt of baseflow is even nearly the same as streamflow during the beginning of some precipitation events this is inconsistent with the anticipated delayed response of baseflow and this high increasing rate of baseflow is also not hydrologically plausible these large dq dt values are also observed when the furey and gupta approach is applied to the hydrographs based on the abnormal dq dt values these three baseflow estimation approaches are not considered to be good estimation approaches for the acw together with the examination of baseflow hydrographs the use of dq dt has been found to be very useful in assessing the hydrologic plausibility of baseflow separation techniques 3 as true baseflow hydrographs are not available at the acw synthetic baseflow hydrographs generated with hgs at ten study locations within the watershed are utilized as true baseflow to help assess the performances of baseflow separation techniques examination of synthetic baseflow at ten study locations revealed that they are in general flat and smooth throughout the year it does not show any significant increases between or during the precipitation events and generally the baseflow values are low which is only around 5 to 15 of streamflow during precipitation when precipitation values are large when precipitation values are low the proportion of synthetic baseflow in streamflow can reach 20 or higher compared with synthetic results the estimated baseflow hydrographs obtained through the eckhardt lyne and hollick as well as furey and gupta approaches are several times higher than synthetic baseflow during rainy seasons and this was especially the case for the furey and gupta approach the estimated baseflow hydrographs using the fukih approach is most similar with hgs results and they both exhibit low baseflow values and flat baseflow hydrographs for the acw 4 to quantitatively evaluate the goodness of fit of baseflow values computed from each baseflow separation approach with synthetic baseflow from hgs several model performance metrics are utilized from the scatterplots and regression lines it is inferred that synthetic baseflow from hgs is relatively low thus it is generally smaller than estimated baseflow in most cases in particular the nse number as well as l1 and l2 norms are also calculated for ten baseflow separation approaches at ten different monitoring locations within the acw and the results show that the most optimal approach at different locations are not consistent of the ten monitoring locations the fukih approach ranked the best at six locations the chapman and maxwell approach ranked to have the best performance at three locations while the eckhardt approach yielded the best results at one location 5 from the baseflow hydrographs at ten study locations seasonal patterns of changes to baseflow could be obviously observed during summertime baseflow becomes slightly higher corresponding to higher precipitation whereas during wintertime baseflow always decreases after comparing baseflow and streamflow hydrographs the increase in baseflow is much smaller than streamflow when there is a precipitation event corresponding with the feature of baseflow it almost always shows a muted and delayed response to precipitation events during rainy days the daily ratio of baseflow to streamflow varies from 0 20 to 0 60 whereas during dry seasons virtually all of streamflow constitutes baseflow underscoring the importance of groundwater to watershed fluxes the ratio of baseflow to streamflow also varies in different seasons during the winter season from november to april the ratio of baseflow to streamflow is generally higher than the ratio during other seasons from may to october 6 at different study locations within the acw the most optimal baseflow separation technique is not the same that is baseflow hydrographs at different location might be different caused through spatiotemporal variations in hydrological and geologic conditions therefore the baseflow separation technique that generates the most reasonable baseflow estimates may vary with environmental factors such as land use topography geology slope and hydraulic parameters to name a few further studies on how spatiotemporal variability in hydrological and geological conditions affect baseflow need to be investigated to better understand the factors that influence the genesis of baseflow and to also help the investigation of the selection of baseflow separation technique in a more rigorous fashion lastly while hgs simulation results are instructive in generating realistic baseflow estimates there is a clear need to obtain accurate baseflow estimates in the field more efficiently so that they can be compared to values estimated from baseflow separation techniques credit authorship contribution statement siyu cheng conceptualization methodology formal analysis investigation writing original draft visualization xin tong software methodology formal analysis investigation writing review editing walter a illman supervision conceptualization resources writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by a research grant from the canada first research excellence fund cfref and the discovery grant from natural sciences engineering research council of canada nserc awarded to walter a illman appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128279 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
2904,hydrological models are often applied to acquire estimates of evapotranspiration eta using quality inputs of reference evapotranspiration et0 however their application may be limited by the need for good quality long term data inputs in data scarce regions the use of satellite earth observation data as inputs to these models may provide a potential solution to overcome data acquisition challenges associated with conventional data collection approaches in this study the agricultural catchments research unit acru hydrological model was applied to estimate the eta using both in situ and satellite derived estimates of et0 as inputs to the model the simulated eta estimates were then evaluated through comparisons against field based measurements of eta acquired from an eddy covariance system ecet as well as from the application of the surface energy balance system sebs model the results of these investigations demonstrated that the meteorologically based acru eta simulations marginally outperformed the satellite based acru eta simulations while these results highlight the influence which the quality of et0 inputs may have on the accuracy of the acru derived eta estimates the concurrent application and evaluation of sebs demonstrated that alternate approaches to hydrological modelling may be better suited for eta estimation in certain instances keywords evapotranspiration earth observation sebs hydrological modelling data availability the authors do not have permission to share data 1 introduction globally the effects of anthropogenic induced climate and land use change coupled with the rapid expansion of the human population have resulted in further pressures being placed upon water security molle et al 2010 pittock and lankford 2010 timmermans et al 2013 this situation takes on added significance in semi arid and arid environments such as south africa where securing sufficient water supply to all water users remains a challenge rodda et al 2016 enqvist and ziervogel 2019 consequently improving upon existing hydrological process understanding and accurately quantifying spatio temporal dynamics of these processes is paramount to ensure the judicious use and management of water resources jovanovic et al 2015 hydrological models are often implemented as tools to guide water resources management decisions as they are able to provide relatively simplistic representations of complex systems consequently allowing for a logical and quantitative understanding of hydrological process dynamics to be attained davie 2008 although the implementation of these tools can prove to be expedient to facilitate improved water resources management good quality and long term in situ data to drive these models is often unavailable meijerink et al 2007 lekula and lubczynski 2019 consequently this may limit the efficacy of effectively utilizing these tools to guide water resources management decisions as these in situ observations are required to understand and assess intrinsic model limitations related to process representation at various spatio temporal scales as well as to limit the uncertainty associated with simulated output gokool et al 2019 jiang and wang 2019 globally and particularly from a south african perspective this is a significant issue due to the rapid decline in long term monitoring networks pitman 2011 dwa 2013 pegram et al 2016 toucher et al 2016 lekula and lubczynski 2019 continuous advancements in earth observation eo technologies over the last few decades have provided a potential solution to address data scarcity as eo is able to overcome many of the limitations associated with traditional field based data collection approaches consequently in recent times the use of eo derived data inputs has begun to feature more prominently in hydrological modelling applications van dijk and renzullo 2011 fern andez prieto et al 2012 coelho et al 2017 jiang and wang 2019 earth observation data can be used in hydrological models at three different levels i direct use of eo data as inputs to hydrological simulation models ii using eo data for the calibration of parameters within the model and iii assimilation of eo data into hydrological models in order to improve model simulations xu et al 2014 there have been ample studies focusing on the use of calibration and data assimilation procedures in the estimation of satellite eta kamble and irmak 2008 vazifedoust et al 2009 zhang et al 2009 hartanto et al 2017 jiang et al 2020 bennour et al 2022 however there is a general lack of studies focusing on using eta as a direct input into models this is because most hydrological models were developed to allow for the input of et0 data which is then used to calculate eta therefore most studies focus on the modification of the model code in order to accommodate eta as direct input into the model for example chen et al 2005 calculated eta using landsat data with the objective of capturing the spatial and temporal variability of eta over a small watershed in saskatchewan canada the wigmosta model code was then modified to allow for the ingestion of the satellite derived eta stisen et al 2008 and liu et al 2012 performed similar studies incorporating eo data directly into the mike she model stisen et al 2008 used eo data from the advanced very high resolution radiometer avhrr satellite liu et al 2012 developed a separate routine in the mike she model to allow for the direct input of eta estimates calculated from modis data both studies found that eo data can be confidently used to replace field based data when faced with a lack of sufficient data records whilst these studies have proven the successful incorporation of eta into models operational water resource managers continue to be more inclined towards the use of conventional data as direct input into hydrological models van dijk and renzullo 2011 mengistu et al 2014 a review of previous studies using level 1 shows that there are two ways to incorporate satellite eta into models through the input of satellite based et0 in the model or the input of satellite based eta in the model the main purpose of this study is to establish the best way of doing this should we take advantage of the way hydrological models are presently conceptualized and estimate eta through inputs of satellite based et0 or should consideration be given to developing the model further to accommodate eta as an input we attempt to shed some light on these questions through i the determination of eta with the agricultural catchments research unit acru hydrological model using conventional and satellite derived et0 data sets ii the concurrent estimation of eta using the surface energy balance system sebs model both modis and landsat data will be used to assess the impact of spatial resolution on eta and iii the comparison of different methods and data sources on the resultant eta we present our case in the context of a sub catchment situated in the western cape province of south africa the study site was chosen based on sufficient data availability and extensive knowledge about the area which are important factors to consider when modelling a system the intended purpose of the study was not to extend knowledge of the site itself but to apply the model in which our hypothesis could be tested the representation of the study site within the model was sufficient for the intercomparisons that we tried to achieve in this study 2 materials and methods 2 1 site description the study was conducted in the olifants doorn catchment situated in the western cape province of south africa fig 1 the main river in the catchment is the olifants river of which the sout river and the doring river are its main tributaries dwaf 2005 the local conditions are characterized by a mediterranean climate with a mean annual precipitation map of 200 mm year 1 which is exceeded by the potential evapotranspiration ep of 1800 mm year 1 making the catchment prone to extreme water scarcity dwaf 2005 the study site lies in the southern hemisphere and therefore experiences an austral winter and austral summer temperatures in winter are as low as 3 c and reach a high of up to 44 c in summer dwaf 2005 the altitude for the catchment varies from 114 m in the lower lying areas to 1186 m in the mountainous regions weepener et al 2011 the western part of the olifants doorn catchment is dominated by metamorphic rocks and the eastern part by shale department of water affairs dwa 2012 the focus of this study is within a quinary catchment e10f3 which possesses an area of 197 87 km2 fig 1 quinaries are a further subdivision of quaternaries into smaller more homogeneous catchments for the purpose of modelling schulze et al 2010 2 2 instrumentation data collection and data processing 2 2 1 in situ data two eddy covariance ec systems were installed by the council for scientific and industrial research csir within the study area approximately 5 km apart from each other fig 1 shows the ec system situated at the patrysberg farm where navel oranges are grown and the second ec system which is situated on the brakfontein farm where afourer mandarins are grown taylor et al 2014 vahrmeijer et al 2018 the ec systems were installed in the centre of the fields and possessed a fetch distance of approximately 400 m and 150 m respectively both ec systems included li7500 infrared gas analysers which were equipped with csat 3 d sonic anemometers and hc2s3 rotronic humidity and temperature probes net irradiance was measured at the brakfontein farm with a kipp and zonen nr lite radiometer mounted 9 00 m above the ground and at the patrysberg farm with a kipp and zonen cnr4 radiometer mounted 8 00 m above the ground soil heat flux at both farms were measured using two hfp 01 soil heat flux plates buried at 0 08 m below the soil surface cs616 water content reflectometers positioned in the upper 0 06 m of the soil to measure volumetric water content and tcav l soil temperature averaging probes buried 0 02 m and 0 06 m below the soil surface which were used to correct the soil heat flux measurements further details regarding the instrumentation setup can be found in gush 2015 and gush 2016 data collection for afourer mandarins occurred in three separate intervals during 2016 8 17 march 27 may 8 june and 6 21 july to capture the seasonal variation in eta data collection for navel oranges was captured only between 3 and 17 march 2015 a south african weather services saws weather station which is situated approximately 25 km away from the edge of the catchment was selected as a source for meteorological data input as required by the model the selection of the station was based on closest proximity to the catchment as well as similar altitude of the station to the validation sites solar radiation rs was absent from the saws database and was therefore derived from an empirical equation by samani 2000 2 3 eta modelling 2 3 1 acru configuration the acru agrohydrological model is a physical conceptual model which operates on a daily time step the origins of the model can be traced back to the early 1970s from a study based on distributed catchment eta schulze 1995a the model has been extensively applied in south africa and generally provides a good representation of south african hydrological conditions smithers et al 1997 jewitt and schulze 1999 schulze 2000 warburton et al 2010 chetty and smithers 2011 there are two evapotranspiration routines evtr which can be used to calculate eta within acru this study made use of evtr1 the routine which allows for the calculation of soil water evaporation and transpiration as a single entity evtr1 is ideally suited for scenarios where there is a lack of detailed information regarding the study site and was therefore ideal for use in this study smithers et al 1995 further information regarding the evapotranspiration routines in acru can be found in schulze 1995b a total of four simulations were performed using acru with different et0 methods being used during each simulation fig 4 the methods chosen included the fao 56 pm method and the hargreaves and samani hs method hargreaves and samani 1985 though the use of the fao 56 pm method for et0 estimation has been criticized for being data intensive it is the worldwide standard for et0 estimation allen et al 1998 furthermore the availability of an eo based fao 56 product sinclair and pegram 2010 warranted the use of this approach in this study hourly estimates from this product are freely available from the sahg website ftp sahg ukzn ac za at a spatial resolution of 12 km and has been validated by mengistu et al 2014 these hourly estimates were summed up to acquire daily eta estimates for input into the acru model physically based models such as the fao 56 pm aim to represent all the fundamental principles behind the estimation of et0 the model therefore requires at the least daily estimates of solar radiation rs minimum temperature tmin maximum temperature tmax average wind speed and relative humidity allen et al 1998 the hargreaves and samani hs model is an empirically based model which is much less data intensive requiring estimates of tmin and tmax hargreaves and samani 1985 this model was selected for application as it has been proven to be a feasible alternative to the fao 56 pm model across a range of different climatic regimes gavil√°n et al 2006 kannan et al 2007 kisi 2008 sabziparvar and tabari 2010 tabari 2010 maeda et al 2011 tomas burguera et al 2017 estimates of fao 56 pm et0 and hs et0 were calculated using the saws data and these estimates were used for the meteorologically based et0 comparisons temperature data was acquired from the mod11a1 daily product from which minimum and maximum temperatures were derived and used for the estimation of eto the mod11a1 product is available at a 1 km spatial resolution wan 2013 processing of this data was undertaken using python in the eclipse environment and involved the conversion from hdf to geotiff format and the extraction of subdatasets to acquire temperatures missing temperature data was prevalent in both the meteorological and satellite derived records consequently a linear regression equation was used as an infilling method as suggested in maeda et al 2011 and campozano et al 2014 shen and leptoukh 2011 applied the method using modis lst and ta data the x and y variables in the equation were edited according to the variables present in the study 1 ta a b l s t where ta is the air temperature from meteorological data which represents the x intercept lst is the modis lst which represents the y intercept and a and b are parameters determined from the regression equation formulated between x and y when infilling lst then ta was used as the y intercept to derive parameters a and b shen and leptoukh 2011 many previous studies stated that rigorous local calibration of the hs method is required due to the empirical nature of this equation kisi 2008 maeda et al 2011 heydari and heydari 2014 this is particularly important when applying the equation to arid and semi arid environments due to the increased influence of advection heydari and heydari 2014 however calibration could not be conducted in this study as the hs derived et0 estimates were calculated within the acru model and not used as direct input it should be noted that there is a difference in the physical definitions of ta and lst however many studies have attempted to make use of lst as a surrogate due to the close linear relationship between these two variables vancutsem et al 2010 maeda et al 2011 shen and leptoukh 2011 zhu et al 2013 tao et al 2014 yang et al 2017 in addition to this mutiibwa et al 2015 stated that differences in ta and lst are amplified in complex terrain i e mountainous regions whereas the present study took place over relatively flat terrain mean annual precipitation map for the study site was extracted from the grid developed by lynch 2004 altitude data was obtained from the 90 m shuttle radar topography mission srtm digital elevation model dem weepener et al 2011 the different landuse and landcover classes lulc present in the quinary were derived from the national land cover nlc of 2013 dea and gti 2015 a major limitation in south africa is the lack of spatially explicit detailed soils information therefore values were extracted from the landtype map developed by the agricultural research council institute for soil climate and water arc iscw 2007 the satellite derived input based on the modified version of the fao 56 pm method sahg ukzn et0 product was also used as input into the acru model the landtype per catchment was selected based on the most frequently occurring landtype throughout each hydrological response unit hru the main hru in the catchment is the cultivated orchards over which the validation data lies crop coefficient values for navel oranges were derived from a study by taylor et al 2015 however the kc values for afourer mandarins could not be identified the kc values for these afourer mandarins were therefore acquired from a decision support database compoveg which is available within the acru model this was also done to try and replicate the sebs setup as much as possible as sebs does not require a priori knowledge to model eta the modelling of acru eta with the least possible information then allowed for a fair comparison between sebs eta and acru eta the acru model uses kc values to calculate eta monthly kc values were used as input into the model which were then converted within the model to daily kc values by means of a fourier analysis schulze and kunz 1995 the flow network of the model is shown below in fig 2 the hrus which were set up in the model are broad representatives of the smaller lulcs present in the catchment details regarding transfer water schemes were unknown and water flowing into the catchment from upstream was not being accounted for in the model as only a single quinary catchment was modelled this means that the amount of water received by the catchment was restricted to rainfall values only according to dwaf 2005 the agricultural sector in the olifants doorn catchment contributes more to the local economy than any other sector and this highlights the importance of agricultural activity in this sector the importance of this sector means that the farmers in the area are less likely to allow the crops to undergo stress and will therefore ensure sufficient irrigation in periods of low rainfall and this implies well managed irrigated areas the option to irrigate from an unlimited water supply was therefore chosen based on the assumption that the irrigated orchards receive a sufficient supply of irrigation drip irrigation systems are used within the study site gush 2015 gush 2016 due to uncertainties regarding irrigation scheduling it was assumed that irrigation would commence once the soil moisture status was at the drained upper limit dul the plant available water paw was set to 50 0 5 as recommended by the fao guidelines allen et al 1998 the critical leaf potential and maximum rooting depth rdmax were obtained from lecler and schulze 1995 the model was run for the years 2015 and 2016 however it should be noted that infilled values used in the estimation of et a were omitted from the et a analysis due to the introduction of uncertainty 2 3 2 sebs sebs su 2002 is a single source model which was originally developed for application on agricultural fields the conceptualization of sebs is based on eq 2 where eta can be estimated based upon the parameterization of the simplified surface energy balance equation su 2002 2 r n g l e h where rn is the net radiation w m2 g is the soil heat flux w m2 h is the sensible heat flux w m2 and le is the latent energy w m2 the sebs model is available as an open source model within the integrated land and water information system ilwis and has been extensively applied both locally and internationally for the estimation of terrestrial fluxes su 2002 elhag et al 2011 gibson et al 2013 ma et al 2013 a detailed description and conceptualization of sebs is provided in su 2002 in this study sebs was applied using inputs of land surface variables derived from landsat and modis imagery landsat imagery is available at a 30 m spatial resolution and a temporal resolution of 16 days usgs 2016 the modis product is a daily product available at a spatial resolution of 1 km justice et al 2002 the rationale for using two separate sources of multispectral imagery to derive the requisite inputs used by sebs was to compare the effect of the spatial resolution on the accuracy of the eta estimations modis and landsat imagery that were acquired were run on the days of available eta field data meteorological data required to run the model was obtained from the saws station fig 3 shows the estimation of eta in the sebs model modis and landsat images were downloaded for periods which coincided with the 62 day validation period https earthdata nasa gov fifty six clear sky mod21 land emissivity and mod03 geolocation level 1b geotiff products were downloaded during the 62 day validation period the modis images were processed according to the procedures outlined in su and wang 2013 prior to their use in sebs due to low temporal resolution of landsat only five clear sky landsat 8 images which coincided with the available eta field data were obtained the equations used to process landsat imagery are detailed in usgs 2016 once sebs and acru had been successfully implemented the estimated eta acquired from these models was then compared against ecet fig 4 table 1 provides a description of each of the eta simulations performed during this study 3 results 3 1 validation of et0 the et0 determined from the use of in situ measurements in the fao 56 pm equation was used as a reference point for comparison in the et0 analysis several other comparative studies have used the fao 56 pm as a means of validation allen et al 1998 sabziparvar and tabari 2010 maeda et al 2011 valipour 2017 although the study made use of daily temperature estimates the et0 was validated on a monthly scale where all infilled estimates were omitted from analysis this is due to 334 days of missing data over the 2 year period monthly graphs were therefore used to avoid deducing on trends based on greater than 50 of infilled data in addition to this the monthly graphs allowed for better visualization of seasonal variation throughout the year the et0 derived from sim4 was directly affected by the accuracy of the modis lst product as the hs equation is primarily a temperature based equation fig 5 shows that the satellite derived et0 calculated from the hs equation follows sim1 very closely in the winter months and deviates in the summer months the sim2 presents the least accurate estimates when compared to sim1 estimates across all months apart from summer months where sim4 estimates seem to be the highest and show an over simulation of approximately 50 the sim3 et0 deviates from the sim1 estimates more than the sim4 et0 particularly in the winter months 3 2 acru eta kalma et al 2008 assessed 30 different published validations and found that eta from seb methods fell within accuracies between 15 and 30 the sebs eta in this section was therefore assessed using a 30 threshold the eta output from the acru model was assessed using the same threshold to allow for a fair comparison between acru eta and sebs eta therefore each point of the observed dataset was increased and decreased by 30 and these values were used as the upper and lower thresholds respectively a two sampled t test for a two tailed distribution with unequal variance and a two way annova without replication was applied the null and alternate hypothesis are as follows h0 simulated acru eta observed ecet ha simulated acru eta observed ecet the simulated eta in 2015 was compared against ecet for navel oranges and the simulated eta in 2016 was compared against ecet for afourer mandarins overall results showed that the eta produced from all runs were being oversimulated with sim1 oversimulating to the lowest degree the eta results could not be related back to et0 results as they were obtained at different scales the et0 was obtained at a catchment scale and the eta was obtained at an hru scale in addition to this the climatic conditions where the ec systems are installed are different to those of the saws meteorological station as these two stations are approximately 30 km apart for example on the 4th of march 2015 the tmean is 20 2 c at the saws weather station and 26 2 c at the ec validation site this means that the et0 calculated from the meteorological station could have potentially been different in comparison to the et0 at the validation site the observed data for each simulation was different due to varying availability of input data required for each method the ecet for both the patrysberg and brakfontein farms were combined to create one observed record that was used for validation as the time periods for the ec data available on these farms did not overlap the r2 and pearson s r coefficients although low for both sim1 and sim3 when compared against ecet performed similarly with a difference of less than 10 between the values of both statistical indicators however other statistical indicators showed that the sim3 was in poorer agreement with the in situ data than the sim1 with an over simulation of 107 4 whereas sim1 was oversimulating by just 14 6 table 2 sim3 showed mean annual errors of 2 2 mm day 1 whereas sim1 showed mean annual errors of 1 1 mm day 1 the results for the annova and the t test showed that there were significant differences between the variance and means of the observed and simulated eta for all runs except the sim1 where the t test showed no significant difference between the means sim4 yielded a rmse of 1 8 mm day 1 and was oversimulating by 79 1 when compared against ecet however in fig 6 32 4 of the simulated data fell within a 30 accuracy range this was very close to sim1 where 32 7 of the simulated data fell within the 30 accuracy range this value is also much higher than sim3 which showed that only 9 1 fell within the 30 accuracy range the results displayed in the previous section showed high errors when compared to ecet the sensitivity analysis was conducted to determine the effect that the kc values had on eta and results showed that when using locally derived kc values there is a substantial decrease in errors for mae and rmse fig 7 3 3 sebs eta the sebs simulations were carried out using both modis and landsat images as input into the model the null and alternate hypothesis for the sebs simulations is stated as follows h0 simulated eta observed ecet ha simulated eta observed ecet overall the eta estimates calculated using landsat were in closer agreement to ecet than the eta estimates calculated using modis in fig 8 37 5 of the simulated modis fell within a 30 accuracy range whereas the percentage was much higher for landsat 60 the rve of 51 5 for modis simulations was relatively high when compared to a low rve of 11 1 for landsat simulations the r2 was also very low for landsat 0 01 whereas modis displayed a much higher r2 of 0 52 table 3 however the low r2 value for landsat is possibly due to the availability of just 4 data points which can be seen in fig 8 4 discussion the comparison between meteorologically based runs and satellite based runs simulated in the acru model were noteworthy as the results of these simulations were in contrast to those that had been attained and described in previous studies for example studies by kisi 2008 sabziparvar and tabari 2010 tabari 2010 and tomas burguera et al 2017 showed that the hs equation was a suitable alternative for the estimation of et0 in data limited circumstances subsequently it was assumed that the eta derived from sim3 would return satisfactory results however this was not the case as the estimated eta generated during this simulation showed the poorest performance when compared to in situ observations the simulated eta derived from the satellite based hs equation was oversimulated to a lesser degree than all other simulations apart from sim1 a closer look at the modis lst data used to calculate the eta in sim4 provides a plausible explanation as to why sim4 produced the illusion of accuracy the values of night time lst were overestimated whilst the values of daytime lst were underestimated this then resulted in a smaller temperature range than that of the meteorological data causing the sim4 values to be lower and thus closer to sim1 it is therefore the inaccuracies of the modis lst product that allowed sim4 estimates to be better correlated than other methods as mentioned previously calibration of hs estimates could not be carried out due to the temperatures being used as direct input into the acru model the absence of calibration could have affected the accuracy of both sim3 and sim4 in addition to this the results for the hs runs were over an inland region and were concurrent with the study by vanderlinden et al 2004 which found that hs estimates are overestimated in inland regions during the summer months overall the results obtained from hs runs in this study highlight the limitations associated with using empirically based models the sim2 estimates were possibly oversimulated due to the very coarse spatial resolution of the satellite product however it should be noted that even in the case of sim1 the percentage of data which fell within the acceptable accuracies was unexpectedly low fig 6 it is also important to note that the meteorological data did not lie within the catchment of interest but 5 km away from the edge of the catchment the station was however selected due to similar altitude and closest proximity to the catchment the availability of meteorological data was a major limitation throughout the project and the selection of the station may have had an adverse impact on the validation results the use of more than one station which fell within the catchment would have been more ideal the saws meteorological station also did not contain estimates of rs and was therefore calculated using an empirical equation the use of empirically derived rs increased uncertainty in the study there were certain assumptions made in the setup of the acru model which may also have led to these discrepancies the option to irrigate from an unlimited supply in the model was based on the assumption that the importance of agriculture in this sector implies well irrigated areas however eta rates as high as those obtained in this study is a highly unlikely situation in reality since atmospheric demand was high and soil and plant water availability was not limited transpiration and soil water evaporation were occurring at maximum rates within the model potentially causing all eta values to be oversimulated the kc sensitivity analysis also proved that kc values that were built into the acru model were possibly unrepresentative of the study area and had a negative effect on eta results fig 7 most hydrological models make use of the kc factor to estimate eta though the current study took place in an agricultural setting for which the kc approach is primarily driven et0 values were still misrepresented when using kc factors built into the model the sebs model bypasses the need for the kc factor as eta is estimated as a residual of the energy balance a comparison between the results from the acru and sebs models showed that the sebs model outperformed all acru simulations in graphical as well as statistical analyses when using landsat data to calculate eta although the acru results were due to various reasons relating to user input and uncertainty it also highlights the possibility of inadequate representation of eta within the acru model despite the use of trusted conventional data a comparison between the results for sim5 and sim6 eta were consistent with the results from other studies mccabe and wood 2006 shoko et al 2015 sharma et al 2016 which showed that the input data used in sebs derived from landsat imagery was able to capture the heterogeneity of eta and energy fluxes within the catchment whereas the data derived from modis imagery failed to do so due to coarse spatial resolution even though landsat was able to simulate eta within acceptable accuracies considering this type of data as input into a hydrological model gives rise to the well known trade off between spatial and temporal resolution where continuous estimates of fine resolution data are required but not available there have been ample studies to address this trade off through downscaling techniques hong et al 2011 however when validating eo data there is also an inevitable scale mismatch that arises when the area of the field data is smaller than a single pixel from a satellite as in the case of this study the scale mismatch leads to the introduction of uncertainty in the entire validation process future studies should make use of the upscaling methods that exist to solve the spatial scale mismatch upscaling is defined as the spatial or temporal conversion of fine resolution data to coarse resolution data this means that the application of this method allows for validation data to be converted to the same scale as that of satellite pixels liu et al 2016 li et al 2021 however in addition to the issues of coarse resolution data and scale mismatch we cannot ignore the susceptibility of ec instruments to errors in measurements through factors such as malfunctioning instrumentation violation of theoretical assumptions and human errors during sensor configuration despite the limitations of this study a clear judgement can be drawn on the comparison between the results of the acru model and the sebs model the sebs model was able to produce reliable estimates of eta using landsat data without the use of apriori knowledge the acru model results were dependent on many factors relating to the accuracy of the input data and the user s knowledge of the study site when configuring the model despite the use of in situ measurements as input to the model during some of the simulations the model still produced unsatisfactory estimates of eta when compared against observations subsequently this lends further strength to the argument that alternate options should be considered and made available within hydrological models to allow users the option of including reliable eta estimates as an input rather than solely relying on the model to simulate this variable the ability to better represent and account for eta during the modelling process can potentially lead to an improved representation of other hydrological processes within the model and subsequently contribute to more reliable and realistic simulations 5 conclusions this study focused on the incorporation of satellite derived et0 in the acru model over the olifants doorn catchment in the western cape province of south africa in parallel the sebs model which is able to utilize eo data as an input was used to estimate eta with modis and landsat imagery all eta estimates were validated against eta field data derived from an ec system the comparative analyses show that between the sebs model and the acru model the sebs model was able to return the most credible results with the use of fine resolution imagery the use of satellite products as input into the acru model proved unsatisfactory however the use of the meteorologically based hs method also returned inaccurate results this result is in direct disagreement with previous studies that have stated that hs can be used as an alternative to the fao 56 pm method when faced with a lack of data many limitations associated with the use of the et0 method were identified in this study and the development of hydrological models is thus recommended credit authorship contribution statement t peerbhai methodology validation investigation writing review editing funding acquisition formal analysis writing original draft visualization data curation k t chetty supervision writing review editing d j clark software writing review editing s gokool supervision conceptualization project administration writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors of this paper would like to acknowledge the national research foundation for funding this research the research has been funded under grant number sfh160614171200 all opinions and findings expressed in this paper are that of the authors and do not necessarily reflect the opinions of the national research foundation appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128347 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
2904,hydrological models are often applied to acquire estimates of evapotranspiration eta using quality inputs of reference evapotranspiration et0 however their application may be limited by the need for good quality long term data inputs in data scarce regions the use of satellite earth observation data as inputs to these models may provide a potential solution to overcome data acquisition challenges associated with conventional data collection approaches in this study the agricultural catchments research unit acru hydrological model was applied to estimate the eta using both in situ and satellite derived estimates of et0 as inputs to the model the simulated eta estimates were then evaluated through comparisons against field based measurements of eta acquired from an eddy covariance system ecet as well as from the application of the surface energy balance system sebs model the results of these investigations demonstrated that the meteorologically based acru eta simulations marginally outperformed the satellite based acru eta simulations while these results highlight the influence which the quality of et0 inputs may have on the accuracy of the acru derived eta estimates the concurrent application and evaluation of sebs demonstrated that alternate approaches to hydrological modelling may be better suited for eta estimation in certain instances keywords evapotranspiration earth observation sebs hydrological modelling data availability the authors do not have permission to share data 1 introduction globally the effects of anthropogenic induced climate and land use change coupled with the rapid expansion of the human population have resulted in further pressures being placed upon water security molle et al 2010 pittock and lankford 2010 timmermans et al 2013 this situation takes on added significance in semi arid and arid environments such as south africa where securing sufficient water supply to all water users remains a challenge rodda et al 2016 enqvist and ziervogel 2019 consequently improving upon existing hydrological process understanding and accurately quantifying spatio temporal dynamics of these processes is paramount to ensure the judicious use and management of water resources jovanovic et al 2015 hydrological models are often implemented as tools to guide water resources management decisions as they are able to provide relatively simplistic representations of complex systems consequently allowing for a logical and quantitative understanding of hydrological process dynamics to be attained davie 2008 although the implementation of these tools can prove to be expedient to facilitate improved water resources management good quality and long term in situ data to drive these models is often unavailable meijerink et al 2007 lekula and lubczynski 2019 consequently this may limit the efficacy of effectively utilizing these tools to guide water resources management decisions as these in situ observations are required to understand and assess intrinsic model limitations related to process representation at various spatio temporal scales as well as to limit the uncertainty associated with simulated output gokool et al 2019 jiang and wang 2019 globally and particularly from a south african perspective this is a significant issue due to the rapid decline in long term monitoring networks pitman 2011 dwa 2013 pegram et al 2016 toucher et al 2016 lekula and lubczynski 2019 continuous advancements in earth observation eo technologies over the last few decades have provided a potential solution to address data scarcity as eo is able to overcome many of the limitations associated with traditional field based data collection approaches consequently in recent times the use of eo derived data inputs has begun to feature more prominently in hydrological modelling applications van dijk and renzullo 2011 fern andez prieto et al 2012 coelho et al 2017 jiang and wang 2019 earth observation data can be used in hydrological models at three different levels i direct use of eo data as inputs to hydrological simulation models ii using eo data for the calibration of parameters within the model and iii assimilation of eo data into hydrological models in order to improve model simulations xu et al 2014 there have been ample studies focusing on the use of calibration and data assimilation procedures in the estimation of satellite eta kamble and irmak 2008 vazifedoust et al 2009 zhang et al 2009 hartanto et al 2017 jiang et al 2020 bennour et al 2022 however there is a general lack of studies focusing on using eta as a direct input into models this is because most hydrological models were developed to allow for the input of et0 data which is then used to calculate eta therefore most studies focus on the modification of the model code in order to accommodate eta as direct input into the model for example chen et al 2005 calculated eta using landsat data with the objective of capturing the spatial and temporal variability of eta over a small watershed in saskatchewan canada the wigmosta model code was then modified to allow for the ingestion of the satellite derived eta stisen et al 2008 and liu et al 2012 performed similar studies incorporating eo data directly into the mike she model stisen et al 2008 used eo data from the advanced very high resolution radiometer avhrr satellite liu et al 2012 developed a separate routine in the mike she model to allow for the direct input of eta estimates calculated from modis data both studies found that eo data can be confidently used to replace field based data when faced with a lack of sufficient data records whilst these studies have proven the successful incorporation of eta into models operational water resource managers continue to be more inclined towards the use of conventional data as direct input into hydrological models van dijk and renzullo 2011 mengistu et al 2014 a review of previous studies using level 1 shows that there are two ways to incorporate satellite eta into models through the input of satellite based et0 in the model or the input of satellite based eta in the model the main purpose of this study is to establish the best way of doing this should we take advantage of the way hydrological models are presently conceptualized and estimate eta through inputs of satellite based et0 or should consideration be given to developing the model further to accommodate eta as an input we attempt to shed some light on these questions through i the determination of eta with the agricultural catchments research unit acru hydrological model using conventional and satellite derived et0 data sets ii the concurrent estimation of eta using the surface energy balance system sebs model both modis and landsat data will be used to assess the impact of spatial resolution on eta and iii the comparison of different methods and data sources on the resultant eta we present our case in the context of a sub catchment situated in the western cape province of south africa the study site was chosen based on sufficient data availability and extensive knowledge about the area which are important factors to consider when modelling a system the intended purpose of the study was not to extend knowledge of the site itself but to apply the model in which our hypothesis could be tested the representation of the study site within the model was sufficient for the intercomparisons that we tried to achieve in this study 2 materials and methods 2 1 site description the study was conducted in the olifants doorn catchment situated in the western cape province of south africa fig 1 the main river in the catchment is the olifants river of which the sout river and the doring river are its main tributaries dwaf 2005 the local conditions are characterized by a mediterranean climate with a mean annual precipitation map of 200 mm year 1 which is exceeded by the potential evapotranspiration ep of 1800 mm year 1 making the catchment prone to extreme water scarcity dwaf 2005 the study site lies in the southern hemisphere and therefore experiences an austral winter and austral summer temperatures in winter are as low as 3 c and reach a high of up to 44 c in summer dwaf 2005 the altitude for the catchment varies from 114 m in the lower lying areas to 1186 m in the mountainous regions weepener et al 2011 the western part of the olifants doorn catchment is dominated by metamorphic rocks and the eastern part by shale department of water affairs dwa 2012 the focus of this study is within a quinary catchment e10f3 which possesses an area of 197 87 km2 fig 1 quinaries are a further subdivision of quaternaries into smaller more homogeneous catchments for the purpose of modelling schulze et al 2010 2 2 instrumentation data collection and data processing 2 2 1 in situ data two eddy covariance ec systems were installed by the council for scientific and industrial research csir within the study area approximately 5 km apart from each other fig 1 shows the ec system situated at the patrysberg farm where navel oranges are grown and the second ec system which is situated on the brakfontein farm where afourer mandarins are grown taylor et al 2014 vahrmeijer et al 2018 the ec systems were installed in the centre of the fields and possessed a fetch distance of approximately 400 m and 150 m respectively both ec systems included li7500 infrared gas analysers which were equipped with csat 3 d sonic anemometers and hc2s3 rotronic humidity and temperature probes net irradiance was measured at the brakfontein farm with a kipp and zonen nr lite radiometer mounted 9 00 m above the ground and at the patrysberg farm with a kipp and zonen cnr4 radiometer mounted 8 00 m above the ground soil heat flux at both farms were measured using two hfp 01 soil heat flux plates buried at 0 08 m below the soil surface cs616 water content reflectometers positioned in the upper 0 06 m of the soil to measure volumetric water content and tcav l soil temperature averaging probes buried 0 02 m and 0 06 m below the soil surface which were used to correct the soil heat flux measurements further details regarding the instrumentation setup can be found in gush 2015 and gush 2016 data collection for afourer mandarins occurred in three separate intervals during 2016 8 17 march 27 may 8 june and 6 21 july to capture the seasonal variation in eta data collection for navel oranges was captured only between 3 and 17 march 2015 a south african weather services saws weather station which is situated approximately 25 km away from the edge of the catchment was selected as a source for meteorological data input as required by the model the selection of the station was based on closest proximity to the catchment as well as similar altitude of the station to the validation sites solar radiation rs was absent from the saws database and was therefore derived from an empirical equation by samani 2000 2 3 eta modelling 2 3 1 acru configuration the acru agrohydrological model is a physical conceptual model which operates on a daily time step the origins of the model can be traced back to the early 1970s from a study based on distributed catchment eta schulze 1995a the model has been extensively applied in south africa and generally provides a good representation of south african hydrological conditions smithers et al 1997 jewitt and schulze 1999 schulze 2000 warburton et al 2010 chetty and smithers 2011 there are two evapotranspiration routines evtr which can be used to calculate eta within acru this study made use of evtr1 the routine which allows for the calculation of soil water evaporation and transpiration as a single entity evtr1 is ideally suited for scenarios where there is a lack of detailed information regarding the study site and was therefore ideal for use in this study smithers et al 1995 further information regarding the evapotranspiration routines in acru can be found in schulze 1995b a total of four simulations were performed using acru with different et0 methods being used during each simulation fig 4 the methods chosen included the fao 56 pm method and the hargreaves and samani hs method hargreaves and samani 1985 though the use of the fao 56 pm method for et0 estimation has been criticized for being data intensive it is the worldwide standard for et0 estimation allen et al 1998 furthermore the availability of an eo based fao 56 product sinclair and pegram 2010 warranted the use of this approach in this study hourly estimates from this product are freely available from the sahg website ftp sahg ukzn ac za at a spatial resolution of 12 km and has been validated by mengistu et al 2014 these hourly estimates were summed up to acquire daily eta estimates for input into the acru model physically based models such as the fao 56 pm aim to represent all the fundamental principles behind the estimation of et0 the model therefore requires at the least daily estimates of solar radiation rs minimum temperature tmin maximum temperature tmax average wind speed and relative humidity allen et al 1998 the hargreaves and samani hs model is an empirically based model which is much less data intensive requiring estimates of tmin and tmax hargreaves and samani 1985 this model was selected for application as it has been proven to be a feasible alternative to the fao 56 pm model across a range of different climatic regimes gavil√°n et al 2006 kannan et al 2007 kisi 2008 sabziparvar and tabari 2010 tabari 2010 maeda et al 2011 tomas burguera et al 2017 estimates of fao 56 pm et0 and hs et0 were calculated using the saws data and these estimates were used for the meteorologically based et0 comparisons temperature data was acquired from the mod11a1 daily product from which minimum and maximum temperatures were derived and used for the estimation of eto the mod11a1 product is available at a 1 km spatial resolution wan 2013 processing of this data was undertaken using python in the eclipse environment and involved the conversion from hdf to geotiff format and the extraction of subdatasets to acquire temperatures missing temperature data was prevalent in both the meteorological and satellite derived records consequently a linear regression equation was used as an infilling method as suggested in maeda et al 2011 and campozano et al 2014 shen and leptoukh 2011 applied the method using modis lst and ta data the x and y variables in the equation were edited according to the variables present in the study 1 ta a b l s t where ta is the air temperature from meteorological data which represents the x intercept lst is the modis lst which represents the y intercept and a and b are parameters determined from the regression equation formulated between x and y when infilling lst then ta was used as the y intercept to derive parameters a and b shen and leptoukh 2011 many previous studies stated that rigorous local calibration of the hs method is required due to the empirical nature of this equation kisi 2008 maeda et al 2011 heydari and heydari 2014 this is particularly important when applying the equation to arid and semi arid environments due to the increased influence of advection heydari and heydari 2014 however calibration could not be conducted in this study as the hs derived et0 estimates were calculated within the acru model and not used as direct input it should be noted that there is a difference in the physical definitions of ta and lst however many studies have attempted to make use of lst as a surrogate due to the close linear relationship between these two variables vancutsem et al 2010 maeda et al 2011 shen and leptoukh 2011 zhu et al 2013 tao et al 2014 yang et al 2017 in addition to this mutiibwa et al 2015 stated that differences in ta and lst are amplified in complex terrain i e mountainous regions whereas the present study took place over relatively flat terrain mean annual precipitation map for the study site was extracted from the grid developed by lynch 2004 altitude data was obtained from the 90 m shuttle radar topography mission srtm digital elevation model dem weepener et al 2011 the different landuse and landcover classes lulc present in the quinary were derived from the national land cover nlc of 2013 dea and gti 2015 a major limitation in south africa is the lack of spatially explicit detailed soils information therefore values were extracted from the landtype map developed by the agricultural research council institute for soil climate and water arc iscw 2007 the satellite derived input based on the modified version of the fao 56 pm method sahg ukzn et0 product was also used as input into the acru model the landtype per catchment was selected based on the most frequently occurring landtype throughout each hydrological response unit hru the main hru in the catchment is the cultivated orchards over which the validation data lies crop coefficient values for navel oranges were derived from a study by taylor et al 2015 however the kc values for afourer mandarins could not be identified the kc values for these afourer mandarins were therefore acquired from a decision support database compoveg which is available within the acru model this was also done to try and replicate the sebs setup as much as possible as sebs does not require a priori knowledge to model eta the modelling of acru eta with the least possible information then allowed for a fair comparison between sebs eta and acru eta the acru model uses kc values to calculate eta monthly kc values were used as input into the model which were then converted within the model to daily kc values by means of a fourier analysis schulze and kunz 1995 the flow network of the model is shown below in fig 2 the hrus which were set up in the model are broad representatives of the smaller lulcs present in the catchment details regarding transfer water schemes were unknown and water flowing into the catchment from upstream was not being accounted for in the model as only a single quinary catchment was modelled this means that the amount of water received by the catchment was restricted to rainfall values only according to dwaf 2005 the agricultural sector in the olifants doorn catchment contributes more to the local economy than any other sector and this highlights the importance of agricultural activity in this sector the importance of this sector means that the farmers in the area are less likely to allow the crops to undergo stress and will therefore ensure sufficient irrigation in periods of low rainfall and this implies well managed irrigated areas the option to irrigate from an unlimited water supply was therefore chosen based on the assumption that the irrigated orchards receive a sufficient supply of irrigation drip irrigation systems are used within the study site gush 2015 gush 2016 due to uncertainties regarding irrigation scheduling it was assumed that irrigation would commence once the soil moisture status was at the drained upper limit dul the plant available water paw was set to 50 0 5 as recommended by the fao guidelines allen et al 1998 the critical leaf potential and maximum rooting depth rdmax were obtained from lecler and schulze 1995 the model was run for the years 2015 and 2016 however it should be noted that infilled values used in the estimation of et a were omitted from the et a analysis due to the introduction of uncertainty 2 3 2 sebs sebs su 2002 is a single source model which was originally developed for application on agricultural fields the conceptualization of sebs is based on eq 2 where eta can be estimated based upon the parameterization of the simplified surface energy balance equation su 2002 2 r n g l e h where rn is the net radiation w m2 g is the soil heat flux w m2 h is the sensible heat flux w m2 and le is the latent energy w m2 the sebs model is available as an open source model within the integrated land and water information system ilwis and has been extensively applied both locally and internationally for the estimation of terrestrial fluxes su 2002 elhag et al 2011 gibson et al 2013 ma et al 2013 a detailed description and conceptualization of sebs is provided in su 2002 in this study sebs was applied using inputs of land surface variables derived from landsat and modis imagery landsat imagery is available at a 30 m spatial resolution and a temporal resolution of 16 days usgs 2016 the modis product is a daily product available at a spatial resolution of 1 km justice et al 2002 the rationale for using two separate sources of multispectral imagery to derive the requisite inputs used by sebs was to compare the effect of the spatial resolution on the accuracy of the eta estimations modis and landsat imagery that were acquired were run on the days of available eta field data meteorological data required to run the model was obtained from the saws station fig 3 shows the estimation of eta in the sebs model modis and landsat images were downloaded for periods which coincided with the 62 day validation period https earthdata nasa gov fifty six clear sky mod21 land emissivity and mod03 geolocation level 1b geotiff products were downloaded during the 62 day validation period the modis images were processed according to the procedures outlined in su and wang 2013 prior to their use in sebs due to low temporal resolution of landsat only five clear sky landsat 8 images which coincided with the available eta field data were obtained the equations used to process landsat imagery are detailed in usgs 2016 once sebs and acru had been successfully implemented the estimated eta acquired from these models was then compared against ecet fig 4 table 1 provides a description of each of the eta simulations performed during this study 3 results 3 1 validation of et0 the et0 determined from the use of in situ measurements in the fao 56 pm equation was used as a reference point for comparison in the et0 analysis several other comparative studies have used the fao 56 pm as a means of validation allen et al 1998 sabziparvar and tabari 2010 maeda et al 2011 valipour 2017 although the study made use of daily temperature estimates the et0 was validated on a monthly scale where all infilled estimates were omitted from analysis this is due to 334 days of missing data over the 2 year period monthly graphs were therefore used to avoid deducing on trends based on greater than 50 of infilled data in addition to this the monthly graphs allowed for better visualization of seasonal variation throughout the year the et0 derived from sim4 was directly affected by the accuracy of the modis lst product as the hs equation is primarily a temperature based equation fig 5 shows that the satellite derived et0 calculated from the hs equation follows sim1 very closely in the winter months and deviates in the summer months the sim2 presents the least accurate estimates when compared to sim1 estimates across all months apart from summer months where sim4 estimates seem to be the highest and show an over simulation of approximately 50 the sim3 et0 deviates from the sim1 estimates more than the sim4 et0 particularly in the winter months 3 2 acru eta kalma et al 2008 assessed 30 different published validations and found that eta from seb methods fell within accuracies between 15 and 30 the sebs eta in this section was therefore assessed using a 30 threshold the eta output from the acru model was assessed using the same threshold to allow for a fair comparison between acru eta and sebs eta therefore each point of the observed dataset was increased and decreased by 30 and these values were used as the upper and lower thresholds respectively a two sampled t test for a two tailed distribution with unequal variance and a two way annova without replication was applied the null and alternate hypothesis are as follows h0 simulated acru eta observed ecet ha simulated acru eta observed ecet the simulated eta in 2015 was compared against ecet for navel oranges and the simulated eta in 2016 was compared against ecet for afourer mandarins overall results showed that the eta produced from all runs were being oversimulated with sim1 oversimulating to the lowest degree the eta results could not be related back to et0 results as they were obtained at different scales the et0 was obtained at a catchment scale and the eta was obtained at an hru scale in addition to this the climatic conditions where the ec systems are installed are different to those of the saws meteorological station as these two stations are approximately 30 km apart for example on the 4th of march 2015 the tmean is 20 2 c at the saws weather station and 26 2 c at the ec validation site this means that the et0 calculated from the meteorological station could have potentially been different in comparison to the et0 at the validation site the observed data for each simulation was different due to varying availability of input data required for each method the ecet for both the patrysberg and brakfontein farms were combined to create one observed record that was used for validation as the time periods for the ec data available on these farms did not overlap the r2 and pearson s r coefficients although low for both sim1 and sim3 when compared against ecet performed similarly with a difference of less than 10 between the values of both statistical indicators however other statistical indicators showed that the sim3 was in poorer agreement with the in situ data than the sim1 with an over simulation of 107 4 whereas sim1 was oversimulating by just 14 6 table 2 sim3 showed mean annual errors of 2 2 mm day 1 whereas sim1 showed mean annual errors of 1 1 mm day 1 the results for the annova and the t test showed that there were significant differences between the variance and means of the observed and simulated eta for all runs except the sim1 where the t test showed no significant difference between the means sim4 yielded a rmse of 1 8 mm day 1 and was oversimulating by 79 1 when compared against ecet however in fig 6 32 4 of the simulated data fell within a 30 accuracy range this was very close to sim1 where 32 7 of the simulated data fell within the 30 accuracy range this value is also much higher than sim3 which showed that only 9 1 fell within the 30 accuracy range the results displayed in the previous section showed high errors when compared to ecet the sensitivity analysis was conducted to determine the effect that the kc values had on eta and results showed that when using locally derived kc values there is a substantial decrease in errors for mae and rmse fig 7 3 3 sebs eta the sebs simulations were carried out using both modis and landsat images as input into the model the null and alternate hypothesis for the sebs simulations is stated as follows h0 simulated eta observed ecet ha simulated eta observed ecet overall the eta estimates calculated using landsat were in closer agreement to ecet than the eta estimates calculated using modis in fig 8 37 5 of the simulated modis fell within a 30 accuracy range whereas the percentage was much higher for landsat 60 the rve of 51 5 for modis simulations was relatively high when compared to a low rve of 11 1 for landsat simulations the r2 was also very low for landsat 0 01 whereas modis displayed a much higher r2 of 0 52 table 3 however the low r2 value for landsat is possibly due to the availability of just 4 data points which can be seen in fig 8 4 discussion the comparison between meteorologically based runs and satellite based runs simulated in the acru model were noteworthy as the results of these simulations were in contrast to those that had been attained and described in previous studies for example studies by kisi 2008 sabziparvar and tabari 2010 tabari 2010 and tomas burguera et al 2017 showed that the hs equation was a suitable alternative for the estimation of et0 in data limited circumstances subsequently it was assumed that the eta derived from sim3 would return satisfactory results however this was not the case as the estimated eta generated during this simulation showed the poorest performance when compared to in situ observations the simulated eta derived from the satellite based hs equation was oversimulated to a lesser degree than all other simulations apart from sim1 a closer look at the modis lst data used to calculate the eta in sim4 provides a plausible explanation as to why sim4 produced the illusion of accuracy the values of night time lst were overestimated whilst the values of daytime lst were underestimated this then resulted in a smaller temperature range than that of the meteorological data causing the sim4 values to be lower and thus closer to sim1 it is therefore the inaccuracies of the modis lst product that allowed sim4 estimates to be better correlated than other methods as mentioned previously calibration of hs estimates could not be carried out due to the temperatures being used as direct input into the acru model the absence of calibration could have affected the accuracy of both sim3 and sim4 in addition to this the results for the hs runs were over an inland region and were concurrent with the study by vanderlinden et al 2004 which found that hs estimates are overestimated in inland regions during the summer months overall the results obtained from hs runs in this study highlight the limitations associated with using empirically based models the sim2 estimates were possibly oversimulated due to the very coarse spatial resolution of the satellite product however it should be noted that even in the case of sim1 the percentage of data which fell within the acceptable accuracies was unexpectedly low fig 6 it is also important to note that the meteorological data did not lie within the catchment of interest but 5 km away from the edge of the catchment the station was however selected due to similar altitude and closest proximity to the catchment the availability of meteorological data was a major limitation throughout the project and the selection of the station may have had an adverse impact on the validation results the use of more than one station which fell within the catchment would have been more ideal the saws meteorological station also did not contain estimates of rs and was therefore calculated using an empirical equation the use of empirically derived rs increased uncertainty in the study there were certain assumptions made in the setup of the acru model which may also have led to these discrepancies the option to irrigate from an unlimited supply in the model was based on the assumption that the importance of agriculture in this sector implies well irrigated areas however eta rates as high as those obtained in this study is a highly unlikely situation in reality since atmospheric demand was high and soil and plant water availability was not limited transpiration and soil water evaporation were occurring at maximum rates within the model potentially causing all eta values to be oversimulated the kc sensitivity analysis also proved that kc values that were built into the acru model were possibly unrepresentative of the study area and had a negative effect on eta results fig 7 most hydrological models make use of the kc factor to estimate eta though the current study took place in an agricultural setting for which the kc approach is primarily driven et0 values were still misrepresented when using kc factors built into the model the sebs model bypasses the need for the kc factor as eta is estimated as a residual of the energy balance a comparison between the results from the acru and sebs models showed that the sebs model outperformed all acru simulations in graphical as well as statistical analyses when using landsat data to calculate eta although the acru results were due to various reasons relating to user input and uncertainty it also highlights the possibility of inadequate representation of eta within the acru model despite the use of trusted conventional data a comparison between the results for sim5 and sim6 eta were consistent with the results from other studies mccabe and wood 2006 shoko et al 2015 sharma et al 2016 which showed that the input data used in sebs derived from landsat imagery was able to capture the heterogeneity of eta and energy fluxes within the catchment whereas the data derived from modis imagery failed to do so due to coarse spatial resolution even though landsat was able to simulate eta within acceptable accuracies considering this type of data as input into a hydrological model gives rise to the well known trade off between spatial and temporal resolution where continuous estimates of fine resolution data are required but not available there have been ample studies to address this trade off through downscaling techniques hong et al 2011 however when validating eo data there is also an inevitable scale mismatch that arises when the area of the field data is smaller than a single pixel from a satellite as in the case of this study the scale mismatch leads to the introduction of uncertainty in the entire validation process future studies should make use of the upscaling methods that exist to solve the spatial scale mismatch upscaling is defined as the spatial or temporal conversion of fine resolution data to coarse resolution data this means that the application of this method allows for validation data to be converted to the same scale as that of satellite pixels liu et al 2016 li et al 2021 however in addition to the issues of coarse resolution data and scale mismatch we cannot ignore the susceptibility of ec instruments to errors in measurements through factors such as malfunctioning instrumentation violation of theoretical assumptions and human errors during sensor configuration despite the limitations of this study a clear judgement can be drawn on the comparison between the results of the acru model and the sebs model the sebs model was able to produce reliable estimates of eta using landsat data without the use of apriori knowledge the acru model results were dependent on many factors relating to the accuracy of the input data and the user s knowledge of the study site when configuring the model despite the use of in situ measurements as input to the model during some of the simulations the model still produced unsatisfactory estimates of eta when compared against observations subsequently this lends further strength to the argument that alternate options should be considered and made available within hydrological models to allow users the option of including reliable eta estimates as an input rather than solely relying on the model to simulate this variable the ability to better represent and account for eta during the modelling process can potentially lead to an improved representation of other hydrological processes within the model and subsequently contribute to more reliable and realistic simulations 5 conclusions this study focused on the incorporation of satellite derived et0 in the acru model over the olifants doorn catchment in the western cape province of south africa in parallel the sebs model which is able to utilize eo data as an input was used to estimate eta with modis and landsat imagery all eta estimates were validated against eta field data derived from an ec system the comparative analyses show that between the sebs model and the acru model the sebs model was able to return the most credible results with the use of fine resolution imagery the use of satellite products as input into the acru model proved unsatisfactory however the use of the meteorologically based hs method also returned inaccurate results this result is in direct disagreement with previous studies that have stated that hs can be used as an alternative to the fao 56 pm method when faced with a lack of data many limitations associated with the use of the et0 method were identified in this study and the development of hydrological models is thus recommended credit authorship contribution statement t peerbhai methodology validation investigation writing review editing funding acquisition formal analysis writing original draft visualization data curation k t chetty supervision writing review editing d j clark software writing review editing s gokool supervision conceptualization project administration writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors of this paper would like to acknowledge the national research foundation for funding this research the research has been funded under grant number sfh160614171200 all opinions and findings expressed in this paper are that of the authors and do not necessarily reflect the opinions of the national research foundation appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128347 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
