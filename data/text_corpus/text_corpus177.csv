index,text
885,traditional design flood estimation approaches have focused on peak discharges and have often neglected other hydrograph characteristics such as hydrograph volume and shape synthetic design hydrograph estimation procedures overcome this deficiency by jointly considering peak discharge hydrograph volume and shape such procedures have recently been extended to allow for the consideration of process variability within a catchment by a flood type specific construction of design hydrographs however they depend on observed runoff time series and are not directly applicable in ungauged catchments where such series are not available to obtain reliable flood estimates there is a need for an approach that allows for the consideration of process variability in the construction of synthetic design hydrographs in ungauged catchments in this study we therefore propose an approach that combines a bivariate index flood approach with event type specific synthetic design hydrograph construction first regions of similar flood reactivity are delineated and a classification rule that enables the assignment of ungauged catchments to one of these reactivity regions is established second event type specific synthetic design hydrographs are constructed using the pooled data divided by event type from the corresponding reactivity region in a bivariate index flood procedure the approach was tested and validated on a dataset of 163 swiss catchments the results indicated that 1 random forest is a suitable classification model for the assignment of an ungauged catchment to one of the reactivity regions 2 the combination of a bivariate index flood approach and event type specific synthetic design hydrograph construction enables the consideration of event types in ungauged catchments and 3 the use of probabilistic class memberships in regional synthetic design hydrograph construction helps to alleviate the problem of misclassification event type specific synthetic design hydrograph sets enable the inclusion of process variability into design flood estimation and can be used as a compromise between single best estimate synthetic design hydrographs and continuous simulation studies keywords classification random forest homogeneous regions regionalization mixtures floods 1 introduction classical design flood estimation has been focusing on the univariate analysis of peak discharges even though other event characteristics such as hydrograph volume and shape are equally important for hydraulic design tasks involving storage pilgrim 1986 more recent flood estimation procedures allow the representation of both the magnitude and the shape of an event through synthetic design hydrographs sdhs synthetic design hydrographs provide a more complete picture of the flood behavior of a catchment than classical approaches sdhs include event based approaches using event rainfall as input grimaldi et al 2012 rogger et al 2012 and statistical approaches using observed runoff in bivariate flood frequency analyses brunner et al 2017b however as the classical approaches they neglect the variability of flood events within a catchment caused by different processes which are mirrored by various flood types such as flash floods short rain long rain and rain on snow floods merz and blöschl 2003 to overcome this deficiency brunner et al 2017b proposed an approach for the construction of a set of flood type specific sdhs the approach splits the flood sample into four subsets one for each flood type and uses each of these samples to construct a flood type specific design hydrograph the shape of the design hydrographs is modeled by a probability density function pdf while the magnitude of the event is modeled via a bivariate frequency analysis taking into account the dependence between peak discharges and hydrograph volumes via a copula model this ensemble based sdh construction approach takes into account process variability but is based on observed flood events and cannot be easily transferred to ungauged catchments where no runoff information is available there design floods have traditionally been estimated by a regional index flood approach focusing on peak discharges the index flood approach consists of two main steps in a first step regions with a similar flood behavior are delineated in a second step the data within these similar regions are used for regional flood frequency analysis hydrologically similar regions are often delineated based on hydrological catchment characteristics or runoff signatures burn and boorman 1992 since physiographical and climatological catchment similarity do often not correspond to hydrological similarity ali et al 2012 oudin et al 2010 brunner et al 2017a suggested to use entire hydrograph shapes in the delineation of homogeneous regions with the argument that those provide more information on the flood behavior of a catchment than statistical measures of individual hydrograph characteristics in this previous study it was shown that flood reactivity regions can be delineated by characterizing each catchment in the dataset by a set of three representative hydrograph shapes a fast an intermediate and a slow shape grouping catchments with similar sets of representative hydrograph shapes delineates regions which are similar in terms of their flood behavior such regions were shown to have a hydro meteorological meaning and are potentially useful in regional flood frequency analysis regional frequency analysis is often done using the index flood approach which was proposed by dalrymple 1960 for annual maxima series and later extended to partial duration peak over threshold series madsen et al 1997 it assumes that frequency distributions at different sites within a region are identical apart from a scale factor it describes a local quantile estimate qi f as the product of an index flood μi and a regional growth curve q f estimated based on the data at n sites as 1 q i f μ i q f i 1 n the index flood can be any location measure of the at site distribution but is often taken to be its mean the regional growth curve is a dimensionless quantile function computed based on dimensionless regional data which are obtained by dividing the observed flood event data by the index flood regional analysis using the index flood approach yields more accurate quantile estimates than at site analysis even if a region is heterogeneous it was thus found to be a robust and efficient estimation procedure lettenmaier et al 1987 madsen et al 1997 the classical index flood procedure focuses on peak discharges requena et al 2016 therefore proposed an approach for a multivariate regional index approach that allows for the consideration of more than one design hydrograph characteristic e g peak discharge and hydrograph volume while such a bivariate regional approach allows the joint consideration of peak discharges and hydrograph volumes neither hydrograph shape nor process variability can be considered to our knowledge no methodology has so far been proposed for the regional construction of event type specific sets of sdhs in ungauged catchments the aim of this study was therefore to propose an approach that allows for the construction of sdhs in ungauged catchments which on the one hand jointly represents the magnitude and shape of an event and on the other hand allows for the consideration of process variability we here propose an approach that delineates regions of a similar flood reactivity using the approach by brunner et al 2017a applies the bivariate index flood approach proposed by requena et al 2016 within these flood reactivity regions and uses the resulting design variable pairs in the sdh construction approach proposed by brunner et al 2017b instead of flood types we use the three event types fast intermediate and slow in design hydrograph construction brunner et al 2017a the three event type specific sdhs together form a set of design hydrographs which considers the process variability within an ungauged catchment our research more specifically addresses the following research questions 1 how can an ungauged catchment best be assigned to one of the flood reactivity regions 2 how can event type specific sdh sets for ungauged catchments be constructed 3 can probabilistic class memberships be used in regional sdh construction to reduce the problem of misclassification 2 data this analysis used runoff and catchment characteristics data from 163 swiss catchments fig 1 with a wide range of catchment characteristics and flood behaviors the selected catchments have hourly flow series of at least 20 years in duration ranging up to 53 years in these catchments runoff is neither altered by regulated lakes upstream or inland canals nor by urbanized areas the catchments are small to medium size 6 to 1800 km2 situated at mean elevations between 400 and 2600 m a s l and have no or only a minor glacier coverage the basis for the analysis was samples of flood events extracted from the runoff time series of the 163 study catchments to sample flood events we used a peak over threshold approach based on the procedure proposed by lang et al 1999 the threshold for the peak discharge was chosen iteratively to fulfill a target condition of four events per year on average which is a trade off between maximizing the information content in the sample and keeping the assumption of independence between events for each of these events sampled according to the flood peaks the flood volume was determined over the actual event duration the actual duration was determined as the time between the onset of the event defined as the time where discharge first exceeds 0 05 times the peak discharge and the end of the event discharge falls below 0 05 times the peak discharge the baseflow was separated from the direct flow using a recursive digital filter eckhardt 2005 the resulting direct flow component of the hydrographs was then normalized so that the volume of the modified hydrographs was equal to one this was done by dividing the ordinate of each hydrograph by the volume v in the remainder of this paper we refer to these normalized hydrographs as hydrograph shapes to make the sampled event hydrographs comparable they were brought to a length of 72 hours by appending hours with the minimum discharge until the series consisted of 72 values we refer the reader to brunner et al 2017b for a more detailed description of the flood sampling and baseflow separation procedures 3 methods in the regional approach for the construction of event type specific sets of sdhs we assigned an ungauged catchment to a flood reactivity region and subsequently used the data from this reactivity region for the estimation of a set of sdhs representing three event types comprising a fast an intermediate and a slow event the regional approach consists of three main steps 1 delineation of reactivity regions by clustering catchments using their catchment specific sets of representative hydrograph shapes 2 establishment of a classification rule allowing the attribution of an ungauged catchment to one of the reactivity regions 3 construction of a set of event type specific design hydrographs using i region specific hydrograph shape sets and ii event magnitudes estimated by event type in a bivariate index flood approach the individual steps of the methodology are illustrated in fig 2 and described in more detail in the following paragraphs 3 1 step 1 delineation of regions with similar flood reactivity brunner et al 2017a showed that the hydrograph shape variability within swiss catchments can be summarized by a set of three representative hydrograph shapes a fast an intermediate and a slow hydrograph in this previous study we represented normalized hydrograph shapes as functional data i e as continuous functions by projecting them on a set of four basis splines b spline bases a spline function is determined by the order of the polynomial segments and the number and placement of knots the number of knots determines the ability of spline functions to represent sharp features in a curve and the knots can be placed such that they are denser in areas with stronger variations than in smooth areas höllig and hörner 2013 the sets of four coefficients one per b spline base were used in a k means clustering algorithm gordon 1999 to identify clusters of similar hydrograph shapes three shape clusters were found to well explain the shape variability within swiss catchments each cluster was summarized by its median hydrograph shape the three median shapes together formed the set of representative hydrograph shapes consisting of a fast an intermediate and a slow hydrograph shape the fast event type is characterized by both steep rising and recession limbs the intermediate event type is characterized by a rather steep rising but a slow recession limb and the slow event type is characterized by both slow rising and recession limbs brunner et al 2017a brunner et al 2017a then used these catchment specific sets of representative hydrograph shapes for the identification of flood reactivity regions i e regions that were similar in terms of their representative hydrograph shape sets we modified the approach proposed by brunner et al 2017a in the following two ways 1 the clustering was done using the representative hydrograph sets of all catchments without separating a uniformly reactive catchment as done in brunner et al 2017a because this was found to be a disadvantage for the identification of a classification rule in step 2 2 we delineated four instead of three regions with a similar flood reactivity using the functional representation of catchment specific sets of hydrograph shapes as an input for the hierarchical clustering algorithm four regions were found to be better since the hierarchical clustering tree showed a clear symmetry and cutting it at three or five clusters would not have been sensible we called these regions a to d region a is characterized by a quick runoff reaction i e all three representative hydrograph shapes showed a rather quick response compared to the representative hydrograph shapes in catchments belonging to the other three regions regions b and c were characterized by an intermediate or slow reactivity respectively region d showed a rather uniform reaction to rainfall input i e the fast intermediate and slow shapes were difficult to distinguish the runoff behavior of catchments within a region was summarized by a set of median event type specific hydrograph shapes median shape sets the cluster memberships of the 163 study catchments were used in step 2 to identify a classification rule allowing for the assignment of an ungauged catchment to one of the four reactivity regions 3 2 step 2 attribution of ungauged catchment to reactivity region we established a relationship between the catchment characteristics and the region memberships of catchments to be able to attribute an ungauged catchment to one of the four reactivity regions based on catchment characteristics only an initial comparison of several classification methods showed that random forest harrell 2015 james et al 2013 was the most suitable classification model in cross validation the set of explanatory variables used to fit the models consisted of the following seven weakly correlated catchment characteristics catchment area network density y coordinate soil topographic index percentage area of karstic rocks sunshine duration and vapor pressure catchment area and network density were derived from the digital elevation model the soil topographic index from the digital map of land surface characteristics eidgenössische forschungsanstalt für wald schnee und landschaft wsl 1999 the percentage area of karstic rock from a map focusing on groudwater resources bitterli et al 2007 and sunshine duration and vapor pressure from gridded meteorological data provided by meteoswiss meteoswiss 2013 we used the random forest classification model to attribute ungauged catchments to one of the reactivity regions according to its best class membership and to compute probabilities of class memberships which we hereafter refer to as probabilistic class memberships for each of the four regions considering probabilistic class memberships allowed the alleviation of the problem of misclassification regions b and c were found to be difficult to distinguish when assigning a best class membership to a catchment assigning probabilistic class memberships and using them in sdh construction helped to take into consideration this source of uncertainty 3 3 step 3 construction of a set of event type specific sdhs an ungauged catchment was assigned to one of the reactivity regions delineated in step 1 via the random forest classification model established in step 2 the construction of an event type specific set of sdhs for this ungauged catchment was based on the pool of data of the reactivity region it was assigned to best class membership the approach was at a later stage extended to probabilistic region memberships as described under step 2 we first focus on the construction of event type specific sets of sdhs using the best class membership the event type specific construction procedure was based on the sdh construction procedure proposed by brunner et al 2017b for different flood types merz and blöschl 2003 sikorska et al 2015 instead of differentiating flood types we here distinguished between the three event types fast intermediate and slow which cover a large part of shape variability within a catchment and were used in section 3 1 for the delineation of reactivity regions a set of three sdhs was constructed by combining shape estimates represented by a probability density function with magnitude estimates represented by the bivariate design variable quantiles peak discharge and hydrograph volume the basic idea of the procedure is to do regional flood frequency analysis within the reactivity region of interest using a bivariate index flood approach requena et al 2016 for each of the three event types fast intermediate and slow separately this regional sdh construction approach consists of three steps see fig 2 i computation of design event shape ii computation of design event magnitude by estimating a a regional growth curve and b a local index flood and iii construction of design hydrograph by combining magnitude and shape these steps are described in detail in the following paragraphs 3 3 1 i computation of design event shape the design hydrograph shapes were estimated using the three representative hydrograph shapes fast intermediate and slow of the region the ungauged catchment was assigned to the three hydrograph shapes were each fitted by a lognormal probability density function pdf yue et al 2002 which was expressed in terms of their time to peak peak discharge and time base nadarajah 2007 rai et al 2009 the lognormal pdf was chosen out of a selection of eight pdfs normal lognormal fréchet weibull beta gamma inverse gamma and logistic whose fit to the representative hydrograph shapes was assessed via the kling gupta and nash sutcliffe efficiencies gupta et al 2009 3 3 2 ii computation of design event magnitude we formed pools of observed flood events for each event type within the predicted reactivity region the region was characterized by three pools of data fast events intermediate events and slow events the individual data pools consisted of all the event type specific events of the catchments within the corresponding reactivity region the data pools consisted of dimensionless peak discharges peak discharges normalized by mean catchment peak discharge i e index flood peak and dimensionless hydrograph volumes hydrograph volumes normalized by mean catchment hydrograph volume i e index hydrograph volume to make values from different catchments comparable these pooled data were used in a bivariate flood frequency analysis to derive regional growth curves for peak discharges and hydrograph volumes requena et al 2016 the bivariate frequency analysis was based on the marginal distributions of peak discharges q p and hydrograph volumes v and their dependence was modeled via a copula function a regional growth curves the four regions were characterized by differences in q p and v q p generally decreased from region a to d while v increased q p and v not only differed between regions but also between the three event types within a catchment fast and intermediate events were generally characterized by higher magnitudes in terms of q p and smaller magnitudes in terms of v than slow events we used the flexible five parameter wakeby distribution houghton 1978 griffiths 1989 to model the marginal distributions of q p and v because this distribution can mimic the shapes of many commonly used skew distributions such as the extreme value distribution the lognormal or pearson type iii distributions the wakeby distribution provided a good fit to the data which was confirmed by the kolmogorov smirnov goodness of fit test level of significance α 0 05 fitting a distribution with five parameters was not a problem in our case since the sample size was sufficiently large when working with the pooled data the wakeby distribution f x is not explicitly defined however its inverse x f can be expressed by the five parameters α β γ λ and ξ hosking 1986 as follows 2 x f ξ α β 1 1 f β γ δ 1 1 f δ when δ 0 the wakeby distribution has a heavy upper tail and can give rise to data sets containing occasional high outliers the upper tail behavior of the wakeby distribution is determined by the parameters γ and δ unless γ 0 as f 1 the density function of the wakeby distribution is asymptotically equivalent to that of a generalized pareto distribution hosking 1986 other distributions commonly used in flood frequency analysis such as the generalized extreme value distribution and the generalized pareto distribution coles 2001 did not provide a good fit to the data compared to the wakeby distribution their flexibility is limited by the lower number of parameters three the parameters of the wakeby distribution were estimated for both the q p and v in each of the data pools using l moments hosking and wallis 1997 and its parameters were found to differ between the data pools the form of the dependence between q p and v did not strongly differ for the three event types within a region nor was it different between the four reactivity regions it could therefore be modeled by the same copula family for all event types and regions the dependence between q p and v was modeled using the elliptical student t copula frahm et al 2003 which is able to model lower and upper non null tail dependence as present in the data assessed via the tail dependence estimator proposed by schmid and schmidt 2007 we tested the suitability of several copula families the independence copula several archimedean gumbel clayton joe frank amh hüsler reiss galambos farlie gumbel morgenstern fgm tawn plackett and survival clayton and two elliptical copulas normal student t to model the dependence between q p and v by computing the cramér von mises goodness of fit statistic genest and favre 2007 the elliptical copulas provided a better fit to the data than the archimedean copulas when comparing their cramér von mises test statistics the student t copula was chosen instead of the normal copula because it is able to model positive tail dependence frahm et al 2003 in addition to the form of the dependence the intensity of the dependence measured by kendall s tau and spearman s rho only slightly differed for the three event types within a region and between the four reactivity regions the pair of dimensionless growth curves for q p and v was estimated using the marginal distributions of the variables represented by wakeby distributions and the student t copula for a joint return period of t considering that both design variables are equally important brunner et al 2016 we here focused on a return period of t 100 years since it is often used in practice camezind wildi 2005 however the approach is not limited to this return period b index floods the index floods were computed for both peak discharges and hydrograph volumes and for each of the regions and event types separately the index flood peak and volume were predicted based on a gamma generalized linear model glm with a log link which does not give rise to a negative estimated response myers et al 2010 using the same catchment characteristics as explanatory variables as used for establishing the classification rule section 3 2 the glms were fitted for each of the twelve 4 3 data pools separately we used a stepwise regression procedure harrell 2015 to identify the model with the fewest explanatory variables still providing us with a useful model for index flood prediction we found that the index flood peaks and volumes could be predicted by only a few explanatory variables which were similar for both design variables q p and v the most important explanatory variables across all regions and event types were catchment area and network density the regional growth curves were used together with the catchment specific index floods to obtain local design variable quantile estimates using eq 1 3 3 3 iii construction of design hydrograph by combining magnitude and shape the three estimated design variable pairs section 3 3 2 and the regional pdfs section 3 3 1 were used to construct three representative sdhs for an ungauged catchment an sdh can be expressed as 3 q t t f t v t d t b where f t represents the pdf used to model the shape of the hydrograph vt and dt the design quantiles for hydrograph volume and duration for the return period t and b the baseflow component dt can be derived as d t f t p v t q t where tp is the time to peak and qt the design quantile for peak discharge baseflow was added via a mean event baseflow index which was computed per reactivity region independently of the event type proportionally to the direct runoff see brunner et al 2017b the construction of event type specific sdh sets using probabilistic class memberships proceeded similarly to the construction procedure described above when using the best class membership it again differentiated between pools of fast intermediate and slow events to compute the design event magnitude we computed the regional growth curves for each of the four regions and used them to compute an averaged regional growth curve weighting the individual growth curves by the probabilities of membership to each of the corresponding regions in addition we predicted four index floods using the four glms for each of the regions and computed again a weighted average of these predictions using the probabilities of region membership as weights the design event magnitude was finally computed by upscaling the weighted average of the regional growth curves with the weighted average of the index floods the design event shapes were also computed as a weighted average from the shapes of the four regions using again the probabilities of region memberships as weights for the individual pdfs the event type specific regional sdh procedure was applied both using the best class membership and the probabilistic class memberships this resulted in two sets of regionally estimated sdhs 3 4 validation of approach we compared these two sets of regionally estimated sdhs to sdhs computed using local runoff observations the local estimation was done based on the event type specific data within a catchment using the procedure proposed in brunner et al 2017b for the construction of flood type specific sdhs this meant that three event type specific sdhs were computed for each catchment local event type specific sdhs were only constructed for event types with more than five observations this prevented from completely unreliable estimates however every estimate obtained by a sample of less than twenty observations had to be considered to be not really reliable deutsche vereinigung für wasserwirtschaft abwasser und abfall 2012 this meant that even though the local estimates have been computed using observed data they might not represent the true sdhs for the catchment under consideration nonetheless we used them as a basis for validation we computed the relative and the absolute relative error of the regional estimates compared to the local estimates for four hydrograph characteristics peak discharge q p hydrograph volume v time to peak t p and half recession time t p05 i e the time from peak to where the recession curve falls back to half the peak discharge 4 results 4 1 region assignment the catchment specific sets of representative hydrograph shapes were used to delineate regions with similar flood behaviors their clustering resulted in four clusters regions with distinct flood event reaction times region a with catchments with a generally fast runoff reaction see fig 3 a 30 catchments region b with catchments with a generally intermediate runoff reaction see fig 3b 45 catchments region c with catchments with a generally slow runoff reaction see fig 3c 58 catchments and region d with catchments with a generally rather uniform runoff reaction see fig 3d 30 catchments the catchments belonging to region a were mainly small catchments located in the swiss plateau catchments belonging to region d were mostly located in the jura mountains and regions b and c consisted of catchments in the swiss plateau and in alpine regions catchments in region a were characterized by hydrograph sets with a steeper recession limb than the catchments in the regions b c and d fig 4 the differences in hydrograph shapes between the four regions were largest for the fast event shapes well visible for the intermediate event shapes and rather weak for the slow event shapes the reactivity regions not only differed in terms of their representative hydrograph shapes but also in terms of hydrograph magnitudes table 1 events occurring in region a were characterized by rather high peak discharges compared to flood volumes while events occurring in region d showed rather high volumes compared to peak discharges regions b and c lay somewhere in between an ungauged catchment can be assigned to one of the four reactivity regions via a classification rule we found that the most suitable model to establish a classification rule was random forest which had a misclassification error of 45 see fig 5 this implies that an ungauged catchment will be attributed to the correct region with a probability of 55 the classification error could mainly be explained by catchments attributed to region b instead of c and vice versa 17 these two clusters seemed to be difficult to distinguish using catchment characteristics i e the probabilities of belonging to one or the other regions were quite similar some catchments were also attributed to region c instead of d only a few catchments were attributed to a non neighboring region e g to region c instead of a 12 the most important catchment characteristics for predicting the region membership of a catchment among the seven characteristics used were found to be catchment area network density and location in space region a was characterized by small catchments with a rather high network density and low sunshine duration these catchments were mainly located in the swiss plateau on the contrary region d was characterized by large catchments with a low network density high sunshine duration and a high percentage area of karstic rock these catchments were mainly located in the jura mountains and northeastern switzerland the catchments belonging to regions b and c were medium size characterized by medium network densities and sunshine durations they were located in both the swiss plateau and the alps and were not easy to attribute to one or the other region 4 2 regional event type specific sdh sets the previously established regions were used in regional flood frequency analysis to derive two sets of representative design hydrographs for ungauged catchments for a specified return period we focused on the two return periods 10 and 100 years for illustration purposes since these return periods are often used in practice camezind wildi 2005 as described in section 3 3 we computed two regional sets of three hydrographs fast intermediate and slow the first set was computed using regional information of the region with the highest probability of membership called best class membership on the contrary the second set was computed using regional information of the four regions weighted according to the probabilistic region memberships fig 6 shows the two regionally estimated sdh sets thin and thick bold lines together with a locally estimated sdh set dashed lines and a catchment specific sdh not distinguishing between event types computed using local observations black dashed line for a return period of 100 years the two sets of regionally estimated sdhs compared well with the locally estimated sdhs in most catchments furthermore the regionally estimated sdhs lay in the order of magnitude of the highest observed event of a catchment grey lines the relative error of the four hydrograph characteristics peak discharge hydrograph volume time to peak and half recession time was roughly 50 for all the event types for both return periods considered 10 and 100 years fig 7 however the variability of the relative errors across catchments was slightly lower for t 10 than for t 100 the relative errors were similar when using the best and the probabilistic class memberships while the median relative error was not highly affected by using probabilistic memberships instead of the best class membership the variability of the relative errors was clearly higher when applying the best class membership the relative error of peak discharges was independent of the event type while it depended on the event type for the other three hydrograph characteristics it was generally higher for the fast sdhs than for the intermediate and slow sdhs the variability of the relative error was larger towards negative values i e underestimation of the regional estimates and did not specifically depend on the hydrograph characteristics considered 5 discussion 5 1 region assignment four regions with a similar flood behavior were identified catchments with a generally quick runoff response independent of the event type formed the quickly reactive region region a events occurring in this region are characterized by rather high peak discharges but rather low hydrograph volumes for all three event types the catchments belonging to the quickly reactive region are small and mainly lie in the swiss plateau they are characterized by a circular shape impermeable rocks a high network density and low sunshine duration which is related to their location in the swiss plateau that is often covered by fog in the winter time all these characteristics contributed to a fast runoff reaction a high network density allows for an efficient drainage after a precipitation event and is related to increases in the flood peaks ogden et al 2011 impermeable rocks prevent from rainfall infiltration and favor surface runoff and a circular shape leads to the confluence of discharge from different parts of the catchment at the same time catchments in regions b and c with a generally intermediate or slow runoff response showed similar catchment characteristics the events occurring in these catchments generally showed higher volumes but lower peak discharges compared to events occurring in the catchments of the quickly reactive region these catchments typically lie in the swiss plateau or the alps compared to the catchments in the quickly reactive region they are more elongated have more permeable rocks and lower network densities which lead to a dampening of the runoff events catchments with a uniform runoff reaction belong to region d the uniformly reactive region the events occurring in the catchments belonging to this region are generally characterized by slow rising and falling limbs high volumes and low peak discharges the catchments belonging to this region are rather large and mainly lie in the jura but also comprise a few large catchments in the swiss plateau they are characterized by an elongated shape karstic geology with permeable rock and a low network density these catchment properties lead to a damped runoff reaction that leads to similar flood events independent of the triggering mechanism and antecedent wetness the mean floods of the three event types for the catchments in the four regions could be mainly explained by catchment area and network density we found that random forest was a suitable approach for establishing a classification rule allowing for the assignment of an ungauged catchment to one of the four reactivity regions even though the misclassification error seems rather high with 45 however not all misclassification errors were equally serious since we dealt with ordered classes assigning a catchment of region a to region b for example was less severe than assigning it to region c because regions a and b were more similar than regions a and c most misclassification errors were related to placing a catchment into a neighboring region more specifically to placing a catchment belonging to region b into region c or vice versa these two classes were found to be difficult to distinguish using the classification rule one could argue that these two regions could be combined as this would reduce the number of classes and therewith also the misclassification error however this combining would also increase the heterogeneity of flood characteristics of catchments within the combined class which is not desirable for the sdh construction procedure we therefore decided to keep the four classes and to benefit from the characteristics of the output of the ensemble based random forest model the ensemble based method did not only provide a best class membership for a catchment but also probabilistic class memberships for each of the reactivity regions which could be used in regional sdh construction the weighting of estimates from different regions using the probabilistic region memberships helped to reduce the uncertainty related to misclassification and led to a reduction in the variability of the relative prediction error across catchments 5 2 regional event type specific sdh sets the four reactivity regions and the three event types were found to be useful for regional sdh construction since the events belonging to one event type within a region were found to be more similar than events belonging to another event type in the same region or the same event type in another region even though the individual data pools were not homogeneous in a statistical sense hosking and wallis 1997 they were still useful for regional flood frequency analysis the different regional data pools did neither show strongly different forms nor intensities of dependence even though grimaldi et al 2016 suggested that basins with different times of concentration and different soil uses might show different dependence structures this might be explained by the fact that the catchments under study were all located in the swiss lowlands or prealps which led to a certain similarity in land use and other catchment attributes high alpine catchments which were shown to have very low dependence between peak discharges and flood volumes due to a mix of flood types gaál et al 2015 were not considered in the analysis the regional sdh construction approach relied on an index flood procedure that is applicable in ungauged catchments the strongest explanatory variable for the index floods in the four regions was found to be catchment area which is in line with findings by blöschl and sivapalan 1997 who found that there is a clear tendency of mean annual floods per area to decrease with catchment area potentially this regional sdh construction approach can also be applied to catchments with only a few years of observations there the index floods could be derived from observed data and be combined with their regional growth curve furthermore information could also be extended temporally merz and blöschl 2008 by including historical information wetter 2017 which could potentially reduce the uncertainty in flood risk estimates kjeldsen et al 2014 the regional sdh construction approach was developed on a set of swiss catchments but can be extended to other geographical regions for which a large enough dataset is available to delineate meaningful regions and to fit region specific generalized linear models for the prediction of index floods however a few assumptions would need to be verified and possibly adjusted these comprise the number of flood reactivity regions the fitting of the classification rule the choice of catchment characteristics used in the classification model and the glm for the prediction of the index flood and the copula model used to model the dependence between peak discharges and hydrograph volumes the regionally estimated event type specific sdhs were compared to locally estimated event type specific sdhs this is not optimal since the locally estimated sdhs might not represent reliable estimates if they are estimated based on a very small flood sample still the relative error of regionalized estimates compared to local estimates was quantified to lie around 50 on average across the 163 study catchments the prediction errors were found to be generally higher for fast sdhs than for the intermediate and slow sdhs this might be related to the fact that the slow events are more homogeneous across regions and event types than the fast events which generally show a higher variability 6 conclusions the advantage of the event type specific sdh construction procedure proposed here compared to a catchment specific sdh construction procedure is that the three resulting sdhs provide us with a much better idea on the variability of potential design events they depict a range of potential design flood outcomes showing the uncertainty related to different processes that can potentially occur within a catchment this ensemble or set of design events can be used by engineers in hydraulic modeling or in a cost benefit analyses when designing reservoir storage the use of design flood ensembles in flood hazard mapping is advisable since flood peak attenuation varies with hydrograph magnitude and shape which could result in different water levels and flood extents this ensemble based design flood approach is a compromise between using a single best estimate design hydrograph and using a continuous simulation model for flood hazard mapping contrary to a best single estimate design hydrograph it allows for the representation of process variability and does not give a result that is elusively precise still compared to continuous models it does neither require the stochastic simulation of rainfall fields nor the calibration of a rainfall runoff model it has the advantage that it is easily applicable in ungauged catchments and circumvents the simulation of rainfall and assumptions related to its transformation into runoff however setting up a regional index flood model might require as much data as setting up a regional continuous simulation model the ensemble based design hydrograph approach proposed in this study makes a step from a pure statistical approach towards a process based method allowing for the representation of process variability in design flood estimation in ungauged catchments acknowledgments we thank the federal office for the environment foen for funding the project contract 13 0028 kp m285 0623 and for providing runoff measurement data the data used in this study are available upon order from the foen for the hydrological data of the federal stations the order form under http www bafu admin ch wasser 13462 13494 15076 index html lang de can be used the hydrological data of the cantonal stations can be ordered from the respective cantons we thank the two reviewers for their constructive feedback supplementary material supplementary material associated with this article can be found in the online version at 10 1016 j advwatres 2017 12 018 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
885,traditional design flood estimation approaches have focused on peak discharges and have often neglected other hydrograph characteristics such as hydrograph volume and shape synthetic design hydrograph estimation procedures overcome this deficiency by jointly considering peak discharge hydrograph volume and shape such procedures have recently been extended to allow for the consideration of process variability within a catchment by a flood type specific construction of design hydrographs however they depend on observed runoff time series and are not directly applicable in ungauged catchments where such series are not available to obtain reliable flood estimates there is a need for an approach that allows for the consideration of process variability in the construction of synthetic design hydrographs in ungauged catchments in this study we therefore propose an approach that combines a bivariate index flood approach with event type specific synthetic design hydrograph construction first regions of similar flood reactivity are delineated and a classification rule that enables the assignment of ungauged catchments to one of these reactivity regions is established second event type specific synthetic design hydrographs are constructed using the pooled data divided by event type from the corresponding reactivity region in a bivariate index flood procedure the approach was tested and validated on a dataset of 163 swiss catchments the results indicated that 1 random forest is a suitable classification model for the assignment of an ungauged catchment to one of the reactivity regions 2 the combination of a bivariate index flood approach and event type specific synthetic design hydrograph construction enables the consideration of event types in ungauged catchments and 3 the use of probabilistic class memberships in regional synthetic design hydrograph construction helps to alleviate the problem of misclassification event type specific synthetic design hydrograph sets enable the inclusion of process variability into design flood estimation and can be used as a compromise between single best estimate synthetic design hydrographs and continuous simulation studies keywords classification random forest homogeneous regions regionalization mixtures floods 1 introduction classical design flood estimation has been focusing on the univariate analysis of peak discharges even though other event characteristics such as hydrograph volume and shape are equally important for hydraulic design tasks involving storage pilgrim 1986 more recent flood estimation procedures allow the representation of both the magnitude and the shape of an event through synthetic design hydrographs sdhs synthetic design hydrographs provide a more complete picture of the flood behavior of a catchment than classical approaches sdhs include event based approaches using event rainfall as input grimaldi et al 2012 rogger et al 2012 and statistical approaches using observed runoff in bivariate flood frequency analyses brunner et al 2017b however as the classical approaches they neglect the variability of flood events within a catchment caused by different processes which are mirrored by various flood types such as flash floods short rain long rain and rain on snow floods merz and blöschl 2003 to overcome this deficiency brunner et al 2017b proposed an approach for the construction of a set of flood type specific sdhs the approach splits the flood sample into four subsets one for each flood type and uses each of these samples to construct a flood type specific design hydrograph the shape of the design hydrographs is modeled by a probability density function pdf while the magnitude of the event is modeled via a bivariate frequency analysis taking into account the dependence between peak discharges and hydrograph volumes via a copula model this ensemble based sdh construction approach takes into account process variability but is based on observed flood events and cannot be easily transferred to ungauged catchments where no runoff information is available there design floods have traditionally been estimated by a regional index flood approach focusing on peak discharges the index flood approach consists of two main steps in a first step regions with a similar flood behavior are delineated in a second step the data within these similar regions are used for regional flood frequency analysis hydrologically similar regions are often delineated based on hydrological catchment characteristics or runoff signatures burn and boorman 1992 since physiographical and climatological catchment similarity do often not correspond to hydrological similarity ali et al 2012 oudin et al 2010 brunner et al 2017a suggested to use entire hydrograph shapes in the delineation of homogeneous regions with the argument that those provide more information on the flood behavior of a catchment than statistical measures of individual hydrograph characteristics in this previous study it was shown that flood reactivity regions can be delineated by characterizing each catchment in the dataset by a set of three representative hydrograph shapes a fast an intermediate and a slow shape grouping catchments with similar sets of representative hydrograph shapes delineates regions which are similar in terms of their flood behavior such regions were shown to have a hydro meteorological meaning and are potentially useful in regional flood frequency analysis regional frequency analysis is often done using the index flood approach which was proposed by dalrymple 1960 for annual maxima series and later extended to partial duration peak over threshold series madsen et al 1997 it assumes that frequency distributions at different sites within a region are identical apart from a scale factor it describes a local quantile estimate qi f as the product of an index flood μi and a regional growth curve q f estimated based on the data at n sites as 1 q i f μ i q f i 1 n the index flood can be any location measure of the at site distribution but is often taken to be its mean the regional growth curve is a dimensionless quantile function computed based on dimensionless regional data which are obtained by dividing the observed flood event data by the index flood regional analysis using the index flood approach yields more accurate quantile estimates than at site analysis even if a region is heterogeneous it was thus found to be a robust and efficient estimation procedure lettenmaier et al 1987 madsen et al 1997 the classical index flood procedure focuses on peak discharges requena et al 2016 therefore proposed an approach for a multivariate regional index approach that allows for the consideration of more than one design hydrograph characteristic e g peak discharge and hydrograph volume while such a bivariate regional approach allows the joint consideration of peak discharges and hydrograph volumes neither hydrograph shape nor process variability can be considered to our knowledge no methodology has so far been proposed for the regional construction of event type specific sets of sdhs in ungauged catchments the aim of this study was therefore to propose an approach that allows for the construction of sdhs in ungauged catchments which on the one hand jointly represents the magnitude and shape of an event and on the other hand allows for the consideration of process variability we here propose an approach that delineates regions of a similar flood reactivity using the approach by brunner et al 2017a applies the bivariate index flood approach proposed by requena et al 2016 within these flood reactivity regions and uses the resulting design variable pairs in the sdh construction approach proposed by brunner et al 2017b instead of flood types we use the three event types fast intermediate and slow in design hydrograph construction brunner et al 2017a the three event type specific sdhs together form a set of design hydrographs which considers the process variability within an ungauged catchment our research more specifically addresses the following research questions 1 how can an ungauged catchment best be assigned to one of the flood reactivity regions 2 how can event type specific sdh sets for ungauged catchments be constructed 3 can probabilistic class memberships be used in regional sdh construction to reduce the problem of misclassification 2 data this analysis used runoff and catchment characteristics data from 163 swiss catchments fig 1 with a wide range of catchment characteristics and flood behaviors the selected catchments have hourly flow series of at least 20 years in duration ranging up to 53 years in these catchments runoff is neither altered by regulated lakes upstream or inland canals nor by urbanized areas the catchments are small to medium size 6 to 1800 km2 situated at mean elevations between 400 and 2600 m a s l and have no or only a minor glacier coverage the basis for the analysis was samples of flood events extracted from the runoff time series of the 163 study catchments to sample flood events we used a peak over threshold approach based on the procedure proposed by lang et al 1999 the threshold for the peak discharge was chosen iteratively to fulfill a target condition of four events per year on average which is a trade off between maximizing the information content in the sample and keeping the assumption of independence between events for each of these events sampled according to the flood peaks the flood volume was determined over the actual event duration the actual duration was determined as the time between the onset of the event defined as the time where discharge first exceeds 0 05 times the peak discharge and the end of the event discharge falls below 0 05 times the peak discharge the baseflow was separated from the direct flow using a recursive digital filter eckhardt 2005 the resulting direct flow component of the hydrographs was then normalized so that the volume of the modified hydrographs was equal to one this was done by dividing the ordinate of each hydrograph by the volume v in the remainder of this paper we refer to these normalized hydrographs as hydrograph shapes to make the sampled event hydrographs comparable they were brought to a length of 72 hours by appending hours with the minimum discharge until the series consisted of 72 values we refer the reader to brunner et al 2017b for a more detailed description of the flood sampling and baseflow separation procedures 3 methods in the regional approach for the construction of event type specific sets of sdhs we assigned an ungauged catchment to a flood reactivity region and subsequently used the data from this reactivity region for the estimation of a set of sdhs representing three event types comprising a fast an intermediate and a slow event the regional approach consists of three main steps 1 delineation of reactivity regions by clustering catchments using their catchment specific sets of representative hydrograph shapes 2 establishment of a classification rule allowing the attribution of an ungauged catchment to one of the reactivity regions 3 construction of a set of event type specific design hydrographs using i region specific hydrograph shape sets and ii event magnitudes estimated by event type in a bivariate index flood approach the individual steps of the methodology are illustrated in fig 2 and described in more detail in the following paragraphs 3 1 step 1 delineation of regions with similar flood reactivity brunner et al 2017a showed that the hydrograph shape variability within swiss catchments can be summarized by a set of three representative hydrograph shapes a fast an intermediate and a slow hydrograph in this previous study we represented normalized hydrograph shapes as functional data i e as continuous functions by projecting them on a set of four basis splines b spline bases a spline function is determined by the order of the polynomial segments and the number and placement of knots the number of knots determines the ability of spline functions to represent sharp features in a curve and the knots can be placed such that they are denser in areas with stronger variations than in smooth areas höllig and hörner 2013 the sets of four coefficients one per b spline base were used in a k means clustering algorithm gordon 1999 to identify clusters of similar hydrograph shapes three shape clusters were found to well explain the shape variability within swiss catchments each cluster was summarized by its median hydrograph shape the three median shapes together formed the set of representative hydrograph shapes consisting of a fast an intermediate and a slow hydrograph shape the fast event type is characterized by both steep rising and recession limbs the intermediate event type is characterized by a rather steep rising but a slow recession limb and the slow event type is characterized by both slow rising and recession limbs brunner et al 2017a brunner et al 2017a then used these catchment specific sets of representative hydrograph shapes for the identification of flood reactivity regions i e regions that were similar in terms of their representative hydrograph shape sets we modified the approach proposed by brunner et al 2017a in the following two ways 1 the clustering was done using the representative hydrograph sets of all catchments without separating a uniformly reactive catchment as done in brunner et al 2017a because this was found to be a disadvantage for the identification of a classification rule in step 2 2 we delineated four instead of three regions with a similar flood reactivity using the functional representation of catchment specific sets of hydrograph shapes as an input for the hierarchical clustering algorithm four regions were found to be better since the hierarchical clustering tree showed a clear symmetry and cutting it at three or five clusters would not have been sensible we called these regions a to d region a is characterized by a quick runoff reaction i e all three representative hydrograph shapes showed a rather quick response compared to the representative hydrograph shapes in catchments belonging to the other three regions regions b and c were characterized by an intermediate or slow reactivity respectively region d showed a rather uniform reaction to rainfall input i e the fast intermediate and slow shapes were difficult to distinguish the runoff behavior of catchments within a region was summarized by a set of median event type specific hydrograph shapes median shape sets the cluster memberships of the 163 study catchments were used in step 2 to identify a classification rule allowing for the assignment of an ungauged catchment to one of the four reactivity regions 3 2 step 2 attribution of ungauged catchment to reactivity region we established a relationship between the catchment characteristics and the region memberships of catchments to be able to attribute an ungauged catchment to one of the four reactivity regions based on catchment characteristics only an initial comparison of several classification methods showed that random forest harrell 2015 james et al 2013 was the most suitable classification model in cross validation the set of explanatory variables used to fit the models consisted of the following seven weakly correlated catchment characteristics catchment area network density y coordinate soil topographic index percentage area of karstic rocks sunshine duration and vapor pressure catchment area and network density were derived from the digital elevation model the soil topographic index from the digital map of land surface characteristics eidgenössische forschungsanstalt für wald schnee und landschaft wsl 1999 the percentage area of karstic rock from a map focusing on groudwater resources bitterli et al 2007 and sunshine duration and vapor pressure from gridded meteorological data provided by meteoswiss meteoswiss 2013 we used the random forest classification model to attribute ungauged catchments to one of the reactivity regions according to its best class membership and to compute probabilities of class memberships which we hereafter refer to as probabilistic class memberships for each of the four regions considering probabilistic class memberships allowed the alleviation of the problem of misclassification regions b and c were found to be difficult to distinguish when assigning a best class membership to a catchment assigning probabilistic class memberships and using them in sdh construction helped to take into consideration this source of uncertainty 3 3 step 3 construction of a set of event type specific sdhs an ungauged catchment was assigned to one of the reactivity regions delineated in step 1 via the random forest classification model established in step 2 the construction of an event type specific set of sdhs for this ungauged catchment was based on the pool of data of the reactivity region it was assigned to best class membership the approach was at a later stage extended to probabilistic region memberships as described under step 2 we first focus on the construction of event type specific sets of sdhs using the best class membership the event type specific construction procedure was based on the sdh construction procedure proposed by brunner et al 2017b for different flood types merz and blöschl 2003 sikorska et al 2015 instead of differentiating flood types we here distinguished between the three event types fast intermediate and slow which cover a large part of shape variability within a catchment and were used in section 3 1 for the delineation of reactivity regions a set of three sdhs was constructed by combining shape estimates represented by a probability density function with magnitude estimates represented by the bivariate design variable quantiles peak discharge and hydrograph volume the basic idea of the procedure is to do regional flood frequency analysis within the reactivity region of interest using a bivariate index flood approach requena et al 2016 for each of the three event types fast intermediate and slow separately this regional sdh construction approach consists of three steps see fig 2 i computation of design event shape ii computation of design event magnitude by estimating a a regional growth curve and b a local index flood and iii construction of design hydrograph by combining magnitude and shape these steps are described in detail in the following paragraphs 3 3 1 i computation of design event shape the design hydrograph shapes were estimated using the three representative hydrograph shapes fast intermediate and slow of the region the ungauged catchment was assigned to the three hydrograph shapes were each fitted by a lognormal probability density function pdf yue et al 2002 which was expressed in terms of their time to peak peak discharge and time base nadarajah 2007 rai et al 2009 the lognormal pdf was chosen out of a selection of eight pdfs normal lognormal fréchet weibull beta gamma inverse gamma and logistic whose fit to the representative hydrograph shapes was assessed via the kling gupta and nash sutcliffe efficiencies gupta et al 2009 3 3 2 ii computation of design event magnitude we formed pools of observed flood events for each event type within the predicted reactivity region the region was characterized by three pools of data fast events intermediate events and slow events the individual data pools consisted of all the event type specific events of the catchments within the corresponding reactivity region the data pools consisted of dimensionless peak discharges peak discharges normalized by mean catchment peak discharge i e index flood peak and dimensionless hydrograph volumes hydrograph volumes normalized by mean catchment hydrograph volume i e index hydrograph volume to make values from different catchments comparable these pooled data were used in a bivariate flood frequency analysis to derive regional growth curves for peak discharges and hydrograph volumes requena et al 2016 the bivariate frequency analysis was based on the marginal distributions of peak discharges q p and hydrograph volumes v and their dependence was modeled via a copula function a regional growth curves the four regions were characterized by differences in q p and v q p generally decreased from region a to d while v increased q p and v not only differed between regions but also between the three event types within a catchment fast and intermediate events were generally characterized by higher magnitudes in terms of q p and smaller magnitudes in terms of v than slow events we used the flexible five parameter wakeby distribution houghton 1978 griffiths 1989 to model the marginal distributions of q p and v because this distribution can mimic the shapes of many commonly used skew distributions such as the extreme value distribution the lognormal or pearson type iii distributions the wakeby distribution provided a good fit to the data which was confirmed by the kolmogorov smirnov goodness of fit test level of significance α 0 05 fitting a distribution with five parameters was not a problem in our case since the sample size was sufficiently large when working with the pooled data the wakeby distribution f x is not explicitly defined however its inverse x f can be expressed by the five parameters α β γ λ and ξ hosking 1986 as follows 2 x f ξ α β 1 1 f β γ δ 1 1 f δ when δ 0 the wakeby distribution has a heavy upper tail and can give rise to data sets containing occasional high outliers the upper tail behavior of the wakeby distribution is determined by the parameters γ and δ unless γ 0 as f 1 the density function of the wakeby distribution is asymptotically equivalent to that of a generalized pareto distribution hosking 1986 other distributions commonly used in flood frequency analysis such as the generalized extreme value distribution and the generalized pareto distribution coles 2001 did not provide a good fit to the data compared to the wakeby distribution their flexibility is limited by the lower number of parameters three the parameters of the wakeby distribution were estimated for both the q p and v in each of the data pools using l moments hosking and wallis 1997 and its parameters were found to differ between the data pools the form of the dependence between q p and v did not strongly differ for the three event types within a region nor was it different between the four reactivity regions it could therefore be modeled by the same copula family for all event types and regions the dependence between q p and v was modeled using the elliptical student t copula frahm et al 2003 which is able to model lower and upper non null tail dependence as present in the data assessed via the tail dependence estimator proposed by schmid and schmidt 2007 we tested the suitability of several copula families the independence copula several archimedean gumbel clayton joe frank amh hüsler reiss galambos farlie gumbel morgenstern fgm tawn plackett and survival clayton and two elliptical copulas normal student t to model the dependence between q p and v by computing the cramér von mises goodness of fit statistic genest and favre 2007 the elliptical copulas provided a better fit to the data than the archimedean copulas when comparing their cramér von mises test statistics the student t copula was chosen instead of the normal copula because it is able to model positive tail dependence frahm et al 2003 in addition to the form of the dependence the intensity of the dependence measured by kendall s tau and spearman s rho only slightly differed for the three event types within a region and between the four reactivity regions the pair of dimensionless growth curves for q p and v was estimated using the marginal distributions of the variables represented by wakeby distributions and the student t copula for a joint return period of t considering that both design variables are equally important brunner et al 2016 we here focused on a return period of t 100 years since it is often used in practice camezind wildi 2005 however the approach is not limited to this return period b index floods the index floods were computed for both peak discharges and hydrograph volumes and for each of the regions and event types separately the index flood peak and volume were predicted based on a gamma generalized linear model glm with a log link which does not give rise to a negative estimated response myers et al 2010 using the same catchment characteristics as explanatory variables as used for establishing the classification rule section 3 2 the glms were fitted for each of the twelve 4 3 data pools separately we used a stepwise regression procedure harrell 2015 to identify the model with the fewest explanatory variables still providing us with a useful model for index flood prediction we found that the index flood peaks and volumes could be predicted by only a few explanatory variables which were similar for both design variables q p and v the most important explanatory variables across all regions and event types were catchment area and network density the regional growth curves were used together with the catchment specific index floods to obtain local design variable quantile estimates using eq 1 3 3 3 iii construction of design hydrograph by combining magnitude and shape the three estimated design variable pairs section 3 3 2 and the regional pdfs section 3 3 1 were used to construct three representative sdhs for an ungauged catchment an sdh can be expressed as 3 q t t f t v t d t b where f t represents the pdf used to model the shape of the hydrograph vt and dt the design quantiles for hydrograph volume and duration for the return period t and b the baseflow component dt can be derived as d t f t p v t q t where tp is the time to peak and qt the design quantile for peak discharge baseflow was added via a mean event baseflow index which was computed per reactivity region independently of the event type proportionally to the direct runoff see brunner et al 2017b the construction of event type specific sdh sets using probabilistic class memberships proceeded similarly to the construction procedure described above when using the best class membership it again differentiated between pools of fast intermediate and slow events to compute the design event magnitude we computed the regional growth curves for each of the four regions and used them to compute an averaged regional growth curve weighting the individual growth curves by the probabilities of membership to each of the corresponding regions in addition we predicted four index floods using the four glms for each of the regions and computed again a weighted average of these predictions using the probabilities of region membership as weights the design event magnitude was finally computed by upscaling the weighted average of the regional growth curves with the weighted average of the index floods the design event shapes were also computed as a weighted average from the shapes of the four regions using again the probabilities of region memberships as weights for the individual pdfs the event type specific regional sdh procedure was applied both using the best class membership and the probabilistic class memberships this resulted in two sets of regionally estimated sdhs 3 4 validation of approach we compared these two sets of regionally estimated sdhs to sdhs computed using local runoff observations the local estimation was done based on the event type specific data within a catchment using the procedure proposed in brunner et al 2017b for the construction of flood type specific sdhs this meant that three event type specific sdhs were computed for each catchment local event type specific sdhs were only constructed for event types with more than five observations this prevented from completely unreliable estimates however every estimate obtained by a sample of less than twenty observations had to be considered to be not really reliable deutsche vereinigung für wasserwirtschaft abwasser und abfall 2012 this meant that even though the local estimates have been computed using observed data they might not represent the true sdhs for the catchment under consideration nonetheless we used them as a basis for validation we computed the relative and the absolute relative error of the regional estimates compared to the local estimates for four hydrograph characteristics peak discharge q p hydrograph volume v time to peak t p and half recession time t p05 i e the time from peak to where the recession curve falls back to half the peak discharge 4 results 4 1 region assignment the catchment specific sets of representative hydrograph shapes were used to delineate regions with similar flood behaviors their clustering resulted in four clusters regions with distinct flood event reaction times region a with catchments with a generally fast runoff reaction see fig 3 a 30 catchments region b with catchments with a generally intermediate runoff reaction see fig 3b 45 catchments region c with catchments with a generally slow runoff reaction see fig 3c 58 catchments and region d with catchments with a generally rather uniform runoff reaction see fig 3d 30 catchments the catchments belonging to region a were mainly small catchments located in the swiss plateau catchments belonging to region d were mostly located in the jura mountains and regions b and c consisted of catchments in the swiss plateau and in alpine regions catchments in region a were characterized by hydrograph sets with a steeper recession limb than the catchments in the regions b c and d fig 4 the differences in hydrograph shapes between the four regions were largest for the fast event shapes well visible for the intermediate event shapes and rather weak for the slow event shapes the reactivity regions not only differed in terms of their representative hydrograph shapes but also in terms of hydrograph magnitudes table 1 events occurring in region a were characterized by rather high peak discharges compared to flood volumes while events occurring in region d showed rather high volumes compared to peak discharges regions b and c lay somewhere in between an ungauged catchment can be assigned to one of the four reactivity regions via a classification rule we found that the most suitable model to establish a classification rule was random forest which had a misclassification error of 45 see fig 5 this implies that an ungauged catchment will be attributed to the correct region with a probability of 55 the classification error could mainly be explained by catchments attributed to region b instead of c and vice versa 17 these two clusters seemed to be difficult to distinguish using catchment characteristics i e the probabilities of belonging to one or the other regions were quite similar some catchments were also attributed to region c instead of d only a few catchments were attributed to a non neighboring region e g to region c instead of a 12 the most important catchment characteristics for predicting the region membership of a catchment among the seven characteristics used were found to be catchment area network density and location in space region a was characterized by small catchments with a rather high network density and low sunshine duration these catchments were mainly located in the swiss plateau on the contrary region d was characterized by large catchments with a low network density high sunshine duration and a high percentage area of karstic rock these catchments were mainly located in the jura mountains and northeastern switzerland the catchments belonging to regions b and c were medium size characterized by medium network densities and sunshine durations they were located in both the swiss plateau and the alps and were not easy to attribute to one or the other region 4 2 regional event type specific sdh sets the previously established regions were used in regional flood frequency analysis to derive two sets of representative design hydrographs for ungauged catchments for a specified return period we focused on the two return periods 10 and 100 years for illustration purposes since these return periods are often used in practice camezind wildi 2005 as described in section 3 3 we computed two regional sets of three hydrographs fast intermediate and slow the first set was computed using regional information of the region with the highest probability of membership called best class membership on the contrary the second set was computed using regional information of the four regions weighted according to the probabilistic region memberships fig 6 shows the two regionally estimated sdh sets thin and thick bold lines together with a locally estimated sdh set dashed lines and a catchment specific sdh not distinguishing between event types computed using local observations black dashed line for a return period of 100 years the two sets of regionally estimated sdhs compared well with the locally estimated sdhs in most catchments furthermore the regionally estimated sdhs lay in the order of magnitude of the highest observed event of a catchment grey lines the relative error of the four hydrograph characteristics peak discharge hydrograph volume time to peak and half recession time was roughly 50 for all the event types for both return periods considered 10 and 100 years fig 7 however the variability of the relative errors across catchments was slightly lower for t 10 than for t 100 the relative errors were similar when using the best and the probabilistic class memberships while the median relative error was not highly affected by using probabilistic memberships instead of the best class membership the variability of the relative errors was clearly higher when applying the best class membership the relative error of peak discharges was independent of the event type while it depended on the event type for the other three hydrograph characteristics it was generally higher for the fast sdhs than for the intermediate and slow sdhs the variability of the relative error was larger towards negative values i e underestimation of the regional estimates and did not specifically depend on the hydrograph characteristics considered 5 discussion 5 1 region assignment four regions with a similar flood behavior were identified catchments with a generally quick runoff response independent of the event type formed the quickly reactive region region a events occurring in this region are characterized by rather high peak discharges but rather low hydrograph volumes for all three event types the catchments belonging to the quickly reactive region are small and mainly lie in the swiss plateau they are characterized by a circular shape impermeable rocks a high network density and low sunshine duration which is related to their location in the swiss plateau that is often covered by fog in the winter time all these characteristics contributed to a fast runoff reaction a high network density allows for an efficient drainage after a precipitation event and is related to increases in the flood peaks ogden et al 2011 impermeable rocks prevent from rainfall infiltration and favor surface runoff and a circular shape leads to the confluence of discharge from different parts of the catchment at the same time catchments in regions b and c with a generally intermediate or slow runoff response showed similar catchment characteristics the events occurring in these catchments generally showed higher volumes but lower peak discharges compared to events occurring in the catchments of the quickly reactive region these catchments typically lie in the swiss plateau or the alps compared to the catchments in the quickly reactive region they are more elongated have more permeable rocks and lower network densities which lead to a dampening of the runoff events catchments with a uniform runoff reaction belong to region d the uniformly reactive region the events occurring in the catchments belonging to this region are generally characterized by slow rising and falling limbs high volumes and low peak discharges the catchments belonging to this region are rather large and mainly lie in the jura but also comprise a few large catchments in the swiss plateau they are characterized by an elongated shape karstic geology with permeable rock and a low network density these catchment properties lead to a damped runoff reaction that leads to similar flood events independent of the triggering mechanism and antecedent wetness the mean floods of the three event types for the catchments in the four regions could be mainly explained by catchment area and network density we found that random forest was a suitable approach for establishing a classification rule allowing for the assignment of an ungauged catchment to one of the four reactivity regions even though the misclassification error seems rather high with 45 however not all misclassification errors were equally serious since we dealt with ordered classes assigning a catchment of region a to region b for example was less severe than assigning it to region c because regions a and b were more similar than regions a and c most misclassification errors were related to placing a catchment into a neighboring region more specifically to placing a catchment belonging to region b into region c or vice versa these two classes were found to be difficult to distinguish using the classification rule one could argue that these two regions could be combined as this would reduce the number of classes and therewith also the misclassification error however this combining would also increase the heterogeneity of flood characteristics of catchments within the combined class which is not desirable for the sdh construction procedure we therefore decided to keep the four classes and to benefit from the characteristics of the output of the ensemble based random forest model the ensemble based method did not only provide a best class membership for a catchment but also probabilistic class memberships for each of the reactivity regions which could be used in regional sdh construction the weighting of estimates from different regions using the probabilistic region memberships helped to reduce the uncertainty related to misclassification and led to a reduction in the variability of the relative prediction error across catchments 5 2 regional event type specific sdh sets the four reactivity regions and the three event types were found to be useful for regional sdh construction since the events belonging to one event type within a region were found to be more similar than events belonging to another event type in the same region or the same event type in another region even though the individual data pools were not homogeneous in a statistical sense hosking and wallis 1997 they were still useful for regional flood frequency analysis the different regional data pools did neither show strongly different forms nor intensities of dependence even though grimaldi et al 2016 suggested that basins with different times of concentration and different soil uses might show different dependence structures this might be explained by the fact that the catchments under study were all located in the swiss lowlands or prealps which led to a certain similarity in land use and other catchment attributes high alpine catchments which were shown to have very low dependence between peak discharges and flood volumes due to a mix of flood types gaál et al 2015 were not considered in the analysis the regional sdh construction approach relied on an index flood procedure that is applicable in ungauged catchments the strongest explanatory variable for the index floods in the four regions was found to be catchment area which is in line with findings by blöschl and sivapalan 1997 who found that there is a clear tendency of mean annual floods per area to decrease with catchment area potentially this regional sdh construction approach can also be applied to catchments with only a few years of observations there the index floods could be derived from observed data and be combined with their regional growth curve furthermore information could also be extended temporally merz and blöschl 2008 by including historical information wetter 2017 which could potentially reduce the uncertainty in flood risk estimates kjeldsen et al 2014 the regional sdh construction approach was developed on a set of swiss catchments but can be extended to other geographical regions for which a large enough dataset is available to delineate meaningful regions and to fit region specific generalized linear models for the prediction of index floods however a few assumptions would need to be verified and possibly adjusted these comprise the number of flood reactivity regions the fitting of the classification rule the choice of catchment characteristics used in the classification model and the glm for the prediction of the index flood and the copula model used to model the dependence between peak discharges and hydrograph volumes the regionally estimated event type specific sdhs were compared to locally estimated event type specific sdhs this is not optimal since the locally estimated sdhs might not represent reliable estimates if they are estimated based on a very small flood sample still the relative error of regionalized estimates compared to local estimates was quantified to lie around 50 on average across the 163 study catchments the prediction errors were found to be generally higher for fast sdhs than for the intermediate and slow sdhs this might be related to the fact that the slow events are more homogeneous across regions and event types than the fast events which generally show a higher variability 6 conclusions the advantage of the event type specific sdh construction procedure proposed here compared to a catchment specific sdh construction procedure is that the three resulting sdhs provide us with a much better idea on the variability of potential design events they depict a range of potential design flood outcomes showing the uncertainty related to different processes that can potentially occur within a catchment this ensemble or set of design events can be used by engineers in hydraulic modeling or in a cost benefit analyses when designing reservoir storage the use of design flood ensembles in flood hazard mapping is advisable since flood peak attenuation varies with hydrograph magnitude and shape which could result in different water levels and flood extents this ensemble based design flood approach is a compromise between using a single best estimate design hydrograph and using a continuous simulation model for flood hazard mapping contrary to a best single estimate design hydrograph it allows for the representation of process variability and does not give a result that is elusively precise still compared to continuous models it does neither require the stochastic simulation of rainfall fields nor the calibration of a rainfall runoff model it has the advantage that it is easily applicable in ungauged catchments and circumvents the simulation of rainfall and assumptions related to its transformation into runoff however setting up a regional index flood model might require as much data as setting up a regional continuous simulation model the ensemble based design hydrograph approach proposed in this study makes a step from a pure statistical approach towards a process based method allowing for the representation of process variability in design flood estimation in ungauged catchments acknowledgments we thank the federal office for the environment foen for funding the project contract 13 0028 kp m285 0623 and for providing runoff measurement data the data used in this study are available upon order from the foen for the hydrological data of the federal stations the order form under http www bafu admin ch wasser 13462 13494 15076 index html lang de can be used the hydrological data of the cantonal stations can be ordered from the respective cantons we thank the two reviewers for their constructive feedback supplementary material supplementary material associated with this article can be found in the online version at 10 1016 j advwatres 2017 12 018 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
886,catchment classification poses a significant challenge to hydrology and hydrologic modeling restricting widespread transfer of knowledge from well studied sites the identification of important physical climatological or hydrologic attributes to varying degrees depending on application data availability has traditionally been the focus for catchment classification classification approaches are regularly assessed with regard to their ability to provide suitable hydrologic predictions commonly by transferring fitted hydrologic parameters at a data rich catchment to a data poor catchment deemed similar by the classification while such approaches to hydrology s grand challenges are intuitive they often ignore the most uncertain aspect of the process the model itself we explore catchment classification and parameter transferability and the concept of universal donor acceptor catchments we identify the implications of the assumption that the transfer of parameters between similar catchments is reciprocal i e non directional these concepts are considered through three case studies situated across multiple gradients that include model complexity process description and site characteristics case study results highlight that some catchments are more successfully used as donor catchments and others are better suited as acceptor catchments these results were observed for both black box and process consistent hydrologic models as well as for differing levels of catchment similarity therefore we suggest that similarity does not adequately satisfy the underlying assumptions being made in parameter regionalization approaches regardless of model appropriateness furthermore we suggest that the directionality of parameter transfer is an important factor in determining the success of parameter regionalization approaches keywords catchment classification runoff model transferability regionalization 1 introduction catchment classification the systematic arrangement of catchments into similar groups based on form and or function has the potential to be a powerful concept in our understanding and conceptualization of hydrologic processes and fundamental catchment characteristics across spatial and temporal scales mcdonnell and woods 2004 wagener et al 2007 as a tool classification enables an objective framework within which hydrologic experiments model conceptualization and model testing are conducted and or reconciled a key anticipated outcome of such an approach is the ability to produce improved model predictions this is of particular importance in catchments with no or limited data availability in this case the information at a data rich catchment can be shared with a similarly classified data poor catchment to leverage available information the scope of the predictions in ungauged basins problem is vast and concerns many aspects of hydrologic understanding and prediction sivapalan et al 2003 here we seek to focus on catchment classification and its frequent application in the context of predictions in ungauged basins hrachowitz et al 2013 under such scenarios it is commonly assumed that the attribute similarity of catchments physical climatological hydrological leads to a parameter similarity bárdossy 2007 classification information is typically exploited through a regionalization approach to obtain knowledge about an ungauged location such as hydrologic model parameters e g hundecha et al 2008 oudin et al 2008 di prinzio et al 2011 hydrologic function e g carrillo et al 2011 sawicz et al 2011 ye et al 2012 or catchment form winter 2001 e g leibowitz et al 2016 implicit in catchment classification and the associated regionalization studies is the concept of reciprocity a mutual exchange of information resources services etc if the catchments are reciprocal it should not matter which is acting as the donor supplying information and which is acting as the acceptor receiving information reciprocal catchments have a mutual non directional exchange of information this means that information from one catchment may be successfully transferred to any similarly classified catchment with minimized impact to the resulting model application many regionalization approaches are predicated on this assumption e g mcintyre et al 2005 oudin et al 2008 smith et al 2014 however it is probable that catchments differ in their ability to donate or accept model parameters within a classified group given the realities of model and observational errors as models are reconciled with data in this way individual catchments may be better considered as analogous to blood types a b ab o where the donor type controls the directionality of the transfer the inherent uncertainty associated with the hydrologic model itself e g process representation complexity etc will impact assumptions made in developing robust regionalization approaches using catchment classification tools indeed it is this disconnect between the mathematical model and catchment structure that has contributed to the lack of a reliable universal classification framework in modeling applications addressing such issues requires developing a better understanding of assumptions where they hold where they fail and how they propagate through the modeling process we sought to examine the underlying assumptions of catchment classification i e reciprocity through the lens of hydrologic model regionalization using direct parameter transfer we apply a cross validation approach considering gradients across model structures in terms of complexity process fidelity and diverse catchment settings in particular we were interested in addressing the questions does physical similarity in a broad sense guarantee parameter transfer reciprocity is there a relationship between physical and functional parameter similarity how do model complexity and realism affect the transferability of model parameter sets are any relationships identified consistent across diverse sets of catchments 2 analysis scenarios three scenarios were investigated to explore cases across gradients of catchment attributes and model realism scenarios 1 and 2 feature several well studied and highly monitored catchments located within the tenderfoot creek experimental forest in montana combined these scenarios explore the importance of model realism on the directionality of model parameter transferability scenario 3 features a widely used collection of catchments with basic hydrometric and catchment attribute data located in southeastern australia in conjunction with scenario 2 the importance of catchment attribute similarity on the direction of model parameter transferability is explored the directionality of model parameter transferability was considered within each scenario and across scenarios to leverage the combined results in each of the subsequent scenarios a group of catchments was identified that could be classified as being similar based on climate topography proximity vegetation or the parametric similarity of an optimized hydrologic model then a hydrologic model was selected to represent the perceived dominant hydrologic processes with different levels of realism based on our a priori knowledge the hydrologic model parameters were calibrated to observed streamflow at each individual catchment to be considered following this a leave one out transferability analysis was performed where each catchment was used in turn as a donor to the other catchments changes in model performance were tracked not only for the ability of a catchment to serve as a donor to other catchments but also for its ability to serve as a recipient from other catchments donor suitability was assessed based on an average reduction in nse where each catchment was benchmarked to its own site specific calibration such an approach allows for the validity of the assumption that catchment similarity is an effective surrogate for model parameter similarity to be considered if this assumption is valid it is expected that catchment performance should be similar when transferring model parameters to another similar catchment in both directions i e as donor and as recipient 2 1 scenario 1 process consistent model applied to tenderfoot creek experimental forest the tenderfoot creek experimental forest tcef located in montana usa encompasses an area of 22 8 km2 and is drained by tenderfoot creek a tributary to the smith river tcef lat 46 55 n long 1110 52 w fig 1 is a highly monitored research site where many previous scientific investigations have been conducted e g jencso et al 2009 jencso et al 2010 jencso and mcglynn 2011 nippgen et al 2011 payn et al 2009 2012 smith et al 2014 smith and marshall 2008 2010 tcef is a well suited research site to consider catchment classification due to the expansive detailed knowledge gained through collocated field and model based investigations in this scenario six sub catchments nested within the lower tenderfoot creek ltc catchment are considered bubbling creek bub lower stringer creek lsc middle stringer creek msc spring park creek spc sun creek sun and upper tenderfoot creek utc tcef has a historical mean annual temperature of 0 c and an average annual precipitation of 880 mm approximately 75 as snow for additional descriptions of the study area refer to jencso et al 2009 2010 jencso and mcglynn 2011 and nippgen et al 2011 the catchment connectivity model ccm smith et al 2013 2016 which was developed for use at tcef was applied to each of the seven tcef catchments the ccm simulates shallow groundwater connectivity by exploiting the empirical relationship between connectivity and hillslope size as upslope accumulated area observed at tcef jencso et al 2009 the storage within each hillslope is computed by mass balance and its connectivity to the stream is achieved when the storage exceeds a threshold value based on hillslope size as upslope accumulated area water is released from connected hillslopes as shallow groundwater at a rate equal to q a calibrated parameter only connected hillslopes contribute water to total discharge at the catchment outlet the ccm structure is a spatially explicit process verifiable three parameter hydrologic model table 1 is underpinned by the concept that the frequency of hydrologic connections of the hillslopes to the stream drives streamflow rather than the magnitude of any single hydrologic connection jencso et al 2009 the ccm model was implemented on a 6 hourly time step with model forcing data including snotel precipitation cf nippgen et al 2011 and eddy covariance derived evapotranspiration emanuel et al 2010 model calibration to streamflow data nippgen et al 2011 for the period of october 2005 through september 2009 at each catchment topographic data 10 m dems derived from 1 m lidar were used to determine catchment upslope accumulated areas uaa a model input shallow groundwater connectivity data jencso et al 2009 was utilized for independent model process verification ccm parameters were estimated using a monte carlo sampling approach e g kuczera and parent 1998 where 100 000 parameter sets were randomly sampled and the top 20 based on nash sutcliffe efficiency retained for additional model analysis initial parameter ranges were selected considering field based observations of parameter constraints following the findings presented in smith et al 2016 where such an approach was found to yield more physically consistent model simulations the average nash sutcliffe efficiency for the best performing ccm parameter set at each of the seven tcef catchments was 0 82 max 0 88 at ltc min 0 69 at utc using the site specific calibration performance as a benchmark for parameter transferability the average reduction in model performance was computed as a percent change nse 1 regional nse site nse this metric was produced for each catchment as both a parameter donor and a parameter acceptor fig 2 when the catchment is used as a donor this metric is calculated as the average change in fit across the other six tcef catchments each benchmarked to their own site specific nse when the catchment is used as an acceptor this metric is calculated as the average change in fit when utilizing the optimum parameter set from each of the other six tcef catchments again benchmarked to site specific nse to facilitate comparison an average reduction in model performance threshold of 10 was included to represent acceptable model performance degradation due to model transfer the ccm parameter transferability results fig 2 clearly refute the implicit assumption that model transferability is reciprocal i e if catchment a is a good donor for catchment b then catchment b will be a good donor for catchment a although variation is to be expected some catchments e g msc and lsc show a propensity for being acceptors and not donors while other catchments e g sun and utc show a propensity for being donors and not acceptors the remaining catchments e g ltc bub and spc exhibit a more equitable correspondence between donor and acceptor performance to understand the causes of these relationships we explored the parameter space for each of the site specific calibrations fig 3 the regions of high model performance hot colors are clearly variable from catchment to catchment both in terms of the location within the parameter space and the spread across the parameter space strong variabilities in terms of the range and location of suitable values are particularly noticeable across the catchments in terms of the parameter controlling the discharge of stored water from hydrologically connected hillslopes q catchments where model performance as nse was less sensitive to q e g lsc and msc were found to be well suited as parameter acceptors but poorly suited as parameter donors fig 2 this is a result of such catchments having a large range of q values resulting in good nse values but having optimal q values at non coincident locations in the parameter space relative to the other catchments the opposite was true for catchments where model performance was more sensitive to q e g sun and utc in these catchments the optimal parameter set to be donated to the other catchments correspond to areas of high model performance in the accepting catchments variability in the sensitivity of model performance to the stored water release parameter q has been linked to catchment structure specifically the distribution of catchment upslope accumulated area smith et al 2016 2 2 scenario 2 conceptual model applied to tenderfoot creek experimental forest the analysis presented in scenario 1 was repeated using the gr4j model perrin et al 2003 to understand the degree to which the model structure itself controls the transferability between catchments the gr4j model is a simple conceptual model 4 calibrated parameters table 2 based on soil moisture accounting and unit hydrograph theory that has been applied extensively and shown to perform well across a range of catchment conditions the gr4j model structure was selected to provide a distinct alternative to the ccm structure used in scenario 1 where ccm represents a specific runoff generating mechanism that is intrinsically linked to catchment form and condition and gr4j represents a structure aimed at flexibly representing a range of catchment conditions and hydrologic processes perrin et al 2003 the same catchments fig 1 input data and temporal resolution were maintained in this scenario gr4j parameters were estimated using a monte carlo sampling approach e g kuczera and parent 1998 where 100 000 parameter sets were randomly sampled and the top 20 based on nash sutcliffe efficiency retained for additional model analysis initial parameter ranges table 2 were selected based on the values suggested by perrin et al 2003 the average nash sutcliffe efficiency for the best performing gr4j parameter set at each of the seven tcef catchments was 0 83 max 0 87 at bub min 0 78 at sun although average gr4j model performance was comparable to ccm performance average nse 0 82 see scenario 1 it should be noted that the degree to which the gr4j reproduces the actual hydrological processes is unknown due to a lack of corroboration to other hydrologic variables conversely the fidelity of simulated hydrological processes at these catchments has been previously verified using auxiliary groundwater data utilizing the ccm applied in scenario 1 smith et al 2016 again the site specific calibration performance is utilized as a benchmark for gr4j parameter transferability and the average reduction in model performance as a percent change δnse 1 regional nse site nse was computed for each catchment as both a parameter donor and a parameter acceptor fig 4 the average reduction threshold of 10 was maintained to allow for direct comparison across the scenarios the gr4j parameter transferability results fig 4 demonstrate the same patterns as were observed in scenario 1 with some catchments e g msc and lsc acting as suitable acceptors and not donors other catchments e g sun and utc acting as suitable donors and not acceptors and the remaining catchments e g ltc bub and spc acting as mostly equitable donors and acceptors the parameter space dotty plots for each of the site specific calibrations fig 5 again highlighted a consistent variability in regions of high model performance from catchment to catchment in scenario 1 this variability was linked to the parameter controlling the discharge of stored water from hydrologically connected hillslopes q table 1 in this scenario the variability can be linked to the parameter controlling the maximum capacity of the soil moisture storage x 1 table 2 catchments where model performance as nse was less sensitive to x 1 e g lsc and msc were found to be well suited as parameter acceptors but poorly suited as parameter donors fig 4 the opposite was true for catchments where model performance was more sensitive to x 1 e g sun and utc in these catchments the optimal parameter set to be donated to the other catchments correspond to areas of high model performance in the accepting catchments variability in the sensitivity of model performance to the soil moisture storage capacity x 1 and subsequent release as percolation in the model structure a function of x 1 suggests catchment structure plays an important role in model parameterization even for models that lack an explicit connection to such information 2 3 scenario 3 conceptual model applied to collection of australian catchments in order to place the analysis from scenarios 1 and 2 into a broader context previous work by smith et al 2014 that explored the role of model parameter similarity on model transferability and uncertainty was extended to analyze transferability across a vastly different collection of catchments than was considered in scenarios 1 and 2 in their study smith et al 2014 applied the probability distributed model pdm moore 1985 to 118 catchments located across southeastern australia the pdm is a six parameter soil moisture accounting model table 3 capable of representing a wide range hydrologic conditions runoff production is controlled by the spatial variability of soil capacities across the catchment via a flexible probability distributed soil storage capacity and water is routed through two storages representing surface quick and subsurface slow response mechanisms to produce total streamflow smith et al 2014 sought to understand the value of donor catchments as a function of their similarity to the catchment of interest as a result they considered three donor catchment classifications random proximity and cluster that represented varying levels of classification information fig 6 random donors were simply selected at random from the collection of catchments proximity donors were selected based on distance from the target catchment and cluster donors were selected based on similarity of calibrated optimal pdm parameters where each parameter was given equal weight in the clustering in this scenario we repeated the transferability analysis utilized in the previous two scenarios across each of the three donor classifications from the study of smith et al to assess the degree to which parameter similarity influences reciprocal transferability between catchments and provide comparison points to the catchments studied in scenarios 1 and 2 the optimal pdm parameters were estimated using the dynamically dimensioned search dds algorithm tolson and shoemaker 2007 the average nash sutcliffe efficiency for each of the classification levels were 0 73 for cluster donors max 0 88 min 0 59 0 76 for proximity donors max 0 86 min 0 60 and 0 71 for random donors max 0 86 min 0 54 note that each group consists of 10 unique member catchments and 1 common catchment based on the conditions of smith et al 2014 as with the gr4j model performance from scenario 2 the degree to which hydrological processes were accurately simulated with the pdm at these catchments is uncertain despite reasonable performance across classification groups the average reduction in model performance as percent change in nse was computed for each classification group and each catchment as both a parameter donor and a parameter acceptor fig 7 catchment similarity from the random to proximity class directly impacts the magnitude of performance reduction fig 7a and b note individual subplot axes a reflection of the role that catchment similarity plays in parameter transferability in general and reciprocal transferability in particular an additional improvement in transferability is observed between the proximity and cluster based catchments fig 7b and c however improvements due to catchment similarity physical climatological characteristics fig 7a and b or model parameter similarity fig 7b and c do not provide a strict control on the reciprocity of such transfers in each grouping some catchments were more suitable as donors while others were more suitable as acceptors the degree to which that is true is a function of the sensitivity of the model performance to model parameter variability 3 discussion catchment classification provides a means within which the complexity of hydrologic systems can be organized to facilitate more fruitful applications and discovery for this ideal to be met however the assumptions of the classification must be satisfied i e the group members within the classification are functionally similar donor reciprocity is a simple concept inherent to most catchment classification approaches in the context of regionalization it simply represents the idea that once classified as similar the transfer of information between the catchments can occur in either direction with equivalent value in this study we have demonstrated through three scenarios across gradients of model realism and catchment attributes that parameters are not transferred bi directionally with equivalent results and that the directionality can be attributed to model sensitivities and uncertainties if the model and the classification were perfect the transferability of model parameters should be bi directional however model uncertainty as defined by parameter response surfaces has a confounding effect on the results what do these results suggest for the usefulness of the catchment classification from a modeling perspective 3 1 do similar catchments act as universal donors acceptors the catchments of the tenderfoot creek experimental forest receive the same climatological inputs and are similar in terms of most typical similarity metrics each has similar soils parent geology and vegetation as well as other physical characteristics e g relief elevation average slope area distance from creek gradient to creek etc given the apparent similarity of these catchments we sought to illustrate the directionality of information transfer from a model parameterization perspective extending the study of smith et al 2016 on parameter transferability of the process verifiable catchment connectivity model applied to the tenderfoot creek experimental forest we plotted 4d response surfaces fig 3 that clearly demonstrate the variability in the optimal parameter space across the similar neighboring catchments this analysis was repeated for the conceptual gr4j model fig 5 to better understand the results with respect to differences in model structures similar results were observed for both models tested strengthening the universality of the results from a classification regionalization perspective using a simple direct transfer of the optimal hydrologic model parameter set this parameter sensitivity variability will play a determining role in model performance at the target accepting catchment at tenderfoot creek experimental forest a transfer of the optimal parameter set from sun to lsc will result in marginal performance degradation while a transfer from lsc to sun will result in significant performance degradation figs 2 and 5 this directionality occurs due to the optimal parameter spaces not being coincident 3 2 is there a relationship between physical and functional parameter similarity the sensitivity of model parameters is directly linked to model structure and its errors and uncertainties unquestionably the use of conceptual rainfall runoff models presents a challenge with regard to regionalization approaches via catchment classification based on physical characteristics due to a lack of verifiable process consistency though this issue may persist despite model fidelity see scenario 1 the pub decadal initiative bore this out with no classification approach consistently outperforming another across diverse catchment datasets for regionalization hrachowitz et al 2013 this should necessarily reflect both the model structure and the assumptions of the regionalization approach as sources of great uncertainty smith et al 2014 present an alternative approach to classification where the typical regionalization problem was inverted rather than classifying catchments by physical characteristics they were instead classified by optimal parameter values such an approach where the analysis begins with the desired answer i e catchments with similar hydrologic performance fit and works backwards to the question i e does catchment classification by physical climatological or hydrological attributes work can be particularly instructive in better understanding the assumptions and limitations of the underlying methodology i e model regionalization the results suggest that catchment similarity can be predicted from a modeling perspective but that significant model error can result in sub optimal performance exploring this concept further we performed an additional analysis on the model simulations performed by smith et al 2014 who utilized a catchment classification approach that compared classes consisting of random members spatially proximal members and functionally proximal members using cluster analysis to group catchments with similar optimal parameterizations contrasting the conditions examined in scenarios 1 and 2 the catchments utilized here spanned a wide range of physical and climatological conditions particularly in the random and cluster selected catchments the lack of spatial proximity of the cluster selected catchments fig 6 in and of itself suggests that the link between model parameterization and catchment similarity is weak results from this analysis again demonstrated the directionality inherent to hydrologic model transferability fig 7 regardless of the similarity of the catchments or their optimal parameterization this indicates the weakness of single parameter set transfers in a regionalization context and suggests that including parameter variability uncertainty is a necessary component to achieve successful reliable transfer 3 3 how do model complexity and realism affect the transferability of model parameter sets three conceptual hydrologic models ccm gr4j and pdm were considered in this study although each had similar numbers of model parameters 3 4 and 6 respectively the models make unique assumptions that impact their complexity and realism holding the catchments constant scenarios 1 and 2 explored the impact of changing the model structure from the process verifiable ccm e g smith et al 2013 2016 to the black box implementation of the unit hydrograph based gr4j despite the differences in verifiable process fidelity both models resulted in sensitivities to parameters controlling the soil moisture accounting of the watersheds for the ccm the affected parameter q can be tied directly to the catchment structure the distribution of hillslope sizes i e the elements of the watershed upon which the model carries out computations in effect this allows for a priori identification of parameter sensitivity and therefore parameter transferability and this is the primary advantage process consistent models hold over more black box approaches where this information can only be obtained a posteriori based on the model parameterization as was found with scenario 2 3 4 are any relationships identified consistent across diverse sets of catchments when classifying catchments as similar using physical area topography shape etc climatological or hydrological signatures metrics there is an implicit assumption made namely that the relationship is reciprocal i e if catchment a and catchment b share the determining metric s catchment a can be used as a donor to catchment b and catchment b can be used as a donor to catchment a our findings indicate that this assumption is largely inappropriate we found that across multiple gradients hydrologic model complexity fidelity dominant runoff processes climate size degree of physical similarity degree of optimal parameter similarity figs 2 4 and 7 most catchments were ill suited as both donor and acceptor rather a subset of catchments was suitable only as donors while another subset was suitable only as acceptors ultimately parameter sensitivity controls the success and directionality of direct parameter transferability understanding the link between physical climatological characteristics and optimal hydrologic parameters remains a challenge this study better defines the domain of the problem and how such characteristics propagate into parameter sensitivity 4 conclusion catchment classification has long been viewed as a rosetta stone for hydrologic modeling representing the promise of unlocking the ability to transfer model information across space and time a key component in this thinking is the assumption that classification based on catchment properties yields similar model properties e g parameter values and while this is perhaps logical on the surface it necessarily ignores the uncertainties of the model and data as well as the potential for non reciprocal relationships to exist the results of this study highlight the potential pitfalls of classifying physical characteristics to inform the regionalization transfer of hydrologic model information the three test cases utilizing diverse data sets and hydrologic model selection approaches catchment specific v flexible provided examples across hydrologic conditions scale and detail we found that 1 belonging to a group of physically similar classified catchments is not sufficient to ensure the transfer of model information e g parameterization is reciprocal i e non directional 2 there is not a clear relationship between physical and functional i e parameter similarity due to model data uncertainty 3 the fidelity of the model structure to observed hydrologic functioning does little to affect the ability of catchments to serve as donors acceptors and 4 the lack of relationship between catchment similarity and model similarity is not data or site specific given these observations it is clear that while catchment classification has the potential to improve water resources management significant work remains in understanding the relationships between catchment form and hydrologic model functioning acknowledgments data for tenderfoot creek experimental forest can be obtained at request from the u s forest service http www fs fed us rm tenderfoot creek data for streamflow from the national resources conservation service http www wcc nrcs usda gov snow snotel data html for meteorological variables and from the national center for airborne laser mapping http dx doi org 10 5069 g92f7kcn for topography data for the australian catchments can be obtained at request from the australian bureau of meteorology http www bom gov au water hrs supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2017 12 020 appendix supplementary materials image application 1 
886,catchment classification poses a significant challenge to hydrology and hydrologic modeling restricting widespread transfer of knowledge from well studied sites the identification of important physical climatological or hydrologic attributes to varying degrees depending on application data availability has traditionally been the focus for catchment classification classification approaches are regularly assessed with regard to their ability to provide suitable hydrologic predictions commonly by transferring fitted hydrologic parameters at a data rich catchment to a data poor catchment deemed similar by the classification while such approaches to hydrology s grand challenges are intuitive they often ignore the most uncertain aspect of the process the model itself we explore catchment classification and parameter transferability and the concept of universal donor acceptor catchments we identify the implications of the assumption that the transfer of parameters between similar catchments is reciprocal i e non directional these concepts are considered through three case studies situated across multiple gradients that include model complexity process description and site characteristics case study results highlight that some catchments are more successfully used as donor catchments and others are better suited as acceptor catchments these results were observed for both black box and process consistent hydrologic models as well as for differing levels of catchment similarity therefore we suggest that similarity does not adequately satisfy the underlying assumptions being made in parameter regionalization approaches regardless of model appropriateness furthermore we suggest that the directionality of parameter transfer is an important factor in determining the success of parameter regionalization approaches keywords catchment classification runoff model transferability regionalization 1 introduction catchment classification the systematic arrangement of catchments into similar groups based on form and or function has the potential to be a powerful concept in our understanding and conceptualization of hydrologic processes and fundamental catchment characteristics across spatial and temporal scales mcdonnell and woods 2004 wagener et al 2007 as a tool classification enables an objective framework within which hydrologic experiments model conceptualization and model testing are conducted and or reconciled a key anticipated outcome of such an approach is the ability to produce improved model predictions this is of particular importance in catchments with no or limited data availability in this case the information at a data rich catchment can be shared with a similarly classified data poor catchment to leverage available information the scope of the predictions in ungauged basins problem is vast and concerns many aspects of hydrologic understanding and prediction sivapalan et al 2003 here we seek to focus on catchment classification and its frequent application in the context of predictions in ungauged basins hrachowitz et al 2013 under such scenarios it is commonly assumed that the attribute similarity of catchments physical climatological hydrological leads to a parameter similarity bárdossy 2007 classification information is typically exploited through a regionalization approach to obtain knowledge about an ungauged location such as hydrologic model parameters e g hundecha et al 2008 oudin et al 2008 di prinzio et al 2011 hydrologic function e g carrillo et al 2011 sawicz et al 2011 ye et al 2012 or catchment form winter 2001 e g leibowitz et al 2016 implicit in catchment classification and the associated regionalization studies is the concept of reciprocity a mutual exchange of information resources services etc if the catchments are reciprocal it should not matter which is acting as the donor supplying information and which is acting as the acceptor receiving information reciprocal catchments have a mutual non directional exchange of information this means that information from one catchment may be successfully transferred to any similarly classified catchment with minimized impact to the resulting model application many regionalization approaches are predicated on this assumption e g mcintyre et al 2005 oudin et al 2008 smith et al 2014 however it is probable that catchments differ in their ability to donate or accept model parameters within a classified group given the realities of model and observational errors as models are reconciled with data in this way individual catchments may be better considered as analogous to blood types a b ab o where the donor type controls the directionality of the transfer the inherent uncertainty associated with the hydrologic model itself e g process representation complexity etc will impact assumptions made in developing robust regionalization approaches using catchment classification tools indeed it is this disconnect between the mathematical model and catchment structure that has contributed to the lack of a reliable universal classification framework in modeling applications addressing such issues requires developing a better understanding of assumptions where they hold where they fail and how they propagate through the modeling process we sought to examine the underlying assumptions of catchment classification i e reciprocity through the lens of hydrologic model regionalization using direct parameter transfer we apply a cross validation approach considering gradients across model structures in terms of complexity process fidelity and diverse catchment settings in particular we were interested in addressing the questions does physical similarity in a broad sense guarantee parameter transfer reciprocity is there a relationship between physical and functional parameter similarity how do model complexity and realism affect the transferability of model parameter sets are any relationships identified consistent across diverse sets of catchments 2 analysis scenarios three scenarios were investigated to explore cases across gradients of catchment attributes and model realism scenarios 1 and 2 feature several well studied and highly monitored catchments located within the tenderfoot creek experimental forest in montana combined these scenarios explore the importance of model realism on the directionality of model parameter transferability scenario 3 features a widely used collection of catchments with basic hydrometric and catchment attribute data located in southeastern australia in conjunction with scenario 2 the importance of catchment attribute similarity on the direction of model parameter transferability is explored the directionality of model parameter transferability was considered within each scenario and across scenarios to leverage the combined results in each of the subsequent scenarios a group of catchments was identified that could be classified as being similar based on climate topography proximity vegetation or the parametric similarity of an optimized hydrologic model then a hydrologic model was selected to represent the perceived dominant hydrologic processes with different levels of realism based on our a priori knowledge the hydrologic model parameters were calibrated to observed streamflow at each individual catchment to be considered following this a leave one out transferability analysis was performed where each catchment was used in turn as a donor to the other catchments changes in model performance were tracked not only for the ability of a catchment to serve as a donor to other catchments but also for its ability to serve as a recipient from other catchments donor suitability was assessed based on an average reduction in nse where each catchment was benchmarked to its own site specific calibration such an approach allows for the validity of the assumption that catchment similarity is an effective surrogate for model parameter similarity to be considered if this assumption is valid it is expected that catchment performance should be similar when transferring model parameters to another similar catchment in both directions i e as donor and as recipient 2 1 scenario 1 process consistent model applied to tenderfoot creek experimental forest the tenderfoot creek experimental forest tcef located in montana usa encompasses an area of 22 8 km2 and is drained by tenderfoot creek a tributary to the smith river tcef lat 46 55 n long 1110 52 w fig 1 is a highly monitored research site where many previous scientific investigations have been conducted e g jencso et al 2009 jencso et al 2010 jencso and mcglynn 2011 nippgen et al 2011 payn et al 2009 2012 smith et al 2014 smith and marshall 2008 2010 tcef is a well suited research site to consider catchment classification due to the expansive detailed knowledge gained through collocated field and model based investigations in this scenario six sub catchments nested within the lower tenderfoot creek ltc catchment are considered bubbling creek bub lower stringer creek lsc middle stringer creek msc spring park creek spc sun creek sun and upper tenderfoot creek utc tcef has a historical mean annual temperature of 0 c and an average annual precipitation of 880 mm approximately 75 as snow for additional descriptions of the study area refer to jencso et al 2009 2010 jencso and mcglynn 2011 and nippgen et al 2011 the catchment connectivity model ccm smith et al 2013 2016 which was developed for use at tcef was applied to each of the seven tcef catchments the ccm simulates shallow groundwater connectivity by exploiting the empirical relationship between connectivity and hillslope size as upslope accumulated area observed at tcef jencso et al 2009 the storage within each hillslope is computed by mass balance and its connectivity to the stream is achieved when the storage exceeds a threshold value based on hillslope size as upslope accumulated area water is released from connected hillslopes as shallow groundwater at a rate equal to q a calibrated parameter only connected hillslopes contribute water to total discharge at the catchment outlet the ccm structure is a spatially explicit process verifiable three parameter hydrologic model table 1 is underpinned by the concept that the frequency of hydrologic connections of the hillslopes to the stream drives streamflow rather than the magnitude of any single hydrologic connection jencso et al 2009 the ccm model was implemented on a 6 hourly time step with model forcing data including snotel precipitation cf nippgen et al 2011 and eddy covariance derived evapotranspiration emanuel et al 2010 model calibration to streamflow data nippgen et al 2011 for the period of october 2005 through september 2009 at each catchment topographic data 10 m dems derived from 1 m lidar were used to determine catchment upslope accumulated areas uaa a model input shallow groundwater connectivity data jencso et al 2009 was utilized for independent model process verification ccm parameters were estimated using a monte carlo sampling approach e g kuczera and parent 1998 where 100 000 parameter sets were randomly sampled and the top 20 based on nash sutcliffe efficiency retained for additional model analysis initial parameter ranges were selected considering field based observations of parameter constraints following the findings presented in smith et al 2016 where such an approach was found to yield more physically consistent model simulations the average nash sutcliffe efficiency for the best performing ccm parameter set at each of the seven tcef catchments was 0 82 max 0 88 at ltc min 0 69 at utc using the site specific calibration performance as a benchmark for parameter transferability the average reduction in model performance was computed as a percent change nse 1 regional nse site nse this metric was produced for each catchment as both a parameter donor and a parameter acceptor fig 2 when the catchment is used as a donor this metric is calculated as the average change in fit across the other six tcef catchments each benchmarked to their own site specific nse when the catchment is used as an acceptor this metric is calculated as the average change in fit when utilizing the optimum parameter set from each of the other six tcef catchments again benchmarked to site specific nse to facilitate comparison an average reduction in model performance threshold of 10 was included to represent acceptable model performance degradation due to model transfer the ccm parameter transferability results fig 2 clearly refute the implicit assumption that model transferability is reciprocal i e if catchment a is a good donor for catchment b then catchment b will be a good donor for catchment a although variation is to be expected some catchments e g msc and lsc show a propensity for being acceptors and not donors while other catchments e g sun and utc show a propensity for being donors and not acceptors the remaining catchments e g ltc bub and spc exhibit a more equitable correspondence between donor and acceptor performance to understand the causes of these relationships we explored the parameter space for each of the site specific calibrations fig 3 the regions of high model performance hot colors are clearly variable from catchment to catchment both in terms of the location within the parameter space and the spread across the parameter space strong variabilities in terms of the range and location of suitable values are particularly noticeable across the catchments in terms of the parameter controlling the discharge of stored water from hydrologically connected hillslopes q catchments where model performance as nse was less sensitive to q e g lsc and msc were found to be well suited as parameter acceptors but poorly suited as parameter donors fig 2 this is a result of such catchments having a large range of q values resulting in good nse values but having optimal q values at non coincident locations in the parameter space relative to the other catchments the opposite was true for catchments where model performance was more sensitive to q e g sun and utc in these catchments the optimal parameter set to be donated to the other catchments correspond to areas of high model performance in the accepting catchments variability in the sensitivity of model performance to the stored water release parameter q has been linked to catchment structure specifically the distribution of catchment upslope accumulated area smith et al 2016 2 2 scenario 2 conceptual model applied to tenderfoot creek experimental forest the analysis presented in scenario 1 was repeated using the gr4j model perrin et al 2003 to understand the degree to which the model structure itself controls the transferability between catchments the gr4j model is a simple conceptual model 4 calibrated parameters table 2 based on soil moisture accounting and unit hydrograph theory that has been applied extensively and shown to perform well across a range of catchment conditions the gr4j model structure was selected to provide a distinct alternative to the ccm structure used in scenario 1 where ccm represents a specific runoff generating mechanism that is intrinsically linked to catchment form and condition and gr4j represents a structure aimed at flexibly representing a range of catchment conditions and hydrologic processes perrin et al 2003 the same catchments fig 1 input data and temporal resolution were maintained in this scenario gr4j parameters were estimated using a monte carlo sampling approach e g kuczera and parent 1998 where 100 000 parameter sets were randomly sampled and the top 20 based on nash sutcliffe efficiency retained for additional model analysis initial parameter ranges table 2 were selected based on the values suggested by perrin et al 2003 the average nash sutcliffe efficiency for the best performing gr4j parameter set at each of the seven tcef catchments was 0 83 max 0 87 at bub min 0 78 at sun although average gr4j model performance was comparable to ccm performance average nse 0 82 see scenario 1 it should be noted that the degree to which the gr4j reproduces the actual hydrological processes is unknown due to a lack of corroboration to other hydrologic variables conversely the fidelity of simulated hydrological processes at these catchments has been previously verified using auxiliary groundwater data utilizing the ccm applied in scenario 1 smith et al 2016 again the site specific calibration performance is utilized as a benchmark for gr4j parameter transferability and the average reduction in model performance as a percent change δnse 1 regional nse site nse was computed for each catchment as both a parameter donor and a parameter acceptor fig 4 the average reduction threshold of 10 was maintained to allow for direct comparison across the scenarios the gr4j parameter transferability results fig 4 demonstrate the same patterns as were observed in scenario 1 with some catchments e g msc and lsc acting as suitable acceptors and not donors other catchments e g sun and utc acting as suitable donors and not acceptors and the remaining catchments e g ltc bub and spc acting as mostly equitable donors and acceptors the parameter space dotty plots for each of the site specific calibrations fig 5 again highlighted a consistent variability in regions of high model performance from catchment to catchment in scenario 1 this variability was linked to the parameter controlling the discharge of stored water from hydrologically connected hillslopes q table 1 in this scenario the variability can be linked to the parameter controlling the maximum capacity of the soil moisture storage x 1 table 2 catchments where model performance as nse was less sensitive to x 1 e g lsc and msc were found to be well suited as parameter acceptors but poorly suited as parameter donors fig 4 the opposite was true for catchments where model performance was more sensitive to x 1 e g sun and utc in these catchments the optimal parameter set to be donated to the other catchments correspond to areas of high model performance in the accepting catchments variability in the sensitivity of model performance to the soil moisture storage capacity x 1 and subsequent release as percolation in the model structure a function of x 1 suggests catchment structure plays an important role in model parameterization even for models that lack an explicit connection to such information 2 3 scenario 3 conceptual model applied to collection of australian catchments in order to place the analysis from scenarios 1 and 2 into a broader context previous work by smith et al 2014 that explored the role of model parameter similarity on model transferability and uncertainty was extended to analyze transferability across a vastly different collection of catchments than was considered in scenarios 1 and 2 in their study smith et al 2014 applied the probability distributed model pdm moore 1985 to 118 catchments located across southeastern australia the pdm is a six parameter soil moisture accounting model table 3 capable of representing a wide range hydrologic conditions runoff production is controlled by the spatial variability of soil capacities across the catchment via a flexible probability distributed soil storage capacity and water is routed through two storages representing surface quick and subsurface slow response mechanisms to produce total streamflow smith et al 2014 sought to understand the value of donor catchments as a function of their similarity to the catchment of interest as a result they considered three donor catchment classifications random proximity and cluster that represented varying levels of classification information fig 6 random donors were simply selected at random from the collection of catchments proximity donors were selected based on distance from the target catchment and cluster donors were selected based on similarity of calibrated optimal pdm parameters where each parameter was given equal weight in the clustering in this scenario we repeated the transferability analysis utilized in the previous two scenarios across each of the three donor classifications from the study of smith et al to assess the degree to which parameter similarity influences reciprocal transferability between catchments and provide comparison points to the catchments studied in scenarios 1 and 2 the optimal pdm parameters were estimated using the dynamically dimensioned search dds algorithm tolson and shoemaker 2007 the average nash sutcliffe efficiency for each of the classification levels were 0 73 for cluster donors max 0 88 min 0 59 0 76 for proximity donors max 0 86 min 0 60 and 0 71 for random donors max 0 86 min 0 54 note that each group consists of 10 unique member catchments and 1 common catchment based on the conditions of smith et al 2014 as with the gr4j model performance from scenario 2 the degree to which hydrological processes were accurately simulated with the pdm at these catchments is uncertain despite reasonable performance across classification groups the average reduction in model performance as percent change in nse was computed for each classification group and each catchment as both a parameter donor and a parameter acceptor fig 7 catchment similarity from the random to proximity class directly impacts the magnitude of performance reduction fig 7a and b note individual subplot axes a reflection of the role that catchment similarity plays in parameter transferability in general and reciprocal transferability in particular an additional improvement in transferability is observed between the proximity and cluster based catchments fig 7b and c however improvements due to catchment similarity physical climatological characteristics fig 7a and b or model parameter similarity fig 7b and c do not provide a strict control on the reciprocity of such transfers in each grouping some catchments were more suitable as donors while others were more suitable as acceptors the degree to which that is true is a function of the sensitivity of the model performance to model parameter variability 3 discussion catchment classification provides a means within which the complexity of hydrologic systems can be organized to facilitate more fruitful applications and discovery for this ideal to be met however the assumptions of the classification must be satisfied i e the group members within the classification are functionally similar donor reciprocity is a simple concept inherent to most catchment classification approaches in the context of regionalization it simply represents the idea that once classified as similar the transfer of information between the catchments can occur in either direction with equivalent value in this study we have demonstrated through three scenarios across gradients of model realism and catchment attributes that parameters are not transferred bi directionally with equivalent results and that the directionality can be attributed to model sensitivities and uncertainties if the model and the classification were perfect the transferability of model parameters should be bi directional however model uncertainty as defined by parameter response surfaces has a confounding effect on the results what do these results suggest for the usefulness of the catchment classification from a modeling perspective 3 1 do similar catchments act as universal donors acceptors the catchments of the tenderfoot creek experimental forest receive the same climatological inputs and are similar in terms of most typical similarity metrics each has similar soils parent geology and vegetation as well as other physical characteristics e g relief elevation average slope area distance from creek gradient to creek etc given the apparent similarity of these catchments we sought to illustrate the directionality of information transfer from a model parameterization perspective extending the study of smith et al 2016 on parameter transferability of the process verifiable catchment connectivity model applied to the tenderfoot creek experimental forest we plotted 4d response surfaces fig 3 that clearly demonstrate the variability in the optimal parameter space across the similar neighboring catchments this analysis was repeated for the conceptual gr4j model fig 5 to better understand the results with respect to differences in model structures similar results were observed for both models tested strengthening the universality of the results from a classification regionalization perspective using a simple direct transfer of the optimal hydrologic model parameter set this parameter sensitivity variability will play a determining role in model performance at the target accepting catchment at tenderfoot creek experimental forest a transfer of the optimal parameter set from sun to lsc will result in marginal performance degradation while a transfer from lsc to sun will result in significant performance degradation figs 2 and 5 this directionality occurs due to the optimal parameter spaces not being coincident 3 2 is there a relationship between physical and functional parameter similarity the sensitivity of model parameters is directly linked to model structure and its errors and uncertainties unquestionably the use of conceptual rainfall runoff models presents a challenge with regard to regionalization approaches via catchment classification based on physical characteristics due to a lack of verifiable process consistency though this issue may persist despite model fidelity see scenario 1 the pub decadal initiative bore this out with no classification approach consistently outperforming another across diverse catchment datasets for regionalization hrachowitz et al 2013 this should necessarily reflect both the model structure and the assumptions of the regionalization approach as sources of great uncertainty smith et al 2014 present an alternative approach to classification where the typical regionalization problem was inverted rather than classifying catchments by physical characteristics they were instead classified by optimal parameter values such an approach where the analysis begins with the desired answer i e catchments with similar hydrologic performance fit and works backwards to the question i e does catchment classification by physical climatological or hydrological attributes work can be particularly instructive in better understanding the assumptions and limitations of the underlying methodology i e model regionalization the results suggest that catchment similarity can be predicted from a modeling perspective but that significant model error can result in sub optimal performance exploring this concept further we performed an additional analysis on the model simulations performed by smith et al 2014 who utilized a catchment classification approach that compared classes consisting of random members spatially proximal members and functionally proximal members using cluster analysis to group catchments with similar optimal parameterizations contrasting the conditions examined in scenarios 1 and 2 the catchments utilized here spanned a wide range of physical and climatological conditions particularly in the random and cluster selected catchments the lack of spatial proximity of the cluster selected catchments fig 6 in and of itself suggests that the link between model parameterization and catchment similarity is weak results from this analysis again demonstrated the directionality inherent to hydrologic model transferability fig 7 regardless of the similarity of the catchments or their optimal parameterization this indicates the weakness of single parameter set transfers in a regionalization context and suggests that including parameter variability uncertainty is a necessary component to achieve successful reliable transfer 3 3 how do model complexity and realism affect the transferability of model parameter sets three conceptual hydrologic models ccm gr4j and pdm were considered in this study although each had similar numbers of model parameters 3 4 and 6 respectively the models make unique assumptions that impact their complexity and realism holding the catchments constant scenarios 1 and 2 explored the impact of changing the model structure from the process verifiable ccm e g smith et al 2013 2016 to the black box implementation of the unit hydrograph based gr4j despite the differences in verifiable process fidelity both models resulted in sensitivities to parameters controlling the soil moisture accounting of the watersheds for the ccm the affected parameter q can be tied directly to the catchment structure the distribution of hillslope sizes i e the elements of the watershed upon which the model carries out computations in effect this allows for a priori identification of parameter sensitivity and therefore parameter transferability and this is the primary advantage process consistent models hold over more black box approaches where this information can only be obtained a posteriori based on the model parameterization as was found with scenario 2 3 4 are any relationships identified consistent across diverse sets of catchments when classifying catchments as similar using physical area topography shape etc climatological or hydrological signatures metrics there is an implicit assumption made namely that the relationship is reciprocal i e if catchment a and catchment b share the determining metric s catchment a can be used as a donor to catchment b and catchment b can be used as a donor to catchment a our findings indicate that this assumption is largely inappropriate we found that across multiple gradients hydrologic model complexity fidelity dominant runoff processes climate size degree of physical similarity degree of optimal parameter similarity figs 2 4 and 7 most catchments were ill suited as both donor and acceptor rather a subset of catchments was suitable only as donors while another subset was suitable only as acceptors ultimately parameter sensitivity controls the success and directionality of direct parameter transferability understanding the link between physical climatological characteristics and optimal hydrologic parameters remains a challenge this study better defines the domain of the problem and how such characteristics propagate into parameter sensitivity 4 conclusion catchment classification has long been viewed as a rosetta stone for hydrologic modeling representing the promise of unlocking the ability to transfer model information across space and time a key component in this thinking is the assumption that classification based on catchment properties yields similar model properties e g parameter values and while this is perhaps logical on the surface it necessarily ignores the uncertainties of the model and data as well as the potential for non reciprocal relationships to exist the results of this study highlight the potential pitfalls of classifying physical characteristics to inform the regionalization transfer of hydrologic model information the three test cases utilizing diverse data sets and hydrologic model selection approaches catchment specific v flexible provided examples across hydrologic conditions scale and detail we found that 1 belonging to a group of physically similar classified catchments is not sufficient to ensure the transfer of model information e g parameterization is reciprocal i e non directional 2 there is not a clear relationship between physical and functional i e parameter similarity due to model data uncertainty 3 the fidelity of the model structure to observed hydrologic functioning does little to affect the ability of catchments to serve as donors acceptors and 4 the lack of relationship between catchment similarity and model similarity is not data or site specific given these observations it is clear that while catchment classification has the potential to improve water resources management significant work remains in understanding the relationships between catchment form and hydrologic model functioning acknowledgments data for tenderfoot creek experimental forest can be obtained at request from the u s forest service http www fs fed us rm tenderfoot creek data for streamflow from the national resources conservation service http www wcc nrcs usda gov snow snotel data html for meteorological variables and from the national center for airborne laser mapping http dx doi org 10 5069 g92f7kcn for topography data for the australian catchments can be obtained at request from the australian bureau of meteorology http www bom gov au water hrs supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2017 12 020 appendix supplementary materials image application 1 
887,mine waste rock dumps have highly variable flowpaths caused by contrasting textures and geometry of materials laid down during the plug dumping process numerical experiments were conducted to investigate how these characteristics control unsaturated zone flow and transport hypothetical profiles of inner lift structure were generated with multiple point statistics and populated with hydraulic parameters of a finer and coarser material early arrival of water and solutes at the bottom of the lifts was observed after spring snowmelt the leaching efficiency a measure of the proportion of a resident solute that is flushed out of the rock via infiltrating snowmelt or rainfall was consistently high but modified by the structure and texture of the lift under high rates of net percolation during snowmelt preferential flow was generated in coarse textured part of the rock and solutes in the fine textured parts of the rock remained stagnant under lower rates of net percolation during the summer and fall finer materialswere flushed too and the spatial variability of solute concentration in the lift was reduced layering of lifts leads to lower flow rates at depth minimizing preferential flow and increased leaching of resident solutes these findings highlight the limited role of large scale connected geometries on focusing flow and transport under dynamic surface net percolation conditions as such our findings agree with recent numerical results from soil studies with gaussian connected geometries as well as recent experimental findings emphasizing the dominant role of matrix flow and high leaching efficiency in large waste rock dumps keywords unsaturated preferential flow stochastic pattern generation solute leaching mine waste rock dumps 1 introduction surface mining operations generate large volumes of coarse textured waste rock which is placed in large above ground dumps that remain unsaturated these dumps often contain readily soluble and mobile chemicals referred to here as constituents of interest or cis associated with initial blasting and deposition such as nitrate bailey et al 2013 in addition oxygen ingress can lead to rapid weathering of these deposits and the concomitant generation of additional cis which are transported from the pile by water migration through the waste rock waste rock effluent can have a detrimental impact on downstream environments for many decades following dump construction and consequently poses environmental risks to adjacent groundwater and surface water morin and hutt 1997 lottermoser 2010 amos et al 2015 a thorough understanding of the dynamics of water flow through waste rock piles is central to interpreting and estimating removal rates of cis associated with water migration through these dumps smith and beckie 2003 the combination of contrasting textures and complex structures i e arrangements of materials and generally unsaturated conditions creates flowpaths that are highly variable in space and time and difficult to monitor and predict while there is ample evidence of preferential or non capillary flow playing an important role in water flow and solute transport through waste rock dumps e g harries and ritchie 1985 eriksson and destouni 1997 stockwell et al 2006 blackmore et al 2014 an increasing number of studies have found that even coarse textured dumps may have a particle size distribution that promotes capillarity and matrix dominated water flow and transport eriksson et al 1997 nichol et al 2005 webb et al 2008 neuner et al 2013 barbour et al 2016 the dominant flow process may vary between dumps as well as in time meaning that the flow mechanisms need to be represented carefully when simulating flow and transport for a particular dump particle sizes within dumps may range over four to six orders of magnitude from clay particles to boulders anterrieu et al 2010 stockwell et al 2006 martin et al 2005 the various construction methods arrange these different textural fractions in random isolated zones or continuous highly connected features within the dumps for example the pushing of waste rock over an angle of repose face can create dipping layers of coarser and finer deposits aubertin et al 2005 azam et al 2007 and the levelling of benches or lifts of waste rock in preparation for subsequent dumping creates horizontal compacted layers fala et al 2003 high degrees of spatial and temporal variability of water content and pore water concentrations imply dynamic and heterogeneous flow paths whilst high leaching efficiencies imply homogeneous piston type flow reconciling both high variability and high leaching efficiency is a key question in these studies of large waste rock dumps the role of geometrical patterns within dumps in trapping or preferentially removing cis remains poorly understood it is widely recognized that in deep subsurface geologic formations special attention should be paid to connected features that concentrate flow and reduce travel times knudby and carrera 2005 renard and allard 2013 near surface geologic formations and particularly unsaturated soils are considered more randomly heterogeneous nielsen et al 1973 kolterman and gorelick 1996 botros et al 2009 while a considerable amount of work has been done on flow and transport in gaussian bimodal heterogeneous formations e g russo et al 2001 russo 2005 2010 2012 few unsaturated zone studies have addressed the effects of connectivity on flow and transport beyond features such as macropores or cracks an exception being russo 2015 in saturated formations where high hydraulic conductivity materials are geometrically connected the effective hydraulic conductivity of the formation can be larger than the geometric mean of the conductivity in the formation zinn and harvey 2003 knudby and carrera 2005 in unsaturated formations with a similar geometric connection channeling of flow not only depends on the spatial variability of the soil hydraulic properties but also on temporal variations in flow rate which cause the dominant flow path to switch between higher and lower capillarity pores or macropores yeh et al 1985 neuweiler and cirpka 2005 neuweiler and vogel 2007 beven and germann 2013 connectivity of transport and flow are typically correlated though the strength of the correlation depends on material geometry and flow properties knudby and carrera 2005 transport connectivity i e existence of paths of early solute arrival is mainly controlled by the existence of narrow possibly discontinuous high conductivity paths and much less by barriers which control flow connectivity knudby and carrera 2005 russo 2015 in this study we investigate the high variability in water content and solute concentration and the simultaneous high leaching efficiencies that are typical features of waste rock dumps we use exploratory numerical experiments applied to a semi hypothetical lift in a mine waste rock dump our study is inspired by experimental work in waste rock dumps in canada where snowfall and snowmelt are important hydrological events barbour et al 2016 we hypothesize that i it is possible to model high spatial and temporal variability in solute concentrations and high leaching efficiencies simultaneously by considering geometrically connected patterns of two distinct materials with contrasting texture ii the high variability in water contents solute concentration is related to the internal geometry created during dump construction and iii that the high leaching efficiency is due to the large variation in percolation rates in different seasons that results in switching of flowpaths between finer and coarser domains the spatial patterns were generated with a multiple point statistical algorithm filtersim to simulate non gaussian geometrical connectivity in a lift created by the free dumping of materials in individual heaps plug dumping this type of random field generation has not been used in waste rock studies before we interpret the simulation results from a connectivity perspective and reflect on implications for multi lift waste rock dumps 2 methods 2 1 the numerical model water flow and solute transport were solved with the finite element code hydrus 2d šimůnek et al 2012 the two dimensional richards equation is given by 1 θ t x k ψ ψ x z k ψ ψ z 1 where θ is the volumetric water content ψ is the pressure head m k ψ is the hydraulic conductivity function m d 1 t is time d and x and z are horizontal and depth coordinates m the relationships between k ψ and θ were established with the van genuchten mualem functions van genuchten 1980 2 s e ψ θ ψ θ r θ s θ r 1 α ψ n m 3 k ψ k s s e l 1 1 s e 1 m m 2 where se ψ is the relative saturation ks is the saturated hydraulic conductivity m d 1 θs and θr are the saturated and residual volumetric water content respectively α m 1 m and n are empirical parameters dependent on soil type with m 1 1 n and l denotes a tortuosity factor that was set to 0 5 the advection dispersion equation describing the transport of a conservative solute that is not subject to sorption or degradation is given by 4 θ c t v x θ c x v z θ c z d i j θ 2 c x 2 2 c z 2 where c is the solute concentration in the liquid phase g m 3 v x and v z are the mean pore water velocities m d 1 in the horizontal and vertical direction respectively and d ij is the dispersion coefficient tensor m2 d 1 the latter is given by 5 θ d i j α l v δ i j α l α t v x v z v θ d e τ δ i j where α l and α t are the longitudinal and transversal dispersivity respectively m v is the magnitude of the pore water velocity m d 1 de is the molecular diffusion coefficient m2 d 1 τ is a tortuosity factor millington and quirk 1961 and δ ij is the kronecker delta 2 2 characteristics of the mine waste rock in the mining environment of interest for this study particle size distributions may be unimodal bimodal or multimodal e g smith et al 2013 amos et al 2015 a uni or multivariate gaussian distribution is not always the most appropriate representation as shown in conceptual models of dump structure proposed by aubertin et al 2005 and poisson et al 2009 it is often possible to identify strongly discontinuous zones for an example see fig 5 in poisson et al 2009 of segregated and non segregated materials therefore a bimodal distribution whereby the rock is comprised of two distinct materials one finer and one coarser is the simplest conceptualization that is able to capture the discontinuity of materials stochastically generated variability can be added to account for smaller scale soil heterogeneity similar assumptions have been made in numerical models by russo et al 2001 2005 2010 2012 2015 and fala et al 2013 this conceptualization does not include small features on the extremity of the permeability spectrum such as fractures and cracks or clay lenses 2 2 1 soil structural variability structure formed as a result of the spatial distribution of the two textural classes was generated by creating two dimensional random fields with the filtersim algorithm one of the multiple point statistics mps simulation algorithms in the sgems toolbox for matlab wu et al 2008a b mps is an alternate approach to geostatistics that uses a training image instead of a variogram built on two point correlations to estimate the conditional probability at interpolation locations given observed and already interpolated data guardiano and srivastava 1993 the models characterizing the image are parameterized with proportion scale and anisotropy of the variable in the image instead of the sill range and nugget that parameterize variogram models guardiano and srivastava 1993 the main advantage of mps algorithms is their ability to reproduce complex geometric shapes while preserving horizontal and vertical extent orientation and connectivity because the simulations are not restricted by two point correlations wu et al 2008a b the filtersim algorithm classifies all spatial patterns of a designated size in a training image ti with general linear filters the patterns are classified into bins according to how their filter scores meet a similarity and distance criterion a pattern template or prototype is determined for each bin class after this learning phase a new random image is constructed by generating a random sequence of points in the desired domain as in any sequential simulation and selecting one pattern from the library for each point this selection is either based on the class of the closest conditioning point in the grid e g well data or performed randomly for unconditional simulations the filtersim algorithm is fast because the dimensionality of the problem is reduced by creating filter summaries of all patterns that can be found in an image filtersim is applicable on continuous datasets though the performance of the algorithm can be limited because of its reliance on linear filters that may not be able to represent all geometries properly represented we consider a synthetic lift created by plug dumping fig 1 which is the free dumping of material with trucks in the form of individual heaps of material 2 to 5 m in height after each lift is placed it is leveled to create a horizontal surface fala et al 2003 based on a reference photograph of material from a dumping operation fig 1 a schematic vertical cross section of a lift was constructed to serve as a training image for the generation of 2d spatial distributions of two textural classes with the filtersim algorithm wu et al 2008a the training image fig 2 a contained a stand alone coarser dipping lense coarser dipping lenses that are connected to coarser materials forming the base of some individual heaps coarser lenses enveloping large blobs of finer material and places where the coarser outer layers of heaps touch each other we assumed that the space between the heaps is filled during the levelling process where the coarser materials separate out more towards the bottom of the lifts the result is a schematic with dipping coarser lenses of varying length and connectivity to other lenses fig 2a we used this schematic cross section as a training image for the generation of 2d spatial distributions of two textural classes with the filtersim algorithm wu et al 2008a the generated lifts fig 2b were 30 m wide and 6 m tall and covered at the top with a 0 25 m storage layer with an artificially high porosity table 1 to prevent runoff generation during the spring freshet the statistical consistency of the sample size was tested with a jackknife analysis of the outflow signal of the lifts we considered the mean and variance of the daily outflow rate for each sample size when differences in mean and variance between sample sets were smaller than 0 1 the sample size was considered statistically representative this threshold was achieved for sets of thirteen cross sections and consequently fifteen cross sections were created for the flow and transport simulations 2 2 2 soil textural variability three combinations hereafter sets of finer and coarser materials were considered to represent textural variability each set contained a finer and a coarser material table 1 we emphasize that these terms are relative since all of the materials are coarse when placed in a broader spectrum of soil types however waste rock dumps containing more than 20 particle mass smaller than 2 0 mm or 40 smaller than 4 75 mm are considered to be soil like dawson and morgenstern 1995 dawson et al 1998 smith et al 1995 barbour et al 2016 in that water flow through these dumps is governed by richard s equation and water storage can be described by capillary theory nichol et al 2005 webb et al 2008 neuner et al 2013 all materials in table 1 meet these requirements of particle size distribution the actual values of the soil hydraulic parameters of the textural classes were obtained from literature table 1 parameter set 1 was based on the characterization of waste rock at the golden sunlight mine montana usa azam et al 2007 the finer texture class selected for this parameter set was described as well graded gravelly sand whilst the coarser class was described as sandy gravel parameter set 2 was based on material from waste rock in a mine in south carolina usa with relatively low values of hydraulic conductivity fines 2006 and a finer grain size distribution than that of parameter set 1 the finer texture class selected for this parameter set was described as silty sand whilst the coarser class was described as silty gravel parameter set 3 was based on waste material from the diavik diamond mine in northern canada neuner et al 2013 while piles from this material are sometimes classified as rock like the grain size distribution of the matrix material of this pile was intermediate between those of sets 1 and 2 the finer texture class selected for this parameter set was described as coarse sand whilst the coarser class was described as poorly graded gravel for each parameter set the saturated conductivity was different for the finer and coarser textural classes but more importantly the shape of the k ψ curves differed due to unique values for the van genuchten parameters α and n table 1 such that the locations of their cross over points occurred at different suctions under steady state flow into a deep uniform column of unsaturated soil with a free drainage lower boundary the value of k ψ is equal to the flow rate newman et al 1997 barbour 1990 and the corresponding value of ψ can be inferred from the k ψ relationship the same does not hold under transient conditions since the hydraulic gradients may also vary but the range of flow rates are roughly indicative of the range of k ψ and hence suctions are likely to develop the differences in suction will tend to divert water laterally from one soil texture to the other and once the suctions equilibrate the texture with the highest k ψ would preferentially conduct water the shaded bar in fig 3 b highlights the range of flow rates in the simulations the position of the cross over point with respect to the range of flow rates would suggest that the finer regions will be the primary flow paths during the growing season for sets 1 and 3 while the coarser domain would likely be more active during the spring freshet the cross over of k in set 2 occurred within the range of expected flow rates meaning that both domains could be active flow paths during the growing season and spring freshet heterogeneity within the two material classes of each set was created with the stochastic scaling factor feature in hydrus hydrus incorporates the scaling method developed by vogel et al 1991 which assumes the space and time variability of soil hydraulic properties can be expressed in terms of a linear transformation of the k ψ and θ ψ functions as such fields of log normally distributed scaling factors for pressure head volumetric water content and hydraulic conductivity were generated stochastically table 2 we followed russo 2010 2012 for the value of standard deviation and correlation lengths table 2 because information on the size of local variability was not available from the studies that we used for the large scale parameterization this parameterization may seem rather arbitrary but it is one that will affect flow and transport russo 2010 2012 while not overshadowing the large scale heterogeneity generated by the geometry of the profiles 2 3 numerical experiments 2 3 1 domain setup the 2d model domain was bounded by no flow boundaries at the sides a unit hydraulic gradient drainage boundary at the bottom and a net percolation boundary at the top i e a transient flux boundary condition the targeted size of the finite elements in the domains was 0 08 m and the total numbers of nodes and elements were 44 000 and 87 000 on average the 30 m domain width ensured that flow effects created by the no flow boundaries did not dominate the outflow signal the explicit consideration of large scale heterogeneity through the geometrical patterns forms a macrodispersivity on a scale of 1 to 8 m based on the summary provided by gelhar et al 1992 longitudinal dispersivity scales in the order of 1 10 to 1 100 to domain length for domains between 1 10 m length corresponding to α l ranging from 0 06 to 0 6 m in our 6 m lifts that same publication suggests a ratio of longitudinal to transverse dispersivity between two and four by choosing a longitudinal dispersivity of 0 2 m we had a value that was representative of the range presented by gelhar et al 1992 which was still large enough to span two to three grid blocks targeted grid block size 0 08 m and be applicable to an α l α t 2 ratio where α t was at least bigger than the targeted grid block size the dispersion tensor was homogeneous within each domain however by its very nature it creates anisotropic mixing according to the α l and α t values associated with the parallel and transverse directions of the variable velocity field a nominal coefficient of molecular diffusion de of 1 2 10 10 m2 s 1 was used in all models as a spin up of the simulations a constant net percolation rate the daily average of the transient net percolation time series was applied to the domains until steady state was reached from an arbitrary initial condition all of the transport simulations were diffusion dominated with maximum péclet numbers for the numerical solutions of 0 54 calculated with the grid element dimensions average courant numbers c r of the numerical simulations varied between the parameter sets c r 1 except for one or two days per spring freshet when cr reached 1 25 for set 1 and 1 75 for set 3 no numerical oscillations were observed during or after these timesteps with c r 1 and numerical instability was small in the rest of the simulations 2 3 2 net percolation model forcing we investigated two model forcing time series the yearly weather cycle in regions with long cold winters such as western canada can be subdivided in three different net percolation time periods fig 4 a winter during which most precipitation falls as snow and minimal infiltration or evaporation takes place spring during which the snow cover melts causing a high infiltration flux into the soil commonly called the freshet and the growing season during which most precipitation falls as rain and both infiltration and evaporation occur the first forcing time series consisted of a transient yearly time series of net percolation based on a 40 year meteorological dataset from an environment and climate change canada eccc climate station in fernie british columbia canada eccc 2015 actual evaporation was determined from this dataset with a representative hydrus 1d model and subtracted from the daily precipitation the 40 year time series was then averaged to obtain an annual transient net percolation series that was not governed by the peculiarities of any single meteorological year the annual transient net percolation time series fig 4a starting at the beginning of the snow covered period was applied 4 times to each domain uniformly distributed along the surface this created a dynamic repeated cyclic response in which the discharge flux and patterns of ψ and θ eventually repeated themselves on a yearly cycle annual net percolation was 491 mm yr 1 50 of which occurred as snowmelt and 50 as rainfall during summer and fall this range of net percolation would be typical for large waste rock dumps in sub humid regions of western canada such as those reported by villeneuve et al 2017 for coal mines in british columbia canada the second forcing time series consisted of a constant net percolation rate equal to the year averaged net percolation rate from the transient infiltration regime 2 3 3 solutes two solute transport simulation experiments were performed in the first experiment the flushing of a conservative species contained within the pore water of the dump was simulated this would be similar to the flushing of explosive derived nitrate which can be considered a conservative species under the oxidizing conditions that prevail in dumps bailey et al 2013 mahmood et al 2017 or the flushing of soluble contaminants produced by oxidation reactions within the waste dump to achieve this the model was seeded with a uniform concentration of a conservative solute in the pore water c 0 10 g m 3 the second experiment simulated the breakthrough characteristics of a solute pulse in the infiltrating water this was applied during the peak of the spring freshet doy 100 solute s1 c s1 100 g m 3 de 1 2 10 10 m2 s 1 in one experiment and in early autumn doy 244 solute s2 c s2 100 g m 3 de 1 2 10 10 m2 s 1 in another in both cases in the first year of the four year simulation these experiments provide a comparison of the flow and transport behavior of these hypothetical lifts to that of test dumps where similar tracer experiments have been performed nichol et al 2005 neuner et al 2013 2 4 analysis of solute leaching in addition to breakthrough curves the solute export from the dumps was evaluated by calculating the leached fraction lf leached fraction or interchangeably leaching efficiency is commonly used in the mining industry but not well defined in literature we will use a working definition of this term here as the percentage of solute mass that has been removed from the domain after a volume of water equal to one average stored volume 1 asv of water within the domain has passed through the domain here that asv is estimated as the annual average stored water volume within the lift the asv is similar to the concept of a pore volume 1 pv used to analyze break through curves in column testing or the pore volume injected 1 pvi in the oil industry renard and allard 2013 based on these definitions the value of lf is calculated as follows 6 l f m t t m i 100 where mt t is the solute mass kg that has been leached from the lift at time t t is the time at which the cumulative discharge from the lift equals 1 asv and mi is the initial mass of solute kg in case of a resident solute this is the total mass of solute present in the domain in the case of a surface applied solute it is the total mass of solute applied to the lift lf of a resident solute will always be larger than that of a surface applied solute because leaching of the solute starts as soon as the column starts draining 3 results 3 1 emergent flow from the lifts the snowmelt infiltration pulse fig 4a propagated rapidly through the lifts to produce discharge which when integrated over the base of the lift showed little variation for ensembles with the same hydraulic parameters fig 4b set 1 and set 3 lifts featured similar peak discharge rates of 14 15 mm d 1 despite having an order of magnitude difference in saturated hydraulic conductivity in set 2 lifts the flow signal was more attenuated producing lower peak flows and sustaining the lower flow rates over longer times the spatial variability of flow along the lower boundary of the lifts was largest leading up to peak flow fig 4c in set 2 variability along the bottom dropped sharply after the flow peak whereas that in set 1 and set 3 was sustained throughout the growing season and part of the winter set 1 lifts featured the highest spatial variability five times higher than that of set 3 lifts the variance of the outflow signals of the lifts did not increase after considering thirteen or more lifts confirming that our sample size was large enough to capture the geostatistics of the textural pattern the relative water mass balance error was on average 1 during the first six months of each simulation and dropped to a stable average 0 2 after that the simulated average velocities of the spring freshet wetting front calculated from the time required for the first daily discharge disturbance after the winter period to be observed at the lift bottom were 0 4 m d 1 set 1 0 2 m d 1 set 2 and 0 45 m d 1 set 3 these rates are consistent with test pile studies in climates with cold snowy winters which report wetting front velocities following snowmelt between 0 4 m d 1 in a 5 m tall test pile nichol et al 2005 and 0 25 m d 1 in a 15 m tall test pile smith et al 2013 neuner et al 2013 3 2 leaching of solutes from the lifts removal of the resident solute was fastest in set 3 lifts with average outflow concentrations of 0 01 g m 3 after four years fig 5 in set 3 lifts intra element variability of the solute concentration peaked shortly after the second spring freshet in contrast that same variability in set 1 lifts remained large throughout the four year simulation in set 2 lifts average outflow concentrations decreased more slowly with intra element variability peaking before the fourth spring freshet the initial mass was different between the sets because of differences in initial volumetric water content in set 1 the average initial mass was 306 1 9 kg in set 2542 4 0 kg and in set 3247 13 3 kg when the solute was applied at the surface the differences in solute outflow between the sets followed a similar pattern fig 6 solute application later in the hydrological year decreased the arrival time and the magnitude of the peak concentration this effect was strongest in set 1 and set 3 lifts where water content differences limited diffusion of solutes between the finer and coarser materials during the growing season and winter in set 2 lifts breakthrough curves for the two application times were almost identical compared to most observed breakthrough curves e g nichol et al 2005 webb et al 2008 and blackmore et al 2014 an initial spike of water and solute is missing from our simulations because non capillary flow was not accounted for comparing outflow tails from simulations to those in field experiments is difficult because the monitoring period in field experiments is often not long enough to capture the entire tail for both the resident and the surface applied tracers the relative mass balance errors fluctuated between 2 and 3 in the first year of simulation depending on the soil hydraulic parameter set and the geometric pattern and stabilized to values 1 after that the empirical cumulative distribution function ecdf of mass leaching from all the elements along the bottom boundaries of the lifts of each set fig 7 showed that solute outflow variability ranked with the textural contrast characteristics set 2 featured the characteristic s shape of a normal gaussian distribution with a minimal skew towards areas with high mass outflow the lower part of the ecdf of set 3 lifts was linear indicating a larger proportion of elements that contribute little to solute outflow set 1 lifts featured portions of the domain that did not contribute to mass leaching at all and exhibited the largest skew with respect to a small number of elements contributing disproportionally to solute outflow 3 3 internal dynamics of flow and transport of the resident solute relative saturation resident solute concentration and flow vectors within a portion of the domain are presented in fig 8 for three different days during two years of the transient simulations during and shortly after the spring freshet as well as later in the growing season in all lifts the structural variability caused more variation in the spatial distribution of water content than the stochastic variability figs 8a1 f1 set 2 lifts figs 8d1 f4 behaved most homogeneously with flow moving freely between the two materials during the entire simulation while the propagation of the spring freshet infiltration front was locally delayed by textural interfaces focusing of flow was absent in these lifts high saturation levels of both finer and coarser materials figs 8d1 e1 f1 allowed diffusion processes to exchange mass between these different flow domains throughout the growing season set 1 and set 3 lifts featured flow concentrations caused by textural differences in set 3 lifts figs 8g1 i4 water and solute breakthrough at the bottom boundary occurred first from the coarse conduits that extended from top to bottom of the lift fig 2a these conduits also carried water received from overlying fine layers due to the absence of capillary breaks during the spring freshet low water saturation in the coarser materials and increased the flow of water in the finer materials during the growing season allowing solute concentration differences to persist longer than in set 2 lifts in set 1 lifts figs 8a1 c4 capillary breaks were common during the spring freshet the early arrival of water and solutes in response to the spring freshet in these lifts did not occur through connected conduits of coarser material but rather by the funneling of water within the finer materials along textural interfaces to confluences of dipping features fig 2a where head could build until break through into the coarser material occured fig 8g1 i4 therefore the emergent flow at the bottom of the lifts and the dynamics of leached fraction related more strongly to the geometry of the upper part of the lifts than to that of the lower parts trapping of solutes occurred in the zones bypassed during the spring freshet diffusion of solutes out of these zones was much slower than in the other textural sets because coarser zones remained drier during the entire year while the patterns of saturation and solute concentration were unique for each lift the statistics of solute concentration distribution with depth confirmed the variability of spatial solute distribution at various moments during the leaching process fig 9 for reasons of conciseness we only show set 1 and set 3 lifts in fig 9 set 2 profiles were very similar to set 3 profiles under transient net percolation fig 9a b set 1 lifts retained more resident surface applied solutes higher up in the lifts than set 3 lifts as evidenced by higher positions of the maxima of mean and sd profiles of depth averaged concentrations the same was true under constant net percolation fig 9c d in set 1 lifts however the spatial distributions of solutes with depth in the later phases of the leaching process lf 50 were different with respect to those under transient conditions the mean concentrations of the resident solute were lower in the top half of the lift while the sd remained high a second peak in sd of the resident solute concentration was present in the middle of the lifts these shapes were indicative of bimodal heterogeneous behavior in the lifts harter and yeh 1996 the mean concentration profiles of the surface applied solute no longer featured two peaks the sd profile was very similar in the lower half of the lifts but featured a smaller peak in the upper layer of the lifts by contrast the shapes of mean and sd solute profiles of sets 2 and 3 set 2 not shown in fig 9 indicated unimodal heterogeneous behavior harter and yeh 1996 here the mean solute concentration profile only featured one peak surface applied solutes and the largest sd of concentration occurred near the inflection points of the mean solute concentration profile with a local minimum at the plume centre 4 discussion 4 1 impacts of model assumptions and simplifications on results the extent to which general conclusions regarding waste rock dump flow and transport can be drawn from the presented simulations is constrained by the applied model assumptions and system simplifications as highlighted in the introduction the importance of non capillary flow may vary between dumps field studies by nichol et al 2005 webb et al 2008 and blackmore et al 2014 suggest that in piles consisting of soil like materials between 0 1 and 5 of total flow may still move through macropores early arrival of water and solutes was underestimated because we did not account for non capillary flow the simplified representation of more complex 3d structures with a 2d domain implies reduced complexity of the simulated outflow patterns as well as of the internal distributions of water and solutes studies that involve multiple lysimeters positioned under a dump or test pile typically display a large variability of initial arrival time peak timing flux rates and total leached solute mass and water volumes nichol et al 2005 webb et al 2008 while we observed a similar variety of flow and mass export along the bottom in dumps with contrasting textures most strong in set 1 to a lesser extent in set 3 a 3d geometry would imply a broader range of dipping and converging features fig 2b resulting in larger differences in the focusing of flow our domains were small relative to the size of the geometrical features as compared to real dumps and consequently the presence of lateral zero flux boundary conditions is likely to constrain the flow patterns however for every feature that directed water to pile up against a vertical boundary the set of fifteen realizations also contained features that diverted it away from them any potential effect of the zero flux boundary conditions was statistically consistent within the sets as demonstrated by the jackknife analysis the parameterization of soil textures by α n and k s into two main classes per set cannot do justice to the soil heterogeneity associated with the variability of particle size distributions within dumps e g azam et al 2007 herasymuik et al 2006 nichol et al 2005 webb et al 2008 blackmore et al 2014 the presence of a larger array of k cross over characteristics will lead to more complex flow behavior and increased focusing of flow under high infiltration rates see e g fala et al 2013 for a more extreme k function contrast however our simulations do highlight how various parts of a complex geometry will respond to transient infiltration signals lastly our simulations were forced with a simplified time series of net percolation instead of estimating actual precipitation and evaporation fluxes except for the spring freshet the net 40 year average percolation fluxes are smaller than infiltration rates resulting individual storm events by a factor 2 to 50 eccc 2015 a similar underestimation of evaporation fluxes results from the averaging procedure though in this case differences are limited to a factor 2 to 5 net percolation is expected to vary in space with large melt or precipitation events resulting in redistribution of net percolation along the dump surface the underestimation of net percolation and the associated spatial variability could lead to an underestimation of flow focusing along textural interfaces however as will be discussed in section 4 2 these flow differences may not result in sustained focused flow domains under transient conditions in summary the limitations of our study are likely to lead to an underestimation of the variability of flow and transport processes relative to actual waste rock dumps however they do capture key characteristics of these large unsaturated formations 4 2 connectivity of flow and transport in relation to geometric connectivity despite the pockets of persistent solute fig 8 and the variability of solute outflow figs 5 and7 the leaching of the resident and the surface applied solute was highly efficient in our simulations average leaching efficiencies varied between 80 90 resident solute figs 10 a and b and 30 45 surface applied solute fig 10c and d after one asv flush as noted in section 2 4 the leaching behavior of a resident and surface applied solute are inherently different therefore the leaching efficiency at one asv of a resident solute will always be higher than that of a surface applied solute for the resident solute only the upper half of the lf curve contains information on the leaching process set 2 lifts leached most efficiently although four years of simulation were not enough to flush more than 92 of the initial mass and followed the piston curve the longest set 3 lifts leached most of the initial mass whereas set 1 lifts approached a limit value of 90 of the initial mass differences between sets were subtle and not consistent between the transient and constant infiltration regimes under constant infiltration set 1 lifts leached more efficiently than set 3 lifts until 90 lf had been achieved differences between our modeled results and observations of flow transport and leaching efficiency were expected from the simplified conceptualization in this study flow and transport field experiments are typically performed on test piles that are smaller in size than operational piles notable exceptions can be found in azam et al 2007 fines 2006 even so experimental periods are often too short to flush one average stored volume nichol et al 2005 neuner et al 2013 which implies that the curves of fig 10 can only be partially compared to observations displayed as points in fig 10 simulated lf was higher than observed lf in all but one of the studies incorporated in fig 10 our simulations with a resident solute fig 10a are representative of residues from undetonated blasting agents or other non reactive components that are slowly flushed out of a waste rock pile bailey et al 2013 guerin et al 2006 mahmood et al 2017 the leaching efficiency of such tracers after one asv outflow varies widely in the field as indicated in fig 10a from a 5 no3 n recovery from a test pile in the northwest territories bailey et al 2013 to a 25 45 total leachable u and 31 58 total leachable ni recovery from a full size waste rock dump in northern saskatchewan guerin et al 2006 to 40 no3 n recovery from small test piles in bc canada mahmood et al 2017 with an exceptional 80 lf for total leachable u in a test pile in northern saskatchewan guerin et al 2006 mahmood et al 2017 noted variability of leaching efficiencies at various spatial scales for matrix flow dominated waste rock in bc canada with an average of 20 in laboratory sized humidity cells increasing to an average of 47 min max range 24 80 in three small 2 m height test piles versus 70 to 90 estimated from profiles obtained in full scale dumps for surface tracer experiments fig 10c values of 34 tracer recovery after 0 45 asv transient drainage nichol et al 2005 and 55 70 after 1 0 asv eriksson et al 1997 have been observed in test piles or field lysimeters this overestimation could be attributed to the lack of low permeability stagnant zones in the model domains as well as the lack of dry starting period that occurs after construction of a waste rock pile in bimodal unsaturated soil formations solute transport has been noted to be more controlled by cumulative influx than influx rates russo et al 2001 the sensitivity of our model to its initial conditions forced us to start the transport simulations from a wetter situation than encountered in field experiments contributing to the higher efficiency of the modeled first asv flush other numerical and stochastic studies of flow through bimodal all capillary formations have found effects of geometry on flow variability and solute spreading under high influx rates the effects of bimodality in terms of inhibiting or focusing flow are larger than under low influx rates russo et al 2001 russo et al 2010 russo et al 2012 embedded features of either finer or coarser materials may act as a capture zone for solutes under high flux conditions depending on the average wetness of the formation russo 2010 under transient conditions however this capture capacity disappears and the main direction of flow is vertical allowing displaced water solutes to sample the heterogeneity of the formation effectively russo 2010 2012 the incorporation of connected multi gaussian features has been observed to enhance channeling of unsaturated flow in a previous numerical study russo 2015 however under intermittent and dynamic flow rates effects on emergent flow and transport have been noted to be rather small regardless of the formation s texture russo 2015 our results confirm these findings for formations with non gaussian connected features and strongly seasonal infiltration rates textural contrasts with k cross over points outside or at the upper limit of the range of infiltration rates encountered resulted in flow focusing along the connected geometrical features during sustained high infiltration events i e the spring freshet period in our simulations fig 8 flow focusing did not extend all the way throughout the lifts and as a result breakthrough of water flow and solute mass could not be mapped to the material distribution along the bottom of the domains the role of the geometry in guiding flow paths was temporary as well the flow paths did not follow geometry under lower flow rates i e during the growing season and the winter period of our simulations similar to russo s 2015 findings in multi gaussian formations in addition during this time the coarser and finer domains in the formations were wet enough to allow diffusion of solutes from pockets that were bypassed during the spring freshet as a result leaching of solutes expressed as a function of drained volume from the lifts was efficient within the limitations of our domain and the processes considered section 4 1 this work shows that the effects of geometric connectivity on the hydrological connectivity of unsaturated flow and transport vary within formations this has implications for the analysis of large unsaturated domains and demonstrates that geometry should sometimes be considered explicitly however measures that quantify the connectivity of a formation geometrically for an overview see renard and allard 2013 are not informative indicators of unsaturated flow and transport properties of a formation as flow and transport connectivity are largely determined by characteristics of the net percolation signal 4 3 implications for multi lift waste rock dumps in the real mining landscape lifts do not act in isolation but rather are part of a larger number of complex lift and end dumping structures the four numerical experiments conducted in this study are most representative of the flow and transport processes in the upper most lift of a waste rock dump if we consider the coarser material combinations represented by set 1 and 3 the most representative of actual dumps then it is clear that flow and transport processes are likely to be highly variable both in space and time within test pile waste rock study sites the distinction between flow focusing through pathways that are generated during dump construction versus flow that follows a vertical pathway across structures has been noted in experimental piles e g in neuner et al 2013 who contrasts test piles from nichol et al 2005 and andrina 2009 when vertical flow is evenly distributed laterally as in set 2 lifts it can be used to the mine operators advantage as it promotes chemical mixing between leachate from different layers layering or mixing in specific rock types to create geochemical conditions that promote attenuation or containment of solutes in dumps are techniques that receive considerable attention in current waste rock research andrina 2009 hirsche et al 2017 however the uncertainties around how such conditions can be achieved are still large especially when degrees of flow channeling vary hirsche et al 2017 as our simulations show such variation may occur within lifts at various depths and within years as a function of infiltration dynamics and dampening of flow variability as lifts are progressively buried under new lifts the concentration distributions and increased variability of leaching efficiency for resident and surface applied solutes under constant infiltration rates imply that the outflow tail of mass release from a pile will probably be longer than what would be expected from tracer experiments in single lift test piles surface tracer infiltration experiments only reveal part of the transport connectivity within the waste rock piles when a variety of textures are present such experiments will typically overestimate the first flush transport connectivity and underestimate the transport connectivity of the tail of leaching of other internally loaded solutes from dumps in real dumps with multiple lifts and embedded texturally contrasting structures e g compaction lifts solutes that have been sequestered under high net percolation rates could be mobilized when buried to depths that only experience low percolation rates 5 conclusions this study presented numerical experiments of unsaturated flow and solute transport in a 2d domain with textural and structural variability in a climate zone where spring snow melt is an important event in the hydrological year while simplified in terms of textural contrasts and geometry the model results highlight that highly variable water content and concentration distributions should not necessarily be interpreted as indicators of inefficient leaching at the dump scale early arrival of water and mass at specific points and times at the bottom of a dump reflected the variable nature of flow and transport but did not provide definite answers to the areas within the dump that contributed to this variability depending on the textural contrasts the geometrically connected structures in the lifts promoted efficient flow through coarser conduits set 3 lifts or along textural interfaces set 1 lifts the geometries could not be used to predict peak outflow locations at the bottom of dumps because the presence and strength of flow focusing along textural interfaces varied within the formations and over time in regions with distinct percolation seasons such as western canada the snowmelt period is the primary driver of efficient flow and transport and geometry and texture guided fast and focused flow during this period however the low percolation periods provided ample opportunity for solutes to diffuse and be leached during subsequent high percolation events this behavior was subtly different from the seasonal flow switching we hypothesized in that both finer and coarser domains contributed to flow and leaching under low percolation conditions rather the focusing and barrier functions of textural interfaces disappeared and vertical flow dominated during low percolation periods increasing the extent of hydrological activity of the lifts these observations underscore the need for continued monitoring of integrated flow and mass release from full scale dump structures as well as sampling of internal variability of water content and solute concentrations to fully evaluate the long term dynamics in both mass and water release our simulations show that designing an adequate internal monitoring scheme is challenging because observations can only be meaningfully interpreted in a larger context of geometry texture and percolation dynamics the relationship between percolation rate and the variability of leaching efficiency observed in our simulations also highlights the need to consider changes in a waste rock dump s water balance when it is reclaimed bare uncovered waste rock dumps will have a higher more dynamic rate of percolation than reclaimed vegetated dumps this change in the magnitude and the spatial variability in percolation will result in substantive differences in the rates and pathways of water and mass release from the dump as lower percolation rates will most likely limit the formation of zones isolated from active water flow and chemical transport acknowledgments financial support was provided by teck resources ltd and funding through a syncrude nserc industrial chair slb grant 428588 11 
887,mine waste rock dumps have highly variable flowpaths caused by contrasting textures and geometry of materials laid down during the plug dumping process numerical experiments were conducted to investigate how these characteristics control unsaturated zone flow and transport hypothetical profiles of inner lift structure were generated with multiple point statistics and populated with hydraulic parameters of a finer and coarser material early arrival of water and solutes at the bottom of the lifts was observed after spring snowmelt the leaching efficiency a measure of the proportion of a resident solute that is flushed out of the rock via infiltrating snowmelt or rainfall was consistently high but modified by the structure and texture of the lift under high rates of net percolation during snowmelt preferential flow was generated in coarse textured part of the rock and solutes in the fine textured parts of the rock remained stagnant under lower rates of net percolation during the summer and fall finer materialswere flushed too and the spatial variability of solute concentration in the lift was reduced layering of lifts leads to lower flow rates at depth minimizing preferential flow and increased leaching of resident solutes these findings highlight the limited role of large scale connected geometries on focusing flow and transport under dynamic surface net percolation conditions as such our findings agree with recent numerical results from soil studies with gaussian connected geometries as well as recent experimental findings emphasizing the dominant role of matrix flow and high leaching efficiency in large waste rock dumps keywords unsaturated preferential flow stochastic pattern generation solute leaching mine waste rock dumps 1 introduction surface mining operations generate large volumes of coarse textured waste rock which is placed in large above ground dumps that remain unsaturated these dumps often contain readily soluble and mobile chemicals referred to here as constituents of interest or cis associated with initial blasting and deposition such as nitrate bailey et al 2013 in addition oxygen ingress can lead to rapid weathering of these deposits and the concomitant generation of additional cis which are transported from the pile by water migration through the waste rock waste rock effluent can have a detrimental impact on downstream environments for many decades following dump construction and consequently poses environmental risks to adjacent groundwater and surface water morin and hutt 1997 lottermoser 2010 amos et al 2015 a thorough understanding of the dynamics of water flow through waste rock piles is central to interpreting and estimating removal rates of cis associated with water migration through these dumps smith and beckie 2003 the combination of contrasting textures and complex structures i e arrangements of materials and generally unsaturated conditions creates flowpaths that are highly variable in space and time and difficult to monitor and predict while there is ample evidence of preferential or non capillary flow playing an important role in water flow and solute transport through waste rock dumps e g harries and ritchie 1985 eriksson and destouni 1997 stockwell et al 2006 blackmore et al 2014 an increasing number of studies have found that even coarse textured dumps may have a particle size distribution that promotes capillarity and matrix dominated water flow and transport eriksson et al 1997 nichol et al 2005 webb et al 2008 neuner et al 2013 barbour et al 2016 the dominant flow process may vary between dumps as well as in time meaning that the flow mechanisms need to be represented carefully when simulating flow and transport for a particular dump particle sizes within dumps may range over four to six orders of magnitude from clay particles to boulders anterrieu et al 2010 stockwell et al 2006 martin et al 2005 the various construction methods arrange these different textural fractions in random isolated zones or continuous highly connected features within the dumps for example the pushing of waste rock over an angle of repose face can create dipping layers of coarser and finer deposits aubertin et al 2005 azam et al 2007 and the levelling of benches or lifts of waste rock in preparation for subsequent dumping creates horizontal compacted layers fala et al 2003 high degrees of spatial and temporal variability of water content and pore water concentrations imply dynamic and heterogeneous flow paths whilst high leaching efficiencies imply homogeneous piston type flow reconciling both high variability and high leaching efficiency is a key question in these studies of large waste rock dumps the role of geometrical patterns within dumps in trapping or preferentially removing cis remains poorly understood it is widely recognized that in deep subsurface geologic formations special attention should be paid to connected features that concentrate flow and reduce travel times knudby and carrera 2005 renard and allard 2013 near surface geologic formations and particularly unsaturated soils are considered more randomly heterogeneous nielsen et al 1973 kolterman and gorelick 1996 botros et al 2009 while a considerable amount of work has been done on flow and transport in gaussian bimodal heterogeneous formations e g russo et al 2001 russo 2005 2010 2012 few unsaturated zone studies have addressed the effects of connectivity on flow and transport beyond features such as macropores or cracks an exception being russo 2015 in saturated formations where high hydraulic conductivity materials are geometrically connected the effective hydraulic conductivity of the formation can be larger than the geometric mean of the conductivity in the formation zinn and harvey 2003 knudby and carrera 2005 in unsaturated formations with a similar geometric connection channeling of flow not only depends on the spatial variability of the soil hydraulic properties but also on temporal variations in flow rate which cause the dominant flow path to switch between higher and lower capillarity pores or macropores yeh et al 1985 neuweiler and cirpka 2005 neuweiler and vogel 2007 beven and germann 2013 connectivity of transport and flow are typically correlated though the strength of the correlation depends on material geometry and flow properties knudby and carrera 2005 transport connectivity i e existence of paths of early solute arrival is mainly controlled by the existence of narrow possibly discontinuous high conductivity paths and much less by barriers which control flow connectivity knudby and carrera 2005 russo 2015 in this study we investigate the high variability in water content and solute concentration and the simultaneous high leaching efficiencies that are typical features of waste rock dumps we use exploratory numerical experiments applied to a semi hypothetical lift in a mine waste rock dump our study is inspired by experimental work in waste rock dumps in canada where snowfall and snowmelt are important hydrological events barbour et al 2016 we hypothesize that i it is possible to model high spatial and temporal variability in solute concentrations and high leaching efficiencies simultaneously by considering geometrically connected patterns of two distinct materials with contrasting texture ii the high variability in water contents solute concentration is related to the internal geometry created during dump construction and iii that the high leaching efficiency is due to the large variation in percolation rates in different seasons that results in switching of flowpaths between finer and coarser domains the spatial patterns were generated with a multiple point statistical algorithm filtersim to simulate non gaussian geometrical connectivity in a lift created by the free dumping of materials in individual heaps plug dumping this type of random field generation has not been used in waste rock studies before we interpret the simulation results from a connectivity perspective and reflect on implications for multi lift waste rock dumps 2 methods 2 1 the numerical model water flow and solute transport were solved with the finite element code hydrus 2d šimůnek et al 2012 the two dimensional richards equation is given by 1 θ t x k ψ ψ x z k ψ ψ z 1 where θ is the volumetric water content ψ is the pressure head m k ψ is the hydraulic conductivity function m d 1 t is time d and x and z are horizontal and depth coordinates m the relationships between k ψ and θ were established with the van genuchten mualem functions van genuchten 1980 2 s e ψ θ ψ θ r θ s θ r 1 α ψ n m 3 k ψ k s s e l 1 1 s e 1 m m 2 where se ψ is the relative saturation ks is the saturated hydraulic conductivity m d 1 θs and θr are the saturated and residual volumetric water content respectively α m 1 m and n are empirical parameters dependent on soil type with m 1 1 n and l denotes a tortuosity factor that was set to 0 5 the advection dispersion equation describing the transport of a conservative solute that is not subject to sorption or degradation is given by 4 θ c t v x θ c x v z θ c z d i j θ 2 c x 2 2 c z 2 where c is the solute concentration in the liquid phase g m 3 v x and v z are the mean pore water velocities m d 1 in the horizontal and vertical direction respectively and d ij is the dispersion coefficient tensor m2 d 1 the latter is given by 5 θ d i j α l v δ i j α l α t v x v z v θ d e τ δ i j where α l and α t are the longitudinal and transversal dispersivity respectively m v is the magnitude of the pore water velocity m d 1 de is the molecular diffusion coefficient m2 d 1 τ is a tortuosity factor millington and quirk 1961 and δ ij is the kronecker delta 2 2 characteristics of the mine waste rock in the mining environment of interest for this study particle size distributions may be unimodal bimodal or multimodal e g smith et al 2013 amos et al 2015 a uni or multivariate gaussian distribution is not always the most appropriate representation as shown in conceptual models of dump structure proposed by aubertin et al 2005 and poisson et al 2009 it is often possible to identify strongly discontinuous zones for an example see fig 5 in poisson et al 2009 of segregated and non segregated materials therefore a bimodal distribution whereby the rock is comprised of two distinct materials one finer and one coarser is the simplest conceptualization that is able to capture the discontinuity of materials stochastically generated variability can be added to account for smaller scale soil heterogeneity similar assumptions have been made in numerical models by russo et al 2001 2005 2010 2012 2015 and fala et al 2013 this conceptualization does not include small features on the extremity of the permeability spectrum such as fractures and cracks or clay lenses 2 2 1 soil structural variability structure formed as a result of the spatial distribution of the two textural classes was generated by creating two dimensional random fields with the filtersim algorithm one of the multiple point statistics mps simulation algorithms in the sgems toolbox for matlab wu et al 2008a b mps is an alternate approach to geostatistics that uses a training image instead of a variogram built on two point correlations to estimate the conditional probability at interpolation locations given observed and already interpolated data guardiano and srivastava 1993 the models characterizing the image are parameterized with proportion scale and anisotropy of the variable in the image instead of the sill range and nugget that parameterize variogram models guardiano and srivastava 1993 the main advantage of mps algorithms is their ability to reproduce complex geometric shapes while preserving horizontal and vertical extent orientation and connectivity because the simulations are not restricted by two point correlations wu et al 2008a b the filtersim algorithm classifies all spatial patterns of a designated size in a training image ti with general linear filters the patterns are classified into bins according to how their filter scores meet a similarity and distance criterion a pattern template or prototype is determined for each bin class after this learning phase a new random image is constructed by generating a random sequence of points in the desired domain as in any sequential simulation and selecting one pattern from the library for each point this selection is either based on the class of the closest conditioning point in the grid e g well data or performed randomly for unconditional simulations the filtersim algorithm is fast because the dimensionality of the problem is reduced by creating filter summaries of all patterns that can be found in an image filtersim is applicable on continuous datasets though the performance of the algorithm can be limited because of its reliance on linear filters that may not be able to represent all geometries properly represented we consider a synthetic lift created by plug dumping fig 1 which is the free dumping of material with trucks in the form of individual heaps of material 2 to 5 m in height after each lift is placed it is leveled to create a horizontal surface fala et al 2003 based on a reference photograph of material from a dumping operation fig 1 a schematic vertical cross section of a lift was constructed to serve as a training image for the generation of 2d spatial distributions of two textural classes with the filtersim algorithm wu et al 2008a the training image fig 2 a contained a stand alone coarser dipping lense coarser dipping lenses that are connected to coarser materials forming the base of some individual heaps coarser lenses enveloping large blobs of finer material and places where the coarser outer layers of heaps touch each other we assumed that the space between the heaps is filled during the levelling process where the coarser materials separate out more towards the bottom of the lifts the result is a schematic with dipping coarser lenses of varying length and connectivity to other lenses fig 2a we used this schematic cross section as a training image for the generation of 2d spatial distributions of two textural classes with the filtersim algorithm wu et al 2008a the generated lifts fig 2b were 30 m wide and 6 m tall and covered at the top with a 0 25 m storage layer with an artificially high porosity table 1 to prevent runoff generation during the spring freshet the statistical consistency of the sample size was tested with a jackknife analysis of the outflow signal of the lifts we considered the mean and variance of the daily outflow rate for each sample size when differences in mean and variance between sample sets were smaller than 0 1 the sample size was considered statistically representative this threshold was achieved for sets of thirteen cross sections and consequently fifteen cross sections were created for the flow and transport simulations 2 2 2 soil textural variability three combinations hereafter sets of finer and coarser materials were considered to represent textural variability each set contained a finer and a coarser material table 1 we emphasize that these terms are relative since all of the materials are coarse when placed in a broader spectrum of soil types however waste rock dumps containing more than 20 particle mass smaller than 2 0 mm or 40 smaller than 4 75 mm are considered to be soil like dawson and morgenstern 1995 dawson et al 1998 smith et al 1995 barbour et al 2016 in that water flow through these dumps is governed by richard s equation and water storage can be described by capillary theory nichol et al 2005 webb et al 2008 neuner et al 2013 all materials in table 1 meet these requirements of particle size distribution the actual values of the soil hydraulic parameters of the textural classes were obtained from literature table 1 parameter set 1 was based on the characterization of waste rock at the golden sunlight mine montana usa azam et al 2007 the finer texture class selected for this parameter set was described as well graded gravelly sand whilst the coarser class was described as sandy gravel parameter set 2 was based on material from waste rock in a mine in south carolina usa with relatively low values of hydraulic conductivity fines 2006 and a finer grain size distribution than that of parameter set 1 the finer texture class selected for this parameter set was described as silty sand whilst the coarser class was described as silty gravel parameter set 3 was based on waste material from the diavik diamond mine in northern canada neuner et al 2013 while piles from this material are sometimes classified as rock like the grain size distribution of the matrix material of this pile was intermediate between those of sets 1 and 2 the finer texture class selected for this parameter set was described as coarse sand whilst the coarser class was described as poorly graded gravel for each parameter set the saturated conductivity was different for the finer and coarser textural classes but more importantly the shape of the k ψ curves differed due to unique values for the van genuchten parameters α and n table 1 such that the locations of their cross over points occurred at different suctions under steady state flow into a deep uniform column of unsaturated soil with a free drainage lower boundary the value of k ψ is equal to the flow rate newman et al 1997 barbour 1990 and the corresponding value of ψ can be inferred from the k ψ relationship the same does not hold under transient conditions since the hydraulic gradients may also vary but the range of flow rates are roughly indicative of the range of k ψ and hence suctions are likely to develop the differences in suction will tend to divert water laterally from one soil texture to the other and once the suctions equilibrate the texture with the highest k ψ would preferentially conduct water the shaded bar in fig 3 b highlights the range of flow rates in the simulations the position of the cross over point with respect to the range of flow rates would suggest that the finer regions will be the primary flow paths during the growing season for sets 1 and 3 while the coarser domain would likely be more active during the spring freshet the cross over of k in set 2 occurred within the range of expected flow rates meaning that both domains could be active flow paths during the growing season and spring freshet heterogeneity within the two material classes of each set was created with the stochastic scaling factor feature in hydrus hydrus incorporates the scaling method developed by vogel et al 1991 which assumes the space and time variability of soil hydraulic properties can be expressed in terms of a linear transformation of the k ψ and θ ψ functions as such fields of log normally distributed scaling factors for pressure head volumetric water content and hydraulic conductivity were generated stochastically table 2 we followed russo 2010 2012 for the value of standard deviation and correlation lengths table 2 because information on the size of local variability was not available from the studies that we used for the large scale parameterization this parameterization may seem rather arbitrary but it is one that will affect flow and transport russo 2010 2012 while not overshadowing the large scale heterogeneity generated by the geometry of the profiles 2 3 numerical experiments 2 3 1 domain setup the 2d model domain was bounded by no flow boundaries at the sides a unit hydraulic gradient drainage boundary at the bottom and a net percolation boundary at the top i e a transient flux boundary condition the targeted size of the finite elements in the domains was 0 08 m and the total numbers of nodes and elements were 44 000 and 87 000 on average the 30 m domain width ensured that flow effects created by the no flow boundaries did not dominate the outflow signal the explicit consideration of large scale heterogeneity through the geometrical patterns forms a macrodispersivity on a scale of 1 to 8 m based on the summary provided by gelhar et al 1992 longitudinal dispersivity scales in the order of 1 10 to 1 100 to domain length for domains between 1 10 m length corresponding to α l ranging from 0 06 to 0 6 m in our 6 m lifts that same publication suggests a ratio of longitudinal to transverse dispersivity between two and four by choosing a longitudinal dispersivity of 0 2 m we had a value that was representative of the range presented by gelhar et al 1992 which was still large enough to span two to three grid blocks targeted grid block size 0 08 m and be applicable to an α l α t 2 ratio where α t was at least bigger than the targeted grid block size the dispersion tensor was homogeneous within each domain however by its very nature it creates anisotropic mixing according to the α l and α t values associated with the parallel and transverse directions of the variable velocity field a nominal coefficient of molecular diffusion de of 1 2 10 10 m2 s 1 was used in all models as a spin up of the simulations a constant net percolation rate the daily average of the transient net percolation time series was applied to the domains until steady state was reached from an arbitrary initial condition all of the transport simulations were diffusion dominated with maximum péclet numbers for the numerical solutions of 0 54 calculated with the grid element dimensions average courant numbers c r of the numerical simulations varied between the parameter sets c r 1 except for one or two days per spring freshet when cr reached 1 25 for set 1 and 1 75 for set 3 no numerical oscillations were observed during or after these timesteps with c r 1 and numerical instability was small in the rest of the simulations 2 3 2 net percolation model forcing we investigated two model forcing time series the yearly weather cycle in regions with long cold winters such as western canada can be subdivided in three different net percolation time periods fig 4 a winter during which most precipitation falls as snow and minimal infiltration or evaporation takes place spring during which the snow cover melts causing a high infiltration flux into the soil commonly called the freshet and the growing season during which most precipitation falls as rain and both infiltration and evaporation occur the first forcing time series consisted of a transient yearly time series of net percolation based on a 40 year meteorological dataset from an environment and climate change canada eccc climate station in fernie british columbia canada eccc 2015 actual evaporation was determined from this dataset with a representative hydrus 1d model and subtracted from the daily precipitation the 40 year time series was then averaged to obtain an annual transient net percolation series that was not governed by the peculiarities of any single meteorological year the annual transient net percolation time series fig 4a starting at the beginning of the snow covered period was applied 4 times to each domain uniformly distributed along the surface this created a dynamic repeated cyclic response in which the discharge flux and patterns of ψ and θ eventually repeated themselves on a yearly cycle annual net percolation was 491 mm yr 1 50 of which occurred as snowmelt and 50 as rainfall during summer and fall this range of net percolation would be typical for large waste rock dumps in sub humid regions of western canada such as those reported by villeneuve et al 2017 for coal mines in british columbia canada the second forcing time series consisted of a constant net percolation rate equal to the year averaged net percolation rate from the transient infiltration regime 2 3 3 solutes two solute transport simulation experiments were performed in the first experiment the flushing of a conservative species contained within the pore water of the dump was simulated this would be similar to the flushing of explosive derived nitrate which can be considered a conservative species under the oxidizing conditions that prevail in dumps bailey et al 2013 mahmood et al 2017 or the flushing of soluble contaminants produced by oxidation reactions within the waste dump to achieve this the model was seeded with a uniform concentration of a conservative solute in the pore water c 0 10 g m 3 the second experiment simulated the breakthrough characteristics of a solute pulse in the infiltrating water this was applied during the peak of the spring freshet doy 100 solute s1 c s1 100 g m 3 de 1 2 10 10 m2 s 1 in one experiment and in early autumn doy 244 solute s2 c s2 100 g m 3 de 1 2 10 10 m2 s 1 in another in both cases in the first year of the four year simulation these experiments provide a comparison of the flow and transport behavior of these hypothetical lifts to that of test dumps where similar tracer experiments have been performed nichol et al 2005 neuner et al 2013 2 4 analysis of solute leaching in addition to breakthrough curves the solute export from the dumps was evaluated by calculating the leached fraction lf leached fraction or interchangeably leaching efficiency is commonly used in the mining industry but not well defined in literature we will use a working definition of this term here as the percentage of solute mass that has been removed from the domain after a volume of water equal to one average stored volume 1 asv of water within the domain has passed through the domain here that asv is estimated as the annual average stored water volume within the lift the asv is similar to the concept of a pore volume 1 pv used to analyze break through curves in column testing or the pore volume injected 1 pvi in the oil industry renard and allard 2013 based on these definitions the value of lf is calculated as follows 6 l f m t t m i 100 where mt t is the solute mass kg that has been leached from the lift at time t t is the time at which the cumulative discharge from the lift equals 1 asv and mi is the initial mass of solute kg in case of a resident solute this is the total mass of solute present in the domain in the case of a surface applied solute it is the total mass of solute applied to the lift lf of a resident solute will always be larger than that of a surface applied solute because leaching of the solute starts as soon as the column starts draining 3 results 3 1 emergent flow from the lifts the snowmelt infiltration pulse fig 4a propagated rapidly through the lifts to produce discharge which when integrated over the base of the lift showed little variation for ensembles with the same hydraulic parameters fig 4b set 1 and set 3 lifts featured similar peak discharge rates of 14 15 mm d 1 despite having an order of magnitude difference in saturated hydraulic conductivity in set 2 lifts the flow signal was more attenuated producing lower peak flows and sustaining the lower flow rates over longer times the spatial variability of flow along the lower boundary of the lifts was largest leading up to peak flow fig 4c in set 2 variability along the bottom dropped sharply after the flow peak whereas that in set 1 and set 3 was sustained throughout the growing season and part of the winter set 1 lifts featured the highest spatial variability five times higher than that of set 3 lifts the variance of the outflow signals of the lifts did not increase after considering thirteen or more lifts confirming that our sample size was large enough to capture the geostatistics of the textural pattern the relative water mass balance error was on average 1 during the first six months of each simulation and dropped to a stable average 0 2 after that the simulated average velocities of the spring freshet wetting front calculated from the time required for the first daily discharge disturbance after the winter period to be observed at the lift bottom were 0 4 m d 1 set 1 0 2 m d 1 set 2 and 0 45 m d 1 set 3 these rates are consistent with test pile studies in climates with cold snowy winters which report wetting front velocities following snowmelt between 0 4 m d 1 in a 5 m tall test pile nichol et al 2005 and 0 25 m d 1 in a 15 m tall test pile smith et al 2013 neuner et al 2013 3 2 leaching of solutes from the lifts removal of the resident solute was fastest in set 3 lifts with average outflow concentrations of 0 01 g m 3 after four years fig 5 in set 3 lifts intra element variability of the solute concentration peaked shortly after the second spring freshet in contrast that same variability in set 1 lifts remained large throughout the four year simulation in set 2 lifts average outflow concentrations decreased more slowly with intra element variability peaking before the fourth spring freshet the initial mass was different between the sets because of differences in initial volumetric water content in set 1 the average initial mass was 306 1 9 kg in set 2542 4 0 kg and in set 3247 13 3 kg when the solute was applied at the surface the differences in solute outflow between the sets followed a similar pattern fig 6 solute application later in the hydrological year decreased the arrival time and the magnitude of the peak concentration this effect was strongest in set 1 and set 3 lifts where water content differences limited diffusion of solutes between the finer and coarser materials during the growing season and winter in set 2 lifts breakthrough curves for the two application times were almost identical compared to most observed breakthrough curves e g nichol et al 2005 webb et al 2008 and blackmore et al 2014 an initial spike of water and solute is missing from our simulations because non capillary flow was not accounted for comparing outflow tails from simulations to those in field experiments is difficult because the monitoring period in field experiments is often not long enough to capture the entire tail for both the resident and the surface applied tracers the relative mass balance errors fluctuated between 2 and 3 in the first year of simulation depending on the soil hydraulic parameter set and the geometric pattern and stabilized to values 1 after that the empirical cumulative distribution function ecdf of mass leaching from all the elements along the bottom boundaries of the lifts of each set fig 7 showed that solute outflow variability ranked with the textural contrast characteristics set 2 featured the characteristic s shape of a normal gaussian distribution with a minimal skew towards areas with high mass outflow the lower part of the ecdf of set 3 lifts was linear indicating a larger proportion of elements that contribute little to solute outflow set 1 lifts featured portions of the domain that did not contribute to mass leaching at all and exhibited the largest skew with respect to a small number of elements contributing disproportionally to solute outflow 3 3 internal dynamics of flow and transport of the resident solute relative saturation resident solute concentration and flow vectors within a portion of the domain are presented in fig 8 for three different days during two years of the transient simulations during and shortly after the spring freshet as well as later in the growing season in all lifts the structural variability caused more variation in the spatial distribution of water content than the stochastic variability figs 8a1 f1 set 2 lifts figs 8d1 f4 behaved most homogeneously with flow moving freely between the two materials during the entire simulation while the propagation of the spring freshet infiltration front was locally delayed by textural interfaces focusing of flow was absent in these lifts high saturation levels of both finer and coarser materials figs 8d1 e1 f1 allowed diffusion processes to exchange mass between these different flow domains throughout the growing season set 1 and set 3 lifts featured flow concentrations caused by textural differences in set 3 lifts figs 8g1 i4 water and solute breakthrough at the bottom boundary occurred first from the coarse conduits that extended from top to bottom of the lift fig 2a these conduits also carried water received from overlying fine layers due to the absence of capillary breaks during the spring freshet low water saturation in the coarser materials and increased the flow of water in the finer materials during the growing season allowing solute concentration differences to persist longer than in set 2 lifts in set 1 lifts figs 8a1 c4 capillary breaks were common during the spring freshet the early arrival of water and solutes in response to the spring freshet in these lifts did not occur through connected conduits of coarser material but rather by the funneling of water within the finer materials along textural interfaces to confluences of dipping features fig 2a where head could build until break through into the coarser material occured fig 8g1 i4 therefore the emergent flow at the bottom of the lifts and the dynamics of leached fraction related more strongly to the geometry of the upper part of the lifts than to that of the lower parts trapping of solutes occurred in the zones bypassed during the spring freshet diffusion of solutes out of these zones was much slower than in the other textural sets because coarser zones remained drier during the entire year while the patterns of saturation and solute concentration were unique for each lift the statistics of solute concentration distribution with depth confirmed the variability of spatial solute distribution at various moments during the leaching process fig 9 for reasons of conciseness we only show set 1 and set 3 lifts in fig 9 set 2 profiles were very similar to set 3 profiles under transient net percolation fig 9a b set 1 lifts retained more resident surface applied solutes higher up in the lifts than set 3 lifts as evidenced by higher positions of the maxima of mean and sd profiles of depth averaged concentrations the same was true under constant net percolation fig 9c d in set 1 lifts however the spatial distributions of solutes with depth in the later phases of the leaching process lf 50 were different with respect to those under transient conditions the mean concentrations of the resident solute were lower in the top half of the lift while the sd remained high a second peak in sd of the resident solute concentration was present in the middle of the lifts these shapes were indicative of bimodal heterogeneous behavior in the lifts harter and yeh 1996 the mean concentration profiles of the surface applied solute no longer featured two peaks the sd profile was very similar in the lower half of the lifts but featured a smaller peak in the upper layer of the lifts by contrast the shapes of mean and sd solute profiles of sets 2 and 3 set 2 not shown in fig 9 indicated unimodal heterogeneous behavior harter and yeh 1996 here the mean solute concentration profile only featured one peak surface applied solutes and the largest sd of concentration occurred near the inflection points of the mean solute concentration profile with a local minimum at the plume centre 4 discussion 4 1 impacts of model assumptions and simplifications on results the extent to which general conclusions regarding waste rock dump flow and transport can be drawn from the presented simulations is constrained by the applied model assumptions and system simplifications as highlighted in the introduction the importance of non capillary flow may vary between dumps field studies by nichol et al 2005 webb et al 2008 and blackmore et al 2014 suggest that in piles consisting of soil like materials between 0 1 and 5 of total flow may still move through macropores early arrival of water and solutes was underestimated because we did not account for non capillary flow the simplified representation of more complex 3d structures with a 2d domain implies reduced complexity of the simulated outflow patterns as well as of the internal distributions of water and solutes studies that involve multiple lysimeters positioned under a dump or test pile typically display a large variability of initial arrival time peak timing flux rates and total leached solute mass and water volumes nichol et al 2005 webb et al 2008 while we observed a similar variety of flow and mass export along the bottom in dumps with contrasting textures most strong in set 1 to a lesser extent in set 3 a 3d geometry would imply a broader range of dipping and converging features fig 2b resulting in larger differences in the focusing of flow our domains were small relative to the size of the geometrical features as compared to real dumps and consequently the presence of lateral zero flux boundary conditions is likely to constrain the flow patterns however for every feature that directed water to pile up against a vertical boundary the set of fifteen realizations also contained features that diverted it away from them any potential effect of the zero flux boundary conditions was statistically consistent within the sets as demonstrated by the jackknife analysis the parameterization of soil textures by α n and k s into two main classes per set cannot do justice to the soil heterogeneity associated with the variability of particle size distributions within dumps e g azam et al 2007 herasymuik et al 2006 nichol et al 2005 webb et al 2008 blackmore et al 2014 the presence of a larger array of k cross over characteristics will lead to more complex flow behavior and increased focusing of flow under high infiltration rates see e g fala et al 2013 for a more extreme k function contrast however our simulations do highlight how various parts of a complex geometry will respond to transient infiltration signals lastly our simulations were forced with a simplified time series of net percolation instead of estimating actual precipitation and evaporation fluxes except for the spring freshet the net 40 year average percolation fluxes are smaller than infiltration rates resulting individual storm events by a factor 2 to 50 eccc 2015 a similar underestimation of evaporation fluxes results from the averaging procedure though in this case differences are limited to a factor 2 to 5 net percolation is expected to vary in space with large melt or precipitation events resulting in redistribution of net percolation along the dump surface the underestimation of net percolation and the associated spatial variability could lead to an underestimation of flow focusing along textural interfaces however as will be discussed in section 4 2 these flow differences may not result in sustained focused flow domains under transient conditions in summary the limitations of our study are likely to lead to an underestimation of the variability of flow and transport processes relative to actual waste rock dumps however they do capture key characteristics of these large unsaturated formations 4 2 connectivity of flow and transport in relation to geometric connectivity despite the pockets of persistent solute fig 8 and the variability of solute outflow figs 5 and7 the leaching of the resident and the surface applied solute was highly efficient in our simulations average leaching efficiencies varied between 80 90 resident solute figs 10 a and b and 30 45 surface applied solute fig 10c and d after one asv flush as noted in section 2 4 the leaching behavior of a resident and surface applied solute are inherently different therefore the leaching efficiency at one asv of a resident solute will always be higher than that of a surface applied solute for the resident solute only the upper half of the lf curve contains information on the leaching process set 2 lifts leached most efficiently although four years of simulation were not enough to flush more than 92 of the initial mass and followed the piston curve the longest set 3 lifts leached most of the initial mass whereas set 1 lifts approached a limit value of 90 of the initial mass differences between sets were subtle and not consistent between the transient and constant infiltration regimes under constant infiltration set 1 lifts leached more efficiently than set 3 lifts until 90 lf had been achieved differences between our modeled results and observations of flow transport and leaching efficiency were expected from the simplified conceptualization in this study flow and transport field experiments are typically performed on test piles that are smaller in size than operational piles notable exceptions can be found in azam et al 2007 fines 2006 even so experimental periods are often too short to flush one average stored volume nichol et al 2005 neuner et al 2013 which implies that the curves of fig 10 can only be partially compared to observations displayed as points in fig 10 simulated lf was higher than observed lf in all but one of the studies incorporated in fig 10 our simulations with a resident solute fig 10a are representative of residues from undetonated blasting agents or other non reactive components that are slowly flushed out of a waste rock pile bailey et al 2013 guerin et al 2006 mahmood et al 2017 the leaching efficiency of such tracers after one asv outflow varies widely in the field as indicated in fig 10a from a 5 no3 n recovery from a test pile in the northwest territories bailey et al 2013 to a 25 45 total leachable u and 31 58 total leachable ni recovery from a full size waste rock dump in northern saskatchewan guerin et al 2006 to 40 no3 n recovery from small test piles in bc canada mahmood et al 2017 with an exceptional 80 lf for total leachable u in a test pile in northern saskatchewan guerin et al 2006 mahmood et al 2017 noted variability of leaching efficiencies at various spatial scales for matrix flow dominated waste rock in bc canada with an average of 20 in laboratory sized humidity cells increasing to an average of 47 min max range 24 80 in three small 2 m height test piles versus 70 to 90 estimated from profiles obtained in full scale dumps for surface tracer experiments fig 10c values of 34 tracer recovery after 0 45 asv transient drainage nichol et al 2005 and 55 70 after 1 0 asv eriksson et al 1997 have been observed in test piles or field lysimeters this overestimation could be attributed to the lack of low permeability stagnant zones in the model domains as well as the lack of dry starting period that occurs after construction of a waste rock pile in bimodal unsaturated soil formations solute transport has been noted to be more controlled by cumulative influx than influx rates russo et al 2001 the sensitivity of our model to its initial conditions forced us to start the transport simulations from a wetter situation than encountered in field experiments contributing to the higher efficiency of the modeled first asv flush other numerical and stochastic studies of flow through bimodal all capillary formations have found effects of geometry on flow variability and solute spreading under high influx rates the effects of bimodality in terms of inhibiting or focusing flow are larger than under low influx rates russo et al 2001 russo et al 2010 russo et al 2012 embedded features of either finer or coarser materials may act as a capture zone for solutes under high flux conditions depending on the average wetness of the formation russo 2010 under transient conditions however this capture capacity disappears and the main direction of flow is vertical allowing displaced water solutes to sample the heterogeneity of the formation effectively russo 2010 2012 the incorporation of connected multi gaussian features has been observed to enhance channeling of unsaturated flow in a previous numerical study russo 2015 however under intermittent and dynamic flow rates effects on emergent flow and transport have been noted to be rather small regardless of the formation s texture russo 2015 our results confirm these findings for formations with non gaussian connected features and strongly seasonal infiltration rates textural contrasts with k cross over points outside or at the upper limit of the range of infiltration rates encountered resulted in flow focusing along the connected geometrical features during sustained high infiltration events i e the spring freshet period in our simulations fig 8 flow focusing did not extend all the way throughout the lifts and as a result breakthrough of water flow and solute mass could not be mapped to the material distribution along the bottom of the domains the role of the geometry in guiding flow paths was temporary as well the flow paths did not follow geometry under lower flow rates i e during the growing season and the winter period of our simulations similar to russo s 2015 findings in multi gaussian formations in addition during this time the coarser and finer domains in the formations were wet enough to allow diffusion of solutes from pockets that were bypassed during the spring freshet as a result leaching of solutes expressed as a function of drained volume from the lifts was efficient within the limitations of our domain and the processes considered section 4 1 this work shows that the effects of geometric connectivity on the hydrological connectivity of unsaturated flow and transport vary within formations this has implications for the analysis of large unsaturated domains and demonstrates that geometry should sometimes be considered explicitly however measures that quantify the connectivity of a formation geometrically for an overview see renard and allard 2013 are not informative indicators of unsaturated flow and transport properties of a formation as flow and transport connectivity are largely determined by characteristics of the net percolation signal 4 3 implications for multi lift waste rock dumps in the real mining landscape lifts do not act in isolation but rather are part of a larger number of complex lift and end dumping structures the four numerical experiments conducted in this study are most representative of the flow and transport processes in the upper most lift of a waste rock dump if we consider the coarser material combinations represented by set 1 and 3 the most representative of actual dumps then it is clear that flow and transport processes are likely to be highly variable both in space and time within test pile waste rock study sites the distinction between flow focusing through pathways that are generated during dump construction versus flow that follows a vertical pathway across structures has been noted in experimental piles e g in neuner et al 2013 who contrasts test piles from nichol et al 2005 and andrina 2009 when vertical flow is evenly distributed laterally as in set 2 lifts it can be used to the mine operators advantage as it promotes chemical mixing between leachate from different layers layering or mixing in specific rock types to create geochemical conditions that promote attenuation or containment of solutes in dumps are techniques that receive considerable attention in current waste rock research andrina 2009 hirsche et al 2017 however the uncertainties around how such conditions can be achieved are still large especially when degrees of flow channeling vary hirsche et al 2017 as our simulations show such variation may occur within lifts at various depths and within years as a function of infiltration dynamics and dampening of flow variability as lifts are progressively buried under new lifts the concentration distributions and increased variability of leaching efficiency for resident and surface applied solutes under constant infiltration rates imply that the outflow tail of mass release from a pile will probably be longer than what would be expected from tracer experiments in single lift test piles surface tracer infiltration experiments only reveal part of the transport connectivity within the waste rock piles when a variety of textures are present such experiments will typically overestimate the first flush transport connectivity and underestimate the transport connectivity of the tail of leaching of other internally loaded solutes from dumps in real dumps with multiple lifts and embedded texturally contrasting structures e g compaction lifts solutes that have been sequestered under high net percolation rates could be mobilized when buried to depths that only experience low percolation rates 5 conclusions this study presented numerical experiments of unsaturated flow and solute transport in a 2d domain with textural and structural variability in a climate zone where spring snow melt is an important event in the hydrological year while simplified in terms of textural contrasts and geometry the model results highlight that highly variable water content and concentration distributions should not necessarily be interpreted as indicators of inefficient leaching at the dump scale early arrival of water and mass at specific points and times at the bottom of a dump reflected the variable nature of flow and transport but did not provide definite answers to the areas within the dump that contributed to this variability depending on the textural contrasts the geometrically connected structures in the lifts promoted efficient flow through coarser conduits set 3 lifts or along textural interfaces set 1 lifts the geometries could not be used to predict peak outflow locations at the bottom of dumps because the presence and strength of flow focusing along textural interfaces varied within the formations and over time in regions with distinct percolation seasons such as western canada the snowmelt period is the primary driver of efficient flow and transport and geometry and texture guided fast and focused flow during this period however the low percolation periods provided ample opportunity for solutes to diffuse and be leached during subsequent high percolation events this behavior was subtly different from the seasonal flow switching we hypothesized in that both finer and coarser domains contributed to flow and leaching under low percolation conditions rather the focusing and barrier functions of textural interfaces disappeared and vertical flow dominated during low percolation periods increasing the extent of hydrological activity of the lifts these observations underscore the need for continued monitoring of integrated flow and mass release from full scale dump structures as well as sampling of internal variability of water content and solute concentrations to fully evaluate the long term dynamics in both mass and water release our simulations show that designing an adequate internal monitoring scheme is challenging because observations can only be meaningfully interpreted in a larger context of geometry texture and percolation dynamics the relationship between percolation rate and the variability of leaching efficiency observed in our simulations also highlights the need to consider changes in a waste rock dump s water balance when it is reclaimed bare uncovered waste rock dumps will have a higher more dynamic rate of percolation than reclaimed vegetated dumps this change in the magnitude and the spatial variability in percolation will result in substantive differences in the rates and pathways of water and mass release from the dump as lower percolation rates will most likely limit the formation of zones isolated from active water flow and chemical transport acknowledgments financial support was provided by teck resources ltd and funding through a syncrude nserc industrial chair slb grant 428588 11 
888,assessing the impacts of land use lu and climate change on future streamflow projections is necessary for efficient management of water resources however model projections are burdened with significant uncertainty arising from various sources most of the previous studies have considered climate models and scenarios as major sources of uncertainty but uncertainties introduced by land use change and hydrologic model assumptions are rarely investigated in this paper an attempt is made to segregate the contribution from i general circulation models gcms ii emission scenarios iii land use scenarios iv stationarity assumption of the hydrologic model and v internal variability of the processes to overall uncertainty in streamflow projections using analysis of variance anova approach generally most of the impact assessment studies are carried out with unchanging hydrologic model parameters in future it is however necessary to address the nonstationarity in model parameters with changing land use and climate in this paper a regression based methodology is presented to obtain the hydrologic model parameters with changing land use and climate scenarios in future the upper ganga basin ugb in india is used as a case study to demonstrate the methodology the semi distributed variable infiltration capacity vic model is set up over the basin under nonstationary conditions results indicate that model parameters vary with time thereby invalidating the often used assumption of model stationarity the streamflow in ugb under the nonstationary model condition is found to reduce in future the flows are also found to be sensitive to changes in land use segregation results suggest that model stationarity assumption and gcms along with their interactions with emission scenarios act as dominant sources of uncertainty this paper provides a generalized framework for hydrologists to examine stationarity assumption of models before considering them for future streamflow projections and segregate the contribution of various sources to the uncertainty keywords nonstationarity hydrologic model segregation uncertainty anova 1 introduction projecting the hydrologic impacts of land use lu and climate change is necessary for developing adaptive water resources management policies hydrologic models are most widely used tools for performing impact assessment studies using a hydrologic model for such studies involves calibrating the model by optimizing the model parameters to match the model simulations with observed records usually a single split sample technique is followed where the model is calibrated for a particular time slice and then validated over another time slice li et al 2012 this process is based on the implicit assumption of hydrologic model stationarity in which the calibrated model parameters are assumed to be time invariant milly et al 2008 assessing the applicability of this assumption is necessary to ensure the transferability of the model to future time periods recently temporal variability of the hydrologic model parameters is also addressed in model calibration merz et al 2011 evaluated time stability of model parameters by calibrating the model for 6 consecutive 5 year periods and concluded that the impact of assuming model parameters to be stationary on model output can be significant li et al 2012 assessed the transferability of hydrologic models by splitting the data into 120 time windows over 4 climatic periods they observed that the model calibrated under one set of the climatic condition is transferable only to time periods having similar climatic conditions from the literature it is clear that the assumption of stationarity may not be valid for all the cases and caution should be exercised while transferring a model to future conditions hereafter nonstationarity of hydrologic model parameters will be referred to as nonstationarity of the hydrologic model for simplicity further impact assessment studies involve a cascade of uncertainty sources such as lu projections climate models and scenarios model assumptions along with inherent variability of the system bastola et al 2011 bosshard et al 2013 that contribute significantly to the uncertainty in streamflow projections performing hydrologic impact analysis within the uncertainty framework is essential for quantifying future water availability beven 2002 wheater and gober 2013 numerous studies in the past used a combination of aforementioned sources with an attempt to reduce uncertainty in streamflow simulations but segregating the contribution of individual sources to uncertainty in hydrologic projections is rarely considered the factors mentioned earlier i e lu projections climate models model assumptions and internal variability of the system in general do not contribute equally to the uncertainty in streamflow projections it is therefore necessary to segregate their individual contribution to gain insight into the importance of each source in this regard a few studies deal with uncertainty contribution from various sources jung et al 2011 addor et al 2014 exbrayat et al 2014 hingray and said 2014 mockler et al 2016 parajka et al 2016 and whateley and brown 2016 wilby and harris 2006 quantified uncertainty from general circulation models gcms emission scenarios downscaling hydrologic model parameters and model structure within the probabilistic framework and observed that gcms and downscaling technique are significant sources of uncertainty to changes in low flow regime of thames river bosshard et al 2013 used a combination of 8 climate models 2 post processing techniques and 2 hydrologic models to quantify uncertainty from these sources on hydrologic projections in alpine rhine and reached a similar conclusion that the climate models are the dominant source of uncertainty more recently the work of mockler et al 2016 assessed the importance of rainfall and model parameters along with their interactions on hydrologic model simulations they found that rainfall along with the choice of hydrologic model has a significant contribution to the uncertainty none of the studies conducted earlier consider simultaneously nonstationarity in the hydrologic model and lu change as the source of uncertainty in streamflow projections with this background this study aims at decomposing the streamflow uncertainty into the contribution from various sources under nonstationary model conditions specifically three objectives are undertaken in this study 1 investigating the effect of nonstationary model parameters in the hydrologic model 2 assessing the difference in hydrologic impacts of future lu and climate scenarios under nonstationary and stationary model conditions and 3 segregating the contribution of different sources to the uncertainty for exploring nonstationarity in the hydrologic model a multiple split sample approach is used the contribution of different sources to the uncertainty in model output projected streamflow is quantified using the analysis of variance anova approach it is to be noted that variance or spread in the projections is referred to as uncertainty in this paper uncertainty sources considered are i gcms ii emission scenarios sce iii lu iv hydrologic model parameters mp assumed to be stationary or nonstationary and v and internal variability iv of the system fig 1 presents the framework of the methodology followed in this paper upper ganga basin ugb located in northern india is selected as the study region for analysis fig 2 ganga basin is densely populated 44 of india s population according to the census report 2011 and is of great socio economic importance to india it occupies 30 of india s cropland area uncertainty assessment in the present work is carried out by employing a semi distributed variable infiltration capacity vic hydrologic model liang et al 1994 a key feature of the vic model lies in its ability to represent land surface in the form of grids where the size of each grid can vary from 1 8 to 2 each grid can have multiple soil layers but typically 3 layers are considered within a vic model grid heterogeneity in vegetation is represented in the form of tiles owing to the difference in the land surface properties each tile generates varying response to the input precipitation through infiltration soil moisture storage evapotranspiration and runoff for each grid water balance equation is solved to obtain different components of the hydrologic cycle a complete description of the vic model is provided in detail by liang et al 1994 liang et al 1996 and nijssen et al 1997 once vic concludes the computation of water balance for each grid within the watershed streamflow is simulated by employing a separate routing model lohmann et al 1996 1998a b the following section describes data used followed by the description of the methodology employed in this work 2 data and methods 2 1 study area and observed data the study region upper ganga basin ugb in india spans 25 30 n 31 30 n in latitude and 77 30 e 80 e in longitude with an approximate area of 96 000 km2 fig 2 topographic information of the region is obtained data from aster advanced spaceborne thermal emission and reflection radiometer dem digital elevation model available at 30 m spatial resolution significant variation in the topographic profile of the region can be observed from upstream to downstream reaches of the ugb fig 2 based on the distinct topography and lu the ugb is divided into three sub basins fig 2 upstream from the upstream most point of the basin till bhimgodha outlet covering 24 of the ugb midstream from bhimgodha to ankinghat outlet 63 of the ugb and downstream from ankinghat to the basin outlet at allahabad covering 13 of the ugb further details pertaining to the study area are described elaborately by chawla and mujumdar 2015 the diversity in the physiography and climatology of the region makes this as an interesting case study to pursue in the current context observed or historic rainfall maximum temperature and minimum temperature for the present study is acquired from indian meteorological department rajeevan et al 2006 and wind speed is procured from princeton university sheffield et al 2006 climate data from both the sources are brought to a common resolution of 0 5 which is also the scale at which the vic model is executed in the present work observed streamflow data is obtained from uttar pradesh irrigation department and central water commission cwc the observed streamflow in the ugb is available for two locations a bhimgodha 1987 2011 and b ankinghat 1977 2009 fig 2 at monthly scale the vic model calibration and validation is carried out at these locations however between bhimgodha and ankinghat several control structures are located fig 2 b the effect of these control structures is taken into account by converting the observed regulated flow to naturalized flow considering the outflow from the bhimgodha barrage and the discharges in the canals the data of bhimgodha barrage operations and the discharges in the canals were procured from the cwc the naturalized flow data thus obtained is used for model calibration and validation soil dataset used in this study is obtained from the national bureau of soil survey and land use planning nbss lup 2 2 future land use and climate projections land use lu is considered as a major driver of change in water resources vörösmarty et al 2000 defries and eshleman 2004 oki and kanae 2006 therefore modeling spatio temporal changes in the lu pattern of a region and understanding its implication on hydrologic processes have drawn significant attention in the recent decade buytaert et al 2007 randhir and tsvetkova 2011 wilson and weng 2011 öztürk et al 2013 in order to assess future estimates of water resources in a region future projections of lu are required which serve as key input for the hydrologic model a wide range of spatially explicit lu models are available to obtain future lu projections of a region a review of which is presented in verburg et al 2004 and mas et al 2014 these models perform change projection by empirically relating the transitions of interests with driving variables of lu change mas et al 2014 spatial distance between these variables and the target layer comprising of pixels being mapped for change in future is calculated and considered as an input data for lu change modeling in this paper a neural network based lu model is considered for projecting lu into the future to achieve this digitized network of roads streams urban areas elevation and slope are considered as driving variables output layer comprises of temporal transitions such as forest to crop land or barren land to the urban area to be modeled further details related to lu modeling using the neural network which are beyond the scope of this paper can be obtained from atkinson tatnall 1997 and eastman 2009 the process of projecting lu into the future is carried out in two stages in the first stage observed lu maps for the years 1980 and 2000 are used to simulate lu for the year 2011 observed lu maps for the region are created using the landsat imageries results and accuracy are provided by chawla and mujumdar 2015 simulated lu map of 2011 is compared with the observed map of 2011 for determining the potential errors this exercise acts as validation to assess the ability of the lu model to appropriately predict changes using the considered set of drivers further details pertaining to validation of the lu model are provided in appendix a the model was found to replicate the spatial pattern of lu of the year 2011 with a reasonable accuracy areas under different lu categories are also found to be close to each other in the two images appendix a table a 1 post validation lu maps of 2000 and 2011 are used to predict lu for the year 2020 further using the observed map of 2011 and predicted map of 2020 lu is projected for 2030 the same process is repeated using the maps to 2020 and 2030 to obtain lu for the year 2040 due to uncertainty associated with the transition that may be dominant in future 4 plausible lu scenarios are generated table 1 the entire procedure for lu modeling is carried out within the land change modeler framework of the idrisi model https clarklabs org fig 3 presents results corresponding to scenario 1 across the three years for which lu is simulated the lu projection maps for rest of the scenarios along with the percentage of area under various lu categories as obtained for different years under different lu scenarios are presented in appendix b there are two major limitations associated with lu projections verburg et al 2004 first lu modeling assumes that the transitions that occurred in the past may occur in future making this framework applicable for only short term projections and second if the ongoing trend in lu categories changes in future due to any reason the methodology becomes incapable of projecting the change due to these limitations projections of lu for only three time steps ahead in future are carried out in the present work climate projections for a period of 129 years 1971 2099 were procured from the coupled model intercomparison project cmip5 gcm simulations the projected data was provided by the coordinated regional climate downscaling experiment cordex south asia group http cccr tropmet res in cordex index jsp at daily scale for 2 representative concentration pathway rcp climate scenarios rcp 4 5 signifies low to medium warming scenario in future and rcp 8 5 high warming future scenario 6 cmip5 gcms as selected by chawla and mujumdar 2015 which provide data corresponding to all the requisite input variables rainfall p maximum temperature t max minimum temperature t min and wind speed ws for the vic model are considered in the present work table c 1 the output variables from all the gcms are interpolated to a grid resolution of 0 5 in order to match the spatial resolution of the historic observed data for the study region climate outputs obtained from the gcms are bias corrected at the grid level with respect to the observed record before being used for hydrologic modeling details pertaining to bias correction and performance of gcms after bias correction may be obtained from chawla and mujumdar 2015 overall model performance evaluated by comparing monthly climatology and computing correlation metric between model outputs and observed data in the present study is found to be reasonably good 0 6 0 7 for p and 0 95 for t max and t min for all the models due to which all the 6 models for 2 climate scenarios are considered for hydrologic simulations under future scenarios to understand the behavior of climate variables under future scenarios 2006 2099 mean mean and different quantile values 5th quantile q 5 50th quantile q 50 and 95th quantile q 95 across 6 gcms are computed for 3 climate variables p t max and t min results of which are presented as boxplots in fig 4 historic values 1971 2005 for different climate variables are also shown in the same plot as red dots the historic values presented in fig 4 are the long term averages for instance historic time series comprises of 35 annual values for a climate variable mean and quantiles across these 35 values are obtained and presented as red dots in fig 4 red bars through the mean values are standard deviations of the annual series similarly for future 12 projections corresponding to 6 gcms and 2 scenarios are available each projection has a series of 94 annual values mean and quantiles across these 94 values for the 12 projections are shown as box plots in fig 4 from fig 4 it can be inferred that in general annual p may decrease across all the three regions in the ugb in future compared to historic observed values however in upstream and midstream regions a slight increase in the magnitude of low p events may occur in future although the decrease in the magnitude of high rainfall events q 95 is noticed higher variability across the gcms is observed in this case annual t max and t min in upstream and midstream regions are found to increase in future time periods approximately 2 and 1 rise in temperature is observed for upstream and midstream regions respectively across mean and quantile values in case of t max and t min higher variability amongst the model values is observed for q 95 similar to the results obtained for p this indicates higher uncertainty in the gcms to simulate extreme events in general for upstream and midstream regions with the decrease in p and increase in annual t max and t min more losses are expected from the region that could lead to water deficit conditions in these regions for the downstream region mean and q 50 values of future annual t max and t min are observed to be comparable to the historic values while p is noticed to decrease for both the cases this could lead to the reduction in water availability in the basin for the q 5 values of the downstream region all the three variables are observed to decrease therefore the influence on water availability might be minimum in this case as the reduction in p will get balanced by the decrease in the amount of losses from the region the climate projections 6 gcms for 2 climate scenarios along with 4 lu scenarios thus obtained are used to generate 48 plausible lu climate combinations which are fed into the vic model for the three regions of ugb execution of the vic model is facilitated by the calibration validation study over the historic time period 2 3 calibration of hydrologic model hybrid approach calibration of the hydrologic models can be carried out either manually or automatically to obtain best set of model parameter values in the present study for the vic model from the set of model parameters that need to be determined for model execution 3 parameters b ds and ws are identified which require calibration all the three parameters considered here are dimensionless b is an infiltration curve parameter which indirectly influences the surface runoff in general b parameter is inversely related to infiltration i e a high value of b parameter indicates low infiltration more surface runoff and vice versa ws parameter is the fraction of maximum soil moisture where nonlinear baseflow occurs a higher value of ws parameter will increase the amount of water content in the lowest soil layer required to initiate nonlinear baseflow as a consequence there will be high soil moisture storage ds parameter regulates the sub surface flow in the form of baseflow a high value of ds results in an increased nonlinear baseflow at lower water content there are studies reported in the literature demaria et al 2007 where parameters such as soil depth and saturated hydraulic conductivity are also considered in addition to the above mentioned parameters for calibration however for the present study all the parameters except the three mentioned above are derived from the digital soil map procured from nbss lup which limits the number of parameters that require calibration to three parameter estimation in the current work is carried out using a hybrid approach where knowledge of manual calibration is integrated with automatic calibration automatic calibration of the vic model is carried out by coupling it with an optimization algorithm which searches the feasible parameter space defined by upper and lower bounds of each of the parameters with an objective of minimizing the error between observed and simulated streamflows optimization algorithm in this study is employed by means of an optimization program referred to as parameter estimation pest doherty 2001 which has been used extensively in applications related to water resources govender and everson 2005 goegebeur and pauwels 2007 wang and brubaker 2015 through this work pest vic interface is established for effective implementation of optimization algorithm to obtain best parameter estimates of the vic model for the ugb typically the optimization algorithm carries out search towards attaining global minima parameters where the objective function is minimized by initiating the procedure from a random starting point which plays an important role in achieving the desired output if this starting point is selected to be far away from optimum the optimization algorithm can fail in pointing out the real best set of parameters and also unqualified outside the feasible parameter space starting point may increase the computational expense hence in order to address these issues a hybrid calibration procedure is employed wherein the knowledge gained from manual calibration is utilized in providing an appropriate starting point to the automatic calibration the outcomes of manual calibration of the vic model over the ugb are obtained from the analysis carried out by chawla and mujumdar 2015 in the present work the pest model is executed with an objective function of minimizing the squared sum of errors sse between model simulated streamflow q sim values and observed streamflow q obs details pertaining to the concept of pest model can be obtained from doherty 2001 and goegebeur and pauwels 2007 2 4 stationarity assumption of the hydrologic model the vic model is initially calibrated for the historic time period through a single split sample approach using hybrid calibration wherein data is divided into 60 and 40 for calibration and validation respectively information from the associated model parameters is used for projection of streamflows in the future time period typically the model is assumed to be stationary in this case wherein a fixed set of parameters is used for generating future streamflows without assessing their temporal dynamics this might lead to unreliable streamflow estimates hence there is a need to assess stationarity assumption of model parameters to deduce if parameters can be kept constant in the future time period in order to investigate model stationarity multiple split sample procedure is followed wherein the entire time period available for calibration is divided into several small time slices ts and the vic model is executed independently through hybrid calibration over each ts to obtain a series of model parameters through which insights can be gained over temporal variability of the parameters the time slicing is carried out by considering widths of 1 yr through 5 yr for example a 3 yr width time slicing carried out from 1987 to 2004 consists of a total of 6 time periods 1987 89 1990 92 1993 95 1996 98 1999 2001 2002 04 within which the vic model is independently calibrated for each of the time period construction of single and multiple split sample procedures to test model stationarity is depicted in fig 5 the whole modeling exercise at this stage is aimed to address the research questions is the model stationary in time and can be directly transferred to future scenarios results of this experiment are presented in section 3 2 to assess the effect of model stationarity on streamflow simulations within a particular ts the model parameter values obtained for the first time period are used to simulate streamflows for rest of the time periods in data series for instance for 6 time periods of the 3 yr time slice model parameters obtained for the first time period are used to execute the vic model for the other 5 time periods this is referred to as verification stage the results of same are presented in section 3 2 2 5 uncertainty quantification to quantify uncertainty in streamflow projections a total of 96 simulations are considered 48 corresponding to changing lu and climate combinations under nonstationary model conditions and other 48 with changing lu and climate but with stationary model conditions for stationary model condition parameters obtained from the calibration of the vic model through single split sample procedure are used to obtain streamflow projections however for obtaining streamflow simulations under nonstationary model conditions the parameters of calibrated vic model in the historic time period are projected into future by developing a quantitative relationship between model parameters obtained for 1 yr ts and climate variables assuming that the relationship will hold good for the future time period further details for the same are presented in section 3 3 the contribtuion of different factors to uncertainty in simulated streamflow is quantified using the anova framework von storch and zweirs 2001 yip et al 2011 bosshard et al 2013 herein the difference between simulated value and observed value eq 1 is considered as the input for segregating the uncertainty contribution from different factors the analysis is carried out using mean q 5 q 50 and q 95 as summary statistics for streamflow 1 δ x x mod x o b s x m e a n q 5 q 50 q 95 where x mod and xobs respectively represent the model simulated and observed values for a given x a multifactor anova model is constructed with gcms represented as α with 6 gcms represented as i 6 levels in the anova model sce β j 2 levels lu γ k 4 levels mp stationary or nonstationary δ l 2 levels and iv of the system ε as the contributing factors eq 2 the interaction between these factors which represent the nonlinear effect on uncertainty is also considered as a contributing source 2 δ x μ α i β j γ k δ l α β i j α γ i k α δ i l β γ j k β δ j l γ δ k l ɛ i j k l the total variance in the streamflow projection is given by the total sum of squares sst and is decomposed to the sum of squares from contributors and their interactions sum of squares from different sources is represented as ssf f α β γ δ ε furthermore the interaction between different sources is given as ssn n αβ αγ αδ βγ βδ γδ eq 3 provides the multifactor anova model considered in this study 3 s s t s s α s s β s s γ s s δ s s α β s s α γ s s α δ s s β γ s s β δ s s γ δ s s ɛ variance contribution η2 of each source is computed as the ratio between ssf or ssn and sst for example η α 2 s s α s s t similarly η2 for all the factors is calculated and has a value between 0 and 100 percent where 0 percent means no contribution of a particular factor while 100 percent means that the given factor is solely responsible for uncertainty in the output further details related to the anova approach can be obtained from bosshard et al 2013 and parajka et al 2016 3 results and discussion 3 1 calibration and validation of the hydrologic model the vic model is initially calibrated and validated through the single split sample procedure hybrid approach for the upstream and midstream regions of the ugb section 2 3 in case of the upstream region 13 years 1987 99 and 6 years 2000 05 of q obs records are used for calibration and validation respectively at monthly scale the midstream region is calibrated and validated using 19 years 1977 95 and 10 years 1996 05 of q obs respectively at monthly scale results for the calibration and validation phase are shown in fig 6 the model performance is assessed at monthly scale using the statistics of normalized root mean squared error e nrmse coefficient of determination r 2 nash sutcliffe efficiency e nse and bias b where positive sign of b indicates that the model overestimates the streamflow and vice versa results of the model performance are presented in table 2 the peaks are found to be under estimated consistently during calibration and validation since modeling of extremes is not the focus of present work this misfit is deemed not to be a major concern the values of the performance measures shown in table 2 indicate good performance of the hybrid method particularly in terms of b however during validation phase fig 6 b d the performance of the model deteriorated the deterioration during validation could be due to two factors one the vic model might have been subjected to over fitting during the calibration phase and two the low flows during validation phase are observed to be slightly overestimated although rest of the features are found to be comparable to that of calibration phase which could have resulted in poor performance metrics these results indicate that despite the good performance of the model caution needs to be exercised while using the model for validation purpose the contrasting behavior of the vic model during the two different time periods raises a necessity to understand stationarity of the model with time to determine if model calibrated at certain time period is indeed transferable to the future time period the following section addresses this issue by analyzing the temporal variability of the vic model parameters and the influence of chosen time slice for calibration on the model simulations 3 2 assessing stationarity of the vic model to assess stationarity of the vic model the optimum set of parameters obtained in each of the time slicing experiments section 2 4 are analyzed for their temporal variability it is observed that during 1 yr and 2 yr time slicing exercise model parameters exhibited high variability due to which meaningful interpretation could not be made from 3 yr ts onwards temporal variability of the model parameters is observed to be more prominent hence results pertaining to 3 yr ts are used to generalize the temporal behavior of model parameters 4 yr and 5 yr ts have less number of time periods due to which they are not considered for generalization either fig 7 presents results pertaining to this experiment 3 yr ts for upstream region of the ugb fig 7 a c present total p average t max and average t min for the specified time period respectively and fig 7 d f present the temporal variability of b ds and ws parameter values respectively results from the experimental investigation indicate that all the 3 parameters exhibit temporal variability indicating nonstationarity in the hydrologic model therefore it is now of interest to understand the causal factors for temporal changes in the model parameters previous works by demaria et al 2007 and troy et al 2008 have shown vic parameters to be sensitive to climate in this paper a non linear spearman rank correlation coefficient is used to determine the dependence between model parameters and climate indicators results for which are presented in appendix d table d 1 it is observed that b and ds parameters are strongly correlated to p while ws parameter is highly correlated with t max and t min the relationship between model parameters and climate variables is also shown in fig 7 in general across any two time periods a decrease in p is accompanied by an increase in b parameter value which indicates the reduction in infiltration of water into the soil a drop in the value of t max and t min may cause the decrease in losses from the system consequently ws parameter value may decrease or vice versa the decrease in the value of ws parameter is linked with an increase in ds parameter value demonstrating an increase in baseflow contribution at low soil moisture content towards total runoff overall it can be inferred that b parameter is indirectly related to p whereas t max and t min have a direct relationship with ws parameter ds parameter complements the effect of variations in b and ws parameters similar behavior in model parameters with respect to the change in climate indicators is demonstrated by the midstream region of the ugb appendix e fig e 1 further to assess the effect of the nonstationary vic model on streamflow simulations bias b is estimated between q sim for calibration and verification phase section 2 4 for further information for each time period results of the analysis are presented in fig 8 if there is no effect of model parameters on streamflow simulations then b should be approximately equal to zero the analysis indicates that exclusive changes either in b or ds parameters will have a proportional effect over streamflow moreover a simultaneous increase in both b and ds parameters is observed to result in significant increase in streamflow it is also observed that an increase in b parameter along with a decrease in ws parameter leads to increase in streamflow and vice versa however the extent to which overestimation or underestimation of streamflow occurs depends on the amount by which each of the parameter value changes therefore it can be concluded that assuming the hydrologic model to be stationary may have a significant effect on streamflow projections consequently for assessing the contribution of different factors to uncertainty in streamflow projection nonstationarity should be considered it is now important to assess if the width of ts has any effect on the dynamics of streamflow simulations so as to comment if the inferences drawn above for the 3 yr time slice experiment can be applied to other ts experiments this inherently provides us with an insight about uncertainty due to the choice of ts during calibration the objective is addressed by initially executing the vic model under all the ts widths along with complete time period upstream 1987 05 midstream 1977 05 and the resulting q sim is compared with q obs using e nse and b measures the corresponding results are presented in fig 9 the performance measures indicate that all the ts except complete time period have well simulated the streamflows with comparable accuracies in both upstream and midstream regions consideration of complete time period resulted in poor simulations in both the regions this could be due to overestimation of flows during model validation phase section 3 1 it can be inferred from the results that changing ts width has minimal effect on the model through which it can be said that uncertainty due to the choice of ts is negligible and can be ignored in the current work from this section it is established that model parameters indeed vary over time with noticeable effect over streamflow simulations hence it can be concluded that the vic model is not stationary consequently not directly transferable to future scenarios i e calibrated model parameters obtained for the past cannot be applied directly to future conditions since it is evident from previous analysis that the model parameters are influenced by climate variables a regression mechanism is set up for the historic data by which model parameters for the future time periods are estimated 3 3 model parameters for future time periods the parameters of calibrated vic model in the historic time period are projected into future by developing a quantitative relationship between parameters and climate variables assuming that the relationship thus established will hold good for the future time period however the regression model to be setup is rather complicated due to multidimensional nature of both predictor 3 climate variables p t max and t min and predictand 3 model parameters b ws and ds datasets under such circumstances dattalo 2013 suggested that if the predictand variables are poorly correlated among themselves correlation ρ 0 2 then each of these variables can be modeled separately with respect to predictor variables in the present work the model parameters are observed to be uncorrelated due to which each one of the parameters is individually regressed with predictors for establishing the relationship support vector regression svr algorithm is employed wherein model parameters predictors and climate variables predictands corresponding to 1 yr width ts are considered which resulted in 19 and 29 number of datasets available in the upstream and midstream regions respectively these datasets are divided into 70 and 30 respectively for training and validation of relationship svr technique initially developed by cortes and vapnik 1995 has been widely applied in the past few decades for classification and regression analysis owing to its ability in solving large scale complex problems tripathi et al 2006 it is based on a general idea of mapping dependent variables nonlinearly to the high dimensional independent variables brief description of the svr algorithm is provided in appendix f further details can be obtained from cortes and vapnik 1995 smola 1996 smola et al 1998 hsu et al 2003 tripathi et al 2006 and ghosh 2010 results corresponding to training and validation of svr for the upstream and the midstream regions of the ugb are provided in terms of the correlation coefficient in table 3 the results indicate that in general svr has modeled parameters in the upstream and midstream regions with a reasonable accuracy despite slight inconsistency in validating ds parameter at the end of this modeling exercise each region contains 3 trained svr models corresponding to the b ds and ws parameters these models are fed with future projections of the 3 climate variables corresponding to the 6 gcms and 2 climate scenarios so as to obtain projected values of model parameters 3 4 hydrologic impacts of future land use and climate change the vic model with projected model parameters nonstationary model condition is executed in future time periods across 48 climate and lu scenarios to obtain future q sim for the ugb further the vic model is also run for the same set of lu and climate projections with model parameters obtained during the single split sample calibration procedure i e stationary model condition and the resulting streamflows act as a baseline fig 10 presents boxplots of summary statistics for the streamflow projections obtained for 48 projections under both nonstationary and stationary conditions along with historic observations streamflow is noticed to decrease in future for both nonstationary and stationary conditions this is due to decrease in rainfall and increase in temperature obtained for future projections across all the gcms fig 4 further amongst the two conditions streamflow is noticed to be significantly low for the nonstationary model this difference is attributed to contrast in model parameters b ws and ds used in two conditions under the stationary condition model parameters used for simulations are basically tuned for historic climate thus being insensitive to future climate projections due to strong dependency of model parameters with climate conditions section 3 2 parameters are misrepresented in stationary condition resulting in unrealistically higher future streamflows this issue is effectively addressed by implementing nonstationary vic model wherein model parameters for future time period vary according to prevalent climate resulting in lower streamflow projections for instance in the upstream region under the nonstationary condition average values of ws and b across all the gcms and sce are found to lie between 0 79 to 0 83 and 0 104 to 0 121 respectively whereas 0 63 and 0 137 respectively are the values considered in the stationary condition this resulted in higher streamflow for the latter condition for low flow case q 5 in upstream and midstream regions streamflow values under stationary conditions are found to be comparable to the historic values this could be due to the insignificant change in the low rainfall events in the two regions fig 4 further it indicates that the influence of the increase in temperature is not reflected in streamflow projections obtained using stationary hydrologic model condition however significantly lower streamflow is obtained for the nonstationary condition under the same case which could be due to increase in ws parameter values as a result of an increase in temperature in addition to this uncertainty in streamflow values for the nonstationary case is observed to be higher compared to the stationary case this could be due to variability in the model parameters and consequently in streamflow projections across different gcms and sce for high flows q 95 uncertainty is observed to be maximum as reflected through widest box plot amongst all the cases although most of the values are either below the historic values of lie towards the lower end they are exceeding the stationary values in some cases a mismatch between the parameters obtained for high rainfall events could be the cause for obtaining these varying values this implies that the methodology should be exercised with caution for high rainfall events a separate relationship in such situation might reduce the uncertainty in simulations 3 5 uncertainty contribution from different sources as described in section 2 5 uncertainty in the streamflow projections is decomposed into individual components gcms sce lu mp and iv using the anova approach results for three regions of ugb are presented in fig 11 gcms and mp assumption of nonstationary and stationary are observed to be the primary source of uncertainty across all the three regions and for most of the cases this could be due to the fact that there is a noteworthy difference in the streamflow projections obtained for different lu and climate scenarios under stationary and nonstationary conditions and also within each of these conditions q 95 of midstream and downstream regions exhibited significant variability for both nonstationary and stationary model conditions therefore gcms contribution to q 95 case is observed to be less in comparison to the mean case further uncertainty contribution from mp towards change in q 5 of midstream and downstream regions is noticed to be very high 96 and 82 respectively this is attributed to significant difference between the low flows obtained under the two conditions for midstream and downstream regions interactions between gcms sce gcms mp and sce mp are found to be the next significant contributor with contribution ranging between 30 50 across all the cases except q 5 case of midstream and downstream regions this indicates that gcms sce and model assumptions should be considered together for future assessment of water resources within the uncertainty framework in addition to this contribution from lu and iv is found to be less but not negligible from this analysis it can be inferred that consideration of hydrologic model to be stationary or nonstationary might be a significant source of uncertainty in future streamflow projections to understand the influence of other factors on uncertainty a separate set of analysis is performed where streamflow projections only from nonstationary model conditions are considered result pertaining to the same are presented in fig 12 in the nonstationary case gcms and sce are observed to be the dominant contributor to uncertainty in streamflow across all the cases this is expected due to variability in the streamflow simulations under nonstationary conditions for different models and scenarios for upstream and midstream regions the contribution from lu is also noticeable in all the cases however this contribution is not observed for the downstream region this could be due to the lesser contributing area in the downstream region least amongst the three sub basins the effect of the amount of contributing area is also seen in the results for the other two regions wherein midstream region having maximum basin area has highest lu contribution towards uncertainty which reduces for the upstream region 4 summary and conclusions this paper sought to address two main objectives first assessing the influence of model stationarity on future streamflow simulations and second quantify the contribution of gcms emission scenarios lu model parameters and internal variability of the hydrologic model to uncertainty in streamflow projections a semi distributed vic hydrologic model combined with the pest optimization algorithm is used to carry out the analysis calibration of the vic model is carried out through a hybrid approach which involves integrating the manual calibration with that of automatic calibration using the pest model through time slicing experiment it is noticed that the model parameters exhibit temporal variability thus leading to the necessity of using a nonstationary model for streamflow projections streamflow is observed to decline under future lu and climate conditions further low flows are observed to be critically low which may become a matter of concern for assessment of future water availability upon segregating the contribution of different factors to uncertainty in streamflow projections it is observed that gcms and model assumption of stationary and nonstationary conditions are the major source of uncertainty within the nonstationary case gcms are found to be the dominant contributor to the uncertainty in streamflow projections it is also revealed that the nonlinear interactions between gcms and scenarios are important for uncertainty quantification in streamflow projections streamflow is noticed to be sensitive to subtle changes in the lu the key aspect of this paper is that the hydrologic models cannot be assumed to be stationary for impact assessment studies instead it can be the significant source of uncertainty in the model output in addition to this future lu scenarios can also contribute towards uncertainty although the results presented in this paper are not directly applicable to another catchment with different hydrological properties the methodology presented is general and can be performed independently of the study area this study will be helpful for assessing future impacts of lu and climate change on streamflow within the uncertainty framework 4 1 limitations and future scope analysis presented in this paper is subjected to a few limitations a segregation results obtained are limited to the gcms selected for the study b uncertainty in streamflow simulations due to model structure is not considered c irrigation and groundwater extraction which are dominant phenomenon in the region misra 2011 madhusoodhanan et al 2016 may also be a source of uncertainty which are not included in the present model set up d due to the drawbacks associated with lu modelling lu could be projected only for a short time in future 2040 and e optimization of the hydrologic model is carried out based on a single objective function the multi objective optimization of the vic model with evapotranspiration and soil moisture might improve the results and should be attempted in future work in addition to the above mentioned limitations care should be exercised while using the hydrologic model for simulating extreme rainfall events as it is observed that the vic model doesn t capture the extremes well in the present case study section 3 1 appendix a validation results of the lu model fig a 1 along with table a 1 present the area under different lu categoried for observed and simulated lu map of the year 2011 the accuracy of the simulated map of 2011 is measured using kappa index of agreement kia originally developed by pontius 2000 value of kia may lie between 0 to 1 where 1 indicates perfect agreement between simulated and observed images and 0 indicates that the agreement is as good as expected by chance in this paper three variants of kia pontius 2000 are used table a 2 to measure different characteristics pertaining to simulation capability of the lu model the quantitative kia metrics indicate that the lu model has simulated the quantity of correctly classified pixels with better accuracy than spatial accuracy however overall capability of the model to simulate change κstandard is observed to be reasonably good appendix b future land use lu projections corresponding to different scenarios from scenario 1 fig b 1 and table b 1 where changes in scrub forest and crop land areas are modeled a slight increase in both the categories can be observed from 2020 through 2040 this increase is noticed to be at the expense of dense forest category in case of scenario 2 which focuses on crop land changes an increase in this category is noticed for 2020 and 2030 at the expense of barren land and scrub forest categories however this scenario witnessed a slight unexpected decrease in crop land area during 2040 which is compensated with an increase in area under scrub forest this feature although negligible could be viewed as a modeling inconsistency scenario 3 fig b 2 which models changes in urban area witnessed urban area expansion from 2020 to 2040 at the cost of scrub forest and crop land areas this can be considered as an increase in the size of existing urban areas in the region in the coming years due to population growth lastly in scenario 4 fig b 3 where changes in crop land and urban areas are modeled through time increase in crop land area is observed to have replaced scrub forests from 2020 to 2040 while urban area remained constant after an initial increase in 2020 appendix c list of gcms considered in the present work appendix d appendix e appendix f quantitative relationship between model parameters and climate variables is established through support vector regression svr algorithm it is based on a general idea of mapping dependent variables nonlinearly to the high dimensional independent variables the formulation of svr is provided below consider a training sample of n datasets of predictors x and predictand y xi yi i 1 2 n where xi is the ith vector containing n number of predictor variables i e xi x i1 x i2 xin the structure of the svr is given by the following equation f 1 y i 1 n w i k x i x b where wi are the adjustable weights b is the bias y is an estimate of y and k is a kernel function the kernel function transforms the training data into high dimensional space so as to model nonlinear dependencies between predictors and predictand in the present work radial basis function rbf is used as a kernel function eq f 2 f 2 k x i x exp x i x 2 2 σ 2 where σ is the width of the rbf kernel svr systematically adjusts weights and bias with an objective of minimizing the error between y and y 
888,assessing the impacts of land use lu and climate change on future streamflow projections is necessary for efficient management of water resources however model projections are burdened with significant uncertainty arising from various sources most of the previous studies have considered climate models and scenarios as major sources of uncertainty but uncertainties introduced by land use change and hydrologic model assumptions are rarely investigated in this paper an attempt is made to segregate the contribution from i general circulation models gcms ii emission scenarios iii land use scenarios iv stationarity assumption of the hydrologic model and v internal variability of the processes to overall uncertainty in streamflow projections using analysis of variance anova approach generally most of the impact assessment studies are carried out with unchanging hydrologic model parameters in future it is however necessary to address the nonstationarity in model parameters with changing land use and climate in this paper a regression based methodology is presented to obtain the hydrologic model parameters with changing land use and climate scenarios in future the upper ganga basin ugb in india is used as a case study to demonstrate the methodology the semi distributed variable infiltration capacity vic model is set up over the basin under nonstationary conditions results indicate that model parameters vary with time thereby invalidating the often used assumption of model stationarity the streamflow in ugb under the nonstationary model condition is found to reduce in future the flows are also found to be sensitive to changes in land use segregation results suggest that model stationarity assumption and gcms along with their interactions with emission scenarios act as dominant sources of uncertainty this paper provides a generalized framework for hydrologists to examine stationarity assumption of models before considering them for future streamflow projections and segregate the contribution of various sources to the uncertainty keywords nonstationarity hydrologic model segregation uncertainty anova 1 introduction projecting the hydrologic impacts of land use lu and climate change is necessary for developing adaptive water resources management policies hydrologic models are most widely used tools for performing impact assessment studies using a hydrologic model for such studies involves calibrating the model by optimizing the model parameters to match the model simulations with observed records usually a single split sample technique is followed where the model is calibrated for a particular time slice and then validated over another time slice li et al 2012 this process is based on the implicit assumption of hydrologic model stationarity in which the calibrated model parameters are assumed to be time invariant milly et al 2008 assessing the applicability of this assumption is necessary to ensure the transferability of the model to future time periods recently temporal variability of the hydrologic model parameters is also addressed in model calibration merz et al 2011 evaluated time stability of model parameters by calibrating the model for 6 consecutive 5 year periods and concluded that the impact of assuming model parameters to be stationary on model output can be significant li et al 2012 assessed the transferability of hydrologic models by splitting the data into 120 time windows over 4 climatic periods they observed that the model calibrated under one set of the climatic condition is transferable only to time periods having similar climatic conditions from the literature it is clear that the assumption of stationarity may not be valid for all the cases and caution should be exercised while transferring a model to future conditions hereafter nonstationarity of hydrologic model parameters will be referred to as nonstationarity of the hydrologic model for simplicity further impact assessment studies involve a cascade of uncertainty sources such as lu projections climate models and scenarios model assumptions along with inherent variability of the system bastola et al 2011 bosshard et al 2013 that contribute significantly to the uncertainty in streamflow projections performing hydrologic impact analysis within the uncertainty framework is essential for quantifying future water availability beven 2002 wheater and gober 2013 numerous studies in the past used a combination of aforementioned sources with an attempt to reduce uncertainty in streamflow simulations but segregating the contribution of individual sources to uncertainty in hydrologic projections is rarely considered the factors mentioned earlier i e lu projections climate models model assumptions and internal variability of the system in general do not contribute equally to the uncertainty in streamflow projections it is therefore necessary to segregate their individual contribution to gain insight into the importance of each source in this regard a few studies deal with uncertainty contribution from various sources jung et al 2011 addor et al 2014 exbrayat et al 2014 hingray and said 2014 mockler et al 2016 parajka et al 2016 and whateley and brown 2016 wilby and harris 2006 quantified uncertainty from general circulation models gcms emission scenarios downscaling hydrologic model parameters and model structure within the probabilistic framework and observed that gcms and downscaling technique are significant sources of uncertainty to changes in low flow regime of thames river bosshard et al 2013 used a combination of 8 climate models 2 post processing techniques and 2 hydrologic models to quantify uncertainty from these sources on hydrologic projections in alpine rhine and reached a similar conclusion that the climate models are the dominant source of uncertainty more recently the work of mockler et al 2016 assessed the importance of rainfall and model parameters along with their interactions on hydrologic model simulations they found that rainfall along with the choice of hydrologic model has a significant contribution to the uncertainty none of the studies conducted earlier consider simultaneously nonstationarity in the hydrologic model and lu change as the source of uncertainty in streamflow projections with this background this study aims at decomposing the streamflow uncertainty into the contribution from various sources under nonstationary model conditions specifically three objectives are undertaken in this study 1 investigating the effect of nonstationary model parameters in the hydrologic model 2 assessing the difference in hydrologic impacts of future lu and climate scenarios under nonstationary and stationary model conditions and 3 segregating the contribution of different sources to the uncertainty for exploring nonstationarity in the hydrologic model a multiple split sample approach is used the contribution of different sources to the uncertainty in model output projected streamflow is quantified using the analysis of variance anova approach it is to be noted that variance or spread in the projections is referred to as uncertainty in this paper uncertainty sources considered are i gcms ii emission scenarios sce iii lu iv hydrologic model parameters mp assumed to be stationary or nonstationary and v and internal variability iv of the system fig 1 presents the framework of the methodology followed in this paper upper ganga basin ugb located in northern india is selected as the study region for analysis fig 2 ganga basin is densely populated 44 of india s population according to the census report 2011 and is of great socio economic importance to india it occupies 30 of india s cropland area uncertainty assessment in the present work is carried out by employing a semi distributed variable infiltration capacity vic hydrologic model liang et al 1994 a key feature of the vic model lies in its ability to represent land surface in the form of grids where the size of each grid can vary from 1 8 to 2 each grid can have multiple soil layers but typically 3 layers are considered within a vic model grid heterogeneity in vegetation is represented in the form of tiles owing to the difference in the land surface properties each tile generates varying response to the input precipitation through infiltration soil moisture storage evapotranspiration and runoff for each grid water balance equation is solved to obtain different components of the hydrologic cycle a complete description of the vic model is provided in detail by liang et al 1994 liang et al 1996 and nijssen et al 1997 once vic concludes the computation of water balance for each grid within the watershed streamflow is simulated by employing a separate routing model lohmann et al 1996 1998a b the following section describes data used followed by the description of the methodology employed in this work 2 data and methods 2 1 study area and observed data the study region upper ganga basin ugb in india spans 25 30 n 31 30 n in latitude and 77 30 e 80 e in longitude with an approximate area of 96 000 km2 fig 2 topographic information of the region is obtained data from aster advanced spaceborne thermal emission and reflection radiometer dem digital elevation model available at 30 m spatial resolution significant variation in the topographic profile of the region can be observed from upstream to downstream reaches of the ugb fig 2 based on the distinct topography and lu the ugb is divided into three sub basins fig 2 upstream from the upstream most point of the basin till bhimgodha outlet covering 24 of the ugb midstream from bhimgodha to ankinghat outlet 63 of the ugb and downstream from ankinghat to the basin outlet at allahabad covering 13 of the ugb further details pertaining to the study area are described elaborately by chawla and mujumdar 2015 the diversity in the physiography and climatology of the region makes this as an interesting case study to pursue in the current context observed or historic rainfall maximum temperature and minimum temperature for the present study is acquired from indian meteorological department rajeevan et al 2006 and wind speed is procured from princeton university sheffield et al 2006 climate data from both the sources are brought to a common resolution of 0 5 which is also the scale at which the vic model is executed in the present work observed streamflow data is obtained from uttar pradesh irrigation department and central water commission cwc the observed streamflow in the ugb is available for two locations a bhimgodha 1987 2011 and b ankinghat 1977 2009 fig 2 at monthly scale the vic model calibration and validation is carried out at these locations however between bhimgodha and ankinghat several control structures are located fig 2 b the effect of these control structures is taken into account by converting the observed regulated flow to naturalized flow considering the outflow from the bhimgodha barrage and the discharges in the canals the data of bhimgodha barrage operations and the discharges in the canals were procured from the cwc the naturalized flow data thus obtained is used for model calibration and validation soil dataset used in this study is obtained from the national bureau of soil survey and land use planning nbss lup 2 2 future land use and climate projections land use lu is considered as a major driver of change in water resources vörösmarty et al 2000 defries and eshleman 2004 oki and kanae 2006 therefore modeling spatio temporal changes in the lu pattern of a region and understanding its implication on hydrologic processes have drawn significant attention in the recent decade buytaert et al 2007 randhir and tsvetkova 2011 wilson and weng 2011 öztürk et al 2013 in order to assess future estimates of water resources in a region future projections of lu are required which serve as key input for the hydrologic model a wide range of spatially explicit lu models are available to obtain future lu projections of a region a review of which is presented in verburg et al 2004 and mas et al 2014 these models perform change projection by empirically relating the transitions of interests with driving variables of lu change mas et al 2014 spatial distance between these variables and the target layer comprising of pixels being mapped for change in future is calculated and considered as an input data for lu change modeling in this paper a neural network based lu model is considered for projecting lu into the future to achieve this digitized network of roads streams urban areas elevation and slope are considered as driving variables output layer comprises of temporal transitions such as forest to crop land or barren land to the urban area to be modeled further details related to lu modeling using the neural network which are beyond the scope of this paper can be obtained from atkinson tatnall 1997 and eastman 2009 the process of projecting lu into the future is carried out in two stages in the first stage observed lu maps for the years 1980 and 2000 are used to simulate lu for the year 2011 observed lu maps for the region are created using the landsat imageries results and accuracy are provided by chawla and mujumdar 2015 simulated lu map of 2011 is compared with the observed map of 2011 for determining the potential errors this exercise acts as validation to assess the ability of the lu model to appropriately predict changes using the considered set of drivers further details pertaining to validation of the lu model are provided in appendix a the model was found to replicate the spatial pattern of lu of the year 2011 with a reasonable accuracy areas under different lu categories are also found to be close to each other in the two images appendix a table a 1 post validation lu maps of 2000 and 2011 are used to predict lu for the year 2020 further using the observed map of 2011 and predicted map of 2020 lu is projected for 2030 the same process is repeated using the maps to 2020 and 2030 to obtain lu for the year 2040 due to uncertainty associated with the transition that may be dominant in future 4 plausible lu scenarios are generated table 1 the entire procedure for lu modeling is carried out within the land change modeler framework of the idrisi model https clarklabs org fig 3 presents results corresponding to scenario 1 across the three years for which lu is simulated the lu projection maps for rest of the scenarios along with the percentage of area under various lu categories as obtained for different years under different lu scenarios are presented in appendix b there are two major limitations associated with lu projections verburg et al 2004 first lu modeling assumes that the transitions that occurred in the past may occur in future making this framework applicable for only short term projections and second if the ongoing trend in lu categories changes in future due to any reason the methodology becomes incapable of projecting the change due to these limitations projections of lu for only three time steps ahead in future are carried out in the present work climate projections for a period of 129 years 1971 2099 were procured from the coupled model intercomparison project cmip5 gcm simulations the projected data was provided by the coordinated regional climate downscaling experiment cordex south asia group http cccr tropmet res in cordex index jsp at daily scale for 2 representative concentration pathway rcp climate scenarios rcp 4 5 signifies low to medium warming scenario in future and rcp 8 5 high warming future scenario 6 cmip5 gcms as selected by chawla and mujumdar 2015 which provide data corresponding to all the requisite input variables rainfall p maximum temperature t max minimum temperature t min and wind speed ws for the vic model are considered in the present work table c 1 the output variables from all the gcms are interpolated to a grid resolution of 0 5 in order to match the spatial resolution of the historic observed data for the study region climate outputs obtained from the gcms are bias corrected at the grid level with respect to the observed record before being used for hydrologic modeling details pertaining to bias correction and performance of gcms after bias correction may be obtained from chawla and mujumdar 2015 overall model performance evaluated by comparing monthly climatology and computing correlation metric between model outputs and observed data in the present study is found to be reasonably good 0 6 0 7 for p and 0 95 for t max and t min for all the models due to which all the 6 models for 2 climate scenarios are considered for hydrologic simulations under future scenarios to understand the behavior of climate variables under future scenarios 2006 2099 mean mean and different quantile values 5th quantile q 5 50th quantile q 50 and 95th quantile q 95 across 6 gcms are computed for 3 climate variables p t max and t min results of which are presented as boxplots in fig 4 historic values 1971 2005 for different climate variables are also shown in the same plot as red dots the historic values presented in fig 4 are the long term averages for instance historic time series comprises of 35 annual values for a climate variable mean and quantiles across these 35 values are obtained and presented as red dots in fig 4 red bars through the mean values are standard deviations of the annual series similarly for future 12 projections corresponding to 6 gcms and 2 scenarios are available each projection has a series of 94 annual values mean and quantiles across these 94 values for the 12 projections are shown as box plots in fig 4 from fig 4 it can be inferred that in general annual p may decrease across all the three regions in the ugb in future compared to historic observed values however in upstream and midstream regions a slight increase in the magnitude of low p events may occur in future although the decrease in the magnitude of high rainfall events q 95 is noticed higher variability across the gcms is observed in this case annual t max and t min in upstream and midstream regions are found to increase in future time periods approximately 2 and 1 rise in temperature is observed for upstream and midstream regions respectively across mean and quantile values in case of t max and t min higher variability amongst the model values is observed for q 95 similar to the results obtained for p this indicates higher uncertainty in the gcms to simulate extreme events in general for upstream and midstream regions with the decrease in p and increase in annual t max and t min more losses are expected from the region that could lead to water deficit conditions in these regions for the downstream region mean and q 50 values of future annual t max and t min are observed to be comparable to the historic values while p is noticed to decrease for both the cases this could lead to the reduction in water availability in the basin for the q 5 values of the downstream region all the three variables are observed to decrease therefore the influence on water availability might be minimum in this case as the reduction in p will get balanced by the decrease in the amount of losses from the region the climate projections 6 gcms for 2 climate scenarios along with 4 lu scenarios thus obtained are used to generate 48 plausible lu climate combinations which are fed into the vic model for the three regions of ugb execution of the vic model is facilitated by the calibration validation study over the historic time period 2 3 calibration of hydrologic model hybrid approach calibration of the hydrologic models can be carried out either manually or automatically to obtain best set of model parameter values in the present study for the vic model from the set of model parameters that need to be determined for model execution 3 parameters b ds and ws are identified which require calibration all the three parameters considered here are dimensionless b is an infiltration curve parameter which indirectly influences the surface runoff in general b parameter is inversely related to infiltration i e a high value of b parameter indicates low infiltration more surface runoff and vice versa ws parameter is the fraction of maximum soil moisture where nonlinear baseflow occurs a higher value of ws parameter will increase the amount of water content in the lowest soil layer required to initiate nonlinear baseflow as a consequence there will be high soil moisture storage ds parameter regulates the sub surface flow in the form of baseflow a high value of ds results in an increased nonlinear baseflow at lower water content there are studies reported in the literature demaria et al 2007 where parameters such as soil depth and saturated hydraulic conductivity are also considered in addition to the above mentioned parameters for calibration however for the present study all the parameters except the three mentioned above are derived from the digital soil map procured from nbss lup which limits the number of parameters that require calibration to three parameter estimation in the current work is carried out using a hybrid approach where knowledge of manual calibration is integrated with automatic calibration automatic calibration of the vic model is carried out by coupling it with an optimization algorithm which searches the feasible parameter space defined by upper and lower bounds of each of the parameters with an objective of minimizing the error between observed and simulated streamflows optimization algorithm in this study is employed by means of an optimization program referred to as parameter estimation pest doherty 2001 which has been used extensively in applications related to water resources govender and everson 2005 goegebeur and pauwels 2007 wang and brubaker 2015 through this work pest vic interface is established for effective implementation of optimization algorithm to obtain best parameter estimates of the vic model for the ugb typically the optimization algorithm carries out search towards attaining global minima parameters where the objective function is minimized by initiating the procedure from a random starting point which plays an important role in achieving the desired output if this starting point is selected to be far away from optimum the optimization algorithm can fail in pointing out the real best set of parameters and also unqualified outside the feasible parameter space starting point may increase the computational expense hence in order to address these issues a hybrid calibration procedure is employed wherein the knowledge gained from manual calibration is utilized in providing an appropriate starting point to the automatic calibration the outcomes of manual calibration of the vic model over the ugb are obtained from the analysis carried out by chawla and mujumdar 2015 in the present work the pest model is executed with an objective function of minimizing the squared sum of errors sse between model simulated streamflow q sim values and observed streamflow q obs details pertaining to the concept of pest model can be obtained from doherty 2001 and goegebeur and pauwels 2007 2 4 stationarity assumption of the hydrologic model the vic model is initially calibrated for the historic time period through a single split sample approach using hybrid calibration wherein data is divided into 60 and 40 for calibration and validation respectively information from the associated model parameters is used for projection of streamflows in the future time period typically the model is assumed to be stationary in this case wherein a fixed set of parameters is used for generating future streamflows without assessing their temporal dynamics this might lead to unreliable streamflow estimates hence there is a need to assess stationarity assumption of model parameters to deduce if parameters can be kept constant in the future time period in order to investigate model stationarity multiple split sample procedure is followed wherein the entire time period available for calibration is divided into several small time slices ts and the vic model is executed independently through hybrid calibration over each ts to obtain a series of model parameters through which insights can be gained over temporal variability of the parameters the time slicing is carried out by considering widths of 1 yr through 5 yr for example a 3 yr width time slicing carried out from 1987 to 2004 consists of a total of 6 time periods 1987 89 1990 92 1993 95 1996 98 1999 2001 2002 04 within which the vic model is independently calibrated for each of the time period construction of single and multiple split sample procedures to test model stationarity is depicted in fig 5 the whole modeling exercise at this stage is aimed to address the research questions is the model stationary in time and can be directly transferred to future scenarios results of this experiment are presented in section 3 2 to assess the effect of model stationarity on streamflow simulations within a particular ts the model parameter values obtained for the first time period are used to simulate streamflows for rest of the time periods in data series for instance for 6 time periods of the 3 yr time slice model parameters obtained for the first time period are used to execute the vic model for the other 5 time periods this is referred to as verification stage the results of same are presented in section 3 2 2 5 uncertainty quantification to quantify uncertainty in streamflow projections a total of 96 simulations are considered 48 corresponding to changing lu and climate combinations under nonstationary model conditions and other 48 with changing lu and climate but with stationary model conditions for stationary model condition parameters obtained from the calibration of the vic model through single split sample procedure are used to obtain streamflow projections however for obtaining streamflow simulations under nonstationary model conditions the parameters of calibrated vic model in the historic time period are projected into future by developing a quantitative relationship between model parameters obtained for 1 yr ts and climate variables assuming that the relationship will hold good for the future time period further details for the same are presented in section 3 3 the contribtuion of different factors to uncertainty in simulated streamflow is quantified using the anova framework von storch and zweirs 2001 yip et al 2011 bosshard et al 2013 herein the difference between simulated value and observed value eq 1 is considered as the input for segregating the uncertainty contribution from different factors the analysis is carried out using mean q 5 q 50 and q 95 as summary statistics for streamflow 1 δ x x mod x o b s x m e a n q 5 q 50 q 95 where x mod and xobs respectively represent the model simulated and observed values for a given x a multifactor anova model is constructed with gcms represented as α with 6 gcms represented as i 6 levels in the anova model sce β j 2 levels lu γ k 4 levels mp stationary or nonstationary δ l 2 levels and iv of the system ε as the contributing factors eq 2 the interaction between these factors which represent the nonlinear effect on uncertainty is also considered as a contributing source 2 δ x μ α i β j γ k δ l α β i j α γ i k α δ i l β γ j k β δ j l γ δ k l ɛ i j k l the total variance in the streamflow projection is given by the total sum of squares sst and is decomposed to the sum of squares from contributors and their interactions sum of squares from different sources is represented as ssf f α β γ δ ε furthermore the interaction between different sources is given as ssn n αβ αγ αδ βγ βδ γδ eq 3 provides the multifactor anova model considered in this study 3 s s t s s α s s β s s γ s s δ s s α β s s α γ s s α δ s s β γ s s β δ s s γ δ s s ɛ variance contribution η2 of each source is computed as the ratio between ssf or ssn and sst for example η α 2 s s α s s t similarly η2 for all the factors is calculated and has a value between 0 and 100 percent where 0 percent means no contribution of a particular factor while 100 percent means that the given factor is solely responsible for uncertainty in the output further details related to the anova approach can be obtained from bosshard et al 2013 and parajka et al 2016 3 results and discussion 3 1 calibration and validation of the hydrologic model the vic model is initially calibrated and validated through the single split sample procedure hybrid approach for the upstream and midstream regions of the ugb section 2 3 in case of the upstream region 13 years 1987 99 and 6 years 2000 05 of q obs records are used for calibration and validation respectively at monthly scale the midstream region is calibrated and validated using 19 years 1977 95 and 10 years 1996 05 of q obs respectively at monthly scale results for the calibration and validation phase are shown in fig 6 the model performance is assessed at monthly scale using the statistics of normalized root mean squared error e nrmse coefficient of determination r 2 nash sutcliffe efficiency e nse and bias b where positive sign of b indicates that the model overestimates the streamflow and vice versa results of the model performance are presented in table 2 the peaks are found to be under estimated consistently during calibration and validation since modeling of extremes is not the focus of present work this misfit is deemed not to be a major concern the values of the performance measures shown in table 2 indicate good performance of the hybrid method particularly in terms of b however during validation phase fig 6 b d the performance of the model deteriorated the deterioration during validation could be due to two factors one the vic model might have been subjected to over fitting during the calibration phase and two the low flows during validation phase are observed to be slightly overestimated although rest of the features are found to be comparable to that of calibration phase which could have resulted in poor performance metrics these results indicate that despite the good performance of the model caution needs to be exercised while using the model for validation purpose the contrasting behavior of the vic model during the two different time periods raises a necessity to understand stationarity of the model with time to determine if model calibrated at certain time period is indeed transferable to the future time period the following section addresses this issue by analyzing the temporal variability of the vic model parameters and the influence of chosen time slice for calibration on the model simulations 3 2 assessing stationarity of the vic model to assess stationarity of the vic model the optimum set of parameters obtained in each of the time slicing experiments section 2 4 are analyzed for their temporal variability it is observed that during 1 yr and 2 yr time slicing exercise model parameters exhibited high variability due to which meaningful interpretation could not be made from 3 yr ts onwards temporal variability of the model parameters is observed to be more prominent hence results pertaining to 3 yr ts are used to generalize the temporal behavior of model parameters 4 yr and 5 yr ts have less number of time periods due to which they are not considered for generalization either fig 7 presents results pertaining to this experiment 3 yr ts for upstream region of the ugb fig 7 a c present total p average t max and average t min for the specified time period respectively and fig 7 d f present the temporal variability of b ds and ws parameter values respectively results from the experimental investigation indicate that all the 3 parameters exhibit temporal variability indicating nonstationarity in the hydrologic model therefore it is now of interest to understand the causal factors for temporal changes in the model parameters previous works by demaria et al 2007 and troy et al 2008 have shown vic parameters to be sensitive to climate in this paper a non linear spearman rank correlation coefficient is used to determine the dependence between model parameters and climate indicators results for which are presented in appendix d table d 1 it is observed that b and ds parameters are strongly correlated to p while ws parameter is highly correlated with t max and t min the relationship between model parameters and climate variables is also shown in fig 7 in general across any two time periods a decrease in p is accompanied by an increase in b parameter value which indicates the reduction in infiltration of water into the soil a drop in the value of t max and t min may cause the decrease in losses from the system consequently ws parameter value may decrease or vice versa the decrease in the value of ws parameter is linked with an increase in ds parameter value demonstrating an increase in baseflow contribution at low soil moisture content towards total runoff overall it can be inferred that b parameter is indirectly related to p whereas t max and t min have a direct relationship with ws parameter ds parameter complements the effect of variations in b and ws parameters similar behavior in model parameters with respect to the change in climate indicators is demonstrated by the midstream region of the ugb appendix e fig e 1 further to assess the effect of the nonstationary vic model on streamflow simulations bias b is estimated between q sim for calibration and verification phase section 2 4 for further information for each time period results of the analysis are presented in fig 8 if there is no effect of model parameters on streamflow simulations then b should be approximately equal to zero the analysis indicates that exclusive changes either in b or ds parameters will have a proportional effect over streamflow moreover a simultaneous increase in both b and ds parameters is observed to result in significant increase in streamflow it is also observed that an increase in b parameter along with a decrease in ws parameter leads to increase in streamflow and vice versa however the extent to which overestimation or underestimation of streamflow occurs depends on the amount by which each of the parameter value changes therefore it can be concluded that assuming the hydrologic model to be stationary may have a significant effect on streamflow projections consequently for assessing the contribution of different factors to uncertainty in streamflow projection nonstationarity should be considered it is now important to assess if the width of ts has any effect on the dynamics of streamflow simulations so as to comment if the inferences drawn above for the 3 yr time slice experiment can be applied to other ts experiments this inherently provides us with an insight about uncertainty due to the choice of ts during calibration the objective is addressed by initially executing the vic model under all the ts widths along with complete time period upstream 1987 05 midstream 1977 05 and the resulting q sim is compared with q obs using e nse and b measures the corresponding results are presented in fig 9 the performance measures indicate that all the ts except complete time period have well simulated the streamflows with comparable accuracies in both upstream and midstream regions consideration of complete time period resulted in poor simulations in both the regions this could be due to overestimation of flows during model validation phase section 3 1 it can be inferred from the results that changing ts width has minimal effect on the model through which it can be said that uncertainty due to the choice of ts is negligible and can be ignored in the current work from this section it is established that model parameters indeed vary over time with noticeable effect over streamflow simulations hence it can be concluded that the vic model is not stationary consequently not directly transferable to future scenarios i e calibrated model parameters obtained for the past cannot be applied directly to future conditions since it is evident from previous analysis that the model parameters are influenced by climate variables a regression mechanism is set up for the historic data by which model parameters for the future time periods are estimated 3 3 model parameters for future time periods the parameters of calibrated vic model in the historic time period are projected into future by developing a quantitative relationship between parameters and climate variables assuming that the relationship thus established will hold good for the future time period however the regression model to be setup is rather complicated due to multidimensional nature of both predictor 3 climate variables p t max and t min and predictand 3 model parameters b ws and ds datasets under such circumstances dattalo 2013 suggested that if the predictand variables are poorly correlated among themselves correlation ρ 0 2 then each of these variables can be modeled separately with respect to predictor variables in the present work the model parameters are observed to be uncorrelated due to which each one of the parameters is individually regressed with predictors for establishing the relationship support vector regression svr algorithm is employed wherein model parameters predictors and climate variables predictands corresponding to 1 yr width ts are considered which resulted in 19 and 29 number of datasets available in the upstream and midstream regions respectively these datasets are divided into 70 and 30 respectively for training and validation of relationship svr technique initially developed by cortes and vapnik 1995 has been widely applied in the past few decades for classification and regression analysis owing to its ability in solving large scale complex problems tripathi et al 2006 it is based on a general idea of mapping dependent variables nonlinearly to the high dimensional independent variables brief description of the svr algorithm is provided in appendix f further details can be obtained from cortes and vapnik 1995 smola 1996 smola et al 1998 hsu et al 2003 tripathi et al 2006 and ghosh 2010 results corresponding to training and validation of svr for the upstream and the midstream regions of the ugb are provided in terms of the correlation coefficient in table 3 the results indicate that in general svr has modeled parameters in the upstream and midstream regions with a reasonable accuracy despite slight inconsistency in validating ds parameter at the end of this modeling exercise each region contains 3 trained svr models corresponding to the b ds and ws parameters these models are fed with future projections of the 3 climate variables corresponding to the 6 gcms and 2 climate scenarios so as to obtain projected values of model parameters 3 4 hydrologic impacts of future land use and climate change the vic model with projected model parameters nonstationary model condition is executed in future time periods across 48 climate and lu scenarios to obtain future q sim for the ugb further the vic model is also run for the same set of lu and climate projections with model parameters obtained during the single split sample calibration procedure i e stationary model condition and the resulting streamflows act as a baseline fig 10 presents boxplots of summary statistics for the streamflow projections obtained for 48 projections under both nonstationary and stationary conditions along with historic observations streamflow is noticed to decrease in future for both nonstationary and stationary conditions this is due to decrease in rainfall and increase in temperature obtained for future projections across all the gcms fig 4 further amongst the two conditions streamflow is noticed to be significantly low for the nonstationary model this difference is attributed to contrast in model parameters b ws and ds used in two conditions under the stationary condition model parameters used for simulations are basically tuned for historic climate thus being insensitive to future climate projections due to strong dependency of model parameters with climate conditions section 3 2 parameters are misrepresented in stationary condition resulting in unrealistically higher future streamflows this issue is effectively addressed by implementing nonstationary vic model wherein model parameters for future time period vary according to prevalent climate resulting in lower streamflow projections for instance in the upstream region under the nonstationary condition average values of ws and b across all the gcms and sce are found to lie between 0 79 to 0 83 and 0 104 to 0 121 respectively whereas 0 63 and 0 137 respectively are the values considered in the stationary condition this resulted in higher streamflow for the latter condition for low flow case q 5 in upstream and midstream regions streamflow values under stationary conditions are found to be comparable to the historic values this could be due to the insignificant change in the low rainfall events in the two regions fig 4 further it indicates that the influence of the increase in temperature is not reflected in streamflow projections obtained using stationary hydrologic model condition however significantly lower streamflow is obtained for the nonstationary condition under the same case which could be due to increase in ws parameter values as a result of an increase in temperature in addition to this uncertainty in streamflow values for the nonstationary case is observed to be higher compared to the stationary case this could be due to variability in the model parameters and consequently in streamflow projections across different gcms and sce for high flows q 95 uncertainty is observed to be maximum as reflected through widest box plot amongst all the cases although most of the values are either below the historic values of lie towards the lower end they are exceeding the stationary values in some cases a mismatch between the parameters obtained for high rainfall events could be the cause for obtaining these varying values this implies that the methodology should be exercised with caution for high rainfall events a separate relationship in such situation might reduce the uncertainty in simulations 3 5 uncertainty contribution from different sources as described in section 2 5 uncertainty in the streamflow projections is decomposed into individual components gcms sce lu mp and iv using the anova approach results for three regions of ugb are presented in fig 11 gcms and mp assumption of nonstationary and stationary are observed to be the primary source of uncertainty across all the three regions and for most of the cases this could be due to the fact that there is a noteworthy difference in the streamflow projections obtained for different lu and climate scenarios under stationary and nonstationary conditions and also within each of these conditions q 95 of midstream and downstream regions exhibited significant variability for both nonstationary and stationary model conditions therefore gcms contribution to q 95 case is observed to be less in comparison to the mean case further uncertainty contribution from mp towards change in q 5 of midstream and downstream regions is noticed to be very high 96 and 82 respectively this is attributed to significant difference between the low flows obtained under the two conditions for midstream and downstream regions interactions between gcms sce gcms mp and sce mp are found to be the next significant contributor with contribution ranging between 30 50 across all the cases except q 5 case of midstream and downstream regions this indicates that gcms sce and model assumptions should be considered together for future assessment of water resources within the uncertainty framework in addition to this contribution from lu and iv is found to be less but not negligible from this analysis it can be inferred that consideration of hydrologic model to be stationary or nonstationary might be a significant source of uncertainty in future streamflow projections to understand the influence of other factors on uncertainty a separate set of analysis is performed where streamflow projections only from nonstationary model conditions are considered result pertaining to the same are presented in fig 12 in the nonstationary case gcms and sce are observed to be the dominant contributor to uncertainty in streamflow across all the cases this is expected due to variability in the streamflow simulations under nonstationary conditions for different models and scenarios for upstream and midstream regions the contribution from lu is also noticeable in all the cases however this contribution is not observed for the downstream region this could be due to the lesser contributing area in the downstream region least amongst the three sub basins the effect of the amount of contributing area is also seen in the results for the other two regions wherein midstream region having maximum basin area has highest lu contribution towards uncertainty which reduces for the upstream region 4 summary and conclusions this paper sought to address two main objectives first assessing the influence of model stationarity on future streamflow simulations and second quantify the contribution of gcms emission scenarios lu model parameters and internal variability of the hydrologic model to uncertainty in streamflow projections a semi distributed vic hydrologic model combined with the pest optimization algorithm is used to carry out the analysis calibration of the vic model is carried out through a hybrid approach which involves integrating the manual calibration with that of automatic calibration using the pest model through time slicing experiment it is noticed that the model parameters exhibit temporal variability thus leading to the necessity of using a nonstationary model for streamflow projections streamflow is observed to decline under future lu and climate conditions further low flows are observed to be critically low which may become a matter of concern for assessment of future water availability upon segregating the contribution of different factors to uncertainty in streamflow projections it is observed that gcms and model assumption of stationary and nonstationary conditions are the major source of uncertainty within the nonstationary case gcms are found to be the dominant contributor to the uncertainty in streamflow projections it is also revealed that the nonlinear interactions between gcms and scenarios are important for uncertainty quantification in streamflow projections streamflow is noticed to be sensitive to subtle changes in the lu the key aspect of this paper is that the hydrologic models cannot be assumed to be stationary for impact assessment studies instead it can be the significant source of uncertainty in the model output in addition to this future lu scenarios can also contribute towards uncertainty although the results presented in this paper are not directly applicable to another catchment with different hydrological properties the methodology presented is general and can be performed independently of the study area this study will be helpful for assessing future impacts of lu and climate change on streamflow within the uncertainty framework 4 1 limitations and future scope analysis presented in this paper is subjected to a few limitations a segregation results obtained are limited to the gcms selected for the study b uncertainty in streamflow simulations due to model structure is not considered c irrigation and groundwater extraction which are dominant phenomenon in the region misra 2011 madhusoodhanan et al 2016 may also be a source of uncertainty which are not included in the present model set up d due to the drawbacks associated with lu modelling lu could be projected only for a short time in future 2040 and e optimization of the hydrologic model is carried out based on a single objective function the multi objective optimization of the vic model with evapotranspiration and soil moisture might improve the results and should be attempted in future work in addition to the above mentioned limitations care should be exercised while using the hydrologic model for simulating extreme rainfall events as it is observed that the vic model doesn t capture the extremes well in the present case study section 3 1 appendix a validation results of the lu model fig a 1 along with table a 1 present the area under different lu categoried for observed and simulated lu map of the year 2011 the accuracy of the simulated map of 2011 is measured using kappa index of agreement kia originally developed by pontius 2000 value of kia may lie between 0 to 1 where 1 indicates perfect agreement between simulated and observed images and 0 indicates that the agreement is as good as expected by chance in this paper three variants of kia pontius 2000 are used table a 2 to measure different characteristics pertaining to simulation capability of the lu model the quantitative kia metrics indicate that the lu model has simulated the quantity of correctly classified pixels with better accuracy than spatial accuracy however overall capability of the model to simulate change κstandard is observed to be reasonably good appendix b future land use lu projections corresponding to different scenarios from scenario 1 fig b 1 and table b 1 where changes in scrub forest and crop land areas are modeled a slight increase in both the categories can be observed from 2020 through 2040 this increase is noticed to be at the expense of dense forest category in case of scenario 2 which focuses on crop land changes an increase in this category is noticed for 2020 and 2030 at the expense of barren land and scrub forest categories however this scenario witnessed a slight unexpected decrease in crop land area during 2040 which is compensated with an increase in area under scrub forest this feature although negligible could be viewed as a modeling inconsistency scenario 3 fig b 2 which models changes in urban area witnessed urban area expansion from 2020 to 2040 at the cost of scrub forest and crop land areas this can be considered as an increase in the size of existing urban areas in the region in the coming years due to population growth lastly in scenario 4 fig b 3 where changes in crop land and urban areas are modeled through time increase in crop land area is observed to have replaced scrub forests from 2020 to 2040 while urban area remained constant after an initial increase in 2020 appendix c list of gcms considered in the present work appendix d appendix e appendix f quantitative relationship between model parameters and climate variables is established through support vector regression svr algorithm it is based on a general idea of mapping dependent variables nonlinearly to the high dimensional independent variables the formulation of svr is provided below consider a training sample of n datasets of predictors x and predictand y xi yi i 1 2 n where xi is the ith vector containing n number of predictor variables i e xi x i1 x i2 xin the structure of the svr is given by the following equation f 1 y i 1 n w i k x i x b where wi are the adjustable weights b is the bias y is an estimate of y and k is a kernel function the kernel function transforms the training data into high dimensional space so as to model nonlinear dependencies between predictors and predictand in the present work radial basis function rbf is used as a kernel function eq f 2 f 2 k x i x exp x i x 2 2 σ 2 where σ is the width of the rbf kernel svr systematically adjusts weights and bias with an objective of minimizing the error between y and y 
889,fresh groundwater is widespread globally in offshore aquifers and is particularly dependent on the properties of offshore aquitards which inhibit seawater freshwater mixing thereby allowing offshore freshwater to persist however little is known of the salinity distribution in subsea aquitards especially in relation to the offshore freshwater distribution this is critical for the application of recent analytical solutions to subsea freshwater extent given requisite assumptions about aquitard salinity in this paper we use numerical simulation to explore the extent of offshore freshwater in simplified situations of subsea aquifers and overlying aquitards including in relation to the upward leakage of freshwater the results show that available analytical solutions significantly overestimate the offshore extent of upwelling freshwater due to the presumption of seawater in the aquitard whereas the seawater wedge toe is less sensitive to the assumed aquitard salinity we also explore the use of implicit conductance based representations of the aquitard i e using the popular seawat code and find that seawat s implicit approach i e ghb package can represent the offshore distance of upwelling freshwater using a novel parameterization strategy the results show that an estimate of the upward freshwater flow that is required to freshen the aquitard is associated with the dimensionless rayleigh number whereby the critical rayleigh number that distinguishes fresh and saline regions based on the position of the 0 5 isochlor within the aquitard is approximately 2 keywords density dependent flow seawater intrusion coastal aquifer offshore freshwater aquitard submarine groundwater discharge 1 introduction despite the widespread presence of freshwater beneath the seafloor e g post et al 2013a the processes accompanying the occurrence of fresh offshore groundwater are under studied relative to the current knowledge of seawater freshwater relationships in onshore aquifers case studies of freshwater bodies in offshore aquifers have been undertaken for hong kong china jiao et al 2015 kwong and jiao 2016 suriname groen et al 2000 and the atlantic continental shelf usa including nantucket island marksamer et al 2007 and the subsea aquifers near the border between georgia and florida johnston 1983 in each of these cases fresh offshore groundwater underlies an extensive low permeability sequence i e an aquitard which inhibits mixing between the fresh groundwater and overlying seawater offshore freshwater may be derived from modern discharge originating from onshore aquifers and or may be the consequence of paleo freshwater entrapped during the low sea levels of the pleistocene epoch cohen et al 2010 here we define modern discharge as occurring under current sea levels whereby favourable conditions lead to freshwater discharge into offshore aquifers in some cases modern discharge has created offshore freshwater extending considerable seaward distances within continental shelves bakker 2006 studied such a system near the georgia florida border usa where pre development i e prior to human impacts groundwater heads are thought to have created a fresh groundwater body that reaches the edge of the continental shelf i e 120 km offshore kooi and groen 2001 studied the size of hypothetical offshore freshwater reserves driven by the onshore groundwater conditions also concluding that freshwater may extend tens of kilometres offshore as a result of modern groundwater discharge in the remainder of this manuscript only the simplified case of offshore fresh groundwater that is in equilibrium with the onshore conditions is considered i e paleo freshwater in offshore aquifers is neglected according to post et al 2013a paleo freshwater is an important worldwide phenomenon that can be regarded as a potential freshwater resource however in the interests of scrutinizing the solution of bakker 2006 described later in this paper we neglect paleo freshwater fig 1 presents a schematic of the conceptual model aside from the onshore hydraulic heads other factors play important roles in the offshore distribution of freshwater for example frind 1982 concluded that the vertical hydraulic conductivity kz of the subsea aquitard has a critical influence on the offshore distance of upward freshwater discharge which in turn affects the salinity distribution in the underlying aquifer he used two different values for kz to demonstrate that the lower value resulted in increased thickness of the aquifer s freshwater seawater mixing zone and a larger offshore distance of freshwater leakage to the sea lu et al 2013 undertook a more detailed analysis of the effect of kz on freshwater seawater mixing and showed that as the aquitard aquifer contrast in hydraulic conductivity increases refraction across the aquitard aquifer interface creates a broader mixing zone in the aquitard michael et al 2016 showed the important role of aquifer heterogeneities in controlling subsea groundwater salinity distributions concluding that modern continental discharge can account for freshened offshore groundwater to tens or hundreds of kilometres offshore where preferential flow creates active offshore flow systems analytical solutions to the steady state extent of freshwater under the sea in offshore semi confined aquifers have been produced by edelman 1972 kooi and groen 2001 and bakker 2006 they adopted steady state sharp interface representations of the freshwater seawater mixing zone and other simplifications to enable mathematical tractability in these solutions fresh groundwater discharge through the overlying subsea aquitard is treated as a head dependent leakage term this calculation requires that the groundwater salinity within the aquitard is a priori known in the analytical solutions of kooi and groen 2001 and bakker 2006 the entire offshore aquitard is presumed to contain seawater the implications of this assumption in terms of the predictability of these analytical approaches are tested in the current analysis we expect that the upward leakage of freshwater in bakker s 2006 solution creates freshening of the overlying aquitard as opposed to it containing seawater this is scrutinized by considering advective dispersive and buoyancy forces occurring within the aquitard i e due to seawater above the aquitard and freshwater below it the primary aim of this paper is to assess the offshore extent of freshwater and seawater in idealized coastal aquifer aquitard settings i e under conditions that allow for comparison with the bakker 2006 solution the salinity distributions in subsea aquitards are explored in relation to subsea freshwater extents and the accompanying upward leakage of freshwater to the sea using numerical models a mixed convection evaluation of the unstable density situation of offshore aquitards is undertaken to incorporate the factors that lead to density driven aquitard salinization in applying the popular seawat code to reproduce numerically bakker s 2006 analytical solution we also report on attempts to model the offshore aquitard using an implicit representation i e a head dependent boundary condition as an approximation of the explicit representation of the aquitard while the implicit method is numerically efficient it has not been evaluated with respect to the more physically reliable explicit approach in terms of subsea aquifer aquitard simulation both explicit and implicit models are used to explore the assumptions adopted by bakker 2006 regarding the aquitard salinity 2 methodology 2 1 analytical solution edelman 1972 developed the first analytical solution of the extent of offshore freshwater within a semi confined subsea aquifer where buoyancy forces and the location of the freshwater seawater interface influence the upwelling freshwater discharge through the offshore aquitard in his solution the tip of the interface i e where the interface intersects the top of the aquifer is offshore and the freshwater body otherwise occurs as a lens similar to the situation of small islands kooi and groen 2001 produced a solution for the situation when the toe i e where the interface intersects the bottom of the aquifer is offshore both edelman 1972 and kooi and groen 2001 considered infinitely long offshore aquifer aquitard systems bakker 2006 built on their solutions by solving for the situation where freshwater reaches the offshore limit of the subsea aquifer e g the edge of the continental shelf which he represented as a vertical boundary that reflects the hydrostatic head of the sea bakker s 2006 conceptual model is consistent with the situation illustrated in fig 1 an offshore semi confined aquifer containing freshwater and seawater that are in equilibrium i e steady state conditions and connected to a confined onshore aquifer freshwater enters the aquifer at the landward boundary and eventually flows above a body of seawater assumed immobile the shape of the freshwater seawater interface which is treated as a sharp pressure equilibrium boundary is a function of buoyancy forces arising from the density difference between freshwater and seawater losses of freshwater from the offshore aquifer referred to here as submarine fresh groundwater discharge sfgd occur as upward seepage through the offshore aquitard or as outflow where the aquifer is exposed at the continental shelf fig 1 illustrates the case where offshore freshwater does not extend to the continental shelf and therefore the only discharge pathway for sfgd from the semi confined aquifer is via upward leakage through the aquitard fig 2 shows the 2d cross section and associated variables adopted by bakker 2006 in developing his analytical solution the onshore confined aquifer and offshore semi confined aquifer have uniform thickness h and are assumed horizontal homogeneous and isotropic the offshore aquitard which is also homogeneous and isotropic has a uniform thickness hl and is overlain by a depth of seawater equal to hs the offshore domain extends a distance ls to the continental shelf which is represented by a vertical specified head boundary condition of hydrostatic seawater heads freshwater inflow qc l2 t 1 to the model domain occurs through the left hand boundary which is situated at a landward distance lc from the shoreline the sea level is zs above the base of the aquifer freshwater and seawater densities are designated ρf and ρs respectively analogous conceptual models were adopted by kooi and groen 2001 bakker 2006 and bakker et al 2017 the equivalent freshwater head of the ocean at the top of the aquitard ht is given by bakker 2006 1 h t z s ρ s ρ f ρ f h s application of darcy s law accounting for the buoyancy force that arises from the assumption of seawater in the aquitard produces the following equation for upward freshwater flow qz l t 1 2 q z k z h h t h l ρ s ρ f ρ f here h is the head within the freshwater region of the subsea aquifer and kz is the vertical hydraulic conductivity in this case of the aquitard l t 1 if the aquitard contains freshwater the buoyancy term ρs ρf ρf should be removed from eq 2 bakker 2006 rewrites eq 2 in terms of the hydrostatic freshwater head of the sea at the base of the aquitard hs defined in terms of ht as 3 h s h t ρ s ρ f ρ f h l combining eqs 2 and 3 produces bakker 2006 4 q z k z h l h h s eq 4 is presented in the density independent form of darcy s law applied to flow across the aquitard the density effect introduced by assuming that the aquitard contains seawater which requires application of the density dependent form of darcy s law is manifested by formulating hs equal to the equivalent freshwater head of a hydrostatic seawater column representing sea level at the base of the aquitard bakker 2006 identifies four possible situations regarding the position of the interface toe and tip relative to both the shoreline and continental shelf boundary which of the four cases arises from a particular set of parameters is determined using two dimensionless parameters see bakker 2006 these then lead to relevant analytical solutions to solve for the extent of offshore freshwater bakker et al 2017 correct an inaccuracy in bakker 2006 regarding the evaluation of the incomplete elliptic integrals for the solution of the two cases where the tip of the interface reaches the edge of the continental shelf i e cases iii and iv bakker 2006 we replaced the inland specified flux boundary condition used by bakker 2006 with a specified head condition because inland head values are preferred as input to the problem that is groundwater heads are known more commonly than groundwater fluxes the head boundary condition was satisfied using a numerical shooting approach based on the classical 4th order runge kutta technique thomann 2017 this approach was necessary because the head based method provided by bakker et al 2017 was not available at the time of our investigation 2 2 numerical modelling numerical modelling was used to assess the offshore extent of freshwater and seawater in both the aquifer and aquitard below the sea under conditions that allow for comparison with the bakker 2006 solution seawat version 4 langevin et al 2008 was adopted for this purpose seawat has been extensively tested and is widely used for the simulation of density dependent groundwater flow and solute transport combining modflow 2000 harbaugh et al 2000 and mt3dms zheng and wang 1999 the flow and transport components are coupled through the fluid density term which is taken as a linear function of solute concentration the methods adopted by seawat are described in the user manual langevin et al 2008 and are therefore omitted here for brevity we test both explicit and implicit representations of the subsea aquitard in numerical experiments because implicit representation offers significant computational savings and is therefore an attractive option for practical field scale problems in the explicit approach the aquitard is subdivided into horizontal layers an overlying specified head boundary condition top layer represents the hydrostatic head of the sea and groundwater discharges at the ambient concentration whereas inflowing water has seawater salinity 2 2 1 implicit simulation of the subsea aquitard implicit representation of the subsea aquitard is at least theoretically possible through application of seawat s general head boundary ghb package langevin et al 2008 the implicit approach is appealing because it adopts a similar conductance based representation of the subsea aquitard as described by bakker 2006 that is the ghb package simulates flow qghb l3 t 1 into or out of a cell as a function of the difference between the head of the cell and that of an external sink source harbaugh 2005 in our case the latter is the sea solute concentrations accompanying inflow and outflow via the ghb package are dealt with in the sink and source mixing ssm package of mt3dms zheng and wang 1999 a schematic of the ghb package is given in fig 3 and is discussed in more detail below the ghb package adopts the following formulation guo and langevin 2002 5 q g h b c g h b h f i h f g h b ρ ρ f ρ f z i z g h b here zi is the cell centre elevation zghb is the user specified base elevation of the ghb reservoir hf i is the equivalent freshwater head at the centre of the model cell l and hf ghb is the equivalent freshwater head at the base of the ghb reservoir fig 3 seawat obtains hf ghb from the user specified hghb the water level in the ghb reservoir using the formulation h f g h b h g h b ρ g h b ρ f z g h b ρ g h b ρ f ρ f seawat determines the value of ρghb density of water in the ghb reservoir through conversion of the user specified solute concentration for the water in the ghb reservoir cghb is the user specified boundary conductance l2 t 1 given by kghba l where kghb is the hydraulic conductivity of material between the ghb reservoir and the model cell l t 1 a is the area perpendicular to ghb flow l2 and l is the distance between the cell centre and the base of the ghb reservoir ρ m l 3 represents the density of water between the ghb reservoir and the model cell seawat s formulation of ρ makes application of the ghb package to the variable density arrangement of fig 3 challenging ρ is assumed in seawat to be equal to the average of ρghb and the fluid density of the model cell ρi whereas in reality groundwater between the model cell and the boundary i e in the aquitard is likely to change depending on the direction of flow seawat s approach is a simplification of otherwise a priori unknown salinity conditions that occur within the aquitard i e in the connection between the ghb reservoir and the boundary cell the most appropriate value of ρ for the simulation of subsea aquitards within the current conceptual models is presently unclear that is the correct fluid density to use for aquitards overlying fresh subsea aquifers is unstudied to address this we develop guidance on the selection of ghb parameters for the current problem through model testing using various ghb parameter combinations the intent is to apply the ghb package so that it reproduces as closely as possible the mathematics representing boundary discharge as adopted by bakker 2006 the ghb package is also tested for consistency against the results of models that adopt an explicit i e physically based representation of the aquitard table 1 contains the final list of ghb parameters given in terms of variables defined by bakker 2006 and that reproduce bakker s 2006 formulae for flow through the aquitard the derivation of parameters is described below in our use of the ghb package we aim to impose three alternative salinity conditions in the subsea aquitard namely entirely seawater freshwater or mixed salinity water this can be achieved by manipulating the ghb parameters of ρghb and zghb consider firstly the situation where the upper aquifer cell contains freshwater but the aquitard contains seawater i e bakker s 2006 assumption this allows hl l on the basis that l can be taken from the top of the cell i e rather than from the cell centre as shown in fig 3 given the dupuit assumption and because freshwater within the aquifer cell precludes the need to correct the cell s equivalent freshwater head for the reference elevation also by taking ρghb ρf ρ ρf when the aquifer cell contains freshwater thereby eliminating the buoyancy term from eq 5 which is not present in bakker s 2006 equation i e eq 4 in order to account for seawater occurring in the aquitard given ρghb ρf hghb is assigned the value of hs making the table 1 substitutions eq 5 reduces to eq 4 thereby replicating bakker s 2006 formula eq 5 arrives at eq 4 using table 1 substitutions only when the subsea aquifer contains freshwater however the substitution of table 1 parameters into eq 5 results in flow across the aquitard where the aquifer contains seawater as apparent in the analysis that follows in violation of the assumptions of bakker 2006 to account for this a modification is made to table 1 parameter substitutions so that no flow will occur when the model cell contains seawater that is we require qghb 0 where ρi ρs model cells representing the aquifer that are filled with seawater should reflect the hydrostatic head of the ocean giving rise to hf i zi zs zi ρs ρf from direct application of bernoulli s equation substituting these conditions into eq 5 considering the abovementioned definition of ρ and adopting a selection of the table 1 substitutions leads to 6 c g h b z i ρ s ρ f z s z i h s ρ s ρ f 2 ρ f z i z g h b 0 in eq 6 only zghb can be adjusted without changing the freshwater flow formulation because the buoyancy term is eliminated under freshwater conditions in the aquifer as explained above thus eq 6 is rearranged in terms of zghb 7 z g h b 2 ρ s ρ f ρ s z s ρ f h s z i hence in combination with the use of ρf for ρghb eq 7 creates vertical aquitard flow at rates that assume that the aquitard contains seawater where there is freshwater in the aquifer whereas there is no flow in the aquitard where the underlying aquifer contains only seawater i e following bakker s 2006 approach an alternative ghb parameterization is needed to represent the same conditions except where the aquitard contains freshwater in regions of freshwater in the underlying aquifer considering the situation of freshwater in the top of the aquifer the buoyancy term in eq 2 is removed and the value for hf ghb used in eq 5 is ht again we require qghb 0 where ρi ρs leading to the following substitution for zghb 8 z g h b 2 ρ s ρ f ρ s z s ρ f h t z i the approaches to ghb parameterization described above were tested by comparing bakker s 2006 method with models that adopt implicit and explicit representations of the subsea aquitard 2 2 2 description of numerical experiments table 2 describes the baseline parameters used in the analytical and numerical models parameters are typical of previous coastal aquifer modelling by kooi and groen 2001 post and kooi 2003 werner and simmons 2009 laattoe et al 2013 and werner 2017b with some trial and error to achieve tip positions that were landward of the model s offshore boundary we did this to ensure that the tip position was sensitive to differences between models rather than being located at the continental shelf two different scales were considered labelled as sections 1 and 2 in table 2 the smaller domain size of section 1 allowed for fine discretization and was used for cases of lower contrast between the aquitard kz and the aquifer k the longer extent of section 2 provided insight into situations involving higher k contrasts and more realistic scales the same onshore head h 32 m was used in all simulations thereby creating various rates of qc as a consequence of changes to other parameters two phases of numerical experimentation were used to achieve the objectives of the investigation phase 1 numerical models adopted an explicit representation of the offshore aquitard allowing for physically based simulation of the mixed convective processes occurring in the aquifer aquitard system at least to the degree that the low dispersion conditions adopted in this study allow dispersion parameters were set to zero to reflect the sharp interface approach of bakker 2006 and only unavoidable artificial numerical dispersion referred to hereafter as artificial dispersion e g werner 2017a creates widening of the mixing zone in order to minimize oscillation problems produced by simulating purely advective scenarios in which the grid peclet number exceeds the recommended maximum value for finite difference methods of 2 zheng and bennett 2002 the third order tvd method zheng and wang 1999 was used in solving the transport equation in all simulations the modelling results were compared to bakker s 2006 solution to assess the validity of his underlying assumptions regarding the aquitard salinity phase 2 numerical modelling involved implicit representation of the offshore aquitard commensurate with the approach of bakker 2006 thereby exploring the use of the ghb package of seawat in simulating offshore conditions substitutions as described in section 2 2 1 were adopted to allow for different aquitard salinities to be tested and comparisons were made with models that simulate the aquitard explicitly in the two phases several values of the aquifer k aquitard kz contrast were tested as outlined in table 3 which lists the parameters that differentiate the various numerical experiments steady state results were achieved by running seawat in transient mode until no further changes were discernible two different finite difference grids were used as shown in fig 4 models 1 2 and 3 adopted the model domain grid shown in fig 4a for which the horizontal grid resolution varies from 0 1 m at the seaward boundary increasing to 10 m at the landward boundary the grid was designed such that the interface was contained within the part of the model with 0 1 m resolution layers are 0 1 m deep the upper layer of explicit models contains high k specified head cells within the offshore region to simulate the effect of the sea the next ten layers represent the 1 m thick aquitard in the implicit aquitard models of phase 2 the grid of fig 4a was used without the upper eleven layers that simulate the aquitard and the overlying specified head boundary condition the ghb package was instead used to simulate the aquitard and the sea fig 4b shows the finite difference grid used for models 4 5 and 6 for which the grid resolution represents a trade off between model execution times and accuracy the horizontal grid resolution varies from 50 m at the left hand boundary decreasing to 2 m at the seaward boundary the region of the model containing the interface has a 5 m horizontal discretization vertical discretization is again 0 10 m the boundary condition at the onshore limit left boundary is a specified head condition with a concentration boundary condition that adopts a fixed salinity equal to freshwater i e relative salinity of zero for groundwater flow entering the system the influence of the sea is represented by 20 m and 3000 m of horizontal seafloor in fig 4a and b respectively along with the right vertical edge of the model aside from the region where the aquitard is exposed to the sea which was assigned a no flow condition this general layout is similar to that described by kooi and groen 2001 seawater hydrostatic heads are specified at sea boundaries in combination with a concentration condition of seawater salinity i e relative salinity of 1 0 for the incoming groundwater whereas groundwater discharges to the sea at the ambient concentration three different salinity conditions were assigned to the aquitard in the phase 2 numerical experiments models 7 8 and 9 represent bakker s 2006 assumption of seawater in the aquitard while models 10 11 and 12 presume that the aquitard contains freshwater see section 2 2 1 for ghb parameters finally seawat s default calculation of mixed water was tested using models 13 14 and 15 whereby the aquitard s water has a density equal to the average of the water in the uppermost aquifer cell and seawater in this case the program is used in its more intuitive form whereby hf ghb is calculated internally and both ρghb and zghb represent the current conceptual conditions i e seawater density and the height of the top of the aquitard respectively table 4 summarizes the case specific parameters used in phase 2 2 3 mixed convective analysis of the subsea aquitard salinization of the aquitard is a mixed convective problem in which the unstable configuration of higher density seawater overlying lower density freshwater gives rise to a downwards gravity or buoyancy force on the seawater at the upper boundary of the aquitard downward flow will occur in the aquitard where buoyancy forces have overcome the advective forces associated with sfgd wooding et al 1997 attempted to predict the salinity distribution within low permeable sediments subject to mixed convective processes they showed that the solute motion in unstable density configurations is initially driven by solute dispersion which forms a saline boundary layer if the upward flow of freshwater is sufficient to counteract dispersion the conditions may remain in equilibrium thereby avoiding the creation of density driven solute fingers based on these principles and under equilibrium conditions kooi and groen 2001 simplified the saline boundary layer thickness δ to 9 δ d q z where d is the dispersion coefficient l2 t 1 and qz is the darcy velocity of vertical freshwater flow l t 1 kooi and groen 2001 and wooding et al 1997 considered dispersion as only molecular diffusion on this basis kooi and groen 2001 suggested that complete salinization of the aquitard will occur when the aquitard thickness is equal to δ they then used this definition to redefine the location of the interface tip whereby their analytical estimates of the offshore freshwater length were modified such that sfgd was terminated at the offshore position where δ equals hl the approach adopted by kooi and groen 2001 resulted in a reduction of 50 80 of the offshore freshwater length for the various cases that were analysed unfortunately they were unable to obtain consistent agreement between their numerical simulations and their δ based truncation of the offshore freshwater extent the forces acting in the boundary layer are represented by wooding et al s 1997 boundary rayleigh number raδ which is a dimensionless parameter defined by the ratio of buoyancy forces to resistive forces i e dispersion wooding et al 1997 proposed the following definition 10 r a δ ρ s ρ f k z δ ρ f d the onset of instability in the boundary layer that is when buoyancy forces overcome dispersion leads to a critical value of raδ namely rac whereby dispersive transport transitions to density driven transport in the form of unstable saline fingers wooding et al 1997 found that rac is approximately 10 in silty and sandy clay bearing sediments that is unstable fingers develop once raδ exceeds 10 kooi and groen 2001 do not report values of raδ in the analytical development provided by bakker 2006 there is no consideration of boundary layer development and the possibility that it truncates the extent of offshore sfgd smith and turner 2001 used a modified equation for the rayleigh number ra to analyse the effects of mixed convection within a two dimensional cross sectional model of freshwater discharge to a saline estuary their conceptual model bears many similarities to the current one except the estuary was represented as a horizontal one dimensional boundary condition i e non penetrating and immediately overlying the aquifer of specified head and concentration that is the intervening aquitard considered in figs 1 and 2 was not included smith and turner 2001 concluded that the critical ra for the occurrence of saltwater below the estuary is approximately five the three applications of rayleigh theory described above i e wooding et al 1997 smith and turner 2001 kooi and groen 2001 differ to the current situation for example while wooding et al 1997 consider mixed convective forces in a vertical homogeneous one dimensional setting our problem contains two materials aquifer and aquitard in a two dimensional flow field smith and turner s 2001 saltwater boundary is coincident with the top of the aquifer whereas our problem has an intervening aquitard between the ocean floor and the aquifer kooi and groen 2001 consider that aquifer salinization will arise when boundary layer theory predicts that the aquitard is entirely saline but this neglects any boundary layer in the aquifer in addition validation is required to test the veracity of kooi and groen s 2001 method furthermore we adopt the more physically realistic sea floor boundary condition of different mass concentrations for inflow seawater and outflow ambient groundwater whereas kooi and groen 2001 and smith and turner 2001 used specified concentration dirichlet boundary conditions smith 2004 and abarca et al 2007 explain why the flow dependent concentration boundary condition that we use is more realistic relative to the dirichlet condition of previous subsea aquifer investigations for example dirichlet concentration boundaries may lead to anomalous backward dispersion effects for outflowing groundwater where it differs in concentration to the boundary value smith 2004 found significant differences between the two boundary condition types in terms of mixed convective processes in his evaluation of seawater recirculation rates the development of the boundary layer needed for the application of rayleigh theory is a dispersion based process in this study dispersion effects i e molecular diffusion and mechanical dispersion have been neglected in an attempt to match the sharp interface assumed by bakker 2006 to test the rayleigh number theory in the investigated conceptual framework an unknown dispersion value da l2 t 1 represents the artificial dispersion in seawat simulations for example da may be adopted in eq 9 assuming that da is constant within the aquitard e g kooi and groen 2001 in any case dispersion can be eliminated from eq 10 through substitution of eq 9 leading to a dispersion independent form wooding et al 1997 11 r a δ ρ s ρ f k z ρ f q z eq 11 was used to obtain the lateral distribution of raδ from the results of phase 1 modelling which involved explicit simulation of the aquitard the upward flow at the base of the aquitard was used for qz 3 results 3 1 phase 1 fig 5 shows the steady state salinity distributions for the six explicit aquitard models of phase 1 compared to bakker s 2006 analytical solution the offshore distance to the interface tip xtip increases as the aquitard kz is reduced for a given aquifer k see table 3 in agreement with the findings of frind 1982 however significant differences between the numerical results and bakker s 2006 analytical solution are found for example the analytical solution estimates that xtip reaches the end of the offshore aquifer in model 3 whereas the numerical model predicts that the freshwater body reaches only the midpoint of the offshore aquifer aside from the discrepancy in xtip the analytical solution provides a reasonable match to most of the interfaces shapes the toe position xtoe from numerical models is slightly underestimated by the analytical solution this difference may be attributable to the effects of artificial dispersion e g werner 2017a which is assessed in the sub sections that follow a quantitative comparison between numerical and analytical results from phase 1 is given in fig 6 in which the 0 5 isochlor salinity has been used to represent xtip in numerical results fig 6 shows that xtip over prediction is greater in relative terms in situations where the aquifer k aquitard kz contrast is smaller the discrepancy ranges between 42 high contrast and 154 low contrast the velocities produced by seawat are depicted in fig 7 to show aquitard flow patterns in relation to salinity distributions fig 7 provides an enlarged representation of the aquitard mixing zone which widens as kz is reduced for a given aquifer k artificial dispersion clearly plays a role in the behaviour of the aquitard mixing zone which would otherwise behave as a sharp interface the location of the divide between upwards and downwards flow in the aquitard occurs where the salinity relative to seawater is between 0 9 and 0 99 fig 7 3 2 phase 2 fig 8 shows the results obtained when bakker s 2006 assumption of seawater in the aquitard is reproduced using the ghb package the analytical and numerical results are in close agreement and in particular xtip is very well matched the good match indicates that the implicit aquitard method and the sharp interface application of seawat are mathematically robust and that artificial dispersion in seawat is low as discussed further in the following section fig 9 presents rates of upward discharge through the aquitard from both numerical modelling and the analytical solution the strong match is consistent with the salinity results from corresponding cases shown in fig 8 these results further validate the parameterization of the ghb package developed in section 2 2 1 aimed at reproducing bakker s 2006 assumptions a higher aquifer k aquitard kz contrast i e 10 000 1 was also tested using the grid of fig 4b without the upper layers that represent the aquitard and the sea and the discharge obtained is illustrated in fig 9d we take confidence from the comparison shown in figs 8 and 9 that the implicit method is suitable for exploring other assumed values for the salinity within the aquitard fig 10 illustrates salinity distributions obtained when the aquitard represented implicitly in numerical models is presumed to contain freshwater these are compared to bakker s 2006 analytical solution the xtip obtained from corresponding phase 1 explicit models is also shown black arrows fig 10 the results indicate that models assuming freshwater within the implicit aquitard and models simulating the aquitard explicitly are well matched in addition to the models shown in fig 10 a simulation with a higher hydraulic conductivity contrast equal to 10 000 1 and using the model grid of fig 4b without the upper layers that represent the aquitard and the sea was tested not shown here for brevity implicit and explicit representations of the aquitard were similarly well matched fig 11 illustrates interface distributions obtained when intuitive ghb parameters are adopted as described in section 2 2 1 the resulting xtip positions are located approximately midway between the position of bakker s 2006 xtip and the explicit result this is a rather expected outcome of using the average salinity to set the water density ρ within the aquitard which produces an intermediate value of xtip a higher aquifer k aquitard kz contrast i e 10 000 1 was also tested using the grid of fig 4b without the upper layers that represent the aquitard and the sea and this produced a similar over prediction of xtip using the implicit model 4 discussion the aquifer and aquitard salinity distributions of explicit models show more complex patterns than those that arise from sharp interface representations for example while analytical methods account for the upward flow of only freshwater seawater recirculation leads to saline groundwater discharge through the aquitard e g fig 7 at concentrations of up to 0 99 of seawater huyakorn et al 1987 obtained a similar outcome from numerical modelling of seawater intrusion in a semi confined subsea aquifer in which upward flow of groundwater with salinities greater than 0 9 of seawater occurred it is perhaps unsurprising that the well documented recirculation of seawater in coastal aquifers e g smith 2004 post et al 2013b can be expected also in subsea aquifers due to similar mixed convection processes leading to convective overturn of the seawater body the results also show that the mixing zone in the aquitard widens when the aquitard kz is reduced fig 7 consistent with numerical modelling and sand tank experiments of stratified aquifers by lu et al 2013 according to lu et al 2013 upward diluted seawater is refracted when flowing from a higher k unit aquifer towards an overlying lower k layer aquitard producing separation of streamlines within the aquitard which in turn enhances the width of the mixing zone this phenomenon may contribute to the smaller but nonetheless significant discrepancy between phase 1 numerical models and bakker s 2006 analytical solution as the aquifer k aquitard kz contrast increases see fig 6 that is enhanced mixing in the aquitard under strong k contrasts may lead to higher solute concentrations in the aquitard which tends towards the assumption by bakker 2006 that the aquitard contains seawater seawater recirculation and other dispersive effects in our results are caused by unavoidable artificial dispersion e g werner 2017a artificial dispersion appears to have only a small influence on the interface location given the close correlation between numerical and analytical methods e g fig 8 this is consistent with the small dispersion parameters i e transverse dispersivity of around 10 7 10 6 m obtained by werner 2017a b in reproducing the effect of artificial dispersion in models of similar scales nevertheless artificial dispersion allows for a rayleigh type analysis of the mixed convective processes occurring in the aquitard fig 12 shows the values of raδ for three different salinity conditions 0 1 0 5 and 0 9 isochlors the value of raδ for the 0 5 isochlor is relatively consistent across the six models at approximately 2 whereas there is variation in raδ for the 0 1 and 0 9 isochlors the stability of the 0 5 isochlor value is convenient for defining a critical value of raδ because this concentration is widely used to indicate the penetration of seawater in variable density problems e g volker and rushton 1982 abarca et al 2007 sebben et al 2015 the error in the sharp interface prediction of the interface tip as determined by comparison to the explicit numerical solution increases as the presumed salinity of the offshore aquitard increases this is quantified in fig 13 in which xtip reflects the location of the 0 5 isochlor at the top of the offshore aquifer error values show reducing discrepancies with increasing aquifer k aquitard kz as discussed above 5 conclusions our numerical modelling results indicate that the salinity structure within offshore aquitards is closely related to that of offshore aquifers in contradiction to bakker s 2006 assumption of seawater in the aquitard and in general agreement with the conclusion by kooi and groen 2001 that salinization of the aquitard leads to salinization of the underlying aquifer rayleigh theory is applied to the results of numerical models that simulate offshore aquitards explicitly adding to previous rayleigh applications that consider alternative conceptual arrangements of the unstable mixed convective problem we find that a critical rayleigh number of about 2 accords with the position where the aquitard salinity transitions from freshwater to seawater whether this critical value applies to subsea problems involving more realistic dispersion parameters is the subject of further research the numerical experiments undertaken in this study reveal that bakker s 2006 analytical solution over predicts the offshore extent of freshwater specifically the position of the interface tip a novel application of the ghb package of seawat to the current conceptual model allowed us to determine that bakker s 2006 analytical solution is sensitive to the aquitard salinity assumption and that the over prediction of the interface tip is associated with the assumption of seawater in the aquitard seawat s ghb formulation does not allow for accurate representation of the analytically derived offshore aquitard conditions without artificial modification of the ghb input parameters to account for the buoyancy effects that accompany predetermined aquitard salinity values we offer guidance on ghb application for offshore aquifer aquitard simulation and compare models with implicit and explicit aquitard representation to show that the ghb package can reliably simulate offshore freshwater extent using our proposed method the results of this investigation show that the overestimation of the offshore freshwater extent produced by recent analytical solutions appears correctable if freshwater instead of seawater is presumed to occur in the offshore aquitard where the underlying aquifer contains freshwater a reformulation of the analytical solution using the condition that the aquitard contains freshwater instead of seawater is the subject of concurrent research acknowledgements this research is a part of the masters thesis of the first author at flinders university adrian werner is the recipient of an australian research council future fellowship project number ft150100403 no new field or laboratory data were produced in the course of this research all data for this paper are properly cited and referred to in the reference list we also gratefully acknowledge the suggestions of two anonymous reviewers supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2017 11 025 appendix supplementary materials image application 1 
889,fresh groundwater is widespread globally in offshore aquifers and is particularly dependent on the properties of offshore aquitards which inhibit seawater freshwater mixing thereby allowing offshore freshwater to persist however little is known of the salinity distribution in subsea aquitards especially in relation to the offshore freshwater distribution this is critical for the application of recent analytical solutions to subsea freshwater extent given requisite assumptions about aquitard salinity in this paper we use numerical simulation to explore the extent of offshore freshwater in simplified situations of subsea aquifers and overlying aquitards including in relation to the upward leakage of freshwater the results show that available analytical solutions significantly overestimate the offshore extent of upwelling freshwater due to the presumption of seawater in the aquitard whereas the seawater wedge toe is less sensitive to the assumed aquitard salinity we also explore the use of implicit conductance based representations of the aquitard i e using the popular seawat code and find that seawat s implicit approach i e ghb package can represent the offshore distance of upwelling freshwater using a novel parameterization strategy the results show that an estimate of the upward freshwater flow that is required to freshen the aquitard is associated with the dimensionless rayleigh number whereby the critical rayleigh number that distinguishes fresh and saline regions based on the position of the 0 5 isochlor within the aquitard is approximately 2 keywords density dependent flow seawater intrusion coastal aquifer offshore freshwater aquitard submarine groundwater discharge 1 introduction despite the widespread presence of freshwater beneath the seafloor e g post et al 2013a the processes accompanying the occurrence of fresh offshore groundwater are under studied relative to the current knowledge of seawater freshwater relationships in onshore aquifers case studies of freshwater bodies in offshore aquifers have been undertaken for hong kong china jiao et al 2015 kwong and jiao 2016 suriname groen et al 2000 and the atlantic continental shelf usa including nantucket island marksamer et al 2007 and the subsea aquifers near the border between georgia and florida johnston 1983 in each of these cases fresh offshore groundwater underlies an extensive low permeability sequence i e an aquitard which inhibits mixing between the fresh groundwater and overlying seawater offshore freshwater may be derived from modern discharge originating from onshore aquifers and or may be the consequence of paleo freshwater entrapped during the low sea levels of the pleistocene epoch cohen et al 2010 here we define modern discharge as occurring under current sea levels whereby favourable conditions lead to freshwater discharge into offshore aquifers in some cases modern discharge has created offshore freshwater extending considerable seaward distances within continental shelves bakker 2006 studied such a system near the georgia florida border usa where pre development i e prior to human impacts groundwater heads are thought to have created a fresh groundwater body that reaches the edge of the continental shelf i e 120 km offshore kooi and groen 2001 studied the size of hypothetical offshore freshwater reserves driven by the onshore groundwater conditions also concluding that freshwater may extend tens of kilometres offshore as a result of modern groundwater discharge in the remainder of this manuscript only the simplified case of offshore fresh groundwater that is in equilibrium with the onshore conditions is considered i e paleo freshwater in offshore aquifers is neglected according to post et al 2013a paleo freshwater is an important worldwide phenomenon that can be regarded as a potential freshwater resource however in the interests of scrutinizing the solution of bakker 2006 described later in this paper we neglect paleo freshwater fig 1 presents a schematic of the conceptual model aside from the onshore hydraulic heads other factors play important roles in the offshore distribution of freshwater for example frind 1982 concluded that the vertical hydraulic conductivity kz of the subsea aquitard has a critical influence on the offshore distance of upward freshwater discharge which in turn affects the salinity distribution in the underlying aquifer he used two different values for kz to demonstrate that the lower value resulted in increased thickness of the aquifer s freshwater seawater mixing zone and a larger offshore distance of freshwater leakage to the sea lu et al 2013 undertook a more detailed analysis of the effect of kz on freshwater seawater mixing and showed that as the aquitard aquifer contrast in hydraulic conductivity increases refraction across the aquitard aquifer interface creates a broader mixing zone in the aquitard michael et al 2016 showed the important role of aquifer heterogeneities in controlling subsea groundwater salinity distributions concluding that modern continental discharge can account for freshened offshore groundwater to tens or hundreds of kilometres offshore where preferential flow creates active offshore flow systems analytical solutions to the steady state extent of freshwater under the sea in offshore semi confined aquifers have been produced by edelman 1972 kooi and groen 2001 and bakker 2006 they adopted steady state sharp interface representations of the freshwater seawater mixing zone and other simplifications to enable mathematical tractability in these solutions fresh groundwater discharge through the overlying subsea aquitard is treated as a head dependent leakage term this calculation requires that the groundwater salinity within the aquitard is a priori known in the analytical solutions of kooi and groen 2001 and bakker 2006 the entire offshore aquitard is presumed to contain seawater the implications of this assumption in terms of the predictability of these analytical approaches are tested in the current analysis we expect that the upward leakage of freshwater in bakker s 2006 solution creates freshening of the overlying aquitard as opposed to it containing seawater this is scrutinized by considering advective dispersive and buoyancy forces occurring within the aquitard i e due to seawater above the aquitard and freshwater below it the primary aim of this paper is to assess the offshore extent of freshwater and seawater in idealized coastal aquifer aquitard settings i e under conditions that allow for comparison with the bakker 2006 solution the salinity distributions in subsea aquitards are explored in relation to subsea freshwater extents and the accompanying upward leakage of freshwater to the sea using numerical models a mixed convection evaluation of the unstable density situation of offshore aquitards is undertaken to incorporate the factors that lead to density driven aquitard salinization in applying the popular seawat code to reproduce numerically bakker s 2006 analytical solution we also report on attempts to model the offshore aquitard using an implicit representation i e a head dependent boundary condition as an approximation of the explicit representation of the aquitard while the implicit method is numerically efficient it has not been evaluated with respect to the more physically reliable explicit approach in terms of subsea aquifer aquitard simulation both explicit and implicit models are used to explore the assumptions adopted by bakker 2006 regarding the aquitard salinity 2 methodology 2 1 analytical solution edelman 1972 developed the first analytical solution of the extent of offshore freshwater within a semi confined subsea aquifer where buoyancy forces and the location of the freshwater seawater interface influence the upwelling freshwater discharge through the offshore aquitard in his solution the tip of the interface i e where the interface intersects the top of the aquifer is offshore and the freshwater body otherwise occurs as a lens similar to the situation of small islands kooi and groen 2001 produced a solution for the situation when the toe i e where the interface intersects the bottom of the aquifer is offshore both edelman 1972 and kooi and groen 2001 considered infinitely long offshore aquifer aquitard systems bakker 2006 built on their solutions by solving for the situation where freshwater reaches the offshore limit of the subsea aquifer e g the edge of the continental shelf which he represented as a vertical boundary that reflects the hydrostatic head of the sea bakker s 2006 conceptual model is consistent with the situation illustrated in fig 1 an offshore semi confined aquifer containing freshwater and seawater that are in equilibrium i e steady state conditions and connected to a confined onshore aquifer freshwater enters the aquifer at the landward boundary and eventually flows above a body of seawater assumed immobile the shape of the freshwater seawater interface which is treated as a sharp pressure equilibrium boundary is a function of buoyancy forces arising from the density difference between freshwater and seawater losses of freshwater from the offshore aquifer referred to here as submarine fresh groundwater discharge sfgd occur as upward seepage through the offshore aquitard or as outflow where the aquifer is exposed at the continental shelf fig 1 illustrates the case where offshore freshwater does not extend to the continental shelf and therefore the only discharge pathway for sfgd from the semi confined aquifer is via upward leakage through the aquitard fig 2 shows the 2d cross section and associated variables adopted by bakker 2006 in developing his analytical solution the onshore confined aquifer and offshore semi confined aquifer have uniform thickness h and are assumed horizontal homogeneous and isotropic the offshore aquitard which is also homogeneous and isotropic has a uniform thickness hl and is overlain by a depth of seawater equal to hs the offshore domain extends a distance ls to the continental shelf which is represented by a vertical specified head boundary condition of hydrostatic seawater heads freshwater inflow qc l2 t 1 to the model domain occurs through the left hand boundary which is situated at a landward distance lc from the shoreline the sea level is zs above the base of the aquifer freshwater and seawater densities are designated ρf and ρs respectively analogous conceptual models were adopted by kooi and groen 2001 bakker 2006 and bakker et al 2017 the equivalent freshwater head of the ocean at the top of the aquitard ht is given by bakker 2006 1 h t z s ρ s ρ f ρ f h s application of darcy s law accounting for the buoyancy force that arises from the assumption of seawater in the aquitard produces the following equation for upward freshwater flow qz l t 1 2 q z k z h h t h l ρ s ρ f ρ f here h is the head within the freshwater region of the subsea aquifer and kz is the vertical hydraulic conductivity in this case of the aquitard l t 1 if the aquitard contains freshwater the buoyancy term ρs ρf ρf should be removed from eq 2 bakker 2006 rewrites eq 2 in terms of the hydrostatic freshwater head of the sea at the base of the aquitard hs defined in terms of ht as 3 h s h t ρ s ρ f ρ f h l combining eqs 2 and 3 produces bakker 2006 4 q z k z h l h h s eq 4 is presented in the density independent form of darcy s law applied to flow across the aquitard the density effect introduced by assuming that the aquitard contains seawater which requires application of the density dependent form of darcy s law is manifested by formulating hs equal to the equivalent freshwater head of a hydrostatic seawater column representing sea level at the base of the aquitard bakker 2006 identifies four possible situations regarding the position of the interface toe and tip relative to both the shoreline and continental shelf boundary which of the four cases arises from a particular set of parameters is determined using two dimensionless parameters see bakker 2006 these then lead to relevant analytical solutions to solve for the extent of offshore freshwater bakker et al 2017 correct an inaccuracy in bakker 2006 regarding the evaluation of the incomplete elliptic integrals for the solution of the two cases where the tip of the interface reaches the edge of the continental shelf i e cases iii and iv bakker 2006 we replaced the inland specified flux boundary condition used by bakker 2006 with a specified head condition because inland head values are preferred as input to the problem that is groundwater heads are known more commonly than groundwater fluxes the head boundary condition was satisfied using a numerical shooting approach based on the classical 4th order runge kutta technique thomann 2017 this approach was necessary because the head based method provided by bakker et al 2017 was not available at the time of our investigation 2 2 numerical modelling numerical modelling was used to assess the offshore extent of freshwater and seawater in both the aquifer and aquitard below the sea under conditions that allow for comparison with the bakker 2006 solution seawat version 4 langevin et al 2008 was adopted for this purpose seawat has been extensively tested and is widely used for the simulation of density dependent groundwater flow and solute transport combining modflow 2000 harbaugh et al 2000 and mt3dms zheng and wang 1999 the flow and transport components are coupled through the fluid density term which is taken as a linear function of solute concentration the methods adopted by seawat are described in the user manual langevin et al 2008 and are therefore omitted here for brevity we test both explicit and implicit representations of the subsea aquitard in numerical experiments because implicit representation offers significant computational savings and is therefore an attractive option for practical field scale problems in the explicit approach the aquitard is subdivided into horizontal layers an overlying specified head boundary condition top layer represents the hydrostatic head of the sea and groundwater discharges at the ambient concentration whereas inflowing water has seawater salinity 2 2 1 implicit simulation of the subsea aquitard implicit representation of the subsea aquitard is at least theoretically possible through application of seawat s general head boundary ghb package langevin et al 2008 the implicit approach is appealing because it adopts a similar conductance based representation of the subsea aquitard as described by bakker 2006 that is the ghb package simulates flow qghb l3 t 1 into or out of a cell as a function of the difference between the head of the cell and that of an external sink source harbaugh 2005 in our case the latter is the sea solute concentrations accompanying inflow and outflow via the ghb package are dealt with in the sink and source mixing ssm package of mt3dms zheng and wang 1999 a schematic of the ghb package is given in fig 3 and is discussed in more detail below the ghb package adopts the following formulation guo and langevin 2002 5 q g h b c g h b h f i h f g h b ρ ρ f ρ f z i z g h b here zi is the cell centre elevation zghb is the user specified base elevation of the ghb reservoir hf i is the equivalent freshwater head at the centre of the model cell l and hf ghb is the equivalent freshwater head at the base of the ghb reservoir fig 3 seawat obtains hf ghb from the user specified hghb the water level in the ghb reservoir using the formulation h f g h b h g h b ρ g h b ρ f z g h b ρ g h b ρ f ρ f seawat determines the value of ρghb density of water in the ghb reservoir through conversion of the user specified solute concentration for the water in the ghb reservoir cghb is the user specified boundary conductance l2 t 1 given by kghba l where kghb is the hydraulic conductivity of material between the ghb reservoir and the model cell l t 1 a is the area perpendicular to ghb flow l2 and l is the distance between the cell centre and the base of the ghb reservoir ρ m l 3 represents the density of water between the ghb reservoir and the model cell seawat s formulation of ρ makes application of the ghb package to the variable density arrangement of fig 3 challenging ρ is assumed in seawat to be equal to the average of ρghb and the fluid density of the model cell ρi whereas in reality groundwater between the model cell and the boundary i e in the aquitard is likely to change depending on the direction of flow seawat s approach is a simplification of otherwise a priori unknown salinity conditions that occur within the aquitard i e in the connection between the ghb reservoir and the boundary cell the most appropriate value of ρ for the simulation of subsea aquitards within the current conceptual models is presently unclear that is the correct fluid density to use for aquitards overlying fresh subsea aquifers is unstudied to address this we develop guidance on the selection of ghb parameters for the current problem through model testing using various ghb parameter combinations the intent is to apply the ghb package so that it reproduces as closely as possible the mathematics representing boundary discharge as adopted by bakker 2006 the ghb package is also tested for consistency against the results of models that adopt an explicit i e physically based representation of the aquitard table 1 contains the final list of ghb parameters given in terms of variables defined by bakker 2006 and that reproduce bakker s 2006 formulae for flow through the aquitard the derivation of parameters is described below in our use of the ghb package we aim to impose three alternative salinity conditions in the subsea aquitard namely entirely seawater freshwater or mixed salinity water this can be achieved by manipulating the ghb parameters of ρghb and zghb consider firstly the situation where the upper aquifer cell contains freshwater but the aquitard contains seawater i e bakker s 2006 assumption this allows hl l on the basis that l can be taken from the top of the cell i e rather than from the cell centre as shown in fig 3 given the dupuit assumption and because freshwater within the aquifer cell precludes the need to correct the cell s equivalent freshwater head for the reference elevation also by taking ρghb ρf ρ ρf when the aquifer cell contains freshwater thereby eliminating the buoyancy term from eq 5 which is not present in bakker s 2006 equation i e eq 4 in order to account for seawater occurring in the aquitard given ρghb ρf hghb is assigned the value of hs making the table 1 substitutions eq 5 reduces to eq 4 thereby replicating bakker s 2006 formula eq 5 arrives at eq 4 using table 1 substitutions only when the subsea aquifer contains freshwater however the substitution of table 1 parameters into eq 5 results in flow across the aquitard where the aquifer contains seawater as apparent in the analysis that follows in violation of the assumptions of bakker 2006 to account for this a modification is made to table 1 parameter substitutions so that no flow will occur when the model cell contains seawater that is we require qghb 0 where ρi ρs model cells representing the aquifer that are filled with seawater should reflect the hydrostatic head of the ocean giving rise to hf i zi zs zi ρs ρf from direct application of bernoulli s equation substituting these conditions into eq 5 considering the abovementioned definition of ρ and adopting a selection of the table 1 substitutions leads to 6 c g h b z i ρ s ρ f z s z i h s ρ s ρ f 2 ρ f z i z g h b 0 in eq 6 only zghb can be adjusted without changing the freshwater flow formulation because the buoyancy term is eliminated under freshwater conditions in the aquifer as explained above thus eq 6 is rearranged in terms of zghb 7 z g h b 2 ρ s ρ f ρ s z s ρ f h s z i hence in combination with the use of ρf for ρghb eq 7 creates vertical aquitard flow at rates that assume that the aquitard contains seawater where there is freshwater in the aquifer whereas there is no flow in the aquitard where the underlying aquifer contains only seawater i e following bakker s 2006 approach an alternative ghb parameterization is needed to represent the same conditions except where the aquitard contains freshwater in regions of freshwater in the underlying aquifer considering the situation of freshwater in the top of the aquifer the buoyancy term in eq 2 is removed and the value for hf ghb used in eq 5 is ht again we require qghb 0 where ρi ρs leading to the following substitution for zghb 8 z g h b 2 ρ s ρ f ρ s z s ρ f h t z i the approaches to ghb parameterization described above were tested by comparing bakker s 2006 method with models that adopt implicit and explicit representations of the subsea aquitard 2 2 2 description of numerical experiments table 2 describes the baseline parameters used in the analytical and numerical models parameters are typical of previous coastal aquifer modelling by kooi and groen 2001 post and kooi 2003 werner and simmons 2009 laattoe et al 2013 and werner 2017b with some trial and error to achieve tip positions that were landward of the model s offshore boundary we did this to ensure that the tip position was sensitive to differences between models rather than being located at the continental shelf two different scales were considered labelled as sections 1 and 2 in table 2 the smaller domain size of section 1 allowed for fine discretization and was used for cases of lower contrast between the aquitard kz and the aquifer k the longer extent of section 2 provided insight into situations involving higher k contrasts and more realistic scales the same onshore head h 32 m was used in all simulations thereby creating various rates of qc as a consequence of changes to other parameters two phases of numerical experimentation were used to achieve the objectives of the investigation phase 1 numerical models adopted an explicit representation of the offshore aquitard allowing for physically based simulation of the mixed convective processes occurring in the aquifer aquitard system at least to the degree that the low dispersion conditions adopted in this study allow dispersion parameters were set to zero to reflect the sharp interface approach of bakker 2006 and only unavoidable artificial numerical dispersion referred to hereafter as artificial dispersion e g werner 2017a creates widening of the mixing zone in order to minimize oscillation problems produced by simulating purely advective scenarios in which the grid peclet number exceeds the recommended maximum value for finite difference methods of 2 zheng and bennett 2002 the third order tvd method zheng and wang 1999 was used in solving the transport equation in all simulations the modelling results were compared to bakker s 2006 solution to assess the validity of his underlying assumptions regarding the aquitard salinity phase 2 numerical modelling involved implicit representation of the offshore aquitard commensurate with the approach of bakker 2006 thereby exploring the use of the ghb package of seawat in simulating offshore conditions substitutions as described in section 2 2 1 were adopted to allow for different aquitard salinities to be tested and comparisons were made with models that simulate the aquitard explicitly in the two phases several values of the aquifer k aquitard kz contrast were tested as outlined in table 3 which lists the parameters that differentiate the various numerical experiments steady state results were achieved by running seawat in transient mode until no further changes were discernible two different finite difference grids were used as shown in fig 4 models 1 2 and 3 adopted the model domain grid shown in fig 4a for which the horizontal grid resolution varies from 0 1 m at the seaward boundary increasing to 10 m at the landward boundary the grid was designed such that the interface was contained within the part of the model with 0 1 m resolution layers are 0 1 m deep the upper layer of explicit models contains high k specified head cells within the offshore region to simulate the effect of the sea the next ten layers represent the 1 m thick aquitard in the implicit aquitard models of phase 2 the grid of fig 4a was used without the upper eleven layers that simulate the aquitard and the overlying specified head boundary condition the ghb package was instead used to simulate the aquitard and the sea fig 4b shows the finite difference grid used for models 4 5 and 6 for which the grid resolution represents a trade off between model execution times and accuracy the horizontal grid resolution varies from 50 m at the left hand boundary decreasing to 2 m at the seaward boundary the region of the model containing the interface has a 5 m horizontal discretization vertical discretization is again 0 10 m the boundary condition at the onshore limit left boundary is a specified head condition with a concentration boundary condition that adopts a fixed salinity equal to freshwater i e relative salinity of zero for groundwater flow entering the system the influence of the sea is represented by 20 m and 3000 m of horizontal seafloor in fig 4a and b respectively along with the right vertical edge of the model aside from the region where the aquitard is exposed to the sea which was assigned a no flow condition this general layout is similar to that described by kooi and groen 2001 seawater hydrostatic heads are specified at sea boundaries in combination with a concentration condition of seawater salinity i e relative salinity of 1 0 for the incoming groundwater whereas groundwater discharges to the sea at the ambient concentration three different salinity conditions were assigned to the aquitard in the phase 2 numerical experiments models 7 8 and 9 represent bakker s 2006 assumption of seawater in the aquitard while models 10 11 and 12 presume that the aquitard contains freshwater see section 2 2 1 for ghb parameters finally seawat s default calculation of mixed water was tested using models 13 14 and 15 whereby the aquitard s water has a density equal to the average of the water in the uppermost aquifer cell and seawater in this case the program is used in its more intuitive form whereby hf ghb is calculated internally and both ρghb and zghb represent the current conceptual conditions i e seawater density and the height of the top of the aquitard respectively table 4 summarizes the case specific parameters used in phase 2 2 3 mixed convective analysis of the subsea aquitard salinization of the aquitard is a mixed convective problem in which the unstable configuration of higher density seawater overlying lower density freshwater gives rise to a downwards gravity or buoyancy force on the seawater at the upper boundary of the aquitard downward flow will occur in the aquitard where buoyancy forces have overcome the advective forces associated with sfgd wooding et al 1997 attempted to predict the salinity distribution within low permeable sediments subject to mixed convective processes they showed that the solute motion in unstable density configurations is initially driven by solute dispersion which forms a saline boundary layer if the upward flow of freshwater is sufficient to counteract dispersion the conditions may remain in equilibrium thereby avoiding the creation of density driven solute fingers based on these principles and under equilibrium conditions kooi and groen 2001 simplified the saline boundary layer thickness δ to 9 δ d q z where d is the dispersion coefficient l2 t 1 and qz is the darcy velocity of vertical freshwater flow l t 1 kooi and groen 2001 and wooding et al 1997 considered dispersion as only molecular diffusion on this basis kooi and groen 2001 suggested that complete salinization of the aquitard will occur when the aquitard thickness is equal to δ they then used this definition to redefine the location of the interface tip whereby their analytical estimates of the offshore freshwater length were modified such that sfgd was terminated at the offshore position where δ equals hl the approach adopted by kooi and groen 2001 resulted in a reduction of 50 80 of the offshore freshwater length for the various cases that were analysed unfortunately they were unable to obtain consistent agreement between their numerical simulations and their δ based truncation of the offshore freshwater extent the forces acting in the boundary layer are represented by wooding et al s 1997 boundary rayleigh number raδ which is a dimensionless parameter defined by the ratio of buoyancy forces to resistive forces i e dispersion wooding et al 1997 proposed the following definition 10 r a δ ρ s ρ f k z δ ρ f d the onset of instability in the boundary layer that is when buoyancy forces overcome dispersion leads to a critical value of raδ namely rac whereby dispersive transport transitions to density driven transport in the form of unstable saline fingers wooding et al 1997 found that rac is approximately 10 in silty and sandy clay bearing sediments that is unstable fingers develop once raδ exceeds 10 kooi and groen 2001 do not report values of raδ in the analytical development provided by bakker 2006 there is no consideration of boundary layer development and the possibility that it truncates the extent of offshore sfgd smith and turner 2001 used a modified equation for the rayleigh number ra to analyse the effects of mixed convection within a two dimensional cross sectional model of freshwater discharge to a saline estuary their conceptual model bears many similarities to the current one except the estuary was represented as a horizontal one dimensional boundary condition i e non penetrating and immediately overlying the aquifer of specified head and concentration that is the intervening aquitard considered in figs 1 and 2 was not included smith and turner 2001 concluded that the critical ra for the occurrence of saltwater below the estuary is approximately five the three applications of rayleigh theory described above i e wooding et al 1997 smith and turner 2001 kooi and groen 2001 differ to the current situation for example while wooding et al 1997 consider mixed convective forces in a vertical homogeneous one dimensional setting our problem contains two materials aquifer and aquitard in a two dimensional flow field smith and turner s 2001 saltwater boundary is coincident with the top of the aquifer whereas our problem has an intervening aquitard between the ocean floor and the aquifer kooi and groen 2001 consider that aquifer salinization will arise when boundary layer theory predicts that the aquitard is entirely saline but this neglects any boundary layer in the aquifer in addition validation is required to test the veracity of kooi and groen s 2001 method furthermore we adopt the more physically realistic sea floor boundary condition of different mass concentrations for inflow seawater and outflow ambient groundwater whereas kooi and groen 2001 and smith and turner 2001 used specified concentration dirichlet boundary conditions smith 2004 and abarca et al 2007 explain why the flow dependent concentration boundary condition that we use is more realistic relative to the dirichlet condition of previous subsea aquifer investigations for example dirichlet concentration boundaries may lead to anomalous backward dispersion effects for outflowing groundwater where it differs in concentration to the boundary value smith 2004 found significant differences between the two boundary condition types in terms of mixed convective processes in his evaluation of seawater recirculation rates the development of the boundary layer needed for the application of rayleigh theory is a dispersion based process in this study dispersion effects i e molecular diffusion and mechanical dispersion have been neglected in an attempt to match the sharp interface assumed by bakker 2006 to test the rayleigh number theory in the investigated conceptual framework an unknown dispersion value da l2 t 1 represents the artificial dispersion in seawat simulations for example da may be adopted in eq 9 assuming that da is constant within the aquitard e g kooi and groen 2001 in any case dispersion can be eliminated from eq 10 through substitution of eq 9 leading to a dispersion independent form wooding et al 1997 11 r a δ ρ s ρ f k z ρ f q z eq 11 was used to obtain the lateral distribution of raδ from the results of phase 1 modelling which involved explicit simulation of the aquitard the upward flow at the base of the aquitard was used for qz 3 results 3 1 phase 1 fig 5 shows the steady state salinity distributions for the six explicit aquitard models of phase 1 compared to bakker s 2006 analytical solution the offshore distance to the interface tip xtip increases as the aquitard kz is reduced for a given aquifer k see table 3 in agreement with the findings of frind 1982 however significant differences between the numerical results and bakker s 2006 analytical solution are found for example the analytical solution estimates that xtip reaches the end of the offshore aquifer in model 3 whereas the numerical model predicts that the freshwater body reaches only the midpoint of the offshore aquifer aside from the discrepancy in xtip the analytical solution provides a reasonable match to most of the interfaces shapes the toe position xtoe from numerical models is slightly underestimated by the analytical solution this difference may be attributable to the effects of artificial dispersion e g werner 2017a which is assessed in the sub sections that follow a quantitative comparison between numerical and analytical results from phase 1 is given in fig 6 in which the 0 5 isochlor salinity has been used to represent xtip in numerical results fig 6 shows that xtip over prediction is greater in relative terms in situations where the aquifer k aquitard kz contrast is smaller the discrepancy ranges between 42 high contrast and 154 low contrast the velocities produced by seawat are depicted in fig 7 to show aquitard flow patterns in relation to salinity distributions fig 7 provides an enlarged representation of the aquitard mixing zone which widens as kz is reduced for a given aquifer k artificial dispersion clearly plays a role in the behaviour of the aquitard mixing zone which would otherwise behave as a sharp interface the location of the divide between upwards and downwards flow in the aquitard occurs where the salinity relative to seawater is between 0 9 and 0 99 fig 7 3 2 phase 2 fig 8 shows the results obtained when bakker s 2006 assumption of seawater in the aquitard is reproduced using the ghb package the analytical and numerical results are in close agreement and in particular xtip is very well matched the good match indicates that the implicit aquitard method and the sharp interface application of seawat are mathematically robust and that artificial dispersion in seawat is low as discussed further in the following section fig 9 presents rates of upward discharge through the aquitard from both numerical modelling and the analytical solution the strong match is consistent with the salinity results from corresponding cases shown in fig 8 these results further validate the parameterization of the ghb package developed in section 2 2 1 aimed at reproducing bakker s 2006 assumptions a higher aquifer k aquitard kz contrast i e 10 000 1 was also tested using the grid of fig 4b without the upper layers that represent the aquitard and the sea and the discharge obtained is illustrated in fig 9d we take confidence from the comparison shown in figs 8 and 9 that the implicit method is suitable for exploring other assumed values for the salinity within the aquitard fig 10 illustrates salinity distributions obtained when the aquitard represented implicitly in numerical models is presumed to contain freshwater these are compared to bakker s 2006 analytical solution the xtip obtained from corresponding phase 1 explicit models is also shown black arrows fig 10 the results indicate that models assuming freshwater within the implicit aquitard and models simulating the aquitard explicitly are well matched in addition to the models shown in fig 10 a simulation with a higher hydraulic conductivity contrast equal to 10 000 1 and using the model grid of fig 4b without the upper layers that represent the aquitard and the sea was tested not shown here for brevity implicit and explicit representations of the aquitard were similarly well matched fig 11 illustrates interface distributions obtained when intuitive ghb parameters are adopted as described in section 2 2 1 the resulting xtip positions are located approximately midway between the position of bakker s 2006 xtip and the explicit result this is a rather expected outcome of using the average salinity to set the water density ρ within the aquitard which produces an intermediate value of xtip a higher aquifer k aquitard kz contrast i e 10 000 1 was also tested using the grid of fig 4b without the upper layers that represent the aquitard and the sea and this produced a similar over prediction of xtip using the implicit model 4 discussion the aquifer and aquitard salinity distributions of explicit models show more complex patterns than those that arise from sharp interface representations for example while analytical methods account for the upward flow of only freshwater seawater recirculation leads to saline groundwater discharge through the aquitard e g fig 7 at concentrations of up to 0 99 of seawater huyakorn et al 1987 obtained a similar outcome from numerical modelling of seawater intrusion in a semi confined subsea aquifer in which upward flow of groundwater with salinities greater than 0 9 of seawater occurred it is perhaps unsurprising that the well documented recirculation of seawater in coastal aquifers e g smith 2004 post et al 2013b can be expected also in subsea aquifers due to similar mixed convection processes leading to convective overturn of the seawater body the results also show that the mixing zone in the aquitard widens when the aquitard kz is reduced fig 7 consistent with numerical modelling and sand tank experiments of stratified aquifers by lu et al 2013 according to lu et al 2013 upward diluted seawater is refracted when flowing from a higher k unit aquifer towards an overlying lower k layer aquitard producing separation of streamlines within the aquitard which in turn enhances the width of the mixing zone this phenomenon may contribute to the smaller but nonetheless significant discrepancy between phase 1 numerical models and bakker s 2006 analytical solution as the aquifer k aquitard kz contrast increases see fig 6 that is enhanced mixing in the aquitard under strong k contrasts may lead to higher solute concentrations in the aquitard which tends towards the assumption by bakker 2006 that the aquitard contains seawater seawater recirculation and other dispersive effects in our results are caused by unavoidable artificial dispersion e g werner 2017a artificial dispersion appears to have only a small influence on the interface location given the close correlation between numerical and analytical methods e g fig 8 this is consistent with the small dispersion parameters i e transverse dispersivity of around 10 7 10 6 m obtained by werner 2017a b in reproducing the effect of artificial dispersion in models of similar scales nevertheless artificial dispersion allows for a rayleigh type analysis of the mixed convective processes occurring in the aquitard fig 12 shows the values of raδ for three different salinity conditions 0 1 0 5 and 0 9 isochlors the value of raδ for the 0 5 isochlor is relatively consistent across the six models at approximately 2 whereas there is variation in raδ for the 0 1 and 0 9 isochlors the stability of the 0 5 isochlor value is convenient for defining a critical value of raδ because this concentration is widely used to indicate the penetration of seawater in variable density problems e g volker and rushton 1982 abarca et al 2007 sebben et al 2015 the error in the sharp interface prediction of the interface tip as determined by comparison to the explicit numerical solution increases as the presumed salinity of the offshore aquitard increases this is quantified in fig 13 in which xtip reflects the location of the 0 5 isochlor at the top of the offshore aquifer error values show reducing discrepancies with increasing aquifer k aquitard kz as discussed above 5 conclusions our numerical modelling results indicate that the salinity structure within offshore aquitards is closely related to that of offshore aquifers in contradiction to bakker s 2006 assumption of seawater in the aquitard and in general agreement with the conclusion by kooi and groen 2001 that salinization of the aquitard leads to salinization of the underlying aquifer rayleigh theory is applied to the results of numerical models that simulate offshore aquitards explicitly adding to previous rayleigh applications that consider alternative conceptual arrangements of the unstable mixed convective problem we find that a critical rayleigh number of about 2 accords with the position where the aquitard salinity transitions from freshwater to seawater whether this critical value applies to subsea problems involving more realistic dispersion parameters is the subject of further research the numerical experiments undertaken in this study reveal that bakker s 2006 analytical solution over predicts the offshore extent of freshwater specifically the position of the interface tip a novel application of the ghb package of seawat to the current conceptual model allowed us to determine that bakker s 2006 analytical solution is sensitive to the aquitard salinity assumption and that the over prediction of the interface tip is associated with the assumption of seawater in the aquitard seawat s ghb formulation does not allow for accurate representation of the analytically derived offshore aquitard conditions without artificial modification of the ghb input parameters to account for the buoyancy effects that accompany predetermined aquitard salinity values we offer guidance on ghb application for offshore aquifer aquitard simulation and compare models with implicit and explicit aquitard representation to show that the ghb package can reliably simulate offshore freshwater extent using our proposed method the results of this investigation show that the overestimation of the offshore freshwater extent produced by recent analytical solutions appears correctable if freshwater instead of seawater is presumed to occur in the offshore aquitard where the underlying aquifer contains freshwater a reformulation of the analytical solution using the condition that the aquitard contains freshwater instead of seawater is the subject of concurrent research acknowledgements this research is a part of the masters thesis of the first author at flinders university adrian werner is the recipient of an australian research council future fellowship project number ft150100403 no new field or laboratory data were produced in the course of this research all data for this paper are properly cited and referred to in the reference list we also gratefully acknowledge the suggestions of two anonymous reviewers supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2017 11 025 appendix supplementary materials image application 1 
