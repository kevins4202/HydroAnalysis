index,text
2455,forecasting daily runoff is of great importance to the allocation of water resources and flood prevention many existing methods utilize identical networks to learn the long term dependencies and the short term ones in addition the importance of data augmentation in a deep network is ignored in order to attain more accurate and reliable runoff forecasts this paper proposes a novel framework that designs two different components in nonlinear part to learn the long term data and the short term ones respectively a long short term components neural network lstcnet is presented to verify the effectiveness of the framework meanwhile we introduce ar model to capture the linear dependencies furthermore considering that the daily runoff data are unstable and change frequently and sharply in flood season a linear interpolation method that focuses on the peak values is used to enhance the stability of hydrological data experimental results of lstcnet the multivariate adaptive regression spline mars the long short term memory neural networks lstm the attention mechanism based lstm model am lstm and the caganet model show that lstcnet achieves the best performance in accurate daily runoff prediction the lstcnet s numerical values of mean absolute error mae root mean square error rmse the nash sutcliffe effciency nse correlation coefficient cc and willmott s index wi can reach 0 32 1 50 0 997 0 999 and 0 999 respectively keywords combined neural network daily runoff forecasting data augmentation gru long short term framework residual structure data availability the authors do not have permission to share data 1 introduction accurate prediction of daily runoff is beneficial to allocate water resources efficiently and provide forceful guidance for flood prevention the runoff process has the characteristics of randomness chaos and fuzziness due to many factors such as meteorology conditions river basin surface mantle as well as human activities traditional process driven algorithms such as fuzzy analysis luchetta and manetti 2003 wavelet analysis sang et al 2016 and other traditional algorithms are used to decompose time series then describe the complex physical process of runoff formation by mathematical formulas based on principles of hydraulics and hydrology however traditional algorithms often need a great number of boundary conditions and measured information which may not always be available in addition the performance of the algorithms largely depends on the application experiences of researchers as a result accurate forecasting of daily runoff is still a challenging problem for conventional hydrological models the data driven approach may offer a promising alternative to the existing methods for the hydrological prediction of daily runoff machine learning is an end to end learning approach that can predict daily runoff of a watershed accurately without relying on experiences or considering physical processes it has shown remarkable potential since it was introduced into hydrology field and is developing boomingly based on the assumption that the time series is linear or nearly linear data driven methods such as box jenkins autoregressive ar moving average ma autoregressive moving average arma and autoregressive integrated moving average arima have been proposed in recent decades tang et al 1991 li et al 2015 bayer et al 2017 al balasmeh et al 2019 they can learn linear features in the sequence and predict stationary linear time series very well whereas they are unable to learn nonlinear features and non stationary time series therefore the above algorithms are not suitable for accurate prediction of hydrological time series which do not meet stationary and linear conditions it is in this context that data driven models with nonlinear mapping ability are introduced into this field and have received extensive attention artificial neural networks ann adaptive neuro fuzzy inference systems anfis and support vector machines svm show strong learning ability in time series forecasting lin et al 2006 jabbari and bae 2018 zhou et al 2019 the nonlinear and nonparametric regression based models e g mars might be an alternative for difficult nonlinear situations yin et al 2018 unfortunately it is difficult for these models to learn the complex characteristics of hydrological systems and there is still great development potential and space for accurate forecasting recurrent neural network rnn is proposed to learn the dependencies between time series despite that rnn has a great advantage in processing time series tasks hrnjica and bonacci 2019 yang et al 2019 rnn has problems of gradient explosion and gradient disappearance after multiple time steps of backpropagation resulting in that rnn only has short term memory in order to solve this bottleneck two variants of rnn lstm and gated recurrent networks gru have been proposed by introducing input gate output gate and forget gate into the cell structure lstm is able to capture intrinsic connections and memorize information across all the time steps as a result lstm has the merit of fast convergence speed and is good at simulating complex systems and extracting nonlinear characteristics in addition gru simplifies the structure of lstm and reduces the number of parameters accordingly gru has higher training efficiency and lower possibility of overfitting compared with lstm both of them summarize all cell states across time steps overcoming the disadvantages of traditional rnn and learning the long term dependencies inspired by the theory of human attention attention mechanism is introduced in lstm to select the hidden states of relevant time steps in all time steps thus am lstm can make more accurate prediction of daily runoff than lstm there are a large number of successful examples that lstm and gru networks are applied to various aspects of hydrological forecasting such as rainfall groundwater level and flood hu et al 2018 bowes et al 2019 kao et al 2020 a deep sequential structure that the convolutional neural network is incorporated into gru was introduced to predict each recombined subseries which are obtained by decomposing the normalized runoff data chen et al 2020 bi et al divided the data into long term data and short term data and adopted caganet to learn complex long term and short term dependencies of hydrological time series bi et al 2020 compared with lstm and am lstm the prediction accuracy of caganet is effectively improved the cascade long short term memory c lstm model was proposed which can construct different feature mappings bai et al 2021 the first lstm level extracts the features between the precipitation and evaporation at present and learns several meteorological variables one day in advance next the second lstm level forecasts the daily runoff using the historical and simulated precipitation and evaporation data produced by the first lstm level cho et al designed a model by using lstm and a gru lstm gru to obtain better performance of water level prediction than multi lstm and multi gru cho et al 2022 unlike neural network model design many hybrid models are proposed to optimize the key parameters of existing models with the help of different optimization algorithms optimally pruned extreme learning machine op elm the hybrid least squares support vector machine and gravitational search algorithm lssvm gsa the hybrid long short term memory neural network and ant lion optimizer model lstm alo the hybrid extreme learning machine combined with hybrid particle swarm optimization and grey wolf optimization elm psogwo the hybrid adaptive neuro fuzzy inference system coupled with the new hybrid heuristic algorithm techniques anfis wcamfo the hybrid support vector regression with the simulated annealing algorithm and the mayfly optimization algorithm svr samoa the hybrid adaptive neuro fuzzy system with gradient based optimization anfis gbo algorithm have been proposed in pertinent works of literature of recent years miche et al 2010 yuan et al 2015 2018 adan et al 2021a 2021b 2022a 2022b in comparison with standalone machine learning models those hybrid models make full use of the advantages of data driven models and the superiority of the optimizers to achieve more satisfactory results and the combination scheme of models and optimization algorithms is a promising research approach the existing studies do not pay enough attention to the discrepancies of the long term and the short term data although researchers have improved lstm and gru networks and put forward various network structures these networks adopt the same structure to extract and learn long term and short term features without distinction ignoring the differences between them therefore these networks are not sufficient to extract highly nonlinear and complicated hydrological features and accurate and reliable daily runoff forecasting is still a challenging task for them to our knowledge few studies have used different network components to learn these two feature types in runoff forecasting it is worth mentioning that although bi et al divide the data into long term data and short term data they still use the same network structure the combined neural network structure with a convolutional layer an am and a gru to learn these two kinds of data bi et al 2020 in view of this situation we propose to use different network components to learn long term and short term relationships respectively among the existing research of studying daily runoff forecasting other methods failed to pay attention to data stability problems and bi et al observed that some predicted values were higher than the observed values on the data set this does not affect the prediction of high flow values but it does affect low flow values bi et al believed that this phenomenon was caused by the instability of the data so they proposed to use the linear interpolation li method to process the data bi et al 2020 through one or multiple interpolation processing the data could be relatively stable and the peak value and overall prediction accuracy could be improved in this way all data are interpolated indiscriminately and the data in flood season and non flood season are treated in a same way in flood season data change sharply and appropriate interpolation times rather than fixed times as the li method adopts are required to be selected elaborately whereas in non flood season data change gently which interpolation usually makes no sense consequently the li method has low efficiency and limited improvement therefore we propose a dynamic interpolation di method to improve accuracy and time efficiency pearson correlation coefficient analysis is used to determine the input time length of data and reduce the impact of subjective selection wang et al selected rainfall and discharge data in 11 h before forecasting as input wang et al 2021 based on the thermal map of the linear pearson correlation coefficients of historical data and the actual situation rainfall data in the past 3 days evaporation in the past 2 day as well as the flow in the past 2 day were selected as features by bi et al bi et al 2020 the selection of features will also affect the accuracy of the final prediction results therefore noise caused by the introduction of irrelevant features should be avoided in this paper we propose a deep learning framework designed for daily runoff forecasting according to the different characteristics of long term data and short term data different network components are proposed lstcnet leverages the strengths of the convolutional layer to extract the features and an attention mechanism am is introduced to select relative time across all time steps of long term data adaptively the multi layer residual structure is used to fuse multi level features in short term data which can effectively improve the performance of the model the traditional ar model is incorporated as the linear neural network part to enhance the learning of the linear dependencies between variables and modify the output predicted value in order to improve the prediction performance as well as time efficiency we propose a data processing method that can adapt to different scenarios the threshold value of dynamic interpolation di method is adaptively selected according to the specific situation of the dataset we evaluate our approach by using qingxi dataset with mars lstm am lstm and caganet the results demonstrate the advantages of our approach compared with 4 baselines in summary the following are our main contributions in this paper firstly we propose a novel and practical framework to improve the performance of daily runoff forecasting the proposed framework applies different architectures to learn the long term data and the short term ones secondly we present a deep learning model based on the proposed framwork namely lstcnet with the help of two different components that we elaborately designed lstcnet can achieve a competitive performance in extracting the long term and short term dependencies thirdly we propose a flexible data augmentation method di method in the training and testing process the prediction performance can be improved and the computing time can be reduced finally we carry out extensive experiments on five datasets in terms of daily runoff forecasting task experimental results demonstrate that our model achieves state of the art performance among five models 2 methods 2 1 our model the overall structure of our model is shown in the fig 1 including nonlinear and linear parts and the details of rc layer are manifested in fig 2 we take a set of long term time series historical data l i l 1 l 2 l n and a short term data s as input the nonlinear part uses different network components which are named as long term component and short term component to process l and s while the linear part adopts the traditional ar model to process s the long term component processes long term data the long term data are input into the convolutional layer to extract the characteristics of time distribution and the local dependencies between variables the recurrent component is a recurrent layer with the gru the gru layer automatically learns the importance of extracted features with the support of the attention mechanism and different weights are assigned according to the importance of features the detailed work of the process is described below let the input matrix be l where l r t d and the convolutional layer consists of k kernels with size ω 1 d the k th filter sweeps through the input matrix l which can be formulated as 1 h k 1 r e l u w k 1 l b k 1 where donates the convolutional operation w k 1 and b k 1 are the learnable parameters the activation function is r e l u x m a x 0 x krizhevsky et al 2017 the padding option is valid the output h k 1 would be a vector the output matrix vector h l of the convolutional layer is k t c and t c t ω 1 1 where t represents the time step introducing attention mechanism over the time dimension can help the model select relative time steps across all the time steps adaptively the attention layer is applied to act on the hidden state of the gru and the hidden state of recurrent units at time t can be formulated as 2 r t x t w xr h t 1 w hr b r 3 u t σ x t w xu h t 1 w hu b u 4 c t re l u x t w xc r t h t 1 w hc b c 5 h t 1 u t h t 1 u t c t where is the element wise multiplication σ is the sigmoid activation function r t and u t indicate the outputs of the reset and the update gates respectively x t is the input of this layer at time t the output of this layer is the hidden state at each time stamp we can regard h l as a sequence of k dimensional vectors with a length of t c which will be fed into two gru layers for n times each gru layer contains g cells and the output of the recurrent component are h t n where h t n r g the output o l of the whole process is the result of integrating each h t n where o l r n g the short term component processes short term data compared with long term data short term data is more relevant to the target using a convolutional layer can only extract low level features which is not suitable for the extraction of short term data features therefore we use the residual structure composed of convolutional layers namely rc layer to make full use of the multi level feature information multiple convolutional layers are used to extract high level features of short term data and the residual structure layer can fuse multi level feature information to increase the comprehensiveness of feature information the structure of rc layer is illustrated in fig 2 furthermore the appropriate number of residual structure layers is determined according to the specific scenarios for more accurate estimation rcs are more suitable for capturing the short term dependencies and learning the characteristics of short term data as shown in fig 2 a rc layer contains two relu functions and two convolutional layers each convolutional layer contains j kernels and the kernel size is ω 2 ω 2 in which the former ω 2 is the time dimension and the latter ω 2 is the variable dimension the input of rc layer that is s i will be fed into the convolutional layer after going through relu activation function to obtain a shallow feature matrix f s i and then f s i will be fed into next relu activation function as well as convolutional layer to obtain a deep feature matrix f d i finally the output of rc is obtained by integrating the input s i and matrix f d i through residual structure let the input matrix be s where s r t d input s into rcs that contain i rc layers which can be formulated as 6 s i 1 r e l u w s 2 r e l u w s 1 s i b s 1 b s 2 s i i 1 i where w s 1 and b s 1 are the learnable parameters of the former convolutional layer w s 2 and b s 2 are the learnable parameters of the latter convolutional layer s i is the input of rc layer and s i 1 is the output the padding option is same and the output s i 1 would be a vector where s i 1 r t d then we feed s i 1 the output of rcs into another convolutional layer after going through relu activation function at this step the convolutional layer consists of k kernels with size ω 2 ω 2 the k th filter sweeps through the input matrix s i 1 which can be formulated as 7 h k 2 r e l u w k 2 s i 1 b k 2 where w k 2 and b k 2 are the learnable parameters the padding option is same and the ouput of the convolutional layer is h s as shown in fig 1 h s is connected by a fully connected layer fcl to obtain o s where o s r g which is the prediction result of short term data the linear part processes short term data the nonlinear part consists of a large number of nonlinear layers which can effectively extract nonlinear relationships of hydrological sequences if only nonlinear part is introduced the model will ignore the linear relationships consequently we introduce ar model to enhance the ability of capturing the linear dependencies between variables making correction to the predicted value of the nonlinear part let the input matrix be s and the ar model is formulated as follow 8 y t ar p 1 q w p ar s t p b ar where y t ar is the output of ar model w p ar and b ar are the learnable parameters s t p is the input of this layer at time t q is the size of the input window representing the amount of past information required by the model the final prediction of the model the final prediction of the model comes from the sum of the outputs of the long term component short term component and ar component we use a fcl to combine the outputs of long term data and short term data in the nonlinear part the output of the fcl is computed as 9 y t nl w nl o l o s b nl where w nl and b nl are the learnable parameters of the fcl o l and o s are the outputs of long term and short term historical data prediction respectively y t nl is the nonlinear output of our model then the final prediction of our model is obtained by integrating the outputs of the nonlinear part and linear part 10 y t y t nl y t ar our model can be trained to predict y t by minimizing mean absolute error between the predicted values and observed values adam optimizer is used in the model training process and the objective function is 11 o y t y t 1 n n 1 n m 1 d y t m n y t m n where n is the number of training samples d is the dimension of target data we implemented our model in the tensorflow framework 2 2 dynamic interpolation given that the daily runoff sequence is abrupt and unstable bi et al use a linear interpolation li method to enhance the stability of hydrological data bi et al 2020 as is shown in fig 3 a the li method inserts the linear mean value of two adjacent data into the data although this method is able to improve the peak value and overall prediction accuracy to a certain extent it adopts the same treatment for data in flood season and non flood season without distinction which is inefficient in the actual daily runoff forecasting process the model can predict the smaller floods well whereas it is difficult for the model to predict the larger floods accurately the phenomenon is caused by characteristics of data during in flood season that is the values of flow will change frequently and sharply due to the influence of rainstorm therefore it is more effective to selectively process the peak values which can significantly improve the performance of the model at the same time the li method adopts fixed times of interpolation ignoring that the degree of data fluctuation in flood season and non flood season is significantly different as shown in fig 3 b we propose a dynamic interpolation di method to solve these problems in light of the requirements of accuracy and speed the threshold value of interpolation is determined adaptively from d 2 2 d 2 3 d 2 10 based on the difference d between the maximum and minimum flow then the data to be interpolated are screened out according to the threshold value and the whole dataset is traversed until the difference between any adjacent data is less than the threshold value 2 3 workflow and algorithm algorithm 1 our training algorithm input long term time series historical data l i l 1 l 2 l n short term time series historical data s output learned lstcnet model construct training instances 1 d 2 for all available time interval t 1 t t do 3 l l 1 t t l 1 t 1 l n t t l n t 1 4 s s t t s t 1 x t is the target at time t 5 input a training instance l s x t into d train the model 6 initialize all learnable parameters in our model 7 repeat 8 randomly select a batch of instances d b from d 9 find all learnable parameters by minimizing the objective 12 with d b 10 until stopping criteria is met algorithm 1 outlines the lstcnet training process we first construct the training instances from the original sequence data line 1 5 then lstcnet is trained via backpropagation and adam line 6 10 by combining fig 1 the principal procedures of the proposed model for daily runoff forecasting are summarized as follows collect and normalize the dataset divide the dataset into training 90 and testing 10 sets the training set is divided into long term data l i l 1 l 2 l n and short term data s adopt different components of nonlinear part to process l and s respectively input s into ar component to capture the linear dependencies between variables and calculate the linear prediction results accumulate all the prediction results of nonlinear and linear part to deduce the ultimate prediction results of the collected runoff series test the trained model by dividing the testing set and forecasting the target variable as in the previous step 3 6 2 4 evaluation metrics in this paper five commonly statistical metrics mae rmse nse cc and wi are adopted to quantitatively evaluate all the experimental models which can contribute scientifically to interpreting the improvements obtained by the proposed approach the nse measures the ability to predict variables different from the mean and presents the proportion of the initial variance accounted for by the model nash and sutcliffe 1970 the cc signifies the strength and direction of a linear relationship among observed and predicted values they are illustrated as follows 12 mae 1 n i 1 n y i y i 13 rmse 1 n i 1 n y i y i 2 14 nse 1 i 1 n y i y i 2 i 1 n y i y i 2 15 cc i 1 n y i y i y i y i i 1 n y i y i 2 i 1 n y i y i 2 16 wi 1 i 1 n y i y i 2 i 1 n y i y i y i y i 2 where y i and y i are observed and predicted runoff at time t respectively y i and y i are the mean of observed and predicted runoff respectively n is the total number of observations the nse values range from to 1 cc values range from 1 to 1 wi values range from 0 to 1 and mae as well as rmse equals to zero implying a perfect fit generally the model produces reliable results when the mae and rmse values are small and the nse wi and cc values are approximately 1 3 experimental results 3 1 study area and dataset the qingxi river a tributary of the zhou river is located in xuanhan county sichuan province china it originates in baima township flowing through guanshan and qingxi town from northeast to southwest and drains into the houhe river qingxi river is a stream with a total length of 46 km covers an area of 297 km2 and the river width is about 15 30 m the locations of a basic hydrological station and three rain gauge stations are depicted in fig 4 in this study the following variables are used and a daily step is selected rainfall evaporation and runoff to evaluate the performance of the proposed model the daily time series are collected from 1 january 1986 to 31 december 2005 the data come from the hydrology and water resources bureau of sichuan province information of stations the sequence length of data collected and the pearson correlation coefficients pccs which are obtained by calculating sequences between historical runoff data of qingxi station and rainfall as well as evaporation data at each station are listed in table 1 meanwhile a total of 20 years of data 1986 2005 are utilized for the model calibration the statistical information of training 1986 2003 and testing 2004 2005 data such as minimum value maximum value and mean value are presented in table 2 3 2 selection of input variables table 1 shows the linear correlation between the runoff data of qingxi station and the historical time series of other data for the daily runoff at time t the rainfall data at time t 1 are more linearly correlated with the daily runoff data than data at other historical time which can be observed from table 1 for the sake of accurate prediction we elaborately select six features which are shown in table 3 in combination with the actual situation as well as the proposal for simplifying the calculation 3 3 selection of parameters a critical problem in constructing the structure of lstcnet is the selection of the number of neurons and layers consequently a grid search is chosen to determine the optimal values the results are shown in table 4 by decreasing or increasing the value that is selected from 2 2 2 3 2 8 compared with other structures the performance of lstcnet model achieves best when the number is 16 for convolutional layers and gru neurons in order to learn the dependencies more effectively we select the values of parameters illustrated in table 5 to train the model the adaptable parameters of the neural network will be updated depending on a given loss function during an iteration step in addition the time step value of 6 and n 6 are recommended empirically for this study 3 4 prediction results in view of the differences between long term and short term data the lstcnet applies different components to extract and learn the different features the model is tested on five datasets the original dataset the first li dataset dataset gained after performing linear interpolation the first time the second li dataset dataset gained after performing linear interpolation the second time the di 32 dataset dataset gained after performing dynamic interpolation with threshold of d 2 5 and the di 64 dataset dataset gained after performing dynamic interpolation with threshold of d 2 6 results i the first three datasets we first present the comparison of 4 other models on the original dataset the first li dataset and the second li dataset as shown in table 6 7 and 8 table 6 7 and 8 list the evaluation results of all the models 5 on three test sets in all the metrics 5 respectively clearly the proposed model lstcnet achieves the best performance besides lstcnet outperforms the strong neural baseline caganet by 6 8 46 3 and 46 7 in mae on the original dataset the first li dataset and the second li dataset respectively meanwhile lstcnet outperforms caganet by 2 5 20 7 and 41 9 in rmse metric on three datasets the improvements demonstrate the effectiveness of the framework designed for differences between long term and short term data in addition the performance of mars on the three datasets is quite different compared with other models it is the worst on the original dataset while it performs well on the other two datasets therefore the generalization ability of this model is not strong enough after the data augmentation the prediction performance of lstcnet is significantly improved for visualizing the effectiveness of data augmentation the comparison results of the predicted and observed runoff with without performing linear interpolation once are shown in figs 5 and 6 black bars are the ground truth rainfall time series blue lines are the ground truth runoff data and red lines are the prediction what s more the figures located in right part of figs 5 and 6 imply that data pairs closest to the orange line indicate better prediction results for visualization analysis fig 5 presents the prediction results of the original dataset we can observe that the overall prediction of lstcnet performs well and the peak prediction performance is close to observed values in most points however it should be noted that part of the predicted values are higher than the observed values which is caused by the instability of the data and the prediction performance needs to be further improved the method of linear interpolation is utilized to make the data relatively stable the results of the first li dataset are displayed in fig 6 and the prediction performance is significantly improved after data augmentation the predicted values are closer to the observed values both in terms of peak results and overall results than the results of fig 5 furthermore the improvement of linear fit further indicates the feasibility and validity of the data augmentation results ii the last two datasets fig 7 is a detailed view of fig 5 and it displays that the prediction of the smaller floods is better than the larger floods which are emphasized by the ellipses in the figure on the basis of the li method we improve the li method which adopts an interpolation process on all data and apply the dynamic interpolation di method to focus on the peak values resulting in the improvement of accuracy as well as time efficiency these experiments are conducted in pycharm on a computer with a 2 9 ghz cpu and 16 gb ram according to the the difference d between the maximum and minimum runoff which is shown in table 2 d 2 4 d 2 5 d 2 6 d 2 7 are selected as thresholds and the relationship between different thresholds and interpolation quantity is listed in table 9 in comparison with the number of interpolated data of the first li dataset we select the di 32 and di 64 datasets to verify the performance of the di method with lstcnet and the results are revealed in table 10 in table 10 rmse of the di 32 dataset reached 3 61 which is 26 8 better than the first li dataset even though mae is worse than the first li dataset the number of interpolated data is reduced and the training time is saved sharply as for the di 64 dataset the evaluation metrics mae 0 84 rmse 2 97 nse 0 991 cc 0 997 and wi 0 998 are obtained which are 3 4 39 8 0 9 0 8 and 0 5 better than that of the first li dataset at the same time the percentage reductions in the number of interpolated data and training time are 20 2 and 8 6 respectively fig 8 and fig 9 manifest the prediction results of the di 32 dataset and the di 64 dataset respectively since the di method pays more attention to the larger values it can improve the overall accuracy and allocate computing resources more effectively to improve the performance of the peak prediction in practical application different thresholds can be selected for training according to actual requirements among the three datasets the di 32 dataset has the optimal training time and it is suitable for scenarios with strict training time requirements besides the di 64 dataset has the best performance in three metrics which is suitable for the scenarios with strict prediction accuracy according to formula 12 and formula 13 we can find out that mae corresponds to the l1 norm and rmse corresponds to the l2 norm the value of rmse is more relevant to larger differences between the observed and the predicted values than smaller ones in other words the metric rmse is sensitive to those predicted values that evidently deviated from the observed values accordingly the improvement of rmse is significantly reflected in the increase of the peak values prediction accuracy which can be observed by comparing figs 5 8 and 9 moreover in order to study the distribution of the absolute error the violin plot of the absolute errors is plotted in fig 10 the width of the violin plot represents the density of the distribution of data points and the blue lines above and below indicate the maximum and minimum values of data the absolute error of lstcnet on the di 64 dataset is characterized by a quasi normal distribution with a mean near 0 the ranges of the main errors are 86 45 51 7 and 25 12 for the original dataset the di 32 dataset and the di 64 dataset respectively the qualitative analysis results are supplemented by the quantitative evaluation results the results of various datasets reveal that lstcnet is beneficial for learning the sophisticated features of the target variable and its influencing factors and it exhibits a better capacity for daily runoff forecasting moreover the di method is more excellent and efficient than the li method which can adaptively enhance the data in different scenarios 3 5 ablation study to demonstrate the efficiency of our proposed framework a careful ablation study is conducted some ablation experiments are performed on the original dataset effect of the three components in the lstcnet model the nonlinear part contains two different components to process the long term and the short term data while the linear part utilizes ar component to extract linear features based on this architecture the ablation experiments remove the three components respectively specifically we remove each module at a time in our lstcnet framework and we present the results in table 11 several observations from these results are worth highlighting firstly the best result is obtained with the complete lstcnet framework secondly removing the long term and short term components caused big performance drops in the dataset thirdly removing the ar component from the full model caused the performance drops showing the indispensable role of the ar component in general in a word all the components of lstcnet together lead to the robust performance of our approach effect of the combination scheme we adopt the long term component to process the long term data and the short term component to process the short term data aiming to extract and learn the dependencies efficiently there are four combination schemes which can be trained to find out the best option and we name them as follows 1 long long the model applies the long term component to process the long term and the short term data 2 long short the model applies the long term component to process the long term data and the short term component to process the short term data 3 short long the model applies the short term component to process the long term data and the long term component to process the short term data 4 short short the model applies the short term component to process the long term and the short term data consequently we can calculate the mae rmse nse cc and wi of different schemes on the original dataset as shown in table 12 we can observe that the long short scheme performs best among all schemes and it is worth mentioning that the short long scheme has caused the most significant performance drops demonstrating the different roles of two components in extracting and learning long term and short term patterns in summary this ablation study clearly justifies the efficiency of our proposed model effect of the rcs in our proposed method rc layers are stacked upon each other to fuse multi level features which can improve the learning of short term data to verify the appropriate number of rcs we conduct experiments by adding the rc layer incrementally the experimental results are shown in table 13 when three rc layers are stacked together and applied into the network the mae rmse nse cc and wi reach to 2 90 11 92 0 855 0 947 0 961 which achieves the best performance compared with other structures the experimental results illustrate that the multi level information generated by the stacked rcs can promote accuracy 4 discussion the focus of this paper is to prove the effectiveness of the proposed framework on daily runoff forecasting therefore lstcnet is presented and five quantitative standard statistical measures including mae rmse nse cc and wi are adopted to evaluate model performance although the promising results of lstcnet in daily runoff forecasting are illustrated in this study there are still some limitations the main limitations of this study and possible recommendations on the basis of these limitations are discussed below firstly the main goal of this paper is to verify the framework that elaborately designs two different components for learning the long term and short term dependencies respectively for the sake of eliminating the improvement of the prediction effect brought by the decomposition methods and better verifying the effectiveness of lstcnet the effect of the decomposition method is not taken into consideration further research on the incorporation of decomposition techniques and this model is required to be done in future work secondly the hyper parameters are determined by grid search resulting in uncertainty in our optimal results it is obvious that parameter settings play a key role in improving the performance of the machine learning model thus in the future the hybrid model which combines the optimization algorithm and the current model is planned to be adopted to search globally optimal values thirdly this study is limited for the runoff of qingxi river basin further studies are suggested to cover other basins so that better forecasting performance of the framework can be evaluated finally accurate runoff forecasting is a challenging issue due to the nonlinearity and complexity of the hydrological time series in this study rainfall evaporation and runoff data are regarded as inputs for runoff prediction however there remains other meteorological parameters including air temperature wind speed sunshine duration and so on which have not been taken into consideration therefore this work can be extended in the future by accumulating and incorporating other input data to generate more accurate predictions 5 conclusion in this paper we propose a novel framework and a combined end to end deep network called lstcnet based on the framework for accurate daily runoff forecasting two network components correspond to two kinds of dependencies which is the long term dependencies and the short term ones in addition we propose an interpolation method namely dynamic interpolation method which focuses on the peak values and is used to enhance the relative stability of the data comparative experiments are performed among mars lstm am lstm caganet and lstcnet the experimental results demonstrate that our model achieves competitive performance compared with other models on daily runoff forecasting credit authorship contribution statement jinyu zhang conceptualization methodology software investigation formal analysis writing original draft hua yan conceptualization resources supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
2455,forecasting daily runoff is of great importance to the allocation of water resources and flood prevention many existing methods utilize identical networks to learn the long term dependencies and the short term ones in addition the importance of data augmentation in a deep network is ignored in order to attain more accurate and reliable runoff forecasts this paper proposes a novel framework that designs two different components in nonlinear part to learn the long term data and the short term ones respectively a long short term components neural network lstcnet is presented to verify the effectiveness of the framework meanwhile we introduce ar model to capture the linear dependencies furthermore considering that the daily runoff data are unstable and change frequently and sharply in flood season a linear interpolation method that focuses on the peak values is used to enhance the stability of hydrological data experimental results of lstcnet the multivariate adaptive regression spline mars the long short term memory neural networks lstm the attention mechanism based lstm model am lstm and the caganet model show that lstcnet achieves the best performance in accurate daily runoff prediction the lstcnet s numerical values of mean absolute error mae root mean square error rmse the nash sutcliffe effciency nse correlation coefficient cc and willmott s index wi can reach 0 32 1 50 0 997 0 999 and 0 999 respectively keywords combined neural network daily runoff forecasting data augmentation gru long short term framework residual structure data availability the authors do not have permission to share data 1 introduction accurate prediction of daily runoff is beneficial to allocate water resources efficiently and provide forceful guidance for flood prevention the runoff process has the characteristics of randomness chaos and fuzziness due to many factors such as meteorology conditions river basin surface mantle as well as human activities traditional process driven algorithms such as fuzzy analysis luchetta and manetti 2003 wavelet analysis sang et al 2016 and other traditional algorithms are used to decompose time series then describe the complex physical process of runoff formation by mathematical formulas based on principles of hydraulics and hydrology however traditional algorithms often need a great number of boundary conditions and measured information which may not always be available in addition the performance of the algorithms largely depends on the application experiences of researchers as a result accurate forecasting of daily runoff is still a challenging problem for conventional hydrological models the data driven approach may offer a promising alternative to the existing methods for the hydrological prediction of daily runoff machine learning is an end to end learning approach that can predict daily runoff of a watershed accurately without relying on experiences or considering physical processes it has shown remarkable potential since it was introduced into hydrology field and is developing boomingly based on the assumption that the time series is linear or nearly linear data driven methods such as box jenkins autoregressive ar moving average ma autoregressive moving average arma and autoregressive integrated moving average arima have been proposed in recent decades tang et al 1991 li et al 2015 bayer et al 2017 al balasmeh et al 2019 they can learn linear features in the sequence and predict stationary linear time series very well whereas they are unable to learn nonlinear features and non stationary time series therefore the above algorithms are not suitable for accurate prediction of hydrological time series which do not meet stationary and linear conditions it is in this context that data driven models with nonlinear mapping ability are introduced into this field and have received extensive attention artificial neural networks ann adaptive neuro fuzzy inference systems anfis and support vector machines svm show strong learning ability in time series forecasting lin et al 2006 jabbari and bae 2018 zhou et al 2019 the nonlinear and nonparametric regression based models e g mars might be an alternative for difficult nonlinear situations yin et al 2018 unfortunately it is difficult for these models to learn the complex characteristics of hydrological systems and there is still great development potential and space for accurate forecasting recurrent neural network rnn is proposed to learn the dependencies between time series despite that rnn has a great advantage in processing time series tasks hrnjica and bonacci 2019 yang et al 2019 rnn has problems of gradient explosion and gradient disappearance after multiple time steps of backpropagation resulting in that rnn only has short term memory in order to solve this bottleneck two variants of rnn lstm and gated recurrent networks gru have been proposed by introducing input gate output gate and forget gate into the cell structure lstm is able to capture intrinsic connections and memorize information across all the time steps as a result lstm has the merit of fast convergence speed and is good at simulating complex systems and extracting nonlinear characteristics in addition gru simplifies the structure of lstm and reduces the number of parameters accordingly gru has higher training efficiency and lower possibility of overfitting compared with lstm both of them summarize all cell states across time steps overcoming the disadvantages of traditional rnn and learning the long term dependencies inspired by the theory of human attention attention mechanism is introduced in lstm to select the hidden states of relevant time steps in all time steps thus am lstm can make more accurate prediction of daily runoff than lstm there are a large number of successful examples that lstm and gru networks are applied to various aspects of hydrological forecasting such as rainfall groundwater level and flood hu et al 2018 bowes et al 2019 kao et al 2020 a deep sequential structure that the convolutional neural network is incorporated into gru was introduced to predict each recombined subseries which are obtained by decomposing the normalized runoff data chen et al 2020 bi et al divided the data into long term data and short term data and adopted caganet to learn complex long term and short term dependencies of hydrological time series bi et al 2020 compared with lstm and am lstm the prediction accuracy of caganet is effectively improved the cascade long short term memory c lstm model was proposed which can construct different feature mappings bai et al 2021 the first lstm level extracts the features between the precipitation and evaporation at present and learns several meteorological variables one day in advance next the second lstm level forecasts the daily runoff using the historical and simulated precipitation and evaporation data produced by the first lstm level cho et al designed a model by using lstm and a gru lstm gru to obtain better performance of water level prediction than multi lstm and multi gru cho et al 2022 unlike neural network model design many hybrid models are proposed to optimize the key parameters of existing models with the help of different optimization algorithms optimally pruned extreme learning machine op elm the hybrid least squares support vector machine and gravitational search algorithm lssvm gsa the hybrid long short term memory neural network and ant lion optimizer model lstm alo the hybrid extreme learning machine combined with hybrid particle swarm optimization and grey wolf optimization elm psogwo the hybrid adaptive neuro fuzzy inference system coupled with the new hybrid heuristic algorithm techniques anfis wcamfo the hybrid support vector regression with the simulated annealing algorithm and the mayfly optimization algorithm svr samoa the hybrid adaptive neuro fuzzy system with gradient based optimization anfis gbo algorithm have been proposed in pertinent works of literature of recent years miche et al 2010 yuan et al 2015 2018 adan et al 2021a 2021b 2022a 2022b in comparison with standalone machine learning models those hybrid models make full use of the advantages of data driven models and the superiority of the optimizers to achieve more satisfactory results and the combination scheme of models and optimization algorithms is a promising research approach the existing studies do not pay enough attention to the discrepancies of the long term and the short term data although researchers have improved lstm and gru networks and put forward various network structures these networks adopt the same structure to extract and learn long term and short term features without distinction ignoring the differences between them therefore these networks are not sufficient to extract highly nonlinear and complicated hydrological features and accurate and reliable daily runoff forecasting is still a challenging task for them to our knowledge few studies have used different network components to learn these two feature types in runoff forecasting it is worth mentioning that although bi et al divide the data into long term data and short term data they still use the same network structure the combined neural network structure with a convolutional layer an am and a gru to learn these two kinds of data bi et al 2020 in view of this situation we propose to use different network components to learn long term and short term relationships respectively among the existing research of studying daily runoff forecasting other methods failed to pay attention to data stability problems and bi et al observed that some predicted values were higher than the observed values on the data set this does not affect the prediction of high flow values but it does affect low flow values bi et al believed that this phenomenon was caused by the instability of the data so they proposed to use the linear interpolation li method to process the data bi et al 2020 through one or multiple interpolation processing the data could be relatively stable and the peak value and overall prediction accuracy could be improved in this way all data are interpolated indiscriminately and the data in flood season and non flood season are treated in a same way in flood season data change sharply and appropriate interpolation times rather than fixed times as the li method adopts are required to be selected elaborately whereas in non flood season data change gently which interpolation usually makes no sense consequently the li method has low efficiency and limited improvement therefore we propose a dynamic interpolation di method to improve accuracy and time efficiency pearson correlation coefficient analysis is used to determine the input time length of data and reduce the impact of subjective selection wang et al selected rainfall and discharge data in 11 h before forecasting as input wang et al 2021 based on the thermal map of the linear pearson correlation coefficients of historical data and the actual situation rainfall data in the past 3 days evaporation in the past 2 day as well as the flow in the past 2 day were selected as features by bi et al bi et al 2020 the selection of features will also affect the accuracy of the final prediction results therefore noise caused by the introduction of irrelevant features should be avoided in this paper we propose a deep learning framework designed for daily runoff forecasting according to the different characteristics of long term data and short term data different network components are proposed lstcnet leverages the strengths of the convolutional layer to extract the features and an attention mechanism am is introduced to select relative time across all time steps of long term data adaptively the multi layer residual structure is used to fuse multi level features in short term data which can effectively improve the performance of the model the traditional ar model is incorporated as the linear neural network part to enhance the learning of the linear dependencies between variables and modify the output predicted value in order to improve the prediction performance as well as time efficiency we propose a data processing method that can adapt to different scenarios the threshold value of dynamic interpolation di method is adaptively selected according to the specific situation of the dataset we evaluate our approach by using qingxi dataset with mars lstm am lstm and caganet the results demonstrate the advantages of our approach compared with 4 baselines in summary the following are our main contributions in this paper firstly we propose a novel and practical framework to improve the performance of daily runoff forecasting the proposed framework applies different architectures to learn the long term data and the short term ones secondly we present a deep learning model based on the proposed framwork namely lstcnet with the help of two different components that we elaborately designed lstcnet can achieve a competitive performance in extracting the long term and short term dependencies thirdly we propose a flexible data augmentation method di method in the training and testing process the prediction performance can be improved and the computing time can be reduced finally we carry out extensive experiments on five datasets in terms of daily runoff forecasting task experimental results demonstrate that our model achieves state of the art performance among five models 2 methods 2 1 our model the overall structure of our model is shown in the fig 1 including nonlinear and linear parts and the details of rc layer are manifested in fig 2 we take a set of long term time series historical data l i l 1 l 2 l n and a short term data s as input the nonlinear part uses different network components which are named as long term component and short term component to process l and s while the linear part adopts the traditional ar model to process s the long term component processes long term data the long term data are input into the convolutional layer to extract the characteristics of time distribution and the local dependencies between variables the recurrent component is a recurrent layer with the gru the gru layer automatically learns the importance of extracted features with the support of the attention mechanism and different weights are assigned according to the importance of features the detailed work of the process is described below let the input matrix be l where l r t d and the convolutional layer consists of k kernels with size ω 1 d the k th filter sweeps through the input matrix l which can be formulated as 1 h k 1 r e l u w k 1 l b k 1 where donates the convolutional operation w k 1 and b k 1 are the learnable parameters the activation function is r e l u x m a x 0 x krizhevsky et al 2017 the padding option is valid the output h k 1 would be a vector the output matrix vector h l of the convolutional layer is k t c and t c t ω 1 1 where t represents the time step introducing attention mechanism over the time dimension can help the model select relative time steps across all the time steps adaptively the attention layer is applied to act on the hidden state of the gru and the hidden state of recurrent units at time t can be formulated as 2 r t x t w xr h t 1 w hr b r 3 u t σ x t w xu h t 1 w hu b u 4 c t re l u x t w xc r t h t 1 w hc b c 5 h t 1 u t h t 1 u t c t where is the element wise multiplication σ is the sigmoid activation function r t and u t indicate the outputs of the reset and the update gates respectively x t is the input of this layer at time t the output of this layer is the hidden state at each time stamp we can regard h l as a sequence of k dimensional vectors with a length of t c which will be fed into two gru layers for n times each gru layer contains g cells and the output of the recurrent component are h t n where h t n r g the output o l of the whole process is the result of integrating each h t n where o l r n g the short term component processes short term data compared with long term data short term data is more relevant to the target using a convolutional layer can only extract low level features which is not suitable for the extraction of short term data features therefore we use the residual structure composed of convolutional layers namely rc layer to make full use of the multi level feature information multiple convolutional layers are used to extract high level features of short term data and the residual structure layer can fuse multi level feature information to increase the comprehensiveness of feature information the structure of rc layer is illustrated in fig 2 furthermore the appropriate number of residual structure layers is determined according to the specific scenarios for more accurate estimation rcs are more suitable for capturing the short term dependencies and learning the characteristics of short term data as shown in fig 2 a rc layer contains two relu functions and two convolutional layers each convolutional layer contains j kernels and the kernel size is ω 2 ω 2 in which the former ω 2 is the time dimension and the latter ω 2 is the variable dimension the input of rc layer that is s i will be fed into the convolutional layer after going through relu activation function to obtain a shallow feature matrix f s i and then f s i will be fed into next relu activation function as well as convolutional layer to obtain a deep feature matrix f d i finally the output of rc is obtained by integrating the input s i and matrix f d i through residual structure let the input matrix be s where s r t d input s into rcs that contain i rc layers which can be formulated as 6 s i 1 r e l u w s 2 r e l u w s 1 s i b s 1 b s 2 s i i 1 i where w s 1 and b s 1 are the learnable parameters of the former convolutional layer w s 2 and b s 2 are the learnable parameters of the latter convolutional layer s i is the input of rc layer and s i 1 is the output the padding option is same and the output s i 1 would be a vector where s i 1 r t d then we feed s i 1 the output of rcs into another convolutional layer after going through relu activation function at this step the convolutional layer consists of k kernels with size ω 2 ω 2 the k th filter sweeps through the input matrix s i 1 which can be formulated as 7 h k 2 r e l u w k 2 s i 1 b k 2 where w k 2 and b k 2 are the learnable parameters the padding option is same and the ouput of the convolutional layer is h s as shown in fig 1 h s is connected by a fully connected layer fcl to obtain o s where o s r g which is the prediction result of short term data the linear part processes short term data the nonlinear part consists of a large number of nonlinear layers which can effectively extract nonlinear relationships of hydrological sequences if only nonlinear part is introduced the model will ignore the linear relationships consequently we introduce ar model to enhance the ability of capturing the linear dependencies between variables making correction to the predicted value of the nonlinear part let the input matrix be s and the ar model is formulated as follow 8 y t ar p 1 q w p ar s t p b ar where y t ar is the output of ar model w p ar and b ar are the learnable parameters s t p is the input of this layer at time t q is the size of the input window representing the amount of past information required by the model the final prediction of the model the final prediction of the model comes from the sum of the outputs of the long term component short term component and ar component we use a fcl to combine the outputs of long term data and short term data in the nonlinear part the output of the fcl is computed as 9 y t nl w nl o l o s b nl where w nl and b nl are the learnable parameters of the fcl o l and o s are the outputs of long term and short term historical data prediction respectively y t nl is the nonlinear output of our model then the final prediction of our model is obtained by integrating the outputs of the nonlinear part and linear part 10 y t y t nl y t ar our model can be trained to predict y t by minimizing mean absolute error between the predicted values and observed values adam optimizer is used in the model training process and the objective function is 11 o y t y t 1 n n 1 n m 1 d y t m n y t m n where n is the number of training samples d is the dimension of target data we implemented our model in the tensorflow framework 2 2 dynamic interpolation given that the daily runoff sequence is abrupt and unstable bi et al use a linear interpolation li method to enhance the stability of hydrological data bi et al 2020 as is shown in fig 3 a the li method inserts the linear mean value of two adjacent data into the data although this method is able to improve the peak value and overall prediction accuracy to a certain extent it adopts the same treatment for data in flood season and non flood season without distinction which is inefficient in the actual daily runoff forecasting process the model can predict the smaller floods well whereas it is difficult for the model to predict the larger floods accurately the phenomenon is caused by characteristics of data during in flood season that is the values of flow will change frequently and sharply due to the influence of rainstorm therefore it is more effective to selectively process the peak values which can significantly improve the performance of the model at the same time the li method adopts fixed times of interpolation ignoring that the degree of data fluctuation in flood season and non flood season is significantly different as shown in fig 3 b we propose a dynamic interpolation di method to solve these problems in light of the requirements of accuracy and speed the threshold value of interpolation is determined adaptively from d 2 2 d 2 3 d 2 10 based on the difference d between the maximum and minimum flow then the data to be interpolated are screened out according to the threshold value and the whole dataset is traversed until the difference between any adjacent data is less than the threshold value 2 3 workflow and algorithm algorithm 1 our training algorithm input long term time series historical data l i l 1 l 2 l n short term time series historical data s output learned lstcnet model construct training instances 1 d 2 for all available time interval t 1 t t do 3 l l 1 t t l 1 t 1 l n t t l n t 1 4 s s t t s t 1 x t is the target at time t 5 input a training instance l s x t into d train the model 6 initialize all learnable parameters in our model 7 repeat 8 randomly select a batch of instances d b from d 9 find all learnable parameters by minimizing the objective 12 with d b 10 until stopping criteria is met algorithm 1 outlines the lstcnet training process we first construct the training instances from the original sequence data line 1 5 then lstcnet is trained via backpropagation and adam line 6 10 by combining fig 1 the principal procedures of the proposed model for daily runoff forecasting are summarized as follows collect and normalize the dataset divide the dataset into training 90 and testing 10 sets the training set is divided into long term data l i l 1 l 2 l n and short term data s adopt different components of nonlinear part to process l and s respectively input s into ar component to capture the linear dependencies between variables and calculate the linear prediction results accumulate all the prediction results of nonlinear and linear part to deduce the ultimate prediction results of the collected runoff series test the trained model by dividing the testing set and forecasting the target variable as in the previous step 3 6 2 4 evaluation metrics in this paper five commonly statistical metrics mae rmse nse cc and wi are adopted to quantitatively evaluate all the experimental models which can contribute scientifically to interpreting the improvements obtained by the proposed approach the nse measures the ability to predict variables different from the mean and presents the proportion of the initial variance accounted for by the model nash and sutcliffe 1970 the cc signifies the strength and direction of a linear relationship among observed and predicted values they are illustrated as follows 12 mae 1 n i 1 n y i y i 13 rmse 1 n i 1 n y i y i 2 14 nse 1 i 1 n y i y i 2 i 1 n y i y i 2 15 cc i 1 n y i y i y i y i i 1 n y i y i 2 i 1 n y i y i 2 16 wi 1 i 1 n y i y i 2 i 1 n y i y i y i y i 2 where y i and y i are observed and predicted runoff at time t respectively y i and y i are the mean of observed and predicted runoff respectively n is the total number of observations the nse values range from to 1 cc values range from 1 to 1 wi values range from 0 to 1 and mae as well as rmse equals to zero implying a perfect fit generally the model produces reliable results when the mae and rmse values are small and the nse wi and cc values are approximately 1 3 experimental results 3 1 study area and dataset the qingxi river a tributary of the zhou river is located in xuanhan county sichuan province china it originates in baima township flowing through guanshan and qingxi town from northeast to southwest and drains into the houhe river qingxi river is a stream with a total length of 46 km covers an area of 297 km2 and the river width is about 15 30 m the locations of a basic hydrological station and three rain gauge stations are depicted in fig 4 in this study the following variables are used and a daily step is selected rainfall evaporation and runoff to evaluate the performance of the proposed model the daily time series are collected from 1 january 1986 to 31 december 2005 the data come from the hydrology and water resources bureau of sichuan province information of stations the sequence length of data collected and the pearson correlation coefficients pccs which are obtained by calculating sequences between historical runoff data of qingxi station and rainfall as well as evaporation data at each station are listed in table 1 meanwhile a total of 20 years of data 1986 2005 are utilized for the model calibration the statistical information of training 1986 2003 and testing 2004 2005 data such as minimum value maximum value and mean value are presented in table 2 3 2 selection of input variables table 1 shows the linear correlation between the runoff data of qingxi station and the historical time series of other data for the daily runoff at time t the rainfall data at time t 1 are more linearly correlated with the daily runoff data than data at other historical time which can be observed from table 1 for the sake of accurate prediction we elaborately select six features which are shown in table 3 in combination with the actual situation as well as the proposal for simplifying the calculation 3 3 selection of parameters a critical problem in constructing the structure of lstcnet is the selection of the number of neurons and layers consequently a grid search is chosen to determine the optimal values the results are shown in table 4 by decreasing or increasing the value that is selected from 2 2 2 3 2 8 compared with other structures the performance of lstcnet model achieves best when the number is 16 for convolutional layers and gru neurons in order to learn the dependencies more effectively we select the values of parameters illustrated in table 5 to train the model the adaptable parameters of the neural network will be updated depending on a given loss function during an iteration step in addition the time step value of 6 and n 6 are recommended empirically for this study 3 4 prediction results in view of the differences between long term and short term data the lstcnet applies different components to extract and learn the different features the model is tested on five datasets the original dataset the first li dataset dataset gained after performing linear interpolation the first time the second li dataset dataset gained after performing linear interpolation the second time the di 32 dataset dataset gained after performing dynamic interpolation with threshold of d 2 5 and the di 64 dataset dataset gained after performing dynamic interpolation with threshold of d 2 6 results i the first three datasets we first present the comparison of 4 other models on the original dataset the first li dataset and the second li dataset as shown in table 6 7 and 8 table 6 7 and 8 list the evaluation results of all the models 5 on three test sets in all the metrics 5 respectively clearly the proposed model lstcnet achieves the best performance besides lstcnet outperforms the strong neural baseline caganet by 6 8 46 3 and 46 7 in mae on the original dataset the first li dataset and the second li dataset respectively meanwhile lstcnet outperforms caganet by 2 5 20 7 and 41 9 in rmse metric on three datasets the improvements demonstrate the effectiveness of the framework designed for differences between long term and short term data in addition the performance of mars on the three datasets is quite different compared with other models it is the worst on the original dataset while it performs well on the other two datasets therefore the generalization ability of this model is not strong enough after the data augmentation the prediction performance of lstcnet is significantly improved for visualizing the effectiveness of data augmentation the comparison results of the predicted and observed runoff with without performing linear interpolation once are shown in figs 5 and 6 black bars are the ground truth rainfall time series blue lines are the ground truth runoff data and red lines are the prediction what s more the figures located in right part of figs 5 and 6 imply that data pairs closest to the orange line indicate better prediction results for visualization analysis fig 5 presents the prediction results of the original dataset we can observe that the overall prediction of lstcnet performs well and the peak prediction performance is close to observed values in most points however it should be noted that part of the predicted values are higher than the observed values which is caused by the instability of the data and the prediction performance needs to be further improved the method of linear interpolation is utilized to make the data relatively stable the results of the first li dataset are displayed in fig 6 and the prediction performance is significantly improved after data augmentation the predicted values are closer to the observed values both in terms of peak results and overall results than the results of fig 5 furthermore the improvement of linear fit further indicates the feasibility and validity of the data augmentation results ii the last two datasets fig 7 is a detailed view of fig 5 and it displays that the prediction of the smaller floods is better than the larger floods which are emphasized by the ellipses in the figure on the basis of the li method we improve the li method which adopts an interpolation process on all data and apply the dynamic interpolation di method to focus on the peak values resulting in the improvement of accuracy as well as time efficiency these experiments are conducted in pycharm on a computer with a 2 9 ghz cpu and 16 gb ram according to the the difference d between the maximum and minimum runoff which is shown in table 2 d 2 4 d 2 5 d 2 6 d 2 7 are selected as thresholds and the relationship between different thresholds and interpolation quantity is listed in table 9 in comparison with the number of interpolated data of the first li dataset we select the di 32 and di 64 datasets to verify the performance of the di method with lstcnet and the results are revealed in table 10 in table 10 rmse of the di 32 dataset reached 3 61 which is 26 8 better than the first li dataset even though mae is worse than the first li dataset the number of interpolated data is reduced and the training time is saved sharply as for the di 64 dataset the evaluation metrics mae 0 84 rmse 2 97 nse 0 991 cc 0 997 and wi 0 998 are obtained which are 3 4 39 8 0 9 0 8 and 0 5 better than that of the first li dataset at the same time the percentage reductions in the number of interpolated data and training time are 20 2 and 8 6 respectively fig 8 and fig 9 manifest the prediction results of the di 32 dataset and the di 64 dataset respectively since the di method pays more attention to the larger values it can improve the overall accuracy and allocate computing resources more effectively to improve the performance of the peak prediction in practical application different thresholds can be selected for training according to actual requirements among the three datasets the di 32 dataset has the optimal training time and it is suitable for scenarios with strict training time requirements besides the di 64 dataset has the best performance in three metrics which is suitable for the scenarios with strict prediction accuracy according to formula 12 and formula 13 we can find out that mae corresponds to the l1 norm and rmse corresponds to the l2 norm the value of rmse is more relevant to larger differences between the observed and the predicted values than smaller ones in other words the metric rmse is sensitive to those predicted values that evidently deviated from the observed values accordingly the improvement of rmse is significantly reflected in the increase of the peak values prediction accuracy which can be observed by comparing figs 5 8 and 9 moreover in order to study the distribution of the absolute error the violin plot of the absolute errors is plotted in fig 10 the width of the violin plot represents the density of the distribution of data points and the blue lines above and below indicate the maximum and minimum values of data the absolute error of lstcnet on the di 64 dataset is characterized by a quasi normal distribution with a mean near 0 the ranges of the main errors are 86 45 51 7 and 25 12 for the original dataset the di 32 dataset and the di 64 dataset respectively the qualitative analysis results are supplemented by the quantitative evaluation results the results of various datasets reveal that lstcnet is beneficial for learning the sophisticated features of the target variable and its influencing factors and it exhibits a better capacity for daily runoff forecasting moreover the di method is more excellent and efficient than the li method which can adaptively enhance the data in different scenarios 3 5 ablation study to demonstrate the efficiency of our proposed framework a careful ablation study is conducted some ablation experiments are performed on the original dataset effect of the three components in the lstcnet model the nonlinear part contains two different components to process the long term and the short term data while the linear part utilizes ar component to extract linear features based on this architecture the ablation experiments remove the three components respectively specifically we remove each module at a time in our lstcnet framework and we present the results in table 11 several observations from these results are worth highlighting firstly the best result is obtained with the complete lstcnet framework secondly removing the long term and short term components caused big performance drops in the dataset thirdly removing the ar component from the full model caused the performance drops showing the indispensable role of the ar component in general in a word all the components of lstcnet together lead to the robust performance of our approach effect of the combination scheme we adopt the long term component to process the long term data and the short term component to process the short term data aiming to extract and learn the dependencies efficiently there are four combination schemes which can be trained to find out the best option and we name them as follows 1 long long the model applies the long term component to process the long term and the short term data 2 long short the model applies the long term component to process the long term data and the short term component to process the short term data 3 short long the model applies the short term component to process the long term data and the long term component to process the short term data 4 short short the model applies the short term component to process the long term and the short term data consequently we can calculate the mae rmse nse cc and wi of different schemes on the original dataset as shown in table 12 we can observe that the long short scheme performs best among all schemes and it is worth mentioning that the short long scheme has caused the most significant performance drops demonstrating the different roles of two components in extracting and learning long term and short term patterns in summary this ablation study clearly justifies the efficiency of our proposed model effect of the rcs in our proposed method rc layers are stacked upon each other to fuse multi level features which can improve the learning of short term data to verify the appropriate number of rcs we conduct experiments by adding the rc layer incrementally the experimental results are shown in table 13 when three rc layers are stacked together and applied into the network the mae rmse nse cc and wi reach to 2 90 11 92 0 855 0 947 0 961 which achieves the best performance compared with other structures the experimental results illustrate that the multi level information generated by the stacked rcs can promote accuracy 4 discussion the focus of this paper is to prove the effectiveness of the proposed framework on daily runoff forecasting therefore lstcnet is presented and five quantitative standard statistical measures including mae rmse nse cc and wi are adopted to evaluate model performance although the promising results of lstcnet in daily runoff forecasting are illustrated in this study there are still some limitations the main limitations of this study and possible recommendations on the basis of these limitations are discussed below firstly the main goal of this paper is to verify the framework that elaborately designs two different components for learning the long term and short term dependencies respectively for the sake of eliminating the improvement of the prediction effect brought by the decomposition methods and better verifying the effectiveness of lstcnet the effect of the decomposition method is not taken into consideration further research on the incorporation of decomposition techniques and this model is required to be done in future work secondly the hyper parameters are determined by grid search resulting in uncertainty in our optimal results it is obvious that parameter settings play a key role in improving the performance of the machine learning model thus in the future the hybrid model which combines the optimization algorithm and the current model is planned to be adopted to search globally optimal values thirdly this study is limited for the runoff of qingxi river basin further studies are suggested to cover other basins so that better forecasting performance of the framework can be evaluated finally accurate runoff forecasting is a challenging issue due to the nonlinearity and complexity of the hydrological time series in this study rainfall evaporation and runoff data are regarded as inputs for runoff prediction however there remains other meteorological parameters including air temperature wind speed sunshine duration and so on which have not been taken into consideration therefore this work can be extended in the future by accumulating and incorporating other input data to generate more accurate predictions 5 conclusion in this paper we propose a novel framework and a combined end to end deep network called lstcnet based on the framework for accurate daily runoff forecasting two network components correspond to two kinds of dependencies which is the long term dependencies and the short term ones in addition we propose an interpolation method namely dynamic interpolation method which focuses on the peak values and is used to enhance the relative stability of the data comparative experiments are performed among mars lstm am lstm caganet and lstcnet the experimental results demonstrate that our model achieves competitive performance compared with other models on daily runoff forecasting credit authorship contribution statement jinyu zhang conceptualization methodology software investigation formal analysis writing original draft hua yan conceptualization resources supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
2456,with the recent phase of the coupled model intercomparison project cmip water professionals especially flood modelers are eager to examine how well climate models represent flood dynamics in the sixth phase of the cmip i e cmip6 in comparison to the previous phase i e cmip5 and how will climate change affect them in the future in this study the results obtained from cmip5 and cmip6 based on the canadian earth system models in calculating the amount of precipitation were compared and the effect of these two reports on the amount of runoff was investigated for this purpose two models of canesm2 and canesm5 were used the flood frequency analysis ffa results indicated that the average return periods rps calculated by the annual mean discharge amd for all distributions based on the canesm5 are higher than those calculated by canesm2 besides the average rps by apd for all distributions except log pearson3 calculated based on the canesm5 are higher than those calculated by the canesm2 for monthly mean discharge mmd the average mmd calculated by canesm5 is 2 higher than those for canesm2 the seasonality mean discharge smd for canesm2 in both summer i e 0 37 and spring i e 6 8 are larger than the canesm5 values the smd for canesm5 in both winter i e 7 48 and autumn i e 4 72 are larger than the canesm2 values for monthly peak discharge mpd and seasonality peak discharge spd the difference between the flow discharges in canesm2 and canesm5 is significantly different based on the month or season as well as the station the general comparison of the canesm2 and canesm5 indicates that the average mpd and average spd related to the canesm5 are 10 and 5 higher than those for canesm2 keywords climate change canesm2 and canesm5 cmip5 and cmip6 flood frequency analysis flood susceptibility water resource management data availability data will be made available on request 1 introduction the issue of climate change cc is one of the most pressing in the world today however adjusting to its long term effects is proving an extreme challenge due to its significant spatial variations e g reduction in the magnitude of temperature from high to low latitudes areas and decreases versus increases in precipitation from dry to wet areas and the broad range of its consequences e g both more frequent flood events and unexpected prolonged droughts wang et al 2013 giorgi 2019 soltani et al 2021a cc is known to have critical impacts on both regional and global hydrologic processes yuan et al 2021 the consequences of which are now being faced by human societies especially in communities more susceptible to natural hazards such as floods doulabian et al 2021 eingrüber and korres 2022 as a result of increased cc induced flood events flood forecasting has become an essential tool for reducing community vulnerability to flood risk and forms an integral part of the national strategy to live with floods and contribute to national sustainability mitigation measures based on climate projections require sustainable management of water resources and floods along with investment in long lasting infrastructures broderick et al 2019 subsequently developing a reliable climate scenario with high resolution is crucial to support resilient engineering planning and informed decision making by exploring all possible alterations to regional climatology and quantifying probable risks associated with cc to natural systems and human society wang et al 2014 wang et al 2019 when assessing and projecting impacts associated with cc it is crucial to use global climate models gcms however selecting an appropriate subset of gcms is the greatest challenge associated with this approach there is a multitude of uncertainties associated with gcm simulations such as initial assumptions calibration processes mathematical formulation and model resolution all of which inherently confine the use of these models to regional or local climate projections salman et al 2018 khan et al 2018 accordingly a subset of gcms may be recommended by excluding the less proficient models in replicating the observed climate to reduce projection uncertainty ahmed et al 2019 as a means of decreasing uncertainty in the projection of climate variables previous studies gleckler et al 2008 lutz et al 2016 salman et al 2018 suggest selecting gcms based on their ability to simulate those variables such as temperature and precipitation due to the absence of well established procedures for choosing proper gcms studies evaluating simulations of different climatic variables did not provide formal guidance on gcm selection the selected gcm is expected to be able to reproduce historical climate distribution including the spatial variability and mean ahmed et al 2020 climate models considering complicated biogeochemical systems are crucial for forecasting future cc ipcc 2013 the results of the sixth phase of the coupled model intercomparison project cmip6 was recently released by the intergovernmental panel on climate change ipcc with some notable differences from the fifth phase report i e cmip5 there is a crucial difference between cmip5 and cmip6 regarding the future scenario in cmip5 the projections are provided based on 2100 radiative forcing values for four greenhouse gas emissions pathways ipcc 2014 whereas cmip6 uses socio economic pathways ssp o neill et al 2014 such as urbanization population growth economics and other factors o neill et al 2016 eyring et al 2016 four representative concentration pathways rcps were used to generate the cmip5 model s future climate projections namely the rcp8 5 rcp6 0 rcp4 5 and rcp2 6 ipcc 2014 rcps are numerically classified according to the radiative forcing level rfl in 2100 i e rfl considered for rcp4 5 is 4 5 w m in the year 2100 the results of the cmip6 were provided through five ssps i e ssp1 ssp2 ssp3 ssp4 ssp5 with seven 2100 forcing levels i e 1 9 2 6 3 4 4 5 6 7 8 5 w m2 several studies have compared cmip6 gcms and cmip5 gcms in different regions casale et al 2021 evaluated the operation performance of lake como in italy under different hydrological conditions based on the cmip5 and cmip6 projections the authors found that the lake performance based on the cmip5 is better than the cmip6 yanxin et al 2022 utilized the hydroclimatic intensity index as well as cmip5 and cmip6 to assess china s hydroclimatic intensity change and its future trend due to the results of this study a changing pattern such as higher highs and lower lows was discovered in china this is expected to rise over the vast majority of the country furthermore the studies revealed that places with moderate hydroclimatic intensity would experience a significant rise try et al 2022 evaluated the mekong river basin flooding as a result of climate change the results of their studies indicated less error and a higher correlation of the cmip6 compared to the cmip5 besides the cmip6 s climate change model also projected significant increases in flooding in the future guo et al 2022 compared the performance of the cmip5 and cmip6 in the hydrological regime simulation of the yellow river basin china the emblematic annual mean temperature eamt was evaluated for two future periods p1 2026 2055 and p2 2066 2095 for p1 and p2 the minimum and maximum of the eamt related to the cmip6 are lower and higher respectively than those for cmip5 furthermore the precipitation enhancement in both p1 and p2 periods related to the cmip6 are higher than those for cmip5 due to the fact that flood hazard fh is a spatio temporal phenomenon and depends on factors such as soil land use topography hydrology and climate gcms cannot provide adaptive management strategies that are universally applicable considering the probable effects of climate change a comprehensive approach to fh evaluation is necessary to guarantee effective measures in fh reduction ullah et al 2019 globally extreme flood events are becoming increasingly common ivanov et al 2021 due to the fact that numerous various factors influence the frequency of extreme flood events at once it is challenging to ascertain their relative significance and any possible interactions bonakdari et al 2020 mallakpour and villarini 2015 in any case it is clear that the worldwide hydroclimate is becoming increasingly intense fischer and knutti 2016 and flooding changes coincide with variations in precipitation extremes sanderson et al 2019 as a result soltani et al 2021b developed a new approach by combining machine learning ml and remote sensing rs techniques to predict watershed runoff in this study the authors introduced a new scheme of the group method of data handling gmdh known as the generalized structure of gmdh gsgmdh using the gsgmdh a simple but accurate model was developed to perform the normalized difference vegetation index ndvi calculation for the rs the authors used modis data along with javascript based coding to process the collected data in the google earth engine gee finally the gsgmdh was applied to provide a runoff forecasting model in nine stations in the quebec basin stations using precipitation and ndvi as inputs the detailed comparison of the developed model against historical data indicated that it not only could estimate runoff with a high level of accuracy but also it could be able to predict the extreme values of the runoff it is still uncertain how effectively the latest cmip6 models will mimic quebec s climate response to flooding according to the canadian disaster database https cdd publicsafety gc ca the estimated total cost of floods in the province of quebec was more than 236 million cad from 2010 to 2017 comparing cmip5 and cmip6 models is essential for quebec as policymakers are currently managing the high vulnerability of the province to flooding by evaluating climate change impacts using the cmip5 any significant advancement within the cmip6 projections compared to cmip5 models could lead to a modification of the plausible effect and an adjustment of the management approach shashikanth et al 2014 in any case the flood susceptibility with different return periods has not been analyzed in the current study area so far as a result a comprehensive evaluation of flood prediction in quebec comparing both the cmip5 and cmip6 models based on the canadian earth systems models is of significant interest in the current study canadian earth system model versions 5 and 6 i e canesm2 and canesm5 are used to calculate future precipitation and its impact on runoff in these two cimp reports hence different scenarios of these two models i e canesm2 and canesm5 are examined with historical measurements to obtain the best scenario for precipitation calculation using the obtained precipitation and recently developed model for runoff calculating the effect of these two reports on the amount of runoff and their differences are examined in terms of the flood frequency analysis interannual average monthly flow interannual average seasonality flow interannual monthly peak flow and interannual seasonality peak flow 2 materials and methods 2 1 study area the study area is located between latitudes 46 04 n 46 59 n and longitude 72 23 w 72 30 w fig 1 the western part of the study area includes parts of the administrative regions of center du québec and mauritius while the northern reach includes parts of the capitale nationale the eastern southern and central parts are also located in the administrative region of chaudière appalaches the study area s maximum height is 688 m above mean sea level with an average height of 192 m and average annual precipitation of 1141 mm http climate weather gc ca the location of the study area hydrometric and climate stations as well as distribution of the historical precipitations are given in fig 1 see soltani et al 2021b for more information 2 2 coupled model intercomparison project in this study two models of canesm2 and canesm5 were used to calculate the amount of precipitation and the results of their best scenario were used to calculate the amount of runoff in the future the second generation of the canadian earth system model canesm2 that was prepared for the coupled model intercomparison project phase 5 cmip5 is one of the models included in the fifth assessment report ar5 of the ipcc javaherian et al 2021 which was published in september 2013 ipcc 2013 araji et al 2018 canadian earth system model version 5 canesm5 is the sixth phase of coupled model intercomparison project published in august 2021 it is the new structure of cmip coupled model intercomparison project phase 6 cmip6 in ar6 five shared socioeconomic pathways ssps scenarios are considered i e ssp1 ssp2 ssp3 ssp4 and ssp5 which show sustainability middle of the road regional rivalry inequality and fossil fuel development respectively describe the possible future worlds and represent different combinations of mitigation and adaptation challenges huang et al 2019 ssp1 2 6 ssp2 4 5 ssp4 6 0 and ssp5 8 5 are updated versions of the representative concentration pathways rcps scenarios in cmip5 and ssp1 1 9 ssp4 3 4 and ssp3 7 0 are new scenarios of ar6 ssp1 1 9 focuses on limiting the warming level to below 1 5 c which corresponds to the goal of the paris agreement ssp4 3 4 represents an intermediate mitigation effort pathway that falls between rcp2 6 and rcp4 5 ssp3 7 0 represents the medium to high end of future emissions and warming wang et al 2021 su et al 2021 liu et al 2022 arunrat et al 2022 canesm5 have 5 scenarios from 7 scenarios in ar6 i e ssp1 1 9 ssp1 2 6 ssp2 4 5 ssp3 0 70 and ssp5 8 5 in the current study a single member for each model typically the first member r1i1p1f1 for cmip6 and r1i1p1 for cmip5 which is used by most of the newly published studies lin and chen 2020 tian and dong 2020 mudryk et al 2020 zhang and chen 2021 de medeiros et al 2022 is used for fair comparisons of the cmip5 and cmip6 climate models based on the canadian earth system models i e canesm2 and canesm5 in this study similar to the article presented by soltani et al 2021b the canesm5 from the sixth ipcc report was used to obtain future precipitation and the results were compared with the canesm2 from the fifth ipcc report the change factor cf a common approach to estimate future climate parameters tirpak et al 2021 mansouri et al 2022 is used in this research and is calculated as shown below soltani et al 2021b 1 p p p obs p fut p hist where p p p obs p fut and p hist are the predicted observed future and historical precipitation respectively 2 3 runoff estimation in the current study a new machine learning ml technique along with the remote sensing methodology developed by soltani et al 2021b are employed to calculate the runoff the ml model was developed based on a new scheme of the group method of data handling gmdh a well known flood forecasting technique moosavi et al 2017 walton et al 2019 dodangeh et al 2020 elkurdy et al 2021 the generalized structure of the gmdh gsgmdh soltani et al 2021b model was developed with precipitation and the normalized difference vegetation index was introduced as input variables for runoff forecasting using the collected precipitation data from the fifth and sixth phases of the cmip in terms of canesm2 and canesm5 respectively in spatial and temporal variability the runoff is estimated in the future years 2 4 flood frequency analysis for flood recurrence and flood frequency analysis ffa estimation four well known probability distributions are used farooq et al 2018 swetapadma and ojha 2020 malik and pal 2021 namely weibull wb lognormal ln log pearson3 lp3 and gumbel max gm the wb ln and gm distributions use two parameters while the lp3 uses three parameters table 1 a detailed description of the probability distributions can be found in mccuen 2016 the probability density functions pdf for each of the wb ln lp3 and gm distributions are provided in equations 2 5 respectively 2 f x α β x β α 1 exp x β α 3 f x exp 1 2 ln x γ μ σ 2 π 2 x γ σ 4 f x 1 x β γ α ln x γ β α 1 exp ln x γ β 5 f x 1 σ x μ σ exp x μ σ the main advantages of the weibull distribution are as abernethy 2004 i it is capable of providing accurate failure analysis and failure forecasting in extremely small samples because of this it is feasible to conduct cost effective studies with small samples ii it provides a simple and meaningful representation of failure data and iii it has the most diverse distribution shapes making it the most popular however its maximum likelihood estimators fail to perform correctly for all parameter values weibull distributions have increasing hazard functions from zero to infinity when the shape parameter is greater than one but this function may not be suitable in some circumstances bain 1978 because the values in the lognormal are positive it is a rightward skewed distribution so that for a constant location or shape parameter the degree of skewness has a direct relationship with the shape or location parameter a very long tail is one of the key characteristics of this distribution sayama and ishii 2013 since the water resources council 1967 1982 of the united states recommended using the log pearson type 3 distribution as the basis for hydrologic frequency analyses it has been the most frequently used distribution compared to two parameter distributions such as gambel max weibull and lognormal three parameter distributions such as log pearson3 have lower biases as well as larger standard error cunnane 2010 2 5 goodness of fit in order to fit the flow samples a number of goodness of fit criteria are employed to seek an optimum distribution these criteria include the kolmogorov smirnov test kst the anderson darling test adt and the chi squared test cst in the kst the empirical cumulative distribution function cdf determines if a sample is part of a continuous hypothesized distribution in hydrological applications highly asymmetric distributions are often encountered and the adt has demonstrated a strong ability to be able to handle this type of data baldassarre et al 2009 adt provides a general measure of the fit between the observed and expected cdfs the weight assigned to the tails in adt is more than kst taking into account the most significant vertical difference between the empirical and theoretical cdf the kst statistic is defined the adt d and kst a2 statistics are defined as equations 6 and 7 respectively 6 d max 1 i n f x i i 1 n i n f x i 7 a 2 n 1 n i 1 n 2 i 1 ln f x i ln 1 f x n i 1 where n is the number of elements in the sample and f is the hypothesized distribution the chi squared test cst available for continuous samples is utilized to determine the event that a sample originates from a population that has a particular distribution such as wb ln lp3 gm as the cst is applied to binned data the statistic of this test is highly dependent on the number of bins and how the data is binned the cst statistic is defined as follows 8 χ 2 i 1 k o i e i 2 e i where ei and oi denote the expected and observed frequency respectively for the ith bin and k is the number of bins the expected frequency is determined as follows 9 e i f x 1 f x 2 where the limits of the ith bin are defined as x1 and x2 and the f is the cdf of the desired probability distribution the empirical formula applied in the current study to determine the number of bins is based on the samples size and is defined as follows 10 k 1 log 2 n where k is the number of bins and n is the number of samples the relative difference rd index is applied to compare the different variables defined in the current study based on the canesm2 and canesm5 the rd is defined as follows 11 rd x c a n e s m 2 x c a n e s m 5 x c a n e s m 2 100 where x c a n e s m 2 and x c a n e s m 5 are the values of the desired parameters calculated using canesm2 and canesm5 respectively 3 results this section provides the results of the comprehensive comparison of the canesm2 and canesm5 for the study area i e quebec canada the canesm2 and canesm5 models are compared using flood frequency analysis in terms of the annual mean and peak discharge the interannual average monthly and seasonal discharge as well as interannual monthly and seasonal peak discharges 3 1 ffa results as discussed in section 2 3 four different probability distributions were considered for the ffa including wb ln lp3 and gm to evaluate the performance of each distribution three tests i e kst adt and cst defined in section 2 4 were employed as an example the pdf of station 02pd010 for both the canesm2 and canesm5 models is provided in fig 2 according to this figure the pdf of all distributions strongly fit the observed data so that they can be used for flood recurrence estimation due to the ability of these probability distributions to fit the observed data ffas were performed using both the annual mean and peak discharge the goodness of fit results related to all probability distributions for both the canesm2 and canesm5 models for flood recurrence calculation tables a1 to a4 as well as the corresponding parameters of each probability distribution table a5 are provided in the appendix 3 1 1 ffa based on the annual mean discharge amd this section compares the canesm2 and canesm5 models for calculating the return periods using four probability distributions based on the annual mean discharge the applied probability distributions include wb fig 3 ln fig 4 lp3 figures 5 and a2 and gm figures 6 and a3 besides the goodness of fit evaluation for all probability distributions using the canesm2 and canesm5 models and the amd are provided in tables a1 and a2 respectively based on the provided results in this table it can be seen that gm ln and wb have successfully passed 96 3 of tests i e ks ad and cst for all nine stations while this percentage for lp3 is 92 59 finally it could be concluded that gm ln and wb performances in ffa based on amd are similar while the lp3 s performance is lower than the others fig 3 compares the canesm2 and canesm5 models in calculating return periods using the wb distribution based on the amd for different rps one to 100 years the minimum and maximum computed rps are observed at stations 02pj034 and 02 pb019 respectively the maximum rd for the stations with the lowest and highest amd are less than 5 5 and 3 5 respectively figure a1 according to the presented results in fig 3 for all rps calculated using the wb distribution amds calculated based on the canesm5 model are greater at all stations than those for canesm2 the rp was found to be directly related to rd except at station 02 pb019 so that at a given station the higher the rp value the higher the rd between canesm2 and canesm5 indeed the highest and lowest rds were observed at 100 year and 5 year rps respectively for station 02 pb019 the rd is in the range of 2 49 3 26 the maximum rds are observed at station 02pd010 located in the north of the case study the range of rd for this station is 39 94 81 25 with the minimum rd for this station being greater than the maximum rd of all other stations i e 19 38 the range of rd of the rps calculated using wb distribution in canesm2 and canesm5 for all stations is 0 38 81 25 while the average value of rd is 11 given that the range of rd values is significantly different from the average values of each station the use of the average value in this case cannot be evaluated as an acceptable comparative index the maximum rd is 81 25 related to the rp 100 at station 02pd010 while the minimum rd is 0 38 related to the rp 5 at station 02ph014 as shown on the map the station 02pd010 is located upstream of quebec city the rd between the canesm2 and canesm5 for rps of 5 10 20 50 and 100 are 39 94 52 62 35 73 84 and 81 25 respectively due to the significant difference in rps at this station located upstream of quebec city based on the canesm2 and canesm5 the importance of re examining the proposed canesm2 based designs is clearly observed station 02pc017 is ranked second after 02pd010 based on the maximum rd in both stations the rd has a direct relation with rp so as the value of rp increases the rd also increases and vice versa fig 4 compares the canesm2 and canesm5 models for calculating rps using the ln distribution based on the amd according to the regional maps presented in the figure the rps calculated using ln distribution and the canesm5 model are higher at all stations except station 02pd010 compared to when the canesm2 model is considered for the wb distribution it was observed that the highest rd is corresponded to station 02pd010 while when the ln distribution was used the maximum rd for this station occurred for the 100 year rp and was less than 4 for ln probability distribution the rd is in the range of 3 86 13 68 yielding an average rd of 3 42 the rd between the canesm2 and canesm5 at station 02pj030 which has the higher rd and is the farthest from quebec city for rps of 5 10 20 50 and 100 are 4 75 7 56 9 82 12 21 and 13 68 respectively according to the results obtained from these maps it can be concluded that the rd related to rps calculated by ln is much less than when the wb distribution is considered it should be noted that at all stations except 02pd010 the rps obtained for canesm5 are larger than for canesm2 which is the only difference between the rps obtained based on the ln and wb the maximum rd at all rps is related to station 02pj030 except for rp of 5 which is related to station 02pc017 the rd in stations 02pb019 02ph011 and 02pk009 for all rps is less than 1 indeed the studies conducted for these stations using ln probability distribution based on the canesm2 are not significantly different from canesm5 in these stations there is no direct or indirect relationship between the rd and rps for example the rps of 100 5 50 10 and 20 are ranked from one to five in terms of the highest rd at station 02pb019 the remarkable thing about station 02pc017 located in the west of quebec city is that the rd value is almost constant in all rps so the rp provided by canesm5 is approximately 6 higher than the rps provided by canesm2 the rd between the rp values calculated using ln probability distributions derived from canesm2 and canesm5 for stations 02pd010 02pj034 02pj030 02pl005 and 02ph014 has a direct relationship with the value of rp when rp increases the rd between rp values calculated using the ln probability distribution derived from canesm2 and canesm5 also increases a comparison between the canesm2 and canesm5 models for calculating the rps using the lp3 distribution based on the amd was performed similar to the wb distribution a significant increase in canesm5 related rps was observed in the central study area compared to when canesm2 was used for rp evaluation at rps of 10 to 100 years the highest rd fig 5 is related to station 02pj030 located at the southwest of the study area figure a2 while for a rp of 5 years the maximum rd is related to station 02pc017 the absolute difference between the value of this index at rp 5 in these two stations is 1 11 for the rps of 5 10 20 50 and 100 the maximum rd is 5 39 6 8 8 84 10 99 and 12 32 respectively at all stations except station 02pc017 with increasing rp the rd value also increases so that the lowest value of this index is observed at a 5 year rp and the highest is related to the 100 year rp the rd for this distribution is in the range of 0 03 12 32 while the average rd is less than 3 for station 02pc017 the maximum rd is observed at rp 5 rd 5 39 while the lowest value of this index is observed at rp 100 rd 4 32 in stations 02pd010 and 02ph011 the calculated rp using lp3 based on the canesm5 is lower than those for canesm2 figure a2 for stations 02pc017 02 pb019 02pj030 02pl005 and 02ph014 the calculated rp using lp3 based on the canesm2 is lower than those for canesm5 the difference between the rd of station 02pj030 which has the highest rd at rps of 10 to 100 for rp 5 to 100 is about 2 so that the rd of rp 5 is 4 23 and for rps of 10 20 50 and 100 are 6 8 8 84 10 99 and 12 32 respectively for station 02pl005 which is ranked second with the highest rd after station 02pj030 the rd of rps of 5 10 20 50 and 100 are 1 75 3 18 4 47 6 and 7 respectively due to the differences in the values of rps provided by lp3 probability distribution using canesm2 and canesm5 models especially in stations 02pj030 and 02pl005 there is a need to review the provided plans based on rps obtained using lp3 and canesm5 fig 6 indicates the rd of the rp calculated based on gm for the canesm2 model compared to the canesm5 model besides the corresponding maps of the different rps calculated by gm based on the canesm2 and canesm5 are provided in the appendix figure a3 for all stations except 02pd010 and 02ph011 the calculated discharge flow with the specific rps based on canesm5 is higher than those based on canesm2 due to fig 6 for all stations except 02pc017 and 02 pb019 the rd has a direct relation with rp so that as the value of rp increases the rd also increases and vice versa for stations 02pc017 and 02 pb019 it is entirely opposite to other stations so that the value of rp increases the rd also decreases and vice versa for all stations except 02pd010 and 02ph011 the discharge calculated based on different rps related to canesm5 is higher than canesm2 the maximum rd for these stations at rps of 5 10 20 50 and 100 are 5 28 6 04 7 88 9 92 and 11 24 respectively so that the first one is related to station 02pc017 while the others are related to station 02pj030 for stations 02pd010 and 02ph011 rds are less than 1 5 and 3 respectively which are related to the rp of 100 the average rd for all stations and rps is about 2 5 according to the obtained results from figures 5 and a3 it can be concluded that in most stations the difference between the rps calculated using gm probability distribution and the annual mean discharge based on canesm2 and canesm5 models are not significantly different from each other fig 7 shows the distribution of the amds calculated using all probability distributions with the canesm2 and canesm5 models as well as their rds the range of rd between the estimated amd values using wb ln lp3 and gm distributions are 81 25 0 38 13 68 3 86 13 32 5 68 and 11 24 2 88 respectively the average absolute difference between the estimated apds using wb ln lp3 and gm distributions are 11 13 3 42 2 94 and 2 47 respectively a comparison of the canesm2 and canesm5 models in terms of rps generated from four different probability distributions based on the amd figs 3 to 6 indicates that more than 75 of calculated rps related to the canesm5 model are higher than those for the canesm2 model for rps computed using the canesm2 model which are higher than those of the canesm5 model the rds are in the range of 0 01 5 68 with an average of 1 49 for rps computed using the canesm5 model which are higher than those of the canesm2 model the rds are in the range of 0 03 81 25 with an average of 6 02 the amd distribution calculated by all probability distributions for canesm5 is generally larger than canesm2 3 1 2 ffa based on the annual peak discharge apd the goodness of fit evaluation for all probability distributions using the canesm2 and canesm5 model and the apd are provided in tables a3 and a4 respectively besides the probability distribution parameters fitted for the canesm2 and canesm5 models are provided in table a5 due to the results of tables a3 and a4 lp3 has successfully passed 100 of all tests while this percentage for gm ln and wb are 98 15 94 44 and 90 74 respectively therefore the lp3 is ranked first for the ffa based on the apd and gm ln and wb are ranked second to fourth respectively comparison of the all probability distribution for both amd and apd tables a1 to a4 is also indicated that the gm lp3 ln and wb are ranked first to fourth respectively in ffa so that gm lp3 ln and wb have successfully passed 97 22 96 30 95 37 and 93 52 respectively fig 8 shows the study area map for the 5 10 20 50 and 100 years of rps that were calculated based on the apd using the wb probability distribution a qualitative comparison of the canesm2 and canesm5 models for the 5 year rp indicates that the computed discharge distribution from both models is almost the same the maximum 5 year rp for the canesm2 and canesm5 models are 112 58 and 112 35 m3 s respectively while the minimum 5 year rp for the canesm2 and canesm5 models are 6 28 and 6 32 m3 s respectively indeed not only is there no significant difference between the minimum and maximum values when calculated using the canesm2 and canesm5 models but also the minimum and maximum values in both cases occur at the same stations analysis of the 5 year rp indicated that the average discharge of all stations when using the canesm2 model is 31 97 m3 s while it is 30 75 m3 s for the canesm5 model although the distribution of 5 year rp is almost the same for the two models it is expected that some stations may exhibit significant variations due to the observed difference between the average values from the two models comparing the 5 year rp for the canesm5 model and the canesm2 model shows that the relative increase or decrease of rps are in the range 32 13 38 48 for all stations for the absolute changes the difference of the 5 year rp computed using the canesm5 model compared to the canesm2 model is in the range of 0 21 38 48 similar to the 5 year rp the minimum and maximum 10 20 50 and 100 year rp values computed using both the canesm2 and canesm5 models are located at stations 02pj034 and 02 pb019 respectively as the rp value increases the absolute value of relative error increases at all stations except at station 02p005 where the range of the relative error was found to be 0 6 1 31 figure a4 this indicates that the rps calculated by both the canesm2 and canesm5 models are very close together due to fig 8 the maximum rd between the rps calculated based on the canesm2 and canesm5 models at station 02 pb019 is less than 3 which is insignificant the maximum rd between the calculated rps was found at station 02pc017 where the 100 year rps were 28 6 m3 s and 37 8 m3 s based on the canesm2 and canesm5 models respectively it is interesting to note that the highest rd value of each rp is associated with the station where the apd value is closest to the average the different contour maps from the 5 10 20 50 and 100 year rps using the apd and ln distribution were generated figure a5 the minimum average and maximum rps for the canesm2 model were 7 43 46 and 155 27 m3 s respectively while the minimum average and maximum rps for the canesm5 model were 7 11 42 149 8 m3 s respectively indeed the rd between minimum average and maximum rps of the canesm2 and canesm5 models is 1 52 3 35 and 3 54 respectively due to fig 9 the rps calculated using the canesm2 model for all stations are higher than those calculated with the canesm5 model except at stations 02pc017 and 02pj034 besides the rps calculated for station 02pk009 using canesm2 and canesm5 are very close together so that the rds are less than 1 for the rps of 5 10 and 20 canesm2 provided higher values than canesm5 while for rps of 50 and 100 canesm5 presented higher values than canesm2 as can be seen in this figure the rd has a direct relationship with the rp so for all stations except 02pl005 and 02pk009 the lowest and highest rd were observed at rps of 5 and 100 respectively for station 02pd010 with the average apd of about 17 m3 s the maximum difference between the calculated apd based on the ln distributions using canesm2 and canesm5 for different rps is less than 3 5 for rp of 100 the rd of the other stations with higher and lower average apd is entirely different for example the average apd for station 02pk009 is about 19 m3 s which is very similar to the previous one while the difference between the rps calculated based on the canesm2 and canesm5 is negligible another example is station 02ph011 whose maximum apd for both canesm2 and canesm5 is lower than those for station 02pd010 for this station the rd between the rps calculated using the canesm2 and canesm5 is in the range of 6 38 11 32 so the lowest and highest rd are related to the rps of 5 and 100 respectively the highest rd was observed at station 02pc017 and was found to be in the range of 19 23 which is remarkably similar to the values computed using the wb distribution the maximum rps 5 to 100 years for both the canesm2 and canesm5 models were observed in the northeast of the study area which is where station 02 pb019 is located the rd at the100 year rp was found to be less than 4 greater than the 1 observed for the wb distribution at the maximum rp values there is no significant difference between the calculated rps of the canesm2 and canesm5 models while for values close to or less than the average rp there are substantial differences in some stations fig 10 compares the canesm2 and canesm5 models for calculating rps using lp3 distribution based on the apd a qualitative comparison of the canesm2 and canesm5 models indicates that the computed apd from both models has a significant difference at station 02pj030 for all rps the quantitative comparison of the canesm2 and canesm5 indicated that the rd of the calculated rps based on the canesm2 and canesm5 at this station for all rps is in the range 11 81 12 41 indeed all calculated rps based on the canesm2 model and lp3 probability distribution in this station are about 12 lower than those calculated based on the canesm5 model in all stations except 02pd010 02pc017 and 02ph011 the rd is positive indeed calculated apds for all rps based on the canesm5 model are higher than the canesm2 figure a6 therefore existing plans based on the canesm2 and calculated rps using lp3 are underestimated for stations 02pd010 and 02pc017 the rd is negative which means using existing plans is overestimated and there is no economic justification for using them especially for station 02pc017 whose absolute rd is in the range of 20 25 for all rps moreover for station 02ph011 the rd of the 5 years rp is positive while for the other rps this value is negative with the absolute rd of more than 9 of the 100 year rp for both the canesm2 and canesm5 models the lowest 5 to 100 year rps were found at station 02pj034 with the 100 year rp being less than 12 m3 s the corresponding difference between the apd calculated based on different rps using the canesm2 and canesm5 models and the lp3 distribution is less than 2 for both the canesm2 and canesm5 models the highest 5 to 100 year rps are associated with the 100 year rp at the 02 pb019 station with the lp3 distribution yielding a rp of 163 m3 s the corresponding difference between the rps calculated using the canesm2 and canesm5 models and the lp3 distribution is less than 1 therefore it could be concluded that the rd between calculated rps at stations with the lowest and highest rps is insignificant similar to previous distributions the difference between the average rps 5 to 100 years for canesm2 and canesm5 is also negligible i e less than 2 m3 s fig 11 shows the relative difference between the calculated apd using canesm2 and canesm5 models based on gm probability distribution for different rps besides the spatial distributions of each apd for all rps are provided in the appendix figure a7 based on the qualitative comparison of the results presented in the maps the rd values obtained from canesm2 and canesm5 and gm distribution for different rps at station 02pj030 are significantly different so that the rds for 50 and 100 are higher than 27 and 29 respectively the maximum absolute rd for rps of 5 10 20 50 and 100 are 19 75 21 67 23 54 27 04 and 29 21 so that the first two ones are related to station 02pc017 and the other ones are related to station 02pj030 for stations 02pj034 02pj030 02pl005 02ph014 and 02pk009 the apd calculated based on the canesm5 for all rps are higher than those calculated for canesm2 so that the existing plans need to be reconsidered because they are underestimated while for the stations 02pd010 02pc017 and 02 pb019 the apd calculated based on the canesm5 for all rps except for rp 5 at station 02 pb019 are lower than those calculated for canesm2 therefore the existing plans for these stations are overestimated and need to be reconsidered especially for station 02pc017 with the rd in the range of 19 7 24 89 the absolute rd between the calculated rps based on the canesm2 and canesm5 models using the gm distribution is in the range of 0 05 29 21 the maximum rd was observed at station 02pj030 29 21 for the 100 year rp where the rp was more than 2 times greater than the average rp i e 7 87 this however was not the maximum rp which was observed to occur at station 02 pb019 the rd between the rps calculated based on the canesm2 and canesm5 models at station 02 pb019 is less than 2 the most salient observation from figs 8 to 11 is that the canesm2 model does not yield larger rps than canesm5 at all stations for example the rps calculated using all distributions and the canesm2 model are lower than those calculated based on the canesm5 model at station 02pc017 while at stations 02pl005 02ph014 and 02pk009 the rps using the canesm2 model were exclusively higher than for the canesm5 model the calculated rps based on the canesm2 model are lower and or higher in all probability distributions for other stations fig 12 shows the distribution of the apd calculated using all probability distributions with the canesm2 and canesm5 models as well as their rds the range of rd between the estimated apd using wb ln lp3 and gm distributions were 32 12 38 48 22 89 19 32 25 69 12 41 and 24 89 29 21 respectively the average absolute difference between the estimated apd using wb ln lp3 and gm was 10 16 8 23 6 86 and 7 87 respectively in general the apd distribution calculated using all probability distributions with the canesm2 model is slightly larger than when computed using the canesm5 model 3 2 interannual average monthly flow fig 13 compares the canesm2 and canesm5 models when using the monthly mean discharge mmd for modeling in the southeast of the study area i e station 02pj030 there is a significant difference between the flow calculated using the canesm2 and canesm5 models yielding a range of absolute rd of 11 24 38 23 it is noteworthy that during the cold months of the year october to march and august the values estimated using the canesm5 model are greater than those of the canesm2 model while in the warm months april to july and september the opposite is true given that most floods occur in late spring and early summer in the study area the use of canesm2 data which shows larger values in these months is recommended for the southeast of the study area at station 02 pb019 which has the maximum mmd in the study area the mmd computed using the canesm5 model for five months i e february march september november and december is greater than that computed using the canesm2 with the rd in the range of 1 5 7 3 for the other months of the year the mmd computed using the canesm2 model is greater than when the canesm5 model is used with a rd in the range of 1 9 5 4 indeed no significant difference was observed between the mmd computed using the canesm2 and canesm5 models in different months and therefore the use of one model cannot be recommended over the other especially as climate change results in higher or lower mmd for the mmd presented in fig 13 more than 49 of mmd values calculated using the canems5 model are greater than those computed using the canems2 which indicates the insignificant difference between the average of the estimated mmd based on each climate change scenario the rd between the mmd computed using the canesm2 and canesm5 models was in the range of 38 9 100 for example in station 02pc017 the mmd related computed using the canems2 model was 3 47 m3 s while it was 6 97 m3 s for the canesm5 model due to the computed mmd values being close to the average of 17 m3 s the mentioned difference is not remarkable according to the provided results in fig 13 the maximum mmd calculated based on the canesm2 and canesm5 at all stations are not the same for stations 02 pb019 02pj034 and 02pl005 the maximum mmd calculated based on canesm2 and canesm5 are in the same month while for the other stations the maximum mmd calculated based on canesm2 and canesm5 are not the same for stations 02pc017 02ph011 and 02pk009 the maximum mmd calculated based on the canesm2 occurred one month before the maximum mmd calculated based on the canesm5 for station 02pd010 the maximum mmd calculated based on the canesm2 occurred one month after the maximum mmd calculated based on the canesm5 for stations 02pj030 and 02ph014 the maximum mmd calculated based on the canesm2 is related to july and april respectively while the maximum mmd calculated based on the canesm5 is related to october and february respectively according to these results it can be said that the trend of changes in different stations has occurred in different directions of the case study and it is not possible to provide a general conclusion that the maximum mmd of stations located in a certain direction of the case study will move from one month to other one or not by changing climate change model from canesm2 to canesm5 3 3 interannual average seasonality flow fig 14 compares the canesm2 and canesm5 models based on the seasonal mean discharge smd similar to the results for mmd in the southeast of the study area i e station 02pj030 smd values computed using the canesm2 model in both the spring and summer are larger than those of the canesm5 model with a rd of more than 25 and 9 respectively for the winter and autumn seasons the smd calculated based on the canesm5 model is larger than those based on the canesm2 model with a rd of more than 28 and 18 respectively in other regions of the study area similar to in the southeast calculated smd using the canesm5 model in autumn and winter is higher than when the canesm2 is considered while the opposite is true for other seasons indeed the results presented in this section confirm that the use of the canesm2 model is preferred for predicting flood events using climate change data because most of the floods in the study area are observed at the end of spring and the beginning of the summer at this time of year the flow discharge provided by canesm2 is larger than canesm5 providing a conservative assessment of flood risk potential the average absolute rd between smd computed using the canesm2 and canesm5 models for winter spring summer and autumn was 7 47 6 82 3 25 and 4 72 respectively indeed the maximum and minimum absolute rd in all stations was related to winter and summer seasons respectively a comparison of the canesm2 and canesm5 based on the provided results in fig 14 indicated that the maximum smd at all stations except 02pc017 and 02pj030 are in the same season for stations 02pc017 and 02pj030 the maximum smd based on the canesm2 is in the autumn and summer respectively while the maximum smd based on the canesm5 is in the summer and autumn respectively 3 4 interannual monthly peak discharge fig 15 shows the distribution of the mpd for all stations using boxplot analysis for station 02pd010 the minimum mpd found using the canesm2 model i e 10 79 m3 s was lower than that calculated using the canesm5 i e 11 22 m3 s a difference of about 4 the difference observed between the average and maximum mpd values computed using the canesm2 and canesm5 models was found to be almost zero in addition to the minimum and maximum values another important parameter identified in the boxplot is the interquartile range iqr defined as the difference between the third and first quartiles iqr q3 q1 the rd of the iqr for the canesm2 and canesm5 models was found to be greater than 5 given that the maximum and average mpd values for the canesm2 and canesm5 models are approximately equal and that the minimum and iqr for the canesm5 model are greater than for the canesm2 model it can be said that for mpd values in the iqr the canesm5 model provides a higher peak discharge while for mpd values lower than q1 and higher than q3 the canesm2 provides higher peak discharge for station 02pc017 the distribution of the mpd for the canesm2 and canesm5 models is entirely different the minimum mpd found using the canesm5 model i e 9 53 m3 s is 1 68 times higher than that of the canesm2 model i e 5 67 m3 s the rds between the minimum average maximum q1 q3 and iqr of the mpd for this station are more than 68 39 28 62 77 87 respectively indicating that the canesm5 model projected higher mpds it can be concluded that considering the average of all months the mpd estimated using the canesm5 model is higher than that of the canesm2 it should be noted that this statement is not valid for october where the mpd computed using the canesm2 model is more than double that of canesm5 as shown in figure a8 for station 02 pb019 which has the maximum mpd in the study area the minimum mpd computed using the canesm2 model is more than 4 greater than that of the canesm5 model when the maximum mpd value is considered the difference between models increases to more than 6 5 for the average mpd and q1 values the canesm5 model was found to yield higher values although the rd between it and the canesm2 model was less than 1 given that the mean value found using the canesm2 model is much lower than when the canesm5 model is considered it can be said that on average the mpd for the canesm2 model is lower than that of the canesm5 model but at maximum values the difference in mpd estimated based on canesm2 is significantly higher than those related to the canesm5 for station 02ph011 the difference between the minimum and maximum mpd using the canesm2 and canesm5 models is insignificant while the absolute rd of mpd between them is remarkably high i e 42 based on the boxplot for this station it can be concluded that the mpd for the canesm2 and canesm5 models are nearly equal for high mpd values but for the lower mpd values those computed using the canesm2 model are greater than those for the canesm5 model for station 02pj034 the differences between the maximum and q1 of the mpd values computed using the canesm2 and canesm5 models are insignificant it should be noted that although the maximum values in both boxplots for this station are equal the maximum value defined in the concept of the boxplot q3 1 5 iqr for canesm5 is significantly larger i e 11 78 m3 s than those for canesm2 i e 7 85 m3 s for station 02pj030 not only are the minimum q1 1 5 iqr and the maximum q3 1 5 iqr values of the box plot for the canesm2 model higher than those for the canesm5 model but also the iqr of the canesm2 model is larger than that of the canesm5 model it should be noted that the maximum mpd is associated with the use of the canesm5 model in general there is no significant difference between mpds computed using the canesm2 and canesm5 models in this station but their performance displayed monthly variation in this case for some months both models offer the same mpd values while in other months those of the canesm2 model or vice versa are larger than those of the canesm5 for station 02pl005 the difference between q1 q3 and the maximum for the canesm2 and canesm5 models is insignificant with the most remarkable difference being the minimum the boxplot shows that the minimum of the canesm2 model is more than 15 higher than that of the canesm5 model indeed it can be said that the difference between the mean mpd in two boxplots is less than 4 in general in most months the canesm2 model delivers a larger mpd than canesm5 for station 02ph014 the boxplot demonstrates that the canesm2 model yields higher values for all indices except for the maximum therefore it can be said that the canesm2 model generally offers larger mpd values than the canesm5 model although at the highest mpd value for this condition the mpd related to the canesm5 is 7 higher than that for canesm2 for station 02pk009 it can be seen from the boxplots that the minimum and iqr of the canesm2 model are lower than the canesm5 model while for all other indices the opposite is true in the months where the maximum observed mpd values occurred the canesm2 model yielded larger values than the canesm5 model while in the other months the values from one model may be higher or lower than another one the results for the different stations of the study are shown significant differences in mpd related when calculated using the canesm2 and canesm5 models based on the observed results selecting one model as optimistic or pessimistic was impossible instead the difference between each model should be examined according to the specific station under consideration and the project s objective fig 16 shows the rd between the mpd calculated using the canesm2 and canesm5 models based on the rd presented for january the canesm5 model yields a higher mpd compared to the canesm2 model in the stations located in the south southeast and center of the study area stations 02pj034 02pj030 02pl005 for other stations in the study area the mpd values determined using the canesm2 model are greater than those computed using the canesm5 model it should be noted that the highest absolute rd is observed in the southeast of the study area i e station 02pj030 in february the highest mpd was found at the northernmost station i e 02 pb019 in the easternmost station i e 02ph014 the only station located at the west of the study area i e 02pk009 and the northernmost station the maximum mpd are related to the canesm5 for other stations the mpds determined using the canesm2 model offer larger values than those computed using the canesm5 model for march results from the canesm2 and canesm5 models were practically the same as those previously discussed for january with the exception that for the westernmost station i e 02pk009 the canesm5 model also offered a higher mpd than the canesm2 model the rd for the two stations 02pj030 and 02pk009 was found to be more than 47 and 77 which indicates a significant increase in mpd when using the canesm5 model instead of canesm2 comparing the canesm2 and canesm5 models for the entire spring season shows that canesm5 yields greater mpd values than the canesm2 model in only four cases the northernmost station i e 02 pb019 with rd 18 in may the westernmost station i e 02pk009 with rd 13 in june as well as stations 02pd010 rd 1 49 and 02pc017 rd 2 36 in june and may respectively for july stations 02pk009 rd 28 28 02pj034 rd 21 82 and 02pc017 rd 28 72 were found to have higher mpd values when computed using the canesm5 model than when the canesm2 model was considered for the other stations the mpd found using the canesm2 model was greater than that found from the canesm5 model the average rd in stations where the mpd found using the canesm2 model was higher than from the canesm5 model was less than 18 maximum rd 27 5 for august two general cases were observed first the mpd values estimated were the same for both models stations 02pc017 02pb019 and 02pj034 or second the mpd values estimated from the canesm5 model were higher than those of the canesm2 model indeed it seems that the results from the canesm2 model for this month are underestimates and therefore do not accurately predict flood potential severity the use of the canesm2 model for august may expose the study area to unpredictable compensation risks resulting from inaccurate flood forecasting especially in the southeast of the study area i e station 02pj030 where the absolute rd is more than 74 the performance of the canesm2 and canesm5 models for calculating the mpd in september was very similar to july at stations with almost the same mpd by canesm2 and canesm5 in july i e 02pc017 02 pb019 and 02pj034 the canesm2 offered higher mpd than canesm5 for the other stations similar to july the canesm5 provided higher mpd compared to the canesm2 it should be noted that for september the absolute rd observed at the 02pc017 station where the mpd value from the canesm5 model was higher than the canesm2 model was more than 155 which is a significant amount at this same station and for november and december the projected mpd values using the canesm5 and canesm2 models were also found to have high absolute rd values of more than 277 and 114 respectively such a high rd for this station indicates that the selection of either the canesm5 or canesm2 models may yield very different results highlighting the need to modify the existing project designed based on the canesm2 the distribution of the mpd for all showed that there are significant differences between the mpd values computed by the canesm2 or canesm5 models figure a8 from fig 16 the rd range for all stations is 586 6 59 a general comparison of the mpd values found using either the canesm2 or canesm5 models fig 16 indicates that in about 39 of cases the mpd values determined using the canesm5 model are higher than those calculated using the canesm2 model while in about 50 of cases the opposite is true for the remaining 11 of cases the mpds determined using both models were found to be approximately equal the minimum average and maximum mpd values found using the canesm2 and canesm5 models for all stations and months were 4 48 35 01 161 92 and 4 29 35 1 151 09 respectively it can be seen that the minimum and mean mpd are almost equal in both cases but the maximum determined using the canesm5 model is about 7 lower than the value found using the canesm2 model a comparison of the mpd values determined using the canesm2 and canesm5 models at station 02 pb019 which has the maximum flow discharge indicates that the canesm2 model projects higher mpds than the canesm5 model for six months i e january march april june july and november for the remaining months of the year with the exception of august the mpd values determined using the canesm5 model were greater than those determined from the canesm2 model the rd for mpds calculated for all months at this station was in the range of 27 91 18 08 it should be noted that for the case where the mpd values determined using the canesm5 model were greater than those from the canesm2 model the calculated rd was significantly higher than the case when the when the mpd computed using the canesm2 model was greater for example in station 02pc017 the maximum rd is 59 46 while the minimum is 586 60 a significant difference between the computed mpd values for the canesm2 and canesm5 models was detected figure a8 it is not easy to achieve which model provides a more considerable mpd although there is a significant difference between the mpd values determined using the canesm2 and canesm5 models it could not be concluded in general terms which model provides higher or lower mpd in each station according to the provided results in fig 16 the maximum mpd calculated based on the canesm2 and canesm5 at all stations is not the same for stations 02pd010 02ph011 02pj034 and 02ph014 the maximum mpd calculated based on canesm2 and canesm5 are in the same month while for the other stations the maximum mpd calculated based on canesm2 and canesm5 are not the same for station 02pc017 the maximum mpd calculated based on the canesm2 occurred one month before the maximum mpd calculated based on the canesm5 for stations 02pb019 02pj030 02pl005 and 02pk009 the maximum mpd calculated based on the canesm2 is related to june june february and november respectively while the maximum mpd calculated based on the canesm5 is related to february august december june respectively 3 5 interannual seasonality peak flow fig 17 shows the distribution of the seasonal peak discharge spd for all stations based on this figure the spd in station 02pd010 is almost the same whether the canesm2 or canesm5 model is used for the winter months for the stations located in the south i e 02pl005 northeast i e 02ph014 and west i e 02pk009 of the study area the spd during the winter months computed using the canesm2 model were greater than those computed using the canesm5 model for these three stations rd during the winter months was found to be 9 2 12 27 and 20 3 respectively see fig 18 for the other stations and the winter season the spd found using the canesm5 model was greater than that found using the canesm2 model with a range of rd of 81 5 2 85 the absolute rd for station 02pj030 located at the north of the study area and having the highest spd was found to be more than 67 with the spd provided by the canesm5 model being 58 m3 s while that of the canesm2 model was 98 m3 s unlike winter the spd values determined using the canesm5 model in the summer are approximately 13 higher than the corresponding value determined using the canesm2 model fig 18 except for station 02pj030 in other stations the values determined using both the canesm2 and canesm5 models were found to be either the same or the canesm2 model gave a higher value stations 02pc017 02 pb019 and 02pj030 according to fig 18 the maximum rd i e rd 41 86 corresponds to station 02pj030 which also has the highest spd compared to the other stations given that most floods in the study area occur in late spring and early summer the significant differences between the computed spd values at this station will necessitate review and evaluation studies to be conducted for the summer the spd values determined from the canesm2 model were greater than those of the canesm5 model at only two stations stations 02pl005 rd 14 67 and 02pk009 rd 3 27 which are located in the south and west respectively of the study area the spd found using both the canesm2 and canesm5 models for station 02pj034 was almost the same while for other stations the canesm5 model yielded higher spd values than the canesm2 model the rd for these stations was in the range of 44 46 7 17 in which stations 02pc017 and 02pj030 with 44 46 and 31 38 have the highest absolute rd for the autumn the maximum absolute rd occurred at station 02pc017 and was found to be 28 26 this value is the highest rd in winter and summer while it is lower than the maximum absolute rd compared to the other seasons for stations 02pd010 rd 2 69 02pj030 rd 13 35 02ph014 rd 6 26 and 02pk009 rd 17 05 the spd provided by the canesm2 is higher than the canesm5 and for the others the canesm5 presented higher spd compared to the canesm2 based on fig 17 the maximum absolute rd was found at station 02pc017 with the spd value determined using the canesm5 model being 81 5 higher than that determined from the canesm2 model contour maps were shown in appendix figure a9 from fig 18 it can be observed that at all stations except 02pj034 either the canesm2 or canesm5 model will estimate a higher or lower spd value for all seasons identifying one model as superior to the other for all stations and seasons is impossible for station 02pj034 the spd values determined using the canesm5 model during the winter and autumn seasons were higher than that from the canesm2 model while for the other seasons the performance of the two models was practically identical given that the rd value is in the range the average rd for all the stations in winter summer spring and autumn is 13 66 5 22 10 24 and 2 1 respectively indeed it can be said that on average canesm5 offers higher spd than canesm2 in all seasons except spring although the excessive size of some rd values increases the uncertainty of finding by comparing the provided spd in each station it could be said that the canesm2 or canesm5 did not offer higher spd than canesm5 or canesm2 in all seasons therefore it could be concluded that the canesm2 and canesm5 could be selected based on the desired station and season as well as the needs of the current project a comparison of the canesm2 and canesm5 based on the provided results in fig 17 indicated that the maximum spd at five stations i e 02pd010 02pc017 02ph011 02pj034 02ph014 are in the same season for stations 02 pb019 02pj030 02pl005 and 02pk009 the maximum spd based on the canesm2 is in the spring spring winter and autumn respectively while the maximum spd based on the canesm5 is in the winter summer autumn and spring respectively 4 advantages limitations and future improvements owing to the importance of long term flood forecasting in hydrology the relative performance of the canesm2 and canesm5 models was evaluated in this study using flood frequency analysis ffa in terms of the amd and apd the interannual average monthly and seasonal flow discharge as well as the interannual monthly and seasonal peak flow given that the selection of particular probability distribution may introduce a level of uncertainty this study evaluated the performance of these two models using four different distributions in an effort to reduce uncertainty as much as possible four widely used probability distributions for the ffa namely the wb ln lp3 and gm distributions were employed to calculate the 5 to 100 year return periods each of these distributions has its own set of advantages and limitations when dealing with a particular type of data series for example the wb distribution has been known to provide reasonably accurate failure analysis and failure forecasting despite small sample sizes pasha et al 2006 balasubramanian and wu 2016 using the ln distribution modeling heavily tailed distributions is possible zeng and gonda 2014 the lp3 distribution can be used to extrapolate future flood events with a rp that is well beyond the observed flooding events griffis and stedinger 2009 the gm distribution has been extensively applied to extreme values analysis in many research areas such as geological environmental earth sciences etc kalaylioglu 2022 to verify the performance of each probability distribution three different tests including kolmogorov smirnov anderson darling and chi squared were applied the main advantage of the adt is its ability to test for deviations of observed data from different theoretical distributions jäntschi and bolboacă 2018 the kst statistic s distribution is independent of the underlying cumulative distribution function being examined which is an advantageous characteristic of this test despite the mentioned advantages for the kst it also has some disadvantages including 1 covering continuous distribution 2 this test is more sensitive near to distribution center than the tails and 3 it should be fully specified which is the main limitation of the kst ayuketang and joseph 2014 given that the use of any of these tests for data with different distributions may have strong or poor performance the simultaneous use of all three tests can decrease existing uncertainty due to the poor performance of the models zeng et al 2015 the current study used the gsgmdh soltani et al 2021b for runoff calculation based on the projected precipitations by canesm2 and canesm5 models since this model like all existing models does not have 100 accuracy there are induced errors within the model results due to the use of this model for both canesm2 and canesm5 the existing uncertainty related to the applied model is significantly reduced because the current uncertainty will work the same for both models other uncertainties may be due to the probability distributions used for ffa given that for both canesm2 and canesm5 four different distributions and three different tests were used simultaneously this uncertainty could be reduced to an acceptable level considering that in this study a machine learning based method has been used to calculate discharge flow in the future it is suggested that future work should consider the use of conceptual models such as the gr4j model for discharge flow calculation based on the canesm2 and canesm5 models and compared their results with the current study 5 conclusions in the current study the precipitation projected using the canesm2 and canesm5 models are applied in the newly developed machine learning based techniques known as generalized structure of group method of data handling gsgmdh to project the flow discharge in the future the projected flow discharges based on the canesm2 and canesm5 were compared in terms of flood frequency analysis ffa interannual average monthly flow interannual average seasonality flow interannual monthly peak flow and interannual seasonality peak flow the main results of the current study are as follows the cc results showed that the best results for precipitation calculation in the study area were achieved using the rcp4 5 and ssp245 scenarios for the canesm2 and canesm5 models respectively the ffa results indicated that the average rps calculated with the amd for the wb ln lp3 and gm distributions were 11 01 2 81 1 52 and 1 71 respectively indeed the average rps computed with the amd for all distributions using the canesm5 model were higher than those calculated by the canesm2 model when the rps were calculated by considering the apd and the wb ln lp3 and gm distributions their rds were 2 65 2 06 0 76 and 2 21 respectively indeed the average rps determined using the apd for all distributions except lp3 were higher when calculated using the canesm5 compared to the canesm2 for the mmd more than 49 of estimated values were more significant when computed using the canesm5 model than the canesm2 model indicating the insignificant difference between the average of the estimated mmd based on each climate change scenario the average rd between the mmd computed using the canesm2 and canesm5 models for all stations was 2 09 which indicates that the canesm5 model provided slightly higher values than the canesm2 the smd computed using the canesm2 model in both the summer i e 0 37 and spring i e 6 8 seasons was greater than when computed using the canesm5 model for the winter and autumn the average smd determined for all stations using the canesm5 model was greater than those of the canesm2 model with the rd being 7 48 and 4 72 respectively for the mpd and spd the distribution of flow discharges computed using the canesm2 and canesm5 models were almost identical and did not differ significantly although the provided maps show a significant difference in mpd and spd at different stations it is not easy to say which model provides a more considerable mdp in all conditions stations and months a general comparison of the canesm2 and canesm5 models indicates that the mpd values average of all months and stations calculated using the canesm5 model were 10 higher than those of the canesm2 model besides the general comparison of the canesm2 and canesm5 models indicates that the calculated spd average of all seasons and stations related to canesm5 is 5 higher than the one for canesm2 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge the support of the natural sciences and engineering research council of canada nserc discovery grant rgpin 2020 04583 and the fond de recherche du québec nature et technologies québec government b2x 315020 author contribution statements all authors discussed the results and contributed to the final manuscript h b supervised the project appendix 
2456,with the recent phase of the coupled model intercomparison project cmip water professionals especially flood modelers are eager to examine how well climate models represent flood dynamics in the sixth phase of the cmip i e cmip6 in comparison to the previous phase i e cmip5 and how will climate change affect them in the future in this study the results obtained from cmip5 and cmip6 based on the canadian earth system models in calculating the amount of precipitation were compared and the effect of these two reports on the amount of runoff was investigated for this purpose two models of canesm2 and canesm5 were used the flood frequency analysis ffa results indicated that the average return periods rps calculated by the annual mean discharge amd for all distributions based on the canesm5 are higher than those calculated by canesm2 besides the average rps by apd for all distributions except log pearson3 calculated based on the canesm5 are higher than those calculated by the canesm2 for monthly mean discharge mmd the average mmd calculated by canesm5 is 2 higher than those for canesm2 the seasonality mean discharge smd for canesm2 in both summer i e 0 37 and spring i e 6 8 are larger than the canesm5 values the smd for canesm5 in both winter i e 7 48 and autumn i e 4 72 are larger than the canesm2 values for monthly peak discharge mpd and seasonality peak discharge spd the difference between the flow discharges in canesm2 and canesm5 is significantly different based on the month or season as well as the station the general comparison of the canesm2 and canesm5 indicates that the average mpd and average spd related to the canesm5 are 10 and 5 higher than those for canesm2 keywords climate change canesm2 and canesm5 cmip5 and cmip6 flood frequency analysis flood susceptibility water resource management data availability data will be made available on request 1 introduction the issue of climate change cc is one of the most pressing in the world today however adjusting to its long term effects is proving an extreme challenge due to its significant spatial variations e g reduction in the magnitude of temperature from high to low latitudes areas and decreases versus increases in precipitation from dry to wet areas and the broad range of its consequences e g both more frequent flood events and unexpected prolonged droughts wang et al 2013 giorgi 2019 soltani et al 2021a cc is known to have critical impacts on both regional and global hydrologic processes yuan et al 2021 the consequences of which are now being faced by human societies especially in communities more susceptible to natural hazards such as floods doulabian et al 2021 eingrüber and korres 2022 as a result of increased cc induced flood events flood forecasting has become an essential tool for reducing community vulnerability to flood risk and forms an integral part of the national strategy to live with floods and contribute to national sustainability mitigation measures based on climate projections require sustainable management of water resources and floods along with investment in long lasting infrastructures broderick et al 2019 subsequently developing a reliable climate scenario with high resolution is crucial to support resilient engineering planning and informed decision making by exploring all possible alterations to regional climatology and quantifying probable risks associated with cc to natural systems and human society wang et al 2014 wang et al 2019 when assessing and projecting impacts associated with cc it is crucial to use global climate models gcms however selecting an appropriate subset of gcms is the greatest challenge associated with this approach there is a multitude of uncertainties associated with gcm simulations such as initial assumptions calibration processes mathematical formulation and model resolution all of which inherently confine the use of these models to regional or local climate projections salman et al 2018 khan et al 2018 accordingly a subset of gcms may be recommended by excluding the less proficient models in replicating the observed climate to reduce projection uncertainty ahmed et al 2019 as a means of decreasing uncertainty in the projection of climate variables previous studies gleckler et al 2008 lutz et al 2016 salman et al 2018 suggest selecting gcms based on their ability to simulate those variables such as temperature and precipitation due to the absence of well established procedures for choosing proper gcms studies evaluating simulations of different climatic variables did not provide formal guidance on gcm selection the selected gcm is expected to be able to reproduce historical climate distribution including the spatial variability and mean ahmed et al 2020 climate models considering complicated biogeochemical systems are crucial for forecasting future cc ipcc 2013 the results of the sixth phase of the coupled model intercomparison project cmip6 was recently released by the intergovernmental panel on climate change ipcc with some notable differences from the fifth phase report i e cmip5 there is a crucial difference between cmip5 and cmip6 regarding the future scenario in cmip5 the projections are provided based on 2100 radiative forcing values for four greenhouse gas emissions pathways ipcc 2014 whereas cmip6 uses socio economic pathways ssp o neill et al 2014 such as urbanization population growth economics and other factors o neill et al 2016 eyring et al 2016 four representative concentration pathways rcps were used to generate the cmip5 model s future climate projections namely the rcp8 5 rcp6 0 rcp4 5 and rcp2 6 ipcc 2014 rcps are numerically classified according to the radiative forcing level rfl in 2100 i e rfl considered for rcp4 5 is 4 5 w m in the year 2100 the results of the cmip6 were provided through five ssps i e ssp1 ssp2 ssp3 ssp4 ssp5 with seven 2100 forcing levels i e 1 9 2 6 3 4 4 5 6 7 8 5 w m2 several studies have compared cmip6 gcms and cmip5 gcms in different regions casale et al 2021 evaluated the operation performance of lake como in italy under different hydrological conditions based on the cmip5 and cmip6 projections the authors found that the lake performance based on the cmip5 is better than the cmip6 yanxin et al 2022 utilized the hydroclimatic intensity index as well as cmip5 and cmip6 to assess china s hydroclimatic intensity change and its future trend due to the results of this study a changing pattern such as higher highs and lower lows was discovered in china this is expected to rise over the vast majority of the country furthermore the studies revealed that places with moderate hydroclimatic intensity would experience a significant rise try et al 2022 evaluated the mekong river basin flooding as a result of climate change the results of their studies indicated less error and a higher correlation of the cmip6 compared to the cmip5 besides the cmip6 s climate change model also projected significant increases in flooding in the future guo et al 2022 compared the performance of the cmip5 and cmip6 in the hydrological regime simulation of the yellow river basin china the emblematic annual mean temperature eamt was evaluated for two future periods p1 2026 2055 and p2 2066 2095 for p1 and p2 the minimum and maximum of the eamt related to the cmip6 are lower and higher respectively than those for cmip5 furthermore the precipitation enhancement in both p1 and p2 periods related to the cmip6 are higher than those for cmip5 due to the fact that flood hazard fh is a spatio temporal phenomenon and depends on factors such as soil land use topography hydrology and climate gcms cannot provide adaptive management strategies that are universally applicable considering the probable effects of climate change a comprehensive approach to fh evaluation is necessary to guarantee effective measures in fh reduction ullah et al 2019 globally extreme flood events are becoming increasingly common ivanov et al 2021 due to the fact that numerous various factors influence the frequency of extreme flood events at once it is challenging to ascertain their relative significance and any possible interactions bonakdari et al 2020 mallakpour and villarini 2015 in any case it is clear that the worldwide hydroclimate is becoming increasingly intense fischer and knutti 2016 and flooding changes coincide with variations in precipitation extremes sanderson et al 2019 as a result soltani et al 2021b developed a new approach by combining machine learning ml and remote sensing rs techniques to predict watershed runoff in this study the authors introduced a new scheme of the group method of data handling gmdh known as the generalized structure of gmdh gsgmdh using the gsgmdh a simple but accurate model was developed to perform the normalized difference vegetation index ndvi calculation for the rs the authors used modis data along with javascript based coding to process the collected data in the google earth engine gee finally the gsgmdh was applied to provide a runoff forecasting model in nine stations in the quebec basin stations using precipitation and ndvi as inputs the detailed comparison of the developed model against historical data indicated that it not only could estimate runoff with a high level of accuracy but also it could be able to predict the extreme values of the runoff it is still uncertain how effectively the latest cmip6 models will mimic quebec s climate response to flooding according to the canadian disaster database https cdd publicsafety gc ca the estimated total cost of floods in the province of quebec was more than 236 million cad from 2010 to 2017 comparing cmip5 and cmip6 models is essential for quebec as policymakers are currently managing the high vulnerability of the province to flooding by evaluating climate change impacts using the cmip5 any significant advancement within the cmip6 projections compared to cmip5 models could lead to a modification of the plausible effect and an adjustment of the management approach shashikanth et al 2014 in any case the flood susceptibility with different return periods has not been analyzed in the current study area so far as a result a comprehensive evaluation of flood prediction in quebec comparing both the cmip5 and cmip6 models based on the canadian earth systems models is of significant interest in the current study canadian earth system model versions 5 and 6 i e canesm2 and canesm5 are used to calculate future precipitation and its impact on runoff in these two cimp reports hence different scenarios of these two models i e canesm2 and canesm5 are examined with historical measurements to obtain the best scenario for precipitation calculation using the obtained precipitation and recently developed model for runoff calculating the effect of these two reports on the amount of runoff and their differences are examined in terms of the flood frequency analysis interannual average monthly flow interannual average seasonality flow interannual monthly peak flow and interannual seasonality peak flow 2 materials and methods 2 1 study area the study area is located between latitudes 46 04 n 46 59 n and longitude 72 23 w 72 30 w fig 1 the western part of the study area includes parts of the administrative regions of center du québec and mauritius while the northern reach includes parts of the capitale nationale the eastern southern and central parts are also located in the administrative region of chaudière appalaches the study area s maximum height is 688 m above mean sea level with an average height of 192 m and average annual precipitation of 1141 mm http climate weather gc ca the location of the study area hydrometric and climate stations as well as distribution of the historical precipitations are given in fig 1 see soltani et al 2021b for more information 2 2 coupled model intercomparison project in this study two models of canesm2 and canesm5 were used to calculate the amount of precipitation and the results of their best scenario were used to calculate the amount of runoff in the future the second generation of the canadian earth system model canesm2 that was prepared for the coupled model intercomparison project phase 5 cmip5 is one of the models included in the fifth assessment report ar5 of the ipcc javaherian et al 2021 which was published in september 2013 ipcc 2013 araji et al 2018 canadian earth system model version 5 canesm5 is the sixth phase of coupled model intercomparison project published in august 2021 it is the new structure of cmip coupled model intercomparison project phase 6 cmip6 in ar6 five shared socioeconomic pathways ssps scenarios are considered i e ssp1 ssp2 ssp3 ssp4 and ssp5 which show sustainability middle of the road regional rivalry inequality and fossil fuel development respectively describe the possible future worlds and represent different combinations of mitigation and adaptation challenges huang et al 2019 ssp1 2 6 ssp2 4 5 ssp4 6 0 and ssp5 8 5 are updated versions of the representative concentration pathways rcps scenarios in cmip5 and ssp1 1 9 ssp4 3 4 and ssp3 7 0 are new scenarios of ar6 ssp1 1 9 focuses on limiting the warming level to below 1 5 c which corresponds to the goal of the paris agreement ssp4 3 4 represents an intermediate mitigation effort pathway that falls between rcp2 6 and rcp4 5 ssp3 7 0 represents the medium to high end of future emissions and warming wang et al 2021 su et al 2021 liu et al 2022 arunrat et al 2022 canesm5 have 5 scenarios from 7 scenarios in ar6 i e ssp1 1 9 ssp1 2 6 ssp2 4 5 ssp3 0 70 and ssp5 8 5 in the current study a single member for each model typically the first member r1i1p1f1 for cmip6 and r1i1p1 for cmip5 which is used by most of the newly published studies lin and chen 2020 tian and dong 2020 mudryk et al 2020 zhang and chen 2021 de medeiros et al 2022 is used for fair comparisons of the cmip5 and cmip6 climate models based on the canadian earth system models i e canesm2 and canesm5 in this study similar to the article presented by soltani et al 2021b the canesm5 from the sixth ipcc report was used to obtain future precipitation and the results were compared with the canesm2 from the fifth ipcc report the change factor cf a common approach to estimate future climate parameters tirpak et al 2021 mansouri et al 2022 is used in this research and is calculated as shown below soltani et al 2021b 1 p p p obs p fut p hist where p p p obs p fut and p hist are the predicted observed future and historical precipitation respectively 2 3 runoff estimation in the current study a new machine learning ml technique along with the remote sensing methodology developed by soltani et al 2021b are employed to calculate the runoff the ml model was developed based on a new scheme of the group method of data handling gmdh a well known flood forecasting technique moosavi et al 2017 walton et al 2019 dodangeh et al 2020 elkurdy et al 2021 the generalized structure of the gmdh gsgmdh soltani et al 2021b model was developed with precipitation and the normalized difference vegetation index was introduced as input variables for runoff forecasting using the collected precipitation data from the fifth and sixth phases of the cmip in terms of canesm2 and canesm5 respectively in spatial and temporal variability the runoff is estimated in the future years 2 4 flood frequency analysis for flood recurrence and flood frequency analysis ffa estimation four well known probability distributions are used farooq et al 2018 swetapadma and ojha 2020 malik and pal 2021 namely weibull wb lognormal ln log pearson3 lp3 and gumbel max gm the wb ln and gm distributions use two parameters while the lp3 uses three parameters table 1 a detailed description of the probability distributions can be found in mccuen 2016 the probability density functions pdf for each of the wb ln lp3 and gm distributions are provided in equations 2 5 respectively 2 f x α β x β α 1 exp x β α 3 f x exp 1 2 ln x γ μ σ 2 π 2 x γ σ 4 f x 1 x β γ α ln x γ β α 1 exp ln x γ β 5 f x 1 σ x μ σ exp x μ σ the main advantages of the weibull distribution are as abernethy 2004 i it is capable of providing accurate failure analysis and failure forecasting in extremely small samples because of this it is feasible to conduct cost effective studies with small samples ii it provides a simple and meaningful representation of failure data and iii it has the most diverse distribution shapes making it the most popular however its maximum likelihood estimators fail to perform correctly for all parameter values weibull distributions have increasing hazard functions from zero to infinity when the shape parameter is greater than one but this function may not be suitable in some circumstances bain 1978 because the values in the lognormal are positive it is a rightward skewed distribution so that for a constant location or shape parameter the degree of skewness has a direct relationship with the shape or location parameter a very long tail is one of the key characteristics of this distribution sayama and ishii 2013 since the water resources council 1967 1982 of the united states recommended using the log pearson type 3 distribution as the basis for hydrologic frequency analyses it has been the most frequently used distribution compared to two parameter distributions such as gambel max weibull and lognormal three parameter distributions such as log pearson3 have lower biases as well as larger standard error cunnane 2010 2 5 goodness of fit in order to fit the flow samples a number of goodness of fit criteria are employed to seek an optimum distribution these criteria include the kolmogorov smirnov test kst the anderson darling test adt and the chi squared test cst in the kst the empirical cumulative distribution function cdf determines if a sample is part of a continuous hypothesized distribution in hydrological applications highly asymmetric distributions are often encountered and the adt has demonstrated a strong ability to be able to handle this type of data baldassarre et al 2009 adt provides a general measure of the fit between the observed and expected cdfs the weight assigned to the tails in adt is more than kst taking into account the most significant vertical difference between the empirical and theoretical cdf the kst statistic is defined the adt d and kst a2 statistics are defined as equations 6 and 7 respectively 6 d max 1 i n f x i i 1 n i n f x i 7 a 2 n 1 n i 1 n 2 i 1 ln f x i ln 1 f x n i 1 where n is the number of elements in the sample and f is the hypothesized distribution the chi squared test cst available for continuous samples is utilized to determine the event that a sample originates from a population that has a particular distribution such as wb ln lp3 gm as the cst is applied to binned data the statistic of this test is highly dependent on the number of bins and how the data is binned the cst statistic is defined as follows 8 χ 2 i 1 k o i e i 2 e i where ei and oi denote the expected and observed frequency respectively for the ith bin and k is the number of bins the expected frequency is determined as follows 9 e i f x 1 f x 2 where the limits of the ith bin are defined as x1 and x2 and the f is the cdf of the desired probability distribution the empirical formula applied in the current study to determine the number of bins is based on the samples size and is defined as follows 10 k 1 log 2 n where k is the number of bins and n is the number of samples the relative difference rd index is applied to compare the different variables defined in the current study based on the canesm2 and canesm5 the rd is defined as follows 11 rd x c a n e s m 2 x c a n e s m 5 x c a n e s m 2 100 where x c a n e s m 2 and x c a n e s m 5 are the values of the desired parameters calculated using canesm2 and canesm5 respectively 3 results this section provides the results of the comprehensive comparison of the canesm2 and canesm5 for the study area i e quebec canada the canesm2 and canesm5 models are compared using flood frequency analysis in terms of the annual mean and peak discharge the interannual average monthly and seasonal discharge as well as interannual monthly and seasonal peak discharges 3 1 ffa results as discussed in section 2 3 four different probability distributions were considered for the ffa including wb ln lp3 and gm to evaluate the performance of each distribution three tests i e kst adt and cst defined in section 2 4 were employed as an example the pdf of station 02pd010 for both the canesm2 and canesm5 models is provided in fig 2 according to this figure the pdf of all distributions strongly fit the observed data so that they can be used for flood recurrence estimation due to the ability of these probability distributions to fit the observed data ffas were performed using both the annual mean and peak discharge the goodness of fit results related to all probability distributions for both the canesm2 and canesm5 models for flood recurrence calculation tables a1 to a4 as well as the corresponding parameters of each probability distribution table a5 are provided in the appendix 3 1 1 ffa based on the annual mean discharge amd this section compares the canesm2 and canesm5 models for calculating the return periods using four probability distributions based on the annual mean discharge the applied probability distributions include wb fig 3 ln fig 4 lp3 figures 5 and a2 and gm figures 6 and a3 besides the goodness of fit evaluation for all probability distributions using the canesm2 and canesm5 models and the amd are provided in tables a1 and a2 respectively based on the provided results in this table it can be seen that gm ln and wb have successfully passed 96 3 of tests i e ks ad and cst for all nine stations while this percentage for lp3 is 92 59 finally it could be concluded that gm ln and wb performances in ffa based on amd are similar while the lp3 s performance is lower than the others fig 3 compares the canesm2 and canesm5 models in calculating return periods using the wb distribution based on the amd for different rps one to 100 years the minimum and maximum computed rps are observed at stations 02pj034 and 02 pb019 respectively the maximum rd for the stations with the lowest and highest amd are less than 5 5 and 3 5 respectively figure a1 according to the presented results in fig 3 for all rps calculated using the wb distribution amds calculated based on the canesm5 model are greater at all stations than those for canesm2 the rp was found to be directly related to rd except at station 02 pb019 so that at a given station the higher the rp value the higher the rd between canesm2 and canesm5 indeed the highest and lowest rds were observed at 100 year and 5 year rps respectively for station 02 pb019 the rd is in the range of 2 49 3 26 the maximum rds are observed at station 02pd010 located in the north of the case study the range of rd for this station is 39 94 81 25 with the minimum rd for this station being greater than the maximum rd of all other stations i e 19 38 the range of rd of the rps calculated using wb distribution in canesm2 and canesm5 for all stations is 0 38 81 25 while the average value of rd is 11 given that the range of rd values is significantly different from the average values of each station the use of the average value in this case cannot be evaluated as an acceptable comparative index the maximum rd is 81 25 related to the rp 100 at station 02pd010 while the minimum rd is 0 38 related to the rp 5 at station 02ph014 as shown on the map the station 02pd010 is located upstream of quebec city the rd between the canesm2 and canesm5 for rps of 5 10 20 50 and 100 are 39 94 52 62 35 73 84 and 81 25 respectively due to the significant difference in rps at this station located upstream of quebec city based on the canesm2 and canesm5 the importance of re examining the proposed canesm2 based designs is clearly observed station 02pc017 is ranked second after 02pd010 based on the maximum rd in both stations the rd has a direct relation with rp so as the value of rp increases the rd also increases and vice versa fig 4 compares the canesm2 and canesm5 models for calculating rps using the ln distribution based on the amd according to the regional maps presented in the figure the rps calculated using ln distribution and the canesm5 model are higher at all stations except station 02pd010 compared to when the canesm2 model is considered for the wb distribution it was observed that the highest rd is corresponded to station 02pd010 while when the ln distribution was used the maximum rd for this station occurred for the 100 year rp and was less than 4 for ln probability distribution the rd is in the range of 3 86 13 68 yielding an average rd of 3 42 the rd between the canesm2 and canesm5 at station 02pj030 which has the higher rd and is the farthest from quebec city for rps of 5 10 20 50 and 100 are 4 75 7 56 9 82 12 21 and 13 68 respectively according to the results obtained from these maps it can be concluded that the rd related to rps calculated by ln is much less than when the wb distribution is considered it should be noted that at all stations except 02pd010 the rps obtained for canesm5 are larger than for canesm2 which is the only difference between the rps obtained based on the ln and wb the maximum rd at all rps is related to station 02pj030 except for rp of 5 which is related to station 02pc017 the rd in stations 02pb019 02ph011 and 02pk009 for all rps is less than 1 indeed the studies conducted for these stations using ln probability distribution based on the canesm2 are not significantly different from canesm5 in these stations there is no direct or indirect relationship between the rd and rps for example the rps of 100 5 50 10 and 20 are ranked from one to five in terms of the highest rd at station 02pb019 the remarkable thing about station 02pc017 located in the west of quebec city is that the rd value is almost constant in all rps so the rp provided by canesm5 is approximately 6 higher than the rps provided by canesm2 the rd between the rp values calculated using ln probability distributions derived from canesm2 and canesm5 for stations 02pd010 02pj034 02pj030 02pl005 and 02ph014 has a direct relationship with the value of rp when rp increases the rd between rp values calculated using the ln probability distribution derived from canesm2 and canesm5 also increases a comparison between the canesm2 and canesm5 models for calculating the rps using the lp3 distribution based on the amd was performed similar to the wb distribution a significant increase in canesm5 related rps was observed in the central study area compared to when canesm2 was used for rp evaluation at rps of 10 to 100 years the highest rd fig 5 is related to station 02pj030 located at the southwest of the study area figure a2 while for a rp of 5 years the maximum rd is related to station 02pc017 the absolute difference between the value of this index at rp 5 in these two stations is 1 11 for the rps of 5 10 20 50 and 100 the maximum rd is 5 39 6 8 8 84 10 99 and 12 32 respectively at all stations except station 02pc017 with increasing rp the rd value also increases so that the lowest value of this index is observed at a 5 year rp and the highest is related to the 100 year rp the rd for this distribution is in the range of 0 03 12 32 while the average rd is less than 3 for station 02pc017 the maximum rd is observed at rp 5 rd 5 39 while the lowest value of this index is observed at rp 100 rd 4 32 in stations 02pd010 and 02ph011 the calculated rp using lp3 based on the canesm5 is lower than those for canesm2 figure a2 for stations 02pc017 02 pb019 02pj030 02pl005 and 02ph014 the calculated rp using lp3 based on the canesm2 is lower than those for canesm5 the difference between the rd of station 02pj030 which has the highest rd at rps of 10 to 100 for rp 5 to 100 is about 2 so that the rd of rp 5 is 4 23 and for rps of 10 20 50 and 100 are 6 8 8 84 10 99 and 12 32 respectively for station 02pl005 which is ranked second with the highest rd after station 02pj030 the rd of rps of 5 10 20 50 and 100 are 1 75 3 18 4 47 6 and 7 respectively due to the differences in the values of rps provided by lp3 probability distribution using canesm2 and canesm5 models especially in stations 02pj030 and 02pl005 there is a need to review the provided plans based on rps obtained using lp3 and canesm5 fig 6 indicates the rd of the rp calculated based on gm for the canesm2 model compared to the canesm5 model besides the corresponding maps of the different rps calculated by gm based on the canesm2 and canesm5 are provided in the appendix figure a3 for all stations except 02pd010 and 02ph011 the calculated discharge flow with the specific rps based on canesm5 is higher than those based on canesm2 due to fig 6 for all stations except 02pc017 and 02 pb019 the rd has a direct relation with rp so that as the value of rp increases the rd also increases and vice versa for stations 02pc017 and 02 pb019 it is entirely opposite to other stations so that the value of rp increases the rd also decreases and vice versa for all stations except 02pd010 and 02ph011 the discharge calculated based on different rps related to canesm5 is higher than canesm2 the maximum rd for these stations at rps of 5 10 20 50 and 100 are 5 28 6 04 7 88 9 92 and 11 24 respectively so that the first one is related to station 02pc017 while the others are related to station 02pj030 for stations 02pd010 and 02ph011 rds are less than 1 5 and 3 respectively which are related to the rp of 100 the average rd for all stations and rps is about 2 5 according to the obtained results from figures 5 and a3 it can be concluded that in most stations the difference between the rps calculated using gm probability distribution and the annual mean discharge based on canesm2 and canesm5 models are not significantly different from each other fig 7 shows the distribution of the amds calculated using all probability distributions with the canesm2 and canesm5 models as well as their rds the range of rd between the estimated amd values using wb ln lp3 and gm distributions are 81 25 0 38 13 68 3 86 13 32 5 68 and 11 24 2 88 respectively the average absolute difference between the estimated apds using wb ln lp3 and gm distributions are 11 13 3 42 2 94 and 2 47 respectively a comparison of the canesm2 and canesm5 models in terms of rps generated from four different probability distributions based on the amd figs 3 to 6 indicates that more than 75 of calculated rps related to the canesm5 model are higher than those for the canesm2 model for rps computed using the canesm2 model which are higher than those of the canesm5 model the rds are in the range of 0 01 5 68 with an average of 1 49 for rps computed using the canesm5 model which are higher than those of the canesm2 model the rds are in the range of 0 03 81 25 with an average of 6 02 the amd distribution calculated by all probability distributions for canesm5 is generally larger than canesm2 3 1 2 ffa based on the annual peak discharge apd the goodness of fit evaluation for all probability distributions using the canesm2 and canesm5 model and the apd are provided in tables a3 and a4 respectively besides the probability distribution parameters fitted for the canesm2 and canesm5 models are provided in table a5 due to the results of tables a3 and a4 lp3 has successfully passed 100 of all tests while this percentage for gm ln and wb are 98 15 94 44 and 90 74 respectively therefore the lp3 is ranked first for the ffa based on the apd and gm ln and wb are ranked second to fourth respectively comparison of the all probability distribution for both amd and apd tables a1 to a4 is also indicated that the gm lp3 ln and wb are ranked first to fourth respectively in ffa so that gm lp3 ln and wb have successfully passed 97 22 96 30 95 37 and 93 52 respectively fig 8 shows the study area map for the 5 10 20 50 and 100 years of rps that were calculated based on the apd using the wb probability distribution a qualitative comparison of the canesm2 and canesm5 models for the 5 year rp indicates that the computed discharge distribution from both models is almost the same the maximum 5 year rp for the canesm2 and canesm5 models are 112 58 and 112 35 m3 s respectively while the minimum 5 year rp for the canesm2 and canesm5 models are 6 28 and 6 32 m3 s respectively indeed not only is there no significant difference between the minimum and maximum values when calculated using the canesm2 and canesm5 models but also the minimum and maximum values in both cases occur at the same stations analysis of the 5 year rp indicated that the average discharge of all stations when using the canesm2 model is 31 97 m3 s while it is 30 75 m3 s for the canesm5 model although the distribution of 5 year rp is almost the same for the two models it is expected that some stations may exhibit significant variations due to the observed difference between the average values from the two models comparing the 5 year rp for the canesm5 model and the canesm2 model shows that the relative increase or decrease of rps are in the range 32 13 38 48 for all stations for the absolute changes the difference of the 5 year rp computed using the canesm5 model compared to the canesm2 model is in the range of 0 21 38 48 similar to the 5 year rp the minimum and maximum 10 20 50 and 100 year rp values computed using both the canesm2 and canesm5 models are located at stations 02pj034 and 02 pb019 respectively as the rp value increases the absolute value of relative error increases at all stations except at station 02p005 where the range of the relative error was found to be 0 6 1 31 figure a4 this indicates that the rps calculated by both the canesm2 and canesm5 models are very close together due to fig 8 the maximum rd between the rps calculated based on the canesm2 and canesm5 models at station 02 pb019 is less than 3 which is insignificant the maximum rd between the calculated rps was found at station 02pc017 where the 100 year rps were 28 6 m3 s and 37 8 m3 s based on the canesm2 and canesm5 models respectively it is interesting to note that the highest rd value of each rp is associated with the station where the apd value is closest to the average the different contour maps from the 5 10 20 50 and 100 year rps using the apd and ln distribution were generated figure a5 the minimum average and maximum rps for the canesm2 model were 7 43 46 and 155 27 m3 s respectively while the minimum average and maximum rps for the canesm5 model were 7 11 42 149 8 m3 s respectively indeed the rd between minimum average and maximum rps of the canesm2 and canesm5 models is 1 52 3 35 and 3 54 respectively due to fig 9 the rps calculated using the canesm2 model for all stations are higher than those calculated with the canesm5 model except at stations 02pc017 and 02pj034 besides the rps calculated for station 02pk009 using canesm2 and canesm5 are very close together so that the rds are less than 1 for the rps of 5 10 and 20 canesm2 provided higher values than canesm5 while for rps of 50 and 100 canesm5 presented higher values than canesm2 as can be seen in this figure the rd has a direct relationship with the rp so for all stations except 02pl005 and 02pk009 the lowest and highest rd were observed at rps of 5 and 100 respectively for station 02pd010 with the average apd of about 17 m3 s the maximum difference between the calculated apd based on the ln distributions using canesm2 and canesm5 for different rps is less than 3 5 for rp of 100 the rd of the other stations with higher and lower average apd is entirely different for example the average apd for station 02pk009 is about 19 m3 s which is very similar to the previous one while the difference between the rps calculated based on the canesm2 and canesm5 is negligible another example is station 02ph011 whose maximum apd for both canesm2 and canesm5 is lower than those for station 02pd010 for this station the rd between the rps calculated using the canesm2 and canesm5 is in the range of 6 38 11 32 so the lowest and highest rd are related to the rps of 5 and 100 respectively the highest rd was observed at station 02pc017 and was found to be in the range of 19 23 which is remarkably similar to the values computed using the wb distribution the maximum rps 5 to 100 years for both the canesm2 and canesm5 models were observed in the northeast of the study area which is where station 02 pb019 is located the rd at the100 year rp was found to be less than 4 greater than the 1 observed for the wb distribution at the maximum rp values there is no significant difference between the calculated rps of the canesm2 and canesm5 models while for values close to or less than the average rp there are substantial differences in some stations fig 10 compares the canesm2 and canesm5 models for calculating rps using lp3 distribution based on the apd a qualitative comparison of the canesm2 and canesm5 models indicates that the computed apd from both models has a significant difference at station 02pj030 for all rps the quantitative comparison of the canesm2 and canesm5 indicated that the rd of the calculated rps based on the canesm2 and canesm5 at this station for all rps is in the range 11 81 12 41 indeed all calculated rps based on the canesm2 model and lp3 probability distribution in this station are about 12 lower than those calculated based on the canesm5 model in all stations except 02pd010 02pc017 and 02ph011 the rd is positive indeed calculated apds for all rps based on the canesm5 model are higher than the canesm2 figure a6 therefore existing plans based on the canesm2 and calculated rps using lp3 are underestimated for stations 02pd010 and 02pc017 the rd is negative which means using existing plans is overestimated and there is no economic justification for using them especially for station 02pc017 whose absolute rd is in the range of 20 25 for all rps moreover for station 02ph011 the rd of the 5 years rp is positive while for the other rps this value is negative with the absolute rd of more than 9 of the 100 year rp for both the canesm2 and canesm5 models the lowest 5 to 100 year rps were found at station 02pj034 with the 100 year rp being less than 12 m3 s the corresponding difference between the apd calculated based on different rps using the canesm2 and canesm5 models and the lp3 distribution is less than 2 for both the canesm2 and canesm5 models the highest 5 to 100 year rps are associated with the 100 year rp at the 02 pb019 station with the lp3 distribution yielding a rp of 163 m3 s the corresponding difference between the rps calculated using the canesm2 and canesm5 models and the lp3 distribution is less than 1 therefore it could be concluded that the rd between calculated rps at stations with the lowest and highest rps is insignificant similar to previous distributions the difference between the average rps 5 to 100 years for canesm2 and canesm5 is also negligible i e less than 2 m3 s fig 11 shows the relative difference between the calculated apd using canesm2 and canesm5 models based on gm probability distribution for different rps besides the spatial distributions of each apd for all rps are provided in the appendix figure a7 based on the qualitative comparison of the results presented in the maps the rd values obtained from canesm2 and canesm5 and gm distribution for different rps at station 02pj030 are significantly different so that the rds for 50 and 100 are higher than 27 and 29 respectively the maximum absolute rd for rps of 5 10 20 50 and 100 are 19 75 21 67 23 54 27 04 and 29 21 so that the first two ones are related to station 02pc017 and the other ones are related to station 02pj030 for stations 02pj034 02pj030 02pl005 02ph014 and 02pk009 the apd calculated based on the canesm5 for all rps are higher than those calculated for canesm2 so that the existing plans need to be reconsidered because they are underestimated while for the stations 02pd010 02pc017 and 02 pb019 the apd calculated based on the canesm5 for all rps except for rp 5 at station 02 pb019 are lower than those calculated for canesm2 therefore the existing plans for these stations are overestimated and need to be reconsidered especially for station 02pc017 with the rd in the range of 19 7 24 89 the absolute rd between the calculated rps based on the canesm2 and canesm5 models using the gm distribution is in the range of 0 05 29 21 the maximum rd was observed at station 02pj030 29 21 for the 100 year rp where the rp was more than 2 times greater than the average rp i e 7 87 this however was not the maximum rp which was observed to occur at station 02 pb019 the rd between the rps calculated based on the canesm2 and canesm5 models at station 02 pb019 is less than 2 the most salient observation from figs 8 to 11 is that the canesm2 model does not yield larger rps than canesm5 at all stations for example the rps calculated using all distributions and the canesm2 model are lower than those calculated based on the canesm5 model at station 02pc017 while at stations 02pl005 02ph014 and 02pk009 the rps using the canesm2 model were exclusively higher than for the canesm5 model the calculated rps based on the canesm2 model are lower and or higher in all probability distributions for other stations fig 12 shows the distribution of the apd calculated using all probability distributions with the canesm2 and canesm5 models as well as their rds the range of rd between the estimated apd using wb ln lp3 and gm distributions were 32 12 38 48 22 89 19 32 25 69 12 41 and 24 89 29 21 respectively the average absolute difference between the estimated apd using wb ln lp3 and gm was 10 16 8 23 6 86 and 7 87 respectively in general the apd distribution calculated using all probability distributions with the canesm2 model is slightly larger than when computed using the canesm5 model 3 2 interannual average monthly flow fig 13 compares the canesm2 and canesm5 models when using the monthly mean discharge mmd for modeling in the southeast of the study area i e station 02pj030 there is a significant difference between the flow calculated using the canesm2 and canesm5 models yielding a range of absolute rd of 11 24 38 23 it is noteworthy that during the cold months of the year october to march and august the values estimated using the canesm5 model are greater than those of the canesm2 model while in the warm months april to july and september the opposite is true given that most floods occur in late spring and early summer in the study area the use of canesm2 data which shows larger values in these months is recommended for the southeast of the study area at station 02 pb019 which has the maximum mmd in the study area the mmd computed using the canesm5 model for five months i e february march september november and december is greater than that computed using the canesm2 with the rd in the range of 1 5 7 3 for the other months of the year the mmd computed using the canesm2 model is greater than when the canesm5 model is used with a rd in the range of 1 9 5 4 indeed no significant difference was observed between the mmd computed using the canesm2 and canesm5 models in different months and therefore the use of one model cannot be recommended over the other especially as climate change results in higher or lower mmd for the mmd presented in fig 13 more than 49 of mmd values calculated using the canems5 model are greater than those computed using the canems2 which indicates the insignificant difference between the average of the estimated mmd based on each climate change scenario the rd between the mmd computed using the canesm2 and canesm5 models was in the range of 38 9 100 for example in station 02pc017 the mmd related computed using the canems2 model was 3 47 m3 s while it was 6 97 m3 s for the canesm5 model due to the computed mmd values being close to the average of 17 m3 s the mentioned difference is not remarkable according to the provided results in fig 13 the maximum mmd calculated based on the canesm2 and canesm5 at all stations are not the same for stations 02 pb019 02pj034 and 02pl005 the maximum mmd calculated based on canesm2 and canesm5 are in the same month while for the other stations the maximum mmd calculated based on canesm2 and canesm5 are not the same for stations 02pc017 02ph011 and 02pk009 the maximum mmd calculated based on the canesm2 occurred one month before the maximum mmd calculated based on the canesm5 for station 02pd010 the maximum mmd calculated based on the canesm2 occurred one month after the maximum mmd calculated based on the canesm5 for stations 02pj030 and 02ph014 the maximum mmd calculated based on the canesm2 is related to july and april respectively while the maximum mmd calculated based on the canesm5 is related to october and february respectively according to these results it can be said that the trend of changes in different stations has occurred in different directions of the case study and it is not possible to provide a general conclusion that the maximum mmd of stations located in a certain direction of the case study will move from one month to other one or not by changing climate change model from canesm2 to canesm5 3 3 interannual average seasonality flow fig 14 compares the canesm2 and canesm5 models based on the seasonal mean discharge smd similar to the results for mmd in the southeast of the study area i e station 02pj030 smd values computed using the canesm2 model in both the spring and summer are larger than those of the canesm5 model with a rd of more than 25 and 9 respectively for the winter and autumn seasons the smd calculated based on the canesm5 model is larger than those based on the canesm2 model with a rd of more than 28 and 18 respectively in other regions of the study area similar to in the southeast calculated smd using the canesm5 model in autumn and winter is higher than when the canesm2 is considered while the opposite is true for other seasons indeed the results presented in this section confirm that the use of the canesm2 model is preferred for predicting flood events using climate change data because most of the floods in the study area are observed at the end of spring and the beginning of the summer at this time of year the flow discharge provided by canesm2 is larger than canesm5 providing a conservative assessment of flood risk potential the average absolute rd between smd computed using the canesm2 and canesm5 models for winter spring summer and autumn was 7 47 6 82 3 25 and 4 72 respectively indeed the maximum and minimum absolute rd in all stations was related to winter and summer seasons respectively a comparison of the canesm2 and canesm5 based on the provided results in fig 14 indicated that the maximum smd at all stations except 02pc017 and 02pj030 are in the same season for stations 02pc017 and 02pj030 the maximum smd based on the canesm2 is in the autumn and summer respectively while the maximum smd based on the canesm5 is in the summer and autumn respectively 3 4 interannual monthly peak discharge fig 15 shows the distribution of the mpd for all stations using boxplot analysis for station 02pd010 the minimum mpd found using the canesm2 model i e 10 79 m3 s was lower than that calculated using the canesm5 i e 11 22 m3 s a difference of about 4 the difference observed between the average and maximum mpd values computed using the canesm2 and canesm5 models was found to be almost zero in addition to the minimum and maximum values another important parameter identified in the boxplot is the interquartile range iqr defined as the difference between the third and first quartiles iqr q3 q1 the rd of the iqr for the canesm2 and canesm5 models was found to be greater than 5 given that the maximum and average mpd values for the canesm2 and canesm5 models are approximately equal and that the minimum and iqr for the canesm5 model are greater than for the canesm2 model it can be said that for mpd values in the iqr the canesm5 model provides a higher peak discharge while for mpd values lower than q1 and higher than q3 the canesm2 provides higher peak discharge for station 02pc017 the distribution of the mpd for the canesm2 and canesm5 models is entirely different the minimum mpd found using the canesm5 model i e 9 53 m3 s is 1 68 times higher than that of the canesm2 model i e 5 67 m3 s the rds between the minimum average maximum q1 q3 and iqr of the mpd for this station are more than 68 39 28 62 77 87 respectively indicating that the canesm5 model projected higher mpds it can be concluded that considering the average of all months the mpd estimated using the canesm5 model is higher than that of the canesm2 it should be noted that this statement is not valid for october where the mpd computed using the canesm2 model is more than double that of canesm5 as shown in figure a8 for station 02 pb019 which has the maximum mpd in the study area the minimum mpd computed using the canesm2 model is more than 4 greater than that of the canesm5 model when the maximum mpd value is considered the difference between models increases to more than 6 5 for the average mpd and q1 values the canesm5 model was found to yield higher values although the rd between it and the canesm2 model was less than 1 given that the mean value found using the canesm2 model is much lower than when the canesm5 model is considered it can be said that on average the mpd for the canesm2 model is lower than that of the canesm5 model but at maximum values the difference in mpd estimated based on canesm2 is significantly higher than those related to the canesm5 for station 02ph011 the difference between the minimum and maximum mpd using the canesm2 and canesm5 models is insignificant while the absolute rd of mpd between them is remarkably high i e 42 based on the boxplot for this station it can be concluded that the mpd for the canesm2 and canesm5 models are nearly equal for high mpd values but for the lower mpd values those computed using the canesm2 model are greater than those for the canesm5 model for station 02pj034 the differences between the maximum and q1 of the mpd values computed using the canesm2 and canesm5 models are insignificant it should be noted that although the maximum values in both boxplots for this station are equal the maximum value defined in the concept of the boxplot q3 1 5 iqr for canesm5 is significantly larger i e 11 78 m3 s than those for canesm2 i e 7 85 m3 s for station 02pj030 not only are the minimum q1 1 5 iqr and the maximum q3 1 5 iqr values of the box plot for the canesm2 model higher than those for the canesm5 model but also the iqr of the canesm2 model is larger than that of the canesm5 model it should be noted that the maximum mpd is associated with the use of the canesm5 model in general there is no significant difference between mpds computed using the canesm2 and canesm5 models in this station but their performance displayed monthly variation in this case for some months both models offer the same mpd values while in other months those of the canesm2 model or vice versa are larger than those of the canesm5 for station 02pl005 the difference between q1 q3 and the maximum for the canesm2 and canesm5 models is insignificant with the most remarkable difference being the minimum the boxplot shows that the minimum of the canesm2 model is more than 15 higher than that of the canesm5 model indeed it can be said that the difference between the mean mpd in two boxplots is less than 4 in general in most months the canesm2 model delivers a larger mpd than canesm5 for station 02ph014 the boxplot demonstrates that the canesm2 model yields higher values for all indices except for the maximum therefore it can be said that the canesm2 model generally offers larger mpd values than the canesm5 model although at the highest mpd value for this condition the mpd related to the canesm5 is 7 higher than that for canesm2 for station 02pk009 it can be seen from the boxplots that the minimum and iqr of the canesm2 model are lower than the canesm5 model while for all other indices the opposite is true in the months where the maximum observed mpd values occurred the canesm2 model yielded larger values than the canesm5 model while in the other months the values from one model may be higher or lower than another one the results for the different stations of the study are shown significant differences in mpd related when calculated using the canesm2 and canesm5 models based on the observed results selecting one model as optimistic or pessimistic was impossible instead the difference between each model should be examined according to the specific station under consideration and the project s objective fig 16 shows the rd between the mpd calculated using the canesm2 and canesm5 models based on the rd presented for january the canesm5 model yields a higher mpd compared to the canesm2 model in the stations located in the south southeast and center of the study area stations 02pj034 02pj030 02pl005 for other stations in the study area the mpd values determined using the canesm2 model are greater than those computed using the canesm5 model it should be noted that the highest absolute rd is observed in the southeast of the study area i e station 02pj030 in february the highest mpd was found at the northernmost station i e 02 pb019 in the easternmost station i e 02ph014 the only station located at the west of the study area i e 02pk009 and the northernmost station the maximum mpd are related to the canesm5 for other stations the mpds determined using the canesm2 model offer larger values than those computed using the canesm5 model for march results from the canesm2 and canesm5 models were practically the same as those previously discussed for january with the exception that for the westernmost station i e 02pk009 the canesm5 model also offered a higher mpd than the canesm2 model the rd for the two stations 02pj030 and 02pk009 was found to be more than 47 and 77 which indicates a significant increase in mpd when using the canesm5 model instead of canesm2 comparing the canesm2 and canesm5 models for the entire spring season shows that canesm5 yields greater mpd values than the canesm2 model in only four cases the northernmost station i e 02 pb019 with rd 18 in may the westernmost station i e 02pk009 with rd 13 in june as well as stations 02pd010 rd 1 49 and 02pc017 rd 2 36 in june and may respectively for july stations 02pk009 rd 28 28 02pj034 rd 21 82 and 02pc017 rd 28 72 were found to have higher mpd values when computed using the canesm5 model than when the canesm2 model was considered for the other stations the mpd found using the canesm2 model was greater than that found from the canesm5 model the average rd in stations where the mpd found using the canesm2 model was higher than from the canesm5 model was less than 18 maximum rd 27 5 for august two general cases were observed first the mpd values estimated were the same for both models stations 02pc017 02pb019 and 02pj034 or second the mpd values estimated from the canesm5 model were higher than those of the canesm2 model indeed it seems that the results from the canesm2 model for this month are underestimates and therefore do not accurately predict flood potential severity the use of the canesm2 model for august may expose the study area to unpredictable compensation risks resulting from inaccurate flood forecasting especially in the southeast of the study area i e station 02pj030 where the absolute rd is more than 74 the performance of the canesm2 and canesm5 models for calculating the mpd in september was very similar to july at stations with almost the same mpd by canesm2 and canesm5 in july i e 02pc017 02 pb019 and 02pj034 the canesm2 offered higher mpd than canesm5 for the other stations similar to july the canesm5 provided higher mpd compared to the canesm2 it should be noted that for september the absolute rd observed at the 02pc017 station where the mpd value from the canesm5 model was higher than the canesm2 model was more than 155 which is a significant amount at this same station and for november and december the projected mpd values using the canesm5 and canesm2 models were also found to have high absolute rd values of more than 277 and 114 respectively such a high rd for this station indicates that the selection of either the canesm5 or canesm2 models may yield very different results highlighting the need to modify the existing project designed based on the canesm2 the distribution of the mpd for all showed that there are significant differences between the mpd values computed by the canesm2 or canesm5 models figure a8 from fig 16 the rd range for all stations is 586 6 59 a general comparison of the mpd values found using either the canesm2 or canesm5 models fig 16 indicates that in about 39 of cases the mpd values determined using the canesm5 model are higher than those calculated using the canesm2 model while in about 50 of cases the opposite is true for the remaining 11 of cases the mpds determined using both models were found to be approximately equal the minimum average and maximum mpd values found using the canesm2 and canesm5 models for all stations and months were 4 48 35 01 161 92 and 4 29 35 1 151 09 respectively it can be seen that the minimum and mean mpd are almost equal in both cases but the maximum determined using the canesm5 model is about 7 lower than the value found using the canesm2 model a comparison of the mpd values determined using the canesm2 and canesm5 models at station 02 pb019 which has the maximum flow discharge indicates that the canesm2 model projects higher mpds than the canesm5 model for six months i e january march april june july and november for the remaining months of the year with the exception of august the mpd values determined using the canesm5 model were greater than those determined from the canesm2 model the rd for mpds calculated for all months at this station was in the range of 27 91 18 08 it should be noted that for the case where the mpd values determined using the canesm5 model were greater than those from the canesm2 model the calculated rd was significantly higher than the case when the when the mpd computed using the canesm2 model was greater for example in station 02pc017 the maximum rd is 59 46 while the minimum is 586 60 a significant difference between the computed mpd values for the canesm2 and canesm5 models was detected figure a8 it is not easy to achieve which model provides a more considerable mpd although there is a significant difference between the mpd values determined using the canesm2 and canesm5 models it could not be concluded in general terms which model provides higher or lower mpd in each station according to the provided results in fig 16 the maximum mpd calculated based on the canesm2 and canesm5 at all stations is not the same for stations 02pd010 02ph011 02pj034 and 02ph014 the maximum mpd calculated based on canesm2 and canesm5 are in the same month while for the other stations the maximum mpd calculated based on canesm2 and canesm5 are not the same for station 02pc017 the maximum mpd calculated based on the canesm2 occurred one month before the maximum mpd calculated based on the canesm5 for stations 02pb019 02pj030 02pl005 and 02pk009 the maximum mpd calculated based on the canesm2 is related to june june february and november respectively while the maximum mpd calculated based on the canesm5 is related to february august december june respectively 3 5 interannual seasonality peak flow fig 17 shows the distribution of the seasonal peak discharge spd for all stations based on this figure the spd in station 02pd010 is almost the same whether the canesm2 or canesm5 model is used for the winter months for the stations located in the south i e 02pl005 northeast i e 02ph014 and west i e 02pk009 of the study area the spd during the winter months computed using the canesm2 model were greater than those computed using the canesm5 model for these three stations rd during the winter months was found to be 9 2 12 27 and 20 3 respectively see fig 18 for the other stations and the winter season the spd found using the canesm5 model was greater than that found using the canesm2 model with a range of rd of 81 5 2 85 the absolute rd for station 02pj030 located at the north of the study area and having the highest spd was found to be more than 67 with the spd provided by the canesm5 model being 58 m3 s while that of the canesm2 model was 98 m3 s unlike winter the spd values determined using the canesm5 model in the summer are approximately 13 higher than the corresponding value determined using the canesm2 model fig 18 except for station 02pj030 in other stations the values determined using both the canesm2 and canesm5 models were found to be either the same or the canesm2 model gave a higher value stations 02pc017 02 pb019 and 02pj030 according to fig 18 the maximum rd i e rd 41 86 corresponds to station 02pj030 which also has the highest spd compared to the other stations given that most floods in the study area occur in late spring and early summer the significant differences between the computed spd values at this station will necessitate review and evaluation studies to be conducted for the summer the spd values determined from the canesm2 model were greater than those of the canesm5 model at only two stations stations 02pl005 rd 14 67 and 02pk009 rd 3 27 which are located in the south and west respectively of the study area the spd found using both the canesm2 and canesm5 models for station 02pj034 was almost the same while for other stations the canesm5 model yielded higher spd values than the canesm2 model the rd for these stations was in the range of 44 46 7 17 in which stations 02pc017 and 02pj030 with 44 46 and 31 38 have the highest absolute rd for the autumn the maximum absolute rd occurred at station 02pc017 and was found to be 28 26 this value is the highest rd in winter and summer while it is lower than the maximum absolute rd compared to the other seasons for stations 02pd010 rd 2 69 02pj030 rd 13 35 02ph014 rd 6 26 and 02pk009 rd 17 05 the spd provided by the canesm2 is higher than the canesm5 and for the others the canesm5 presented higher spd compared to the canesm2 based on fig 17 the maximum absolute rd was found at station 02pc017 with the spd value determined using the canesm5 model being 81 5 higher than that determined from the canesm2 model contour maps were shown in appendix figure a9 from fig 18 it can be observed that at all stations except 02pj034 either the canesm2 or canesm5 model will estimate a higher or lower spd value for all seasons identifying one model as superior to the other for all stations and seasons is impossible for station 02pj034 the spd values determined using the canesm5 model during the winter and autumn seasons were higher than that from the canesm2 model while for the other seasons the performance of the two models was practically identical given that the rd value is in the range the average rd for all the stations in winter summer spring and autumn is 13 66 5 22 10 24 and 2 1 respectively indeed it can be said that on average canesm5 offers higher spd than canesm2 in all seasons except spring although the excessive size of some rd values increases the uncertainty of finding by comparing the provided spd in each station it could be said that the canesm2 or canesm5 did not offer higher spd than canesm5 or canesm2 in all seasons therefore it could be concluded that the canesm2 and canesm5 could be selected based on the desired station and season as well as the needs of the current project a comparison of the canesm2 and canesm5 based on the provided results in fig 17 indicated that the maximum spd at five stations i e 02pd010 02pc017 02ph011 02pj034 02ph014 are in the same season for stations 02 pb019 02pj030 02pl005 and 02pk009 the maximum spd based on the canesm2 is in the spring spring winter and autumn respectively while the maximum spd based on the canesm5 is in the winter summer autumn and spring respectively 4 advantages limitations and future improvements owing to the importance of long term flood forecasting in hydrology the relative performance of the canesm2 and canesm5 models was evaluated in this study using flood frequency analysis ffa in terms of the amd and apd the interannual average monthly and seasonal flow discharge as well as the interannual monthly and seasonal peak flow given that the selection of particular probability distribution may introduce a level of uncertainty this study evaluated the performance of these two models using four different distributions in an effort to reduce uncertainty as much as possible four widely used probability distributions for the ffa namely the wb ln lp3 and gm distributions were employed to calculate the 5 to 100 year return periods each of these distributions has its own set of advantages and limitations when dealing with a particular type of data series for example the wb distribution has been known to provide reasonably accurate failure analysis and failure forecasting despite small sample sizes pasha et al 2006 balasubramanian and wu 2016 using the ln distribution modeling heavily tailed distributions is possible zeng and gonda 2014 the lp3 distribution can be used to extrapolate future flood events with a rp that is well beyond the observed flooding events griffis and stedinger 2009 the gm distribution has been extensively applied to extreme values analysis in many research areas such as geological environmental earth sciences etc kalaylioglu 2022 to verify the performance of each probability distribution three different tests including kolmogorov smirnov anderson darling and chi squared were applied the main advantage of the adt is its ability to test for deviations of observed data from different theoretical distributions jäntschi and bolboacă 2018 the kst statistic s distribution is independent of the underlying cumulative distribution function being examined which is an advantageous characteristic of this test despite the mentioned advantages for the kst it also has some disadvantages including 1 covering continuous distribution 2 this test is more sensitive near to distribution center than the tails and 3 it should be fully specified which is the main limitation of the kst ayuketang and joseph 2014 given that the use of any of these tests for data with different distributions may have strong or poor performance the simultaneous use of all three tests can decrease existing uncertainty due to the poor performance of the models zeng et al 2015 the current study used the gsgmdh soltani et al 2021b for runoff calculation based on the projected precipitations by canesm2 and canesm5 models since this model like all existing models does not have 100 accuracy there are induced errors within the model results due to the use of this model for both canesm2 and canesm5 the existing uncertainty related to the applied model is significantly reduced because the current uncertainty will work the same for both models other uncertainties may be due to the probability distributions used for ffa given that for both canesm2 and canesm5 four different distributions and three different tests were used simultaneously this uncertainty could be reduced to an acceptable level considering that in this study a machine learning based method has been used to calculate discharge flow in the future it is suggested that future work should consider the use of conceptual models such as the gr4j model for discharge flow calculation based on the canesm2 and canesm5 models and compared their results with the current study 5 conclusions in the current study the precipitation projected using the canesm2 and canesm5 models are applied in the newly developed machine learning based techniques known as generalized structure of group method of data handling gsgmdh to project the flow discharge in the future the projected flow discharges based on the canesm2 and canesm5 were compared in terms of flood frequency analysis ffa interannual average monthly flow interannual average seasonality flow interannual monthly peak flow and interannual seasonality peak flow the main results of the current study are as follows the cc results showed that the best results for precipitation calculation in the study area were achieved using the rcp4 5 and ssp245 scenarios for the canesm2 and canesm5 models respectively the ffa results indicated that the average rps calculated with the amd for the wb ln lp3 and gm distributions were 11 01 2 81 1 52 and 1 71 respectively indeed the average rps computed with the amd for all distributions using the canesm5 model were higher than those calculated by the canesm2 model when the rps were calculated by considering the apd and the wb ln lp3 and gm distributions their rds were 2 65 2 06 0 76 and 2 21 respectively indeed the average rps determined using the apd for all distributions except lp3 were higher when calculated using the canesm5 compared to the canesm2 for the mmd more than 49 of estimated values were more significant when computed using the canesm5 model than the canesm2 model indicating the insignificant difference between the average of the estimated mmd based on each climate change scenario the average rd between the mmd computed using the canesm2 and canesm5 models for all stations was 2 09 which indicates that the canesm5 model provided slightly higher values than the canesm2 the smd computed using the canesm2 model in both the summer i e 0 37 and spring i e 6 8 seasons was greater than when computed using the canesm5 model for the winter and autumn the average smd determined for all stations using the canesm5 model was greater than those of the canesm2 model with the rd being 7 48 and 4 72 respectively for the mpd and spd the distribution of flow discharges computed using the canesm2 and canesm5 models were almost identical and did not differ significantly although the provided maps show a significant difference in mpd and spd at different stations it is not easy to say which model provides a more considerable mdp in all conditions stations and months a general comparison of the canesm2 and canesm5 models indicates that the mpd values average of all months and stations calculated using the canesm5 model were 10 higher than those of the canesm2 model besides the general comparison of the canesm2 and canesm5 models indicates that the calculated spd average of all seasons and stations related to canesm5 is 5 higher than the one for canesm2 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge the support of the natural sciences and engineering research council of canada nserc discovery grant rgpin 2020 04583 and the fond de recherche du québec nature et technologies québec government b2x 315020 author contribution statements all authors discussed the results and contributed to the final manuscript h b supervised the project appendix 
2457,many current decomposition ensemble streamflow forecasting models have been incorrectly developed and their parameter solving methods are tedious which undermines their application to forecasting in the real world this study therefore developed a time varying stepwise decomposition ensemble tv sde framework for nonstationary and nonlinear streamflow series along with an optimization strategy combining a two stage calibration strategy with a particle swarm optimization algorithm namely tsc pso pso for parameter optimization to test the efficiency of the developed tv sde framework a tv sde model based on variational mode decomposition and support vector machine namely tv vmd svm was built and was compared with single models the monthly streamflow data from nine hydrological stations in china were used to assess the models results showed that 1 the time varying decomposition ensemble models were superior to the single models 2 the tsc pso pso optimization strategy outperformed the optimization strategy combining a two stage calibration strategy with a particle swarm optimization algorithm and cross validation algorithm for the tv sde framework and 3 the tv vmd svm model based on the tsc pso pso optimization strategy was a significant improvement over each single model and had the best streamflow forecasting performance among all models with the nash sutcliffe coefficient greater than 0 83 and willimot index greater than 0 79 the tv sde framework has potential to have a wide range of applications in the hydrology and water resources filed as well as other fields keywords time varying stepwise decomposition ensemble framework streamflow prediction variational mode decomposition support vector machine data availability data will be made available on request 1 introduction reliable streamflow forecasts play a crucial role in flood warning systems water planning and management and water distribution optimization fathian et al 2019 ni et al 2020 troin et al 2021 however due to the influence of climate change land surface changes and human activities streamflow series are non stationary and nonlinear and their forecast is challenging yaseen et al 2016 streamflow forecasting models can be broadly grouped into two categories physics driven models and data driven models wagena et al 2020 physics driven models help understand physical processes but require an extensive amount of hydrometeorological data and sophisticated mathematical tools gao et al 2020 on the other hand without considering the complex physical processes data driven models i e statistical models and machine learning ml models produce satisfactory forecasting results by fitting linear or nonlinear relationships between input and output variables adnan et al 2022 guo et al 2022 rahman et al 2020 compared to statistical models ml models do not need any explicit model structure and can better capture non linearity this is why ml models have wide applications in forecasting complex hydrologic systems barzegar et al 2017 lian et al 2022 however these models are not without limitations especially in forecasting nonstationary hydrological series graf et al 2019 in this regard numerous decomposition ensemble models which couple data decomposition methods and ml models have been widely applied in hydrology and have been shown to be more efficient than single ml models he et al 2020 wen et al 2019 however these decomposition ensemble models do not apply for real world forecasting because the overall decomposition based odb sampling technique is incorrectly developed du et al 2017 fang et al 2019 karthikeyan and kumar 2013 quilty and adamowski 2018 rahman et al 2020 zhang et al 2015 the odb sampling technique first decomposes the entire data into subseries using decomposition techniques and then divides each subseries into training and validation periods to build models the resulting subseries are calculated using some future information that is unavailable at that particular moment in a forecasting experiment leading to hindcasting experiments fang et al 2019 zhang et al 2015 zuo et al 2020 in recent years the karthikeyan nagesh kn karthikeyan and kumar 2013 and stepwise decomposition based sdb fang et al 2019 sampling techniques have been developed to address the aforementioned issue these techniques first divide the entire data into training and validation periods and then decompose the training period into subseries which strictly excludes future information and can be used for actual forecast studies by zhang et al 2015 and du et al 2017 showed that compared with decomposition ensemble models based on the kn technique the decomposition ensemble models based on the odb technique achieved higher prediction accuracy but such high prediction performance was not credible the reason was that the future information from the validation period was wrongly transmitted into the training of models in the odb technique in order to mitigate the impact of boundary effects on the prediction accuracy of the decomposition ensemble models tan et al 2018 and quilty and adamowski 2018 adopted two boundary effect processing approaches namely adaptive boundary effect and removal boundary effect to build an adaptive ensemble empirical mode decomposition eemd ann model and a wavelet data driven forecasting framework wddff based on the kn technique respectively studies have demonstrated that the adaptive eemd ann model and wddff are useful tools for real world streamflow forecasting ghaemi et al 2019 mouatadid et al 2019 rahman et al 2020 however removing the boundary affected coefficients in the wddff might result in the loss of valuable information for streamflow forecasting zuo et al 2020 to further improve the prediction accuracy of the decomposition ensemble models fang et al 2019 proposed the sdb sampling technique and compared it with odb and kn techniques in the development of decomposition ensemble models they showed that the forecasts by the models based on the sdb technique were better than those based on the kn technique however the nash sutcliffe efficiency coefficient of the hybrid model built by fang et al 2019 was usually less than 0 50 which was too low for actual forecasts in addition the emd method is not applicable in the sdb technique because the number of subseries changes with the length of the time series hence it is better to implement in depth study of decomposition ensemble models based on the sdb technique referred to as stepwise decomposition ensemble models hereafter for real world streamflow forecasting global change mainly climate change and human activities results in more prominent and complex non stationarity and nonlinearity of streamflow to better reflect the changing nature of streamflow model parameters should change over time because model parameters represent transient characteristics of streamflow xiong et al 2019 thus traditional time invariant parameter models for streamflow forecasting will be challenged time varying parameter models such as time varying autoregressive lanne and luoto 2017 time varying vector autoregressive koop and korobilis 2013 time varying heterogeneous autoregressive liu et al 2020 generalized autoregressive conditional heteroskedasticity bollerslev 1986 and stochastic volatility chan and grant 2016 models have been mainly applied in economics but have been shown to be effective for non stationary and nonlinear time series analysis and they can serve as a reference for the improvement of stepwise decomposition ensemble models however to the best of our knowledge the existing literature on time varying models has mainly focused on time varying time series models but no study seems to have introduced time varying parameters into decomposition ensemble forecasting models to explore the performance of time varying decomposition ensemble models further when the decomposition method and prediction model of the decomposition ensemble model are selected the model performance is mainly affected by input variables input and output of the models and the hyperparameters of the prediction model many studies li et al 2022 wang et al 2021 zhao et al 2017 have used only historical streamflow data as input variable to construct univariate models to predict streamflow and have achieved satisfactory prediction results using only historical streamflow data univariate models render prediction free from the tedium of collecting data on influencing variables and identifying model input variables that are useful for prediction from influencing variables lam and oshodi 2016 moreover forecasts by univariate models are better than by multivariate models when forecast steps are small chayama and hirata 2016 rana et al 2016 when building univariate decomposition ensemble models using only historical streamflow data input and output are mainly influenced by the decomposition number of the decomposition methods and the prediction variable for the previous days i e lag time the decomposition number of the emd and eemd is determined adaptively while that of the variational mode decomposition vmd method is determined by the center frequency huang et al 2019 zuo et al 2020 correlation coefficient and trial and error gao et al 2022 methods the time lags is determined by trial and error meng et al 2019 tan et al 2018 and pacf feng et al 2020 sun et al 2018 methods the optimal hyperparameters of the prediction model are calculated by optimization algorithms such as cross validation an et al 2007 genetic algorithm meng et al 2019 qi et al 2011 or particle swarm optimization pso wang et al 2020 however these algorithms tend to fall into local optimum and overfitting which affect the prediction performance of the model a two stage calibration strategy can solve this problem to a certain extent and improve the prediction accuracy of the model fang et al 2019 in the above studies input output and the hyperparameters of the decomposition ensemble model were determined separately by different methods which increased the model uncertainty and the calculation steps were tedious and complex which limited the application of the decomposition ensemble model in practice in general the current studies have the following shortcomings 1 most decomposition ensemble models are incorrectly developed and cannot be used in actual streamflow forecasting work the prediction accuracy of the few correctly developed decomposition ensemble models is not too high and needs to be improved 2 the time varying characteristics of streamflow series in changing environments lead to the low accuracy of time invariant parameter decomposition ensemble models however no researcher has yet developed and studied the time varying decomposition ensemble model 3 the input output and the hyperparameters of the decomposition ensemble model were determined separately by different methods increasing the model uncertainty and the calculation steps were tedious and complex limiting the application of the decomposition ensemble model in practice thus we developed a comprehensive and integrated univariate decomposition ensemble forecasting framework namely a time varying stepwise decomposition ensemble tv sde framework which can simultaneously solve for all unknown parameters including the decomposition number of decomposition method the input and output of the model and the hyperparameters of the prediction model with one objective function by one optimization algorithm the tv sde framework is updated stepwise as new streamflow data is added which adapts to the non stationary and nonlinear characteristics of streamflow the parameters of the tv sde framework are time varying overcoming the limitations of the decomposition method in the tv sde framework the parameters of prediction model are time varying and are thus regarded as local parameters while the decomposition number of the decomposition methods and time lags are constant and are thus regarded as global parameters to optimize the parameters of the tv sde framework we proposed an optimization strategy combining a nested two stage calibration tsc strategy with a particle swarm optimization pso algorithm namely tsc pso pso where the tsc pso and pso were used to obtain the optimal global parameter combination and the optimal local parameter combination respectively the contribution of this paper to hydrological field includes the following 1 development of a tv sde framework that has potential for practical forecasting with high accuracy which can simultaneously solve the problems of the decomposition number of decomposition method the input and output of the model and the hyperparameters of the machine learning model under one objective function 2 introduction of time varying parameters into the decomposition ensemble forecasting models to adapt to the non stationarity and nonlinearity of streamflow and to overcome the limitations of decomposition methods 3 the development of the tsc pso pso optimization algorithm for the tv sde framework 2 materials and methods 2 1 variational mode decomposition the vmd technique dragomiretskiy and zosso 2014 decomposes an original signal x t into different intrinsic mode functions imfs which are obtained by searching for the optimal solution of the following constrained variational problem 1 min i n i z e μ k ω k k 1 k t δ t j π t μ k t e j ω k t subject t o k 1 k μ k t x t 2 where μ k t μ 1 t μ 2 t μ k t and ω k t ω 1 t ω 2 t ω k t are the sets of all imfs and the corresponding central frequencies respectively and k represents the number of imfs the symbol is the convolution operator and δ t is the dirac distribution the augmented lagrange function is used to transform the variational problem in eq 1 into the unconstrained problem in eq 2 2 l μ k ω k λ α k 1 k t δ t j π t μ k t e j ω k t 2 x t k 1 k μ k t 2 2 2 λ t x t k 1 k μ k t where α and λ t are the quadratic penalty and lagrange multipliers respectively the saddle point of the unconstrained problem in eq 2 can be obtained by the alternate direction method of multipliers admm algorithm that solves convex optimization problems by breaking them into smaller pieces each of which is then easier to handle dimitrip 1982 the complete implementation processes of vmd can be summarized as follows step1 initialize μ k 1 ω ω k 1 λ 1 ω and n to 0 setp2 update μ k n 1 ω ω k n 1 and λ n 1 ω by eq 3 3 μ k n 1 ω x ω i k μ i n 1 ω i k μ i n ω 1 2 λ n ω 1 2 α ω ω k n 2 ω k n 1 0 ω μ k n 1 ω 2 d ω 0 μ k n 1 ω 2 d ω λ n 1 ω λ n ω τ x ω k μ k n 1 ω where n is the number of iterations τ indicates the noise tolerance and μ k n 1 ω λ n 1 ω and x ω are the fourier transforms of μ k n 1 t λ n 1 t and x t respectively the iterative procedure continues until the conditions in eq 4 are met 4 k μ k n 1 μ k n 2 2 μ k n 2 2 ε ε 0 where ε is discrimination accuracy setp3 obtain μ k t by the inverse fourier transform of μ k ω 2 2 support vector machine as an effective statistical machine learning method svm is mainly used for classification and regression cortes and vapnik 1995 this method can deal with nonlinear regression problems by using a nonlinear mapping function to map a sample space to a higher dimensional feature space because several studies cortes and vapnik 1995 pan et al 2020 yoon et al 2016 have introduced theoretical derivation of svm in detail and the library of svm is relatively mature the description of svm is omitted in this paper the library of svm libsvm chang and lin 2011 is widely used for developing svm models so it will be used in this study the generalization of svm is closely related to the selection of kernel functions and the determination of parameters rajaee et al 2019 among the existing kernel functions the radial basis function rbf kernel has fewer tuning parameters which influence the model complexity captures nonlinear relation between class labels and attributes and achieves good regression performance yaseen et al 2015 therefore the rbf was chosen as the kernel function in this paper the two most important parameters of svm are the regularization parameter c and the kernel parameter γ the larger the value of c is the easier it is to cause overfitting while smaller the value of c is the easier it is to under fit wu and ye 2016 the gaussian kernel parameter γ will affect the scope of the gaussian function and then affect the generalization performance of the svm the larger the γ value is the more the gaussian function acts near the support vector sample and the worse the classification effect of the unknown sample is in libsvm the cv algorithm is used to estimate the parameters of the svm model in l fold cv one divides the data into l subsets of approximately equal size and trains the classifier l times each time leaving out one of the subsets from training but using the omitted subset to compute the classification error 2 3 tv sde framework structure the performance of the tv sde framework can be reflected by that of the corresponding model in order to highlight the advantages of the tv sde framework itself we choose the widely used decomposition method and prediction model with moderate accuracy to build the decomposition ensemble model up to now there has been many time series decomposition methods applied to streamflow forecasting such as emd eemd singular spectrum analysis ssa discrete wavelet transformation dwt and vmd among these techniques the vmd method has been shown be most feasible for streamflow forecasting because it controls the central frequency aliasing and noise level xie et al 2019 zuo et al 2020 over the past two decades support vector machine svm has been popularized as a powerful ml model and has been found a large number of practical applications including time series forecasting adnan et al 2020 rajaee et al 2019 moreover many studies have reported good performance of svm for streamflow forecasting li et al 2019 tikhamarine et al 2020 therefore a tv sde model based on vmd and svm namely tv vmd svm was built to evaluate the efficiency of the developed tv sde framework the tv vmd svm model presented in fig 1 is further elaborated as follows 1 data partitioning the entire streamflow series q t t 1 2 n is split into training period q t t t 1 2 t and validation period q v t t t 1 t 2 n to prevent model overfitting the training period q t t t 1 2 t is further divided into calibration period q c t t 1 2 c and test period q t t t c 1 c 2 t 2 input and output variable selection because svm does not measure the importance of inputs internally the input selection is a very important step in developing an svm model rahman et al 2020 herein the steps for selecting inputs and outputs are as follows initialization k l 1 and the streamflow subset q t t 1 2 k is decomposed into k imfs s 1 t s 2 t s k t t 1 2 k using the vmd algorithm which is used to establish an svm model the last column element s 1 k s 2 k s kk of the imfs s 1 t s 2 t s k t t 1 2 k are extracted as the outputs of the svm model and the l column elements s i k l s i k l 1 s i k 1 i 1 2 k before last column element was used as input the above inputs and outputs are used to train the regularization parameter c and kernel parameter γ of the svm model the last l column elements s i k l 1 s i k l 2 s i k i 1 2 k of the imfs are used as predictors of the trained svm model to calculate the fitted value s 1 k 1 f s 2 k 1 f s k k 1 f and obtain the fitted value q f k 1 of q k 1 by summing the component fitted values s 1 k 1 f s 2 k 1 f s k k 1 f let k k 1 and repeat the above steps until k t 1 then the fitted values of calibration period q c f q f t l 2 l 3 c and the fitted values of the test period q t f q f t c 1 c 2 t can be obtained the above steps indicate that the parameter combinations c γ of the svm model is adaptively updated with the update of sample k therefore parameters c and γ are regarded as local parameters while parameters k and l are global parameters 3 model training and parameter optimization a tsc pso pso strategy combining the tsc strategy with the pso optimization algorithm is proposed to determine the optimal parameters of tv vmd svm model in this study the tsc pso pso strategy consists of internal optimization and external optimization and is summarized as follows the optimal local parameter combination c γ is obtained by solving the optimization model as eq 5 using the pso algorithm the optimization model takes the minimum root mean square error rmse as the objective function 5 c y minimize rmse where rmse 1 n i 1 k s ik s ik f 2 with each new sample a new svm model is established which means that as the sample is updated the rmse k of the optimal model needs to be updated to find out the new optimal parameter combination c γ the objective of the stepwise optimization of svm model is to obtain the forecast of calibration period q c f and the test period q t f that will be used for the optimization of global parameter combination k l therefore the optimization of parameter combination c γ is regarded internal optimization while that of parameter combination k l is called external optimization the optimal global parameter combination k l is acquired by the tsc pso algorithm the optimization model as eq 6 takes the minimum of the bigger rmse in the calibration and test periods as the objective function and is solved by the pso algorithm obviously the tsc pso algorithm finds out the optimal parameters based on the performance during the two stages namely the calibration and test periods which is different from the traditional algorithms based only on the performance during the training period 6 l k minimize max i m i z e rms e calibration r m s e test where rms e calibration 1 n t l 2 c q t q f t 2 and rms e test 1 n t c 1 t q t q f t 2 4 model forecasting and comparison initialize k t and then repeat the aforementioned process of input and output variable selection where the parameter combination k l is taken from the optimal values already obtained while c γ is obtained by solving the optimization model as eq 5 until k n 1 finally the forecast for the validation period q v f q f t t 1 t 2 n is obtained to analyze the influence of cv and pso algorithm on the time varying models i e tv svm and tv vmd svm this study compared the performance of the tv svm1 tv svm2 tv vmd svm1 and tv vmd svm2 models in which 1 and 2 represent the tsc pso cv and tsc pso pso strategy respectively as is known the seasonal autoregressive integrated moving average sarima model is the most commonly used model for modeling and forecasting monthly streamflow alonso brito et al 2021 mohammad 2015 therefore to further demonstrate the superiority of the tv sde framework the sarima model was compared with the tv vmd svm model in addition the single time invariant svm model namely svm and single time varying svm model namely tv svm were also compared to sum up this study compared the performance of the sarima svm tv svm1 tv svm2 tv vmd svm1 and tv vmd svm2 models because the sarima model belongs to the stochastic hydrological model there was no need to further divide the training period into calibration and test periods when establishing the sarima model 2 4 indicators for performance evaluation the forecasting models were evaluated by four commonly used error analysis indicators namely rmse in eq 8 nash sutcliffe coefficient nse in eq 9 willimot index wi willmott et al 2012 in eq 10 and peak difference metric pdiff moriasi et al 2007 in eq 11 the closer the values of nse and wi are to 1 and the closer the rmse and pdiff value is to 0 the better the performance of the model will be 8 rmse 1 n t 1 n q t q f t 2 9 nse 1 t 1 n q t q f t 2 t 1 n q t q 2 10 wi 1 t 1 n q f t q t 2 t 1 n q f t q q t q 2 11 pdiff max q t m a x q f t where q and q f denote the mean of the observed series and the forecast series respectively n denotes the length of the q f and was calculated by 12 n c l c a l i b r a t i o n p e r i o d t c t e s t p e r i o d n t v a l i d a t i o n p e r i o d furthermore diebold mariano dm test diebold and mariano 2002 was used to determine whether forecasts were significantly different if the absolute value of dm statistic is greater than two tailed critical value for the standard normal distribution there will be a significant difference between forecasts let e t and r t be the residuals for the two forecasts and we define the loss differential d t as follows 13 d t e t 2 r t 2 then the dm statistic is defined as follows 14 dm d γ 0 2 t 1 h 1 γ k n where d is the mean of d t and γ k is the autocovariance of d t at lag k it is generally sufficient to use the value h n 1 3 1 3 study areas and data the hei river basin yellow river basin and han river basin were selected as study areas monthly streamflow data from nine hydrological stations namely qilian ql wafang wf minhe mh lanzhou lz longmen lm huaxian hx baimasi bms xianyang xy and yangxian yx were selected to evaluate the proposed models the geographical location of the study areas and the hydrological stations are shown in fig 2 the hei river is the second largest inland river in northwest china and has a length of 168 km and its watershed has an area of 1506 km2 the catchment experiences a sub humid and temperate continental monsoon climate ql and wf stations are located on the upper reach of the hei river basin the yellow river as the second longest river in china is about 5 464 km long and covers a total drainage area of 752 443 km2 the yellow river flows through nine provinces of china mh and lz stations are located on the upper reach of the yellow river basin while lm hx bms and xy stations are situated on the middle reach of the yrb mh hx bms and xy stations are situated on the huangshui river wei river and yiluo river basins respectively which are sub basins of the yellow river basin while lz and lm stations are located on the mainstream of the yellow river basin the han river the largest tributary of the yangtze river has a total drainage area of 159 000 km2 xie et al 2019 it belongs to the east asian subtropical monsoon climate zone with a warm and humid climate and abundant water resources yx hydrological station is located in the upper reach of the han river basin the monthly streamflow data from all hydrological stations in hei river basin were acquired from hydrological yearbook of the hei river basin the monthly streamflow data of mh lz lm hx and bms hydrological stations in yellow river basin were acquired from the yellow river conservancy commission of the ministry of water resources the monthly streamflow data of xy and yx hydrological stations were collected from zuo et al 2020 a non stationary time series is a time series whose statistical properties change over time and thus a time series with a trend or seasonality is non stationary therefore monthly streamflow data are non stationary because they have seasonality to check the nonlinearity in streamflow the bds test brock et al 1996 was performed the null hypothesis of bds approach is that the data has linear dependency which implies that the data is linear results of bds test and statistical properties of streamflow are shown in table 1 it was concluded that all streamflow series are nonlinear at a specified significance level a 0 05 to avoid overfitting of the models the streamflow data was partitioned into calibration period about 60 of the total records test period about 20 of the total records and validation period about 20 of the total records which is shown in fig 3 statistical properties of the streamflow series are shown in table 2 as is clear generally similar statistical parameters were observed for calibration test and validation periods in addition to make the model training process converge faster the model input variables were normalized using eq 11 prior to model calibration barzegar et al 2019 11 q norm t q t q min q max q min where q norm t q max and q min are the normalized maximum and minimum values of the observed series q t respectively note that test and validation periods were normalized using the normalized indicators i e q min and q max of the calibration period 4 results for the time varying models parameters c and γ are the local parameters which are time varying therefore table 3 only presents the results of the global parameters k and l it can be seen that for different models and different stations there is no general rule of optimal parameters however results of the optimal parameters could provide a reference for the range of parameters of the model table 4 presents the evaluation criteria of the all models for streamflow from all stations throughout the periods the performance indicators of the test period for the sarima models were actually for the entire training period in the calibration period the tv svm2 models were the optimal models among all models for all stations however as obtained by the tsc optimization strategy l was different for different models and different stations as a result the length of the streamflow series n involved in calculating the performance indicators of the models in the calibration period was different for different models and different stations therefore the analysis for the training period focused on the performance comparison for the test period not for the calibration period in the test period we found that the results of rmse and nse for the evaluation of the model fit performance at individual stations are not consistent with those of wi for example when comparing the fit results of sarima and svm models at wf stations in the test period it was found that the rmse and nse values of the svm model were smaller and larger than those of sarima model respectively but its wi was smaller than that of sarima model this indicates that the svm model had a better overall fit performance while the saima model better captured the variance of streamflow observations therefore to summarize the conclusions more conveniently comparisons between models were based more on the values of rmse and nse than on wi if there are differences between error indicators comparison between single and decomposition ensemble models showed that the decomposition ensemble model was superior to the single model when comparing the single models the optimal model was the time invariant single svm model comparison between tsc pso pso and tsc pso cv algorithms showed that the tsc pso cv algorithm was superior to the tsc pso pso algorithm for all stations except hx station for the time varying single models i e tv svm1 and tv svm2 models while the tsc pso pso algorithm outperformed the tsc pso cv algorithm for all stations except mh lz and yx stations for the time varying decomposition ensemble framework i e tv vmd svm1 and tv vmd svm2 models to better compare the forecasting performance of the models fig 4 shows the taylor diagrams which present a comparison of the streamflow observations with predictions from the six models in terms of their correlation coefficient centered root mean square difference and normalized standard deviations taylor 2001 in fig 4 the closer the model point is to the observation point the better the model prediction performance is considering the model forecasting performance metrics presented in table 4 and fig 4 comprehensively we can conclude the following 1 when comparing the svm models with the optimal models of the two tv svm models i e tv svm1 and tv svm2 models the optimal single model was found to be the tv svm like model it indicates that the time varying single models are superior to the time invariant single models 2 compared to four single models the time varying decomposition ensemble models produced larger values of nse and wi and smaller rmse values during the validation period and were closer to with the streamflow observations this indicates that the time varying decomposition ensemble models outperform the single models 3 when comparing the tv svm1 models and the tv svm2 models it was found that the tv svm1 models outperformed the tv svm2 models at ql wf mh lm hx bms xy and yx stations while the opposite was true at lz station this indicates that the tsc pso cv optimization algorithm outperforms the tsc pso pso algorithm for the time varying single models when comparing the tv vmd svm1 and tv vmd svm2 models it was found that the tv vmd svm2 models outperformed the tv vmd svm1 models at all stations this indicates that the tsc pso pso optimization algorithm outperforms the tsc pso cv algorithm for the time varying decomposition ensemble framework 4 both the evaluation criteria in bold in the validation period and the taylor diagrams demonstrate that the tv vmd svm2 models had the best forecasting performance for streamflow at all stations among all six models moreover for the streamflow forecasting at all stations the nash sutcliffe coefficient and willimot index of the tv vmd svm2 models were larger than 0 83 and 0 79 respectively furthermore the diebold mariano dm test diebold and mariano 1995 was used to test the significance level which indicated that tv vmd svm2 model is more accurate than other models as shown in table 4 the p values of the dm test between tv vmd svm2 models and tv vmd svm1 models were larger than 0 95 at the ql wf lz hx xy and yx stations while those were smaller than 0 95 at the mh lm and bms stations which indicates that at the ql wf lz hx xy and yx stations the improvement of the tv vmd svm2 models over the tv vmd svm1 model was significant but at the mh lm and bms stations it was not significant however the p values of the dm test between tv vmd svm2 models and all single models i e sarima svm tvsvm1 and tvsvm2 were larger than 0 95 at all stations which indicated that at all stations the improvement of the tv vmd svm2 models over each single model was significant to better compare the forecasting results of the models fig 5 and fig 6 shows scatter plots and violin plots of observed and predicted streamflow from the six models at nine stations in the validation period respectively for yx station the forecasted results of the tv svm2 model showed a large variability with the observations and predictions of other models therefore the violin plots of the observations and predictions of other models except the tv svm2 model are placed in the small plot of the results plot at yx station fig 6 no matter the four single models i e sarima svm tv svm1 and tv svm2 models or the two time varying decomposition ensemble models i e tv vmd svm1 and tv vmd svm2 models the scatter distribution diagram and the fit line in fig 5 and the distribution in fig 6 were relatively similar except for the prediction results of the tv svm2 model at the lz and yx stations this indicates that the four single models produced similar forecasting performance and the two time varying decomposition ensemble models showed the similar forecasting performance for streamflow compared to the four single models the fit lines of the time varying decomposition ensemble models were closer to the 1 1 line fig 5 and the distributions of their predictions especially the outliers among them were most similar to that of observations fig 6 these results indicate that the time varying decomposition ensemble models had remarkably higher forecasting performance than the single models especially for extreme values however it also can be seen from fig 5 that the fitted line of the time varying decomposition ensemble models was close to the 1 1 line in the low and medium values parts but farther apart in the high values part it indicates that the time varying decomposition ensemble models considerably performed well for low and medium streamflow but they had difficulty in forecasting the high values of streamflow to further quantify the prediction accuracy of all models for high value part of streamflow table 5 and table 6 show the error evaluation metrics of all models for the largest streamflow extreme and peak streamflow respectively the largest streamflow extremes are the streamflow values that exceed 95th percentile of the streamflow series as can be seen from table 5 among all models the tv vmd svm1 models had the smallest rmse values for the largest streamflow extreme forecast at ql lz and bms stations while the tv vmd svm2 models had the smallest rmse for the largest streamflow extreme prediction at wf lm mh hx xy and yx stations this result indicated that tv vmd svm1 models achieved the best forecasting performance for the largest streamflow extreme at ql lz and bms stations while the tv vmd svm2 models achieved the best forecasting performance for the largest streamflow extreme at wf lm mh hx xy and yx stations as shown in table 6 the tv vmd svm1 models had the optimal pdiff values for the peak streamflow forecast at ql lz mh hx bms and xy stations while the tv vmd svm2 models had the optimal pdiff values for the peak streamflow forecast at wf lm and yx stations this result indicated that the tv vmd svm1 models had the best forecasting performance for the peak streamflow at ql lz mh hx bms and xy stations while the tv vmd svm2 models had the best forecasting performance for peak streamflow at wf lm and yx stations in conclusion among all models all optimal models for forecasting the high value part of streamflow at all stations were the time varying decomposition ensemble models i e tv vmd svm1 and tv vmd svm2 models 5 discussion 5 1 reasons for high precision of the tv sde framework the reasons for the superior forecasting performance of tv sde framework can be summarized as follows 1 stepwise decomposition ensemble framework 2 time varying parameters and 3 the tsc pso pso algorithm the stepwise decomposition ensemble framework decomposes the time series into simple components that are easy to describe and have specific meanings so as to grasp the hidden influencing factors of the data reduce the modeling difficulty and improve the model prediction performance moreover stepwise decomposition ensemble framework strictly excludes future streamflow data and can be used for actual forecast which is consistent with the findings of the studies he et al 2022 meng et al 2021 when new streamflow data is added the parameters of time varying models are updated it means that the time varying models could respond well to the addition of new information or changes of influencing factors furthermore this response is self adaptive and in real time therefore the time varying models represent the characteristics of instantaneous streamflow series in this study a tsc pso pso algorithm combining a tsc strategy with pso algorithm is proposed to find out the optimal parameter of the tv sde framework the tsc pso pso algorithm is based on the performance during the two stages namely the calibration and test periods which is different from traditional algorithms which based only on the performance in the training period therefore the tsc pso pso algorithm can prevent model overfitting to further explore the effectiveness of a tsc strategy for tv sde framework the tsc pso pso algorithm and tsc pso cv algorithm were compared although the prediction results of all models for the high value part of streamflow indicated that both the tsc pso pso algorithm and the tsc pso cv algorithm performed optimally for the tv sde framework the prediction results for the entire validation period indicated that the tsc pso pso algorithm outperformed tsc pso cv algorithm for the tv sde framework 5 2 generalization performance of tv sde framework although in the tv sde framework the decomposition must be repeatedly performed when new streamflow data is added the parameters of the svm models are updated this means that when new data is gradually added to streamflow data the number of decompositions k does not have to be constant therefore the emd method can be used in the tv sde framework for actual forecasting practice furthermore if emd method was used the optimal parameter combination k l c γ would be reduced to l c γ it indicates that the tv sde framework overcomes the limitations that the emd is inapplicable to real world streamflow forecasting fang et al 2019 similarly wa ssa and other decomposition methods can also be used in the tv sde framework to build more models for the actual forecasting practice more ml or time series models can also be used in the tv sde framework to build more forecasting models besides the pso and cv optimization algorithms selected in this study other novel and effective optimization algorithms can also be used to construct hybrid optimization algorithms based on the tsc optimization strategy to optimize the parameters of the tv sde framework moreover since the tv sde framework is time varying it is reasonable to believe that this framework can be applied to the prediction of other hydrological variables with non stationary nonlinearity such as rainfall groundwater etc in summary the tv sde forecasting framework has a good generalization performance 5 3 limitations of tv sde framework in this study we constructed the inputs to the tv sde framework based on historical streamflow data and did not consider the influence of many exogenous variables such as precipitation temperature evapotranspiration and land on streamflow moreover we did not consider the relationship between multiple stations when developing the tv sde framework resulting in this framework only obtaining streamflow prediction results for a single hydrological station at a time therefore future research can try to further improve the prediction performance of the tv sde framework by adding the effects of many exogenous variables on streamflow and the relationship between multiple stations to this framework when establishing the decomposition ensemble model the boundary effect degrades the forecasting performance in this study the tv sde framework adopted the improved sdb sampling method to adapt to the boundary effect based on the sdb sampling method xu et al 2022 proposed a stepwise decomposition integration prediction considering boundary correction framework and the results showed that the boundary correction can further enhance the forecasting accuracy of stepwise decomposition integration prediction framework therefore future studies could attempt to improve the tv sde framework by correcting the boundary effect although the tv sde framework has relatively high complexity due to the time varying parameters and sampling methods it makes a significant improvement over each single model however it is still necessary to develop a forecasting framework with lower complexity and higher accuracy 6 conclusions for addressing the pitfalls and errors of the traditional decomposition ensemble model for the real world streamflow forecasting a novel decomposition ensemble framework namely time varying stepwise decomposition ensemble tv sde framework was developed in this study the tv sde framework which can simultaneously solve for all unknown parameters including the decomposition number of decomposition method the input and output of the model and the hyperparameters of the prediction model with one objective function by one optimization algorithm moreover the tv sde framework are time varying and can be self adaptively updated as new streamflow data is added in addition to avoid over fitting and enhance the generalization ability of the framework the training period is further divided into calibration and test periods and a tsc pso pso optimization strategy is proposed to optimize model parameters to evaluate the performance of tv sde framework the tv vmd svm1 tv vmd svm2 tv svm1 tv svm2 svm and sarima models were compared for monthly streamflow data from nine hydrological stations in china the study results indicate that 1 the time varying decomposition ensemble models outperform the single models 2 the tsc pso pso optimization algorithm outperforms the tsc pso cv algorithm for the time varying decomposition ensemble framework and 3 the tv vmd svm2 models makes a significant improvement over each single model and have the best forecasting performance for streamflow at all stations among all six models with the nash sutcliffe coefficient greater than 0 83 and willimot index greater than 0 79 and for the streamflow forecasting at all stations the nash sutcliffe coefficient and willimot index of the tv vmd svm2 models are larger than 0 83 and 0 79 respectively overall this study showed that the tv sde framework is useful for highly nonstationary and nonlinear monthly streamflow series forecasting in actual practice in addition the tv sde framework is expected to have a wide range of applications in the hydrology and water resources as well as potentially other fields this study only used the monthly streamflow series that are characterized by non stationarity due to the existence of seasonal and periodic patterns to test the forecasting performance of the tv sde framework it is necessary to use other nonstationary and nonlinear hydrological time series which exhibit trend jump and chaotic patterns to validate the performance of the framework in future studies guo et al 2021 in addition this study only analyzes and builds the tv sde framework from the perspective of the time domain lacking a deeper dive into the frequency domain it is suggested that further studies explore more valuable information from the perspective of frequency domain to build superior prediction models for example we can forecast the periodic series by frequency domain approaches from koopmans 1974 which have been used successfully for space weather reikard 2011 and other types of periodic series schlink et al 1997 we can also develop a combined model using both frequency and time domain methods in two stages using a frequency domain algorithm to estimate and forecast streamflow in the first stage and using the forecasts as inputs in time domain model in the second stage reikard 2013 credit authorship contribution statement tianli guo conceptualization methodology software visualization writing original draft songbai song conceptualization data curation methodology supervision validation writing review editing vijay p singh writing review editing ting wei writing review editing te zhang visualization xin liu visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the authors acknowledge the grant support from the national natural science foundation in china grand number 52079110 the authors wish to thank the respected editor and anonymous reviewers for their valuable comments and insightful suggestions that improved the quality of this manuscript data data in hei river basin were acquired from hydrological yearbook of the hei river basin data of mh lz lm hx and bms hydrological stations in yellow river basin were acquired from the yellow river conservancy commission of the ministry of water resources http www yrcc gov cn data of xy and yx hydrological stations were collected from zuo et al 2020 
2457,many current decomposition ensemble streamflow forecasting models have been incorrectly developed and their parameter solving methods are tedious which undermines their application to forecasting in the real world this study therefore developed a time varying stepwise decomposition ensemble tv sde framework for nonstationary and nonlinear streamflow series along with an optimization strategy combining a two stage calibration strategy with a particle swarm optimization algorithm namely tsc pso pso for parameter optimization to test the efficiency of the developed tv sde framework a tv sde model based on variational mode decomposition and support vector machine namely tv vmd svm was built and was compared with single models the monthly streamflow data from nine hydrological stations in china were used to assess the models results showed that 1 the time varying decomposition ensemble models were superior to the single models 2 the tsc pso pso optimization strategy outperformed the optimization strategy combining a two stage calibration strategy with a particle swarm optimization algorithm and cross validation algorithm for the tv sde framework and 3 the tv vmd svm model based on the tsc pso pso optimization strategy was a significant improvement over each single model and had the best streamflow forecasting performance among all models with the nash sutcliffe coefficient greater than 0 83 and willimot index greater than 0 79 the tv sde framework has potential to have a wide range of applications in the hydrology and water resources filed as well as other fields keywords time varying stepwise decomposition ensemble framework streamflow prediction variational mode decomposition support vector machine data availability data will be made available on request 1 introduction reliable streamflow forecasts play a crucial role in flood warning systems water planning and management and water distribution optimization fathian et al 2019 ni et al 2020 troin et al 2021 however due to the influence of climate change land surface changes and human activities streamflow series are non stationary and nonlinear and their forecast is challenging yaseen et al 2016 streamflow forecasting models can be broadly grouped into two categories physics driven models and data driven models wagena et al 2020 physics driven models help understand physical processes but require an extensive amount of hydrometeorological data and sophisticated mathematical tools gao et al 2020 on the other hand without considering the complex physical processes data driven models i e statistical models and machine learning ml models produce satisfactory forecasting results by fitting linear or nonlinear relationships between input and output variables adnan et al 2022 guo et al 2022 rahman et al 2020 compared to statistical models ml models do not need any explicit model structure and can better capture non linearity this is why ml models have wide applications in forecasting complex hydrologic systems barzegar et al 2017 lian et al 2022 however these models are not without limitations especially in forecasting nonstationary hydrological series graf et al 2019 in this regard numerous decomposition ensemble models which couple data decomposition methods and ml models have been widely applied in hydrology and have been shown to be more efficient than single ml models he et al 2020 wen et al 2019 however these decomposition ensemble models do not apply for real world forecasting because the overall decomposition based odb sampling technique is incorrectly developed du et al 2017 fang et al 2019 karthikeyan and kumar 2013 quilty and adamowski 2018 rahman et al 2020 zhang et al 2015 the odb sampling technique first decomposes the entire data into subseries using decomposition techniques and then divides each subseries into training and validation periods to build models the resulting subseries are calculated using some future information that is unavailable at that particular moment in a forecasting experiment leading to hindcasting experiments fang et al 2019 zhang et al 2015 zuo et al 2020 in recent years the karthikeyan nagesh kn karthikeyan and kumar 2013 and stepwise decomposition based sdb fang et al 2019 sampling techniques have been developed to address the aforementioned issue these techniques first divide the entire data into training and validation periods and then decompose the training period into subseries which strictly excludes future information and can be used for actual forecast studies by zhang et al 2015 and du et al 2017 showed that compared with decomposition ensemble models based on the kn technique the decomposition ensemble models based on the odb technique achieved higher prediction accuracy but such high prediction performance was not credible the reason was that the future information from the validation period was wrongly transmitted into the training of models in the odb technique in order to mitigate the impact of boundary effects on the prediction accuracy of the decomposition ensemble models tan et al 2018 and quilty and adamowski 2018 adopted two boundary effect processing approaches namely adaptive boundary effect and removal boundary effect to build an adaptive ensemble empirical mode decomposition eemd ann model and a wavelet data driven forecasting framework wddff based on the kn technique respectively studies have demonstrated that the adaptive eemd ann model and wddff are useful tools for real world streamflow forecasting ghaemi et al 2019 mouatadid et al 2019 rahman et al 2020 however removing the boundary affected coefficients in the wddff might result in the loss of valuable information for streamflow forecasting zuo et al 2020 to further improve the prediction accuracy of the decomposition ensemble models fang et al 2019 proposed the sdb sampling technique and compared it with odb and kn techniques in the development of decomposition ensemble models they showed that the forecasts by the models based on the sdb technique were better than those based on the kn technique however the nash sutcliffe efficiency coefficient of the hybrid model built by fang et al 2019 was usually less than 0 50 which was too low for actual forecasts in addition the emd method is not applicable in the sdb technique because the number of subseries changes with the length of the time series hence it is better to implement in depth study of decomposition ensemble models based on the sdb technique referred to as stepwise decomposition ensemble models hereafter for real world streamflow forecasting global change mainly climate change and human activities results in more prominent and complex non stationarity and nonlinearity of streamflow to better reflect the changing nature of streamflow model parameters should change over time because model parameters represent transient characteristics of streamflow xiong et al 2019 thus traditional time invariant parameter models for streamflow forecasting will be challenged time varying parameter models such as time varying autoregressive lanne and luoto 2017 time varying vector autoregressive koop and korobilis 2013 time varying heterogeneous autoregressive liu et al 2020 generalized autoregressive conditional heteroskedasticity bollerslev 1986 and stochastic volatility chan and grant 2016 models have been mainly applied in economics but have been shown to be effective for non stationary and nonlinear time series analysis and they can serve as a reference for the improvement of stepwise decomposition ensemble models however to the best of our knowledge the existing literature on time varying models has mainly focused on time varying time series models but no study seems to have introduced time varying parameters into decomposition ensemble forecasting models to explore the performance of time varying decomposition ensemble models further when the decomposition method and prediction model of the decomposition ensemble model are selected the model performance is mainly affected by input variables input and output of the models and the hyperparameters of the prediction model many studies li et al 2022 wang et al 2021 zhao et al 2017 have used only historical streamflow data as input variable to construct univariate models to predict streamflow and have achieved satisfactory prediction results using only historical streamflow data univariate models render prediction free from the tedium of collecting data on influencing variables and identifying model input variables that are useful for prediction from influencing variables lam and oshodi 2016 moreover forecasts by univariate models are better than by multivariate models when forecast steps are small chayama and hirata 2016 rana et al 2016 when building univariate decomposition ensemble models using only historical streamflow data input and output are mainly influenced by the decomposition number of the decomposition methods and the prediction variable for the previous days i e lag time the decomposition number of the emd and eemd is determined adaptively while that of the variational mode decomposition vmd method is determined by the center frequency huang et al 2019 zuo et al 2020 correlation coefficient and trial and error gao et al 2022 methods the time lags is determined by trial and error meng et al 2019 tan et al 2018 and pacf feng et al 2020 sun et al 2018 methods the optimal hyperparameters of the prediction model are calculated by optimization algorithms such as cross validation an et al 2007 genetic algorithm meng et al 2019 qi et al 2011 or particle swarm optimization pso wang et al 2020 however these algorithms tend to fall into local optimum and overfitting which affect the prediction performance of the model a two stage calibration strategy can solve this problem to a certain extent and improve the prediction accuracy of the model fang et al 2019 in the above studies input output and the hyperparameters of the decomposition ensemble model were determined separately by different methods which increased the model uncertainty and the calculation steps were tedious and complex which limited the application of the decomposition ensemble model in practice in general the current studies have the following shortcomings 1 most decomposition ensemble models are incorrectly developed and cannot be used in actual streamflow forecasting work the prediction accuracy of the few correctly developed decomposition ensemble models is not too high and needs to be improved 2 the time varying characteristics of streamflow series in changing environments lead to the low accuracy of time invariant parameter decomposition ensemble models however no researcher has yet developed and studied the time varying decomposition ensemble model 3 the input output and the hyperparameters of the decomposition ensemble model were determined separately by different methods increasing the model uncertainty and the calculation steps were tedious and complex limiting the application of the decomposition ensemble model in practice thus we developed a comprehensive and integrated univariate decomposition ensemble forecasting framework namely a time varying stepwise decomposition ensemble tv sde framework which can simultaneously solve for all unknown parameters including the decomposition number of decomposition method the input and output of the model and the hyperparameters of the prediction model with one objective function by one optimization algorithm the tv sde framework is updated stepwise as new streamflow data is added which adapts to the non stationary and nonlinear characteristics of streamflow the parameters of the tv sde framework are time varying overcoming the limitations of the decomposition method in the tv sde framework the parameters of prediction model are time varying and are thus regarded as local parameters while the decomposition number of the decomposition methods and time lags are constant and are thus regarded as global parameters to optimize the parameters of the tv sde framework we proposed an optimization strategy combining a nested two stage calibration tsc strategy with a particle swarm optimization pso algorithm namely tsc pso pso where the tsc pso and pso were used to obtain the optimal global parameter combination and the optimal local parameter combination respectively the contribution of this paper to hydrological field includes the following 1 development of a tv sde framework that has potential for practical forecasting with high accuracy which can simultaneously solve the problems of the decomposition number of decomposition method the input and output of the model and the hyperparameters of the machine learning model under one objective function 2 introduction of time varying parameters into the decomposition ensemble forecasting models to adapt to the non stationarity and nonlinearity of streamflow and to overcome the limitations of decomposition methods 3 the development of the tsc pso pso optimization algorithm for the tv sde framework 2 materials and methods 2 1 variational mode decomposition the vmd technique dragomiretskiy and zosso 2014 decomposes an original signal x t into different intrinsic mode functions imfs which are obtained by searching for the optimal solution of the following constrained variational problem 1 min i n i z e μ k ω k k 1 k t δ t j π t μ k t e j ω k t subject t o k 1 k μ k t x t 2 where μ k t μ 1 t μ 2 t μ k t and ω k t ω 1 t ω 2 t ω k t are the sets of all imfs and the corresponding central frequencies respectively and k represents the number of imfs the symbol is the convolution operator and δ t is the dirac distribution the augmented lagrange function is used to transform the variational problem in eq 1 into the unconstrained problem in eq 2 2 l μ k ω k λ α k 1 k t δ t j π t μ k t e j ω k t 2 x t k 1 k μ k t 2 2 2 λ t x t k 1 k μ k t where α and λ t are the quadratic penalty and lagrange multipliers respectively the saddle point of the unconstrained problem in eq 2 can be obtained by the alternate direction method of multipliers admm algorithm that solves convex optimization problems by breaking them into smaller pieces each of which is then easier to handle dimitrip 1982 the complete implementation processes of vmd can be summarized as follows step1 initialize μ k 1 ω ω k 1 λ 1 ω and n to 0 setp2 update μ k n 1 ω ω k n 1 and λ n 1 ω by eq 3 3 μ k n 1 ω x ω i k μ i n 1 ω i k μ i n ω 1 2 λ n ω 1 2 α ω ω k n 2 ω k n 1 0 ω μ k n 1 ω 2 d ω 0 μ k n 1 ω 2 d ω λ n 1 ω λ n ω τ x ω k μ k n 1 ω where n is the number of iterations τ indicates the noise tolerance and μ k n 1 ω λ n 1 ω and x ω are the fourier transforms of μ k n 1 t λ n 1 t and x t respectively the iterative procedure continues until the conditions in eq 4 are met 4 k μ k n 1 μ k n 2 2 μ k n 2 2 ε ε 0 where ε is discrimination accuracy setp3 obtain μ k t by the inverse fourier transform of μ k ω 2 2 support vector machine as an effective statistical machine learning method svm is mainly used for classification and regression cortes and vapnik 1995 this method can deal with nonlinear regression problems by using a nonlinear mapping function to map a sample space to a higher dimensional feature space because several studies cortes and vapnik 1995 pan et al 2020 yoon et al 2016 have introduced theoretical derivation of svm in detail and the library of svm is relatively mature the description of svm is omitted in this paper the library of svm libsvm chang and lin 2011 is widely used for developing svm models so it will be used in this study the generalization of svm is closely related to the selection of kernel functions and the determination of parameters rajaee et al 2019 among the existing kernel functions the radial basis function rbf kernel has fewer tuning parameters which influence the model complexity captures nonlinear relation between class labels and attributes and achieves good regression performance yaseen et al 2015 therefore the rbf was chosen as the kernel function in this paper the two most important parameters of svm are the regularization parameter c and the kernel parameter γ the larger the value of c is the easier it is to cause overfitting while smaller the value of c is the easier it is to under fit wu and ye 2016 the gaussian kernel parameter γ will affect the scope of the gaussian function and then affect the generalization performance of the svm the larger the γ value is the more the gaussian function acts near the support vector sample and the worse the classification effect of the unknown sample is in libsvm the cv algorithm is used to estimate the parameters of the svm model in l fold cv one divides the data into l subsets of approximately equal size and trains the classifier l times each time leaving out one of the subsets from training but using the omitted subset to compute the classification error 2 3 tv sde framework structure the performance of the tv sde framework can be reflected by that of the corresponding model in order to highlight the advantages of the tv sde framework itself we choose the widely used decomposition method and prediction model with moderate accuracy to build the decomposition ensemble model up to now there has been many time series decomposition methods applied to streamflow forecasting such as emd eemd singular spectrum analysis ssa discrete wavelet transformation dwt and vmd among these techniques the vmd method has been shown be most feasible for streamflow forecasting because it controls the central frequency aliasing and noise level xie et al 2019 zuo et al 2020 over the past two decades support vector machine svm has been popularized as a powerful ml model and has been found a large number of practical applications including time series forecasting adnan et al 2020 rajaee et al 2019 moreover many studies have reported good performance of svm for streamflow forecasting li et al 2019 tikhamarine et al 2020 therefore a tv sde model based on vmd and svm namely tv vmd svm was built to evaluate the efficiency of the developed tv sde framework the tv vmd svm model presented in fig 1 is further elaborated as follows 1 data partitioning the entire streamflow series q t t 1 2 n is split into training period q t t t 1 2 t and validation period q v t t t 1 t 2 n to prevent model overfitting the training period q t t t 1 2 t is further divided into calibration period q c t t 1 2 c and test period q t t t c 1 c 2 t 2 input and output variable selection because svm does not measure the importance of inputs internally the input selection is a very important step in developing an svm model rahman et al 2020 herein the steps for selecting inputs and outputs are as follows initialization k l 1 and the streamflow subset q t t 1 2 k is decomposed into k imfs s 1 t s 2 t s k t t 1 2 k using the vmd algorithm which is used to establish an svm model the last column element s 1 k s 2 k s kk of the imfs s 1 t s 2 t s k t t 1 2 k are extracted as the outputs of the svm model and the l column elements s i k l s i k l 1 s i k 1 i 1 2 k before last column element was used as input the above inputs and outputs are used to train the regularization parameter c and kernel parameter γ of the svm model the last l column elements s i k l 1 s i k l 2 s i k i 1 2 k of the imfs are used as predictors of the trained svm model to calculate the fitted value s 1 k 1 f s 2 k 1 f s k k 1 f and obtain the fitted value q f k 1 of q k 1 by summing the component fitted values s 1 k 1 f s 2 k 1 f s k k 1 f let k k 1 and repeat the above steps until k t 1 then the fitted values of calibration period q c f q f t l 2 l 3 c and the fitted values of the test period q t f q f t c 1 c 2 t can be obtained the above steps indicate that the parameter combinations c γ of the svm model is adaptively updated with the update of sample k therefore parameters c and γ are regarded as local parameters while parameters k and l are global parameters 3 model training and parameter optimization a tsc pso pso strategy combining the tsc strategy with the pso optimization algorithm is proposed to determine the optimal parameters of tv vmd svm model in this study the tsc pso pso strategy consists of internal optimization and external optimization and is summarized as follows the optimal local parameter combination c γ is obtained by solving the optimization model as eq 5 using the pso algorithm the optimization model takes the minimum root mean square error rmse as the objective function 5 c y minimize rmse where rmse 1 n i 1 k s ik s ik f 2 with each new sample a new svm model is established which means that as the sample is updated the rmse k of the optimal model needs to be updated to find out the new optimal parameter combination c γ the objective of the stepwise optimization of svm model is to obtain the forecast of calibration period q c f and the test period q t f that will be used for the optimization of global parameter combination k l therefore the optimization of parameter combination c γ is regarded internal optimization while that of parameter combination k l is called external optimization the optimal global parameter combination k l is acquired by the tsc pso algorithm the optimization model as eq 6 takes the minimum of the bigger rmse in the calibration and test periods as the objective function and is solved by the pso algorithm obviously the tsc pso algorithm finds out the optimal parameters based on the performance during the two stages namely the calibration and test periods which is different from the traditional algorithms based only on the performance during the training period 6 l k minimize max i m i z e rms e calibration r m s e test where rms e calibration 1 n t l 2 c q t q f t 2 and rms e test 1 n t c 1 t q t q f t 2 4 model forecasting and comparison initialize k t and then repeat the aforementioned process of input and output variable selection where the parameter combination k l is taken from the optimal values already obtained while c γ is obtained by solving the optimization model as eq 5 until k n 1 finally the forecast for the validation period q v f q f t t 1 t 2 n is obtained to analyze the influence of cv and pso algorithm on the time varying models i e tv svm and tv vmd svm this study compared the performance of the tv svm1 tv svm2 tv vmd svm1 and tv vmd svm2 models in which 1 and 2 represent the tsc pso cv and tsc pso pso strategy respectively as is known the seasonal autoregressive integrated moving average sarima model is the most commonly used model for modeling and forecasting monthly streamflow alonso brito et al 2021 mohammad 2015 therefore to further demonstrate the superiority of the tv sde framework the sarima model was compared with the tv vmd svm model in addition the single time invariant svm model namely svm and single time varying svm model namely tv svm were also compared to sum up this study compared the performance of the sarima svm tv svm1 tv svm2 tv vmd svm1 and tv vmd svm2 models because the sarima model belongs to the stochastic hydrological model there was no need to further divide the training period into calibration and test periods when establishing the sarima model 2 4 indicators for performance evaluation the forecasting models were evaluated by four commonly used error analysis indicators namely rmse in eq 8 nash sutcliffe coefficient nse in eq 9 willimot index wi willmott et al 2012 in eq 10 and peak difference metric pdiff moriasi et al 2007 in eq 11 the closer the values of nse and wi are to 1 and the closer the rmse and pdiff value is to 0 the better the performance of the model will be 8 rmse 1 n t 1 n q t q f t 2 9 nse 1 t 1 n q t q f t 2 t 1 n q t q 2 10 wi 1 t 1 n q f t q t 2 t 1 n q f t q q t q 2 11 pdiff max q t m a x q f t where q and q f denote the mean of the observed series and the forecast series respectively n denotes the length of the q f and was calculated by 12 n c l c a l i b r a t i o n p e r i o d t c t e s t p e r i o d n t v a l i d a t i o n p e r i o d furthermore diebold mariano dm test diebold and mariano 2002 was used to determine whether forecasts were significantly different if the absolute value of dm statistic is greater than two tailed critical value for the standard normal distribution there will be a significant difference between forecasts let e t and r t be the residuals for the two forecasts and we define the loss differential d t as follows 13 d t e t 2 r t 2 then the dm statistic is defined as follows 14 dm d γ 0 2 t 1 h 1 γ k n where d is the mean of d t and γ k is the autocovariance of d t at lag k it is generally sufficient to use the value h n 1 3 1 3 study areas and data the hei river basin yellow river basin and han river basin were selected as study areas monthly streamflow data from nine hydrological stations namely qilian ql wafang wf minhe mh lanzhou lz longmen lm huaxian hx baimasi bms xianyang xy and yangxian yx were selected to evaluate the proposed models the geographical location of the study areas and the hydrological stations are shown in fig 2 the hei river is the second largest inland river in northwest china and has a length of 168 km and its watershed has an area of 1506 km2 the catchment experiences a sub humid and temperate continental monsoon climate ql and wf stations are located on the upper reach of the hei river basin the yellow river as the second longest river in china is about 5 464 km long and covers a total drainage area of 752 443 km2 the yellow river flows through nine provinces of china mh and lz stations are located on the upper reach of the yellow river basin while lm hx bms and xy stations are situated on the middle reach of the yrb mh hx bms and xy stations are situated on the huangshui river wei river and yiluo river basins respectively which are sub basins of the yellow river basin while lz and lm stations are located on the mainstream of the yellow river basin the han river the largest tributary of the yangtze river has a total drainage area of 159 000 km2 xie et al 2019 it belongs to the east asian subtropical monsoon climate zone with a warm and humid climate and abundant water resources yx hydrological station is located in the upper reach of the han river basin the monthly streamflow data from all hydrological stations in hei river basin were acquired from hydrological yearbook of the hei river basin the monthly streamflow data of mh lz lm hx and bms hydrological stations in yellow river basin were acquired from the yellow river conservancy commission of the ministry of water resources the monthly streamflow data of xy and yx hydrological stations were collected from zuo et al 2020 a non stationary time series is a time series whose statistical properties change over time and thus a time series with a trend or seasonality is non stationary therefore monthly streamflow data are non stationary because they have seasonality to check the nonlinearity in streamflow the bds test brock et al 1996 was performed the null hypothesis of bds approach is that the data has linear dependency which implies that the data is linear results of bds test and statistical properties of streamflow are shown in table 1 it was concluded that all streamflow series are nonlinear at a specified significance level a 0 05 to avoid overfitting of the models the streamflow data was partitioned into calibration period about 60 of the total records test period about 20 of the total records and validation period about 20 of the total records which is shown in fig 3 statistical properties of the streamflow series are shown in table 2 as is clear generally similar statistical parameters were observed for calibration test and validation periods in addition to make the model training process converge faster the model input variables were normalized using eq 11 prior to model calibration barzegar et al 2019 11 q norm t q t q min q max q min where q norm t q max and q min are the normalized maximum and minimum values of the observed series q t respectively note that test and validation periods were normalized using the normalized indicators i e q min and q max of the calibration period 4 results for the time varying models parameters c and γ are the local parameters which are time varying therefore table 3 only presents the results of the global parameters k and l it can be seen that for different models and different stations there is no general rule of optimal parameters however results of the optimal parameters could provide a reference for the range of parameters of the model table 4 presents the evaluation criteria of the all models for streamflow from all stations throughout the periods the performance indicators of the test period for the sarima models were actually for the entire training period in the calibration period the tv svm2 models were the optimal models among all models for all stations however as obtained by the tsc optimization strategy l was different for different models and different stations as a result the length of the streamflow series n involved in calculating the performance indicators of the models in the calibration period was different for different models and different stations therefore the analysis for the training period focused on the performance comparison for the test period not for the calibration period in the test period we found that the results of rmse and nse for the evaluation of the model fit performance at individual stations are not consistent with those of wi for example when comparing the fit results of sarima and svm models at wf stations in the test period it was found that the rmse and nse values of the svm model were smaller and larger than those of sarima model respectively but its wi was smaller than that of sarima model this indicates that the svm model had a better overall fit performance while the saima model better captured the variance of streamflow observations therefore to summarize the conclusions more conveniently comparisons between models were based more on the values of rmse and nse than on wi if there are differences between error indicators comparison between single and decomposition ensemble models showed that the decomposition ensemble model was superior to the single model when comparing the single models the optimal model was the time invariant single svm model comparison between tsc pso pso and tsc pso cv algorithms showed that the tsc pso cv algorithm was superior to the tsc pso pso algorithm for all stations except hx station for the time varying single models i e tv svm1 and tv svm2 models while the tsc pso pso algorithm outperformed the tsc pso cv algorithm for all stations except mh lz and yx stations for the time varying decomposition ensemble framework i e tv vmd svm1 and tv vmd svm2 models to better compare the forecasting performance of the models fig 4 shows the taylor diagrams which present a comparison of the streamflow observations with predictions from the six models in terms of their correlation coefficient centered root mean square difference and normalized standard deviations taylor 2001 in fig 4 the closer the model point is to the observation point the better the model prediction performance is considering the model forecasting performance metrics presented in table 4 and fig 4 comprehensively we can conclude the following 1 when comparing the svm models with the optimal models of the two tv svm models i e tv svm1 and tv svm2 models the optimal single model was found to be the tv svm like model it indicates that the time varying single models are superior to the time invariant single models 2 compared to four single models the time varying decomposition ensemble models produced larger values of nse and wi and smaller rmse values during the validation period and were closer to with the streamflow observations this indicates that the time varying decomposition ensemble models outperform the single models 3 when comparing the tv svm1 models and the tv svm2 models it was found that the tv svm1 models outperformed the tv svm2 models at ql wf mh lm hx bms xy and yx stations while the opposite was true at lz station this indicates that the tsc pso cv optimization algorithm outperforms the tsc pso pso algorithm for the time varying single models when comparing the tv vmd svm1 and tv vmd svm2 models it was found that the tv vmd svm2 models outperformed the tv vmd svm1 models at all stations this indicates that the tsc pso pso optimization algorithm outperforms the tsc pso cv algorithm for the time varying decomposition ensemble framework 4 both the evaluation criteria in bold in the validation period and the taylor diagrams demonstrate that the tv vmd svm2 models had the best forecasting performance for streamflow at all stations among all six models moreover for the streamflow forecasting at all stations the nash sutcliffe coefficient and willimot index of the tv vmd svm2 models were larger than 0 83 and 0 79 respectively furthermore the diebold mariano dm test diebold and mariano 1995 was used to test the significance level which indicated that tv vmd svm2 model is more accurate than other models as shown in table 4 the p values of the dm test between tv vmd svm2 models and tv vmd svm1 models were larger than 0 95 at the ql wf lz hx xy and yx stations while those were smaller than 0 95 at the mh lm and bms stations which indicates that at the ql wf lz hx xy and yx stations the improvement of the tv vmd svm2 models over the tv vmd svm1 model was significant but at the mh lm and bms stations it was not significant however the p values of the dm test between tv vmd svm2 models and all single models i e sarima svm tvsvm1 and tvsvm2 were larger than 0 95 at all stations which indicated that at all stations the improvement of the tv vmd svm2 models over each single model was significant to better compare the forecasting results of the models fig 5 and fig 6 shows scatter plots and violin plots of observed and predicted streamflow from the six models at nine stations in the validation period respectively for yx station the forecasted results of the tv svm2 model showed a large variability with the observations and predictions of other models therefore the violin plots of the observations and predictions of other models except the tv svm2 model are placed in the small plot of the results plot at yx station fig 6 no matter the four single models i e sarima svm tv svm1 and tv svm2 models or the two time varying decomposition ensemble models i e tv vmd svm1 and tv vmd svm2 models the scatter distribution diagram and the fit line in fig 5 and the distribution in fig 6 were relatively similar except for the prediction results of the tv svm2 model at the lz and yx stations this indicates that the four single models produced similar forecasting performance and the two time varying decomposition ensemble models showed the similar forecasting performance for streamflow compared to the four single models the fit lines of the time varying decomposition ensemble models were closer to the 1 1 line fig 5 and the distributions of their predictions especially the outliers among them were most similar to that of observations fig 6 these results indicate that the time varying decomposition ensemble models had remarkably higher forecasting performance than the single models especially for extreme values however it also can be seen from fig 5 that the fitted line of the time varying decomposition ensemble models was close to the 1 1 line in the low and medium values parts but farther apart in the high values part it indicates that the time varying decomposition ensemble models considerably performed well for low and medium streamflow but they had difficulty in forecasting the high values of streamflow to further quantify the prediction accuracy of all models for high value part of streamflow table 5 and table 6 show the error evaluation metrics of all models for the largest streamflow extreme and peak streamflow respectively the largest streamflow extremes are the streamflow values that exceed 95th percentile of the streamflow series as can be seen from table 5 among all models the tv vmd svm1 models had the smallest rmse values for the largest streamflow extreme forecast at ql lz and bms stations while the tv vmd svm2 models had the smallest rmse for the largest streamflow extreme prediction at wf lm mh hx xy and yx stations this result indicated that tv vmd svm1 models achieved the best forecasting performance for the largest streamflow extreme at ql lz and bms stations while the tv vmd svm2 models achieved the best forecasting performance for the largest streamflow extreme at wf lm mh hx xy and yx stations as shown in table 6 the tv vmd svm1 models had the optimal pdiff values for the peak streamflow forecast at ql lz mh hx bms and xy stations while the tv vmd svm2 models had the optimal pdiff values for the peak streamflow forecast at wf lm and yx stations this result indicated that the tv vmd svm1 models had the best forecasting performance for the peak streamflow at ql lz mh hx bms and xy stations while the tv vmd svm2 models had the best forecasting performance for peak streamflow at wf lm and yx stations in conclusion among all models all optimal models for forecasting the high value part of streamflow at all stations were the time varying decomposition ensemble models i e tv vmd svm1 and tv vmd svm2 models 5 discussion 5 1 reasons for high precision of the tv sde framework the reasons for the superior forecasting performance of tv sde framework can be summarized as follows 1 stepwise decomposition ensemble framework 2 time varying parameters and 3 the tsc pso pso algorithm the stepwise decomposition ensemble framework decomposes the time series into simple components that are easy to describe and have specific meanings so as to grasp the hidden influencing factors of the data reduce the modeling difficulty and improve the model prediction performance moreover stepwise decomposition ensemble framework strictly excludes future streamflow data and can be used for actual forecast which is consistent with the findings of the studies he et al 2022 meng et al 2021 when new streamflow data is added the parameters of time varying models are updated it means that the time varying models could respond well to the addition of new information or changes of influencing factors furthermore this response is self adaptive and in real time therefore the time varying models represent the characteristics of instantaneous streamflow series in this study a tsc pso pso algorithm combining a tsc strategy with pso algorithm is proposed to find out the optimal parameter of the tv sde framework the tsc pso pso algorithm is based on the performance during the two stages namely the calibration and test periods which is different from traditional algorithms which based only on the performance in the training period therefore the tsc pso pso algorithm can prevent model overfitting to further explore the effectiveness of a tsc strategy for tv sde framework the tsc pso pso algorithm and tsc pso cv algorithm were compared although the prediction results of all models for the high value part of streamflow indicated that both the tsc pso pso algorithm and the tsc pso cv algorithm performed optimally for the tv sde framework the prediction results for the entire validation period indicated that the tsc pso pso algorithm outperformed tsc pso cv algorithm for the tv sde framework 5 2 generalization performance of tv sde framework although in the tv sde framework the decomposition must be repeatedly performed when new streamflow data is added the parameters of the svm models are updated this means that when new data is gradually added to streamflow data the number of decompositions k does not have to be constant therefore the emd method can be used in the tv sde framework for actual forecasting practice furthermore if emd method was used the optimal parameter combination k l c γ would be reduced to l c γ it indicates that the tv sde framework overcomes the limitations that the emd is inapplicable to real world streamflow forecasting fang et al 2019 similarly wa ssa and other decomposition methods can also be used in the tv sde framework to build more models for the actual forecasting practice more ml or time series models can also be used in the tv sde framework to build more forecasting models besides the pso and cv optimization algorithms selected in this study other novel and effective optimization algorithms can also be used to construct hybrid optimization algorithms based on the tsc optimization strategy to optimize the parameters of the tv sde framework moreover since the tv sde framework is time varying it is reasonable to believe that this framework can be applied to the prediction of other hydrological variables with non stationary nonlinearity such as rainfall groundwater etc in summary the tv sde forecasting framework has a good generalization performance 5 3 limitations of tv sde framework in this study we constructed the inputs to the tv sde framework based on historical streamflow data and did not consider the influence of many exogenous variables such as precipitation temperature evapotranspiration and land on streamflow moreover we did not consider the relationship between multiple stations when developing the tv sde framework resulting in this framework only obtaining streamflow prediction results for a single hydrological station at a time therefore future research can try to further improve the prediction performance of the tv sde framework by adding the effects of many exogenous variables on streamflow and the relationship between multiple stations to this framework when establishing the decomposition ensemble model the boundary effect degrades the forecasting performance in this study the tv sde framework adopted the improved sdb sampling method to adapt to the boundary effect based on the sdb sampling method xu et al 2022 proposed a stepwise decomposition integration prediction considering boundary correction framework and the results showed that the boundary correction can further enhance the forecasting accuracy of stepwise decomposition integration prediction framework therefore future studies could attempt to improve the tv sde framework by correcting the boundary effect although the tv sde framework has relatively high complexity due to the time varying parameters and sampling methods it makes a significant improvement over each single model however it is still necessary to develop a forecasting framework with lower complexity and higher accuracy 6 conclusions for addressing the pitfalls and errors of the traditional decomposition ensemble model for the real world streamflow forecasting a novel decomposition ensemble framework namely time varying stepwise decomposition ensemble tv sde framework was developed in this study the tv sde framework which can simultaneously solve for all unknown parameters including the decomposition number of decomposition method the input and output of the model and the hyperparameters of the prediction model with one objective function by one optimization algorithm moreover the tv sde framework are time varying and can be self adaptively updated as new streamflow data is added in addition to avoid over fitting and enhance the generalization ability of the framework the training period is further divided into calibration and test periods and a tsc pso pso optimization strategy is proposed to optimize model parameters to evaluate the performance of tv sde framework the tv vmd svm1 tv vmd svm2 tv svm1 tv svm2 svm and sarima models were compared for monthly streamflow data from nine hydrological stations in china the study results indicate that 1 the time varying decomposition ensemble models outperform the single models 2 the tsc pso pso optimization algorithm outperforms the tsc pso cv algorithm for the time varying decomposition ensemble framework and 3 the tv vmd svm2 models makes a significant improvement over each single model and have the best forecasting performance for streamflow at all stations among all six models with the nash sutcliffe coefficient greater than 0 83 and willimot index greater than 0 79 and for the streamflow forecasting at all stations the nash sutcliffe coefficient and willimot index of the tv vmd svm2 models are larger than 0 83 and 0 79 respectively overall this study showed that the tv sde framework is useful for highly nonstationary and nonlinear monthly streamflow series forecasting in actual practice in addition the tv sde framework is expected to have a wide range of applications in the hydrology and water resources as well as potentially other fields this study only used the monthly streamflow series that are characterized by non stationarity due to the existence of seasonal and periodic patterns to test the forecasting performance of the tv sde framework it is necessary to use other nonstationary and nonlinear hydrological time series which exhibit trend jump and chaotic patterns to validate the performance of the framework in future studies guo et al 2021 in addition this study only analyzes and builds the tv sde framework from the perspective of the time domain lacking a deeper dive into the frequency domain it is suggested that further studies explore more valuable information from the perspective of frequency domain to build superior prediction models for example we can forecast the periodic series by frequency domain approaches from koopmans 1974 which have been used successfully for space weather reikard 2011 and other types of periodic series schlink et al 1997 we can also develop a combined model using both frequency and time domain methods in two stages using a frequency domain algorithm to estimate and forecast streamflow in the first stage and using the forecasts as inputs in time domain model in the second stage reikard 2013 credit authorship contribution statement tianli guo conceptualization methodology software visualization writing original draft songbai song conceptualization data curation methodology supervision validation writing review editing vijay p singh writing review editing ting wei writing review editing te zhang visualization xin liu visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the authors acknowledge the grant support from the national natural science foundation in china grand number 52079110 the authors wish to thank the respected editor and anonymous reviewers for their valuable comments and insightful suggestions that improved the quality of this manuscript data data in hei river basin were acquired from hydrological yearbook of the hei river basin data of mh lz lm hx and bms hydrological stations in yellow river basin were acquired from the yellow river conservancy commission of the ministry of water resources http www yrcc gov cn data of xy and yx hydrological stations were collected from zuo et al 2020 
2458,climate change is altering flood risk globally the nature of those alterations varies locally creating the need for regional assessments to inform flood risk management and planning this study projects future changes in flood regime in the yangtze river basin to characterize flood regimes we use a multi attribute approach that measures the relative change in flood magnitude timing frequency and duration between historical and future periods we use climate projections from the coupled model intercomparison project phase 6 cmip6 to force the soil and water assessment tool swat and generate daily streamflow projections along the yangtze river network for two shared socioeconomic pathways ssps ssp2 4 5 and ssp5 8 5 we use seasonal maxima annual maxima and peaks over threshold to determine the different flood attributes results show that downscaled cmip6 precipitation and near surface temperature are both projected to increase substantially in the future with a consequent surge in floods across the basin in the far future years 2061 2100 under ssp5 8 5 average annual flood magnitude timing frequency and duration are projected to increase 66 6 arrive 1 9 days earlier increase 27 5 and prolong 19 1 days respectively projected changes in flood attributes at annual timescale are generally higher in the basin s northern tributaries than in the southern ones changes in flood magnitude and frequency tend to resemble each other whereas flood timing and duration exhibit distinct change patterns our multi attribute approach to flood regime characterization provides a systematic way for translating raw cmip6 projections into informative future flood projections this approach can help inform flood risk planning and improve the reliability of climate change impact assessment keywords climate projections cmip6 hydrologic modeling flood projections yangtze river basin data availability data will be made available on request 1 introduction the yangtze river basin yrb one of the largest river basins in the world occupies approximately 1 2 of the world s land area wang et al 2020a accommodates about 5 8 of world s population li et al 2021a and contributes over 7 0 of world s total gross domestic product gdp chen 2019 flooding is the most frequent and damaging natural disaster in the yrb xia and chen 2020 the most damaging flood since the start of the observation record occurred in 1954 yu et al 2009 causing over 30 000 fatalities and inundating 3 17 million hectares of land kundzewicz et al 2019 the second most disastrous basin wide flood occurred in 1998 yu et al 2009 which resulted in approximately 13 2 million people left homeless 3 600 fatalities and 36 billion us in nominal 1998 dollars in economic losses ye and glantz 2005 hence the chinese government has invested substantial resources to develop flood adaptation mitigation and management strategies in the yrb wei et al 2020 for example in 2011 the overall plan for the follow up work of the three gorges project invested 61 70 billion yuan 9 5 billion us to enhance the safety standards of 26 hazardous projects in the hunan and hubei provinces chen 2019 the 172 major water conservancy projects for water saving and water supply in china invested 103 billion yuan 15 8 billion us to strengthen the flood protection capability of 11 projects along the yangtze river in the jiangxi anhui and jiangsu provinces chen 2019 despite the implementation of these flood risk management strategies chen 2019 which included improved safety standards for flood defense projects ma 2020 and an advanced early warning system shang et al 2020 the recent flood of 2020 resulted in devastating losses zhou et al 2021 this flood event has been considered the worst since 1998 wei et al 2020 affecting over 78 6 million people with 279 fatalities and 5 3 million evacuees nationwide causing in china over 41 billion us in direct economic losses ministry of water resources of china 2021 the majority of these losses were attributed to flooding in the yrb xia and chen 2020 zhou et al 2021 with knowledge of significant flooding losses in the yrb s past question arises on how will climate change drive the changes in the pattern of flood regimes in the yrb s future study based on climate projections from the coupled model intercomparison project phase 5 cmip5 indicates that projected flood magnitude across yrb is overall increasing yu et al 2018a b future floods in the yrb have also been projected using the cmip6 output yang et al 2022 concludes that floods in the yrb are projected to be more frequent and severe due to the variability of the western pacific subtropical high under greenhouse warming whereas xiong et al 2022 using the flood potential index projects decrease in flood potential with future climate several other studies have used cmip6 outputs to explore trends in future hydroclimatic extremes in the yrb li et al 2021b wu et al 2022 zhao et al 2022 however these studies have mostly relied on a single index to assess or infer flood hazards in future periods we perform here for the first time a multi attribute i e magnitude timing frequency and duration analysis of projected flood regimes for the yrb by using multiple attributes we provide a more complete picture of flood hazards than possible based on a single attribute comprehensive and detailed characterization on changes of flood regimes are relevant to decision and policy making the main objective of this study is to assess the projected changes in flood magnitude timing frequency and duration at both annual and seasonal timescales across the yrb using the cmip6 climate model ensemble under two shared socioeconomic pathways ssps ssp2 4 5 and ssp5 8 5 for this downscaled climate variables precipitation and near surface temperature from 10 cmip6 climate models under both the ssp2 4 5 and ssp5 8 5 scenarios are used to force the soil and water assessment tool swat and generate a spatially and temporally consistent ensemble of streamflow projections changes in flood magnitude timing frequency and duration are examined and compared for two future periods 2021 2060 and 2061 2100 relative to the baseline period 1971 2010 by considering multiple flood attributes and their concurrent responses we offer a new perspective for understanding flood regimes under different global warming scenarios using multiple flood attributes this study addresses the following questions i what are the patterns of flood regime in the yrb during the baseline period of 1971 2010 ii how are those patterns projected to change at both annual and seasonal timescales based on cmip6 climate projections and iii how do changes in different flood attributes affect the assessment of current and future flood hazard 2 materials and methods 2 1 study area the yangtze river also known as the changjiang is the longest in asia and third longest in the world and a major waterway globally gao et al 2021 zhang et al 2022 the yangtze river originates in the qinghai tibet plateau and flows generally eastwards into the east china sea fig 1 the drainage area of the yrb is roughly 1 8 million km2 precipitation is abundant in the yrb with an annual average precipitation of around 1 200 mm li et al 2021a however the spatial and temporal distribution of precipitation is highly uneven the annual precipitation increases from west to east ranging from 300 mm year in the west to 2400 mm year in the east li et al 2021a and over 75 of the annual precipitation occurs in summer yu et al 2009 this spatiotemporal difference is partly due to complex terrain across the yrb the total altitude difference from the source of the yangtze river to its estuary is more than 6 000 m zhu et al 2021 in such a mega and complex river system a comprehensive understanding of future flood projections is crucial to inform adaptive decision making and flood management 2 2 hydrologic modeling and model calibration we use the soil and water assessment tool swat to simulate the long term streamflow response to climate change in the yrb the swat model is a physically based distributed hydrological model for long term simulation in large and complex basins arnold et al 2012 the swat model has been successfully used to conduct flood hazard assessment in various contexts e g cheng et al 2017 shadmehri toosi et al 2019 yu et al 2018a b similar studies on hydrological extremes have been increasingly conducted around the world tan et al 2020 the detailed information on setting up calibration and validation of the constructed swat for the yrb used in this study have been reported elsewhere in sun et al 2019a b for the sake of completeness we report here the calibration and validation details the swat model was calibrated and validated using 21 year long consecutive daily streamflow observations from 18 hydrological gauges across the yrb the streamflow data were provided by the changjiang river water resources commission cwrc the calibration and validation period are 15 years january 1st 1990 december 31st 2004 and 6 years january 1st 2005 december 31st 2010 respectively swat model performance is routinely measured by the coefficient of determination r2 and the nash sutcliffe coefficient ns r2 measures the proportion of the variance in measured data explained by the modeled data which ranges between 0 and 1 the higher the value the better the fit and values greater than 0 5 are considered acceptable castillo et al 2014 ns measures the relative magnitude of the residual variance compared to the measured data variance which ranges from to 1 with the performance rating acceptable if values between 0 and 1 castillo et al 2014 over the combined calibration and validation period of 1990 2010 the average r2 and ns values are 0 84 0 44 0 9 and 0 71 0 32 0 89 table 1 and fig 2 respectively fig 2 shows that the calibrated swat model reasonably captures both the average and extreme daily flows in the yrb which makes the model suitable for the present study 2 3 cmip6 projections and post processing cmip6 outputs are used to force the swat model and obtain projected daily streamflow time series across reaches in the yrb together these reaches represent the yrb s main river network fig 1 we use 10 climate models as forcing to the swat model table 2 study suggests that using the median of around 10 climate models in studies of climate change impacts on hydrology generates similar uncertainty components as the whole ensemble wang et al 2020b the climate models are searched using the following constraints variable pr tasmax tasmin frequency day variant label r1i1p1f1 experiment id historical ssp245 ssp585 grid label gn https esgf node llnl gov search cmip6 from the search results we adopt all climate models with no missing data to examine extreme events with emphasis on climate change we employ two commonly used scenarios that representing the medium to high end of future forcing pathway ssp2 4 5 and ssp5 8 5 the ssp2 4 5 scenario updates the rcp4 5 in cmip5 radiative forcing stabilized at 4 5 w m2 before 2100 and the ssp5 8 5 scenario updates the rcp8 5 radiative forcing n8 5 w m2 by 2100 eyring et al 2016 o neill et al 2016 however for regional studies bias correction and spatial downscaling are needed to adjust global climate projections therefore for each climate model simulation 20 in total 10 models times 2 scenarios the meteorological fields of precipitation and maximum minimum near surface temperatures are downscaled the downscaled climate variables are then used to generate daily streamflow projections for the period of 2021 2100 at 125 subbasin outlets in the yrb a modified version of the daily bias correction spatial disaggregation bcsd downscaling approach girvetz et al 2013 wood et al 2004 is used to bias correct the meteorological fields this downscaling approach has been successfully applied in several previous studies sun et al 2019b 2020 zeng et al 2021 to correct systematic biases in different meteorological variables further details about the modified version of the daily bcsd method are described elsewhere sun et al 2019b 2020 zeng et al 2021 after forcing the swat model with the downscaled meteorological variables 20 different streamflow projections are obtained one streamflow projection for each climate model simulation 10 climate models times 2 scenarios 2 4 flood regime analysis for the flood regime analysis we use the daily streamflow projections to calculate the four flood attributes magnitude timing frequency and duration by using multiple attributes we perform for the first time a multi attribute analysis of projected flood regimes in the yrb the flood attributes are calculated for the near future 2021 2060 and the far future 2061 2100 and compared against the baseline period 1971 2010 floods along the yangtze river have distinct seasonal characteristics yu et al 2009 and studies suggest that gcms perform satisfactorily at both the annual and seasonal timescales villarini and zhang 2020 hence we perform the flood analysis at both of these timescales seasons are defined as follows spring march may summer june august autumn september november and winter december february the same method is used to derive seasonal and annual floods but seasonal floods are calculated by only considering the streamflow time series for the seasonal period under consideration e g for the spring season the period is march 1st to may 31st whereas annual floods are based on the whole year the determination of floods varies depending on the flood attribute as described next see eqs 1 10 note that in all the equations year n indicates one of the 40 years in the baseline or future periods model m indicates one of the 10 selected climate models reach indicates one of the yangtze river network s 125 reaches baseline indicates the baseline period scenario indicates the ssp2 4 5 or ssp5 8 5 scenario and future indicates the near or far future period 2 4 1 flood magnitude the magnitude of a flood is quantified as the maximum daily streamflow value of a flood event flood magnitude is characterized using the seasonal or annual maximum streamflow mudersbach et al 2017 the annual flood magnitude indicates the maximum value of streamflow in each year 12 months whereas the seasonal flood magnitude represents the maximum streamflow in each season 3 months the relative change of flood magnitude between the baseline and future period δ f m reach s c e n a r i o f u t u r e is calculated as 1 δ f m reach s c e n a r i o f u t u r e fm reach s c e n a r i o f u t u r e fm reach b a s e l i n e fm reach b a s e l i n e 100 where fm reach b a s e l i n e is the median of the annual maximum streamflow across n years for the baseline scenario and fm reach s c e n a r i o f u t u r e is the median of the annual maximum streamflow for the m selected climate models across n years for the future period eq 1 together with the seasonal maximum streamflow is also used to calculate the relative change of flood magnitude for each season 2 4 2 flood timing flood timing is defined as the date of occurrence of a flood blöschl et al 2017 flood timing has gained prominence as a tool for flood hazard analysis do et al 2020 ficchì and stephens 2019 wasko et al 2020 similar to flood magnitude flood timing is also calculated using the maximum streamflow over a given time interval that is the same definition of flood is used to calculate both flood magnitude and timing however we do not perform the seasonal analysis for flood timing since flood timing itself could reflect seasonal changes blöschl et al 2017 do et al 2020 circular statistics are often used to investigate flood timing as it exists on a cyclical continuum wasko et al 2020 on a circular scale the ordinal day from 1 to 365 or 366 and starting on january 1st of a flood at the end of a year is close to a flood occurring at the start of the following year but on a linear scale these day numbers are far apart bayliss and jones 1993 to perform circular statistics the ordinal day d i needs to be converted to an angular value θ i 2 θ i d i m i 2 π 0 θ i 2 π where m i is the number of days in the ith year i e 365 days for a normal year and 366 days for leap years and i 1 n is the number of years the mean timing in ordinal day is given by fisher 1993 x 1 n i 1 n cos θ i y 1 n i 1 n sin θ i m 1 n i 1 n m i 3 d tan 1 y x m 2 π x 0 y 0 tan 1 y x π m 2 π x 0 tan 1 y x 2 π m 2 π x 0 y 0 another useful metric of flood seasonality is the concentration index ci which communicates information about changes in the flood timing concentration 4 ci x 2 y 2 0 c i 1 note that ci varies from 0 to 1 with ci 0 indicating that the flood occurrence dates are spread evenly throughout the year and ci 1 indicating that all flooding events occur on the same ordinal day do et al 2020 for our analysis we compute the change in the timing and concentration index between the baseline and future periods for each reach 2 4 3 flood frequency flood frequency is defined as the number of flood events within a time interval e g a season or year when dealing with flood frequency we employ the peaks over threshold pot approach the pot dataset extracts all the streamflow values exceeding a selected streamflow threshold the number of separate excursions above the threshold in each year is counted as the frequency of flood villarini et al 2012 several approaches have been proposed for threshold selection lang et al 1999 in this study the threshold for each reach is selected so that there are two floods per year on average in the baseline period a pot dataset including two or three floods per year on average was suggested by lang et al 1999 and this criterion has been adopted in other studies roth et al 2012 villarini et al 2011 to consistently compare the baseline and future flood frequencies we use the same threshold from the baseline period to count the number of flood events in future periods we calculate the flood frequency at annual timescale for each reach for the baseline period we obtain the maximum of 80 2 floods 40 years floods f m 80 reach b a s e l i n e with the condition that only one flood is counted within a 15 day time window this is commonly done to avoid counting the same event twice lang et al 1999 mallakpour and villarini 2015 5 f m 80 reach b a s e l i n e m a x 80 streamflow reach b a s e l i n e date f l o o d s e q j 1 date f l o o d s e q j 15 0 j 80 where date f l o o d s e q j indicates the date serial date number of the number j flood we assign the minimum value of f m 80 reach b a s e l i n e as the threshold threshhold reach b a s e l i n e for identifying floods in the future periods for the future periods we iteratively add 1 to the frequency of flood ff if a streamflow is higher than or equal to the threshhold reach b a s e l i n e note that the 15 day period rule applied in the baseline period is also applied in eq 6 6 ff ff 1 s t r e a m f l o w model r e a c h s c e n a r i o f u t u r e threshhold reach b a s e l i n e f f 0 streamflow model r e a c h s c e n a r i o f u t u r e threshhold reach b a s e l i n e date f l o o d s e q j 1 date f l o o d s e q j 15 lastly we calculate the median flood frequency for the m selected climate models such that 7 ff reach s c e n a r i o f u t u r e m e d i a n ff model 1 r e a c h s c e n a r i o f u t u r e ff model m r e a c h s c e n a r i o f u t u r e given that the value of flood frequency is easier to interpret than for the other flood regime attributes we use the absolute value rather than the change relative to the baseline period to analyze the flood frequency thus an average of 2 floods per year in the future projected period indicates a similar flood frequency to the baseline period whereas higher values more than 2 floods per year on average indicate an increase in flood frequency for the future compared to the baseline 2 4 4 flood duration the duration of a flood event is defined as the number of consecutive days between the flood beginning and end dates najibi and devineni 2018 thus a flood includes the date when the streamflow first climbs above the selected threshold as the beginning and the date before the streamflow first drops below the threshold as the end for consistency the same threshold is used to calculate both the flood duration and flood frequency metrics however the 15 day period rule applied to the flood frequency metric is not used for flood duration to avoid disrupting the flood duration information we compute the flood duration for each reach at the annual timescale to do this we replace streamflow values with 1 for flood magnitudes greater than or equal to the threshhold reach b a s e l i n e and 0 otherwise eq 8 threshhold reach b a s e l i n e is the flood magnitude threshold derived from the baseline period fd is the derived binary time series and fm model r e a c h s c e n a r i o p e r i o d indicates the flood magnitude time series for a particular combination of model reach scenario and period 8 fd 1 fm model r e a c h s c e n a r i o f u t u r e threshhold reach b a s e l i n e 0 fm model r e a c h s c e n a r i o f u t u r e threshhold reach b a s e l i n e the yearly averaged flood duration fd model r e a c h s c e n a r i o p e r i o d is calculated as the total number of days greater than or equal to the baseline threshold divided by the number of years n 9 fd model r e a c h s c e n a r i o f u t u r e s u m f d n and the change in flood duration δ f d reach s e n a r i o f u t u r e between the baseline and future period is calculated as 10 δ f d reach s e n a r i o f u t u r e fd reach s e n a r i o f u t u r e fd reach b a s e l i n e where fd reach b a s e l i n e is the average flood duration for the baseline period and fd reach s c e n a r i o f u t u r e is the median of the m climate models average flood duration for the future period 3 results and discussion 3 1 precipitation and temperature projections downscaled mean precipitation and maximum minimum temperatures are used as forcing to the swat model for projecting river streamflow in the future periods appropriate downscaling performance guarantees the reliability of streamflow projections girvetz et al 2013 sun et al 2020 fig 3 illustrates the downscaling performance of mean precipitation and maximum minimum temperatures for the ssp2 4 5 left panels and ssp5 8 5 right panels scenarios in the period 1955 2014 the average daily observed mean precipitation fig 3a b maximum temperature fig 3c d and minimum temperature fig 3e f are 2 8 mm day 18 7 and 8 7 respectively by contrast for the same historical period the cmip6 ensemble means of raw precipitation maximum temperature and minimum temperature are 4 1 mm day 14 3 and 6 5 respectively overall for the yrb the raw cmip6 ensemble tends to overestimate precipitation by 1 3 mm day 46 4 and underestimate maximum temperature by 4 4 23 5 and mimimum temperature by 2 2 25 3 on average large variability exists among different cmip6 climate models in the baseline period the outputs average values from the 10 climate models ranges between 3 2 mm day 14 3 mri esm2 0 and 5 1 mm day 82 1 access esm1 5 for precipitation 10 6 43 3 nesm3 and 17 0 9 1 miroc6 for maximum temperature and 3 0 65 5 canesm5 and 9 0 3 4 nesm3 for minimum temperature fig 3 the bias and variability of the raw cmip6 historical simulations extend to the raw cmip6 future projections suggesting the need to use downscaled bias corrected climate projections as done in this study when assessing future floods fig 3 shows that after implementing the downscaling algorithm the large bias between the raw model projections orange shade with blue line and observations black solid line is substantially reduced and that there is a smooth temporal transition between the downscaled projections blue shade with yellow line and observations the average standard deviations of downscaled precipitation maximum temperature and minimum temperature ensembles are reduced from 0 7 to 0 2 1 9 to 0 4 and 1 2 to 0 6 respectively compared to the raw ensembles the downscaled projections largely improve the credibility of cmip6 precipitation and temperature projections and therefore contribute to improving the credibility of the streamflow projections derived here from these climate outputs a reliable downscaling technique should not only correct the bias but also preserve the projected temporal trend for each variable fig 3 shows that after downscaling the trend of the downscaled variables is well preserved e g the r2 between the raw and downscaled rcps is 0 98 on average the overall downscaled trend consists of i increase in precipitation of 0 3 mm day 10 0 and 0 6 mm day 19 3 for ssp2 4 5 and ssp5 8 5 respectively ii increase in maximum temperature of 2 3 11 6 and 5 0 25 9 respectively iii increase in minimum temperature of 2 0 20 4 and 4 6 48 7 respectively fig 3 further both precipitation and temperature are projected to increase significantly under future climates p value 0 01 studies indicate that a warmer and wetter atmosphere will intensify the water cycle and ultimately generate more severe flood events li et al 2021b najibi and devineni 2018 yang et al 2019 hence the increasing trends observed in the cmip6 projections support the need to investigate regional flood hazards in the flood prone yrb 3 2 flood magnitude fig 4 shows the simulated annual and seasonal flood magnitude in 1971 2010 the annual flood magnitude ranges from 100 6 to 82 375 0 m3 s along the yangtze river network which mainly reflects an increase in flood magnitude with the accumulation of drainage area as one moves from upstream to downstream in the river network flood magnitude shows a distinct seasonal variation flood magnitude is typically larger in summer followed by autumn whereas winter has generally a lower flood magnitude fig 4 the relative differences between seasonal and annual floods across the river network are 69 3 spring 11 1 summer 45 7 autumn and 83 0 winter on average the relatively small difference as well as the close resemblance pearson s correlation r 0 99 between summer and annual floods indicate that summer is the most flood prone season in the yrb fig 5 shows the annual and seasonal percent change in flood magnitude in the near future 2021 2060 and far future 2061 2100 relative to the baseline period 1971 2010 recall that we characterize future floods using two socioeconomic scenarios ssp2 4 5 and ssp5 8 5 the percent change is categorized using five classes with colder colors indicating negative changes and warmer colors positive changes negative changes indicate decreased flood magnitude in the future period compared to the historical period whereas positive changes indicate increased changes at the annual timescale fig 5a d in the near future 63 2 and 60 8 of the yangtze river network experiences a flood magnitude shift greater than 25 in the ssp2 4 5 fig 5a and ssp5 8 5 fig 5b scenarios respectively these percentages jump to 68 0 and 86 4 in the far future under ssp2 4 5 fig 5c and ssp5 8 5 fig 5d respectively the annual positive shift is mostly contributed by spring fig 5e h and summer fig 5i l floods which together account for 56 4 of the network reaches exceeding a 25 relative change by contrast the winter flood magnitudes show a clear negative shift with 84 8 and 80 0 of the network reaches exhibiting negative change values for ssp2 4 5 fig 5q and ssp5 8 5 fig 5r in the near future respectively however these negative change values reduce to 72 0 and 61 6 of the network reaches in the far future for ssp2 4 5 fig 5s and ssp5 8 5 fig 5t respectively in autumn neither the positive nor the negative changes are as evident as in other seasons flood magnitude is expected to increase drastically in future climate projections under the ssp5 8 5 scenario fig 5 for instance the average relative changes are projected to be 66 6 82 3 51 3 47 4 and 3 8 at the annual spring summer autumn and winter timescales respectively there are 49 tributaries in the yrb with an area larger than one million km2 and flow rates as high as millions cubic per second chen 2019 with the potential to cause catastrophic losses therefore the projected increase in flood magnitude has important implications for current flood design standards and flood protection infrastructure in the yrb for example the flood control standards for the middle and lower reaches of the yrb were designed based on the 1954 flood xia and chen 2020 in addition most of the 51 200 reservoirs in the yrb which together have brought huge flood protection benefits in the past were built between 1950 and 1970 cao and zhang 2012 given outdated design standards and reservoirs that are approaching their design life future increases in flood magnitude raise concerns about the resilience of current flood control infrastructure in the yrb the overall spatial variability of flood magnitude is explained by differences in the hydrological behavior of major tributaries fig 5 for example the jinsha tributary located on the western yrb near the eastern himalayas fig 1 shows large positive changes in flood magnitude higher than 50 in the spring and summer across the climate scenarios and future time periods this projected increase in flood magnitude may due to glacier melt from the himalayas more than 5 000 glacier lakes have already spawned in the himalayas veh et al 2020 this process of melting glaciers is rapidly growing and would accelerate under future global warming scenarios gao et al 2021 maurer et al 2020 the abundant water storage in the glacier lakes can introduce glacier lake outburst floods in the jinsha tributary wang et al 2021 studies suggest that flood magnitude from glacier lake outburst in the himalayas can rival monsoon fed discharges in major rivers hundreds to thousands of kilometers downstream veh et al 2020 indeed fig 5a d shows that the warmer the climate the more severe the flood magnitude 3 3 flood timing in the baseline period fig 6 a average values of flood timing fall between may 23rd ordinal date of 143 and september 13th ordinal date of 256 with an average date of july 26th ordinal date of 207 overall flood timing lags behind on the western and southern yrb compared to rivers on the eastern and northern yrb which is consistent with the results from chen 2019 flood timing is similar in the near and far future periods for both climate scenarios fig 6b f for the future periods the average flood timing falls between june 1st ordinal date of 152 and august 19th ordinal date of 231 with an average date of july 23th ordinal date of 204 compared to the baseline period future flood timing dates are anticipated to arrive 13 9 days earlier on average in the jinsha tributary while a timing delay 0 05 days on average is expected on the central and eastern portions of the yangtze river network the earlier timing in the upstream yangtze may potentially contribute to the increased changes in future flood magnitude along the jinsha tributary in spring and summer compared to the baseline period fig 5 the earlier onset and longer duration of the mei yu in chinese also called baiu in japanese season zhou et al 2021 was previously reported kundzewicz et al 2019 which could increase risk of spring and summer floods the concentration of flood timing is generally lower in the future than in the baseline period fig 6g the future projected concentration of flood timing is consistent across the ssp2 4 5 and ssp5 8 5 scenarios suggesting that this may be a persistent feature of future flood regimes that is likely to manifest in the near future fig 6h i k and l overall an average percent of 53 4 77 8 and 94 4 reaches show backward or forward timing variations within 5 days 10 days and 20 days respectively some of the mechanisms driving the changing pattern of flood timing could be intense precipitation snowmelt and rain on snow events do et al 2020 the future changes in flood timing reported here have important implications for agricultural activities in the yrb given the flat terrain abundant water resources and moderate temperature in the middle and lower reaches of the yangtze river this area has long been known as the land of fish and rice liu et al 2019 to cope with already manifested earlier floods farmers in the middle and lower basins of the yrb have adjusted their rice planting structure in recent years adding middle and late rice varieties with higher yields zhang et al 2018 nonetheless studies suggest that even small shifts in flood timing can have a marked impact on crop production losses ficchì and stephens 2019 wasko et al 2020 this in combination with our flood timing results suggests that farmers on the yangtze floodplains will need to continue adapting their agricultural practices to a changing pattern of flood timing 3 4 flood frequency at the annual timescale for the less optimistic ssp5 8 5 scenario and far future flood frequency is high with flood occurrence greater than 2 covering a large fraction of the yangtze river network fig 7 a d note that a higher lower than 2 flood occurrence in the future indicates increased reduced number of flood events per year or season compared to the baseline period the highest values flood occurrence 4 tend to occur on the western part of the basin and along the yangtze river at the annual timescale flood frequency is projected to be 2 37 18 6 relative to the baseline and 2 43 21 4 for ssp2 4 5 and ssp5 8 5 in the near future respectively and 2 64 32 2 and 3 10 54 8 for ssp2 4 5 and ssp5 8 5 in the far future respectively at the seasonal timescale accounting for both scenarios and future time periods flood frequency is projected to be 2 52 25 9 2 24 12 0 2 05 2 7 1 67 16 7 for spring summer autumn and winter respectively fig 7e t these elevated values of flood frequency could lead to more frequent episodes of high soil moisture content and high river water levels thus potentially reducing the available recovery time between flood events when examining the spatial pattern of flood frequency similar to flood magnitude fig 5 the jinsha tributary stands out flood frequency in the jinsha tributary is projected to be 3 30 65 1 and 3 46 72 9 floods on average in the near and far future respectively although the frequency of glacial lake outburst floods in the himalaya has not changed in 1988 2017 veh et al 2019 the rapidly growing glacial lakes and acceleration of glacier melt in recent decades gao et al 2021 maurer et al 2020 veh et al 2020 wang et al 2021 are bound to continue into the future which would ultimately trigger more frequent flood hazard and could be an important factor driving increased flood risk along the jinsha tributary our results also indicate that future floods in the jinsha tributary tend to be more severe and frequent which could impact hydroelectricity generation from dams along the jinsha river the jinsha tributary is an important hydropower base in china four large hydropower stations with total installed capacity of 42 960 mw are located along the lower jinsha river wang et al 2015 thus adaptive long term planning will need to be implemented to efficiently balance hydropower and flood mitigation goals future flood mitigation plans should consider the projected changes in flood frequency and magnitude reported here flood frequency in the dongting tributary is projected to decrease or stay stable occurrence 2 compared to the baseline period fig 7 this result has important socioeconomic implications for the hunan province over 96 of the land territory of the hunan province is located in the dongting tributary fig 1 in 2021 the gdp of hunan province which ranked 7th among the 34 provincial administrative regions of china exceeded 5 001 billion yuan 769 4 billion us our results suggest that human activities and infrastructure in the hunan province can be protected against future flood hazard with reasonable investments 3 5 flood duration for the baseline period 1971 2010 and annual timescale flood duration is substantially greater on the western part of the basin than on the eastern part fig 8 a with the flood duration ranging from 2 6 to 31 7 days this pattern varies across seasons fig 8b e the basinwide average value of flood duration is 9 2 14 8 11 3 20 0 and 22 0 days for the whole year spring summer autumn and winter respectively the correlation between annual and seasonal flood duration in descending order is 0 96 summer 0 76 autumn 0 38 spring and 0 31 winter this indicates that the annual flood duration is controlled by summer floods overall there is a tendency for future flood duration to increase across the yangtze river network at the annual timescale fig 9 a d these increases range from 1 7 to 48 5 days and are largest along the main stem of the yrb considering all the future projections two time periods and two scenarios about 77 with yellow orange and red colors out of the 125 reaches are expected to have at least 10 0 days of prolonged flood duration on average at the annual timescale fig 9a d in terms of future seasonal changes the longest flood duration change of 60 4 days occurs in the spring fig 9e h in the summer future flood duration change is mostly positive fig 9i l regardless of time period and scenario by contrast flood duration change tends to be negative in the winter e g 83 reaches mainly located in the upper and middle streams with blue green and yellow colors are projected to experience negative changes fig 9q t flood duration also varies in space for instance the northern yrb exhibits larger duration changes than the southern yrb in the spring and summer seasons however reaches in the southern yrb including the dongting and poyang tributaries show larger duration changes in autumn and winter than the northern yrb flood duration has direct socioeconomic implications in the yrb in general intense rainfall in the yangtze river s lower reaches falls earlier than in the upper reaches and rainfall in the southern yrb falls earlier than in the northern yrb chao et al 2021 these spatial rainfall gradients have generally provided adequate time and regulation capacity to recover between flood events however with longer flood durations the probability of encountering simultaneous floods from multiple tributaries increases which may create conditions for more frequent mega floods in the yrb chen 2019 the 2020 yangtze flood is a vivid example which lasted from early july to late august xia and chen 2020 this long lasting flood resulted in accumulated water levels of 167 65 m in the three gorges dam tgd which is the highest recorded level in the flood season since the tgd s completion mega floods in the yangtze river have the potential to cause large damages for example chongqing a large city with over 32 million people was flooded during the 2020 yangtze flood forcing 251 000 people to take emergency shelter and causing direct economic losses of approximately 0 37 billion us dollars xia and chen 2020 our results show large increases in flood magnitude frequency and duration along the yangtze river highlighting the need to accelerate preparedness efforts for dealing with future flood related surprises 3 6 implications of the multi attribute flood projection projecting flood from a multi attribute perspective offers a more comprehensive view of the potential evolution of future floods projected flood attributes in the yrb converge or diverge in their response to future climate change changes in flood magnitude fig 5 and frequency fig 7 tend to converge by resembling each other the similarities appear across decadal seasonal and spatial changing patterns however flood timing fig 6 and duration fig 9 are not coordinated with changes in flood magnitude and frequency for instance at the annual timescale the most prominent positive changes are projected to take place in the western yrb for flood magnitude and frequency in the middle and lower reaches of the yangtze river for flood timing and in the northern areas of the yrb for flood duration indeed flood duration exhibits a markedly different spatial pattern than flood magnitude the duration of flood decreases from the upper reaches to the lower reaches of the yangtze river fig 8a whereas this trend reverses for flood magnitude fig 4a the diverse temporal and spatial changing patterns of future floods reflected by the multiple flood attributes have different implications for communities in the yrb projected changing signals in flood magnitude and frequency should raise concerns for flood control infrastructure managers changes in flood timing and their potential consequences to agricultural production will be crucially important to farmers urban planners and managers in flood prone cities along the yangtze river network should be concerned with the prolonged duration of future floods as this could make future floods even more damaging than expected from changes in magnitude alone the complex flood signals suggest the need for different stakeholders to come together to develop mitigation strategies for future flooding that emcompass multiple sectors in the yrb 4 conclusion this study projects annual and seasonal relative changes in flood magnitude timing frequency and duration between a baseline 1971 2010 and future period 2021 2060 and 2061 2100 across the yrb china to this end precipitation and maximum minimum temperatures from 10 cmip6 climate models under both ssp2 45 and ssp4 8 5 scenarios are spatially downscaled and bias corrected to force the swat hydrologic model daily projected streamflow derived from the swat model outputs are used to characterize future floods the maxima approach is used to define flood series for flood magnitude and timing whereas the pot approach is used to characterize flood frequency and duration to understand changes in flood regime patterns under global warming in the yrb flood magnitude timing frequency and duration are analyzed and compared at the spatial scale of 125 reaches and temporal scale of three 40 year periods 1971 2010 2021 2060 and 2061 2100 on the basis of our results we emphasize the following conclusions relative to observations in 1971 2010 for the yrb the raw cmip6 ensembles overestimate precipitation by 1 3 mm day whereas the maximum and minimum temperatures are underestimated by 4 4 and 2 2 respectively on average after downscaling the bias between observations and modeled climate variables is largely reduced downscaled climate variables are all projected to increase substantially in the future the increasing trend in climate variables could lead to higher flood hazard and risk highlighting the need to have sound projections of flood hazard under climate change across the yrb future floods in the yrb exhibit pronounced temporal changes from a multi decadal perspective future floods are expected to be the most severe in the far future under the ssp5 8 5 scenario followed by ssp2 4 5 2061 2100 ssp5 8 5 2021 2060 and ssp2 4 5 2021 2060 from a seasonal perspective the most flood prone season in the past has been summer followed by autumn however the most drastic changes in future floods are likely to occur in spring followed by summer autumn and winter thus future strategies will need to account for shifting seasonal floods future floods in the yrb exhibit distinctive patterns of spatial heterogeneity first for the upstream yangtze specifically the jinsha tributary future flood magnitude is projected to increase higher than 25 in spring and summer whereas it decreases lower than 25 in winter flood timing is likely to advance in time flood frequency is anticipated to increase higher than 2 occurrences per year in spring and summer whereas it remains unchanged in autumn and winter second the yrb s northern reaches are projected to experience larger changes than the southern reaches in spring and summer whereas for autumn and winter the projected changes are larger on the southern reaches to improve the effectiveness of flood risk management strategies it will be important to consider these projected changes in the spatial pattern of flood regimes this will require the coordination of flood mitigation strategies at the regional scale overall this study demonstrates the use of multiple flood attributes to improve our understanding of changing flood regimes under future global warming scenarios flood attributes may converge or diverge in their response to climate change which has different implications for communities in the yrb these patterns of future flood attribute changes suggest that different stakeholders need to come together in planning and implementing flood mitigation strategies future studies could further emphasize the complex interactions between different flood generating mechanisms e g extreme rainfall snowmelt and soil moisture and flood regimes this study mostly focusses on characterizing changing flood hazards under future climate change in addition translating flood hazards to risk would require exploring the intersection between flood hazard exposure and vulnerability credit authorship contribution statement chen zhang conceptualization supervision fengyun sun conceptualization writing original draft methodology software formal analysis funding acquisition sanjib sharma methodology writing review editing peng zeng software alfonso mejia formal analysis writing review editing yongpeng lyu investigation jun gao data curation rui zhou resources yue che supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work is supported by the national science foundation for young scientists of china grant number 42007417 
2458,climate change is altering flood risk globally the nature of those alterations varies locally creating the need for regional assessments to inform flood risk management and planning this study projects future changes in flood regime in the yangtze river basin to characterize flood regimes we use a multi attribute approach that measures the relative change in flood magnitude timing frequency and duration between historical and future periods we use climate projections from the coupled model intercomparison project phase 6 cmip6 to force the soil and water assessment tool swat and generate daily streamflow projections along the yangtze river network for two shared socioeconomic pathways ssps ssp2 4 5 and ssp5 8 5 we use seasonal maxima annual maxima and peaks over threshold to determine the different flood attributes results show that downscaled cmip6 precipitation and near surface temperature are both projected to increase substantially in the future with a consequent surge in floods across the basin in the far future years 2061 2100 under ssp5 8 5 average annual flood magnitude timing frequency and duration are projected to increase 66 6 arrive 1 9 days earlier increase 27 5 and prolong 19 1 days respectively projected changes in flood attributes at annual timescale are generally higher in the basin s northern tributaries than in the southern ones changes in flood magnitude and frequency tend to resemble each other whereas flood timing and duration exhibit distinct change patterns our multi attribute approach to flood regime characterization provides a systematic way for translating raw cmip6 projections into informative future flood projections this approach can help inform flood risk planning and improve the reliability of climate change impact assessment keywords climate projections cmip6 hydrologic modeling flood projections yangtze river basin data availability data will be made available on request 1 introduction the yangtze river basin yrb one of the largest river basins in the world occupies approximately 1 2 of the world s land area wang et al 2020a accommodates about 5 8 of world s population li et al 2021a and contributes over 7 0 of world s total gross domestic product gdp chen 2019 flooding is the most frequent and damaging natural disaster in the yrb xia and chen 2020 the most damaging flood since the start of the observation record occurred in 1954 yu et al 2009 causing over 30 000 fatalities and inundating 3 17 million hectares of land kundzewicz et al 2019 the second most disastrous basin wide flood occurred in 1998 yu et al 2009 which resulted in approximately 13 2 million people left homeless 3 600 fatalities and 36 billion us in nominal 1998 dollars in economic losses ye and glantz 2005 hence the chinese government has invested substantial resources to develop flood adaptation mitigation and management strategies in the yrb wei et al 2020 for example in 2011 the overall plan for the follow up work of the three gorges project invested 61 70 billion yuan 9 5 billion us to enhance the safety standards of 26 hazardous projects in the hunan and hubei provinces chen 2019 the 172 major water conservancy projects for water saving and water supply in china invested 103 billion yuan 15 8 billion us to strengthen the flood protection capability of 11 projects along the yangtze river in the jiangxi anhui and jiangsu provinces chen 2019 despite the implementation of these flood risk management strategies chen 2019 which included improved safety standards for flood defense projects ma 2020 and an advanced early warning system shang et al 2020 the recent flood of 2020 resulted in devastating losses zhou et al 2021 this flood event has been considered the worst since 1998 wei et al 2020 affecting over 78 6 million people with 279 fatalities and 5 3 million evacuees nationwide causing in china over 41 billion us in direct economic losses ministry of water resources of china 2021 the majority of these losses were attributed to flooding in the yrb xia and chen 2020 zhou et al 2021 with knowledge of significant flooding losses in the yrb s past question arises on how will climate change drive the changes in the pattern of flood regimes in the yrb s future study based on climate projections from the coupled model intercomparison project phase 5 cmip5 indicates that projected flood magnitude across yrb is overall increasing yu et al 2018a b future floods in the yrb have also been projected using the cmip6 output yang et al 2022 concludes that floods in the yrb are projected to be more frequent and severe due to the variability of the western pacific subtropical high under greenhouse warming whereas xiong et al 2022 using the flood potential index projects decrease in flood potential with future climate several other studies have used cmip6 outputs to explore trends in future hydroclimatic extremes in the yrb li et al 2021b wu et al 2022 zhao et al 2022 however these studies have mostly relied on a single index to assess or infer flood hazards in future periods we perform here for the first time a multi attribute i e magnitude timing frequency and duration analysis of projected flood regimes for the yrb by using multiple attributes we provide a more complete picture of flood hazards than possible based on a single attribute comprehensive and detailed characterization on changes of flood regimes are relevant to decision and policy making the main objective of this study is to assess the projected changes in flood magnitude timing frequency and duration at both annual and seasonal timescales across the yrb using the cmip6 climate model ensemble under two shared socioeconomic pathways ssps ssp2 4 5 and ssp5 8 5 for this downscaled climate variables precipitation and near surface temperature from 10 cmip6 climate models under both the ssp2 4 5 and ssp5 8 5 scenarios are used to force the soil and water assessment tool swat and generate a spatially and temporally consistent ensemble of streamflow projections changes in flood magnitude timing frequency and duration are examined and compared for two future periods 2021 2060 and 2061 2100 relative to the baseline period 1971 2010 by considering multiple flood attributes and their concurrent responses we offer a new perspective for understanding flood regimes under different global warming scenarios using multiple flood attributes this study addresses the following questions i what are the patterns of flood regime in the yrb during the baseline period of 1971 2010 ii how are those patterns projected to change at both annual and seasonal timescales based on cmip6 climate projections and iii how do changes in different flood attributes affect the assessment of current and future flood hazard 2 materials and methods 2 1 study area the yangtze river also known as the changjiang is the longest in asia and third longest in the world and a major waterway globally gao et al 2021 zhang et al 2022 the yangtze river originates in the qinghai tibet plateau and flows generally eastwards into the east china sea fig 1 the drainage area of the yrb is roughly 1 8 million km2 precipitation is abundant in the yrb with an annual average precipitation of around 1 200 mm li et al 2021a however the spatial and temporal distribution of precipitation is highly uneven the annual precipitation increases from west to east ranging from 300 mm year in the west to 2400 mm year in the east li et al 2021a and over 75 of the annual precipitation occurs in summer yu et al 2009 this spatiotemporal difference is partly due to complex terrain across the yrb the total altitude difference from the source of the yangtze river to its estuary is more than 6 000 m zhu et al 2021 in such a mega and complex river system a comprehensive understanding of future flood projections is crucial to inform adaptive decision making and flood management 2 2 hydrologic modeling and model calibration we use the soil and water assessment tool swat to simulate the long term streamflow response to climate change in the yrb the swat model is a physically based distributed hydrological model for long term simulation in large and complex basins arnold et al 2012 the swat model has been successfully used to conduct flood hazard assessment in various contexts e g cheng et al 2017 shadmehri toosi et al 2019 yu et al 2018a b similar studies on hydrological extremes have been increasingly conducted around the world tan et al 2020 the detailed information on setting up calibration and validation of the constructed swat for the yrb used in this study have been reported elsewhere in sun et al 2019a b for the sake of completeness we report here the calibration and validation details the swat model was calibrated and validated using 21 year long consecutive daily streamflow observations from 18 hydrological gauges across the yrb the streamflow data were provided by the changjiang river water resources commission cwrc the calibration and validation period are 15 years january 1st 1990 december 31st 2004 and 6 years january 1st 2005 december 31st 2010 respectively swat model performance is routinely measured by the coefficient of determination r2 and the nash sutcliffe coefficient ns r2 measures the proportion of the variance in measured data explained by the modeled data which ranges between 0 and 1 the higher the value the better the fit and values greater than 0 5 are considered acceptable castillo et al 2014 ns measures the relative magnitude of the residual variance compared to the measured data variance which ranges from to 1 with the performance rating acceptable if values between 0 and 1 castillo et al 2014 over the combined calibration and validation period of 1990 2010 the average r2 and ns values are 0 84 0 44 0 9 and 0 71 0 32 0 89 table 1 and fig 2 respectively fig 2 shows that the calibrated swat model reasonably captures both the average and extreme daily flows in the yrb which makes the model suitable for the present study 2 3 cmip6 projections and post processing cmip6 outputs are used to force the swat model and obtain projected daily streamflow time series across reaches in the yrb together these reaches represent the yrb s main river network fig 1 we use 10 climate models as forcing to the swat model table 2 study suggests that using the median of around 10 climate models in studies of climate change impacts on hydrology generates similar uncertainty components as the whole ensemble wang et al 2020b the climate models are searched using the following constraints variable pr tasmax tasmin frequency day variant label r1i1p1f1 experiment id historical ssp245 ssp585 grid label gn https esgf node llnl gov search cmip6 from the search results we adopt all climate models with no missing data to examine extreme events with emphasis on climate change we employ two commonly used scenarios that representing the medium to high end of future forcing pathway ssp2 4 5 and ssp5 8 5 the ssp2 4 5 scenario updates the rcp4 5 in cmip5 radiative forcing stabilized at 4 5 w m2 before 2100 and the ssp5 8 5 scenario updates the rcp8 5 radiative forcing n8 5 w m2 by 2100 eyring et al 2016 o neill et al 2016 however for regional studies bias correction and spatial downscaling are needed to adjust global climate projections therefore for each climate model simulation 20 in total 10 models times 2 scenarios the meteorological fields of precipitation and maximum minimum near surface temperatures are downscaled the downscaled climate variables are then used to generate daily streamflow projections for the period of 2021 2100 at 125 subbasin outlets in the yrb a modified version of the daily bias correction spatial disaggregation bcsd downscaling approach girvetz et al 2013 wood et al 2004 is used to bias correct the meteorological fields this downscaling approach has been successfully applied in several previous studies sun et al 2019b 2020 zeng et al 2021 to correct systematic biases in different meteorological variables further details about the modified version of the daily bcsd method are described elsewhere sun et al 2019b 2020 zeng et al 2021 after forcing the swat model with the downscaled meteorological variables 20 different streamflow projections are obtained one streamflow projection for each climate model simulation 10 climate models times 2 scenarios 2 4 flood regime analysis for the flood regime analysis we use the daily streamflow projections to calculate the four flood attributes magnitude timing frequency and duration by using multiple attributes we perform for the first time a multi attribute analysis of projected flood regimes in the yrb the flood attributes are calculated for the near future 2021 2060 and the far future 2061 2100 and compared against the baseline period 1971 2010 floods along the yangtze river have distinct seasonal characteristics yu et al 2009 and studies suggest that gcms perform satisfactorily at both the annual and seasonal timescales villarini and zhang 2020 hence we perform the flood analysis at both of these timescales seasons are defined as follows spring march may summer june august autumn september november and winter december february the same method is used to derive seasonal and annual floods but seasonal floods are calculated by only considering the streamflow time series for the seasonal period under consideration e g for the spring season the period is march 1st to may 31st whereas annual floods are based on the whole year the determination of floods varies depending on the flood attribute as described next see eqs 1 10 note that in all the equations year n indicates one of the 40 years in the baseline or future periods model m indicates one of the 10 selected climate models reach indicates one of the yangtze river network s 125 reaches baseline indicates the baseline period scenario indicates the ssp2 4 5 or ssp5 8 5 scenario and future indicates the near or far future period 2 4 1 flood magnitude the magnitude of a flood is quantified as the maximum daily streamflow value of a flood event flood magnitude is characterized using the seasonal or annual maximum streamflow mudersbach et al 2017 the annual flood magnitude indicates the maximum value of streamflow in each year 12 months whereas the seasonal flood magnitude represents the maximum streamflow in each season 3 months the relative change of flood magnitude between the baseline and future period δ f m reach s c e n a r i o f u t u r e is calculated as 1 δ f m reach s c e n a r i o f u t u r e fm reach s c e n a r i o f u t u r e fm reach b a s e l i n e fm reach b a s e l i n e 100 where fm reach b a s e l i n e is the median of the annual maximum streamflow across n years for the baseline scenario and fm reach s c e n a r i o f u t u r e is the median of the annual maximum streamflow for the m selected climate models across n years for the future period eq 1 together with the seasonal maximum streamflow is also used to calculate the relative change of flood magnitude for each season 2 4 2 flood timing flood timing is defined as the date of occurrence of a flood blöschl et al 2017 flood timing has gained prominence as a tool for flood hazard analysis do et al 2020 ficchì and stephens 2019 wasko et al 2020 similar to flood magnitude flood timing is also calculated using the maximum streamflow over a given time interval that is the same definition of flood is used to calculate both flood magnitude and timing however we do not perform the seasonal analysis for flood timing since flood timing itself could reflect seasonal changes blöschl et al 2017 do et al 2020 circular statistics are often used to investigate flood timing as it exists on a cyclical continuum wasko et al 2020 on a circular scale the ordinal day from 1 to 365 or 366 and starting on january 1st of a flood at the end of a year is close to a flood occurring at the start of the following year but on a linear scale these day numbers are far apart bayliss and jones 1993 to perform circular statistics the ordinal day d i needs to be converted to an angular value θ i 2 θ i d i m i 2 π 0 θ i 2 π where m i is the number of days in the ith year i e 365 days for a normal year and 366 days for leap years and i 1 n is the number of years the mean timing in ordinal day is given by fisher 1993 x 1 n i 1 n cos θ i y 1 n i 1 n sin θ i m 1 n i 1 n m i 3 d tan 1 y x m 2 π x 0 y 0 tan 1 y x π m 2 π x 0 tan 1 y x 2 π m 2 π x 0 y 0 another useful metric of flood seasonality is the concentration index ci which communicates information about changes in the flood timing concentration 4 ci x 2 y 2 0 c i 1 note that ci varies from 0 to 1 with ci 0 indicating that the flood occurrence dates are spread evenly throughout the year and ci 1 indicating that all flooding events occur on the same ordinal day do et al 2020 for our analysis we compute the change in the timing and concentration index between the baseline and future periods for each reach 2 4 3 flood frequency flood frequency is defined as the number of flood events within a time interval e g a season or year when dealing with flood frequency we employ the peaks over threshold pot approach the pot dataset extracts all the streamflow values exceeding a selected streamflow threshold the number of separate excursions above the threshold in each year is counted as the frequency of flood villarini et al 2012 several approaches have been proposed for threshold selection lang et al 1999 in this study the threshold for each reach is selected so that there are two floods per year on average in the baseline period a pot dataset including two or three floods per year on average was suggested by lang et al 1999 and this criterion has been adopted in other studies roth et al 2012 villarini et al 2011 to consistently compare the baseline and future flood frequencies we use the same threshold from the baseline period to count the number of flood events in future periods we calculate the flood frequency at annual timescale for each reach for the baseline period we obtain the maximum of 80 2 floods 40 years floods f m 80 reach b a s e l i n e with the condition that only one flood is counted within a 15 day time window this is commonly done to avoid counting the same event twice lang et al 1999 mallakpour and villarini 2015 5 f m 80 reach b a s e l i n e m a x 80 streamflow reach b a s e l i n e date f l o o d s e q j 1 date f l o o d s e q j 15 0 j 80 where date f l o o d s e q j indicates the date serial date number of the number j flood we assign the minimum value of f m 80 reach b a s e l i n e as the threshold threshhold reach b a s e l i n e for identifying floods in the future periods for the future periods we iteratively add 1 to the frequency of flood ff if a streamflow is higher than or equal to the threshhold reach b a s e l i n e note that the 15 day period rule applied in the baseline period is also applied in eq 6 6 ff ff 1 s t r e a m f l o w model r e a c h s c e n a r i o f u t u r e threshhold reach b a s e l i n e f f 0 streamflow model r e a c h s c e n a r i o f u t u r e threshhold reach b a s e l i n e date f l o o d s e q j 1 date f l o o d s e q j 15 lastly we calculate the median flood frequency for the m selected climate models such that 7 ff reach s c e n a r i o f u t u r e m e d i a n ff model 1 r e a c h s c e n a r i o f u t u r e ff model m r e a c h s c e n a r i o f u t u r e given that the value of flood frequency is easier to interpret than for the other flood regime attributes we use the absolute value rather than the change relative to the baseline period to analyze the flood frequency thus an average of 2 floods per year in the future projected period indicates a similar flood frequency to the baseline period whereas higher values more than 2 floods per year on average indicate an increase in flood frequency for the future compared to the baseline 2 4 4 flood duration the duration of a flood event is defined as the number of consecutive days between the flood beginning and end dates najibi and devineni 2018 thus a flood includes the date when the streamflow first climbs above the selected threshold as the beginning and the date before the streamflow first drops below the threshold as the end for consistency the same threshold is used to calculate both the flood duration and flood frequency metrics however the 15 day period rule applied to the flood frequency metric is not used for flood duration to avoid disrupting the flood duration information we compute the flood duration for each reach at the annual timescale to do this we replace streamflow values with 1 for flood magnitudes greater than or equal to the threshhold reach b a s e l i n e and 0 otherwise eq 8 threshhold reach b a s e l i n e is the flood magnitude threshold derived from the baseline period fd is the derived binary time series and fm model r e a c h s c e n a r i o p e r i o d indicates the flood magnitude time series for a particular combination of model reach scenario and period 8 fd 1 fm model r e a c h s c e n a r i o f u t u r e threshhold reach b a s e l i n e 0 fm model r e a c h s c e n a r i o f u t u r e threshhold reach b a s e l i n e the yearly averaged flood duration fd model r e a c h s c e n a r i o p e r i o d is calculated as the total number of days greater than or equal to the baseline threshold divided by the number of years n 9 fd model r e a c h s c e n a r i o f u t u r e s u m f d n and the change in flood duration δ f d reach s e n a r i o f u t u r e between the baseline and future period is calculated as 10 δ f d reach s e n a r i o f u t u r e fd reach s e n a r i o f u t u r e fd reach b a s e l i n e where fd reach b a s e l i n e is the average flood duration for the baseline period and fd reach s c e n a r i o f u t u r e is the median of the m climate models average flood duration for the future period 3 results and discussion 3 1 precipitation and temperature projections downscaled mean precipitation and maximum minimum temperatures are used as forcing to the swat model for projecting river streamflow in the future periods appropriate downscaling performance guarantees the reliability of streamflow projections girvetz et al 2013 sun et al 2020 fig 3 illustrates the downscaling performance of mean precipitation and maximum minimum temperatures for the ssp2 4 5 left panels and ssp5 8 5 right panels scenarios in the period 1955 2014 the average daily observed mean precipitation fig 3a b maximum temperature fig 3c d and minimum temperature fig 3e f are 2 8 mm day 18 7 and 8 7 respectively by contrast for the same historical period the cmip6 ensemble means of raw precipitation maximum temperature and minimum temperature are 4 1 mm day 14 3 and 6 5 respectively overall for the yrb the raw cmip6 ensemble tends to overestimate precipitation by 1 3 mm day 46 4 and underestimate maximum temperature by 4 4 23 5 and mimimum temperature by 2 2 25 3 on average large variability exists among different cmip6 climate models in the baseline period the outputs average values from the 10 climate models ranges between 3 2 mm day 14 3 mri esm2 0 and 5 1 mm day 82 1 access esm1 5 for precipitation 10 6 43 3 nesm3 and 17 0 9 1 miroc6 for maximum temperature and 3 0 65 5 canesm5 and 9 0 3 4 nesm3 for minimum temperature fig 3 the bias and variability of the raw cmip6 historical simulations extend to the raw cmip6 future projections suggesting the need to use downscaled bias corrected climate projections as done in this study when assessing future floods fig 3 shows that after implementing the downscaling algorithm the large bias between the raw model projections orange shade with blue line and observations black solid line is substantially reduced and that there is a smooth temporal transition between the downscaled projections blue shade with yellow line and observations the average standard deviations of downscaled precipitation maximum temperature and minimum temperature ensembles are reduced from 0 7 to 0 2 1 9 to 0 4 and 1 2 to 0 6 respectively compared to the raw ensembles the downscaled projections largely improve the credibility of cmip6 precipitation and temperature projections and therefore contribute to improving the credibility of the streamflow projections derived here from these climate outputs a reliable downscaling technique should not only correct the bias but also preserve the projected temporal trend for each variable fig 3 shows that after downscaling the trend of the downscaled variables is well preserved e g the r2 between the raw and downscaled rcps is 0 98 on average the overall downscaled trend consists of i increase in precipitation of 0 3 mm day 10 0 and 0 6 mm day 19 3 for ssp2 4 5 and ssp5 8 5 respectively ii increase in maximum temperature of 2 3 11 6 and 5 0 25 9 respectively iii increase in minimum temperature of 2 0 20 4 and 4 6 48 7 respectively fig 3 further both precipitation and temperature are projected to increase significantly under future climates p value 0 01 studies indicate that a warmer and wetter atmosphere will intensify the water cycle and ultimately generate more severe flood events li et al 2021b najibi and devineni 2018 yang et al 2019 hence the increasing trends observed in the cmip6 projections support the need to investigate regional flood hazards in the flood prone yrb 3 2 flood magnitude fig 4 shows the simulated annual and seasonal flood magnitude in 1971 2010 the annual flood magnitude ranges from 100 6 to 82 375 0 m3 s along the yangtze river network which mainly reflects an increase in flood magnitude with the accumulation of drainage area as one moves from upstream to downstream in the river network flood magnitude shows a distinct seasonal variation flood magnitude is typically larger in summer followed by autumn whereas winter has generally a lower flood magnitude fig 4 the relative differences between seasonal and annual floods across the river network are 69 3 spring 11 1 summer 45 7 autumn and 83 0 winter on average the relatively small difference as well as the close resemblance pearson s correlation r 0 99 between summer and annual floods indicate that summer is the most flood prone season in the yrb fig 5 shows the annual and seasonal percent change in flood magnitude in the near future 2021 2060 and far future 2061 2100 relative to the baseline period 1971 2010 recall that we characterize future floods using two socioeconomic scenarios ssp2 4 5 and ssp5 8 5 the percent change is categorized using five classes with colder colors indicating negative changes and warmer colors positive changes negative changes indicate decreased flood magnitude in the future period compared to the historical period whereas positive changes indicate increased changes at the annual timescale fig 5a d in the near future 63 2 and 60 8 of the yangtze river network experiences a flood magnitude shift greater than 25 in the ssp2 4 5 fig 5a and ssp5 8 5 fig 5b scenarios respectively these percentages jump to 68 0 and 86 4 in the far future under ssp2 4 5 fig 5c and ssp5 8 5 fig 5d respectively the annual positive shift is mostly contributed by spring fig 5e h and summer fig 5i l floods which together account for 56 4 of the network reaches exceeding a 25 relative change by contrast the winter flood magnitudes show a clear negative shift with 84 8 and 80 0 of the network reaches exhibiting negative change values for ssp2 4 5 fig 5q and ssp5 8 5 fig 5r in the near future respectively however these negative change values reduce to 72 0 and 61 6 of the network reaches in the far future for ssp2 4 5 fig 5s and ssp5 8 5 fig 5t respectively in autumn neither the positive nor the negative changes are as evident as in other seasons flood magnitude is expected to increase drastically in future climate projections under the ssp5 8 5 scenario fig 5 for instance the average relative changes are projected to be 66 6 82 3 51 3 47 4 and 3 8 at the annual spring summer autumn and winter timescales respectively there are 49 tributaries in the yrb with an area larger than one million km2 and flow rates as high as millions cubic per second chen 2019 with the potential to cause catastrophic losses therefore the projected increase in flood magnitude has important implications for current flood design standards and flood protection infrastructure in the yrb for example the flood control standards for the middle and lower reaches of the yrb were designed based on the 1954 flood xia and chen 2020 in addition most of the 51 200 reservoirs in the yrb which together have brought huge flood protection benefits in the past were built between 1950 and 1970 cao and zhang 2012 given outdated design standards and reservoirs that are approaching their design life future increases in flood magnitude raise concerns about the resilience of current flood control infrastructure in the yrb the overall spatial variability of flood magnitude is explained by differences in the hydrological behavior of major tributaries fig 5 for example the jinsha tributary located on the western yrb near the eastern himalayas fig 1 shows large positive changes in flood magnitude higher than 50 in the spring and summer across the climate scenarios and future time periods this projected increase in flood magnitude may due to glacier melt from the himalayas more than 5 000 glacier lakes have already spawned in the himalayas veh et al 2020 this process of melting glaciers is rapidly growing and would accelerate under future global warming scenarios gao et al 2021 maurer et al 2020 the abundant water storage in the glacier lakes can introduce glacier lake outburst floods in the jinsha tributary wang et al 2021 studies suggest that flood magnitude from glacier lake outburst in the himalayas can rival monsoon fed discharges in major rivers hundreds to thousands of kilometers downstream veh et al 2020 indeed fig 5a d shows that the warmer the climate the more severe the flood magnitude 3 3 flood timing in the baseline period fig 6 a average values of flood timing fall between may 23rd ordinal date of 143 and september 13th ordinal date of 256 with an average date of july 26th ordinal date of 207 overall flood timing lags behind on the western and southern yrb compared to rivers on the eastern and northern yrb which is consistent with the results from chen 2019 flood timing is similar in the near and far future periods for both climate scenarios fig 6b f for the future periods the average flood timing falls between june 1st ordinal date of 152 and august 19th ordinal date of 231 with an average date of july 23th ordinal date of 204 compared to the baseline period future flood timing dates are anticipated to arrive 13 9 days earlier on average in the jinsha tributary while a timing delay 0 05 days on average is expected on the central and eastern portions of the yangtze river network the earlier timing in the upstream yangtze may potentially contribute to the increased changes in future flood magnitude along the jinsha tributary in spring and summer compared to the baseline period fig 5 the earlier onset and longer duration of the mei yu in chinese also called baiu in japanese season zhou et al 2021 was previously reported kundzewicz et al 2019 which could increase risk of spring and summer floods the concentration of flood timing is generally lower in the future than in the baseline period fig 6g the future projected concentration of flood timing is consistent across the ssp2 4 5 and ssp5 8 5 scenarios suggesting that this may be a persistent feature of future flood regimes that is likely to manifest in the near future fig 6h i k and l overall an average percent of 53 4 77 8 and 94 4 reaches show backward or forward timing variations within 5 days 10 days and 20 days respectively some of the mechanisms driving the changing pattern of flood timing could be intense precipitation snowmelt and rain on snow events do et al 2020 the future changes in flood timing reported here have important implications for agricultural activities in the yrb given the flat terrain abundant water resources and moderate temperature in the middle and lower reaches of the yangtze river this area has long been known as the land of fish and rice liu et al 2019 to cope with already manifested earlier floods farmers in the middle and lower basins of the yrb have adjusted their rice planting structure in recent years adding middle and late rice varieties with higher yields zhang et al 2018 nonetheless studies suggest that even small shifts in flood timing can have a marked impact on crop production losses ficchì and stephens 2019 wasko et al 2020 this in combination with our flood timing results suggests that farmers on the yangtze floodplains will need to continue adapting their agricultural practices to a changing pattern of flood timing 3 4 flood frequency at the annual timescale for the less optimistic ssp5 8 5 scenario and far future flood frequency is high with flood occurrence greater than 2 covering a large fraction of the yangtze river network fig 7 a d note that a higher lower than 2 flood occurrence in the future indicates increased reduced number of flood events per year or season compared to the baseline period the highest values flood occurrence 4 tend to occur on the western part of the basin and along the yangtze river at the annual timescale flood frequency is projected to be 2 37 18 6 relative to the baseline and 2 43 21 4 for ssp2 4 5 and ssp5 8 5 in the near future respectively and 2 64 32 2 and 3 10 54 8 for ssp2 4 5 and ssp5 8 5 in the far future respectively at the seasonal timescale accounting for both scenarios and future time periods flood frequency is projected to be 2 52 25 9 2 24 12 0 2 05 2 7 1 67 16 7 for spring summer autumn and winter respectively fig 7e t these elevated values of flood frequency could lead to more frequent episodes of high soil moisture content and high river water levels thus potentially reducing the available recovery time between flood events when examining the spatial pattern of flood frequency similar to flood magnitude fig 5 the jinsha tributary stands out flood frequency in the jinsha tributary is projected to be 3 30 65 1 and 3 46 72 9 floods on average in the near and far future respectively although the frequency of glacial lake outburst floods in the himalaya has not changed in 1988 2017 veh et al 2019 the rapidly growing glacial lakes and acceleration of glacier melt in recent decades gao et al 2021 maurer et al 2020 veh et al 2020 wang et al 2021 are bound to continue into the future which would ultimately trigger more frequent flood hazard and could be an important factor driving increased flood risk along the jinsha tributary our results also indicate that future floods in the jinsha tributary tend to be more severe and frequent which could impact hydroelectricity generation from dams along the jinsha river the jinsha tributary is an important hydropower base in china four large hydropower stations with total installed capacity of 42 960 mw are located along the lower jinsha river wang et al 2015 thus adaptive long term planning will need to be implemented to efficiently balance hydropower and flood mitigation goals future flood mitigation plans should consider the projected changes in flood frequency and magnitude reported here flood frequency in the dongting tributary is projected to decrease or stay stable occurrence 2 compared to the baseline period fig 7 this result has important socioeconomic implications for the hunan province over 96 of the land territory of the hunan province is located in the dongting tributary fig 1 in 2021 the gdp of hunan province which ranked 7th among the 34 provincial administrative regions of china exceeded 5 001 billion yuan 769 4 billion us our results suggest that human activities and infrastructure in the hunan province can be protected against future flood hazard with reasonable investments 3 5 flood duration for the baseline period 1971 2010 and annual timescale flood duration is substantially greater on the western part of the basin than on the eastern part fig 8 a with the flood duration ranging from 2 6 to 31 7 days this pattern varies across seasons fig 8b e the basinwide average value of flood duration is 9 2 14 8 11 3 20 0 and 22 0 days for the whole year spring summer autumn and winter respectively the correlation between annual and seasonal flood duration in descending order is 0 96 summer 0 76 autumn 0 38 spring and 0 31 winter this indicates that the annual flood duration is controlled by summer floods overall there is a tendency for future flood duration to increase across the yangtze river network at the annual timescale fig 9 a d these increases range from 1 7 to 48 5 days and are largest along the main stem of the yrb considering all the future projections two time periods and two scenarios about 77 with yellow orange and red colors out of the 125 reaches are expected to have at least 10 0 days of prolonged flood duration on average at the annual timescale fig 9a d in terms of future seasonal changes the longest flood duration change of 60 4 days occurs in the spring fig 9e h in the summer future flood duration change is mostly positive fig 9i l regardless of time period and scenario by contrast flood duration change tends to be negative in the winter e g 83 reaches mainly located in the upper and middle streams with blue green and yellow colors are projected to experience negative changes fig 9q t flood duration also varies in space for instance the northern yrb exhibits larger duration changes than the southern yrb in the spring and summer seasons however reaches in the southern yrb including the dongting and poyang tributaries show larger duration changes in autumn and winter than the northern yrb flood duration has direct socioeconomic implications in the yrb in general intense rainfall in the yangtze river s lower reaches falls earlier than in the upper reaches and rainfall in the southern yrb falls earlier than in the northern yrb chao et al 2021 these spatial rainfall gradients have generally provided adequate time and regulation capacity to recover between flood events however with longer flood durations the probability of encountering simultaneous floods from multiple tributaries increases which may create conditions for more frequent mega floods in the yrb chen 2019 the 2020 yangtze flood is a vivid example which lasted from early july to late august xia and chen 2020 this long lasting flood resulted in accumulated water levels of 167 65 m in the three gorges dam tgd which is the highest recorded level in the flood season since the tgd s completion mega floods in the yangtze river have the potential to cause large damages for example chongqing a large city with over 32 million people was flooded during the 2020 yangtze flood forcing 251 000 people to take emergency shelter and causing direct economic losses of approximately 0 37 billion us dollars xia and chen 2020 our results show large increases in flood magnitude frequency and duration along the yangtze river highlighting the need to accelerate preparedness efforts for dealing with future flood related surprises 3 6 implications of the multi attribute flood projection projecting flood from a multi attribute perspective offers a more comprehensive view of the potential evolution of future floods projected flood attributes in the yrb converge or diverge in their response to future climate change changes in flood magnitude fig 5 and frequency fig 7 tend to converge by resembling each other the similarities appear across decadal seasonal and spatial changing patterns however flood timing fig 6 and duration fig 9 are not coordinated with changes in flood magnitude and frequency for instance at the annual timescale the most prominent positive changes are projected to take place in the western yrb for flood magnitude and frequency in the middle and lower reaches of the yangtze river for flood timing and in the northern areas of the yrb for flood duration indeed flood duration exhibits a markedly different spatial pattern than flood magnitude the duration of flood decreases from the upper reaches to the lower reaches of the yangtze river fig 8a whereas this trend reverses for flood magnitude fig 4a the diverse temporal and spatial changing patterns of future floods reflected by the multiple flood attributes have different implications for communities in the yrb projected changing signals in flood magnitude and frequency should raise concerns for flood control infrastructure managers changes in flood timing and their potential consequences to agricultural production will be crucially important to farmers urban planners and managers in flood prone cities along the yangtze river network should be concerned with the prolonged duration of future floods as this could make future floods even more damaging than expected from changes in magnitude alone the complex flood signals suggest the need for different stakeholders to come together to develop mitigation strategies for future flooding that emcompass multiple sectors in the yrb 4 conclusion this study projects annual and seasonal relative changes in flood magnitude timing frequency and duration between a baseline 1971 2010 and future period 2021 2060 and 2061 2100 across the yrb china to this end precipitation and maximum minimum temperatures from 10 cmip6 climate models under both ssp2 45 and ssp4 8 5 scenarios are spatially downscaled and bias corrected to force the swat hydrologic model daily projected streamflow derived from the swat model outputs are used to characterize future floods the maxima approach is used to define flood series for flood magnitude and timing whereas the pot approach is used to characterize flood frequency and duration to understand changes in flood regime patterns under global warming in the yrb flood magnitude timing frequency and duration are analyzed and compared at the spatial scale of 125 reaches and temporal scale of three 40 year periods 1971 2010 2021 2060 and 2061 2100 on the basis of our results we emphasize the following conclusions relative to observations in 1971 2010 for the yrb the raw cmip6 ensembles overestimate precipitation by 1 3 mm day whereas the maximum and minimum temperatures are underestimated by 4 4 and 2 2 respectively on average after downscaling the bias between observations and modeled climate variables is largely reduced downscaled climate variables are all projected to increase substantially in the future the increasing trend in climate variables could lead to higher flood hazard and risk highlighting the need to have sound projections of flood hazard under climate change across the yrb future floods in the yrb exhibit pronounced temporal changes from a multi decadal perspective future floods are expected to be the most severe in the far future under the ssp5 8 5 scenario followed by ssp2 4 5 2061 2100 ssp5 8 5 2021 2060 and ssp2 4 5 2021 2060 from a seasonal perspective the most flood prone season in the past has been summer followed by autumn however the most drastic changes in future floods are likely to occur in spring followed by summer autumn and winter thus future strategies will need to account for shifting seasonal floods future floods in the yrb exhibit distinctive patterns of spatial heterogeneity first for the upstream yangtze specifically the jinsha tributary future flood magnitude is projected to increase higher than 25 in spring and summer whereas it decreases lower than 25 in winter flood timing is likely to advance in time flood frequency is anticipated to increase higher than 2 occurrences per year in spring and summer whereas it remains unchanged in autumn and winter second the yrb s northern reaches are projected to experience larger changes than the southern reaches in spring and summer whereas for autumn and winter the projected changes are larger on the southern reaches to improve the effectiveness of flood risk management strategies it will be important to consider these projected changes in the spatial pattern of flood regimes this will require the coordination of flood mitigation strategies at the regional scale overall this study demonstrates the use of multiple flood attributes to improve our understanding of changing flood regimes under future global warming scenarios flood attributes may converge or diverge in their response to climate change which has different implications for communities in the yrb these patterns of future flood attribute changes suggest that different stakeholders need to come together in planning and implementing flood mitigation strategies future studies could further emphasize the complex interactions between different flood generating mechanisms e g extreme rainfall snowmelt and soil moisture and flood regimes this study mostly focusses on characterizing changing flood hazards under future climate change in addition translating flood hazards to risk would require exploring the intersection between flood hazard exposure and vulnerability credit authorship contribution statement chen zhang conceptualization supervision fengyun sun conceptualization writing original draft methodology software formal analysis funding acquisition sanjib sharma methodology writing review editing peng zeng software alfonso mejia formal analysis writing review editing yongpeng lyu investigation jun gao data curation rui zhou resources yue che supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work is supported by the national science foundation for young scientists of china grant number 42007417 
2459,urban flooding is one of the most widespread natural hazards in modern cities risk mapping provides critical information for flood risk management to reduce life and economic loss as a widely used approach to support flood risk mapping physical based modeling suffers from model accuracy and computation complexity empirical methods rely on availability of rich disaster data and are not normally transferable for fast flood prediction to different cities both methods require high quality hazard data and disaster information for reliable prediction which are not always available this paper presents an alternative near real time flood risk mapping method for data scarce environments developed using social sensing and region stable deep neural network rs dnn by extracting disaster information in near real time using social sensing techniques and considering risk distribution factors rather than flood influencing factors this new method enables flood risk mapping and analysis cross a large domain in minutes with all input data openly available the proposed method can be adapted to different disaster process and different case study cities through timely social sensing keywords data scarcity flood risk mapping region stable dnn risk distribution factors social sensing data availability data will be made available on request 1 introduction urban flooding is a widespread natural hazard threatening people s lives and properties in urban cities across the world rapid urbanization in the 21 century has increased the density of both population and property in cities leading to substantially increased flood vulnerability pourghasemi et al 2019 globally flooding accounts for more than 30 of total disaster loss every year yousefi et al 2021 and the flood impact has a clear increasing trend due to climate change and the on going urbanization jongman et al 2018 rahmati et al 2020 rusk et al 2022 a devastating flood event hit beijing on july 21 2012 caused more than 70 deaths and affected 1 6 million jongman et al 2014 wang et al 2020 a recent flood disaster occurred in zhengzhou china on july 20 2021 leading to hundreds of deaths and rmb 40 billions of economic loss urban flooding induced by intense rainfall is commonly associated with a highly transient process that occurs at a short period of time fast flood risk assessment provides an important tool for disaster risk reduction pourghasemi et al 2019 flood risk mapping correlates flood information such as water depth with potential property or life losses providing an effective way to estimate disaster level mukerji et al 2009 tehrany et al 2014 urban flood risk mapping has undergone rapid development in recent years and different types of models and approaches have been developed and applied to predict analyze and quantify flood impact which may be largely classified into physically based and empirical models mudashiru et al 2021 physically based models simulate the physical process of flooding by numerically solving the hydrodynamic equations or their simplified forms in one dimension two dimensions and three dimensions kourgialas and karatzas 2017 the typical examples of physical based hydrodynamic or hydrological models are she devia et al 2015 swat jodar abellan et al 2019 swmm dai et al 2020 hipims xia et al 2019 physical based models require initial conditions boundary conditions and relevant spatial data to set up and predict flooding process xing et al 2018 and so the availability of hydrometeorological measurements e g rainfall river flow and other data describing the physical setting of the simulation domain such as dem land use types are essential teng et al 2017 these data especially high resolution data are difficult to access or unavailable furthermore these models require measured flood information for model calibration and validation which are challenging to collect especially during a flood event without high quality input and validation data the simulation accuracy and transferability of a model are clearly questionable in the last decades the rapid development and application of remote sensing technologies have significantly eased the data availability issue although data scarcity is still a common problem in many places in the world especially the low and middle income countries on the other hand whilst data availability has been continuously improved to support more detailed flood simulation the substantially increased computational cost associated with the resulting high resolution simulations presents another challenge for the application of physically based models empirical models are usually data driven to build the correlationship between the flood influencing factors as input and the empirical disaster results as output these models have been proved to be useful when high resolution input data are not available or sufficient to support physically based modeling mudashiru et al 2021 yao and wang 2020 flood influencing factors may include a range of natural factors like rainfall intensity domain topography and river networks and engineering factors like road networks and flood protection infrastructure huang et al 2018a empirical models include a subcategory that is built on expert opinions such as ahp mcdm lin et al 2019 these methods use expert knowledge to build a linear model to provide influencing factors with different weights in terms of influencing the final disaster which cannot interpret the actual flood dynamics and the complex correlations between the driving factors and flood impact in real world situations the flood influencing factors are typically inter dependent interact and influence each other during a flood event mudashiru et al 2021 furthermore flooding process is highly dynamical and non linear which cannot be reliably captured and interpreted by a simple linear model based on subjective expert opinions mudashiru et al 2021 empirical models also include another subcategory of machine learning approaches e g woe svm cnn dnn these models are data driven and can achieve high accuracy when sufficient amount of high quality training data are available to train the models to build the relationships between inputs and outputs chen et al 2017 once properly trained these models can be highly efficient for fast urban flood risk mapping however machine learning approaches are generally not linked to the actual physical process of flooding and the model performance highly relies on data accuracy and quantity therefore the predictability and performance of both physically based and empirical models rely heavily on data quantity and quality the application of these models in data scare environments still represents a current challenge in flood risk assessment research and practice van ackere et al 2019 mishra et al 2022 this paper proposes an alternative social sensing method to address this challenge social sensing broadly refers to a set of sensing and data collection paradigms where data are collected by humans or devices on their behalf wang et al 2015 in the modern world it is common for urban citizens to share local disaster information in social media like tiktok wechat space facebook community etc most of the information is in the format of text with images or short videos such social information could be an accurate reflection of local flood information available in nearly real time large volume of such crowd sourced data can help remove individual bias and provide a wide coverage in the study areas social sensing has been used for extracting fast disaster information since 2010 sakaki et al 2010 with the rapid development of big data analytic technology in recent years a wide range of commercial or open source software tools are available for fast acquisition and visualization of disaster related social data these analytic techniques have also been widely exploited in many flooding related applications including development of databases for flood records bruijn et al 2019 supporting post flood analysis zhang et al 2016 huang et al 2018b cervone et al 2016 young et al 2022 near real time flood area mapping pereira et al 2020 arthur et al 2018 fohringer et al 2015 li et al 2018 karmegam et al 2021 community risk management fakhruddin et al 2015 yadav and rahman 2016 etc however the application of social sensing to flood risk assessment is still in its infancy which requires more detailed and reliable hazard data e g inundation depth and risk loss information that may not be easily extracted from social sensing there have been a few preliminary attempts along this line reported in recent years for example smith et al 2017 presented an innovative approach to collect social sensing data to validate a physical based simulation model for flood forecasting zhang et al 2021 proposed an algorithm to analyze semantic risk using social sensing data an effective and efficient method to extract flood risk level in the social sensing realm is still missing social sensing data have also been used to support flood mapping by providing discrete inundation depth across a study domain rosser et al 2017 smith et al 2017 karmegam et al 2021 however for more detailed flood risk assessment a practical challenge for the application of social sensing is to expand the discrete point wise information to the entire research area to provide meaningful risk information to address this gap some recent attempts have been made rosser et al 2017 sadiq et al 2022 to integrate remote sensing data with social sensing information to support flood area mapping remote sensing data from satellite images provide a better coverage but have inherent shortages of high latency and low resolution associated with the long revisit time of the satellite and the spectrum resolution moreover satellite images only provide flood extent and more accurate inundation information may be extracted from social sensing data in terms of expanding the point wise social sensing information to map domain wise inundation most of the existing works simply used interpolation karmegam et al 2021 fohringer et al 2015 direct extension to the neighboring points rosser et al 2017 or kernel based voting li et al 2018 to support whole area mapping however the global flood maps generated by these simple approaches can rarely reflect the reality as demonstrated by the two typical examples in fig 1 in summary data scarcity is still a bottleneck restricting the development and application of physical based and empirical models for rapid flood prediction and risk mapping this paper proposes a new near real time flood risk mapping method for data scarce environments developed by integrating social sensing with region stable deep neural networks rs dnn the main contributions of this paper are highlighted as follows an effective method through the use of social sensing and risk distribution factors is proposed to address the bottleneck for flood risk assessment caused by data scarcity an innovative approach is developed to extend the point wise flood information to the whole domain using risk distribution factors and rs dnn effectively achieving the so called training with region but predict for whole the proposed model is computationally efficient and can be used to directly and rapidly map local and large scale flood risk 2 methodology fig 2 illustrates the proposed methodology framework firstly social sensing techniques are used to extract near real time disaster information labelled with gps locations then the discrete point wise data is extended to its neighbouring areas using a region growing algorithm to provide more training data assuming the neighbouring areas having a similar disaster level to reflect the real world reality after that the flood influence factors are stacked to images of the same resolution and all image layers are spatially aligned to support the following analysis the pixels on all influence factor image layers with extended disaster information are used as the training and validation datasets for rs dnn after a fast training process rs dnn will be able to predict the disaster information for the whole research area effectively realizing training with regional but prediction for whole finally flood risk map is produced by classifying the disaster information 2 1 social sensing fig 3 presents the social sensing procedure as proposed in this work which includes three steps social data collection flood information extraction and data cleaning in the social data collection step pure flood related text information is collected from field data volunteer data social media data and internet field data are provided by experts or field monitoring schemes which can be classified as structured data including concise and accurate text descriptions inundated depths gps data and time tags etc these data are considered to be reliable but available in small quantity volunteer data refers to the information obtained from online questionnaires which includes pure flood descriptions and the built in text information appeared on site images with examples shown in fig 4 other alternative data are acquired from keyword inquiry in social media and internet which provides a higher volume of near real time data all keywords are related to the target flood event e g event date locations submerged cars waterlogging damaged buildings prolonged rainfall etc the volume of social sensing data is important for the latter rs dnn training and validation the use of fixed pre defined keywords may restrict the keyword inquiry process and reduce the data volume this may be solved by creating a dynamic keyword set so that the inquiry keywords can be updated maintainned regularly to better reflect the changing real world situation for example new phrases or key words that are not included in the inquiry database may be identified and selected from the word segmentation step in fig 3 this step ensures the inquiry keywords are updated with the current free form social media to increase data volume for built in text information in images the optical character recognition ocr techniques are used to extract the pure structured texts when extracting flood information from the text descriptions three attributes are considered i e time tag gps location and flood risk level the first step is to segment the text into meaningful words and phrases for example the title of this paper rapid urban flood risk mapping for data scarce environments using social sensing and region stable deep neural network may be segmented to rapid urban flood risk mapping data scarce social sensing region stable and deep neural network by removing the connecting words like for using and etc many mature software packages can be used for this text segmentation task and they can cover different languages like chinese and english in the next step of text categorization the extracted words are classified into four categories i e time tag location flood risk level and others that do not belong to any of the three categories many text categorization algorithms are openly available for this task and can be used after being retrained for customized applications and the training process can be easily achieved off line after all of the words or phrases are classified into four categories the time tag can be readily converted into numbers and location related information can be integrated with digital maps to extract accurate gps location to assign flood risk level another neural network categorization tool can be retrained to classify the flood level ranging from 1 to 5 to prepare the training data a risk classification rule is developed according to the national flood assessment standards of china sl597 2012 based on which a risk scoring method can be subsequently established and used to map the relevant text words into risk levels ranging from 1 to 5 this step defines flood risk levels according to the text descriptions about inundation depth and damage to properties transportation systems lifeline infrastructure e g gas water electricity facilities etc table 1 provides some examples of keyword sets and the respective risk levels these keyword phrases are selected to ensure consistency with the relevant descriptions provided in the standards to obtain a more accurate classification the aforementioned dynamic keyword scheme can be also implemented here whilst the current risk classification approach is developed based on the national flood assessment standards of china sl597 2012 it can be readily adapted to local standards a data cleaning step is further implemented to remove those data with missing attributes and data that are not connected to the research area in more detail data cleaning involves checking and refining information such as errors exceptions data with missing items redundancy etc a geo graphic location feature verification algorithm can be used to check the acquired location information in terms of the latitude and longitude in google earth and remove duplicated data and noises data with missing attributes either time tag gps location or flood risk level will be removed flood information with time or location tags will be integrated any information with a time or location tag that is not connected with the study event is removed a point wise risk map can be finally produced for the research area after these steps it should be noted that the neural network based approach for flood risk level classification developed in this work may need further improvement for wider application currently the neural networks uses only words or phrases as input to predict flood risk level however the same words phrases may have different meanings in different context especially in social media which may not link to flood risk or the assigned risk level a potential solution is to allow the deep neural network algorithm to also take a sentence or short paragraph as input to more accurately capture the background description and directly link the flooding description text with flood risk level block in fig 3 this may substantially complicate the deep neural network model and restrict the data collection process to reduce the data volume this will need substantial further research and is currently out of the scope of this paper 2 2 region growing for deep neural networks more training data can potentially lead to better performance region growing expands the point wise flood depth information to its neighbouring pixels according to a restriction rule that considers the real world situations if the expanding radius r 10 pixel lengths the point wise information can be expanded by π r 2 314 times for a plain city that has relatively small regional dem changes we may assume the disaster information for a small cell like 600 m 600 m to be similar this approach may not be suitable for those regions with substantial topographic changes e g a mountainous region where simply expanding point wise disaster information to the neighbouring areas may be unreliable and an alternative approach should be explored the region growing algorithm is reinforced to only extend the collected point wise disaster information to the neighboring pixels that have a relatively similar topographic settings as to the data point i e seed point using the area featured with a lake as shown in the region growing part of fig 1 as an example the information in the seed point marked as the white point in fig 2 can be only extended to the blue lake area according to the local landscape dem fig 5 a shows the detailed steps invloved in this region growing algorithm the model has two key parameters i e expanding radius and dem threshold fig 5 b shows the influence of these two parameters on the final region growing results in which s1 s2 and s3 indicate that relaxation on the dem threshold leads to a more expanded region and s3 and s4 indicate that the expanding radius reinforces a limit on the maximum expanded region the two parameters are usually set empirically smaller values achieve a better confidence level on the flooding risk in the expanded region at the price of sacrificing the volume of training data this paper recommends the use of dem threshold of less than 3 m and expanding radius of less than 300 m theoretically this region growing process is no longer needed if sufficient social sensing data points are available e g when more than 20 of pixels in the study area are evenly distributed seed points with data but this is usually hard to achieve in real world 2 3 flood risk distribution factors flood risk distribution factors are defined as the factors influencing the distribution of risk level during the flooding process the occurrence spatial distribution and therefore the risk of flooding are directly or indirectly affected by multiple environmental and also social variables as a main driver of flooding rainfall and relevant meteorological conditions are an important environmental factor determining the spatial distribution of flooding process and risk however in many developing countries including china it is commonly difficult or even 324 impossible to access to real time weather forecasting data furthermore real time weather forecasting data are typically associated with high uncertainties and are considered to be the main source of uncertainty affecting the accuracy and reliability of flood forecasting when a rainfall event occurs in an urban area the local physical settings built and social environments determine the hydrological and flooding process on the ground and directly influence the distribution of flood risk therefore following existing literature review costache and tien bui 2020 khosravi et al 2019 pham et al 2021 pourghasemi et al 2019 tehrany et al 2014 tien bui et al 2020 wu et al 2020 yousefi et al 2020 and field investigation 12 factors are considered and selected as the predominant factors influencing flood risk distribution in the study site including ground elevation slope topographic wetness index twi normalized difference vegetation index ndvi land use type distance from rivers distance from roads distance from drainage population density building density road density and healthcare facility density the data interpreting these parameters can be pre processed to produce standardized inputs for fast model training 2 4 region stable deep neural network rs dnn rs dnn builds the relationship between the flood distribution factors and flood risk to achieve training with region but predict the whole area herein we call the expanded area from each of the social sensing points as a block e g the every block as a batch in fig 6 the input flood risk distribution factors and the output risk map are scaled to have the same image size and strictly aligned so that the coordinates of the same pixel in each of image layers are always associated with the same gps location as shown in the flood risk distribution factors component in fig 2 vertically the pixels with same coordinates on each of the image layers are treated as the smallest training unit a block i e a training batch usually includes many pixels which is defined as a basic unit for calculating a loss value all of the blocks in each risk distribution factor layer are used as training and validation data after training the rest of the study region in the flood risk distribution factor images is used for producing the whole area risk map rs dnn ensures the prediction results for neighbor pixels are smooth i e regional stable because a small region with similar topographic features tends to have identical flood risk situation in a real world flood event the network structure of rs dnn is shown in fig 6 which has multiple inputs and the input number is the same as the number of the flood influencing factor layers the input sequence for the factor layers must be the same for training and prediction four hidden fully connected linear layers with respective dimensions of 48 96 96 48 are used in rs dnn the output layer provides five numbers between 0 to 1 with a sum of 1 the output layer provides five numbers between 0 to 1 and their summation is 1 this output format is the result of sigmoid and softmax as an activation function for the last hidden layer the five numbers in the output layer represent the probability of each risk level i e very high high medium low very low each of the individual pixels is classified with the risk level that has the greatest probability the regional stable effect in rs dnn is introduced by making every block as a training batch and imposing batch stable constrain in loss function all the pixels in the same block are trained simultaneously to calculate a loss value using the regional stable loss function in eq 1 1 l 1 n i 1 n j 1 c g i j log p i j 1 n i 1 n y i μ 2 1 a u c where n is the total number of pixels in a batch c is class number g i j is 1 if classification is right otherwise to be 0 p i j is the probability for i th sample to be one class y i is the classification results μ is the mean value for all predictions for the batch the first term is cross entropy loss to indicate classification ability the second term is standard deviation to guarantee regional stable and the last term is area under curve auc to ensure classification accuracy before training each block is randomly divided into two sub sets for training and validation during training drop out procedures are used for each hidden layer to avoid over fitting 3 case study 3 1 the study area the highly urbanized area of central zhengzhou i e the area within the city s fourth ring road is chosen as the case study for this work as shown in fig 7 as the city is highly populated and has been frequently impacted by severe flood hazards providing an ideal example to demonstrate the potential of the proposed social sensing flood risk mapping framework zhengzhou is the capital city of henan province in china the city has more than 12 millions of population and is located in the lower reach of the yellow river between 112 4 2 e 114 1 4 e and 34 1 6 n 34 5 8 n it is an important transportation hub and a mega city of the central plain region of china zhengzhou straddles the yellow river and the huai river and possesses a complex river network consisting of 124 river streams of different sizes the highest and lowest points of the city are located in the southwest and northeast sides respectively creating an elevation difference of 30 m zhengzhou has a total area of 1070 square kilometers and is split into six administrative districts the region is predominated by continental climate extreme floods creating devastating impact in zhengzhou have been recorded in 1957 1963 1964 1982 2005 and 2021 with the latest 7 20 flood in 2021 marked as the most disastrous event in city s history during the 7 20 flood the daily precipitation was measured to exceed the historical records in all 10 national meteorological stations in the region the maximum rainfall was recorded to be 906 mm h recorded while the annual average precipitation is only 641 mm many places in the city observed more than 2 meters of waterlogging the flooding process lasted for several days between 17th and 23rd july peaked on 20th july which is specifically considered in this work 3 2 social sensing region growing results by inquiring flood related keywords on web wechat microblog tencent and sina and also through an online questionnaire with the time tag of 20th july more than one thousand messages were collected including 1093 pure text messages in chinese 673 photos and 223 pieces of structured questionnaire data for photos this work adopts the baidu ocr tools 2 2 https cloud baidu com product ocr general to extract the built in text to process all the text messages including those extracted from photos a popular chinese language segmentation software called ictclas 3 3 http ictclas org is used which has a segmentation accuracy of 98 45 after that a word classification package called pytorch nlu is also used to further process the acquired information a retraining process is imposed to four labels i e words related to flood situation words related to location time tag and others taking words phrases related to the flood situation as input another neural network model is retrained for five labels corresponding to the flood risk levels from 1 to 5 after data cleaning there remain 242 social sensing messages as shown in fig 8 with each message linked to a single pixel with an expanded radius of 300 m and elevation threshold of 1 5 m each of these 242 social sensing points is expanded to its neighboring pixels as shown in fig 9 in the three zoom in regions in fig 9 the one in the middle shows a wrong expansion area that is stretched beyond the research domain which can be removed automatically by cropping the final risk map if there are overlaps between any two neighboring regions the overlapped areas are randomly sampled from the two corresponding social sensing points the expanded social sensing results have 1382 pixels in total which will be used by the rs dnn to predict the pixel based risk values for the rest of the study area 3 3 flood risk distribution factors of the research area arcgis 10 8 qgis 3 22 5 and matlab are used to develop the corresponding thematic layers the raw flood distribution factors for zhengzhou are shown in fig a 1 after all of the factors are prepared they are uniformly converted onto the raster data format with a resolution of 5 m 5 m and 668 rows and 795 columns due to limited data resolution and the edge effect of administration district the density factors show a sudden change which does not reflect the real world situation simple interpolation has been used to remove the edge effect as shown in the right part of fig a 1 before training the rs dnn all data is normalized from 1 to 1 3 4 flood risk mapping using rs dnn for rs dnn the expanded region in fig 9 and the corresponding area on each normalized distribution factor are used as the datasets resulting in 1382 pieces of data each individual block is used as a batch for regional stable loss during training the ratio of data volume for training and evaluation is set as 8 2 in the evaluation set 1382 0 2 276 points auc are calculated as part of the loss in eq 1 learning rate is initiated as 0 01 and gradually decays to 0 0001 in polynomial rule with an adam optimizer the training epoch number is 1500 the losses for the first 500 epochs are shown in fig 10 after training risk distribution factors in the rest of regions are used for prediction the final flood risk map is shown in fig 11 most of the study areas are above the middle risk level high and very high risk regions are in the north and the central part of the city which are consistent with the social sensing results there are some very high risk regions on the southwest tips but these regions are in relatively high elevation that should be low risk the reason for the obvious mistaken predictions is because these regions do not have any social sensing data i e more social data leads to more reliable results this research does not focus on setting inquiry keywords and a more comprehensive keyword set may help acquire more social sensing data to improve data coverage this will be further discussed in the following subsection related to model uncertainty 3 5 performance evaluation and uncertainty discussion traditionally roc curves and auc scores are used for evalating model performance herein the ground truth data used for evaluate the flood risk mapping results include point wise survey data sensor data and social sensing data which are point wise data known as the point of interest poi most of poi data have been used for model training and the rest for model validation calculating performance metrics like accuracy precision recall curve or drawing roc curves to produce auc scores to show the overall model performance on handling the datasets specifically 80 of the social sensing points are used for model training and the rest 20 for validation it should be noted that the validation loss is calculated during the model training process as shown in fig 10 the resulting validation loss curve validates the trained model on never seen data on the other hand this work employs auc score as part of the training loss function so the proposed rs dnn will lead to higher auc score during training as shown in fig 12 the final auc score after 1500 epochs of training reaches 0 983 which is much higher than the recently published results on the same event peng and zhang 2022 see table 2 as for model efficiency the proposed rapid flood risk mapping method is developed for automatic risk mapping to enable fast near real time flood risk assessment in minutes for wider and further flood risk mapping applications with the availability of social sensing data available rapidly improving in time the proposed approach is highly robust and transferable and more reliable flood risk assessment outputs can be produced by retraining the rs dnn with new data as expected all models come with uncertainties and the main sources of uncertainty of the proposed modelling framework are related to 1 accuracy of risk classification through social sensing messages 2 the region growing process and 3 volume and quality of social sensing data regarding the accuracy of risk classification through social sensing information it is mainly related to the use of the language language i e the same words may have different meanings in different contexts and so risk classification based on works or short phases may not be entirely accurate potential improvement in the future can be made by using sentences or paragraphs of text as input to provide contextual based classification as discussed in section 2 1 in the region growing process the risk level indicated by the collected point wise social sensing data is expanded to its neighboring area this process inevitably creates uncertainties particularly those expanded pixels that are further from the seeding data point may have higher chance of having different risk level than those closer pixels the uncertainty may be reduced by choosing smaller expanding radius as is recommended in section 2 2 with continuously increasing volume of social sensing data this is feasible and will even reduce the necessity of region growing finally sufficient volume and coverage of training data are always important to improve the performance of deep learning methods like the previously mentioned uncertainties the increasing availability of social sensing data will help reduce this uncertainty as well furthermore better social sensing algorithms may be developed to acquire data from multiple sources extract more useful information from text image audio messages and handle missing attribute data deep learning models may be also trained to handle different level of data scarcity for example the mistaken prediction at the southwest tips of the case study as shown in fig 11 was caused by the lack of social sensing data in the less populated mountain areas in practice it may be possible to also include the physical domain feature and hydrological processes into the deep machine learning which may help better classify flood risk in those areas where social sensing observations are not available this remains to be a challenging and exciting topic for future research for both flood model and artificial intelligence research communities 4 conclusions and future works this paper proposes the use of social sensing and a neural network called rs dnn for near real time flood risk mapping in data scare environments data scarcity limits the application of either physically based models or empirical models for rapid flood risk prediction by extracting near real time disaster information using social sensing techniques and considering risk distribution factors rather than flood influencing factors the proposed method enables flood risk mapping analysis in the whole case study area within minutes with all the input data automatically obtained the proposed modelling approach can be adapted to new hazardous processes or different case studies through quick retraining with new social sensing data the proposed flood risk mapping framework has several limitations worth further research and investigation section 3 5 discussed the potential uncertainties of the model and suggested 582 potential solutions and future research to reduce the main uncertainties availability of high quality social sensing data may reduce all model uncertainties being discussed and hence further improve the model performance following the rapid advances of computing and information technologies social sensing data from different sources are continuously becoming more and more available which will clearly contribute to further improvement of the proposed neural network based rapid flood mapping model furthermore extracting flood information for pure pictures or short videos without text description is another interesting direction for further research because many social sensing data are not labeled with text according to our survey credit authorship contribution statement lin lin conceptualization methodology software formal analysis investigation resources writing original draft visualization chaoqing tang conceptualization methodology software investigation writing original draft writing review editing qiuhua liang conceptualization writing review editing resources supervision zening wu writing review editing funding acquisition xinling wang conceptualization writing review editing resources visualization supervision project administration shan zhao software validation data curation visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work is supported by the national natural science foundation of china no 51739009 no 62103154 the authors are grateful to colleagues and friends who shared their meteorological and hydrological data with us we also thank reviewers for insightful comments that improved an earlier version of this manuscript appendix flood risk distribution influencing factors for zhengzhou see fig a 1 
2459,urban flooding is one of the most widespread natural hazards in modern cities risk mapping provides critical information for flood risk management to reduce life and economic loss as a widely used approach to support flood risk mapping physical based modeling suffers from model accuracy and computation complexity empirical methods rely on availability of rich disaster data and are not normally transferable for fast flood prediction to different cities both methods require high quality hazard data and disaster information for reliable prediction which are not always available this paper presents an alternative near real time flood risk mapping method for data scarce environments developed using social sensing and region stable deep neural network rs dnn by extracting disaster information in near real time using social sensing techniques and considering risk distribution factors rather than flood influencing factors this new method enables flood risk mapping and analysis cross a large domain in minutes with all input data openly available the proposed method can be adapted to different disaster process and different case study cities through timely social sensing keywords data scarcity flood risk mapping region stable dnn risk distribution factors social sensing data availability data will be made available on request 1 introduction urban flooding is a widespread natural hazard threatening people s lives and properties in urban cities across the world rapid urbanization in the 21 century has increased the density of both population and property in cities leading to substantially increased flood vulnerability pourghasemi et al 2019 globally flooding accounts for more than 30 of total disaster loss every year yousefi et al 2021 and the flood impact has a clear increasing trend due to climate change and the on going urbanization jongman et al 2018 rahmati et al 2020 rusk et al 2022 a devastating flood event hit beijing on july 21 2012 caused more than 70 deaths and affected 1 6 million jongman et al 2014 wang et al 2020 a recent flood disaster occurred in zhengzhou china on july 20 2021 leading to hundreds of deaths and rmb 40 billions of economic loss urban flooding induced by intense rainfall is commonly associated with a highly transient process that occurs at a short period of time fast flood risk assessment provides an important tool for disaster risk reduction pourghasemi et al 2019 flood risk mapping correlates flood information such as water depth with potential property or life losses providing an effective way to estimate disaster level mukerji et al 2009 tehrany et al 2014 urban flood risk mapping has undergone rapid development in recent years and different types of models and approaches have been developed and applied to predict analyze and quantify flood impact which may be largely classified into physically based and empirical models mudashiru et al 2021 physically based models simulate the physical process of flooding by numerically solving the hydrodynamic equations or their simplified forms in one dimension two dimensions and three dimensions kourgialas and karatzas 2017 the typical examples of physical based hydrodynamic or hydrological models are she devia et al 2015 swat jodar abellan et al 2019 swmm dai et al 2020 hipims xia et al 2019 physical based models require initial conditions boundary conditions and relevant spatial data to set up and predict flooding process xing et al 2018 and so the availability of hydrometeorological measurements e g rainfall river flow and other data describing the physical setting of the simulation domain such as dem land use types are essential teng et al 2017 these data especially high resolution data are difficult to access or unavailable furthermore these models require measured flood information for model calibration and validation which are challenging to collect especially during a flood event without high quality input and validation data the simulation accuracy and transferability of a model are clearly questionable in the last decades the rapid development and application of remote sensing technologies have significantly eased the data availability issue although data scarcity is still a common problem in many places in the world especially the low and middle income countries on the other hand whilst data availability has been continuously improved to support more detailed flood simulation the substantially increased computational cost associated with the resulting high resolution simulations presents another challenge for the application of physically based models empirical models are usually data driven to build the correlationship between the flood influencing factors as input and the empirical disaster results as output these models have been proved to be useful when high resolution input data are not available or sufficient to support physically based modeling mudashiru et al 2021 yao and wang 2020 flood influencing factors may include a range of natural factors like rainfall intensity domain topography and river networks and engineering factors like road networks and flood protection infrastructure huang et al 2018a empirical models include a subcategory that is built on expert opinions such as ahp mcdm lin et al 2019 these methods use expert knowledge to build a linear model to provide influencing factors with different weights in terms of influencing the final disaster which cannot interpret the actual flood dynamics and the complex correlations between the driving factors and flood impact in real world situations the flood influencing factors are typically inter dependent interact and influence each other during a flood event mudashiru et al 2021 furthermore flooding process is highly dynamical and non linear which cannot be reliably captured and interpreted by a simple linear model based on subjective expert opinions mudashiru et al 2021 empirical models also include another subcategory of machine learning approaches e g woe svm cnn dnn these models are data driven and can achieve high accuracy when sufficient amount of high quality training data are available to train the models to build the relationships between inputs and outputs chen et al 2017 once properly trained these models can be highly efficient for fast urban flood risk mapping however machine learning approaches are generally not linked to the actual physical process of flooding and the model performance highly relies on data accuracy and quantity therefore the predictability and performance of both physically based and empirical models rely heavily on data quantity and quality the application of these models in data scare environments still represents a current challenge in flood risk assessment research and practice van ackere et al 2019 mishra et al 2022 this paper proposes an alternative social sensing method to address this challenge social sensing broadly refers to a set of sensing and data collection paradigms where data are collected by humans or devices on their behalf wang et al 2015 in the modern world it is common for urban citizens to share local disaster information in social media like tiktok wechat space facebook community etc most of the information is in the format of text with images or short videos such social information could be an accurate reflection of local flood information available in nearly real time large volume of such crowd sourced data can help remove individual bias and provide a wide coverage in the study areas social sensing has been used for extracting fast disaster information since 2010 sakaki et al 2010 with the rapid development of big data analytic technology in recent years a wide range of commercial or open source software tools are available for fast acquisition and visualization of disaster related social data these analytic techniques have also been widely exploited in many flooding related applications including development of databases for flood records bruijn et al 2019 supporting post flood analysis zhang et al 2016 huang et al 2018b cervone et al 2016 young et al 2022 near real time flood area mapping pereira et al 2020 arthur et al 2018 fohringer et al 2015 li et al 2018 karmegam et al 2021 community risk management fakhruddin et al 2015 yadav and rahman 2016 etc however the application of social sensing to flood risk assessment is still in its infancy which requires more detailed and reliable hazard data e g inundation depth and risk loss information that may not be easily extracted from social sensing there have been a few preliminary attempts along this line reported in recent years for example smith et al 2017 presented an innovative approach to collect social sensing data to validate a physical based simulation model for flood forecasting zhang et al 2021 proposed an algorithm to analyze semantic risk using social sensing data an effective and efficient method to extract flood risk level in the social sensing realm is still missing social sensing data have also been used to support flood mapping by providing discrete inundation depth across a study domain rosser et al 2017 smith et al 2017 karmegam et al 2021 however for more detailed flood risk assessment a practical challenge for the application of social sensing is to expand the discrete point wise information to the entire research area to provide meaningful risk information to address this gap some recent attempts have been made rosser et al 2017 sadiq et al 2022 to integrate remote sensing data with social sensing information to support flood area mapping remote sensing data from satellite images provide a better coverage but have inherent shortages of high latency and low resolution associated with the long revisit time of the satellite and the spectrum resolution moreover satellite images only provide flood extent and more accurate inundation information may be extracted from social sensing data in terms of expanding the point wise social sensing information to map domain wise inundation most of the existing works simply used interpolation karmegam et al 2021 fohringer et al 2015 direct extension to the neighboring points rosser et al 2017 or kernel based voting li et al 2018 to support whole area mapping however the global flood maps generated by these simple approaches can rarely reflect the reality as demonstrated by the two typical examples in fig 1 in summary data scarcity is still a bottleneck restricting the development and application of physical based and empirical models for rapid flood prediction and risk mapping this paper proposes a new near real time flood risk mapping method for data scarce environments developed by integrating social sensing with region stable deep neural networks rs dnn the main contributions of this paper are highlighted as follows an effective method through the use of social sensing and risk distribution factors is proposed to address the bottleneck for flood risk assessment caused by data scarcity an innovative approach is developed to extend the point wise flood information to the whole domain using risk distribution factors and rs dnn effectively achieving the so called training with region but predict for whole the proposed model is computationally efficient and can be used to directly and rapidly map local and large scale flood risk 2 methodology fig 2 illustrates the proposed methodology framework firstly social sensing techniques are used to extract near real time disaster information labelled with gps locations then the discrete point wise data is extended to its neighbouring areas using a region growing algorithm to provide more training data assuming the neighbouring areas having a similar disaster level to reflect the real world reality after that the flood influence factors are stacked to images of the same resolution and all image layers are spatially aligned to support the following analysis the pixels on all influence factor image layers with extended disaster information are used as the training and validation datasets for rs dnn after a fast training process rs dnn will be able to predict the disaster information for the whole research area effectively realizing training with regional but prediction for whole finally flood risk map is produced by classifying the disaster information 2 1 social sensing fig 3 presents the social sensing procedure as proposed in this work which includes three steps social data collection flood information extraction and data cleaning in the social data collection step pure flood related text information is collected from field data volunteer data social media data and internet field data are provided by experts or field monitoring schemes which can be classified as structured data including concise and accurate text descriptions inundated depths gps data and time tags etc these data are considered to be reliable but available in small quantity volunteer data refers to the information obtained from online questionnaires which includes pure flood descriptions and the built in text information appeared on site images with examples shown in fig 4 other alternative data are acquired from keyword inquiry in social media and internet which provides a higher volume of near real time data all keywords are related to the target flood event e g event date locations submerged cars waterlogging damaged buildings prolonged rainfall etc the volume of social sensing data is important for the latter rs dnn training and validation the use of fixed pre defined keywords may restrict the keyword inquiry process and reduce the data volume this may be solved by creating a dynamic keyword set so that the inquiry keywords can be updated maintainned regularly to better reflect the changing real world situation for example new phrases or key words that are not included in the inquiry database may be identified and selected from the word segmentation step in fig 3 this step ensures the inquiry keywords are updated with the current free form social media to increase data volume for built in text information in images the optical character recognition ocr techniques are used to extract the pure structured texts when extracting flood information from the text descriptions three attributes are considered i e time tag gps location and flood risk level the first step is to segment the text into meaningful words and phrases for example the title of this paper rapid urban flood risk mapping for data scarce environments using social sensing and region stable deep neural network may be segmented to rapid urban flood risk mapping data scarce social sensing region stable and deep neural network by removing the connecting words like for using and etc many mature software packages can be used for this text segmentation task and they can cover different languages like chinese and english in the next step of text categorization the extracted words are classified into four categories i e time tag location flood risk level and others that do not belong to any of the three categories many text categorization algorithms are openly available for this task and can be used after being retrained for customized applications and the training process can be easily achieved off line after all of the words or phrases are classified into four categories the time tag can be readily converted into numbers and location related information can be integrated with digital maps to extract accurate gps location to assign flood risk level another neural network categorization tool can be retrained to classify the flood level ranging from 1 to 5 to prepare the training data a risk classification rule is developed according to the national flood assessment standards of china sl597 2012 based on which a risk scoring method can be subsequently established and used to map the relevant text words into risk levels ranging from 1 to 5 this step defines flood risk levels according to the text descriptions about inundation depth and damage to properties transportation systems lifeline infrastructure e g gas water electricity facilities etc table 1 provides some examples of keyword sets and the respective risk levels these keyword phrases are selected to ensure consistency with the relevant descriptions provided in the standards to obtain a more accurate classification the aforementioned dynamic keyword scheme can be also implemented here whilst the current risk classification approach is developed based on the national flood assessment standards of china sl597 2012 it can be readily adapted to local standards a data cleaning step is further implemented to remove those data with missing attributes and data that are not connected to the research area in more detail data cleaning involves checking and refining information such as errors exceptions data with missing items redundancy etc a geo graphic location feature verification algorithm can be used to check the acquired location information in terms of the latitude and longitude in google earth and remove duplicated data and noises data with missing attributes either time tag gps location or flood risk level will be removed flood information with time or location tags will be integrated any information with a time or location tag that is not connected with the study event is removed a point wise risk map can be finally produced for the research area after these steps it should be noted that the neural network based approach for flood risk level classification developed in this work may need further improvement for wider application currently the neural networks uses only words or phrases as input to predict flood risk level however the same words phrases may have different meanings in different context especially in social media which may not link to flood risk or the assigned risk level a potential solution is to allow the deep neural network algorithm to also take a sentence or short paragraph as input to more accurately capture the background description and directly link the flooding description text with flood risk level block in fig 3 this may substantially complicate the deep neural network model and restrict the data collection process to reduce the data volume this will need substantial further research and is currently out of the scope of this paper 2 2 region growing for deep neural networks more training data can potentially lead to better performance region growing expands the point wise flood depth information to its neighbouring pixels according to a restriction rule that considers the real world situations if the expanding radius r 10 pixel lengths the point wise information can be expanded by π r 2 314 times for a plain city that has relatively small regional dem changes we may assume the disaster information for a small cell like 600 m 600 m to be similar this approach may not be suitable for those regions with substantial topographic changes e g a mountainous region where simply expanding point wise disaster information to the neighbouring areas may be unreliable and an alternative approach should be explored the region growing algorithm is reinforced to only extend the collected point wise disaster information to the neighboring pixels that have a relatively similar topographic settings as to the data point i e seed point using the area featured with a lake as shown in the region growing part of fig 1 as an example the information in the seed point marked as the white point in fig 2 can be only extended to the blue lake area according to the local landscape dem fig 5 a shows the detailed steps invloved in this region growing algorithm the model has two key parameters i e expanding radius and dem threshold fig 5 b shows the influence of these two parameters on the final region growing results in which s1 s2 and s3 indicate that relaxation on the dem threshold leads to a more expanded region and s3 and s4 indicate that the expanding radius reinforces a limit on the maximum expanded region the two parameters are usually set empirically smaller values achieve a better confidence level on the flooding risk in the expanded region at the price of sacrificing the volume of training data this paper recommends the use of dem threshold of less than 3 m and expanding radius of less than 300 m theoretically this region growing process is no longer needed if sufficient social sensing data points are available e g when more than 20 of pixels in the study area are evenly distributed seed points with data but this is usually hard to achieve in real world 2 3 flood risk distribution factors flood risk distribution factors are defined as the factors influencing the distribution of risk level during the flooding process the occurrence spatial distribution and therefore the risk of flooding are directly or indirectly affected by multiple environmental and also social variables as a main driver of flooding rainfall and relevant meteorological conditions are an important environmental factor determining the spatial distribution of flooding process and risk however in many developing countries including china it is commonly difficult or even 324 impossible to access to real time weather forecasting data furthermore real time weather forecasting data are typically associated with high uncertainties and are considered to be the main source of uncertainty affecting the accuracy and reliability of flood forecasting when a rainfall event occurs in an urban area the local physical settings built and social environments determine the hydrological and flooding process on the ground and directly influence the distribution of flood risk therefore following existing literature review costache and tien bui 2020 khosravi et al 2019 pham et al 2021 pourghasemi et al 2019 tehrany et al 2014 tien bui et al 2020 wu et al 2020 yousefi et al 2020 and field investigation 12 factors are considered and selected as the predominant factors influencing flood risk distribution in the study site including ground elevation slope topographic wetness index twi normalized difference vegetation index ndvi land use type distance from rivers distance from roads distance from drainage population density building density road density and healthcare facility density the data interpreting these parameters can be pre processed to produce standardized inputs for fast model training 2 4 region stable deep neural network rs dnn rs dnn builds the relationship between the flood distribution factors and flood risk to achieve training with region but predict the whole area herein we call the expanded area from each of the social sensing points as a block e g the every block as a batch in fig 6 the input flood risk distribution factors and the output risk map are scaled to have the same image size and strictly aligned so that the coordinates of the same pixel in each of image layers are always associated with the same gps location as shown in the flood risk distribution factors component in fig 2 vertically the pixels with same coordinates on each of the image layers are treated as the smallest training unit a block i e a training batch usually includes many pixels which is defined as a basic unit for calculating a loss value all of the blocks in each risk distribution factor layer are used as training and validation data after training the rest of the study region in the flood risk distribution factor images is used for producing the whole area risk map rs dnn ensures the prediction results for neighbor pixels are smooth i e regional stable because a small region with similar topographic features tends to have identical flood risk situation in a real world flood event the network structure of rs dnn is shown in fig 6 which has multiple inputs and the input number is the same as the number of the flood influencing factor layers the input sequence for the factor layers must be the same for training and prediction four hidden fully connected linear layers with respective dimensions of 48 96 96 48 are used in rs dnn the output layer provides five numbers between 0 to 1 with a sum of 1 the output layer provides five numbers between 0 to 1 and their summation is 1 this output format is the result of sigmoid and softmax as an activation function for the last hidden layer the five numbers in the output layer represent the probability of each risk level i e very high high medium low very low each of the individual pixels is classified with the risk level that has the greatest probability the regional stable effect in rs dnn is introduced by making every block as a training batch and imposing batch stable constrain in loss function all the pixels in the same block are trained simultaneously to calculate a loss value using the regional stable loss function in eq 1 1 l 1 n i 1 n j 1 c g i j log p i j 1 n i 1 n y i μ 2 1 a u c where n is the total number of pixels in a batch c is class number g i j is 1 if classification is right otherwise to be 0 p i j is the probability for i th sample to be one class y i is the classification results μ is the mean value for all predictions for the batch the first term is cross entropy loss to indicate classification ability the second term is standard deviation to guarantee regional stable and the last term is area under curve auc to ensure classification accuracy before training each block is randomly divided into two sub sets for training and validation during training drop out procedures are used for each hidden layer to avoid over fitting 3 case study 3 1 the study area the highly urbanized area of central zhengzhou i e the area within the city s fourth ring road is chosen as the case study for this work as shown in fig 7 as the city is highly populated and has been frequently impacted by severe flood hazards providing an ideal example to demonstrate the potential of the proposed social sensing flood risk mapping framework zhengzhou is the capital city of henan province in china the city has more than 12 millions of population and is located in the lower reach of the yellow river between 112 4 2 e 114 1 4 e and 34 1 6 n 34 5 8 n it is an important transportation hub and a mega city of the central plain region of china zhengzhou straddles the yellow river and the huai river and possesses a complex river network consisting of 124 river streams of different sizes the highest and lowest points of the city are located in the southwest and northeast sides respectively creating an elevation difference of 30 m zhengzhou has a total area of 1070 square kilometers and is split into six administrative districts the region is predominated by continental climate extreme floods creating devastating impact in zhengzhou have been recorded in 1957 1963 1964 1982 2005 and 2021 with the latest 7 20 flood in 2021 marked as the most disastrous event in city s history during the 7 20 flood the daily precipitation was measured to exceed the historical records in all 10 national meteorological stations in the region the maximum rainfall was recorded to be 906 mm h recorded while the annual average precipitation is only 641 mm many places in the city observed more than 2 meters of waterlogging the flooding process lasted for several days between 17th and 23rd july peaked on 20th july which is specifically considered in this work 3 2 social sensing region growing results by inquiring flood related keywords on web wechat microblog tencent and sina and also through an online questionnaire with the time tag of 20th july more than one thousand messages were collected including 1093 pure text messages in chinese 673 photos and 223 pieces of structured questionnaire data for photos this work adopts the baidu ocr tools 2 2 https cloud baidu com product ocr general to extract the built in text to process all the text messages including those extracted from photos a popular chinese language segmentation software called ictclas 3 3 http ictclas org is used which has a segmentation accuracy of 98 45 after that a word classification package called pytorch nlu is also used to further process the acquired information a retraining process is imposed to four labels i e words related to flood situation words related to location time tag and others taking words phrases related to the flood situation as input another neural network model is retrained for five labels corresponding to the flood risk levels from 1 to 5 after data cleaning there remain 242 social sensing messages as shown in fig 8 with each message linked to a single pixel with an expanded radius of 300 m and elevation threshold of 1 5 m each of these 242 social sensing points is expanded to its neighboring pixels as shown in fig 9 in the three zoom in regions in fig 9 the one in the middle shows a wrong expansion area that is stretched beyond the research domain which can be removed automatically by cropping the final risk map if there are overlaps between any two neighboring regions the overlapped areas are randomly sampled from the two corresponding social sensing points the expanded social sensing results have 1382 pixels in total which will be used by the rs dnn to predict the pixel based risk values for the rest of the study area 3 3 flood risk distribution factors of the research area arcgis 10 8 qgis 3 22 5 and matlab are used to develop the corresponding thematic layers the raw flood distribution factors for zhengzhou are shown in fig a 1 after all of the factors are prepared they are uniformly converted onto the raster data format with a resolution of 5 m 5 m and 668 rows and 795 columns due to limited data resolution and the edge effect of administration district the density factors show a sudden change which does not reflect the real world situation simple interpolation has been used to remove the edge effect as shown in the right part of fig a 1 before training the rs dnn all data is normalized from 1 to 1 3 4 flood risk mapping using rs dnn for rs dnn the expanded region in fig 9 and the corresponding area on each normalized distribution factor are used as the datasets resulting in 1382 pieces of data each individual block is used as a batch for regional stable loss during training the ratio of data volume for training and evaluation is set as 8 2 in the evaluation set 1382 0 2 276 points auc are calculated as part of the loss in eq 1 learning rate is initiated as 0 01 and gradually decays to 0 0001 in polynomial rule with an adam optimizer the training epoch number is 1500 the losses for the first 500 epochs are shown in fig 10 after training risk distribution factors in the rest of regions are used for prediction the final flood risk map is shown in fig 11 most of the study areas are above the middle risk level high and very high risk regions are in the north and the central part of the city which are consistent with the social sensing results there are some very high risk regions on the southwest tips but these regions are in relatively high elevation that should be low risk the reason for the obvious mistaken predictions is because these regions do not have any social sensing data i e more social data leads to more reliable results this research does not focus on setting inquiry keywords and a more comprehensive keyword set may help acquire more social sensing data to improve data coverage this will be further discussed in the following subsection related to model uncertainty 3 5 performance evaluation and uncertainty discussion traditionally roc curves and auc scores are used for evalating model performance herein the ground truth data used for evaluate the flood risk mapping results include point wise survey data sensor data and social sensing data which are point wise data known as the point of interest poi most of poi data have been used for model training and the rest for model validation calculating performance metrics like accuracy precision recall curve or drawing roc curves to produce auc scores to show the overall model performance on handling the datasets specifically 80 of the social sensing points are used for model training and the rest 20 for validation it should be noted that the validation loss is calculated during the model training process as shown in fig 10 the resulting validation loss curve validates the trained model on never seen data on the other hand this work employs auc score as part of the training loss function so the proposed rs dnn will lead to higher auc score during training as shown in fig 12 the final auc score after 1500 epochs of training reaches 0 983 which is much higher than the recently published results on the same event peng and zhang 2022 see table 2 as for model efficiency the proposed rapid flood risk mapping method is developed for automatic risk mapping to enable fast near real time flood risk assessment in minutes for wider and further flood risk mapping applications with the availability of social sensing data available rapidly improving in time the proposed approach is highly robust and transferable and more reliable flood risk assessment outputs can be produced by retraining the rs dnn with new data as expected all models come with uncertainties and the main sources of uncertainty of the proposed modelling framework are related to 1 accuracy of risk classification through social sensing messages 2 the region growing process and 3 volume and quality of social sensing data regarding the accuracy of risk classification through social sensing information it is mainly related to the use of the language language i e the same words may have different meanings in different contexts and so risk classification based on works or short phases may not be entirely accurate potential improvement in the future can be made by using sentences or paragraphs of text as input to provide contextual based classification as discussed in section 2 1 in the region growing process the risk level indicated by the collected point wise social sensing data is expanded to its neighboring area this process inevitably creates uncertainties particularly those expanded pixels that are further from the seeding data point may have higher chance of having different risk level than those closer pixels the uncertainty may be reduced by choosing smaller expanding radius as is recommended in section 2 2 with continuously increasing volume of social sensing data this is feasible and will even reduce the necessity of region growing finally sufficient volume and coverage of training data are always important to improve the performance of deep learning methods like the previously mentioned uncertainties the increasing availability of social sensing data will help reduce this uncertainty as well furthermore better social sensing algorithms may be developed to acquire data from multiple sources extract more useful information from text image audio messages and handle missing attribute data deep learning models may be also trained to handle different level of data scarcity for example the mistaken prediction at the southwest tips of the case study as shown in fig 11 was caused by the lack of social sensing data in the less populated mountain areas in practice it may be possible to also include the physical domain feature and hydrological processes into the deep machine learning which may help better classify flood risk in those areas where social sensing observations are not available this remains to be a challenging and exciting topic for future research for both flood model and artificial intelligence research communities 4 conclusions and future works this paper proposes the use of social sensing and a neural network called rs dnn for near real time flood risk mapping in data scare environments data scarcity limits the application of either physically based models or empirical models for rapid flood risk prediction by extracting near real time disaster information using social sensing techniques and considering risk distribution factors rather than flood influencing factors the proposed method enables flood risk mapping analysis in the whole case study area within minutes with all the input data automatically obtained the proposed modelling approach can be adapted to new hazardous processes or different case studies through quick retraining with new social sensing data the proposed flood risk mapping framework has several limitations worth further research and investigation section 3 5 discussed the potential uncertainties of the model and suggested 582 potential solutions and future research to reduce the main uncertainties availability of high quality social sensing data may reduce all model uncertainties being discussed and hence further improve the model performance following the rapid advances of computing and information technologies social sensing data from different sources are continuously becoming more and more available which will clearly contribute to further improvement of the proposed neural network based rapid flood mapping model furthermore extracting flood information for pure pictures or short videos without text description is another interesting direction for further research because many social sensing data are not labeled with text according to our survey credit authorship contribution statement lin lin conceptualization methodology software formal analysis investigation resources writing original draft visualization chaoqing tang conceptualization methodology software investigation writing original draft writing review editing qiuhua liang conceptualization writing review editing resources supervision zening wu writing review editing funding acquisition xinling wang conceptualization writing review editing resources visualization supervision project administration shan zhao software validation data curation visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work is supported by the national natural science foundation of china no 51739009 no 62103154 the authors are grateful to colleagues and friends who shared their meteorological and hydrological data with us we also thank reviewers for insightful comments that improved an earlier version of this manuscript appendix flood risk distribution influencing factors for zhengzhou see fig a 1 
