index,text
25895,due to heterogeneous and inconsistent key performance indicators kpis for the quantitative evaluation of a sustainable city s operational status it is a great challenge to share multidimensional multi source and heterogeneous indicators we propose a heterogeneous kpi capability representation model hkpm in our study based on the meta object facility architecture a nine tuple multi hierarchical meta model is formulated to define the metadata components nine specific representation element datasets for specific kpis are proposed to represent the meta model besides the kpi classification based on sustainable development goals sdgs has been accomplished to support hkpm instantiated in concrete application experiments are conducted with the multi type kpis to validate the feasibility of hkpm as shown in public service and air quality index kpi instantiation example furthermore the kpis can be characterized in different dimensions which can be modelled in a stereoscopic manner promoting a comprehensive perception of sustainable cities keywords kpi meta model formulization framework heterogeneity geospatial sensor web sdgs 1 introduction 1 1 heterogeneous key performance indicators kpis in a sustainable city 17 sustainable development goals sdgs aim to turn to the sustainable development path and solve the development problems of social economic and environmental dimensions nations 2015 a sustainable city is a city designed with consideration for social economic environmental impact and resilient habitat for existing populations huan et al 2021 zhang et al 2019 along with the emergence of new technologies such as the internet of things 5g and ubiquitous communication the innovative concept of sustainable cities can help improve the resource utilization efficiency enhance urban management services and strengthen the quality of life of citizens by integrating urban systems and services lewis and ogra 2010 sustainable cities offer efficient transparent collaborative and standardized electronic platforms and external services for the government and the public bhati et al 2017 cox et al 2003 deng et al 2017 giuseppe et al 2017 lv et al sustainable cities application requires perception of environmental situations and the activities of the population to achieve smart responses and interactions ainuddin et al 2014 sustainable city perception of environmental situations from different perspectives such as those of the air quality health condition the macro economy industry development condition tu et al 2020 cao et al 2020 public sentiment situation could achieve the stereoscopic and multidimensional understanding of city operational conditions the perception of different aspects of cities is important and essential llinares et al 2013 because it is the basis for other parts of sustainable cities such as data centre establishment smart applications in transportation tourism people s livelihoods economic policy decision and other applications cagliero et al 2015 some big data analytic tools have been applied into sustainable business management including city perception raut et al 2019b singh et al 2018 the big data potential and opportunities include business intelligence value creation and business decisions kumar et al 2013 big data analytics capabilities are data driven and enjoy advantages as follows of data analysis and generation process m song 2015 suggested integration or fusion from the heterogeneous data sources giroux et al 2019 qiu et al 2017 sun et al 2019 assimilates different types of findings into the unified business process sodhro et al 2019 sun et al 2019 and data visualization capability simplifies the decision making process ren et al 2019 hard and soft indicators for evaluating green management practice have been explored and interrelationship between the green practices and business performance has been explored raut et al 2019a meanwhile the proposed model is applied to assess the sustainability productivity of 133 countries from an empirical perspective concerning sustainable city perception of environmental situations such as air quality indicator aqi the sensor web can help achieve stereoscopic and omnidirectional perception the sensor web enablement initiative of the open gis consortium ogc defines a sensor web as an cyber infrastructure enabling access to sensor networks and archived sensor data which can be discovered and accessed using standard protocols and interfaces botts et al 2008 different with a sensor network a sensor web shields the underlying device layers the heterogeneous sensor hardware and the network communication details broring et al 2011 however employing a sensor web and integrating it with sustainable cities is a great challenge because there is no standard or replicate sustainable city blueprint for the construction of sustainable cities around the world there are some policy and technical problems for the construction of sustainable cities furthermore there are no universally standard and uniform data or metadata representation models in general 1 2 related work on comprehensive kpi monitoring to achieve comprehensive city monitoring such as aqi the kpi cyber monitoring infrastructure provides an effective and convenient method for sustainable city affairs reddy et al 2014b regarding the kpi monitoring information framework technology cyberinfrastructure ci consists of computing systems data storage systems advanced instruments and data repositories visualization environments moreover all these components or devices are linked by software and high performance networks to improve productivity and to enable breakthroughs that would not otherwise be possible personal et al 2014 reddy et al 2014a mohammed et al extended the task technology matching model to measure the attributes of specific technologies and to empirically examine the model with new technologies mohammed et al 2017 cai et al proposed a framework using a systematic approach for improving the establishment of iterative kpis in a supply chain context cai et al 2009 with a government affairs service platform for sustainable cities a series of sustainable city services can be conducted to manage users and operations supervisors in government agencies and other sustainable city industries lv et al 2018 chen proposed the concepts and architecture of cloud storage data modelling and visualization of geographical environment observation task chen et al 2016 hu et al 2020 hara et al hara et al 2016 conducted an application by applying the proposed kpi specifications to individual information and communication technology solutions of internet protocol announcements wi fi hotspot and information transmission and control which had already been installed in a sustainable city standardization of the representation of kpis can help solve these problems through a systematic approach to improving the iterative establishment of kpis in a supply chain kpis can be applied by the decision makers in a supply chain cagliero et al 2015 wetzstein et al 2012 through standardization kpi can be calculated to quantify the performance of the evaluated object hara et al 2016 in cities there are many indexes such as economic operation indicators climate indicators population indicators urban event indicators ecological environment indicators and other indicators moreover the multi source heterogeneous kpi in a sustainable city contains multiple aspects covering multiple aspects in a real world or city nevertheless the listed kpi cannot exhaust all kpi of objective existence for the city covers the real world is a complex multidimensional space it should be noted that the kpi could be divided into multi scale and multi level sub kpi such as national provincial municipal county town level not only the kpi observations but also the kpi metadata differ among different datasets therefore the representation standardization of multi source heterogeneous kpis should be paid more attention 1 3 existing metadata models and problems however many heterogeneous kpi representation models exist the international organization for standardization iso 19 115 iso 2014 provides basic metadata for describing and locating geographical information iso 37106 2018 iso 2018 defines an open collaborative citizen centric and digitally enabled operating model for their city that put its vision for a sustainable future into operation the european organization for standardization une en iso 178 301 2015 une 2015 defines open data in a sustainable city in spain the sensor model language sensorml 2 0 of the ogc opengis 2007 defines a standardized format for metadata representation for sensor modelling and reduces the heterogeneity of multiple sensors under the sensor web environment the ogc observations measurements o m opengis 2010 2 0 encoding model defines a conceptual schema and extensible mark up language xml encoding for observations and features involved in sampling presently metadata specifications for the representation of kpi information are mainly defined by the international organization for standardization technical committee iso tc 211 the ogc and une en iso as shown in table 1 the corresponding metadata specifications or drafts which contain iso ts 37151 2015 iso 37106 2018 une 178301 2015 ogc 14 115 sustainable cities spatial information framework ogc sensorml 1 0 and 2 0 and ogc o m 1 0 and 2 0 are listed in table 1 at the same time standardization administration of china sac has developed the national standard guide technical documents gb t 34 678 2017 sac 2017b gb t 34680 3 2017 sac 2017a and gb t 37 043 2018 sac 2018a sac 2018b to define the formulation of the geospatial metadata xml for digital cities sustainable cities and the surveying and mapping industry these standards define the metadata for establishing sustainable city operating models for sustainable communities di et al di et al 2009 noted that these standards could be applied to determine the correct resources for the correct times and locations with the appropriate quality as shown in table 1 most indicator has been recorded and most aspects of cities such as the economy education and energy have been included to provide a comprehensive and stereoscopic view of the city moreover six kpis or sensor related metadata specifications or standards are considered together with descriptions of the metadata content encoding schema and applications to reduce heterogeneity of the multiple kpi representation models and to accomplish multilevel and thorough kpi monitoring in sustainable cities defined in sdgs there are some difficulties that must be solved 1 the multiple metadata standards listed above show distinct descriptive features for different applications which are relatively suitable for the modelling of specific metadata in a unified manner however it is still difficult include adequate metadata content to satisfy the characteristics of various heterogeneous kpi metadata consequently the various existing metadata representations or standards result in information silos among different systems fan et al 2015 2 there are many types of kpis as the current kpi types contain more than hundreds of types in sustainable cities in addition the greater effort has been applied to sensor metadata sensor capabilities and sensor web nodes furthermore kpi modelling has received little attention 3 the necessary computing capability for the calculation of kpis during the perception process is great to achieve kpis modelled in a stereoscopic manner the data volume of kpis can reach to gigabyte gb or hundreds of millions of data records hindering the efficient data access for government administrators 1 4 contribution and organization in terms of research objectives we propose a heterogeneous kpi perception meta model hkpm to unify the heterogeneous kpi representation model and to enhance city perception in a stereoscopic manner such as air quality index aqi under a sensor web moghaddam et al 2010 zhang et al 2018 environment sheltering kpi encoding heterogeneity in diverse metadata encoding standards by coupling heterogeneous kpi metadata model with meta object facility mof framework the hkpm covers the most attributes in table 1 to be a beneficial encoding model to support different kinds of kpi encoding in the standard representation framework in sustainable cities moreover indicators in hkpm are built based on sgds framework covering some related indicators from sdgs aiming to be an important representation model support for the establishment of sustainable cities accessed from the sensor observation service sos in sensor web enablement kpis can be accessed in a unified manner for application or government traffic manager zhou et al 2020 based on the mof a nine tuple multi hierarchical meta model is formulated to define the metadata components nine specific representation element datasets for specific kpis are proposed to represent the meta model the open geospatial consortium observations measurements o m modelling language is applied to formulate hkpm besides the kpi classification based on sdgs has been accomplished to support hkpm instantiated in the experiment as demonstrated in section 3 the monitoring and control of urban operational indicators platform mcupip is designed and developed to achieve kpi monitoring from multiple kpi aspects taking aqi for example this paper is organized as following the details of the hkpm are described in section 2 the experiments are conducted in section 3 to validate the feasibility of the model section 4 provides a discussion and the conclusions of the study and potential future directions are also discussed 2 hkpm meta modelling is a process that builds a collection of components elements and sub collections that are a further abstraction of the core parts of the metadata to construct a model to achieve unified metadata modelling to reduce heterogeneity of the kpi representation model for the economy humanity and the environment meta modelling is applied in our study as a method for abstraction and aggregation the heterogeneous kpi model defines the meta modelling layers information describing rules associations and metadata definition standards see fig 1 2 1 hkpm meta modelling based on mof in proposing the heterogeneous kpi meta model to describe the kpis in a unified manner in the sensor web we consider the mof framework the mof is a data standard for meta modelling with a venerable multilayer architecture atkinson and kuhne 2003 determining the modelling concepts and their relationships based on the meta layers of mof the kpi meta modelling architecture consists of a hierarchy of four typical levels as shown in fig 2 each level is characterized as an instance of the level above the top level m3 generally called the meta meta model layer holds the related concepts and relationships of the node meta modelling the next level m2 is the meta model layer which includes the formalization meta model modelling facility meta model and information description meta model which formulates the formalizing rules facility constraints and metadata components level m1 is the model layer that holds the information description model the xml modelling language and the detailed metadata contents and structure at the bottom of the hierarchy level m0 holds the kpi monitoring metadata instances including the sensing nodes such as the satellites and hydrological stations the processing nodes such as the kpi extractors and the application nodes such as those displaying air quality the meta meta model layer that is level m3 is the kpi meta meta model which is an abstraction of the meta model the meta model layer that is level m2 is the instance of the meta meta model layer of m3 which is an abstraction of m1 the model layer that is level m1 is the instance of the meta model layer of m2 this m1 layer determines the nine tuple metadata structure based on the general framework defined by the information describing the meta model in level m2 to formalize the nine tuple metadata structure it is essential to use the modelling facilities and to formally express the standardization of the metadata which is defined by the formalization meta model and the modelling facility meta model in level m2 as well as the modelling facility based on the standard xml coding thus establishing a descriptive meta model of the kpi observations the instance layer that is level m0 which is at the bottom of the hierarchy also contains the instances of the heterogeneous kpi monitoring data each instance has its own specific data information formalized by the modelling facilities and certain rules of formal expression for finally establishing a descriptive model of the kpi monitoring data that can be accessed online 2 2 nine tuple information description structure referring to the internal metadata element and structure the nine tuple information description structure of the hkpm is shown in fig 3 in this part the identification data quality product tag distribution format data content transfer type product affiliated info temporal dimension spatial dimension distributor contact and observation reference fields meet the formal representation requirements of the different elements specifically the whole metadata organization of hkpm can be generalized as follows hkpm identification data content data affiliated data quality distribution format transfer type temporal dimension spatial dimension and administration which represents nine tuples of the kpi metadata the product tag content metadata quality and geolocation metadata are supported by nine tuples as shown in fig 3 these basic components are formalized by a detailed data type 1 identification information information about the kpi identification name type and level while the identification is uniquely defined by a globally unique code 2 data content information information about the kpi data content such as its smartness and interoperability and what type of records it contains such as economic education energy environmental recreation safety shelter and solid waste data records 3 data affiliated information about additional metadata products such as kpi snapshots kpi introductions meanings grades and other metadata 4 distribution format information information about the storage method of the kpis and the storage format storage form and storage environment which is related to kpi access efficiency e different data scales 5 transfer type information information about the kpi transfer form type and format which is directly responsible for kpi data accessibility 6 data quality information information about the kpi product quality and web service quality features this feature refers to the accessibility of the kpi web services 7 spatial dimension information information about the spatio temporal reference framework the location and the valid time features which describes the observation site 8 temporal dimension information information about the temporal reference framework and valid observation time features which describe the observation time 9 administration information information about the administrative department including the contact information and historical information 2 3 kpi classification and uml diagram for kpm regarding to the realization of kpi monitoring in hkpm manner the indicators could be computed in parallel during the process multiple kpi computation is an essential phase in the hkpm because it is applied to display the kpis to users to inform them about the urban operation status the kpis are designed to show the urban state from different perspectives there can be more than 100 indicators the city kpis were designed by the united nations sdgs fritz et al 2019 and include first level and second level indicators the first level indicators include those for the urban population and residences traffic and convenience land use cultural and natural heritage risk control and management strategies and ecological environment the second level indicators contain the sub indicators of the first level indicators the city kpis designed by the united nations sdgs contain mostly macro indicators instead of the elements or components of the kpi metadata therefore the kpi meta model should be defined in our study in our study we propose a monitoring oriented kpi dataset to facilitate analysis of the urban operation status involved indicators are used to achieve different aspects of city monitoring the content element in nine tuples of hkpm can be generalized as follows public service public sentiment urban emergency city management macro economy tourism government data centre population topic and so on as shown in fig 4 the sgds relevant on city level containing core sdgs have been added in the revised mapping relationship the core sdgs contains sustainable cities and communities goal peace justice and strong institutions goal no poverty goal zero hunger goal affordable and clean energy goal gender equality goal reduced inequalities good health and well being goal responsible consumption and production decent work and economic growth and climate action respectively 11 7 goal in sdgs provide access to safe and inclusive green and public spaces and 16 9 goal in sdgs provide universal legal identity which are related to residence service legal identity service is mapped to public service 1 3 goal in sdgs implement social protection systems 2 1 goal in sdgs universal access to safe and nutritious food 7 1 goal in sdgs universal access to modern energy 10 a special and differential treatment for developing countries 5 1 goal in sdgs end discrimination against women and girls 3 1 3 d goals in sdgs all goals and 12 4 goal in sdgs responsible management of chemicals and waste which are related to people s life and work demands are mapped to public sentiment and city management 8 1 goal in sdgs sustainable economic growth is mapped to macro economy 8 9 goal in sdgs promote beneficial and sustainable tourism which is related to sustainable tourism is mapped to tourism 13 1 goal in sdgs strengthen resilience and adaptive capacity to climate related disasters which is related wo disasters rescue is mapped to urban emergency 11 sdgs have been mapped to hkpm is fig 4 via the mapping relationship sdgs provides the goal support for heterogeneous kpis classification in sustainable cities public service indicator refers to the online government services for citizens such as event handling and social security services macro economy indicator refers to the gross domestic product gdp of the city and the economic growth rate in the most recent year public sentiment indicator refers to the basic living allowances and the old age group flood prevention indicator refers to the amount of precipitation and the water levels the government data centre indicator refers to all of the data and the number of data coverage departments the ecological indicator refers to the air quality urban greening rate and forest coverage rate indicators and city management indicator refers to the city appearance events street order events case completion rate and number of cases to be completed in kpi components in a sustainable city as showing in fig 5 indicators for city monitoring are designed to reflect the operational status of the city the hkpm cover the eight main aspects for monitoring the city as a sustainable city to achieve comprehensive sustainable city management the indicators for city monitoring should contain every aspect of city operation from the perspective of government from the perspective of the government the city operation aspects cover the public services for citizens which include the number of callers the number of accepted cases and citizen satisfaction indicator the macro economic perspective reflects the economic state which includes the industries fixed investments financial budget and retail sales and the government data centre aspect reflects the operational state of the data centre which includes the data categories departmental scope and data exchange after kpi classification section hkpm instantiation containing public service public sentiment urban emergency city management macro economy tourism government data centre and population topic sub kpi is essential in specific application scenarios fig 6 shows the uml diagram of hkpm defining common features and different data types supplying a means of encoding for 8 sub kpi in model instantiation phase each sub kpi is initialized according to the uml diagram to generate an instantiation file with specific indicator information moreover the uml diagram keeps up with the nine tuple information description structure in section 2 2 closely therefore the nine tuple information description structure is mapped to the instantiation file completely 2 4 integrating the hkpm observations with sos to integrate the kpi observations with the sensor web as described in the introduction section the data accessed from the sos in sensor web enablement should be stored in the database in this way the observations and metadata encoded with the hkpm can be accessed via sos implementation in sensor web enablement the sos offers pull based and uniform access to heterogeneous kpi measurements or the metadata and provides standardized access to the kpi observations and sensor metadata ogc 2007a in sos enablement the hkpm enables the uniform data access therefore sos makes it possible to access the heterogeneous and massive kpi data the ogc provides the interface of the observation measurements ogc 2007b ogc 2007c which encodes the data and metadata associated with the observations therefore the approach for integrating multiple indicators with the sos is the use of the data tables designed in the database to improve the retrieval efficiency of the massive kpi data and metadata in hkpm the hbase database is selected in our study in general data retrieval efficiency of hbase can reach several thousand instances per second for the exclusive indexing mechanism in distributed database mechanism in addition hbase is highly efficient for spatio temporal data retrieval li et al 2014a 2014b in the data tables in hbase the kpi metadata and data are stored in contrast to the ogc implementations such as from 52 north sos v1 0 to v4 0 52 north 2007 the data tables should include the characteristics of streaming data to integrate hbase with the sos the metadata and data should be encoded with the specified data tables in hbase to keep up with hkpm as fig 7 shows data tables in the hbase contain seven sub data tables including a kpi sensor type table a kpi sensor table a kpi observation table a phenomenon table an offering table and a feature of interest table the observation table is used to store the kpi observations the phenomenon table is used to store the details of the kpi observations including the organization name the phenomenon name and the sensor information and the feature of interest table is used to store the spatial arrangement of observations including the name and coordinates encoded with the geojson data type 3 experiments and evaluations section 3 1 describes the experimental sites and the experimental environments section 3 2 describes the prototype architecture section 3 3 describes the experimental process and section 3 3 describes the analysis of the experimental results 3 1 experimental environment as one of the most important cities in the group of cities on the guanzhong plain in china xi an plays an important role in education cultural diplomacy and economic development in shanxi province lintong is one of the most popular tourism districts in xi an city due to the emperor qin s terra cotta warriors which have been listed in the world heritage list organization 2009 xi an city is chosen for the experiment lintong is one of the most famous districts in xi an city which is an important national central city in western china that is rapidly developing as a sustainable city to show the kpi of xi an in from different aspects the results of most of the indicators should be visually displayed in this way the kpis of the city can be displayed from many aspects and angles thus the period considered in this study extends from march 26 2018 to april 09 2018 and the spatial extent of the experiment includes the case study area from 108 21e to 108 23e and the latitude range from 33 38n to 35 38n air is the most essential factor that sustains life on earth including indoor life becerra et al 2020 air pollution is a major problem caused by urban growth and poses a high risk to human health hence it is always advisable to monitor the quality of the air in our environments accurate and reliable aqi forecasting is extremely crucial for ecological environments and public health wu et al 2017 zhu et al 2017 at the same time as a rapidly developing city xi an has been suffering from air quality problems in recent years li ning 2015 there is some study on the air pollution prediction a geo long short term memory lstm neural network with good accuracy is proposed to interpolate the spatial distribution of pm2 5 ma et al 2019a a new methodology framework that combines lstm network and inverse distance weighted techniques to predict the air pollutant concentration based on historical records is proposed ma et al 2019b which is excellent and innovative before the experiment the distribution environment is established in our experimental environment the distributed computing clusters are established in each cluster five computers are employed with the same configuration the configuration of each node is i7 4720hq 6 m caches 8 cores 2 60 ghz 5 gt s with 16 gigabytes of random access memory they are connected with each other with a 100 gb s infiniband 3 2 hkpm realization framework to design the architecture of the hkpm there are some obvious essentials that need to be considered availability performance and scalability availability refers to the hkpm that should be available to different users including the government industry and citizens performance refers to the framework which should have a high performance because the number of users could reach into the hundreds of thousands scalability refers to the framework of the hkpm that should provide capability achieving the aims of the other kpi modelling in this framework as showing in fig 8 the cyber physical prototype framework based on the hkpm can be divided into three layers the application layer the cyber physical layer and the physical layer the application layer refers to the client of the hkpm which is used to achieve the interaction between users and the hkpm see fig 9 the application layer is an application that can be used with multiple types of terminal displays including desktops tablets personal computers and mobile phones with the mobile terminal the application layer can display the kpis of city operations and the results of the indicator computation with 4g or wireless fidelity wireless network connection technology the application layer can access the data or information from the cyber physical layer the cyber physical layer is a web service infrastructure strengthened by a cloud computing mechanism containing the business layer and a base layer when assisted by a distributed computing model the web service infrastructure can achieve high performance under the sensor web environment botts et al 2008 the sos web service zhou et al 2016 has been introduced to achieve the sharing of the different types of kpis for convenience and efficiency in addition many software frameworks have been developed such as hadoop arasanal and rumani 2013 philip chen and zhang 2014 spark wang et al 2016 and storm zhou et al 2017 due to its popularity and stability a hadoop cluster is selected as the basic cloud environment for the experiment dean and ghemawat dean and ghemawat 2008 first introduced mapreduce this model uses two core steps to process a task one is the map phase in which a key value pair is processed to generate a set of intermediate key value pairs and the other is the reduce phase in which all intermediate values associated with the same intermediate key are processed moreover the kpi computation is to achieve the computations such as total kpi and per capita kpi computation during the computation phase the extremum values and mean values can be computed as some of the kpis vary slowly such as the macro economy flood prevention indicator and ecological indicator and government data centre changes once per year public service kpi public sentiment kpi group concerns kpi and city management kpi change rapidly every day in our study hbase is applied to store the massive data insertions and the query demands dan and stroulia 2013 the hbase database is a distributed and column oriented storage system built on top of the hdfs when applied to lots of open source large scale datasets in real time hbase shows excellent performance nishimura et al 2013 the physical layer refers to the sensor layer madria et al 2014 marcus et al creating or collecting data including the economic indicator data tourism indicator data public sentiment perception data flood prevention indicator data attention of the masses indicator data data centre indicator data ecological indicator data and the city management indicator data the sensor layer conducts the indicators reading including the involved indicators the sensor layer makes up the physical layer which can push data into the cyber physical layer via the proposed standard encoding model encapsulated with the hkpm the kpi data can be pushed into hbase in hdfs in this way the data can be accessed with the sos in a uniform way 3 3 kpi monitoring with the hkpm during the kpis instantiation phase different kpis metadata modelling such as number of accepted cases aqi are instantiated to deliver the metadata for application or government users based on hkpm meta model disordered metadata information is integrated into a unified metadata model mover the kpis in other aspects can be instantiated in the unified manner promoting the discovery and further utilization of metadata number of cases accepted satisfaction pm 10 co and other kpis can be modelled via hkpm sheltering the heterogeneity of the multiple kpi representation models the two kpis to validate our proposed model the metadata of two kpis have been modelled in the instances so the feasibility of the proposed model has been validated in our experiments based on the hkpm the mcupip is designed to validate the feasibility and effectiveness of hkpm in this section based on the hkpm and mcupip realization architecture the monitoring and control of the urban operational indicator platform are developed fig 10 shows the air quality modelling example which is selected as a typical example of the experiment in the experiments heterogeneous observation sensors or platforms are selected that contained in situ sensors including moderate resolution imaging spectroradiometer modis and aqi sensor which form three dimensional and omnidirectional observations the identification data quality distribution format data content transfer type product affiliated info temporal dimension spatial dimension administration information is defined in the air quality modelling example when all elements are filled which is intuitive and convenient in the modelling phase the metadata corresponding to the nine tuple meta model of the hkpm have been assigned and instantiated through the kpi modelling module the instantiation files based on the xml format are created and then inserted into the database layer via the sos web service based on the table design containing multiple kpi observations in the modelling phase the identification information is initialized as illustrated overview of the kpi sensors identification platform info and keywords is defined so that these fields could be filled in the identification section the uuid full name and short name fields which uniquely identify the sensors are defined there are some specific details first kpi sensors can be divided into remote sensing sensors and in situ sensors remote sensing sensors include terra modis avhrr the french centre national d etudes spatiales and other satellites the in situ sensors contain multiple ground observation sensors second the kpi sensor metadata are conducive to locating and utilizing the kpi sensor observation data fig 11 shows all indicators demonstrated in the mcupip in fig 11 eight parts are displayed on the page including the public service indicator macroeconomy indicator tourism indicator online public opinion indicator urban emergency indicator population indicator data centre indicator enterprise indicator and city management indicator in a stereoscopic manner the public services show the number of accepted cases the number of handled cases the number of untreated cases the number of callings and the annual satisfaction rate the macro economy indicator shows the industrial output values financial budget gross domestic product gdp fixed investments and retail sales the tourism indicator shows the number of tourist complaints monthly tourist satisfaction and annual tourist satisfaction the online public opinion indicator shows the daily number of public complaint and the keywords of the public opinions the urban emergency indicator shows the rainfall information and the real time water levels the population indicator shows the proportion of men and women and the ethnic distribution the data centre shows the number of data categories the number of departments and the data exchange capacity the enterprise indicator shows the number of corporate enterprises individual businesses and family businesses among others city management shows the number of cases accepted today and the number of cases handled today the public service indicator of the hkpm shows the decisions and analysis of the public service status including the caller analysis satisfaction analysis analysis of case disposal analysis of departmental effectiveness economic hot words analysis and case analysis the caller analysis indicator contains the number of callers the number of answers and the reception ratio the satisfaction analysis indicator contains a comparison of the satisfaction with the different departments and the satisfaction ranking analysis of case disposal indicator contains comparisons of the amount of time it took each case to be handled the analysis of departmental effectiveness contains a comparison of the performances of different departments economic hot spot analysis contains a comparison of the frequency of different economic hot spots the case analysis contains the case handling number number of accepted cases and rate of cases handled on time the public sentiment monitoring of the hkpm shows the decision and analysis of the public opinion monitoring of the mcupip from multidimensional perspectives including four parts report of the media statistics indicator trends of concern indicator daily public opinion indicator and real time hot words indicator the report of the media statistics indicator contains the network media report ranking print media report ranking and the analysis of the distribution of media sources trends of concern indicator contain the degree of concern the attention levels towards different hot words the day public opinion indicator contains the daily popular daily stories in xi an city the real time hot words analysis indicator refers to the real time most widely searched words the urban emergence indicator of the hkpm shows the decisions and analysis of the urban management decision of the hkpm which contains the cases reported indicator case period indicator and the proportion of case content indicator in the cases reported indicator the cases in the city are counted including the daily number of cases reported the daily number of cases handled and the number of overdue cases in the case period indicator the period of the case occurrence the rate of settlements and the rate of filings is displayed in the proportion of cases content indicator the outstanding problems are classified and the numbers of different types of cases are illustrated the whole hkpm can cover the public service indicator macro economy indicator public sentiment indicator flood indicator the group concern indicator government data centre indicator ecological indicator and city management indicator to evaluate urban level sustainable cities taking xi an city as an example the hkpm prototype verifies the effectiveness of the hkpm in multiple aspects thorough perception at the urban level is achieved with the implementation of the sos web service concrete kpi values are accessed to create the kpi display in the hkpm prototype as shown in fig 12 multi year aqi from 2015 to 2016 is represented with a scatterplot and a boxplot which come from the mcupip prototype the aqi in summer and autumn is lower than that in spring and winter for xi an city which has an urban collective heating pattern in winter and a unique geographical location surrounded by the qinling mountains and the loess plateau for the exhibition of aqi the understanding of the aqi encoded in hkpm can be accessed by different users providing a comprehensive understanding of the aqi which is comprised of indicator about the pm 2 5 so2 no2 co o3 and pm 10 3 4 experimental performance evaluation to better define the feasibility and efficiency we evaluate the performance of the hkpm and the performance of the hkpm under different sizes of kpi data is evaluated and analysed with different nodes the kpi computational performance is different the performance of the indicator computation varied with different computation nodes in addition clusters can provide the capability for elastic expansion which can increase the computing nodes automatically according to the calculation or storage need in our experiments we select aqi with different volume including 6 89 8 34 and 10 24 billion which cover multiple data volumes reaching ten billion of the kpis we choose xi an kpi observation access at the scale of less than 100 million data volumes fig 13 shows the time needed for the system response in xi an city in the 52 north sos single node hkpm five nodes hkpm four nodes hkpm three nodes and hkpm two nodes the time taken by the hkpm with five nodes for 6 89 8 34 and 10 24 million is 0 9 1 0 and 1 1 s respectively while the time taken by the hkpm with a single node for 689 834 and 1024 ten thousand are 8 3 9 4 and 10 6 s respectively consequently efficiency of kpi access of the hkpm with five nodes is two times higher than the implementation of the 52 north sos to compare it with other more high performance data retrieval framework or methods we conduct the performance between hkpm realization and mongodb which is widely used lightweight stable and with excellent performance yang et al 2012 therefore we make the performance comparison between hkpm and mongodb as shown in fig 14 for 0 35 billion 2 45 billion and 10 24 billion indicator data volumes the time consumption by the mongodb method is approximately 0 6 s 8 s and 20 s respectively and consumption by the hkpm realization is 0 2 s 0 7 s and 1 1 s the mongodb approach reaches approximately 20 s while the hkpm realization approach reaches 1 1 s when access 10 24 billion data overall the efficiency of hkpm realization is approximately 3 20 times higher than that of mongodb as shown in fig 14 moreover it has should be noted that the larger the data scale is the more obvious the efficiency difference is 4 discussion and analysis 4 1 versatility and extensibility of the kpis modelling in terms of the heterogeneous kpis and their representation models such as iso gb t ogc and une we propose a unified and standard representation framework based on the mof architecture the metadata of the kpis are defined in a unified way with the representation framework the heterogeneity of the kpis is demonstrated in the modelling heterogeneous kpis and the detailed metadata of these kpis which ensure kpi sharing and interoperability under the geospatial sensor web environment in standards or specifications such as iso gb t ogc and une the kpi modelling focus on the top level design containing the concept technical system and framework instead of the metadata modelling and definitions different with iso gb t ogc and une we define the fulfilling the meta model with the multiple elements assembly and party group relationship therefore we provide a more concrete and meticulous manner for kpi modelling in environment water conservancy and urban management fields regarding to the kpi modelling extendibility we define the mandatory and non mandatory elements and the essential elements and provide the metadata expansion capability to define the specific and customized metadata elements therefore users or applications can extend the hkpm model to satisfy various needs by inheriting the extending interface or components 4 2 efficient kpi access for application or government users due to the very large quantity of kpi observations generated daily more attention should be paid to the accessibility of kpi observations consequently the content element in nine tuple of hkpm can be generalized as follows public service public sentiment urban emergency city management macro economy tourism government data centre population topic and so on in this manner diverse kpi instantiation process is unified besides mapping from some sdgs to hkpm has been summarized via the mapping relationship sdgs provides the support for heterogeneous kpis classification moreover uml diagram holds out the heterogeneous kpis metadata instantiation for application or government users such as such as number of accepted cases aqi in fig 8 in addition the cyber physical prototype architecture based on the hkpm is to apply distributed storage and computation technology to enhance the access performance of largescale kpi datasets as demonstrated in section 3 4 designing hkpm observations tables with sensor web enablement kpis observation can easily be accessed via sos in performance evaluation the efficiency of kpi access of the hkpm with five nodes is two times higher than that implemented in the 52 north sos as suggested above 4 3 application scope in sustainable cities different from xi an a typical tourist city it is necessary to consider the applicability of hkpm in other cities owing to the extensibility of kpis modelling in hkpm heterogeneous kpis in other city can be modelled via the mandatory elements in considering of other specific kpis no mandatory elements can support the kpis modelling capability in special aspects or not in sdgs moreover hkpm does not limit the scope of kpi modelling and hkpm provides the corresponding extension ability for other applications consequently kpis modelling has been strengthened and support the general or special kpis modelling requirements in other cities our work can be applied in urban management affairs for government administrators such as case management urban cases economic development environmental protection and social management population management population assistance in terms of other sustainable cities application such as corona virus disease covid 2019 fire flood explosion and other typical public safety events the capability hkpm supply should be considered seriously in order to better build sustainable cities especially when the covid 2019 is raging today kpis of such events should be defined by mathematical formula to be modelled then the metadata of such events is to be modelled in hkpm and displayed in the hkpm instantiation file with uml diagram at last the instantiation file can be accessed with sos web service by different applications therefore the technical process is the same with xi an sustainable cities application as exhibited in section 3 3 the difference is just to define kpi and metadata information in specific application scenarios 5 conclusions in conclusion this study proposes a heterogeneous kpi meta model to achieve standardization of many types of kpi representation sheltering kpi encoding heterogeneity in diverse metadata encoding standards in addition the structure of basic metadata components and the design a nine tuple kpi information description structure based on o m encoding model is defined besides the kpi classification based on sdgs has been accomplished to support hkpm instantiated in concrete public service and aqi kpi modelling instances in the sustainable city method proposed in section 2 the hkpm model covers eight aspects of the urban operational state including public services public sentiment urban emergencies city management macro economy tourism government data centre and population data in the experiment as demonstrated in section 3 the mcupip is designed and developed to achieve kpi monitoring from multiple kpi aspects in the performance test experiment the performance of the hkpm with five nodes is much faster than those of 52 north sos and hkpm with single nodes in this way multiple kpi observations in xi an city are monitored from eight aspects to achieve stereoscopic and omnidirectional city perception which can guarantee efficient urban sustainable development especially in sustainable cities application such as in covid 19 fire flood explosion and other typical public safety events hkpm can still supply the metadata encoding support for effective extensibility aiming to support the all round kpis encoding capability for government users however hkpm is not omnipotent in every city or application so hkpm should be more general covering eight aspects in sustainable cities and deeply bound to lintong district hkpm is not conducive to expansion to other cities such as shenzhen hong kong singapore after extension and adjustment hkpm can support the kpis displaying and visualization for sustainable cities monitoring this situation cannot be avoided because the specific situation of different cities is quite different however we can try more efforts to reduce the workload of adjustment in the future there will be some things to be studied first it is necessary to consider a closer relationship with sdg to increase the comprehensiveness of hkpm and strengthen the role of sdg in kpi coding however it is also necessary to consider the needs of diverse urban development characteristics in hkpm improvement second the adaptive kpi prototype could be further expanded to support the urban operation display and emergency rescue such as in material distribution and personnel rescue third kpi event service capability fan et al 2013 liu et al 2013 du et al 2019 could be studied to achieve disaster warnings and predictions via kpi analysis and mining technology such as artificial intelligence to guarantee the safety of the city during emergencies to construct a sustainable city fourth a smart city is a city that leverages the ict infrastructure in an adaptable reliable scalable accessible secure safe and resilient manner itu 2020 besides smart city digital city internet of things cloud computing li et al 2014a so we will deserve to apply the more advanced technology such as augmented reality virtual reality internet of things and artificial intelligence upgrading to a smart city declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was in part by supported by the national key research and development program of china 2019yfb2103104 national science foundation of china u1934215 41974006 the department of education of guangdong province 2018ktscx196 the shenzhen scientific research and development funding program kqjscx20180328093453763 jcyj20180305125101282 and grants from the china postdoctoral science foundation funded project 2018m632921 2019m663071 
25895,due to heterogeneous and inconsistent key performance indicators kpis for the quantitative evaluation of a sustainable city s operational status it is a great challenge to share multidimensional multi source and heterogeneous indicators we propose a heterogeneous kpi capability representation model hkpm in our study based on the meta object facility architecture a nine tuple multi hierarchical meta model is formulated to define the metadata components nine specific representation element datasets for specific kpis are proposed to represent the meta model besides the kpi classification based on sustainable development goals sdgs has been accomplished to support hkpm instantiated in concrete application experiments are conducted with the multi type kpis to validate the feasibility of hkpm as shown in public service and air quality index kpi instantiation example furthermore the kpis can be characterized in different dimensions which can be modelled in a stereoscopic manner promoting a comprehensive perception of sustainable cities keywords kpi meta model formulization framework heterogeneity geospatial sensor web sdgs 1 introduction 1 1 heterogeneous key performance indicators kpis in a sustainable city 17 sustainable development goals sdgs aim to turn to the sustainable development path and solve the development problems of social economic and environmental dimensions nations 2015 a sustainable city is a city designed with consideration for social economic environmental impact and resilient habitat for existing populations huan et al 2021 zhang et al 2019 along with the emergence of new technologies such as the internet of things 5g and ubiquitous communication the innovative concept of sustainable cities can help improve the resource utilization efficiency enhance urban management services and strengthen the quality of life of citizens by integrating urban systems and services lewis and ogra 2010 sustainable cities offer efficient transparent collaborative and standardized electronic platforms and external services for the government and the public bhati et al 2017 cox et al 2003 deng et al 2017 giuseppe et al 2017 lv et al sustainable cities application requires perception of environmental situations and the activities of the population to achieve smart responses and interactions ainuddin et al 2014 sustainable city perception of environmental situations from different perspectives such as those of the air quality health condition the macro economy industry development condition tu et al 2020 cao et al 2020 public sentiment situation could achieve the stereoscopic and multidimensional understanding of city operational conditions the perception of different aspects of cities is important and essential llinares et al 2013 because it is the basis for other parts of sustainable cities such as data centre establishment smart applications in transportation tourism people s livelihoods economic policy decision and other applications cagliero et al 2015 some big data analytic tools have been applied into sustainable business management including city perception raut et al 2019b singh et al 2018 the big data potential and opportunities include business intelligence value creation and business decisions kumar et al 2013 big data analytics capabilities are data driven and enjoy advantages as follows of data analysis and generation process m song 2015 suggested integration or fusion from the heterogeneous data sources giroux et al 2019 qiu et al 2017 sun et al 2019 assimilates different types of findings into the unified business process sodhro et al 2019 sun et al 2019 and data visualization capability simplifies the decision making process ren et al 2019 hard and soft indicators for evaluating green management practice have been explored and interrelationship between the green practices and business performance has been explored raut et al 2019a meanwhile the proposed model is applied to assess the sustainability productivity of 133 countries from an empirical perspective concerning sustainable city perception of environmental situations such as air quality indicator aqi the sensor web can help achieve stereoscopic and omnidirectional perception the sensor web enablement initiative of the open gis consortium ogc defines a sensor web as an cyber infrastructure enabling access to sensor networks and archived sensor data which can be discovered and accessed using standard protocols and interfaces botts et al 2008 different with a sensor network a sensor web shields the underlying device layers the heterogeneous sensor hardware and the network communication details broring et al 2011 however employing a sensor web and integrating it with sustainable cities is a great challenge because there is no standard or replicate sustainable city blueprint for the construction of sustainable cities around the world there are some policy and technical problems for the construction of sustainable cities furthermore there are no universally standard and uniform data or metadata representation models in general 1 2 related work on comprehensive kpi monitoring to achieve comprehensive city monitoring such as aqi the kpi cyber monitoring infrastructure provides an effective and convenient method for sustainable city affairs reddy et al 2014b regarding the kpi monitoring information framework technology cyberinfrastructure ci consists of computing systems data storage systems advanced instruments and data repositories visualization environments moreover all these components or devices are linked by software and high performance networks to improve productivity and to enable breakthroughs that would not otherwise be possible personal et al 2014 reddy et al 2014a mohammed et al extended the task technology matching model to measure the attributes of specific technologies and to empirically examine the model with new technologies mohammed et al 2017 cai et al proposed a framework using a systematic approach for improving the establishment of iterative kpis in a supply chain context cai et al 2009 with a government affairs service platform for sustainable cities a series of sustainable city services can be conducted to manage users and operations supervisors in government agencies and other sustainable city industries lv et al 2018 chen proposed the concepts and architecture of cloud storage data modelling and visualization of geographical environment observation task chen et al 2016 hu et al 2020 hara et al hara et al 2016 conducted an application by applying the proposed kpi specifications to individual information and communication technology solutions of internet protocol announcements wi fi hotspot and information transmission and control which had already been installed in a sustainable city standardization of the representation of kpis can help solve these problems through a systematic approach to improving the iterative establishment of kpis in a supply chain kpis can be applied by the decision makers in a supply chain cagliero et al 2015 wetzstein et al 2012 through standardization kpi can be calculated to quantify the performance of the evaluated object hara et al 2016 in cities there are many indexes such as economic operation indicators climate indicators population indicators urban event indicators ecological environment indicators and other indicators moreover the multi source heterogeneous kpi in a sustainable city contains multiple aspects covering multiple aspects in a real world or city nevertheless the listed kpi cannot exhaust all kpi of objective existence for the city covers the real world is a complex multidimensional space it should be noted that the kpi could be divided into multi scale and multi level sub kpi such as national provincial municipal county town level not only the kpi observations but also the kpi metadata differ among different datasets therefore the representation standardization of multi source heterogeneous kpis should be paid more attention 1 3 existing metadata models and problems however many heterogeneous kpi representation models exist the international organization for standardization iso 19 115 iso 2014 provides basic metadata for describing and locating geographical information iso 37106 2018 iso 2018 defines an open collaborative citizen centric and digitally enabled operating model for their city that put its vision for a sustainable future into operation the european organization for standardization une en iso 178 301 2015 une 2015 defines open data in a sustainable city in spain the sensor model language sensorml 2 0 of the ogc opengis 2007 defines a standardized format for metadata representation for sensor modelling and reduces the heterogeneity of multiple sensors under the sensor web environment the ogc observations measurements o m opengis 2010 2 0 encoding model defines a conceptual schema and extensible mark up language xml encoding for observations and features involved in sampling presently metadata specifications for the representation of kpi information are mainly defined by the international organization for standardization technical committee iso tc 211 the ogc and une en iso as shown in table 1 the corresponding metadata specifications or drafts which contain iso ts 37151 2015 iso 37106 2018 une 178301 2015 ogc 14 115 sustainable cities spatial information framework ogc sensorml 1 0 and 2 0 and ogc o m 1 0 and 2 0 are listed in table 1 at the same time standardization administration of china sac has developed the national standard guide technical documents gb t 34 678 2017 sac 2017b gb t 34680 3 2017 sac 2017a and gb t 37 043 2018 sac 2018a sac 2018b to define the formulation of the geospatial metadata xml for digital cities sustainable cities and the surveying and mapping industry these standards define the metadata for establishing sustainable city operating models for sustainable communities di et al di et al 2009 noted that these standards could be applied to determine the correct resources for the correct times and locations with the appropriate quality as shown in table 1 most indicator has been recorded and most aspects of cities such as the economy education and energy have been included to provide a comprehensive and stereoscopic view of the city moreover six kpis or sensor related metadata specifications or standards are considered together with descriptions of the metadata content encoding schema and applications to reduce heterogeneity of the multiple kpi representation models and to accomplish multilevel and thorough kpi monitoring in sustainable cities defined in sdgs there are some difficulties that must be solved 1 the multiple metadata standards listed above show distinct descriptive features for different applications which are relatively suitable for the modelling of specific metadata in a unified manner however it is still difficult include adequate metadata content to satisfy the characteristics of various heterogeneous kpi metadata consequently the various existing metadata representations or standards result in information silos among different systems fan et al 2015 2 there are many types of kpis as the current kpi types contain more than hundreds of types in sustainable cities in addition the greater effort has been applied to sensor metadata sensor capabilities and sensor web nodes furthermore kpi modelling has received little attention 3 the necessary computing capability for the calculation of kpis during the perception process is great to achieve kpis modelled in a stereoscopic manner the data volume of kpis can reach to gigabyte gb or hundreds of millions of data records hindering the efficient data access for government administrators 1 4 contribution and organization in terms of research objectives we propose a heterogeneous kpi perception meta model hkpm to unify the heterogeneous kpi representation model and to enhance city perception in a stereoscopic manner such as air quality index aqi under a sensor web moghaddam et al 2010 zhang et al 2018 environment sheltering kpi encoding heterogeneity in diverse metadata encoding standards by coupling heterogeneous kpi metadata model with meta object facility mof framework the hkpm covers the most attributes in table 1 to be a beneficial encoding model to support different kinds of kpi encoding in the standard representation framework in sustainable cities moreover indicators in hkpm are built based on sgds framework covering some related indicators from sdgs aiming to be an important representation model support for the establishment of sustainable cities accessed from the sensor observation service sos in sensor web enablement kpis can be accessed in a unified manner for application or government traffic manager zhou et al 2020 based on the mof a nine tuple multi hierarchical meta model is formulated to define the metadata components nine specific representation element datasets for specific kpis are proposed to represent the meta model the open geospatial consortium observations measurements o m modelling language is applied to formulate hkpm besides the kpi classification based on sdgs has been accomplished to support hkpm instantiated in the experiment as demonstrated in section 3 the monitoring and control of urban operational indicators platform mcupip is designed and developed to achieve kpi monitoring from multiple kpi aspects taking aqi for example this paper is organized as following the details of the hkpm are described in section 2 the experiments are conducted in section 3 to validate the feasibility of the model section 4 provides a discussion and the conclusions of the study and potential future directions are also discussed 2 hkpm meta modelling is a process that builds a collection of components elements and sub collections that are a further abstraction of the core parts of the metadata to construct a model to achieve unified metadata modelling to reduce heterogeneity of the kpi representation model for the economy humanity and the environment meta modelling is applied in our study as a method for abstraction and aggregation the heterogeneous kpi model defines the meta modelling layers information describing rules associations and metadata definition standards see fig 1 2 1 hkpm meta modelling based on mof in proposing the heterogeneous kpi meta model to describe the kpis in a unified manner in the sensor web we consider the mof framework the mof is a data standard for meta modelling with a venerable multilayer architecture atkinson and kuhne 2003 determining the modelling concepts and their relationships based on the meta layers of mof the kpi meta modelling architecture consists of a hierarchy of four typical levels as shown in fig 2 each level is characterized as an instance of the level above the top level m3 generally called the meta meta model layer holds the related concepts and relationships of the node meta modelling the next level m2 is the meta model layer which includes the formalization meta model modelling facility meta model and information description meta model which formulates the formalizing rules facility constraints and metadata components level m1 is the model layer that holds the information description model the xml modelling language and the detailed metadata contents and structure at the bottom of the hierarchy level m0 holds the kpi monitoring metadata instances including the sensing nodes such as the satellites and hydrological stations the processing nodes such as the kpi extractors and the application nodes such as those displaying air quality the meta meta model layer that is level m3 is the kpi meta meta model which is an abstraction of the meta model the meta model layer that is level m2 is the instance of the meta meta model layer of m3 which is an abstraction of m1 the model layer that is level m1 is the instance of the meta model layer of m2 this m1 layer determines the nine tuple metadata structure based on the general framework defined by the information describing the meta model in level m2 to formalize the nine tuple metadata structure it is essential to use the modelling facilities and to formally express the standardization of the metadata which is defined by the formalization meta model and the modelling facility meta model in level m2 as well as the modelling facility based on the standard xml coding thus establishing a descriptive meta model of the kpi observations the instance layer that is level m0 which is at the bottom of the hierarchy also contains the instances of the heterogeneous kpi monitoring data each instance has its own specific data information formalized by the modelling facilities and certain rules of formal expression for finally establishing a descriptive model of the kpi monitoring data that can be accessed online 2 2 nine tuple information description structure referring to the internal metadata element and structure the nine tuple information description structure of the hkpm is shown in fig 3 in this part the identification data quality product tag distribution format data content transfer type product affiliated info temporal dimension spatial dimension distributor contact and observation reference fields meet the formal representation requirements of the different elements specifically the whole metadata organization of hkpm can be generalized as follows hkpm identification data content data affiliated data quality distribution format transfer type temporal dimension spatial dimension and administration which represents nine tuples of the kpi metadata the product tag content metadata quality and geolocation metadata are supported by nine tuples as shown in fig 3 these basic components are formalized by a detailed data type 1 identification information information about the kpi identification name type and level while the identification is uniquely defined by a globally unique code 2 data content information information about the kpi data content such as its smartness and interoperability and what type of records it contains such as economic education energy environmental recreation safety shelter and solid waste data records 3 data affiliated information about additional metadata products such as kpi snapshots kpi introductions meanings grades and other metadata 4 distribution format information information about the storage method of the kpis and the storage format storage form and storage environment which is related to kpi access efficiency e different data scales 5 transfer type information information about the kpi transfer form type and format which is directly responsible for kpi data accessibility 6 data quality information information about the kpi product quality and web service quality features this feature refers to the accessibility of the kpi web services 7 spatial dimension information information about the spatio temporal reference framework the location and the valid time features which describes the observation site 8 temporal dimension information information about the temporal reference framework and valid observation time features which describe the observation time 9 administration information information about the administrative department including the contact information and historical information 2 3 kpi classification and uml diagram for kpm regarding to the realization of kpi monitoring in hkpm manner the indicators could be computed in parallel during the process multiple kpi computation is an essential phase in the hkpm because it is applied to display the kpis to users to inform them about the urban operation status the kpis are designed to show the urban state from different perspectives there can be more than 100 indicators the city kpis were designed by the united nations sdgs fritz et al 2019 and include first level and second level indicators the first level indicators include those for the urban population and residences traffic and convenience land use cultural and natural heritage risk control and management strategies and ecological environment the second level indicators contain the sub indicators of the first level indicators the city kpis designed by the united nations sdgs contain mostly macro indicators instead of the elements or components of the kpi metadata therefore the kpi meta model should be defined in our study in our study we propose a monitoring oriented kpi dataset to facilitate analysis of the urban operation status involved indicators are used to achieve different aspects of city monitoring the content element in nine tuples of hkpm can be generalized as follows public service public sentiment urban emergency city management macro economy tourism government data centre population topic and so on as shown in fig 4 the sgds relevant on city level containing core sdgs have been added in the revised mapping relationship the core sdgs contains sustainable cities and communities goal peace justice and strong institutions goal no poverty goal zero hunger goal affordable and clean energy goal gender equality goal reduced inequalities good health and well being goal responsible consumption and production decent work and economic growth and climate action respectively 11 7 goal in sdgs provide access to safe and inclusive green and public spaces and 16 9 goal in sdgs provide universal legal identity which are related to residence service legal identity service is mapped to public service 1 3 goal in sdgs implement social protection systems 2 1 goal in sdgs universal access to safe and nutritious food 7 1 goal in sdgs universal access to modern energy 10 a special and differential treatment for developing countries 5 1 goal in sdgs end discrimination against women and girls 3 1 3 d goals in sdgs all goals and 12 4 goal in sdgs responsible management of chemicals and waste which are related to people s life and work demands are mapped to public sentiment and city management 8 1 goal in sdgs sustainable economic growth is mapped to macro economy 8 9 goal in sdgs promote beneficial and sustainable tourism which is related to sustainable tourism is mapped to tourism 13 1 goal in sdgs strengthen resilience and adaptive capacity to climate related disasters which is related wo disasters rescue is mapped to urban emergency 11 sdgs have been mapped to hkpm is fig 4 via the mapping relationship sdgs provides the goal support for heterogeneous kpis classification in sustainable cities public service indicator refers to the online government services for citizens such as event handling and social security services macro economy indicator refers to the gross domestic product gdp of the city and the economic growth rate in the most recent year public sentiment indicator refers to the basic living allowances and the old age group flood prevention indicator refers to the amount of precipitation and the water levels the government data centre indicator refers to all of the data and the number of data coverage departments the ecological indicator refers to the air quality urban greening rate and forest coverage rate indicators and city management indicator refers to the city appearance events street order events case completion rate and number of cases to be completed in kpi components in a sustainable city as showing in fig 5 indicators for city monitoring are designed to reflect the operational status of the city the hkpm cover the eight main aspects for monitoring the city as a sustainable city to achieve comprehensive sustainable city management the indicators for city monitoring should contain every aspect of city operation from the perspective of government from the perspective of the government the city operation aspects cover the public services for citizens which include the number of callers the number of accepted cases and citizen satisfaction indicator the macro economic perspective reflects the economic state which includes the industries fixed investments financial budget and retail sales and the government data centre aspect reflects the operational state of the data centre which includes the data categories departmental scope and data exchange after kpi classification section hkpm instantiation containing public service public sentiment urban emergency city management macro economy tourism government data centre and population topic sub kpi is essential in specific application scenarios fig 6 shows the uml diagram of hkpm defining common features and different data types supplying a means of encoding for 8 sub kpi in model instantiation phase each sub kpi is initialized according to the uml diagram to generate an instantiation file with specific indicator information moreover the uml diagram keeps up with the nine tuple information description structure in section 2 2 closely therefore the nine tuple information description structure is mapped to the instantiation file completely 2 4 integrating the hkpm observations with sos to integrate the kpi observations with the sensor web as described in the introduction section the data accessed from the sos in sensor web enablement should be stored in the database in this way the observations and metadata encoded with the hkpm can be accessed via sos implementation in sensor web enablement the sos offers pull based and uniform access to heterogeneous kpi measurements or the metadata and provides standardized access to the kpi observations and sensor metadata ogc 2007a in sos enablement the hkpm enables the uniform data access therefore sos makes it possible to access the heterogeneous and massive kpi data the ogc provides the interface of the observation measurements ogc 2007b ogc 2007c which encodes the data and metadata associated with the observations therefore the approach for integrating multiple indicators with the sos is the use of the data tables designed in the database to improve the retrieval efficiency of the massive kpi data and metadata in hkpm the hbase database is selected in our study in general data retrieval efficiency of hbase can reach several thousand instances per second for the exclusive indexing mechanism in distributed database mechanism in addition hbase is highly efficient for spatio temporal data retrieval li et al 2014a 2014b in the data tables in hbase the kpi metadata and data are stored in contrast to the ogc implementations such as from 52 north sos v1 0 to v4 0 52 north 2007 the data tables should include the characteristics of streaming data to integrate hbase with the sos the metadata and data should be encoded with the specified data tables in hbase to keep up with hkpm as fig 7 shows data tables in the hbase contain seven sub data tables including a kpi sensor type table a kpi sensor table a kpi observation table a phenomenon table an offering table and a feature of interest table the observation table is used to store the kpi observations the phenomenon table is used to store the details of the kpi observations including the organization name the phenomenon name and the sensor information and the feature of interest table is used to store the spatial arrangement of observations including the name and coordinates encoded with the geojson data type 3 experiments and evaluations section 3 1 describes the experimental sites and the experimental environments section 3 2 describes the prototype architecture section 3 3 describes the experimental process and section 3 3 describes the analysis of the experimental results 3 1 experimental environment as one of the most important cities in the group of cities on the guanzhong plain in china xi an plays an important role in education cultural diplomacy and economic development in shanxi province lintong is one of the most popular tourism districts in xi an city due to the emperor qin s terra cotta warriors which have been listed in the world heritage list organization 2009 xi an city is chosen for the experiment lintong is one of the most famous districts in xi an city which is an important national central city in western china that is rapidly developing as a sustainable city to show the kpi of xi an in from different aspects the results of most of the indicators should be visually displayed in this way the kpis of the city can be displayed from many aspects and angles thus the period considered in this study extends from march 26 2018 to april 09 2018 and the spatial extent of the experiment includes the case study area from 108 21e to 108 23e and the latitude range from 33 38n to 35 38n air is the most essential factor that sustains life on earth including indoor life becerra et al 2020 air pollution is a major problem caused by urban growth and poses a high risk to human health hence it is always advisable to monitor the quality of the air in our environments accurate and reliable aqi forecasting is extremely crucial for ecological environments and public health wu et al 2017 zhu et al 2017 at the same time as a rapidly developing city xi an has been suffering from air quality problems in recent years li ning 2015 there is some study on the air pollution prediction a geo long short term memory lstm neural network with good accuracy is proposed to interpolate the spatial distribution of pm2 5 ma et al 2019a a new methodology framework that combines lstm network and inverse distance weighted techniques to predict the air pollutant concentration based on historical records is proposed ma et al 2019b which is excellent and innovative before the experiment the distribution environment is established in our experimental environment the distributed computing clusters are established in each cluster five computers are employed with the same configuration the configuration of each node is i7 4720hq 6 m caches 8 cores 2 60 ghz 5 gt s with 16 gigabytes of random access memory they are connected with each other with a 100 gb s infiniband 3 2 hkpm realization framework to design the architecture of the hkpm there are some obvious essentials that need to be considered availability performance and scalability availability refers to the hkpm that should be available to different users including the government industry and citizens performance refers to the framework which should have a high performance because the number of users could reach into the hundreds of thousands scalability refers to the framework of the hkpm that should provide capability achieving the aims of the other kpi modelling in this framework as showing in fig 8 the cyber physical prototype framework based on the hkpm can be divided into three layers the application layer the cyber physical layer and the physical layer the application layer refers to the client of the hkpm which is used to achieve the interaction between users and the hkpm see fig 9 the application layer is an application that can be used with multiple types of terminal displays including desktops tablets personal computers and mobile phones with the mobile terminal the application layer can display the kpis of city operations and the results of the indicator computation with 4g or wireless fidelity wireless network connection technology the application layer can access the data or information from the cyber physical layer the cyber physical layer is a web service infrastructure strengthened by a cloud computing mechanism containing the business layer and a base layer when assisted by a distributed computing model the web service infrastructure can achieve high performance under the sensor web environment botts et al 2008 the sos web service zhou et al 2016 has been introduced to achieve the sharing of the different types of kpis for convenience and efficiency in addition many software frameworks have been developed such as hadoop arasanal and rumani 2013 philip chen and zhang 2014 spark wang et al 2016 and storm zhou et al 2017 due to its popularity and stability a hadoop cluster is selected as the basic cloud environment for the experiment dean and ghemawat dean and ghemawat 2008 first introduced mapreduce this model uses two core steps to process a task one is the map phase in which a key value pair is processed to generate a set of intermediate key value pairs and the other is the reduce phase in which all intermediate values associated with the same intermediate key are processed moreover the kpi computation is to achieve the computations such as total kpi and per capita kpi computation during the computation phase the extremum values and mean values can be computed as some of the kpis vary slowly such as the macro economy flood prevention indicator and ecological indicator and government data centre changes once per year public service kpi public sentiment kpi group concerns kpi and city management kpi change rapidly every day in our study hbase is applied to store the massive data insertions and the query demands dan and stroulia 2013 the hbase database is a distributed and column oriented storage system built on top of the hdfs when applied to lots of open source large scale datasets in real time hbase shows excellent performance nishimura et al 2013 the physical layer refers to the sensor layer madria et al 2014 marcus et al creating or collecting data including the economic indicator data tourism indicator data public sentiment perception data flood prevention indicator data attention of the masses indicator data data centre indicator data ecological indicator data and the city management indicator data the sensor layer conducts the indicators reading including the involved indicators the sensor layer makes up the physical layer which can push data into the cyber physical layer via the proposed standard encoding model encapsulated with the hkpm the kpi data can be pushed into hbase in hdfs in this way the data can be accessed with the sos in a uniform way 3 3 kpi monitoring with the hkpm during the kpis instantiation phase different kpis metadata modelling such as number of accepted cases aqi are instantiated to deliver the metadata for application or government users based on hkpm meta model disordered metadata information is integrated into a unified metadata model mover the kpis in other aspects can be instantiated in the unified manner promoting the discovery and further utilization of metadata number of cases accepted satisfaction pm 10 co and other kpis can be modelled via hkpm sheltering the heterogeneity of the multiple kpi representation models the two kpis to validate our proposed model the metadata of two kpis have been modelled in the instances so the feasibility of the proposed model has been validated in our experiments based on the hkpm the mcupip is designed to validate the feasibility and effectiveness of hkpm in this section based on the hkpm and mcupip realization architecture the monitoring and control of the urban operational indicator platform are developed fig 10 shows the air quality modelling example which is selected as a typical example of the experiment in the experiments heterogeneous observation sensors or platforms are selected that contained in situ sensors including moderate resolution imaging spectroradiometer modis and aqi sensor which form three dimensional and omnidirectional observations the identification data quality distribution format data content transfer type product affiliated info temporal dimension spatial dimension administration information is defined in the air quality modelling example when all elements are filled which is intuitive and convenient in the modelling phase the metadata corresponding to the nine tuple meta model of the hkpm have been assigned and instantiated through the kpi modelling module the instantiation files based on the xml format are created and then inserted into the database layer via the sos web service based on the table design containing multiple kpi observations in the modelling phase the identification information is initialized as illustrated overview of the kpi sensors identification platform info and keywords is defined so that these fields could be filled in the identification section the uuid full name and short name fields which uniquely identify the sensors are defined there are some specific details first kpi sensors can be divided into remote sensing sensors and in situ sensors remote sensing sensors include terra modis avhrr the french centre national d etudes spatiales and other satellites the in situ sensors contain multiple ground observation sensors second the kpi sensor metadata are conducive to locating and utilizing the kpi sensor observation data fig 11 shows all indicators demonstrated in the mcupip in fig 11 eight parts are displayed on the page including the public service indicator macroeconomy indicator tourism indicator online public opinion indicator urban emergency indicator population indicator data centre indicator enterprise indicator and city management indicator in a stereoscopic manner the public services show the number of accepted cases the number of handled cases the number of untreated cases the number of callings and the annual satisfaction rate the macro economy indicator shows the industrial output values financial budget gross domestic product gdp fixed investments and retail sales the tourism indicator shows the number of tourist complaints monthly tourist satisfaction and annual tourist satisfaction the online public opinion indicator shows the daily number of public complaint and the keywords of the public opinions the urban emergency indicator shows the rainfall information and the real time water levels the population indicator shows the proportion of men and women and the ethnic distribution the data centre shows the number of data categories the number of departments and the data exchange capacity the enterprise indicator shows the number of corporate enterprises individual businesses and family businesses among others city management shows the number of cases accepted today and the number of cases handled today the public service indicator of the hkpm shows the decisions and analysis of the public service status including the caller analysis satisfaction analysis analysis of case disposal analysis of departmental effectiveness economic hot words analysis and case analysis the caller analysis indicator contains the number of callers the number of answers and the reception ratio the satisfaction analysis indicator contains a comparison of the satisfaction with the different departments and the satisfaction ranking analysis of case disposal indicator contains comparisons of the amount of time it took each case to be handled the analysis of departmental effectiveness contains a comparison of the performances of different departments economic hot spot analysis contains a comparison of the frequency of different economic hot spots the case analysis contains the case handling number number of accepted cases and rate of cases handled on time the public sentiment monitoring of the hkpm shows the decision and analysis of the public opinion monitoring of the mcupip from multidimensional perspectives including four parts report of the media statistics indicator trends of concern indicator daily public opinion indicator and real time hot words indicator the report of the media statistics indicator contains the network media report ranking print media report ranking and the analysis of the distribution of media sources trends of concern indicator contain the degree of concern the attention levels towards different hot words the day public opinion indicator contains the daily popular daily stories in xi an city the real time hot words analysis indicator refers to the real time most widely searched words the urban emergence indicator of the hkpm shows the decisions and analysis of the urban management decision of the hkpm which contains the cases reported indicator case period indicator and the proportion of case content indicator in the cases reported indicator the cases in the city are counted including the daily number of cases reported the daily number of cases handled and the number of overdue cases in the case period indicator the period of the case occurrence the rate of settlements and the rate of filings is displayed in the proportion of cases content indicator the outstanding problems are classified and the numbers of different types of cases are illustrated the whole hkpm can cover the public service indicator macro economy indicator public sentiment indicator flood indicator the group concern indicator government data centre indicator ecological indicator and city management indicator to evaluate urban level sustainable cities taking xi an city as an example the hkpm prototype verifies the effectiveness of the hkpm in multiple aspects thorough perception at the urban level is achieved with the implementation of the sos web service concrete kpi values are accessed to create the kpi display in the hkpm prototype as shown in fig 12 multi year aqi from 2015 to 2016 is represented with a scatterplot and a boxplot which come from the mcupip prototype the aqi in summer and autumn is lower than that in spring and winter for xi an city which has an urban collective heating pattern in winter and a unique geographical location surrounded by the qinling mountains and the loess plateau for the exhibition of aqi the understanding of the aqi encoded in hkpm can be accessed by different users providing a comprehensive understanding of the aqi which is comprised of indicator about the pm 2 5 so2 no2 co o3 and pm 10 3 4 experimental performance evaluation to better define the feasibility and efficiency we evaluate the performance of the hkpm and the performance of the hkpm under different sizes of kpi data is evaluated and analysed with different nodes the kpi computational performance is different the performance of the indicator computation varied with different computation nodes in addition clusters can provide the capability for elastic expansion which can increase the computing nodes automatically according to the calculation or storage need in our experiments we select aqi with different volume including 6 89 8 34 and 10 24 billion which cover multiple data volumes reaching ten billion of the kpis we choose xi an kpi observation access at the scale of less than 100 million data volumes fig 13 shows the time needed for the system response in xi an city in the 52 north sos single node hkpm five nodes hkpm four nodes hkpm three nodes and hkpm two nodes the time taken by the hkpm with five nodes for 6 89 8 34 and 10 24 million is 0 9 1 0 and 1 1 s respectively while the time taken by the hkpm with a single node for 689 834 and 1024 ten thousand are 8 3 9 4 and 10 6 s respectively consequently efficiency of kpi access of the hkpm with five nodes is two times higher than the implementation of the 52 north sos to compare it with other more high performance data retrieval framework or methods we conduct the performance between hkpm realization and mongodb which is widely used lightweight stable and with excellent performance yang et al 2012 therefore we make the performance comparison between hkpm and mongodb as shown in fig 14 for 0 35 billion 2 45 billion and 10 24 billion indicator data volumes the time consumption by the mongodb method is approximately 0 6 s 8 s and 20 s respectively and consumption by the hkpm realization is 0 2 s 0 7 s and 1 1 s the mongodb approach reaches approximately 20 s while the hkpm realization approach reaches 1 1 s when access 10 24 billion data overall the efficiency of hkpm realization is approximately 3 20 times higher than that of mongodb as shown in fig 14 moreover it has should be noted that the larger the data scale is the more obvious the efficiency difference is 4 discussion and analysis 4 1 versatility and extensibility of the kpis modelling in terms of the heterogeneous kpis and their representation models such as iso gb t ogc and une we propose a unified and standard representation framework based on the mof architecture the metadata of the kpis are defined in a unified way with the representation framework the heterogeneity of the kpis is demonstrated in the modelling heterogeneous kpis and the detailed metadata of these kpis which ensure kpi sharing and interoperability under the geospatial sensor web environment in standards or specifications such as iso gb t ogc and une the kpi modelling focus on the top level design containing the concept technical system and framework instead of the metadata modelling and definitions different with iso gb t ogc and une we define the fulfilling the meta model with the multiple elements assembly and party group relationship therefore we provide a more concrete and meticulous manner for kpi modelling in environment water conservancy and urban management fields regarding to the kpi modelling extendibility we define the mandatory and non mandatory elements and the essential elements and provide the metadata expansion capability to define the specific and customized metadata elements therefore users or applications can extend the hkpm model to satisfy various needs by inheriting the extending interface or components 4 2 efficient kpi access for application or government users due to the very large quantity of kpi observations generated daily more attention should be paid to the accessibility of kpi observations consequently the content element in nine tuple of hkpm can be generalized as follows public service public sentiment urban emergency city management macro economy tourism government data centre population topic and so on in this manner diverse kpi instantiation process is unified besides mapping from some sdgs to hkpm has been summarized via the mapping relationship sdgs provides the support for heterogeneous kpis classification moreover uml diagram holds out the heterogeneous kpis metadata instantiation for application or government users such as such as number of accepted cases aqi in fig 8 in addition the cyber physical prototype architecture based on the hkpm is to apply distributed storage and computation technology to enhance the access performance of largescale kpi datasets as demonstrated in section 3 4 designing hkpm observations tables with sensor web enablement kpis observation can easily be accessed via sos in performance evaluation the efficiency of kpi access of the hkpm with five nodes is two times higher than that implemented in the 52 north sos as suggested above 4 3 application scope in sustainable cities different from xi an a typical tourist city it is necessary to consider the applicability of hkpm in other cities owing to the extensibility of kpis modelling in hkpm heterogeneous kpis in other city can be modelled via the mandatory elements in considering of other specific kpis no mandatory elements can support the kpis modelling capability in special aspects or not in sdgs moreover hkpm does not limit the scope of kpi modelling and hkpm provides the corresponding extension ability for other applications consequently kpis modelling has been strengthened and support the general or special kpis modelling requirements in other cities our work can be applied in urban management affairs for government administrators such as case management urban cases economic development environmental protection and social management population management population assistance in terms of other sustainable cities application such as corona virus disease covid 2019 fire flood explosion and other typical public safety events the capability hkpm supply should be considered seriously in order to better build sustainable cities especially when the covid 2019 is raging today kpis of such events should be defined by mathematical formula to be modelled then the metadata of such events is to be modelled in hkpm and displayed in the hkpm instantiation file with uml diagram at last the instantiation file can be accessed with sos web service by different applications therefore the technical process is the same with xi an sustainable cities application as exhibited in section 3 3 the difference is just to define kpi and metadata information in specific application scenarios 5 conclusions in conclusion this study proposes a heterogeneous kpi meta model to achieve standardization of many types of kpi representation sheltering kpi encoding heterogeneity in diverse metadata encoding standards in addition the structure of basic metadata components and the design a nine tuple kpi information description structure based on o m encoding model is defined besides the kpi classification based on sdgs has been accomplished to support hkpm instantiated in concrete public service and aqi kpi modelling instances in the sustainable city method proposed in section 2 the hkpm model covers eight aspects of the urban operational state including public services public sentiment urban emergencies city management macro economy tourism government data centre and population data in the experiment as demonstrated in section 3 the mcupip is designed and developed to achieve kpi monitoring from multiple kpi aspects in the performance test experiment the performance of the hkpm with five nodes is much faster than those of 52 north sos and hkpm with single nodes in this way multiple kpi observations in xi an city are monitored from eight aspects to achieve stereoscopic and omnidirectional city perception which can guarantee efficient urban sustainable development especially in sustainable cities application such as in covid 19 fire flood explosion and other typical public safety events hkpm can still supply the metadata encoding support for effective extensibility aiming to support the all round kpis encoding capability for government users however hkpm is not omnipotent in every city or application so hkpm should be more general covering eight aspects in sustainable cities and deeply bound to lintong district hkpm is not conducive to expansion to other cities such as shenzhen hong kong singapore after extension and adjustment hkpm can support the kpis displaying and visualization for sustainable cities monitoring this situation cannot be avoided because the specific situation of different cities is quite different however we can try more efforts to reduce the workload of adjustment in the future there will be some things to be studied first it is necessary to consider a closer relationship with sdg to increase the comprehensiveness of hkpm and strengthen the role of sdg in kpi coding however it is also necessary to consider the needs of diverse urban development characteristics in hkpm improvement second the adaptive kpi prototype could be further expanded to support the urban operation display and emergency rescue such as in material distribution and personnel rescue third kpi event service capability fan et al 2013 liu et al 2013 du et al 2019 could be studied to achieve disaster warnings and predictions via kpi analysis and mining technology such as artificial intelligence to guarantee the safety of the city during emergencies to construct a sustainable city fourth a smart city is a city that leverages the ict infrastructure in an adaptable reliable scalable accessible secure safe and resilient manner itu 2020 besides smart city digital city internet of things cloud computing li et al 2014a so we will deserve to apply the more advanced technology such as augmented reality virtual reality internet of things and artificial intelligence upgrading to a smart city declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was in part by supported by the national key research and development program of china 2019yfb2103104 national science foundation of china u1934215 41974006 the department of education of guangdong province 2018ktscx196 the shenzhen scientific research and development funding program kqjscx20180328093453763 jcyj20180305125101282 and grants from the china postdoctoral science foundation funded project 2018m632921 2019m663071 
25896,assessing the effects of land disturbance on sediment yield requires quantification of erosion and sediment connectivity off road vehicle orv tracks represent sources of sediment pollution to coral reefs and coastal wetlands in a dry tropical setting of southwestern puerto rico this study assesses their contribution through a combined empirical and modeling approach rainfall simulation experiments and sediment accumulation in detention ponds indicate that orv track erosion rates are 31 83 mg ha 1 yr 1 and these are one to two orders of magnitude greater than background erosion rates a new sediment connectivity model predicted a watershed scale sediment yield of 2 7 mg ha 1 yr 1 from a 11 9 km km 2 of orv track network and this exceeds those from comparable watersheds in the caribbean the spatially explicit nature of the model outputs allows for site specific quantification of sediment contributions and for an evaluation of the effectiveness of mitigation methods such as detention ponds keywords connectivity off road vehicles erosion coral sediment yield tropics 1 introduction human induced land disturbance typically results in accelerated surface erosion garcía ruiz 2010 sidle 2010 labrière et al 2015 which may lead to increased sediment delivery to freshwater bilotta and brazier 2008 and marine ecosystems bartley et al 2014 in tropical settings accelerated sediment delivery to marine ecosystems can smother corals reduce light availability and increase the potential for bleaching and disease incidence rogers 1990 fabricius 2005 erftemeijer et al 2012 coastal wetlands can also be affected if incoming sediment alters substrate character or shifts the balance between sea level rise and accretion mckee 2011 understandably the effects of agricultural practices on erosion have been thoroughly studied as this represents an issue of worldwide concern garcía ruiz et al 2015 zhuang et al 2015 however unsurfaced roads have proven capable of dominating sediment budgets of agriculturally active areas and even exceeding contributions from cropland ziegler et al 2004 labrière et al 2015 in comparison to agricultural settings relatively few studies have relied on quantitative approaches to evaluate the effects of outdoor recreational activities on runoff generation and erosion for exceptions see bodoque et al 2005 ramos scharrón et al 2014 salesa and cerdà 2020 although much is known about unpaved road erosion and connectivity fundamental differences in how roads are built maintained and used compared to orv tracks could translate into different runoff sediment production and connectivity capacities the adverse physical effects of orvs on runoff and erosion have been documented on both arid e g griggs and walsh 1981 assaeed et al 2019 and wet forest covered landscapes e g ouren et al 2007 meadows et al 2008 melton 2008 documented direct effects of orv use on soils include a 1 1 2 7 times increase in dry bulk densities a 32 97 reduction in infiltration capacities and a 2 103 increase in erosion rates relative to undisturbed soils the high erosion rates of orv tracks are largely due to the effects of unregulated vehicular traffic on extremely steep hillslopes which seldom have protective cover or a runoff management design meadows et al 2008 while on site effects of orv tracks have been documented no quantitative studies have assessed their impacts on sediment yields and connectivity the effects of accelerated erosion due to land use change cannot be simply upscaled to watershed sediment output this is in part due to the spatio temporal variability of factors controlling sediment transport and storage walling 1999 church 2017 historically attempts to translate changes in erosion to sediment yields mostly relied on watershed size dependent sediment delivery ratios sdr boyce 1975 aksoy and kavvas 2005 in small dry tropical watersheds of the insular caribbean size dependent sdrs have been used to evaluate the effects of unpaved roads on sediment yields e g bégin et al 2014 these approaches have two major weaknesses first they assume a constant sdr regardless of rainstorm magnitude second they assume that all locations within the sdr contributing area will have equal opportunity to contribute to sediment yields regardless of their characteristics and position walling 1983 parsons et al 2006 parsons 2011 sediment routing approaches were first developed in the late 1970s as an alternative to sdr dependent modeling swanson et al 1982 and their fundamental aspects are now reflected in the concept of sediment connectivity fryirs 2012 bracken et al 2015 logistical constrains have prevented measuring sediment connectivity directly and this has thwarted the development of proven approaches turnbull et al 2018 as a consequence current sediment connectivity studies still rely largely on unvalidated indices heckmann et al 2018 improvements on how to quantitatively describe the degree of sediment connectivity from a source to a watershed outlet can be of benefit to land managers attempting to mitigate the impacts of land use change on sediment yields slaymaker 2003 walling and collins 2008 road networks are known to enhance the delivery of runoff and sediment to stream networks and other water bodies jones et al 2001 luce 2002 croke and hairsine 2006 in part this is because roads represent contributing source areas essential for runoff generation a la ambroise 2004 particularly for low order streams during small to moderately sized storms ziegler and giambelluca 1997 ramos scharrón and lafevor 2016 the timing and extent of road runoff and sediment connectivity depend on several factors these include the size of the road surface area that contributes to road drainage the flow distance from drainages to streams or coastlines and the infiltration and sediment storage capacities of the intervening flow pathway ketcheson and megahan 1996 lamarche and lettenmaier 1998 croke et al 1999 empirical connectivity assessments have included mapping the extent of sediment plumes or direct pathways such as rills and gullies below road drains megahan and ketcheson 1996 wemple et al 1996 sidle et al 2004 croke et al 2005 sosa pérez and macdonald 2016 2017 phillips et al 2020 results from some of these studies have been integrated into road erosion and connectivity models such as graip and warsem dubé et al 2004 black et al 2012 data required for these models relies on field based or remotely sensed descriptions of the intervening land between individual road drainages and streams e g flow distance presence absence of rills and gullies forest condition gradient etc for wepp road the level of connectivity is not only dependent on the characteristics of the intervening land but also on road segment dimensions and characteristics e g native soil graveled surface road surface pitch etc elliot and hall 1997 for these models algorithms rely on these values to assign drainage specific average sediment delivery ratios others have followed a water balance approach to establish the level of connectivity of both rilled and diffusive flow pathways i e flow paths below road drains lacking a clearly defined erosional feature e g the readi model by benda et al 2019 the principles of this approach have been incorporated into the volume to breakthrough vb concept which defines the volume of water required for runoff to reach 1 m of distance along a flow path lane et al 2006 bracken and croke 2007 in essence vb represents a measure of connectivity impedance in units of m3 m 1 that incorporates both infiltration and depression storage vb has been proven adequate in describing runoff connectivity of both direct and diffusive road runoff flow pathways ramos scharrón and lafevor 2018 in contrast with graip warsem and wepp road the model described in this article follows the vb approach at the time scale of individual storms and not on average delivery ratios readi differs from this new model in that if relies on physically based approach to model connectivity at sub storm temporal scales benda et al 2019 the model developed here has the unique feature of being able incorporate detention ponds in its connectivity analyses tools tailored to quantify erosion and sediment delivery from the specific types of land disturbances that threaten coastal ecosystems are needed larsen and webb 2009 bartley et al 2014 such need is evident in the los pozos lp area of southwestern pr where sediments produced from orv tracks are believed to threaten both coral reefs and wetland ecosystems sturm et al 2015 although orv tracks have been identified as a potential source of stress to coral reefs elsewhere e g kobryn et al 2017 no other study appears to have estimated their effects on sediment yields to coastal environments the objectives of this study were to 1 quantify runoff and sediment production from orv tracks through rainfall simulation experiments 2 quantify sediment yield rates at the road segment to the sub watershed scale by measuring sediment accumulation rates in three newly built sediment detention structures and 3 assess sediment delivery from orv tracks to coastlines and wetlands by way of a new gis runoff and sediment connectivity model called roadconnect 2 study area the lp study site encompasses a 490 ha area draining towards boquerón bay and the boquerón state forest fig 1 the lithology of the area is quite complex but 58 is underlain by bioclastic limestone rocks of the melones and parguera formations additional lithologies include a brownish red chert of the mariquita formation 6 of the area and an unnamed grayish serpentinite formation 13 volckmann 1984 associated soils include aridisols such as the altamira gravelly clay series over limestone rocks and the bermeja cobbly sandy loam series overlying cherts muñoz et al 2018 lp also contains vertisols such as the casabe clay series produced from serpentinite rocks climate is subtropical dry with an annual rainfall of 1200 mm yr 1 daly et al 2003 average monthly temperatures range from 23 to 27 c and annual potential evapotranspiration is 1860 mm yr 1 goyal 1988 about 54 of the annual rainfall occurs during the months of august and november and is strongly associated to low pressure tropical systems the landscape is covered by low standing deciduous vegetation ewel and whitmore 1973 including native trees like sweet acacia acacia farnesiana and gumbo limbo bursera simaruba and introduced species such as mesquite prosopis juliflora and jerusalem thorn parkinsonia aculeata miller and lugo 2009 all streams are ephemeral unpaved roads have been present in lp since at least the 1930s when the area appears to have been used mostly for pasture additional access roads were eventually added in a failed attempt to urbanize the land with condos r viqueira ríos pers comm roads remained open and the area eventually became a magnet for clandestine orv recreation currently there are about 58 9 km of orv tracks for a density of 11 9 km km 2 and these cover about 5 4 of the area the potential threat that the orv tracks represent to both nearshore coral reefs and wetlands led to it being targeted for remediation in 2018 sturm et al 2015 mitigation strategies consisted in regrading about 6 7 km of tracks to divert their runoff and sediment into four newly constructed sediment detention ponds in addition to these four new structures two other pre existing artificial cattle watering ponds have been identified in the area 3 methods 3 1 rainfall simulation experiments each runoff experiment relied on artificial rainfall provided through a pair of single nozzle simulators these were made of 1 9 cm diameter iron pipes set at a height of 4 57 m and connected to a water pump generating 70 kpa of pressure luk et al 1986 rainfall was directed towards a roughly an area bounded by 2 5 cm thick and 20 cm tall iron plates that were vertically pounded 5 cm into the ground after breaking the surface with a chipping hammer disturbed sediment along the plot borders was repacked by hand and tapped into place with a sledgehammer fig 2 a c plot installation is believed to have limited effect on erosion as most overland flow tended to flow along the center of the plots eight non recording rain gauges placed a few inches from plot borders were evenly spaced around the perimeter of the plot these were read manually every 5 min to quantify rainfall intensities in mm hr 1 a pair of soil samples were collected from the plot surface for texture analyses by the dry sieving method bowles 1992 plot dimensions were measured with a tape measure slopes with a clinometer plot length from top to outlet was slightly less than 5 m long and 1 m wide plot surface area averaged 4 8 m2 this plot size is a compromise among a variety of logistical factors including the area effectively wetted by the two rainfall simulators the amount of water required to apply a desired rainfall intensity for a chosen duration and the volumetric capacity of the water truck plots of this scale are expected to measure only interrill erosion by rainsplash and sheetwash boix fayos 2006 kinnell 2016 in addition to their inability to measure rilling or gullying erosion rates measured by 5 m long plots on slopes steeper than 8 are expected to slightly underrepresent erosion rates because flow velocities at this scale fail to reach equilibrium velocities chaplot and le bissonnais 2000 nevertheless plots of similar or even smaller slope lengths are widely used to measure erosion rates e g guo et al 2015 comino et al 2016 simulations lasted for 30 60 min runoff was measured manually with a pre calibrated bottle and a stopwatch every minute as the volume of water exiting through a collection trough located at the downslope end of the plot m3 min 1 runoff samples were collected every 5 min in 0 5 l bottles for suspended sediment concentration analyses following the evaporation method astm 2000 these field data were used to establish the time to runoff the rainfall runoff threshold total runoff runoff coefficient average infiltration rate during the last 10 min of each simulation and rain and area normalized erosion rate g m 2 mm 1 in total 24 simulations were run 8 in each of the three aforementioned lithologies slopes ranged from 6 to 34 and for every lithology about half of the simulations were on tracks exceeding 15 to test for the statistical significance of differences in runoff and erosion response anova post hoc tukey tests were used for variables displaying equal variance across the three lithologies based on levene s test the kruskal wallis and dunn s post hoc tested for differences when variances were proven unequal 3 2 sediment accumulation in detention ponds sediment pond construction was completed in late april 2018 a recording tipping bucket rain gauge was installed a week after the end of mitigation work 4 may 2018 topographical surveys were conducted 9 11 august 2018 and relied on a differential gnss system trimble r8 fig 2d e surveys were conducted for only three of the four new ponds because pond 3 had stagnant water during field visits the remaining three ponds were surveyed twice one survey mapped the current topography of the overall layout of the pond and the surface of the accumulated sediment current surface 282 373 points per survey since no topographical survey was conducted immediately following pond construction about 15 20 holes were dug into the accumulated sediment to identify and survey the original bottom of each pond initial surface 233 323 points per survey the original bottom was easily identifiable as it was layered with cobble sized riprap and was relatively smooth and flat point data was post processed to improve accuracy trimble rtx post processing https www trimblertx com and exported as a point shapefile to arcgis 10 7 1 where a 0 25 m resolution digital elevation model was developed through interpolation geostatistical analyst simple krigging the lip of the outlet for each of the three ponds was used as a reference elevation from where the volume of each pond was determined for both the initial and the current surfaces 3 d analyst surface volume tool the difference between these two volumes equals the volume of sediment that had accumulated since the pond was built this approach is considered as a type of detailed method to measure sediment yield from accumulated sediment ramos diez et al 2017 that for ponds and watersheds with sizes similar to those in lp is expected to provide sediment yields with a percent error of only 20 30 verstraeten and poesen 2002 a dry bulk density of 1 1 mg m 3 was used to translate the volume of trapped sediment to a mass following verstraeten and poesen 2001 3 3 roadconnect routines roadconnect is built as a set of model builder routines in arcgis 10 7 1 the model is based on the concept of sediment cascades in which runoff and sediment are passed along interlinked and topographically defined flow paths fryirs 2013 the model follows a graph theory setup in which runoff and sediment pathways originating from orv tracks are abstracted into virtual nodes i e points and links i e lines fig 3 cossart and fressard 2017 attributes required by the model are stored in three geographical databases and these are linked through a common node id attribute a point database defines the locations and identification codes for orv drains i e nodes where orv tracks collect and divert water off the track network end nodes i e watershed delivery points to coastlines or wetlands detention ponds and other nodes serving as connectors for coalescing flow paths this point database contains a series of attributes that trace the entire beginning to end flow pathway for all nodes another database corresponds to orv track lines developed by on screen digitizing using georeferenced aerial images from 2010 and 2017 fig 3a with the aid of a 1 m digital elevation model the orv track network was delineated into segments that conform with topographically defined surface flow pathways each orv track has attributes defining its length and width lithological substrate and a node id code the node id represents the drain in the nodes database where runoff and sediment are forced off individual tracks finally a line database represents flow path tracks that serve as links between nodes flow paths were established through least cost path analyses using the 1 m resolution digital elevation model to delineate steepest slope pathways from individual nodes an attribute in the flow path database defines the upslope source node and the length of each flow path see supplementary materials a for a complete description of the required geodatabase and model flow connectivity in roadconnect is defined as the total amount of runoff and sediment from a node that gets delivered to the next downslope node along a flow path the model can account for the total runoff and sediment reaching the coastline the volume that gets trapped in sediment detention ponds and the amount that reaches either the coastline or a wetland area from every single orv track drain connectivity analyses are performed on a per rainstorm basis roadconnect first addresses hydrologic connectivity prior to solving for sediment connectivity the basic approach used by the model is based on the premise that connectivity is a balance between the delivery potential of a node and the impedance offered by the flow path connecting that node to its downslope counterpart unlike the approach used for the development of connectivity indices that rely on the ratio of potential to impedance e g crema and cavalli 2018 here we rely on the difference between these as follows 1 d e l i v e r y p o t e n t i a l i m p e d a n c e where potential is simply determined by the amount of runoff generated by the orv track delivered to a given node and impedance is the volume of runoff intercepted by the combined effect of sediment detention ponds and losses by infiltration or depression storage along the flow path runoff includes that generated by any orv track segment that relies on that node as a drain in addition to any upslope contributions surface runoff in roadconnect is generated only by precipitation excess from orv track surfaces runoff and sediment are calculated for each drain as the sum of the volume of runoff q orv and the mass of sediment qs orv generated by all of the orv tracks served by that drain as 2 q o r v r t l t w r c 1 000 3 q s o r v r t l t w e r where q orv is in cubic meters r is storm total rainfall in mm tl and tw are orv track length and width in meters rc is runoff coefficient as a decimal qs orv is in megagrams and er is erosion rate in mg m 2 mm 1 runoff coefficients and erosion rates used are those resulting from the rainfall simulation analyses for each lithology impedance to downslope runoff transfer by ponds simply equals the volumetric capacity of the pond hydrologic connectivity from one node to another is based on the following formula 4 q i j q d i r q u p v p o n d f l o s s where qi j represents the volume of runoff passing from node i to node j along a flow path qdir is the volume of runoff directly delivered from orv tracks to node i qup refers to the total connected volume of runoff passed on from all nodes located upslope of node i vpond is the effective detention pond volume and floss is the potential volume of runoff that may be retained along the i j flow path all in m3 impedance to downslope transfer of runoff along flow paths is based on the volume to breakthrough vb concept croke et al 1999 the value used for roadconnect simulations in lp was 0 05 m3 m 1 which represents an empirically derived value for a dry tropical ephemeral stream setting calculated for the island of st john under conditions similar to those of lp ramos scharrón and lafevor 2018 if qdir qup do not exceed vpond no runoff is passed on to the flow path if qdir qup exceed vpond then 5 f l o s s v b f l where fl refers to flow path length in meters if qi j 0 then its value is forced to zero as this means that runoff from node i does not reach node j no connectivity sediment connectivity in roadconnect relies strongly on runoff connectivity the basic equation to quantify the amount of sediment passing from one node to the next along a flow path qs i j in mg is 6 q s i j q s d i r q s u p q s p o n d q s p a t h where qs dir and qs up are the direct and upslope sediment contributions to node i respectively qs pond is the mass of sediment retained by any pond along the flow path and qs path is the sediment retained by the flow path due to infiltration and depression storage losses the mass of sediment retained by ponds depends on the amount of sediment reaching it and the trapping efficiency te of the pond 7 q s p o n d q s d i r q s u p t e where te follows the equation initially developed by brune 1953 eventually modified by heinemann 1981 and adapted here as 8 t e 22 119 6 v p o n d q d i r q u p 0 012 1 02 v p o n d q d i r q u p the mass of sediment that gets past the pond and passed on to the next downslope flow path qs pond path is 9 q s p o n d p a t h q s d i r q s u p q s p o n d the mass of sediment retained along the flow path is directly proportional to the portion of runoff loss along the flow path and is calculated as 10 q s p a t h q s p o n d p a t h 1 q i j q d i r q u p v p o n d roadconnect calculates hydrologic and sediment connectivity for all flow paths through a series of iterations in order to properly account for all upslope contributions the model assumes that no runoff nor sediment is retained by orv tracks when upslope flow paths intersect other lower tracks in those cases all of the upslope contributions are added as upslope contributions to the drain for the receiving orv track segment fig 3b the key outputs of roadconnect are stored in a combination of geographical datasets and tables containing the following 1 an accounting of sediment reaching individual watershed outlets distinguished by whether they reach an open seawater coastline or a wetland 2 a drain by drain accounting of the sediment reaching the coastline or wetlands and 3 the amount of sediment retained by detention ponds 4 results 4 1 rainfall simulation experiments bounded plot surface areas ranged from 4 2 to 5 4 m2 plot slopes averaged 14 table 1 tracks underlain by chert were coarser 49 gravel than those on serpentinite and limestone 37 and 17 gravel respectively sand made up a substantial portion of the surfaces for all three lithological types but was particularly important for limestone 75 on average silts and clays represented only between 3 and 8 of the surface for all three lithologies applied rainfall averaged 28 1 mm for all three lithologies however rainfall intensities for plots in serpentinite were significantly lower 38 4 mm h 1 than those for plots on chert and limestone 56 7 and 53 7 mm h 1 due in part to windier conditions during some simulations on average it took 14 1 min to trigger runoff on serpentinite tracks and only 9 1 and 6 4 min for chert and limestone tracks the effects of lower rain intensities likely affected time to runoff however these differences were not statistically significant except those between serpentinite and limestone table 1 fig 4 a the rainfall threshold for runoff generation averaged 6 7 mm but the range for individual simulations was from 1 9 to 17 7 mm average infiltration rates for the last 10 min of simulation were statistically similar for all three lithologies with an overall average of 18 3 mm h 1 but the average for limestone was 63 and 71 relative to those for chert and serpentinite respectively fig 4b the average runoff coefficient for serpentinite was 28 and this was significantly different than that for limestone 54 but statistically similar to that from chert 41 fig 4c the overall average sediment concentration for all tracks was 12 150 mg l 1 even though the average sediment concentration for serpentinite was 4800 and 6300 mg l 1 lower than for chert and limestone respectively differences among mean values were not statistically significant average area and rainfall normalized erosion rates for all plots was 5 5 g m 2 mm 1 5 5 10 6 mg m 2 mm 1 even though erosion rates for serpentinite 2 77 g m 2 mm 1 was 37 and 45 of those for limestone and chert none of the differences were statistically significant table 1 fig 4d assuming 1200 mm yr 1 of rainfall annualized erosion rates for serpentinite chert and limestone tracks are 31 69 and 83 mg ha 1 yr 1 respectively 4 2 sediment accumulation in detention ponds a total of 145 8 mm of precipitation was registered from 4 may 2018 to 9 aug 2018 and was distributed over 19 individual rain storms fig 5 a the average precipitation per storm was 7 7 mm and the largest storm dropped 40 8 mm 23 jun 2018 maximum 15 min rain intensity was 32 0 mm h 1 the associated sediment accumulation in ponds 1 2 and 4 were 6 33 1 01 and 4 83 m3 respectively table 2 assuming a bulk density of 1 1 mg m 3 these volumes translate into 6 9 1 2 and 4 8 mg respectively 4 3 roadconnect results nine of the 19 rainstorms registered between 4 may 2018 and 9 aug 2018 exceeded what rainfall simulations suggest is an appropriate total rainfall threshold to initiate runoff on orv tracks 6 mm roadconnect was used to estimate runoff and sediment production for only these nine storms fig 5 among these storms the estimated per unit rainfall runoff and sediment production rate from all orv tracks in the lp area was 114 m3 mm 1 and 1 6 mg mm 1 respectively it is important to note that some runoff and sediment are predicted to be delivered to the coastline during every event that exceeds the orv runoff threshold the estimated sediment delivery for the entire three month period was 155 mg with 54 of it being delivered directly to coastlines and the remaining to wetlands about 32 of the estimated sediment delivery is predicted to have occurred during the 23 jun 18 event which generated 28 of all rainfall the estimated per unit rainfall sediment delivery rate to coastlines and wetlands is 1 1 mg mm 1 when considering rainfall from all 20 rainstorms assuming that rainfall during the monitoring period is representative of long term patterns the estimated annualized sediment yield for lp is 2 7 mg ha 1 yr 1 the overall sediment delivery ratio is 70 with values for individual storms being directly related to rainfall totals and varying from 60 to 77 net sediment accumulation estimates for the nine rain events exceeding 6 mm of rainfall in the six detention ponds equals 18 3 mg this is 12 of the sediment estimated to reach coastlines and wetlands the four new ponds built in apr 2018 for the purposes of reducing sediment delivery were estimated to trap 13 9 mg of sediment or 9 of the net estimated sediment delivery estimated pond accumulation rates ranged from 0 007 to 0 044 mg mm 1 for ponds 5 and 1 respectively absolute differences in estimated accumulation rates and those measured through surveys were 0 56 0 12 and 2 3 mg for ponds 1 2 and 4 respectively pond 4 estimates were 47 lower than measured while those estimated for ponds 1 and 2 were within 10 of observed values 5 discussion 5 1 rainfall simulation experiments the rainfall simulator used in this study applied 30 to 60 min rainfall intensities ranging from 38 to 57 mm h 1 these intensities are lower than the average intensities used in other rainfall simulation studies 100 mm h 1 dunkerley 2008 yet these are higher than the maximum 15 min rain intensity observed during the detention pond monitoring period 32 mm h 1 however expected 30 and 60 min rainfall rates with a one year recurrence interval in southwest pr are 68 and 51 mm h 1 respectively bonnin et al 2008 therefore the applied intensities represent rates that are a common occurrence in lp average infiltration rates for orv tracks ranged from 2 0 to 37 7 mm h 1 these rates are similar to those for a variety of orv tracks in forested areas of the u s foltz 2006 but faster than those on arid environments iverson 1980 table 3 orv track runoff coefficients and infiltration rates in lp are within the 30 70 and 2 36 mm h 1 range reported in the literature for unpaved roads compiled by ramos scharrón and lafevor 2016 and only slightly different than those from a study conducted on unused unpaved roads in la parguera just 15 km east of lp 12 30 7 10 mm h 1 ramos scharrón 2018 orv track erosion rates in lp varied according to lithological substrate and ranged from 31 to 83 mg ha 1 yr 1 these rates are in the low end of reported orv erosion rates 75 1500 mg ha 1 yr 1 table 3 yet most of the higher values reported are for rilling and gullying in arid settings however orv erosion rates in lp are within the range for unpaved roads in dry tropical settings in the caribbean including la parguera 10 340 mg ha 1 yr 1 ramos scharrón 2018 st john vi 45 100 mg ha 1 yr 1 ramos scharrón and macdonald 2005 and isla de culebra pr 29 55 mg ha 1 yr 1 mclaughlin 2019 this study made no attempt to quantify natural surface erosion rates but field observations from la parguera suggest an annual rate of about 1 mg ha 1 yr 1 ramos scharrón 2010 therefore orv tracks appear to increase erosion rates by one to two orders of magnitude above background and this is similar to that reported for orv tracks elsewhere and to unpaved roads in dry tropical settings of the caribbean table 3 ramos scharrón and macdonald 2007 mclaughlin 2019 5 2 sediment accumulation in ponds sediment accumulation rates in the three ponds surveyed ranged from a low of 0 008 mg mm 1 for pond 2 to 0 033 and 0 048 mg mm 1 for ponds 4 and 1 respectively infilling rate relative to initial volumetric capacities were highest for pond 1 0 10 reduction per mm of rain and 4 0 23 mm 1 at those rates pond 1 and 4 are expected to fill in with less than a normal amount of annual rainfall in fact rates in pond 4 imply that the pond could fill in almost three times over the course of a single year pond infilling rate is related to the total length of orv tracks fig 6 a the highest accumulation rates occurred at pond 1 because it intercepts sediment produced by 3 14 km of tracks in contrast pond 2 and 4 lie downstream of 0 46 and 0 85 km of orv tracks respectively at an average orv track width of 4 7 m total orv surface areas draining towards ponds 1 2 and 4 equal 1 47 0 22 and 0 40 ha respectively by assuming that the sediment that accumulated was exclusively generated by the orv tracks an estimate of road erosion rates results in values in the 3 3 8 3 g m 2 mm 1 range and this is similar to the overall average erosion rate of 5 5 g m 2 mm 1 established through rainfall simulation table 2 5 3 roadconnect results a comparison between predicted and observed sediment accumulation rates at three of the six sediment detention ponds is used here as an informal validation of the model s combined runoff erosion sediment routing and pond trapping efficiency algorithms most comparisons are encouraging as predictions for ponds 1 and 2 are within 10 of observed values fig 5f however predicted sediment accumulation at pond 4 was 53 lower than observed sediment that accumulates in pond 4 is generated by one 0 85 km long moderately steep 10 20 segment that serves as the main access road to lp traffic on this surface includes orvs but also pick up trucks hauling the orvs and sometimes even small boats additionally this section of the network was graded and pitched by heavy machinery as part of the mitigation efforts in april 2018 traffic type intensity and frequency of grading are known to potentially double unpaved road erosion rates ziegler et al 2001 ramos scharrón and macdonald 2005 given the lack of data for these effects in lp roadconnect cannot incorporate this effect into its erosion algorithms nevertheless comparisons between observed and predicted do provide evidence of the reliability of the model to generate acceptable sediment delivery results at least for the purposes of watershed management roadconnect s results provide some confidence for untested sediment delivery ratio assumptions made by previous sediment yield assessments in similar dry tropical micro watershed settings previous models built to predict sediment production and delivery for small 1 s to 10 s km2 coastal watersheds drained by ephemeral streams assumed sediment delivery ratios in the range of 50 100 for those areas lacking salt ponds or marshes that could serve as sediment sinks this assumption was used in predicting sediment delivery from watersheds in st john usvi culebra pr and the island of saint lucia ramos scharrón and macdonald 2007 ramos scharrón et al 2012a and bégin et al 2014 roadconnect estimated an overall sdr of 70 for lp and this supports the use of relatively high sediment delivery ratios for routing sediments on these small and steep coastal watersheds when other more sophisticated modeling approaches are not possible or warranted area normalized annual sediment yields for lp are 2 7 mg ha 1 yr 1 this is the highest value reported among a series of fourteen small watersheds for which yields have been estimated in the eastern caribbean 0 7 2 2 mg ha 1 yr 1 two shared characteristics of all these watersheds are that first unpaved roads or orv tracks are the most important source of sediment and second that they are in dry tropical areas with annual rainfall ranging from 990 to 1750 mm yr 1 sediment yields from these watersheds are strongly dependent on unpaved road abundance with an average 22 mg ha 1 yr 1 increase for every 1 km km 2 expansion in road or orv track density fig 6 the estimate for saint lucia does not follow the trend of all other watersheds because this is the only area where cropland erosion is also included in the sediment yield value the lp area has the highest roaded area density amongst all of these watersheds and that explains its relatively high estimated sediment yield it is important to note some of roadconnect s limitations in its runoff erosion and routing algorithms first the model only accounts for orv track runoff generated by precipitation excess under natural conditions runoff in the ephemeral streams draining the lp landscape is presumed to be generated by saturation overland flow or subsurface stormflow in st john vi runoff generation from ephemeral streams receiving no road runoff requires from 10 to 80 mm of total rainfall depending on antecedent conditions and this only occurs 4 times per year ramos scharrón and lafevor 2018 once runoff is generated by these processes orv track runoff is expected to be a relatively minor contributor of total runoff ramos scharrón and lafevor 2016 and therefore the sediment trapping efficiency calculations by roadconnect in detention ponds and along flow paths are likely not applicable second the model does not account for potentially important differences in orv runoff coefficients associated to antecedent conditions or storm size third qualities of the flow paths are not considered in the calculation of runoff or sediment losses relevant qualities might include slope and roughness offered by intervening vegetation borselli et al 2008 and whether the flow paths represent direct i e rilled or gullied or diffuse i e unrilled pathways croke et al 2005 fourth is that its erosion algorithms fail to incorporate factors considered important for unpaved trafficked surfaces such as rilling and gullying traffic intensity grading frequency or slope fu et al 2010 finally the current version of the model contains no means to incorporate other sources of sediment such as cropland or streambank erosion in spite of its limitations roadconnect can still help inform management decisions first the model is able to quantify the relative contribution to sediment delivery from individual orv track drainage points and thus help prioritize mitigative actions fig 7 similarly the model is able to quantify the delivery of sediment at individual points along coastlines and wetland perimeters and thus help in ranking management needs for example almost half of the sediment delivery for the 40 8 mm rain event on 23 jun 2018 is estimated to occur through only five of the 55 delivery outlets found along the coastline and the wetland area of lp i e sediment delivery points highlighted in red and orange in fig 7b therefore addressing erosion and sediment connectivity of orv tracks connected to those particular outlets are likely to result in a greater reduction in sediment yields than if management actions are applied randomly across the area alternatively if the distance from a sediment outlet to a coastal resource is deemed as an important factor controlling sediment stress levels e g otaño cruz et al 2017 the model can help rank all sources linked to those outlets in terms of sediment contribution and provide targeted recommendations roadconnect can also help evaluate the effectiveness of existing or proposed sediment detention ponds guide pond dimension design and placement and help plan for pond maintenance schedules 6 conclusions controlling terrestrial sediment delivery to coastal environments has been a priority for marine habitat conservation for decades however science based tools that can adequately guide management decisions must be appropriate for the particular types of land disturbances and physical settings that typify those watersheds flowing into sensitive habitats this study addresses such a need in a dry tropical area in southwest puerto rico where erosion from a dense network of clandestine off road vehicle orv tracks are perceived to represent a threat to nearshore coral reefs and wetlands the study relied on an approach that combined empirical measurements from the plot to the sub catchment scale with a new runoff and connectivity model to evaluate the effects of the orv tracks on sediment delivery empirical evidence from the los pozos study area suggests that land disturbance in the form of orv tracks represents a one to almost two orders of magnitude increase in erosion rates relative to undisturbed hillslopes further field data confirmed that the combination of runoff erosion and sediment connectivity algorithms used by the new model generate acceptable sediment yield estimates estimated sediment yields for the area are the highest reported for several dry tropical coastal watersheds in the caribbean where unpaved roads are known to dominate sediment budgets the high degree of watershed connectivity accelerated erosion rates and orv track densities explain why this area displays such high sediment yields the model developed by this study can guide watershed management decisions associated to footpath unpaved road and orv trail runoff and surface erosion in other similar areas for which the required runoff erosion and connectivity algorithms are available specifically the model is useful for identifying portions of the orv track network that contribute large quantities of sediments to coastal environments and for predicting the suitability of mitigative strategies e g detention ponds more generally this study highlighted how multi scale and combined empirical modeling approaches may inform understanding of the complex connectivity between terrestrial sediment sources and imperiled aquatic habitats declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the field and lab components of this research were funded by national fish and wildlife foundation s coral reef conservation fund program 2016 nfwf project id 0302 16 053108 my sincere gratitude goes to josé méndez upr yasiel figueroa upr víctor snyder upr and miguel vázquez upr and to protectores de cuencas inc and its field crew rubén rodríguez and ángel santos for providing the logistical support required for rain simulations and laboratory analyses sincere thanks to matt lafevor u alabama and several anonymous reviewers for reviewing earlier versions of this manuscript appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104957 
25896,assessing the effects of land disturbance on sediment yield requires quantification of erosion and sediment connectivity off road vehicle orv tracks represent sources of sediment pollution to coral reefs and coastal wetlands in a dry tropical setting of southwestern puerto rico this study assesses their contribution through a combined empirical and modeling approach rainfall simulation experiments and sediment accumulation in detention ponds indicate that orv track erosion rates are 31 83 mg ha 1 yr 1 and these are one to two orders of magnitude greater than background erosion rates a new sediment connectivity model predicted a watershed scale sediment yield of 2 7 mg ha 1 yr 1 from a 11 9 km km 2 of orv track network and this exceeds those from comparable watersheds in the caribbean the spatially explicit nature of the model outputs allows for site specific quantification of sediment contributions and for an evaluation of the effectiveness of mitigation methods such as detention ponds keywords connectivity off road vehicles erosion coral sediment yield tropics 1 introduction human induced land disturbance typically results in accelerated surface erosion garcía ruiz 2010 sidle 2010 labrière et al 2015 which may lead to increased sediment delivery to freshwater bilotta and brazier 2008 and marine ecosystems bartley et al 2014 in tropical settings accelerated sediment delivery to marine ecosystems can smother corals reduce light availability and increase the potential for bleaching and disease incidence rogers 1990 fabricius 2005 erftemeijer et al 2012 coastal wetlands can also be affected if incoming sediment alters substrate character or shifts the balance between sea level rise and accretion mckee 2011 understandably the effects of agricultural practices on erosion have been thoroughly studied as this represents an issue of worldwide concern garcía ruiz et al 2015 zhuang et al 2015 however unsurfaced roads have proven capable of dominating sediment budgets of agriculturally active areas and even exceeding contributions from cropland ziegler et al 2004 labrière et al 2015 in comparison to agricultural settings relatively few studies have relied on quantitative approaches to evaluate the effects of outdoor recreational activities on runoff generation and erosion for exceptions see bodoque et al 2005 ramos scharrón et al 2014 salesa and cerdà 2020 although much is known about unpaved road erosion and connectivity fundamental differences in how roads are built maintained and used compared to orv tracks could translate into different runoff sediment production and connectivity capacities the adverse physical effects of orvs on runoff and erosion have been documented on both arid e g griggs and walsh 1981 assaeed et al 2019 and wet forest covered landscapes e g ouren et al 2007 meadows et al 2008 melton 2008 documented direct effects of orv use on soils include a 1 1 2 7 times increase in dry bulk densities a 32 97 reduction in infiltration capacities and a 2 103 increase in erosion rates relative to undisturbed soils the high erosion rates of orv tracks are largely due to the effects of unregulated vehicular traffic on extremely steep hillslopes which seldom have protective cover or a runoff management design meadows et al 2008 while on site effects of orv tracks have been documented no quantitative studies have assessed their impacts on sediment yields and connectivity the effects of accelerated erosion due to land use change cannot be simply upscaled to watershed sediment output this is in part due to the spatio temporal variability of factors controlling sediment transport and storage walling 1999 church 2017 historically attempts to translate changes in erosion to sediment yields mostly relied on watershed size dependent sediment delivery ratios sdr boyce 1975 aksoy and kavvas 2005 in small dry tropical watersheds of the insular caribbean size dependent sdrs have been used to evaluate the effects of unpaved roads on sediment yields e g bégin et al 2014 these approaches have two major weaknesses first they assume a constant sdr regardless of rainstorm magnitude second they assume that all locations within the sdr contributing area will have equal opportunity to contribute to sediment yields regardless of their characteristics and position walling 1983 parsons et al 2006 parsons 2011 sediment routing approaches were first developed in the late 1970s as an alternative to sdr dependent modeling swanson et al 1982 and their fundamental aspects are now reflected in the concept of sediment connectivity fryirs 2012 bracken et al 2015 logistical constrains have prevented measuring sediment connectivity directly and this has thwarted the development of proven approaches turnbull et al 2018 as a consequence current sediment connectivity studies still rely largely on unvalidated indices heckmann et al 2018 improvements on how to quantitatively describe the degree of sediment connectivity from a source to a watershed outlet can be of benefit to land managers attempting to mitigate the impacts of land use change on sediment yields slaymaker 2003 walling and collins 2008 road networks are known to enhance the delivery of runoff and sediment to stream networks and other water bodies jones et al 2001 luce 2002 croke and hairsine 2006 in part this is because roads represent contributing source areas essential for runoff generation a la ambroise 2004 particularly for low order streams during small to moderately sized storms ziegler and giambelluca 1997 ramos scharrón and lafevor 2016 the timing and extent of road runoff and sediment connectivity depend on several factors these include the size of the road surface area that contributes to road drainage the flow distance from drainages to streams or coastlines and the infiltration and sediment storage capacities of the intervening flow pathway ketcheson and megahan 1996 lamarche and lettenmaier 1998 croke et al 1999 empirical connectivity assessments have included mapping the extent of sediment plumes or direct pathways such as rills and gullies below road drains megahan and ketcheson 1996 wemple et al 1996 sidle et al 2004 croke et al 2005 sosa pérez and macdonald 2016 2017 phillips et al 2020 results from some of these studies have been integrated into road erosion and connectivity models such as graip and warsem dubé et al 2004 black et al 2012 data required for these models relies on field based or remotely sensed descriptions of the intervening land between individual road drainages and streams e g flow distance presence absence of rills and gullies forest condition gradient etc for wepp road the level of connectivity is not only dependent on the characteristics of the intervening land but also on road segment dimensions and characteristics e g native soil graveled surface road surface pitch etc elliot and hall 1997 for these models algorithms rely on these values to assign drainage specific average sediment delivery ratios others have followed a water balance approach to establish the level of connectivity of both rilled and diffusive flow pathways i e flow paths below road drains lacking a clearly defined erosional feature e g the readi model by benda et al 2019 the principles of this approach have been incorporated into the volume to breakthrough vb concept which defines the volume of water required for runoff to reach 1 m of distance along a flow path lane et al 2006 bracken and croke 2007 in essence vb represents a measure of connectivity impedance in units of m3 m 1 that incorporates both infiltration and depression storage vb has been proven adequate in describing runoff connectivity of both direct and diffusive road runoff flow pathways ramos scharrón and lafevor 2018 in contrast with graip warsem and wepp road the model described in this article follows the vb approach at the time scale of individual storms and not on average delivery ratios readi differs from this new model in that if relies on physically based approach to model connectivity at sub storm temporal scales benda et al 2019 the model developed here has the unique feature of being able incorporate detention ponds in its connectivity analyses tools tailored to quantify erosion and sediment delivery from the specific types of land disturbances that threaten coastal ecosystems are needed larsen and webb 2009 bartley et al 2014 such need is evident in the los pozos lp area of southwestern pr where sediments produced from orv tracks are believed to threaten both coral reefs and wetland ecosystems sturm et al 2015 although orv tracks have been identified as a potential source of stress to coral reefs elsewhere e g kobryn et al 2017 no other study appears to have estimated their effects on sediment yields to coastal environments the objectives of this study were to 1 quantify runoff and sediment production from orv tracks through rainfall simulation experiments 2 quantify sediment yield rates at the road segment to the sub watershed scale by measuring sediment accumulation rates in three newly built sediment detention structures and 3 assess sediment delivery from orv tracks to coastlines and wetlands by way of a new gis runoff and sediment connectivity model called roadconnect 2 study area the lp study site encompasses a 490 ha area draining towards boquerón bay and the boquerón state forest fig 1 the lithology of the area is quite complex but 58 is underlain by bioclastic limestone rocks of the melones and parguera formations additional lithologies include a brownish red chert of the mariquita formation 6 of the area and an unnamed grayish serpentinite formation 13 volckmann 1984 associated soils include aridisols such as the altamira gravelly clay series over limestone rocks and the bermeja cobbly sandy loam series overlying cherts muñoz et al 2018 lp also contains vertisols such as the casabe clay series produced from serpentinite rocks climate is subtropical dry with an annual rainfall of 1200 mm yr 1 daly et al 2003 average monthly temperatures range from 23 to 27 c and annual potential evapotranspiration is 1860 mm yr 1 goyal 1988 about 54 of the annual rainfall occurs during the months of august and november and is strongly associated to low pressure tropical systems the landscape is covered by low standing deciduous vegetation ewel and whitmore 1973 including native trees like sweet acacia acacia farnesiana and gumbo limbo bursera simaruba and introduced species such as mesquite prosopis juliflora and jerusalem thorn parkinsonia aculeata miller and lugo 2009 all streams are ephemeral unpaved roads have been present in lp since at least the 1930s when the area appears to have been used mostly for pasture additional access roads were eventually added in a failed attempt to urbanize the land with condos r viqueira ríos pers comm roads remained open and the area eventually became a magnet for clandestine orv recreation currently there are about 58 9 km of orv tracks for a density of 11 9 km km 2 and these cover about 5 4 of the area the potential threat that the orv tracks represent to both nearshore coral reefs and wetlands led to it being targeted for remediation in 2018 sturm et al 2015 mitigation strategies consisted in regrading about 6 7 km of tracks to divert their runoff and sediment into four newly constructed sediment detention ponds in addition to these four new structures two other pre existing artificial cattle watering ponds have been identified in the area 3 methods 3 1 rainfall simulation experiments each runoff experiment relied on artificial rainfall provided through a pair of single nozzle simulators these were made of 1 9 cm diameter iron pipes set at a height of 4 57 m and connected to a water pump generating 70 kpa of pressure luk et al 1986 rainfall was directed towards a roughly an area bounded by 2 5 cm thick and 20 cm tall iron plates that were vertically pounded 5 cm into the ground after breaking the surface with a chipping hammer disturbed sediment along the plot borders was repacked by hand and tapped into place with a sledgehammer fig 2 a c plot installation is believed to have limited effect on erosion as most overland flow tended to flow along the center of the plots eight non recording rain gauges placed a few inches from plot borders were evenly spaced around the perimeter of the plot these were read manually every 5 min to quantify rainfall intensities in mm hr 1 a pair of soil samples were collected from the plot surface for texture analyses by the dry sieving method bowles 1992 plot dimensions were measured with a tape measure slopes with a clinometer plot length from top to outlet was slightly less than 5 m long and 1 m wide plot surface area averaged 4 8 m2 this plot size is a compromise among a variety of logistical factors including the area effectively wetted by the two rainfall simulators the amount of water required to apply a desired rainfall intensity for a chosen duration and the volumetric capacity of the water truck plots of this scale are expected to measure only interrill erosion by rainsplash and sheetwash boix fayos 2006 kinnell 2016 in addition to their inability to measure rilling or gullying erosion rates measured by 5 m long plots on slopes steeper than 8 are expected to slightly underrepresent erosion rates because flow velocities at this scale fail to reach equilibrium velocities chaplot and le bissonnais 2000 nevertheless plots of similar or even smaller slope lengths are widely used to measure erosion rates e g guo et al 2015 comino et al 2016 simulations lasted for 30 60 min runoff was measured manually with a pre calibrated bottle and a stopwatch every minute as the volume of water exiting through a collection trough located at the downslope end of the plot m3 min 1 runoff samples were collected every 5 min in 0 5 l bottles for suspended sediment concentration analyses following the evaporation method astm 2000 these field data were used to establish the time to runoff the rainfall runoff threshold total runoff runoff coefficient average infiltration rate during the last 10 min of each simulation and rain and area normalized erosion rate g m 2 mm 1 in total 24 simulations were run 8 in each of the three aforementioned lithologies slopes ranged from 6 to 34 and for every lithology about half of the simulations were on tracks exceeding 15 to test for the statistical significance of differences in runoff and erosion response anova post hoc tukey tests were used for variables displaying equal variance across the three lithologies based on levene s test the kruskal wallis and dunn s post hoc tested for differences when variances were proven unequal 3 2 sediment accumulation in detention ponds sediment pond construction was completed in late april 2018 a recording tipping bucket rain gauge was installed a week after the end of mitigation work 4 may 2018 topographical surveys were conducted 9 11 august 2018 and relied on a differential gnss system trimble r8 fig 2d e surveys were conducted for only three of the four new ponds because pond 3 had stagnant water during field visits the remaining three ponds were surveyed twice one survey mapped the current topography of the overall layout of the pond and the surface of the accumulated sediment current surface 282 373 points per survey since no topographical survey was conducted immediately following pond construction about 15 20 holes were dug into the accumulated sediment to identify and survey the original bottom of each pond initial surface 233 323 points per survey the original bottom was easily identifiable as it was layered with cobble sized riprap and was relatively smooth and flat point data was post processed to improve accuracy trimble rtx post processing https www trimblertx com and exported as a point shapefile to arcgis 10 7 1 where a 0 25 m resolution digital elevation model was developed through interpolation geostatistical analyst simple krigging the lip of the outlet for each of the three ponds was used as a reference elevation from where the volume of each pond was determined for both the initial and the current surfaces 3 d analyst surface volume tool the difference between these two volumes equals the volume of sediment that had accumulated since the pond was built this approach is considered as a type of detailed method to measure sediment yield from accumulated sediment ramos diez et al 2017 that for ponds and watersheds with sizes similar to those in lp is expected to provide sediment yields with a percent error of only 20 30 verstraeten and poesen 2002 a dry bulk density of 1 1 mg m 3 was used to translate the volume of trapped sediment to a mass following verstraeten and poesen 2001 3 3 roadconnect routines roadconnect is built as a set of model builder routines in arcgis 10 7 1 the model is based on the concept of sediment cascades in which runoff and sediment are passed along interlinked and topographically defined flow paths fryirs 2013 the model follows a graph theory setup in which runoff and sediment pathways originating from orv tracks are abstracted into virtual nodes i e points and links i e lines fig 3 cossart and fressard 2017 attributes required by the model are stored in three geographical databases and these are linked through a common node id attribute a point database defines the locations and identification codes for orv drains i e nodes where orv tracks collect and divert water off the track network end nodes i e watershed delivery points to coastlines or wetlands detention ponds and other nodes serving as connectors for coalescing flow paths this point database contains a series of attributes that trace the entire beginning to end flow pathway for all nodes another database corresponds to orv track lines developed by on screen digitizing using georeferenced aerial images from 2010 and 2017 fig 3a with the aid of a 1 m digital elevation model the orv track network was delineated into segments that conform with topographically defined surface flow pathways each orv track has attributes defining its length and width lithological substrate and a node id code the node id represents the drain in the nodes database where runoff and sediment are forced off individual tracks finally a line database represents flow path tracks that serve as links between nodes flow paths were established through least cost path analyses using the 1 m resolution digital elevation model to delineate steepest slope pathways from individual nodes an attribute in the flow path database defines the upslope source node and the length of each flow path see supplementary materials a for a complete description of the required geodatabase and model flow connectivity in roadconnect is defined as the total amount of runoff and sediment from a node that gets delivered to the next downslope node along a flow path the model can account for the total runoff and sediment reaching the coastline the volume that gets trapped in sediment detention ponds and the amount that reaches either the coastline or a wetland area from every single orv track drain connectivity analyses are performed on a per rainstorm basis roadconnect first addresses hydrologic connectivity prior to solving for sediment connectivity the basic approach used by the model is based on the premise that connectivity is a balance between the delivery potential of a node and the impedance offered by the flow path connecting that node to its downslope counterpart unlike the approach used for the development of connectivity indices that rely on the ratio of potential to impedance e g crema and cavalli 2018 here we rely on the difference between these as follows 1 d e l i v e r y p o t e n t i a l i m p e d a n c e where potential is simply determined by the amount of runoff generated by the orv track delivered to a given node and impedance is the volume of runoff intercepted by the combined effect of sediment detention ponds and losses by infiltration or depression storage along the flow path runoff includes that generated by any orv track segment that relies on that node as a drain in addition to any upslope contributions surface runoff in roadconnect is generated only by precipitation excess from orv track surfaces runoff and sediment are calculated for each drain as the sum of the volume of runoff q orv and the mass of sediment qs orv generated by all of the orv tracks served by that drain as 2 q o r v r t l t w r c 1 000 3 q s o r v r t l t w e r where q orv is in cubic meters r is storm total rainfall in mm tl and tw are orv track length and width in meters rc is runoff coefficient as a decimal qs orv is in megagrams and er is erosion rate in mg m 2 mm 1 runoff coefficients and erosion rates used are those resulting from the rainfall simulation analyses for each lithology impedance to downslope runoff transfer by ponds simply equals the volumetric capacity of the pond hydrologic connectivity from one node to another is based on the following formula 4 q i j q d i r q u p v p o n d f l o s s where qi j represents the volume of runoff passing from node i to node j along a flow path qdir is the volume of runoff directly delivered from orv tracks to node i qup refers to the total connected volume of runoff passed on from all nodes located upslope of node i vpond is the effective detention pond volume and floss is the potential volume of runoff that may be retained along the i j flow path all in m3 impedance to downslope transfer of runoff along flow paths is based on the volume to breakthrough vb concept croke et al 1999 the value used for roadconnect simulations in lp was 0 05 m3 m 1 which represents an empirically derived value for a dry tropical ephemeral stream setting calculated for the island of st john under conditions similar to those of lp ramos scharrón and lafevor 2018 if qdir qup do not exceed vpond no runoff is passed on to the flow path if qdir qup exceed vpond then 5 f l o s s v b f l where fl refers to flow path length in meters if qi j 0 then its value is forced to zero as this means that runoff from node i does not reach node j no connectivity sediment connectivity in roadconnect relies strongly on runoff connectivity the basic equation to quantify the amount of sediment passing from one node to the next along a flow path qs i j in mg is 6 q s i j q s d i r q s u p q s p o n d q s p a t h where qs dir and qs up are the direct and upslope sediment contributions to node i respectively qs pond is the mass of sediment retained by any pond along the flow path and qs path is the sediment retained by the flow path due to infiltration and depression storage losses the mass of sediment retained by ponds depends on the amount of sediment reaching it and the trapping efficiency te of the pond 7 q s p o n d q s d i r q s u p t e where te follows the equation initially developed by brune 1953 eventually modified by heinemann 1981 and adapted here as 8 t e 22 119 6 v p o n d q d i r q u p 0 012 1 02 v p o n d q d i r q u p the mass of sediment that gets past the pond and passed on to the next downslope flow path qs pond path is 9 q s p o n d p a t h q s d i r q s u p q s p o n d the mass of sediment retained along the flow path is directly proportional to the portion of runoff loss along the flow path and is calculated as 10 q s p a t h q s p o n d p a t h 1 q i j q d i r q u p v p o n d roadconnect calculates hydrologic and sediment connectivity for all flow paths through a series of iterations in order to properly account for all upslope contributions the model assumes that no runoff nor sediment is retained by orv tracks when upslope flow paths intersect other lower tracks in those cases all of the upslope contributions are added as upslope contributions to the drain for the receiving orv track segment fig 3b the key outputs of roadconnect are stored in a combination of geographical datasets and tables containing the following 1 an accounting of sediment reaching individual watershed outlets distinguished by whether they reach an open seawater coastline or a wetland 2 a drain by drain accounting of the sediment reaching the coastline or wetlands and 3 the amount of sediment retained by detention ponds 4 results 4 1 rainfall simulation experiments bounded plot surface areas ranged from 4 2 to 5 4 m2 plot slopes averaged 14 table 1 tracks underlain by chert were coarser 49 gravel than those on serpentinite and limestone 37 and 17 gravel respectively sand made up a substantial portion of the surfaces for all three lithological types but was particularly important for limestone 75 on average silts and clays represented only between 3 and 8 of the surface for all three lithologies applied rainfall averaged 28 1 mm for all three lithologies however rainfall intensities for plots in serpentinite were significantly lower 38 4 mm h 1 than those for plots on chert and limestone 56 7 and 53 7 mm h 1 due in part to windier conditions during some simulations on average it took 14 1 min to trigger runoff on serpentinite tracks and only 9 1 and 6 4 min for chert and limestone tracks the effects of lower rain intensities likely affected time to runoff however these differences were not statistically significant except those between serpentinite and limestone table 1 fig 4 a the rainfall threshold for runoff generation averaged 6 7 mm but the range for individual simulations was from 1 9 to 17 7 mm average infiltration rates for the last 10 min of simulation were statistically similar for all three lithologies with an overall average of 18 3 mm h 1 but the average for limestone was 63 and 71 relative to those for chert and serpentinite respectively fig 4b the average runoff coefficient for serpentinite was 28 and this was significantly different than that for limestone 54 but statistically similar to that from chert 41 fig 4c the overall average sediment concentration for all tracks was 12 150 mg l 1 even though the average sediment concentration for serpentinite was 4800 and 6300 mg l 1 lower than for chert and limestone respectively differences among mean values were not statistically significant average area and rainfall normalized erosion rates for all plots was 5 5 g m 2 mm 1 5 5 10 6 mg m 2 mm 1 even though erosion rates for serpentinite 2 77 g m 2 mm 1 was 37 and 45 of those for limestone and chert none of the differences were statistically significant table 1 fig 4d assuming 1200 mm yr 1 of rainfall annualized erosion rates for serpentinite chert and limestone tracks are 31 69 and 83 mg ha 1 yr 1 respectively 4 2 sediment accumulation in detention ponds a total of 145 8 mm of precipitation was registered from 4 may 2018 to 9 aug 2018 and was distributed over 19 individual rain storms fig 5 a the average precipitation per storm was 7 7 mm and the largest storm dropped 40 8 mm 23 jun 2018 maximum 15 min rain intensity was 32 0 mm h 1 the associated sediment accumulation in ponds 1 2 and 4 were 6 33 1 01 and 4 83 m3 respectively table 2 assuming a bulk density of 1 1 mg m 3 these volumes translate into 6 9 1 2 and 4 8 mg respectively 4 3 roadconnect results nine of the 19 rainstorms registered between 4 may 2018 and 9 aug 2018 exceeded what rainfall simulations suggest is an appropriate total rainfall threshold to initiate runoff on orv tracks 6 mm roadconnect was used to estimate runoff and sediment production for only these nine storms fig 5 among these storms the estimated per unit rainfall runoff and sediment production rate from all orv tracks in the lp area was 114 m3 mm 1 and 1 6 mg mm 1 respectively it is important to note that some runoff and sediment are predicted to be delivered to the coastline during every event that exceeds the orv runoff threshold the estimated sediment delivery for the entire three month period was 155 mg with 54 of it being delivered directly to coastlines and the remaining to wetlands about 32 of the estimated sediment delivery is predicted to have occurred during the 23 jun 18 event which generated 28 of all rainfall the estimated per unit rainfall sediment delivery rate to coastlines and wetlands is 1 1 mg mm 1 when considering rainfall from all 20 rainstorms assuming that rainfall during the monitoring period is representative of long term patterns the estimated annualized sediment yield for lp is 2 7 mg ha 1 yr 1 the overall sediment delivery ratio is 70 with values for individual storms being directly related to rainfall totals and varying from 60 to 77 net sediment accumulation estimates for the nine rain events exceeding 6 mm of rainfall in the six detention ponds equals 18 3 mg this is 12 of the sediment estimated to reach coastlines and wetlands the four new ponds built in apr 2018 for the purposes of reducing sediment delivery were estimated to trap 13 9 mg of sediment or 9 of the net estimated sediment delivery estimated pond accumulation rates ranged from 0 007 to 0 044 mg mm 1 for ponds 5 and 1 respectively absolute differences in estimated accumulation rates and those measured through surveys were 0 56 0 12 and 2 3 mg for ponds 1 2 and 4 respectively pond 4 estimates were 47 lower than measured while those estimated for ponds 1 and 2 were within 10 of observed values 5 discussion 5 1 rainfall simulation experiments the rainfall simulator used in this study applied 30 to 60 min rainfall intensities ranging from 38 to 57 mm h 1 these intensities are lower than the average intensities used in other rainfall simulation studies 100 mm h 1 dunkerley 2008 yet these are higher than the maximum 15 min rain intensity observed during the detention pond monitoring period 32 mm h 1 however expected 30 and 60 min rainfall rates with a one year recurrence interval in southwest pr are 68 and 51 mm h 1 respectively bonnin et al 2008 therefore the applied intensities represent rates that are a common occurrence in lp average infiltration rates for orv tracks ranged from 2 0 to 37 7 mm h 1 these rates are similar to those for a variety of orv tracks in forested areas of the u s foltz 2006 but faster than those on arid environments iverson 1980 table 3 orv track runoff coefficients and infiltration rates in lp are within the 30 70 and 2 36 mm h 1 range reported in the literature for unpaved roads compiled by ramos scharrón and lafevor 2016 and only slightly different than those from a study conducted on unused unpaved roads in la parguera just 15 km east of lp 12 30 7 10 mm h 1 ramos scharrón 2018 orv track erosion rates in lp varied according to lithological substrate and ranged from 31 to 83 mg ha 1 yr 1 these rates are in the low end of reported orv erosion rates 75 1500 mg ha 1 yr 1 table 3 yet most of the higher values reported are for rilling and gullying in arid settings however orv erosion rates in lp are within the range for unpaved roads in dry tropical settings in the caribbean including la parguera 10 340 mg ha 1 yr 1 ramos scharrón 2018 st john vi 45 100 mg ha 1 yr 1 ramos scharrón and macdonald 2005 and isla de culebra pr 29 55 mg ha 1 yr 1 mclaughlin 2019 this study made no attempt to quantify natural surface erosion rates but field observations from la parguera suggest an annual rate of about 1 mg ha 1 yr 1 ramos scharrón 2010 therefore orv tracks appear to increase erosion rates by one to two orders of magnitude above background and this is similar to that reported for orv tracks elsewhere and to unpaved roads in dry tropical settings of the caribbean table 3 ramos scharrón and macdonald 2007 mclaughlin 2019 5 2 sediment accumulation in ponds sediment accumulation rates in the three ponds surveyed ranged from a low of 0 008 mg mm 1 for pond 2 to 0 033 and 0 048 mg mm 1 for ponds 4 and 1 respectively infilling rate relative to initial volumetric capacities were highest for pond 1 0 10 reduction per mm of rain and 4 0 23 mm 1 at those rates pond 1 and 4 are expected to fill in with less than a normal amount of annual rainfall in fact rates in pond 4 imply that the pond could fill in almost three times over the course of a single year pond infilling rate is related to the total length of orv tracks fig 6 a the highest accumulation rates occurred at pond 1 because it intercepts sediment produced by 3 14 km of tracks in contrast pond 2 and 4 lie downstream of 0 46 and 0 85 km of orv tracks respectively at an average orv track width of 4 7 m total orv surface areas draining towards ponds 1 2 and 4 equal 1 47 0 22 and 0 40 ha respectively by assuming that the sediment that accumulated was exclusively generated by the orv tracks an estimate of road erosion rates results in values in the 3 3 8 3 g m 2 mm 1 range and this is similar to the overall average erosion rate of 5 5 g m 2 mm 1 established through rainfall simulation table 2 5 3 roadconnect results a comparison between predicted and observed sediment accumulation rates at three of the six sediment detention ponds is used here as an informal validation of the model s combined runoff erosion sediment routing and pond trapping efficiency algorithms most comparisons are encouraging as predictions for ponds 1 and 2 are within 10 of observed values fig 5f however predicted sediment accumulation at pond 4 was 53 lower than observed sediment that accumulates in pond 4 is generated by one 0 85 km long moderately steep 10 20 segment that serves as the main access road to lp traffic on this surface includes orvs but also pick up trucks hauling the orvs and sometimes even small boats additionally this section of the network was graded and pitched by heavy machinery as part of the mitigation efforts in april 2018 traffic type intensity and frequency of grading are known to potentially double unpaved road erosion rates ziegler et al 2001 ramos scharrón and macdonald 2005 given the lack of data for these effects in lp roadconnect cannot incorporate this effect into its erosion algorithms nevertheless comparisons between observed and predicted do provide evidence of the reliability of the model to generate acceptable sediment delivery results at least for the purposes of watershed management roadconnect s results provide some confidence for untested sediment delivery ratio assumptions made by previous sediment yield assessments in similar dry tropical micro watershed settings previous models built to predict sediment production and delivery for small 1 s to 10 s km2 coastal watersheds drained by ephemeral streams assumed sediment delivery ratios in the range of 50 100 for those areas lacking salt ponds or marshes that could serve as sediment sinks this assumption was used in predicting sediment delivery from watersheds in st john usvi culebra pr and the island of saint lucia ramos scharrón and macdonald 2007 ramos scharrón et al 2012a and bégin et al 2014 roadconnect estimated an overall sdr of 70 for lp and this supports the use of relatively high sediment delivery ratios for routing sediments on these small and steep coastal watersheds when other more sophisticated modeling approaches are not possible or warranted area normalized annual sediment yields for lp are 2 7 mg ha 1 yr 1 this is the highest value reported among a series of fourteen small watersheds for which yields have been estimated in the eastern caribbean 0 7 2 2 mg ha 1 yr 1 two shared characteristics of all these watersheds are that first unpaved roads or orv tracks are the most important source of sediment and second that they are in dry tropical areas with annual rainfall ranging from 990 to 1750 mm yr 1 sediment yields from these watersheds are strongly dependent on unpaved road abundance with an average 22 mg ha 1 yr 1 increase for every 1 km km 2 expansion in road or orv track density fig 6 the estimate for saint lucia does not follow the trend of all other watersheds because this is the only area where cropland erosion is also included in the sediment yield value the lp area has the highest roaded area density amongst all of these watersheds and that explains its relatively high estimated sediment yield it is important to note some of roadconnect s limitations in its runoff erosion and routing algorithms first the model only accounts for orv track runoff generated by precipitation excess under natural conditions runoff in the ephemeral streams draining the lp landscape is presumed to be generated by saturation overland flow or subsurface stormflow in st john vi runoff generation from ephemeral streams receiving no road runoff requires from 10 to 80 mm of total rainfall depending on antecedent conditions and this only occurs 4 times per year ramos scharrón and lafevor 2018 once runoff is generated by these processes orv track runoff is expected to be a relatively minor contributor of total runoff ramos scharrón and lafevor 2016 and therefore the sediment trapping efficiency calculations by roadconnect in detention ponds and along flow paths are likely not applicable second the model does not account for potentially important differences in orv runoff coefficients associated to antecedent conditions or storm size third qualities of the flow paths are not considered in the calculation of runoff or sediment losses relevant qualities might include slope and roughness offered by intervening vegetation borselli et al 2008 and whether the flow paths represent direct i e rilled or gullied or diffuse i e unrilled pathways croke et al 2005 fourth is that its erosion algorithms fail to incorporate factors considered important for unpaved trafficked surfaces such as rilling and gullying traffic intensity grading frequency or slope fu et al 2010 finally the current version of the model contains no means to incorporate other sources of sediment such as cropland or streambank erosion in spite of its limitations roadconnect can still help inform management decisions first the model is able to quantify the relative contribution to sediment delivery from individual orv track drainage points and thus help prioritize mitigative actions fig 7 similarly the model is able to quantify the delivery of sediment at individual points along coastlines and wetland perimeters and thus help in ranking management needs for example almost half of the sediment delivery for the 40 8 mm rain event on 23 jun 2018 is estimated to occur through only five of the 55 delivery outlets found along the coastline and the wetland area of lp i e sediment delivery points highlighted in red and orange in fig 7b therefore addressing erosion and sediment connectivity of orv tracks connected to those particular outlets are likely to result in a greater reduction in sediment yields than if management actions are applied randomly across the area alternatively if the distance from a sediment outlet to a coastal resource is deemed as an important factor controlling sediment stress levels e g otaño cruz et al 2017 the model can help rank all sources linked to those outlets in terms of sediment contribution and provide targeted recommendations roadconnect can also help evaluate the effectiveness of existing or proposed sediment detention ponds guide pond dimension design and placement and help plan for pond maintenance schedules 6 conclusions controlling terrestrial sediment delivery to coastal environments has been a priority for marine habitat conservation for decades however science based tools that can adequately guide management decisions must be appropriate for the particular types of land disturbances and physical settings that typify those watersheds flowing into sensitive habitats this study addresses such a need in a dry tropical area in southwest puerto rico where erosion from a dense network of clandestine off road vehicle orv tracks are perceived to represent a threat to nearshore coral reefs and wetlands the study relied on an approach that combined empirical measurements from the plot to the sub catchment scale with a new runoff and connectivity model to evaluate the effects of the orv tracks on sediment delivery empirical evidence from the los pozos study area suggests that land disturbance in the form of orv tracks represents a one to almost two orders of magnitude increase in erosion rates relative to undisturbed hillslopes further field data confirmed that the combination of runoff erosion and sediment connectivity algorithms used by the new model generate acceptable sediment yield estimates estimated sediment yields for the area are the highest reported for several dry tropical coastal watersheds in the caribbean where unpaved roads are known to dominate sediment budgets the high degree of watershed connectivity accelerated erosion rates and orv track densities explain why this area displays such high sediment yields the model developed by this study can guide watershed management decisions associated to footpath unpaved road and orv trail runoff and surface erosion in other similar areas for which the required runoff erosion and connectivity algorithms are available specifically the model is useful for identifying portions of the orv track network that contribute large quantities of sediments to coastal environments and for predicting the suitability of mitigative strategies e g detention ponds more generally this study highlighted how multi scale and combined empirical modeling approaches may inform understanding of the complex connectivity between terrestrial sediment sources and imperiled aquatic habitats declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the field and lab components of this research were funded by national fish and wildlife foundation s coral reef conservation fund program 2016 nfwf project id 0302 16 053108 my sincere gratitude goes to josé méndez upr yasiel figueroa upr víctor snyder upr and miguel vázquez upr and to protectores de cuencas inc and its field crew rubén rodríguez and ángel santos for providing the logistical support required for rain simulations and laboratory analyses sincere thanks to matt lafevor u alabama and several anonymous reviewers for reviewing earlier versions of this manuscript appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104957 
25897,fuzzy cognitive maps were missing in the latest guidance by kelly et al 2013 which reviewed five common integrated modeling approaches through a scoping review the paper shows how fuzzy cognitive maps satisfy key criteria for suitability in integrated environmental assessment such as model purpose types of data available to build a model requirements in terms of spatial and temporal scales stakeholder involvement and treatment of uncertainty the paper consequently updates the guiding framework that can be used by modelers to select the most appropriate modeling approach by including fuzzy cognitive map techniques we argue that the method can be the starting point of any integrated environmental assessment research to map out perspectives and potential system sensitivities they constitute a great addition to the integrated assessment modeling toolbox as they can complement quantitative model approaches that are invariably constructed around a single perspective that relates to available data keywords fuzzy cognitive maps integrated environmental assessment environmental modeling 1 introduction environmental and climate change scenarios reveal an increase in natural hazards and environmental distress due to unsustainable trends driven by anthropogenic economic and development factors terzi et al 2019 the need to cope with the challenges of unsustainable development is recognized internationally as a fundamental step towards the effective implementation of adaptation and mitigation strategies environmental problems and climate change hazards are usually characterized by complex nonlinear interactions feedback loops among multiple socioeconomic and environmental stressors high uncertainty and the need to include policy and adaptation in changing final system states jakeman and letcher 2003 rotmans and dowlatabadi 1997 sperotto et al 2017 the use of modeling has been widely recognized as being critical to environmental management as it can reveal hidden patterns and can bring new insights to decision makers carnevale et al 2012 gidden et al 2018 hong et al 2012 howells et al 2011 huppmann et al 2019 meinshausen et al 2011 müller 2008 rotmans 2012 schreinemachers and berger 2011 the holistic approach of integrated assessment is usually used as a platform to deal with the abovementioned challenges and to assist policy makers with addressing complex environmental problems jakeman and letcher 2003 according to hamilton et al 2015 the integration concept refers to the combination of system components across several dimensions that reflect the real world system aspects the methodological aspects as well as the technological aspects integrated environmental assessments are analytical models that combine diverse multidisciplinary knowledge data and models into a single framework they can capture complex trends and synthesize useful insights by making cross linkages between the different socioeconomic factors and environmental phenomena rotmans and dowlatabadi 1997 and more recently by engaging decision makers and the broader public in this adaptive process jordan et al 2012 voinov and bousquet 2010 voinov et al 2016 integrated environmental assessment is usually conducted within a framework that is linked to policy to help differentiate among policy alternatives with recognition of any feedbacks and impediments allowing an assessment of the feasibility of pathways to achieving specific goals jakeman and letcher 2003 finally integrated assessment models can also characterize and handle different types of uncertainties including the less quantifiable aspects such as the lack of knowledge ambiguity and ignorance van asselt and rotmans 2002 voinov and shugart 2013 classified integrated assessment research into two categories the integral approach consists of building the model as a whole by integrating data and knowledge from different sources and interdisciplinary fields integral models are usually built by the same team with cohesive resolutions and runtime synchronization kragt et al 2011 integral models are commonly designed to deal with coarse scale general trends and they are typically implemented using the same modeling method like system dynamics duran encalada et al 2017 bayesian networks sperotto et al 2017 or agent based modeling becu et al 2016 even when they are built based on existing models the parts they are usually re implemented and integrated into the larger system the whole to yield a meaningful and useful product the second approach is the integrated approach which consists in assembling existing ecological and economic models representing various subsystems to overcome their limitations when used separately by building an integrated tool suite to provide decision support mcintosh et al 2011 rizzoli and young 1997 the models might be implemented using different paradigms and in general are loosely linked where the output from one model is fed as input to another one several modeling approaches can be used to build integrated environmental assessment applications a position paper by kelly et al 2013 discussed five different modeling techniques that have been used in the literature for integrated environmental assessment and management which are system dynamics sds bayesian networks bns knowledge based systems kbss agent based models abms and coupled component models ccms several considerations in model development were chosen by the authors to investigate the potential of each modeling approach as an integrated environmental assessment method namely i the model s purpose ii types of data available iii whether or not the model supports feedback iv capture of spatial and temporal dynamics v characterization of uncertainties vi treatment of entities and vii technical mechanism to resolve the model s output i e simulation or optimization a summary of model considerations with possible alternatives to consider is shown in fig 1 the approaches reviewed by kelly et al 2013 feature different advantages and limitations and are subsequently suitable for different modeling purposes fuzzy cognitive maps fcms were missing from the guidance framework proposed by the authors in this work we would like to demonstrate that fcms have the capacity to cope with the central challenges of integrated environmental assessment and can serve as a modeling approach in multiple types of environmental applications fcms are simple models that can depict directions of change in environmental systems they can efficiently bridge the gap between the design of causal loops in qualitative systems that lack analytical capabilities and their effective use to support environmental management decision making under uncertainty or policy development this paper is a scoping review that aims at exploring to what extent fcms are useful in integrated assessments based on our own experience and the breath of fcm research showcasing the utility of the method through environmental and ecological case studies we also aim to update the guidance framework of kelly et al 2013 to help modelers select the right method among the different approaches to integrated environmental assessment modeling in section 2 we provide brief background information about fcms in section 3 we review the potentials of fcms as a modeling approach in integrated assessment applications with respect to the main modeling criteria in this context we discuss how some fcm extensions with environmental case studies deal with the method s limitations in section 4 in section 5 we use the insights gained from the previous sections to update the framework developed by kelly et al 2013 to assist the modelers in choosing the most appropriate modeling method for their integrated assessment applications we also highlight the main advantages and drawbacks of fcm modeling in comparison to the other modeling approaches we conclude by emphasizing where the fcm method finds its niche in the integrated environmental assessment toolkit in section 6 2 fcm essentials 2 1 what are fuzzy cognitive maps fcms are signed directed graphs that explicitly represent a set of variables and their causal relationships using fuzzy causal weights kosko 1986 they are semi quantitative models that can be used to represent the behavior of complex systems on a macro level fcms can capture the functional and causal interactions among system factors using experts and lay experts knowledge beliefs and understanding to design the causal diagram of a fcm modelers choose the relevant concepts that capture the system s dynamics and describe relationships between them by assigning a degree of influence positive negative or none that one concept can have on another fcms graph structure allows capturing system dynamics and causal reasoning in fcms permits feedback which encourages closed loop reasoning gray et al 2019 the dynamics of the inference can be used to analyze complex interactions to find the key system drivers or leverage points to act on in order to trigger changes on the system as a whole which makes them useful as a decision making support tool fcm nodes are often divided into endogenous variables that have values determined by using fcm inference and exogenous nodes that are usually used to represent causal perturbations such as management interventions or variations in the main system drivers and stressors the dynamics of fcm inference is very close to neural network mechanisms the outcome of the model is derived by multiplying the fcm s weight matrix by the state vector of perturbations kosko 1987 according to 1 1 c i k 1 s j 0 n c j k w j i where c i k 1 is the activation value of the effect concept c i at iteration k 1 c j k is the value of causal concept cj at iteration k w j i is the weight of the cause effect link between cj and ci s is a nonlinear activation function such as sigmoid that is used to transform the results in a nonlinear way bueno and salmeron 2009 a fcm example is shown by fig 2 from left to right a represents the fcm model b depicts the corresponding relationships encoded in a weight matrix and c shows the effects of four different policy options on the system drivers using fcm inference fcms have applications in a wide spectrum of scientific fields and they have also shown a good promise in modeling complex socio ecological and environmental systems jetter and kok 2014 papageorgiou and salmeron 2013 although they were designed to explore uncertainties among system variables and their effects on the system s behavior several studies highlighted the use of the method as a systems thinking approach even though they do not provide any specific mechanism to build an integrated application they are built based on experts beliefs by combining interdisciplinary knowledge that can be seen as integrated as such hence they can address a variety of environmental and ecological problems under different settings malek 2017 like the development of climate change scenarios biloslavo and dolinšek 2010 the development of bio based economy scenarios penn et al 2013 simulation of precision farming scenarios mourhir et al 2017 papageorgiou et al 2009 livelihood vulnerability analysis murungweni et al 2011 singh and nair 2014 community disaster planning henly shepard et al 2015 and drought or water management kafetzis et al 2010 van vliet et al 2010 examples of how fcms were used to investigate complex interactions in socio ecological and environmental management systems are provided in the supplementary material s1 2 2 fcm software tools from the surveyed papers mental modeler 1 1 http www mentalmodeler org developed by gray et al 2013 seems to be the most frequently adopted tool to build fcm based environmental applications douglas et al 2016 gray et al 2015b henly shepard et al 2015 htun et al 2016 singer et al 2017 mental modeler is particularly handy for non technical users experts and stakeholders it features a web based interface that provides support for collaborative modeling as well as analysis and aggregation of multiple fcm models other researchers opted for fcmapper 2 2 http www fcmappers net joomla to design their fcms christen et al 2015 lopolito et al 2015 martinez et al 2018 olazabal and pascual 2016 solana gutiérrez et al 2017 wildenberg et al 2010 fcmapper is one of the first non commercial fcm analysis tools available online designed as a ms excel worksheet it allows visualizing the fcm graph as a net file format some studies reported performing the fcm analysis using the fuzzy cognitive mapping integrated environment 1 16 software package which was designed in collaboration with the information technology company interplanetic kafetzis et al 2010 meliadou et al 2012 mouratiadou and moran 2007 however the software package is only available upon request from the developers 3 3 for further information on the software availability contact dimitris tsalkakis at dts interplanetic com for more sophisticated fcm extensions such as fuzzy grey cognitive maps fgcms which tend with their native support of uncertainty to create a much larger search space in which to run the model modelers can make use of parallel fuzzy cognitive maps 4 4 https osf io qyujt it is an open source python library used for intensive simulations capable of running multiple fcms in parallel lavin and giabbanelli 2017 lavin et al 2018 although other software such as fcm expert and isemk seem to offer the perhaps most comprehensive list of tools and apis for model development featuring learning and optimization techniques they have been released recently and did not mature enough to report on them nikas et al 2019 we recommend several recent articles for readers interested in a more comprehensive overview of existing fcm software packages felix et al 2017 giabbanelli et al 2019 papageorgiou et al 2018 the decision to select a specific software should not be taken lightly as most of the fcm features or extensions may not be simply selected from a software s toolbox considering the participatory nature of integrated assessments among the criteria that should be considered to choose the software package is the ease of use flexibility for incorporating changes into the model s structure and the ability to incorporate extra functionality elsawah et al 2017 fcms do not benefit as yet from high level modeling software platforms with a comprehensive list of features in order to provide support to the integrated environmental assessment community we believe that there is a substantial effort that should be deployed in building software packages with easy to reuse components excellent visualization features and implementation of different extensions suggested in fcm research 3 how do fcms deal with model considerations in order to meet the aims of our work a set of fcm applications in the field of environmental modeling and management were selected and examined these applications integrated a broad range of social ecological economic and management components and involved a variety of stakeholders they differ on the methodologies and development choices followed for constructing the fcms as well as on the purpose of using fcms in this section we review the potentials of fcms in integrated environmental assessment modeling with respect to the main modeling criteria used in this context a summary of the sorts of choices used in fcm integrated environmental modeling is given in table 1 and discussed in more detail within the next sections 3 1 fcms in the environmental modeling process the challenges of integrated environmental assessment must be addressed throughout the different phases of the modeling process starting with engaging the different actors followed by system conceptualization characterization of uncertainty and synthesis of the results in this section we highlight the way fcms fulfill integrated environmental assessment modeling considerations by relating the discussion to the different phases of the modeling process 3 1 1 stakeholder involvement there is a variety of stakeholders that can have a direct influence on the decision making process stakeholders can be affected citizens influencing industrial or lobbying groups experts or political decision makers from an integrated environmental perspective involving diverse multidisciplinary stakeholders is necessary from methodological political and learning standpoints unlike the conventional participatory approaches narratives questionnaires and surveys a fcm is a relatively easy to understand semi quantitative method that takes a further step in involving stakeholders by formalizing the collected knowledge in a logical framework with an emphasis on drawing mental models and beliefs gray et al 2015b in a recent review by voinov et al 2018 about tools and methods for participatory modeling fcms were described as requesting low time and cost and requiring low methodological expertise of stakeholders the somewhat ease of use and graphical structure of fcms makes it relatively accessible to non modelers and suitable in different research contexts involving different types of participants hence a fcm can be used as an elicitation tool to collect and organize knowledge and to allow individuals to share their experiences and understandings several studies have shown that mental models suitable for simulations could be extracted in the form of fcms amirkhani et al 2017 jetter and kok 2014 which offers some scalability giabbanelli 2014 and allows for stakeholder participation using platforms such as mentalmodeler gray et al 2014a in a participatory setting two strategies are commonly used to collect knowledge namely the different participants are either invited to one to one interviews where a fcm is developed for each respondent giordano and vurro 2010 papageorgiou et al 2009 samarasinghe and strickert 2013 or to group meetings and workshops where the fcm is built collectively henly shepard et al 2015 hobbs et al 2002 penn et al 2013 van vliet et al 2010 both approaches exhibit particular advantages individual models provide a more robust representation of an individual s understanding and uncover differences in mental beliefs and perceptions of involved stakeholders however building individual fcms might be time consuming and might require many resources and knowledge heterogeneity across maps might make it challenging to generate aggregated system complexities and simulate scenarios from the reviewed case studies when this approach is adopted the individual maps can be compared and analyzed separately jetter and schweinfort 2011 kafetzis et al 2010 tan and özesmi 2006 aggregated into one fcm henly shepard et al 2015 papageorgiou et al 2009 samarasinghe and strickert 2013 or aggregated into different fcms representing separate groups özesmi and özesmi 2003 solana gutiérrez et al 2017 on the other hand the process of building a group model is less time and resource consuming as it can be produced collaboratively by stakeholders at a workshop it is not uncommon when this latter approach is adopted that participants would usually get divided into separate groups with similar institutional perspectives and values lavin et al 2018 meliadou et al 2012 singer et al 2017 other case studies take a complementary approach for instance santoro et al 2019 collected individual fcms to capture stakeholders risk perceptions about flood management and group modeling to define potential shared flood protection strategies the construction of fcm maps relies heavily on expert and human input participants express their beliefs using their heuristics knowledge values or perception of risk one way to perform comparisons across stakeholder groups or individuals is by analyzing the map structure using graph theory indices gray et al 2014a certain graph metrics can provide insights into uncertainty about the structural variation across stakeholders for example the centrality network metric is an index that shows the total strength of the concept s connections it is a measure of the concept s contribution to the cognitive map the centrality metric is used in different ways in fcm studies for example lavin et al 2018 suggested that network centrality can serve as a tool to compare group models instead of comparing them through multiple scenario simulations the authors performed experiments on their 264 fcms in the context of fishery management the results of comparison suggest that if stakeholder groups agree on the central factors they also tend to agree on simulation outcomes and thus share a paradigm santoro et al 2019 argue that computing the centrality indices for the most common variables helps to understand the differences that each actor attributes to the same problem and helps highlighting out the divergences of problem frames the hierarchy metric is another index that takes a value between 0 and 1 a high value indicates that the system is top down hierarchical system whereas a low value indicates a fully democratic system stakeholders with democratic maps perceive the system as being more adaptable to changes hence they can be a starting point for achieving management objectives sandell 1996 for example tan and özesmi 2006 compared fcms from ngos government officials and villagers about wetland ecosystems in turkey they discovered that the latter group developed structurally democratic maps indicating that they acquired a higher capacity to adapt to the socio ecological changing conditions compared to the other groups of stakeholders from the reviewed papers we note that different fcm studies formally involved stakeholders in the early stages of model conceptualization and also in the late stages of scenario development uncertainty exploration simulation and assessment which demonstrates the potential of the method as a fully participative tool to perform integrated assessments 3 1 2 model conceptualization the objective of fcm model conceptualization is to identify the model s structure by designing a causal diagram that depicts the main interacting components of the studied system and their causal relationships the choice of concepts is a critical determinant in any integrated environmental assessment application certain studies focus on day to day environmental management concepts while others focus on more synthesized variables that are relevant to the policy life cycle and that can help decision makers take informed decisions some approaches combined fcms with dpsir 5 5 https www eea europa eu publications tec25 drivers pressures state impacts responses as a method to frame the selection of relevant variables during the early phases of the project in order to make cross connections between the socioeconomic drivers and the natural environment within a policy oriented context gray et al 2014b mehryar et al 2017 mourhir et al 2016 two techniques are usually used for choosing the list of concepts standardized concepts or freely associated concepts gray et al 2014a when a standardized list of concepts is used stakeholders are provided with a pre compiled list of concepts to design their individual fcms building fcms this way facilitates the combination of knowledge through the addition of models using their corresponding connection matrices however standardizing the model s concepts may compromise its reliability as the participants cognitive images might get biased by the predefined list conversely using a free association of concepts might yield richer fcms since a variety of mental perceptions and heterogeneous knowledge can also be captured nevertheless fcm design using freely associated concepts can be resource intensive as it requires extra effort to generate the group map the synthesized group map can be produced by augmenting the connection matrices of individual maps to reflect all concepts as identified by different participants averaging of connection weights is commonly used as a method to aggregate the causal relationships from the individual fcms and produce a combined model enriched with knowledge from all experts and stakeholders gray et al 2014a aggregation of fcms in a group model might also require the use of credibility weights to distinguish between different types of participants depending on expertise kosko 1988 another challenge when freely associated concepts are used is related to variations in language resulting in the use of different terms for the same construct in order to address this issue there is a need for a homogenization step in fcm modeling that consists in grouping concepts that have the same meaning and selecting a standard and consistent wording across maps olazabal et al 2018b reckien 2014 this is usually done qualitatively like by using grounded theory glaser and strauss 2017 which suggests taking a systematic approach in defining a common terminology by collecting and analyzing related data to produce a meta text that describes the subject field in terms of high level themes the meta text can then be used as a common ground for defining fcm concepts when producing a fcm the modelers must ideally find the right compromise between producing a robust model with enough cognition that interrogates the different facets of the studied phenomenon and yet keeping it simple to interpret and gain useful insights some approaches opted for systematic approaches e g özesmi and özesmi 2003 used a method based on randomized accumulation curves and tan and özesmi 2006 used a method based on monte carlo simulations in order to determine whether there is a need to include more concepts in their models singh and nair 2014 condensation of fcms is a methodological enhancement that was also used by many environmental studies to meet both objectives one approach to condensation is to construct preliminary fcms containing all identified variables and then gather similar variables and those that belong to the same upper level themes under one broader category using qualitative aggregation martinez et al 2018 özesmi and özesmi 2003 van vliet et al 2010 another approach is to aggregate variables following a quantitative methodology as is the case with samarasinghe and strickert 2013 who used self organizing maps som in order to cluster different concepts ortolani et al 2010 also applied hierarchical cluster analysis and principal components analysis pca 6 6 https www nature com articles nmeth 4346 to a set of 20 fcms representing individual farmers beliefs to identify separate groups which would consequently be represented as agents mourhir et al 2016 used a semi quantitative method to compile a set of related indicators e g dpsir pressure variables into a composite index to bring their air pollution model to a lower resolution obiedat and samarasinghe 2016 used a two stage process to reduce the system s complexity made of subjective condensation of similar variables and aggregation of fcms into a collective map using a quantitative method based on a 2 tuple fuzzy representation and stakeholders credibility weights to condense imprecise connections computationally although the advocated enhancements might help with condensing the knowledge maps effectively the condensation approach is not always straightforward and might raise methodological challenges that need to be addressed adequately for example building a composite index is similar to building a model which is likely to be affected by uncertainties such as the choice of indicators and the aggregation method one way to evaluate the complexity of a fcm model is by using graph theory indices that analyze the map structure particularly the complexity metric ratio of receiver to transmitter variables might be used as an indicator of the map s complexity for example a large value indicates a complex map with a high number of outcomes and fewer driving forces gray et al 2014a using this structural metric henly shepard et al 2015 demonstrated that one group of stakeholders developed a more complex model compared to other groups though the model had fewer connections and a lower density fcms can be built using both qualitative and quantitative data however they are particularly useful when there is a lack of data to build a model empirically different sources can be used to derive the qualitative knowledge the maps are built upon typically integrated assessment applications are conducted in a participatory approach where the modelers seek input from interdisciplinary stakeholders solana gutiérrez et al 2017 however in some cases the authors of the paper play the role of experts by providing the necessary knowledge to build the model de kok et al 2000 or extract the causal relationships using previous reports experiments and studies ramsey and norbury 2009 or combine such knowledge with their own expertise kok 2009 some case studies learn the fcm model using historical data in an attempt to improve the robustness and accuracy of fcm output especially in prediction tasks papageorgiou et al 2009 the main objective of fcm learning algorithms in the literature is to define or update the initial knowledge of experts in order to produce fcm influence weights while this approach produces relationships based on empirical data and might help the model converge to a desired state it requires the availability of a dataset to learn from few environmental studies tried a data driven approach to learn the fcm model from due to the lack of data because of the multi disciplinarily aspect of problems at stake namely ramsey et al 2012 developed fcm models to understand the impacts of deer control on forest ecosystems in new zealand by using approximate bayesian computation abc to generate the causal weights and select among alternative models using data buruzs et al 2015 also used a bacterial evolutionary algorithm bea to design a fcm model to support decision making in waste management by relying on the system factors time series in a precision agriculture application papageorgiou et al 2009 proposed the nonlinear hebbian learning nhl algorithm to train a fcm for cotton yield prediction using soil properties data driven practices do not take advantage of one of the perhaps most fundamental benefits of cognitive mapping consisting in the development of a model that encompasses different aspects of the system by acquiring knowledge from domain experts htun et al 2016 papageorgiou et al 2009 van vliet et al 2010 and involving different groups of stakeholders henly shepard et al 2015 hobbs et al 2002 murungweni et al 2011 penn et al 2013 soler et al 2012 for example argue that the expert based fcm models are likely to translate better processes occurring at broader scales compared to data based fcms given the spatial nature of data used to build the latter they also suggest that the expert based fcm can be used as complementary to a data based fcm to reduce the limitations of the latter namely scaling and literature availability issues we notice from the reviewed literature that data based fcms focus on the concepts for which measurable observations are easily collected hence excluding the less quantifiable ones like social and policy related indicators which reduces the capacity of the technique to be used in integrated assessments unless combined with other methods some authors use correlation coefficients as a starting point to quantify causal relationships for example huang et al 2013 used structural equation modeling sem 7 7 https www sciencedirect com topics neuroscience structural equation modeling to identify the correlations between the elements governing wind power based on which the strengths of causal relationships between the different concepts were encoded into a fcm model we also note here the work of soler et al 2012 who designed a land cover fcm by quantifying the causal relationships using correlation coefficients as extracted from spatial data using soil fertility maps since correlation might not always imply causation soler et al 2012 confronted the relationships with existing research and only retained the significant correlations that were confirmed by a literature review table 2 summarizes the alternative approaches used by fcm applications during the different steps of model conceptualization 3 1 3 resolving the model s output two main approaches are commonly used to resolve the model s output depending on the end user considerations models might be tailored to answer what if questions by running simulations or might be optimization based simulations can help with improving our comprehension of the system s dynamics by studying subsequent states derived from an initial stimulus and can help one develop a better understanding of interdependencies between system variables simulations can serve as a useful instrument to support decision makers in a policy exercise allowing them to perform a proactive analysis by testing how voluntary alternative scenarios could have an impact on the environmental future in a transparent manner they can help managers and decision makers with assessing the current environmental status and planning for effective responses based on strengthening preventive and mitigating measures to reduce the consequences of environmental degradation examples of how fcm simulations were used in the reviewed case studies are discussed in section 3 2 optimization based models help decision makers find an optimal solution that satisfies preset outcomes and objectives it allows performing a goal oriented analysis which is a useful exercise that can assist managers in achieving the targets of sustainable development fcms are not considerably used in goal oriented analysis of complex systems as the nonlinearities prevent backward chaining i e reversibility however some authors proposed optimization approaches by using evolutionary algorithms genetic and immune he 2008 khan et al 2004 to obtain the optimal initial stimulus state that is likely to lead to the target state that represents the initial goals or to find the cause of a sudden change of internal state kim et al 2008 the approach consists of minimizing an objective function e g euclidean distance between a target state of interest and input policy vectors picked from a randomly generated population of vectors the backward inference algorithm calls the forward inference to evaluate the vectors picked from the random population of vectors this is followed by the evaluation of the objective function to keep only the vectors that achieved good performance this process is repeated until satisfactory performance is achieved or a number of iterations is completed however the computational expense of these approaches can explode quickly and should be further explored to enhance the effectiveness of fcms in optimization problems fcms are really about concepts and modeling causal relationships between them to get an understanding of system dynamics so the whole idea of optimization will need some additional definitions and further development to be used in environmental management 3 1 4 characterization of uncertainties during the environmental modeling process the different causes of uncertainty affect the framing the structure and output of fcm models walker et al 2003 uncertainty and its effects cannot be considered in absolute terms identifying uncertainties should entirely depend on what the goals of the modeling exercise are the primary goal of environmental studies is to increase system understanding or perform exploratory analysis by involving multi and trans disciplinary stakeholders with divergent beliefs and experiences and by making use of scenarios to extrapolate beyond what is known to compute approximate projections of future situations that do not exist as yet walker et al 2003 some of these uncertainties are not necessarily considered as undesirable if applicable these uncertainties should be adequately characterized and included in the model s structure to produce alternative views and scenarios to be explored in this section we create a correspondence between the methodologies presented by refsgaard et al 2007 to characterize and handle uncertainties in environmental applications with the sources and types of uncertainties as distinguished in the uncertainty taxonomy that was developed by walker et al 2003 and updated by warmink et al 2010 the conceptual uncertainty framework helps characterizing uncertainties using a three dimensional representation based on the location level and nature of the uncertainty the location indicates the place where uncertainty is exhibited within the studied system which could be in the context the input data the model s structure or technical implementation the model s parameters or the output the level indicates the strength or severity of uncertainty within a spectrum that ranges from determinism to total ignorance we distinguish between three categories statistical uncertainty can be characterized probabilistically in scenario uncertainty outcomes might be known but we cannot attribute probabilities to them whereas with recognized ignorance the full range of possible outcomes is unknown it is also common to categorize uncertainty according to its basic nature epistemic uncertainty due to the imperfection of knowledge ambiguity that can arise from subjective judgments and language issues warmink et al 2010 and intrinsic randomness or natural variability such as deviations from standard behavioral patterns in a manner that is beyond control table 3 summarizes approaches used in fcm based integrated environmental assessment case studies to characterize and deal with uncertainty using the uncertainty matrix walker et al 2003 warmink et al 2010 the fact that political climate seeks a participatory approach most environmental assessment and management applications deal with context uncertainty i e are we considering all the relevant issues and the desired outcomes of the system and this is achieved by inviting stakeholders from different disciplines to the early scoping and framing stages of the environmental modeling process model structure uncertainty implies that there could be several acceptable representations that can reasonably represent the system several fcm based integrated assessment applications make use of multiple model simulation mms as a strategy to address uncertainty about the model s structure with mms several alternative models are created to conduct the assessment instead of using a single model murungweni et al 2011 ramsey and norbury 2009 soler et al 2012 research with experimental data could also perform model selection for example ramsey et al 2012 created four alternative models and selected the model that best describes the system using a markov chain monte carlo algorithm together with approximate bayesian computation mcmc abc by confronting the competing models with collected ground truth data mms is usually conducted within a framework that performs a comprehensive sensitivity analysis sa to investigate the model s structure uncertainty and map the variation in the system s output to variations in the system s structure htun et al 2016 this sensitivity analysis gives insights into the robustness of the outcomes of scenario analysis and shows how strongly they can be affected by changes in the weights of the relationships sa also helps with highlighting those interactions that matter the most to allow researchers to focus on more ramsey and norbury 2009 fcms inherently deal with ambiguity and vagueness and are particularly suitable for analyzing causality when the underlying knowledge domain is soft that is when the system s factors and their corresponding relationships are basically fuzzy kosko 1986 in some of the reviewed studies fuzzy logic fl is used to account for the uncertainty that results from the linguistic approximations in the fcm model s structure by representing fuzzy concepts and causal strengths using fuzzy sets mourhir et al 2016 obiedat and samarasinghe 2016 ramsey et al 2012 ramsey and norbury 2009 when fuzzy logic is used to handle ambiguity a sensitivity analysis is sometimes performed to attribute the uncertainty in fcm outcomes to the parameterization of the fuzzy sets ramsey and norbury 2009 however we note that there is less attention paid to the technical uncertainties related to the choice of the implication and inference methods giabbanelli et al 2012 another interesting approach to deal with uncertainty when the modeler does not know all causal relationships is fgcms which give the edges a range of possible values and hence offer a larger search space in which to run the model by simulating grey scenarios salmeron 2010 they have successful applications in several domains however they have not been investigated so far in integrated environmental assessment research we also note that some fcm environmental assessment models paid some attention to technical uncertainties of fcm development especially the convergence issues such as investigating the uniqueness of the equilibrium point or the effect of tuning the parameters controlling the slope of the transfer function benjamín et al 2017 for example in their fcm about the establishment of a bio based economy in the humber region penn et al 2013 compared scenario outcomes using both linear and sigmoidal transformation functions the results of the technical sensitivity analysis allowed the authors to strengthen the verification process like most other approaches reviewed by kelly et al 2013 fcms require running monte carlo simulations to cope with uncertainty about driving forces that have an influence on the system and its performance such as the relevant scenario and policy variables to build a fcm model singh and nair 2014 tan and özesmi 2006 according to soler et al 2012 the process itself of relying on qualitative data from different sources in fcm modeling is considered as a way to overcome the inaccuracies of working with quantitative data such as scale spatial inaccuracies and autocorrelation as for parameter uncertainty the only tuned fcm parameter is the relaxation parameter that was used in few case studies to accelerate convergence to equilibrium hobbs et al 2002 ramsey and norbury 2009 these case studies varied the value of the relaxation parameter and produced a set of interpretable fixed point solutions through a sa both research studies reported that 0 5 was found to be an optimal value another aspect of uncertainty is the model outcome s uncertainty which is the accumulated uncertainty caused by the uncertainties that stem from the different locations it is the difference between the ground truth observable value and the value predicted by the model if ground truth data is available a discrepancy error can be computed by running a formal validation exercise and confronting the causal chain of the model with empirically established relationships mourhir and papageorgiou 2017 consequently potential adjustments to the model s structure and tuning of weights can be performed automatically using the family of hebbian learning algorithms papageorgiou et al 2009 or by selecting weights manually among plausible ranges in the model s structure hobbs et al 2002 however empirical data is rarely available in fcm based environmental studies moreover most policy analysis models make use of simulations to extrapolate outputs for proactive scenarios that are beyond what is known in the absence of ground truths when applicable fcm output should be confronted with trends derived from stylized behavior patterns generated from robust observations schwanitz 2013 it is also very important to check the credibility of the model s outcome in consultation with its intended end users some benchmarks such as the degree of consensus and acceptability were proposed by certain fcm based environmental research for the assessment of the desirability and the level of approval of management scenarios by stakeholders giordano and vurro 2010 henly shepard et al 2015 kafetzis et al 2010 ultimately considering the systemic nature of integrated assessment applications one should be opened to insights that can be gained from fcm analysis which could be missing in existing scientific studies focusing on one dimension e g ecosystem approach that usually miss external linkages and feedbacks fcms are built using the knowledge and mental views of stakeholders if the choice of participants reflects the dynamics of the system at stake the outcome of fcm exercises should not be considered as arbitrary and should be credible giabbanelli and crutzen 2014 we notice that none of the studies conducted a comprehensive analysis of uncertainty which might lead to a false interpretation of the model s results walker et al 2003 warmink et al 2010 we believe that the typology of uncertainties in the three dimensional framework and more specifically the uncertainty matrix um should be a good starting point to identify uncertainties in fcm based integrated assessment applications in order to avoid confusion that could lead to informing the decision making process with sub optimal recommendations several techniques to assess and characterize uncertainties were reported in the literature a guidance framework to the applicability of the most commonly applied methods in the environmental modeling process can be found in refsgaard et al 2007 3 2 what types of applications are fcms used for in the field of ia models are generally built to satisfy one or more of five main model purposes i prediction ii forecasting iii management and decision making under uncertainty iv social learning and v developing system understanding or experimentation kelly et al 2013 in the absence of observed history or ground truths in integrated assessment applications mainly because we consider inter disciplinary complex problems fcms can be particularly useful with applications where there is a lack of data but expert and lay experts knowledge about the studied phenomenon is available gray et al 2014a 2015b jetter and kok 2014 özesmi and özesmi 2004 from the reviewed papers we notice that there is a typology of three modeling purposes fcm models are built for goal driven top down decision making and management developing system understanding and social learning the purpose of building models usually has an impact on the way stakeholders are involved in the modeling and simulation of fcms table 4 maps the modeling purpose with typical collection strategies and the type of involved stakeholders 3 2 1 top down decision making in top down strategies experts physicians scientists engineers are usually solicited when there is a need to include specialized knowledge about physical chemical biological or social processes and interactions in this case the method is used as an elicitation tool to collect the tacit knowledge of experts about a domain where there is limited data or components are not comprehensively linked in particular fcms are used as a measure to give structure to what would otherwise be loosely linked to demystify highly complex interactions or reduce uncertainty about a system s domain however modelers play a mediator role they collect qualitative input from stakeholders design the fcm model s and present the results to decision makers the stakeholders might not be directly involved in elaborating their cognitive models and using their outcome aggregation of fcms is usually needed in this case to generate a combined perspective of system complexities before running simulations the homogenization step is likely to throw items that are not commonly described by participants as the focus is shifted from empowering individual stakeholders with a tool to voice their opinions towards a focus on an imposed compulsory component or concept that is the central subject of the study doukas and nikas 2019 lopolito et al 2011 mourhir et al 2016 soler et al 2012 3 2 2 developing system understanding when the model s purpose is to enhance system understanding and inform the decision making process the focus is on using fcms as an analysis tool to study how the future might develop by relying on the simulation capabilities of fcms the simplicity of the method is used to allow stakeholders from different disciplines to draw their own cognitive models they are also usually involved in analyzing the produced collective knowledge obiedat and samarasinghe 2016 the results of group discussions can then be used to inform decision making in a top down manner obiedat and samarasinghe 2016 fcm models can help developing system understanding in two ways i by summarizing and integrating available knowledge this is mainly achieved by linking qualitative scenario narratives to quantitative models and ii by experimenting with the model using scenario analysis to discover how it reacts to changes in system drivers these two modes are not mutually exclusive in all case studies that aim at linking quantitative data with qualitative scenarios the conversion is performed within a framework allowing interaction between modelers and stakeholders developing narratives simultaneously and converting them to fcm models kok 2009 mallampalli et al 2016 singer et al 2017 van vliet et al 2010 the quantifications made using fcms concern mainly the relationships between the key concepts of the studied system parameterization of the variables themselves by stakeholders can follow by using other methods such as fuzzy sets or probability distributions heng jie et al 2006 hossard et al 2013 system understanding is also achieved through scenario analysis capabilities of fcms to study the derived states of fcm simulations which offer a projection of the system in the future and can reveal unintended effects of various system drivers scenario analysis can help improve stakeholder understanding of the system s current trends or help identify the gaps between possible futures and desired ones jetter 2006 the outcome of scenario analysis can then be used for further discussion compared to previous knowledge or employed as a backbone to design new policies or management options kok 2009 kontogianni et al 2012 van vliet et al 2010 from the reviewed case studies we note that scenarios can be predictive or informative saxena and vrat 1992 predictive scenarios are built to clarify how specific drivers will develop such as by studying the impacts of current socioeconomic or natural trends or providing quite comprehensive interpretations of what the future could hold by testing different hypotheses anezakis et al 2016 these studies allow stakeholders to understand the various dynamics and feedbacks that rule the system at stake informative scenarios on the other hand try to pro act on the desired outcomes by exploring possible pathways primarily through simulation of alternative management interventions or identification of barriers to their proper implementation kafetzis et al 2010 olazabal et al 2018a samarasinghe and strickert 2013 zhao et al 2014 some case studies start with a baseline scenario without considering any management action then make use of fcm simulations to discover possible restoration scenarios or to highlight worst and best scenario deviations from the baseline scenario amer et al 2011 jetter and schweinfort 2011 solana gutiérrez et al 2017 fcm simulation allows also identifying the mix of management options that are likely to optimize objectives by relying on the capacity of fcms to simulate different simultaneous perturbations which is more efficient than simulating perturbations separately and aggregating the results afterward doukas and nikas 2019 huang et al 2013 mourhir et al 2016 usually the collection of individual fcms is followed by a homogenization step and aggregation of knowledge into a collective map to analyze scenarios here all knowledge is welcome there is no focus on a single component and differences in fcm models among stakeholders are considered as a room for learning and identifying possible uncertainties stakeholders would also contribute to any validation of the aggregated model 3 2 3 promoting social learning social learning refers to a potential change that occurs in the mental models of stakeholders resulting from interactions among them in a social network in this perspective stakeholders are involved in a participatory approach the emphasis is more on the process of building the model collaboratively and sharing management and decision making or seeking acceptance of management decisions fcms are rather used as a facilitation method among diverse stakeholders and not necessarily as a formal assessment tool the focus is shifted from the simulation of policy outcomes to building trust and empowering stakeholders with a tool to challenge negotiate and influence the design of new regulations social learning happens through the capture of individual mental models allowing for agreements and inconsistencies to be discussed and potentially engaging in scenario analysis to foster adaptation to environmental changes henly shepard et al 2015 with this respect social learning usually focuses on non traditional forms of knowledge while encoding the fcm model by including stakeholder preferences as well as shared goals and values common to groups of stakeholders we can distinguish between two types of applications the first category where fcms are merely used as a communication tool to help determine how the different stakeholders are likely to react to management approaches in this case the method is usually used to capture individual or group mental models followed by a comparison of knowledge variation across groups to identify areas of compliance or non compliance to mandated policies or areas of multidisciplinary conflicts and agreements christen et al 2015 the comparison can be performed qualitatively giordano and vurro 2010 henly shepard et al 2015 kafetzis et al 2010 or based on quantitative approaches such as the non metric multidimensional scaling nmds to highlight differences between the individual models across groups vasslides and jensen 2016 the outcome of this exercise can be used to derive recommendations on how to adapt policies and ensure their effectiveness in the future for example fcms can help disentangle any potential misalignment between perceptions of the different groups by pointing out which anchoring points can be established among heterogeneous perceptions towards that end christen et al 2015 suggest using transmitter concepts forcing variables which only influence other concepts with a strong effect on a central concept as anchoring points for which policy development could be further developed in the second category fcms are used as a negotiation tool to help different groups of stakeholders develop a shared understanding of complex systems negotiate conflicting views and eventually reach consensus fcms in this case will facilitate planning help overcome the several barriers to adopting management measures and help to avoid institutional failure due to potential stakeholder opposition henly shepard et al 2015 herein the decision making process typically consists of two main phases the divergent and convergent thinking phases giordano and vurro 2010 during the divergent thinking phase the different views and alternatives are encouraged but also the shared objectives are defined during the convergent thinking phase the performance of the different alternatives is analyzed against objectives in the former phase fcms are used as an elicitation tool whereas the latter phase takes advantage of the simulation capabilities of fcms to assess the impacts of management options and compare trade offs scenario simulation is usually followed by an analysis of the acceptability and degree of consensus of management actions to rank and select the best alternative giordano et al 2007 the iterative modeling aspect is also emphasized by henly shepard et al 2015 the authors used single loop learning to encourage individual reflections double loop learning to build consensus using group discussions and triple loop learning to revise the action plan based on the newly emerging knowledge and collective system understanding nevertheless effective engagement of stakeholders especially for resolving conflicts is a very challenging task and might even be considered as controversial it is likely to be strongly influenced by political and sectoral attitudes which would necessitate several measures beyond modeling to ensure successful stakeholder participation and coordination irvine and o brien 2009 3 3 integration of methods and models from the reviewed case studies we also notice that there is some interest in combining fcms with other modeling approaches see table 5 the coupling of fcms with other modeling approaches is usually needed particularly to overcome the limitations of fcm modeling or to leverage the strengths of the other approaches for example fcms were jointly used with abm modeling or cellular automata ca to capture the influence of the dynamic behavior and interaction of entities such as inhabitants on the studied system in some case studies fcm concept maps were simply used as a step toward developing abm models elsawah et al 2015 wildenberg et al 2010 while other approaches engineered the models to work together to share inputs and outputs giabbanelli et al 2017 discussed two different ways in which abm can be combined with fcm modeling in socio ecological systems in particular the authors show that the hybrid approach can be built by i embedding a fcm within each stakeholder agent halbrendt et al 2014 or ii or by refining the key fcm concepts using abm and connecting the abms to concepts gray et al 2015a the first approach is useful if the modeling aim is to focus on studying how interactions among agents and with their environment influenced stakeholders understanding and behavior the second approach can rather be used as a decision support tool that helps with examining the dynamics of the studied socio ecological system itself some integrated assessment applications coupled fcms with other components by applying socioeconomic or natural models such as physical processes to describe complex interactions in the surveyed case studies the coupling is usually achieved by using the empirical outputs of physical or socioeconomic models as inputs to fcms htun et al 2016 or by including qualitative social science concepts into the quantitative modeling framework de kok et al 2000 van vliet et al 2010 the coupling is sometimes used to generate real scenarios that can be tested using fcm simulation anezakis et al 2016 or as an elicitation step to identify key sensitivities before assessing those using socioeconomic quantitative modeling frameworks nikas et al 2018 fcms were also used as an interface between the storyline approach and other quantitative frameworks like the social network analysis sna in problems where there is a need to understand the actual complexity of interactions among the different actors like in emergency management giordano et al 2017 nonetheless like with all types of coupled component models ccms reviewed by kelly et al 2013 there are still some structural and technical limitations and pitfalls to integrating fcms with other models voinov and shugart 2013 one of the challenges in building ccms is to ensure that after plugging the pieces of software together the produced knowledge is scientifically coherent in order to ensure coherence the different system components should be brought to compatible resolutions with respect to data scales and uncertainty it seems that ensuring conceptual and scientific consistency is an overlooked issue in fcm based ccms as there is no indicator on how these ccms ensure compatibility among coupled components or how the information is exchanged between components to allow legacy models to be incorporated in fact none of these integrated instances is designed to integrate legacy code but they rather interact in an input output fashion coherence issues are likely to be resolved mechanically by the development team responsible for the integration of components laniak et al 2013 for instance in order to be able to use fcms and the watergap model as complementary tools van vliet et al 2017 had to scale up and down between the fcm scale river basin and the watergap scales grid or country depending on variables despite the substantial resources going into these different implementations models are mostly used by their original developers they are not used beyond their respective development teams fcm based ccms are not developed to be reused and did not mature enough to be leveraged into integrated frameworks many best practices could be shared by increasing openness reproducibility and standardization of these models huppmann et al 2019 moreover we believe that the use of ontologies could play a significant role in harmonizing the semantic information and in providing a unified framework for building fcm based ccms voinov and shugart 2013 4 how to deal with fcm modeling limitations the major limitations of fcm modeling are related to the methodology of the approach itself in this section we discuss how fcm based integrated assessment applications deal with fcm limitations especially by adding spatial and temporal dynamics and nonlinear relationships 4 1 spatial and temporal dynamics environmental issues may operate at a variety of time poses days months or decades and spatial resolutions e g region forest river or basin although fcm simulations are run for many iterations before converging these intermediate steps do not represent dynamic time steps fcms do not have a temporal dimension and are not explicitly spatial this issue is usually solved in two ways the first approach is to build models that are independent of any scale assuming that all studied processes operate at the same temporal or spatial scale malek 2017 the second approach consists of building lumped models i e producing a single output for the entire modeled area or a time period such as by averaging bourgani et al 2016 park and kim 1995 from the reviewed case studies it is usually implied that the fcm model is spatially aggregated for a specific resolution or at best models few spatial units hence few studies consider possible system changes over different time periods or spatial distributions some authors coupled fcms with gis either to extract soil properties markinos et al 2007 or to produce thematic maps skov and svenning 2003 which can be used as a proxy to delineate management zones in spatial planning applications we also note that some case studies combined fcms and gis within a framework to derive the fcm structure using spatial information soler et al 2012 there are two main ways of integrating gis in integrated assessments either the analysis is carried within the gis or externally by linking the gis to the model this latter approach is the common method used with fcm case studies fcms can represent spatial concepts by coupling fcms with gis but not spatial heterogeneity although fcms are coupled with gis the coupling is loose as none of the approaches investigates the use of spatial nodes within the fcm maps to provide a more spatially explicit assessment of the studied system this is typical with other modeling approaches as well because gis and these methods do not integrate well due to fundamental incompatibilities in their conceptual representations fcms allow only producing static models among the reviewed applications few authors developed dynamic fcm models that are capable of capturing dynamic changes through time nikas and doukas 2016 designed a fcm model to estimate the impacts of climate change management policies and how soon they are likely to produce the calculated results the approach is based on the assumption that all relationships are yearly hence prompting the stakeholders for the number of year units for each causal relationship accordingly a new simulation function was proposed to include the delay notion by multiplying the weight of a relationship with the activation value of the cause concept minus the time delay of the respective causal link towards the same end biloslavo and dolinšek 2010 also developed a fcm time extension to perform dynamic simulation of the world s climate development the authors took a different approach by considering time delays between a cause concept and its effects as a time function four function types are considered namely step linear concave convex and sigmoid simulation with these fcm time extensions can be carried until a time horizon objective is reached 4 2 nonlinear dynamics the second major shortcoming of fcms is that they focus on depicting causalities between system variables rather than effects or rates of change a link represents a fuzzy causal relationship between two concepts and fcm inference allows drawing conclusions about what is caused and what is not caused which provides a resolution for indeterminacy in cognitive maps calais 2011 however fcms have been heavily used in the literature beyond the simple propagation of causalities modelers have used fcms as sd models where the links represent the magnitude of change induced by one concept on another one nevertheless despite the fact that the graph represents a sd system the developed models used causality related features of conventional fcms helfgott et al 2015 mourhir et al 2016 first these implementations make use of fuzzy binaries to quantify the influence exerted by one concept on another by forcing the link s weight into a static value in the range 1 1 the fcm s structure hence models monotonic and symmetric relationships which may overlook the complex dynamics of the studied system carvalho and tomé 2009 fcms are not dynamic models and do not allow the modeling of nonlinear relationships in a dynamic model the weight is a mathematical function of other factors influences and there is no reason why it should be a static value furthermore rather than representing units a fcm models the extent to which concepts are present or not which might constraint the interpretation of the results for example the method cannot be used for predicting real valued quantitative outputs so the model and its outcome can only be interpreted qualitatively whereas variables in a sd model map to a universe of discourse within their maximum and minimum state limits moreover due to their structural limitations fcms are not intrinsically stable fcm models might not be able to maintain the stability of the original real world system causing a theoretically unstable fcm to converge mainly due to the use of squashing functions and the use of bivalent or trivalent concept values carvalho and tome 2002b few authors worked and presented some examples with case scenarios in the literature on dynamic fcm mechanisms among the first to reveal the several shortcomings of conventional fcms that can be overcome by using rule based systems are carvalho and tome 2000 and khan and khor 2004 mourhir et al 2016 also proposed a dynamic rule based fuzzy cognitive map drbfcm as an alternative to sd by combining the properties of fcms and fuzzy inference systems fiss to model nonlinear relationships and sort out the abovementioned limitations aguilar and contreras 2010 introduced a dynamic fcm approach based on mathematical equations which can only be useful if a cognitive map is connected to a real system where causal relationships have been modeled using mathematical equations aguilar 2013 in rule based fcm approaches fuzzy logic facilitates the representation of nonlinear cause effect relationships they can adapt influence weights by mapping dynamically causal node states to effect node states using if then rules ross 2009 aside from the capacity to represent nonlinear relationships using the rules they operate on real values which makes them suitable to predict real values as output unlike auto associative neural networks that normalize all values between 1 and 1 rule based fcm models allow reasoning in terms of deterministic system variables states computed using quantified perturbations produced by fuzzy inference since they add true fuzziness to fcms by using fuzzy logic zadeh 1965 they can be used as a natural interface to capture human beliefs and expertise and as a technique to solve knowledge ambiguity usually faced in multidisciplinary systems they support the same type of applications featured by conventional fcm models they are not explicitly spatial or temporal but like traditional fcms they can be designed for a specific spatiotemporal resolution and the use of rules can make it easy to express time in qualitative system dynamics carvalho and tome 2001 in addition to that these models maintain the properties of the modeled system since they reflect the understanding and findings about the dynamics of the real world system and concept values are not randomly altered by squashing functions hence stability is more inherent to the original real world model carvalho and tome 2002a contrarily to conventional fcms rule based fcms also improve the interpretability of fcm models as they generate outputs that can be interpreted by tracing the rules that contributed to the results however rule based fcms tend to get complex and might suffer from rule explosion as the number of concepts increases drbfcm is the only rule based fcm modeling technique that was applied as an integrated environmental assessment method in a policy development exercise to investigate the impacts of several mixes of emission abatement strategies on air pollution mourhir et al 2016 a variant of drbfcm used to highlight spatial variability in a precision agriculture application emphasized that the rules were useful in describing nonlinear causal relationships for nitrogen recommendations mourhir et al 2017 particularly nitrogen is required in relatively large amounts by cotton plants however too much nitrogen might have a negative impact as it can delay crop maturity and can be consequently harmful to cotton production 5 update of the framework to select the most appropriate modeling approach kelly et al 2013 developed a framework that can be used by modelers to choose the appropriate integrated environmental modeling approach using considerations such as the type of available data to build a model handling of uncertainty whether the focus of the model is to represent depth in specific processes or breadth of the whole system model purpose and the type of processes of interest such as interactions between individuals generation of aggregated system effects and support of feedback loops we refined the framework in a couple of ways first we distinguish between whether the model can handle uncertainties that are basically stochastic probabilistic or subjective in nature ambiguity and vagueness or due to lack of knowledge when individuals are involved we might be interested as well in aggregating their knowledge to build larger knowledge bases in the updated framework we differentiate between models that can support group modeling in a participatory setting and models that have the capacity to compute and generate aggregate system complexities table 6 summarizes how the different approaches perform with regard to the considered modeling criteria in table 6 crosses denote the standard practices and uses extra properties that can be developed as extensions are denoted with stars the updated guiding framework that can be used by modelers to choose the most appropriate modeling approach is also represented in the form of a decision tree in fig 3 assuming a standard application aside from the capacity to support uncertainty due to ambiguities and ill defined variables feedback and integration of both qualitative scenarios and quantitative information fcms are particularly useful in a participatory approach as an elicitation tool that allows capture and sharing of individuals knowledge and as a simulation tool to support the decision making process by fostering system thinking although they do not provide any particular mechanism to model individuals behaviors they have been successfully coupled with abm modeling to overcome this limitation like the other approaches the holistic system thinking of integrated assessment is not technically emphasized by fcm models but implied considering that fcm modeling usually integrates interdisciplinary participants compared to other modeling approaches fcms are similar to network based approaches because they build on graph theory they focus on perceptions of stakeholders which would allow linking them conceptually to abms and can represent system dynamics in a close way to sds sds and fcms are similar in their potential to increase our system understanding and to foster social learning these models focus on exploring and investigating how the future may develop using proactive alternative scenarios rather than on providing accurate predictions about a variable s quantity both sds and rule based fcms are capable of representing nonlinear relationships developing integrated environmental assessment models typically made up of many equations like with sds is a challenging task as much of the system s behavior should be described using mathematical equations the complexity of the model might be intimidating and prohibiting for lay experts participation especially when the number of considered interactions and feedback loops is high these models based on mathematical equations are not only hard to develop but also hard to understand in terms of interactions and to interpret in terms of outcome users might employ these models in a black box fashion hence the risk of creating a veneer of scientific legitimacy if the results are used in a policy analysis exercise or to support decision making pindyck 2017 knowing that most ecological and environmental knowledge does not always take the form of numerical or mathematical formulations we believe that the use of fcms and in particular rule based fcms might be valuable in applications where there is a need to study system dynamics by incorporating qualitative knowledge that cannot be expressed in the form of equations knowledge expressed in the form of rules is more intuitive than mathematical modeling and can be easily understood and traced to interpret the produced results when the modelers are interested in behavioral characteristics of entities in their interaction with the studied environment abms are the most appropriate modeling approach however unlike models built around networks such as fcms or sds where the top level structure makes the mental model explicit and highlights the feedbacks in abm systems modelers would encode the feedbacks in the rules governing the different agents wang et al 2018 fcm models are similar to kbss they can typically be used to provide support to decision makers and managers in complex environmental problems under uncertainty similarly to kbss especially rule based expert systems producing a robust rule based fcm model with enough cognition to interrogate the different facets of a system will result in increasing its complexity the more concepts added to the model the higher the number of if then rules to be elicited from experts to model the system s complexities and to be evaluated by the model the process of knowledge acquisition is deemed to be intensive and time consuming due to the many steps involved during the different stages and the entailed cognitive effort to collect domain knowledge similarly to all types of expert systems fcm approaches can encode subjective misjudgments and wrong speculations of the parties involved in the modeling process however the knowledge based approach in these techniques remains defensible as it can capture knowledge that will be hard to formalize differently considering the complexity of integrated assessment applications technically it can be argued that rule based fcms and rule based kbss have many properties in common and can be used interchangeably however there are some differences to discriminate between the two approaches fcms have a pre built capacity to account for feedback while other tree based expert systems do not rule based kbss have the capacity to capture compound conditional events between influencing variables using conjunctions and disjunctions fcms cannot unlike the conventional participatory approaches narratives questionnaires and surveys modeling approaches such as bns and fcms are relatively easy to understand semi quantitative methods that take a further step in involving stakeholders by formalizing the collected knowledge in a logical framework with an emphasis on drawing mental models and making them explicit these approaches aim at collecting characteristics of the studied system using causal relationships organized into a graph structure hence they allow a smoother integration of collected knowledge into simulation models bns and fcms can both use qualitative information quantitative data or both they have some affinity especially in their transparent graphical representation which is simple particularly for non expert users however the lack of support for feedback in bns might hinder their application in integrated environmental assessments also and due to their methodological construct bns are rather descriptive than causal they can only reveal the occurrence of events in contrast to simulation based approaches like fcms they may not be able to describe the process leading to the event environmental modelers understand that there is a significant amount of uncertainty inherent to environmental models handling of uncertainty in integrated environmental assessment is usually performed by assigning probability distributions to certain key parameters bns can handle incomplete data and the use of probabilistic relationships makes the method suitable for stochastic uncertainty when models based on probability are used formally involving stakeholders during model development might be a challenging task considering that they are required to provide specialized knowledge however specifying a probability based on prior and observed facts might not be intuitive nor straightforward moreover the use of probability distributions to handle uncertainty due to randomness makes it difficult to cope with other forms of epistemic uncertainties namely ambiguity and vagueness which are strongly present in participatory modeling for example the design of future change scenarios will usually contain various interpretations that can be attributed to the use of imprecise linguistic descriptions of socioeconomic interactions on the part of stakeholders the use of fuzzy logic with fcms makes it particularly easy to include qualitative representation of knowledge and handle ambiguities inherent to modeling with stakeholders fcm models handle better ambiguity and vagueness but they are based on the assumption that the modeler knows all causal relationships between entities however with fgcms one can further handle partial or total epistemic uncertainties using grey theory the literature shows that both fcms and rule based fcms can be applied to a variety of different problems however in general integrated assessment models have characteristics in favor of the application of rule based fcms qualitative expert knowledge the nonlinearity of system relationships and the absence of adequate mathematical models the combination of qualitative scenarios and fuzzy logic in rule based fcm models forms a particularly useful supplement to the tools for modeling integrated systems the choice between fcms and rule based fcms should primarily be based on the degree of domain knowledge about the system to be described and the nonlinearity of relationships the estimation of quantitative threshold values for the variables and the description of causal relationships in the form of if then rules necessary for the rule based fcm approach may complicate the satisfactory representation of social science or policy concepts in that case the application of traditional fcms may be more appropriate no mathematical concepts are required except for simple matrix algebra and the model can be as complex as desirable without complicating the calculations understanding complex systems is sometimes best done with formalizations that are rather simple more advanced approaches can then be sought using sophisticated models shall data becomes available moreover choosing between fcm and rule based fcm modeling would also depend on constraints such as the time scope and budget quantitative models can produce accurate predictions and can potentially make temporal forecasts of certain quantities however the task of parameterizing and calibrating a model may turn out to be difficult and costly semi quantitative models designed using fcms though they might only produce equilibrium outcomes are useful in systems where interactions are characterized by approximate or imprecise information ramsey and norbury 2009 on the other hand fcm models are appropriate for systems ruled by equilibrium conditions they might not be suitable for systems characterized by altered patterns due to high variability and which may never settle in an equilibrium state 6 conclusions in this paper we reviewed fcm applications in the field of environmental assessment and management with the aim of exploring the potential of fcms as integrated assessment models in our opinion different fcm approaches can successfully support many aspects of integrated environmental assessment and significantly contribute to the field although they are not best suited for producing accurate predictions like quantitative systems they are particularly instrumental in complex decision making processes with nonlinearities and approximate information about the underlying system interactions and which are characterized by feedback and equilibrium conditions with fcms we would use expert opinions to craft simple transparent and easy to understand models although simple models might not convey the kind of scientific legitimacy message that might be expressed by large scale models they help us to clarify stakeholder knowledge and beliefs about the studied issues and they make sense of complexity through a structured framework that is capable of producing credible outcomes by comparing and evaluating alternatives through scenario analysis along with fcm potentials as an integrated assessment tool we discussed some of the method s limitations including the representation of spatial and temporal dynamics and nonlinear cause effect relationships many of the reviewed applications could successfully overcome these limitations by coupling fcms with other modeling approaches or natural and economic models or by developing new extensions one of the main motivations behind integrated assessment is the promise of real transdisciplinary model integration although fcms do not provide any specific mechanism to build an integrated assessment application they have been integrated with other modeling approaches to leverage their combined strengths we believe that using an integral approach by combining fcms with other models and using ontologies would perhaps be a realistic approach to produce transdisciplinary models that not only inherit the properties of their pieces but will produce systems that can bring new insights that might not be gained by the sum of the parts more stakeholder involvement throughout the whole environmental modeling process would also be essential to ensure coherence between transdisciplinary models and the credibility of scenarios by enhancing communication between disciplines the relatively low uptake of fcm approaches by environmental modelers might be due to the fact that the method is relatively new and the recent advances in fcm modeling temporal dynamics stability handling nonlinear relationships have not been leveraged yet in an integrated framework that shall pave the floor for a broad audience of practitioners in the field of integrated environmental assessment there are two main takeaways from this work first fcms can be used as the starting point of any research as a tool to map out perspectives and potential system sensitivities before applying other models especially in wicked environmental problems that are complex involve many parties and have no straightforward solutions second they can significantly support integrated assessment applications by supplementing quantitative model approaches which are invariably constructed around one perspective that relates to available data with qualitative information derived from a structured stakeholder engagement process considering the systemic nature of integrated assessment applications one should be opened to insights that can be gained from fcm analysis which could be missing in scientific studies focusing on one dimension e g ecosystem approach that usually exclude the less quantifiable links and feedbacks which reduces the capacity of the model to integrate all aspects of the real world system in this regard fcms are likely to translate better the processes occurring at broader scales and inform decision makers especially in a data poor environment where even highly uncertain predictions can provide value for a wide range of decisions we hope that this article could shed light on the salient features of fcms to raise even more interest among integrated environmental assessment practitioners to adopt and adapt the method in the design of their integrated assessment applications declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment we would like to thank the reviewers for their helpful comments and insightful input appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104891 
25897,fuzzy cognitive maps were missing in the latest guidance by kelly et al 2013 which reviewed five common integrated modeling approaches through a scoping review the paper shows how fuzzy cognitive maps satisfy key criteria for suitability in integrated environmental assessment such as model purpose types of data available to build a model requirements in terms of spatial and temporal scales stakeholder involvement and treatment of uncertainty the paper consequently updates the guiding framework that can be used by modelers to select the most appropriate modeling approach by including fuzzy cognitive map techniques we argue that the method can be the starting point of any integrated environmental assessment research to map out perspectives and potential system sensitivities they constitute a great addition to the integrated assessment modeling toolbox as they can complement quantitative model approaches that are invariably constructed around a single perspective that relates to available data keywords fuzzy cognitive maps integrated environmental assessment environmental modeling 1 introduction environmental and climate change scenarios reveal an increase in natural hazards and environmental distress due to unsustainable trends driven by anthropogenic economic and development factors terzi et al 2019 the need to cope with the challenges of unsustainable development is recognized internationally as a fundamental step towards the effective implementation of adaptation and mitigation strategies environmental problems and climate change hazards are usually characterized by complex nonlinear interactions feedback loops among multiple socioeconomic and environmental stressors high uncertainty and the need to include policy and adaptation in changing final system states jakeman and letcher 2003 rotmans and dowlatabadi 1997 sperotto et al 2017 the use of modeling has been widely recognized as being critical to environmental management as it can reveal hidden patterns and can bring new insights to decision makers carnevale et al 2012 gidden et al 2018 hong et al 2012 howells et al 2011 huppmann et al 2019 meinshausen et al 2011 müller 2008 rotmans 2012 schreinemachers and berger 2011 the holistic approach of integrated assessment is usually used as a platform to deal with the abovementioned challenges and to assist policy makers with addressing complex environmental problems jakeman and letcher 2003 according to hamilton et al 2015 the integration concept refers to the combination of system components across several dimensions that reflect the real world system aspects the methodological aspects as well as the technological aspects integrated environmental assessments are analytical models that combine diverse multidisciplinary knowledge data and models into a single framework they can capture complex trends and synthesize useful insights by making cross linkages between the different socioeconomic factors and environmental phenomena rotmans and dowlatabadi 1997 and more recently by engaging decision makers and the broader public in this adaptive process jordan et al 2012 voinov and bousquet 2010 voinov et al 2016 integrated environmental assessment is usually conducted within a framework that is linked to policy to help differentiate among policy alternatives with recognition of any feedbacks and impediments allowing an assessment of the feasibility of pathways to achieving specific goals jakeman and letcher 2003 finally integrated assessment models can also characterize and handle different types of uncertainties including the less quantifiable aspects such as the lack of knowledge ambiguity and ignorance van asselt and rotmans 2002 voinov and shugart 2013 classified integrated assessment research into two categories the integral approach consists of building the model as a whole by integrating data and knowledge from different sources and interdisciplinary fields integral models are usually built by the same team with cohesive resolutions and runtime synchronization kragt et al 2011 integral models are commonly designed to deal with coarse scale general trends and they are typically implemented using the same modeling method like system dynamics duran encalada et al 2017 bayesian networks sperotto et al 2017 or agent based modeling becu et al 2016 even when they are built based on existing models the parts they are usually re implemented and integrated into the larger system the whole to yield a meaningful and useful product the second approach is the integrated approach which consists in assembling existing ecological and economic models representing various subsystems to overcome their limitations when used separately by building an integrated tool suite to provide decision support mcintosh et al 2011 rizzoli and young 1997 the models might be implemented using different paradigms and in general are loosely linked where the output from one model is fed as input to another one several modeling approaches can be used to build integrated environmental assessment applications a position paper by kelly et al 2013 discussed five different modeling techniques that have been used in the literature for integrated environmental assessment and management which are system dynamics sds bayesian networks bns knowledge based systems kbss agent based models abms and coupled component models ccms several considerations in model development were chosen by the authors to investigate the potential of each modeling approach as an integrated environmental assessment method namely i the model s purpose ii types of data available iii whether or not the model supports feedback iv capture of spatial and temporal dynamics v characterization of uncertainties vi treatment of entities and vii technical mechanism to resolve the model s output i e simulation or optimization a summary of model considerations with possible alternatives to consider is shown in fig 1 the approaches reviewed by kelly et al 2013 feature different advantages and limitations and are subsequently suitable for different modeling purposes fuzzy cognitive maps fcms were missing from the guidance framework proposed by the authors in this work we would like to demonstrate that fcms have the capacity to cope with the central challenges of integrated environmental assessment and can serve as a modeling approach in multiple types of environmental applications fcms are simple models that can depict directions of change in environmental systems they can efficiently bridge the gap between the design of causal loops in qualitative systems that lack analytical capabilities and their effective use to support environmental management decision making under uncertainty or policy development this paper is a scoping review that aims at exploring to what extent fcms are useful in integrated assessments based on our own experience and the breath of fcm research showcasing the utility of the method through environmental and ecological case studies we also aim to update the guidance framework of kelly et al 2013 to help modelers select the right method among the different approaches to integrated environmental assessment modeling in section 2 we provide brief background information about fcms in section 3 we review the potentials of fcms as a modeling approach in integrated assessment applications with respect to the main modeling criteria in this context we discuss how some fcm extensions with environmental case studies deal with the method s limitations in section 4 in section 5 we use the insights gained from the previous sections to update the framework developed by kelly et al 2013 to assist the modelers in choosing the most appropriate modeling method for their integrated assessment applications we also highlight the main advantages and drawbacks of fcm modeling in comparison to the other modeling approaches we conclude by emphasizing where the fcm method finds its niche in the integrated environmental assessment toolkit in section 6 2 fcm essentials 2 1 what are fuzzy cognitive maps fcms are signed directed graphs that explicitly represent a set of variables and their causal relationships using fuzzy causal weights kosko 1986 they are semi quantitative models that can be used to represent the behavior of complex systems on a macro level fcms can capture the functional and causal interactions among system factors using experts and lay experts knowledge beliefs and understanding to design the causal diagram of a fcm modelers choose the relevant concepts that capture the system s dynamics and describe relationships between them by assigning a degree of influence positive negative or none that one concept can have on another fcms graph structure allows capturing system dynamics and causal reasoning in fcms permits feedback which encourages closed loop reasoning gray et al 2019 the dynamics of the inference can be used to analyze complex interactions to find the key system drivers or leverage points to act on in order to trigger changes on the system as a whole which makes them useful as a decision making support tool fcm nodes are often divided into endogenous variables that have values determined by using fcm inference and exogenous nodes that are usually used to represent causal perturbations such as management interventions or variations in the main system drivers and stressors the dynamics of fcm inference is very close to neural network mechanisms the outcome of the model is derived by multiplying the fcm s weight matrix by the state vector of perturbations kosko 1987 according to 1 1 c i k 1 s j 0 n c j k w j i where c i k 1 is the activation value of the effect concept c i at iteration k 1 c j k is the value of causal concept cj at iteration k w j i is the weight of the cause effect link between cj and ci s is a nonlinear activation function such as sigmoid that is used to transform the results in a nonlinear way bueno and salmeron 2009 a fcm example is shown by fig 2 from left to right a represents the fcm model b depicts the corresponding relationships encoded in a weight matrix and c shows the effects of four different policy options on the system drivers using fcm inference fcms have applications in a wide spectrum of scientific fields and they have also shown a good promise in modeling complex socio ecological and environmental systems jetter and kok 2014 papageorgiou and salmeron 2013 although they were designed to explore uncertainties among system variables and their effects on the system s behavior several studies highlighted the use of the method as a systems thinking approach even though they do not provide any specific mechanism to build an integrated application they are built based on experts beliefs by combining interdisciplinary knowledge that can be seen as integrated as such hence they can address a variety of environmental and ecological problems under different settings malek 2017 like the development of climate change scenarios biloslavo and dolinšek 2010 the development of bio based economy scenarios penn et al 2013 simulation of precision farming scenarios mourhir et al 2017 papageorgiou et al 2009 livelihood vulnerability analysis murungweni et al 2011 singh and nair 2014 community disaster planning henly shepard et al 2015 and drought or water management kafetzis et al 2010 van vliet et al 2010 examples of how fcms were used to investigate complex interactions in socio ecological and environmental management systems are provided in the supplementary material s1 2 2 fcm software tools from the surveyed papers mental modeler 1 1 http www mentalmodeler org developed by gray et al 2013 seems to be the most frequently adopted tool to build fcm based environmental applications douglas et al 2016 gray et al 2015b henly shepard et al 2015 htun et al 2016 singer et al 2017 mental modeler is particularly handy for non technical users experts and stakeholders it features a web based interface that provides support for collaborative modeling as well as analysis and aggregation of multiple fcm models other researchers opted for fcmapper 2 2 http www fcmappers net joomla to design their fcms christen et al 2015 lopolito et al 2015 martinez et al 2018 olazabal and pascual 2016 solana gutiérrez et al 2017 wildenberg et al 2010 fcmapper is one of the first non commercial fcm analysis tools available online designed as a ms excel worksheet it allows visualizing the fcm graph as a net file format some studies reported performing the fcm analysis using the fuzzy cognitive mapping integrated environment 1 16 software package which was designed in collaboration with the information technology company interplanetic kafetzis et al 2010 meliadou et al 2012 mouratiadou and moran 2007 however the software package is only available upon request from the developers 3 3 for further information on the software availability contact dimitris tsalkakis at dts interplanetic com for more sophisticated fcm extensions such as fuzzy grey cognitive maps fgcms which tend with their native support of uncertainty to create a much larger search space in which to run the model modelers can make use of parallel fuzzy cognitive maps 4 4 https osf io qyujt it is an open source python library used for intensive simulations capable of running multiple fcms in parallel lavin and giabbanelli 2017 lavin et al 2018 although other software such as fcm expert and isemk seem to offer the perhaps most comprehensive list of tools and apis for model development featuring learning and optimization techniques they have been released recently and did not mature enough to report on them nikas et al 2019 we recommend several recent articles for readers interested in a more comprehensive overview of existing fcm software packages felix et al 2017 giabbanelli et al 2019 papageorgiou et al 2018 the decision to select a specific software should not be taken lightly as most of the fcm features or extensions may not be simply selected from a software s toolbox considering the participatory nature of integrated assessments among the criteria that should be considered to choose the software package is the ease of use flexibility for incorporating changes into the model s structure and the ability to incorporate extra functionality elsawah et al 2017 fcms do not benefit as yet from high level modeling software platforms with a comprehensive list of features in order to provide support to the integrated environmental assessment community we believe that there is a substantial effort that should be deployed in building software packages with easy to reuse components excellent visualization features and implementation of different extensions suggested in fcm research 3 how do fcms deal with model considerations in order to meet the aims of our work a set of fcm applications in the field of environmental modeling and management were selected and examined these applications integrated a broad range of social ecological economic and management components and involved a variety of stakeholders they differ on the methodologies and development choices followed for constructing the fcms as well as on the purpose of using fcms in this section we review the potentials of fcms in integrated environmental assessment modeling with respect to the main modeling criteria used in this context a summary of the sorts of choices used in fcm integrated environmental modeling is given in table 1 and discussed in more detail within the next sections 3 1 fcms in the environmental modeling process the challenges of integrated environmental assessment must be addressed throughout the different phases of the modeling process starting with engaging the different actors followed by system conceptualization characterization of uncertainty and synthesis of the results in this section we highlight the way fcms fulfill integrated environmental assessment modeling considerations by relating the discussion to the different phases of the modeling process 3 1 1 stakeholder involvement there is a variety of stakeholders that can have a direct influence on the decision making process stakeholders can be affected citizens influencing industrial or lobbying groups experts or political decision makers from an integrated environmental perspective involving diverse multidisciplinary stakeholders is necessary from methodological political and learning standpoints unlike the conventional participatory approaches narratives questionnaires and surveys a fcm is a relatively easy to understand semi quantitative method that takes a further step in involving stakeholders by formalizing the collected knowledge in a logical framework with an emphasis on drawing mental models and beliefs gray et al 2015b in a recent review by voinov et al 2018 about tools and methods for participatory modeling fcms were described as requesting low time and cost and requiring low methodological expertise of stakeholders the somewhat ease of use and graphical structure of fcms makes it relatively accessible to non modelers and suitable in different research contexts involving different types of participants hence a fcm can be used as an elicitation tool to collect and organize knowledge and to allow individuals to share their experiences and understandings several studies have shown that mental models suitable for simulations could be extracted in the form of fcms amirkhani et al 2017 jetter and kok 2014 which offers some scalability giabbanelli 2014 and allows for stakeholder participation using platforms such as mentalmodeler gray et al 2014a in a participatory setting two strategies are commonly used to collect knowledge namely the different participants are either invited to one to one interviews where a fcm is developed for each respondent giordano and vurro 2010 papageorgiou et al 2009 samarasinghe and strickert 2013 or to group meetings and workshops where the fcm is built collectively henly shepard et al 2015 hobbs et al 2002 penn et al 2013 van vliet et al 2010 both approaches exhibit particular advantages individual models provide a more robust representation of an individual s understanding and uncover differences in mental beliefs and perceptions of involved stakeholders however building individual fcms might be time consuming and might require many resources and knowledge heterogeneity across maps might make it challenging to generate aggregated system complexities and simulate scenarios from the reviewed case studies when this approach is adopted the individual maps can be compared and analyzed separately jetter and schweinfort 2011 kafetzis et al 2010 tan and özesmi 2006 aggregated into one fcm henly shepard et al 2015 papageorgiou et al 2009 samarasinghe and strickert 2013 or aggregated into different fcms representing separate groups özesmi and özesmi 2003 solana gutiérrez et al 2017 on the other hand the process of building a group model is less time and resource consuming as it can be produced collaboratively by stakeholders at a workshop it is not uncommon when this latter approach is adopted that participants would usually get divided into separate groups with similar institutional perspectives and values lavin et al 2018 meliadou et al 2012 singer et al 2017 other case studies take a complementary approach for instance santoro et al 2019 collected individual fcms to capture stakeholders risk perceptions about flood management and group modeling to define potential shared flood protection strategies the construction of fcm maps relies heavily on expert and human input participants express their beliefs using their heuristics knowledge values or perception of risk one way to perform comparisons across stakeholder groups or individuals is by analyzing the map structure using graph theory indices gray et al 2014a certain graph metrics can provide insights into uncertainty about the structural variation across stakeholders for example the centrality network metric is an index that shows the total strength of the concept s connections it is a measure of the concept s contribution to the cognitive map the centrality metric is used in different ways in fcm studies for example lavin et al 2018 suggested that network centrality can serve as a tool to compare group models instead of comparing them through multiple scenario simulations the authors performed experiments on their 264 fcms in the context of fishery management the results of comparison suggest that if stakeholder groups agree on the central factors they also tend to agree on simulation outcomes and thus share a paradigm santoro et al 2019 argue that computing the centrality indices for the most common variables helps to understand the differences that each actor attributes to the same problem and helps highlighting out the divergences of problem frames the hierarchy metric is another index that takes a value between 0 and 1 a high value indicates that the system is top down hierarchical system whereas a low value indicates a fully democratic system stakeholders with democratic maps perceive the system as being more adaptable to changes hence they can be a starting point for achieving management objectives sandell 1996 for example tan and özesmi 2006 compared fcms from ngos government officials and villagers about wetland ecosystems in turkey they discovered that the latter group developed structurally democratic maps indicating that they acquired a higher capacity to adapt to the socio ecological changing conditions compared to the other groups of stakeholders from the reviewed papers we note that different fcm studies formally involved stakeholders in the early stages of model conceptualization and also in the late stages of scenario development uncertainty exploration simulation and assessment which demonstrates the potential of the method as a fully participative tool to perform integrated assessments 3 1 2 model conceptualization the objective of fcm model conceptualization is to identify the model s structure by designing a causal diagram that depicts the main interacting components of the studied system and their causal relationships the choice of concepts is a critical determinant in any integrated environmental assessment application certain studies focus on day to day environmental management concepts while others focus on more synthesized variables that are relevant to the policy life cycle and that can help decision makers take informed decisions some approaches combined fcms with dpsir 5 5 https www eea europa eu publications tec25 drivers pressures state impacts responses as a method to frame the selection of relevant variables during the early phases of the project in order to make cross connections between the socioeconomic drivers and the natural environment within a policy oriented context gray et al 2014b mehryar et al 2017 mourhir et al 2016 two techniques are usually used for choosing the list of concepts standardized concepts or freely associated concepts gray et al 2014a when a standardized list of concepts is used stakeholders are provided with a pre compiled list of concepts to design their individual fcms building fcms this way facilitates the combination of knowledge through the addition of models using their corresponding connection matrices however standardizing the model s concepts may compromise its reliability as the participants cognitive images might get biased by the predefined list conversely using a free association of concepts might yield richer fcms since a variety of mental perceptions and heterogeneous knowledge can also be captured nevertheless fcm design using freely associated concepts can be resource intensive as it requires extra effort to generate the group map the synthesized group map can be produced by augmenting the connection matrices of individual maps to reflect all concepts as identified by different participants averaging of connection weights is commonly used as a method to aggregate the causal relationships from the individual fcms and produce a combined model enriched with knowledge from all experts and stakeholders gray et al 2014a aggregation of fcms in a group model might also require the use of credibility weights to distinguish between different types of participants depending on expertise kosko 1988 another challenge when freely associated concepts are used is related to variations in language resulting in the use of different terms for the same construct in order to address this issue there is a need for a homogenization step in fcm modeling that consists in grouping concepts that have the same meaning and selecting a standard and consistent wording across maps olazabal et al 2018b reckien 2014 this is usually done qualitatively like by using grounded theory glaser and strauss 2017 which suggests taking a systematic approach in defining a common terminology by collecting and analyzing related data to produce a meta text that describes the subject field in terms of high level themes the meta text can then be used as a common ground for defining fcm concepts when producing a fcm the modelers must ideally find the right compromise between producing a robust model with enough cognition that interrogates the different facets of the studied phenomenon and yet keeping it simple to interpret and gain useful insights some approaches opted for systematic approaches e g özesmi and özesmi 2003 used a method based on randomized accumulation curves and tan and özesmi 2006 used a method based on monte carlo simulations in order to determine whether there is a need to include more concepts in their models singh and nair 2014 condensation of fcms is a methodological enhancement that was also used by many environmental studies to meet both objectives one approach to condensation is to construct preliminary fcms containing all identified variables and then gather similar variables and those that belong to the same upper level themes under one broader category using qualitative aggregation martinez et al 2018 özesmi and özesmi 2003 van vliet et al 2010 another approach is to aggregate variables following a quantitative methodology as is the case with samarasinghe and strickert 2013 who used self organizing maps som in order to cluster different concepts ortolani et al 2010 also applied hierarchical cluster analysis and principal components analysis pca 6 6 https www nature com articles nmeth 4346 to a set of 20 fcms representing individual farmers beliefs to identify separate groups which would consequently be represented as agents mourhir et al 2016 used a semi quantitative method to compile a set of related indicators e g dpsir pressure variables into a composite index to bring their air pollution model to a lower resolution obiedat and samarasinghe 2016 used a two stage process to reduce the system s complexity made of subjective condensation of similar variables and aggregation of fcms into a collective map using a quantitative method based on a 2 tuple fuzzy representation and stakeholders credibility weights to condense imprecise connections computationally although the advocated enhancements might help with condensing the knowledge maps effectively the condensation approach is not always straightforward and might raise methodological challenges that need to be addressed adequately for example building a composite index is similar to building a model which is likely to be affected by uncertainties such as the choice of indicators and the aggregation method one way to evaluate the complexity of a fcm model is by using graph theory indices that analyze the map structure particularly the complexity metric ratio of receiver to transmitter variables might be used as an indicator of the map s complexity for example a large value indicates a complex map with a high number of outcomes and fewer driving forces gray et al 2014a using this structural metric henly shepard et al 2015 demonstrated that one group of stakeholders developed a more complex model compared to other groups though the model had fewer connections and a lower density fcms can be built using both qualitative and quantitative data however they are particularly useful when there is a lack of data to build a model empirically different sources can be used to derive the qualitative knowledge the maps are built upon typically integrated assessment applications are conducted in a participatory approach where the modelers seek input from interdisciplinary stakeholders solana gutiérrez et al 2017 however in some cases the authors of the paper play the role of experts by providing the necessary knowledge to build the model de kok et al 2000 or extract the causal relationships using previous reports experiments and studies ramsey and norbury 2009 or combine such knowledge with their own expertise kok 2009 some case studies learn the fcm model using historical data in an attempt to improve the robustness and accuracy of fcm output especially in prediction tasks papageorgiou et al 2009 the main objective of fcm learning algorithms in the literature is to define or update the initial knowledge of experts in order to produce fcm influence weights while this approach produces relationships based on empirical data and might help the model converge to a desired state it requires the availability of a dataset to learn from few environmental studies tried a data driven approach to learn the fcm model from due to the lack of data because of the multi disciplinarily aspect of problems at stake namely ramsey et al 2012 developed fcm models to understand the impacts of deer control on forest ecosystems in new zealand by using approximate bayesian computation abc to generate the causal weights and select among alternative models using data buruzs et al 2015 also used a bacterial evolutionary algorithm bea to design a fcm model to support decision making in waste management by relying on the system factors time series in a precision agriculture application papageorgiou et al 2009 proposed the nonlinear hebbian learning nhl algorithm to train a fcm for cotton yield prediction using soil properties data driven practices do not take advantage of one of the perhaps most fundamental benefits of cognitive mapping consisting in the development of a model that encompasses different aspects of the system by acquiring knowledge from domain experts htun et al 2016 papageorgiou et al 2009 van vliet et al 2010 and involving different groups of stakeholders henly shepard et al 2015 hobbs et al 2002 murungweni et al 2011 penn et al 2013 soler et al 2012 for example argue that the expert based fcm models are likely to translate better processes occurring at broader scales compared to data based fcms given the spatial nature of data used to build the latter they also suggest that the expert based fcm can be used as complementary to a data based fcm to reduce the limitations of the latter namely scaling and literature availability issues we notice from the reviewed literature that data based fcms focus on the concepts for which measurable observations are easily collected hence excluding the less quantifiable ones like social and policy related indicators which reduces the capacity of the technique to be used in integrated assessments unless combined with other methods some authors use correlation coefficients as a starting point to quantify causal relationships for example huang et al 2013 used structural equation modeling sem 7 7 https www sciencedirect com topics neuroscience structural equation modeling to identify the correlations between the elements governing wind power based on which the strengths of causal relationships between the different concepts were encoded into a fcm model we also note here the work of soler et al 2012 who designed a land cover fcm by quantifying the causal relationships using correlation coefficients as extracted from spatial data using soil fertility maps since correlation might not always imply causation soler et al 2012 confronted the relationships with existing research and only retained the significant correlations that were confirmed by a literature review table 2 summarizes the alternative approaches used by fcm applications during the different steps of model conceptualization 3 1 3 resolving the model s output two main approaches are commonly used to resolve the model s output depending on the end user considerations models might be tailored to answer what if questions by running simulations or might be optimization based simulations can help with improving our comprehension of the system s dynamics by studying subsequent states derived from an initial stimulus and can help one develop a better understanding of interdependencies between system variables simulations can serve as a useful instrument to support decision makers in a policy exercise allowing them to perform a proactive analysis by testing how voluntary alternative scenarios could have an impact on the environmental future in a transparent manner they can help managers and decision makers with assessing the current environmental status and planning for effective responses based on strengthening preventive and mitigating measures to reduce the consequences of environmental degradation examples of how fcm simulations were used in the reviewed case studies are discussed in section 3 2 optimization based models help decision makers find an optimal solution that satisfies preset outcomes and objectives it allows performing a goal oriented analysis which is a useful exercise that can assist managers in achieving the targets of sustainable development fcms are not considerably used in goal oriented analysis of complex systems as the nonlinearities prevent backward chaining i e reversibility however some authors proposed optimization approaches by using evolutionary algorithms genetic and immune he 2008 khan et al 2004 to obtain the optimal initial stimulus state that is likely to lead to the target state that represents the initial goals or to find the cause of a sudden change of internal state kim et al 2008 the approach consists of minimizing an objective function e g euclidean distance between a target state of interest and input policy vectors picked from a randomly generated population of vectors the backward inference algorithm calls the forward inference to evaluate the vectors picked from the random population of vectors this is followed by the evaluation of the objective function to keep only the vectors that achieved good performance this process is repeated until satisfactory performance is achieved or a number of iterations is completed however the computational expense of these approaches can explode quickly and should be further explored to enhance the effectiveness of fcms in optimization problems fcms are really about concepts and modeling causal relationships between them to get an understanding of system dynamics so the whole idea of optimization will need some additional definitions and further development to be used in environmental management 3 1 4 characterization of uncertainties during the environmental modeling process the different causes of uncertainty affect the framing the structure and output of fcm models walker et al 2003 uncertainty and its effects cannot be considered in absolute terms identifying uncertainties should entirely depend on what the goals of the modeling exercise are the primary goal of environmental studies is to increase system understanding or perform exploratory analysis by involving multi and trans disciplinary stakeholders with divergent beliefs and experiences and by making use of scenarios to extrapolate beyond what is known to compute approximate projections of future situations that do not exist as yet walker et al 2003 some of these uncertainties are not necessarily considered as undesirable if applicable these uncertainties should be adequately characterized and included in the model s structure to produce alternative views and scenarios to be explored in this section we create a correspondence between the methodologies presented by refsgaard et al 2007 to characterize and handle uncertainties in environmental applications with the sources and types of uncertainties as distinguished in the uncertainty taxonomy that was developed by walker et al 2003 and updated by warmink et al 2010 the conceptual uncertainty framework helps characterizing uncertainties using a three dimensional representation based on the location level and nature of the uncertainty the location indicates the place where uncertainty is exhibited within the studied system which could be in the context the input data the model s structure or technical implementation the model s parameters or the output the level indicates the strength or severity of uncertainty within a spectrum that ranges from determinism to total ignorance we distinguish between three categories statistical uncertainty can be characterized probabilistically in scenario uncertainty outcomes might be known but we cannot attribute probabilities to them whereas with recognized ignorance the full range of possible outcomes is unknown it is also common to categorize uncertainty according to its basic nature epistemic uncertainty due to the imperfection of knowledge ambiguity that can arise from subjective judgments and language issues warmink et al 2010 and intrinsic randomness or natural variability such as deviations from standard behavioral patterns in a manner that is beyond control table 3 summarizes approaches used in fcm based integrated environmental assessment case studies to characterize and deal with uncertainty using the uncertainty matrix walker et al 2003 warmink et al 2010 the fact that political climate seeks a participatory approach most environmental assessment and management applications deal with context uncertainty i e are we considering all the relevant issues and the desired outcomes of the system and this is achieved by inviting stakeholders from different disciplines to the early scoping and framing stages of the environmental modeling process model structure uncertainty implies that there could be several acceptable representations that can reasonably represent the system several fcm based integrated assessment applications make use of multiple model simulation mms as a strategy to address uncertainty about the model s structure with mms several alternative models are created to conduct the assessment instead of using a single model murungweni et al 2011 ramsey and norbury 2009 soler et al 2012 research with experimental data could also perform model selection for example ramsey et al 2012 created four alternative models and selected the model that best describes the system using a markov chain monte carlo algorithm together with approximate bayesian computation mcmc abc by confronting the competing models with collected ground truth data mms is usually conducted within a framework that performs a comprehensive sensitivity analysis sa to investigate the model s structure uncertainty and map the variation in the system s output to variations in the system s structure htun et al 2016 this sensitivity analysis gives insights into the robustness of the outcomes of scenario analysis and shows how strongly they can be affected by changes in the weights of the relationships sa also helps with highlighting those interactions that matter the most to allow researchers to focus on more ramsey and norbury 2009 fcms inherently deal with ambiguity and vagueness and are particularly suitable for analyzing causality when the underlying knowledge domain is soft that is when the system s factors and their corresponding relationships are basically fuzzy kosko 1986 in some of the reviewed studies fuzzy logic fl is used to account for the uncertainty that results from the linguistic approximations in the fcm model s structure by representing fuzzy concepts and causal strengths using fuzzy sets mourhir et al 2016 obiedat and samarasinghe 2016 ramsey et al 2012 ramsey and norbury 2009 when fuzzy logic is used to handle ambiguity a sensitivity analysis is sometimes performed to attribute the uncertainty in fcm outcomes to the parameterization of the fuzzy sets ramsey and norbury 2009 however we note that there is less attention paid to the technical uncertainties related to the choice of the implication and inference methods giabbanelli et al 2012 another interesting approach to deal with uncertainty when the modeler does not know all causal relationships is fgcms which give the edges a range of possible values and hence offer a larger search space in which to run the model by simulating grey scenarios salmeron 2010 they have successful applications in several domains however they have not been investigated so far in integrated environmental assessment research we also note that some fcm environmental assessment models paid some attention to technical uncertainties of fcm development especially the convergence issues such as investigating the uniqueness of the equilibrium point or the effect of tuning the parameters controlling the slope of the transfer function benjamín et al 2017 for example in their fcm about the establishment of a bio based economy in the humber region penn et al 2013 compared scenario outcomes using both linear and sigmoidal transformation functions the results of the technical sensitivity analysis allowed the authors to strengthen the verification process like most other approaches reviewed by kelly et al 2013 fcms require running monte carlo simulations to cope with uncertainty about driving forces that have an influence on the system and its performance such as the relevant scenario and policy variables to build a fcm model singh and nair 2014 tan and özesmi 2006 according to soler et al 2012 the process itself of relying on qualitative data from different sources in fcm modeling is considered as a way to overcome the inaccuracies of working with quantitative data such as scale spatial inaccuracies and autocorrelation as for parameter uncertainty the only tuned fcm parameter is the relaxation parameter that was used in few case studies to accelerate convergence to equilibrium hobbs et al 2002 ramsey and norbury 2009 these case studies varied the value of the relaxation parameter and produced a set of interpretable fixed point solutions through a sa both research studies reported that 0 5 was found to be an optimal value another aspect of uncertainty is the model outcome s uncertainty which is the accumulated uncertainty caused by the uncertainties that stem from the different locations it is the difference between the ground truth observable value and the value predicted by the model if ground truth data is available a discrepancy error can be computed by running a formal validation exercise and confronting the causal chain of the model with empirically established relationships mourhir and papageorgiou 2017 consequently potential adjustments to the model s structure and tuning of weights can be performed automatically using the family of hebbian learning algorithms papageorgiou et al 2009 or by selecting weights manually among plausible ranges in the model s structure hobbs et al 2002 however empirical data is rarely available in fcm based environmental studies moreover most policy analysis models make use of simulations to extrapolate outputs for proactive scenarios that are beyond what is known in the absence of ground truths when applicable fcm output should be confronted with trends derived from stylized behavior patterns generated from robust observations schwanitz 2013 it is also very important to check the credibility of the model s outcome in consultation with its intended end users some benchmarks such as the degree of consensus and acceptability were proposed by certain fcm based environmental research for the assessment of the desirability and the level of approval of management scenarios by stakeholders giordano and vurro 2010 henly shepard et al 2015 kafetzis et al 2010 ultimately considering the systemic nature of integrated assessment applications one should be opened to insights that can be gained from fcm analysis which could be missing in existing scientific studies focusing on one dimension e g ecosystem approach that usually miss external linkages and feedbacks fcms are built using the knowledge and mental views of stakeholders if the choice of participants reflects the dynamics of the system at stake the outcome of fcm exercises should not be considered as arbitrary and should be credible giabbanelli and crutzen 2014 we notice that none of the studies conducted a comprehensive analysis of uncertainty which might lead to a false interpretation of the model s results walker et al 2003 warmink et al 2010 we believe that the typology of uncertainties in the three dimensional framework and more specifically the uncertainty matrix um should be a good starting point to identify uncertainties in fcm based integrated assessment applications in order to avoid confusion that could lead to informing the decision making process with sub optimal recommendations several techniques to assess and characterize uncertainties were reported in the literature a guidance framework to the applicability of the most commonly applied methods in the environmental modeling process can be found in refsgaard et al 2007 3 2 what types of applications are fcms used for in the field of ia models are generally built to satisfy one or more of five main model purposes i prediction ii forecasting iii management and decision making under uncertainty iv social learning and v developing system understanding or experimentation kelly et al 2013 in the absence of observed history or ground truths in integrated assessment applications mainly because we consider inter disciplinary complex problems fcms can be particularly useful with applications where there is a lack of data but expert and lay experts knowledge about the studied phenomenon is available gray et al 2014a 2015b jetter and kok 2014 özesmi and özesmi 2004 from the reviewed papers we notice that there is a typology of three modeling purposes fcm models are built for goal driven top down decision making and management developing system understanding and social learning the purpose of building models usually has an impact on the way stakeholders are involved in the modeling and simulation of fcms table 4 maps the modeling purpose with typical collection strategies and the type of involved stakeholders 3 2 1 top down decision making in top down strategies experts physicians scientists engineers are usually solicited when there is a need to include specialized knowledge about physical chemical biological or social processes and interactions in this case the method is used as an elicitation tool to collect the tacit knowledge of experts about a domain where there is limited data or components are not comprehensively linked in particular fcms are used as a measure to give structure to what would otherwise be loosely linked to demystify highly complex interactions or reduce uncertainty about a system s domain however modelers play a mediator role they collect qualitative input from stakeholders design the fcm model s and present the results to decision makers the stakeholders might not be directly involved in elaborating their cognitive models and using their outcome aggregation of fcms is usually needed in this case to generate a combined perspective of system complexities before running simulations the homogenization step is likely to throw items that are not commonly described by participants as the focus is shifted from empowering individual stakeholders with a tool to voice their opinions towards a focus on an imposed compulsory component or concept that is the central subject of the study doukas and nikas 2019 lopolito et al 2011 mourhir et al 2016 soler et al 2012 3 2 2 developing system understanding when the model s purpose is to enhance system understanding and inform the decision making process the focus is on using fcms as an analysis tool to study how the future might develop by relying on the simulation capabilities of fcms the simplicity of the method is used to allow stakeholders from different disciplines to draw their own cognitive models they are also usually involved in analyzing the produced collective knowledge obiedat and samarasinghe 2016 the results of group discussions can then be used to inform decision making in a top down manner obiedat and samarasinghe 2016 fcm models can help developing system understanding in two ways i by summarizing and integrating available knowledge this is mainly achieved by linking qualitative scenario narratives to quantitative models and ii by experimenting with the model using scenario analysis to discover how it reacts to changes in system drivers these two modes are not mutually exclusive in all case studies that aim at linking quantitative data with qualitative scenarios the conversion is performed within a framework allowing interaction between modelers and stakeholders developing narratives simultaneously and converting them to fcm models kok 2009 mallampalli et al 2016 singer et al 2017 van vliet et al 2010 the quantifications made using fcms concern mainly the relationships between the key concepts of the studied system parameterization of the variables themselves by stakeholders can follow by using other methods such as fuzzy sets or probability distributions heng jie et al 2006 hossard et al 2013 system understanding is also achieved through scenario analysis capabilities of fcms to study the derived states of fcm simulations which offer a projection of the system in the future and can reveal unintended effects of various system drivers scenario analysis can help improve stakeholder understanding of the system s current trends or help identify the gaps between possible futures and desired ones jetter 2006 the outcome of scenario analysis can then be used for further discussion compared to previous knowledge or employed as a backbone to design new policies or management options kok 2009 kontogianni et al 2012 van vliet et al 2010 from the reviewed case studies we note that scenarios can be predictive or informative saxena and vrat 1992 predictive scenarios are built to clarify how specific drivers will develop such as by studying the impacts of current socioeconomic or natural trends or providing quite comprehensive interpretations of what the future could hold by testing different hypotheses anezakis et al 2016 these studies allow stakeholders to understand the various dynamics and feedbacks that rule the system at stake informative scenarios on the other hand try to pro act on the desired outcomes by exploring possible pathways primarily through simulation of alternative management interventions or identification of barriers to their proper implementation kafetzis et al 2010 olazabal et al 2018a samarasinghe and strickert 2013 zhao et al 2014 some case studies start with a baseline scenario without considering any management action then make use of fcm simulations to discover possible restoration scenarios or to highlight worst and best scenario deviations from the baseline scenario amer et al 2011 jetter and schweinfort 2011 solana gutiérrez et al 2017 fcm simulation allows also identifying the mix of management options that are likely to optimize objectives by relying on the capacity of fcms to simulate different simultaneous perturbations which is more efficient than simulating perturbations separately and aggregating the results afterward doukas and nikas 2019 huang et al 2013 mourhir et al 2016 usually the collection of individual fcms is followed by a homogenization step and aggregation of knowledge into a collective map to analyze scenarios here all knowledge is welcome there is no focus on a single component and differences in fcm models among stakeholders are considered as a room for learning and identifying possible uncertainties stakeholders would also contribute to any validation of the aggregated model 3 2 3 promoting social learning social learning refers to a potential change that occurs in the mental models of stakeholders resulting from interactions among them in a social network in this perspective stakeholders are involved in a participatory approach the emphasis is more on the process of building the model collaboratively and sharing management and decision making or seeking acceptance of management decisions fcms are rather used as a facilitation method among diverse stakeholders and not necessarily as a formal assessment tool the focus is shifted from the simulation of policy outcomes to building trust and empowering stakeholders with a tool to challenge negotiate and influence the design of new regulations social learning happens through the capture of individual mental models allowing for agreements and inconsistencies to be discussed and potentially engaging in scenario analysis to foster adaptation to environmental changes henly shepard et al 2015 with this respect social learning usually focuses on non traditional forms of knowledge while encoding the fcm model by including stakeholder preferences as well as shared goals and values common to groups of stakeholders we can distinguish between two types of applications the first category where fcms are merely used as a communication tool to help determine how the different stakeholders are likely to react to management approaches in this case the method is usually used to capture individual or group mental models followed by a comparison of knowledge variation across groups to identify areas of compliance or non compliance to mandated policies or areas of multidisciplinary conflicts and agreements christen et al 2015 the comparison can be performed qualitatively giordano and vurro 2010 henly shepard et al 2015 kafetzis et al 2010 or based on quantitative approaches such as the non metric multidimensional scaling nmds to highlight differences between the individual models across groups vasslides and jensen 2016 the outcome of this exercise can be used to derive recommendations on how to adapt policies and ensure their effectiveness in the future for example fcms can help disentangle any potential misalignment between perceptions of the different groups by pointing out which anchoring points can be established among heterogeneous perceptions towards that end christen et al 2015 suggest using transmitter concepts forcing variables which only influence other concepts with a strong effect on a central concept as anchoring points for which policy development could be further developed in the second category fcms are used as a negotiation tool to help different groups of stakeholders develop a shared understanding of complex systems negotiate conflicting views and eventually reach consensus fcms in this case will facilitate planning help overcome the several barriers to adopting management measures and help to avoid institutional failure due to potential stakeholder opposition henly shepard et al 2015 herein the decision making process typically consists of two main phases the divergent and convergent thinking phases giordano and vurro 2010 during the divergent thinking phase the different views and alternatives are encouraged but also the shared objectives are defined during the convergent thinking phase the performance of the different alternatives is analyzed against objectives in the former phase fcms are used as an elicitation tool whereas the latter phase takes advantage of the simulation capabilities of fcms to assess the impacts of management options and compare trade offs scenario simulation is usually followed by an analysis of the acceptability and degree of consensus of management actions to rank and select the best alternative giordano et al 2007 the iterative modeling aspect is also emphasized by henly shepard et al 2015 the authors used single loop learning to encourage individual reflections double loop learning to build consensus using group discussions and triple loop learning to revise the action plan based on the newly emerging knowledge and collective system understanding nevertheless effective engagement of stakeholders especially for resolving conflicts is a very challenging task and might even be considered as controversial it is likely to be strongly influenced by political and sectoral attitudes which would necessitate several measures beyond modeling to ensure successful stakeholder participation and coordination irvine and o brien 2009 3 3 integration of methods and models from the reviewed case studies we also notice that there is some interest in combining fcms with other modeling approaches see table 5 the coupling of fcms with other modeling approaches is usually needed particularly to overcome the limitations of fcm modeling or to leverage the strengths of the other approaches for example fcms were jointly used with abm modeling or cellular automata ca to capture the influence of the dynamic behavior and interaction of entities such as inhabitants on the studied system in some case studies fcm concept maps were simply used as a step toward developing abm models elsawah et al 2015 wildenberg et al 2010 while other approaches engineered the models to work together to share inputs and outputs giabbanelli et al 2017 discussed two different ways in which abm can be combined with fcm modeling in socio ecological systems in particular the authors show that the hybrid approach can be built by i embedding a fcm within each stakeholder agent halbrendt et al 2014 or ii or by refining the key fcm concepts using abm and connecting the abms to concepts gray et al 2015a the first approach is useful if the modeling aim is to focus on studying how interactions among agents and with their environment influenced stakeholders understanding and behavior the second approach can rather be used as a decision support tool that helps with examining the dynamics of the studied socio ecological system itself some integrated assessment applications coupled fcms with other components by applying socioeconomic or natural models such as physical processes to describe complex interactions in the surveyed case studies the coupling is usually achieved by using the empirical outputs of physical or socioeconomic models as inputs to fcms htun et al 2016 or by including qualitative social science concepts into the quantitative modeling framework de kok et al 2000 van vliet et al 2010 the coupling is sometimes used to generate real scenarios that can be tested using fcm simulation anezakis et al 2016 or as an elicitation step to identify key sensitivities before assessing those using socioeconomic quantitative modeling frameworks nikas et al 2018 fcms were also used as an interface between the storyline approach and other quantitative frameworks like the social network analysis sna in problems where there is a need to understand the actual complexity of interactions among the different actors like in emergency management giordano et al 2017 nonetheless like with all types of coupled component models ccms reviewed by kelly et al 2013 there are still some structural and technical limitations and pitfalls to integrating fcms with other models voinov and shugart 2013 one of the challenges in building ccms is to ensure that after plugging the pieces of software together the produced knowledge is scientifically coherent in order to ensure coherence the different system components should be brought to compatible resolutions with respect to data scales and uncertainty it seems that ensuring conceptual and scientific consistency is an overlooked issue in fcm based ccms as there is no indicator on how these ccms ensure compatibility among coupled components or how the information is exchanged between components to allow legacy models to be incorporated in fact none of these integrated instances is designed to integrate legacy code but they rather interact in an input output fashion coherence issues are likely to be resolved mechanically by the development team responsible for the integration of components laniak et al 2013 for instance in order to be able to use fcms and the watergap model as complementary tools van vliet et al 2017 had to scale up and down between the fcm scale river basin and the watergap scales grid or country depending on variables despite the substantial resources going into these different implementations models are mostly used by their original developers they are not used beyond their respective development teams fcm based ccms are not developed to be reused and did not mature enough to be leveraged into integrated frameworks many best practices could be shared by increasing openness reproducibility and standardization of these models huppmann et al 2019 moreover we believe that the use of ontologies could play a significant role in harmonizing the semantic information and in providing a unified framework for building fcm based ccms voinov and shugart 2013 4 how to deal with fcm modeling limitations the major limitations of fcm modeling are related to the methodology of the approach itself in this section we discuss how fcm based integrated assessment applications deal with fcm limitations especially by adding spatial and temporal dynamics and nonlinear relationships 4 1 spatial and temporal dynamics environmental issues may operate at a variety of time poses days months or decades and spatial resolutions e g region forest river or basin although fcm simulations are run for many iterations before converging these intermediate steps do not represent dynamic time steps fcms do not have a temporal dimension and are not explicitly spatial this issue is usually solved in two ways the first approach is to build models that are independent of any scale assuming that all studied processes operate at the same temporal or spatial scale malek 2017 the second approach consists of building lumped models i e producing a single output for the entire modeled area or a time period such as by averaging bourgani et al 2016 park and kim 1995 from the reviewed case studies it is usually implied that the fcm model is spatially aggregated for a specific resolution or at best models few spatial units hence few studies consider possible system changes over different time periods or spatial distributions some authors coupled fcms with gis either to extract soil properties markinos et al 2007 or to produce thematic maps skov and svenning 2003 which can be used as a proxy to delineate management zones in spatial planning applications we also note that some case studies combined fcms and gis within a framework to derive the fcm structure using spatial information soler et al 2012 there are two main ways of integrating gis in integrated assessments either the analysis is carried within the gis or externally by linking the gis to the model this latter approach is the common method used with fcm case studies fcms can represent spatial concepts by coupling fcms with gis but not spatial heterogeneity although fcms are coupled with gis the coupling is loose as none of the approaches investigates the use of spatial nodes within the fcm maps to provide a more spatially explicit assessment of the studied system this is typical with other modeling approaches as well because gis and these methods do not integrate well due to fundamental incompatibilities in their conceptual representations fcms allow only producing static models among the reviewed applications few authors developed dynamic fcm models that are capable of capturing dynamic changes through time nikas and doukas 2016 designed a fcm model to estimate the impacts of climate change management policies and how soon they are likely to produce the calculated results the approach is based on the assumption that all relationships are yearly hence prompting the stakeholders for the number of year units for each causal relationship accordingly a new simulation function was proposed to include the delay notion by multiplying the weight of a relationship with the activation value of the cause concept minus the time delay of the respective causal link towards the same end biloslavo and dolinšek 2010 also developed a fcm time extension to perform dynamic simulation of the world s climate development the authors took a different approach by considering time delays between a cause concept and its effects as a time function four function types are considered namely step linear concave convex and sigmoid simulation with these fcm time extensions can be carried until a time horizon objective is reached 4 2 nonlinear dynamics the second major shortcoming of fcms is that they focus on depicting causalities between system variables rather than effects or rates of change a link represents a fuzzy causal relationship between two concepts and fcm inference allows drawing conclusions about what is caused and what is not caused which provides a resolution for indeterminacy in cognitive maps calais 2011 however fcms have been heavily used in the literature beyond the simple propagation of causalities modelers have used fcms as sd models where the links represent the magnitude of change induced by one concept on another one nevertheless despite the fact that the graph represents a sd system the developed models used causality related features of conventional fcms helfgott et al 2015 mourhir et al 2016 first these implementations make use of fuzzy binaries to quantify the influence exerted by one concept on another by forcing the link s weight into a static value in the range 1 1 the fcm s structure hence models monotonic and symmetric relationships which may overlook the complex dynamics of the studied system carvalho and tomé 2009 fcms are not dynamic models and do not allow the modeling of nonlinear relationships in a dynamic model the weight is a mathematical function of other factors influences and there is no reason why it should be a static value furthermore rather than representing units a fcm models the extent to which concepts are present or not which might constraint the interpretation of the results for example the method cannot be used for predicting real valued quantitative outputs so the model and its outcome can only be interpreted qualitatively whereas variables in a sd model map to a universe of discourse within their maximum and minimum state limits moreover due to their structural limitations fcms are not intrinsically stable fcm models might not be able to maintain the stability of the original real world system causing a theoretically unstable fcm to converge mainly due to the use of squashing functions and the use of bivalent or trivalent concept values carvalho and tome 2002b few authors worked and presented some examples with case scenarios in the literature on dynamic fcm mechanisms among the first to reveal the several shortcomings of conventional fcms that can be overcome by using rule based systems are carvalho and tome 2000 and khan and khor 2004 mourhir et al 2016 also proposed a dynamic rule based fuzzy cognitive map drbfcm as an alternative to sd by combining the properties of fcms and fuzzy inference systems fiss to model nonlinear relationships and sort out the abovementioned limitations aguilar and contreras 2010 introduced a dynamic fcm approach based on mathematical equations which can only be useful if a cognitive map is connected to a real system where causal relationships have been modeled using mathematical equations aguilar 2013 in rule based fcm approaches fuzzy logic facilitates the representation of nonlinear cause effect relationships they can adapt influence weights by mapping dynamically causal node states to effect node states using if then rules ross 2009 aside from the capacity to represent nonlinear relationships using the rules they operate on real values which makes them suitable to predict real values as output unlike auto associative neural networks that normalize all values between 1 and 1 rule based fcm models allow reasoning in terms of deterministic system variables states computed using quantified perturbations produced by fuzzy inference since they add true fuzziness to fcms by using fuzzy logic zadeh 1965 they can be used as a natural interface to capture human beliefs and expertise and as a technique to solve knowledge ambiguity usually faced in multidisciplinary systems they support the same type of applications featured by conventional fcm models they are not explicitly spatial or temporal but like traditional fcms they can be designed for a specific spatiotemporal resolution and the use of rules can make it easy to express time in qualitative system dynamics carvalho and tome 2001 in addition to that these models maintain the properties of the modeled system since they reflect the understanding and findings about the dynamics of the real world system and concept values are not randomly altered by squashing functions hence stability is more inherent to the original real world model carvalho and tome 2002a contrarily to conventional fcms rule based fcms also improve the interpretability of fcm models as they generate outputs that can be interpreted by tracing the rules that contributed to the results however rule based fcms tend to get complex and might suffer from rule explosion as the number of concepts increases drbfcm is the only rule based fcm modeling technique that was applied as an integrated environmental assessment method in a policy development exercise to investigate the impacts of several mixes of emission abatement strategies on air pollution mourhir et al 2016 a variant of drbfcm used to highlight spatial variability in a precision agriculture application emphasized that the rules were useful in describing nonlinear causal relationships for nitrogen recommendations mourhir et al 2017 particularly nitrogen is required in relatively large amounts by cotton plants however too much nitrogen might have a negative impact as it can delay crop maturity and can be consequently harmful to cotton production 5 update of the framework to select the most appropriate modeling approach kelly et al 2013 developed a framework that can be used by modelers to choose the appropriate integrated environmental modeling approach using considerations such as the type of available data to build a model handling of uncertainty whether the focus of the model is to represent depth in specific processes or breadth of the whole system model purpose and the type of processes of interest such as interactions between individuals generation of aggregated system effects and support of feedback loops we refined the framework in a couple of ways first we distinguish between whether the model can handle uncertainties that are basically stochastic probabilistic or subjective in nature ambiguity and vagueness or due to lack of knowledge when individuals are involved we might be interested as well in aggregating their knowledge to build larger knowledge bases in the updated framework we differentiate between models that can support group modeling in a participatory setting and models that have the capacity to compute and generate aggregate system complexities table 6 summarizes how the different approaches perform with regard to the considered modeling criteria in table 6 crosses denote the standard practices and uses extra properties that can be developed as extensions are denoted with stars the updated guiding framework that can be used by modelers to choose the most appropriate modeling approach is also represented in the form of a decision tree in fig 3 assuming a standard application aside from the capacity to support uncertainty due to ambiguities and ill defined variables feedback and integration of both qualitative scenarios and quantitative information fcms are particularly useful in a participatory approach as an elicitation tool that allows capture and sharing of individuals knowledge and as a simulation tool to support the decision making process by fostering system thinking although they do not provide any particular mechanism to model individuals behaviors they have been successfully coupled with abm modeling to overcome this limitation like the other approaches the holistic system thinking of integrated assessment is not technically emphasized by fcm models but implied considering that fcm modeling usually integrates interdisciplinary participants compared to other modeling approaches fcms are similar to network based approaches because they build on graph theory they focus on perceptions of stakeholders which would allow linking them conceptually to abms and can represent system dynamics in a close way to sds sds and fcms are similar in their potential to increase our system understanding and to foster social learning these models focus on exploring and investigating how the future may develop using proactive alternative scenarios rather than on providing accurate predictions about a variable s quantity both sds and rule based fcms are capable of representing nonlinear relationships developing integrated environmental assessment models typically made up of many equations like with sds is a challenging task as much of the system s behavior should be described using mathematical equations the complexity of the model might be intimidating and prohibiting for lay experts participation especially when the number of considered interactions and feedback loops is high these models based on mathematical equations are not only hard to develop but also hard to understand in terms of interactions and to interpret in terms of outcome users might employ these models in a black box fashion hence the risk of creating a veneer of scientific legitimacy if the results are used in a policy analysis exercise or to support decision making pindyck 2017 knowing that most ecological and environmental knowledge does not always take the form of numerical or mathematical formulations we believe that the use of fcms and in particular rule based fcms might be valuable in applications where there is a need to study system dynamics by incorporating qualitative knowledge that cannot be expressed in the form of equations knowledge expressed in the form of rules is more intuitive than mathematical modeling and can be easily understood and traced to interpret the produced results when the modelers are interested in behavioral characteristics of entities in their interaction with the studied environment abms are the most appropriate modeling approach however unlike models built around networks such as fcms or sds where the top level structure makes the mental model explicit and highlights the feedbacks in abm systems modelers would encode the feedbacks in the rules governing the different agents wang et al 2018 fcm models are similar to kbss they can typically be used to provide support to decision makers and managers in complex environmental problems under uncertainty similarly to kbss especially rule based expert systems producing a robust rule based fcm model with enough cognition to interrogate the different facets of a system will result in increasing its complexity the more concepts added to the model the higher the number of if then rules to be elicited from experts to model the system s complexities and to be evaluated by the model the process of knowledge acquisition is deemed to be intensive and time consuming due to the many steps involved during the different stages and the entailed cognitive effort to collect domain knowledge similarly to all types of expert systems fcm approaches can encode subjective misjudgments and wrong speculations of the parties involved in the modeling process however the knowledge based approach in these techniques remains defensible as it can capture knowledge that will be hard to formalize differently considering the complexity of integrated assessment applications technically it can be argued that rule based fcms and rule based kbss have many properties in common and can be used interchangeably however there are some differences to discriminate between the two approaches fcms have a pre built capacity to account for feedback while other tree based expert systems do not rule based kbss have the capacity to capture compound conditional events between influencing variables using conjunctions and disjunctions fcms cannot unlike the conventional participatory approaches narratives questionnaires and surveys modeling approaches such as bns and fcms are relatively easy to understand semi quantitative methods that take a further step in involving stakeholders by formalizing the collected knowledge in a logical framework with an emphasis on drawing mental models and making them explicit these approaches aim at collecting characteristics of the studied system using causal relationships organized into a graph structure hence they allow a smoother integration of collected knowledge into simulation models bns and fcms can both use qualitative information quantitative data or both they have some affinity especially in their transparent graphical representation which is simple particularly for non expert users however the lack of support for feedback in bns might hinder their application in integrated environmental assessments also and due to their methodological construct bns are rather descriptive than causal they can only reveal the occurrence of events in contrast to simulation based approaches like fcms they may not be able to describe the process leading to the event environmental modelers understand that there is a significant amount of uncertainty inherent to environmental models handling of uncertainty in integrated environmental assessment is usually performed by assigning probability distributions to certain key parameters bns can handle incomplete data and the use of probabilistic relationships makes the method suitable for stochastic uncertainty when models based on probability are used formally involving stakeholders during model development might be a challenging task considering that they are required to provide specialized knowledge however specifying a probability based on prior and observed facts might not be intuitive nor straightforward moreover the use of probability distributions to handle uncertainty due to randomness makes it difficult to cope with other forms of epistemic uncertainties namely ambiguity and vagueness which are strongly present in participatory modeling for example the design of future change scenarios will usually contain various interpretations that can be attributed to the use of imprecise linguistic descriptions of socioeconomic interactions on the part of stakeholders the use of fuzzy logic with fcms makes it particularly easy to include qualitative representation of knowledge and handle ambiguities inherent to modeling with stakeholders fcm models handle better ambiguity and vagueness but they are based on the assumption that the modeler knows all causal relationships between entities however with fgcms one can further handle partial or total epistemic uncertainties using grey theory the literature shows that both fcms and rule based fcms can be applied to a variety of different problems however in general integrated assessment models have characteristics in favor of the application of rule based fcms qualitative expert knowledge the nonlinearity of system relationships and the absence of adequate mathematical models the combination of qualitative scenarios and fuzzy logic in rule based fcm models forms a particularly useful supplement to the tools for modeling integrated systems the choice between fcms and rule based fcms should primarily be based on the degree of domain knowledge about the system to be described and the nonlinearity of relationships the estimation of quantitative threshold values for the variables and the description of causal relationships in the form of if then rules necessary for the rule based fcm approach may complicate the satisfactory representation of social science or policy concepts in that case the application of traditional fcms may be more appropriate no mathematical concepts are required except for simple matrix algebra and the model can be as complex as desirable without complicating the calculations understanding complex systems is sometimes best done with formalizations that are rather simple more advanced approaches can then be sought using sophisticated models shall data becomes available moreover choosing between fcm and rule based fcm modeling would also depend on constraints such as the time scope and budget quantitative models can produce accurate predictions and can potentially make temporal forecasts of certain quantities however the task of parameterizing and calibrating a model may turn out to be difficult and costly semi quantitative models designed using fcms though they might only produce equilibrium outcomes are useful in systems where interactions are characterized by approximate or imprecise information ramsey and norbury 2009 on the other hand fcm models are appropriate for systems ruled by equilibrium conditions they might not be suitable for systems characterized by altered patterns due to high variability and which may never settle in an equilibrium state 6 conclusions in this paper we reviewed fcm applications in the field of environmental assessment and management with the aim of exploring the potential of fcms as integrated assessment models in our opinion different fcm approaches can successfully support many aspects of integrated environmental assessment and significantly contribute to the field although they are not best suited for producing accurate predictions like quantitative systems they are particularly instrumental in complex decision making processes with nonlinearities and approximate information about the underlying system interactions and which are characterized by feedback and equilibrium conditions with fcms we would use expert opinions to craft simple transparent and easy to understand models although simple models might not convey the kind of scientific legitimacy message that might be expressed by large scale models they help us to clarify stakeholder knowledge and beliefs about the studied issues and they make sense of complexity through a structured framework that is capable of producing credible outcomes by comparing and evaluating alternatives through scenario analysis along with fcm potentials as an integrated assessment tool we discussed some of the method s limitations including the representation of spatial and temporal dynamics and nonlinear cause effect relationships many of the reviewed applications could successfully overcome these limitations by coupling fcms with other modeling approaches or natural and economic models or by developing new extensions one of the main motivations behind integrated assessment is the promise of real transdisciplinary model integration although fcms do not provide any specific mechanism to build an integrated assessment application they have been integrated with other modeling approaches to leverage their combined strengths we believe that using an integral approach by combining fcms with other models and using ontologies would perhaps be a realistic approach to produce transdisciplinary models that not only inherit the properties of their pieces but will produce systems that can bring new insights that might not be gained by the sum of the parts more stakeholder involvement throughout the whole environmental modeling process would also be essential to ensure coherence between transdisciplinary models and the credibility of scenarios by enhancing communication between disciplines the relatively low uptake of fcm approaches by environmental modelers might be due to the fact that the method is relatively new and the recent advances in fcm modeling temporal dynamics stability handling nonlinear relationships have not been leveraged yet in an integrated framework that shall pave the floor for a broad audience of practitioners in the field of integrated environmental assessment there are two main takeaways from this work first fcms can be used as the starting point of any research as a tool to map out perspectives and potential system sensitivities before applying other models especially in wicked environmental problems that are complex involve many parties and have no straightforward solutions second they can significantly support integrated assessment applications by supplementing quantitative model approaches which are invariably constructed around one perspective that relates to available data with qualitative information derived from a structured stakeholder engagement process considering the systemic nature of integrated assessment applications one should be opened to insights that can be gained from fcm analysis which could be missing in scientific studies focusing on one dimension e g ecosystem approach that usually exclude the less quantifiable links and feedbacks which reduces the capacity of the model to integrate all aspects of the real world system in this regard fcms are likely to translate better the processes occurring at broader scales and inform decision makers especially in a data poor environment where even highly uncertain predictions can provide value for a wide range of decisions we hope that this article could shed light on the salient features of fcms to raise even more interest among integrated environmental assessment practitioners to adopt and adapt the method in the design of their integrated assessment applications declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment we would like to thank the reviewers for their helpful comments and insightful input appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104891 
25898,we review concepts that have been used to address uncertainty in integrated modeling although conceptual approaches to tackle uncertainty seem diverse a synthesis reveals more similarities than differences in the concepts published especially if one adopts a model application oriented focus given our findings we slightly adapt the uncertainty framework table uft developed by walker et al 2003 and apply it for an existing integrated modeling framework for the bio economy the use of color coded ufts with a graphical visualization of uncertainty propagation pathways has facilitated a better overview and communication of uncertainties and uncertainty propagation pathways among the authors systematic consideration of uncertainties in integrated modeling may allow for more trust in model results and if simulations are conducted for a better robustness check of policy interventions keywords uncertainty concept uncertainty framework table uncertainty propagation integrated modeling bio economy 1 introduction uncertainty analysis is essential for identifying robust business strategies and policy interventions e g climate adaptation or mitigation measures information on location type and nature of uncertainty increases the transparency of and confidence in scientific analyses by researchers decision makers and stakeholders gabbert et al 2010 uncertainty analysis is generally required for scientific publications of model based quantitative assessments troost et al 2015 and is considered a good modeling practice jakeman et al 2006 integrated model assessments are useful to guide complex business or policy decisions in unprecedented situations rotmans and van asselt 2001 and are employed for studying real world problems that cross disciplinary boundaries laniak et al 2013 many applications of integrated modeling are found in the global change research community moss et al 2010 here we define integrated modeling similar to laniak et al 2013 as an interdisciplinary system of linked empirical datasets and mathematical models that are based on disciplinary theories 1 1 our definition aims at subsuming similar concepts such as integrated environmental modeling iem integrated assessment modeling iam and so forth see box 1 in laniak et al 2013 for an overview although differences exist e g iem are often natural science based whereas top down iam are centered around macro economic models they all have in common the linkage of disciplinary models i e frame workers matott et al 2009 usually integrated modeling is motivated by real world problems e g flood control climate change environmental pollution sustainable economic growth to identify either adequate optimal or robust policy options or consequences of policy options along multiple dimensions and indicators the overall structure of a specific set of integrated models can be referred to as an integrated modeling framework epa 2009 compared to disciplinary approaches integrated modeling can provide a more holistic picture and adequately represent human environmental interactions van ittersum et al 2008 thus they are expected to identify realistic business strategies and policy interventions that provide a balanced outcome between alternative development objectives considering changing socio environmental conditions rounsevell et al 2012 integrated modeling is no panacea disadvantages include communication difficulties across disciplines and between scientists and stakeholders lack of interoperability between disciplinary models i e semantic ontological and technical differences and typical methodological challenges of complex uncertain and computational demanding modeling systems sohl and claggett 2013 some methodological problems have been addressed in the integrated modeling community for example semantic and ontological issues e g janssen et al 2011 lack of stakeholder participation and challenges in communication e g gabbert et al 2010 hewitt et al 2014 mitter et al 2014 inadequate model linkages e g ewert et al 2011 2009 helming et al 2011b as well as the development of more appropriate analytical concepts e g helming et al 2011a uncertainty is a major challenge for integrated modeling and may materialize and accumulate throughout an integrated modeling framework existing integrated modeling frameworks tackle uncertainty mostly in two ways first uncertainty of future developments is often addressed through scenarios moss et al 2010 reilly and willenbockel 2010 i e alternative descriptions of internally consistent possible futures mitter et al 2019 van der heijden 2011 second uncertainty related to different data sources and model designs e g elliott et al 2014 nelson et al 2014 is addressed by systematic model comparisons within the scientific community e g the inter model comparison projects isi mip warszawski et al 2014 and agmip rosenzweig et al 2013 with contributions by members of this research team folberth et al 2019 rosenzweig et al 2014 relatively little effort has been dedicated to comprehensively identify and trace uncertainties in integrated modeling i e how uncertainty propagates between models bastin et al 2013 while such analysis was already identified as an important research gap in the early stages of integrated modeling rotmans and van asselt 2001 subsequent studies mostly defined and classified the myriad sources of uncertainty and identified and quantified the potential of cascade effects wilby and dessai 2010 however a few notable exemptions exist specifically for the uncertainty propagation from climate change models to crop models to land use optimization models holzkämper et al 2015 karner et al 2019 mitter and schmid 2019 one possible explanation for the scarcity of uncertainty propagation analyses in integrated modeling is its data computer and human resource requirement the development of an integrated modeling framework typically requires effort to modify individual models establish and improve model linkages and apply the integrated modeling framework to specific research questions in contrast to disciplinary modeling where these issues might also exist integrated modeling teams typically come from different institutions working together temporarily this makes the establishment of e g mutual modeling software platforms or databases even more challenging further limiting the availability of resources that can be dedicated to uncertainty propagation analyses although quantitative uncertainty analyses for integrated modeling are scarce suitable uncertainty concepts are available however the landscape of publications on uncertainty concepts is still fragmented first many publications originate from specific disciplinary backgrounds e g water management geography land use economics nature conservation or environmental risk assessments second there is some disagreement on how to define conceptualize and communicate uncertainty for example see the correspondence between norton et al 2006 and von krauss et al 2006 on the uncertainty framework table uft developed by walker et al 2003 as well as the general criticism of skinner et al 2014 on existing concepts these studies discuss the inherent subjectivism of the concepts developed and the omission or implicit weighting of specific aspects e g linguistic uncertainty non statistical methods extrapolation and user perspectives section 5 contains a more detailed review and discussion of these aspects this paper aims to 1 review uncertainty concepts for integrated modeling with focus on real world problems 2 analyze for each uncertainty concept the applicability to deterministic bottom up 2 2 notably most integrated modeling frameworks are deterministic and do not take uncertainty into account by default this is particularly the case for relatively large integrated modeling frameworks we thus focus on how to deal with uncertainty in deterministic integrated modeling i e uncertainty propagation this has to be distinguished from stochastic models which can integrate information on probability to obtain optimal decisions under uncertainty kann and weyant 2000 bottom up is thereby defined as a detailed representation of production technology choices and a detailed spatial representation of the heterogeneity of resource endowments in contrast top down refers to the use of aggregate production functions integrated modeling frameworks for assessments of bio economies henceforth labeled imf be 3 adapt general uncertainty concepts to our specific integrated modeling context and 4 apply the adapted concept from 3 to identify uncertainties within an established imf be regarding the second objective a concept is judged applicable by us if it i provides a comprehensive as well as a concise overview of uncertainties and uncertainty propagation in an integrated modeling framework ii can be used to identify and highlight uncertainties and uncertainty propagation pathways from a modeler s perspective and iii increases transparency and uncertainty communication between scientists the uncertainty concept used for communication should thereby be easily understandable without sacrificing scientific accuracy the uncertainty concept aims to be generic and flexible enough to allow for its application for other integrated modeling teams moreover our findings will provide the conceptual basis for quantitative uncertainty propagation analyses with an established imf be what we explicitly do not address is on the one hand how to quantify or reduce uncertainties in integrated modeling and on the other hand how to communicate uncertainty or risk such as the ipcc treatment of verbally communicating probabilities mastrandrea et al 2010 our review and application remain on a conceptual level i e how we can think about uncertainties and how to identify them qualitatively in integrated modeling this article is structured as follows section 2 provides and discusses definitions of uncertainty section 3 reviews relevant literature on uncertainty concepts and provides an adapted version of the uncertainty framework table uft developed by walker et al 2003 in section 4 we identify uncertainties and uncertainty pathways for an established imf be by applying the adapted uft and a comprehensive system graph this is followed by a discussion section 5 as well as conclusions and outlook section 6 2 defining uncertainty intuitively uncertainty could mean that complete information about something is lacking for example currently no one can predict accurately if climate change will lead to increases or decreases in crop yields in austria until 2050 one may be quite certain that yields of a specific crop will decrease or increase in some sub regions of austria e g grassland yields in humid regions are likely to increase in existing climate change scenarios whereas crop yields in semi arid regions are likely to decrease without irrigation measures but to pinpoint the exact change will be mere impossible given the plethora of uncertain and unknown factors that influence this outcome moreover many people associate uncertainty with outcomes represented in terms of confidence intervals upper and lower bounds probability density functions box plots or means and standard deviations knight s 1921 famous differentiation between risk i e measurable uncertainty and true uncertainty i e situations where probabilities are unknown can be seen as an initial spark to think about uncertainty in broader aspects hence current uncertainty definitions and concepts are more nuanced and often provide a full taxonomy of uncertainty concerning different characteristics such as why it exists if and how it can be expressed and where it manifests the seminal publication by funtowicz and ravetz 1990 highlights the need to extend the focus of quantitative uncertainty analyses to qualitative social science e g science policy interface for decision making and stakeholders interests this is because modeling results are often viewed and used as scientific knowledge to guide decision making for real world problems e g flood protection nitrogen emissions in agriculture food safety climate change mitigation which is particularly the case for integrated modeling laniak et al 2013 the eu water framework directive for example explicitly demands uncertainty be addressed in water management plans brown 2004 sigel et al 2010 hence uncertainty concepts that have been developed by modeling and integrated modeling teams with focus on real world problems primarily provide guidance at the science policy interface generic definitions from this point of view thus depart from a positivistic natural science perspective i e statistical probability but aim at a compromise between natural and social sciences in order to increase comprehensibility they focus on subjective levels of confidences brown 2004 kann and weyant 2000 with respect to model outputs and the knowledge generated by applying them e g lack of confidence in our knowledge sigel et al 2010 p 502 3 3 both lack of confidence in our knowledge i e uncertainty and lack of knowledge make it difficult to decide what is best lack of confidence in outcomes refsgaard et al 2007 p 1546 4 4 a person is uncertain if s he lacks confidence about the specific outcomes of an event reasons for this lack of confidence might include a judgement of the information as incomplete blurred inaccurate unreliable inconclusive or potentially false lack of confidence in model outputs kann and weyant 2000 p 29 5 5 in addition to clarifying the assumptions on model inputs modelers should be more explicit about their level of confidence in model outputs this implicitly or explicitly accounts for the social processes in which knowledge has been generated by acknowledging the subjectivity of the researchers and thus of the generated knowledge uncertainty is thus seen as the spectrum between two contrasting states of subjective confidence i e certainty on the one hand and total lack of knowledge total ignorance on the other with a diverse continuum of limited knowledge van asselt and rotmans 2002 ignorance is sometimes viewed as distinct from uncertainty especially if defined as being unaware of imperfect knowledge brown 2004 nevertheless considering that one may be aware that he may be unaware of imperfect knowledge i e acknowledging the existence of a void brown 2004 it is sometimes subsumed as part of uncertainty labeled recognized ignorance walker et al 2003 or accepted ignorance faber et al 1996 finally knowledge can be further classified into knowledge about the probability of an outcome and knowledge about possible outcomes where uncertainty may be unbounded if not all outcomes are known brown 2004 for example we may know with some confidence the likely impact an unprecedented quarantine has on the spread of a virus in a population employing state of the art agent based models i e probability of an outcome but we might be currently unaware of other outcomes regarding social economic environmental or psychological issues i e total ignorance of an outcome there are also more generic definitions available such as the one provided by walker et al 2003 p 8 which aims at encompassing all possible aspects of uncertainty by defining it as any departure from the unachievable ideal of complete determinism 3 a model application oriented uncertainty concept for integrated modeling to gain a more comprehensive insight into uncertainties of integrated modeling and to facilitate better communication among scientists decision makers and stakeholders many modelers have tried to develop uncertainty concepts that encompass possible characteristics perspectives dimensions or taxonomies of uncertainty see table 5 in appendix b from a modeler s perspective these three following dimensions first conceptualized by walker et al 2003 provide a good starting point 1 the nature of uncertainty why does uncertainty exist 2 the type of uncertainty how can uncertainty be expressed 3 the location of uncertainty where does uncertainty manifest in a single model and in an integrated modeling framework although not all publications reviewed explicitly frame uncertainties along these dimensions often their concepts can be attributed to at least one of them considering our findings which are presented in the subsequent sections we suggest the following model application oriented uncertainty framework table uft in table 1 importantly we take the initial uft by walker et al 2003 and the adjustments by refsgaard et al 2007 as well as warmink et al 2010 as a starting point in addition to this uft our uncertainty concept also comprises color coding and the application of a comprehensive system graph to aid in the visualization of uncertainty propagation pathways see table 3 and fig 1 and in section 4 the following sections will elaborate on these dimensions and provide a succinct overview and assessment synthesis of the concepts and typologies identified in the literature we thereby follow a deductive approach building on theoretical concepts developed in the literature a more detailed review of concepts is provided in the appendix c 3 1 the nature of uncertainty why does uncertainty exist 3 1 1 overview the ultimate cause or nature of uncertainty is a central part of any publication that focuses on uncertainty concepts at an aggregate level there seems to be agreement on the differentiation between two primary causes of uncertainty 1 epistemic reducible uncertainty i e uncertainty due to lack of knowledge this refers to uncertainty which is due to lack of information and of understanding of the natural and human systems that encompass us theoretically epistemic uncertainty is reducible with further investigations and empirical research however gaining more and new information may not necessarily reduce uncertainty but reveal an even greater lack of understanding than previously assumed kann and weyant 2000 van asselt and rotmans 2002 2 stochastic irreducible uncertainty i e uncertainty due to the inherent variability of natural and human systems also labeled natural ontological phenomenological or aleatory uncertainty this refers to uncertainty that is practically irreducible such as natural variability e g flood events precipitation events or chaotic systems e g cloud behavior social dynamics although some authors argue that chaotic systems are basically deterministic it often remains too difficult to measure important variables e g initial states and thus to predict future outcomes this is famously depicted in edward lorenz s butterfly metaphor lorenz 1995 2000 many publications refer solely to these two primary causes of uncertainty matott et al 2009 refsgaard et al 2007 rotmans and van asselt 2001 uusitalo et al 2015 van asselt and rotmans 2002 walker et al 2003 whereas others include more for example linguistic uncertainty language i e uncertainty due to the imprecision of our language ascough et al 2008 regan et al 2002 decision uncertainty i e uncertainty in decision making due to different human value system ascough et al 2008 peterson 2006 ambiguous uncertainty i e the existence of different but equally valid expert knowledge expert subjectivity warmink et al 2010 or practical causes of uncertainty i e limited financial resources sigel et al 2010 3 1 2 comparison and synthesis we organize the various categories of the nature of uncertainty reviewed along a hierarchical structure see table 2 this structuring helps to highlight that most of the concepts in the literature reviewed can be amalgamated for a detailed comparison see appendix c and fig 2 as main categories we use the established differentiation between i epistemic and ii stochastic uncertainty these are differentiated by sub categories which include for instance linguistic uncertainty as well as specific causes such as value judgements we did not include practical causes of uncertainty as we see this aspect implicitly reflected in epistemic causes and it also relates to another conceptual issue i e identifying barriers for reducing epistemic uncertainty notably we do not see specific causes of uncertainty as being unique but as interconnected for example uncertainty in model input data may stem from natural variation natural variability stochastic imprecise measurements inexactness unreliability epistemic as well as lack of process knowledge process system understanding epistemic furthermore specific causes may interact e g lack of knowledge about processes causes or effects system understanding could mean that measurements are not being carried out correctly unreliability the epistemic sub categories unreliability inexactness lack of observations and practically immeasurable and structural uncertainty conflicting evidence reducible ignorance irreducible ignorance and indeterminacy are taken from van asselt and rotmans 2002 these causes point primarily to uncertainty typically located in data collection hence we explicitly also consider system understanding i e process cause and effect as proposed by skinner et al 2014 this is the fundamental knowledge on which theories models and integrated modeling frameworks are developed we agree with skinner et al 2014 that linguistic uncertainty and its subcategories identified by regan et al 2002 vagueness ambiguity underspecificity indeterminacy of theoretical terms and context dependence may be viewed as reducible at least to some extent and are thus part of epistemic uncertainty the stochastic sub category natural variability can be distinguished into inherent randomness e g chaotic systems and natural variations e g flood frequency regan et al 2002 human variability consists of values and subjective judgment i e mental models kann and weyant 2000 regan et al 2002 van asselt and rotmans 2002 as well as behavior institutions and technological breakthroughs ascough et al 2008 van asselt and rotmans 2002 we do not include extrapolation skinner et al 2014 in the nature dimension but see it as part of the location dimension see section 3 3 as it manifest usually when data is transferred to or between models skinner et al 2014 emphasize that extrapolation is the result of epistemic failures and stochastic uncertainty i e inherent randomness describing systems that are not irreducible to a deterministic one from our manifestation point of view it is thus adequate to treat it as a location i e the point where extrapolation takes place e g when one model output is transferred to another and to attribute the nature of uncertainty to several causes e g practically immeasurable unreliability epistemic and inherent randomness natural variability stochastic 3 2 the type of uncertainty how can uncertainty be expressed 3 2 1 overview from a modeler s point of view an important aspect is how uncertainty can be expressed i e the type of uncertainty some publications adopt the assumption that the most convenient way to express uncertainty is by quantification bastin et al 2013 kann and weyant 2000 expressing uncertainty through statistical methods e g frequentist or bayesian is the most common approach in modeling e g using probability functions bounds means or standard deviations however it is by no means the only way to express uncertainty walker et al 2003 further include scenario uncertainty i e outcomes are quantified but probabilities are not attached recognized ignorance e g lack of knowledge about mechanisms and relationships and total ignorance unknown unknowns all of which may not be statistically quantifiable refsgaard et al 2007 introduce in addition also qualitative uncertainty i e plausible possibilities e g linguistic probabilities warmink et al 2010 adopt the same types as refsgaard et al 2007 peterson 2006 further shows that statistically quantified uncertainty may also be expressed verbally e g the ipcc nomenclature on probability and rightfully highlights that many publications provide guestimate distribution e g a mixture of guessing literature review and estimation rather than true distributions refsgaard et al 2007 emphasize a notable relationship between uncertainty types and brown s 2004 uncertainty taxonomy which distinguishes between knowledge about probabilities and knowledge about outcomes if both outcomes and probabilities are known uncertainty can be expressed statistically if probabilities are unknown but at least some outcomes are known uncertainty can be expressed as a scenario if at least some qualitative uncertainties and at least some outcomes are known uncertainty can be expressed qualitatively furthermore the epistemic sub categories of funtowicz and ravetz 1990 rotmans and van asselt 2001 as well as van asselt and rotmans 2002 also bear some connection to the type of uncertainty statistical uncertainty is closely related to inexactness and lack of observation whereby qualitative and scenario uncertainty may be connected to practically immeasurable and conflicting evidence recognized ignorance is resembled by border with ignorance funtowicz and ravetz 1990 or practically immeasurable rotmans and van asselt 2001 van asselt and rotmans 2002 this dimension thus seems to be the one with the highest agreement in the literature reviewed although it is not explicitly addressed by many usually those that adopt a probability based approach and there are some overlaps with the nature dimension of uncertainty 3 2 2 comparison and synthesis the general types of uncertainty provided by refsgaard et al 2007 statistical scenario qualitative and recognized ignorance provide the most comprehensive overview without being too detailed we still propose that a more nuanced understanding and use of the term ignorance could provide added value for both modelers as well as for improving transparency and communication with stakeholders walker et al 2003 p 12 define recognized ignorance as fundamental uncertainty about the mechanisms and functional relationships being studied such a definition fits much better in the nature dimension of uncertainty than in the type dimension since the type dimension is concerned about how uncertainty can be expressed this seems not very helpful a more appropriate definition if applied in the type dimension could be acknowledging that uncertainty in some processes is ignored due to lack of knowledge in addition if taken more literal ignorance could mean that researchers deliberately ignore certain rather well known mechanisms for example detailed trade patterns in single country studies this often results from the assumption that the added knowledge value of including certain processes is not worth the costs for including them e g system boundaries need to be defined see section 3 3 given computational and resource constraints or it may be advantageous to keep a model ignorant of e g an uncertain process if this pushes the model to extreme and unrealistic boundary solutions akin to van asselt and rotmans 2002 levels of limited knowledge ignorance could be phrased we know what knowledge we ignore hence we think it could be useful to also include this kind of deliberate ignorance i e acknowledging that rather well known processes are not accounted for in the type dimension and to put it together with recognized ignorance i e acknowledging that uncertainty in some processes is ignored due to lack of knowledge total ignorance by definition cannot be highlighted as this refers to unknown unknowns ignorance could also be categorized as a nature of uncertainty just as sigel et al 2010 did with their category of practical uncertainty which is very closely related to our concept of deliberate ignorance still we prefer ignorance to be attributed to the type of uncertainty as this is how it is ultimately expressed by simply acknowledging what we did not account for it and ideally providing arguments why this is the case hopefully such transparency leads to increased trust and accountability by research peers and stakeholders notable statistical uncertainty can be interpreted widely including both frequentist or bayesian approaches as well as methods that are not purely statistical e g semi quantitative approaches such as rough sets or fuzzy sets this should accommodate the reasonable criticism by norton et al 2006 that the category statistical uncertainty may omit such approaches 3 3 the location of uncertainty where does uncertainty manifest in a single model and in an integrated modeling framework 3 3 1 overview the location of uncertainty is an ambiguous term and is interpreted differently in the publications reviewed there are those that define the location of uncertainty as the ultimate cause nature of uncertainty e g measurement errors in field experiments e g ascough et al 2008 bastin et al 2013 skinner et al 2014 and those that define the location of uncertainty as its manifestation within a model or modeling framework e g input data model structure outcome e g matott et al 2009 van asselt and rotmans 2002 walker et al 2003 warmink et al 2010 we define in accordance with walker et al 2003 the location of uncertainty as the location where uncertainty manifests in the model or modeling framework this helps modelers in identifying where uncertainty has to be addressed within a model or integrated modeling framework it will however remain difficult to provide a clear distinction between the ultimate cause nature and manifestation for example model structure can be seen both as a cause e g real processes are not fully understood and as the location where uncertainty manifests i e in the mathematical formulation of the model setting the differences between cause and manifestation aside our literature review has shown that there is much agreement on the potential locations of uncertainty manifestation within an individual model at an aggregate level there are at least three major locations 1 context 2 model and 3 outcomes although many include 4 inputs data next to model and some highlight 5 parameters calibrated data or 6 technical implementation more precise locations are available for these major categories and although there are differences in the literature with respect to the number of sub locations and probably slightly different understandings of individual location names most align quite perfectly there seems to be more disagreement with the practically irrelevant classification of individual locations to aggregate location categories detailed information and comparison between the different concepts for the location dimension is provided in appendix c and fig 3 3 3 2 comparison and synthesis similar to most other concepts we characterize four major locations where uncertainty manifests in the model or modeling framework 1 context 2 inputs 3 model and 4 outcome we think that these four major location categories represent very different phases in the modeling process i e the conceptualization phase context data collection inputs model implementation model as well as model linkage and evaluation outcome 3 3 2 1 context in contrast to walker et al 2003 and refsgaard et al 2007 we not only consider system boundaries but also system resolution for the category context drawing on the category of resolution by matott et al 2009 and representation by bastin et al 2013 although the two latter publications consider system resolution to be located in the model category we think that it fits better into the conceptualization phase and thus the context category the spatial time or technology resolution for integrated modeling is usually considered and decided in the conceptualization or problem framing phase system boundaries refer to the selective systems that one considers within integrated modeling e g agricultural and forestry land use but not commercial or residential land use or the number of economic sectors actors considered in the analysis van asselt and rotmans 2002 system resolution aspects then define the locations temporal horizon and technology options within the chosen systems e g whether land use is modeled at 1 km or 500 m grid resolution whether land use choices are stratified annually or seasonally in the model or which land use management technologies are available the general objectives of integrated modeling for example capturing human environment interactions in the agricultural land use system are implicitly acknowledged in this category as the objective defines the boundaries of the model system 3 3 2 2 inputs the inputs category consists as suggested by walker et al 2003 of system data and system drivers this distinction is especially useful for integrated modeling as they often provide policy simulations for the mid term or even the long term future system data represents empirical data used to define initial states for the base year s and system drivers represent the development of the system external driving forces such as costs technology policy changes economic progress or demographic developments 3 3 2 3 model although parameters and data are often seen as synonymous in the modeling context there is a clear distinction in the uncertainty literature here parameters are defined as data that is calibrated usually to fit model outputs to observed or reported data this can be done for example by maximum likelihood estimations e g ols calculating constants in behavioral estimations to fit observations or the estimation of unknown cost parameters by applying the positive mathematical programming pmp methods heckelei et al 2012 howitt 1995 parameter calibration usually demands an initial model run so it is often subsumed under the location model e g ascough et al 2008 bastin et al 2013 refsgaard et al 2007 of course parameterization also heavily depends on the system data so highlighting it as its own major location may be quite warranted as well e g walker et al 2003 warmink et al 2010 however we opted to include parameters in the category model in order to minimize the number of aggregate locations other important sub locations within the model category are model structure and hardware software which refers to the technical implementation the model structure encompasses all endogenous processes kann and weyant 2000 and therefore the mathematical formulation of the system of interest definitions calculations equations algorithms walker et al 2003 it is thus closely linked to context as this is where the general relationships and processes to be considered are determined warmink et al 2010 hardware software encompasses coding software and hardware aspects walker et al 2003 this also includes the choice of algorithms and their option settings as well as the imprecision of numerical solvers there is no precise agreement in the literature whether algorithms and their imprecision belong to the location model structure van asselt and rotmans 2002 walker et al 2003 or model hardware software matott et al 2009 warmink et al 2010 3 3 2 4 outcome the location category outcome differs the most from the initial concept by walker et al 2003 their category model outcomes relates to the overall impact of all other uncertainties on model outcomes that are relevant for policy or decision making in the context of integrated modeling model outcomes gain further importance for capturing uncertainty propagation in integrated modeling we therefore recommend to split the category outcome into two different aspects both of which implicitly rely on the overall model outcome i e linkage extrapolation and decision support uncertainty skinner et al 2014 linkage extrapolation because model outputs often need to be extrapolated as a input for other models in the modeling framework or b for the criteria indicators used for evaluation or decision making furthermore decision support and evaluations of model outomces are made not only with respect to the uncertainty inherent in the final model outcome indicators but also with respect to different values and thus weights attributed to different decision criteria this should also be reflected and implicitly accounts for the propagated uncertainty at this point two uncertainty concepts that are closely related to decision support uncertainty are used by the ipcc paradigmatic uncertainty and translational uncertainty kunreuther et al 2014 paradigmatic uncertainty is caused by disagreement on problem framing and methods while translational uncertainty occurs when disagreement on scientific findings allows supporting contrasting policy options they are important concepts at the core of the science policy interface but become relevant before paradigmatic or after translational the modeling process hence their usefulness for identifying uncertainties in integrated modeling is rather limited from a model user s perspective and we therefore do not include them 4 identifying uncertainties and uncertainty propagation in integrated modeling here we want to test the usefulness of the presented uft for integrated modeling including the application of color coding and a comprehensive system graph to visualize uncertainty propagation pathways we use an established imf be which is briefly outlined section 4 1 to identify nature type and location of uncertainties as well as uncertainty propagation pathways section 4 2 4 1 an integrated modeling framework for the bio economy imf be the imf be examined here focuses on a primary supply sector of the austrian bio economy i e agriculture and its embedment in the global bio economy as well as other economic sectors in austria fig 1 aims to capture both the model linkages of our imf be as well as associated uncertainty locations uncertainty types and uncertainty propagation pathways the imf be connects climate data e g chimani et al 2016 the biophysical process model epic balkovič et al 2013 izaurralde et al 2006 williams 1995 an agronomic crop rotation model schönhart et al 2011b the global economic bottom up land use model global fasom schneider et al 2018 based on schneider et al 2007 the economic bottom up land use model biomat for austria feusthuber et al 2017 karner et al 2019 mitter et al 2015b stürmer et al 2013 and the macroeconomic environment energy model dynk for austria kirchner et al 2019 sommer and kratena 2017 climate variables impact crop and grassland yields simulated by epic epic further receives crop rotational input from the agronomic model croprota epic is applied to simulate crop yields factor use and agro ecological impacts at austrian 1 km and global scale 30 arcmin and is part of the international research initiatives agmip folberth et al 2019 rosenzweig et al 2014 and isi mip warszawski et al 2014 yield data from epic is then transmitted to the economic bottom up land use models global fasom global and biomat austria these models and dynk are also driven by changes in socio economic factors such as changes in population technological development and policies biomat receives changes in input and output prices from global fasom finally a feedback loop is implemented between biomat and dynk where biomat transmits changes in value added to dynk dynk then simulates domestic macroeconomic feedbacks from production or consumption changes in the agriculture sector and can feedback changes in wages and input prices to biomat 4 2 relevant uncertainties and uncertainty propagation pathways to provide a glimpse on possible uncertainty propagation pathways we include a non exhaustive list of pathways in fig 1 by applying the uft dimensions location and type to provide a better overview we omit the nature dimension the location category context as well as the type category ignorance in this figure for highlighting uncertainty propagation pathways in the uft as well we indicate by color and or font 1 if uncertainty is received from other models green 2 if output is propagated to other models purple and also 3 if uncertainty deliberately ignored in a single model has been addressed by other models in the modeling framework grey and cursive text uncertainties and uncertainty propagation pathways are identified with respect to their relevance for a the research domain of the bio economy and global change and b the individual models and the integrated modeling framework for example we focused only on relevant system boundaries for the bio economy by focusing on uncertainties and uncertainty propagation pathways judged relevant by the integrated modeling team we can keep the ufts concise and provide a better overview albeit at the cost of being non exhaustive the following sections describe uncertainty propagation pathways from fig 1 and the application of the uft from section 3 for the individual models table 3 in this section for biomat and table 6 to table 9 for all other models in appendix d 4 2 1 climate models since the model linkages in our imf be are mostly sequential we start with the identification of uncertainties at the beginning of the integrated modeling framework i e climate data we can access climate data from different general circulation models gcms which account for various representative concentration pathways rcps of greenhouse gases moss et al 2010 at global level and climate data from regional climate models rcms for austria i e the öks15 data set chimani et al 2016 regarding location uncertainty these data reflect model structure uncertainty application of different gcms and rcms and system drivers uncertainty application of different rcps both uncertainties are not quantified statistically hence they are expressed as scenario uncertainty all climate data is quantified but no probability values are attached the nature of this uncertainty is related to many causes such as enforcement of international and national climate policies human variability stochastic uncertainty chaotic systems such as precipitation events natural variability stochastic uncertainty or lack of observations to better validate model outputs unreliability and system understanding epistemic uncertainty 4 2 2 epic and croprota epic may incorporate these uncertainties by providing simulations for all available gcm rcp or öks15 rcp combinations i e by applying scenario analysis practically only few combinations are feasible to simulate which ideally should capture the bandwidth of all climate model and rcp simulation runs in addition different equations to simulate major biophysical processes are available in epic such as for potential evapotranspiration e g hargreaves baier robertson penman monteith water erosion e g usle onstad foster rusle soil temperature and soil water see doro et al 2017 which impact crop yields and agro ecological processes furthermore a range of values i e confidence intervals is provided for many function parameters by the model developers this considers uncertainty manifested in the model structure of epic location and is caused due to lack of system understanding as well as observations both epistemic uncertainty when choosing between different equations it remains difficult to compare the likelihood of one equation form with another to represent real life processes many forms of an equation may represent the same real life process given that they can be calibrated to observed values their fit may have as much to do with data uncertainty as with the form of the equation hence comparing the outcomes of different equations akin to model comparisons is best expressed as scenario uncertainty type and thus by applying scenario analysis furthermore croprota provides important information on possible crop rotations for the spatial simulation units in epic croprota utilizes expert judgments that help to rank the agronomic suitability of different crop rotations in order to obtain typical shares of crop rotations in a region or farm by maximizing the agronomic value schönhart et al 2011b although by default the model does not provide output in terms of probabilities it implicitly is affected by stochastic uncertainty i e the existence of different but equally valid expert value judgment this uncertainty is located in the system data and could be expressed statistically e g by applying bayesian s theorem or as a scenario furthermore these crop rotation shares are available at a coarser spatial resolution than needed for epic so they have to be distributed across different spatial units with different soil topographical and climate characteristics this introduces the uncertainty of linkage extrapolation location which is caused by lack of observations nature and may be expressed as a scenario or deliberate ignorance type finally data on soils topography and management options provide further location sources of uncertainty in epic potential other uncertainties not visualized in fig 1 can be seen in the ufts in table 6 and table 7 appendix d and mostly relate to uncertainties that can only be expressed as deliberate or recognized ignorance for example we know that epic accounts for major biophysical processes in agricultural land management on areas smaller than 100 ha system boundaries context location the spatial heterogeneity e g soils topography of a region can only be captured by delineating homogenous response units hrus 6 6 individual location units e g 1 km grid cells are clustered as hrus that share similar soil and topographical characteristics this reduces the amount of simulations particularly for global scale analyses and thus saves valuable computational resources albeit at the expense of losing some information and thus introducing uncertainty and simulating these independently system resolution context location the development of hrus is an established method in biophysical crop modeling to deal with heterogeneity e g balkovič et al 2013 strauss et al 2013 stürmer et al 2013 however the flow of water sediment and nutrients across hrus is not considered in epic deliberate ignorance of known processes model structure location there might also be errors in code and mathematical formulations currently undetected and unknown factors that affect plant growth water and nutrient cycles considerably finally the importance of outputs from epic may be valued differently by stakeholders and decision makers decision support outcome location such as crop yields or agro ecological impacts e g nutrient emissions all of the uncertainties identified and described above are propagated to the outputs of epic for example crop and grassland yields or nutrient emissions hence these outputs are affected by uncertainty located in model structure e g gcms rcms co2 fertilization effect system data e g expert judgement on agronomic value of crop rotations and linkage extrapolation e g extrapolation of regional crop rotation shares to spatial simulation units in epic which are caused by both epistemic e g lack of observations lack of process understanding and stochastic e g inherent randomness expert judgment values uncertainty and expressed as scenario uncertainty i e quantified but without probabilities 4 2 3 global fasom and biomat by transferring crop yield and agro ecological data to global fasom or biomat a linkage extrapolation location uncertainty manifests in the imf be e g the spatial aggregation to the simulation units of global fasom 7 7 biomat and epic share the same spatial resolution 1 km so there is no need for spatial aggregation between these two models or the temporal aggregation of annual outputs from epic to average annual outputs for a specific period e g 30 years for biomat this reduces the variability of epic outputs but may lead to an underestimation of uncertainty this uncertainty may be quantified statistically type and is caused inter alia due to pragmatic system simplification epistemic uncertainty as the application of hrus and periods instead of years eases computational burdens therefore yield data can be both expressed as a scenario uncertainty e g gcm rcm rcps co2 fertilization evapotranspiration management specifications crop rotation data and each of these scenario uncertainties can contain statistical uncertainty due to the necessary extrapolation to global fasom and all other statistical uncertainty in epic outputs mainly system data hence one could apply both scenario analysis as well as statistical methods for quantifying uncertainties propagated from epic global fasom and biomat also inherent all ignorance uncertainty from epic e g pre determined crop rotations and management options the economic bottom up land use models global fasom and biomat are further affected by location uncertainty in system drivers e g shared socio economic pathways ssps see for example riahi et al 2017 which provide inputs for population and technological development agricultural ssps for europe i e eur agri ssps are currently being developed mitter et al 2018 2019 2020 this is a typical case of applying scenario uncertainty and analysis i e plausible narratives of internally consistent futures are quantified the nature of uncertainty is diverse similar to the nature of uncertainty underlying the climate data see section 4 2 1 both models are also affected by the choice and imprecision of the numerical solver i e model structure and hardware software location for example allowing small negligible deviations from the optimal solution of optimization problems in a numerical solver may reveal that very different endogenous variable choices may lead to almost identical optimization values e g welfare but considerably different outcomes for other criteria e g emissions the nature of this uncertainty can be attributed to inexactness unreliability epistemic uncertainty but also value judgements human variability stochastic uncertainty the type of uncertainty may be expressed statistically qualitatively or as a scenario a further uncertainty located in the economic bottom up land use models is parameter calibration uncertainty for example the calibration of physical resource and commodity reference values global fasom or the calibration of unknown cost factors functions to fit endogenous model land use variables to observed land use data global fasom biomat the nature of this uncertainty is mostly due to lack of observations practically immeasurability conflicting evidence unreliability and structural uncertainty epistemic uncertainty as well as behavioral variability human variability stochastic uncertainty it may be difficult to express this uncertainty statistically especially if parameters are calibrated so that model outputs fit observed data exactly i e for a given model structure and input data the calibrated value has a probability of one parameter uncertainty is thus intrinsically linked to both model structure and system data if uncertainty in system data can be expressed statistically this can be transmitted to parameter uncertainty although there is always one true value for each system data sample furthermore many different realizations of cost functions are possible e g linear or polynomial cost functions of different degrees this can be incorporated as scenario uncertainty biomat receives not only the uncertainty inherent in crop yields and environmental outcomes from epic as well as the associated linkage extrapolation uncertainty but also the uncertainty in prices from empirical data as well as prices from global fasom commodity output prices and dynk input prices and labor costs extrapolation will be necessary as global fasom and dynk consider considerably fewer commodities than available in biomat and one has to assume that relative price changes in one commodity are similar to related commodities if empirical data is available correlation coefficients and associated uncertainty values could be used to incorporate this uncertainty statistical uncertainty however this task will also involve some kind of deliberate ignorance i e assuming that very specific commodities are reflected by an aggregate commodity index furthermore commodity prices and labor costs are also affected by scenario uncertainty propagated due to the scenarios run by dynk and global fasom a comprehensive overview of uncertainties also including context uncertainties location as well as deliberate and recognized ignorance type can be seen in the uft for biomat here table 3 and for global fasom in appendix d table 8 for example both global fasom and biomat do not consider the full heterogeneity of farms and farmers which is a deliberate trade off in order to model larger regions they also do not directly account for the feedback from other sectors although this uncertainty can potentially be accounted for in the imf be by connecting biomat with dynk iteratively both land use models also assume that land use decisions are made with respect to annual decadal averages which may not adequately reflect the variability and associated risk preferences of farmers 4 2 4 dynk finally dynk will receive the uncertainty propagated through the output on value added from biomat linkage extrapolation uncertainty will manifest here as well biomat does not model sector output and input fully consistent with the input output framework e g investments and therefore does not correspond exactly to the absolute sector values in dynk therefore approximations have to be used practically this means that relative changes are used instead of absolute changes this can be viewed as deliberate ignorance however note that due the other uncertainties propagating to and within biomat and thus also to dynk value added is also expressed as a scenario uncertainty and within each scenario as statistical uncertainty similar to global fasom and biomat dynk is affected by uncertainty in system drivers population technological development export development quantified as scenario uncertainty with the same plethora of natural causes model structure uncertainty can be incorporated by different behavioral functions e g whether household expenditure is driven by changes in income or cash on hands this can be expressed as scenario uncertainty and the nature of this uncertainty can be attributed to conflicting evidence structural uncertainty epistemic uncertainty and human variability stochastic uncertainty important manifestations of uncertainty in the system data are the elasticities in the behavioral equations this uncertainty can be quantified statistically and is mostly due to lack of observations unreliability epistemic uncertainty but is also closely connected to the functional form and thus model structure uncertainty the same is true for the elasticities in the global fasom model 4 2 5 final overview indicators outcome obtained from the imf be can be used to evaluate policy and climate change impacts on the bio economy from global to local levels this can highlight for example associated trade offs between climate change adaptation and mitigation measures not all indicators will be obtained at the end of the model sequence some will already be provided by epic e g climate change impact on crop yields by geo spatial simulation units crops and management variants or by global fasom e g climate change impacts on trade balances commodity prices plant production ghg emissions and global land use change or by biomat e g climate change impacts on spatially explicit land use and land management choices and nutrient emissions in austria finally dynk can provide additional information on macro economic feedback and indicators e g sectoral outputs gpd as well as associated energy and ghg emissions the preceding sections illustrate how outcome indicators are influenced not only by uncertainty inherent within individual models but also through uncertainty propagation across the whole integrated modeling framework table 4 provides a final overview of where uncertainty has been identified in the imf be examined and how it might be expressed deliberate recognized ignorance is widely present especially in defining the context and system boundaries of all models but also with respect to model structure and hardware software issues there is generally a tendency to apply statistical uncertainty for system data and scenario uncertainty for system drivers however especially due to the propagation of uncertainty all combinations are present model uncertainty can be accounted for with a mix of scenario uncertainty e g selecting different equally plausible behavioral equations as well statistical uncertainty e g algorithm imprecision uncertainty created at the model linkages is specifically highlighted it is either expressed via statistical uncertainty e g aggregation or by deliberate ignorance i e accepting that some variables between models are not a perfect fit e g different commodity types and assuming that further model improvements are not worth the cost qualitative uncertainty is not of major importance for this quantitative integrated modeling framework we still highlight its importance with respect to the use of model outcomes for decision support the overview excludes the nature dimension as our exercise focuses on identifying uncertainties in order to account for them in subsequent quantitative uncertainty analysis the nature dimension is more helpful in identifying the causes of uncertainty and to identify ways to reduce it see also our discussion in section 5 5 discussion while our review rests heavily on the uft developed by walker et al 2003 we see our main contribution in comparing and assessing other available concepts and by showing that these concepts despite their different approaches often attributable to language ambiguity can be put under the umbrella of our newly adapted uft to our knowledge we also provide one of the first applications of such an uncertainty concept for an existing integrated modeling framework a notable exception for an earlier application is provided by refsgaard et al 2013 their approach is tailored towards eliciting important uncertainties for a specific issue e g climate change adaptation whereas we focus on eliciting uncertainty propagation pathways in a particular integrated modeling framework this makes clear that the objective of an analysis also influences which uncertainty dimensions are critical and how uncertainties are finally labeled our literature review suggests that small adjustments to the uft by walker et al 2003 might be warranted in this application the adjustments have proven adequate from an integrated modeling perspective potentially they could help to achieve the goals of an uncertainty concept for integrated modeling 1 a systematic reflection of locations and types of uncertainty propagation pathways 2 minimize chances that key uncertainties are overlooked and 3 facilitate communication among different disciplines policymakers and stakeholders von krauss et al 2006 the most important differences introduced in our uncertainty concept are the following we identified additional location categories that are crucial to integrated modeling specifically system resolution linkage norton et al 2006 skinner et al 2014 and decision support ascough et al 2008 norton et al 2006 skinner et al 2014 the importance of these categories is confirmed by the application of the uft to our imf be we use a more comprehensive definition for ignorance to highlight transparently not only where we accept that knowledge is missing recognized ignorance but that available knowledge is often deliberately ignored deliberate ignorance we use a more nuanced differentiation of the nature dimension we introduce color coding in the uft to highlight uncertainty propagation we develop in addition to the uft a system graph to aid the visualization of uncertainty propagation pathways along some of the uft dimensions especially the category linkage improves the applicability of the uft for integrated modeling it highlights that the uncertainty propagated to other models not only includes the interaction not the sum of all other uncertainties but that new uncertainty can be introduced with each model linkage the application of the uft for our imf be emphasizes this see section 4 considering deliberative ignorance also strengthens the uft for integrated modeling despite aiming at a holistic representation of human environmental interactions integrated modeling frameworks are per definition simplified reflections of reality whereby deliberative decisions for disregarding specific actors or processes are ubiquitous visualization techniques are used because humans are known to process visual information more effectively than pure textual information however if this effect can be achieved with color coding in the uft and with the help of a system graph requires further testing further improvements on how to visualize uncertainty propagation are certainly possible e g animated visualizations but will require to dedicate research resources to expertise in graphic design our synthesis and the adapted uncertainty concept have been oriented to applications of individual models and integrated modeling although our motivation is thus on accounting for uncertainty and not on reducing uncertainty these two aspects are not necessarily mutually exclusive unfortunately project research resources often only allow for one or the other by including the nature dimension the uft should also help to think about the actual cause s of uncertainty manifestations in integrated modeling identifying and accounting for uncertainty can be seen as a prerequisite for knowing where resources should be dedicated in the future for reducing uncertainty if possible it also seems that major discrepancies between manifestation and causes of uncertainty in the literature can be traced back to these implicit motivations i e publications that focus on reducing uncertainty see location and cause as identical whereas publications that focus on accounting for uncertainty aim to identify manifestations of uncertainty in order to account for them the concept and application shown in this article clearly belongs to the latter group evidently the uncertainty concept is not free of drawbacks norton el 2006 criticize that the implicit ordering of uncertainty types from statistical to ignorance introduces a false notion of confidence this was probably more relevant for the original label of this dimension by walker et al 2003 i e level of uncertainty by following gabbert et al 2010 in labeling this dimension type we hopefully avoid this false notion walker et al 2003 acknowledge that their uft is not free of ambiguity and that attributing uncertainty to only particular parts of the uft dimensions might not be possible we agree and add that ambiguity is mostly related to the uncertainty dimensions type and nature although there is also much overlap between the category system boundaries in the location dimension and the category deliberative ignorance in the type dimension the location manifestation of uncertainty can mostly be pinpointed exactly in a particular integrated modeling framework an exemption to this argument is parameter uncertainty as this is closely linked to both system data and model structure uncertainty refsgaard et al 2007 some publications did aim to provide an unambiguous taxonomy i e uncertainty is attributed to only one location type and nature e g warmink et al 2010 these are often publications that implicitly assume location to be the ultimate cause of uncertainty and not the manifestation in the model ascough et al 2008 skinner et al 2014 however we remain unconvinced that this is a reasonable approach especially for the nature dimension for example the combined nature category by skinner et al 2014 is obsolete if one defines model structure as part of the location manifestation dimension of uncertainty and acknowledges that it is caused by both epistemic and stochastic uncertainty nature dimension similarly the uncertainty concept by ascough et al 2008 implicitly suggests that model uncertainty is solely caused by epistemic uncertainty an argument that does not hold if closely scrutinized the attempt by warmink et al 2010 to elicit unique attributions of location type and nature to specific uncertainties is commendable but neglects that i recognized or deliberate ignorance might always be present especially with respect to model uncertainty and that ii there can be strong interaction between epistemic and stochastic variability e g assuming that the period of peak discharge is solely a natural variability implicitly assumes that one has collected so much data that there is no epistemic uncertainty left it seems reasonable to assume that some of the uncertainty in peak discharge might also be caused by a lack of observations skinner et al 2014 criticize that typologies commonly applied are subjective based on small scale literature reviews and as is partly the case here simply amalgamations of existing uncertainty concepts instead they derived an inductive based empirical novel typology based on almost 200 environmental weight of evidence assessments this is laudable but still restricts the typology to a specific area subjectivity will also remain an issue due the inherent subjectivity of uncertainty selection in the assessments themselves a non empirical deductive based concept comes with the advantage that it may encompass important aspects typologies that have not been considered in empirical analyses so far in addition uncertainty propagation analyses for integrated modeling and specifically imf be are rarely conducted so our empirical sample would be too small for such an approach finally we do not see why amalgamations are valued negative if the advantages of previous approaches are combined in a new context the process of amalgamation might reveal that concepts are not that different as skinner et al 2014 for example suggest we think that the concepts and typologies reviewed here can all be reasonably amalgamated into the uft by walker et al 2003 this reasoning also suggests an uft may be easily applied by other integrated modeling frameworks or single models nonetheless it will remain impossible to develop a fully generic approach for the diversity of integrated modeling frameworks available and under development this is evident by the numerous failed efforts to establish a generic approach and to define the standard bastin et al 2013 matott et al 2009 we thus refrain from claiming to have identified a new standard or the only approach suitable for integrated modeling in contrast our analysis highlights that there is much to gain from established although at times seemingly inconsistent concepts while the dimensions location type and nature may be appropriate to structure uncertainties in various integrated modeling frameworks adaptations in the sub dimensions may be necessary for specific research and model domains our uncertainty concept for integrated modeling is clearly tailored toward producers of model output i e model developers and model users and not users of model output i e stakeholders a criticism already raised by norton et al 2006 with respect to the uft by walker et al 2003 it has to be acknowledged that the user s or stakeholder s perspective may differ substantially from the producer s or model developer s perspective congalton 1991 gabbert et al 2010 users are primarily interested in the uncertainty range of model outcomes and parameters while model developers interest often spans across all uncertainty aspects gabbert et al 2010 hence while the oversight and visualization of uncertainty propagation in integrated modeling might be of particular interest to model developers it remains to be seen if this provides added value to stakeholders in the course of our research we were able to present this concept to stakeholders from the austrian ministry of sustainability and tourism researchers from other disciplines social ecology climatology and agricultural extension services the general response from these potential users to the uncertainty concept presented here was rather favorable indicating that a deeper insight into uncertainty concepts and propagation pathways could indeed be a helpful visualization and communication tool in stakeholder interaction however as in gabbert et al 2010 they were much more interested in the uncertainty of model outcomes than in identifying the location type or nature of uncertainties much more stakeholder interactions are required to empirically validate this first impression and to adjust the uncertainty concept to stakeholder needs 6 conclusion and outlook we provide a review of uncertainty concepts which has shown that the uncertainty framework table uft developed by walker et al 2003 still remains state of the art and useful for capturing uncertainties in integrated modeling we identify various additional uncertainty categories that could be included acknowledging a modeler s perspective and a focus on uncertainty propagation in integrated modeling e g system resolution linkage deliberate ignorance furthermore we make a first attempt to visualize uncertainty propagation pathways through color coding in ufts and a system graph to indicate the applicability of such a model application oriented uncertainty concept we applied it in an existing integrated modeling framework for the bio economy imf be this application has facilitated overview and communication of uncertainties among researchers with different disciplinary backgrounds there is still room for improvement the general applicability of our uncertainty concept can only be shown if other integrated modeling teams apply this particular concept as well while our uncertainty concept focuses on the modeler s perspective the uft and the visualization of uncertainty propagation should in a next step be tailored towards stakeholder user needs by focusing on how to properly communicate uncertainty or by developing software for a better interactive visualization this requires thorough testing with potential users of model outputs and the dedication of research resources to graphic design and communication science the uncertainty concept might also be further improved by developing a variant that allows a more detailed investigation of uncertainties as the concept developed here remains on a rather aggregate level in addition to these limitations it remains to be emphasized that there are likely more limitations that we are currently not aware of total ignorance unknown unknowns keeping these caveats in mind we think that the uncertainty concept developed here could be particularly useful in order to provide a comprehensive yet relatively concise overview of relevant uncertainties as well as of uncertainty propagation pathways to be addressed in an integrated modeling framework this makes it an ideal prerequisite for conducting appropriate quantitative or qualitative uncertainty analyses by identifying relevant locations pathways and types of uncertainties or if the level of detail remains too aggregate for an actual uncertainty analysis it can at least highlight where more effort for identifying uncertainties should be dedicated to all of this may help to increase understanding transparency and trust in integrated modeling exercises especially with respect to the communication between scientists and with relevant stakeholders declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research has been supported by the project uncertprop uncertainty propagation in integrated modeling approaches for global change impacts on the bio economy funded by the austrian klima und energiefonds climate and energy fund within the austrian climate research program acrp funding number kr16ac0k13332 the study also contributes to the cluster of excellence cliccs climate climatic change and society of universität hamburg and the associated helmholtz excellence network exnet 0025 phase 2 3 the publication is further supported by the university of natural resources and life sciences boku vienna open access publishing fund we highly appreciate the helpful feedback of three anonymous reviewers which helped greatly in improving this paper appendix appendix a research background given the diversity of uncertainty concepts available in the literature which seem to stem from both different methodological and disciplinary backgrounds e g nature conservation management vs hydrological modeling and pursue different aims e g pragmatic applications vs consistent scientific theories we aim to transparently communicate our research background and approach the uncertainty dimensions are explored for an existing integrated modeling framework for the bio economy imf be which focuses on the sustainability of the bio economy in an era of global change the essential core modeling framework usually comprises of a sequential linkage between a climate change model or data a biophysical process model that simulates plant growth and nutrient emissions an agronomic model to derive crop rotations and a spatially explicit economic bottom up economic land use farm model for the agriculture and forestry sector with a geographic core focus on austria feusthuber et al 2017 kirchner et al 2016 kirchner and schmid 2013 mitter et al 2015a 2015b schönhart et al 2011a in the past this core modeling framework has been adapted and extended in various forms e g with energy system models schmidt et al 2012 forestry growth and macro economic models kirchner et al 2015 mitter et al 2015c biorefinery models höltinger et al 2014 hydrological models schönhart et al 2018 zessner et al 2017 or gis based landscape elements analysis kirchner et al 2015 schönhart et al 2016 the applications focused primarily on climate change i e impacts adaptation and or mitigation with focus on land use and agricultural environmental climate and or energy policies e g agri environmental programs pest management the model applications have always aimed at providing a diverse set of indicators to assess the consequences of drivers and policies on sustainability e g environmental indicators such as nitrogen phosphorous and ghg emissions biodiversity or soil erosion and socio economic indicators such as farm income gross margins gdp or landscape amenities and thus to provide guidance to various stakeholders such as agricultural extension specialists and administration hence stakeholder participation has been of particular focus in many applications mitter et al 2014 schönhart et al 2018 more recent publications now also focus more on uncertainty propagation specifically the impact of stochastic climate change scenarios karner et al 2019 mitter and schmid 2019 other imf be that bear similarities to ours are for example briner et al 2012 leclère et al 2013 the seamless if integrated modeling framework gabbert et al 2010 van ittersum et al 2008 as well as the integrated modeling frameworks considered in nelson et al 2014 such as globiom frank et al 2013 schneider et al 2011 appendix b literature overview we based our literature review on various combinations of the following search terms uncertainty uncertainty concept uncertainty propagation uncertainty framework modeling integrated modeling google scholar and scopus were primarily used to obtain first search results we identified key articles i e funtowicz and ravetz 1990 van asselt and rotmans 2002 walker et al 2003 that fit our review purposes and from those we applied the snowball method to obtain more relevant publications i e looking at the references as well as citations of each publication moreover we specifically searched the journal of environmental modeling and software as well as the now terminated the integrated assessment journal which both published key articles on the topic of uncertainty and modeling the relevant publications selected by us are shown in table 5 table 5 overview of sci publications on uncertainty concepts considered in the literature review table 5 appendix c framing uncertainty the nature of uncertainty this appendix section summarizes differences as well as overlaps in the literature identified in particular with respect to sub categories in the uncertainty framework table uft fig 2 should aid in understanding the following paragraphs as it is not a straightforward task to compare the sometimes quite disparate approaches and the different nomenclature applied beside differences in the number and types of primary causes of uncertainty some more notable disagreements can be found at an aggregate level skinner et al 2014 classify linguistic uncertainty as a sub category of epistemic uncertainty claiming that imprecision in language can theoretically be both quantified and eliminated furthermore they allow a combined category that refers to both epistemic and stochastic uncertainty this highlights that the causes of uncertainty do not have to be mutually exclusive and may be quite interlinked refsgaard et al 2007 i e uncertainty in specific data inputs may be caused by multiple primary causes of uncertainty regan et al 2002 p 620 identify natural uncertainty as a sub category of epistemic uncertainty although they explicitly acknowledge that natural variation is not a cause of epistemic uncertainty per se and that inherent randomness occurs not because of our limited understanding but because the system is irreducible to a deterministic one we would agree with most other authors that it is convenient to highlight stochastic uncertainty next to other primary causes of uncertainty 8 8 the distinction between ontology the state of being natural variability and epistemology the state of knowing has its origins in greek philosophy socrates as pointed out by brown 2004 some publications offer further sub categories which introduce more differences and nuances especially with respect to epistemic uncertainty for example funtowicz and ravetz 1990 who implicitly only address epistemic uncertainty classify causes of uncertainty into i inexactness error ii unreliability systematic error confidence in assessment and iii border with ignorance gaps in knowledge in a similar manner and partly based on funtowicz and ravetz 1990 rotmans and van asselt 2001 as well as van asselt and rotmans 2002 categorize epistemic uncertainty into a unreliability which comprises of inexactness we roughly know lack of observations we could have known and practically immeasurable we know what we do not know as well as b structural uncertainty which comprises of conflicting evidence we don t know what we know reducible ignorance we don t know what we do not know indeterminacy we will never know and irreducible ignorance we cannot know regan et al 2002 distinguish between measurement errors systematic errors bias and model uncertainty simplification of reality as well as inherent randomness system is irreducible to a deterministic one natural variation system is too difficult to predict and subjective judgment interpretation of data as mentioned above it may be more suitable to attribute inherent randomness and natural variation to stochastic uncertainty whereas subjective judgment values is attributed by others to stochastic uncertainty rotmans and van asselt 2001 van asselt and rotmans 2002 or if assumed to be related to decision uncertainty as its own primary cause ascough et al 2008 warmink et al 2010 ascough et al 2008 differentiate between i process understanding limits of scientific understanding ii model uncertainty which is further disaggregated into parametric data uncertainty e g measurement errors misclassifications lack of observations structural uncertainty simplification and technical uncertainty software or hardware errors as well as iii model output accumulated uncertainty skinner et al 2014 provide the most comprehensive sub categorization and identify a data uncertainty which comprises of precision accuracy availability incompleteness and reliability trustworthiness b system uncertainty which comprises of process not understanding something vital to the assessment cause lack of clarity regarding the source of an outcome and effect lack of knowledge about the influence of the source on the outcome as well as c model uncertainty which comprises of structure representation of real world systems and output confidence in results as well as decision uncertainty doubt due to the accumulated uncertainty model and decision uncertainty is subsumed under their category of combined uncertainty which refers to the existence of both epistemic and stochastic uncertainty this is distinct from ascough et al 2008 who use decision as its own primary cause of uncertainty next to epistemic stochastic and linguistic uncertainty ascough et al 2008 disaggregate decision uncertainty into goals and objectives as well as assessment criteria compared to the sub categories of epistemic uncertainty there seem to be more similarities with respect to the sub categories of linguistic uncertainty as well as stochastic uncertainty three publications address linguistic uncertainty explicitly although ascough et al 2008 and skinner et al 2014 thereby follow the publication on linguistic uncertainty by regan et al 2002 while all three emphasize vagueness unclear meanings ambiguity multiple meanings and underspecificity unwanted generalization regan et al 2002 further identified linguistic uncertainty due to the indeterminacy of theoretical terms future use of theoretical terms may change as well as context dependency failure to specify context stochastic uncertainty is categorized by rotmans and van asselt 2001 as well as van asselt and rotmans 2002 into 1 inherent randomness unpredictable natural processes 2 value diversity norms views and values 3 behavioral human variability e g cognitive dissonance 4 societal social economic cultural variability e g policy agreements institutional conditions and 5 technological surprises ascough et al 2008 provide an almost identical classification the distinction between natural and human variability is also found in skinner et al 2014 who in addition also introduce extrapolation as another important sub category of natural uncertainty which encompasses intraspecies from species member to other species member interspecies from one species to another species laboratory from laboratory to the real world quantitative from one quantity to another spatial from one scale to another and temporal from one timescale to another extrapolation as highlighted above regan et al 2002 distinguish between inherent randomness natural variation and subjective judgment but classify them as part of epistemic uncertainty fig 2 framing the nature of uncertainty own note sub categories have been vertically aligned if assumed to be synonymous or similar and colors correspond to the primary causes of uncertainty for interpretation of the references to color in this figure legend the reader is referred to the web version of this article fig 2 the location of uncertainty walker et al 2003 who explicitly focus on the manifestation of uncertainty within a model provide the following categorization of uncertainty locations 1 context e g model boundaries 2 inputs and data a system data e g the initial data for the system under investigation b driving forces e g data for the driving forces of the system under investigation 3 parameters i e calibrated data 4 model a structure e g simplification mathematical formulas algorithms b technical implementation e g software or hardware errors 5 outcomes e g the accumulated uncertainty subsequent publications that draw on the uncertainty concept developed by walker et al 2003 adopt this classification with negligible modifications e g classifying parameter calibration as part of the aggregate category inputs data gabbert et al 2010 or model refsgaard et al 2007 whereas warmink et al 2010 simply do not provide different levels of aggregation similar classifications of locations can also be found in earlier publications see figure 3 for an overview kann and weyant 2000 distinguish between exogenous e g data and parameters endogenous processes e g model structure technical approaches for simplifying models and value judgments e g choice of discount rate from our point of view value judgments may be rather seen as part of the nature dimension than the location dimension for example uncertainty with respect to the chosen discount rate manifests itself in the input data i e the quantified discount rate which is caused by different value judgments stochastic or decision uncertainty rotmans and van asselt 2001 as well as van asselt and rotmans 2002 identified the following potential locations of uncertainty model quantities e g data and parameters model form e g structure algorithms model adequacy e g representation of relevant processes and model operation e g technical errors as with kann and weyant 2000 in the case of value judgment it might be better to classify model adequacy as a cause nature of uncertainty which manifests in the chosen model structure or to alternatively frame it as part of model context and boundaries matott et al 2009 differentiate between input uncertainty and model uncertainty input uncertainty includes data e g initial and boundary conditions response data e g site specific measurements or expert judgments and calibrated parameters model uncertainty refers to structure e g hypotheses equations resolution e g spatio temporal boundaries code e g algorithms solvers and correspondence e g representation of real world systems system resolution might be better viewed as part of model boundaries and correspondences might fit better within the nature dimension e g does it represent real world processes with respect to those publications that define the location of uncertainty more or less synonymous with the nature of uncertainty one still finds a resemblance with the categories above ascough et al 2008 who see model uncertainty as a distinct part of epistemic uncertainty disaggregate it into data parameters structure and technical issues as well as model output bastin et al 2013 provide a lot of detail on the location of input uncertainty which includes measurement errors representativeness sensor uncertainty or transmission uncertainty as well as model uncertainty which includes structure e g simplification representation e g spatio temporal calibrated parameters and numerical uncertainty e g solver imprecision finally skinner et al 2014 define the location of uncertainty as a sub level of the nature dimension of uncertainty i e their sub categories in the nature dimension displayed in fig 2 are explicitly labeled location of uncertainty by them this includes relevant locations manifestations of uncertainty from our point of view i e where uncertainty manifests in the model or integrated modeling framework such as data uncertainty e g availability precision and reliability model uncertainty e g simplifications structure and technical and output extrapolation and decision uncertainty e g accumulated uncertainty fig 3 framing the location manifestation of uncertainty in imf own note sub categories have been vertically aligned if assumed to be synonymous or similar and colors correspond to the primary locations of uncertainty for interpretation of the references to color in this figure legend the reader is referred to the web version of this article fig 3 appendix d uncertainty framework tables ufts table 6 uncertainty framework table uft for croprota table 6 table 7 uncertainty framework table uft for epic table 7 table 8 uncertainty framework table uft for global fasom table 8 table 9 uncertainty framework table uft for dynk table 9 
25898,we review concepts that have been used to address uncertainty in integrated modeling although conceptual approaches to tackle uncertainty seem diverse a synthesis reveals more similarities than differences in the concepts published especially if one adopts a model application oriented focus given our findings we slightly adapt the uncertainty framework table uft developed by walker et al 2003 and apply it for an existing integrated modeling framework for the bio economy the use of color coded ufts with a graphical visualization of uncertainty propagation pathways has facilitated a better overview and communication of uncertainties and uncertainty propagation pathways among the authors systematic consideration of uncertainties in integrated modeling may allow for more trust in model results and if simulations are conducted for a better robustness check of policy interventions keywords uncertainty concept uncertainty framework table uncertainty propagation integrated modeling bio economy 1 introduction uncertainty analysis is essential for identifying robust business strategies and policy interventions e g climate adaptation or mitigation measures information on location type and nature of uncertainty increases the transparency of and confidence in scientific analyses by researchers decision makers and stakeholders gabbert et al 2010 uncertainty analysis is generally required for scientific publications of model based quantitative assessments troost et al 2015 and is considered a good modeling practice jakeman et al 2006 integrated model assessments are useful to guide complex business or policy decisions in unprecedented situations rotmans and van asselt 2001 and are employed for studying real world problems that cross disciplinary boundaries laniak et al 2013 many applications of integrated modeling are found in the global change research community moss et al 2010 here we define integrated modeling similar to laniak et al 2013 as an interdisciplinary system of linked empirical datasets and mathematical models that are based on disciplinary theories 1 1 our definition aims at subsuming similar concepts such as integrated environmental modeling iem integrated assessment modeling iam and so forth see box 1 in laniak et al 2013 for an overview although differences exist e g iem are often natural science based whereas top down iam are centered around macro economic models they all have in common the linkage of disciplinary models i e frame workers matott et al 2009 usually integrated modeling is motivated by real world problems e g flood control climate change environmental pollution sustainable economic growth to identify either adequate optimal or robust policy options or consequences of policy options along multiple dimensions and indicators the overall structure of a specific set of integrated models can be referred to as an integrated modeling framework epa 2009 compared to disciplinary approaches integrated modeling can provide a more holistic picture and adequately represent human environmental interactions van ittersum et al 2008 thus they are expected to identify realistic business strategies and policy interventions that provide a balanced outcome between alternative development objectives considering changing socio environmental conditions rounsevell et al 2012 integrated modeling is no panacea disadvantages include communication difficulties across disciplines and between scientists and stakeholders lack of interoperability between disciplinary models i e semantic ontological and technical differences and typical methodological challenges of complex uncertain and computational demanding modeling systems sohl and claggett 2013 some methodological problems have been addressed in the integrated modeling community for example semantic and ontological issues e g janssen et al 2011 lack of stakeholder participation and challenges in communication e g gabbert et al 2010 hewitt et al 2014 mitter et al 2014 inadequate model linkages e g ewert et al 2011 2009 helming et al 2011b as well as the development of more appropriate analytical concepts e g helming et al 2011a uncertainty is a major challenge for integrated modeling and may materialize and accumulate throughout an integrated modeling framework existing integrated modeling frameworks tackle uncertainty mostly in two ways first uncertainty of future developments is often addressed through scenarios moss et al 2010 reilly and willenbockel 2010 i e alternative descriptions of internally consistent possible futures mitter et al 2019 van der heijden 2011 second uncertainty related to different data sources and model designs e g elliott et al 2014 nelson et al 2014 is addressed by systematic model comparisons within the scientific community e g the inter model comparison projects isi mip warszawski et al 2014 and agmip rosenzweig et al 2013 with contributions by members of this research team folberth et al 2019 rosenzweig et al 2014 relatively little effort has been dedicated to comprehensively identify and trace uncertainties in integrated modeling i e how uncertainty propagates between models bastin et al 2013 while such analysis was already identified as an important research gap in the early stages of integrated modeling rotmans and van asselt 2001 subsequent studies mostly defined and classified the myriad sources of uncertainty and identified and quantified the potential of cascade effects wilby and dessai 2010 however a few notable exemptions exist specifically for the uncertainty propagation from climate change models to crop models to land use optimization models holzkämper et al 2015 karner et al 2019 mitter and schmid 2019 one possible explanation for the scarcity of uncertainty propagation analyses in integrated modeling is its data computer and human resource requirement the development of an integrated modeling framework typically requires effort to modify individual models establish and improve model linkages and apply the integrated modeling framework to specific research questions in contrast to disciplinary modeling where these issues might also exist integrated modeling teams typically come from different institutions working together temporarily this makes the establishment of e g mutual modeling software platforms or databases even more challenging further limiting the availability of resources that can be dedicated to uncertainty propagation analyses although quantitative uncertainty analyses for integrated modeling are scarce suitable uncertainty concepts are available however the landscape of publications on uncertainty concepts is still fragmented first many publications originate from specific disciplinary backgrounds e g water management geography land use economics nature conservation or environmental risk assessments second there is some disagreement on how to define conceptualize and communicate uncertainty for example see the correspondence between norton et al 2006 and von krauss et al 2006 on the uncertainty framework table uft developed by walker et al 2003 as well as the general criticism of skinner et al 2014 on existing concepts these studies discuss the inherent subjectivism of the concepts developed and the omission or implicit weighting of specific aspects e g linguistic uncertainty non statistical methods extrapolation and user perspectives section 5 contains a more detailed review and discussion of these aspects this paper aims to 1 review uncertainty concepts for integrated modeling with focus on real world problems 2 analyze for each uncertainty concept the applicability to deterministic bottom up 2 2 notably most integrated modeling frameworks are deterministic and do not take uncertainty into account by default this is particularly the case for relatively large integrated modeling frameworks we thus focus on how to deal with uncertainty in deterministic integrated modeling i e uncertainty propagation this has to be distinguished from stochastic models which can integrate information on probability to obtain optimal decisions under uncertainty kann and weyant 2000 bottom up is thereby defined as a detailed representation of production technology choices and a detailed spatial representation of the heterogeneity of resource endowments in contrast top down refers to the use of aggregate production functions integrated modeling frameworks for assessments of bio economies henceforth labeled imf be 3 adapt general uncertainty concepts to our specific integrated modeling context and 4 apply the adapted concept from 3 to identify uncertainties within an established imf be regarding the second objective a concept is judged applicable by us if it i provides a comprehensive as well as a concise overview of uncertainties and uncertainty propagation in an integrated modeling framework ii can be used to identify and highlight uncertainties and uncertainty propagation pathways from a modeler s perspective and iii increases transparency and uncertainty communication between scientists the uncertainty concept used for communication should thereby be easily understandable without sacrificing scientific accuracy the uncertainty concept aims to be generic and flexible enough to allow for its application for other integrated modeling teams moreover our findings will provide the conceptual basis for quantitative uncertainty propagation analyses with an established imf be what we explicitly do not address is on the one hand how to quantify or reduce uncertainties in integrated modeling and on the other hand how to communicate uncertainty or risk such as the ipcc treatment of verbally communicating probabilities mastrandrea et al 2010 our review and application remain on a conceptual level i e how we can think about uncertainties and how to identify them qualitatively in integrated modeling this article is structured as follows section 2 provides and discusses definitions of uncertainty section 3 reviews relevant literature on uncertainty concepts and provides an adapted version of the uncertainty framework table uft developed by walker et al 2003 in section 4 we identify uncertainties and uncertainty pathways for an established imf be by applying the adapted uft and a comprehensive system graph this is followed by a discussion section 5 as well as conclusions and outlook section 6 2 defining uncertainty intuitively uncertainty could mean that complete information about something is lacking for example currently no one can predict accurately if climate change will lead to increases or decreases in crop yields in austria until 2050 one may be quite certain that yields of a specific crop will decrease or increase in some sub regions of austria e g grassland yields in humid regions are likely to increase in existing climate change scenarios whereas crop yields in semi arid regions are likely to decrease without irrigation measures but to pinpoint the exact change will be mere impossible given the plethora of uncertain and unknown factors that influence this outcome moreover many people associate uncertainty with outcomes represented in terms of confidence intervals upper and lower bounds probability density functions box plots or means and standard deviations knight s 1921 famous differentiation between risk i e measurable uncertainty and true uncertainty i e situations where probabilities are unknown can be seen as an initial spark to think about uncertainty in broader aspects hence current uncertainty definitions and concepts are more nuanced and often provide a full taxonomy of uncertainty concerning different characteristics such as why it exists if and how it can be expressed and where it manifests the seminal publication by funtowicz and ravetz 1990 highlights the need to extend the focus of quantitative uncertainty analyses to qualitative social science e g science policy interface for decision making and stakeholders interests this is because modeling results are often viewed and used as scientific knowledge to guide decision making for real world problems e g flood protection nitrogen emissions in agriculture food safety climate change mitigation which is particularly the case for integrated modeling laniak et al 2013 the eu water framework directive for example explicitly demands uncertainty be addressed in water management plans brown 2004 sigel et al 2010 hence uncertainty concepts that have been developed by modeling and integrated modeling teams with focus on real world problems primarily provide guidance at the science policy interface generic definitions from this point of view thus depart from a positivistic natural science perspective i e statistical probability but aim at a compromise between natural and social sciences in order to increase comprehensibility they focus on subjective levels of confidences brown 2004 kann and weyant 2000 with respect to model outputs and the knowledge generated by applying them e g lack of confidence in our knowledge sigel et al 2010 p 502 3 3 both lack of confidence in our knowledge i e uncertainty and lack of knowledge make it difficult to decide what is best lack of confidence in outcomes refsgaard et al 2007 p 1546 4 4 a person is uncertain if s he lacks confidence about the specific outcomes of an event reasons for this lack of confidence might include a judgement of the information as incomplete blurred inaccurate unreliable inconclusive or potentially false lack of confidence in model outputs kann and weyant 2000 p 29 5 5 in addition to clarifying the assumptions on model inputs modelers should be more explicit about their level of confidence in model outputs this implicitly or explicitly accounts for the social processes in which knowledge has been generated by acknowledging the subjectivity of the researchers and thus of the generated knowledge uncertainty is thus seen as the spectrum between two contrasting states of subjective confidence i e certainty on the one hand and total lack of knowledge total ignorance on the other with a diverse continuum of limited knowledge van asselt and rotmans 2002 ignorance is sometimes viewed as distinct from uncertainty especially if defined as being unaware of imperfect knowledge brown 2004 nevertheless considering that one may be aware that he may be unaware of imperfect knowledge i e acknowledging the existence of a void brown 2004 it is sometimes subsumed as part of uncertainty labeled recognized ignorance walker et al 2003 or accepted ignorance faber et al 1996 finally knowledge can be further classified into knowledge about the probability of an outcome and knowledge about possible outcomes where uncertainty may be unbounded if not all outcomes are known brown 2004 for example we may know with some confidence the likely impact an unprecedented quarantine has on the spread of a virus in a population employing state of the art agent based models i e probability of an outcome but we might be currently unaware of other outcomes regarding social economic environmental or psychological issues i e total ignorance of an outcome there are also more generic definitions available such as the one provided by walker et al 2003 p 8 which aims at encompassing all possible aspects of uncertainty by defining it as any departure from the unachievable ideal of complete determinism 3 a model application oriented uncertainty concept for integrated modeling to gain a more comprehensive insight into uncertainties of integrated modeling and to facilitate better communication among scientists decision makers and stakeholders many modelers have tried to develop uncertainty concepts that encompass possible characteristics perspectives dimensions or taxonomies of uncertainty see table 5 in appendix b from a modeler s perspective these three following dimensions first conceptualized by walker et al 2003 provide a good starting point 1 the nature of uncertainty why does uncertainty exist 2 the type of uncertainty how can uncertainty be expressed 3 the location of uncertainty where does uncertainty manifest in a single model and in an integrated modeling framework although not all publications reviewed explicitly frame uncertainties along these dimensions often their concepts can be attributed to at least one of them considering our findings which are presented in the subsequent sections we suggest the following model application oriented uncertainty framework table uft in table 1 importantly we take the initial uft by walker et al 2003 and the adjustments by refsgaard et al 2007 as well as warmink et al 2010 as a starting point in addition to this uft our uncertainty concept also comprises color coding and the application of a comprehensive system graph to aid in the visualization of uncertainty propagation pathways see table 3 and fig 1 and in section 4 the following sections will elaborate on these dimensions and provide a succinct overview and assessment synthesis of the concepts and typologies identified in the literature we thereby follow a deductive approach building on theoretical concepts developed in the literature a more detailed review of concepts is provided in the appendix c 3 1 the nature of uncertainty why does uncertainty exist 3 1 1 overview the ultimate cause or nature of uncertainty is a central part of any publication that focuses on uncertainty concepts at an aggregate level there seems to be agreement on the differentiation between two primary causes of uncertainty 1 epistemic reducible uncertainty i e uncertainty due to lack of knowledge this refers to uncertainty which is due to lack of information and of understanding of the natural and human systems that encompass us theoretically epistemic uncertainty is reducible with further investigations and empirical research however gaining more and new information may not necessarily reduce uncertainty but reveal an even greater lack of understanding than previously assumed kann and weyant 2000 van asselt and rotmans 2002 2 stochastic irreducible uncertainty i e uncertainty due to the inherent variability of natural and human systems also labeled natural ontological phenomenological or aleatory uncertainty this refers to uncertainty that is practically irreducible such as natural variability e g flood events precipitation events or chaotic systems e g cloud behavior social dynamics although some authors argue that chaotic systems are basically deterministic it often remains too difficult to measure important variables e g initial states and thus to predict future outcomes this is famously depicted in edward lorenz s butterfly metaphor lorenz 1995 2000 many publications refer solely to these two primary causes of uncertainty matott et al 2009 refsgaard et al 2007 rotmans and van asselt 2001 uusitalo et al 2015 van asselt and rotmans 2002 walker et al 2003 whereas others include more for example linguistic uncertainty language i e uncertainty due to the imprecision of our language ascough et al 2008 regan et al 2002 decision uncertainty i e uncertainty in decision making due to different human value system ascough et al 2008 peterson 2006 ambiguous uncertainty i e the existence of different but equally valid expert knowledge expert subjectivity warmink et al 2010 or practical causes of uncertainty i e limited financial resources sigel et al 2010 3 1 2 comparison and synthesis we organize the various categories of the nature of uncertainty reviewed along a hierarchical structure see table 2 this structuring helps to highlight that most of the concepts in the literature reviewed can be amalgamated for a detailed comparison see appendix c and fig 2 as main categories we use the established differentiation between i epistemic and ii stochastic uncertainty these are differentiated by sub categories which include for instance linguistic uncertainty as well as specific causes such as value judgements we did not include practical causes of uncertainty as we see this aspect implicitly reflected in epistemic causes and it also relates to another conceptual issue i e identifying barriers for reducing epistemic uncertainty notably we do not see specific causes of uncertainty as being unique but as interconnected for example uncertainty in model input data may stem from natural variation natural variability stochastic imprecise measurements inexactness unreliability epistemic as well as lack of process knowledge process system understanding epistemic furthermore specific causes may interact e g lack of knowledge about processes causes or effects system understanding could mean that measurements are not being carried out correctly unreliability the epistemic sub categories unreliability inexactness lack of observations and practically immeasurable and structural uncertainty conflicting evidence reducible ignorance irreducible ignorance and indeterminacy are taken from van asselt and rotmans 2002 these causes point primarily to uncertainty typically located in data collection hence we explicitly also consider system understanding i e process cause and effect as proposed by skinner et al 2014 this is the fundamental knowledge on which theories models and integrated modeling frameworks are developed we agree with skinner et al 2014 that linguistic uncertainty and its subcategories identified by regan et al 2002 vagueness ambiguity underspecificity indeterminacy of theoretical terms and context dependence may be viewed as reducible at least to some extent and are thus part of epistemic uncertainty the stochastic sub category natural variability can be distinguished into inherent randomness e g chaotic systems and natural variations e g flood frequency regan et al 2002 human variability consists of values and subjective judgment i e mental models kann and weyant 2000 regan et al 2002 van asselt and rotmans 2002 as well as behavior institutions and technological breakthroughs ascough et al 2008 van asselt and rotmans 2002 we do not include extrapolation skinner et al 2014 in the nature dimension but see it as part of the location dimension see section 3 3 as it manifest usually when data is transferred to or between models skinner et al 2014 emphasize that extrapolation is the result of epistemic failures and stochastic uncertainty i e inherent randomness describing systems that are not irreducible to a deterministic one from our manifestation point of view it is thus adequate to treat it as a location i e the point where extrapolation takes place e g when one model output is transferred to another and to attribute the nature of uncertainty to several causes e g practically immeasurable unreliability epistemic and inherent randomness natural variability stochastic 3 2 the type of uncertainty how can uncertainty be expressed 3 2 1 overview from a modeler s point of view an important aspect is how uncertainty can be expressed i e the type of uncertainty some publications adopt the assumption that the most convenient way to express uncertainty is by quantification bastin et al 2013 kann and weyant 2000 expressing uncertainty through statistical methods e g frequentist or bayesian is the most common approach in modeling e g using probability functions bounds means or standard deviations however it is by no means the only way to express uncertainty walker et al 2003 further include scenario uncertainty i e outcomes are quantified but probabilities are not attached recognized ignorance e g lack of knowledge about mechanisms and relationships and total ignorance unknown unknowns all of which may not be statistically quantifiable refsgaard et al 2007 introduce in addition also qualitative uncertainty i e plausible possibilities e g linguistic probabilities warmink et al 2010 adopt the same types as refsgaard et al 2007 peterson 2006 further shows that statistically quantified uncertainty may also be expressed verbally e g the ipcc nomenclature on probability and rightfully highlights that many publications provide guestimate distribution e g a mixture of guessing literature review and estimation rather than true distributions refsgaard et al 2007 emphasize a notable relationship between uncertainty types and brown s 2004 uncertainty taxonomy which distinguishes between knowledge about probabilities and knowledge about outcomes if both outcomes and probabilities are known uncertainty can be expressed statistically if probabilities are unknown but at least some outcomes are known uncertainty can be expressed as a scenario if at least some qualitative uncertainties and at least some outcomes are known uncertainty can be expressed qualitatively furthermore the epistemic sub categories of funtowicz and ravetz 1990 rotmans and van asselt 2001 as well as van asselt and rotmans 2002 also bear some connection to the type of uncertainty statistical uncertainty is closely related to inexactness and lack of observation whereby qualitative and scenario uncertainty may be connected to practically immeasurable and conflicting evidence recognized ignorance is resembled by border with ignorance funtowicz and ravetz 1990 or practically immeasurable rotmans and van asselt 2001 van asselt and rotmans 2002 this dimension thus seems to be the one with the highest agreement in the literature reviewed although it is not explicitly addressed by many usually those that adopt a probability based approach and there are some overlaps with the nature dimension of uncertainty 3 2 2 comparison and synthesis the general types of uncertainty provided by refsgaard et al 2007 statistical scenario qualitative and recognized ignorance provide the most comprehensive overview without being too detailed we still propose that a more nuanced understanding and use of the term ignorance could provide added value for both modelers as well as for improving transparency and communication with stakeholders walker et al 2003 p 12 define recognized ignorance as fundamental uncertainty about the mechanisms and functional relationships being studied such a definition fits much better in the nature dimension of uncertainty than in the type dimension since the type dimension is concerned about how uncertainty can be expressed this seems not very helpful a more appropriate definition if applied in the type dimension could be acknowledging that uncertainty in some processes is ignored due to lack of knowledge in addition if taken more literal ignorance could mean that researchers deliberately ignore certain rather well known mechanisms for example detailed trade patterns in single country studies this often results from the assumption that the added knowledge value of including certain processes is not worth the costs for including them e g system boundaries need to be defined see section 3 3 given computational and resource constraints or it may be advantageous to keep a model ignorant of e g an uncertain process if this pushes the model to extreme and unrealistic boundary solutions akin to van asselt and rotmans 2002 levels of limited knowledge ignorance could be phrased we know what knowledge we ignore hence we think it could be useful to also include this kind of deliberate ignorance i e acknowledging that rather well known processes are not accounted for in the type dimension and to put it together with recognized ignorance i e acknowledging that uncertainty in some processes is ignored due to lack of knowledge total ignorance by definition cannot be highlighted as this refers to unknown unknowns ignorance could also be categorized as a nature of uncertainty just as sigel et al 2010 did with their category of practical uncertainty which is very closely related to our concept of deliberate ignorance still we prefer ignorance to be attributed to the type of uncertainty as this is how it is ultimately expressed by simply acknowledging what we did not account for it and ideally providing arguments why this is the case hopefully such transparency leads to increased trust and accountability by research peers and stakeholders notable statistical uncertainty can be interpreted widely including both frequentist or bayesian approaches as well as methods that are not purely statistical e g semi quantitative approaches such as rough sets or fuzzy sets this should accommodate the reasonable criticism by norton et al 2006 that the category statistical uncertainty may omit such approaches 3 3 the location of uncertainty where does uncertainty manifest in a single model and in an integrated modeling framework 3 3 1 overview the location of uncertainty is an ambiguous term and is interpreted differently in the publications reviewed there are those that define the location of uncertainty as the ultimate cause nature of uncertainty e g measurement errors in field experiments e g ascough et al 2008 bastin et al 2013 skinner et al 2014 and those that define the location of uncertainty as its manifestation within a model or modeling framework e g input data model structure outcome e g matott et al 2009 van asselt and rotmans 2002 walker et al 2003 warmink et al 2010 we define in accordance with walker et al 2003 the location of uncertainty as the location where uncertainty manifests in the model or modeling framework this helps modelers in identifying where uncertainty has to be addressed within a model or integrated modeling framework it will however remain difficult to provide a clear distinction between the ultimate cause nature and manifestation for example model structure can be seen both as a cause e g real processes are not fully understood and as the location where uncertainty manifests i e in the mathematical formulation of the model setting the differences between cause and manifestation aside our literature review has shown that there is much agreement on the potential locations of uncertainty manifestation within an individual model at an aggregate level there are at least three major locations 1 context 2 model and 3 outcomes although many include 4 inputs data next to model and some highlight 5 parameters calibrated data or 6 technical implementation more precise locations are available for these major categories and although there are differences in the literature with respect to the number of sub locations and probably slightly different understandings of individual location names most align quite perfectly there seems to be more disagreement with the practically irrelevant classification of individual locations to aggregate location categories detailed information and comparison between the different concepts for the location dimension is provided in appendix c and fig 3 3 3 2 comparison and synthesis similar to most other concepts we characterize four major locations where uncertainty manifests in the model or modeling framework 1 context 2 inputs 3 model and 4 outcome we think that these four major location categories represent very different phases in the modeling process i e the conceptualization phase context data collection inputs model implementation model as well as model linkage and evaluation outcome 3 3 2 1 context in contrast to walker et al 2003 and refsgaard et al 2007 we not only consider system boundaries but also system resolution for the category context drawing on the category of resolution by matott et al 2009 and representation by bastin et al 2013 although the two latter publications consider system resolution to be located in the model category we think that it fits better into the conceptualization phase and thus the context category the spatial time or technology resolution for integrated modeling is usually considered and decided in the conceptualization or problem framing phase system boundaries refer to the selective systems that one considers within integrated modeling e g agricultural and forestry land use but not commercial or residential land use or the number of economic sectors actors considered in the analysis van asselt and rotmans 2002 system resolution aspects then define the locations temporal horizon and technology options within the chosen systems e g whether land use is modeled at 1 km or 500 m grid resolution whether land use choices are stratified annually or seasonally in the model or which land use management technologies are available the general objectives of integrated modeling for example capturing human environment interactions in the agricultural land use system are implicitly acknowledged in this category as the objective defines the boundaries of the model system 3 3 2 2 inputs the inputs category consists as suggested by walker et al 2003 of system data and system drivers this distinction is especially useful for integrated modeling as they often provide policy simulations for the mid term or even the long term future system data represents empirical data used to define initial states for the base year s and system drivers represent the development of the system external driving forces such as costs technology policy changes economic progress or demographic developments 3 3 2 3 model although parameters and data are often seen as synonymous in the modeling context there is a clear distinction in the uncertainty literature here parameters are defined as data that is calibrated usually to fit model outputs to observed or reported data this can be done for example by maximum likelihood estimations e g ols calculating constants in behavioral estimations to fit observations or the estimation of unknown cost parameters by applying the positive mathematical programming pmp methods heckelei et al 2012 howitt 1995 parameter calibration usually demands an initial model run so it is often subsumed under the location model e g ascough et al 2008 bastin et al 2013 refsgaard et al 2007 of course parameterization also heavily depends on the system data so highlighting it as its own major location may be quite warranted as well e g walker et al 2003 warmink et al 2010 however we opted to include parameters in the category model in order to minimize the number of aggregate locations other important sub locations within the model category are model structure and hardware software which refers to the technical implementation the model structure encompasses all endogenous processes kann and weyant 2000 and therefore the mathematical formulation of the system of interest definitions calculations equations algorithms walker et al 2003 it is thus closely linked to context as this is where the general relationships and processes to be considered are determined warmink et al 2010 hardware software encompasses coding software and hardware aspects walker et al 2003 this also includes the choice of algorithms and their option settings as well as the imprecision of numerical solvers there is no precise agreement in the literature whether algorithms and their imprecision belong to the location model structure van asselt and rotmans 2002 walker et al 2003 or model hardware software matott et al 2009 warmink et al 2010 3 3 2 4 outcome the location category outcome differs the most from the initial concept by walker et al 2003 their category model outcomes relates to the overall impact of all other uncertainties on model outcomes that are relevant for policy or decision making in the context of integrated modeling model outcomes gain further importance for capturing uncertainty propagation in integrated modeling we therefore recommend to split the category outcome into two different aspects both of which implicitly rely on the overall model outcome i e linkage extrapolation and decision support uncertainty skinner et al 2014 linkage extrapolation because model outputs often need to be extrapolated as a input for other models in the modeling framework or b for the criteria indicators used for evaluation or decision making furthermore decision support and evaluations of model outomces are made not only with respect to the uncertainty inherent in the final model outcome indicators but also with respect to different values and thus weights attributed to different decision criteria this should also be reflected and implicitly accounts for the propagated uncertainty at this point two uncertainty concepts that are closely related to decision support uncertainty are used by the ipcc paradigmatic uncertainty and translational uncertainty kunreuther et al 2014 paradigmatic uncertainty is caused by disagreement on problem framing and methods while translational uncertainty occurs when disagreement on scientific findings allows supporting contrasting policy options they are important concepts at the core of the science policy interface but become relevant before paradigmatic or after translational the modeling process hence their usefulness for identifying uncertainties in integrated modeling is rather limited from a model user s perspective and we therefore do not include them 4 identifying uncertainties and uncertainty propagation in integrated modeling here we want to test the usefulness of the presented uft for integrated modeling including the application of color coding and a comprehensive system graph to visualize uncertainty propagation pathways we use an established imf be which is briefly outlined section 4 1 to identify nature type and location of uncertainties as well as uncertainty propagation pathways section 4 2 4 1 an integrated modeling framework for the bio economy imf be the imf be examined here focuses on a primary supply sector of the austrian bio economy i e agriculture and its embedment in the global bio economy as well as other economic sectors in austria fig 1 aims to capture both the model linkages of our imf be as well as associated uncertainty locations uncertainty types and uncertainty propagation pathways the imf be connects climate data e g chimani et al 2016 the biophysical process model epic balkovič et al 2013 izaurralde et al 2006 williams 1995 an agronomic crop rotation model schönhart et al 2011b the global economic bottom up land use model global fasom schneider et al 2018 based on schneider et al 2007 the economic bottom up land use model biomat for austria feusthuber et al 2017 karner et al 2019 mitter et al 2015b stürmer et al 2013 and the macroeconomic environment energy model dynk for austria kirchner et al 2019 sommer and kratena 2017 climate variables impact crop and grassland yields simulated by epic epic further receives crop rotational input from the agronomic model croprota epic is applied to simulate crop yields factor use and agro ecological impacts at austrian 1 km and global scale 30 arcmin and is part of the international research initiatives agmip folberth et al 2019 rosenzweig et al 2014 and isi mip warszawski et al 2014 yield data from epic is then transmitted to the economic bottom up land use models global fasom global and biomat austria these models and dynk are also driven by changes in socio economic factors such as changes in population technological development and policies biomat receives changes in input and output prices from global fasom finally a feedback loop is implemented between biomat and dynk where biomat transmits changes in value added to dynk dynk then simulates domestic macroeconomic feedbacks from production or consumption changes in the agriculture sector and can feedback changes in wages and input prices to biomat 4 2 relevant uncertainties and uncertainty propagation pathways to provide a glimpse on possible uncertainty propagation pathways we include a non exhaustive list of pathways in fig 1 by applying the uft dimensions location and type to provide a better overview we omit the nature dimension the location category context as well as the type category ignorance in this figure for highlighting uncertainty propagation pathways in the uft as well we indicate by color and or font 1 if uncertainty is received from other models green 2 if output is propagated to other models purple and also 3 if uncertainty deliberately ignored in a single model has been addressed by other models in the modeling framework grey and cursive text uncertainties and uncertainty propagation pathways are identified with respect to their relevance for a the research domain of the bio economy and global change and b the individual models and the integrated modeling framework for example we focused only on relevant system boundaries for the bio economy by focusing on uncertainties and uncertainty propagation pathways judged relevant by the integrated modeling team we can keep the ufts concise and provide a better overview albeit at the cost of being non exhaustive the following sections describe uncertainty propagation pathways from fig 1 and the application of the uft from section 3 for the individual models table 3 in this section for biomat and table 6 to table 9 for all other models in appendix d 4 2 1 climate models since the model linkages in our imf be are mostly sequential we start with the identification of uncertainties at the beginning of the integrated modeling framework i e climate data we can access climate data from different general circulation models gcms which account for various representative concentration pathways rcps of greenhouse gases moss et al 2010 at global level and climate data from regional climate models rcms for austria i e the öks15 data set chimani et al 2016 regarding location uncertainty these data reflect model structure uncertainty application of different gcms and rcms and system drivers uncertainty application of different rcps both uncertainties are not quantified statistically hence they are expressed as scenario uncertainty all climate data is quantified but no probability values are attached the nature of this uncertainty is related to many causes such as enforcement of international and national climate policies human variability stochastic uncertainty chaotic systems such as precipitation events natural variability stochastic uncertainty or lack of observations to better validate model outputs unreliability and system understanding epistemic uncertainty 4 2 2 epic and croprota epic may incorporate these uncertainties by providing simulations for all available gcm rcp or öks15 rcp combinations i e by applying scenario analysis practically only few combinations are feasible to simulate which ideally should capture the bandwidth of all climate model and rcp simulation runs in addition different equations to simulate major biophysical processes are available in epic such as for potential evapotranspiration e g hargreaves baier robertson penman monteith water erosion e g usle onstad foster rusle soil temperature and soil water see doro et al 2017 which impact crop yields and agro ecological processes furthermore a range of values i e confidence intervals is provided for many function parameters by the model developers this considers uncertainty manifested in the model structure of epic location and is caused due to lack of system understanding as well as observations both epistemic uncertainty when choosing between different equations it remains difficult to compare the likelihood of one equation form with another to represent real life processes many forms of an equation may represent the same real life process given that they can be calibrated to observed values their fit may have as much to do with data uncertainty as with the form of the equation hence comparing the outcomes of different equations akin to model comparisons is best expressed as scenario uncertainty type and thus by applying scenario analysis furthermore croprota provides important information on possible crop rotations for the spatial simulation units in epic croprota utilizes expert judgments that help to rank the agronomic suitability of different crop rotations in order to obtain typical shares of crop rotations in a region or farm by maximizing the agronomic value schönhart et al 2011b although by default the model does not provide output in terms of probabilities it implicitly is affected by stochastic uncertainty i e the existence of different but equally valid expert value judgment this uncertainty is located in the system data and could be expressed statistically e g by applying bayesian s theorem or as a scenario furthermore these crop rotation shares are available at a coarser spatial resolution than needed for epic so they have to be distributed across different spatial units with different soil topographical and climate characteristics this introduces the uncertainty of linkage extrapolation location which is caused by lack of observations nature and may be expressed as a scenario or deliberate ignorance type finally data on soils topography and management options provide further location sources of uncertainty in epic potential other uncertainties not visualized in fig 1 can be seen in the ufts in table 6 and table 7 appendix d and mostly relate to uncertainties that can only be expressed as deliberate or recognized ignorance for example we know that epic accounts for major biophysical processes in agricultural land management on areas smaller than 100 ha system boundaries context location the spatial heterogeneity e g soils topography of a region can only be captured by delineating homogenous response units hrus 6 6 individual location units e g 1 km grid cells are clustered as hrus that share similar soil and topographical characteristics this reduces the amount of simulations particularly for global scale analyses and thus saves valuable computational resources albeit at the expense of losing some information and thus introducing uncertainty and simulating these independently system resolution context location the development of hrus is an established method in biophysical crop modeling to deal with heterogeneity e g balkovič et al 2013 strauss et al 2013 stürmer et al 2013 however the flow of water sediment and nutrients across hrus is not considered in epic deliberate ignorance of known processes model structure location there might also be errors in code and mathematical formulations currently undetected and unknown factors that affect plant growth water and nutrient cycles considerably finally the importance of outputs from epic may be valued differently by stakeholders and decision makers decision support outcome location such as crop yields or agro ecological impacts e g nutrient emissions all of the uncertainties identified and described above are propagated to the outputs of epic for example crop and grassland yields or nutrient emissions hence these outputs are affected by uncertainty located in model structure e g gcms rcms co2 fertilization effect system data e g expert judgement on agronomic value of crop rotations and linkage extrapolation e g extrapolation of regional crop rotation shares to spatial simulation units in epic which are caused by both epistemic e g lack of observations lack of process understanding and stochastic e g inherent randomness expert judgment values uncertainty and expressed as scenario uncertainty i e quantified but without probabilities 4 2 3 global fasom and biomat by transferring crop yield and agro ecological data to global fasom or biomat a linkage extrapolation location uncertainty manifests in the imf be e g the spatial aggregation to the simulation units of global fasom 7 7 biomat and epic share the same spatial resolution 1 km so there is no need for spatial aggregation between these two models or the temporal aggregation of annual outputs from epic to average annual outputs for a specific period e g 30 years for biomat this reduces the variability of epic outputs but may lead to an underestimation of uncertainty this uncertainty may be quantified statistically type and is caused inter alia due to pragmatic system simplification epistemic uncertainty as the application of hrus and periods instead of years eases computational burdens therefore yield data can be both expressed as a scenario uncertainty e g gcm rcm rcps co2 fertilization evapotranspiration management specifications crop rotation data and each of these scenario uncertainties can contain statistical uncertainty due to the necessary extrapolation to global fasom and all other statistical uncertainty in epic outputs mainly system data hence one could apply both scenario analysis as well as statistical methods for quantifying uncertainties propagated from epic global fasom and biomat also inherent all ignorance uncertainty from epic e g pre determined crop rotations and management options the economic bottom up land use models global fasom and biomat are further affected by location uncertainty in system drivers e g shared socio economic pathways ssps see for example riahi et al 2017 which provide inputs for population and technological development agricultural ssps for europe i e eur agri ssps are currently being developed mitter et al 2018 2019 2020 this is a typical case of applying scenario uncertainty and analysis i e plausible narratives of internally consistent futures are quantified the nature of uncertainty is diverse similar to the nature of uncertainty underlying the climate data see section 4 2 1 both models are also affected by the choice and imprecision of the numerical solver i e model structure and hardware software location for example allowing small negligible deviations from the optimal solution of optimization problems in a numerical solver may reveal that very different endogenous variable choices may lead to almost identical optimization values e g welfare but considerably different outcomes for other criteria e g emissions the nature of this uncertainty can be attributed to inexactness unreliability epistemic uncertainty but also value judgements human variability stochastic uncertainty the type of uncertainty may be expressed statistically qualitatively or as a scenario a further uncertainty located in the economic bottom up land use models is parameter calibration uncertainty for example the calibration of physical resource and commodity reference values global fasom or the calibration of unknown cost factors functions to fit endogenous model land use variables to observed land use data global fasom biomat the nature of this uncertainty is mostly due to lack of observations practically immeasurability conflicting evidence unreliability and structural uncertainty epistemic uncertainty as well as behavioral variability human variability stochastic uncertainty it may be difficult to express this uncertainty statistically especially if parameters are calibrated so that model outputs fit observed data exactly i e for a given model structure and input data the calibrated value has a probability of one parameter uncertainty is thus intrinsically linked to both model structure and system data if uncertainty in system data can be expressed statistically this can be transmitted to parameter uncertainty although there is always one true value for each system data sample furthermore many different realizations of cost functions are possible e g linear or polynomial cost functions of different degrees this can be incorporated as scenario uncertainty biomat receives not only the uncertainty inherent in crop yields and environmental outcomes from epic as well as the associated linkage extrapolation uncertainty but also the uncertainty in prices from empirical data as well as prices from global fasom commodity output prices and dynk input prices and labor costs extrapolation will be necessary as global fasom and dynk consider considerably fewer commodities than available in biomat and one has to assume that relative price changes in one commodity are similar to related commodities if empirical data is available correlation coefficients and associated uncertainty values could be used to incorporate this uncertainty statistical uncertainty however this task will also involve some kind of deliberate ignorance i e assuming that very specific commodities are reflected by an aggregate commodity index furthermore commodity prices and labor costs are also affected by scenario uncertainty propagated due to the scenarios run by dynk and global fasom a comprehensive overview of uncertainties also including context uncertainties location as well as deliberate and recognized ignorance type can be seen in the uft for biomat here table 3 and for global fasom in appendix d table 8 for example both global fasom and biomat do not consider the full heterogeneity of farms and farmers which is a deliberate trade off in order to model larger regions they also do not directly account for the feedback from other sectors although this uncertainty can potentially be accounted for in the imf be by connecting biomat with dynk iteratively both land use models also assume that land use decisions are made with respect to annual decadal averages which may not adequately reflect the variability and associated risk preferences of farmers 4 2 4 dynk finally dynk will receive the uncertainty propagated through the output on value added from biomat linkage extrapolation uncertainty will manifest here as well biomat does not model sector output and input fully consistent with the input output framework e g investments and therefore does not correspond exactly to the absolute sector values in dynk therefore approximations have to be used practically this means that relative changes are used instead of absolute changes this can be viewed as deliberate ignorance however note that due the other uncertainties propagating to and within biomat and thus also to dynk value added is also expressed as a scenario uncertainty and within each scenario as statistical uncertainty similar to global fasom and biomat dynk is affected by uncertainty in system drivers population technological development export development quantified as scenario uncertainty with the same plethora of natural causes model structure uncertainty can be incorporated by different behavioral functions e g whether household expenditure is driven by changes in income or cash on hands this can be expressed as scenario uncertainty and the nature of this uncertainty can be attributed to conflicting evidence structural uncertainty epistemic uncertainty and human variability stochastic uncertainty important manifestations of uncertainty in the system data are the elasticities in the behavioral equations this uncertainty can be quantified statistically and is mostly due to lack of observations unreliability epistemic uncertainty but is also closely connected to the functional form and thus model structure uncertainty the same is true for the elasticities in the global fasom model 4 2 5 final overview indicators outcome obtained from the imf be can be used to evaluate policy and climate change impacts on the bio economy from global to local levels this can highlight for example associated trade offs between climate change adaptation and mitigation measures not all indicators will be obtained at the end of the model sequence some will already be provided by epic e g climate change impact on crop yields by geo spatial simulation units crops and management variants or by global fasom e g climate change impacts on trade balances commodity prices plant production ghg emissions and global land use change or by biomat e g climate change impacts on spatially explicit land use and land management choices and nutrient emissions in austria finally dynk can provide additional information on macro economic feedback and indicators e g sectoral outputs gpd as well as associated energy and ghg emissions the preceding sections illustrate how outcome indicators are influenced not only by uncertainty inherent within individual models but also through uncertainty propagation across the whole integrated modeling framework table 4 provides a final overview of where uncertainty has been identified in the imf be examined and how it might be expressed deliberate recognized ignorance is widely present especially in defining the context and system boundaries of all models but also with respect to model structure and hardware software issues there is generally a tendency to apply statistical uncertainty for system data and scenario uncertainty for system drivers however especially due to the propagation of uncertainty all combinations are present model uncertainty can be accounted for with a mix of scenario uncertainty e g selecting different equally plausible behavioral equations as well statistical uncertainty e g algorithm imprecision uncertainty created at the model linkages is specifically highlighted it is either expressed via statistical uncertainty e g aggregation or by deliberate ignorance i e accepting that some variables between models are not a perfect fit e g different commodity types and assuming that further model improvements are not worth the cost qualitative uncertainty is not of major importance for this quantitative integrated modeling framework we still highlight its importance with respect to the use of model outcomes for decision support the overview excludes the nature dimension as our exercise focuses on identifying uncertainties in order to account for them in subsequent quantitative uncertainty analysis the nature dimension is more helpful in identifying the causes of uncertainty and to identify ways to reduce it see also our discussion in section 5 5 discussion while our review rests heavily on the uft developed by walker et al 2003 we see our main contribution in comparing and assessing other available concepts and by showing that these concepts despite their different approaches often attributable to language ambiguity can be put under the umbrella of our newly adapted uft to our knowledge we also provide one of the first applications of such an uncertainty concept for an existing integrated modeling framework a notable exception for an earlier application is provided by refsgaard et al 2013 their approach is tailored towards eliciting important uncertainties for a specific issue e g climate change adaptation whereas we focus on eliciting uncertainty propagation pathways in a particular integrated modeling framework this makes clear that the objective of an analysis also influences which uncertainty dimensions are critical and how uncertainties are finally labeled our literature review suggests that small adjustments to the uft by walker et al 2003 might be warranted in this application the adjustments have proven adequate from an integrated modeling perspective potentially they could help to achieve the goals of an uncertainty concept for integrated modeling 1 a systematic reflection of locations and types of uncertainty propagation pathways 2 minimize chances that key uncertainties are overlooked and 3 facilitate communication among different disciplines policymakers and stakeholders von krauss et al 2006 the most important differences introduced in our uncertainty concept are the following we identified additional location categories that are crucial to integrated modeling specifically system resolution linkage norton et al 2006 skinner et al 2014 and decision support ascough et al 2008 norton et al 2006 skinner et al 2014 the importance of these categories is confirmed by the application of the uft to our imf be we use a more comprehensive definition for ignorance to highlight transparently not only where we accept that knowledge is missing recognized ignorance but that available knowledge is often deliberately ignored deliberate ignorance we use a more nuanced differentiation of the nature dimension we introduce color coding in the uft to highlight uncertainty propagation we develop in addition to the uft a system graph to aid the visualization of uncertainty propagation pathways along some of the uft dimensions especially the category linkage improves the applicability of the uft for integrated modeling it highlights that the uncertainty propagated to other models not only includes the interaction not the sum of all other uncertainties but that new uncertainty can be introduced with each model linkage the application of the uft for our imf be emphasizes this see section 4 considering deliberative ignorance also strengthens the uft for integrated modeling despite aiming at a holistic representation of human environmental interactions integrated modeling frameworks are per definition simplified reflections of reality whereby deliberative decisions for disregarding specific actors or processes are ubiquitous visualization techniques are used because humans are known to process visual information more effectively than pure textual information however if this effect can be achieved with color coding in the uft and with the help of a system graph requires further testing further improvements on how to visualize uncertainty propagation are certainly possible e g animated visualizations but will require to dedicate research resources to expertise in graphic design our synthesis and the adapted uncertainty concept have been oriented to applications of individual models and integrated modeling although our motivation is thus on accounting for uncertainty and not on reducing uncertainty these two aspects are not necessarily mutually exclusive unfortunately project research resources often only allow for one or the other by including the nature dimension the uft should also help to think about the actual cause s of uncertainty manifestations in integrated modeling identifying and accounting for uncertainty can be seen as a prerequisite for knowing where resources should be dedicated in the future for reducing uncertainty if possible it also seems that major discrepancies between manifestation and causes of uncertainty in the literature can be traced back to these implicit motivations i e publications that focus on reducing uncertainty see location and cause as identical whereas publications that focus on accounting for uncertainty aim to identify manifestations of uncertainty in order to account for them the concept and application shown in this article clearly belongs to the latter group evidently the uncertainty concept is not free of drawbacks norton el 2006 criticize that the implicit ordering of uncertainty types from statistical to ignorance introduces a false notion of confidence this was probably more relevant for the original label of this dimension by walker et al 2003 i e level of uncertainty by following gabbert et al 2010 in labeling this dimension type we hopefully avoid this false notion walker et al 2003 acknowledge that their uft is not free of ambiguity and that attributing uncertainty to only particular parts of the uft dimensions might not be possible we agree and add that ambiguity is mostly related to the uncertainty dimensions type and nature although there is also much overlap between the category system boundaries in the location dimension and the category deliberative ignorance in the type dimension the location manifestation of uncertainty can mostly be pinpointed exactly in a particular integrated modeling framework an exemption to this argument is parameter uncertainty as this is closely linked to both system data and model structure uncertainty refsgaard et al 2007 some publications did aim to provide an unambiguous taxonomy i e uncertainty is attributed to only one location type and nature e g warmink et al 2010 these are often publications that implicitly assume location to be the ultimate cause of uncertainty and not the manifestation in the model ascough et al 2008 skinner et al 2014 however we remain unconvinced that this is a reasonable approach especially for the nature dimension for example the combined nature category by skinner et al 2014 is obsolete if one defines model structure as part of the location manifestation dimension of uncertainty and acknowledges that it is caused by both epistemic and stochastic uncertainty nature dimension similarly the uncertainty concept by ascough et al 2008 implicitly suggests that model uncertainty is solely caused by epistemic uncertainty an argument that does not hold if closely scrutinized the attempt by warmink et al 2010 to elicit unique attributions of location type and nature to specific uncertainties is commendable but neglects that i recognized or deliberate ignorance might always be present especially with respect to model uncertainty and that ii there can be strong interaction between epistemic and stochastic variability e g assuming that the period of peak discharge is solely a natural variability implicitly assumes that one has collected so much data that there is no epistemic uncertainty left it seems reasonable to assume that some of the uncertainty in peak discharge might also be caused by a lack of observations skinner et al 2014 criticize that typologies commonly applied are subjective based on small scale literature reviews and as is partly the case here simply amalgamations of existing uncertainty concepts instead they derived an inductive based empirical novel typology based on almost 200 environmental weight of evidence assessments this is laudable but still restricts the typology to a specific area subjectivity will also remain an issue due the inherent subjectivity of uncertainty selection in the assessments themselves a non empirical deductive based concept comes with the advantage that it may encompass important aspects typologies that have not been considered in empirical analyses so far in addition uncertainty propagation analyses for integrated modeling and specifically imf be are rarely conducted so our empirical sample would be too small for such an approach finally we do not see why amalgamations are valued negative if the advantages of previous approaches are combined in a new context the process of amalgamation might reveal that concepts are not that different as skinner et al 2014 for example suggest we think that the concepts and typologies reviewed here can all be reasonably amalgamated into the uft by walker et al 2003 this reasoning also suggests an uft may be easily applied by other integrated modeling frameworks or single models nonetheless it will remain impossible to develop a fully generic approach for the diversity of integrated modeling frameworks available and under development this is evident by the numerous failed efforts to establish a generic approach and to define the standard bastin et al 2013 matott et al 2009 we thus refrain from claiming to have identified a new standard or the only approach suitable for integrated modeling in contrast our analysis highlights that there is much to gain from established although at times seemingly inconsistent concepts while the dimensions location type and nature may be appropriate to structure uncertainties in various integrated modeling frameworks adaptations in the sub dimensions may be necessary for specific research and model domains our uncertainty concept for integrated modeling is clearly tailored toward producers of model output i e model developers and model users and not users of model output i e stakeholders a criticism already raised by norton et al 2006 with respect to the uft by walker et al 2003 it has to be acknowledged that the user s or stakeholder s perspective may differ substantially from the producer s or model developer s perspective congalton 1991 gabbert et al 2010 users are primarily interested in the uncertainty range of model outcomes and parameters while model developers interest often spans across all uncertainty aspects gabbert et al 2010 hence while the oversight and visualization of uncertainty propagation in integrated modeling might be of particular interest to model developers it remains to be seen if this provides added value to stakeholders in the course of our research we were able to present this concept to stakeholders from the austrian ministry of sustainability and tourism researchers from other disciplines social ecology climatology and agricultural extension services the general response from these potential users to the uncertainty concept presented here was rather favorable indicating that a deeper insight into uncertainty concepts and propagation pathways could indeed be a helpful visualization and communication tool in stakeholder interaction however as in gabbert et al 2010 they were much more interested in the uncertainty of model outcomes than in identifying the location type or nature of uncertainties much more stakeholder interactions are required to empirically validate this first impression and to adjust the uncertainty concept to stakeholder needs 6 conclusion and outlook we provide a review of uncertainty concepts which has shown that the uncertainty framework table uft developed by walker et al 2003 still remains state of the art and useful for capturing uncertainties in integrated modeling we identify various additional uncertainty categories that could be included acknowledging a modeler s perspective and a focus on uncertainty propagation in integrated modeling e g system resolution linkage deliberate ignorance furthermore we make a first attempt to visualize uncertainty propagation pathways through color coding in ufts and a system graph to indicate the applicability of such a model application oriented uncertainty concept we applied it in an existing integrated modeling framework for the bio economy imf be this application has facilitated overview and communication of uncertainties among researchers with different disciplinary backgrounds there is still room for improvement the general applicability of our uncertainty concept can only be shown if other integrated modeling teams apply this particular concept as well while our uncertainty concept focuses on the modeler s perspective the uft and the visualization of uncertainty propagation should in a next step be tailored towards stakeholder user needs by focusing on how to properly communicate uncertainty or by developing software for a better interactive visualization this requires thorough testing with potential users of model outputs and the dedication of research resources to graphic design and communication science the uncertainty concept might also be further improved by developing a variant that allows a more detailed investigation of uncertainties as the concept developed here remains on a rather aggregate level in addition to these limitations it remains to be emphasized that there are likely more limitations that we are currently not aware of total ignorance unknown unknowns keeping these caveats in mind we think that the uncertainty concept developed here could be particularly useful in order to provide a comprehensive yet relatively concise overview of relevant uncertainties as well as of uncertainty propagation pathways to be addressed in an integrated modeling framework this makes it an ideal prerequisite for conducting appropriate quantitative or qualitative uncertainty analyses by identifying relevant locations pathways and types of uncertainties or if the level of detail remains too aggregate for an actual uncertainty analysis it can at least highlight where more effort for identifying uncertainties should be dedicated to all of this may help to increase understanding transparency and trust in integrated modeling exercises especially with respect to the communication between scientists and with relevant stakeholders declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research has been supported by the project uncertprop uncertainty propagation in integrated modeling approaches for global change impacts on the bio economy funded by the austrian klima und energiefonds climate and energy fund within the austrian climate research program acrp funding number kr16ac0k13332 the study also contributes to the cluster of excellence cliccs climate climatic change and society of universität hamburg and the associated helmholtz excellence network exnet 0025 phase 2 3 the publication is further supported by the university of natural resources and life sciences boku vienna open access publishing fund we highly appreciate the helpful feedback of three anonymous reviewers which helped greatly in improving this paper appendix appendix a research background given the diversity of uncertainty concepts available in the literature which seem to stem from both different methodological and disciplinary backgrounds e g nature conservation management vs hydrological modeling and pursue different aims e g pragmatic applications vs consistent scientific theories we aim to transparently communicate our research background and approach the uncertainty dimensions are explored for an existing integrated modeling framework for the bio economy imf be which focuses on the sustainability of the bio economy in an era of global change the essential core modeling framework usually comprises of a sequential linkage between a climate change model or data a biophysical process model that simulates plant growth and nutrient emissions an agronomic model to derive crop rotations and a spatially explicit economic bottom up economic land use farm model for the agriculture and forestry sector with a geographic core focus on austria feusthuber et al 2017 kirchner et al 2016 kirchner and schmid 2013 mitter et al 2015a 2015b schönhart et al 2011a in the past this core modeling framework has been adapted and extended in various forms e g with energy system models schmidt et al 2012 forestry growth and macro economic models kirchner et al 2015 mitter et al 2015c biorefinery models höltinger et al 2014 hydrological models schönhart et al 2018 zessner et al 2017 or gis based landscape elements analysis kirchner et al 2015 schönhart et al 2016 the applications focused primarily on climate change i e impacts adaptation and or mitigation with focus on land use and agricultural environmental climate and or energy policies e g agri environmental programs pest management the model applications have always aimed at providing a diverse set of indicators to assess the consequences of drivers and policies on sustainability e g environmental indicators such as nitrogen phosphorous and ghg emissions biodiversity or soil erosion and socio economic indicators such as farm income gross margins gdp or landscape amenities and thus to provide guidance to various stakeholders such as agricultural extension specialists and administration hence stakeholder participation has been of particular focus in many applications mitter et al 2014 schönhart et al 2018 more recent publications now also focus more on uncertainty propagation specifically the impact of stochastic climate change scenarios karner et al 2019 mitter and schmid 2019 other imf be that bear similarities to ours are for example briner et al 2012 leclère et al 2013 the seamless if integrated modeling framework gabbert et al 2010 van ittersum et al 2008 as well as the integrated modeling frameworks considered in nelson et al 2014 such as globiom frank et al 2013 schneider et al 2011 appendix b literature overview we based our literature review on various combinations of the following search terms uncertainty uncertainty concept uncertainty propagation uncertainty framework modeling integrated modeling google scholar and scopus were primarily used to obtain first search results we identified key articles i e funtowicz and ravetz 1990 van asselt and rotmans 2002 walker et al 2003 that fit our review purposes and from those we applied the snowball method to obtain more relevant publications i e looking at the references as well as citations of each publication moreover we specifically searched the journal of environmental modeling and software as well as the now terminated the integrated assessment journal which both published key articles on the topic of uncertainty and modeling the relevant publications selected by us are shown in table 5 table 5 overview of sci publications on uncertainty concepts considered in the literature review table 5 appendix c framing uncertainty the nature of uncertainty this appendix section summarizes differences as well as overlaps in the literature identified in particular with respect to sub categories in the uncertainty framework table uft fig 2 should aid in understanding the following paragraphs as it is not a straightforward task to compare the sometimes quite disparate approaches and the different nomenclature applied beside differences in the number and types of primary causes of uncertainty some more notable disagreements can be found at an aggregate level skinner et al 2014 classify linguistic uncertainty as a sub category of epistemic uncertainty claiming that imprecision in language can theoretically be both quantified and eliminated furthermore they allow a combined category that refers to both epistemic and stochastic uncertainty this highlights that the causes of uncertainty do not have to be mutually exclusive and may be quite interlinked refsgaard et al 2007 i e uncertainty in specific data inputs may be caused by multiple primary causes of uncertainty regan et al 2002 p 620 identify natural uncertainty as a sub category of epistemic uncertainty although they explicitly acknowledge that natural variation is not a cause of epistemic uncertainty per se and that inherent randomness occurs not because of our limited understanding but because the system is irreducible to a deterministic one we would agree with most other authors that it is convenient to highlight stochastic uncertainty next to other primary causes of uncertainty 8 8 the distinction between ontology the state of being natural variability and epistemology the state of knowing has its origins in greek philosophy socrates as pointed out by brown 2004 some publications offer further sub categories which introduce more differences and nuances especially with respect to epistemic uncertainty for example funtowicz and ravetz 1990 who implicitly only address epistemic uncertainty classify causes of uncertainty into i inexactness error ii unreliability systematic error confidence in assessment and iii border with ignorance gaps in knowledge in a similar manner and partly based on funtowicz and ravetz 1990 rotmans and van asselt 2001 as well as van asselt and rotmans 2002 categorize epistemic uncertainty into a unreliability which comprises of inexactness we roughly know lack of observations we could have known and practically immeasurable we know what we do not know as well as b structural uncertainty which comprises of conflicting evidence we don t know what we know reducible ignorance we don t know what we do not know indeterminacy we will never know and irreducible ignorance we cannot know regan et al 2002 distinguish between measurement errors systematic errors bias and model uncertainty simplification of reality as well as inherent randomness system is irreducible to a deterministic one natural variation system is too difficult to predict and subjective judgment interpretation of data as mentioned above it may be more suitable to attribute inherent randomness and natural variation to stochastic uncertainty whereas subjective judgment values is attributed by others to stochastic uncertainty rotmans and van asselt 2001 van asselt and rotmans 2002 or if assumed to be related to decision uncertainty as its own primary cause ascough et al 2008 warmink et al 2010 ascough et al 2008 differentiate between i process understanding limits of scientific understanding ii model uncertainty which is further disaggregated into parametric data uncertainty e g measurement errors misclassifications lack of observations structural uncertainty simplification and technical uncertainty software or hardware errors as well as iii model output accumulated uncertainty skinner et al 2014 provide the most comprehensive sub categorization and identify a data uncertainty which comprises of precision accuracy availability incompleteness and reliability trustworthiness b system uncertainty which comprises of process not understanding something vital to the assessment cause lack of clarity regarding the source of an outcome and effect lack of knowledge about the influence of the source on the outcome as well as c model uncertainty which comprises of structure representation of real world systems and output confidence in results as well as decision uncertainty doubt due to the accumulated uncertainty model and decision uncertainty is subsumed under their category of combined uncertainty which refers to the existence of both epistemic and stochastic uncertainty this is distinct from ascough et al 2008 who use decision as its own primary cause of uncertainty next to epistemic stochastic and linguistic uncertainty ascough et al 2008 disaggregate decision uncertainty into goals and objectives as well as assessment criteria compared to the sub categories of epistemic uncertainty there seem to be more similarities with respect to the sub categories of linguistic uncertainty as well as stochastic uncertainty three publications address linguistic uncertainty explicitly although ascough et al 2008 and skinner et al 2014 thereby follow the publication on linguistic uncertainty by regan et al 2002 while all three emphasize vagueness unclear meanings ambiguity multiple meanings and underspecificity unwanted generalization regan et al 2002 further identified linguistic uncertainty due to the indeterminacy of theoretical terms future use of theoretical terms may change as well as context dependency failure to specify context stochastic uncertainty is categorized by rotmans and van asselt 2001 as well as van asselt and rotmans 2002 into 1 inherent randomness unpredictable natural processes 2 value diversity norms views and values 3 behavioral human variability e g cognitive dissonance 4 societal social economic cultural variability e g policy agreements institutional conditions and 5 technological surprises ascough et al 2008 provide an almost identical classification the distinction between natural and human variability is also found in skinner et al 2014 who in addition also introduce extrapolation as another important sub category of natural uncertainty which encompasses intraspecies from species member to other species member interspecies from one species to another species laboratory from laboratory to the real world quantitative from one quantity to another spatial from one scale to another and temporal from one timescale to another extrapolation as highlighted above regan et al 2002 distinguish between inherent randomness natural variation and subjective judgment but classify them as part of epistemic uncertainty fig 2 framing the nature of uncertainty own note sub categories have been vertically aligned if assumed to be synonymous or similar and colors correspond to the primary causes of uncertainty for interpretation of the references to color in this figure legend the reader is referred to the web version of this article fig 2 the location of uncertainty walker et al 2003 who explicitly focus on the manifestation of uncertainty within a model provide the following categorization of uncertainty locations 1 context e g model boundaries 2 inputs and data a system data e g the initial data for the system under investigation b driving forces e g data for the driving forces of the system under investigation 3 parameters i e calibrated data 4 model a structure e g simplification mathematical formulas algorithms b technical implementation e g software or hardware errors 5 outcomes e g the accumulated uncertainty subsequent publications that draw on the uncertainty concept developed by walker et al 2003 adopt this classification with negligible modifications e g classifying parameter calibration as part of the aggregate category inputs data gabbert et al 2010 or model refsgaard et al 2007 whereas warmink et al 2010 simply do not provide different levels of aggregation similar classifications of locations can also be found in earlier publications see figure 3 for an overview kann and weyant 2000 distinguish between exogenous e g data and parameters endogenous processes e g model structure technical approaches for simplifying models and value judgments e g choice of discount rate from our point of view value judgments may be rather seen as part of the nature dimension than the location dimension for example uncertainty with respect to the chosen discount rate manifests itself in the input data i e the quantified discount rate which is caused by different value judgments stochastic or decision uncertainty rotmans and van asselt 2001 as well as van asselt and rotmans 2002 identified the following potential locations of uncertainty model quantities e g data and parameters model form e g structure algorithms model adequacy e g representation of relevant processes and model operation e g technical errors as with kann and weyant 2000 in the case of value judgment it might be better to classify model adequacy as a cause nature of uncertainty which manifests in the chosen model structure or to alternatively frame it as part of model context and boundaries matott et al 2009 differentiate between input uncertainty and model uncertainty input uncertainty includes data e g initial and boundary conditions response data e g site specific measurements or expert judgments and calibrated parameters model uncertainty refers to structure e g hypotheses equations resolution e g spatio temporal boundaries code e g algorithms solvers and correspondence e g representation of real world systems system resolution might be better viewed as part of model boundaries and correspondences might fit better within the nature dimension e g does it represent real world processes with respect to those publications that define the location of uncertainty more or less synonymous with the nature of uncertainty one still finds a resemblance with the categories above ascough et al 2008 who see model uncertainty as a distinct part of epistemic uncertainty disaggregate it into data parameters structure and technical issues as well as model output bastin et al 2013 provide a lot of detail on the location of input uncertainty which includes measurement errors representativeness sensor uncertainty or transmission uncertainty as well as model uncertainty which includes structure e g simplification representation e g spatio temporal calibrated parameters and numerical uncertainty e g solver imprecision finally skinner et al 2014 define the location of uncertainty as a sub level of the nature dimension of uncertainty i e their sub categories in the nature dimension displayed in fig 2 are explicitly labeled location of uncertainty by them this includes relevant locations manifestations of uncertainty from our point of view i e where uncertainty manifests in the model or integrated modeling framework such as data uncertainty e g availability precision and reliability model uncertainty e g simplifications structure and technical and output extrapolation and decision uncertainty e g accumulated uncertainty fig 3 framing the location manifestation of uncertainty in imf own note sub categories have been vertically aligned if assumed to be synonymous or similar and colors correspond to the primary locations of uncertainty for interpretation of the references to color in this figure legend the reader is referred to the web version of this article fig 3 appendix d uncertainty framework tables ufts table 6 uncertainty framework table uft for croprota table 6 table 7 uncertainty framework table uft for epic table 7 table 8 uncertainty framework table uft for global fasom table 8 table 9 uncertainty framework table uft for dynk table 9 
25899,we wish to introduce qwet a new version of the free and open source qgis plugin for the aquatic ecosystem model wet qwet is as a graphical user interface for the application evaluation and experimentation of wet several new features have been incorporated since its predecessor and here we demonstrate elements of the new plugin by applying it to danish lake ravn among others we compare model simulations against observations and describe how the scenario platform now supports scheduling of state variable manipulation which allows users to explore lake or reservoir restoration interventions such as biomanipulation and oxygenation with qwet we seek to aid practitioners who do not possess the sufficient technical expertise to operate a state of the art complex model system such as wet and thereby hope to facilitate a wider use and adaptation of aquatic ecosystem models keywords lake and reservoir modelling qgis plugin python wet gotm swat software availability name of software qwet developers anders nielsen fenjuan rose schmidt hu nicolas azaña schnedler meyer karsten bolding tobias kuhlmann andersen dennis trolle contact address department of bioscience aarhus university vejlsøvej 25 8600 silkeborg denmark email wet info wet au dk availability www wet au dk license freely available under gnu general public license gpl version 2 1 introduction eutrophication of lakes and reservoirs is a global challenge wurtsbaugh et al 2019 with severe implications for their ecosystem services schallenberg et al 2013 whether a lake or reservoir provides recreational facilities or acts as a fundamental drinking water resource for local communities scientists policy makes managers and consultants aim to understand the reasons behind or examine ways to restore and improve deteriorated water quality to support decision making or scientific examination mathematical models provide a fundamental platform by acting as a virtual laboratory for hypothesis testing or scenario simulation prior to actual implementation of mitigation measures hipsey et al 2015 however application of mathematical models to lakes and reservoirs requires a substantial level of expertise which may hamper their broader adaptation and utilization to provide users with a standardised and easy to use workflow for model application and evaluation of aquatic ecosystems the water ecosystems tool wet was introduced in 2017 as a plugin for qgis 2 x nielsen et al 2017 the plugin operated on top of the coupled one dimensional hydrodynamic ecosystem model gotm fabm pclake bruggeman and bolding 2014 hu et al 2016 umlauf et al 2005 however recent efforts by schnedler meyer et al 2020 have made significant advances to the designated aquatic ecosystem model fabm pclake producing an update representing a new generation still fabm compatible enabling coupling to multiple physical models completely modularised aquatic ecosystem model that allows flexibility in terms of food web configuration moreover the model has been upgraded with features from other state of the art models providing users with options for simulating e g nitrogen fixation and utilising concepts of the foraging arena theory to mediate predator prey interactions to distinctively embody this new aquatic ecosystem model with its capability the developers of the model core and the supporting qgis plugin decided to change the name of the model interface to the qgis water ecosystems tool qwet in this communication we present qwet a new version of the former graphical user interface gui developed as qgis plugin by nielsen et al 2017 with the release of qwet the interface has upgraded its compatibility to accommodate the new aquatic ecosystem model wet coupled to the hydrodynamic model gotm the general ocean turbulence model burchard and bolding 2001 umlauf et al 2005 i e the gotm wet model complex moreover several new features have been implemented into the interface which is now available for qgis 3 x here we demonstrate the features and capabilities of qwet by applying it to lake ravn a mesotrophic lake situated on the peninsula jutland in northern europe latitude 56 105 longitude 9 843 the lake has a surface area of 1 8 km2 a maximum depth of 33 m a mean depth of 15 m and a hydraulic retention time of approximately 1 8 years its watershed is approximately 57 km2 consisting primarily of arable land 70 the lake stratifies approximately five months each year causing oxygen depletion in the hypolimnion and consequently phosphate release from the sediment which stimulates harmful algal blooms in summer trolle et al 2008 qwet is free and open source and echoes the philosophy of its predecessor it seeks to empower users who may otherwise lack the sufficient technical expertise to operate a state of the art complex model system with a stepwise gui for configuration initialisation and model execution similar efforts albeit in other scientific disciplines have been accomplished for e g the soil water assessment tool swat by dile et al 2016 the swat modflow coupled model by park et al 2019 and the weather research and forecasting model wrf by meyer and riechert 2019 modelling experts with solid knowledge of file structures and formatting requirements are capable of operating a model like gotm wet outside an interface via script syntaxes to conduct advanced tasks or to achieve a degree of automation and efficiency of their workflows but an interface reduces the technical skillset requirements for new users and may thus facilitate wider use and adaptation of aquatic ecosystem models 2 overview dependencies and structure qwet was developed to accommodate the model complex gotm wet which is a process based coupled hydrodynamic ecosystem model gotm facilitates a one dimensional representation of the physical domain by accounting for hydrodynamic and thermodynamic essentials in the water column related to vertical mixing burchard and bolding 2001 and wet via state of the art conceptual representations mimics the most important biotic and abiotic functions in the aquatic ecosystem wet is based on the fabm pclake model hu et al 2016 which again is a further development of the original pclake model by janse and van liere 1995 for a detailed description of wet its legacy complexity and concept please see schnedler meyer et al 2020 the hydrodynamic model and the ecosystem model are coupled with two way interaction and dependencies via the framework for aquatic biogeochemical models fabm bruggeman and bolding 2014 since its predecessor qwet has been upgraded to python 3 and is thus available for qgis 3 x to install qwet users must first install the latest stable version of qgis 3 https download qgis org and proceed with the designated qwet plugin installer available at www wet au dk the plugin installation is swift followed by manual one time activation via the manage and install plugins window under the plugins menu in qgis qwet may then be launched from its toolbar within qgis fig 1 in the first release of the plugin nielsen et al 2017 users had to manually and through command prompt syntaxes update the local underlying python environment with certain third party packages that were not included in qgis by default tedious steps that counteracted our intention of lowering the bar for novice model users as highlighted by meyer and riechert 2019 this required programming skills of users to resolve potential installation problems not least in windows due to the demand for administrator privileges for package installation now all dependency packages are directly embedded within qwet and additional python system updates or installations via python s standard package manager pip are not needed this may have some downsides as described by meyer and riechert 2019 but system wise the tool is independent with its own control of package versioning and importantly easy to deploy in addition to qwet s built in plotting functions users may browse model simulations via pyncview a cross platform netcdf viewer developed by bolding bruggeman www bolding bruggeman com pyncview requires independent installation and is available at pypi org once installed the core structure of a qwet project is similar to that of its earlier version and relies on a qgis qgz project file and a neighbouring project specific directory where all project inputs and simulation outputs as well as project specific information are stored in a sqlite database www sqlite org see nielsen et al 2017 for details to anchor explicitly to the model complex gotm wet with a now radically changed model core and almost entirely yaml based configuration files https yaml org qwet is not backward compatible as such editing and execution of projects created through the previous plugin are not supported and users are instead encouraged to set up already existing projects from scratch in qwet 3 required inputs qwet has inherited prerequisites for inputs and configurations from its predecessor and builds on the principle of enabling users to set up a model for a given lake or reservoir based on only a few key details surface area m2 maximum depth m and a number of vertical layers water inflow m3 s and associated nutrient concentrations mg l provided as constants and finally information about the weather optionally represented by a suite of pre defined meteorological time series from the european centre for medium range weather forecasts ecmwf dee et al 2011 available in qwet from here users may choose to refine their configuration and setup by providing hypsographs the relationship between depth m and the corresponding horizontal area m2 to qualify the approximation of the physical domain or time series on inflow and associated nutrients from the watershed in order to better resolve actual transports into the modelled system users also have the option of linking to the watershed model swat soil water assessment tool by arnold et al 1998 when needed nielsen et al 2017 provide a detailed description of configuration options supported by tutorials and test datasets at www wet au dk applicable for qwet 4 new features 4 1 selecting conceptual model representations of the ecosystem a new feature that we proudly present is the possibility of utilising parts of the new modular configuration concept characterising the aquatic ecosystem model wet by schnedler meyer et al 2020 enabling configuration of different model complexities for a given application when creating a new qwet project users may now choose between three different templates i e conceptual representations for the ecosystem fig 2 template 1 a simple nutrient phytoplankton zooplankton detritus npzd representation template 2 a representation equivalent to fabm pclake hu et al 2016 including nutrients three phytoplankton groups zooplankton zoobenthos piscivorous zooplanktivorous and benthivorous fish and macrophytes and template 3 an advanced version of template 2 expanded with an additional zooplankton group several other conceptual representations may be of relevance to tailor case specific needs and qwet supports inclusion of additional templates upon request for our study case danish lake ravn we used template 3 the physical domain was represented by a lake specific hypsograph and time series of inflowing water and associated nutrients were obtained from the danish national monitoring program of the aquatic environment novana model calibration from 1996 to 2000 with 6 prior years of warm up was conducted outside qwet via parsac see https pypi org project parsac a calibration tool that utilises a differential evolution algorithm to calibrate model parameters through optimisation against a maximum likelihood function see chen et al 2019 moras et al 2019 and andersen et al 2020 for other application cases 4 2 accessing model parameters in gui popup to improve the user experience model parameters and model settings in both the physical and aquatic ecosystem domains are now available in qwet via a tree structured gui popup fig 3 users are assisted by various predesigned categorisations fig 3 a for quicker browsing and can change parameter values or initial values of state variables via for instance calibration schemes moreover where needed model settings can be customized by changing e g the methods for determining phytoplankton and light inhibition or by activating ice simulation or nitrogen fixation for cyanobacteria 4 3 comparing model simulations against observations the obs tab now allows qwet users to compare and evaluate model performance against observations thus navigation to an external model directory is possible if e g calibration is conducted via auto calibration routines outside the plugin time series of observation variables should be provided with each variable in its own text file the format obs analogous with that of parsac and tutorial videos of how to import observations into the plugin are provided at www wet au dk fig 4 exemplifies data on lake ravn displaying the modelled and observed water temperature oc users may switch between the variable displayed the temporal period to be viewed and the depth related boundaries to query data for only parts of the water column e g from the surface to 5 m depth fig 4 a moreover users may select between displaying the data as a combined line and scatterplot fig 4 b as a line plot fig 4 c or as profiles not shown conveniently the data and thus the plot rendering may be separated to permit distinction between calibration and validation fig 4 c along with plot generation qwet also produces various statistics e g nash sutcliffe efficiency bias root mean square error and coefficient of determination not shown here to assist users in quantifying the model performance 4 4 introducing manipulations as a scenario feature in the previous version of the plugin a scenario platform was implemented by which users were able to conduct and examine the impacts of climate change scenarios by altering the forcing air temperature or changing the nutrient loads to the lake or reservoir in qwet this scenario platform has been expanded with the possibility of designing and applying manipulations to model state variables with this feature users can mimic and assess various management actions such as the consequences of biomanipulation jeppesen et al 2012 or the effects of oxygenation liboriussen et al 2009 manipulations can now be conducted using either a multiplier that manipulates a state variable during a specific time e g removal of a certain percentage of fish or a rate of change that either increases or decreases a state variable by a specified rate during a specified time interval for the latter a threshold value may also be assigned to control the onset of manipulation e g application of oxygenation only when oxygen levels are below a given threshold to demonstrate its potential usage we simulated oxygenation in the hypolimnion of lake ravn fig 5 with an activation threshold of 6 mg l operating from 2002 onwards in response the simulated hypolimnetic dissolved oxygen concentration rose fig 5 c compared with the pre oxygenation period fig 5 b as such qwet functions as a tool aiding in examining and quantifying oxygenation levels to counteract hypolimnetic oxygen depletion during summer in stratified eutrophic lakes prior to actual implementation of restoration interventions 5 conclusions and future work qwet is a new version of the qgis plugin that allows users to operate and experiment with the gotm fabm pclake model through a gui based workflow qwet now accommodates wet the next generation of fabm pclake a highly customisable aquatic ecosystem model qwet has been upgraded with a new model core and several new features that ease its application for beginners in the aquatic ecosystem modelling discipline and hopefully it will also facilitate further model application worldwide through qwet users may configure run alter and visualise model simulations compare simulations against observations and conduct experimental scenarios in the future development of qwet we aim to accommodate linkage to the watershed model qswat and thereby substitute the current support of the ordinary qswat model another aim is to obtain platform independence to support both linux and macos in addition to its current windows affiliation moreover we will endeavor to explore and qualify how dependencies to third party packages are handled by the plugin possibly via a dedicated component that checks for missing packages and prompts installation ideally plugin dependencies should be processed by qgis itself possibly through incorporation of a flexible plugin dependency declaration similar to the way in which ordinary python package development declares dependencies building such logic into qgis would greatly advance plugin development and potentially also enhance the possibilities of ordinary gis processing by avoiding the currently required tedious installation of special python packages declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the development of qwet was supported by watexr funded by the eu jpi climate initiative prognos project funded by the eu jpi water initiative cashfish funded by the danish council for independent research and a project on mechanistic models for water action planning funded by the danish environmental protection agency moreover we thank anne mette poulsen for valuable editorial comments 
25899,we wish to introduce qwet a new version of the free and open source qgis plugin for the aquatic ecosystem model wet qwet is as a graphical user interface for the application evaluation and experimentation of wet several new features have been incorporated since its predecessor and here we demonstrate elements of the new plugin by applying it to danish lake ravn among others we compare model simulations against observations and describe how the scenario platform now supports scheduling of state variable manipulation which allows users to explore lake or reservoir restoration interventions such as biomanipulation and oxygenation with qwet we seek to aid practitioners who do not possess the sufficient technical expertise to operate a state of the art complex model system such as wet and thereby hope to facilitate a wider use and adaptation of aquatic ecosystem models keywords lake and reservoir modelling qgis plugin python wet gotm swat software availability name of software qwet developers anders nielsen fenjuan rose schmidt hu nicolas azaña schnedler meyer karsten bolding tobias kuhlmann andersen dennis trolle contact address department of bioscience aarhus university vejlsøvej 25 8600 silkeborg denmark email wet info wet au dk availability www wet au dk license freely available under gnu general public license gpl version 2 1 introduction eutrophication of lakes and reservoirs is a global challenge wurtsbaugh et al 2019 with severe implications for their ecosystem services schallenberg et al 2013 whether a lake or reservoir provides recreational facilities or acts as a fundamental drinking water resource for local communities scientists policy makes managers and consultants aim to understand the reasons behind or examine ways to restore and improve deteriorated water quality to support decision making or scientific examination mathematical models provide a fundamental platform by acting as a virtual laboratory for hypothesis testing or scenario simulation prior to actual implementation of mitigation measures hipsey et al 2015 however application of mathematical models to lakes and reservoirs requires a substantial level of expertise which may hamper their broader adaptation and utilization to provide users with a standardised and easy to use workflow for model application and evaluation of aquatic ecosystems the water ecosystems tool wet was introduced in 2017 as a plugin for qgis 2 x nielsen et al 2017 the plugin operated on top of the coupled one dimensional hydrodynamic ecosystem model gotm fabm pclake bruggeman and bolding 2014 hu et al 2016 umlauf et al 2005 however recent efforts by schnedler meyer et al 2020 have made significant advances to the designated aquatic ecosystem model fabm pclake producing an update representing a new generation still fabm compatible enabling coupling to multiple physical models completely modularised aquatic ecosystem model that allows flexibility in terms of food web configuration moreover the model has been upgraded with features from other state of the art models providing users with options for simulating e g nitrogen fixation and utilising concepts of the foraging arena theory to mediate predator prey interactions to distinctively embody this new aquatic ecosystem model with its capability the developers of the model core and the supporting qgis plugin decided to change the name of the model interface to the qgis water ecosystems tool qwet in this communication we present qwet a new version of the former graphical user interface gui developed as qgis plugin by nielsen et al 2017 with the release of qwet the interface has upgraded its compatibility to accommodate the new aquatic ecosystem model wet coupled to the hydrodynamic model gotm the general ocean turbulence model burchard and bolding 2001 umlauf et al 2005 i e the gotm wet model complex moreover several new features have been implemented into the interface which is now available for qgis 3 x here we demonstrate the features and capabilities of qwet by applying it to lake ravn a mesotrophic lake situated on the peninsula jutland in northern europe latitude 56 105 longitude 9 843 the lake has a surface area of 1 8 km2 a maximum depth of 33 m a mean depth of 15 m and a hydraulic retention time of approximately 1 8 years its watershed is approximately 57 km2 consisting primarily of arable land 70 the lake stratifies approximately five months each year causing oxygen depletion in the hypolimnion and consequently phosphate release from the sediment which stimulates harmful algal blooms in summer trolle et al 2008 qwet is free and open source and echoes the philosophy of its predecessor it seeks to empower users who may otherwise lack the sufficient technical expertise to operate a state of the art complex model system with a stepwise gui for configuration initialisation and model execution similar efforts albeit in other scientific disciplines have been accomplished for e g the soil water assessment tool swat by dile et al 2016 the swat modflow coupled model by park et al 2019 and the weather research and forecasting model wrf by meyer and riechert 2019 modelling experts with solid knowledge of file structures and formatting requirements are capable of operating a model like gotm wet outside an interface via script syntaxes to conduct advanced tasks or to achieve a degree of automation and efficiency of their workflows but an interface reduces the technical skillset requirements for new users and may thus facilitate wider use and adaptation of aquatic ecosystem models 2 overview dependencies and structure qwet was developed to accommodate the model complex gotm wet which is a process based coupled hydrodynamic ecosystem model gotm facilitates a one dimensional representation of the physical domain by accounting for hydrodynamic and thermodynamic essentials in the water column related to vertical mixing burchard and bolding 2001 and wet via state of the art conceptual representations mimics the most important biotic and abiotic functions in the aquatic ecosystem wet is based on the fabm pclake model hu et al 2016 which again is a further development of the original pclake model by janse and van liere 1995 for a detailed description of wet its legacy complexity and concept please see schnedler meyer et al 2020 the hydrodynamic model and the ecosystem model are coupled with two way interaction and dependencies via the framework for aquatic biogeochemical models fabm bruggeman and bolding 2014 since its predecessor qwet has been upgraded to python 3 and is thus available for qgis 3 x to install qwet users must first install the latest stable version of qgis 3 https download qgis org and proceed with the designated qwet plugin installer available at www wet au dk the plugin installation is swift followed by manual one time activation via the manage and install plugins window under the plugins menu in qgis qwet may then be launched from its toolbar within qgis fig 1 in the first release of the plugin nielsen et al 2017 users had to manually and through command prompt syntaxes update the local underlying python environment with certain third party packages that were not included in qgis by default tedious steps that counteracted our intention of lowering the bar for novice model users as highlighted by meyer and riechert 2019 this required programming skills of users to resolve potential installation problems not least in windows due to the demand for administrator privileges for package installation now all dependency packages are directly embedded within qwet and additional python system updates or installations via python s standard package manager pip are not needed this may have some downsides as described by meyer and riechert 2019 but system wise the tool is independent with its own control of package versioning and importantly easy to deploy in addition to qwet s built in plotting functions users may browse model simulations via pyncview a cross platform netcdf viewer developed by bolding bruggeman www bolding bruggeman com pyncview requires independent installation and is available at pypi org once installed the core structure of a qwet project is similar to that of its earlier version and relies on a qgis qgz project file and a neighbouring project specific directory where all project inputs and simulation outputs as well as project specific information are stored in a sqlite database www sqlite org see nielsen et al 2017 for details to anchor explicitly to the model complex gotm wet with a now radically changed model core and almost entirely yaml based configuration files https yaml org qwet is not backward compatible as such editing and execution of projects created through the previous plugin are not supported and users are instead encouraged to set up already existing projects from scratch in qwet 3 required inputs qwet has inherited prerequisites for inputs and configurations from its predecessor and builds on the principle of enabling users to set up a model for a given lake or reservoir based on only a few key details surface area m2 maximum depth m and a number of vertical layers water inflow m3 s and associated nutrient concentrations mg l provided as constants and finally information about the weather optionally represented by a suite of pre defined meteorological time series from the european centre for medium range weather forecasts ecmwf dee et al 2011 available in qwet from here users may choose to refine their configuration and setup by providing hypsographs the relationship between depth m and the corresponding horizontal area m2 to qualify the approximation of the physical domain or time series on inflow and associated nutrients from the watershed in order to better resolve actual transports into the modelled system users also have the option of linking to the watershed model swat soil water assessment tool by arnold et al 1998 when needed nielsen et al 2017 provide a detailed description of configuration options supported by tutorials and test datasets at www wet au dk applicable for qwet 4 new features 4 1 selecting conceptual model representations of the ecosystem a new feature that we proudly present is the possibility of utilising parts of the new modular configuration concept characterising the aquatic ecosystem model wet by schnedler meyer et al 2020 enabling configuration of different model complexities for a given application when creating a new qwet project users may now choose between three different templates i e conceptual representations for the ecosystem fig 2 template 1 a simple nutrient phytoplankton zooplankton detritus npzd representation template 2 a representation equivalent to fabm pclake hu et al 2016 including nutrients three phytoplankton groups zooplankton zoobenthos piscivorous zooplanktivorous and benthivorous fish and macrophytes and template 3 an advanced version of template 2 expanded with an additional zooplankton group several other conceptual representations may be of relevance to tailor case specific needs and qwet supports inclusion of additional templates upon request for our study case danish lake ravn we used template 3 the physical domain was represented by a lake specific hypsograph and time series of inflowing water and associated nutrients were obtained from the danish national monitoring program of the aquatic environment novana model calibration from 1996 to 2000 with 6 prior years of warm up was conducted outside qwet via parsac see https pypi org project parsac a calibration tool that utilises a differential evolution algorithm to calibrate model parameters through optimisation against a maximum likelihood function see chen et al 2019 moras et al 2019 and andersen et al 2020 for other application cases 4 2 accessing model parameters in gui popup to improve the user experience model parameters and model settings in both the physical and aquatic ecosystem domains are now available in qwet via a tree structured gui popup fig 3 users are assisted by various predesigned categorisations fig 3 a for quicker browsing and can change parameter values or initial values of state variables via for instance calibration schemes moreover where needed model settings can be customized by changing e g the methods for determining phytoplankton and light inhibition or by activating ice simulation or nitrogen fixation for cyanobacteria 4 3 comparing model simulations against observations the obs tab now allows qwet users to compare and evaluate model performance against observations thus navigation to an external model directory is possible if e g calibration is conducted via auto calibration routines outside the plugin time series of observation variables should be provided with each variable in its own text file the format obs analogous with that of parsac and tutorial videos of how to import observations into the plugin are provided at www wet au dk fig 4 exemplifies data on lake ravn displaying the modelled and observed water temperature oc users may switch between the variable displayed the temporal period to be viewed and the depth related boundaries to query data for only parts of the water column e g from the surface to 5 m depth fig 4 a moreover users may select between displaying the data as a combined line and scatterplot fig 4 b as a line plot fig 4 c or as profiles not shown conveniently the data and thus the plot rendering may be separated to permit distinction between calibration and validation fig 4 c along with plot generation qwet also produces various statistics e g nash sutcliffe efficiency bias root mean square error and coefficient of determination not shown here to assist users in quantifying the model performance 4 4 introducing manipulations as a scenario feature in the previous version of the plugin a scenario platform was implemented by which users were able to conduct and examine the impacts of climate change scenarios by altering the forcing air temperature or changing the nutrient loads to the lake or reservoir in qwet this scenario platform has been expanded with the possibility of designing and applying manipulations to model state variables with this feature users can mimic and assess various management actions such as the consequences of biomanipulation jeppesen et al 2012 or the effects of oxygenation liboriussen et al 2009 manipulations can now be conducted using either a multiplier that manipulates a state variable during a specific time e g removal of a certain percentage of fish or a rate of change that either increases or decreases a state variable by a specified rate during a specified time interval for the latter a threshold value may also be assigned to control the onset of manipulation e g application of oxygenation only when oxygen levels are below a given threshold to demonstrate its potential usage we simulated oxygenation in the hypolimnion of lake ravn fig 5 with an activation threshold of 6 mg l operating from 2002 onwards in response the simulated hypolimnetic dissolved oxygen concentration rose fig 5 c compared with the pre oxygenation period fig 5 b as such qwet functions as a tool aiding in examining and quantifying oxygenation levels to counteract hypolimnetic oxygen depletion during summer in stratified eutrophic lakes prior to actual implementation of restoration interventions 5 conclusions and future work qwet is a new version of the qgis plugin that allows users to operate and experiment with the gotm fabm pclake model through a gui based workflow qwet now accommodates wet the next generation of fabm pclake a highly customisable aquatic ecosystem model qwet has been upgraded with a new model core and several new features that ease its application for beginners in the aquatic ecosystem modelling discipline and hopefully it will also facilitate further model application worldwide through qwet users may configure run alter and visualise model simulations compare simulations against observations and conduct experimental scenarios in the future development of qwet we aim to accommodate linkage to the watershed model qswat and thereby substitute the current support of the ordinary qswat model another aim is to obtain platform independence to support both linux and macos in addition to its current windows affiliation moreover we will endeavor to explore and qualify how dependencies to third party packages are handled by the plugin possibly via a dedicated component that checks for missing packages and prompts installation ideally plugin dependencies should be processed by qgis itself possibly through incorporation of a flexible plugin dependency declaration similar to the way in which ordinary python package development declares dependencies building such logic into qgis would greatly advance plugin development and potentially also enhance the possibilities of ordinary gis processing by avoiding the currently required tedious installation of special python packages declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the development of qwet was supported by watexr funded by the eu jpi climate initiative prognos project funded by the eu jpi water initiative cashfish funded by the danish council for independent research and a project on mechanistic models for water action planning funded by the danish environmental protection agency moreover we thank anne mette poulsen for valuable editorial comments 
