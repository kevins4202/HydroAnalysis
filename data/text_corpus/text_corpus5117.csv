index,text
25585,hillslopes are a fundamental unit of surface hydrology mediating the flow of water to fluvial networks through overland flow and subsurface pathways we present arc hydro tools to delineate hillslope outlines identify hillslope width functions and implement an overland flow model that accounts for hillslope curvature we apply the new tool to subwatersheds in the walnut gulch experimental watershed and las trampas creek watershed to investigate properties of hillslope curvature and impact of curvature on peak flows we found that for these two subwatersheds divergent convergent and uniform width hillslopes account for 43 55 and 2 of subwatershed areas respectively this curvature is substantial enough to increase peak flow predictions by up to a factor of 3 on some hillslopes and can be exaggerated at larger scales as multiple hillslope hydrographs are superimposed our findings suggest that hillslope curvature may play an important role in hydrological processes on real landscapes keywords hillslope curvature geospatial tools overland flow rational method design flow hillslope width function 1 introduction the scale of hydrological modeling determines which hydrological processes dominate the hydrological response and which processes can be resolved in the model blöschl and sivapalan 1995 zehe et al 2014 gridded models enable direct representation of both the physics of flow and the properties of the landscape at the scale of the grid e g topmodel beven 1997 beven and kirkby 1979 kirkby 1997 mike she abbott et al 1986 and parflow e g jones and woodward 2001 ashby and falgout 1996 kollet and maxwell 2006 maxwell 2013 but can become computationally intractable as model scales increase thus at large scales gridded representations are often replaced by the use of semi distributed models in which hydrological response units hrus typically watersheds subwatersheds form the smallest scale on which either landscape properties or hydrological processes are resolved flügel 1996 examples include vic gao et al 2010 prms leavesley et al 1983 swmm metcalf 1971 canoe www canoe hydro com swat arnold et al 2012b and model for urban sewers mouse mouse 1996 among many others intermediate scales 5 200 km2 however can pose challenges for either of these approaches at these scales deterministic gridded approaches become complicated by a combination of numerical observational parameterization and calibration challenges zehe et al 2014 conversely large scale distributed models struggle to resolve landscape heterogeneity that plays a large part in the hydrological response at intermediate scales dooge 1986 sivapalan 2003 wood et al 1990 one approach to overcoming these challenges is to associate hrus with landscape elements at scales smaller than watersheds or subwatersheds such as hillslopes hillslopes are appealing as a basis for hrus as they are topographically delineated by lateral no flux boundaries that simplify their numerical representation theoretical and empirical research on hillslope hydrology began in the mid 20th century kirkby 1988 and demonstrated that hillslope topology and topography impose primary controls on runoff processes dunne and black 1970 freeze 1971 anderson and brooks 1996 betson and marius 1969 in particular the convergence divergence of flow paths along a hillslope has large effects on surface and groundwater hydrographs woolhiser 1969 moore 1985 agiralioglu and singh 1981 baiamonte and singh 2015 noroozpour et al 2014 sherman and singh 1976 agiralioglu 1988 fan and bras 1998 hillslope curvature can also impact the validity of simple predictive tools such as the rational method that implicitly assume uniform width hillslopes lapides et al 2021a yet although some semi distributed models operate explicitly on hillslope scales e g rhessys tague and band 2004 troch et al 2003 fan and bras 1998 and some account for hillslope convergence divergence e g kineros and topmodel woolhiser et al 1990 smith et al 1995 canfield and goodrich 2006 beven 1997 beven and kirkby 1979 kirkby 1997 the use of one dimensional flow theory to estimate hydrographs on convergent divergent hillslopes remains widespread e g swmm swat hec hms rossman and huber 2016 arnold et al 2012a u s army corps of engineers hydrologic engineering center hec 2020 without clear indication of when curved topography invalidates these tools there is considerable scope to improve on this by accounting for some of the two dimensional properties of surface flow without greatly adding to model complexity for example agnese et al 2007 and baiamonte and singh 2016 solved overland flow equations on idealized trapezoidal hillslopes using a shape factor to incorporate planform curvature in an alternative and more general approach troch et al 2002 troch et al 2003 paniconi et al 2003 and troch et al 2004 used the concept of the hillslope width function hwf to formulate analytical models for the hillslope hydrograph as a function of hillslope curvature the hwf is formalized as the linear distance between contour endpoints at each point x l along the axis from the hillslope divide to the stream channel see fig 1 the hwf provides an intuitive way to study hillslope morphology and its impacts on hydrological outcomes and allows mathematical description of the effects of curvature on hillslope surface and groundwater hydrographs troch et al 2003 fan and bras 1998 lapides et al 2020 bogaart and troch 2006 the computation of these hydrographs is particularly straightforward when hwfs adopt or can be approximated by an exponential form applying tools like the hillslope width function to real landscapes however remains challenging although morphogeometric tools e g wilson and gallant 2000 tarboton and ames 2001 are widely used for delineating watershed boundaries and stream networks for modeling and management applications few of the available tools delineate or characterize the topology of hillslopes one exception is the c based tool by lammers and band 1990 methods available to both delineate hillslopes and calculate hwfs are mostly either time consuming and complex matonse and kroll 2009 sahoo and sahoo 2019 or manual broda et al 2014 one exception is noël et al 2014 who presented a method in physitel for delineating hillslopes and fitting trapezoidal or triangular hwfs no equivalent is currently available to apply to exponential hwfs and to our knowledge none of the available hillslope fitting morphometric packages are compatible with the most widely used gis tools for landscape analysis consequently the implications of hillslope properties and morphology on runoff behavior and appropriateness of different hwf shape assumptions are still very much unknown to address these gaps we developed a set of python based tools that rapidly delineate hillslopes estimate exponential hwfs and apply hillslope based runoff analysis these tools named hillslope delineation and critical duration tools are integrated in arc hydro an arcgis based system geared to support water resources applications maidment and morehouse 2002 we use the hillslope delineation and critical duration tools to investigate the hillslope shapes occurring in real landscapes and to assess the importance of hillslope morphology for surface flow predictions on multiple hillslopes and for large spatial scales in particular we examine the impact of hillslope shape on runoff produced by infiltration excess overland flow in two urban peri urban case study watersheds to answer four research questions 1 how prevalent are divergent hillslopes relative to convergent and uniform width hillslopes 2 how well does an exponential hwf approximate real hillslope shapes 3 how do predictions of hillslope peak flows and timescales accounting for hillslope curvature compare to those based on planar rectangular hillslopes 4 how do predictions of peak flows and timescales at the hillslope scale relate to those at the watershed scale facilitating hillslope curvature analysis and its impacts on runoff will allow a better appraisal of the suitability of one dimensional flow assumptions in different landscape settings while fully exploring this problem remains beyond the scope of the present study we present initial results that evaluate curvature effects on the widely used rational method kuichling 1889 mulvaney 1851 we have previously shown the rational method to be susceptible to errors induced by hillslope curvature and infiltration properties of the soil surface lapides et al 2021b a despite these and other known shortcomings ball et al 2019 coombes et al 2015 krimgold 1946 cleveland et al 2011 smith and lee 1984 ben zvi 1989 efstratiadis et al 2014 grimaldi et al 2012 mccuen 2009 the rational method remains widely used at hillslope scales where overland flow mechanisms prevail the arc hydro critical duration tools incorporate the rational method framework described in lapides et al 2020 to explore when topographic curvature invalidates the rational method this functionality allows an initial appraisal of the importance of accounting for topographic curvature when modeling real landscapes 2 arc hydro hillslope and critical duration tools workflow arc hydro hillslope and critical duration tools are python based arc hydro tools that delineate hillslopes fit exponential hwfs to the delineated hillslopes and assess the degree to which curvature may impact hydrological model predictions using the rational method as an illustrative example this is achieved in five arc hydro tools fig 2 that are included in two arc hydro toolboxes the terrain preprocessing toolbox contains 1 the hillslope partitioning tool which delineates hillslope areas and 2 the hillslope width function tool which fits the hillslopes with an exponential hillslope width function hwf the critical duration toolbox contains 3 the hillslope roughness tool which computes the roughness term needed for peak flow calculation 4 the optimize critical duration tool which uses overland flow theory to compute the impact of hillslope curvature on peak flow predictions and 5 the produce hydrograph tool which produces a storm hydrograph for a user defined rainfall duration and intensity the five tools and their inputs are described briefly below full details about the gis methods are provided in the online tool documentation at https downloads esri com archydro archydro doc 2 1 hillslope tools the first two tools hillslope partitioning and hillslope width function can be used to provide estimates of hillslope curvature and shape as well as how well an exponential hwf approximates hillslope curvature and shape prior to using the hillslope partitioning tool basic terrain processing and watershed delineation must be performed esri 2019 for these steps a digital elevation model dem must be run through basic terrain processing tools to generate a flow accumulation raster a flow direction raster drainage lines or streams watersheds and a corresponding flow accumulation threshold that was used to generate the streams 2 2 hillslope partitioning tool after the pre requisite steps are performed the hillslope partitioning tool partitions the watersheds into headwater hillslopes draining to a stream initiation point and lateral hillslopes draining to a stream reach forming the hillslope s lower boundary following the methods of fan and bras 1998 to avoid delineation of spurious hillslope areas i e small slivers that are not topologically connected to hillslopes this tool removes hillslope parts smaller than or the size of one raster cell in addition hillslope parts smaller than a user specified threshold area are also removed 2 3 hillslope width function tool while many forms of the hwf are possible e g exponential triangular trapezoidal computation of hydrographs is particularly straightforward for exponential forms of the hwf troch et al 2003 lapides et al 2020 to leverage the power of this approach the hillslope width function tool approximates hillslopes with an exponential hwf given by 1 w x c e a x where c l parameterizes width at the divide x represents the distance from the divide following the line of steepest descent down the hill and a determines the degree and nature of hillslope curvature when a 0 the hillslope is divergent and when a 0 the hillslope is convergent a 0 describes a uniform width hillslope the hillslope width function tool applies two criteria to estimate hillslope width functions following noël et al 2014 1 monotonicity and 2 conservation of area monotonicity ensures that the hillslope width function is convergent monotonically increasing divergent monotonically decreasing or constant uniform width conservation of area fulfills mass conservation requirements both of these criteria must be explicitly addressed 2 4 approximating the hillslope width function fig 3 outlines the process for estimating the hwf while fulfilling the monotonicity and conservation of area requirements we begin with a delineated hillslope with a marked outlet to the stream network with area a 0 fig 3a first outlet points are generated at the hillslope outlet blue point in fig 3b each lateral hillslope is associated with 2 outlet points marking the extent of the bottom boundary and each headwater hillslope is associated with a single outlet point next j hillslope points number specified by the user are equally spaced in x y space along the hillslope boundary red points in fig 3b in total each hillslope is characterized by 1 headwater or 2 lateral outlet points and j points along the hillslope boundary hillslope points this point selection process can only correctly characterize headwater hillslopes and lateral hillslopes with an outlet along an approximately linear stream segment each hillslope point is associated with a corresponding point on the opposite side of the hillslope based on location along the hillslope outline see fig 3c for instance the nearest point to the outlet on the left is paired with the nearest point to the outlet on the right the two outlet points are paired on lateral hillslopes and the single outlet point is used as a pair on headwater hillslopes the midpoints along the lines connecting paired points or the single outlet point on headwater hillslopes are used to approximate a linear hillslope midline the hillslope midline forms the x axis that defines the hwf with the divide at x x 0 0 and the outlet at x x end the exponential hwf assumes that a hillslope is symmetrical across the x axis the distance between point pairs gives the width of the hillslope w j at the corresponding distance from the divide along the midline x j see fig 3d providing a set of points x j w j to fit the hwf if the width values are not approximately monotonically increasing or decreasing then the algorithms will not produce a visually or quantitatively acceptable fit to the hillslope shape to prevent this error we truncated hillslopes at x x threshold so that only the downslope portion of the hillslope that is monotonically increasing or decreasing is used to fit the exponential hwf fig 3e this is performed by using nonlinear least squares to fit a broken stick function to the hillslope width data 2 w x a 1 x b 1 x x threshold a 2 x b 2 x x threshold where a 1 a 2 b 1 b 2 and x threshold are constants fit by the algorithm if the sign of a 1 is different from the sign of a 2 then the hillslope is truncated at x threshold otherwise the full set of hillslope width data is used from here the value of x threshold effectively becomes the hillslope divide and x 0 shifts to x threshold the remaining points are used to fit an exponential width function defined by c and a fig 3f finally the hillslope area is conserved by tuning the divide location x 0 to the value x top that causes the final area to equal a o while keeping the outlet location x end constant fig 3g 2 5 error metrics the hillslope width function tool also computes metrics that assess four potential sources of error fig 4 i the stream error strm err ii the point selection error pt err iii the truncated point selection error pt trunc err and iv the shape fit shp fit each of these metrics is described below i the stream error strm err fig 4a computed only for lateral hillslopes is the percent error between the euclidean stream distance measured as the linear distance between lateral hillslope outlet points and the actual distance along the stream segment this error metric ranges from 0 to 100 with smaller values meaning that the linear approximation is suitable and larger values meaning that the linear approximation may not be valid ii the point selection error pt err fig 4b is computed as the percent error between the actual hillslope area and the polygon constrained by the hillslope points this metric indicates how well the points represent the hillslope shape if the area bounded by the points is not representative of the shape or area of the original hillslope the magnitude of the point selection error will be large the point selection error identifies the degree to which the shape defined by the points along the hillslope outline is representative of the actual hillslope note that even if the pt err is high the area defined by the hwf and hillslope length will still equal the actual hillslope area iii the truncated point selection error pt trunc err fig 4c is the percent error between a polygon constrained by the hillslope points and a polygon constrained by the truncated hillslope points a high pt trunc err means that a large portion of the hillslope was neglected during the fitting process to maintain monotonicity this means that the points used to fit the hwf are only representative of a small portion of the hillslope and application of the fitted hwf to the entire hillslope may be inappropriate iv the shape fit metric shp fit fig 4d is the r 2 coefficient of the best fit hwf and ranges from 0 to 1 a low r 2 indicates that the exponential hwf is a poor fit to the hillslope shape described by the hillslope points for most hillslopes all of these errors can be reduced by increasing the number of hillslope points used to estimate the exponential hwf an additional potential source of error in the hwf tool is associated with the assumptions inherent to the use of an exponential hwf based on the hillslope outline the width function approximation applied in the hillslope width function tool is fit to the hillslope outline rather than the measured contours from the dem theoretically the width function represents a linear distance between contour endpoints this means that approximating the hwf from the hillslope outline will perform best where a hillslope is nearly symmetric with a relatively constant slope however the approximation of the hwf from the hillslope outline was applied by noël et al 2014 with success supporting the use of this same approximation in arc hydro hillslope after running the hillslope width function tool the following fields are added to each hillslope the exponential hillslope width function constants c and a see equation 1 the x location of the hillslope top x top and bottom x end hillslope length l calculated as x end x top and the error metrics 2 6 critical duration tools illustrative application of hillslope tools the next three tools located in the critical duration arc hydro toolbox apply the hillslope tools above to explore the impact of hillslope shape and curvature on peak flow estimated by the rational method the critical duration tools allow us to address the second research question i e the comparison between a 1d flow model and a flow model that accounts for topographic curvature 2 7 hillslope roughness tool predicting overland flow rates on hillslopes requires a roughness parameter α given by α s o n where s o is the land surface slope l l and n is manning s roughness coefficient l 1 3 t the hillslope roughness tool computes roughness α for each hillslope using the average hillslope slope s o and a hillslope area weighted manning s roughness coefficient n estimated by converting a land cover raster e g the national land cover database nlcd land cover product using the lookup table developed by kalyanapu et al 2009 however if a user has their own roughness raster or roughness values for hillslopes this step may be skipped provided that the roughness values are included in the hillslope feature class in the correct format we refer the reader to the user manual for additional detail https downloads esri com archydro archydro doc 2 8 optimize critical duration tool the conventional rational method kuichling 1889 mulvaney 1851 predicts the maximal peak flow q max for a given return period as 3 q max c a i where c is a runoff coefficient a is the contributing area and i is a design storm intensity while generally understood as a multiplication of constants equation 3 is better understood as the product of three storm duration dependent curves where the rational method attempts to return the maximum value of this product by appropriate selection of the storm duration d lapides et al 2021b in other words the rational method is an optimization of the product of c d a d and i d the storm duration for which q cai is maximal is called the critical duration d crit l using a simplification suggested by kuichling 1889 and mulvaney 1851 d crit is often equated to the time of concentration t c the time when the entire hillslope area is contributing to flow at the outlet this assumption may be invalidated by hillslope curvature so that d crit t c lapides et al 2021b a in all cases d crit t c for cases where hillslope curvature causes d crit t c using t c as the timescale underestimates peak flow lapides et al 2021a b the optimize critical duration tool computes d crit directly by numerically optimizing a runoff coefficient curve c d contributing area curve a d l2 and an intensity duration curve for a given return period i d l t described in appendix i to find the maximal peak flow on the hillslope lapides et al 2021a for each storm duration rational method parameter i are computed from an intensity frequency duration ifd curve and parameters c and a are calculated from analytical solutions for overland flow on hillslopes represented by a hwf with parameters c a x top 0 and x end lapides et al 2020 the differences between rational method peak flow predictions using d crit and those using t c offer one measure of how hillslope curvature may invalidate one dimensional flow assumptions 2 9 optimization inputs the optimize critical duration tool requires an ifd curve defined by constants k and b and a value for saturated hydraulic conductivity k s l t the ifd constants k and b are based on a power law approximation to an ifd curve koutsoyiannis et al 1998 4 i d k d b in this approximation k determines how intense storms are for a given return period stormier climates and longer return periods have larger values of k the constant b usually 0 35 b 0 60 is related to rainfall variability monjo 2016 smaller values of b are associated with monsoonal polar or orographic rainfall patterns and higher values of b are associated with convective rainfall monjo 2016 users can identify these values by fitting equation 4 to regional ifd curves with the user provided k b and k s constants the optimize critical duration tool calculates c d and a d from the analytical solutions described in appendix i this process assumes that c is defined based on a constant loss rate k s but does not take into account the effects of varying antecedent moisture conditions on the infiltration loss behavior lapides et al 2021b k s is incorporated into analytical solutions by altering the ifd curve to an effective rainfall rate i d k d b k s this formulation neglects the impact of infiltration on the falling limb but does not affect the calculation of a design flow in this methodology the c d curve is then calculated from the rational method relationship c d q ai 2 10 optimization outputs the optimization critical duration tool adds five fields to the hillslope feature class q max m 3 s d crit s t c s d crit t c and a boolean field d crit t c that indicates if d crit is less than t c the output q max represents the maximum value of q d the rational method peak flow prediction the output d crit identifies the duration for which q d q max the output t c corresponds to the first storm duration for which the entire hillslope contributes flow to the outlet the final output d crit t c is produced to assist with interpretation of results if d crit t c 1 the performance of the traditional rational method is not worsened by hillslope curvature or infiltration behavior however if d crit t c 1 then the traditional rational method and t c are likely to underestimate q max in some cases the storm properties dictated by the ifd curve mean that there are no conditions for which the entire hillslope contributes to flow at the outlet and thus t c in these cases d crit t c does not exist but since d crit is still less than t c the binary field d crit t c yes 2 11 storm event hydrograph tool the storm event hydrograph tool uses the k b and k s values along with the critical storm duration d crit from the optimize critical duration tool output to compute the rainfall intensity i m s associated with a user defined duration t r s equation 4 and produce the associated storm hydrograph for each hillslope 3 estimating the impact of hillslope curvature at watershed scales spatial scaling of different hydrological processes remains an open challenge thompson et al 2011 peters lidard et al 2017 ichiba et al 2018 linking the arc hydro hillslope and critical duration tools with a routing model that connects flow between hillslopes to simulate a watershed scale response offers an opportunity to explore whether and how hillslope curvature can affect whole of watershed flood responses the final research question outlined for this study to illustrate the potential of this approach we represented watersheds as a collection of hillslopes draining through the stream network to the watershed outlet hydrographs for each hillslope are produced from arc hydro critical duration tools and the stream network is discretized into multiple reaches where each reach receives flow from some fraction of the lateral hillslopes flow into each reach is given by the sum of channel inflow including headwater hillslope and lateral inflow because this study is initial and illustrative we consider only kinematic flow in the channels converting storage per reach to a flow velocity q using the kinematic relationship q αh 1 2 velocities are integrated through time as hillslope hydrographs change this simple modeling approach is represented visually in fig 5 4 case study areas and experimental design we applied the arc hydro hillslope and critical duration tools to two case study subwatersheds fig 6 i a 13 km2 rural subwatershed of usda ars walnut gulch experimental watershed arizona and ii a 9 km2 urban subwatershed of the las trampas creek watershed california the walnut gulch experimental watershed is a semiarid watershed moran et al 2008 located in the transition zone between the chihuahuan and sonoran deserts the mean annual precipitation in this area is approximately 310 mm and about 60 of the rainfall occurs during july august and september almost all runoff in the watershed occurs during these months in response to high intensity convective thunderstorms goodrich et al 2008 we used a subwatershed of walnut gulch that drains 13 km2 of desert soils and impermeable areas in the town of tombstone in southern arizona fig 6a we refer to this case study location as the wg subwatershed las trampas creek watershed flows through city of lafayette california fig 6b the watershed has a mediterranean climate with mean annual precipitation of about 510 mm nearly all of which occurs during the winter months weather atlas 2020 we focused on a small 9 km2 subwatershed of las trampas creek watershed that drains to reliez creek we refer to this case study location as the lt subwatershed the wg and lt subwatersheds both contain relatively wide expanses of impermeable areas either desert soils or impervious surfaces in urban areas making them well suited for application of the rational method peak flow optimization arc hydro tool additionally these watersheds have varied topographywith steep upland areas and flatter areas downstream thus providing an opportunity to test the new arc hydro tools across a range of topographies and potential hillslope shapes 4 1 determining the prevalence of divergent hillslopes and suitability of exponential width function to determine the prevalence of divergent hillslopes we applied the hillslope partitioning and hillslope width function tools to the two case study watersheds we obtained a 10 m dem for the wg subwatershed heilman et al 2008 and for the lt subwatershed contra costa county 2017 and used these dems to delineate hillslopes in each study area using the hillslope partitioning tool we then tested the sensitivity of the hillslope width function tool to the number of hillslope points specified by varying the number of hillslope points j from 8 to 96 based on visual inspection of these results we identified the value of j above which error metrics were relatively constant using this threshold number of hillslope points we i determined the prevalence of divergent a 0 0001 uniform width 0 0001 a 0 0001 and convergent a 0 0001 hillslopes for each study area and ii examined the resulting error metrics 4 2 comparing estimates of timescales and peak flows we obtained land cover rasters for both the wg and lt subwatersheds from the national land cover database and used these as inputs to the hillslope roughness tool section 3 the resulting hillslope feature class containing hillslope width function parameters and roughness estimates for each hillslope was used as input to the optimize critical duration tool section 3 we assumed k s corresponding to loam soils and ifd parameters k and b that correspond to the 50 year return interval see table 1 ifd data for the two case study locations were obtained from local sources for the wg subwatershed in cochise county az tabulated ifd data are available for short storms of return periods from 2 to 100 years keefer et al 2016 for contra costa county ca where the lt subwatershed is located ifd data are available graphically for different mean annual rainfall depths contra costa county flood control and water conservation district a b c d e for each return period we tabulated by hand the rainfall depth associated with the 20 inches yr about 508 mm contour for the same storm durations for which data were available for the wg subwatershed 5 min 10 min 15 min 30 min 1 h those rainfall depths were then converted to average intensities by dividing the depth by duration for each return period tabulated intensity duration data for both the wg and lt subwatersheds were used to find an optimal fit to equation 4 resulting ifd curves are included in appendix b the optimize critical duration tool produced estimates for the critical duration d crit and the time of concentration t c for each hillslope we examined the differences between these timescale estimates d crit and t c and the resulting peak flow estimates q peak d crit and q peak t c using i the timescale ratio d crit t c which is always less than one since d crit t c under the conditions considered and ii the peak flow ratio q peak d crit q peak t c which is at least one by definition since q peak d crit produces the maximum possible flow 4 3 exploring the impact of hillslope curvature at subwatershed scales to explore potential scaling of curvature in the model described in section 4 we consider the simplest topographically meaningful situation of one headwater hillslope and two lateral hillslopes we identified 10 real subwatersheds in each case study area with this configuration for each subwatershed we estimated stream parameters from aerial imagery and previous reports where available stream channels in the wg subwatershed had an average width of 4 m estimated from aerial imagery and were characterized by stream manning s n of 0 03 per bunch c e forbes 2019 stream channel widths could not be determined from aerial imagery of lt subwatershed due to high canopy cover around the stream channel so we assumed the same stream channel width as wg 4 m and estimated stream manning s n as 0 04 gravelly and cobbled bottom chow 1959 in all cases channel propagation is significantly faster than hillslope propagation α is nearly 2 orders of magnitude larger and channel segments are short relative to hillslope sizes we expect in these situations that hillslope responses should be important for the watershed hydrographs relative to the channel conveyance d odorico and rigon 2003 we investigated the influence of the hillslope runoff response on peak flood flows by performing an optimization for peak flow as described in section 3 for the watershed under two assumed situations a using the best fit exponential hillslopes and b using rectangular hillslopes setting the hillslope length equal to the longest flowpath 5 results all results below are shown using j 96 hillslope points see appendix c for details on the effects of varying the number of hillslope points 5 1 prevalence of divergent hillslopes and suitability of exponential width function fig 7 shows for j 96 hillslope points the distribution of hillslope curvature in each case study watershed the majority 91 of headwater hillslopes are convergent while the majority 51 of lateral hillslopes are divergent table 2 by area divergent hillslopes account for 32 and 55 of walnut gulch wg and las trampas lt subwatersheds respectively as shown in the inset pie charts in fig 7 table 2 summarizes the percent of headwater and lateral hillslopes that are divergent convergent and uniform width 5 2 suitability of exponential hillslope width functions we discuss error metrics in depth in appendix d but note here that the shape of both convergent and divergent hillslopes was overall well approximated by the exponential hillslope width function with median r 2 values ranging from 0 52 wg convergent hillslopes to 0 79 lt convergent hillslopes while there is no specific r 2 threshold for which the fit of a function is considered good the majority of r 2 values obtained here are similar to those obtained in previous studies that were considered to be representative of good fits e g sahoo and sahoo 2019 generally considered r 2 0 5 to be representative of good exponential fits other error metrics point error truncated point error and stream error for lateral hillslopes are discussed in detail in appendix d 5 3 effects of hillslope curvature on timescale and peak flow estimates by applying critical duration tools to wg and lt subwatersheds we found that hillslope curvature can result in an underestimation of q peak by up to a factor of 3 when t c is finite fig 8 a larger fraction of hillslopes in lt fig 8b show a pronounced difference between d crit and t c d crit t c 1 than in wg fig 8a which is likely attributed to the larger fraction of hillslopes in lt that are divergent see fig 7 this higher divergence in turn drives the more extreme relationship between the timescale ratio d crit t c and the peak flow ratio q peak d crit q peak t c at lt fig 8d compared to wg fig 8c 5 4 impacts of hillslope divergence at catchment scales for nearly all of the 3 hillslope catchments assessed deviation between t c and d crit is observed at the catchment outlet this deviation is shown by the light grey striped bars in fig 9 a and b the timescale ratio d crit t c is plotted for both hillslope hydrographs hillslope timescale ratio and full catchment hydrographs catchment timescale ratio the catchment timescale ratio d crit t c ranges from 0 7 to 1 for wg subwatershed and 0 2 to 1 for lt subwatershed at catchment scales transit times through the channel non linearly impact the timing of catchment peak flow which can amplify differences between watershed scale t c and d crit this is seen in the greater spread and smaller values of d crit t c for catchments light grey striped bars in fig 9a and b relative to the individual hillslopes blue green bars if uniform width hillslopes are used instead of curved hillslopes for the simulations timescales t c and d crit do not disagree at the hillslope scale for any of the hillslopes in the catchment not shown but t c and d crit can and typically do still separate from each other at the catchment outlet due to the effects of flow propagation along the channel this disagreement however is minimal difference between t c uniform and the red dot on the dashed line in fig 9c d the minimal impact of channel propagation alone on d crit supports the presumption that channel routing timescales are less important than hillslope travel times at this scale the model using uniform width hillslope produces lower peak flow curves at catchment scales relative to peak flow estimates that account for curvature and d crit is delayed the stronger effects of hillslope curvature on catchment peak flow responses in the wg subwatershed panel c than the lt subwatershed panel d are attributable to the lower intensity rainfall and more curved hillslopes in wg compared to lt these results indicate that the magnitude of curvature on real hillslopes is substantial enough to impact peak flow estimates both at the hillslope and small catchment scales when hillslope processes are expected to be important 6 discussion the new arc hydro tools presented here facilitate the delineation morphological characterization and hydrological evaluation of hillslopes for surface runoff predictions by consistently and automatically delineating hillslopes as geomorphic units arc hydro hillslope tools can support a wide variety of hydrological and geomorphic analyses and research at hillslope scales in this study we explored potential applications of the arc hydro hillslope and critical duration tools which focus on hortonian peak flow sensitivity to hillslope curvature as modified by climate and soil permeability lapides et al 2020 2021b beyond this case there is ample scope to link arc hydro hillslope to groundwater hydrograph prediction troch et al 2002 2003 2004 paniconi et al 2003 or to extend it with analysis of spatial patterns of vegetation cover dralle et al 2014 particularly considering that reduced complexity analytical predictions are also available for these situations based on our initial application of arc hydro hillslope and critical duration tools to the case study watersheds several methodological and geomorphological findings should support such use and future extension 6 1 hillslope curvature can be accurately estimated with exponential functions exponential hillslope width functions hwfs offer numerous mathematical benefits when attempting to develop user friendly analytical flow predictions for surface or groundwater discharge from hillslopes lapides et al 2020 troch et al 2003 fortunately exponential hwfs provided a very reasonable approximation to real hillslope morphology hillslope exponential fit median r 2 ranged from 0 52 to 0 79 suggesting a good fit of exponential hwfs to natural hillslopes while the distributions of r 2 were slightly wider for convergent hillslopes than for divergent hillslopes their median values were not substantially different convergent hillslopes were characterized by higher point error truncated point error and stream error these results are consistent with research by sahoo and sahoo 2019 who found that the exponential hwf is better suited for estimating the curvature of divergent hillslope than of convergent hillslopes other approximations for the hillslope width function e g based on triangular rectangular or trapezoidal shapes have been used in previous studies with some success noël et al 2014 baiamonte and singh 2015 and may be more suitable than exponential hwfs in some cases future extensions of arc hydro hillslope to allow the use of these geometries could be a useful direction for development 6 2 high prevalence of divergent hillslopes in the case study watersheds headwater hillslopes were generally convergent and lateral hillslopes were divergent on average see table 2 similar to sahoo and sahoo 2019 in the lt subwatershed we found that divergent hillslopes comprised the majority of the hillslopes however we found a preponderance of convergent hillslopes in the wg subwatershed consistent with other authors e g noël et al 2014 bogaart and troch 2006 the lack of convergence so to speak on this concept is unsurprising watersheds and therefore hillslopes are influenced and shaped by many geomorphic hydrologic and biophysical processes it follows that any variability in these processes among watersheds could influence the relative prevalence of different hillslope shapes and curvatures resulting in different conclusions at different study sites since headwater hillslopes tend to be convergent it is possible that landscape scale may drive the prevalence of convergent vs divergent hillslopes in a small first order watershed a headwater hillslope is a large fraction of the landscape the simplest second order watershed consists of two first order watersheds with an additional pair of lateral hillslopes the fraction of lateral hillslopes increases with watershed order following this pattern in the simplest possible watershed where a nth order watershed is always the joining of two n 1 order watersheds the number of headwater hillslopes grows like the fibonacci sequence 5 h i 2 h i 1 where h i is the number of headwater hillslopes for a simple watershed of order i and the number of lateral hillslopes grows as 6 l i 2 l i 1 2 where l i is the number of lateral hillslopes for a simple watershed of order i as the sequence grows l i grows much faster table 3 and the ratio h i l i approaches an asymptote at 0 25 different asymptotic behavior would be expected for different values of the bifurcation ratio but in general the geometry of the watershed defines the relative prevalence of headwater and lateral hillslopes additionally even within the idealized bifurcation of the network described here there could be convergent lateral hillslopes so the estimate for h i l i represents the lower bound on the ratio of convergent to divergent hillslopes for this prescribed network topology scaling relationships are well developed for watersheds e g crave and davy 1997 zaliapin and kovchegov 2012 burd et al 2000 but similar relationships are less well developed for hillslopes the new functionality offered by archydro hillslope could support the development of datasets that would allow exploration of hillslope scaling relationships and drive the development and testing of theory to explain the observed scaling phenomena relationships 6 3 hillslope curvature impacts peak flows and timescales using the rational method as a simple example we found that realistic landscape curvature has an important impact on hydrological outcomes for hillslopes with divergent curvature we found that the time of concentration t c over estimates the storm duration producing peak flow in the rational method in the case study hillslopes for the 50 year storm the ratio of the flow maximizing timescale d crit to t c varied between 0 and 1 0 this variation was associated with under estimation of peak flow by as much as a factor of 3 fig 8 the deviation between t c and d crit observed at the hillslope scale is non linearly related to the deviation at the catchment outlet we found that timescale deviation and the resultant impact on peak flow estimates is exaggerated at the catchment scale compared to the hillslope scale highlighting the importance of catchment morphology for accurate hydrological prediction these results indicate that hillslope curvature could be important at the catchment scale but further study is required to understand how strong of a role hillslope curvature plays in producing catchment hydrograph characteristics relative to other drivers of hydrograph behavior not included in our model for instance transmission losses in the channel were neglected and may be significantly more important than hillslope curvature in impacting catchment hydrographs at some sites like walnut gulch lane et al 1997 6 4 implications for observations the results of this study illustrate the potential value of arc hydro hillslope and critical duration tools for interpreting the impacts of hillslope curvature on flow estimates they also raise questions about hydrological management and monitoring divergent hillslopes are more challenging to monitor or gauge than convergent hillslopes which route water to a single channel flow records particularly at small scales i e those measuring headwater watersheds or hillslopes may therefore be biased toward locations with convergent topography validating existing hillslope theories on divergent hillslopes will require creative monitoring techniques one strategy that may be able to detect the impact of hillslope curvature on watershed hydrographs is nested gauging where gauges are placed upstream downstream of where a divergent hillslope contributes to a stream channel examining changes in hydrograph shape between the gauge locations could allow inference of the behavior of the hillslope hydrograph for most hydrological applications though calibration and validation are done at catchment or watershed subwatershed scales the knowledge that hillslope curvature could have a large impact on catchment hydrology suggests that monitoring campaigns could gain useful information by deliberately monitoring watersheds with different combinations and orientations of hillslope topologies 6 5 future work arc hydro hillslope tools provide a rapid and efficient way to delineate and fit hwfs to real hillslopes delineation of hwfs using hillslope outlines while efficient masks some complexity within the hillslopes future improvements to the tool could increase capabilities to handle geometrical situations that violate the hillslope width function tool s current assumptions for instance situations where the channel does not flow parallel to the divide or where exponential hwfs provide a poorer description of hillslope morphology than other functions such as trapezoidal or triangular hwfs noël et al 2014 or similar geometric elaborations arc hydro critical duration tools provide tools to predict peak flow similarly to the rational method these tools assume infiltration excess overland flow produced by known spatially uniform and temporally steady rainfall such tools are only appropriately used in small hillslopes with low permeability and modest hillslope gradients lapides et al 2020 2021a lapides et al 2020 found that the curvature constant a 0 02 is a reasonable bound for applicability of the flow prediction tools built into arc hydro critical duration tools under idealized conditions thus in urban landscapes which are characterized by a large fraction of impermeable area and have modest slope and curvature e g due to site grading or site selection these tools are likely to be highly applicable although more research is required to identify the applicability on real landscapes the modest requirements for meteorological and land surface data supports wide applicability of arc hydro critical duration tools to locations where only limited data are available arc hydro hillslope tools can also be used to operationalize other hillslope based models notably exponential hillslope width functions have also been used to model groundwater flow troch et al 2004 under the assumption that groundwater flow follows surface topography arc hydro hillslope could be used as a foundation to implement this model in an accessible platform theoretical studies of the impacts of hillslope properties on hillslope hydrology such as the study conducted by dralle et al 2014 on vegetation patterns and topography use an intuitive theoretical parameter range to describe hillslope shapes with the ability to delineate hillslopes in arc hydro hillslope functionality could be added to calculate realistic parameter ranges and compare performance of different hillslope models on real hillslopes 7 conclusion planners and hydrologists enjoy an unprecedented ability to observe the features of the landscapes they study an ability only likely to increase in the future wood et al 2011 this information availability facilitates increasingly realistic landscape depiction even in simple models hillslopes provide an attractive scale at which to incorporate new information as these scales offer direct links between landscape properties and flow behavior arc hydro hillslope and critical duration tools provide a platform with which to achieve this integration of theory and observation in service of useful hydrological predictions by facilitating rapid landscape analysis at the hillslope scale we anticipate that these tools will enable advances in developing and testing geomorphological understanding of hillslope geometry across large watersheds in testing scale dependence of flow behavior to underlying hillslope topology and processes and in allowing practitioners to readily accommodate hillslope morphology in regular prediction tasks thus archydro hillslope and critical duration tools present a useful step forward to improve research and practice in geomorphology hydrology and water management design software availability statement name of software arc hydro hillslope and critical duration tools developers dana lapides anneliese sytsma gina o neil dean djokic mary nichols sally thompson contact anneliese sytsma berkeley edu year first available 2021 required hardware and software arc hydro hillslope and critical duration tools are available as an arcgis toolset operating on the esri software specifically arcgis pro 2 7 and higher availability arc hydro hillslope and critical duration tools are available on through esri s arc hydro toolbox users should install version 2 7 or higher of arc hydro from http downloads esri com archydro archydro setup pro additional guidelines for installing arc hydro are available from http downloads esri com archydro archydro doc the user manual associated with the arc hydro tools will be maintained on ersi arc hydro website https downloads esri com archydro archydro doc python source code used to calculate ifd curve parameters used as input to the arc hydro tools is published in a github repository at https github com lapidesd intensity duration frequency declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we would like to thank alain rosseau and sebastien tremblay for useful discussion this work was supported by national science foundation s engineering research center for reinventing the nation s urban water infrastructure renuwit eec 1028968 as the national science foundation grants ear 1013339 and ear bsf1632494 dal the hellman foundation dal the gledden foundation at the university of western australia s institute for advanced studies as and the university of california berkeley dal appendix i analytical solutions for overland flow used in rational method optimization to conduct the optimization for peak flow we need to calculate peak flow q peak d as a function of storm duration to do this we follow lapides et al 2020 and calculate peak flow from a kinematic wave model for overland flow assuming that the average flow across a hwf contour is representative then the average flow quantities may be used in conjunction with the hillslope width w to give a pseudo 2d description of flow while retaining the simplicity of a one dimensional solution lapides et al 2020 for the idealized case of constant runoff production and an exponentially hwf the hydrograph can be determined from analytical approximations to the kinematic wave equation lapides et al 2020 by solving the governing equation via the method of characteristics a 1 h w t q w x r w where h l is the average flow along a contour t t is time q l2 t is average flow per unit width and r l t is effective storm intensity for hillslopes with mild to moderate curvature there is excellent agreement between analytical solutions and numerical and laboratory simulations lapides et al 2020 see lapides et al 2020 for full solutions derivations validation and implications to apply these solutions the following information is required i exponential hwf parameters c a x 0 location of divide and x end location of the outlet calculated in step 3 ii roughness α calculated in step 2 iii design storm defined by a constant intensity i and storm length t r specified from an ifd curve provided by the user in step 4 appendix ii ifd curves for different return periods fitted ifd curves and tabulated data are plotted in fig 10 for a walnut gulch subwatershed az and b las trampas subwatershed ca in fig 10a it is clear that the fitted ifd curves for walnut gulch provide a good fit to the data until the longest storms when the storm intensity is over estimated fitted ifd curves for the las trampas subwatershed though fig 10b match the tabulated data perfectly best fit parameters for each return period and location are shown with the plots in fig 10 the larger values of k in walnut gulch indicate generally more intense storms than in las trampas the values of b are comparable between the two study areas although rainfall seasonality is reversed while a large range in k values is represented among the ifd curves for both sites and all return periods the range of b values between sites for all return periods is very narrow compared to the global range observed by monjo 2016 fig 10 fitted exponential ifd curves i k d b for a walnut gulch wg az and b las tramps lt ca the best fit parameters for 5yr and 10yr return periods are shown fig 10 appendix iii effect of varying hillslope points on exponential width function errors fig 11 shows box plots of the error metrics fig 11a c and resulting values of a fig 11d for each point specification the median exponential fit metric r 2 decreases rapidly between j 8 and j 16 falling from a value of 0 1 to 0 8 and remains around 0 8 with increasing number of points a however there is a corresponding sharp decrease in point error with increasing number of points after j 8 thus the fact that r 2 is so high for j 8 does not necessarily suggest that the exponential fit is better for these number of points because as seen in b this low number of points is associated with a high point error meaning that the points selected do a poor job of representing the hillslope shape the median point error for j 8 is relatively constant ranging from 6 to 7 the truncated point error c indicates the proportion of the hillslope that was removed in the truncation process median values ranged from 28 to 40 the impact of these errors on a appears to be minimal for j 8 with median a relatively constant around 0 c we chose to use j 96 for the case study because we observed the best combination of exponential fit and error metrics relative to other j values j 96 has a high r 2 median value of 0 76 and low point error median of 2 7 and truncated point error median of 22 9 we note however that the optimal number of points will vary depending on hillslope morphology and specific application of the hillslope tools fig 11 effect of number of points on exponential fit a point error b truncated point error c and a d for las trampas subwatershed fig 11 appendix iv exponential width function errors across all hillslopes in both case study watersheds the exponential fit metric r 2 ranged from 0 to 1 fig 12a median r 2 values ranged from 0 52 wg convergent hillslopes to 0 79 lt convergent hillslopes the median point errors percent error in point area relative to hillslope area fig 12b are very small ranging from 0 15 wg divergent hillslopes to 2 6 lt divergent hillslopes the full range of point errors goes from 100 to 100 error but the extreme error values are outliers these low median point errors suggest that the points chosen by the hillslope width function tool generally do a good job at estimating both convergent and divergent hillslope areas interestingly the truncated point error percent error in truncated point area relative to non truncated point area fig 12c was noticeably higher for convergent hillslopes across both wg and lt subwatersheds median of 51 and 55 respectively than for divergent hillslopes median of 14 and 3 respectively this suggests that in these two subwatersheds divergent hillslopes tend to be more monotonic and thus require less truncation than convergent hillslopes this may be related to a tendency for hillslopes to originate from a highest point rather than a wide ridge of similar height at the divide stream error for lateral hillslopes the percent error between stream length approximated by a straight line and actual stream length fig 12d is relatively low with median error less than 15 across all hillslope curvatures this suggests that overall approximating the stream channel as a straight line does not contribute substantially to error in the hwf fit fig 12 boxplots of hillslope width function exponential fit a point error b truncated point error c and stream error d metrics for walnut gulch wg and las trampas lt subwatersheds using j 96 points too few uniform hillslopes were present to calculate statistics these hillslopes not shown fig 12 
25585,hillslopes are a fundamental unit of surface hydrology mediating the flow of water to fluvial networks through overland flow and subsurface pathways we present arc hydro tools to delineate hillslope outlines identify hillslope width functions and implement an overland flow model that accounts for hillslope curvature we apply the new tool to subwatersheds in the walnut gulch experimental watershed and las trampas creek watershed to investigate properties of hillslope curvature and impact of curvature on peak flows we found that for these two subwatersheds divergent convergent and uniform width hillslopes account for 43 55 and 2 of subwatershed areas respectively this curvature is substantial enough to increase peak flow predictions by up to a factor of 3 on some hillslopes and can be exaggerated at larger scales as multiple hillslope hydrographs are superimposed our findings suggest that hillslope curvature may play an important role in hydrological processes on real landscapes keywords hillslope curvature geospatial tools overland flow rational method design flow hillslope width function 1 introduction the scale of hydrological modeling determines which hydrological processes dominate the hydrological response and which processes can be resolved in the model blöschl and sivapalan 1995 zehe et al 2014 gridded models enable direct representation of both the physics of flow and the properties of the landscape at the scale of the grid e g topmodel beven 1997 beven and kirkby 1979 kirkby 1997 mike she abbott et al 1986 and parflow e g jones and woodward 2001 ashby and falgout 1996 kollet and maxwell 2006 maxwell 2013 but can become computationally intractable as model scales increase thus at large scales gridded representations are often replaced by the use of semi distributed models in which hydrological response units hrus typically watersheds subwatersheds form the smallest scale on which either landscape properties or hydrological processes are resolved flügel 1996 examples include vic gao et al 2010 prms leavesley et al 1983 swmm metcalf 1971 canoe www canoe hydro com swat arnold et al 2012b and model for urban sewers mouse mouse 1996 among many others intermediate scales 5 200 km2 however can pose challenges for either of these approaches at these scales deterministic gridded approaches become complicated by a combination of numerical observational parameterization and calibration challenges zehe et al 2014 conversely large scale distributed models struggle to resolve landscape heterogeneity that plays a large part in the hydrological response at intermediate scales dooge 1986 sivapalan 2003 wood et al 1990 one approach to overcoming these challenges is to associate hrus with landscape elements at scales smaller than watersheds or subwatersheds such as hillslopes hillslopes are appealing as a basis for hrus as they are topographically delineated by lateral no flux boundaries that simplify their numerical representation theoretical and empirical research on hillslope hydrology began in the mid 20th century kirkby 1988 and demonstrated that hillslope topology and topography impose primary controls on runoff processes dunne and black 1970 freeze 1971 anderson and brooks 1996 betson and marius 1969 in particular the convergence divergence of flow paths along a hillslope has large effects on surface and groundwater hydrographs woolhiser 1969 moore 1985 agiralioglu and singh 1981 baiamonte and singh 2015 noroozpour et al 2014 sherman and singh 1976 agiralioglu 1988 fan and bras 1998 hillslope curvature can also impact the validity of simple predictive tools such as the rational method that implicitly assume uniform width hillslopes lapides et al 2021a yet although some semi distributed models operate explicitly on hillslope scales e g rhessys tague and band 2004 troch et al 2003 fan and bras 1998 and some account for hillslope convergence divergence e g kineros and topmodel woolhiser et al 1990 smith et al 1995 canfield and goodrich 2006 beven 1997 beven and kirkby 1979 kirkby 1997 the use of one dimensional flow theory to estimate hydrographs on convergent divergent hillslopes remains widespread e g swmm swat hec hms rossman and huber 2016 arnold et al 2012a u s army corps of engineers hydrologic engineering center hec 2020 without clear indication of when curved topography invalidates these tools there is considerable scope to improve on this by accounting for some of the two dimensional properties of surface flow without greatly adding to model complexity for example agnese et al 2007 and baiamonte and singh 2016 solved overland flow equations on idealized trapezoidal hillslopes using a shape factor to incorporate planform curvature in an alternative and more general approach troch et al 2002 troch et al 2003 paniconi et al 2003 and troch et al 2004 used the concept of the hillslope width function hwf to formulate analytical models for the hillslope hydrograph as a function of hillslope curvature the hwf is formalized as the linear distance between contour endpoints at each point x l along the axis from the hillslope divide to the stream channel see fig 1 the hwf provides an intuitive way to study hillslope morphology and its impacts on hydrological outcomes and allows mathematical description of the effects of curvature on hillslope surface and groundwater hydrographs troch et al 2003 fan and bras 1998 lapides et al 2020 bogaart and troch 2006 the computation of these hydrographs is particularly straightforward when hwfs adopt or can be approximated by an exponential form applying tools like the hillslope width function to real landscapes however remains challenging although morphogeometric tools e g wilson and gallant 2000 tarboton and ames 2001 are widely used for delineating watershed boundaries and stream networks for modeling and management applications few of the available tools delineate or characterize the topology of hillslopes one exception is the c based tool by lammers and band 1990 methods available to both delineate hillslopes and calculate hwfs are mostly either time consuming and complex matonse and kroll 2009 sahoo and sahoo 2019 or manual broda et al 2014 one exception is noël et al 2014 who presented a method in physitel for delineating hillslopes and fitting trapezoidal or triangular hwfs no equivalent is currently available to apply to exponential hwfs and to our knowledge none of the available hillslope fitting morphometric packages are compatible with the most widely used gis tools for landscape analysis consequently the implications of hillslope properties and morphology on runoff behavior and appropriateness of different hwf shape assumptions are still very much unknown to address these gaps we developed a set of python based tools that rapidly delineate hillslopes estimate exponential hwfs and apply hillslope based runoff analysis these tools named hillslope delineation and critical duration tools are integrated in arc hydro an arcgis based system geared to support water resources applications maidment and morehouse 2002 we use the hillslope delineation and critical duration tools to investigate the hillslope shapes occurring in real landscapes and to assess the importance of hillslope morphology for surface flow predictions on multiple hillslopes and for large spatial scales in particular we examine the impact of hillslope shape on runoff produced by infiltration excess overland flow in two urban peri urban case study watersheds to answer four research questions 1 how prevalent are divergent hillslopes relative to convergent and uniform width hillslopes 2 how well does an exponential hwf approximate real hillslope shapes 3 how do predictions of hillslope peak flows and timescales accounting for hillslope curvature compare to those based on planar rectangular hillslopes 4 how do predictions of peak flows and timescales at the hillslope scale relate to those at the watershed scale facilitating hillslope curvature analysis and its impacts on runoff will allow a better appraisal of the suitability of one dimensional flow assumptions in different landscape settings while fully exploring this problem remains beyond the scope of the present study we present initial results that evaluate curvature effects on the widely used rational method kuichling 1889 mulvaney 1851 we have previously shown the rational method to be susceptible to errors induced by hillslope curvature and infiltration properties of the soil surface lapides et al 2021b a despite these and other known shortcomings ball et al 2019 coombes et al 2015 krimgold 1946 cleveland et al 2011 smith and lee 1984 ben zvi 1989 efstratiadis et al 2014 grimaldi et al 2012 mccuen 2009 the rational method remains widely used at hillslope scales where overland flow mechanisms prevail the arc hydro critical duration tools incorporate the rational method framework described in lapides et al 2020 to explore when topographic curvature invalidates the rational method this functionality allows an initial appraisal of the importance of accounting for topographic curvature when modeling real landscapes 2 arc hydro hillslope and critical duration tools workflow arc hydro hillslope and critical duration tools are python based arc hydro tools that delineate hillslopes fit exponential hwfs to the delineated hillslopes and assess the degree to which curvature may impact hydrological model predictions using the rational method as an illustrative example this is achieved in five arc hydro tools fig 2 that are included in two arc hydro toolboxes the terrain preprocessing toolbox contains 1 the hillslope partitioning tool which delineates hillslope areas and 2 the hillslope width function tool which fits the hillslopes with an exponential hillslope width function hwf the critical duration toolbox contains 3 the hillslope roughness tool which computes the roughness term needed for peak flow calculation 4 the optimize critical duration tool which uses overland flow theory to compute the impact of hillslope curvature on peak flow predictions and 5 the produce hydrograph tool which produces a storm hydrograph for a user defined rainfall duration and intensity the five tools and their inputs are described briefly below full details about the gis methods are provided in the online tool documentation at https downloads esri com archydro archydro doc 2 1 hillslope tools the first two tools hillslope partitioning and hillslope width function can be used to provide estimates of hillslope curvature and shape as well as how well an exponential hwf approximates hillslope curvature and shape prior to using the hillslope partitioning tool basic terrain processing and watershed delineation must be performed esri 2019 for these steps a digital elevation model dem must be run through basic terrain processing tools to generate a flow accumulation raster a flow direction raster drainage lines or streams watersheds and a corresponding flow accumulation threshold that was used to generate the streams 2 2 hillslope partitioning tool after the pre requisite steps are performed the hillslope partitioning tool partitions the watersheds into headwater hillslopes draining to a stream initiation point and lateral hillslopes draining to a stream reach forming the hillslope s lower boundary following the methods of fan and bras 1998 to avoid delineation of spurious hillslope areas i e small slivers that are not topologically connected to hillslopes this tool removes hillslope parts smaller than or the size of one raster cell in addition hillslope parts smaller than a user specified threshold area are also removed 2 3 hillslope width function tool while many forms of the hwf are possible e g exponential triangular trapezoidal computation of hydrographs is particularly straightforward for exponential forms of the hwf troch et al 2003 lapides et al 2020 to leverage the power of this approach the hillslope width function tool approximates hillslopes with an exponential hwf given by 1 w x c e a x where c l parameterizes width at the divide x represents the distance from the divide following the line of steepest descent down the hill and a determines the degree and nature of hillslope curvature when a 0 the hillslope is divergent and when a 0 the hillslope is convergent a 0 describes a uniform width hillslope the hillslope width function tool applies two criteria to estimate hillslope width functions following noël et al 2014 1 monotonicity and 2 conservation of area monotonicity ensures that the hillslope width function is convergent monotonically increasing divergent monotonically decreasing or constant uniform width conservation of area fulfills mass conservation requirements both of these criteria must be explicitly addressed 2 4 approximating the hillslope width function fig 3 outlines the process for estimating the hwf while fulfilling the monotonicity and conservation of area requirements we begin with a delineated hillslope with a marked outlet to the stream network with area a 0 fig 3a first outlet points are generated at the hillslope outlet blue point in fig 3b each lateral hillslope is associated with 2 outlet points marking the extent of the bottom boundary and each headwater hillslope is associated with a single outlet point next j hillslope points number specified by the user are equally spaced in x y space along the hillslope boundary red points in fig 3b in total each hillslope is characterized by 1 headwater or 2 lateral outlet points and j points along the hillslope boundary hillslope points this point selection process can only correctly characterize headwater hillslopes and lateral hillslopes with an outlet along an approximately linear stream segment each hillslope point is associated with a corresponding point on the opposite side of the hillslope based on location along the hillslope outline see fig 3c for instance the nearest point to the outlet on the left is paired with the nearest point to the outlet on the right the two outlet points are paired on lateral hillslopes and the single outlet point is used as a pair on headwater hillslopes the midpoints along the lines connecting paired points or the single outlet point on headwater hillslopes are used to approximate a linear hillslope midline the hillslope midline forms the x axis that defines the hwf with the divide at x x 0 0 and the outlet at x x end the exponential hwf assumes that a hillslope is symmetrical across the x axis the distance between point pairs gives the width of the hillslope w j at the corresponding distance from the divide along the midline x j see fig 3d providing a set of points x j w j to fit the hwf if the width values are not approximately monotonically increasing or decreasing then the algorithms will not produce a visually or quantitatively acceptable fit to the hillslope shape to prevent this error we truncated hillslopes at x x threshold so that only the downslope portion of the hillslope that is monotonically increasing or decreasing is used to fit the exponential hwf fig 3e this is performed by using nonlinear least squares to fit a broken stick function to the hillslope width data 2 w x a 1 x b 1 x x threshold a 2 x b 2 x x threshold where a 1 a 2 b 1 b 2 and x threshold are constants fit by the algorithm if the sign of a 1 is different from the sign of a 2 then the hillslope is truncated at x threshold otherwise the full set of hillslope width data is used from here the value of x threshold effectively becomes the hillslope divide and x 0 shifts to x threshold the remaining points are used to fit an exponential width function defined by c and a fig 3f finally the hillslope area is conserved by tuning the divide location x 0 to the value x top that causes the final area to equal a o while keeping the outlet location x end constant fig 3g 2 5 error metrics the hillslope width function tool also computes metrics that assess four potential sources of error fig 4 i the stream error strm err ii the point selection error pt err iii the truncated point selection error pt trunc err and iv the shape fit shp fit each of these metrics is described below i the stream error strm err fig 4a computed only for lateral hillslopes is the percent error between the euclidean stream distance measured as the linear distance between lateral hillslope outlet points and the actual distance along the stream segment this error metric ranges from 0 to 100 with smaller values meaning that the linear approximation is suitable and larger values meaning that the linear approximation may not be valid ii the point selection error pt err fig 4b is computed as the percent error between the actual hillslope area and the polygon constrained by the hillslope points this metric indicates how well the points represent the hillslope shape if the area bounded by the points is not representative of the shape or area of the original hillslope the magnitude of the point selection error will be large the point selection error identifies the degree to which the shape defined by the points along the hillslope outline is representative of the actual hillslope note that even if the pt err is high the area defined by the hwf and hillslope length will still equal the actual hillslope area iii the truncated point selection error pt trunc err fig 4c is the percent error between a polygon constrained by the hillslope points and a polygon constrained by the truncated hillslope points a high pt trunc err means that a large portion of the hillslope was neglected during the fitting process to maintain monotonicity this means that the points used to fit the hwf are only representative of a small portion of the hillslope and application of the fitted hwf to the entire hillslope may be inappropriate iv the shape fit metric shp fit fig 4d is the r 2 coefficient of the best fit hwf and ranges from 0 to 1 a low r 2 indicates that the exponential hwf is a poor fit to the hillslope shape described by the hillslope points for most hillslopes all of these errors can be reduced by increasing the number of hillslope points used to estimate the exponential hwf an additional potential source of error in the hwf tool is associated with the assumptions inherent to the use of an exponential hwf based on the hillslope outline the width function approximation applied in the hillslope width function tool is fit to the hillslope outline rather than the measured contours from the dem theoretically the width function represents a linear distance between contour endpoints this means that approximating the hwf from the hillslope outline will perform best where a hillslope is nearly symmetric with a relatively constant slope however the approximation of the hwf from the hillslope outline was applied by noël et al 2014 with success supporting the use of this same approximation in arc hydro hillslope after running the hillslope width function tool the following fields are added to each hillslope the exponential hillslope width function constants c and a see equation 1 the x location of the hillslope top x top and bottom x end hillslope length l calculated as x end x top and the error metrics 2 6 critical duration tools illustrative application of hillslope tools the next three tools located in the critical duration arc hydro toolbox apply the hillslope tools above to explore the impact of hillslope shape and curvature on peak flow estimated by the rational method the critical duration tools allow us to address the second research question i e the comparison between a 1d flow model and a flow model that accounts for topographic curvature 2 7 hillslope roughness tool predicting overland flow rates on hillslopes requires a roughness parameter α given by α s o n where s o is the land surface slope l l and n is manning s roughness coefficient l 1 3 t the hillslope roughness tool computes roughness α for each hillslope using the average hillslope slope s o and a hillslope area weighted manning s roughness coefficient n estimated by converting a land cover raster e g the national land cover database nlcd land cover product using the lookup table developed by kalyanapu et al 2009 however if a user has their own roughness raster or roughness values for hillslopes this step may be skipped provided that the roughness values are included in the hillslope feature class in the correct format we refer the reader to the user manual for additional detail https downloads esri com archydro archydro doc 2 8 optimize critical duration tool the conventional rational method kuichling 1889 mulvaney 1851 predicts the maximal peak flow q max for a given return period as 3 q max c a i where c is a runoff coefficient a is the contributing area and i is a design storm intensity while generally understood as a multiplication of constants equation 3 is better understood as the product of three storm duration dependent curves where the rational method attempts to return the maximum value of this product by appropriate selection of the storm duration d lapides et al 2021b in other words the rational method is an optimization of the product of c d a d and i d the storm duration for which q cai is maximal is called the critical duration d crit l using a simplification suggested by kuichling 1889 and mulvaney 1851 d crit is often equated to the time of concentration t c the time when the entire hillslope area is contributing to flow at the outlet this assumption may be invalidated by hillslope curvature so that d crit t c lapides et al 2021b a in all cases d crit t c for cases where hillslope curvature causes d crit t c using t c as the timescale underestimates peak flow lapides et al 2021a b the optimize critical duration tool computes d crit directly by numerically optimizing a runoff coefficient curve c d contributing area curve a d l2 and an intensity duration curve for a given return period i d l t described in appendix i to find the maximal peak flow on the hillslope lapides et al 2021a for each storm duration rational method parameter i are computed from an intensity frequency duration ifd curve and parameters c and a are calculated from analytical solutions for overland flow on hillslopes represented by a hwf with parameters c a x top 0 and x end lapides et al 2020 the differences between rational method peak flow predictions using d crit and those using t c offer one measure of how hillslope curvature may invalidate one dimensional flow assumptions 2 9 optimization inputs the optimize critical duration tool requires an ifd curve defined by constants k and b and a value for saturated hydraulic conductivity k s l t the ifd constants k and b are based on a power law approximation to an ifd curve koutsoyiannis et al 1998 4 i d k d b in this approximation k determines how intense storms are for a given return period stormier climates and longer return periods have larger values of k the constant b usually 0 35 b 0 60 is related to rainfall variability monjo 2016 smaller values of b are associated with monsoonal polar or orographic rainfall patterns and higher values of b are associated with convective rainfall monjo 2016 users can identify these values by fitting equation 4 to regional ifd curves with the user provided k b and k s constants the optimize critical duration tool calculates c d and a d from the analytical solutions described in appendix i this process assumes that c is defined based on a constant loss rate k s but does not take into account the effects of varying antecedent moisture conditions on the infiltration loss behavior lapides et al 2021b k s is incorporated into analytical solutions by altering the ifd curve to an effective rainfall rate i d k d b k s this formulation neglects the impact of infiltration on the falling limb but does not affect the calculation of a design flow in this methodology the c d curve is then calculated from the rational method relationship c d q ai 2 10 optimization outputs the optimization critical duration tool adds five fields to the hillslope feature class q max m 3 s d crit s t c s d crit t c and a boolean field d crit t c that indicates if d crit is less than t c the output q max represents the maximum value of q d the rational method peak flow prediction the output d crit identifies the duration for which q d q max the output t c corresponds to the first storm duration for which the entire hillslope contributes flow to the outlet the final output d crit t c is produced to assist with interpretation of results if d crit t c 1 the performance of the traditional rational method is not worsened by hillslope curvature or infiltration behavior however if d crit t c 1 then the traditional rational method and t c are likely to underestimate q max in some cases the storm properties dictated by the ifd curve mean that there are no conditions for which the entire hillslope contributes to flow at the outlet and thus t c in these cases d crit t c does not exist but since d crit is still less than t c the binary field d crit t c yes 2 11 storm event hydrograph tool the storm event hydrograph tool uses the k b and k s values along with the critical storm duration d crit from the optimize critical duration tool output to compute the rainfall intensity i m s associated with a user defined duration t r s equation 4 and produce the associated storm hydrograph for each hillslope 3 estimating the impact of hillslope curvature at watershed scales spatial scaling of different hydrological processes remains an open challenge thompson et al 2011 peters lidard et al 2017 ichiba et al 2018 linking the arc hydro hillslope and critical duration tools with a routing model that connects flow between hillslopes to simulate a watershed scale response offers an opportunity to explore whether and how hillslope curvature can affect whole of watershed flood responses the final research question outlined for this study to illustrate the potential of this approach we represented watersheds as a collection of hillslopes draining through the stream network to the watershed outlet hydrographs for each hillslope are produced from arc hydro critical duration tools and the stream network is discretized into multiple reaches where each reach receives flow from some fraction of the lateral hillslopes flow into each reach is given by the sum of channel inflow including headwater hillslope and lateral inflow because this study is initial and illustrative we consider only kinematic flow in the channels converting storage per reach to a flow velocity q using the kinematic relationship q αh 1 2 velocities are integrated through time as hillslope hydrographs change this simple modeling approach is represented visually in fig 5 4 case study areas and experimental design we applied the arc hydro hillslope and critical duration tools to two case study subwatersheds fig 6 i a 13 km2 rural subwatershed of usda ars walnut gulch experimental watershed arizona and ii a 9 km2 urban subwatershed of the las trampas creek watershed california the walnut gulch experimental watershed is a semiarid watershed moran et al 2008 located in the transition zone between the chihuahuan and sonoran deserts the mean annual precipitation in this area is approximately 310 mm and about 60 of the rainfall occurs during july august and september almost all runoff in the watershed occurs during these months in response to high intensity convective thunderstorms goodrich et al 2008 we used a subwatershed of walnut gulch that drains 13 km2 of desert soils and impermeable areas in the town of tombstone in southern arizona fig 6a we refer to this case study location as the wg subwatershed las trampas creek watershed flows through city of lafayette california fig 6b the watershed has a mediterranean climate with mean annual precipitation of about 510 mm nearly all of which occurs during the winter months weather atlas 2020 we focused on a small 9 km2 subwatershed of las trampas creek watershed that drains to reliez creek we refer to this case study location as the lt subwatershed the wg and lt subwatersheds both contain relatively wide expanses of impermeable areas either desert soils or impervious surfaces in urban areas making them well suited for application of the rational method peak flow optimization arc hydro tool additionally these watersheds have varied topographywith steep upland areas and flatter areas downstream thus providing an opportunity to test the new arc hydro tools across a range of topographies and potential hillslope shapes 4 1 determining the prevalence of divergent hillslopes and suitability of exponential width function to determine the prevalence of divergent hillslopes we applied the hillslope partitioning and hillslope width function tools to the two case study watersheds we obtained a 10 m dem for the wg subwatershed heilman et al 2008 and for the lt subwatershed contra costa county 2017 and used these dems to delineate hillslopes in each study area using the hillslope partitioning tool we then tested the sensitivity of the hillslope width function tool to the number of hillslope points specified by varying the number of hillslope points j from 8 to 96 based on visual inspection of these results we identified the value of j above which error metrics were relatively constant using this threshold number of hillslope points we i determined the prevalence of divergent a 0 0001 uniform width 0 0001 a 0 0001 and convergent a 0 0001 hillslopes for each study area and ii examined the resulting error metrics 4 2 comparing estimates of timescales and peak flows we obtained land cover rasters for both the wg and lt subwatersheds from the national land cover database and used these as inputs to the hillslope roughness tool section 3 the resulting hillslope feature class containing hillslope width function parameters and roughness estimates for each hillslope was used as input to the optimize critical duration tool section 3 we assumed k s corresponding to loam soils and ifd parameters k and b that correspond to the 50 year return interval see table 1 ifd data for the two case study locations were obtained from local sources for the wg subwatershed in cochise county az tabulated ifd data are available for short storms of return periods from 2 to 100 years keefer et al 2016 for contra costa county ca where the lt subwatershed is located ifd data are available graphically for different mean annual rainfall depths contra costa county flood control and water conservation district a b c d e for each return period we tabulated by hand the rainfall depth associated with the 20 inches yr about 508 mm contour for the same storm durations for which data were available for the wg subwatershed 5 min 10 min 15 min 30 min 1 h those rainfall depths were then converted to average intensities by dividing the depth by duration for each return period tabulated intensity duration data for both the wg and lt subwatersheds were used to find an optimal fit to equation 4 resulting ifd curves are included in appendix b the optimize critical duration tool produced estimates for the critical duration d crit and the time of concentration t c for each hillslope we examined the differences between these timescale estimates d crit and t c and the resulting peak flow estimates q peak d crit and q peak t c using i the timescale ratio d crit t c which is always less than one since d crit t c under the conditions considered and ii the peak flow ratio q peak d crit q peak t c which is at least one by definition since q peak d crit produces the maximum possible flow 4 3 exploring the impact of hillslope curvature at subwatershed scales to explore potential scaling of curvature in the model described in section 4 we consider the simplest topographically meaningful situation of one headwater hillslope and two lateral hillslopes we identified 10 real subwatersheds in each case study area with this configuration for each subwatershed we estimated stream parameters from aerial imagery and previous reports where available stream channels in the wg subwatershed had an average width of 4 m estimated from aerial imagery and were characterized by stream manning s n of 0 03 per bunch c e forbes 2019 stream channel widths could not be determined from aerial imagery of lt subwatershed due to high canopy cover around the stream channel so we assumed the same stream channel width as wg 4 m and estimated stream manning s n as 0 04 gravelly and cobbled bottom chow 1959 in all cases channel propagation is significantly faster than hillslope propagation α is nearly 2 orders of magnitude larger and channel segments are short relative to hillslope sizes we expect in these situations that hillslope responses should be important for the watershed hydrographs relative to the channel conveyance d odorico and rigon 2003 we investigated the influence of the hillslope runoff response on peak flood flows by performing an optimization for peak flow as described in section 3 for the watershed under two assumed situations a using the best fit exponential hillslopes and b using rectangular hillslopes setting the hillslope length equal to the longest flowpath 5 results all results below are shown using j 96 hillslope points see appendix c for details on the effects of varying the number of hillslope points 5 1 prevalence of divergent hillslopes and suitability of exponential width function fig 7 shows for j 96 hillslope points the distribution of hillslope curvature in each case study watershed the majority 91 of headwater hillslopes are convergent while the majority 51 of lateral hillslopes are divergent table 2 by area divergent hillslopes account for 32 and 55 of walnut gulch wg and las trampas lt subwatersheds respectively as shown in the inset pie charts in fig 7 table 2 summarizes the percent of headwater and lateral hillslopes that are divergent convergent and uniform width 5 2 suitability of exponential hillslope width functions we discuss error metrics in depth in appendix d but note here that the shape of both convergent and divergent hillslopes was overall well approximated by the exponential hillslope width function with median r 2 values ranging from 0 52 wg convergent hillslopes to 0 79 lt convergent hillslopes while there is no specific r 2 threshold for which the fit of a function is considered good the majority of r 2 values obtained here are similar to those obtained in previous studies that were considered to be representative of good fits e g sahoo and sahoo 2019 generally considered r 2 0 5 to be representative of good exponential fits other error metrics point error truncated point error and stream error for lateral hillslopes are discussed in detail in appendix d 5 3 effects of hillslope curvature on timescale and peak flow estimates by applying critical duration tools to wg and lt subwatersheds we found that hillslope curvature can result in an underestimation of q peak by up to a factor of 3 when t c is finite fig 8 a larger fraction of hillslopes in lt fig 8b show a pronounced difference between d crit and t c d crit t c 1 than in wg fig 8a which is likely attributed to the larger fraction of hillslopes in lt that are divergent see fig 7 this higher divergence in turn drives the more extreme relationship between the timescale ratio d crit t c and the peak flow ratio q peak d crit q peak t c at lt fig 8d compared to wg fig 8c 5 4 impacts of hillslope divergence at catchment scales for nearly all of the 3 hillslope catchments assessed deviation between t c and d crit is observed at the catchment outlet this deviation is shown by the light grey striped bars in fig 9 a and b the timescale ratio d crit t c is plotted for both hillslope hydrographs hillslope timescale ratio and full catchment hydrographs catchment timescale ratio the catchment timescale ratio d crit t c ranges from 0 7 to 1 for wg subwatershed and 0 2 to 1 for lt subwatershed at catchment scales transit times through the channel non linearly impact the timing of catchment peak flow which can amplify differences between watershed scale t c and d crit this is seen in the greater spread and smaller values of d crit t c for catchments light grey striped bars in fig 9a and b relative to the individual hillslopes blue green bars if uniform width hillslopes are used instead of curved hillslopes for the simulations timescales t c and d crit do not disagree at the hillslope scale for any of the hillslopes in the catchment not shown but t c and d crit can and typically do still separate from each other at the catchment outlet due to the effects of flow propagation along the channel this disagreement however is minimal difference between t c uniform and the red dot on the dashed line in fig 9c d the minimal impact of channel propagation alone on d crit supports the presumption that channel routing timescales are less important than hillslope travel times at this scale the model using uniform width hillslope produces lower peak flow curves at catchment scales relative to peak flow estimates that account for curvature and d crit is delayed the stronger effects of hillslope curvature on catchment peak flow responses in the wg subwatershed panel c than the lt subwatershed panel d are attributable to the lower intensity rainfall and more curved hillslopes in wg compared to lt these results indicate that the magnitude of curvature on real hillslopes is substantial enough to impact peak flow estimates both at the hillslope and small catchment scales when hillslope processes are expected to be important 6 discussion the new arc hydro tools presented here facilitate the delineation morphological characterization and hydrological evaluation of hillslopes for surface runoff predictions by consistently and automatically delineating hillslopes as geomorphic units arc hydro hillslope tools can support a wide variety of hydrological and geomorphic analyses and research at hillslope scales in this study we explored potential applications of the arc hydro hillslope and critical duration tools which focus on hortonian peak flow sensitivity to hillslope curvature as modified by climate and soil permeability lapides et al 2020 2021b beyond this case there is ample scope to link arc hydro hillslope to groundwater hydrograph prediction troch et al 2002 2003 2004 paniconi et al 2003 or to extend it with analysis of spatial patterns of vegetation cover dralle et al 2014 particularly considering that reduced complexity analytical predictions are also available for these situations based on our initial application of arc hydro hillslope and critical duration tools to the case study watersheds several methodological and geomorphological findings should support such use and future extension 6 1 hillslope curvature can be accurately estimated with exponential functions exponential hillslope width functions hwfs offer numerous mathematical benefits when attempting to develop user friendly analytical flow predictions for surface or groundwater discharge from hillslopes lapides et al 2020 troch et al 2003 fortunately exponential hwfs provided a very reasonable approximation to real hillslope morphology hillslope exponential fit median r 2 ranged from 0 52 to 0 79 suggesting a good fit of exponential hwfs to natural hillslopes while the distributions of r 2 were slightly wider for convergent hillslopes than for divergent hillslopes their median values were not substantially different convergent hillslopes were characterized by higher point error truncated point error and stream error these results are consistent with research by sahoo and sahoo 2019 who found that the exponential hwf is better suited for estimating the curvature of divergent hillslope than of convergent hillslopes other approximations for the hillslope width function e g based on triangular rectangular or trapezoidal shapes have been used in previous studies with some success noël et al 2014 baiamonte and singh 2015 and may be more suitable than exponential hwfs in some cases future extensions of arc hydro hillslope to allow the use of these geometries could be a useful direction for development 6 2 high prevalence of divergent hillslopes in the case study watersheds headwater hillslopes were generally convergent and lateral hillslopes were divergent on average see table 2 similar to sahoo and sahoo 2019 in the lt subwatershed we found that divergent hillslopes comprised the majority of the hillslopes however we found a preponderance of convergent hillslopes in the wg subwatershed consistent with other authors e g noël et al 2014 bogaart and troch 2006 the lack of convergence so to speak on this concept is unsurprising watersheds and therefore hillslopes are influenced and shaped by many geomorphic hydrologic and biophysical processes it follows that any variability in these processes among watersheds could influence the relative prevalence of different hillslope shapes and curvatures resulting in different conclusions at different study sites since headwater hillslopes tend to be convergent it is possible that landscape scale may drive the prevalence of convergent vs divergent hillslopes in a small first order watershed a headwater hillslope is a large fraction of the landscape the simplest second order watershed consists of two first order watersheds with an additional pair of lateral hillslopes the fraction of lateral hillslopes increases with watershed order following this pattern in the simplest possible watershed where a nth order watershed is always the joining of two n 1 order watersheds the number of headwater hillslopes grows like the fibonacci sequence 5 h i 2 h i 1 where h i is the number of headwater hillslopes for a simple watershed of order i and the number of lateral hillslopes grows as 6 l i 2 l i 1 2 where l i is the number of lateral hillslopes for a simple watershed of order i as the sequence grows l i grows much faster table 3 and the ratio h i l i approaches an asymptote at 0 25 different asymptotic behavior would be expected for different values of the bifurcation ratio but in general the geometry of the watershed defines the relative prevalence of headwater and lateral hillslopes additionally even within the idealized bifurcation of the network described here there could be convergent lateral hillslopes so the estimate for h i l i represents the lower bound on the ratio of convergent to divergent hillslopes for this prescribed network topology scaling relationships are well developed for watersheds e g crave and davy 1997 zaliapin and kovchegov 2012 burd et al 2000 but similar relationships are less well developed for hillslopes the new functionality offered by archydro hillslope could support the development of datasets that would allow exploration of hillslope scaling relationships and drive the development and testing of theory to explain the observed scaling phenomena relationships 6 3 hillslope curvature impacts peak flows and timescales using the rational method as a simple example we found that realistic landscape curvature has an important impact on hydrological outcomes for hillslopes with divergent curvature we found that the time of concentration t c over estimates the storm duration producing peak flow in the rational method in the case study hillslopes for the 50 year storm the ratio of the flow maximizing timescale d crit to t c varied between 0 and 1 0 this variation was associated with under estimation of peak flow by as much as a factor of 3 fig 8 the deviation between t c and d crit observed at the hillslope scale is non linearly related to the deviation at the catchment outlet we found that timescale deviation and the resultant impact on peak flow estimates is exaggerated at the catchment scale compared to the hillslope scale highlighting the importance of catchment morphology for accurate hydrological prediction these results indicate that hillslope curvature could be important at the catchment scale but further study is required to understand how strong of a role hillslope curvature plays in producing catchment hydrograph characteristics relative to other drivers of hydrograph behavior not included in our model for instance transmission losses in the channel were neglected and may be significantly more important than hillslope curvature in impacting catchment hydrographs at some sites like walnut gulch lane et al 1997 6 4 implications for observations the results of this study illustrate the potential value of arc hydro hillslope and critical duration tools for interpreting the impacts of hillslope curvature on flow estimates they also raise questions about hydrological management and monitoring divergent hillslopes are more challenging to monitor or gauge than convergent hillslopes which route water to a single channel flow records particularly at small scales i e those measuring headwater watersheds or hillslopes may therefore be biased toward locations with convergent topography validating existing hillslope theories on divergent hillslopes will require creative monitoring techniques one strategy that may be able to detect the impact of hillslope curvature on watershed hydrographs is nested gauging where gauges are placed upstream downstream of where a divergent hillslope contributes to a stream channel examining changes in hydrograph shape between the gauge locations could allow inference of the behavior of the hillslope hydrograph for most hydrological applications though calibration and validation are done at catchment or watershed subwatershed scales the knowledge that hillslope curvature could have a large impact on catchment hydrology suggests that monitoring campaigns could gain useful information by deliberately monitoring watersheds with different combinations and orientations of hillslope topologies 6 5 future work arc hydro hillslope tools provide a rapid and efficient way to delineate and fit hwfs to real hillslopes delineation of hwfs using hillslope outlines while efficient masks some complexity within the hillslopes future improvements to the tool could increase capabilities to handle geometrical situations that violate the hillslope width function tool s current assumptions for instance situations where the channel does not flow parallel to the divide or where exponential hwfs provide a poorer description of hillslope morphology than other functions such as trapezoidal or triangular hwfs noël et al 2014 or similar geometric elaborations arc hydro critical duration tools provide tools to predict peak flow similarly to the rational method these tools assume infiltration excess overland flow produced by known spatially uniform and temporally steady rainfall such tools are only appropriately used in small hillslopes with low permeability and modest hillslope gradients lapides et al 2020 2021a lapides et al 2020 found that the curvature constant a 0 02 is a reasonable bound for applicability of the flow prediction tools built into arc hydro critical duration tools under idealized conditions thus in urban landscapes which are characterized by a large fraction of impermeable area and have modest slope and curvature e g due to site grading or site selection these tools are likely to be highly applicable although more research is required to identify the applicability on real landscapes the modest requirements for meteorological and land surface data supports wide applicability of arc hydro critical duration tools to locations where only limited data are available arc hydro hillslope tools can also be used to operationalize other hillslope based models notably exponential hillslope width functions have also been used to model groundwater flow troch et al 2004 under the assumption that groundwater flow follows surface topography arc hydro hillslope could be used as a foundation to implement this model in an accessible platform theoretical studies of the impacts of hillslope properties on hillslope hydrology such as the study conducted by dralle et al 2014 on vegetation patterns and topography use an intuitive theoretical parameter range to describe hillslope shapes with the ability to delineate hillslopes in arc hydro hillslope functionality could be added to calculate realistic parameter ranges and compare performance of different hillslope models on real hillslopes 7 conclusion planners and hydrologists enjoy an unprecedented ability to observe the features of the landscapes they study an ability only likely to increase in the future wood et al 2011 this information availability facilitates increasingly realistic landscape depiction even in simple models hillslopes provide an attractive scale at which to incorporate new information as these scales offer direct links between landscape properties and flow behavior arc hydro hillslope and critical duration tools provide a platform with which to achieve this integration of theory and observation in service of useful hydrological predictions by facilitating rapid landscape analysis at the hillslope scale we anticipate that these tools will enable advances in developing and testing geomorphological understanding of hillslope geometry across large watersheds in testing scale dependence of flow behavior to underlying hillslope topology and processes and in allowing practitioners to readily accommodate hillslope morphology in regular prediction tasks thus archydro hillslope and critical duration tools present a useful step forward to improve research and practice in geomorphology hydrology and water management design software availability statement name of software arc hydro hillslope and critical duration tools developers dana lapides anneliese sytsma gina o neil dean djokic mary nichols sally thompson contact anneliese sytsma berkeley edu year first available 2021 required hardware and software arc hydro hillslope and critical duration tools are available as an arcgis toolset operating on the esri software specifically arcgis pro 2 7 and higher availability arc hydro hillslope and critical duration tools are available on through esri s arc hydro toolbox users should install version 2 7 or higher of arc hydro from http downloads esri com archydro archydro setup pro additional guidelines for installing arc hydro are available from http downloads esri com archydro archydro doc the user manual associated with the arc hydro tools will be maintained on ersi arc hydro website https downloads esri com archydro archydro doc python source code used to calculate ifd curve parameters used as input to the arc hydro tools is published in a github repository at https github com lapidesd intensity duration frequency declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we would like to thank alain rosseau and sebastien tremblay for useful discussion this work was supported by national science foundation s engineering research center for reinventing the nation s urban water infrastructure renuwit eec 1028968 as the national science foundation grants ear 1013339 and ear bsf1632494 dal the hellman foundation dal the gledden foundation at the university of western australia s institute for advanced studies as and the university of california berkeley dal appendix i analytical solutions for overland flow used in rational method optimization to conduct the optimization for peak flow we need to calculate peak flow q peak d as a function of storm duration to do this we follow lapides et al 2020 and calculate peak flow from a kinematic wave model for overland flow assuming that the average flow across a hwf contour is representative then the average flow quantities may be used in conjunction with the hillslope width w to give a pseudo 2d description of flow while retaining the simplicity of a one dimensional solution lapides et al 2020 for the idealized case of constant runoff production and an exponentially hwf the hydrograph can be determined from analytical approximations to the kinematic wave equation lapides et al 2020 by solving the governing equation via the method of characteristics a 1 h w t q w x r w where h l is the average flow along a contour t t is time q l2 t is average flow per unit width and r l t is effective storm intensity for hillslopes with mild to moderate curvature there is excellent agreement between analytical solutions and numerical and laboratory simulations lapides et al 2020 see lapides et al 2020 for full solutions derivations validation and implications to apply these solutions the following information is required i exponential hwf parameters c a x 0 location of divide and x end location of the outlet calculated in step 3 ii roughness α calculated in step 2 iii design storm defined by a constant intensity i and storm length t r specified from an ifd curve provided by the user in step 4 appendix ii ifd curves for different return periods fitted ifd curves and tabulated data are plotted in fig 10 for a walnut gulch subwatershed az and b las trampas subwatershed ca in fig 10a it is clear that the fitted ifd curves for walnut gulch provide a good fit to the data until the longest storms when the storm intensity is over estimated fitted ifd curves for the las trampas subwatershed though fig 10b match the tabulated data perfectly best fit parameters for each return period and location are shown with the plots in fig 10 the larger values of k in walnut gulch indicate generally more intense storms than in las trampas the values of b are comparable between the two study areas although rainfall seasonality is reversed while a large range in k values is represented among the ifd curves for both sites and all return periods the range of b values between sites for all return periods is very narrow compared to the global range observed by monjo 2016 fig 10 fitted exponential ifd curves i k d b for a walnut gulch wg az and b las tramps lt ca the best fit parameters for 5yr and 10yr return periods are shown fig 10 appendix iii effect of varying hillslope points on exponential width function errors fig 11 shows box plots of the error metrics fig 11a c and resulting values of a fig 11d for each point specification the median exponential fit metric r 2 decreases rapidly between j 8 and j 16 falling from a value of 0 1 to 0 8 and remains around 0 8 with increasing number of points a however there is a corresponding sharp decrease in point error with increasing number of points after j 8 thus the fact that r 2 is so high for j 8 does not necessarily suggest that the exponential fit is better for these number of points because as seen in b this low number of points is associated with a high point error meaning that the points selected do a poor job of representing the hillslope shape the median point error for j 8 is relatively constant ranging from 6 to 7 the truncated point error c indicates the proportion of the hillslope that was removed in the truncation process median values ranged from 28 to 40 the impact of these errors on a appears to be minimal for j 8 with median a relatively constant around 0 c we chose to use j 96 for the case study because we observed the best combination of exponential fit and error metrics relative to other j values j 96 has a high r 2 median value of 0 76 and low point error median of 2 7 and truncated point error median of 22 9 we note however that the optimal number of points will vary depending on hillslope morphology and specific application of the hillslope tools fig 11 effect of number of points on exponential fit a point error b truncated point error c and a d for las trampas subwatershed fig 11 appendix iv exponential width function errors across all hillslopes in both case study watersheds the exponential fit metric r 2 ranged from 0 to 1 fig 12a median r 2 values ranged from 0 52 wg convergent hillslopes to 0 79 lt convergent hillslopes the median point errors percent error in point area relative to hillslope area fig 12b are very small ranging from 0 15 wg divergent hillslopes to 2 6 lt divergent hillslopes the full range of point errors goes from 100 to 100 error but the extreme error values are outliers these low median point errors suggest that the points chosen by the hillslope width function tool generally do a good job at estimating both convergent and divergent hillslope areas interestingly the truncated point error percent error in truncated point area relative to non truncated point area fig 12c was noticeably higher for convergent hillslopes across both wg and lt subwatersheds median of 51 and 55 respectively than for divergent hillslopes median of 14 and 3 respectively this suggests that in these two subwatersheds divergent hillslopes tend to be more monotonic and thus require less truncation than convergent hillslopes this may be related to a tendency for hillslopes to originate from a highest point rather than a wide ridge of similar height at the divide stream error for lateral hillslopes the percent error between stream length approximated by a straight line and actual stream length fig 12d is relatively low with median error less than 15 across all hillslope curvatures this suggests that overall approximating the stream channel as a straight line does not contribute substantially to error in the hwf fit fig 12 boxplots of hillslope width function exponential fit a point error b truncated point error c and stream error d metrics for walnut gulch wg and las trampas lt subwatersheds using j 96 points too few uniform hillslopes were present to calculate statistics these hillslopes not shown fig 12 
25586,producing accurate hindcasts and forecasts with coupled models is challenging due to complex parameterizations that are difficult to ground in observational data we present a calibration workflow that utilizes a series of machine learning algorithms paired with windsurf a coupled beach dune model aeolis the coastal dune model and xbeach to produce hindcasts and forecasts of morphologic change along bogue banks north carolina neural networks paired with genetic algorithms allow us to fine tune calibration parameters for the hindcast and then a long short term memory neural network trained on the hindcast produces a 4 year forecast we compare our hindcasts to observations from 2016 to 2017 and find they successfully reproduce observed modes of dune and beach change except for seaward growth of the dune face we compare our forecasts to observations from 2016 to 2020 and find that they produce reasonably accurate predictions of dune change except when there are significant instances of erosion during the forecast period keywords beach dune processes erosion neural network genetic algorithm windsurf forecast 1 introduction understanding foredune growth and erosion is critical for predicting how sandy coastal systems will likely respond over time to sea level rise e g passeri et al 2020 2021 duran vinent and moore 2015 and possible changes in the intensity of storms e g knutson et al 2010 coastal dunes form naturally through biophysical feedbacks between aeolian sediment transport and vegetation growth e g baas and nield 2007 biel et al 2019 davidson arnott et al 2012 durán and moore 2013 hacker et al 2012 2019 p hesp 2002 luna et al 2012 ruggiero et al 2019 zarnetske et al 2015 2012 as well as marine driven sediment transport cohn et al 2019a sufficiently strong winds entrain sand and transport it across the beach toward the dune where turbulence induced from interactions between the wind and vegetation cause the shear stress acting on the grains to drop below the critical threshold for transport resulting in deposition durán and moore 2013 dune grasses are stimulated by sand burial causing them to grow and accrete more sand e g brown and zinnert 2018 hacker et al 2012 2019 harris et al 2017 maun 1998 seneca 1972 zarnetske et al 2012 2015 ultimately promoting the formation of a vegetated foredune located at the seaward most position where vegetation can survive biel et al 2019 hesp 2002 maun 1998 management efforts such as sand fence construction and dune grass planting often carried out in combination promote the formation of artificially constructed dunes that limit the impact of erosion and flooding on infrastructure landward of the dune e g anthony 2013 charbonneau and wnek 2016 grafals soto and nordstrom 2009 itzkin et al 2020 mendelssohn et al 1991 miller et al 2001 conversely dunes are eroded during storms when the water level is sufficiently high to impact dunes directly e g long et al 2014 roelvink et al 2009 sallenger 2000 seabloom et al 2013 stockdon et al 2006 wave runup is proportional to beach slope with steeper beaches experiencing greater runup than shallower beaches for an equivalent wave climate e g battjes 1974 ruggiero et al 2001 stockdon et al 2006 beach slope changes frequently and significantly e g straub et al 2020 theuerkauf and rodriguez 2014 given the myriad of processes that contribute to long term evolution of beaches and dunes modeling coastal evolution over annual to decadal time scales requires consideration of both aeolian and hydrodynamic processes that span the coastal zone from the nearshore to the backshore moore et al 2016 additional considerations must also be made when modeling change along a developed shoreline that has been extensively modified through various management interventions and thus evolves differently than undeveloped coastlines which are governed by natural processes e g mcnamara and lazarus 2018 windsurf cohn et al 2019a couples xbeach roelvink et al 2009 the coastal dune model cdm duran and moore 2013 and aeolis hoonhout and de vries 2016 to simulate hydrodynamic processes multi fraction aeolian sediment transport and feedbacks between vegetation growth and sediment transport windsurf s modular framework allows for the incorporation of additional processes including management initiatives such as sand fences making it well suited for modeling dune and beach behavior on managed coastlines though windsurf allows investigation of coupled beach and dune evolution careful calibration of model parameters must be undertaken to ensure reasonable behavior and predictions calibration of an individual model is a rigorous task e g goldstein and moore 2018 palmsten and holman 2012 simmons et al 2017 splinter and palmsten 2012 vousdoukas et al 2012 and the calibration process for a coupled model such as windsurf is made more difficult by the extensive set of tunable parameters within each model core i e xbeach cdm aeolis nonlinear interactions between parameters within and across the individual model cores further complicates calibration for these reasons one at a time or manual calibration methods and sensitivity tests are not necessarily optimal for identifying a reasonable solution cohn et al 2019a calibrated windsurf using 100 simulations with a random sample of parameters on a high energy dissipative beach in the us pacific northwest however there are additional parameters to tune when modeling a reflective beach roelvink et al 2018 sanuy and jiménez 2019 vousdoukas et al 2011 2012 that makes this random calibration approach computationally expensive due to the need for running a prohibitively large number of simulations a potential avenue for calibrating windsurf efficiently involves the use of data driven techniques some of which have been previously employed on the individual model cores contained within the windsurf coupling previous studies have demonstrated success in calibrating cdm goldstein and moore 2018 and xbeach simmons et al 2017 2019 using automated methods to estimate parameter values simmons et al 2017 identified a set of parameter values for an xbeach simulation of storm erosion in emilia romagna italy using a monte carlo based method that sought to optimize a generalized likelihood metric however the number of calibration simulations required n 15 000 in the paper is prohibitively large for use with windsurf an alternative calibration approach which required a smaller number of simulations is presented by goldstein and moore 2018 who describe a workflow for calibrating cdm that utilizes a genetic algorithm ultimately a calibration method is needed that can quickly converge on a set of optimized parameter values to overcome windsurf s substantial runtime approx 1 5 days on the unc longleaf supercomputer for a one year simulation and nonlinear interactions between model parameters through the development of a calibration workflow that utilizes data driven approaches we allow windsurf to effectively and efficiently auto calibrate n 1 500 simulations without requiring any manual calibration we also note that although while this calibration workflow is specifically applied here to the coastal model windsurf in this paper it could be used more generally to calibrate any environmental model that contains parameters that aren t able to be set from observational data model calibration can be a time consuming process and by utilizing machine learning methods to allow the model to tune itself the researcher can then spend more time on analyzing results and testing hypotheses with their model here we use windsurf to produce a one year hindcast of both a managed and an unmanaged foredune profile sampled from the outer banks of north carolina usa we then use the output from the hindcasts to produce 5 year predictions of changes in foredune morphology the windsurf simulations are paired with a series of neural networks and genetic algorithms described in section 2 2 to enhance the accuracy and efficiency of the hindcasts and to extend predictions of morphologic change beyond the hindcast period hereafter referred to as forecasts the aims of this research are two fold first we demonstrate a potential calibration workflow that can alleviate the challenges of calibrating a complex coupled model by combining process based and machine learning models second we test windsurf s skill at reproducing observed modes of dune and beach change in both managed and unmanaged beach and dune environments when calibrated using the calibration workflow 2 methods 2 1 study area and field data bogue banks bb is an approximately 40 km long east west oriented developed barrier island along the coast of north carolina fig 1 a the island is located immediately west of a chain of barrier islands that makes up cape lookout national seashore calo bogue banks is home to an estimated 6500 people u s census bureau 2018 and a tourism industry that generates over 350 million in annual revenue carteret county economic development 2018 a robust coastal protection strategy has been enacted on the island which includes the use of beach nourishment carteret county shore protection office 2017 sand fences itzkin et al 2020 and dune grass planting hacker et al 2019 to maintain wide beaches and dunes that are resilient to storm impacts itzkin et al 2020 used lidar data to compare dune development in managed versus unmanaged areas with a focus on the effects of sand fencing and found that natural dune growth has been effectively halted where sand fences are present but that the formation of a fenced dune led to the development of a wider dune system in these locations compared to relatively unmanaged portions of the island i e fort macon state park jay et al in review found that ammophila breviligulata a dune building species commonly planted along bogue banks hacker et al 2019 has led to the formation of taller and wider dunes than those that formed in the presence of the more naturally dominant uniola paniculata to characterize and assess the long term dune and beach dynamics of the area field surveys along bogue banks and cape lookout national seashore were carried out between 2016 and 2020 we used real time kinematic global positioning system rtk gps to collect topographic profiles 1 2 km alongshore spacing of the beach and dune figs 1a and 2 vegetation quadrat surveys were also performed at each profile to quantify the density and diversity of the various dune grass species present on the island s sediment samples were collected at the toe of the dunes to identify the sediment size distribution at each profile location additional details on field survey methods and data can be found in hovenga et al 2019 hacker et al 2019 and jay et al in review here we use the 2016 topographic profiles and vegetation data as input conditions for the windsurf hindcasts described below section 2 2 and the 2017 topographic profiles to assess the accuracy of the hindcasts we downloaded noaa national data buoy center ndbc wind ndbc gauges clkn7 and bftn7 wave waverider buoys 41159 and 41110 and tide data ndbc gauge 8656483 to provide a continuous hourly time series of environmental forcing data for bogue banks throughout the study period fig 1 we back shoaled wave parameters wave height period direction to deep water and then transformed them to the 10 m depth contour using linear wave theory to account for refraction shoaling and differences between the different buoys providing input conditions for the model fig 1b and c 2 2 windsurf windsurf is a coupled beach dune evolution modeling framework developed by cohn et al 2019a this framework couples xbeach hydrodynamics and subaqueous sediment transport e g roelvink et al 2009 the coastal dune model vegetation processes interactions between wind and evolving topography and dune growth e g durán and moore 2013 and aeolis multi fraction aeolian sediment transport e g hoonhout and de vries 2016 to simulate morphodynamic behavior across the entirety of the nearshore beach dune profile windsurf validated for use on dissipative beaches in the pacific northwest by cohn et al 2019a presents challenges for use on intermediate reflective and managed beaches e g those on bogue banks in particular there are additional parameters beyond those calibrated by cohn et al 2019a vegetation friction aeolian transport wave asymmetry and wave skewness that need to be tuned for reflective beaches the wet sediment slope and the bed friction coefficient sanuy 2019 palmsten and splinter 2016 roelvink and costas 2019 demonstrate the importance of the gradient factor parameter in xbeach which can be calibrated to allow for erosion or accretion of the shoreline due to a gradient in alongshore sediment transport in an exploratory paper demonstrating how windsurf can replicate key processes ruggiero et al 2019 show that the vegetation density parameter in cdm is important for stabilizing the dune further aeolis and cdm include several parameters that have yet to be fully explored across a range of different locations a full description of the parameters and calibration values used in our model experiments can be found in table 1 2 2 1 modeling the effect of sand fences with windsurf beach nourishment and the construction of sand fences are common management tools used on bogue banks although segments of the beach along bogue banks has been nourished during our study period carteret county shore protection office 2017 our transects do not show the results of these the effects of nourishment events were not detectable in our profiles we are however able to resolve the topographic effects of sand fencing in our transects which is an ubiquitous management tool for modifying dune evolution on bogue banks itzkin et al 2020 to modify windsurf to simulate the effect of sand fences on dune growth e g cornelis and gabriels 2005 itzkin et al 2020 lima et al 2018 nordstrom and mccluskey 1985 we integrated the wind speed reduction factor wsrf formulation of cohn et al 2019b into windsurf the wsrf is a function of a defined fence height zfence and cross shore location fencex 1 w s r f 0 7 0 013 z f e n c e f e n c e x in the cohn et al 2019b formulation the wsrf is multiplied by the wind velocity at each model time step to apply a linear reduction in wind velocity landward of a sand fence thus forming a fenced dune e g cornelis and gabriels 2005 gillies et al 2017 li and sherman 2015 we applied this formulation in windsurf by first defining the height of the fence 1 m and setting a fence grid that is a vector of values that increase offshore and equals 0 at the fence position values become negative landward of the fence the wsrf formulation eq 1 then returns a vector of values that linearly decreases landward from the fence we manually set wsrf to a value of 1 for locations seaward of the fence so that there is no effect from oncoming wind while windsurf runs the wind velocity output from cdm is multiplied by the cosine of the wind direction to calculate the cross shore wind velocity then cross shore wind velocity is multiplied by the output from the wsrf formulation to create a spatially varying wind velocity vector with values decreasing from the fence landward the wind velocity vector is then passed to aeolis to simulate the effects of the sand fence on sediment transport we note that while here we are specifically modeling the effect of sand fences on this model formulation windsurf could also be applied more broadly to model any management intervention that involves placing an obstacle or roughness object seaward of the dune i e planting of beach grass or deposition of wrack that will then promote the formation of a new dune we use windsurf including the new fenced dune formulation to produce two one year 2016 2017 hindcasts of dune and beach change on bogue banks we selected profiles fig 2 based on a classification of the field profiles fig 1 into morphodynamic groupings based on dune development fig 4a vertical and seaward cross shore growth of the dune face representative of unmanaged profiles bgb22 and fenced dune growth representative of managed profiles bgb15 with respect to changes in the beach 6 profiles experienced beach progradation 10 profiles experienced beach erosion and 6 experienced no change in beach width dunes on prograding beaches mostly experienced vertical growth while the number of profiles on eroding beaches were evenly split with half experiencing vertical dune growth and half experiencing seaward growth of the dune face fig 4c within this work we refer to profiles that include a fenced dune which can form in the vicinity of a sand fence even if one does not directly intersect with the profile as managed and we refer to those without a fenced dune as unmanaged to assess the accuracy of the hindcasts we calculated the root mean squared error rmse between the final model output and the 2017 field profiles as 2 r m s e 1 n i 1 n m o d e l i f i e l d i 2 where n is the number of grid points note that rmse is only calculated from the heel of the natural dune seaward to avoid imposing a penalty due to the backdune area that was manually flattened removed to create the model input to prevent artificial boundary effects we also calculated a dune rmse rmsedune from the heel of the natural dune to the toe of the natural dune or fenced dune if present and beach rmse rmsebeach from the toe of the natural or fenced dune to mhw level to assess how well windsurf can reproduce changes to the dune and beach rmsedune includes both the natural and fenced dunes for the managed profile in addition to rmse we calculated the brier skill score bss for every model run as an additional metric to determine how well the hindcasts performed although it is not included in the calibration workflow described in section 2 2 2 bss measures the ratio of the difference between the final model and field profile to the observed change in the field as 3 b s s 1 z f z m 2 z f z 0 2 where z f is the final field profile z m is the model output and z 0 is the initial field profile bss returns a value inf 1 that is qualitatively classified as poor 0 0 3 fair 0 3 0 6 good 0 6 0 8 or excellent 0 8 1 e g splinter et al 2014 sutherland et al 2004 negative values indicate the initial field profile matches the final field profile more closely than the model output like rmse we also calculate a bssdune and bssbeach for each profile from each hindcast we calculated the dune crest dhigh and dune toe dlow elevation at each time step to train the neural networks ahead of forecasting and to compare model and field results 2 2 2 combined process based modeling and machine learning approach we combined windsurf with a series of machine learning models to improve the accuracy and efficiency of model calibration and to produce forecasts of morphologic change from model output fig 3 this calibration and forecasting workflow applied to the two profiles used in this study fig 2 consists of the following 5 steps 1 a set of calibration simulations conducted with random values for parameterizations allows calculation of a root mean squared error rmse value of the morphologic change across the profile for all tested parameter values 2 an artificial neural network nn1 described in section 2 3 2 trained on the results from step 1 predicts an rmse value of morphological change for a given set of input parameters 3 a genetic algorithm ga1 described in section 2 3 3 runs in conjunction with nn1 to identify a potential best parameterization for the hindcast that minimizes the rmse 4 a genetic algorithm ga2 described in section 2 3 3 runs in conjunction with windsurf starting with the parameters output by nn1 in step 3 to fine tune the calibration parameters and produce the hindcast 5 a neural network nn2 described in section 2 3 2 trained on the hindcast output from step 4 and the associated forcing wind wave and tide conditions produces a 5 year forecast of dune morphology change 2 2 2 emulating windsurf error statistics with neural networks neural networks use a series of artificial neurons to identify complex patterns in data lecun et al 2015 neural networks consist of an input layer that takes in the data one or more hidden layers that transform the data and an output layer that returns a predicted value windsurf rmse in this case neurons in the hidden layer s have associated weights and biases that are set during the training phase where data is propagated and backpropagated through the network to minimize a selected error metric within the network during training mean square error in this case lecun et al 2015 datasets used to train neural networks are split into three sets one each for training testing and validation the training data is used to set the weights and biases of the neurons and the validation data is used to test the accuracy of the network through each epoch of training after training the accuracy of the network is determined by comparing predictions made using input values derived from the testing data with predictions made using the observed values following this general approach we used 60 20 and 20 of our data for training testing and validation respectively and then used two different neural networks to emulate windsurf error statistics the first neural network nn1 used in model calibration predicts the rmse values associated with a given set of input parameters nn1 contains 3 hidden layers with 64 nodes each in between the input layer and the hidden layers are dropout layers each set with a dropout rate of 0 1 randomly set 10 of the input values to 0 to prevent overfitting the network to the training data we trained nn1 on the rmse and 8 input parameters table 1 of an initial set of calibration runs appendix a and achieved an accuracy r2 of 0 80 for both profiles figure a1 we trained a separate version of this network for each hindcast profile nn1 was trained using parameter values and rmse scores from a set of previous windsurf simulations n 1459 for bgb15 and n 1324 for bgb22 that were run using random parameter values and manual calibration we ran additional trainings using smaller subsets of the initial calibration runs appendix b and found that a smaller set of initial simulations 300 may have been able to produce comparable results to those made with the full set figure b1 we also note that using a multi dimensional space filling algorithm i e latin hypercube sampling or maximum dissimilarity algorithm loeppky et al 2009 parker et al 2019 to determine the parameter values for the initial calibration runs may also improve the accuracy of nn1 as well as the predictions generated by ga1 described in section 2 2 3 by more efficiently exploring the parameter space while requiring fewer simulations the second neural network nn2 used after model calibration forecasts dune crest height and dune toe elevation change for each profile nn2 contains a single long short term memory lstm layer with 128 nodes that is trained on the environmental forcing data for the hindcast simulations to predict the desired output morphological variable dhigh or dlow lstm layers contain a memory cell that stores untransformed input values for a given number of time steps set to 48 h in this paper to produce longer and more accurate forecasts lecun et al 2015 after nn2 is trained a 5 year forecast is produced using the full 2016 2020 time series of forcing data we produced an additional 10 forecasts with random gaussian noise normally distributed with a magnitude between 0 05 added to the forcing wind wave and tide data and then used the mean one standard deviation of these 10 forecasts to represent uncertainty bounds for the forecasts we note that the extent of the uncertainty bound is related to the amount of random noise we designed both neural networks in python using tensorflow with keras abadi et al 2015 2 2 3 calibrating windsurf parameters with genetic algorithms genetic algorithms are an optimization method that utilize principles of darwinian evolution i e survival of the fittest reproduction mutation and can be used to identify an ideal set of parameters for model calibration this is achieved by iteratively tuning the model through multiple generations until a global minimum is identified on an error surface of unknown form in this case we selected rmse as an error metric assuming windsurf s error surface is a function of the input parameters such that 4 r m s e w i n d s u r f θ where θ represents a vector of parameter values used in the calibration we ran a genetic algorithm ga1 with a population size of 100 for 100 generations to make predictions on nn1 described in section 2 2 2 to identify a good initial parameterization for the windsurf simulations we ran a second genetic algorithm ga2 seeded with the output from nn1 with a population size of 20 for 20 generations to produce the final calibrated windsurf hindcast ga2 uses a multi objective function optimized on multiple error metrics to optimize rmse rmsedune and rmsebeach we designed both genetic algorithms using distributed evolutionary algorithms in python deap fortin et al 2012 3 results 3 1 hindcasting dune and beach change between 2016 and 2017 overall the bgb22 hindcast fig 5 which is representative of the dune growth modes observed in unmanaged locations performed well achieving a rmse of 0 18 m and a bss of 0 83 excellent the simulation reproduced dune growth reasonably well achieving a modeled δz of 0 08 m compared to an observed δz of 0 18 m 20m cross shore fig 5b the simulation also successfully reproduced the evolution of the beach rmsebeach 0 12 m bssbeach 0 93 despite this windsurf was unable to successfully reproduce the growth of the dune face concurrent with appropriate reproduction of beach behavior a hindcast for bgb15 between 2016 and 2017 demonstrates windsurf s ability to reproduce observed changes on a managed foredune profile fig 6 bgb15 has a sand fence on the profile 10 m seaward of the natural dune which promoted the formation of a fenced dune during the hindcast period while the natural dune did not change rmsedune 0 09 m bssdune 0 34 the hindcast achieved an rmse of 0 23 m and a bss of 0 51 fair vertical accretion of the beach in the field was captured reasonably well by the model rmsebeach 0 25 m bssbeach 0 52 the simulation successfully reproduces growth of the fenced dune and its relationship to the natural dune the fenced dune accreted in the appropriate location while the natural dune behind the fenced dune maintained a constant morphology over the hindcast period a full summary of error metrics for both hindcasts appears in table 2 3 2 forecasting dune morphology from 2016 to 2020 our windsurf dhigh forecasts are consistent within vertical error 0 02 m with the dhigh values measured from the first four years of rtk gps profiles but do not capture the values for the final year fig 7 the dlow forecast for bgb22 fig 8 b is within the error of observed values for the full study period while the dlow forecast for bgb15 fig 8a does not capture any of the observed values beyond the hindcast period the inability of the forecast of bgb15 dlow to predict values beyond the hindcast period is likely due to hurricane florence that resulted in complete erosion of the fenced dune and the beach fig 3b which was not consistent with any condition represented in the forcing data that was used to train the lstm 4 discussion 4 1 complexities in calibrating coupled models the novel hindcasting approach described in this paper using neural networks to emulate windsurf output and genetic algorithms to calibrate the parameter values addresses many of the key limitations of the windsurf coupled model framework complex parametrizations and high computational cost while efficiently producing more accurate results than have been achieved by more standard model calibration procedures neural networks have been used in coastal applications previously to model alongshore transport van maanen et al 2010 sandbar behavior pape et al 2007 and to predict shoreline change montaño et al 2020 genetic algorithms have been used before in coastal applications to predict sand wave and sandbar behavior knaapen and hulscher 2002 2003 sediment settling velocity goldstein and coco 2014 cliff erosion limber et al 2014 dune growth goldstein and moore 2018 and nearshore morphodynamics ruessink 2005 to the authors knowledge the combination of genetic algorithms and neural networks presented here has not yet been explored in a coastal application further the incorporation of the lstm network demonstrates the potential for these models to be used to produce longer projections interannual scale of dune and beach morphology change lstm has been used as part of an ensemble approach to predict three years of shoreline positions in new zealand montaño et al 2020 previous windsurf research has typically focused on calibrating one of the model cores for example calibrating xbeach to replicate storm induced erosion e g dissanayake et al 2014 sanuy and jiménez 2019 simmons et al 2017 2019 splinter and palmsten 2012 vousdoukas et al 2012 de winter et al 2015 calibrating aeolis to replicate evolution of the sand engine hoonhout and de vries 2019 or calibrating cdm to simulate dune evolution along the virginia barrier islands duran vinent and moore 2015 the approach we develop here allows us to calibrate all three models in concert while achieving error scores rmse and bss that are comparable to or better than those achieved in previous studies for each model individually 4 2 unmanaged versus managed dune and beach dynamics data driven approaches i e neural networks genetic algorithms etc do not represent the real world processes driving coastal evolution this can be problematic because hindcasts produced using a neural network and genetic algorithms may achieve a high level of accuracy while using unrealistic parameter values that do not reflect real world conditions in the study area or that are physically unreasonable or are very different for profiles that are in close spatial proximity to each other additionally many of the parameters that must be tuned are difficult to obtain from field observations i e wave symmetry wave skewness aeolian transport coefficient bed friction coefficient and thus there is little guidance available beyond literature review to guide the setting and testing of model parameters here we discuss the calibrated parameter values for the managed and unmanaged profile hindcasts to demonstrate that the machine learning models not only produce high quality hindcasts but that they do so by identifying parameterizations that are consistent with observations in the field on the field profiles for the unmanaged dunes we observe two modes of dune change vertical growth of the dune crest and seaward growth of the dune face and three modes of beach change erosion progradation no change fig 4 between 2016 and 2017 among the different modes of change on unmanaged profiles we find that the most common combination of dune and beach change we observed among the field profiles between 2016 and 2017 is a prograding beach with a vertically growing dune fig 4c we find that once calibrated windsurf can reproduce these changes well the calibrated parameters in xbeach table 1 affect the morphology of the beach most critically our approach identified a strong negative alongshore gradient factor lsgrad 0 1 with highly skewed waves facas 0 662 for bgb22 the highly skewed waves in xbeach allow for a large volume of sediment delivery from the nearshore to the beach that helps reproduce the observed amount of shoreline progradation the relatively high compared to the calibrated value for bgb15 aeolian transport coefficient cb 0 9297 is consistent with the wide beach itzkin et al 2020 and finer sediments observed in the area i e fegley et al 2020 which allows for a reasonable degree of sediment flux to the dune to reproduce the observed levels of vertical dune growth despite this windsurf does not adequately reproduce dune face growth which is observed on seven 36 of our unmanaged profiles dune growth is a function of both aeolian sediment transport modeled by aeolis and vegetation growth modeled by cdm this process which is split over addressed by two of windsurf s model cores suggests a limitation with the model coupling to reproduce the observed growth on the dune face the seaward limit of vegetation line lveg in cdm should dynamically adjust seaward as the dune face accretes capturing more sediment on the dune face in the process however the current version of cdm we used implements a static vegetation line parameterized as the minimum vegetation elevation which is set from the field data therefore so while changing this value might produce a better hindcast of the dune evolution it is not appropriate to make this adjustment given that the minimum vegetation elevation is one of the few parameters that is informed by observed values from the field to reproduce the accurately reproducing observed dune face growth without modifying the vegetation limit we had to required use of a particularly high aeolian transport coefficient which led to unrealistic formation of a d however this leadings to the formation of a new dune developing on the beach as the berm greows above the minimum vegetation elevation and becameomes vegetated in the model this result is which is not realistic consistent with observed changes in the field a future avenue for improvement is incorporation of a newer version of cdm by biel et al in review which includes improved vegetation dynamics and a deterministic a dynamic vegetation line limit that evolves as a function of high water events and vegetation growth and mortality allowing constrains plant colonization to at the appropriate cross shore position preventing inappropriate dune growth the key dynamic represented by the managed profile hindcast bgb15 was the formation of a fenced dune in windsurf the sand fence formulation and calibration procedures described in section 2 2 allow windsurf to accurately reproduce the growth of the fenced dune and the corresponding cessation in vertical growth of the natural dune behind the fenced dune i e itzkin et al 2020 here we find that the genetic algorithm was able to identify a parameterization that not only produces an accurate hindcast but is consistent with conditions in the field the algorithm identifies a low value for the aeolian transport coefficient cb 0 1 table 1 which is consistent with reduced aeolian sediment flux as a result of the narrower and more steeply sloped beach compared to that of bgb22 conversely the calibrated vegetation density startingdensity 1 is much higher on the managed profile compared to the unmanaged profile startingdensity 0 386 this is consistent with visual observations in our study area that suggest vegetation tends to be dense from the face of the fenced dune to the heel of the natural dune in managed areas while vegetation on the dune face tends to be sparser on natural dunes in unmanaged areas the two profiles in this study are co located on the same barrier island bogue banks nc and thus there should be similarities between the parameterizations in the hindcasts given that the profiles are 10 km apart and likely experienced a similar wind and wave climate between 2016 and 2017 the machine learning models developed for each hindcast are independent of each other yet they both identified a similar value for the vegetation friction coefficient m table 1 this is consistent with observations that indicate the dominant dune building vegetation uniola paniculata and dune species composition are relatively consistent along the length of bogue banks hacker et al 2019 both profiles are calibrated with a low value for wave asymmetry facas table 1 which is one of the two key parameters describing wave driven onshore sediment transport along with facsk because bogue banks is a concave island shoreline orientation changes alongshore fig 1 and therefore so do the relative angles between the waves and wind with the beach and dunes even though both simulations are being forced with the same input conditions this necessitates different wind and wave parameters table 1 for the different profiles rather than one set of calibration values for both profiles to better explain the subsequent changes in morphology in these locations e g hage et al 2018 2020 sanuy and jiménez 2019 sediment size and distribution at numerous locations across the profile are additional parameters that could be measured in the field and included in the model potentially further improving the accuracy of hindcasts the comparison of parameter values identified by the machine learning models used for calibrating the hindcasts with observed conditions in the field demonstrates that the different data driven approaches can help windsurf better represent the physics involved in driving evolution of the hindcast profiles the importance of this is three fold first while manual calibration approaches also involve adjusting parameters to match field conditions this will ultimately be limited by an inability to account for the complex interactions between parameter values machine learning models are uniquely suited to identify those interactions second while a common critique of machine learning models is that they are a black box the approach here allows us to affirm the decisions made by the machine learning models by comparing them to observations of morphology sediments vegetation and wind wave processes third as we move from producing a hindcast to forecasting changes to the profile described below it is important to ensure that windsurf accurately represents the physics driving evolution of the profile there are an infinite number of potential paths the profile can take in the hindcast however we can only evaluate the hindcast by comparing the initial and final timesteps when observations are available the forecast predictions are derived from how the hindcast evolved at each timestep a physically reasonable parameterization suggests that the intermediate profile evolution is acceptable and provides added confidence in the quality of the forecast 4 3 forecasts the neural network forecasting model with a lstm layer predicts dune morphometric changes reasonably well for both profiles when changes are relatively modest however the model s capability to produce an accurate forecast for the fenced profile is limited by the conditions present in the hindcasting training period because the lstm is not able to sufficiently predict changes that occur during out of sample forcing conditions for example the fenced dune was completely eroded along with much of the beach following hurricane florence in 2018 fig 3b and the lstm was not able to capture this significant erosion fig 8a despite the inclusion of the storm in the wind and wave time series used to make the forecast fig 1b this could potentially be due to the location of the tide gauge within bogue sound fig 1a which may be different than the storm surge at the profile locations however it is widely acknowledged that machine learning methods i e lstm do not adequately extrapolate with out of sample instances beuzen et al 2019 hurricane florence was the most extreme out of sample instance during the forecasting period 2017 2020 evidenced by the degree of observed change to the profile during this time 2017 2018 fig 3b the lstm model is trained on the output from windsurf and thus is limited by the accuracy of the windsurf hindcast and the types of events i e erosional or accretional included in the windsurf hindcast because our windsurf hindcast did not include a significant storm event the lstm model did not necessarily learn how to handle an event of the magnitude of hurricane florence when the neural network was being trained this limitation could be addressed by adjusting the surveying frequency and hindcast period to capture both dune erosion and recovery and by analyzing the accuracy of the hindcast at multiple time periods instead of only at the endpoint a longer hindcast could also address this issue if sufficient computational power is available computational cost currently limits simulations to one year hindcasts while we could run a hindcast for the 2017 2018 period erosion from hurricane florence or for the 2018 2019 period recovery from hurricane florence these might both invoke the same limitation of significant out of sample dune evolution either erosion or recovery depending on the chosen one year period for the hindcast improving forecasts by evaluating windsurf over a hindcast period with multiple observations including erosion and recovery is the subject of ongoing research itzkin et al 2021 but is beyond the scope of this manuscript despite these limitations lstm reproduces the differences in growth rates between natural dunes in managed and unmanaged locations figs 7 and 8 in summary lstm reproduces observed variability in dune growth and erosion for both the managed and unmanaged dunes in addition to the overall change through time the forecast range for the managed profile figs 7a and 8a is narrow consistent with the expectation that the fenced dune will prevent growth and erosion of the natural dune the variability in the forecast over time for the unmanaged profile computed via 10 simulations figs 7b and 8b is larger than for the managed profile and increases over time this is consistent with the natural dune being more exposed to wind and waves and thus being more affected by the differences in forcing between the different ensemble forecasts used to produce the forecast range lstm forecasts may be useful in the production of storm impact assessments which are useful tools for assisting coastal managers in understanding how a given location is likely to be impacted by an oncoming storm e g stockdon et al 2012 storm impact assessments depend on accurate inputs for pre storm morphology which is often outdated and not representative of actual pre storm morphology straub et al 2020 lstm provides a quick and accurate means to extend windsurf projections further into the future with less computational demand to potentially allow for the generation of updated pre storm dune morphology which could improve the accuracy of storm impact assessments 5 conclusions while coupled process based models e g windsurf have the potential to greatly improve our understanding of how dunes and beaches evolve through time their application may be limited by an extensive set of tunable parameters nonlinear interactions between the parameters and computational demands that control the duration and quantity of simulations that can be performed conversely machine learning models e g neural networks genetic algorithms can identify complex relationships in data and make efficient predictions however these data driven approaches may not necessarily represent the physics of real world systems here we present a novel and powerful workflow that combines coupled processed based modeling and two types of machine learning algorithms to leverage their respective strengths the combination of a neural network and genetic algorithm nn1 ga1 allows for thousands of parameter combinations to be evaluated on the order of minutes without having to run windsurf except for seaward dune face growth our hindcasts successfully reproduced observed morphological changes including vertical and fenced dune growth as well as shoreline progradation and beach accretion along bogue banks north carolina the lstm model increases the utility of windsurf by producing accurate forecasts of dune morphology beyond the annual timescale simulated previously this approach allows for the generation of accurate hindcasts and promising forecasts of dune and beach evolution on managed and unmanaged barriers at interannual scale software data availability windsurf is freely available at github ncohn windsurf matlab based coupler to simulate the co evolution of the coastal zone to both winds and waves using xbeach the coastal dune model and aeolis machine learning hindcasting and forecasting code is freely available at micitz windsurf ml calibrate windsurf and produce forecasts github com data is available at zenodo https doi org 10 5281 zenodo 5550354 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we thank an anonymous reviewer and rangely c mickey for their insightful comments and feedback which have improved this manuscript we also thank evan b goldstein for his assistance to m itzkin and feedback on the machine learning methods implemented in this study this work was funded by the us national oceanic and atmospheric association noaa via the nos nccos crp 360 ecological effects of sea level rise program grant no na15nos4780172 to p r s d h and l j m as well as the preston jones and mary elizabeth frances dean martin fellowship fund and by the virginia coast reserve long term ecological research program national science foundation deb 1832221 via a subaward to the university of north carolina at chapel hill any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government appendix a neural network and genetic algorithm calibration accuracy we trained the first neural network nn1 on the rmse using an initial set of calibration runs the training for nn1 ran for 200 epochs with a batch size of 100 the training and validation loss plots figure a 1a d show that the training loss is minimized after 75 epochs for bgb15 and 125 epochs for bgb22 suggesting that this training step could be run for fewer epochs and still achieve a high degree of accuracy ga1 runs for 100 generations with a population size of 100 a crossover probability of 40 and a mutation probability of 20 ga1 identified an optimal parameterization for both profiles after 30 generations figure a 1c f and could thus likely be run for a much shorter amount of time and still identify a reasonable parameterization the total training and optimizing time from the start of nn1 to the final generation of ga1 was 3 1 min each for bgb15 and bgb22 on a pc with a 3 50 ghz intel xeon processor with 64 gb of ram fig a 1 machine learning training accuracy for nn1 a b d e and ga1 c f the top row shows the training accuracy for bgb15 and the bottom row shows the training accuracy for bgb22 the training blue and validation red loss versus each neural network training epoch is shown in the left column a d the observed windsurf versus predicted values from the trained neural network are shown in the middle column b e note that the r2 value in each subplot is calculated using only the testing data red points the right column c f shows the rmse values versus each training generation for the genetic algorithm the dashed line in these subplots shows the lowest rmse value predicted by the genetic algorithm fig a 1 appendix b determining number of calibration instances needed to train nn1 and ga1 we ran additional trainings using smaller subsets of the initial calibration runs to train the first neural network nn1 and the genetic algorithm ga1 we ran a total of 1760 and 1331 manual calibration instances for bgb15 and bgb22 respectively to prevent nn1 and ga1 from identifying any parameterizations that were known to have produced particularly incorrect or incomplete simulations any manual calibration instance that produced a rmse greater than 2 0 m was removed from the training dataset this left a total of 1459 samples for bgb15 and 1324 for bgb22 that were used to train nn1 and run ga1 fig 3 steps 2 and 3 given that the calibration workflow developed for this manuscript came from these initial runs we did not initially consider the number of manual calibrations that might need to be run to produce a good parameter prediction from ga1 here we run nn1 and ga1 using an increasingly larger number of calibration instances which have been randomly sampled from the larger calibration dataset fig 3 step 1 for both profiles we run this analysis with up to n 1300 training instances with a step size of 50 repeating each training step 9 times to account for differences in training accuracy arising from the random sampling here we find that using a smaller number of calibration instances to train nn1 and optimize on ga1 produced a better potential parameterization prediction than those made using a larger number of calibration simulations figure b 1a this trend is less clear for bgb22 than bgb15 which has a relatively consistent best rmse prediction for all training sizes figure b 1a despite this the predictive power of nn1 is much lower when trained with a smaller number of calibration instances figure b 1b this suggests that nn1 may be overfitting to the calibration instances when the number of samples is low taken together it is not clear how many initial calibration samples should be run to generate a good prediction from nn1 and ga1 however our results here suggest that 300 initial calibration simulations may be enough to train nn1 to accurately predict the observed values and allow ga1 to identify an acceptable starting parameterization the number of initial runs could likely be reduced by using an efficient space filling algorithm i e latin hypercube sampling maximum dissimilarity algorithm to explore the parameter space more fully during this step rather than using random parameter values fig b 1 boxplots showing a the best lowest rmse value predicted by ga1 for each profile and b the r2 value for the observed v predicted values generated by nn1 for a training run using n calibration instances from 50 to 1300 fig b 1 
25586,producing accurate hindcasts and forecasts with coupled models is challenging due to complex parameterizations that are difficult to ground in observational data we present a calibration workflow that utilizes a series of machine learning algorithms paired with windsurf a coupled beach dune model aeolis the coastal dune model and xbeach to produce hindcasts and forecasts of morphologic change along bogue banks north carolina neural networks paired with genetic algorithms allow us to fine tune calibration parameters for the hindcast and then a long short term memory neural network trained on the hindcast produces a 4 year forecast we compare our hindcasts to observations from 2016 to 2017 and find they successfully reproduce observed modes of dune and beach change except for seaward growth of the dune face we compare our forecasts to observations from 2016 to 2020 and find that they produce reasonably accurate predictions of dune change except when there are significant instances of erosion during the forecast period keywords beach dune processes erosion neural network genetic algorithm windsurf forecast 1 introduction understanding foredune growth and erosion is critical for predicting how sandy coastal systems will likely respond over time to sea level rise e g passeri et al 2020 2021 duran vinent and moore 2015 and possible changes in the intensity of storms e g knutson et al 2010 coastal dunes form naturally through biophysical feedbacks between aeolian sediment transport and vegetation growth e g baas and nield 2007 biel et al 2019 davidson arnott et al 2012 durán and moore 2013 hacker et al 2012 2019 p hesp 2002 luna et al 2012 ruggiero et al 2019 zarnetske et al 2015 2012 as well as marine driven sediment transport cohn et al 2019a sufficiently strong winds entrain sand and transport it across the beach toward the dune where turbulence induced from interactions between the wind and vegetation cause the shear stress acting on the grains to drop below the critical threshold for transport resulting in deposition durán and moore 2013 dune grasses are stimulated by sand burial causing them to grow and accrete more sand e g brown and zinnert 2018 hacker et al 2012 2019 harris et al 2017 maun 1998 seneca 1972 zarnetske et al 2012 2015 ultimately promoting the formation of a vegetated foredune located at the seaward most position where vegetation can survive biel et al 2019 hesp 2002 maun 1998 management efforts such as sand fence construction and dune grass planting often carried out in combination promote the formation of artificially constructed dunes that limit the impact of erosion and flooding on infrastructure landward of the dune e g anthony 2013 charbonneau and wnek 2016 grafals soto and nordstrom 2009 itzkin et al 2020 mendelssohn et al 1991 miller et al 2001 conversely dunes are eroded during storms when the water level is sufficiently high to impact dunes directly e g long et al 2014 roelvink et al 2009 sallenger 2000 seabloom et al 2013 stockdon et al 2006 wave runup is proportional to beach slope with steeper beaches experiencing greater runup than shallower beaches for an equivalent wave climate e g battjes 1974 ruggiero et al 2001 stockdon et al 2006 beach slope changes frequently and significantly e g straub et al 2020 theuerkauf and rodriguez 2014 given the myriad of processes that contribute to long term evolution of beaches and dunes modeling coastal evolution over annual to decadal time scales requires consideration of both aeolian and hydrodynamic processes that span the coastal zone from the nearshore to the backshore moore et al 2016 additional considerations must also be made when modeling change along a developed shoreline that has been extensively modified through various management interventions and thus evolves differently than undeveloped coastlines which are governed by natural processes e g mcnamara and lazarus 2018 windsurf cohn et al 2019a couples xbeach roelvink et al 2009 the coastal dune model cdm duran and moore 2013 and aeolis hoonhout and de vries 2016 to simulate hydrodynamic processes multi fraction aeolian sediment transport and feedbacks between vegetation growth and sediment transport windsurf s modular framework allows for the incorporation of additional processes including management initiatives such as sand fences making it well suited for modeling dune and beach behavior on managed coastlines though windsurf allows investigation of coupled beach and dune evolution careful calibration of model parameters must be undertaken to ensure reasonable behavior and predictions calibration of an individual model is a rigorous task e g goldstein and moore 2018 palmsten and holman 2012 simmons et al 2017 splinter and palmsten 2012 vousdoukas et al 2012 and the calibration process for a coupled model such as windsurf is made more difficult by the extensive set of tunable parameters within each model core i e xbeach cdm aeolis nonlinear interactions between parameters within and across the individual model cores further complicates calibration for these reasons one at a time or manual calibration methods and sensitivity tests are not necessarily optimal for identifying a reasonable solution cohn et al 2019a calibrated windsurf using 100 simulations with a random sample of parameters on a high energy dissipative beach in the us pacific northwest however there are additional parameters to tune when modeling a reflective beach roelvink et al 2018 sanuy and jiménez 2019 vousdoukas et al 2011 2012 that makes this random calibration approach computationally expensive due to the need for running a prohibitively large number of simulations a potential avenue for calibrating windsurf efficiently involves the use of data driven techniques some of which have been previously employed on the individual model cores contained within the windsurf coupling previous studies have demonstrated success in calibrating cdm goldstein and moore 2018 and xbeach simmons et al 2017 2019 using automated methods to estimate parameter values simmons et al 2017 identified a set of parameter values for an xbeach simulation of storm erosion in emilia romagna italy using a monte carlo based method that sought to optimize a generalized likelihood metric however the number of calibration simulations required n 15 000 in the paper is prohibitively large for use with windsurf an alternative calibration approach which required a smaller number of simulations is presented by goldstein and moore 2018 who describe a workflow for calibrating cdm that utilizes a genetic algorithm ultimately a calibration method is needed that can quickly converge on a set of optimized parameter values to overcome windsurf s substantial runtime approx 1 5 days on the unc longleaf supercomputer for a one year simulation and nonlinear interactions between model parameters through the development of a calibration workflow that utilizes data driven approaches we allow windsurf to effectively and efficiently auto calibrate n 1 500 simulations without requiring any manual calibration we also note that although while this calibration workflow is specifically applied here to the coastal model windsurf in this paper it could be used more generally to calibrate any environmental model that contains parameters that aren t able to be set from observational data model calibration can be a time consuming process and by utilizing machine learning methods to allow the model to tune itself the researcher can then spend more time on analyzing results and testing hypotheses with their model here we use windsurf to produce a one year hindcast of both a managed and an unmanaged foredune profile sampled from the outer banks of north carolina usa we then use the output from the hindcasts to produce 5 year predictions of changes in foredune morphology the windsurf simulations are paired with a series of neural networks and genetic algorithms described in section 2 2 to enhance the accuracy and efficiency of the hindcasts and to extend predictions of morphologic change beyond the hindcast period hereafter referred to as forecasts the aims of this research are two fold first we demonstrate a potential calibration workflow that can alleviate the challenges of calibrating a complex coupled model by combining process based and machine learning models second we test windsurf s skill at reproducing observed modes of dune and beach change in both managed and unmanaged beach and dune environments when calibrated using the calibration workflow 2 methods 2 1 study area and field data bogue banks bb is an approximately 40 km long east west oriented developed barrier island along the coast of north carolina fig 1 a the island is located immediately west of a chain of barrier islands that makes up cape lookout national seashore calo bogue banks is home to an estimated 6500 people u s census bureau 2018 and a tourism industry that generates over 350 million in annual revenue carteret county economic development 2018 a robust coastal protection strategy has been enacted on the island which includes the use of beach nourishment carteret county shore protection office 2017 sand fences itzkin et al 2020 and dune grass planting hacker et al 2019 to maintain wide beaches and dunes that are resilient to storm impacts itzkin et al 2020 used lidar data to compare dune development in managed versus unmanaged areas with a focus on the effects of sand fencing and found that natural dune growth has been effectively halted where sand fences are present but that the formation of a fenced dune led to the development of a wider dune system in these locations compared to relatively unmanaged portions of the island i e fort macon state park jay et al in review found that ammophila breviligulata a dune building species commonly planted along bogue banks hacker et al 2019 has led to the formation of taller and wider dunes than those that formed in the presence of the more naturally dominant uniola paniculata to characterize and assess the long term dune and beach dynamics of the area field surveys along bogue banks and cape lookout national seashore were carried out between 2016 and 2020 we used real time kinematic global positioning system rtk gps to collect topographic profiles 1 2 km alongshore spacing of the beach and dune figs 1a and 2 vegetation quadrat surveys were also performed at each profile to quantify the density and diversity of the various dune grass species present on the island s sediment samples were collected at the toe of the dunes to identify the sediment size distribution at each profile location additional details on field survey methods and data can be found in hovenga et al 2019 hacker et al 2019 and jay et al in review here we use the 2016 topographic profiles and vegetation data as input conditions for the windsurf hindcasts described below section 2 2 and the 2017 topographic profiles to assess the accuracy of the hindcasts we downloaded noaa national data buoy center ndbc wind ndbc gauges clkn7 and bftn7 wave waverider buoys 41159 and 41110 and tide data ndbc gauge 8656483 to provide a continuous hourly time series of environmental forcing data for bogue banks throughout the study period fig 1 we back shoaled wave parameters wave height period direction to deep water and then transformed them to the 10 m depth contour using linear wave theory to account for refraction shoaling and differences between the different buoys providing input conditions for the model fig 1b and c 2 2 windsurf windsurf is a coupled beach dune evolution modeling framework developed by cohn et al 2019a this framework couples xbeach hydrodynamics and subaqueous sediment transport e g roelvink et al 2009 the coastal dune model vegetation processes interactions between wind and evolving topography and dune growth e g durán and moore 2013 and aeolis multi fraction aeolian sediment transport e g hoonhout and de vries 2016 to simulate morphodynamic behavior across the entirety of the nearshore beach dune profile windsurf validated for use on dissipative beaches in the pacific northwest by cohn et al 2019a presents challenges for use on intermediate reflective and managed beaches e g those on bogue banks in particular there are additional parameters beyond those calibrated by cohn et al 2019a vegetation friction aeolian transport wave asymmetry and wave skewness that need to be tuned for reflective beaches the wet sediment slope and the bed friction coefficient sanuy 2019 palmsten and splinter 2016 roelvink and costas 2019 demonstrate the importance of the gradient factor parameter in xbeach which can be calibrated to allow for erosion or accretion of the shoreline due to a gradient in alongshore sediment transport in an exploratory paper demonstrating how windsurf can replicate key processes ruggiero et al 2019 show that the vegetation density parameter in cdm is important for stabilizing the dune further aeolis and cdm include several parameters that have yet to be fully explored across a range of different locations a full description of the parameters and calibration values used in our model experiments can be found in table 1 2 2 1 modeling the effect of sand fences with windsurf beach nourishment and the construction of sand fences are common management tools used on bogue banks although segments of the beach along bogue banks has been nourished during our study period carteret county shore protection office 2017 our transects do not show the results of these the effects of nourishment events were not detectable in our profiles we are however able to resolve the topographic effects of sand fencing in our transects which is an ubiquitous management tool for modifying dune evolution on bogue banks itzkin et al 2020 to modify windsurf to simulate the effect of sand fences on dune growth e g cornelis and gabriels 2005 itzkin et al 2020 lima et al 2018 nordstrom and mccluskey 1985 we integrated the wind speed reduction factor wsrf formulation of cohn et al 2019b into windsurf the wsrf is a function of a defined fence height zfence and cross shore location fencex 1 w s r f 0 7 0 013 z f e n c e f e n c e x in the cohn et al 2019b formulation the wsrf is multiplied by the wind velocity at each model time step to apply a linear reduction in wind velocity landward of a sand fence thus forming a fenced dune e g cornelis and gabriels 2005 gillies et al 2017 li and sherman 2015 we applied this formulation in windsurf by first defining the height of the fence 1 m and setting a fence grid that is a vector of values that increase offshore and equals 0 at the fence position values become negative landward of the fence the wsrf formulation eq 1 then returns a vector of values that linearly decreases landward from the fence we manually set wsrf to a value of 1 for locations seaward of the fence so that there is no effect from oncoming wind while windsurf runs the wind velocity output from cdm is multiplied by the cosine of the wind direction to calculate the cross shore wind velocity then cross shore wind velocity is multiplied by the output from the wsrf formulation to create a spatially varying wind velocity vector with values decreasing from the fence landward the wind velocity vector is then passed to aeolis to simulate the effects of the sand fence on sediment transport we note that while here we are specifically modeling the effect of sand fences on this model formulation windsurf could also be applied more broadly to model any management intervention that involves placing an obstacle or roughness object seaward of the dune i e planting of beach grass or deposition of wrack that will then promote the formation of a new dune we use windsurf including the new fenced dune formulation to produce two one year 2016 2017 hindcasts of dune and beach change on bogue banks we selected profiles fig 2 based on a classification of the field profiles fig 1 into morphodynamic groupings based on dune development fig 4a vertical and seaward cross shore growth of the dune face representative of unmanaged profiles bgb22 and fenced dune growth representative of managed profiles bgb15 with respect to changes in the beach 6 profiles experienced beach progradation 10 profiles experienced beach erosion and 6 experienced no change in beach width dunes on prograding beaches mostly experienced vertical growth while the number of profiles on eroding beaches were evenly split with half experiencing vertical dune growth and half experiencing seaward growth of the dune face fig 4c within this work we refer to profiles that include a fenced dune which can form in the vicinity of a sand fence even if one does not directly intersect with the profile as managed and we refer to those without a fenced dune as unmanaged to assess the accuracy of the hindcasts we calculated the root mean squared error rmse between the final model output and the 2017 field profiles as 2 r m s e 1 n i 1 n m o d e l i f i e l d i 2 where n is the number of grid points note that rmse is only calculated from the heel of the natural dune seaward to avoid imposing a penalty due to the backdune area that was manually flattened removed to create the model input to prevent artificial boundary effects we also calculated a dune rmse rmsedune from the heel of the natural dune to the toe of the natural dune or fenced dune if present and beach rmse rmsebeach from the toe of the natural or fenced dune to mhw level to assess how well windsurf can reproduce changes to the dune and beach rmsedune includes both the natural and fenced dunes for the managed profile in addition to rmse we calculated the brier skill score bss for every model run as an additional metric to determine how well the hindcasts performed although it is not included in the calibration workflow described in section 2 2 2 bss measures the ratio of the difference between the final model and field profile to the observed change in the field as 3 b s s 1 z f z m 2 z f z 0 2 where z f is the final field profile z m is the model output and z 0 is the initial field profile bss returns a value inf 1 that is qualitatively classified as poor 0 0 3 fair 0 3 0 6 good 0 6 0 8 or excellent 0 8 1 e g splinter et al 2014 sutherland et al 2004 negative values indicate the initial field profile matches the final field profile more closely than the model output like rmse we also calculate a bssdune and bssbeach for each profile from each hindcast we calculated the dune crest dhigh and dune toe dlow elevation at each time step to train the neural networks ahead of forecasting and to compare model and field results 2 2 2 combined process based modeling and machine learning approach we combined windsurf with a series of machine learning models to improve the accuracy and efficiency of model calibration and to produce forecasts of morphologic change from model output fig 3 this calibration and forecasting workflow applied to the two profiles used in this study fig 2 consists of the following 5 steps 1 a set of calibration simulations conducted with random values for parameterizations allows calculation of a root mean squared error rmse value of the morphologic change across the profile for all tested parameter values 2 an artificial neural network nn1 described in section 2 3 2 trained on the results from step 1 predicts an rmse value of morphological change for a given set of input parameters 3 a genetic algorithm ga1 described in section 2 3 3 runs in conjunction with nn1 to identify a potential best parameterization for the hindcast that minimizes the rmse 4 a genetic algorithm ga2 described in section 2 3 3 runs in conjunction with windsurf starting with the parameters output by nn1 in step 3 to fine tune the calibration parameters and produce the hindcast 5 a neural network nn2 described in section 2 3 2 trained on the hindcast output from step 4 and the associated forcing wind wave and tide conditions produces a 5 year forecast of dune morphology change 2 2 2 emulating windsurf error statistics with neural networks neural networks use a series of artificial neurons to identify complex patterns in data lecun et al 2015 neural networks consist of an input layer that takes in the data one or more hidden layers that transform the data and an output layer that returns a predicted value windsurf rmse in this case neurons in the hidden layer s have associated weights and biases that are set during the training phase where data is propagated and backpropagated through the network to minimize a selected error metric within the network during training mean square error in this case lecun et al 2015 datasets used to train neural networks are split into three sets one each for training testing and validation the training data is used to set the weights and biases of the neurons and the validation data is used to test the accuracy of the network through each epoch of training after training the accuracy of the network is determined by comparing predictions made using input values derived from the testing data with predictions made using the observed values following this general approach we used 60 20 and 20 of our data for training testing and validation respectively and then used two different neural networks to emulate windsurf error statistics the first neural network nn1 used in model calibration predicts the rmse values associated with a given set of input parameters nn1 contains 3 hidden layers with 64 nodes each in between the input layer and the hidden layers are dropout layers each set with a dropout rate of 0 1 randomly set 10 of the input values to 0 to prevent overfitting the network to the training data we trained nn1 on the rmse and 8 input parameters table 1 of an initial set of calibration runs appendix a and achieved an accuracy r2 of 0 80 for both profiles figure a1 we trained a separate version of this network for each hindcast profile nn1 was trained using parameter values and rmse scores from a set of previous windsurf simulations n 1459 for bgb15 and n 1324 for bgb22 that were run using random parameter values and manual calibration we ran additional trainings using smaller subsets of the initial calibration runs appendix b and found that a smaller set of initial simulations 300 may have been able to produce comparable results to those made with the full set figure b1 we also note that using a multi dimensional space filling algorithm i e latin hypercube sampling or maximum dissimilarity algorithm loeppky et al 2009 parker et al 2019 to determine the parameter values for the initial calibration runs may also improve the accuracy of nn1 as well as the predictions generated by ga1 described in section 2 2 3 by more efficiently exploring the parameter space while requiring fewer simulations the second neural network nn2 used after model calibration forecasts dune crest height and dune toe elevation change for each profile nn2 contains a single long short term memory lstm layer with 128 nodes that is trained on the environmental forcing data for the hindcast simulations to predict the desired output morphological variable dhigh or dlow lstm layers contain a memory cell that stores untransformed input values for a given number of time steps set to 48 h in this paper to produce longer and more accurate forecasts lecun et al 2015 after nn2 is trained a 5 year forecast is produced using the full 2016 2020 time series of forcing data we produced an additional 10 forecasts with random gaussian noise normally distributed with a magnitude between 0 05 added to the forcing wind wave and tide data and then used the mean one standard deviation of these 10 forecasts to represent uncertainty bounds for the forecasts we note that the extent of the uncertainty bound is related to the amount of random noise we designed both neural networks in python using tensorflow with keras abadi et al 2015 2 2 3 calibrating windsurf parameters with genetic algorithms genetic algorithms are an optimization method that utilize principles of darwinian evolution i e survival of the fittest reproduction mutation and can be used to identify an ideal set of parameters for model calibration this is achieved by iteratively tuning the model through multiple generations until a global minimum is identified on an error surface of unknown form in this case we selected rmse as an error metric assuming windsurf s error surface is a function of the input parameters such that 4 r m s e w i n d s u r f θ where θ represents a vector of parameter values used in the calibration we ran a genetic algorithm ga1 with a population size of 100 for 100 generations to make predictions on nn1 described in section 2 2 2 to identify a good initial parameterization for the windsurf simulations we ran a second genetic algorithm ga2 seeded with the output from nn1 with a population size of 20 for 20 generations to produce the final calibrated windsurf hindcast ga2 uses a multi objective function optimized on multiple error metrics to optimize rmse rmsedune and rmsebeach we designed both genetic algorithms using distributed evolutionary algorithms in python deap fortin et al 2012 3 results 3 1 hindcasting dune and beach change between 2016 and 2017 overall the bgb22 hindcast fig 5 which is representative of the dune growth modes observed in unmanaged locations performed well achieving a rmse of 0 18 m and a bss of 0 83 excellent the simulation reproduced dune growth reasonably well achieving a modeled δz of 0 08 m compared to an observed δz of 0 18 m 20m cross shore fig 5b the simulation also successfully reproduced the evolution of the beach rmsebeach 0 12 m bssbeach 0 93 despite this windsurf was unable to successfully reproduce the growth of the dune face concurrent with appropriate reproduction of beach behavior a hindcast for bgb15 between 2016 and 2017 demonstrates windsurf s ability to reproduce observed changes on a managed foredune profile fig 6 bgb15 has a sand fence on the profile 10 m seaward of the natural dune which promoted the formation of a fenced dune during the hindcast period while the natural dune did not change rmsedune 0 09 m bssdune 0 34 the hindcast achieved an rmse of 0 23 m and a bss of 0 51 fair vertical accretion of the beach in the field was captured reasonably well by the model rmsebeach 0 25 m bssbeach 0 52 the simulation successfully reproduces growth of the fenced dune and its relationship to the natural dune the fenced dune accreted in the appropriate location while the natural dune behind the fenced dune maintained a constant morphology over the hindcast period a full summary of error metrics for both hindcasts appears in table 2 3 2 forecasting dune morphology from 2016 to 2020 our windsurf dhigh forecasts are consistent within vertical error 0 02 m with the dhigh values measured from the first four years of rtk gps profiles but do not capture the values for the final year fig 7 the dlow forecast for bgb22 fig 8 b is within the error of observed values for the full study period while the dlow forecast for bgb15 fig 8a does not capture any of the observed values beyond the hindcast period the inability of the forecast of bgb15 dlow to predict values beyond the hindcast period is likely due to hurricane florence that resulted in complete erosion of the fenced dune and the beach fig 3b which was not consistent with any condition represented in the forcing data that was used to train the lstm 4 discussion 4 1 complexities in calibrating coupled models the novel hindcasting approach described in this paper using neural networks to emulate windsurf output and genetic algorithms to calibrate the parameter values addresses many of the key limitations of the windsurf coupled model framework complex parametrizations and high computational cost while efficiently producing more accurate results than have been achieved by more standard model calibration procedures neural networks have been used in coastal applications previously to model alongshore transport van maanen et al 2010 sandbar behavior pape et al 2007 and to predict shoreline change montaño et al 2020 genetic algorithms have been used before in coastal applications to predict sand wave and sandbar behavior knaapen and hulscher 2002 2003 sediment settling velocity goldstein and coco 2014 cliff erosion limber et al 2014 dune growth goldstein and moore 2018 and nearshore morphodynamics ruessink 2005 to the authors knowledge the combination of genetic algorithms and neural networks presented here has not yet been explored in a coastal application further the incorporation of the lstm network demonstrates the potential for these models to be used to produce longer projections interannual scale of dune and beach morphology change lstm has been used as part of an ensemble approach to predict three years of shoreline positions in new zealand montaño et al 2020 previous windsurf research has typically focused on calibrating one of the model cores for example calibrating xbeach to replicate storm induced erosion e g dissanayake et al 2014 sanuy and jiménez 2019 simmons et al 2017 2019 splinter and palmsten 2012 vousdoukas et al 2012 de winter et al 2015 calibrating aeolis to replicate evolution of the sand engine hoonhout and de vries 2019 or calibrating cdm to simulate dune evolution along the virginia barrier islands duran vinent and moore 2015 the approach we develop here allows us to calibrate all three models in concert while achieving error scores rmse and bss that are comparable to or better than those achieved in previous studies for each model individually 4 2 unmanaged versus managed dune and beach dynamics data driven approaches i e neural networks genetic algorithms etc do not represent the real world processes driving coastal evolution this can be problematic because hindcasts produced using a neural network and genetic algorithms may achieve a high level of accuracy while using unrealistic parameter values that do not reflect real world conditions in the study area or that are physically unreasonable or are very different for profiles that are in close spatial proximity to each other additionally many of the parameters that must be tuned are difficult to obtain from field observations i e wave symmetry wave skewness aeolian transport coefficient bed friction coefficient and thus there is little guidance available beyond literature review to guide the setting and testing of model parameters here we discuss the calibrated parameter values for the managed and unmanaged profile hindcasts to demonstrate that the machine learning models not only produce high quality hindcasts but that they do so by identifying parameterizations that are consistent with observations in the field on the field profiles for the unmanaged dunes we observe two modes of dune change vertical growth of the dune crest and seaward growth of the dune face and three modes of beach change erosion progradation no change fig 4 between 2016 and 2017 among the different modes of change on unmanaged profiles we find that the most common combination of dune and beach change we observed among the field profiles between 2016 and 2017 is a prograding beach with a vertically growing dune fig 4c we find that once calibrated windsurf can reproduce these changes well the calibrated parameters in xbeach table 1 affect the morphology of the beach most critically our approach identified a strong negative alongshore gradient factor lsgrad 0 1 with highly skewed waves facas 0 662 for bgb22 the highly skewed waves in xbeach allow for a large volume of sediment delivery from the nearshore to the beach that helps reproduce the observed amount of shoreline progradation the relatively high compared to the calibrated value for bgb15 aeolian transport coefficient cb 0 9297 is consistent with the wide beach itzkin et al 2020 and finer sediments observed in the area i e fegley et al 2020 which allows for a reasonable degree of sediment flux to the dune to reproduce the observed levels of vertical dune growth despite this windsurf does not adequately reproduce dune face growth which is observed on seven 36 of our unmanaged profiles dune growth is a function of both aeolian sediment transport modeled by aeolis and vegetation growth modeled by cdm this process which is split over addressed by two of windsurf s model cores suggests a limitation with the model coupling to reproduce the observed growth on the dune face the seaward limit of vegetation line lveg in cdm should dynamically adjust seaward as the dune face accretes capturing more sediment on the dune face in the process however the current version of cdm we used implements a static vegetation line parameterized as the minimum vegetation elevation which is set from the field data therefore so while changing this value might produce a better hindcast of the dune evolution it is not appropriate to make this adjustment given that the minimum vegetation elevation is one of the few parameters that is informed by observed values from the field to reproduce the accurately reproducing observed dune face growth without modifying the vegetation limit we had to required use of a particularly high aeolian transport coefficient which led to unrealistic formation of a d however this leadings to the formation of a new dune developing on the beach as the berm greows above the minimum vegetation elevation and becameomes vegetated in the model this result is which is not realistic consistent with observed changes in the field a future avenue for improvement is incorporation of a newer version of cdm by biel et al in review which includes improved vegetation dynamics and a deterministic a dynamic vegetation line limit that evolves as a function of high water events and vegetation growth and mortality allowing constrains plant colonization to at the appropriate cross shore position preventing inappropriate dune growth the key dynamic represented by the managed profile hindcast bgb15 was the formation of a fenced dune in windsurf the sand fence formulation and calibration procedures described in section 2 2 allow windsurf to accurately reproduce the growth of the fenced dune and the corresponding cessation in vertical growth of the natural dune behind the fenced dune i e itzkin et al 2020 here we find that the genetic algorithm was able to identify a parameterization that not only produces an accurate hindcast but is consistent with conditions in the field the algorithm identifies a low value for the aeolian transport coefficient cb 0 1 table 1 which is consistent with reduced aeolian sediment flux as a result of the narrower and more steeply sloped beach compared to that of bgb22 conversely the calibrated vegetation density startingdensity 1 is much higher on the managed profile compared to the unmanaged profile startingdensity 0 386 this is consistent with visual observations in our study area that suggest vegetation tends to be dense from the face of the fenced dune to the heel of the natural dune in managed areas while vegetation on the dune face tends to be sparser on natural dunes in unmanaged areas the two profiles in this study are co located on the same barrier island bogue banks nc and thus there should be similarities between the parameterizations in the hindcasts given that the profiles are 10 km apart and likely experienced a similar wind and wave climate between 2016 and 2017 the machine learning models developed for each hindcast are independent of each other yet they both identified a similar value for the vegetation friction coefficient m table 1 this is consistent with observations that indicate the dominant dune building vegetation uniola paniculata and dune species composition are relatively consistent along the length of bogue banks hacker et al 2019 both profiles are calibrated with a low value for wave asymmetry facas table 1 which is one of the two key parameters describing wave driven onshore sediment transport along with facsk because bogue banks is a concave island shoreline orientation changes alongshore fig 1 and therefore so do the relative angles between the waves and wind with the beach and dunes even though both simulations are being forced with the same input conditions this necessitates different wind and wave parameters table 1 for the different profiles rather than one set of calibration values for both profiles to better explain the subsequent changes in morphology in these locations e g hage et al 2018 2020 sanuy and jiménez 2019 sediment size and distribution at numerous locations across the profile are additional parameters that could be measured in the field and included in the model potentially further improving the accuracy of hindcasts the comparison of parameter values identified by the machine learning models used for calibrating the hindcasts with observed conditions in the field demonstrates that the different data driven approaches can help windsurf better represent the physics involved in driving evolution of the hindcast profiles the importance of this is three fold first while manual calibration approaches also involve adjusting parameters to match field conditions this will ultimately be limited by an inability to account for the complex interactions between parameter values machine learning models are uniquely suited to identify those interactions second while a common critique of machine learning models is that they are a black box the approach here allows us to affirm the decisions made by the machine learning models by comparing them to observations of morphology sediments vegetation and wind wave processes third as we move from producing a hindcast to forecasting changes to the profile described below it is important to ensure that windsurf accurately represents the physics driving evolution of the profile there are an infinite number of potential paths the profile can take in the hindcast however we can only evaluate the hindcast by comparing the initial and final timesteps when observations are available the forecast predictions are derived from how the hindcast evolved at each timestep a physically reasonable parameterization suggests that the intermediate profile evolution is acceptable and provides added confidence in the quality of the forecast 4 3 forecasts the neural network forecasting model with a lstm layer predicts dune morphometric changes reasonably well for both profiles when changes are relatively modest however the model s capability to produce an accurate forecast for the fenced profile is limited by the conditions present in the hindcasting training period because the lstm is not able to sufficiently predict changes that occur during out of sample forcing conditions for example the fenced dune was completely eroded along with much of the beach following hurricane florence in 2018 fig 3b and the lstm was not able to capture this significant erosion fig 8a despite the inclusion of the storm in the wind and wave time series used to make the forecast fig 1b this could potentially be due to the location of the tide gauge within bogue sound fig 1a which may be different than the storm surge at the profile locations however it is widely acknowledged that machine learning methods i e lstm do not adequately extrapolate with out of sample instances beuzen et al 2019 hurricane florence was the most extreme out of sample instance during the forecasting period 2017 2020 evidenced by the degree of observed change to the profile during this time 2017 2018 fig 3b the lstm model is trained on the output from windsurf and thus is limited by the accuracy of the windsurf hindcast and the types of events i e erosional or accretional included in the windsurf hindcast because our windsurf hindcast did not include a significant storm event the lstm model did not necessarily learn how to handle an event of the magnitude of hurricane florence when the neural network was being trained this limitation could be addressed by adjusting the surveying frequency and hindcast period to capture both dune erosion and recovery and by analyzing the accuracy of the hindcast at multiple time periods instead of only at the endpoint a longer hindcast could also address this issue if sufficient computational power is available computational cost currently limits simulations to one year hindcasts while we could run a hindcast for the 2017 2018 period erosion from hurricane florence or for the 2018 2019 period recovery from hurricane florence these might both invoke the same limitation of significant out of sample dune evolution either erosion or recovery depending on the chosen one year period for the hindcast improving forecasts by evaluating windsurf over a hindcast period with multiple observations including erosion and recovery is the subject of ongoing research itzkin et al 2021 but is beyond the scope of this manuscript despite these limitations lstm reproduces the differences in growth rates between natural dunes in managed and unmanaged locations figs 7 and 8 in summary lstm reproduces observed variability in dune growth and erosion for both the managed and unmanaged dunes in addition to the overall change through time the forecast range for the managed profile figs 7a and 8a is narrow consistent with the expectation that the fenced dune will prevent growth and erosion of the natural dune the variability in the forecast over time for the unmanaged profile computed via 10 simulations figs 7b and 8b is larger than for the managed profile and increases over time this is consistent with the natural dune being more exposed to wind and waves and thus being more affected by the differences in forcing between the different ensemble forecasts used to produce the forecast range lstm forecasts may be useful in the production of storm impact assessments which are useful tools for assisting coastal managers in understanding how a given location is likely to be impacted by an oncoming storm e g stockdon et al 2012 storm impact assessments depend on accurate inputs for pre storm morphology which is often outdated and not representative of actual pre storm morphology straub et al 2020 lstm provides a quick and accurate means to extend windsurf projections further into the future with less computational demand to potentially allow for the generation of updated pre storm dune morphology which could improve the accuracy of storm impact assessments 5 conclusions while coupled process based models e g windsurf have the potential to greatly improve our understanding of how dunes and beaches evolve through time their application may be limited by an extensive set of tunable parameters nonlinear interactions between the parameters and computational demands that control the duration and quantity of simulations that can be performed conversely machine learning models e g neural networks genetic algorithms can identify complex relationships in data and make efficient predictions however these data driven approaches may not necessarily represent the physics of real world systems here we present a novel and powerful workflow that combines coupled processed based modeling and two types of machine learning algorithms to leverage their respective strengths the combination of a neural network and genetic algorithm nn1 ga1 allows for thousands of parameter combinations to be evaluated on the order of minutes without having to run windsurf except for seaward dune face growth our hindcasts successfully reproduced observed morphological changes including vertical and fenced dune growth as well as shoreline progradation and beach accretion along bogue banks north carolina the lstm model increases the utility of windsurf by producing accurate forecasts of dune morphology beyond the annual timescale simulated previously this approach allows for the generation of accurate hindcasts and promising forecasts of dune and beach evolution on managed and unmanaged barriers at interannual scale software data availability windsurf is freely available at github ncohn windsurf matlab based coupler to simulate the co evolution of the coastal zone to both winds and waves using xbeach the coastal dune model and aeolis machine learning hindcasting and forecasting code is freely available at micitz windsurf ml calibrate windsurf and produce forecasts github com data is available at zenodo https doi org 10 5281 zenodo 5550354 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we thank an anonymous reviewer and rangely c mickey for their insightful comments and feedback which have improved this manuscript we also thank evan b goldstein for his assistance to m itzkin and feedback on the machine learning methods implemented in this study this work was funded by the us national oceanic and atmospheric association noaa via the nos nccos crp 360 ecological effects of sea level rise program grant no na15nos4780172 to p r s d h and l j m as well as the preston jones and mary elizabeth frances dean martin fellowship fund and by the virginia coast reserve long term ecological research program national science foundation deb 1832221 via a subaward to the university of north carolina at chapel hill any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government appendix a neural network and genetic algorithm calibration accuracy we trained the first neural network nn1 on the rmse using an initial set of calibration runs the training for nn1 ran for 200 epochs with a batch size of 100 the training and validation loss plots figure a 1a d show that the training loss is minimized after 75 epochs for bgb15 and 125 epochs for bgb22 suggesting that this training step could be run for fewer epochs and still achieve a high degree of accuracy ga1 runs for 100 generations with a population size of 100 a crossover probability of 40 and a mutation probability of 20 ga1 identified an optimal parameterization for both profiles after 30 generations figure a 1c f and could thus likely be run for a much shorter amount of time and still identify a reasonable parameterization the total training and optimizing time from the start of nn1 to the final generation of ga1 was 3 1 min each for bgb15 and bgb22 on a pc with a 3 50 ghz intel xeon processor with 64 gb of ram fig a 1 machine learning training accuracy for nn1 a b d e and ga1 c f the top row shows the training accuracy for bgb15 and the bottom row shows the training accuracy for bgb22 the training blue and validation red loss versus each neural network training epoch is shown in the left column a d the observed windsurf versus predicted values from the trained neural network are shown in the middle column b e note that the r2 value in each subplot is calculated using only the testing data red points the right column c f shows the rmse values versus each training generation for the genetic algorithm the dashed line in these subplots shows the lowest rmse value predicted by the genetic algorithm fig a 1 appendix b determining number of calibration instances needed to train nn1 and ga1 we ran additional trainings using smaller subsets of the initial calibration runs to train the first neural network nn1 and the genetic algorithm ga1 we ran a total of 1760 and 1331 manual calibration instances for bgb15 and bgb22 respectively to prevent nn1 and ga1 from identifying any parameterizations that were known to have produced particularly incorrect or incomplete simulations any manual calibration instance that produced a rmse greater than 2 0 m was removed from the training dataset this left a total of 1459 samples for bgb15 and 1324 for bgb22 that were used to train nn1 and run ga1 fig 3 steps 2 and 3 given that the calibration workflow developed for this manuscript came from these initial runs we did not initially consider the number of manual calibrations that might need to be run to produce a good parameter prediction from ga1 here we run nn1 and ga1 using an increasingly larger number of calibration instances which have been randomly sampled from the larger calibration dataset fig 3 step 1 for both profiles we run this analysis with up to n 1300 training instances with a step size of 50 repeating each training step 9 times to account for differences in training accuracy arising from the random sampling here we find that using a smaller number of calibration instances to train nn1 and optimize on ga1 produced a better potential parameterization prediction than those made using a larger number of calibration simulations figure b 1a this trend is less clear for bgb22 than bgb15 which has a relatively consistent best rmse prediction for all training sizes figure b 1a despite this the predictive power of nn1 is much lower when trained with a smaller number of calibration instances figure b 1b this suggests that nn1 may be overfitting to the calibration instances when the number of samples is low taken together it is not clear how many initial calibration samples should be run to generate a good prediction from nn1 and ga1 however our results here suggest that 300 initial calibration simulations may be enough to train nn1 to accurately predict the observed values and allow ga1 to identify an acceptable starting parameterization the number of initial runs could likely be reduced by using an efficient space filling algorithm i e latin hypercube sampling maximum dissimilarity algorithm to explore the parameter space more fully during this step rather than using random parameter values fig b 1 boxplots showing a the best lowest rmse value predicted by ga1 for each profile and b the r2 value for the observed v predicted values generated by nn1 for a training run using n calibration instances from 50 to 1300 fig b 1 
25587,small reservoir development is a challenging issue in agricultural catchments facing water scarcity an integrated new and original agro hydrological model considering small reservoirs mhydas small reservoirs is presented the model explicitly represents relevant spatial scales plot small reservoir stream reach groundwater and catchment scales and the agronomic and hydrological links between these scales at which agriculture hydrology interactions occur after numerical verification the model is evaluated by applying it to a 19 km2 catchment the model satisfactorily simulates the annual stream runoff within 6 and daily stream runoff nash efficiency 0 47 but tends to overestimate the crop yield 21 simulations one under actual basin conditions and one under virtual conditions were carried out this highlighted the potential of the model to predict the local and cumulative impacts of small reservoirs hence mhydas small reservoirs is a promising model for land use planning and water management of agricultural catchments containing small reservoirs keywords small reservoirs crop plot farmer decisions agricultural water management 1 introduction the frequency of droughts has been increasing worldwide in many arid and semi arid regions east asia africa australia and the mediterranean basin and temperate regions such as western europe spinoni et al 2013 drought occurrences may increase in the future due to climate change sheffield and wood 2008 and anthropogenic pressures on water resources vörösmarty et al 2000 droughts induce severe consequences notably on hydrology and agriculture malakoff and sugden 2020 van loon 2015 in agricultural catchments small reservoirs are considered by water managers and farmers as a potential way to adapt agricultural practices to drought occurrences e g habets et al 2014 malveira et al 2012 previous global studies have shown the often overlooked potential of small water storage to increase water and food security small water storage or a soft path approach would avoid the construction of large capital intensive and environmentally damaging water infrastructure previous studies estimated that irrigation with small reservoirs can globally feed an additional 800 million people under current climate conditions rosa et al 2020a and an additional 300 million people under a 3 c warmer climate rosa et al 2020b most of these studies are global and cannot account for many local site specific variables small reservoirs are reservoirs whose storage capacity does not exceed 106 m3 habets et al 2018 by intercepting and storing surface subsurface and stream runoff during high flow periods they constitute an alternative water resource for crop irrigation purposes during drought periods as a consequence the number of small reservoirs has multiplied in recent decades in many regions worldwide and their spatial density may exceed 5 small reservoirs per km2 habets et al 2018 however the increase in small reservoirs may impose antagonistic impacts as a positive effect small reservoirs represent an alternative resource required to maintain crop yields biemans et al 2011 wisser et al 2010 as a negative effect each small reservoir may have a local hydrological effect on its nearby environment such as by modifying the groundwater surface exchanges or reducing the stream flow the reservoirs taken as a whole the reservoir network may also induce a cumulative effect hydrological modifications especially local modifications may induce ecological biogeochemical and geomorphological disturbances in catchments and the ecosystems they support habets et al 2018 small reservoirs in an agricultural catchment enhance the interactions between hydrology and agriculture particularly through crop water needs and farmers decisions on crop management and water withdrawals for irrigation fig 1 the elucidation and prediction of the hydrological and agricultural impacts of small reservoirs require the articulation of the different spatial scales involved in these interactions i the agricultural plot where farmers decide cropping practices where crop growth occurs and where water is partitioned between evaporation transpiration runoff and infiltration ii the small reservoir which on the one hand is related to its upstream hydrological drained area and downstream catchment area and on the other hand to each irrigated plot iii the catchment which integrates hydrological effects especially those on stream runoff and groundwater these different scales are linked by hydrological processes surface runoff stream runoff groundwater recharge etc and crop and agricultural water management operations water withdrawal operations from reservoirs and irrigation applications numerical modelling is a widely adopted approach to better understand and predict small reservoir impacts most of the models dedicated to this aim are based on hydrological catchment models among these hydrological models few explicitly consider the plot scale at which management operations are conducted the spatial representation of reservoirs can be explicit deitch et al 2013 nathan et al 2005 statistical e g çetin et al 2009 güntner et al 2004 nathan et al 2005 zhang et al 2012 or global e g habets et al 2014 perrin et al 2012 tarboton and schulze 1991 the explicit spatial representation has the advantage of simulating both local and cumulative hydrological impacts of the reservoir networks deitch et al 2013 nathan et al 2005 regarding the representation of crop growth very few models couple crop and hydrological models e g neitsch et al 2011 therond et al 2014 most models simply represent crop growth through functional parameters e g leaf area and crop development coefficient or forcing variables transpiration fluxes while other models neglect this aspect the interaction between crop growth and hydrological processes is thus not considered water withdrawal from reservoirs and the irrigation amount applied to crops can be modelled depending on both crop water requirements and water availability murgue et al 2014 neitsch et al 2011 however certain models consider constant irrigation amounts over given periods e g hughes and mantel 2010 while others do not consider crop irrigation e g rousseau et al 2013 with the exception of very few catchment models e g therond et al 2014 farmer decisions on crop and agricultural water management are not represented in catchment models dedicated to agricultural catchments containing small reservoirs finally to our knowledge very few if any of these models simultaneously consider the various spatial scales plot reservoir and catchment the water dynamics in small reservoirs in relation to water withdrawals and the agronomic and hydrological links between these scales at which agriculture hydrology interactions occur we developed a new distributed agro hydrological model named mhydas small reservoirs this model is designed for agricultural catchments containing small reservoirs dedicated to irrigation it simulates the interactions between the hydrological behaviour of the catchment crop growth and farmer decisions related to the management of crops and reservoirs mhydas small reservoirs is based on the coupling of three already proven models i the catchment scale distributed mhydas hydrological model moussa et al 2002 ii the plot scale crop model aqyield constantin et al 2015 that includes yield calculation and iii a plot and reservoir scale farmer s decision model murgue et al 2014 without any name that represents the farmer decisions related to crop and water reservoir management the latter two have already been used in a water management model maelia therond et al 2014 which has been applied to water resource catchments of 1000 10 000 km2 with reservoirs dedicated to irrigation e g aveyron catchment in france allain et al 2018 the spatial representation used for mhydas small reservoirs combines landscape objects e g plot reservoir at the catchment scale and is based on that of mhydas fully described in lagacherie et al 2010 this representation proves to be particularly effective for simulating surface hydrology e g hallema et al erosion e g gumière et al 2011 or pesticide transfer e g bouvet et al 2010 in small to medium agricultural catchments the main novelty of this model is thus the explicit representation of the relevant spatial scales plot reservoir and catchment and the links between these scales involved in hydrology agriculture interactions mhydas small reservoirs is intended to be used in catchments of 10 100 km2 to understand and estimate the local and cumulative effects of small reservoirs on the hydrology of catchments especially stream runoff and on crop production the objective of this paper is fourfold first it describes the principles of mhydas small reservoirs in terms of catchment spatial segmentation and the modelling of hydrological processes crop growth and farmer management practices of crops and reservoirs second it demonstrates the numerical and computing consistency of the model third it demonstrates the capacity of the model to represent the hydrological and agricultural functioning of an agricultural catchment containing small reservoirs via an application to a real case study the gélon catchment france fourth it investigates the feasibility of model application in the examination of the hydrological and agricultural impacts of catchment situations in terms of the density of reservoirs dedicated to irrigation 2 model description 2 1 spatial segmentation the catchment is segmented in spatially homogeneous units according to the principles adopted for mhydas model representation moussa et al 2002 and fully described and discussed in lagacherie et al 2010 as shown in fig 1 four spatial unit types corresponding to the physical elements of a catchment are explicitly represented in mhydas small reservoirs fig 1 the surface unit su represents a homogeneous spatial entity in terms of its properties soil and land use corresponding to one sub part of a real plot with a uniform water flow direction therefore depending on the topography a real agricultural or non agricultural plot may be represented in the model as a unique su or several sus the su boundaries are determined by overlapping three geographical layers the plot map the flow direction map derived from the topography and the soil map lagacherie et al 2010 an agricultural su is dedicated to crop cultivation and can be irrigated non agricultural sus are plots with non cultivated vegetation such as forests moors or natural pastures or non vegetated plots e g urban areas bare rock areas and sand areas the water reservoir unit re represents a reservoir that can eventually be used for irrigation the re directly connected upstream to a certain reach of the hydrographic network is hereafter called a connected re this type of re is filled by surface runoff from upstream sus stream runoff from upstream rss and direct rainfall in some countries a minimum flow prescribed by environmental regulations has to be released downstream the re not connected upstream to a reach is hereafter called a non connected re unlike a connected re a non connected re is not filled by stream runoff from upstream rss and a minimum flow has not been prescribed to be released downstream the groundwater unit gu represents a hillslope shallow aquifer characterised by a subsurface saturated flow following the structure of the hydrological catchment each gu is therefore derived from the topography considered to identify the flow direction each gu discharges in a single specific reach segment rs the reach segment unit rs represents a section of the hydrographic network between water sources confluence points and connected re or su boundaries rss are connected to comprise the hydrographic network an rs can be used for irrigation purposes these four spatial unit types differ in their shape and geometrical properties table 1 sus and gus are polygons whose boundaries are fixed based on the topography and anthropogenic discontinuities plots vegetation cover etc rss are linear elements while res are represented by points these units are linked by two types of relations hydrological links correspond to the water flows caused by a hydrological process such as surface runoff stream runoff drainage and groundwater discharge to establish a hydrological link between sus res and rss it is assumed that surface water surface and stream runoff flows along the steepest slope to a downstream spatial unit re rs or su every gu is linked to its upstream sus and downstream rs agronomic links correspond to the water transfer from a water resource re or rs to an irrigated su a water resource can be linked to one or several sus in the three following sections the hydrological crop growth and crop and agricultural withdrawal management models are described the equations are shown for the new model developed specifically for the mhydas small reservoir model 2 2 hydrological processes the fluxes and state variables associated with the following hydrological processes are calculated for each spatial unit corresponding to one of the physical elements su rs re or gu and at each time step the time step can range from 1 s to 1 d for all simulated hydrological processes except for the percolation and evapotranspiration of agricultural sus which are simulated at a daily time step 2 2 1 water excess infiltration percolation and soil water content the water excess is the fraction of the water inputs i e rainfall irrigation or upstream runoff that does not infiltrate and runs off along the soil surface infiltration is the water input fraction infiltrating into the soil the water input distribution between infiltration and water excess is simulated by considering the soil infiltration capacity concept the maximum infiltration rate is equal to the infiltration capacity the soil infiltration capacity varies over time depending on the temporal variations in the soil water content a power law is adopted to relate the soil infiltration capacity and soil water content 1 f p t i i m a x k s s w s s w t i s w s s w r λ k s where f p is the soil infiltration capacity m s t i is the current time index k s is the mean saturated hydraulic conductivity m s over the full soil depth i max is the maximum soil infiltration capacity m s sw s and sw r are the soil water storage capacities m considering the total soil porosity and the water filled soil porosity at the residual water content respectively sw is the available water storage m and λ is a shape parameter in the soil the percolation evaporation and transpiration are considered the main drivers of the soil water dynamics the soil water dynamics modelling differs between agricultural and non agricultural sus in agricultural sus the soil is divided in three homogeneous layers following the aqyield model formalisms constantin et al 2015 the effect of tillage on soil is simulated by decreasing the water storage capacity of the top soil layer every day after the tillage the soil water balance is calculated at a daily time step by simulating the soil water content crop transpiration soil evaporation and percolation in non agricultural sus soil and water assessment tool swat model formalisms are adopted with the principle that percolation in soil occurs as soon as the soil water content exceeds the retention capacity neitsch et al 2011 the soil is divided into several layers for which the water content is calculated by considering evapotranspiration infiltration and percolation these swat formalisms are adapted for use at the sub daily time scale as they are not very sensitive to time scale changes brighenti et al 2019 maharjan et al 2013 regardless of the type of the su agricultural and non agricultural the water flows downward from one layer once the soil water content in the layer reaches the soil water capacity the simulated percolation flux along the soil base of any su whether agricultural or non agricultural contributes to the simulated recharge of the gu connected to the su 2 2 2 surface and stream runoff surface and stream runoff are simulated with the diffusive wave equation solved by the hayami kernel method assuming a unidirectional flow to represent runoff routing as described by moussa 1996 surface runoff corresponds to the downslope propagation of the water excess surface runoff flows downstream from an su to another su an rs or an re depending on the spatial segmentation stream runoff is simulated at every time step in every rs considering the upstream flow from any connected sus rss res and gus to the given rs the simulated stream runoff from an rs or re flows into either a downstream rs or downstream re every connected re or rs used for irrigation is characterised by a user defined parameter called minimum flow used denoted qmin m3 s 1 to model the withdrawals see section 2 4 2 management of the withdrawal from water resources the minimum flow is a floor threshold introduced to represent the minimum flow imposed by water regulation laws to maintain the ecological quality of the stream any water withdrawal can be performed in the stream only if the stream runoff does not fall below this floor threshold 2 2 3 evapotranspiration in regard to the agricultural sus the actual evapotranspiration aet is the sum of the actual crop transpiration and actual soil evaporation the aet is calculated at a daily time step based on the soil surface water content reference evapotranspiration et0 and soil clay content constantin et al 2015 therond and villerd 2020 the actual crop transpiration depends on the crop growth and soil water content please refer to section 2 3 crop growth regarding the non agricultural sus the aet is calculated at each time step according to swat formalisms neitsch et al 2011 based on et0 soil characteristics e g bulk density wilting point and thickness soil water content and the fixed leaf area index depending on the given land use 2 2 4 groundwater recharge and stream baseflow the groundwater unit gu recharge is the sum of the percolation fluxes from all the upstream sus connected to the gu the groundwater discharge from a gu to its connected reach stream rs is calculated with a power law storage discharge function kirchner 2009 as follows 2 q b g u t i a g u q r e f g u s g u t i 1 s r e f g u a b where qb gu is the gu discharge m3 s 1 t i and t i 1 are the current and previous time index respectively qref gu is the reference specific discharge of gu m s 1 a gu is the surface area of gu m2 s gu is the water storage in the gu by area unit m sref gu is a reference water storage by area unit m and a m and b are characteristic parameters of the gu the groundwater discharge from a gu to an rs represents the stream baseflow 2 2 5 water dynamics in reservoirs the water volume dynamics in reservoirs are simulated at each time step based on a water balance inflows include i the surface runoff from upstream sus ii the stream runoff from upstream rss to a connected re and iii the direct rainfall volume the latter is calculated as the product of the rainfall rate and the reservoir maximum water surface the infiltration through the reservoir bed is not considered outflows may include i minimum flow ii overflow iii evaporation volume and iv water withdrawal for crop irrigation 3 v r e t i q r e u p t i q r e o u t t i t i t i 1 r t i a r e m a x e t i a r e t i w t i v r e t i 1 where v re is the water volume of the reservoir m3 t i and t i 1 are the current and previous time indexes respectively q reup is the runoff from the upstream spatial units m3 s 1 q reout is the discharge released by the reservoir m3 s 1 e is the evaporation over the time step m r is the rainfall over the time step m a remax and a re are the maximum surface area and the water surface area of the reservoir respectively m2 and w is the withdrawal volume m3 following the conclusion of numerous studies about reservoir evaporation lowe et al 2009 mcjannet et al 2013 the evaporation is assumed to be proportional by a factor k to the reference evapotranspiration et0 such as e k et0 the released discharge is simulated differently between the non connected and the connected reservoirs a non connected reservoir is generally not equipped with a discharge control system and releases water only when it is full consequently the released discharge is modelled as the water volume vreexceed exceeding the reservoir storage capacity such as qreout vreexceed ti ti 1 when the water volume is lower than the storage capacity the released discharge is simulated as zero following water regulation rules in some countries a connected reservoir has to be equipped with a control system to release a minimum flow considered an ecological flow when the upstream runoff to the reservoir exceeds the minimum flow a discharge equivalent to the regulatory minimum flow has to be released when the upstream runoff is lower than the minimum flow the equivalent of all the upstream runoff has to be released in accordance to these regulatory and management rules the released discharge for a connected reservoir q reout is simulated as follows 4 q r e o u t t i v r e e x c e e d t i t i 1 min q min q r e u p t i 2 3 crop growth the crop growth is calculated only in agricultural sus at daily time steps based on the principles of the aqyield crop model constantin et al 2015 crop growth both aerial and root controls crop transpiration and crop yield the crop aerial development is simulated using a crop coefficient representing foliar growth crop coefficient dynamics are a function of crop transpiration development stage phenology and various parameters specific to a given species globally the crop coefficient increases until the flowering stage and then declines until the harvesting stage crop development stages particularly the flowering and maturity stages are simulated based on the concept of growing degree days with threshold values of the growing degree days and parameters specific to each species and cultivar precocity class the actual crop transpiration is calculated with an empirical function of the maximum transpiration and soil water available to roots the maximum transpiration depends on the crop coefficient and et0 minus soil evaporation the soil water available to roots varies as a function of root growth root growth depends on the cumulative daily effective temperature a species root growth coefficient and a reduction coefficient linked to the soil structure the crop yield is calculated at harvest as a function of the potential yield locally defined for a species or cultivar precocity class and the water satisfaction index defined as the ratio of the actual crop transpiration to the maximum crop transpiration during the cropping season 2 4 crop and agricultural withdrawal management 2 4 1 crop management the model simulates farmer management decisions at daily time steps and for every agricultural su the decisions are related to several practices tillage sowing harvesting and irrigation but only one practice respecting a given priority order is operated each day technical interventions are simulated over a given user defined period of the year within this window period the exact dates of technical operations and amounts of water applied to crops are determined according to decision rules based on crop growth and development characteristics soil type and water content and weather conditions these rules the priority order between practices and the window period for each practice and crop may be adjusted to the context via a user defined set of parameters the thusly simulated technical operations modify the other model variables tillage operations affect the soil structure and thus the soil water content capacity the sowing and harvesting dates determine the start and end respectively of crop cycles irrigation decisions trigger water withdrawal operations from res or rss and influence the su soil water content and thus the crop growth and crop yield the irrigation demand by the farmer depends on the crop water requirement according to its development stage but also accounts for equipment constraints through a minimum delay between two irrigations complementary to the presentation of murgue et al 2014 appendix a details the simulation rules applied to farmer management decisions 2 4 2 management of the withdrawal from water resources management of water withdrawal for irrigation purposes is modelled at a daily time step for each water resource dedicated to irrigation with rs being first withdrawn then re this approach prioritizes stream water as a resource used for irrigation the total irrigation water demand on a given resource re or rs is determined as the sum of the daily farmer s irrigation demand for all irrigable agricultural sus linked to that resource if the available water in the resource is larger than the total irrigation water demand the water demand is satisfied by the water withdrawal and the irrigation volume provided to each su is equal to its demand otherwise the withdrawal volume corresponds to the available water volume in the resource and the irrigation volume applied to each su is proportionally reduced compared to the water demands 5 w t i m i n v w r t i 1 v w r m i n j 1 n s u i r r d e m j t i where w is the water withdrawal from the resource m3 v wr is the water volume in the resource m3 v wrmin is the minimum water volume m3 of the resource below which any withdrawal is never performed t i and t i 1 are the current and previous time indexes respectively irrdem j is the farmer s water demand for suj m3 and n su is the number of su irrigated from the water resource the minimum water volume of the resource v wrmin corresponds to the minimum flow q min multiplied by the daily time step or to a volume threshold v remin when the water resource is a stream reach rs or a reservoir respectively the volume threshold v remin is the water volume below which water pumping is technically difficult and usually not performed due to high concentrations of sediments in the water similarly the available water volume of the resource v wr corresponds to the reservoir water volume v re and to the stream runoff q rs multiplied by the daily time step when the resource is a reservoir and a stream reach respectively 2 5 computer implementation the mhydas small reservoirs model was developed within the openfluid platform fabre et al 2010 2020 this platform facilitates model building by sequentially coupling blocks of code called simulators with each simulator supporting one of the main model functions the openfluid platform achieves the coupling of models via the exchange of simulation variables varying both in space and time the overall structure of the spatial domain is managed using a graph where the nodes are the spatial units here sus rss gus and res and the edges are these relations between the above spatial units hydrological or agronomic links mhydas small reservoirs consists of 16 simulators described in appendix b and considers a total of 40 variables all simulators were written in the c language which allows unit oriented data entry jordan 1990 2 6 input and simulated variables parameters and initial conditions the input variables are weather variables namely rainfall et0 and air temperature fig 2 the input variables are spatially distributed the simulated variables per spatial unit type are shown in fig 2 the parameters adopted in the equations and relations implemented in the simulators are listed in appendix c they correspond to either empirical values or functional properties of the spatial units they can be either global i e a unique and common value for all the spatial unit types or spatially distributed i e each spatial unit has its own value the initial model conditions include the soil water content in all agricultural and non agricultural sus the water level in each gu and the volume of water stored in each re connected or not 3 materials and methods 3 1 study area the gélon catchment was chosen for the application of the model for the hydrologic year 2014 2015 for which most of the data required for model implementation and evaluation was available notably the agricultural plot map 3 1 1 general characteristics the gélon is a 19 8 km2 catchment belonging to the arrats catchment which is a 620 km2 sub catchment of the garonne river located in southwestern france in the gers department fig 3 the outlet is located at 43 51 38 n 0 48 07 e it is a hilly catchment with the elevation ranging from 110 to 193 m above sea level the soils are mainly composed of alluvial and molassic slope deposits party et al 2016 the lithology is globally impermeable without a deep aquifer which leads to a high density of the hydrographic network cavaillé and brgm 1968 the total length of the gélon stream is 8 km the oceanic climate of the catchment induces a rainfall of 675 mm an et0 level of 905 mm and a temperature of 13 5 c on average over the period from 1989 to 2016 the gélon catchment is mostly agricultural the majority 75 of the catchment area is devoted to agriculture representing 585 cultivated plots ign 2015 the remaining 25 244 plots comprises non cultivated urbanized or forested areas mtes 2012 the whole cultivated area is covered by annual field crops and the main crops are straw cereals mostly wheat barley triticale and oats and sunflower accounting for 41 and 33 respectively of the cultivated area in 2015 maize soybeans peas chickpeas lentils flax market gardening largely garlic strawberry butternut and onion sorghum rapeseed and temporary and permanent grassland are also cultivated to a lesser extent in this region where organic farming is increasingly applied most crops are rainfed sunflower permanent grassland and vineyard plots some are systematically irrigated mostly maize and soybeans and others are irrigated only when weather conditions are particularly dry straw cereals temporary grassland market gardening rapeseed and orchards field surveys indicate that farmers generally irrigate their fields with an amount of 30 mm except for rapeseed which can be irrigated only once at the sowing time with half the amount i e 15 mm irrigation occurs during the cropping season namely temporary grasslands are irrigated from april to mid may straw cereals from mid may to mid june maize from mid may to mid september market gardening from mid may to mid october soybeans and orchards from june to september and rapeseed in september the catchment contains 25 water reservoirs of varying capacities 100 30 000 m3 13 of which are used for irrigation while the remaining 12 reservoirs often smaller have no current irrigation use following the change to non irrigated crops or following the purchase of the land by private individuals who are not farmers the 13 reservoirs are the only resource for irrigation water i e in this catchment no water is withdrawn from the river there are no channel networks the water is directly pumped from the reservoirs and distributed to the fields under pressure overall 19 of the agricultural area is irrigated mainly by aspersion using 25 m travelling guns the limited availability of irrigation equipment the time required to install the equipment and the limited flow rate of the equipment result in a delay between two irrigations of 6 or 7 days depending on the crop 3 1 2 weather pedological agricultural and hydrological data the weather variables were retrieved from the safran database of meteofrance durand et al 1993 namely the hourly rainfall and air temperature and daily et0 calculated according to penman s formula at an 8 km 8 km resolution the map of the agricultural plots includes the land use at the field plot level and is available on a yearly basis from the french land parcel identification system ign 2015 crop yield data are only available at the gers department level 6200 km2 from data collected from agricultural cooperatives by public authorities draaf occitanie 2020 no database provides information about the agricultural practices in the gélon catchment but specific surveys offer insights on the irrigation practices in the gélon and arrats catchments the soil data were provided by the référentiel régional pédologique a french soil database party et al 2016 stream discharge data at the gélon outlet have only been available since september 14 2018 we thus estimated the 2014 2015 discharge from the daily specific stream runoff data recorded at the closest station of the french station hydrometric network assuming that both specific stream runoffs were equal this assumption was carefully verified over the period september 14 2018 to september 13 2019 at a daily time step during which the discharge at both catchment outlets was monitored the similarity was very high for 47 of stream runoff i e between 0 086 and 1 0 mm d encountered in the gélon catchment with an r2 value of 0 68 considering linear regression an nseq value of 0 53 and an nsesqrt value of 0 71 fig 4 the similarity was low for extreme stream runoff lower than 0 086 mm d an r2 value of 0 02 or higher than 1 0 mm d an r2 value of 0 11 3 2 model implementation 3 2 1 spatial segmentation several geographic data sources table 2 were adopted to determine and characterise the geometrical properties of all spatial units of the gélon catchment resulting in 25 res 17 gus 365 rss and 2402 sus 1666 of which are agricultural sus 3 2 2 parametrisation as far as possible the parameters corresponding to the functional properties appendix c were determined from existing databases measurements and in situ observations or retrieved from the literature values of crop growth parameters were fixed based on previous studies indeed these parameters were determined previously for several field crops in southwestern france and then validated for three rainfed and irrigated spring crops sunflower maize and sorghum constantin et al 2015 for wheat on 14 experimental sites in france and for rotations on two sites in southwestern france tribouillois et al 2018 we grouped crops into classes to limit the number of crop parameter sets especially for minority crops for example the soybean class includes soybeans as the main crop but also peas chickpeas flax and lentils as minority crops the soil texture and soil depth also used in the crop growth model are parameters derived from the french soil database référentiel régional pédologique party et al 2016 by considering the dominant soil type in each su the soils of the agricultural su show low variability all clay loam soils and all belong to a single soil class in addition the three shape parameters of the su infiltration capacity curve equation 1 not defined in the aqyield database namely i max k s and λ were adjusted as detailed below two of the four parameters of the gu storage discharge function were defined based on an analysis of gélon outflow discharges during recession periods while the other two namely parameters a and b of equation 2 were fitted a simple calibration of the outflow at the outlet of the gélon was performed by considering 3 values for each of the 5 parameters to be fitted and by varying them one at a time thus only 243 sets of parameters were then tested the three values were chosen to explore a realistic range of variation by selecting the minimum and maximum values found in the literature and their arithmetic mean the extreme values for the parameters of the su infiltration curve were defined according to mishra et al 2003 fernández pato et al 2016 party et al 2016 and those for the gu storage discharge function from kirchner 2009 3 2 3 time step of the simulation an hourly simulation time step was adopted for all the hydrological processes blue boxes fig 2 except for those processes for which the formalism required a daily time step as indicated in section 2 namely the water balance of agricultural plots as well as crop growth processes and crop and agricultural water management operations red and green boxes fig 2 3 2 4 climate input variables and initial conditions climate input variables namely rainfall et0 and air temperature were considered spatially uniform in the application of the model to the gélon catchment due to the lack of data all the initial conditions were set using a warm up approach consisting of a simulation over a period long enough to reach equilibrium kollet and maxwell 2008 in this study we adopted the recursive simulation approach described by ajami et al 2014 the previous hydrological year from 2013 to 2014 was repeated 25 times with constant crop rotations we verified that the equilibrium state was reached after these 25 year long simulations by determining whether the annual simulated variations in water storage at a one year interval were lower than 1 in 95 of the units of each type this warm up process was initiated considering a full saturation of the catchment including a complete filling of the reservoirs to limit the spin up time rahman et al 2016 3 3 model verification to verify the model we considered virtual and real catchments and monitored i each simulator ii the model determinism and iii the conservation of water volumes furthermore the computation time was also analysed 3 3 1 simulator testing for each simulator the agreement between the computer code and conceptual model was verified using simple test cases the verifications were based on a comparison of the simulated and expected values of the variables with the latter obtained from either algebraic equations or reference simulations these tests also allowed us to evaluate the hydrological and agronomic links between all the units as an example the combined testing of the irrigation decision and application simulators appendix c allowed us to simultaneously verify the following the identification of all the re or rs dedicated to irrigation and the links between that water resource and the irrigable sus the consistency between the available water volume water withdrawal volume irrigation water demand and irrigation amount provided to crops and the absence of withdrawal from a water resource not dedicated to irrigation 3 3 2 model determinism model determinism is guaranteed when identical simulations repeated in the same computing environment with unchanged parameterizations initial conditions and boundary conditions result in exactly the same simulated values a numerical test was performed on a sub catchment of the gélon catchment modelled with 341 sus 112 rss 69 gus and 13 res with one of the latter being dedicated to irrigation the test was executed by repeating the same 5 year simulation 1000 times and we assessed whether the water volumes in the gus res and sus and water fluxes in the sus and rss remained unchanged across the whole catchment 3 3 3 water volume conservation water volume conservation is an important criterion in hydrological model verification we monitored the water volume conservation in mhydas small reservoirs at the daily resolution considering the whole catchment in the case of perfect water volume conservation the total volume of all simulated outflows from the catchment equals the total volume corresponding to the variation in the simulated water storage and all simulated inflows to the catchment we monitored the water mass conservation level in the same real catchment as was adopted for model determinism assessment section 3 3 2 model determinism at the daily time step considering that the difference between the above two volumes should remain below 0 001 of the total inflow volume 3 4 model evaluation model evaluation determines the ability to simulate hydrological and agricultural functioning in a real case study basically the evaluation relies on the comparison of simulated variables to available observed or reference data as the primary intention in using mhydas small reservoirs is to quantify the cumulative effects of reservoirs on crop yields and on stream runoff at the catchment outlet we chose these two variables to evaluate the model the evaluation therefore followed two steps the first step involved the evaluation of the model in the simulation of global variables corresponding to the annual fluxes across the entire catchment for which reference data were available for the case study in the second step the model ability to finely simulate the daily stream runoff was analysed using the nash sutcliffe efficiency 1970 calculated as follows 6 n s e q 1 i 1 n q i s q i o 2 i 1 n q i s q o 2 where nse q is the nash sutcliffe efficiency of the stream runoff qi o is the reference stream runoff at the ith time index q o is the mean reference stream runoff and qi s is the simulated stream runoff at the ith time index the closer the value is to 1 the higher the quality of the stream runoff simulation is the efficiency considering the square root of the stream runoff denoted as nse sqrt was also calculated since it assigns a high weight to low values of the stream runoff when nse q is highly sensitive to high flows oudin et al 2006 pushpalatha et al 2012 when applying the model to the gélon catchment the efficiencies were calculated based on the daily stream runoff over the full hydrologic year of 2014 2015 starting on 1 september the daily simulated stream runoff q s i was calculated as the sum of hourly simulated stream runoff for the ith day as we determined that the stream runoff data used as reference data were less reliable between june and october and for stream runoff below the threshold of 0 086 mm d cf section 3 1 2 we also calculated the efficiencies by considering those days when the stream runoff exceeded the above threshold excluding the period from june to october 3 5 numerical explorations the model was then applied to simulate in the gélon catchment two situations that differed in terms of crop allocation and reservoir water management table 3 the objective was to analyse the capacity of the model to predict possible future conditions and assess the potential consequences of different policies in crop and agricultural water management strategies as is commonly achieved in scenario exercises using models in water resource management leenhardt et al 2012 the reference situation represents the current state as simulated for the 2014 15 hydrological year which is compared to the second situation named all re the all re situation was not designed to be realistic but for its illustrative potential in this situation we therefore assumed that all reservoirs of the catchment were used for irrigation purposes and that all agricultural sus within a radius of 500 m around every re were irrigated and cropped with maize the most irrigated crop in the region the all re situation thus differs from the reference situation both in terms of number of reservoirs considered for irrigation and in terms of crops and cropping area 4 results 4 1 model verification 4 1 1 simulator testing model determinism and water volume conservation testing of all the simulators was successful since the variables simulated with the model matched the expected values the results are not presented but are available upon request the model determinism was verified since the simulated variables in terms of the total water storage in the gus sus and res and water fluxes surface runoff in the sus and stream runoff in the rss were strictly identical for all 1000 simulations water volume conservation in the simulations was also verified at the annual scale the error was lower than 0 0001 of the inflow volume 4 1 2 computation time the simulation was performed based on an ubuntu quad core microprocessor at 2 90 ghz with 128 gb of ram and a 32 bit cpu the computation time reached 17 h for a 26 year period in the gélon catchment with a display of the daily global variables in the whole domain and an additional display of all of the variables in each spatial unit 3 per rs and gu 7 per re and 30 per su for the last simulated year which represents 4 7 go 4 2 model evaluation at the catchment level the simulated stream runoff over the hydrological year of 2014 2015 is 102 8 mm table 4 which is only 6 4 higher than the reference stream runoff 96 6 mm the efficiencies of nseq and nsesqrt of the simulated daily stream runoff are 0 32 and 0 26 respectively in regard to the days when the stream runoff exceeds 0 086 mm d between november and may when the reference stream data are considered reliable please refer to section 3 1 2 the calculated nseq and nsesqrt values are both 0 47 these values approaching 0 5 indicate that the model yields nearly satisfactory results not only for high flows in terms of nseq moriasi et al 2015 but also for low flows in terms of nsesqrt oudin et al 2006 over the period corresponding to these days the simulated daily stream runoff matches the reference stream runoff well fig 5 during this period the simulated cumulative stream runoff is 82 6 mm which is 3 3 higher than the cumulative reference stream runoff 80 0 mm according to moriasi et al 2015 an error of less than 5 is considered very good on the basis of all the efficiencies and differences between the simulation and reference data the model applied to the gélon catchment yields acceptable or even good simulations of the hydrology table 5 summarizes the simulated and regionally observed crop yields considering all the crops the area weighted average of the relative root mean square errors across the gélon catchment is 21 4 which is quasi acceptable according to cabelguenne et al 1990 and constantin et al 2015 who considered a difference of 20 between the observed and simulated yields acceptable this performance results from the good performance of the model in the simulation of the sunflower and sorghum yields and the poor yield simulation performance for soybeans rapeseed maize and straw cereals 4 3 numerical experiment results 4 3 1 global variables the annual catchment water balance terms in the two situations are reported in table 4 the simulated irrigation amounts rank as expected with the largest volume occurring in the all re situation due to both the large irrigated area and abundant available water resources the simulated stream runoff in the all re situation was 6 lower than in the reference situation the crop yield varies both between crops within a situation and between the two situations table 6 in the all re situations yields of non irrigated crops i e sunflower are not very different from those in the reference situation 2 since a rainfed crop in the reference situation remains non irrigated in all re crops irrigated on only part of their area in the reference situation are either replaced by irrigated maize or maintained as non irrigated in the all re situation as a result when they do not disappear as for rapeseed and sorghum their yield decreases slightly if they were lightly irrigated e g straw cereals or considerably if they were intensively irrigated e g soybeans regarding maize the yield decrease observed in all re 12 compared to the reference has another explanation in all re the number of reservoirs for irrigation increased and all irrigated surfaces were converted into maize crop plots the increase in the overall volume of water available for irrigation purposes did not compensate for the increase in the total water demand resulting from the increase in the area of irrigated maize hence the decrease in yield 4 3 2 spatially distributed variables mhydas small reservoirs simulates a large number of spatially distributed variables related to the hydrological and agricultural responses of a catchment we illustrate three of them namely i stream runoff ii irrigation water demand and iii reservoir filling rate evolution the stream runoff is simulated along the whole hydrographic network at the rs resolution this allows us to assess and compare the inner catchment variability as shown in fig 7 where the difference in the monthly stream runoff along the hydrographic network between the reference and all re situations in december 2014 and july 2015 is plotted these two months were chosen because they corresponded to high flow and low flow periods respectively in that respect several results can be highlighted the first result is that the relative variation in the monthly stream runoff between the situations at the catchment outlet differs from one month to another and that the variation in the annual stream runoff also differs for example although the simulated annual runoff in the all re situation was lower by 6 compared to the reference situation the difference of monthly stream runoff between both situations was 3 in july and 14 in december the second notable result is that the variation in the stream runoff at the outlet may mask the high variability in stream runoff along the hydrographic network the simulated stream runoff variation was negative in most of the stream reaches fig 7 indicating a lower stream runoff in the all re situation than in the reference situation over the two months analysed this result was expected due to i the higher crop water requirement of maize compared to the straw cereals which is the main irrigated crop in the reference situation and ii the larger water withdrawals in the reservoirs in order to irrigate maize this leads to emptier reservoirs at the beginning of the rainy period and thus to an increase of water interception of runoff and stream runoff by the reservoirs and to a decrease of the stream runoff in the catchment however in july in the western branch of the hydrographic network delimited by a and b in fig 7 the stream runoff was higher 9 than that in the reference situation this counterintuitive result is explained by an increase of the baseflow in the all re situation which is 8 higher in july for certain gus in the southwest of the catchment this increase in the baseflow is first related to the irrigation indeed the absence of irrigation under the reference situation in the northwest of the catchment fig 7 leads to a lower soil water content than that in the all re situation where the soils are cropped with highly irrigated maize the rainfall in july and the subsequent infiltration allows the soil water content to exceed the soil field capacity faster thus triggering larger soil percolation in the all re situation than in the reference however this phenomenon is limited to a small part of the catchment indeed in the rest of the catchment the water amount available for irrigation in the reservoirs is smaller than the demand and the mean soil water content in the all re situation remains lower than that in the reference situation thus at the catchment scale the stream runoff is slightly modified by these changes and driven more by the increasing aet due to the maize crops the irrigation water demand also exhibits inner spatial and temporal variability as shown in fig 7 where the irrigation water demand is plotted for the reference and all re situations and two months corresponding to the beginning june and the end august of the irrigation period these two months illustrate well how the water demand depends on crop requirements and water resource availability in reservoirs which usually decreases with time during the irrigation period the water demand is quite uniform in the catchment for the all re situation because all irrigated fields are cropped with the same crop maize the difference in water demand between june and august relies mainly on this situation in crop water requirements in june the maize was planted a few weeks earlier and the crop water requirement and thus the water demand for irrigation is low in august the crop requirement is large due to the crop development and the high et0 fig 5 as the reservoirs are empty at this time fig 8 the water demand remains high most of the time in the reference situation water demand is slightly more variable than for the all re situation because there are different irrigated crops such as straw cereals soybean and maize the crop development in time and the irrigation period are different from one crop to another one as straw cereals are harvested in july all fields with this crop are simulated with a zero water demand in august for the reference situation fields with black dots in the left map of fig 7 as in the all re situation the temporal variation in water demand for maize fields between june and august also results from the water availability in the reservoirs for instance the simulated water demand for the field in maize indicated by a red circle in fig 7 varies from zero in june to more than 60 mm in august the water volume in the reservoir connected to this field grey line in fig 8 is not large enough in august to meet the crop requirement leading to a permanent high water demand the reservoir filling rate which is the ratio between the volume of water stored and the re capacity also reveals a high spatial and temporal variability fig 8 this finding is explained by the spatial distribution of the crops the different water requirements and cycles of the different crops and the locations and properties of the reservoirs whether a reservoir is used for irrigation or not is the first variation factor of the filling rate between reservoirs either connected or non connected res remain almost full throughout the year as long as they are not applied for irrigation purposes the blue and red curves in fig 8b the type of irrigated crop is the second factor namely in the reference situation where the various crops are irrigated the reservoir levels decrease first in june to irrigate the straw cereal market gardening and soybean crops and again from july to september when the maize and soybean crops are irrigated the orange green grey and black lines in fig 8b while in the all re situation with all irrigated plots cropped with maize the decrease in june is not observed all the coloured lines in fig 8c the type of reservoir connected or non connected is another factor explaining the differences in filling rate when the irrigation water demand is high as that during maize irrigation in the all re situation the connected reservoirs the red and orange lines in fig 8b and c are more likely to become filled because they benefit from both surface and stream runoff from the upstream reach while the non connected reservoirs only receiving surface runoff are less likely to become filled the blue and green lines in fig 8b and c the last factor is the location of the reservoir as illustrated by the difference between two non connected reservoirs reserved for irrigation the black and grey lines respectively in fig 8 in one case the black line the drained area is not large enough to fill the reservoir during the surface runoff period and the reservoir remains almost empty throughout the year regardless of the situation in the second case the grey line the drained area is large enough to support a high filling rate as indicated by the filling rate approaching the reservoir capacity during the rainfall events in late june 5 discussion the first application of the mhydas small reservoirs model to the gelon catchment gave promising results fig 5 tables 4 and 5 the main processes underlying the hydrological and agricultural functioning of the catchment seem to be well modelled however considering the application of the model to other catchments and other agropedoclimatic contexts requires questioning i the availability of the data needed for its application to other real case studies and ii the improvements to the model in terms of the processes represented the two points are discussed hereafter the first point of discussion concerns the data needed to use the mhydas small reservoirs model either to define forcing variables to obtain the spatial representation of the flow domain to parameterise it on the study area or to evaluate it most of the necessary data e g topography hydrographic network soil characteristics nature of crops and meteorological variables may be extracted or derived from generic databases often available throughout europe moreover as this model is built on already proven models and on widely used equations some parameters can be fixed from the literature for example this is the case for the plant growing coefficients or for the k factor for converting reference evapotranspiration to reservoir evaporation this makes it easy to envision the use of the model in catchment areas other than the one we studied however there is no generic database for all model inputs or for all variables used for its evaluation in such cases and when available those data may be derived from local databases specific surveys or local expertise this is particularly the case for data on reservoirs there is currently no database at the european or even the french level that allows a complete and high quality description of small water reservoirs the availability and estimation of the small reservoirs properties and the water use from the reservoirs have remained a real challenge regardless of the approaches used in catchment hydrological modelling with reservoirs hughes and mantel 2010 lowe et al 2005 this has motivated the development of remote sensing methods to estimate position and capacity of small reservoirs over large areas ogilvie et al 2016 in france the collective water management structures recently set up in deficit areas organismes uniques de gestion collective de l eau are beginning to create a type of database gathering characteristics and water uses of small reservoirs databases describing agricultural practices are also incomplete either in terms of geographical location or in terms of content as explained in leenhardt et al 2010 2020 therefore this requires the implementation of specific acquisition methods for example as presented for cropping systems by murgue et al 2016 and rizzo et al 2019 it is clear that the lack of generic databases for some of the necessary variables to use or evaluate the model makes using the model more difficult however this constraint is not specific to mhydas small reservoirs and has been encountered by other modelling approaches dealing with the cumulative effect of small reservoirs the quality of the data used also guarantees the predictive quality of the model and the reliability of the model assessment the use of indirect acquisition methods necessarily introduces inaccuracies either because of the quality of the expertise rizzo et al 2019 or because of the method itself for example in our case study we did not manage to meet all the owners of the reservoirs absences or refusals so that the data for some reservoirs correspond to hypotheses based on our observations or on the expertise of neighbours however the existence of generic databases does not exclude the need to examine the quality of the data included in them for example in the present study although we had databases providing stream flow meteorological data and crop yield values we were only able to access stream flow data at a nearby station located within the same basin but outside the gélon catchment while meteorological data and crop yield values respectively were at a resolution that was too low to obtain internal spatial variability on an 8 km2 grid and averaged over the entire gers department these spatial discrepancies necessarily affect the quality of the data more intensive field work for example by monitoring flows at the gélon outlet or by obtaining yield values from agricultural cooperatives or traders who collect crops in this sector would have enabled a better evaluation of the model s performance the second point of discussion is about the way to improve the modelling of processes in mhydas small reservoirs in particular processes directly affecting the reservoir regarding this point the modular design of the mhydas small reservoirs model under the openfluid platform easily allows adding or improving simulators in the current version of the model some processes are neglected this is the case for infiltration of water from the reservoirs to the underlying groundwater or conversely for the discharge of groundwater directly to the reservoirs neglecting these processes appeared to be acceptable in the gélon catchment given the characteristics of the reservoirs and their connection to the groundwater however depending on the pedological and lithological contexts and the properties of the reservoirs in particular the hydrodynamic properties of the reservoir bed exchanges between the reservoir and the groundwater can be dominant processes in the hydrological dynamics of the reservoir bouteffeha et al 2015 modelling the exchanges would therefore improve the model in its ability to simulate a diversity of contexts the modelling could be done simply by considering the differences in water levels between the reservoir and groundwater this type of relationship is reported to well predict the dynamics of exchanges in various contexts sharda et al 2006 another improvement of the model is in the modelling of the water management rules of the reservoirs indeed the cumulative hydrological effect of reservoir networks cannot be explained solely by the geometric characteristics of the network density in terms of number of reservoirs volume or surface area the management rules of the reservoirs which sometimes differ from one reservoir to another appear to be an important factor in this effect habets et al 2018 hughes and mantel 2010 in the present case study the sharing of available water in a reservoir is modelled by a fairly standard approach by considering that the water withdrawn is distributed to the irrigated field proportionally to the water demand but other priority rules could be considered priority could be given for example to crops providing high financial incomes we could also consider defining rules based on short term weather predictions for actual water management rules being modelled within a specific simulator the modular design of the mhydas small reservoirs model will be a clear asset to allow various water management modalities 6 conclusions the mhydas small reservoirs model has been developed to understand and predict the local and cumulative hydrologic and agricultural effects of a reservoir network in an agricultural catchment hydrological models are already available to assess the cumulative impact of reservoir networks compared to these models the originality of mhydas small reservoirs lies in two of its features the first is that it integrates processes related to the three major components of the catchment s agro hydrological functioning hydrology crop growth and water management decisions the second feature is that it explicitly represents the main elements of the agricultural catchment the plot the reach the reservoir and the water table and the hydrological and agricultural relationships between these elements in addition the model distinguishes between reservoirs according to their connection to the hydrographic networks in doing so it allows the simulation of both local effects in the immediate environment of each reservoir and cumulative effects on overall yields table 6 and flows fig 6 numerical verification of the model was successful the first application of the model to a 19 km2 catchment gave promising results in terms of stream runoff and crop yield simulations however the evaluation and validation of the model are incomplete the model could be improved in two directions the first concerns its validation with an analysis of the model performance to simulate the variables for which it was intended such as stream runoff crop yields and water withdrawals and availability in small reservoirs model validation could also gain from its application to catchments where comprehensive reliable and distributed data sets such as water tables stream runoff and crop yield data are available based on in situ measurements and observations the second direction would be to perform a sensitivity analysis in particular a sensitivity analysis of the reservoir characteristics and of the parameters associated with water dynamics modelling in small reservoirs could be helpful when parameterizing the model in future applications thus the mhydas small reservoirs model could potentially be adopted by land use planners and water managers to assist them in their decisions regarding new small reservoir projects in catchments or management of the water stored in reservoirs software and data availability mhydas small reservoirs runs with the openfluid platform openfluid is a software environment for modelling and simulation of complex landscape systems the documentation and versions of openfluid platform can be found on the openfluid site at www openfluid project org a dedicated github workspace is also available at https github com openfluid openfluid the github workspace dedicated to mhydas small reservoir is available at https github com umr lisah mhydas small reservoirs declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests the authors report financial support was provided by onema now ofb france and by région occitanie france acknowledgements this work was financed by a phd scholarship from the french occitanie pyrénées méditerranée region and the french national research institute for agriculture food and environment inrae a part of this work was financed by the french biodiversity agency office français pour la biodiversité the authors thank the compagnie d aménagement des coteaux de gascogne cacg and meteofrance for access to their databases we would like to thank jean christophe fabre openfluid team leader for his help and contribution to the development of the mhydas small reservoirs also special thanks to romain lardy marie estienne manuel chataigner and ekaterina ferry zadonina for their help in the modelling work to koladé akapko victor giffone and lisah technicians sébastien troiano david fages and olivier huttel for facilitating the in situ data collection and to marie lefrancq for providing hydrological data appendix a simulation rules used for farmer management decisions the farmer management decisions considered in the model include tillage sowing harvest and irrigation the decision rules adopted to simulate these technical operations are described below the variables employed as indicators are mentioned between brackets a tillage day occurs during the tillage period temporal window according to the soil type when the soil water content is favourable i e this depends on the weather conditions antecedent cumulative rainfall and soil conditions soil water content a sowing day may occur on the first day of the simulation or after the harvesting period which depends on the weather conditions antecedent cumulative rainfall and minimal temperature possible sowing period temporal window according to the crop type and precocity class and soil conditions soil water content a harvesting day is simulated either when the crop is mature crop development stage or before poor soil and weather conditions occur antecedent cumulative rainfall and soil water content which could result in soil damage depending on the development of the crop and the weather conditions previous rainfall and rainfall forecasts the water demand for irrigation may be zero or have a non zero fixed value this fixed value depends on the crop the soil and the irrigation equipment it is a model parameter e g 30 mm for maize in the gelon catchment application the volume of water actually withdrawn and delivered to the cultivated field is conditioned by the availability of the water resource see section 2 4 2 the farmer s water demand is calculated at a time step depending on the farmer s equipment constraints the time step is a model parameter e g 6 or 7 days in the gelon catchment application depending on the field appendix b description of the mhydas small reservoirs simulator number nb name model component spatial unit type and main simulated variables of every simulator constituting mhydas small reservoirs the model component refers to the integrated model component namely hydrology hydrol crop growth crop or crop and agricultural water management water manag nb name of the simulator model component unit type main simulated variables 1 water atm surf evapotranspiration su files hydrol and crop su reference evapotranspiration 2 water atm surf evaporation re files hydrol re reference evaporation 3 water atm surf rain su files hydrol su rainfall 4 water atm surf rain re files hydrol re rainfall 5 energy atm surf t temperature crop su mean air temperature 6 energy atm surf t temperature min crop su minimum air temperature 7 water surf ecological flow rs re mean annual discharge water manag re ecological flow 8 crop surf practices su decision murgue crop and water manag su farmer management decisions sowing day tillage day harvesting day irrigation day and irrigation water demand 9 crop surf practices su application murgue crop and water manag su application of farmer management decisions sowing day tillage day harvesting day irrigation day and irrigation water demand 10 water surf sz abstraction priority wp decision order water manag wp a priority order for irrigation 11 water surf withdrawal irrigation wp prorata water demand crop and water manag wp a available water for irrigationtotal irrigation water demandwater withdrawalirrigation 12 water soil crop surf uz runoff cropsoilwaterdynamics transfer su storage non connected re horton hayami aqyield water balance crop and hydrol su infiltrationcrop growthevapotranspirationpercolationsurface runoffsoil water contentcrop water requirement re overflowwater storageevaporation 13 water soil surf uz percolation evapotranspiration su soil swat hydrol su evapotranspirationpercolation 14 water surf sz storage baseflow gu storage discharge function hydrol gu water storagedischarge and baseflow 15 water surf transfer rs storage connected re hayami water balance hydrol rs stream runoff re overflowwater storageevaporation 16 water surf variable surface re bathymetric relation hydrol re water surface area a wp withdrawal point corresponds to a water resource rs or re dedicated to irrigation appendix c main parameters of the mhydas small reservoirs model list of the main mhydas small reservoirs model parameters given by spatial unit type for each parameter the spatial unit type the model relying on it a description of the parameter with values of the non distributed parameters and the origin database are listed bold and italicised numbers indicate the number of the simulator as referenced in appendix b that relies on that parameter unit type model component parameters data sources used in the gélon application su agricultural crop crop type 8 12 land parcel identification system of 2015 ign 2015 crop growth potential root growth coefficient evaporation coefficient and sum of the growing degree days at the maturity and flowering stages the complete list of aqyield parameters can be found on the maelia website http maelia platform inra fr donnees donnees agricoles liste des cultures 12 table of crop cultivar characteristics provided by breeders and aqyield calibration constantin et al 2015 su non agricultural hydrol type of land use 12 13 land use inventory of 2012 mtes 2012 grassland root depth 0 80 m 13 moreno et al 2005 forest root depth the maximum soil depth 13 lewis and burgy 1964 algayer et al 2020 su crop and water manag agricultural sus technical itinerary according to the type of crop soil and irrigation equipment 8 irrigation equipment 8 gaudou et al 2016 murgue et al 2014 therond and villerd 2020 field surveys su hydrol soil minimum infiltration capacity coefficient 12 soil maximum infiltration capacity coefficient 12 and shape coefficient 12 mishra et al 2003 fernández pato et al 2016 sensitivity analysis soil maximum infiltration capacity bulk density clay rate potential maximal available water content and thickness 12 13 regional pedological databank party et al 2016 rs and su hydrol manning m s 1 0 05 su 0 10 rs 12 15 chow 1959 celerity m2 s 1 0 045 su 0 49 rs 12 15 diffusivity m s 1 500 su and rs 12 15 iteration number in hayami kernel calculations 100 12 15 moussa et al 2002 re crop and water manag irrigated plots 10 bd cacg ougc ddt completed by field surveys re hydrol and water manag evaporation coefficient 0 6 2 neitsch et al 2011 dead volume of the reservoir 0 25 of the total capacity 11 therond and villerd 2020 minimum flow 10 of the interannual flow 7 lema 2006 gu hydrol reference flow m2 s 1 5 365 10 8 14 divisor parameter 0 05 14 exponential parameter 5 66 14 flow recession curve analysis 
25587,small reservoir development is a challenging issue in agricultural catchments facing water scarcity an integrated new and original agro hydrological model considering small reservoirs mhydas small reservoirs is presented the model explicitly represents relevant spatial scales plot small reservoir stream reach groundwater and catchment scales and the agronomic and hydrological links between these scales at which agriculture hydrology interactions occur after numerical verification the model is evaluated by applying it to a 19 km2 catchment the model satisfactorily simulates the annual stream runoff within 6 and daily stream runoff nash efficiency 0 47 but tends to overestimate the crop yield 21 simulations one under actual basin conditions and one under virtual conditions were carried out this highlighted the potential of the model to predict the local and cumulative impacts of small reservoirs hence mhydas small reservoirs is a promising model for land use planning and water management of agricultural catchments containing small reservoirs keywords small reservoirs crop plot farmer decisions agricultural water management 1 introduction the frequency of droughts has been increasing worldwide in many arid and semi arid regions east asia africa australia and the mediterranean basin and temperate regions such as western europe spinoni et al 2013 drought occurrences may increase in the future due to climate change sheffield and wood 2008 and anthropogenic pressures on water resources vörösmarty et al 2000 droughts induce severe consequences notably on hydrology and agriculture malakoff and sugden 2020 van loon 2015 in agricultural catchments small reservoirs are considered by water managers and farmers as a potential way to adapt agricultural practices to drought occurrences e g habets et al 2014 malveira et al 2012 previous global studies have shown the often overlooked potential of small water storage to increase water and food security small water storage or a soft path approach would avoid the construction of large capital intensive and environmentally damaging water infrastructure previous studies estimated that irrigation with small reservoirs can globally feed an additional 800 million people under current climate conditions rosa et al 2020a and an additional 300 million people under a 3 c warmer climate rosa et al 2020b most of these studies are global and cannot account for many local site specific variables small reservoirs are reservoirs whose storage capacity does not exceed 106 m3 habets et al 2018 by intercepting and storing surface subsurface and stream runoff during high flow periods they constitute an alternative water resource for crop irrigation purposes during drought periods as a consequence the number of small reservoirs has multiplied in recent decades in many regions worldwide and their spatial density may exceed 5 small reservoirs per km2 habets et al 2018 however the increase in small reservoirs may impose antagonistic impacts as a positive effect small reservoirs represent an alternative resource required to maintain crop yields biemans et al 2011 wisser et al 2010 as a negative effect each small reservoir may have a local hydrological effect on its nearby environment such as by modifying the groundwater surface exchanges or reducing the stream flow the reservoirs taken as a whole the reservoir network may also induce a cumulative effect hydrological modifications especially local modifications may induce ecological biogeochemical and geomorphological disturbances in catchments and the ecosystems they support habets et al 2018 small reservoirs in an agricultural catchment enhance the interactions between hydrology and agriculture particularly through crop water needs and farmers decisions on crop management and water withdrawals for irrigation fig 1 the elucidation and prediction of the hydrological and agricultural impacts of small reservoirs require the articulation of the different spatial scales involved in these interactions i the agricultural plot where farmers decide cropping practices where crop growth occurs and where water is partitioned between evaporation transpiration runoff and infiltration ii the small reservoir which on the one hand is related to its upstream hydrological drained area and downstream catchment area and on the other hand to each irrigated plot iii the catchment which integrates hydrological effects especially those on stream runoff and groundwater these different scales are linked by hydrological processes surface runoff stream runoff groundwater recharge etc and crop and agricultural water management operations water withdrawal operations from reservoirs and irrigation applications numerical modelling is a widely adopted approach to better understand and predict small reservoir impacts most of the models dedicated to this aim are based on hydrological catchment models among these hydrological models few explicitly consider the plot scale at which management operations are conducted the spatial representation of reservoirs can be explicit deitch et al 2013 nathan et al 2005 statistical e g çetin et al 2009 güntner et al 2004 nathan et al 2005 zhang et al 2012 or global e g habets et al 2014 perrin et al 2012 tarboton and schulze 1991 the explicit spatial representation has the advantage of simulating both local and cumulative hydrological impacts of the reservoir networks deitch et al 2013 nathan et al 2005 regarding the representation of crop growth very few models couple crop and hydrological models e g neitsch et al 2011 therond et al 2014 most models simply represent crop growth through functional parameters e g leaf area and crop development coefficient or forcing variables transpiration fluxes while other models neglect this aspect the interaction between crop growth and hydrological processes is thus not considered water withdrawal from reservoirs and the irrigation amount applied to crops can be modelled depending on both crop water requirements and water availability murgue et al 2014 neitsch et al 2011 however certain models consider constant irrigation amounts over given periods e g hughes and mantel 2010 while others do not consider crop irrigation e g rousseau et al 2013 with the exception of very few catchment models e g therond et al 2014 farmer decisions on crop and agricultural water management are not represented in catchment models dedicated to agricultural catchments containing small reservoirs finally to our knowledge very few if any of these models simultaneously consider the various spatial scales plot reservoir and catchment the water dynamics in small reservoirs in relation to water withdrawals and the agronomic and hydrological links between these scales at which agriculture hydrology interactions occur we developed a new distributed agro hydrological model named mhydas small reservoirs this model is designed for agricultural catchments containing small reservoirs dedicated to irrigation it simulates the interactions between the hydrological behaviour of the catchment crop growth and farmer decisions related to the management of crops and reservoirs mhydas small reservoirs is based on the coupling of three already proven models i the catchment scale distributed mhydas hydrological model moussa et al 2002 ii the plot scale crop model aqyield constantin et al 2015 that includes yield calculation and iii a plot and reservoir scale farmer s decision model murgue et al 2014 without any name that represents the farmer decisions related to crop and water reservoir management the latter two have already been used in a water management model maelia therond et al 2014 which has been applied to water resource catchments of 1000 10 000 km2 with reservoirs dedicated to irrigation e g aveyron catchment in france allain et al 2018 the spatial representation used for mhydas small reservoirs combines landscape objects e g plot reservoir at the catchment scale and is based on that of mhydas fully described in lagacherie et al 2010 this representation proves to be particularly effective for simulating surface hydrology e g hallema et al erosion e g gumière et al 2011 or pesticide transfer e g bouvet et al 2010 in small to medium agricultural catchments the main novelty of this model is thus the explicit representation of the relevant spatial scales plot reservoir and catchment and the links between these scales involved in hydrology agriculture interactions mhydas small reservoirs is intended to be used in catchments of 10 100 km2 to understand and estimate the local and cumulative effects of small reservoirs on the hydrology of catchments especially stream runoff and on crop production the objective of this paper is fourfold first it describes the principles of mhydas small reservoirs in terms of catchment spatial segmentation and the modelling of hydrological processes crop growth and farmer management practices of crops and reservoirs second it demonstrates the numerical and computing consistency of the model third it demonstrates the capacity of the model to represent the hydrological and agricultural functioning of an agricultural catchment containing small reservoirs via an application to a real case study the gélon catchment france fourth it investigates the feasibility of model application in the examination of the hydrological and agricultural impacts of catchment situations in terms of the density of reservoirs dedicated to irrigation 2 model description 2 1 spatial segmentation the catchment is segmented in spatially homogeneous units according to the principles adopted for mhydas model representation moussa et al 2002 and fully described and discussed in lagacherie et al 2010 as shown in fig 1 four spatial unit types corresponding to the physical elements of a catchment are explicitly represented in mhydas small reservoirs fig 1 the surface unit su represents a homogeneous spatial entity in terms of its properties soil and land use corresponding to one sub part of a real plot with a uniform water flow direction therefore depending on the topography a real agricultural or non agricultural plot may be represented in the model as a unique su or several sus the su boundaries are determined by overlapping three geographical layers the plot map the flow direction map derived from the topography and the soil map lagacherie et al 2010 an agricultural su is dedicated to crop cultivation and can be irrigated non agricultural sus are plots with non cultivated vegetation such as forests moors or natural pastures or non vegetated plots e g urban areas bare rock areas and sand areas the water reservoir unit re represents a reservoir that can eventually be used for irrigation the re directly connected upstream to a certain reach of the hydrographic network is hereafter called a connected re this type of re is filled by surface runoff from upstream sus stream runoff from upstream rss and direct rainfall in some countries a minimum flow prescribed by environmental regulations has to be released downstream the re not connected upstream to a reach is hereafter called a non connected re unlike a connected re a non connected re is not filled by stream runoff from upstream rss and a minimum flow has not been prescribed to be released downstream the groundwater unit gu represents a hillslope shallow aquifer characterised by a subsurface saturated flow following the structure of the hydrological catchment each gu is therefore derived from the topography considered to identify the flow direction each gu discharges in a single specific reach segment rs the reach segment unit rs represents a section of the hydrographic network between water sources confluence points and connected re or su boundaries rss are connected to comprise the hydrographic network an rs can be used for irrigation purposes these four spatial unit types differ in their shape and geometrical properties table 1 sus and gus are polygons whose boundaries are fixed based on the topography and anthropogenic discontinuities plots vegetation cover etc rss are linear elements while res are represented by points these units are linked by two types of relations hydrological links correspond to the water flows caused by a hydrological process such as surface runoff stream runoff drainage and groundwater discharge to establish a hydrological link between sus res and rss it is assumed that surface water surface and stream runoff flows along the steepest slope to a downstream spatial unit re rs or su every gu is linked to its upstream sus and downstream rs agronomic links correspond to the water transfer from a water resource re or rs to an irrigated su a water resource can be linked to one or several sus in the three following sections the hydrological crop growth and crop and agricultural withdrawal management models are described the equations are shown for the new model developed specifically for the mhydas small reservoir model 2 2 hydrological processes the fluxes and state variables associated with the following hydrological processes are calculated for each spatial unit corresponding to one of the physical elements su rs re or gu and at each time step the time step can range from 1 s to 1 d for all simulated hydrological processes except for the percolation and evapotranspiration of agricultural sus which are simulated at a daily time step 2 2 1 water excess infiltration percolation and soil water content the water excess is the fraction of the water inputs i e rainfall irrigation or upstream runoff that does not infiltrate and runs off along the soil surface infiltration is the water input fraction infiltrating into the soil the water input distribution between infiltration and water excess is simulated by considering the soil infiltration capacity concept the maximum infiltration rate is equal to the infiltration capacity the soil infiltration capacity varies over time depending on the temporal variations in the soil water content a power law is adopted to relate the soil infiltration capacity and soil water content 1 f p t i i m a x k s s w s s w t i s w s s w r λ k s where f p is the soil infiltration capacity m s t i is the current time index k s is the mean saturated hydraulic conductivity m s over the full soil depth i max is the maximum soil infiltration capacity m s sw s and sw r are the soil water storage capacities m considering the total soil porosity and the water filled soil porosity at the residual water content respectively sw is the available water storage m and λ is a shape parameter in the soil the percolation evaporation and transpiration are considered the main drivers of the soil water dynamics the soil water dynamics modelling differs between agricultural and non agricultural sus in agricultural sus the soil is divided in three homogeneous layers following the aqyield model formalisms constantin et al 2015 the effect of tillage on soil is simulated by decreasing the water storage capacity of the top soil layer every day after the tillage the soil water balance is calculated at a daily time step by simulating the soil water content crop transpiration soil evaporation and percolation in non agricultural sus soil and water assessment tool swat model formalisms are adopted with the principle that percolation in soil occurs as soon as the soil water content exceeds the retention capacity neitsch et al 2011 the soil is divided into several layers for which the water content is calculated by considering evapotranspiration infiltration and percolation these swat formalisms are adapted for use at the sub daily time scale as they are not very sensitive to time scale changes brighenti et al 2019 maharjan et al 2013 regardless of the type of the su agricultural and non agricultural the water flows downward from one layer once the soil water content in the layer reaches the soil water capacity the simulated percolation flux along the soil base of any su whether agricultural or non agricultural contributes to the simulated recharge of the gu connected to the su 2 2 2 surface and stream runoff surface and stream runoff are simulated with the diffusive wave equation solved by the hayami kernel method assuming a unidirectional flow to represent runoff routing as described by moussa 1996 surface runoff corresponds to the downslope propagation of the water excess surface runoff flows downstream from an su to another su an rs or an re depending on the spatial segmentation stream runoff is simulated at every time step in every rs considering the upstream flow from any connected sus rss res and gus to the given rs the simulated stream runoff from an rs or re flows into either a downstream rs or downstream re every connected re or rs used for irrigation is characterised by a user defined parameter called minimum flow used denoted qmin m3 s 1 to model the withdrawals see section 2 4 2 management of the withdrawal from water resources the minimum flow is a floor threshold introduced to represent the minimum flow imposed by water regulation laws to maintain the ecological quality of the stream any water withdrawal can be performed in the stream only if the stream runoff does not fall below this floor threshold 2 2 3 evapotranspiration in regard to the agricultural sus the actual evapotranspiration aet is the sum of the actual crop transpiration and actual soil evaporation the aet is calculated at a daily time step based on the soil surface water content reference evapotranspiration et0 and soil clay content constantin et al 2015 therond and villerd 2020 the actual crop transpiration depends on the crop growth and soil water content please refer to section 2 3 crop growth regarding the non agricultural sus the aet is calculated at each time step according to swat formalisms neitsch et al 2011 based on et0 soil characteristics e g bulk density wilting point and thickness soil water content and the fixed leaf area index depending on the given land use 2 2 4 groundwater recharge and stream baseflow the groundwater unit gu recharge is the sum of the percolation fluxes from all the upstream sus connected to the gu the groundwater discharge from a gu to its connected reach stream rs is calculated with a power law storage discharge function kirchner 2009 as follows 2 q b g u t i a g u q r e f g u s g u t i 1 s r e f g u a b where qb gu is the gu discharge m3 s 1 t i and t i 1 are the current and previous time index respectively qref gu is the reference specific discharge of gu m s 1 a gu is the surface area of gu m2 s gu is the water storage in the gu by area unit m sref gu is a reference water storage by area unit m and a m and b are characteristic parameters of the gu the groundwater discharge from a gu to an rs represents the stream baseflow 2 2 5 water dynamics in reservoirs the water volume dynamics in reservoirs are simulated at each time step based on a water balance inflows include i the surface runoff from upstream sus ii the stream runoff from upstream rss to a connected re and iii the direct rainfall volume the latter is calculated as the product of the rainfall rate and the reservoir maximum water surface the infiltration through the reservoir bed is not considered outflows may include i minimum flow ii overflow iii evaporation volume and iv water withdrawal for crop irrigation 3 v r e t i q r e u p t i q r e o u t t i t i t i 1 r t i a r e m a x e t i a r e t i w t i v r e t i 1 where v re is the water volume of the reservoir m3 t i and t i 1 are the current and previous time indexes respectively q reup is the runoff from the upstream spatial units m3 s 1 q reout is the discharge released by the reservoir m3 s 1 e is the evaporation over the time step m r is the rainfall over the time step m a remax and a re are the maximum surface area and the water surface area of the reservoir respectively m2 and w is the withdrawal volume m3 following the conclusion of numerous studies about reservoir evaporation lowe et al 2009 mcjannet et al 2013 the evaporation is assumed to be proportional by a factor k to the reference evapotranspiration et0 such as e k et0 the released discharge is simulated differently between the non connected and the connected reservoirs a non connected reservoir is generally not equipped with a discharge control system and releases water only when it is full consequently the released discharge is modelled as the water volume vreexceed exceeding the reservoir storage capacity such as qreout vreexceed ti ti 1 when the water volume is lower than the storage capacity the released discharge is simulated as zero following water regulation rules in some countries a connected reservoir has to be equipped with a control system to release a minimum flow considered an ecological flow when the upstream runoff to the reservoir exceeds the minimum flow a discharge equivalent to the regulatory minimum flow has to be released when the upstream runoff is lower than the minimum flow the equivalent of all the upstream runoff has to be released in accordance to these regulatory and management rules the released discharge for a connected reservoir q reout is simulated as follows 4 q r e o u t t i v r e e x c e e d t i t i 1 min q min q r e u p t i 2 3 crop growth the crop growth is calculated only in agricultural sus at daily time steps based on the principles of the aqyield crop model constantin et al 2015 crop growth both aerial and root controls crop transpiration and crop yield the crop aerial development is simulated using a crop coefficient representing foliar growth crop coefficient dynamics are a function of crop transpiration development stage phenology and various parameters specific to a given species globally the crop coefficient increases until the flowering stage and then declines until the harvesting stage crop development stages particularly the flowering and maturity stages are simulated based on the concept of growing degree days with threshold values of the growing degree days and parameters specific to each species and cultivar precocity class the actual crop transpiration is calculated with an empirical function of the maximum transpiration and soil water available to roots the maximum transpiration depends on the crop coefficient and et0 minus soil evaporation the soil water available to roots varies as a function of root growth root growth depends on the cumulative daily effective temperature a species root growth coefficient and a reduction coefficient linked to the soil structure the crop yield is calculated at harvest as a function of the potential yield locally defined for a species or cultivar precocity class and the water satisfaction index defined as the ratio of the actual crop transpiration to the maximum crop transpiration during the cropping season 2 4 crop and agricultural withdrawal management 2 4 1 crop management the model simulates farmer management decisions at daily time steps and for every agricultural su the decisions are related to several practices tillage sowing harvesting and irrigation but only one practice respecting a given priority order is operated each day technical interventions are simulated over a given user defined period of the year within this window period the exact dates of technical operations and amounts of water applied to crops are determined according to decision rules based on crop growth and development characteristics soil type and water content and weather conditions these rules the priority order between practices and the window period for each practice and crop may be adjusted to the context via a user defined set of parameters the thusly simulated technical operations modify the other model variables tillage operations affect the soil structure and thus the soil water content capacity the sowing and harvesting dates determine the start and end respectively of crop cycles irrigation decisions trigger water withdrawal operations from res or rss and influence the su soil water content and thus the crop growth and crop yield the irrigation demand by the farmer depends on the crop water requirement according to its development stage but also accounts for equipment constraints through a minimum delay between two irrigations complementary to the presentation of murgue et al 2014 appendix a details the simulation rules applied to farmer management decisions 2 4 2 management of the withdrawal from water resources management of water withdrawal for irrigation purposes is modelled at a daily time step for each water resource dedicated to irrigation with rs being first withdrawn then re this approach prioritizes stream water as a resource used for irrigation the total irrigation water demand on a given resource re or rs is determined as the sum of the daily farmer s irrigation demand for all irrigable agricultural sus linked to that resource if the available water in the resource is larger than the total irrigation water demand the water demand is satisfied by the water withdrawal and the irrigation volume provided to each su is equal to its demand otherwise the withdrawal volume corresponds to the available water volume in the resource and the irrigation volume applied to each su is proportionally reduced compared to the water demands 5 w t i m i n v w r t i 1 v w r m i n j 1 n s u i r r d e m j t i where w is the water withdrawal from the resource m3 v wr is the water volume in the resource m3 v wrmin is the minimum water volume m3 of the resource below which any withdrawal is never performed t i and t i 1 are the current and previous time indexes respectively irrdem j is the farmer s water demand for suj m3 and n su is the number of su irrigated from the water resource the minimum water volume of the resource v wrmin corresponds to the minimum flow q min multiplied by the daily time step or to a volume threshold v remin when the water resource is a stream reach rs or a reservoir respectively the volume threshold v remin is the water volume below which water pumping is technically difficult and usually not performed due to high concentrations of sediments in the water similarly the available water volume of the resource v wr corresponds to the reservoir water volume v re and to the stream runoff q rs multiplied by the daily time step when the resource is a reservoir and a stream reach respectively 2 5 computer implementation the mhydas small reservoirs model was developed within the openfluid platform fabre et al 2010 2020 this platform facilitates model building by sequentially coupling blocks of code called simulators with each simulator supporting one of the main model functions the openfluid platform achieves the coupling of models via the exchange of simulation variables varying both in space and time the overall structure of the spatial domain is managed using a graph where the nodes are the spatial units here sus rss gus and res and the edges are these relations between the above spatial units hydrological or agronomic links mhydas small reservoirs consists of 16 simulators described in appendix b and considers a total of 40 variables all simulators were written in the c language which allows unit oriented data entry jordan 1990 2 6 input and simulated variables parameters and initial conditions the input variables are weather variables namely rainfall et0 and air temperature fig 2 the input variables are spatially distributed the simulated variables per spatial unit type are shown in fig 2 the parameters adopted in the equations and relations implemented in the simulators are listed in appendix c they correspond to either empirical values or functional properties of the spatial units they can be either global i e a unique and common value for all the spatial unit types or spatially distributed i e each spatial unit has its own value the initial model conditions include the soil water content in all agricultural and non agricultural sus the water level in each gu and the volume of water stored in each re connected or not 3 materials and methods 3 1 study area the gélon catchment was chosen for the application of the model for the hydrologic year 2014 2015 for which most of the data required for model implementation and evaluation was available notably the agricultural plot map 3 1 1 general characteristics the gélon is a 19 8 km2 catchment belonging to the arrats catchment which is a 620 km2 sub catchment of the garonne river located in southwestern france in the gers department fig 3 the outlet is located at 43 51 38 n 0 48 07 e it is a hilly catchment with the elevation ranging from 110 to 193 m above sea level the soils are mainly composed of alluvial and molassic slope deposits party et al 2016 the lithology is globally impermeable without a deep aquifer which leads to a high density of the hydrographic network cavaillé and brgm 1968 the total length of the gélon stream is 8 km the oceanic climate of the catchment induces a rainfall of 675 mm an et0 level of 905 mm and a temperature of 13 5 c on average over the period from 1989 to 2016 the gélon catchment is mostly agricultural the majority 75 of the catchment area is devoted to agriculture representing 585 cultivated plots ign 2015 the remaining 25 244 plots comprises non cultivated urbanized or forested areas mtes 2012 the whole cultivated area is covered by annual field crops and the main crops are straw cereals mostly wheat barley triticale and oats and sunflower accounting for 41 and 33 respectively of the cultivated area in 2015 maize soybeans peas chickpeas lentils flax market gardening largely garlic strawberry butternut and onion sorghum rapeseed and temporary and permanent grassland are also cultivated to a lesser extent in this region where organic farming is increasingly applied most crops are rainfed sunflower permanent grassland and vineyard plots some are systematically irrigated mostly maize and soybeans and others are irrigated only when weather conditions are particularly dry straw cereals temporary grassland market gardening rapeseed and orchards field surveys indicate that farmers generally irrigate their fields with an amount of 30 mm except for rapeseed which can be irrigated only once at the sowing time with half the amount i e 15 mm irrigation occurs during the cropping season namely temporary grasslands are irrigated from april to mid may straw cereals from mid may to mid june maize from mid may to mid september market gardening from mid may to mid october soybeans and orchards from june to september and rapeseed in september the catchment contains 25 water reservoirs of varying capacities 100 30 000 m3 13 of which are used for irrigation while the remaining 12 reservoirs often smaller have no current irrigation use following the change to non irrigated crops or following the purchase of the land by private individuals who are not farmers the 13 reservoirs are the only resource for irrigation water i e in this catchment no water is withdrawn from the river there are no channel networks the water is directly pumped from the reservoirs and distributed to the fields under pressure overall 19 of the agricultural area is irrigated mainly by aspersion using 25 m travelling guns the limited availability of irrigation equipment the time required to install the equipment and the limited flow rate of the equipment result in a delay between two irrigations of 6 or 7 days depending on the crop 3 1 2 weather pedological agricultural and hydrological data the weather variables were retrieved from the safran database of meteofrance durand et al 1993 namely the hourly rainfall and air temperature and daily et0 calculated according to penman s formula at an 8 km 8 km resolution the map of the agricultural plots includes the land use at the field plot level and is available on a yearly basis from the french land parcel identification system ign 2015 crop yield data are only available at the gers department level 6200 km2 from data collected from agricultural cooperatives by public authorities draaf occitanie 2020 no database provides information about the agricultural practices in the gélon catchment but specific surveys offer insights on the irrigation practices in the gélon and arrats catchments the soil data were provided by the référentiel régional pédologique a french soil database party et al 2016 stream discharge data at the gélon outlet have only been available since september 14 2018 we thus estimated the 2014 2015 discharge from the daily specific stream runoff data recorded at the closest station of the french station hydrometric network assuming that both specific stream runoffs were equal this assumption was carefully verified over the period september 14 2018 to september 13 2019 at a daily time step during which the discharge at both catchment outlets was monitored the similarity was very high for 47 of stream runoff i e between 0 086 and 1 0 mm d encountered in the gélon catchment with an r2 value of 0 68 considering linear regression an nseq value of 0 53 and an nsesqrt value of 0 71 fig 4 the similarity was low for extreme stream runoff lower than 0 086 mm d an r2 value of 0 02 or higher than 1 0 mm d an r2 value of 0 11 3 2 model implementation 3 2 1 spatial segmentation several geographic data sources table 2 were adopted to determine and characterise the geometrical properties of all spatial units of the gélon catchment resulting in 25 res 17 gus 365 rss and 2402 sus 1666 of which are agricultural sus 3 2 2 parametrisation as far as possible the parameters corresponding to the functional properties appendix c were determined from existing databases measurements and in situ observations or retrieved from the literature values of crop growth parameters were fixed based on previous studies indeed these parameters were determined previously for several field crops in southwestern france and then validated for three rainfed and irrigated spring crops sunflower maize and sorghum constantin et al 2015 for wheat on 14 experimental sites in france and for rotations on two sites in southwestern france tribouillois et al 2018 we grouped crops into classes to limit the number of crop parameter sets especially for minority crops for example the soybean class includes soybeans as the main crop but also peas chickpeas flax and lentils as minority crops the soil texture and soil depth also used in the crop growth model are parameters derived from the french soil database référentiel régional pédologique party et al 2016 by considering the dominant soil type in each su the soils of the agricultural su show low variability all clay loam soils and all belong to a single soil class in addition the three shape parameters of the su infiltration capacity curve equation 1 not defined in the aqyield database namely i max k s and λ were adjusted as detailed below two of the four parameters of the gu storage discharge function were defined based on an analysis of gélon outflow discharges during recession periods while the other two namely parameters a and b of equation 2 were fitted a simple calibration of the outflow at the outlet of the gélon was performed by considering 3 values for each of the 5 parameters to be fitted and by varying them one at a time thus only 243 sets of parameters were then tested the three values were chosen to explore a realistic range of variation by selecting the minimum and maximum values found in the literature and their arithmetic mean the extreme values for the parameters of the su infiltration curve were defined according to mishra et al 2003 fernández pato et al 2016 party et al 2016 and those for the gu storage discharge function from kirchner 2009 3 2 3 time step of the simulation an hourly simulation time step was adopted for all the hydrological processes blue boxes fig 2 except for those processes for which the formalism required a daily time step as indicated in section 2 namely the water balance of agricultural plots as well as crop growth processes and crop and agricultural water management operations red and green boxes fig 2 3 2 4 climate input variables and initial conditions climate input variables namely rainfall et0 and air temperature were considered spatially uniform in the application of the model to the gélon catchment due to the lack of data all the initial conditions were set using a warm up approach consisting of a simulation over a period long enough to reach equilibrium kollet and maxwell 2008 in this study we adopted the recursive simulation approach described by ajami et al 2014 the previous hydrological year from 2013 to 2014 was repeated 25 times with constant crop rotations we verified that the equilibrium state was reached after these 25 year long simulations by determining whether the annual simulated variations in water storage at a one year interval were lower than 1 in 95 of the units of each type this warm up process was initiated considering a full saturation of the catchment including a complete filling of the reservoirs to limit the spin up time rahman et al 2016 3 3 model verification to verify the model we considered virtual and real catchments and monitored i each simulator ii the model determinism and iii the conservation of water volumes furthermore the computation time was also analysed 3 3 1 simulator testing for each simulator the agreement between the computer code and conceptual model was verified using simple test cases the verifications were based on a comparison of the simulated and expected values of the variables with the latter obtained from either algebraic equations or reference simulations these tests also allowed us to evaluate the hydrological and agronomic links between all the units as an example the combined testing of the irrigation decision and application simulators appendix c allowed us to simultaneously verify the following the identification of all the re or rs dedicated to irrigation and the links between that water resource and the irrigable sus the consistency between the available water volume water withdrawal volume irrigation water demand and irrigation amount provided to crops and the absence of withdrawal from a water resource not dedicated to irrigation 3 3 2 model determinism model determinism is guaranteed when identical simulations repeated in the same computing environment with unchanged parameterizations initial conditions and boundary conditions result in exactly the same simulated values a numerical test was performed on a sub catchment of the gélon catchment modelled with 341 sus 112 rss 69 gus and 13 res with one of the latter being dedicated to irrigation the test was executed by repeating the same 5 year simulation 1000 times and we assessed whether the water volumes in the gus res and sus and water fluxes in the sus and rss remained unchanged across the whole catchment 3 3 3 water volume conservation water volume conservation is an important criterion in hydrological model verification we monitored the water volume conservation in mhydas small reservoirs at the daily resolution considering the whole catchment in the case of perfect water volume conservation the total volume of all simulated outflows from the catchment equals the total volume corresponding to the variation in the simulated water storage and all simulated inflows to the catchment we monitored the water mass conservation level in the same real catchment as was adopted for model determinism assessment section 3 3 2 model determinism at the daily time step considering that the difference between the above two volumes should remain below 0 001 of the total inflow volume 3 4 model evaluation model evaluation determines the ability to simulate hydrological and agricultural functioning in a real case study basically the evaluation relies on the comparison of simulated variables to available observed or reference data as the primary intention in using mhydas small reservoirs is to quantify the cumulative effects of reservoirs on crop yields and on stream runoff at the catchment outlet we chose these two variables to evaluate the model the evaluation therefore followed two steps the first step involved the evaluation of the model in the simulation of global variables corresponding to the annual fluxes across the entire catchment for which reference data were available for the case study in the second step the model ability to finely simulate the daily stream runoff was analysed using the nash sutcliffe efficiency 1970 calculated as follows 6 n s e q 1 i 1 n q i s q i o 2 i 1 n q i s q o 2 where nse q is the nash sutcliffe efficiency of the stream runoff qi o is the reference stream runoff at the ith time index q o is the mean reference stream runoff and qi s is the simulated stream runoff at the ith time index the closer the value is to 1 the higher the quality of the stream runoff simulation is the efficiency considering the square root of the stream runoff denoted as nse sqrt was also calculated since it assigns a high weight to low values of the stream runoff when nse q is highly sensitive to high flows oudin et al 2006 pushpalatha et al 2012 when applying the model to the gélon catchment the efficiencies were calculated based on the daily stream runoff over the full hydrologic year of 2014 2015 starting on 1 september the daily simulated stream runoff q s i was calculated as the sum of hourly simulated stream runoff for the ith day as we determined that the stream runoff data used as reference data were less reliable between june and october and for stream runoff below the threshold of 0 086 mm d cf section 3 1 2 we also calculated the efficiencies by considering those days when the stream runoff exceeded the above threshold excluding the period from june to october 3 5 numerical explorations the model was then applied to simulate in the gélon catchment two situations that differed in terms of crop allocation and reservoir water management table 3 the objective was to analyse the capacity of the model to predict possible future conditions and assess the potential consequences of different policies in crop and agricultural water management strategies as is commonly achieved in scenario exercises using models in water resource management leenhardt et al 2012 the reference situation represents the current state as simulated for the 2014 15 hydrological year which is compared to the second situation named all re the all re situation was not designed to be realistic but for its illustrative potential in this situation we therefore assumed that all reservoirs of the catchment were used for irrigation purposes and that all agricultural sus within a radius of 500 m around every re were irrigated and cropped with maize the most irrigated crop in the region the all re situation thus differs from the reference situation both in terms of number of reservoirs considered for irrigation and in terms of crops and cropping area 4 results 4 1 model verification 4 1 1 simulator testing model determinism and water volume conservation testing of all the simulators was successful since the variables simulated with the model matched the expected values the results are not presented but are available upon request the model determinism was verified since the simulated variables in terms of the total water storage in the gus sus and res and water fluxes surface runoff in the sus and stream runoff in the rss were strictly identical for all 1000 simulations water volume conservation in the simulations was also verified at the annual scale the error was lower than 0 0001 of the inflow volume 4 1 2 computation time the simulation was performed based on an ubuntu quad core microprocessor at 2 90 ghz with 128 gb of ram and a 32 bit cpu the computation time reached 17 h for a 26 year period in the gélon catchment with a display of the daily global variables in the whole domain and an additional display of all of the variables in each spatial unit 3 per rs and gu 7 per re and 30 per su for the last simulated year which represents 4 7 go 4 2 model evaluation at the catchment level the simulated stream runoff over the hydrological year of 2014 2015 is 102 8 mm table 4 which is only 6 4 higher than the reference stream runoff 96 6 mm the efficiencies of nseq and nsesqrt of the simulated daily stream runoff are 0 32 and 0 26 respectively in regard to the days when the stream runoff exceeds 0 086 mm d between november and may when the reference stream data are considered reliable please refer to section 3 1 2 the calculated nseq and nsesqrt values are both 0 47 these values approaching 0 5 indicate that the model yields nearly satisfactory results not only for high flows in terms of nseq moriasi et al 2015 but also for low flows in terms of nsesqrt oudin et al 2006 over the period corresponding to these days the simulated daily stream runoff matches the reference stream runoff well fig 5 during this period the simulated cumulative stream runoff is 82 6 mm which is 3 3 higher than the cumulative reference stream runoff 80 0 mm according to moriasi et al 2015 an error of less than 5 is considered very good on the basis of all the efficiencies and differences between the simulation and reference data the model applied to the gélon catchment yields acceptable or even good simulations of the hydrology table 5 summarizes the simulated and regionally observed crop yields considering all the crops the area weighted average of the relative root mean square errors across the gélon catchment is 21 4 which is quasi acceptable according to cabelguenne et al 1990 and constantin et al 2015 who considered a difference of 20 between the observed and simulated yields acceptable this performance results from the good performance of the model in the simulation of the sunflower and sorghum yields and the poor yield simulation performance for soybeans rapeseed maize and straw cereals 4 3 numerical experiment results 4 3 1 global variables the annual catchment water balance terms in the two situations are reported in table 4 the simulated irrigation amounts rank as expected with the largest volume occurring in the all re situation due to both the large irrigated area and abundant available water resources the simulated stream runoff in the all re situation was 6 lower than in the reference situation the crop yield varies both between crops within a situation and between the two situations table 6 in the all re situations yields of non irrigated crops i e sunflower are not very different from those in the reference situation 2 since a rainfed crop in the reference situation remains non irrigated in all re crops irrigated on only part of their area in the reference situation are either replaced by irrigated maize or maintained as non irrigated in the all re situation as a result when they do not disappear as for rapeseed and sorghum their yield decreases slightly if they were lightly irrigated e g straw cereals or considerably if they were intensively irrigated e g soybeans regarding maize the yield decrease observed in all re 12 compared to the reference has another explanation in all re the number of reservoirs for irrigation increased and all irrigated surfaces were converted into maize crop plots the increase in the overall volume of water available for irrigation purposes did not compensate for the increase in the total water demand resulting from the increase in the area of irrigated maize hence the decrease in yield 4 3 2 spatially distributed variables mhydas small reservoirs simulates a large number of spatially distributed variables related to the hydrological and agricultural responses of a catchment we illustrate three of them namely i stream runoff ii irrigation water demand and iii reservoir filling rate evolution the stream runoff is simulated along the whole hydrographic network at the rs resolution this allows us to assess and compare the inner catchment variability as shown in fig 7 where the difference in the monthly stream runoff along the hydrographic network between the reference and all re situations in december 2014 and july 2015 is plotted these two months were chosen because they corresponded to high flow and low flow periods respectively in that respect several results can be highlighted the first result is that the relative variation in the monthly stream runoff between the situations at the catchment outlet differs from one month to another and that the variation in the annual stream runoff also differs for example although the simulated annual runoff in the all re situation was lower by 6 compared to the reference situation the difference of monthly stream runoff between both situations was 3 in july and 14 in december the second notable result is that the variation in the stream runoff at the outlet may mask the high variability in stream runoff along the hydrographic network the simulated stream runoff variation was negative in most of the stream reaches fig 7 indicating a lower stream runoff in the all re situation than in the reference situation over the two months analysed this result was expected due to i the higher crop water requirement of maize compared to the straw cereals which is the main irrigated crop in the reference situation and ii the larger water withdrawals in the reservoirs in order to irrigate maize this leads to emptier reservoirs at the beginning of the rainy period and thus to an increase of water interception of runoff and stream runoff by the reservoirs and to a decrease of the stream runoff in the catchment however in july in the western branch of the hydrographic network delimited by a and b in fig 7 the stream runoff was higher 9 than that in the reference situation this counterintuitive result is explained by an increase of the baseflow in the all re situation which is 8 higher in july for certain gus in the southwest of the catchment this increase in the baseflow is first related to the irrigation indeed the absence of irrigation under the reference situation in the northwest of the catchment fig 7 leads to a lower soil water content than that in the all re situation where the soils are cropped with highly irrigated maize the rainfall in july and the subsequent infiltration allows the soil water content to exceed the soil field capacity faster thus triggering larger soil percolation in the all re situation than in the reference however this phenomenon is limited to a small part of the catchment indeed in the rest of the catchment the water amount available for irrigation in the reservoirs is smaller than the demand and the mean soil water content in the all re situation remains lower than that in the reference situation thus at the catchment scale the stream runoff is slightly modified by these changes and driven more by the increasing aet due to the maize crops the irrigation water demand also exhibits inner spatial and temporal variability as shown in fig 7 where the irrigation water demand is plotted for the reference and all re situations and two months corresponding to the beginning june and the end august of the irrigation period these two months illustrate well how the water demand depends on crop requirements and water resource availability in reservoirs which usually decreases with time during the irrigation period the water demand is quite uniform in the catchment for the all re situation because all irrigated fields are cropped with the same crop maize the difference in water demand between june and august relies mainly on this situation in crop water requirements in june the maize was planted a few weeks earlier and the crop water requirement and thus the water demand for irrigation is low in august the crop requirement is large due to the crop development and the high et0 fig 5 as the reservoirs are empty at this time fig 8 the water demand remains high most of the time in the reference situation water demand is slightly more variable than for the all re situation because there are different irrigated crops such as straw cereals soybean and maize the crop development in time and the irrigation period are different from one crop to another one as straw cereals are harvested in july all fields with this crop are simulated with a zero water demand in august for the reference situation fields with black dots in the left map of fig 7 as in the all re situation the temporal variation in water demand for maize fields between june and august also results from the water availability in the reservoirs for instance the simulated water demand for the field in maize indicated by a red circle in fig 7 varies from zero in june to more than 60 mm in august the water volume in the reservoir connected to this field grey line in fig 8 is not large enough in august to meet the crop requirement leading to a permanent high water demand the reservoir filling rate which is the ratio between the volume of water stored and the re capacity also reveals a high spatial and temporal variability fig 8 this finding is explained by the spatial distribution of the crops the different water requirements and cycles of the different crops and the locations and properties of the reservoirs whether a reservoir is used for irrigation or not is the first variation factor of the filling rate between reservoirs either connected or non connected res remain almost full throughout the year as long as they are not applied for irrigation purposes the blue and red curves in fig 8b the type of irrigated crop is the second factor namely in the reference situation where the various crops are irrigated the reservoir levels decrease first in june to irrigate the straw cereal market gardening and soybean crops and again from july to september when the maize and soybean crops are irrigated the orange green grey and black lines in fig 8b while in the all re situation with all irrigated plots cropped with maize the decrease in june is not observed all the coloured lines in fig 8c the type of reservoir connected or non connected is another factor explaining the differences in filling rate when the irrigation water demand is high as that during maize irrigation in the all re situation the connected reservoirs the red and orange lines in fig 8b and c are more likely to become filled because they benefit from both surface and stream runoff from the upstream reach while the non connected reservoirs only receiving surface runoff are less likely to become filled the blue and green lines in fig 8b and c the last factor is the location of the reservoir as illustrated by the difference between two non connected reservoirs reserved for irrigation the black and grey lines respectively in fig 8 in one case the black line the drained area is not large enough to fill the reservoir during the surface runoff period and the reservoir remains almost empty throughout the year regardless of the situation in the second case the grey line the drained area is large enough to support a high filling rate as indicated by the filling rate approaching the reservoir capacity during the rainfall events in late june 5 discussion the first application of the mhydas small reservoirs model to the gelon catchment gave promising results fig 5 tables 4 and 5 the main processes underlying the hydrological and agricultural functioning of the catchment seem to be well modelled however considering the application of the model to other catchments and other agropedoclimatic contexts requires questioning i the availability of the data needed for its application to other real case studies and ii the improvements to the model in terms of the processes represented the two points are discussed hereafter the first point of discussion concerns the data needed to use the mhydas small reservoirs model either to define forcing variables to obtain the spatial representation of the flow domain to parameterise it on the study area or to evaluate it most of the necessary data e g topography hydrographic network soil characteristics nature of crops and meteorological variables may be extracted or derived from generic databases often available throughout europe moreover as this model is built on already proven models and on widely used equations some parameters can be fixed from the literature for example this is the case for the plant growing coefficients or for the k factor for converting reference evapotranspiration to reservoir evaporation this makes it easy to envision the use of the model in catchment areas other than the one we studied however there is no generic database for all model inputs or for all variables used for its evaluation in such cases and when available those data may be derived from local databases specific surveys or local expertise this is particularly the case for data on reservoirs there is currently no database at the european or even the french level that allows a complete and high quality description of small water reservoirs the availability and estimation of the small reservoirs properties and the water use from the reservoirs have remained a real challenge regardless of the approaches used in catchment hydrological modelling with reservoirs hughes and mantel 2010 lowe et al 2005 this has motivated the development of remote sensing methods to estimate position and capacity of small reservoirs over large areas ogilvie et al 2016 in france the collective water management structures recently set up in deficit areas organismes uniques de gestion collective de l eau are beginning to create a type of database gathering characteristics and water uses of small reservoirs databases describing agricultural practices are also incomplete either in terms of geographical location or in terms of content as explained in leenhardt et al 2010 2020 therefore this requires the implementation of specific acquisition methods for example as presented for cropping systems by murgue et al 2016 and rizzo et al 2019 it is clear that the lack of generic databases for some of the necessary variables to use or evaluate the model makes using the model more difficult however this constraint is not specific to mhydas small reservoirs and has been encountered by other modelling approaches dealing with the cumulative effect of small reservoirs the quality of the data used also guarantees the predictive quality of the model and the reliability of the model assessment the use of indirect acquisition methods necessarily introduces inaccuracies either because of the quality of the expertise rizzo et al 2019 or because of the method itself for example in our case study we did not manage to meet all the owners of the reservoirs absences or refusals so that the data for some reservoirs correspond to hypotheses based on our observations or on the expertise of neighbours however the existence of generic databases does not exclude the need to examine the quality of the data included in them for example in the present study although we had databases providing stream flow meteorological data and crop yield values we were only able to access stream flow data at a nearby station located within the same basin but outside the gélon catchment while meteorological data and crop yield values respectively were at a resolution that was too low to obtain internal spatial variability on an 8 km2 grid and averaged over the entire gers department these spatial discrepancies necessarily affect the quality of the data more intensive field work for example by monitoring flows at the gélon outlet or by obtaining yield values from agricultural cooperatives or traders who collect crops in this sector would have enabled a better evaluation of the model s performance the second point of discussion is about the way to improve the modelling of processes in mhydas small reservoirs in particular processes directly affecting the reservoir regarding this point the modular design of the mhydas small reservoirs model under the openfluid platform easily allows adding or improving simulators in the current version of the model some processes are neglected this is the case for infiltration of water from the reservoirs to the underlying groundwater or conversely for the discharge of groundwater directly to the reservoirs neglecting these processes appeared to be acceptable in the gélon catchment given the characteristics of the reservoirs and their connection to the groundwater however depending on the pedological and lithological contexts and the properties of the reservoirs in particular the hydrodynamic properties of the reservoir bed exchanges between the reservoir and the groundwater can be dominant processes in the hydrological dynamics of the reservoir bouteffeha et al 2015 modelling the exchanges would therefore improve the model in its ability to simulate a diversity of contexts the modelling could be done simply by considering the differences in water levels between the reservoir and groundwater this type of relationship is reported to well predict the dynamics of exchanges in various contexts sharda et al 2006 another improvement of the model is in the modelling of the water management rules of the reservoirs indeed the cumulative hydrological effect of reservoir networks cannot be explained solely by the geometric characteristics of the network density in terms of number of reservoirs volume or surface area the management rules of the reservoirs which sometimes differ from one reservoir to another appear to be an important factor in this effect habets et al 2018 hughes and mantel 2010 in the present case study the sharing of available water in a reservoir is modelled by a fairly standard approach by considering that the water withdrawn is distributed to the irrigated field proportionally to the water demand but other priority rules could be considered priority could be given for example to crops providing high financial incomes we could also consider defining rules based on short term weather predictions for actual water management rules being modelled within a specific simulator the modular design of the mhydas small reservoirs model will be a clear asset to allow various water management modalities 6 conclusions the mhydas small reservoirs model has been developed to understand and predict the local and cumulative hydrologic and agricultural effects of a reservoir network in an agricultural catchment hydrological models are already available to assess the cumulative impact of reservoir networks compared to these models the originality of mhydas small reservoirs lies in two of its features the first is that it integrates processes related to the three major components of the catchment s agro hydrological functioning hydrology crop growth and water management decisions the second feature is that it explicitly represents the main elements of the agricultural catchment the plot the reach the reservoir and the water table and the hydrological and agricultural relationships between these elements in addition the model distinguishes between reservoirs according to their connection to the hydrographic networks in doing so it allows the simulation of both local effects in the immediate environment of each reservoir and cumulative effects on overall yields table 6 and flows fig 6 numerical verification of the model was successful the first application of the model to a 19 km2 catchment gave promising results in terms of stream runoff and crop yield simulations however the evaluation and validation of the model are incomplete the model could be improved in two directions the first concerns its validation with an analysis of the model performance to simulate the variables for which it was intended such as stream runoff crop yields and water withdrawals and availability in small reservoirs model validation could also gain from its application to catchments where comprehensive reliable and distributed data sets such as water tables stream runoff and crop yield data are available based on in situ measurements and observations the second direction would be to perform a sensitivity analysis in particular a sensitivity analysis of the reservoir characteristics and of the parameters associated with water dynamics modelling in small reservoirs could be helpful when parameterizing the model in future applications thus the mhydas small reservoirs model could potentially be adopted by land use planners and water managers to assist them in their decisions regarding new small reservoir projects in catchments or management of the water stored in reservoirs software and data availability mhydas small reservoirs runs with the openfluid platform openfluid is a software environment for modelling and simulation of complex landscape systems the documentation and versions of openfluid platform can be found on the openfluid site at www openfluid project org a dedicated github workspace is also available at https github com openfluid openfluid the github workspace dedicated to mhydas small reservoir is available at https github com umr lisah mhydas small reservoirs declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests the authors report financial support was provided by onema now ofb france and by région occitanie france acknowledgements this work was financed by a phd scholarship from the french occitanie pyrénées méditerranée region and the french national research institute for agriculture food and environment inrae a part of this work was financed by the french biodiversity agency office français pour la biodiversité the authors thank the compagnie d aménagement des coteaux de gascogne cacg and meteofrance for access to their databases we would like to thank jean christophe fabre openfluid team leader for his help and contribution to the development of the mhydas small reservoirs also special thanks to romain lardy marie estienne manuel chataigner and ekaterina ferry zadonina for their help in the modelling work to koladé akapko victor giffone and lisah technicians sébastien troiano david fages and olivier huttel for facilitating the in situ data collection and to marie lefrancq for providing hydrological data appendix a simulation rules used for farmer management decisions the farmer management decisions considered in the model include tillage sowing harvest and irrigation the decision rules adopted to simulate these technical operations are described below the variables employed as indicators are mentioned between brackets a tillage day occurs during the tillage period temporal window according to the soil type when the soil water content is favourable i e this depends on the weather conditions antecedent cumulative rainfall and soil conditions soil water content a sowing day may occur on the first day of the simulation or after the harvesting period which depends on the weather conditions antecedent cumulative rainfall and minimal temperature possible sowing period temporal window according to the crop type and precocity class and soil conditions soil water content a harvesting day is simulated either when the crop is mature crop development stage or before poor soil and weather conditions occur antecedent cumulative rainfall and soil water content which could result in soil damage depending on the development of the crop and the weather conditions previous rainfall and rainfall forecasts the water demand for irrigation may be zero or have a non zero fixed value this fixed value depends on the crop the soil and the irrigation equipment it is a model parameter e g 30 mm for maize in the gelon catchment application the volume of water actually withdrawn and delivered to the cultivated field is conditioned by the availability of the water resource see section 2 4 2 the farmer s water demand is calculated at a time step depending on the farmer s equipment constraints the time step is a model parameter e g 6 or 7 days in the gelon catchment application depending on the field appendix b description of the mhydas small reservoirs simulator number nb name model component spatial unit type and main simulated variables of every simulator constituting mhydas small reservoirs the model component refers to the integrated model component namely hydrology hydrol crop growth crop or crop and agricultural water management water manag nb name of the simulator model component unit type main simulated variables 1 water atm surf evapotranspiration su files hydrol and crop su reference evapotranspiration 2 water atm surf evaporation re files hydrol re reference evaporation 3 water atm surf rain su files hydrol su rainfall 4 water atm surf rain re files hydrol re rainfall 5 energy atm surf t temperature crop su mean air temperature 6 energy atm surf t temperature min crop su minimum air temperature 7 water surf ecological flow rs re mean annual discharge water manag re ecological flow 8 crop surf practices su decision murgue crop and water manag su farmer management decisions sowing day tillage day harvesting day irrigation day and irrigation water demand 9 crop surf practices su application murgue crop and water manag su application of farmer management decisions sowing day tillage day harvesting day irrigation day and irrigation water demand 10 water surf sz abstraction priority wp decision order water manag wp a priority order for irrigation 11 water surf withdrawal irrigation wp prorata water demand crop and water manag wp a available water for irrigationtotal irrigation water demandwater withdrawalirrigation 12 water soil crop surf uz runoff cropsoilwaterdynamics transfer su storage non connected re horton hayami aqyield water balance crop and hydrol su infiltrationcrop growthevapotranspirationpercolationsurface runoffsoil water contentcrop water requirement re overflowwater storageevaporation 13 water soil surf uz percolation evapotranspiration su soil swat hydrol su evapotranspirationpercolation 14 water surf sz storage baseflow gu storage discharge function hydrol gu water storagedischarge and baseflow 15 water surf transfer rs storage connected re hayami water balance hydrol rs stream runoff re overflowwater storageevaporation 16 water surf variable surface re bathymetric relation hydrol re water surface area a wp withdrawal point corresponds to a water resource rs or re dedicated to irrigation appendix c main parameters of the mhydas small reservoirs model list of the main mhydas small reservoirs model parameters given by spatial unit type for each parameter the spatial unit type the model relying on it a description of the parameter with values of the non distributed parameters and the origin database are listed bold and italicised numbers indicate the number of the simulator as referenced in appendix b that relies on that parameter unit type model component parameters data sources used in the gélon application su agricultural crop crop type 8 12 land parcel identification system of 2015 ign 2015 crop growth potential root growth coefficient evaporation coefficient and sum of the growing degree days at the maturity and flowering stages the complete list of aqyield parameters can be found on the maelia website http maelia platform inra fr donnees donnees agricoles liste des cultures 12 table of crop cultivar characteristics provided by breeders and aqyield calibration constantin et al 2015 su non agricultural hydrol type of land use 12 13 land use inventory of 2012 mtes 2012 grassland root depth 0 80 m 13 moreno et al 2005 forest root depth the maximum soil depth 13 lewis and burgy 1964 algayer et al 2020 su crop and water manag agricultural sus technical itinerary according to the type of crop soil and irrigation equipment 8 irrigation equipment 8 gaudou et al 2016 murgue et al 2014 therond and villerd 2020 field surveys su hydrol soil minimum infiltration capacity coefficient 12 soil maximum infiltration capacity coefficient 12 and shape coefficient 12 mishra et al 2003 fernández pato et al 2016 sensitivity analysis soil maximum infiltration capacity bulk density clay rate potential maximal available water content and thickness 12 13 regional pedological databank party et al 2016 rs and su hydrol manning m s 1 0 05 su 0 10 rs 12 15 chow 1959 celerity m2 s 1 0 045 su 0 49 rs 12 15 diffusivity m s 1 500 su and rs 12 15 iteration number in hayami kernel calculations 100 12 15 moussa et al 2002 re crop and water manag irrigated plots 10 bd cacg ougc ddt completed by field surveys re hydrol and water manag evaporation coefficient 0 6 2 neitsch et al 2011 dead volume of the reservoir 0 25 of the total capacity 11 therond and villerd 2020 minimum flow 10 of the interannual flow 7 lema 2006 gu hydrol reference flow m2 s 1 5 365 10 8 14 divisor parameter 0 05 14 exponential parameter 5 66 14 flow recession curve analysis 
25588,research on the uncertainty of land use cover change lucc models is still limited through this paper we aim to globally characterize the structural uncertainty of four common software packages ca markov dinamica ego land change modeler metronamica and analyse the options that they offer for uncertainty management the models have been compared qualitatively based on their structures and tools and quantitatively through a study case for the city of cape town results proved how each model conceptualised the modelled system in a different way which led to different outputs statistical or automatic approaches did not provide higher repeatability or validation scores than user driven approaches the available options for uncertainty management vary depending on the model communication of uncertainties is poor across all models keywords uncertainty lucc modeling ca markov dinamica ego land change modeler metronamica 1 introduction uncertainty is inherent in spatial analysis because of the need of abstraction to represent any of the earth s characteristics or processes through a map or a gis procedure it is also inherent to any analysis that involves human understanding of any real world process we understand uncertainty as an indicator of the degree of distrust of the images and concepts of the real world that we are using castilla and hay 2007 this uncertainty must be carefully examined to be aware about the limitations of our analysis and studies land use cover change lucc models have many sources of uncertainty which are difficult to disentangle uusitalo et al 2015 altogether they are known as model output uncertainty refsgaard et al 2007 klein goldewijk and verburg 2013 or the uncertainty cascade refsgaard et al 2013 notwithstanding several authors have tried to classify them in different groups van asselt 2000 walker et al 2003 refsgaard et al 2007 2013 matott et al 2009 klein goldewijk and verburg 2013 garcía álvarez et al 2019 mainly differentiating the following types of uncertainty epistemological uncertainty the uncertainty that comes from the delimitation and conceptualization of the problem to be modelled when strictly referring to the uncertainty of the way a problem is conceptualized in a model several authors talk about structural uncertainty ferchichi et al 2017 brown et al 2021 specifically refer to model paradigms when analysing model structures that lie in a very different conceptualization of the systems to be modelled model technical uncertainty the uncertainty arising from the computer implementation of the model concerning not only the model algorithm but also the data formats resolution and other issues it is related to epistemological uncertainty process variability uncertainty the uncertainty that comes from the different ways a system can evolve in the future input uncertainty the uncertainty that comes from the data used in the model and its ability to represent the earth surface and or its characteristics parameter uncertainty the uncertainty associated to the values at which the different model parameters are calibrated model operation uncertainty the uncertainty that arises from the accumulation and interaction of uncertainties propagated through the model these sources of uncertainty in lucc modelling exercises have been addressed widely in literature many papers assess the output uncertainty of specific exercises memarian et al 2012 ligmann zielinska 2013 whereas others focus on specific sources of uncertainty like parameter uncertainty dietzel and clarke 2004 conway 2009 garcía et al 2011 van vliet et al 2013 houet et al 2015 confalonieri et al 2016 grinblat et al 2016 liao et al 2016 or process variability uncertainty kok and van delden 2009 verburg et al 2013 alexander et al 2015 maier et al 2016 less common is the research about epistemological uncertainties of lucc models and specifically about the models structural uncertainty elsawah et al 2020 some studies address specific topics related to this issue like the different procedures to calculate change potential and change allocation riveira and maseda 2006 lin et al 2011 pérez vega et al 2012 camacho olmedo et al 2013 shafizadeh moghadam et al 2015 ferchichi et al 2017b propose a framework to quantify structural uncertainty of lucc models based on probabilistic theory and sensitivity analysis however there is a lack of studies that characterize the overall structural uncertainty of available lucc model software packages and analyse the tools and options that each model offers for uncertainty management and communication today there is a large availability of standard model software packages to simulate different spatial dynamics camacho olmedo et al 2018b although they are considered too simple by some users to model complex phenomena their use is ever increasing wickramasuriya et al 2009 chaudhuri and clarke 2013 leija et al 2021 and they are tools used in practice for real policy cases barredo et al 2003 van delden et al 2011 eastman and toledano 2018b guzman et al 2020 information about the uncertainty associated to the use of these software packages is not usually widespread and no paper analysing their structural uncertainty and their approaches to uncertainty management has been found in the literature however knowledge about these aspects is required to improve their understanding and characterization in addition it will help to engage planning agents and spread their use in real world problems solving yeh and li 2006 batisani and yarnal 2009 sohl et al 2016 through this paper we aim to fill the previous research gap by characterizing and comparing four standard lucc model software packages model comparison has been proposed by several authors as a way to assess the structural uncertainty kelly et al 2013 uusitalo et al 2015 brown et al 2021 and has been usually employed as a useful approach to better characterize and understand the available software packages garcía et al 2012 toro balbotín 2014 mas et al 2014 aguejdad et al 2016 camacho olmedo et al 2018b through the comparison we will answer the following research questions which are the sources of uncertainty that come from the different model structures how does each model manage and communicates uncertainty we will analyse the model structure of each software and the options that they offer for uncertainty management and communication through a qualitative comparative analysis of the models additionally we will assess the potential uncertainty associated to the model structure by applying the four compared models to the same study case in the following section we explain the methodological approach of this paper in detail 2 materials and methods 2 1 model software packages we compared four standard pattern based lucc model software packages ca markov dinamica ego land change modeler as included in the terrset 2018 version and metronamica below we provide a short description of each model a graphic representation of each one is provided in the annex 1 annex 2 includes a comparative table to evaluate the differences among models the models have been selected based on the authors deep experience with them mas et al 2010 2011 2014 camacho olmedo et al 2018a garcía álvarez 2018 and wide use among the lucc modelling community santé et al 2010 kamusoko 2012 eastman and toledano 2018b ferreira et al 2019 practical experience with the models is essential to fully understand the model conceptualizations and structures and their limitations in real case applications the wide use of these models among the lucc community guarantees the utility of the results here delivered as they help to characterize standard tools used by many users for different purposes either as part of scientific studies or real case applications in addition as they rely on common lucc modelling theories we can draw general lessons from their analysis and comparison which can be applied to any lucc model ca markov eastman and toledano 2018a is a modelling tool which makes use of several procedures integrated in terrset previously idrisi a software of geospatial analysis and modelling the quantity of changed pixels is determined by a markov matrix whereas the location of those pixels is performed through the combination of a series of suitability layers a contiguity filter and a multi objective allocation procedure dinamica ego soares filho et al 2002 2009 rodrigues and soares filho 2018 is a free environmental modelling platform that includes lucc modelling methods due to the flexibility that it offers there is a wide variety of ways to set up a lucc model as common practise markov chains and weights of evidence woe are used for the estimation of the quantities and change potential change allocation is performed through a couple of stochastic cellular automata functions patcher which produces new patches and expander which simulates the growth as expansion of previous patches land change modeler lcm eastman 2015a eastman and toledano 2018b is a constrained lucc model which is also integrated in terrset the change potential calculation is empirically obtained through three possible methods neural networks logistic regression and a machine learning algorithm simweight the change allocation is performed through a multi objective allocation procedure whereas the quantity of change is estimated by means of a markov matrix metronamica riks 2012 van delden and vanhout 2018 is a constrained cellular automata model based on the theory developed by white and engelen in the 90 s white and engelen 1993 white et al 1997 land use is allocated according to a competition for space principle based on the following inputs interaction rules between land uses human behaviour accessibility land suitability environmental conditions and zoning planning demands can be defined externally or by means of a regional model simulating job and population dynamics 2 2 model comparison model structures were compared according to the following aspects change potential calculation including the explanatory factors considered by each model quantity of changes estimation allocation of changes pattern simulation and validation and outputs although only the last one specifically relates with uncertainty management and communication these questions have been reviewed for all other aspects as well regarding the extent to which the models include tools or allow user intervention for uncertainty management the comparison followed a both qualitative and quantitative analysis of each software fig 1 the qualitative analysis complements the limitations of the quantitative analysis to assess sources of uncertainty that are not usually addressed in the literature elsawah et al 2020 through the qualitative approach 2 2 1 we compared the way in which each model conceptualizes the modelled system and the available options they offer for uncertainty management through the quantitative approach 2 2 2 we compared model outputs for the same case study city of cape town to assess the differences that come from the model structure the case study is part of the urban modelling practice accordingly results from our analysis may be affected by the specificities of urban dynamics urban growth is usually simulated through a common set of driving forces accessibility physical suitability zoning and neighbour interactions nonetheless general understanding of the models options for uncertainty management and system conceptualization can be also applied to other types of application the study case is explained in detail in annex 3 it consisted of a model set up with a spatial resolution of 100 m grid cells for the city of cape town and the period 1990 2013 2 2 1 qualitative model characterization we reviewed and characterized the structures and features of the different software packages this includes among other items system conceptualization available methods for quantity of changes estimation change potential calculation change allocation uncertainty management validation and communication of results as well as the theory behind those methods this information was obtained through the model s documentation and based on the deep experience of authors with the analysed software mas et al 2014 2018 paegelow et al 2014 2018 camacho olmedo et al 2018b garcía álvarez 2018 2 2 2 model outputs assessment the four models were calibrated for the same case study following the approach described in annex 3 outputs generated by each model were then analysed and compared this allowed to analyse which differences between simulations came from the use of different model structures according to this criterion the higher the consensus among model outputs the more certain is the simulation simulation success was also measured by comparing each simulation with reference data through common lucc validation indices and metrics kappa simulation van vliet et al 2011 and spatial metrics mcgarigal 2018 see below the higher the agreement between reference and simulated data the more successful the simulation is considered for the comparison of output maps we differentiated between soft classified and hard classified maps camacho olmedo et al 2013 the first ones which we will also refer to as change potential cp maps show the probabilities of change to a specific category hard classified maps which are the final land use maps simulated by the models and we refer to as simulation results assign every pixel to a specific category and therefore show states instead of probabilities agreement between cp maps obtained through different methods of change potential calculation was measured through the spearman correlation coefficient incorporated in the r package enmtools warren et al 2021 to this end transition potential tp maps to the same category in dinamica and lcm were aggregated and compared to the land use potential lup maps for that category in ca markov and metronamica lup maps show the probability of change to a specific category e g b whereas tp maps show the probability of a specific transition e g a to b happening to make both types of maps comparable areas of ca markov and metronamica lup maps not considered in the transitions of dinamica and lcm tp maps were masked hard classified simulated outputs from different models were compared by means of standard cross tabulation techniques kappa simulation ksim and a set of spatial metrics calculated at the class level number of patches patch mean size and standard deviation and proportion of like adjacencies ksim evaluates the agreement between the changes simulated by each model compared to the agreement that is expected by chance van vliet et al 2011 spatial metrics characterize the shape and size of patches and the way they are allocated on the map that is the maps patterns a patch is a group of neighbour pixels with the same value botequilha leitao et al 2006 the proportion of like adjacencies inform about the aggregation or cohesion between patches of the same class mcgarigal 2018 that is how aggregated or fragmented are the patches that make up a class each model was executed 20 times under the same parameters and conditions to assess the intra model output variability only outputs from the first executions were employed for the previous assessments whereas outputs from the remaining 19 executions were only employed to assess the agreement between model executions outputs from different model executions show low variability and do not significantly alter the pattern logic of the simulated cp areas or luc changes thus single outputs are enough to compare the output uncertainty caused by different model structures agreement between change potential maps obtained through the same production method for each model was assessed by calculating the average standard deviation of the pixel values across the 20 outputs intra model agreement between simulations was assessed through ksim and cross tabulation as in the inter model comparison 3 results 3 1 change potential calculation change potential is calculated in the four compared models based on the relation defined or found between a set of factors or drivers of change and the luc changes that relation can be defined by the user in the case of expert driven models ca markov metronamica or calculated through automatic or statistical approaches as defined by van vliet et al 2016 in the case of data driven models dianmica ego lcm in the second case models are trained until the best statistical relation between explanatory factors and luc changes is obtained in the first case models are trained based on user criteria which is usually driven by validation metrics such as kappa or quantity and allocation dis agreement indices although we can obtain the same relation between factors and luc changes through any of the methods implemented in the four software packages each method entails a specific workflow for the combination of factors and produces a specific type of change potential map depending on the method there are also some restrictions regarding the number or type of factors that can be taken into account accordingly the selected methods and the way they have been implemented are closely connected with the model conceptualization 3 1 1 luc and lucc explanatory factors only metronamica puts restrictions regarding the number and type of factors considered it only comprises four factors neighbourhood interactions accessibility suitability and zoning although the user can choose how many base maps he or she likes to include in the different factors and even rule out some of them by modifying the transition potential formula that guides the change potential map creation the metronamica factors may be dynamic the model also includes a random component in the change potential map creation which introduces variability between different cp maps produced by the model yellow cell in table 1 it is possible to run the model in a deterministic way as well random factor 0 although the developers do not recommend this due to the inherent uncertainty in land use dynamics ca markov is not able to work with dynamic factors which makes the model more uncertain when simulating processes that are explained by different or variable factors along time on the other hand dinamica ego and lcm admit any type and number of factors including the dynamic ones notwithstanding for lcm when using logistic regression as the change potential calculation method the model requires factors that are linearly related to the potential for transition eastman 2015b to this end lcm includes tools for factors transformation however they transform the factors based on luc data assuming a temporal stationarity i e the continuation of past trends to the future which may not be real 3 1 2 two different types of change potential maps dinamica ego and lcm produce transition potential tp maps camacho olmedo et al 2013 which indicate the potential of a set of defined land uses to transition to another set of land uses although transitions can take place from any class to every other class on tp maps they are usually restricted to the more meaningful as it is difficult to find statistically significant relationships between a few luc changes and a set of factors in these cases the found relationships may be significantly affected by errors in data or the presence of one off events through expert driven approaches models produce land use potential lup or suitability maps camacho olmedo et al 2013 2018a they indicate the preference of each land use class to occupy any location of a study area based on a set of drivers defined by the user which in practice allows any transition to happen at any point in time they do not necessarily require of historical data to be obtained aguejdad 2021 although camacho olmedo et al 2013 point out how users create these maps based on the understanding of distribution of the considered land uses in time which implicitly includes the understanding of previous past changes for our study case correlation between change potential cp maps is independent of the type of maps compared the ca markov and metronamica lup mas show the highest correlation with the tp maps of lcm whereas tp maps automatically produced by dinamica ego show the highest correlalation with metronamica lup maps table 1 3 1 3 methods for change potential calculation each model calculates the change potential though different procedures fig 2 which are closely related to the way each model has been conceptualized lcm offers three methods for transition potential map creation neural networks and simweight based on machine learning techniques and logistic regression the three methods trust automatic or statistical procedures as defined by van vliet et al 2016 to find out the relation between changes and drivers of change to this end they use a sample of pixels as training and then in the case of neural networks and simweight the inferred relations are compared to a set of validation pixels as far as the analysis sample varies with each model run the inferred relations change with the sample as well kim 2010 although this variation is low table 1 the logistic regression procedure allows the user to employ all the pixels in the analysis and therefore avoid this possible uncertainty dinamica ego makes use of the weights of evidence woe to calculate the change potential maps although the model also admits external maps produced through other methods to bypass the incorporated methods the woe is a bayesian method that relates the presence of a given set of factors with the probability of land use change eastman et al 2005 soares filho et al 2013 developed a genetic algorithm that allows the user to refine the change potential calculated through the woe method the software also allows the user to manually edit the obtained weights to account for some of the uncertainties that the data calibrations periods etc can entail this manual adjustment may have a great impact on the obtained maps in our modelling exercise change potential maps obtained with automatic and adjusted weights showed big differences table 1 ca markov does not integrate a specific method for change potential calculation although the model help advises to employ the multicriteria evaluation mce implemented in terrset as the standard tool for this purpose when using this method the model will rely on user or expert knowledge becoming very dependent on the uncertainty of that knowledge in this regard in this method he decides which factors to use and how they should be transformed and combined he even assigns a weight to every factor in metronamica the change potential map is calculated through a formula that combines a series of input data manually adjusted by the user the user can also edit the formula which gives him the chance to account for the model structure uncertainty however they can also introduce new sources of uncertainty by doing so with the exception of dinamica ego cp maps produced through the different methods implemented by each model show very high correlation among them and lower correlation with cp maps produced by other models table 1 in addition there is not a clear correlation between cp maps based on their production method manual vs automatic statistical approaches accordingly the dinamica ego cp maps automatically produced through the woe show lower correlations with cp maps of other models than the cp maps obtained after the manual modification of the obtained weights 3 2 quantity of changes estimation ca markov dinamica ego and lcm calculate the simulated quantities from markov chains they indicate the probability of every category to transition to every other class and to remain the same camacho olmedo and mas 2018a aguejdad 2021 thence they make the modelling process to focus on transitions instead of land use states through this approach it is difficult to model systems where the land use dynamics change frequently and that do not follow historical patterns of growth mas et al 2018 paegelow 2018 aguejdad 2021 that is systems where the transitions between land uses are not always the same and at similar intensities in addition markov chains usually calculate transition probabilities from past changes extracted by comparing luc maps at two different time points camacho olmedo and mas 2018a in these cases the uncertainty of input maps will be transferred to the obtained probabilities nonetheless the three models allow the user to manually modify the obtained markov probabilities from input data and therefore to account for some of the uncertainties associated to input data however this step may not be easy for some users the markov probabilities tool implemented in terrset and used in the context of ca markov allows to consider in the uncertainty of input maps in the quantity of change estimation however this introduces important modifications in the calculated quantities of change mas et al 2014 accordingly this method can introduce more uncertainty than the one for which it finds an answer metronamica does not include any method for quantity of changes estimation the user enters the total number of cells persistence changes that will make up each function class the tool the user employs to decide the total number of cells will determine the uncertainty of this data in addition the transitions modelled for every category will rely on the settings of the interaction rules in the ca component if the user does not introduce high values of inertia for the existent pixels of the function classes some incongruent transitions can take place moreover since the user cannot enter any information about the quantities of the vacant classes their final size will also rely on the user calibration metronamica is therefore the most flexible model for modelling different types and speeds of change however because of this high level of flexibility the ability of the user to replicate the dynamics of change is critical when calibrating the model and simulating the correct quantities of change all four models calculated different quantities of change despite being based on the same reference data table 2 small differences in the way markov probabilities are calculated and used to calculate the number of pixels explain the disagreements between ca markov dinamica ego and lcm metronamica s differences are explained by its specific method and the user calibration 3 3 allocation of changes lcm ca markov and metronamica follow a deterministic procedure for change or land use allocation on the contrary dinamica ego includes a stochastic algorithm of change allocation that simulates different changes each time that the model is run table 3 and fig 3 lcm and ca markov make use of a multi objective land allocation mola mechanism it selects those pixels with the highest potential to change solving conflicts between different objectives based on the minimum distance to ideal point rule eastman et al 1995 metronamica follows a similar procedure it selects the pixels with the highest potential to change for every category allocating first the demands of the function classes and then the pixels of the vacant classes although the process is deterministic the random factor added to the change potential maps allows transitions to take place in areas less likely to change ca markov includes a contiguity filter as part of the allocation process forcing pixels with lower potential values to be simulated as change if located next to previous pixels of the simulated category in lcm a zoning layer can be included in the allocation of changes step multiplying the values of the change potential maps the allocation functions of dinamica ego patcher and expander include a cellular automata component favouring the simulation of pixels adjacent to land use classes of the same category they also include a stochastic component to account for the unpredictability of human decision making which however is not easy to control it is associated to a specific prune factor which can be managed by the user but also to a monte carlo approach of land use allocation and the parametrization of the expander and patcher functions garcía álvarez 2018 to reduce this stochasticity to a minimum the user must choose a prune factor of 1 define clear and different transition potential values for the candidate cells and parametrize the expander and patcher functions according to the pixel size in our case study the stochasticity was relatively high in 20 model executions only 7 6 of the pixels simulated as change were allocated in the same place with 34 of the changing pixels allocated in the same place less than 10 times table 4 and fig 3 simulated changes from each model usually show more agreement with the outputs from other models than with reference maps table 4 ca markov and metronamica are the models that simulate the most similar changes on the contrary ca markov and dinamica ego are the models simulating more different changes these differences cannot be explained by differences between change potential maps as there is not a direct relation between correlation of change potential maps and the agreement of simulated changes tables 1 and 4 3 4 pattern simulation ca markov dinamica ego and metronamica include a cellular automata component to replicate the real luc pattern this is lacking in lcm which however allows to include a dynamic factor of distance to any of the map categories lcm can infer from this variable the relation between luc changes and the distance to cells of the other categories however this is calculated automatically by the model and therefore dependent on input data uncertainty because there is no user intervention possible there is no direct control of the modelled pattern this ca component or attraction factor is especially relevant to simulate urban dynamics such as the ones of the city of cape town as new urban areas usually grow on the urban edges usually in the search for economies of agglomeration white et al 1997 for our modelling exercise although lcm simulated a general pattern very similar to the reference landscape the simulation includes many small and scattered patches that do not fit the common pattern associated with land uses like urban residential even if we can check a visual coherent pattern in fig 4 the spatial metrics reveal how lcm was the model that simulated the most new patches of urban residential 120 opposite to 7 new patches of change between the reference maps of 2002 and 2013 table 5 in ca markov the user controls the compactness of the simulated pattern through a user defined contiguity filter it up weights the land use potential values of pixels close to pixels of the considered class and down weights those which are far from this camacho olmedo and mas 2018b it applies the same compactness logic to all modelled classes in our study case urban residential and urban informal changes were simulated according to the same pattern patches of both classes became more compact with a reduction in the total number of patches and a bigger mean path size table 5 however urban informal pattern is more scattered large increment of the number of patches and a lower mean patch size than the urban residential one metronamica allows to define neighbourhood interactions between all classes of the map and each function class making it possible to get a specific pattern for each class solving the previous limitation of ca markov the user can also play with the weight of self attraction rules and the random factor to facilitate the production of new patches in metronamica however both ca markov and metronamica faced difficulties when trying to simulate changes as new patches in the two models all changes were simulated as infill of existing patches or as an organic halo from them fig 4 dinamica ego simulates the desired pattern through two different functions expander and patcher which can be used together or independently the expander function simulates changes as expansion of previous patches of the same use whereas the patcher function simulates changes as new patches disconnected from previous pixels of the same use the user must indicate to the model the size and shape of the new patches for each modelled transition through three parameters mean variance and isometry accordingly dinamica ego is the model that gives more control to the user regarding pattern simulation for our study the simulated landscape of dinamica resembled quite well the reference landscape table 5 being maybe the best model when it comes to this point 3 5 tools for validation uncertainty management and communication directly or indirectly all four models offer the user a wide range of tools to test the accuracy and uncertainty of the simulation results this is possible in metronamica through the complementary map comparison kit software and in ca markov and lcm through terrset the software where these models are included the dinamica ego platform is directly able to calculate a wide range of validation measures metronamica is the only model that explicitly includes a tool for scenario management it also allows to inform about the stochasticity associated to single run simulations dinamica ego because of its flexibility can be designed to produce similar results ca markov and lcm are more constrained to this end lcm is only able to simulate business as usual scenarios eastman and toledano 2018b in ca markov different model applications must be set up to account for different scenarios all four models provide manuals and tutorials that describe the models methods and explain how to use them properly soares filho et al 2009 riks 2012 eastman 2015b however information about how to validate or assess the uncertainty of the modelling exercises is usually lacking in addition none of the four models is open source which limits the user development and understanding of the software nonetheless metronamica foundations are deeply addressed in the literature white and engelen 1993 white et al 1997 and described in detail in the model documentation riks 2012 facilitating the replication of the model by other users 4 discussion each of the four model software packages compared conceptualized the systems and processes to be modelled in a different way which resulted in different outputs these sources of structural uncertainty are discussed in detail in section 4 1 in addition all models provide different methods or tools to deal manage and communicate the possible uncertainties of the modelling exercise they are discussed in section 4 2 part of the results here discussed are limited by the study case selected for the model comparison model outputs were only compared for one specific case and one historic period analyses making use of different historic periods and study areas could provide complementary results in addition we have only judged the models success based on their quantitative performance with respect to a historic period of reference assessing the plausibility of model parameters and results based on expert judgment or other strategies could also provide complementary conclusions 4 1 structural uncertainty how a system is conceptualized in a model comes with an important source of epistemological uncertainty which may depend to a great extent on the purpose or objective for which the model was initially developed models developed for a specific purpose and application can include a structure that suit the simulated processes best for standard models like the ones assessed in our application the sources of structural uncertainty can be bigger the models assessed in our study have all developed towards generic modelling frameworks although they might have been developed for a specific purpose originally over time they have been adapted to be able to simulate a wider range of dynamics lcm and dinamica ego were initially developed to simulate deforestation dynamics soares filho et al 2002 eastman 2015a but successfully simulated urban processes in our study case and have been applied with success in other domains eastman and toledano 2018b rodrigues and soares filho 2018 in this regard they do not limit the number or nature of the factors considered which makes them very flexible tools that is also the case of ca markov that was not specifically developed for any application but has been successfully applied to many domains eastman and toledano 2018a metronamica based on the model proposed by white and engelen to simulate urban dynamics white and engelen 1993 white et al 1997 has been also applied to simulate non urban dynamics van delden and vanhout 2018 navarro cerrillo et al 2020 however the model has been specifically designed to simulate urban and regional processes in detail as revealed by the four factors that model considers accessibility neighbourhood suitability and zoning they are the common drivers of urban change but may be limited to simulate dynamics related with farming or natural vegetation in ca models such as ca markov dinamica ego or metronamica the behaviour of a complex system is explained by the relation between every of its components conceptualized as cells and their neighbourhoods if this assumption does not lie on the base of the dynamics of the modelled system these models will probably fail when modelling the intended dynamics this logic fits well with urban processes like the ones of cape town as well as with other ones such as deforestation barredo et al 2003 white et al 2015 kura and beyene 2020 however even in urban environments not all dynamics can be explained following the same ca theory in our study case model s fit was poor for informal settlements annex 3 as this class usually grows scattered and cannot be easily explained by common ca rules ibrahim et al 2019 liu et al 2019 point out at the limited capabilities of ca models to simulate novel urban processes such as urban regeneration gentrification or urban shrinkage nonetheless lauf et al 2016 simulated with success urban shrinkage processes for berlin in a metronamica based model even if relying on the same ca theory models can implement it in a different way leading to variable model structures and sources of uncertainty simple approaches such as the contiguity filter of ca markov may be less suited for complex applications where several categories or dynamics are modelled thus the ca component in ca markov only allows the user to tune the compactness of the entire simulated landscape without distinctions at the class level in our application this hampered the correct simulation of informal settlements whose pattern did not adapt to the general compactness logic applied by the model pontius jr and malanson 2005 considered the ability to control the modelled pattern as an important feature of a modelling exercise ca models allowing the definition of complex interactions attraction and repulsion rules between land uses such as metronamica give an answer to this question however only through the implementation of more complex methods such as the expander and patcher algorithms of dinamica ego the model can simulate different dynamics than the infill or growth from the patch edges in this regard garcía et al 2011 and hewitt and díaz pacheco 2017 point out at the model s ability to simulate emergent growth isolated from previous developments when analysing the complexity of ca models in our study case dinamica ego was the only ca model able to replicate the full complexity of the land use change pattern soares filho et al 2003 and mas et al 2014 proved the high control that this model offers for pattern simulation notwithstanding this flexibility is dependent on the stochasticity introduced in the model which may hamper the user understanding and the model stability garcía álvarez 2018 the simulation of dynamics by means of contiguity rules is also possible through non ca approaches such as lcm a dynamic factor of attraction repulsion between one land use and the others can account for those contiguity patterns for our study case the parametrization of this factor in lcm contributed to the generation of a similar simulation in ca and non ca models the correct or uncertain simulation of the studied dynamics may be also caused by other model characteristics such as the assumption of temporal stationarity of luc change feng et al 2019 markov based models like ca markov dinamica ego and lcm reproduce past processes into the future which makes difficult to simulate turning points in the modelled systems when different land use transitions take place mas et al 2018 paegelow 2018 in addition quantities of change in markov based models are usually calculated from historical data making the models very dependent on input data representativeness and accuracy paegelow 2018 aguejdad 2021 verburg et al 2019 recommend the development of models able to simulate the luc demands explicitly which can link demand and supply models based on tp maps like dinamica ego and lcm also find difficult to simulate different transitions through time and usually trust their calibration in recent changes which may be not enough to represent the system s future variability to account for this process variability models should be also able to handle dynamic factors this is a common feature in the three of the models compared with ca markov as the only software not able to handle these type of factors there is a wide variety of non ca modelling approaches national research council 2014 camacho olmedo et al 2018b many of them like lcm rely on machine learning and statistical procedures through these methods the model studies the relation between past changes and drivers of change and apply it to the future however if not allowing for user intervention the model may become very dependent on input uncertainties from data short calibration periods etc lcm does not offer any room for user intervention to this end which hampered the correction of some pattern inconsistencies in our study case thus in lcm model success entirely depends on the ability of the chosen evaluation method to correctly find the relation between drivers of change and past changes when models relying on automatic or statistical procedures allow for user intervention the users should be aware of the impact of their intervention and the uncertainties that it may bring in dinamica ego the change potential can be calculated through the weights of evidence or a genetic algorithm and the obtained result later modified by the user in our study case this modification produced very different change potential maps to the ones automatically generated by the model models relying on user understanding such as metronamica and ca markov avoid the uncertainties that come from the method but become dependent on the user input s uncertainty botterweg 1995 sohl et al 2016 li et al 2017 they may be even bigger than the ones associated to the selected method for change potential calculation in automatic or statistical approaches the model s success will depend a lot on the data and specifically on the number and statistical representativity of observed changes if these are not large or representative enough the relation that the model finds between changes and drivers of change may be biased however this may be a common feature in those models trusting user knowledge if s he heavily relies on historic dynamics to manually calibrate the models such as in the studies of guzman et al 2020 and tamuka moyo et al 2021 in these cases expert judgment could be a solution as experts can inform about the plausibility of the user s parameters and the simulation results hewitt et al 2014 according to botterweg 1995 user s calibrations are only valid for those users or experts who made the calibration limiting the repeatability of the model application however in our exercise expert based calibrations showed high correlation even with change potential maps obtained through statistical or automatic approaches on the contrary change potential maps obtained through different statistical or automatic approaches showed high variability these findings are similar to the ones obtained by krueger et al 2012 thus although the repeatability and easiness of calculation are usually some of the common advantages pointed out to choose automatic or statistical approaches this is not always the case expert or user knowledge has been pointed out as a useful tool for uncertainty assessment uusitalo et al 2015 nevertheless total user control like in metronamica has important limitations the modeller needs to understand how hundreds of parameters work at the same time accordingly he can struggle during the calibration especially if he does not have the expertise or experience required elsawah et al 2017 a mixture of both data driven and knowledge driven approaches can be considered an adequate solution pérez vega et al 2012 this is already implemented in dinamica ego and has already been tested in ca markov and metronamica ghosh et al 2017 newland et al 2018 4 2 uncertainty management 4 2 1 managing the structural uncertainty models can offer different strategies to deal with the structural uncertainties they may convey one of the most common is the provision of different methods in each of the modelling steps among which the users can choose the most suitable it connects with the models need to provide multiple process representation suggested by verburg et al 2019 another approach is the possibility of direct user intervention the availability of models code is maybe the option that would offer the users more room to deal with the models structural uncertainty although it would require a high level of expertise and user understanding of the model in addition it has been considered a required step by verburg et al 2019 to progress on lucc modelling and the management of uncertainty however none of the four models assessed are open source for the production of change potential maps offering the possibility to use external maps created through other methods is a good solution which has been applied in practice in metronamica and is already implemented in dinamica ego and ca markov in the last case this option is extensively used cai and wang 2020 arora et al 2021 offering a range of methods for change potential calculation is another approach however the different methods should be complementary providing a similar utility dinamica ego provides two different complementary methods weights of evidence genetic algorithm to calculate the change potential this in addition to the admission of external maps gives the user a wide range of chances to deal with the model s structural uncertainty lcm supplies three different methods for change potential calculation plus two extra machine learning techniques that have been included in the last release of the model eastman and toledano 2018b however logistic regression is just provided for pedagogic purposes eastman and toledano 2018b and not recommend by the developers eastman 2015a in addition machine learnings behave like a black boxes kim 2010 mozumder et al 2016 hampering the user understanding of the model if s he cannot understand why one method produces different results than the other s he will not be able to effectively manage the model s structural uncertainty by selecting among the different methods that are available for change allocation models can also offer different algorithms or methods however this is less common than in the change potential calculation all four models compared offer a single method of change or land use allocation which cannot be modified in ca markov and lcm through the provision of flexible frameworks like in dinamica ego models can allow the user to develop their own land allocation algorithms other approach is allowing the user modification of the specific method or algorithm implemented in the model metronamica for example allows the user to modify the transition potential formula that the model uses to allocate land uses for the quantity of changes estimation user intervention is the most common approach for uncertainty management the four models assessed allow users to modify the quantities of simulated changes which give them the chance to employ different methods to calculate those quantities however depending on the format that these quantities must be provided the room for user intervention may be more limited in this regard lcm only allow to introduce markov probabilities ca markov and dinamica ego offer options for the implementation of dynamic methods of quantity of changes estimation in a similar vein metronamica allows the dynamic computation of quantities of change through a regional model that can be parametrized by the user 4 2 2 stochasticity as a means to account for the model allocation uncertainty stochasticity is considered as an important feature by several authors to replicate real phenomena garcía et al 2011 van vliet et al 2012 renard et al 2013 it accounts for the uncertainty of the real world where decisions are dependent on uncertain human actions for a given set of changes there are usually large available areas for development with similar potential to change uncertain human action is the factor that can explain why a change took place in one place or another by including a stochastic component models can account for this uncertainty garcía et al 2011 reviewed two main approaches for the inclusion of randomness in lucc models a stochastic perturbation included in metronamica as part of the change potential calculation and monte carlo methods of change allocation as included in dinamica ego the first approach allows less likely changes to happen and has been pointed out as useful when communicating the uncertainty of the change allocation step white et al 2015 the second approach allows cells with similar potential to change to be simulated at each model execution although may produce important output variability as in our study case 4 2 3 process variability uncertainty at the regional or global levels the aggregation of uncertain local human decisions brings about new drivers or processes of change which finally change the foundations of the systems accordingly real systems are far from equilibrium systems which can evolve to new stages governed by new rules and processes white et al 2015 usually models deal with this process variability uncertainty by accounting for randomness in the modelling process hewitt and díaz pacheco 2017 or by means of the definition of scenarios van asselt 2000 maier et al 2016 some tools have been also proposed to deal with this uncertainty like the self modification algorithm in sleuth clarke 2004 stochasticity facilities those tipping points to happen allowing to replicate more complex systems however changing the foundations of a system is only possible by means of entering a large randomness which at the same time may hamper the user comprehension of the model the stochastic perturbation approach included in metronamica produces limited stochasticity at least when staying between the ranges indicated by the developers as proved in our simulation and other studies wu 2002 garcía et al 2011 hewitt and díaz pacheco 2017 the monte carlo method for change allocation implemented in dinámica ego can produce very stochastic simulations accounting for the process variability uncertainty mentioned above mustafa et al 2018 however the uncertainty that this method introduces in the user comprehension of the performed calibration can be higher than the one for which it finds an answer as the model can show different results every time that it is run making the model parametrization and understanding uncertain accordingly the user must find a balance between the stochasticity of his her model and its stability scenarios allow to manage the process variability uncertainty by providing a range of possible system evolutions under different drivers and processes of change they allow the user to explore future system uncertainties in a transparent way the user knows what is being tested however only those uncertainties that can be thought of will be included while a more black box approach also has the potential to capture the unknown unknowns models only able to produce business as usual scenarios or that offer options for parameter variation like lcm pérez vega et al 2012 eastman and toledano 2018b cannot deal with this source of uncertainty when different scenarios can be produced such as in the other three compared models the provision of specific tools for the management and creation of scenarios like in metronamica may be a very useful tool to manage this source of uncertainty van delden and hagen zanker 2009 riddell et al 2020 caution should be paid regarding the uncertainty that scenarios capture studies show that there are often larger differences between results of a baseline scenario simulated with different model software packages than between different scenarios run with the same model van delden et al 2012 prestele et al 2016 sohl et al 2016 this uncertainty mostly structural should be therefore carefully evaluated to this end model comparison has been repeatedly pointed out as a tool for model validation and characterization of their uncertainty pérez vega et al 2012 sohl et al 2016 paegelow et al 2018 in this regard this study proves how the same model application calibrated through very similar parameters for four different model software packages may deliver different results 4 2 4 validation and uncertainty analysis models usually include specific tools to validate and assess the uncertainty of their outputs however if this is not possible the generation of outputs that can be easily exported to other validation software or even the connection between the models and these software is equally effective in this regard metronamica ca markov and lcm give the user a wide range of options for model validation through the map comparison kit and terrset the provision of flexible gis frameworks where users can design and implement their own validation methods like in dinamica ego is another valid option for the provision of validation and uncertainty management tools it is important that the model developers provide the users guide and assistance when making these validation exercises or generally assessing the model uncertainty in this regard elsawah et al 2020 pointed out a gap between theory and practice in the implementation of uncertainty assessment exercises it is common the availability of model manuals and tutorials that give some tips to this end like in the four models compared however specific guidelines about validation and above all about uncertainty analysis are usually lacking and have been not found for any of the compared models when available they focus on one or a few analyses and do not make the user aware of the complexity that a full validation and uncertainty analysis may entail 4 2 5 communication of uncertainty there is still a lack of attention in the provision of tools to communicate the uncertainty that the models provide which is especially important for their correct use among decision makers and stakeholders elsawah et al 2020 none of the analysed models provides enough tools to communicate most of the uncertainties of the analysis to the audience from the problem conceptualization to the model validation models just focus on specific sources of uncertainty but not on the whole uncertainty of the modelling exercise this can be related with the lack of an agreed framework for uncertainty assessment in lucc modelling the development of external tools easily connected with the models that fulfil that need could be an alternative solution the generation of probability outputs which account for the model stochasticity and variability among model runs is a useful approach to communicate the uncertainty of single outputs however only metronamica includes a tool to produce these outputs which could be especially useful in dinamica ego due to the important stochasticity that the model can convey notwithstanding this result could be inconvenient if it is not properly used it can give the audience a false perspective about the uncertainty of the simulation it just accounts for the system s uncertainty that the models try to replicate through a stochastic component however it does not account for all the other sources of uncertainty which we have addressed in this paper 5 conclusions each model software package conceptualized the modelled system in a different way which led to differences in the way the luc dynamics and changes were simulated despite of these differences there is not a best modelling approach each model entails different uncertainties and limitations which must be carefully considered by their potential users in this regard comparing different model outputs for the same application is a good approach to account for the structural uncertainty of our modelling exercises the less automatic the model workflow is the more options the user has to control the model structural uncertainty in this regard constrained approaches that offer little room for user intervention like lcm can be associated to important sources of structural uncertainty if the model structure does not perfectly fit with the modelled processes nonetheless very flexible approaches which rely a lot on user or expert knowledge may become very dependent on the uncertainties introduced by them thus mixed approaches like dinamica ego are considered preferable nonetheless statistical or automatic modelling approaches did not provide in our study case more repeatability or better simulation scores than models relying on user knowledge which proved that user intervention is not necessarily associated with more uncertain simulations offering several options or methods for change potential calculation quantity of changes estimation and change allocation allows user intervention in the modelled process but does not leave all decisions in the user however when offering several options or methods these should be complementary and provide different approaches in this regard the different options for change potential calculation offered by lcm provided similar results randomness and scenario management were identified as two important elements to account for the uncertainty of the modelled processes but are not usually included in all models in our case only dinamica ego and metronamica were able to both simulate stochastic simulations and generate different scenarios in addition we have identified a lack of attention in models to important aspects related with uncertainty management such as the communication of model uncertainties and the provision of tools and guidance for uncertainty analysis declaration of competing interest the third author of the paper hedwig van delden is the director of the research institute for knowledge systems riks which develops commercializes and promotes the metronamica software there is not any conflict of interest between the rest of the authors and the models assessed acknowledgements this work was supported by the spanish ministry of science innovation and universities and the feder european regional development fund incertimaps pgc2018 100770 b 100 spanish ministry of economy and competitiveness and the european social fund ayudas para contratos predoctorales para la formación de doctores 2014 university of granada contratos puente 2018 spanish ministry of science and innovation ayudas para contratos juan de la cierva formación 2019 fjc2019 040043 the first author also appreciates the support of the university of cape town centre for transport studies in the development and set up of the model used in this paper appendix a supplementary data the following are the supplementary data related to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 multimedia component 3 multimedia component 3 appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2022 105411 
25588,research on the uncertainty of land use cover change lucc models is still limited through this paper we aim to globally characterize the structural uncertainty of four common software packages ca markov dinamica ego land change modeler metronamica and analyse the options that they offer for uncertainty management the models have been compared qualitatively based on their structures and tools and quantitatively through a study case for the city of cape town results proved how each model conceptualised the modelled system in a different way which led to different outputs statistical or automatic approaches did not provide higher repeatability or validation scores than user driven approaches the available options for uncertainty management vary depending on the model communication of uncertainties is poor across all models keywords uncertainty lucc modeling ca markov dinamica ego land change modeler metronamica 1 introduction uncertainty is inherent in spatial analysis because of the need of abstraction to represent any of the earth s characteristics or processes through a map or a gis procedure it is also inherent to any analysis that involves human understanding of any real world process we understand uncertainty as an indicator of the degree of distrust of the images and concepts of the real world that we are using castilla and hay 2007 this uncertainty must be carefully examined to be aware about the limitations of our analysis and studies land use cover change lucc models have many sources of uncertainty which are difficult to disentangle uusitalo et al 2015 altogether they are known as model output uncertainty refsgaard et al 2007 klein goldewijk and verburg 2013 or the uncertainty cascade refsgaard et al 2013 notwithstanding several authors have tried to classify them in different groups van asselt 2000 walker et al 2003 refsgaard et al 2007 2013 matott et al 2009 klein goldewijk and verburg 2013 garcía álvarez et al 2019 mainly differentiating the following types of uncertainty epistemological uncertainty the uncertainty that comes from the delimitation and conceptualization of the problem to be modelled when strictly referring to the uncertainty of the way a problem is conceptualized in a model several authors talk about structural uncertainty ferchichi et al 2017 brown et al 2021 specifically refer to model paradigms when analysing model structures that lie in a very different conceptualization of the systems to be modelled model technical uncertainty the uncertainty arising from the computer implementation of the model concerning not only the model algorithm but also the data formats resolution and other issues it is related to epistemological uncertainty process variability uncertainty the uncertainty that comes from the different ways a system can evolve in the future input uncertainty the uncertainty that comes from the data used in the model and its ability to represent the earth surface and or its characteristics parameter uncertainty the uncertainty associated to the values at which the different model parameters are calibrated model operation uncertainty the uncertainty that arises from the accumulation and interaction of uncertainties propagated through the model these sources of uncertainty in lucc modelling exercises have been addressed widely in literature many papers assess the output uncertainty of specific exercises memarian et al 2012 ligmann zielinska 2013 whereas others focus on specific sources of uncertainty like parameter uncertainty dietzel and clarke 2004 conway 2009 garcía et al 2011 van vliet et al 2013 houet et al 2015 confalonieri et al 2016 grinblat et al 2016 liao et al 2016 or process variability uncertainty kok and van delden 2009 verburg et al 2013 alexander et al 2015 maier et al 2016 less common is the research about epistemological uncertainties of lucc models and specifically about the models structural uncertainty elsawah et al 2020 some studies address specific topics related to this issue like the different procedures to calculate change potential and change allocation riveira and maseda 2006 lin et al 2011 pérez vega et al 2012 camacho olmedo et al 2013 shafizadeh moghadam et al 2015 ferchichi et al 2017b propose a framework to quantify structural uncertainty of lucc models based on probabilistic theory and sensitivity analysis however there is a lack of studies that characterize the overall structural uncertainty of available lucc model software packages and analyse the tools and options that each model offers for uncertainty management and communication today there is a large availability of standard model software packages to simulate different spatial dynamics camacho olmedo et al 2018b although they are considered too simple by some users to model complex phenomena their use is ever increasing wickramasuriya et al 2009 chaudhuri and clarke 2013 leija et al 2021 and they are tools used in practice for real policy cases barredo et al 2003 van delden et al 2011 eastman and toledano 2018b guzman et al 2020 information about the uncertainty associated to the use of these software packages is not usually widespread and no paper analysing their structural uncertainty and their approaches to uncertainty management has been found in the literature however knowledge about these aspects is required to improve their understanding and characterization in addition it will help to engage planning agents and spread their use in real world problems solving yeh and li 2006 batisani and yarnal 2009 sohl et al 2016 through this paper we aim to fill the previous research gap by characterizing and comparing four standard lucc model software packages model comparison has been proposed by several authors as a way to assess the structural uncertainty kelly et al 2013 uusitalo et al 2015 brown et al 2021 and has been usually employed as a useful approach to better characterize and understand the available software packages garcía et al 2012 toro balbotín 2014 mas et al 2014 aguejdad et al 2016 camacho olmedo et al 2018b through the comparison we will answer the following research questions which are the sources of uncertainty that come from the different model structures how does each model manage and communicates uncertainty we will analyse the model structure of each software and the options that they offer for uncertainty management and communication through a qualitative comparative analysis of the models additionally we will assess the potential uncertainty associated to the model structure by applying the four compared models to the same study case in the following section we explain the methodological approach of this paper in detail 2 materials and methods 2 1 model software packages we compared four standard pattern based lucc model software packages ca markov dinamica ego land change modeler as included in the terrset 2018 version and metronamica below we provide a short description of each model a graphic representation of each one is provided in the annex 1 annex 2 includes a comparative table to evaluate the differences among models the models have been selected based on the authors deep experience with them mas et al 2010 2011 2014 camacho olmedo et al 2018a garcía álvarez 2018 and wide use among the lucc modelling community santé et al 2010 kamusoko 2012 eastman and toledano 2018b ferreira et al 2019 practical experience with the models is essential to fully understand the model conceptualizations and structures and their limitations in real case applications the wide use of these models among the lucc community guarantees the utility of the results here delivered as they help to characterize standard tools used by many users for different purposes either as part of scientific studies or real case applications in addition as they rely on common lucc modelling theories we can draw general lessons from their analysis and comparison which can be applied to any lucc model ca markov eastman and toledano 2018a is a modelling tool which makes use of several procedures integrated in terrset previously idrisi a software of geospatial analysis and modelling the quantity of changed pixels is determined by a markov matrix whereas the location of those pixels is performed through the combination of a series of suitability layers a contiguity filter and a multi objective allocation procedure dinamica ego soares filho et al 2002 2009 rodrigues and soares filho 2018 is a free environmental modelling platform that includes lucc modelling methods due to the flexibility that it offers there is a wide variety of ways to set up a lucc model as common practise markov chains and weights of evidence woe are used for the estimation of the quantities and change potential change allocation is performed through a couple of stochastic cellular automata functions patcher which produces new patches and expander which simulates the growth as expansion of previous patches land change modeler lcm eastman 2015a eastman and toledano 2018b is a constrained lucc model which is also integrated in terrset the change potential calculation is empirically obtained through three possible methods neural networks logistic regression and a machine learning algorithm simweight the change allocation is performed through a multi objective allocation procedure whereas the quantity of change is estimated by means of a markov matrix metronamica riks 2012 van delden and vanhout 2018 is a constrained cellular automata model based on the theory developed by white and engelen in the 90 s white and engelen 1993 white et al 1997 land use is allocated according to a competition for space principle based on the following inputs interaction rules between land uses human behaviour accessibility land suitability environmental conditions and zoning planning demands can be defined externally or by means of a regional model simulating job and population dynamics 2 2 model comparison model structures were compared according to the following aspects change potential calculation including the explanatory factors considered by each model quantity of changes estimation allocation of changes pattern simulation and validation and outputs although only the last one specifically relates with uncertainty management and communication these questions have been reviewed for all other aspects as well regarding the extent to which the models include tools or allow user intervention for uncertainty management the comparison followed a both qualitative and quantitative analysis of each software fig 1 the qualitative analysis complements the limitations of the quantitative analysis to assess sources of uncertainty that are not usually addressed in the literature elsawah et al 2020 through the qualitative approach 2 2 1 we compared the way in which each model conceptualizes the modelled system and the available options they offer for uncertainty management through the quantitative approach 2 2 2 we compared model outputs for the same case study city of cape town to assess the differences that come from the model structure the case study is part of the urban modelling practice accordingly results from our analysis may be affected by the specificities of urban dynamics urban growth is usually simulated through a common set of driving forces accessibility physical suitability zoning and neighbour interactions nonetheless general understanding of the models options for uncertainty management and system conceptualization can be also applied to other types of application the study case is explained in detail in annex 3 it consisted of a model set up with a spatial resolution of 100 m grid cells for the city of cape town and the period 1990 2013 2 2 1 qualitative model characterization we reviewed and characterized the structures and features of the different software packages this includes among other items system conceptualization available methods for quantity of changes estimation change potential calculation change allocation uncertainty management validation and communication of results as well as the theory behind those methods this information was obtained through the model s documentation and based on the deep experience of authors with the analysed software mas et al 2014 2018 paegelow et al 2014 2018 camacho olmedo et al 2018b garcía álvarez 2018 2 2 2 model outputs assessment the four models were calibrated for the same case study following the approach described in annex 3 outputs generated by each model were then analysed and compared this allowed to analyse which differences between simulations came from the use of different model structures according to this criterion the higher the consensus among model outputs the more certain is the simulation simulation success was also measured by comparing each simulation with reference data through common lucc validation indices and metrics kappa simulation van vliet et al 2011 and spatial metrics mcgarigal 2018 see below the higher the agreement between reference and simulated data the more successful the simulation is considered for the comparison of output maps we differentiated between soft classified and hard classified maps camacho olmedo et al 2013 the first ones which we will also refer to as change potential cp maps show the probabilities of change to a specific category hard classified maps which are the final land use maps simulated by the models and we refer to as simulation results assign every pixel to a specific category and therefore show states instead of probabilities agreement between cp maps obtained through different methods of change potential calculation was measured through the spearman correlation coefficient incorporated in the r package enmtools warren et al 2021 to this end transition potential tp maps to the same category in dinamica and lcm were aggregated and compared to the land use potential lup maps for that category in ca markov and metronamica lup maps show the probability of change to a specific category e g b whereas tp maps show the probability of a specific transition e g a to b happening to make both types of maps comparable areas of ca markov and metronamica lup maps not considered in the transitions of dinamica and lcm tp maps were masked hard classified simulated outputs from different models were compared by means of standard cross tabulation techniques kappa simulation ksim and a set of spatial metrics calculated at the class level number of patches patch mean size and standard deviation and proportion of like adjacencies ksim evaluates the agreement between the changes simulated by each model compared to the agreement that is expected by chance van vliet et al 2011 spatial metrics characterize the shape and size of patches and the way they are allocated on the map that is the maps patterns a patch is a group of neighbour pixels with the same value botequilha leitao et al 2006 the proportion of like adjacencies inform about the aggregation or cohesion between patches of the same class mcgarigal 2018 that is how aggregated or fragmented are the patches that make up a class each model was executed 20 times under the same parameters and conditions to assess the intra model output variability only outputs from the first executions were employed for the previous assessments whereas outputs from the remaining 19 executions were only employed to assess the agreement between model executions outputs from different model executions show low variability and do not significantly alter the pattern logic of the simulated cp areas or luc changes thus single outputs are enough to compare the output uncertainty caused by different model structures agreement between change potential maps obtained through the same production method for each model was assessed by calculating the average standard deviation of the pixel values across the 20 outputs intra model agreement between simulations was assessed through ksim and cross tabulation as in the inter model comparison 3 results 3 1 change potential calculation change potential is calculated in the four compared models based on the relation defined or found between a set of factors or drivers of change and the luc changes that relation can be defined by the user in the case of expert driven models ca markov metronamica or calculated through automatic or statistical approaches as defined by van vliet et al 2016 in the case of data driven models dianmica ego lcm in the second case models are trained until the best statistical relation between explanatory factors and luc changes is obtained in the first case models are trained based on user criteria which is usually driven by validation metrics such as kappa or quantity and allocation dis agreement indices although we can obtain the same relation between factors and luc changes through any of the methods implemented in the four software packages each method entails a specific workflow for the combination of factors and produces a specific type of change potential map depending on the method there are also some restrictions regarding the number or type of factors that can be taken into account accordingly the selected methods and the way they have been implemented are closely connected with the model conceptualization 3 1 1 luc and lucc explanatory factors only metronamica puts restrictions regarding the number and type of factors considered it only comprises four factors neighbourhood interactions accessibility suitability and zoning although the user can choose how many base maps he or she likes to include in the different factors and even rule out some of them by modifying the transition potential formula that guides the change potential map creation the metronamica factors may be dynamic the model also includes a random component in the change potential map creation which introduces variability between different cp maps produced by the model yellow cell in table 1 it is possible to run the model in a deterministic way as well random factor 0 although the developers do not recommend this due to the inherent uncertainty in land use dynamics ca markov is not able to work with dynamic factors which makes the model more uncertain when simulating processes that are explained by different or variable factors along time on the other hand dinamica ego and lcm admit any type and number of factors including the dynamic ones notwithstanding for lcm when using logistic regression as the change potential calculation method the model requires factors that are linearly related to the potential for transition eastman 2015b to this end lcm includes tools for factors transformation however they transform the factors based on luc data assuming a temporal stationarity i e the continuation of past trends to the future which may not be real 3 1 2 two different types of change potential maps dinamica ego and lcm produce transition potential tp maps camacho olmedo et al 2013 which indicate the potential of a set of defined land uses to transition to another set of land uses although transitions can take place from any class to every other class on tp maps they are usually restricted to the more meaningful as it is difficult to find statistically significant relationships between a few luc changes and a set of factors in these cases the found relationships may be significantly affected by errors in data or the presence of one off events through expert driven approaches models produce land use potential lup or suitability maps camacho olmedo et al 2013 2018a they indicate the preference of each land use class to occupy any location of a study area based on a set of drivers defined by the user which in practice allows any transition to happen at any point in time they do not necessarily require of historical data to be obtained aguejdad 2021 although camacho olmedo et al 2013 point out how users create these maps based on the understanding of distribution of the considered land uses in time which implicitly includes the understanding of previous past changes for our study case correlation between change potential cp maps is independent of the type of maps compared the ca markov and metronamica lup mas show the highest correlation with the tp maps of lcm whereas tp maps automatically produced by dinamica ego show the highest correlalation with metronamica lup maps table 1 3 1 3 methods for change potential calculation each model calculates the change potential though different procedures fig 2 which are closely related to the way each model has been conceptualized lcm offers three methods for transition potential map creation neural networks and simweight based on machine learning techniques and logistic regression the three methods trust automatic or statistical procedures as defined by van vliet et al 2016 to find out the relation between changes and drivers of change to this end they use a sample of pixels as training and then in the case of neural networks and simweight the inferred relations are compared to a set of validation pixels as far as the analysis sample varies with each model run the inferred relations change with the sample as well kim 2010 although this variation is low table 1 the logistic regression procedure allows the user to employ all the pixels in the analysis and therefore avoid this possible uncertainty dinamica ego makes use of the weights of evidence woe to calculate the change potential maps although the model also admits external maps produced through other methods to bypass the incorporated methods the woe is a bayesian method that relates the presence of a given set of factors with the probability of land use change eastman et al 2005 soares filho et al 2013 developed a genetic algorithm that allows the user to refine the change potential calculated through the woe method the software also allows the user to manually edit the obtained weights to account for some of the uncertainties that the data calibrations periods etc can entail this manual adjustment may have a great impact on the obtained maps in our modelling exercise change potential maps obtained with automatic and adjusted weights showed big differences table 1 ca markov does not integrate a specific method for change potential calculation although the model help advises to employ the multicriteria evaluation mce implemented in terrset as the standard tool for this purpose when using this method the model will rely on user or expert knowledge becoming very dependent on the uncertainty of that knowledge in this regard in this method he decides which factors to use and how they should be transformed and combined he even assigns a weight to every factor in metronamica the change potential map is calculated through a formula that combines a series of input data manually adjusted by the user the user can also edit the formula which gives him the chance to account for the model structure uncertainty however they can also introduce new sources of uncertainty by doing so with the exception of dinamica ego cp maps produced through the different methods implemented by each model show very high correlation among them and lower correlation with cp maps produced by other models table 1 in addition there is not a clear correlation between cp maps based on their production method manual vs automatic statistical approaches accordingly the dinamica ego cp maps automatically produced through the woe show lower correlations with cp maps of other models than the cp maps obtained after the manual modification of the obtained weights 3 2 quantity of changes estimation ca markov dinamica ego and lcm calculate the simulated quantities from markov chains they indicate the probability of every category to transition to every other class and to remain the same camacho olmedo and mas 2018a aguejdad 2021 thence they make the modelling process to focus on transitions instead of land use states through this approach it is difficult to model systems where the land use dynamics change frequently and that do not follow historical patterns of growth mas et al 2018 paegelow 2018 aguejdad 2021 that is systems where the transitions between land uses are not always the same and at similar intensities in addition markov chains usually calculate transition probabilities from past changes extracted by comparing luc maps at two different time points camacho olmedo and mas 2018a in these cases the uncertainty of input maps will be transferred to the obtained probabilities nonetheless the three models allow the user to manually modify the obtained markov probabilities from input data and therefore to account for some of the uncertainties associated to input data however this step may not be easy for some users the markov probabilities tool implemented in terrset and used in the context of ca markov allows to consider in the uncertainty of input maps in the quantity of change estimation however this introduces important modifications in the calculated quantities of change mas et al 2014 accordingly this method can introduce more uncertainty than the one for which it finds an answer metronamica does not include any method for quantity of changes estimation the user enters the total number of cells persistence changes that will make up each function class the tool the user employs to decide the total number of cells will determine the uncertainty of this data in addition the transitions modelled for every category will rely on the settings of the interaction rules in the ca component if the user does not introduce high values of inertia for the existent pixels of the function classes some incongruent transitions can take place moreover since the user cannot enter any information about the quantities of the vacant classes their final size will also rely on the user calibration metronamica is therefore the most flexible model for modelling different types and speeds of change however because of this high level of flexibility the ability of the user to replicate the dynamics of change is critical when calibrating the model and simulating the correct quantities of change all four models calculated different quantities of change despite being based on the same reference data table 2 small differences in the way markov probabilities are calculated and used to calculate the number of pixels explain the disagreements between ca markov dinamica ego and lcm metronamica s differences are explained by its specific method and the user calibration 3 3 allocation of changes lcm ca markov and metronamica follow a deterministic procedure for change or land use allocation on the contrary dinamica ego includes a stochastic algorithm of change allocation that simulates different changes each time that the model is run table 3 and fig 3 lcm and ca markov make use of a multi objective land allocation mola mechanism it selects those pixels with the highest potential to change solving conflicts between different objectives based on the minimum distance to ideal point rule eastman et al 1995 metronamica follows a similar procedure it selects the pixels with the highest potential to change for every category allocating first the demands of the function classes and then the pixels of the vacant classes although the process is deterministic the random factor added to the change potential maps allows transitions to take place in areas less likely to change ca markov includes a contiguity filter as part of the allocation process forcing pixels with lower potential values to be simulated as change if located next to previous pixels of the simulated category in lcm a zoning layer can be included in the allocation of changes step multiplying the values of the change potential maps the allocation functions of dinamica ego patcher and expander include a cellular automata component favouring the simulation of pixels adjacent to land use classes of the same category they also include a stochastic component to account for the unpredictability of human decision making which however is not easy to control it is associated to a specific prune factor which can be managed by the user but also to a monte carlo approach of land use allocation and the parametrization of the expander and patcher functions garcía álvarez 2018 to reduce this stochasticity to a minimum the user must choose a prune factor of 1 define clear and different transition potential values for the candidate cells and parametrize the expander and patcher functions according to the pixel size in our case study the stochasticity was relatively high in 20 model executions only 7 6 of the pixels simulated as change were allocated in the same place with 34 of the changing pixels allocated in the same place less than 10 times table 4 and fig 3 simulated changes from each model usually show more agreement with the outputs from other models than with reference maps table 4 ca markov and metronamica are the models that simulate the most similar changes on the contrary ca markov and dinamica ego are the models simulating more different changes these differences cannot be explained by differences between change potential maps as there is not a direct relation between correlation of change potential maps and the agreement of simulated changes tables 1 and 4 3 4 pattern simulation ca markov dinamica ego and metronamica include a cellular automata component to replicate the real luc pattern this is lacking in lcm which however allows to include a dynamic factor of distance to any of the map categories lcm can infer from this variable the relation between luc changes and the distance to cells of the other categories however this is calculated automatically by the model and therefore dependent on input data uncertainty because there is no user intervention possible there is no direct control of the modelled pattern this ca component or attraction factor is especially relevant to simulate urban dynamics such as the ones of the city of cape town as new urban areas usually grow on the urban edges usually in the search for economies of agglomeration white et al 1997 for our modelling exercise although lcm simulated a general pattern very similar to the reference landscape the simulation includes many small and scattered patches that do not fit the common pattern associated with land uses like urban residential even if we can check a visual coherent pattern in fig 4 the spatial metrics reveal how lcm was the model that simulated the most new patches of urban residential 120 opposite to 7 new patches of change between the reference maps of 2002 and 2013 table 5 in ca markov the user controls the compactness of the simulated pattern through a user defined contiguity filter it up weights the land use potential values of pixels close to pixels of the considered class and down weights those which are far from this camacho olmedo and mas 2018b it applies the same compactness logic to all modelled classes in our study case urban residential and urban informal changes were simulated according to the same pattern patches of both classes became more compact with a reduction in the total number of patches and a bigger mean path size table 5 however urban informal pattern is more scattered large increment of the number of patches and a lower mean patch size than the urban residential one metronamica allows to define neighbourhood interactions between all classes of the map and each function class making it possible to get a specific pattern for each class solving the previous limitation of ca markov the user can also play with the weight of self attraction rules and the random factor to facilitate the production of new patches in metronamica however both ca markov and metronamica faced difficulties when trying to simulate changes as new patches in the two models all changes were simulated as infill of existing patches or as an organic halo from them fig 4 dinamica ego simulates the desired pattern through two different functions expander and patcher which can be used together or independently the expander function simulates changes as expansion of previous patches of the same use whereas the patcher function simulates changes as new patches disconnected from previous pixels of the same use the user must indicate to the model the size and shape of the new patches for each modelled transition through three parameters mean variance and isometry accordingly dinamica ego is the model that gives more control to the user regarding pattern simulation for our study the simulated landscape of dinamica resembled quite well the reference landscape table 5 being maybe the best model when it comes to this point 3 5 tools for validation uncertainty management and communication directly or indirectly all four models offer the user a wide range of tools to test the accuracy and uncertainty of the simulation results this is possible in metronamica through the complementary map comparison kit software and in ca markov and lcm through terrset the software where these models are included the dinamica ego platform is directly able to calculate a wide range of validation measures metronamica is the only model that explicitly includes a tool for scenario management it also allows to inform about the stochasticity associated to single run simulations dinamica ego because of its flexibility can be designed to produce similar results ca markov and lcm are more constrained to this end lcm is only able to simulate business as usual scenarios eastman and toledano 2018b in ca markov different model applications must be set up to account for different scenarios all four models provide manuals and tutorials that describe the models methods and explain how to use them properly soares filho et al 2009 riks 2012 eastman 2015b however information about how to validate or assess the uncertainty of the modelling exercises is usually lacking in addition none of the four models is open source which limits the user development and understanding of the software nonetheless metronamica foundations are deeply addressed in the literature white and engelen 1993 white et al 1997 and described in detail in the model documentation riks 2012 facilitating the replication of the model by other users 4 discussion each of the four model software packages compared conceptualized the systems and processes to be modelled in a different way which resulted in different outputs these sources of structural uncertainty are discussed in detail in section 4 1 in addition all models provide different methods or tools to deal manage and communicate the possible uncertainties of the modelling exercise they are discussed in section 4 2 part of the results here discussed are limited by the study case selected for the model comparison model outputs were only compared for one specific case and one historic period analyses making use of different historic periods and study areas could provide complementary results in addition we have only judged the models success based on their quantitative performance with respect to a historic period of reference assessing the plausibility of model parameters and results based on expert judgment or other strategies could also provide complementary conclusions 4 1 structural uncertainty how a system is conceptualized in a model comes with an important source of epistemological uncertainty which may depend to a great extent on the purpose or objective for which the model was initially developed models developed for a specific purpose and application can include a structure that suit the simulated processes best for standard models like the ones assessed in our application the sources of structural uncertainty can be bigger the models assessed in our study have all developed towards generic modelling frameworks although they might have been developed for a specific purpose originally over time they have been adapted to be able to simulate a wider range of dynamics lcm and dinamica ego were initially developed to simulate deforestation dynamics soares filho et al 2002 eastman 2015a but successfully simulated urban processes in our study case and have been applied with success in other domains eastman and toledano 2018b rodrigues and soares filho 2018 in this regard they do not limit the number or nature of the factors considered which makes them very flexible tools that is also the case of ca markov that was not specifically developed for any application but has been successfully applied to many domains eastman and toledano 2018a metronamica based on the model proposed by white and engelen to simulate urban dynamics white and engelen 1993 white et al 1997 has been also applied to simulate non urban dynamics van delden and vanhout 2018 navarro cerrillo et al 2020 however the model has been specifically designed to simulate urban and regional processes in detail as revealed by the four factors that model considers accessibility neighbourhood suitability and zoning they are the common drivers of urban change but may be limited to simulate dynamics related with farming or natural vegetation in ca models such as ca markov dinamica ego or metronamica the behaviour of a complex system is explained by the relation between every of its components conceptualized as cells and their neighbourhoods if this assumption does not lie on the base of the dynamics of the modelled system these models will probably fail when modelling the intended dynamics this logic fits well with urban processes like the ones of cape town as well as with other ones such as deforestation barredo et al 2003 white et al 2015 kura and beyene 2020 however even in urban environments not all dynamics can be explained following the same ca theory in our study case model s fit was poor for informal settlements annex 3 as this class usually grows scattered and cannot be easily explained by common ca rules ibrahim et al 2019 liu et al 2019 point out at the limited capabilities of ca models to simulate novel urban processes such as urban regeneration gentrification or urban shrinkage nonetheless lauf et al 2016 simulated with success urban shrinkage processes for berlin in a metronamica based model even if relying on the same ca theory models can implement it in a different way leading to variable model structures and sources of uncertainty simple approaches such as the contiguity filter of ca markov may be less suited for complex applications where several categories or dynamics are modelled thus the ca component in ca markov only allows the user to tune the compactness of the entire simulated landscape without distinctions at the class level in our application this hampered the correct simulation of informal settlements whose pattern did not adapt to the general compactness logic applied by the model pontius jr and malanson 2005 considered the ability to control the modelled pattern as an important feature of a modelling exercise ca models allowing the definition of complex interactions attraction and repulsion rules between land uses such as metronamica give an answer to this question however only through the implementation of more complex methods such as the expander and patcher algorithms of dinamica ego the model can simulate different dynamics than the infill or growth from the patch edges in this regard garcía et al 2011 and hewitt and díaz pacheco 2017 point out at the model s ability to simulate emergent growth isolated from previous developments when analysing the complexity of ca models in our study case dinamica ego was the only ca model able to replicate the full complexity of the land use change pattern soares filho et al 2003 and mas et al 2014 proved the high control that this model offers for pattern simulation notwithstanding this flexibility is dependent on the stochasticity introduced in the model which may hamper the user understanding and the model stability garcía álvarez 2018 the simulation of dynamics by means of contiguity rules is also possible through non ca approaches such as lcm a dynamic factor of attraction repulsion between one land use and the others can account for those contiguity patterns for our study case the parametrization of this factor in lcm contributed to the generation of a similar simulation in ca and non ca models the correct or uncertain simulation of the studied dynamics may be also caused by other model characteristics such as the assumption of temporal stationarity of luc change feng et al 2019 markov based models like ca markov dinamica ego and lcm reproduce past processes into the future which makes difficult to simulate turning points in the modelled systems when different land use transitions take place mas et al 2018 paegelow 2018 in addition quantities of change in markov based models are usually calculated from historical data making the models very dependent on input data representativeness and accuracy paegelow 2018 aguejdad 2021 verburg et al 2019 recommend the development of models able to simulate the luc demands explicitly which can link demand and supply models based on tp maps like dinamica ego and lcm also find difficult to simulate different transitions through time and usually trust their calibration in recent changes which may be not enough to represent the system s future variability to account for this process variability models should be also able to handle dynamic factors this is a common feature in the three of the models compared with ca markov as the only software not able to handle these type of factors there is a wide variety of non ca modelling approaches national research council 2014 camacho olmedo et al 2018b many of them like lcm rely on machine learning and statistical procedures through these methods the model studies the relation between past changes and drivers of change and apply it to the future however if not allowing for user intervention the model may become very dependent on input uncertainties from data short calibration periods etc lcm does not offer any room for user intervention to this end which hampered the correction of some pattern inconsistencies in our study case thus in lcm model success entirely depends on the ability of the chosen evaluation method to correctly find the relation between drivers of change and past changes when models relying on automatic or statistical procedures allow for user intervention the users should be aware of the impact of their intervention and the uncertainties that it may bring in dinamica ego the change potential can be calculated through the weights of evidence or a genetic algorithm and the obtained result later modified by the user in our study case this modification produced very different change potential maps to the ones automatically generated by the model models relying on user understanding such as metronamica and ca markov avoid the uncertainties that come from the method but become dependent on the user input s uncertainty botterweg 1995 sohl et al 2016 li et al 2017 they may be even bigger than the ones associated to the selected method for change potential calculation in automatic or statistical approaches the model s success will depend a lot on the data and specifically on the number and statistical representativity of observed changes if these are not large or representative enough the relation that the model finds between changes and drivers of change may be biased however this may be a common feature in those models trusting user knowledge if s he heavily relies on historic dynamics to manually calibrate the models such as in the studies of guzman et al 2020 and tamuka moyo et al 2021 in these cases expert judgment could be a solution as experts can inform about the plausibility of the user s parameters and the simulation results hewitt et al 2014 according to botterweg 1995 user s calibrations are only valid for those users or experts who made the calibration limiting the repeatability of the model application however in our exercise expert based calibrations showed high correlation even with change potential maps obtained through statistical or automatic approaches on the contrary change potential maps obtained through different statistical or automatic approaches showed high variability these findings are similar to the ones obtained by krueger et al 2012 thus although the repeatability and easiness of calculation are usually some of the common advantages pointed out to choose automatic or statistical approaches this is not always the case expert or user knowledge has been pointed out as a useful tool for uncertainty assessment uusitalo et al 2015 nevertheless total user control like in metronamica has important limitations the modeller needs to understand how hundreds of parameters work at the same time accordingly he can struggle during the calibration especially if he does not have the expertise or experience required elsawah et al 2017 a mixture of both data driven and knowledge driven approaches can be considered an adequate solution pérez vega et al 2012 this is already implemented in dinamica ego and has already been tested in ca markov and metronamica ghosh et al 2017 newland et al 2018 4 2 uncertainty management 4 2 1 managing the structural uncertainty models can offer different strategies to deal with the structural uncertainties they may convey one of the most common is the provision of different methods in each of the modelling steps among which the users can choose the most suitable it connects with the models need to provide multiple process representation suggested by verburg et al 2019 another approach is the possibility of direct user intervention the availability of models code is maybe the option that would offer the users more room to deal with the models structural uncertainty although it would require a high level of expertise and user understanding of the model in addition it has been considered a required step by verburg et al 2019 to progress on lucc modelling and the management of uncertainty however none of the four models assessed are open source for the production of change potential maps offering the possibility to use external maps created through other methods is a good solution which has been applied in practice in metronamica and is already implemented in dinamica ego and ca markov in the last case this option is extensively used cai and wang 2020 arora et al 2021 offering a range of methods for change potential calculation is another approach however the different methods should be complementary providing a similar utility dinamica ego provides two different complementary methods weights of evidence genetic algorithm to calculate the change potential this in addition to the admission of external maps gives the user a wide range of chances to deal with the model s structural uncertainty lcm supplies three different methods for change potential calculation plus two extra machine learning techniques that have been included in the last release of the model eastman and toledano 2018b however logistic regression is just provided for pedagogic purposes eastman and toledano 2018b and not recommend by the developers eastman 2015a in addition machine learnings behave like a black boxes kim 2010 mozumder et al 2016 hampering the user understanding of the model if s he cannot understand why one method produces different results than the other s he will not be able to effectively manage the model s structural uncertainty by selecting among the different methods that are available for change allocation models can also offer different algorithms or methods however this is less common than in the change potential calculation all four models compared offer a single method of change or land use allocation which cannot be modified in ca markov and lcm through the provision of flexible frameworks like in dinamica ego models can allow the user to develop their own land allocation algorithms other approach is allowing the user modification of the specific method or algorithm implemented in the model metronamica for example allows the user to modify the transition potential formula that the model uses to allocate land uses for the quantity of changes estimation user intervention is the most common approach for uncertainty management the four models assessed allow users to modify the quantities of simulated changes which give them the chance to employ different methods to calculate those quantities however depending on the format that these quantities must be provided the room for user intervention may be more limited in this regard lcm only allow to introduce markov probabilities ca markov and dinamica ego offer options for the implementation of dynamic methods of quantity of changes estimation in a similar vein metronamica allows the dynamic computation of quantities of change through a regional model that can be parametrized by the user 4 2 2 stochasticity as a means to account for the model allocation uncertainty stochasticity is considered as an important feature by several authors to replicate real phenomena garcía et al 2011 van vliet et al 2012 renard et al 2013 it accounts for the uncertainty of the real world where decisions are dependent on uncertain human actions for a given set of changes there are usually large available areas for development with similar potential to change uncertain human action is the factor that can explain why a change took place in one place or another by including a stochastic component models can account for this uncertainty garcía et al 2011 reviewed two main approaches for the inclusion of randomness in lucc models a stochastic perturbation included in metronamica as part of the change potential calculation and monte carlo methods of change allocation as included in dinamica ego the first approach allows less likely changes to happen and has been pointed out as useful when communicating the uncertainty of the change allocation step white et al 2015 the second approach allows cells with similar potential to change to be simulated at each model execution although may produce important output variability as in our study case 4 2 3 process variability uncertainty at the regional or global levels the aggregation of uncertain local human decisions brings about new drivers or processes of change which finally change the foundations of the systems accordingly real systems are far from equilibrium systems which can evolve to new stages governed by new rules and processes white et al 2015 usually models deal with this process variability uncertainty by accounting for randomness in the modelling process hewitt and díaz pacheco 2017 or by means of the definition of scenarios van asselt 2000 maier et al 2016 some tools have been also proposed to deal with this uncertainty like the self modification algorithm in sleuth clarke 2004 stochasticity facilities those tipping points to happen allowing to replicate more complex systems however changing the foundations of a system is only possible by means of entering a large randomness which at the same time may hamper the user comprehension of the model the stochastic perturbation approach included in metronamica produces limited stochasticity at least when staying between the ranges indicated by the developers as proved in our simulation and other studies wu 2002 garcía et al 2011 hewitt and díaz pacheco 2017 the monte carlo method for change allocation implemented in dinámica ego can produce very stochastic simulations accounting for the process variability uncertainty mentioned above mustafa et al 2018 however the uncertainty that this method introduces in the user comprehension of the performed calibration can be higher than the one for which it finds an answer as the model can show different results every time that it is run making the model parametrization and understanding uncertain accordingly the user must find a balance between the stochasticity of his her model and its stability scenarios allow to manage the process variability uncertainty by providing a range of possible system evolutions under different drivers and processes of change they allow the user to explore future system uncertainties in a transparent way the user knows what is being tested however only those uncertainties that can be thought of will be included while a more black box approach also has the potential to capture the unknown unknowns models only able to produce business as usual scenarios or that offer options for parameter variation like lcm pérez vega et al 2012 eastman and toledano 2018b cannot deal with this source of uncertainty when different scenarios can be produced such as in the other three compared models the provision of specific tools for the management and creation of scenarios like in metronamica may be a very useful tool to manage this source of uncertainty van delden and hagen zanker 2009 riddell et al 2020 caution should be paid regarding the uncertainty that scenarios capture studies show that there are often larger differences between results of a baseline scenario simulated with different model software packages than between different scenarios run with the same model van delden et al 2012 prestele et al 2016 sohl et al 2016 this uncertainty mostly structural should be therefore carefully evaluated to this end model comparison has been repeatedly pointed out as a tool for model validation and characterization of their uncertainty pérez vega et al 2012 sohl et al 2016 paegelow et al 2018 in this regard this study proves how the same model application calibrated through very similar parameters for four different model software packages may deliver different results 4 2 4 validation and uncertainty analysis models usually include specific tools to validate and assess the uncertainty of their outputs however if this is not possible the generation of outputs that can be easily exported to other validation software or even the connection between the models and these software is equally effective in this regard metronamica ca markov and lcm give the user a wide range of options for model validation through the map comparison kit and terrset the provision of flexible gis frameworks where users can design and implement their own validation methods like in dinamica ego is another valid option for the provision of validation and uncertainty management tools it is important that the model developers provide the users guide and assistance when making these validation exercises or generally assessing the model uncertainty in this regard elsawah et al 2020 pointed out a gap between theory and practice in the implementation of uncertainty assessment exercises it is common the availability of model manuals and tutorials that give some tips to this end like in the four models compared however specific guidelines about validation and above all about uncertainty analysis are usually lacking and have been not found for any of the compared models when available they focus on one or a few analyses and do not make the user aware of the complexity that a full validation and uncertainty analysis may entail 4 2 5 communication of uncertainty there is still a lack of attention in the provision of tools to communicate the uncertainty that the models provide which is especially important for their correct use among decision makers and stakeholders elsawah et al 2020 none of the analysed models provides enough tools to communicate most of the uncertainties of the analysis to the audience from the problem conceptualization to the model validation models just focus on specific sources of uncertainty but not on the whole uncertainty of the modelling exercise this can be related with the lack of an agreed framework for uncertainty assessment in lucc modelling the development of external tools easily connected with the models that fulfil that need could be an alternative solution the generation of probability outputs which account for the model stochasticity and variability among model runs is a useful approach to communicate the uncertainty of single outputs however only metronamica includes a tool to produce these outputs which could be especially useful in dinamica ego due to the important stochasticity that the model can convey notwithstanding this result could be inconvenient if it is not properly used it can give the audience a false perspective about the uncertainty of the simulation it just accounts for the system s uncertainty that the models try to replicate through a stochastic component however it does not account for all the other sources of uncertainty which we have addressed in this paper 5 conclusions each model software package conceptualized the modelled system in a different way which led to differences in the way the luc dynamics and changes were simulated despite of these differences there is not a best modelling approach each model entails different uncertainties and limitations which must be carefully considered by their potential users in this regard comparing different model outputs for the same application is a good approach to account for the structural uncertainty of our modelling exercises the less automatic the model workflow is the more options the user has to control the model structural uncertainty in this regard constrained approaches that offer little room for user intervention like lcm can be associated to important sources of structural uncertainty if the model structure does not perfectly fit with the modelled processes nonetheless very flexible approaches which rely a lot on user or expert knowledge may become very dependent on the uncertainties introduced by them thus mixed approaches like dinamica ego are considered preferable nonetheless statistical or automatic modelling approaches did not provide in our study case more repeatability or better simulation scores than models relying on user knowledge which proved that user intervention is not necessarily associated with more uncertain simulations offering several options or methods for change potential calculation quantity of changes estimation and change allocation allows user intervention in the modelled process but does not leave all decisions in the user however when offering several options or methods these should be complementary and provide different approaches in this regard the different options for change potential calculation offered by lcm provided similar results randomness and scenario management were identified as two important elements to account for the uncertainty of the modelled processes but are not usually included in all models in our case only dinamica ego and metronamica were able to both simulate stochastic simulations and generate different scenarios in addition we have identified a lack of attention in models to important aspects related with uncertainty management such as the communication of model uncertainties and the provision of tools and guidance for uncertainty analysis declaration of competing interest the third author of the paper hedwig van delden is the director of the research institute for knowledge systems riks which develops commercializes and promotes the metronamica software there is not any conflict of interest between the rest of the authors and the models assessed acknowledgements this work was supported by the spanish ministry of science innovation and universities and the feder european regional development fund incertimaps pgc2018 100770 b 100 spanish ministry of economy and competitiveness and the european social fund ayudas para contratos predoctorales para la formación de doctores 2014 university of granada contratos puente 2018 spanish ministry of science and innovation ayudas para contratos juan de la cierva formación 2019 fjc2019 040043 the first author also appreciates the support of the university of cape town centre for transport studies in the development and set up of the model used in this paper appendix a supplementary data the following are the supplementary data related to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 multimedia component 3 multimedia component 3 appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2022 105411 
25589,the newly developed open source hydrological pixel model hypix written in the fast and flexible julia language efficiently solves the mixed form of the richardson richards equation rre hypix uses a cell centred finite volume scheme for the spatial discretization with an implicit euler scheme for the temporal discretization by using the weighted average inter cell hydraulic conductivity hypix includes the following modules a rainfall interception b root water uptake with compensation algorithm and root growth c soil evaporation d ponding using a novel method for computing sorptivity and e runoff hypix includes a wide range of top and boundary conditions flux pressure free drainage to control the newton raphson iterations hypix incorporates a novel dynamic physical smoothing criterion which improves not only the model performance but also its accuracy compared with using the traditional absolute convergence criterion to control the time step the traditional physical time step management based on changes in the soil water content was specifically designed to solve rre based on soil water content this work adapts the time step management such that it is specifically designed to solve rre based on soil water pressure without introducing further parameters the novel time step management also requires only one parameter and was found to be more efficient than the traditional time step management hypix implements an option to solve the derivatives numerically enabling the rre to be modified and tested e g the inter cell hydraulic conductivity by changing only a few lines of code numerically calculating derivatives was found to be as accurate as deriving the derivatives analytically and only 10 25 slower the well established hydrological model hydrus was used to validate hypix without the sink term the hypix results show good agreement to hydrus validating the algorithms implemented in hypix even for challenging conditions hypix can provide accurate and reliable results using the recommended standard options moreover the algorithm developed in hypix is more efficient than the one used in hydrus particularly for coarse texture soils the recommended options were also tested by running hypix with sink term using field data graphical abstract image 1 keywords richardson richards equation unsaturated porous media variably saturated flow time stepping manager newton raphson step julia language 1 introduction understanding and modelling processes within the critical zone extending from the top of the vegetation canopy to the lower limit of groundwater are of great importance for better managing and protecting water resources e g ranatunga et al 2008 under increasing demands and changing climatic conditions national research council 2001 the vadose zone holds a central position in this complex system governed by numerous interactions as a result the development of robust and efficient numerical solutions describing water flows in unsaturated porous media remains a challenge that is relevant to a wide range of scientists agricultural applications and policy makers the richardson richards equation rre richardson 1922 richards 1931 usually known as richards equation which combines the continuity equation with darcy buckingham s db law provides a physical basis for modelling the water movement through the unsaturated zone e g farthing and ogden 2017 raats 2001 hence it is implemented in many distributed hydrological models at watershed or regional scales e g shen and phanikumar 2010 and also in land surface models that often represent the vertical water movement in the soil through the 1d rre e g bisht et al 2018 dai et al 2019 a key condition to validate this approach remains the existence of a local scale for which db law is valid and suitable physical parameters can be provided for the constitutive relationships describing the k ψ hydraulic conductivity l t 1 and θ ψ volumetric water content l3 l 3 functions of the soil water pressure ψ l since highly non linear parametric models are generally used to describe these interdependent relationships the rre must be solved numerically because there is no exact analytical solution this means that modellers are burdened with solving a non linear partial differential equation potentially varying between a hyperbolic to a parabolic mathematical form depending on the soil condition all things considered the numerical solution of the rre is one of the most challenging problems in earth sciences with a high risk of non convergence e g farthing and ogden 2017 advanced numerical schemes well suited to handling complex spatial grids e g qi et al 2018 and optimized time discretization procedures are available to solve the different forms of the rre fahs et al 2009 farthing and ogden 2017 maina and ackerer 2017 to briefly summarize the current situation the θ form of the rre provides excellent mass balance but cannot handle water flows in saturated zones and exhibits discontinuities in the dependent variable across soil layer boundaries on the other hand the ψ form is continuous in both saturated and unsaturated zones but can suffer large mass balance errors celia et al 1990 hills et al 1989 finally the rre is often presented and solved using the mixed form and the computational codes usually contain a step where the primary variable is chosen to linearize and solve the mathematical system which then updates secondary variables very efficient results have been obtained with variable switching methods these consist of selecting the primary variable to be computed i e θ or ψ for each node of the matrix system as a function of the saturation of the soil diersch and perrochet 1999 forsyth et al 1995 wu and forsyth 2001 improvements especially for non smooth transitions between alternative primary variables have been developed to prevent unrealistic solutions or numerical difficulties krabbenhøft 2007 lehmann and ackerer 1998 zha et al 2017 the temporal discretization usually proceeds with an implicit scheme and the resulting non linear algebraic system requires an efficient and robust linearization technique that maintains mass conservation and accuracy of the solution the picard and newton raphson nr iterative methods are the most widely used procedures for solving the rre due to its robustness and simplicity the picard method is more widespread and has been for instance implemented in several popular numerical codes solving the rre such as the hydrus šimůnek et al 2016 and swap van dam et al 2008 models nonetheless slow or no convergence have been encountered with this technique for cases of saturated unsaturated interfaces gravity drainage or complex time varying boundary conditions paniconi et al 1991 the nr method has been found to be more efficient than the picard iteration method miller et al 1998 paniconi et al 1991 paniconi and putti 1994 but it increases algebraic complexity and computational costs because of the jacobian matrix containing some derivative terms and leading to a non symmetric matrix system paniconi and putti 1994 convergence failure of the nr method can occur in some unfavourable flow conditions especially when simulating infiltration into initially dry soils where the head gradient at the wetting front is extremely large to solve this numerical difficulty zha et al 2019 proposed an algorithm where the ψ before and after the iteration are examined the proposed modifications do not degrade the simulated results leading to more robust convergence performances and cost effective simulations for this particularly challenging conditions alternatively efficient non iterative techniques can also be implemented kavetski et al 2002 li et al 2021 finally linked with the linearization technique and the spatial discretization scheme the numerical solution of the rre can be sensitive to the convergence control strategies and the method to adapt the time step size during the simulation compared to using a fixed time step adaptive time discretization is more efficient and has become quite common ranging from heuristic to control based error methods a large number of heuristic time stepping methods have been proposed in the literature e g thomas and gladwell 1988 kavetski et al 2001 kavetski and binning 2004 miller et al 2006 belfort et al 2007 a key aspect justifying ongoing research of improvements relies on the need to balance run time robustness accuracy and flexibility despite numerous efforts over the last decade algorithms to achieve fast and accurate solutions are still actively being researched e g zha et al 2019 here we propose improvements to the solution of the rre and implement them in the novel hydrological pixel hypix model using the mixed form of the rre the solution of the rre is based on maina and ackerer 2017 for which the rre partial differential equation is solved using a cell centred finite volume implicit finite differences scheme for the spatial discretization with an implicit euler scheme for the temporal discretization by using the weighted average inter cell hydraulic conductivity then hypix solves the mixed form of the rre using the nr method to avoid overshooting and losing control of the nr step we propose a new physical method which automatically controls the convergence rate depending on the difficulty to get the solution as previously mentioned the drawback of solving the rre with the nr method is that it requires reprogramming the computation of the jacobian matrices i e the derivatives of the parameters with respect to ψ hence for testing purposes changing inter cell hydraulic conductivities leads to a reprogramming of the derivatives to overcome this limitation hypix takes advantage of the julia language bezanson et al 2017 perkel 2019 which enables automatic resolution of derivatives revels et al 2016 an updated physical time stepping scheme has been developed that is tailored to solve the rre based on ψ and not θ without introducing additional parameters the time stepping management module optimizes the size of the time step δt such that hypix uses the largest δt while meeting the targeted water balance and accuracy of the solution our technique is adapted from kirkland et al 1992 and ross 2003 because their time stepping management is physically based such that δt is directly derived from the residuals of the water balance and requires fitting of only one physical parameter δt is calculated via a maximum increase or decrease of the degree of saturation for each cell this ensures a higher time resolution when θ variations are large which improves the convergence rate at the wetting front the newly developed model has a reduced number of parameters to manage the solving of the rre compared to other physically based hydrological models hypix can a process a large number of soil layers described by the kosugi 1994 1996 unimodal and bimodal k ψ and θ ψ hydraulic parameters for each soil layer b simulate for the top boundary condition realistic water ponding and runoff at the soil surface by using a novel approach for the computation of sorptivity c compute root water uptake and evaporation d apply a wide range of bottom boundary conditions such as prescribed bottom flux or pressure i e water table free drainage and impermeable layer and e model impermeable layers this paper is organized as follows section 2 presents the bimodal soil kosugi hydraulic functions used in hypix to describe the rre and the novel approaches to solve it section 3 presents the five synthetic test cases used to validate hypix with hydrus and the experimental data from five field sites section 4 presents the results of comparing hydrus with hypix and the performance of different hypix option used with field experimental data section 5 discusses the results of the best hypix options based on synthetic and field experimental data and section 6 summarizes the main conclusions 2 theory 2 1 bimodal kosugi soil hydraulic functions hypix uses the bimodal kosugi 1994 1996 soil hydraulic functions the choice of the kosugi soil hydraulic functions is based on the physical interpretation of their parameters in relation to the soil pore size distribution the kosugi hydraulic parameters can be physically interpreted and constrained by exploiting physical relationship between the parameters fernández gálvez et al 2021 pollacco et al 2013b moreover the selection of bimodal functions is based on the prevalence of soils with bimodal pore system e g jarvis 2007 mcleod et al 2008 where macropores and micropores lead to two stage drainage fast flow macropore flow can occur when the water pressure head exceeds the threshold needed to activate the macropore network adding to the matrix flow below this threshold only the matrix participates in the flow fernández gálvez et al 2021 the representation of the θ ψ and k ψ functions is based on the dual porosity model of pollacco et al 2017 1 θ ψ θ mat ψ θ mac ψ if ψ 0 θ mat ψ 1 2 θ s macmat θ r e r f c ln ψ ψ m 2 σ θ r θ mac ψ 1 2 θ s θ s macmat e r f c ln ψ ψ m mac 2 σ mac elseif ψ 0 θ mat ψ θ s macmat θ mac ψ θ s θ s macmat 2 k ψ k mat s e ψ k mac s e ψ if ψ 0 s e ψ θ θ r θ s θ r 1 2 θ s macmat θ r θ s θ r erfc ln ψ ψ m 2 σ θ s θ s macmat θ s θ r erfc ln ψ ψ m mac 2 σ mac k mat s e ψ k s θ s macmat θ r θ s θ r s e ψ 1 2 erfc ln ψ ψ m 2 σ σ 2 2 k mac s e ψ k s θ s θ s macmat θ s θ r s e ψ 1 2 erfc ln ψ ψ m mac 2 σ mac σ mac 2 2 elseif ψ 0 k mat s e ψ k s θ s macmat θ r θ s θ r k mac s e ψ k s θ s θ s macmat θ s θ r where erfc is the complementary error function θ l3 l 3 represents the volumetric soil water content and ψ l the soil water pressure considering ψ 0 for unsaturated soils i e matrix suction θ s l3 l 3 and θ r l3 l 3 are the saturated and residual volumetric soil water content respectively ln ψ m and σ denote the mean and standard deviation of ln ψ respectively in the soil matrix domain ln ψ mmac and σ mac denote the mean and standard deviation of ln ψ respectively in the macropore soil domain with the argument of ln in units of length i e ψ m ψ and ψ mmac in l θ smacmat l3 l 3 is the volumetric saturated water content that theoretically differentiates inter aggregate pores structural macropores and matrix domains intra aggregate micropores defining the corresponding soil water pressure threshold between macropore and matrix ψ macmat l s e ψ denotes the effective saturation as a function of ψ with values between 0 and 1 k s l t 1 is the saturated hydraulic conductivity and k s e ψ l t 1 refers to the unsaturated hydraulic conductivity written as a function of s e ψ for the case when θ smacmat θ s eq 1 and eq 2 reduce to the unimodal kosugi soil hydraulic functions the soil water capacity of the bimodal kosugi model is computed as follow 3 i f ψ 0 c θ ψ θ ψ θ mat ψ θ mac ψ θ s matmac θ r exp ln ψ ψ m 2 2 σ 2 2 π σ 2 ψ θ s θ s matmac exp ln ψ ψ m mac 2 2 σ mac 2 2 π σ mac ψ e l s e i f ψ 0 c θ ψ 0 and the derivative of k ψ with respect to ψ of the bimodal kosugi model is 4 k ψ k mat ψ k mac ψ i f ψ 0 s e ψ θ θ r θ s θ r 1 2 θ s macmat θ r θ s θ r erfc ln ψ ψ m 2 σ θ s θ s macmat θ s θ r erfc ln ψ ψ m mac 2 σ mac k mat ψ k s 2 π σ ψ θ s macmat θ r θ s θ r erfc ln ψ ψ m 2 σ σ 2 s e ψ exp ln ψ ψ m 2 σ σ 2 2 k s 8 π ψ θ s macmat θ r θ s θ r erfc ln ψ ψ m 2 σ σ 2 2 s e ψ θ s macmat θ r θ s θ r exp ln ψ ψ m 2 σ 2 σ θ s θ s macmat θ s θ r exp ln ψ ψ m mac 2 σ mac 2 σ mac k mac ψ k s 2 π σ mac ψ θ s θ s macmat θ s θ r erfc ln ψ ψ m mac 2 σ mac σ mac 2 s e ψ exp ln ψ ψ m mac 2 σ mac σ mac 2 2 k s 8 π ψ θ s θ s macmat θ s θ r erfc ln ψ ψ m mac 2 σ mac σ mac 2 2 s e ψ θ s macmat θ r θ s θ r exp ln ψ ψ m 2 σ 2 σ θ s θ s macmat θ s θ r exp ln ψ ψ m mac 2 σ mac 2 σ mac e l s e i f ψ 0 k ψ 0 2 2 richardson richards equation of hypix model modelling unsaturated flow in highly heterogeneous soils can be accurately performed by solving the rre richardson 1922 richards 1931 which is commonly adopted by soil vegetation atmosphere transfer models e g jones et al 2021 however the rre is highly non linear and despite numerous efforts over the last decade its solution using numerical methods is demanding and algorithms to achieve fast and accurate solutions are still actively being researched e g zha et al 2019 assuming a rigid solid matrix fig 1 the mixed form of the rre is written as 5 θ i ψ i t θ i ψ i t 1 δ t t s o θ i ψ i t θ s i ψ i t 1 ψ i t δ t t q i 1 2 t q i 1 2 t δ z i s i n k i ψ i t 1 where δt t t is the time step at time t δz i l is the mesh size of cell i with the vertical coordinate positive downwards θ i l3 l 3 is the volumetric soil water content of cell i θ s i l3 l 3 is the saturated volumetric soil water content of cell i s 0 l 1 is a parameter which ranges from 10 7 to 10 10 that accounts for fluid compressibility which is assumed to be constant with depth ψ i l is the soil water pressure of cell i considering ψ 0 for unsaturated soils q l t 1 is the soil water flux based on the extended db law which is positive downward and negative when water moves upwards q i 1 2 t l t 1 is the flux entering cell i and q i 1 2 t l t 1 is the flux exiting cell i and sink i l3 l 3 t 1 taken as positive is the sink term defined as the volume of water per unit time removed from cell i by soil evaporation section 7 6 1 and root water uptake section 7 6 2 2 2 1 water fluxes q 2 2 1 1 q below the top cell 2 i ni the darcian fluid flux q i 1 2 t l t 1 is computed by using the inter cell hydraulic conductivity between cell i and i 1 as described in fig 1 as follows 6 q i 1 2 t k i 1 2 ψ ψ i t ψ i 1 t δ z i 1 2 cos α δ z i 1 2 δ z i δ z i 1 2 k i 1 2 ψ w i k i ψ i t p 1 w i k i 1 ψ i 1 t p 1 p ω i δ z i δ z i δ z i 1 where q i 1 2 t l t 1 is the flux entering cell i from the top and q i 1 2 t is the flux exiting cell i from the bottom k i 1 2 l t 1 refers to the weighted average inter cell hydraulic conductivity e g haverkamp and vauclin 1979 belfort et al 2013 computed with ω i δ z i 1 2 l is the distance between cell centres i and i 1 as depicted in fig 1 α radian refers to the angle between the vertical axis and the slope of the soil s surface and p 1 for weighted average intercell conductivity as in this paper 2 2 1 2 top boundary conditions i 1 ponding and runoff two boundary conditions are currently available in hypix a novel flux boundary condition with infiltration driven by sorptivity section 2 2 1 2 1 and b prescribed top pressure boundary condition section 2 2 1 2 2 2 2 1 2 1 novel top flux boundary condition driven by sorptivity the nomenclature taken in this paper is that δ x is defined as t 1 t x t t 1 t 1 x t for the top flux boundary condition hypix checks if the top flux boundary condition imposed by the user throughfall precipitation δ p r through t l can infiltrate into the top layer if it is not the case the excess of precipitation ponds on top of the soil surface if ponding depth exceed the maximum ponding depth the excess water will be lost to runoff the amount of water infiltrating into the top cell i 1 for a period δt is computed by δ q 1 2 t l fig 1 as the rre cannot compute the top air soil boundary we compute δ q 1 2 t using the two term approximation of haverkamp et al 1994 as suggested by fernández gálvez et al 2019 the maximum infiltration depth for a given δt is δ q m a x 1 2 t l and is computed as 7 b 2 β 3 1 β 3 k θ 1 t 1 k s 1 δ q m a x 1 2 t q m a x 1 2 t δ t t s o r p t θ 1 t 1 δ t t b k s 1 δ t t cos α where q m a x 1 2 t l t 1 is the maximum soil water flux sorpt l t 1 2 is the soil sorptivity β is an integral shape parameter typically fixed at 0 6 haverkamp et al 1994 parlange et al 1982 and the slope α radian is the angle between the flow direction of recharge and the vertical axis 0 α π 2 for inclined flow sorptivity is computed using the mixed formulation proposed by lassabatere et al 2021 2022 the novelty of this sorptivity model is that it is highly efficient and accurate in the computation of sorptivity for all soil types from oven dry to saturation the sorptivity model is computed as 8 d θ k θ d ψ d θ s o r p t 2 θ 1 t 1 θ s 1 θ 1 t 1 θ s 1 θ 1 t 1 2 θ s 1 θ 2 θ 1 t 1 d θ d θ 0 ψ θ s 1 θ 1 t 1 2 θ s 1 θ ψ 2 θ 1 t 1 k ψ d ψ where d θ is the diffusivity function for which d ψ d θ is derived in eq 3 eq 8 splits the integral into two parts to allow the integration of continuous functions over closed intervals in the regular expression the d θ is infinite close to saturation θ θ s in the specific eq 8 the last part of the integration based on ψ is replaced with the integration of the hydraulic conductivity as a function of the water pressure k ψ alleviating the problem of convergence the maximum water infiltrating into the top cell δ q m a x 1 2 t must be less than the maximum available pore volume of the top cell 9 δ s i n k 1 ψ 1 t 1 δ z i δ t t s i n k 1 ψ 1 t 1 δ q m a x 1 2 t min δ q m a x 1 2 t δ z 1 θ s 1 θ 1 t 1 δ s i n k 1 ψ 1 t 1 where θ s1 l3 l 3 is the saturated volumetric soil water content and δsink 1 l the sink term of the top cell i 1 the amount of water that is not able to infiltrate into the soil can either run off laterally due to the slope or get ponded at the surface where ponding h pond t l is computed as 10 h pond t max δ p r through t h pond t 1 δ q m a x 1 2 t 0 where δ p r through t l is the throughfall precipitation i e the amount of water reaching the top cell appendix 7 5 it is to be noted that the novel top flux boundary condition driven by sorptivity does not require any additional hypix parameters runoff δ r u n o f f t l is generated if h pond t exceeds a user defined maximum ponding depth h pond m a x l as follow 11 δ r u n o f f t max h pond t h pond m a x cos α 0 h pond t min h pond t h pond m a x cos α 2 2 1 2 2 prescribed top pressure boundary condition ψtop the prescribed top water pressure boundary condition implies that ψ 1 t ψ top t the flux at the surface boundary is computed as follows 12 q 1 2 t k 1 ψ 1 t ψ 1 t 1 ψ top t δ z 1 2 cos α where ψ top t l is a user defined pressure hypix computes equivalent δ p r through t corresponding to ψ top t ψ 1 t 1 in future research the top water pressure boundary condition can be used to fine tune the sorptivity model eq 8 described above 2 2 1 3 bottom boundary conditions i ni the bottom boundary conditions implemented in hypix are special cases of the following eq 13 derived from eq 6 and include a free drainage section 2 2 1 3 1 b prescribed bottom pressure section 2 2 1 3 2 and c prescribed bottom flux section 2 2 1 3 3 the bottom boundary condition is universally computed as follows 13 q n 1 2 t k n ψ n t ψ n 1 t ψ n t δ z n 2 cos α 2 2 1 3 1 free drainage the free drainage boundary condition at the bottom of the soil profile occurs when ψ n t z n 1 in eq 13 leading to 14 q n 1 2 t k n ψ n t cos α 2 2 1 3 2 prescribed bottom pressure ψbot the prescribed bottom water pressure boundary condition ψ bot t l is a user defined variable positive for saturated and negative for unsaturated conditions set at the bottom of cell n of the soil profile ψ n 1 t which is derived from eq 13 and results in the following flux 15 q n 1 2 t k n ψ bot t ψ bot t ψ n t δ z n 2 cos α 2 2 1 3 3 prescribed bottom flux qbot the prescribed bottom flux boundary condition q bot t l is a user defined variable positive as a sink and negative as a source set at the bottom of cell n of the soil profile which derived from eq 13 results in the following flux 16 q n 1 2 t q bot t 2 3 solving the richardson richards equation using the newton raphson method the picard and newton raphson nr iterative methods are the most widely used procedures for solving the rre the nr method has been found to be more efficient than the picard iteration method lehmann and ackerer 1998 paniconi and putti 1994 so we solved the rre using the nr algorithm the nr method is used to solve ψ i t such that the residuals of each cell r i t l equal close to 0 r i t is derived from eq 5 as follow 17 r i t δ z i θ i ψ i t θ i ψ i t 1 δ z i s o θ i ψ i t θ s i ψ i t ψ i t 1 δ t t q i 1 2 t q i 1 2 t δ s i n k i ψ i t 1 δ s i n k i ψ i t 1 δ z i δ t t s i n k i ψ i t 1 where δsink i l is the sink computed for a given δt to stabilize the numerical scheme δsink i is computed with the ψ i values derived from the previous time step the nr method is computed using a first order taylor development by solving the jacobian matrices of the residuals r eq 17 in an iterative way that updates ψ i t k 1 ψ i t k until convergence is achieved the numerical discretization is a tridiagonal appendix 7 1 non linear set of equations that needs to be solved for ψ i t k 1 ψ i t k and for every iteration k as follows 18 ψ i t k 1 ψ i t 1 r i ψ i t k j i 1 i 1 r i ψ j t k ψ j t k ψ j t k 1 ψ j t k where the derivatives are described in appendices 7 2 and 7 3 the initial ψ i t 0 is derived either from measured θ t 0 or from ψ t 0 the computation of ψ min l which is the minimum allowed value of ψ is based on the assumption that θ ψ is log normal distribution and therefore according to fernández gálvez et al 2021 ψ min can be computed as follows 19 ψ i t ψ min i e ln ψ m i 4 σ i k ψ min i 0 the computation of ψ max l which is the maximum allowed value of ψ is more challenging to compute as it can be positive or negative therefore during the iteration when the water pressure is close to saturation it may change sign causing numerical instability zha et al 2017 to increase numerical stability for soils close to saturation ψ max switches depending on the value of ψ i t 1 as follow 20 if ψ i t 1 ψ macmat 2 ψ max i t ψ maxmax elseif ψ max i t 0 where ψ macmat l is the theoretical water pressure for which macropore starts to fill up corresponding to the minimum water pressure for which a soil can be considered close to saturation often taken as 100 mm e g jarvis 2007 ψ maxmax is a parameter for which its feasible range is provided in table 1 table 1 shows the feasible range as well as the recommended values for the parameters required to solve the rre with the hypix model 2 3 1 convergence criterion for a given time step the iteration of the nr method stops either when k n k where n k is a user defined maximum number of iterations table 1 or when the overall water balance of the residuals wb residual t 1 is satisfied the wb residual convergence criterion for the nr method is based on the euclidean norm of a vector r e g driscoll and braun 2017 kochenderfer and wheeler 2019 kelley 2003 21 w b residual i 1 n i r i t δ t t δ z i 2 n i where n i is the total number of cells as described in fig 1 the residuals are normalized such that wb residual is independent of the cell size δz and the time step δtt the feasible range of wb residual is provided in table 1 2 3 2 automatic differentiation of the jacobian with julia language one of the shortcomings of the nr solver is that it requires the mathematical derivatives of r eq 18 and derivatives described in appendices 7 2 and 7 3 the implementation of which can be complicated and time consuming e g modifying the inter cell hydraulic conductivity eq 6 for testing purposes requires recalculation of the derivatives to address this shortcoming hypix implements an option whereby the derivatives are derived automatically by using the forward mode automatic differentiation forwarddiff in the julia package revels et al 2016 https github com juliadiff forwarddiff version 0 10 24 was found to be as accurate as using the mathematical derivatives and only on average 16 slower compared with using the analytical derivatives we tested that for every boundary condition section 2 2 1 2 and section 2 2 1 3 the derivatives derived analytically section 7 2 give the same results accuracy 10 8 to those derived by using the forward mode automatic differentiation forwarddiff 2 3 3 adaptive time stepping management the time stepping management module optimizes the size of the time step δt such that hypix uses the largest δt while meeting the targeted water balance and accuracy of the solution among the heuristic time stepping methods in the literature we selected and improved the adaptive time stepping management of kirkland et al 1992 and ross 2003 this method is physically based such that δt is directly derived from the residuals of the water balance eq 17 and requires only one physical parameter δt is calculated via a maximum increase or decrease of the degree of saturation for each cell this ensures a higher time resolution when θ variations are large which improves the convergence rate at the wetting front below we present three options to optimize the size of the time step a the traditional time stepping management of kirkland et al 1992 and ross 2003 developed specifically for the rre and based on θ with a more realistic computation of average δ t t section 2 3 3 1 b a novel time stepping management of kirkland et al 1992 and ross 2003 adapted for rre based on ψ and implemented in hypix section 2 3 3 2 and c a condition to rerun hypix with the updated ψ and δ t t section 2 3 3 3 2 3 3 1 traditional adaptive time stepping management time stepping δθ the time stepping management of kirkland et al 1992 and ross 2003 assures numerical stability and avoids oscillation in the solution δt is derived by rearranging the terms of the residual eq 17 assuming that r 0 and s 0 0 s 0 is by definition small and strictly 0 for non compressible fluids and δ θ max θ i ψ i t θ i ψ i t 1 where δθ max l3 l 3 is a constant parameter describing the maximum change of θ for a given δt the δθ max feasible range is provided in table 1 we improved the time stepping computing δtt by putting more weight on cells that are dynamically active q i 1 2 t q i 1 2 t with ψ i t ψ i 1 t δ ψ active in other words hypix computes δtt considering the cells that are wetting up due to for example a wetting front in an initially dry soil bottom cells are inactive therefore δtt is computed as follows 22 n i t 1 for i 1 n i if ψ i t ψ i 1 t δ ψ active δ t i t δ z i δ θ max δ s i n k i ψ i t 1 q i 1 2 t ψ i 1 t 1 q i 1 2 t ψ i t 1 δ t min δ t i t δ t max n i t n i t 1 end end δ t t i 1 n i δ t i t 2 n i t where δt min t and δt max t are user defined minimum and maximum time steps described in table 1 which are used for safety in the code δψ active with a recommended constant value of 1 0 mm also described in table 1 and ni is the total number of cells the selected average δtt of a soil profile is computed from δ t i t which is derived from every cell using a modified euclidean norm of a vector based on driscoll and braun 2017 kochenderfer and wheeler 2019 and kelley 2003 as computed for wb residual in section 2 3 1 as described in eq 22 the computational time in hypix decreases as δt increases δt increases when a the size of the cell δz increases b the hydraulic properties from one cell to another depicted by q do not change dramatically c there are small pressure gradients ψ z d there are small differences in hydraulic properties and e when δθ max increases 2 3 3 2 novel adaptive time stepping management time stepping ψ for the robustness of the solution of the rre eq 5 based on ψ changes of δψ between two consecutive time steps must be small this is particularly the case when simulating infiltration into dry soil where the head gradient at the wetting front is extremely large leading to large computational efforts numerical instability and inaccuracy e g zha et al 2017 nevertheless describing a generic θ ψ a small change of δθ could result in a large change in δlnψ particularly near saturation and at the dry end of the θ ψ curve the traditional ross 2003 time stepping δθ eq 22 is modified by allowing δθ max to vary as described by δ θ max i t ψ such that δlnψ const for this we introduce a temporary parameter computed from and for every cell 23 δ ln ψ max i ln 1 ψ i t ln 1 ψ i t 1 to avoid introducing a second parameter we derive δlnψ max from δθ max for a given ψ θ the smallest δlnψ occurs at θ r θ smacmat 2 or at the kosugi parameter ψ ψ m therefore δ ln ψ max i δ θ max is computed for every cell as follows 24 θ 1 2 i θ r i θ s macmat i 2 θ ψ m δ l n ψ max i δ θ max ln ψ θ 1 2 i δ θ max 2 1 ln ψ θ 1 2 i δ θ max 2 1 2 δ θ max i t ψ is adjusted based on the maximum allowed change of δ ln ψ max i and ψ i t 25 δ θ max i t ψ i t δ ψ max i θ i e ln ψ i t 1 e δ ln ψ max i e δ ln ψ max i the advantage of δ θ max i t ψ δ θ max is that its steps are smaller at the wet end of the θ ψ curve δ t i t is computed by substituting δ θ max i t ψ instead of δθ max into eq 22 2 3 3 3 condition to rerun the time step δtt is computed using the previous water pressure ψ t 1 which may not reflect for example the passage of a wetting front requiring a reduced δtt therefore to assure accurate water balance and stability of the solution of the rre hypix is rerun with the updated δtt if δ t t ψ t δ t t ψ t 1 therefore hypix is rerun if the following condition is meet 26 δ t t ψ t 1 δ t min p δ t rerun 2 where δt min is the minimum time step described in table 1 if the maximum number of iterations is reached k n k and the condition eq 26 is not met then hypix is rerun with a reduced time step as follows 27 δ t t δ t min p δ t rerun 2 2 3 4 controlling newton raphson step the following algorithms are strategies to control the size of the nr step defined as 28 δ n r s t e p i ψ i t k ψ i t k 1 nr steps are implemented to avoid numerical instability and overshooting of the nr method the following algorithms are implemented into hypix a absolute convergence criterion section 2 3 4 1 b traditional smoothing method section 2 3 4 2 c novel dynamic smoothing method section 2 3 4 3 and d modified iteration for initially dry conditions proposed by zha et al 2017 section 2 3 4 4 the advantages of the different algorithms as well as the rationality of the recommended option in hypix are presented in the discussion 2 3 4 1 absolute convergence criterion traditional absolute convergence criterion to avoid overshooting of the nr step in line with common practices of solving the rre the absolute convergence criterion constrains the nr step by using δ ln ψ max i eq 24 in hypix for every cell δ n r s t e p i eq 28 is constrained as follows 29 e δ ln ψ max 1 max ψ i t k ψ i t k 1 i 1 i n i this absolute convergence criterion could be used in conjunction with other constraining methods described in the following sections 2 3 4 2 constant ω traditional smoothing with constant ω to avoid overshooting of the nr step to reduce overshooting of the nr step between two iterations and increase the efficiency we introduce a smoothening algorithm as follows 30 ψ i t k 1 ω ψ i t k 1 1 ω ψ i t k were ω 0 5 is a fixed parameter 2 3 4 3 dynamic ω novel smoothing with dynamic ω to avoid overshooting of the nr step the introduction of ω such as constant ω in section 2 3 4 2 was found to be highly successful in reducing convergence failure we therefore propose to improve the method such that ω varies for every cell and iteration the feasible range of ω is ω min ω max where ω ω max 1 means no reduction of the nr step and ω ω min 0 corresponds to a maximum reduction in the nr step a decrease of ω causes a slower convergence rate but increases the success rate of convergence of the nr for challenging conditions we therefore propose the following ω algorithm 31 ω i t k 1 ψ i t k ω max ω max ω min min θ ψ i t k 1 θ ψ i t k δ θ max i t ψ i t k 1 1 2 ψ i t k 1 ω i t k 1 ψ i t k ψ i t k 1 a 1 ω i t k 1 ψ i t k ψ i t k where δ θ max i t ψ i t k 1 was derived from eq 25 ω max 1 and the feasible range of ω min is provided in table 1 at a given t challenging situations for iteration k occur when θ ψ i t k 1 θ ψ i t k δ θ max i t ψ i t k 1 then the nr step is reduced it will be shown that the dynamic ω method is not only successful in increasing accuracy but also in increasing the speed of convergence 2 3 4 4 dry method modified iteration for initially dry conditions convergence failure normally occurs in some unfavourable flow conditions especially when simulating infiltration into initially dry soils to overcome this numerical difficulty we adopt the algorithm proposed by zha et al 2017 where the water pressure before ψ i t k and after ψ i t k 1 the iteration is examined to determine if there is any oscillation at the dry end of the θ ψ curve if ψ i t k is smaller than a user specified threshold ψ dry and ψ i t k 1 is greater than a user specified threshold ψ wet the risk of numerical divergence for this node is deemed to be very high under this condition ψ i t k 1 is estimated from the derived θ i t k 1 the soil water capacity of the bimodal kosugi model eq 3 32 i f ψ i t k ψ dry σ i and ψ i t k 1 ψ wet σ i ψ i t k 1 ψ θ i t k 1 ψ θ i t k θ i t k ψ i t k ψ i t k 1 ψ i t k the threshold values ψ dry and ψ wet depend on soil type and because σ defines the slope of the θ ψ curve we derived the following empirical expressions as a function of σ with the set of soils published by zha et al 2017 and shown in fig 2 33 ψ wet i max 2 312 σ i 2 2 937 σ i 27 830 0 ψ dry i exp 1 622 ln σ i 8 727 2 4 accuracy and efficiency of simulations 2 4 1 water balance the overall water balance wb l of the simulation is derived from the residuals r eq 17 and is computed for every time step as follows 34 w b t i 1 n i δ z i θ i ψ i t θ i ψ i t 0 i 1 n i t 1 n t δ z i s o θ i ψ i t θ s i ψ i t ψ i t 1 t 1 n t δ t t q 1 2 t q n 1 2 t i 1 n i t 1 n t δ s i n k i ψ i t where n t is the final time step and n i is the bottom cell it is expected that the wb error increases with the length of the simulation it is therefore normalized w b η to the cumulative infiltration 35 w b η w b t t 1 n t δ t t q 1 2 t an acceptable water balance at the end of the simulation occurs when w b η is smaller than the uncertainty of measuring precipitation 2 4 2 efficiency the efficiency of a simulation e ff t 1 is defined as the average number of iterations required to perform a day of simulation computed as follows 36 e f f ς t 1 n t k t t 1 n t δ t t where k is the number of iterations per time step which includes repeated simulation section 2 3 3 3 n t is the number of time steps and ς 86400 s if the units are in seconds therefore the smaller e ff the faster hypix would run for a given w b residual eq 21 2 5 summary of hypix algorithm initialization estimate the percentage of roots δrdf i per cell derived from the vegetation parameters eq 80 compute initial soil water pressure ψ ini l if required derived from initial observed θ t 1 compute δ ψ max i δ θ max i for every cell which will be used to compute the variable time step eq 25 and the dynamic ω eq 31 iteration of the nr which solves ψ of the rre for a given δt compute at the beginning of every time step new time step δt derived from ψ t 1 section 2 3 3 2 sorptivity from ψ t 1 to derive the maximum infiltration rate section 2 2 1 2 1 interpolation of δpr and δpet evap for a given δt vegetation parameters lai and k c which vary monthly section 3 2 2 potential evapotranspiration δpet transp and δpet evap section 7 4 precipitation not intercepted that reaches the ground surface δpr ground section 7 5 soil evaporation computed from ψ t 1 δ e v a p section 7 6 1 root water uptake computed from ψ t 1 δ r w u section 7 6 2 during each iteration compute the residuals eq 17 and derivatives eq 18 described in sections 7 2 and 7 3 compute δ θ max i t ψ i t k 1 eq 25 to manage the nr steps compute dynamic ω i t k 1 ψ i t k eq 31 to smoothen the newton raphson step continue the iteration loop of the nr until either the convergence criterion wb residual is met eq 21 or the maximum allowed iteration is reached after iteration is computed rerun the model if δ t t ψ t δ t t ψ t 1 with the new derived time step section 2 3 3 3 after the simulation is terminated compute the soil water balance and efficiency of simulation section 2 4 compute the outputs of interest at the time step of interest e g θ ψ q 3 material and methods two independent sets of data are used in this study 1 we describe five synthetic test cases for validating hypix with hydrus without including the sink term in the rre and 2 we present the experimental data from five contrasting sites used for testing hypix options under field conditions including the sink term for all test cases considered in this work we assumed that there is no runoff and therefore h pond m a x 3 1 synthetic test cases for validating hypix with hydrus without the sink term to assess the accuracy efficiency and computational costs of the different algorithms of hypix we compared the numerical solution of hydrus version 4 17 0140 radcliffe and simunek 2010 šimůnek et al 2016 with hypix by using five challenging published test cases the algorithm of hypix utilizes the recommended options and the recommended hypix parameters table 1 the hydrus model utilizes the recommended parameters except for the maximum time step δt max being reduced to 1 h and by increasing the maximum number of iterations n k to match that of hypix described in table 1 the reported test cases in the literature use the mualem van genuchten hydraulic functions mualem 1976 van genuchten 1980 and we transformed them into the kosugi 1994 1996 hydraulic functions ensuring the optimal ψ m and σ kosugi hydraulic parameters were physically sound by using the method described in fernández gálvez et al 2021 a description of the different test cases which combine different soil profiles with contrasting initial and boundary conditions tc1 to tc5 are summarized below tc1 infiltration in a homogeneous initially dry sandy loam soil with constant prescribed pressure at the surface and prescribed pressure at the bottom celia et al 1990 this test case is challenging to converge because it models the passage of a wetting front in an initially very dry soil with sudden variation of ψ tc2 same as tc1 but with a free drainage bottom boundary condition tc3 infiltration in a homogeneous clay loam soil initially at hydrostatic equilibrium with a prescribed constant flux at the soil surface and prescribed water table at the bottom miller et al 1998 the profile has linearly decreasing ψ initial conditions this test case models slow moving water in the presence of a water table tc4 infiltration at a constant rate into an initially dry heterogeneous soil with constant top flux at the surface and a free drainage bottom boundary condition zha et al 2017 the soil profile consists of three layers of equal thickness with a clay loam layer sandwiched between two sandy loam layers lehmann and ackerer 1998 the challenge of this test case is to model the movement of water at the interface of very contrasting soils tc5 same as tc4 but with an impermeable bottom boundary condition zha et al 2017 this test case is even more challenging than tc4 as the bottom boundary condition implies a change in the direction of the water fluxes when the wetting front reaches the impermeable bottom layer the soil hydraulic parameters boundary conditions and initial conditions for the five test cases considered are listed in table 2 the vertical discretization used in the simulations for the test cases was δz 10 mm 3 1 1 goodness of fit between hydrus and hypix the goodness of fit between the model outputs corresponding to the profile soil water content from hydrus and hypix was assessed using the root mean squared error rmse and the nash sutcliffe efficiency coefficient nse during a particular period as follows 37 r m s e t 1 n t i 1 n i δ z i θ i hydrus t θ i hypix t 2 n t 38 n s e max 1 t 1 n t i 1 n i δ z i θ i hydrus t θ i hypix t 2 t 1 n t i 1 n i δ z i θ i hydrus t δ z i θ i hydrus t 2 0 where θ i hydrus t and θ i hypix t refer to simulated soil water content values at each cell computed with hydrus and hypix respectively for which both models utilize the same vertical discretization δ z i 10 mm note that δ z i θ i hydrus t is the mean value for every cell i 3 2 field experimental data for testing hypix options with sink term 3 2 1 soils description the five sites used in this study are dairy cattle grazed pasture located in the waikato region of new zealand all soils have formed from airfall volcanic tephra but vary in their soil physical properties and heterogeneity particularly their texture and profile drainage characteristics a brief description of the soils follows the taupō soil is a sandy textured soil formed from volcanic airfall pumice material new zealand classification podzolic orthic pumice soil usda soil taxonomy classification orthod hewitt 2010 the otorohanga and waihou soils are also formed from airfall volcanic material but with finer tephra material compared with the taupō resulting in silty loam topsoil textures grading to silty clay in the subsoil they are classified in new zealand as typic orthic allophanic soils and in soil taxonomy as a haplohumult hewitt 2010 based on the soil morphology the otorohanga and waihou soils would be considered to have the least heterogeneous soil profiles of those used in this study since they have a reduced number of distinct layers the taupō site is expected to show more heterogeneity in water movement due to the stone content cichota et al 2016 the hamilton soil has a silt loam topsoil overlying clayey textured subsoils having formed into strongly weathered volcanic tephra it is classified in new zealand as a typic orthic granular soil and in soil taxonomy as a haplohumult hewitt 2010 the waitoa soil is a silty textured soil it is classified in new zealand as a typic orthic gley soil and in soil taxonomy as a haplohumult hewitt 2010 the soil morphology of hamilton and waitoa shows the greatest heterogeneity of the soils in this study as reflected in previous studies of soils with impeded drainage features mcleod et al 2008 vogeler et al 2019 3 2 2 vegetation data experimental sites are five mixed non irrigated pasture grass sites the trapezoidal feddes et al 1978 water stress response function section 7 6 2 was used with parameters for mixed pasture grass in new zealand derived from wesseling 1991 for all sites we used default values at four soil water pressures ψ feddes1 100 mm ψ feddes2 250 mm ψ feddes3 5000 mm and ψ feddes4 80 000 mm and the maximum root depth z nroot was averaged to 800 mm vogeler and cichota 2019 and percentage of roots in the top 300 mm δrdf top was 90 evans 1978 the crop coefficient k c and the lai section 7 6 2 vary throughout the growing season the range of k c 0 8 to 0 95 was taken from rotated grazing pasture according to an fao irrigation paper 56 allen et al 1998 and the range of the lai 0 19 to 5 10 was taken from van housen 2015 3 2 3 climate and soil water content data daily values of precipitation δpr l were measured using a tipping bucket rain gauge recording at 0 2 mm rain depth resolution potential evapotranspiration δpet l was derived from the new zealand virtual climate stations vcs network tait et al 2006 tait 2008 with estimates based on the spatial interpolation of actual data observations made at climate stations located around the country tait 2010 soil water content θ l3 l 3 was monitored at five depth increments to 1000 mm depth with minor increment variation between soils to reflect soil layer differences for the five sites hypix uses a 2 month period of warm up the yearly average precipitation and potential evapotranspiration using representative wet and dry periods from 6 months data are shown in table 4 4 results the results are organized as follows in section 4 1 we compare θ profile computed with hypix and hydrus by disabling the sink term for the five test cases described in section 3 1 not including the sink term causes a sharper ψ wetting front and therefore is a more challenging problem for the solver of the rre since including the sink term attenuates the wetting front moreover the sink terms computed in hydrus are different from the one computed in hypix in section 4 2 we run hypix using data from contrasting experimental sites section 3 2 and include the sink term to illustrate the benefits of the recommended hypix options derived in the test cases in section 5 1 we recommend hypix options such that in order of priority the results are stable converge are accurate have a good water balance and are efficient 4 1 validation of hypix with hydrus using synthetic test cases hypix simulations were derived using the dynamic ω section 2 3 4 3 the dry method section 2 3 4 4 for controlling the nr steps as well as the time stepping management based on ψ for solving the rre section 2 3 3 2 the comparison of the θ profiles at different times computed by hydrus solid line and hypix dashed line respectively for the five test cases described in section 3 1 are shown in fig 3 the different colours indicate the time since the beginning of each simulation and are evenly spaced red purple and yellow until the total time of simulation blue as shown in fig 3 the matching in θ profile between hydrus and hypix is excellent with almost indistinguishable θ profiles throughout the time for each of the five test cases this is also confirmed in table 3 with rmse eq 37 values very close to zero rmse 1 8 10 2 and nse eq 38 values close to 1 nse 0 93 computed between simulated θ profiles with hydrus and hypix models the drainage from the bottom cell during the total time of simulation δ q n 1 2 n i t computed with hypix and hydrus is similar as shown in table 3 therefore the algorithm implemented in hypix is as robust as the one implemented in hydrus 4 2 hypix tested with experimental sites in this section we run hypix with experimental data section 3 2 using time series of climatic variables soil information from the five contrasting experimental sites and the sink term of the rre to illustrate the benefits of the recommended hypix options in the previous section it was shown that for the five test cases hypix converged successfully using the physical time stepping ψ section 2 3 3 2 and the dynamic ω algorithm to control the nr step section 2 3 4 3 in combination with the dry method derived from zha et al 2017 section 2 3 4 in most applications solving the rre for hydrological modelling coarse vertical resolutions are used to decrease the computational burden an essential element of the numerical solution of the rre is that the solution converges as the spatial resolution increases to simulate hydrological fluxes accurately small vertical cell sizes in the order of 10 mm are required near the soil surface but not throughout the soil column downer and ogden 2004 the performance of hypix which uses the nr algorithm was tested using different discretization ranging from 10 to 100 mm data not shown to evaluate the model performance using the different options implemented in hypix we selected a vertical discretization of δz uz 20 mm and δz lz 50 mm where δz uz is the discretization of the upper zone in the root zone taken here as z 500 mm and δz lz is the discretization of the lower zone below the root zone the maximum errors of the water balance between the finest discretization δz uz 10 mm and δz lz 10 mm compared to a coarser discretization used to illustrate the model performance with the different options δz uz 20 mm and δz lz 50 mm for δdrainage and δsink are below 0 03 for all sites described in section 3 2 the yearly water balance for the five experimental sites is shown in table 4 and the plots are shown in fig 4 the rainfall interception algorithm uses vegetation parameters section 3 2 2 which are described in appendix the closure of the simulated water balance is shown by the normalized overall excellent water balance w b η 10 4 eq 35 for each of the five experimental sites table 5 evaluates hypix performance through w b η and e ff of the simulations by a using not using the dry method and b using the smoothing criteria with ω either constant or dynamic with the recommended options described in the last row we obtain excellent results with w b η 10 4 and e ff 66 day 1 the benefits of using the dry method and the dynamic smoothing criterion are discussed in section 5 5 discussion to concisely interpret the significance of the algorithms implemented in hypix we present in this section the recommended hypix options as well as the pros and cons of each of them as evidenced by the results 5 1 recommended hypix options the results described in fig 3 and table 5 were derived using the time step controlled by using the physical time stepping ψ section 2 3 3 2 and the nr step is managed using the dynamic ω section 2 3 4 3 in combination with the dry method derived from zha et al 2017 section 2 3 4 we did not use the absolute convergence criterion section 2 3 4 1 for reasons discussed in section 5 5 we discuss the recommended hypix options derived from the synthetic test cases section 4 1 and the experimental data set section 4 2 having the greatest probability to be successful in most cases such that in order of priority the results are stable successful converge are accurate have a good water balance and are efficient as described in table 5 for the four test cases except for tc5 the accuracy of the hypix wb is greater than that for hydrus the e ff of hypix for tc1 coarse soils is 44 times more efficient due to the implementation of time stepping ψ and the dynamic ω in combination with the dry methods hypix was also slightly more efficient in tc2 using the same soils as in tc1 the e ff in tc3 with hydrus and hypix are quite similar but hypix was slightly more efficient in tc4 for the modelling of impermeable layers tc5 hydrus was five times more efficient than hypix this is further discussed in section 5 6 5 2 benefits of time stepping ψ compared to time stepping θ by using the hypix parameters described in table 1 we found that for tc1 and tc2 coarse texture soils the model failed to converge when using as an option the traditional time stepping θ nonetheless these cases were successful when using the time stepping ψ for the other test cases the time stepping θ was successful and marginally more efficient in the wb and e ff results not shown than the time stepping ψ the time stepping ψ is more accurate than the time stepping θ particularly for coarse texture soils because the time stepping ψ reduces δt when the soil is close to saturation by reducing δ θ max i t eq 25 this is important because close to saturation we have θ ψ 1 which could lead the nr step to go to infinity therefore the adaptive time stepping management for solving the rre based on ψ is the recommended option for hypix because it enables the success of convergence and accuracy for all soil types and boundary conditions 5 3 benefits of the dry method the use of the modified iteration criterion for initially dry conditions from zha et al 2017 section 2 3 4 4 enables tc1 and tc2 to converge using large δθ max table 1 nevertheless the dry method had no effect for the other finer texture test cases similar results were found in table 5 by using real test cases with finer texture soils the results are in line with those of zha et al 2017 who found that the dry methods only benefited coarse texture soils with small σ and when infiltration occurs into initially dry conditions the dry method successfully detects if there is any oscillation at the dry end of the θ ψ curve caused by infiltration into dry soils if this occurs then the next iteration is computed from θ ψ eq 3 in order to apply the dry method ψ dry σ and ψ wet σ eq 39 need to be computed we recommend applying the dry method for all soils because it gets activated only when oscillation occurs at the dry end of the θ ψ curve 5 4 benefits of dynamic ω the benefits of the novel physical dynamic ω smoothing criterion section 2 3 4 3 for controlling the nr steps compared to the traditional constant ω section 2 3 4 2 was evaluated with the experimental data section 4 2 under variable fluxes and sink term using the universal hypix parameters described in table 1 the novel dynamic ω smoothing criterion outperforms in accuracy and efficiency the smoothing criterion with constant ω for all sites the use of the dynamic ω dramatically reduces w b η eq 35 by three orders of magnitude and increases e ff threefold this is because the nr step reduces automatically during iteration when large θ ψ i t k 1 θ ψ i t k is encountered compared to δ θ max t k eq 25 computed from time stepping ψ the convergence rate is slowed but the success rate of convergence is increased the other benefit of the dynamic ω is that it does not require any extra parameters we therefore strongly recommend the dynamic ω smoothing criterion 5 5 non benefits of the absolute convergence criterion for tc1 and tc2 sandy loam soils there were some minor improvements in the wb and e ff using the absolute convergence criterion section 2 3 4 1 to control the nr step results not shown nevertheless when using the absolute convergence criterion for finer texture soils such as tc3 tc4 and tc5 it failed to converge the absolute convergence criterion δ ln ψ max i ln ψ i t k ln ψ i t k 1 fails to improve the results because the dynamic ω accurately controls the nr step considering a smoother transition in the overall nr method therefore the use of the absolute convergence criterion is not recommended 5 6 impermeable layers in tc5 we model saturating a soil profile from the top with an impermeable layer at the bottom hypix is successful in obtaining excellent water balance being four orders of magnitude more accurate that hydrus and null drainage at the bottom while hydrus has some drainage at the bottom this would explain why hypix is considerably less efficient for this case than hydrus because with the selected parameters hypix has higher accuracy 6 conclusions the newly developed open source hydrological pixel model hypix written in the fast and flexible julia language efficiently solves the mixed form of the rre hypix uses a cell centred finite volume scheme for the spatial discretization with an implicit euler scheme for the temporal discretization by using the weighted average inter cell hydraulic conductivity hypix includes the following modules a rainfall interception b root water uptake with compensation algorithm and root growth c soil evaporation and d ponding and e runoff using a novel method for computing sorptivity hypix includes a wide range of top and boundary conditions flux pressure free the drawback of using the nr method for solving the rre is that every configuration e g changing the inter cell hydraulic conductivity requires reprogramming the derivatives appendix hypix implements an option to solve the derivatives numerically section 2 3 2 enabling the rre to be modified by changing only a few lines of code numerically calculating derivatives was found to be as accurate as deriving the derivatives mathematically and only 10 25 slower for controlling the newton raphson steps hypix incorporates several options where it is demonstrated that the recommended novel physical smoothing criterion for controlling the newton raphson step with dynamic ω improves not only the model performance but also its accuracy compared to using the traditional absolute convergence criterion for controlling the time step the physical time step management based on δθ kirkland et al 1992 ross 2003 was specifically designed to solve rre based on θ therefore we adapted the time step management so that it is specifically designed to solve rre based on ψ without introducing further parameters the novel time step management requires only one parameter and was found to be more efficient than the traditional time step management the well established hydrological model hydrus was used to validate hypix the comparison of both models shows a remarkable agreement confirming the validity of the algorithms implemented in hypix even for challenging conditions hypix can provide accurate and reliable results using the recommended standard options moreover the algorithm developed in hypix generates results more efficiently that the one used in hydrus particularly for coarse texture soils an additional benefit of hypix is its simplicity to use because it requires only eight parameters hydrus has 13 fitting parameters and most of them can be safely kept to the recommended value described in table 1 the stability and robustness of the solution of the rre in hypix enables it to be used for inverse modelling software data availability the hypix model source code and the test cases can be downloaded from https github com manaakiwhenua soilwater toolbox jl and is open source under the gp 3 0 license hypix is written in the open source julia programming language and can be run under multiple platforms https julialang org downloads access to the experimental field data require permission from environment canterbury https www ecan govt nz while the sites and the latest monitoring data can be viewed at https www waikatoregion govt nz environment envirohub environmental maps and data dt soil moisture af latestvalue a latest hypix is part of a set of interlinked modules implemented into the soilwater toolbox ecosystem led by j a p pollacco from manaaki whenua landcare research in new zealand and j fernández gálvez from the university of granada in spain the preliminary objective of the soilwater toolbox is to derive the soil hydraulic parameters by using wide range of cost effective methods the estimated hydraulic parameters can be directly implemented into hypix to compute the soil water budget the soilwater toolbox enables the comparison and sensitivity analyses of the hydraulic parameters computed from different methods on the soil water fluxes the following modules are currently included into the soilwater toolbox intergranular mixing particle size distribution module derives unimodal hydraulic parameters by using particle size distribution pollacco et al 2020 general beerkan estimation of soil transfer parameters module derives the unimodal hydraulic parameters from single ring infiltration experiments fernández gálvez et al 2019 sorptivity module a novel computation of sorptivity used in the general beerkan estimation of soil transfer parameters method lassabatere et al 2021 2022 saturated hydraulic conductivity module derived from unimodal and bimodal θ ψ pollacco et al 2013b 2017 inverse module which inverts hydraulic parameters from θ time series pollacco et al 2022 reduce uniqueness module of a physical bimodal soil kosugi hydraulic parameters from inverse modelling fernández gálvez et al 2021 using water retention and or unsaturated hydraulic conductivity data directly measured in the laboratory or indirectly obtained from inverting θ time series declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could appear to influence the work reported in this paper acknowledgements this research was supported by the winning against wildings research programme funded by the new zealand ministry of business innovation and employment and through the manaaki whenua led next generation s map research programme we would like to thank justin wyatt waikato regional council new zealand for providing monitored data for the field sites funding for open access charge universidad de granada cbua appendix jacobian matrices the newton raphson solution requires the jacobian matrix which can be written in a matrix form as an example with n iz depths the numerical discretization is a tridiagonal non linear set of equations which needs to be solved for ψ i z i t k 1 ψ i z i t k for every time step and for every iteration k 40 i 1 i 2 i 3 i n 1 i n r 1 t k ψ 1 t r 1 t k ψ 2 t 0 0 0 r 2 t k ψ 1 t r 2 t k ψ 2 t r 2 t k ψ 3 t 0 0 0 r 3 t k ψ 2 t r 3 t k ψ 3 t r 3 t k ψ 4 t 0 0 0 r n 1 t k ψ n 2 t r n 1 t k ψ n 1 t r n 1 t k ψ n t 1 0 0 0 r n t k ψ n 1 t r n t k ψ n t ψ 1 t k 1 ψ 1 t k ψ 2 t k 1 ψ 2 t k ψ 3 t k 1 ψ 3 t k ψ n 1 t k 1 ψ n 1 t k ψ n t k 1 ψ n t k r ψ 1 t k r ψ 2 t k r ψ 3 t k r ψ n 1 t k r ψ n t k the solution of these sets takes place by means of the tridiagonal function which is an effective modification of the gauss algorithm for the solution of a tridiagonal linear set of equations in julia we use the efficient tridiagonal function to solve the matrix the derivatives of r are shown below derivatives of residuals julia i 1 eq r ψ r 1 t k ψ 0 t not applicable 41 r ψ r 1 t k ψ 1 t same as 2 i n 1 42 r ψ r 1 t k ψ 2 t same as 2 i n 1 43 2 i n 1 r ψ r i t k ψ i 1 t 1 δ t q i t ψ i 1 t 44 r ψ r i t k ψ i t δ z i θ i ψ i t ψ i t 1 s o θ s ψ i t 1 ψ i t s o θ s θ i ψ i t δ t q i 1 2 t ψ i t q i 1 2 t ψ i t 45 r ψ r i t k ψ i 1 t δ t q i 1 2 t ψ i 1 t 46 i n r ψ r n t k ψ n 1 t same as 2 i n 1 47 r ψ r n t k ψ n t same as 2 i n 1 48 r ψ r n t k ψ n 1 t not applicable 49 derivatives of q julia i 1 eq q ψ q 1 2 t ψ 0 t not applicable 50 q ψ q 1 2 t ψ 1 t flux top boundary condition 0 51 prescribed top pressure boundary condition ψ t o p t ψ 1 t δ z 1 2 cos α k 1 ψ 1 t ψ 1 t k 1 ψ 1 t δ z 1 2 52 q ψ q 1 1 2 t ψ i t same as for 2 i n 53 q ψ q 1 1 2 t 1 ψ 2 t 1 same as for 2 i n 54 julia 2 i n 1 q ψ q i 1 2 t ψ i 1 t 1 w i ψ i 1 t ψ i t δ z i 1 2 cos α k i 1 ψ i 1 t ψ i 1 t w i k i ψ i t 1 w i k i 1 ψ i 1 t δ z i 1 2 55 q ψ q i 1 2 t ψ i t w i ψ i 1 t ψ i t δ z i 1 2 cos α k i ψ i t ψ i t w i k i ψ i t 1 w i k i 1 ψ i 1 t δ z i 1 2 56 q ψ q i 1 2 t ψ i t 1 w i 1 ψ i t ψ i 1 t δ z i 1 2 cos α k i ψ i t ψ i t w i 1 k i 1 ψ i 1 t 1 w i 1 k i ψ i t δ z i 1 2 57 q ψ q i 1 2 t ψ i 1 t w i 1 ψ i t ψ i 1 t δ z i 1 2 cos α k i 1 ψ i 1 t ψ i 1 t w i 1 k i 1 ψ i 1 t 1 w i 1 k i ψ i t δ z i 1 2 58 julia i n recharge q ψ q n 1 2 t ψ n 1 t same as for 2 i n 1 59 q ψ q n 1 2 t ψ n t same as for 2 i n 1 60 q ψ q n 1 2 t ψ n t free drainage bottom boundary condition k n ψ n t ψ n t cos α 61 prescribed bottom pressure boundary condition ψ n t ψ bot t δ z n 2 cos α k n ψ n t ψ n t k n ψ n t δ z n 2 62 bottom boundary condition 0 63 q n 1 2 t 1 ψ n 1 t 1 not applicable as ψ n 1 t 1 const 64 potential evapotranspiration the potential evapotranspiration depth δpet l for a time step δt is computed using the penman monteith equation input variables used the estimates derived from the new zealand virtual climate stations network vcs which are based on the spatial interpolation of actual data observations made at climate stations located around the country tait et al 2006 we assume that 65 δ p e t δ p e t int where δpet int l is the interception potential evaporation depth which is the potential evaporation from a wet canopy the remaining energy that is not used to evaporate water from a wet canopy e g periods with no rainfall allows the potential evapotranspiration depth δpet et l to be computed as 66 δ p e t et δ p e t δ e v a p int where δevap int l is derived from the actual energy used to evaporate water from a wet canopy the potential transpiration depth of vegetation δpet transp l and potential evaporation depth of soil δpet evap l is partitioned from δpet et by using the beer lambert law which uses as parameters the leaf area index lai lai can be derived from remote sensing béland et al 2014 the beer lambert law assumes that the net radiation inside the canopy decreases exponentially therefore the partitioning of δpet et is given by 67 δ p e t evap δ p e t et e k g l a i 68 δ p e t transp δ p e t et δ p e t evap where the extinction coefficient for solar radiation k g is set to 0 5 e g varado et al 2006 rainfall interception the parsimonious physically based interception model is an improvement made by pollacco et al 2013a the following interception model uses potential evaporation of a wet canopy δpet int eq 65 lai and extinction coefficient for solar radiation k g set to 0 5 the gross precipitation depth that falls on top of a canopy δpr l is partitioned following rutter et al 1971 as 69 δ p r δ p r int δ p r ground where δ p r ground l is the fraction of precipitation reaching the soil surface through gaps in the canopy and δ p r int l is the intercepted precipitation depth they are computed as 70 δ p r ground g apfrac δ p r δ p r int 1 g apfrac δ p r where the gap fraction g apfrac is calculated similarly to eq 67 71 g apfrac 1 e k g l a i the foliage of the canopy is considered as water storage filled up to depth sint l with a saturated storage capacity s i n t sat l when the canopy is fully saturated s i n t s i n t sat then any excess of δ p r int overflows δ p r over l to the soil surface the amount of water that reaches the soil surface is the throughfall precipitation l 72 δ p r through δ p r ground δ p r over the water storage of the canopy is first computed as 73 s i n t t s i n t t 1 δ p r int a fraction of the water from sint will be evaporated at the rate of the actual evaporation depth δ e v a p int l during and after a rainfall event the maximum quantity of water that can be evaporated from a wet canopy during a time step is computed according to deardorff 1978 which assumes that δ e v a p int is proportional to the fraction of the canopy that is wet 74 δ e v a p int δ p e t int min s i n t t s i n t sat s i n t sat p e v a p int where pevap int is a constant parameter for which deardorff 1978 gives a constant value of 2 3 δ p r over is computed as 75 δ p r over m i n s i n t t 1 δ p r int δ e v a p int s sat 0 s i n t t m i n s i n t t 1 δ p r int δ e v a p int δ p r over 0 rainfall interception of gross rainfall loss i n t e r c e p t i o n l o s s 0 1 is computed by 76 i n t e r c e p t i o n l o s s 1 t 1 n t δ p r through t t 1 n t δ p r t in the hypix model the rainfall interception module is run first followed by the computation of δpet transp and δpet evap as described in appendix sink term the sink term δsink described in eq 5 is a function of the soil evaporation depth δ e v a p l eq 78 and the root water uptake depth of the vegetation δ r w u l eq 79 77 δ s i n k δ e v a p δ r w u evaporation δevap the evaporation model based on romano and giudici 2009 and adapted by pollacco and mohanty 2012 is computed as 78 δ e v a p δ p e t evap s e 1 where se 1 0 1 refers to the effective soil water content defined in eq 1 for the top cell and δ p e t evap l is the potential evaporation depth computed with the beer lambert law eq 67 root water uptake δrwu the root water uptake computes the volume of water removed per unit time from a unit volume of soil in the root zone and is computed for each cell i 79 δ r w u i min k c δ p e t transp δ r d f i f w a t e r s t r e s s i r o o t c o m p i δ z θ i t θ r i t where δrwu l is the root water uptake depth k c is the crop coefficient δ p e t transp l corresponds to the potential transpiration depth eq 68 δrdf refers to the percentage of roots per cell fwaterstress is the water stress function per cell which computes the reduction of transpiration based on ψ and rootcomp is the root compensation by enabling water uptake from deeper layers when the upper layers are depleted root density function δrdf the percentage of roots per cell i is given by δrdf i which defines the general shape of the roots as given by the example provided in fig 5 the root distribution is based on an improved empirical function of gale and grigal 1987 which was modified by pollacco et al 2008 the model requires as parameters solely the maximum rooting depth z nroot l and the percentage of roots in the top 30 cm other values can be taken δrdf top the model compared to gale and grigal 1987 guarantees that the sum of δrdf i 1 the fraction of roots δrdf i for each cell i is computed as 80 δ r d f i r d z i 1 2 r d z i 1 2 1 r d z n root with i 1 i n root δ r d f i 1 where z i 1 2 and z i 1 2 l are respectively the depth of the top and the bottom of cell i as described in fig 1 r d is the routing distribution parameter computed numerically from z nroot and δrdf top r d varies between 0 7000 and 0 9999 such that when r d is close to 0 7 all the roots are distributed at the top and when r d is close to 1 the roots are evenly distributed within the root zone the value of r d is computed by solving the following equation 81 δ r d f top r d 0 r d 30 1 r d z n root 1 r d 30 1 r d z n root an example of δrdf is provided in fig 5a for a soil that has equal discretization water stress response function f waterstress the water stress response function f waterstress shown in fig 5b is a prescribed dimensionless function of ψ where 0 f w a t e r s t r e s s 1 following feddes et al 1978 f waterstress is defined by using four soil water pressure values leading to a trapezoidal curve so that f waterstress 0 close to saturation at a pressure greater than ψ feddes 1 and also above the permanent wilting point soil water pressure ψ feddes 4 f waterstress 1 between soil water pressures ψ feddes 2 and ψ feddes 3 for soil water pressure between ψ feddes 1 and ψ feddes 2 f waterstress increases linearly for soil water pressure between ψ feddes 3 and ψ feddes 4 f waterstress decreases linearly a schematic plot of this stress response function is depicted in fig 5b compensation mechanism root comp a root water uptake compensation mechanism is introduced to improve the prediction of transpiration by enabling water uptake from deeper layers when the upper layers are depleted although the percentage of roots at deeper depth is limited the compensation mechanism of li et al 2001 validated by braud et al 2005 is introduced the model requires the compensation mechanism parameter c which accounts for the general soil water content profile before computing the water uptake from individual cell i and is derived as 82 δ r o o t c o m p i f w a t e r s t r e s s i δ r d f i c 1 i 1 i n root f w a t e r s t r e s s i δ r d f i c where δ r d f i eq 80 is the vertical fraction of the root density function for each i cell f waterstress is the reduction of root water uptake at pressure head ψ for every cell and c is a parameter such that when c 1 the model is not compensated and when c 0 the δ r d f i becomes constant throughout the whole root zone depth i n root in hypix c 0 5 as suggested by li et al 2001 and braud et al 2005 
25589,the newly developed open source hydrological pixel model hypix written in the fast and flexible julia language efficiently solves the mixed form of the richardson richards equation rre hypix uses a cell centred finite volume scheme for the spatial discretization with an implicit euler scheme for the temporal discretization by using the weighted average inter cell hydraulic conductivity hypix includes the following modules a rainfall interception b root water uptake with compensation algorithm and root growth c soil evaporation d ponding using a novel method for computing sorptivity and e runoff hypix includes a wide range of top and boundary conditions flux pressure free drainage to control the newton raphson iterations hypix incorporates a novel dynamic physical smoothing criterion which improves not only the model performance but also its accuracy compared with using the traditional absolute convergence criterion to control the time step the traditional physical time step management based on changes in the soil water content was specifically designed to solve rre based on soil water content this work adapts the time step management such that it is specifically designed to solve rre based on soil water pressure without introducing further parameters the novel time step management also requires only one parameter and was found to be more efficient than the traditional time step management hypix implements an option to solve the derivatives numerically enabling the rre to be modified and tested e g the inter cell hydraulic conductivity by changing only a few lines of code numerically calculating derivatives was found to be as accurate as deriving the derivatives analytically and only 10 25 slower the well established hydrological model hydrus was used to validate hypix without the sink term the hypix results show good agreement to hydrus validating the algorithms implemented in hypix even for challenging conditions hypix can provide accurate and reliable results using the recommended standard options moreover the algorithm developed in hypix is more efficient than the one used in hydrus particularly for coarse texture soils the recommended options were also tested by running hypix with sink term using field data graphical abstract image 1 keywords richardson richards equation unsaturated porous media variably saturated flow time stepping manager newton raphson step julia language 1 introduction understanding and modelling processes within the critical zone extending from the top of the vegetation canopy to the lower limit of groundwater are of great importance for better managing and protecting water resources e g ranatunga et al 2008 under increasing demands and changing climatic conditions national research council 2001 the vadose zone holds a central position in this complex system governed by numerous interactions as a result the development of robust and efficient numerical solutions describing water flows in unsaturated porous media remains a challenge that is relevant to a wide range of scientists agricultural applications and policy makers the richardson richards equation rre richardson 1922 richards 1931 usually known as richards equation which combines the continuity equation with darcy buckingham s db law provides a physical basis for modelling the water movement through the unsaturated zone e g farthing and ogden 2017 raats 2001 hence it is implemented in many distributed hydrological models at watershed or regional scales e g shen and phanikumar 2010 and also in land surface models that often represent the vertical water movement in the soil through the 1d rre e g bisht et al 2018 dai et al 2019 a key condition to validate this approach remains the existence of a local scale for which db law is valid and suitable physical parameters can be provided for the constitutive relationships describing the k ψ hydraulic conductivity l t 1 and θ ψ volumetric water content l3 l 3 functions of the soil water pressure ψ l since highly non linear parametric models are generally used to describe these interdependent relationships the rre must be solved numerically because there is no exact analytical solution this means that modellers are burdened with solving a non linear partial differential equation potentially varying between a hyperbolic to a parabolic mathematical form depending on the soil condition all things considered the numerical solution of the rre is one of the most challenging problems in earth sciences with a high risk of non convergence e g farthing and ogden 2017 advanced numerical schemes well suited to handling complex spatial grids e g qi et al 2018 and optimized time discretization procedures are available to solve the different forms of the rre fahs et al 2009 farthing and ogden 2017 maina and ackerer 2017 to briefly summarize the current situation the θ form of the rre provides excellent mass balance but cannot handle water flows in saturated zones and exhibits discontinuities in the dependent variable across soil layer boundaries on the other hand the ψ form is continuous in both saturated and unsaturated zones but can suffer large mass balance errors celia et al 1990 hills et al 1989 finally the rre is often presented and solved using the mixed form and the computational codes usually contain a step where the primary variable is chosen to linearize and solve the mathematical system which then updates secondary variables very efficient results have been obtained with variable switching methods these consist of selecting the primary variable to be computed i e θ or ψ for each node of the matrix system as a function of the saturation of the soil diersch and perrochet 1999 forsyth et al 1995 wu and forsyth 2001 improvements especially for non smooth transitions between alternative primary variables have been developed to prevent unrealistic solutions or numerical difficulties krabbenhøft 2007 lehmann and ackerer 1998 zha et al 2017 the temporal discretization usually proceeds with an implicit scheme and the resulting non linear algebraic system requires an efficient and robust linearization technique that maintains mass conservation and accuracy of the solution the picard and newton raphson nr iterative methods are the most widely used procedures for solving the rre due to its robustness and simplicity the picard method is more widespread and has been for instance implemented in several popular numerical codes solving the rre such as the hydrus šimůnek et al 2016 and swap van dam et al 2008 models nonetheless slow or no convergence have been encountered with this technique for cases of saturated unsaturated interfaces gravity drainage or complex time varying boundary conditions paniconi et al 1991 the nr method has been found to be more efficient than the picard iteration method miller et al 1998 paniconi et al 1991 paniconi and putti 1994 but it increases algebraic complexity and computational costs because of the jacobian matrix containing some derivative terms and leading to a non symmetric matrix system paniconi and putti 1994 convergence failure of the nr method can occur in some unfavourable flow conditions especially when simulating infiltration into initially dry soils where the head gradient at the wetting front is extremely large to solve this numerical difficulty zha et al 2019 proposed an algorithm where the ψ before and after the iteration are examined the proposed modifications do not degrade the simulated results leading to more robust convergence performances and cost effective simulations for this particularly challenging conditions alternatively efficient non iterative techniques can also be implemented kavetski et al 2002 li et al 2021 finally linked with the linearization technique and the spatial discretization scheme the numerical solution of the rre can be sensitive to the convergence control strategies and the method to adapt the time step size during the simulation compared to using a fixed time step adaptive time discretization is more efficient and has become quite common ranging from heuristic to control based error methods a large number of heuristic time stepping methods have been proposed in the literature e g thomas and gladwell 1988 kavetski et al 2001 kavetski and binning 2004 miller et al 2006 belfort et al 2007 a key aspect justifying ongoing research of improvements relies on the need to balance run time robustness accuracy and flexibility despite numerous efforts over the last decade algorithms to achieve fast and accurate solutions are still actively being researched e g zha et al 2019 here we propose improvements to the solution of the rre and implement them in the novel hydrological pixel hypix model using the mixed form of the rre the solution of the rre is based on maina and ackerer 2017 for which the rre partial differential equation is solved using a cell centred finite volume implicit finite differences scheme for the spatial discretization with an implicit euler scheme for the temporal discretization by using the weighted average inter cell hydraulic conductivity then hypix solves the mixed form of the rre using the nr method to avoid overshooting and losing control of the nr step we propose a new physical method which automatically controls the convergence rate depending on the difficulty to get the solution as previously mentioned the drawback of solving the rre with the nr method is that it requires reprogramming the computation of the jacobian matrices i e the derivatives of the parameters with respect to ψ hence for testing purposes changing inter cell hydraulic conductivities leads to a reprogramming of the derivatives to overcome this limitation hypix takes advantage of the julia language bezanson et al 2017 perkel 2019 which enables automatic resolution of derivatives revels et al 2016 an updated physical time stepping scheme has been developed that is tailored to solve the rre based on ψ and not θ without introducing additional parameters the time stepping management module optimizes the size of the time step δt such that hypix uses the largest δt while meeting the targeted water balance and accuracy of the solution our technique is adapted from kirkland et al 1992 and ross 2003 because their time stepping management is physically based such that δt is directly derived from the residuals of the water balance and requires fitting of only one physical parameter δt is calculated via a maximum increase or decrease of the degree of saturation for each cell this ensures a higher time resolution when θ variations are large which improves the convergence rate at the wetting front the newly developed model has a reduced number of parameters to manage the solving of the rre compared to other physically based hydrological models hypix can a process a large number of soil layers described by the kosugi 1994 1996 unimodal and bimodal k ψ and θ ψ hydraulic parameters for each soil layer b simulate for the top boundary condition realistic water ponding and runoff at the soil surface by using a novel approach for the computation of sorptivity c compute root water uptake and evaporation d apply a wide range of bottom boundary conditions such as prescribed bottom flux or pressure i e water table free drainage and impermeable layer and e model impermeable layers this paper is organized as follows section 2 presents the bimodal soil kosugi hydraulic functions used in hypix to describe the rre and the novel approaches to solve it section 3 presents the five synthetic test cases used to validate hypix with hydrus and the experimental data from five field sites section 4 presents the results of comparing hydrus with hypix and the performance of different hypix option used with field experimental data section 5 discusses the results of the best hypix options based on synthetic and field experimental data and section 6 summarizes the main conclusions 2 theory 2 1 bimodal kosugi soil hydraulic functions hypix uses the bimodal kosugi 1994 1996 soil hydraulic functions the choice of the kosugi soil hydraulic functions is based on the physical interpretation of their parameters in relation to the soil pore size distribution the kosugi hydraulic parameters can be physically interpreted and constrained by exploiting physical relationship between the parameters fernández gálvez et al 2021 pollacco et al 2013b moreover the selection of bimodal functions is based on the prevalence of soils with bimodal pore system e g jarvis 2007 mcleod et al 2008 where macropores and micropores lead to two stage drainage fast flow macropore flow can occur when the water pressure head exceeds the threshold needed to activate the macropore network adding to the matrix flow below this threshold only the matrix participates in the flow fernández gálvez et al 2021 the representation of the θ ψ and k ψ functions is based on the dual porosity model of pollacco et al 2017 1 θ ψ θ mat ψ θ mac ψ if ψ 0 θ mat ψ 1 2 θ s macmat θ r e r f c ln ψ ψ m 2 σ θ r θ mac ψ 1 2 θ s θ s macmat e r f c ln ψ ψ m mac 2 σ mac elseif ψ 0 θ mat ψ θ s macmat θ mac ψ θ s θ s macmat 2 k ψ k mat s e ψ k mac s e ψ if ψ 0 s e ψ θ θ r θ s θ r 1 2 θ s macmat θ r θ s θ r erfc ln ψ ψ m 2 σ θ s θ s macmat θ s θ r erfc ln ψ ψ m mac 2 σ mac k mat s e ψ k s θ s macmat θ r θ s θ r s e ψ 1 2 erfc ln ψ ψ m 2 σ σ 2 2 k mac s e ψ k s θ s θ s macmat θ s θ r s e ψ 1 2 erfc ln ψ ψ m mac 2 σ mac σ mac 2 2 elseif ψ 0 k mat s e ψ k s θ s macmat θ r θ s θ r k mac s e ψ k s θ s θ s macmat θ s θ r where erfc is the complementary error function θ l3 l 3 represents the volumetric soil water content and ψ l the soil water pressure considering ψ 0 for unsaturated soils i e matrix suction θ s l3 l 3 and θ r l3 l 3 are the saturated and residual volumetric soil water content respectively ln ψ m and σ denote the mean and standard deviation of ln ψ respectively in the soil matrix domain ln ψ mmac and σ mac denote the mean and standard deviation of ln ψ respectively in the macropore soil domain with the argument of ln in units of length i e ψ m ψ and ψ mmac in l θ smacmat l3 l 3 is the volumetric saturated water content that theoretically differentiates inter aggregate pores structural macropores and matrix domains intra aggregate micropores defining the corresponding soil water pressure threshold between macropore and matrix ψ macmat l s e ψ denotes the effective saturation as a function of ψ with values between 0 and 1 k s l t 1 is the saturated hydraulic conductivity and k s e ψ l t 1 refers to the unsaturated hydraulic conductivity written as a function of s e ψ for the case when θ smacmat θ s eq 1 and eq 2 reduce to the unimodal kosugi soil hydraulic functions the soil water capacity of the bimodal kosugi model is computed as follow 3 i f ψ 0 c θ ψ θ ψ θ mat ψ θ mac ψ θ s matmac θ r exp ln ψ ψ m 2 2 σ 2 2 π σ 2 ψ θ s θ s matmac exp ln ψ ψ m mac 2 2 σ mac 2 2 π σ mac ψ e l s e i f ψ 0 c θ ψ 0 and the derivative of k ψ with respect to ψ of the bimodal kosugi model is 4 k ψ k mat ψ k mac ψ i f ψ 0 s e ψ θ θ r θ s θ r 1 2 θ s macmat θ r θ s θ r erfc ln ψ ψ m 2 σ θ s θ s macmat θ s θ r erfc ln ψ ψ m mac 2 σ mac k mat ψ k s 2 π σ ψ θ s macmat θ r θ s θ r erfc ln ψ ψ m 2 σ σ 2 s e ψ exp ln ψ ψ m 2 σ σ 2 2 k s 8 π ψ θ s macmat θ r θ s θ r erfc ln ψ ψ m 2 σ σ 2 2 s e ψ θ s macmat θ r θ s θ r exp ln ψ ψ m 2 σ 2 σ θ s θ s macmat θ s θ r exp ln ψ ψ m mac 2 σ mac 2 σ mac k mac ψ k s 2 π σ mac ψ θ s θ s macmat θ s θ r erfc ln ψ ψ m mac 2 σ mac σ mac 2 s e ψ exp ln ψ ψ m mac 2 σ mac σ mac 2 2 k s 8 π ψ θ s θ s macmat θ s θ r erfc ln ψ ψ m mac 2 σ mac σ mac 2 2 s e ψ θ s macmat θ r θ s θ r exp ln ψ ψ m 2 σ 2 σ θ s θ s macmat θ s θ r exp ln ψ ψ m mac 2 σ mac 2 σ mac e l s e i f ψ 0 k ψ 0 2 2 richardson richards equation of hypix model modelling unsaturated flow in highly heterogeneous soils can be accurately performed by solving the rre richardson 1922 richards 1931 which is commonly adopted by soil vegetation atmosphere transfer models e g jones et al 2021 however the rre is highly non linear and despite numerous efforts over the last decade its solution using numerical methods is demanding and algorithms to achieve fast and accurate solutions are still actively being researched e g zha et al 2019 assuming a rigid solid matrix fig 1 the mixed form of the rre is written as 5 θ i ψ i t θ i ψ i t 1 δ t t s o θ i ψ i t θ s i ψ i t 1 ψ i t δ t t q i 1 2 t q i 1 2 t δ z i s i n k i ψ i t 1 where δt t t is the time step at time t δz i l is the mesh size of cell i with the vertical coordinate positive downwards θ i l3 l 3 is the volumetric soil water content of cell i θ s i l3 l 3 is the saturated volumetric soil water content of cell i s 0 l 1 is a parameter which ranges from 10 7 to 10 10 that accounts for fluid compressibility which is assumed to be constant with depth ψ i l is the soil water pressure of cell i considering ψ 0 for unsaturated soils q l t 1 is the soil water flux based on the extended db law which is positive downward and negative when water moves upwards q i 1 2 t l t 1 is the flux entering cell i and q i 1 2 t l t 1 is the flux exiting cell i and sink i l3 l 3 t 1 taken as positive is the sink term defined as the volume of water per unit time removed from cell i by soil evaporation section 7 6 1 and root water uptake section 7 6 2 2 2 1 water fluxes q 2 2 1 1 q below the top cell 2 i ni the darcian fluid flux q i 1 2 t l t 1 is computed by using the inter cell hydraulic conductivity between cell i and i 1 as described in fig 1 as follows 6 q i 1 2 t k i 1 2 ψ ψ i t ψ i 1 t δ z i 1 2 cos α δ z i 1 2 δ z i δ z i 1 2 k i 1 2 ψ w i k i ψ i t p 1 w i k i 1 ψ i 1 t p 1 p ω i δ z i δ z i δ z i 1 where q i 1 2 t l t 1 is the flux entering cell i from the top and q i 1 2 t is the flux exiting cell i from the bottom k i 1 2 l t 1 refers to the weighted average inter cell hydraulic conductivity e g haverkamp and vauclin 1979 belfort et al 2013 computed with ω i δ z i 1 2 l is the distance between cell centres i and i 1 as depicted in fig 1 α radian refers to the angle between the vertical axis and the slope of the soil s surface and p 1 for weighted average intercell conductivity as in this paper 2 2 1 2 top boundary conditions i 1 ponding and runoff two boundary conditions are currently available in hypix a novel flux boundary condition with infiltration driven by sorptivity section 2 2 1 2 1 and b prescribed top pressure boundary condition section 2 2 1 2 2 2 2 1 2 1 novel top flux boundary condition driven by sorptivity the nomenclature taken in this paper is that δ x is defined as t 1 t x t t 1 t 1 x t for the top flux boundary condition hypix checks if the top flux boundary condition imposed by the user throughfall precipitation δ p r through t l can infiltrate into the top layer if it is not the case the excess of precipitation ponds on top of the soil surface if ponding depth exceed the maximum ponding depth the excess water will be lost to runoff the amount of water infiltrating into the top cell i 1 for a period δt is computed by δ q 1 2 t l fig 1 as the rre cannot compute the top air soil boundary we compute δ q 1 2 t using the two term approximation of haverkamp et al 1994 as suggested by fernández gálvez et al 2019 the maximum infiltration depth for a given δt is δ q m a x 1 2 t l and is computed as 7 b 2 β 3 1 β 3 k θ 1 t 1 k s 1 δ q m a x 1 2 t q m a x 1 2 t δ t t s o r p t θ 1 t 1 δ t t b k s 1 δ t t cos α where q m a x 1 2 t l t 1 is the maximum soil water flux sorpt l t 1 2 is the soil sorptivity β is an integral shape parameter typically fixed at 0 6 haverkamp et al 1994 parlange et al 1982 and the slope α radian is the angle between the flow direction of recharge and the vertical axis 0 α π 2 for inclined flow sorptivity is computed using the mixed formulation proposed by lassabatere et al 2021 2022 the novelty of this sorptivity model is that it is highly efficient and accurate in the computation of sorptivity for all soil types from oven dry to saturation the sorptivity model is computed as 8 d θ k θ d ψ d θ s o r p t 2 θ 1 t 1 θ s 1 θ 1 t 1 θ s 1 θ 1 t 1 2 θ s 1 θ 2 θ 1 t 1 d θ d θ 0 ψ θ s 1 θ 1 t 1 2 θ s 1 θ ψ 2 θ 1 t 1 k ψ d ψ where d θ is the diffusivity function for which d ψ d θ is derived in eq 3 eq 8 splits the integral into two parts to allow the integration of continuous functions over closed intervals in the regular expression the d θ is infinite close to saturation θ θ s in the specific eq 8 the last part of the integration based on ψ is replaced with the integration of the hydraulic conductivity as a function of the water pressure k ψ alleviating the problem of convergence the maximum water infiltrating into the top cell δ q m a x 1 2 t must be less than the maximum available pore volume of the top cell 9 δ s i n k 1 ψ 1 t 1 δ z i δ t t s i n k 1 ψ 1 t 1 δ q m a x 1 2 t min δ q m a x 1 2 t δ z 1 θ s 1 θ 1 t 1 δ s i n k 1 ψ 1 t 1 where θ s1 l3 l 3 is the saturated volumetric soil water content and δsink 1 l the sink term of the top cell i 1 the amount of water that is not able to infiltrate into the soil can either run off laterally due to the slope or get ponded at the surface where ponding h pond t l is computed as 10 h pond t max δ p r through t h pond t 1 δ q m a x 1 2 t 0 where δ p r through t l is the throughfall precipitation i e the amount of water reaching the top cell appendix 7 5 it is to be noted that the novel top flux boundary condition driven by sorptivity does not require any additional hypix parameters runoff δ r u n o f f t l is generated if h pond t exceeds a user defined maximum ponding depth h pond m a x l as follow 11 δ r u n o f f t max h pond t h pond m a x cos α 0 h pond t min h pond t h pond m a x cos α 2 2 1 2 2 prescribed top pressure boundary condition ψtop the prescribed top water pressure boundary condition implies that ψ 1 t ψ top t the flux at the surface boundary is computed as follows 12 q 1 2 t k 1 ψ 1 t ψ 1 t 1 ψ top t δ z 1 2 cos α where ψ top t l is a user defined pressure hypix computes equivalent δ p r through t corresponding to ψ top t ψ 1 t 1 in future research the top water pressure boundary condition can be used to fine tune the sorptivity model eq 8 described above 2 2 1 3 bottom boundary conditions i ni the bottom boundary conditions implemented in hypix are special cases of the following eq 13 derived from eq 6 and include a free drainage section 2 2 1 3 1 b prescribed bottom pressure section 2 2 1 3 2 and c prescribed bottom flux section 2 2 1 3 3 the bottom boundary condition is universally computed as follows 13 q n 1 2 t k n ψ n t ψ n 1 t ψ n t δ z n 2 cos α 2 2 1 3 1 free drainage the free drainage boundary condition at the bottom of the soil profile occurs when ψ n t z n 1 in eq 13 leading to 14 q n 1 2 t k n ψ n t cos α 2 2 1 3 2 prescribed bottom pressure ψbot the prescribed bottom water pressure boundary condition ψ bot t l is a user defined variable positive for saturated and negative for unsaturated conditions set at the bottom of cell n of the soil profile ψ n 1 t which is derived from eq 13 and results in the following flux 15 q n 1 2 t k n ψ bot t ψ bot t ψ n t δ z n 2 cos α 2 2 1 3 3 prescribed bottom flux qbot the prescribed bottom flux boundary condition q bot t l is a user defined variable positive as a sink and negative as a source set at the bottom of cell n of the soil profile which derived from eq 13 results in the following flux 16 q n 1 2 t q bot t 2 3 solving the richardson richards equation using the newton raphson method the picard and newton raphson nr iterative methods are the most widely used procedures for solving the rre the nr method has been found to be more efficient than the picard iteration method lehmann and ackerer 1998 paniconi and putti 1994 so we solved the rre using the nr algorithm the nr method is used to solve ψ i t such that the residuals of each cell r i t l equal close to 0 r i t is derived from eq 5 as follow 17 r i t δ z i θ i ψ i t θ i ψ i t 1 δ z i s o θ i ψ i t θ s i ψ i t ψ i t 1 δ t t q i 1 2 t q i 1 2 t δ s i n k i ψ i t 1 δ s i n k i ψ i t 1 δ z i δ t t s i n k i ψ i t 1 where δsink i l is the sink computed for a given δt to stabilize the numerical scheme δsink i is computed with the ψ i values derived from the previous time step the nr method is computed using a first order taylor development by solving the jacobian matrices of the residuals r eq 17 in an iterative way that updates ψ i t k 1 ψ i t k until convergence is achieved the numerical discretization is a tridiagonal appendix 7 1 non linear set of equations that needs to be solved for ψ i t k 1 ψ i t k and for every iteration k as follows 18 ψ i t k 1 ψ i t 1 r i ψ i t k j i 1 i 1 r i ψ j t k ψ j t k ψ j t k 1 ψ j t k where the derivatives are described in appendices 7 2 and 7 3 the initial ψ i t 0 is derived either from measured θ t 0 or from ψ t 0 the computation of ψ min l which is the minimum allowed value of ψ is based on the assumption that θ ψ is log normal distribution and therefore according to fernández gálvez et al 2021 ψ min can be computed as follows 19 ψ i t ψ min i e ln ψ m i 4 σ i k ψ min i 0 the computation of ψ max l which is the maximum allowed value of ψ is more challenging to compute as it can be positive or negative therefore during the iteration when the water pressure is close to saturation it may change sign causing numerical instability zha et al 2017 to increase numerical stability for soils close to saturation ψ max switches depending on the value of ψ i t 1 as follow 20 if ψ i t 1 ψ macmat 2 ψ max i t ψ maxmax elseif ψ max i t 0 where ψ macmat l is the theoretical water pressure for which macropore starts to fill up corresponding to the minimum water pressure for which a soil can be considered close to saturation often taken as 100 mm e g jarvis 2007 ψ maxmax is a parameter for which its feasible range is provided in table 1 table 1 shows the feasible range as well as the recommended values for the parameters required to solve the rre with the hypix model 2 3 1 convergence criterion for a given time step the iteration of the nr method stops either when k n k where n k is a user defined maximum number of iterations table 1 or when the overall water balance of the residuals wb residual t 1 is satisfied the wb residual convergence criterion for the nr method is based on the euclidean norm of a vector r e g driscoll and braun 2017 kochenderfer and wheeler 2019 kelley 2003 21 w b residual i 1 n i r i t δ t t δ z i 2 n i where n i is the total number of cells as described in fig 1 the residuals are normalized such that wb residual is independent of the cell size δz and the time step δtt the feasible range of wb residual is provided in table 1 2 3 2 automatic differentiation of the jacobian with julia language one of the shortcomings of the nr solver is that it requires the mathematical derivatives of r eq 18 and derivatives described in appendices 7 2 and 7 3 the implementation of which can be complicated and time consuming e g modifying the inter cell hydraulic conductivity eq 6 for testing purposes requires recalculation of the derivatives to address this shortcoming hypix implements an option whereby the derivatives are derived automatically by using the forward mode automatic differentiation forwarddiff in the julia package revels et al 2016 https github com juliadiff forwarddiff version 0 10 24 was found to be as accurate as using the mathematical derivatives and only on average 16 slower compared with using the analytical derivatives we tested that for every boundary condition section 2 2 1 2 and section 2 2 1 3 the derivatives derived analytically section 7 2 give the same results accuracy 10 8 to those derived by using the forward mode automatic differentiation forwarddiff 2 3 3 adaptive time stepping management the time stepping management module optimizes the size of the time step δt such that hypix uses the largest δt while meeting the targeted water balance and accuracy of the solution among the heuristic time stepping methods in the literature we selected and improved the adaptive time stepping management of kirkland et al 1992 and ross 2003 this method is physically based such that δt is directly derived from the residuals of the water balance eq 17 and requires only one physical parameter δt is calculated via a maximum increase or decrease of the degree of saturation for each cell this ensures a higher time resolution when θ variations are large which improves the convergence rate at the wetting front below we present three options to optimize the size of the time step a the traditional time stepping management of kirkland et al 1992 and ross 2003 developed specifically for the rre and based on θ with a more realistic computation of average δ t t section 2 3 3 1 b a novel time stepping management of kirkland et al 1992 and ross 2003 adapted for rre based on ψ and implemented in hypix section 2 3 3 2 and c a condition to rerun hypix with the updated ψ and δ t t section 2 3 3 3 2 3 3 1 traditional adaptive time stepping management time stepping δθ the time stepping management of kirkland et al 1992 and ross 2003 assures numerical stability and avoids oscillation in the solution δt is derived by rearranging the terms of the residual eq 17 assuming that r 0 and s 0 0 s 0 is by definition small and strictly 0 for non compressible fluids and δ θ max θ i ψ i t θ i ψ i t 1 where δθ max l3 l 3 is a constant parameter describing the maximum change of θ for a given δt the δθ max feasible range is provided in table 1 we improved the time stepping computing δtt by putting more weight on cells that are dynamically active q i 1 2 t q i 1 2 t with ψ i t ψ i 1 t δ ψ active in other words hypix computes δtt considering the cells that are wetting up due to for example a wetting front in an initially dry soil bottom cells are inactive therefore δtt is computed as follows 22 n i t 1 for i 1 n i if ψ i t ψ i 1 t δ ψ active δ t i t δ z i δ θ max δ s i n k i ψ i t 1 q i 1 2 t ψ i 1 t 1 q i 1 2 t ψ i t 1 δ t min δ t i t δ t max n i t n i t 1 end end δ t t i 1 n i δ t i t 2 n i t where δt min t and δt max t are user defined minimum and maximum time steps described in table 1 which are used for safety in the code δψ active with a recommended constant value of 1 0 mm also described in table 1 and ni is the total number of cells the selected average δtt of a soil profile is computed from δ t i t which is derived from every cell using a modified euclidean norm of a vector based on driscoll and braun 2017 kochenderfer and wheeler 2019 and kelley 2003 as computed for wb residual in section 2 3 1 as described in eq 22 the computational time in hypix decreases as δt increases δt increases when a the size of the cell δz increases b the hydraulic properties from one cell to another depicted by q do not change dramatically c there are small pressure gradients ψ z d there are small differences in hydraulic properties and e when δθ max increases 2 3 3 2 novel adaptive time stepping management time stepping ψ for the robustness of the solution of the rre eq 5 based on ψ changes of δψ between two consecutive time steps must be small this is particularly the case when simulating infiltration into dry soil where the head gradient at the wetting front is extremely large leading to large computational efforts numerical instability and inaccuracy e g zha et al 2017 nevertheless describing a generic θ ψ a small change of δθ could result in a large change in δlnψ particularly near saturation and at the dry end of the θ ψ curve the traditional ross 2003 time stepping δθ eq 22 is modified by allowing δθ max to vary as described by δ θ max i t ψ such that δlnψ const for this we introduce a temporary parameter computed from and for every cell 23 δ ln ψ max i ln 1 ψ i t ln 1 ψ i t 1 to avoid introducing a second parameter we derive δlnψ max from δθ max for a given ψ θ the smallest δlnψ occurs at θ r θ smacmat 2 or at the kosugi parameter ψ ψ m therefore δ ln ψ max i δ θ max is computed for every cell as follows 24 θ 1 2 i θ r i θ s macmat i 2 θ ψ m δ l n ψ max i δ θ max ln ψ θ 1 2 i δ θ max 2 1 ln ψ θ 1 2 i δ θ max 2 1 2 δ θ max i t ψ is adjusted based on the maximum allowed change of δ ln ψ max i and ψ i t 25 δ θ max i t ψ i t δ ψ max i θ i e ln ψ i t 1 e δ ln ψ max i e δ ln ψ max i the advantage of δ θ max i t ψ δ θ max is that its steps are smaller at the wet end of the θ ψ curve δ t i t is computed by substituting δ θ max i t ψ instead of δθ max into eq 22 2 3 3 3 condition to rerun the time step δtt is computed using the previous water pressure ψ t 1 which may not reflect for example the passage of a wetting front requiring a reduced δtt therefore to assure accurate water balance and stability of the solution of the rre hypix is rerun with the updated δtt if δ t t ψ t δ t t ψ t 1 therefore hypix is rerun if the following condition is meet 26 δ t t ψ t 1 δ t min p δ t rerun 2 where δt min is the minimum time step described in table 1 if the maximum number of iterations is reached k n k and the condition eq 26 is not met then hypix is rerun with a reduced time step as follows 27 δ t t δ t min p δ t rerun 2 2 3 4 controlling newton raphson step the following algorithms are strategies to control the size of the nr step defined as 28 δ n r s t e p i ψ i t k ψ i t k 1 nr steps are implemented to avoid numerical instability and overshooting of the nr method the following algorithms are implemented into hypix a absolute convergence criterion section 2 3 4 1 b traditional smoothing method section 2 3 4 2 c novel dynamic smoothing method section 2 3 4 3 and d modified iteration for initially dry conditions proposed by zha et al 2017 section 2 3 4 4 the advantages of the different algorithms as well as the rationality of the recommended option in hypix are presented in the discussion 2 3 4 1 absolute convergence criterion traditional absolute convergence criterion to avoid overshooting of the nr step in line with common practices of solving the rre the absolute convergence criterion constrains the nr step by using δ ln ψ max i eq 24 in hypix for every cell δ n r s t e p i eq 28 is constrained as follows 29 e δ ln ψ max 1 max ψ i t k ψ i t k 1 i 1 i n i this absolute convergence criterion could be used in conjunction with other constraining methods described in the following sections 2 3 4 2 constant ω traditional smoothing with constant ω to avoid overshooting of the nr step to reduce overshooting of the nr step between two iterations and increase the efficiency we introduce a smoothening algorithm as follows 30 ψ i t k 1 ω ψ i t k 1 1 ω ψ i t k were ω 0 5 is a fixed parameter 2 3 4 3 dynamic ω novel smoothing with dynamic ω to avoid overshooting of the nr step the introduction of ω such as constant ω in section 2 3 4 2 was found to be highly successful in reducing convergence failure we therefore propose to improve the method such that ω varies for every cell and iteration the feasible range of ω is ω min ω max where ω ω max 1 means no reduction of the nr step and ω ω min 0 corresponds to a maximum reduction in the nr step a decrease of ω causes a slower convergence rate but increases the success rate of convergence of the nr for challenging conditions we therefore propose the following ω algorithm 31 ω i t k 1 ψ i t k ω max ω max ω min min θ ψ i t k 1 θ ψ i t k δ θ max i t ψ i t k 1 1 2 ψ i t k 1 ω i t k 1 ψ i t k ψ i t k 1 a 1 ω i t k 1 ψ i t k ψ i t k where δ θ max i t ψ i t k 1 was derived from eq 25 ω max 1 and the feasible range of ω min is provided in table 1 at a given t challenging situations for iteration k occur when θ ψ i t k 1 θ ψ i t k δ θ max i t ψ i t k 1 then the nr step is reduced it will be shown that the dynamic ω method is not only successful in increasing accuracy but also in increasing the speed of convergence 2 3 4 4 dry method modified iteration for initially dry conditions convergence failure normally occurs in some unfavourable flow conditions especially when simulating infiltration into initially dry soils to overcome this numerical difficulty we adopt the algorithm proposed by zha et al 2017 where the water pressure before ψ i t k and after ψ i t k 1 the iteration is examined to determine if there is any oscillation at the dry end of the θ ψ curve if ψ i t k is smaller than a user specified threshold ψ dry and ψ i t k 1 is greater than a user specified threshold ψ wet the risk of numerical divergence for this node is deemed to be very high under this condition ψ i t k 1 is estimated from the derived θ i t k 1 the soil water capacity of the bimodal kosugi model eq 3 32 i f ψ i t k ψ dry σ i and ψ i t k 1 ψ wet σ i ψ i t k 1 ψ θ i t k 1 ψ θ i t k θ i t k ψ i t k ψ i t k 1 ψ i t k the threshold values ψ dry and ψ wet depend on soil type and because σ defines the slope of the θ ψ curve we derived the following empirical expressions as a function of σ with the set of soils published by zha et al 2017 and shown in fig 2 33 ψ wet i max 2 312 σ i 2 2 937 σ i 27 830 0 ψ dry i exp 1 622 ln σ i 8 727 2 4 accuracy and efficiency of simulations 2 4 1 water balance the overall water balance wb l of the simulation is derived from the residuals r eq 17 and is computed for every time step as follows 34 w b t i 1 n i δ z i θ i ψ i t θ i ψ i t 0 i 1 n i t 1 n t δ z i s o θ i ψ i t θ s i ψ i t ψ i t 1 t 1 n t δ t t q 1 2 t q n 1 2 t i 1 n i t 1 n t δ s i n k i ψ i t where n t is the final time step and n i is the bottom cell it is expected that the wb error increases with the length of the simulation it is therefore normalized w b η to the cumulative infiltration 35 w b η w b t t 1 n t δ t t q 1 2 t an acceptable water balance at the end of the simulation occurs when w b η is smaller than the uncertainty of measuring precipitation 2 4 2 efficiency the efficiency of a simulation e ff t 1 is defined as the average number of iterations required to perform a day of simulation computed as follows 36 e f f ς t 1 n t k t t 1 n t δ t t where k is the number of iterations per time step which includes repeated simulation section 2 3 3 3 n t is the number of time steps and ς 86400 s if the units are in seconds therefore the smaller e ff the faster hypix would run for a given w b residual eq 21 2 5 summary of hypix algorithm initialization estimate the percentage of roots δrdf i per cell derived from the vegetation parameters eq 80 compute initial soil water pressure ψ ini l if required derived from initial observed θ t 1 compute δ ψ max i δ θ max i for every cell which will be used to compute the variable time step eq 25 and the dynamic ω eq 31 iteration of the nr which solves ψ of the rre for a given δt compute at the beginning of every time step new time step δt derived from ψ t 1 section 2 3 3 2 sorptivity from ψ t 1 to derive the maximum infiltration rate section 2 2 1 2 1 interpolation of δpr and δpet evap for a given δt vegetation parameters lai and k c which vary monthly section 3 2 2 potential evapotranspiration δpet transp and δpet evap section 7 4 precipitation not intercepted that reaches the ground surface δpr ground section 7 5 soil evaporation computed from ψ t 1 δ e v a p section 7 6 1 root water uptake computed from ψ t 1 δ r w u section 7 6 2 during each iteration compute the residuals eq 17 and derivatives eq 18 described in sections 7 2 and 7 3 compute δ θ max i t ψ i t k 1 eq 25 to manage the nr steps compute dynamic ω i t k 1 ψ i t k eq 31 to smoothen the newton raphson step continue the iteration loop of the nr until either the convergence criterion wb residual is met eq 21 or the maximum allowed iteration is reached after iteration is computed rerun the model if δ t t ψ t δ t t ψ t 1 with the new derived time step section 2 3 3 3 after the simulation is terminated compute the soil water balance and efficiency of simulation section 2 4 compute the outputs of interest at the time step of interest e g θ ψ q 3 material and methods two independent sets of data are used in this study 1 we describe five synthetic test cases for validating hypix with hydrus without including the sink term in the rre and 2 we present the experimental data from five contrasting sites used for testing hypix options under field conditions including the sink term for all test cases considered in this work we assumed that there is no runoff and therefore h pond m a x 3 1 synthetic test cases for validating hypix with hydrus without the sink term to assess the accuracy efficiency and computational costs of the different algorithms of hypix we compared the numerical solution of hydrus version 4 17 0140 radcliffe and simunek 2010 šimůnek et al 2016 with hypix by using five challenging published test cases the algorithm of hypix utilizes the recommended options and the recommended hypix parameters table 1 the hydrus model utilizes the recommended parameters except for the maximum time step δt max being reduced to 1 h and by increasing the maximum number of iterations n k to match that of hypix described in table 1 the reported test cases in the literature use the mualem van genuchten hydraulic functions mualem 1976 van genuchten 1980 and we transformed them into the kosugi 1994 1996 hydraulic functions ensuring the optimal ψ m and σ kosugi hydraulic parameters were physically sound by using the method described in fernández gálvez et al 2021 a description of the different test cases which combine different soil profiles with contrasting initial and boundary conditions tc1 to tc5 are summarized below tc1 infiltration in a homogeneous initially dry sandy loam soil with constant prescribed pressure at the surface and prescribed pressure at the bottom celia et al 1990 this test case is challenging to converge because it models the passage of a wetting front in an initially very dry soil with sudden variation of ψ tc2 same as tc1 but with a free drainage bottom boundary condition tc3 infiltration in a homogeneous clay loam soil initially at hydrostatic equilibrium with a prescribed constant flux at the soil surface and prescribed water table at the bottom miller et al 1998 the profile has linearly decreasing ψ initial conditions this test case models slow moving water in the presence of a water table tc4 infiltration at a constant rate into an initially dry heterogeneous soil with constant top flux at the surface and a free drainage bottom boundary condition zha et al 2017 the soil profile consists of three layers of equal thickness with a clay loam layer sandwiched between two sandy loam layers lehmann and ackerer 1998 the challenge of this test case is to model the movement of water at the interface of very contrasting soils tc5 same as tc4 but with an impermeable bottom boundary condition zha et al 2017 this test case is even more challenging than tc4 as the bottom boundary condition implies a change in the direction of the water fluxes when the wetting front reaches the impermeable bottom layer the soil hydraulic parameters boundary conditions and initial conditions for the five test cases considered are listed in table 2 the vertical discretization used in the simulations for the test cases was δz 10 mm 3 1 1 goodness of fit between hydrus and hypix the goodness of fit between the model outputs corresponding to the profile soil water content from hydrus and hypix was assessed using the root mean squared error rmse and the nash sutcliffe efficiency coefficient nse during a particular period as follows 37 r m s e t 1 n t i 1 n i δ z i θ i hydrus t θ i hypix t 2 n t 38 n s e max 1 t 1 n t i 1 n i δ z i θ i hydrus t θ i hypix t 2 t 1 n t i 1 n i δ z i θ i hydrus t δ z i θ i hydrus t 2 0 where θ i hydrus t and θ i hypix t refer to simulated soil water content values at each cell computed with hydrus and hypix respectively for which both models utilize the same vertical discretization δ z i 10 mm note that δ z i θ i hydrus t is the mean value for every cell i 3 2 field experimental data for testing hypix options with sink term 3 2 1 soils description the five sites used in this study are dairy cattle grazed pasture located in the waikato region of new zealand all soils have formed from airfall volcanic tephra but vary in their soil physical properties and heterogeneity particularly their texture and profile drainage characteristics a brief description of the soils follows the taupō soil is a sandy textured soil formed from volcanic airfall pumice material new zealand classification podzolic orthic pumice soil usda soil taxonomy classification orthod hewitt 2010 the otorohanga and waihou soils are also formed from airfall volcanic material but with finer tephra material compared with the taupō resulting in silty loam topsoil textures grading to silty clay in the subsoil they are classified in new zealand as typic orthic allophanic soils and in soil taxonomy as a haplohumult hewitt 2010 based on the soil morphology the otorohanga and waihou soils would be considered to have the least heterogeneous soil profiles of those used in this study since they have a reduced number of distinct layers the taupō site is expected to show more heterogeneity in water movement due to the stone content cichota et al 2016 the hamilton soil has a silt loam topsoil overlying clayey textured subsoils having formed into strongly weathered volcanic tephra it is classified in new zealand as a typic orthic granular soil and in soil taxonomy as a haplohumult hewitt 2010 the waitoa soil is a silty textured soil it is classified in new zealand as a typic orthic gley soil and in soil taxonomy as a haplohumult hewitt 2010 the soil morphology of hamilton and waitoa shows the greatest heterogeneity of the soils in this study as reflected in previous studies of soils with impeded drainage features mcleod et al 2008 vogeler et al 2019 3 2 2 vegetation data experimental sites are five mixed non irrigated pasture grass sites the trapezoidal feddes et al 1978 water stress response function section 7 6 2 was used with parameters for mixed pasture grass in new zealand derived from wesseling 1991 for all sites we used default values at four soil water pressures ψ feddes1 100 mm ψ feddes2 250 mm ψ feddes3 5000 mm and ψ feddes4 80 000 mm and the maximum root depth z nroot was averaged to 800 mm vogeler and cichota 2019 and percentage of roots in the top 300 mm δrdf top was 90 evans 1978 the crop coefficient k c and the lai section 7 6 2 vary throughout the growing season the range of k c 0 8 to 0 95 was taken from rotated grazing pasture according to an fao irrigation paper 56 allen et al 1998 and the range of the lai 0 19 to 5 10 was taken from van housen 2015 3 2 3 climate and soil water content data daily values of precipitation δpr l were measured using a tipping bucket rain gauge recording at 0 2 mm rain depth resolution potential evapotranspiration δpet l was derived from the new zealand virtual climate stations vcs network tait et al 2006 tait 2008 with estimates based on the spatial interpolation of actual data observations made at climate stations located around the country tait 2010 soil water content θ l3 l 3 was monitored at five depth increments to 1000 mm depth with minor increment variation between soils to reflect soil layer differences for the five sites hypix uses a 2 month period of warm up the yearly average precipitation and potential evapotranspiration using representative wet and dry periods from 6 months data are shown in table 4 4 results the results are organized as follows in section 4 1 we compare θ profile computed with hypix and hydrus by disabling the sink term for the five test cases described in section 3 1 not including the sink term causes a sharper ψ wetting front and therefore is a more challenging problem for the solver of the rre since including the sink term attenuates the wetting front moreover the sink terms computed in hydrus are different from the one computed in hypix in section 4 2 we run hypix using data from contrasting experimental sites section 3 2 and include the sink term to illustrate the benefits of the recommended hypix options derived in the test cases in section 5 1 we recommend hypix options such that in order of priority the results are stable converge are accurate have a good water balance and are efficient 4 1 validation of hypix with hydrus using synthetic test cases hypix simulations were derived using the dynamic ω section 2 3 4 3 the dry method section 2 3 4 4 for controlling the nr steps as well as the time stepping management based on ψ for solving the rre section 2 3 3 2 the comparison of the θ profiles at different times computed by hydrus solid line and hypix dashed line respectively for the five test cases described in section 3 1 are shown in fig 3 the different colours indicate the time since the beginning of each simulation and are evenly spaced red purple and yellow until the total time of simulation blue as shown in fig 3 the matching in θ profile between hydrus and hypix is excellent with almost indistinguishable θ profiles throughout the time for each of the five test cases this is also confirmed in table 3 with rmse eq 37 values very close to zero rmse 1 8 10 2 and nse eq 38 values close to 1 nse 0 93 computed between simulated θ profiles with hydrus and hypix models the drainage from the bottom cell during the total time of simulation δ q n 1 2 n i t computed with hypix and hydrus is similar as shown in table 3 therefore the algorithm implemented in hypix is as robust as the one implemented in hydrus 4 2 hypix tested with experimental sites in this section we run hypix with experimental data section 3 2 using time series of climatic variables soil information from the five contrasting experimental sites and the sink term of the rre to illustrate the benefits of the recommended hypix options in the previous section it was shown that for the five test cases hypix converged successfully using the physical time stepping ψ section 2 3 3 2 and the dynamic ω algorithm to control the nr step section 2 3 4 3 in combination with the dry method derived from zha et al 2017 section 2 3 4 in most applications solving the rre for hydrological modelling coarse vertical resolutions are used to decrease the computational burden an essential element of the numerical solution of the rre is that the solution converges as the spatial resolution increases to simulate hydrological fluxes accurately small vertical cell sizes in the order of 10 mm are required near the soil surface but not throughout the soil column downer and ogden 2004 the performance of hypix which uses the nr algorithm was tested using different discretization ranging from 10 to 100 mm data not shown to evaluate the model performance using the different options implemented in hypix we selected a vertical discretization of δz uz 20 mm and δz lz 50 mm where δz uz is the discretization of the upper zone in the root zone taken here as z 500 mm and δz lz is the discretization of the lower zone below the root zone the maximum errors of the water balance between the finest discretization δz uz 10 mm and δz lz 10 mm compared to a coarser discretization used to illustrate the model performance with the different options δz uz 20 mm and δz lz 50 mm for δdrainage and δsink are below 0 03 for all sites described in section 3 2 the yearly water balance for the five experimental sites is shown in table 4 and the plots are shown in fig 4 the rainfall interception algorithm uses vegetation parameters section 3 2 2 which are described in appendix the closure of the simulated water balance is shown by the normalized overall excellent water balance w b η 10 4 eq 35 for each of the five experimental sites table 5 evaluates hypix performance through w b η and e ff of the simulations by a using not using the dry method and b using the smoothing criteria with ω either constant or dynamic with the recommended options described in the last row we obtain excellent results with w b η 10 4 and e ff 66 day 1 the benefits of using the dry method and the dynamic smoothing criterion are discussed in section 5 5 discussion to concisely interpret the significance of the algorithms implemented in hypix we present in this section the recommended hypix options as well as the pros and cons of each of them as evidenced by the results 5 1 recommended hypix options the results described in fig 3 and table 5 were derived using the time step controlled by using the physical time stepping ψ section 2 3 3 2 and the nr step is managed using the dynamic ω section 2 3 4 3 in combination with the dry method derived from zha et al 2017 section 2 3 4 we did not use the absolute convergence criterion section 2 3 4 1 for reasons discussed in section 5 5 we discuss the recommended hypix options derived from the synthetic test cases section 4 1 and the experimental data set section 4 2 having the greatest probability to be successful in most cases such that in order of priority the results are stable successful converge are accurate have a good water balance and are efficient as described in table 5 for the four test cases except for tc5 the accuracy of the hypix wb is greater than that for hydrus the e ff of hypix for tc1 coarse soils is 44 times more efficient due to the implementation of time stepping ψ and the dynamic ω in combination with the dry methods hypix was also slightly more efficient in tc2 using the same soils as in tc1 the e ff in tc3 with hydrus and hypix are quite similar but hypix was slightly more efficient in tc4 for the modelling of impermeable layers tc5 hydrus was five times more efficient than hypix this is further discussed in section 5 6 5 2 benefits of time stepping ψ compared to time stepping θ by using the hypix parameters described in table 1 we found that for tc1 and tc2 coarse texture soils the model failed to converge when using as an option the traditional time stepping θ nonetheless these cases were successful when using the time stepping ψ for the other test cases the time stepping θ was successful and marginally more efficient in the wb and e ff results not shown than the time stepping ψ the time stepping ψ is more accurate than the time stepping θ particularly for coarse texture soils because the time stepping ψ reduces δt when the soil is close to saturation by reducing δ θ max i t eq 25 this is important because close to saturation we have θ ψ 1 which could lead the nr step to go to infinity therefore the adaptive time stepping management for solving the rre based on ψ is the recommended option for hypix because it enables the success of convergence and accuracy for all soil types and boundary conditions 5 3 benefits of the dry method the use of the modified iteration criterion for initially dry conditions from zha et al 2017 section 2 3 4 4 enables tc1 and tc2 to converge using large δθ max table 1 nevertheless the dry method had no effect for the other finer texture test cases similar results were found in table 5 by using real test cases with finer texture soils the results are in line with those of zha et al 2017 who found that the dry methods only benefited coarse texture soils with small σ and when infiltration occurs into initially dry conditions the dry method successfully detects if there is any oscillation at the dry end of the θ ψ curve caused by infiltration into dry soils if this occurs then the next iteration is computed from θ ψ eq 3 in order to apply the dry method ψ dry σ and ψ wet σ eq 39 need to be computed we recommend applying the dry method for all soils because it gets activated only when oscillation occurs at the dry end of the θ ψ curve 5 4 benefits of dynamic ω the benefits of the novel physical dynamic ω smoothing criterion section 2 3 4 3 for controlling the nr steps compared to the traditional constant ω section 2 3 4 2 was evaluated with the experimental data section 4 2 under variable fluxes and sink term using the universal hypix parameters described in table 1 the novel dynamic ω smoothing criterion outperforms in accuracy and efficiency the smoothing criterion with constant ω for all sites the use of the dynamic ω dramatically reduces w b η eq 35 by three orders of magnitude and increases e ff threefold this is because the nr step reduces automatically during iteration when large θ ψ i t k 1 θ ψ i t k is encountered compared to δ θ max t k eq 25 computed from time stepping ψ the convergence rate is slowed but the success rate of convergence is increased the other benefit of the dynamic ω is that it does not require any extra parameters we therefore strongly recommend the dynamic ω smoothing criterion 5 5 non benefits of the absolute convergence criterion for tc1 and tc2 sandy loam soils there were some minor improvements in the wb and e ff using the absolute convergence criterion section 2 3 4 1 to control the nr step results not shown nevertheless when using the absolute convergence criterion for finer texture soils such as tc3 tc4 and tc5 it failed to converge the absolute convergence criterion δ ln ψ max i ln ψ i t k ln ψ i t k 1 fails to improve the results because the dynamic ω accurately controls the nr step considering a smoother transition in the overall nr method therefore the use of the absolute convergence criterion is not recommended 5 6 impermeable layers in tc5 we model saturating a soil profile from the top with an impermeable layer at the bottom hypix is successful in obtaining excellent water balance being four orders of magnitude more accurate that hydrus and null drainage at the bottom while hydrus has some drainage at the bottom this would explain why hypix is considerably less efficient for this case than hydrus because with the selected parameters hypix has higher accuracy 6 conclusions the newly developed open source hydrological pixel model hypix written in the fast and flexible julia language efficiently solves the mixed form of the rre hypix uses a cell centred finite volume scheme for the spatial discretization with an implicit euler scheme for the temporal discretization by using the weighted average inter cell hydraulic conductivity hypix includes the following modules a rainfall interception b root water uptake with compensation algorithm and root growth c soil evaporation and d ponding and e runoff using a novel method for computing sorptivity hypix includes a wide range of top and boundary conditions flux pressure free the drawback of using the nr method for solving the rre is that every configuration e g changing the inter cell hydraulic conductivity requires reprogramming the derivatives appendix hypix implements an option to solve the derivatives numerically section 2 3 2 enabling the rre to be modified by changing only a few lines of code numerically calculating derivatives was found to be as accurate as deriving the derivatives mathematically and only 10 25 slower for controlling the newton raphson steps hypix incorporates several options where it is demonstrated that the recommended novel physical smoothing criterion for controlling the newton raphson step with dynamic ω improves not only the model performance but also its accuracy compared to using the traditional absolute convergence criterion for controlling the time step the physical time step management based on δθ kirkland et al 1992 ross 2003 was specifically designed to solve rre based on θ therefore we adapted the time step management so that it is specifically designed to solve rre based on ψ without introducing further parameters the novel time step management requires only one parameter and was found to be more efficient than the traditional time step management the well established hydrological model hydrus was used to validate hypix the comparison of both models shows a remarkable agreement confirming the validity of the algorithms implemented in hypix even for challenging conditions hypix can provide accurate and reliable results using the recommended standard options moreover the algorithm developed in hypix generates results more efficiently that the one used in hydrus particularly for coarse texture soils an additional benefit of hypix is its simplicity to use because it requires only eight parameters hydrus has 13 fitting parameters and most of them can be safely kept to the recommended value described in table 1 the stability and robustness of the solution of the rre in hypix enables it to be used for inverse modelling software data availability the hypix model source code and the test cases can be downloaded from https github com manaakiwhenua soilwater toolbox jl and is open source under the gp 3 0 license hypix is written in the open source julia programming language and can be run under multiple platforms https julialang org downloads access to the experimental field data require permission from environment canterbury https www ecan govt nz while the sites and the latest monitoring data can be viewed at https www waikatoregion govt nz environment envirohub environmental maps and data dt soil moisture af latestvalue a latest hypix is part of a set of interlinked modules implemented into the soilwater toolbox ecosystem led by j a p pollacco from manaaki whenua landcare research in new zealand and j fernández gálvez from the university of granada in spain the preliminary objective of the soilwater toolbox is to derive the soil hydraulic parameters by using wide range of cost effective methods the estimated hydraulic parameters can be directly implemented into hypix to compute the soil water budget the soilwater toolbox enables the comparison and sensitivity analyses of the hydraulic parameters computed from different methods on the soil water fluxes the following modules are currently included into the soilwater toolbox intergranular mixing particle size distribution module derives unimodal hydraulic parameters by using particle size distribution pollacco et al 2020 general beerkan estimation of soil transfer parameters module derives the unimodal hydraulic parameters from single ring infiltration experiments fernández gálvez et al 2019 sorptivity module a novel computation of sorptivity used in the general beerkan estimation of soil transfer parameters method lassabatere et al 2021 2022 saturated hydraulic conductivity module derived from unimodal and bimodal θ ψ pollacco et al 2013b 2017 inverse module which inverts hydraulic parameters from θ time series pollacco et al 2022 reduce uniqueness module of a physical bimodal soil kosugi hydraulic parameters from inverse modelling fernández gálvez et al 2021 using water retention and or unsaturated hydraulic conductivity data directly measured in the laboratory or indirectly obtained from inverting θ time series declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could appear to influence the work reported in this paper acknowledgements this research was supported by the winning against wildings research programme funded by the new zealand ministry of business innovation and employment and through the manaaki whenua led next generation s map research programme we would like to thank justin wyatt waikato regional council new zealand for providing monitored data for the field sites funding for open access charge universidad de granada cbua appendix jacobian matrices the newton raphson solution requires the jacobian matrix which can be written in a matrix form as an example with n iz depths the numerical discretization is a tridiagonal non linear set of equations which needs to be solved for ψ i z i t k 1 ψ i z i t k for every time step and for every iteration k 40 i 1 i 2 i 3 i n 1 i n r 1 t k ψ 1 t r 1 t k ψ 2 t 0 0 0 r 2 t k ψ 1 t r 2 t k ψ 2 t r 2 t k ψ 3 t 0 0 0 r 3 t k ψ 2 t r 3 t k ψ 3 t r 3 t k ψ 4 t 0 0 0 r n 1 t k ψ n 2 t r n 1 t k ψ n 1 t r n 1 t k ψ n t 1 0 0 0 r n t k ψ n 1 t r n t k ψ n t ψ 1 t k 1 ψ 1 t k ψ 2 t k 1 ψ 2 t k ψ 3 t k 1 ψ 3 t k ψ n 1 t k 1 ψ n 1 t k ψ n t k 1 ψ n t k r ψ 1 t k r ψ 2 t k r ψ 3 t k r ψ n 1 t k r ψ n t k the solution of these sets takes place by means of the tridiagonal function which is an effective modification of the gauss algorithm for the solution of a tridiagonal linear set of equations in julia we use the efficient tridiagonal function to solve the matrix the derivatives of r are shown below derivatives of residuals julia i 1 eq r ψ r 1 t k ψ 0 t not applicable 41 r ψ r 1 t k ψ 1 t same as 2 i n 1 42 r ψ r 1 t k ψ 2 t same as 2 i n 1 43 2 i n 1 r ψ r i t k ψ i 1 t 1 δ t q i t ψ i 1 t 44 r ψ r i t k ψ i t δ z i θ i ψ i t ψ i t 1 s o θ s ψ i t 1 ψ i t s o θ s θ i ψ i t δ t q i 1 2 t ψ i t q i 1 2 t ψ i t 45 r ψ r i t k ψ i 1 t δ t q i 1 2 t ψ i 1 t 46 i n r ψ r n t k ψ n 1 t same as 2 i n 1 47 r ψ r n t k ψ n t same as 2 i n 1 48 r ψ r n t k ψ n 1 t not applicable 49 derivatives of q julia i 1 eq q ψ q 1 2 t ψ 0 t not applicable 50 q ψ q 1 2 t ψ 1 t flux top boundary condition 0 51 prescribed top pressure boundary condition ψ t o p t ψ 1 t δ z 1 2 cos α k 1 ψ 1 t ψ 1 t k 1 ψ 1 t δ z 1 2 52 q ψ q 1 1 2 t ψ i t same as for 2 i n 53 q ψ q 1 1 2 t 1 ψ 2 t 1 same as for 2 i n 54 julia 2 i n 1 q ψ q i 1 2 t ψ i 1 t 1 w i ψ i 1 t ψ i t δ z i 1 2 cos α k i 1 ψ i 1 t ψ i 1 t w i k i ψ i t 1 w i k i 1 ψ i 1 t δ z i 1 2 55 q ψ q i 1 2 t ψ i t w i ψ i 1 t ψ i t δ z i 1 2 cos α k i ψ i t ψ i t w i k i ψ i t 1 w i k i 1 ψ i 1 t δ z i 1 2 56 q ψ q i 1 2 t ψ i t 1 w i 1 ψ i t ψ i 1 t δ z i 1 2 cos α k i ψ i t ψ i t w i 1 k i 1 ψ i 1 t 1 w i 1 k i ψ i t δ z i 1 2 57 q ψ q i 1 2 t ψ i 1 t w i 1 ψ i t ψ i 1 t δ z i 1 2 cos α k i 1 ψ i 1 t ψ i 1 t w i 1 k i 1 ψ i 1 t 1 w i 1 k i ψ i t δ z i 1 2 58 julia i n recharge q ψ q n 1 2 t ψ n 1 t same as for 2 i n 1 59 q ψ q n 1 2 t ψ n t same as for 2 i n 1 60 q ψ q n 1 2 t ψ n t free drainage bottom boundary condition k n ψ n t ψ n t cos α 61 prescribed bottom pressure boundary condition ψ n t ψ bot t δ z n 2 cos α k n ψ n t ψ n t k n ψ n t δ z n 2 62 bottom boundary condition 0 63 q n 1 2 t 1 ψ n 1 t 1 not applicable as ψ n 1 t 1 const 64 potential evapotranspiration the potential evapotranspiration depth δpet l for a time step δt is computed using the penman monteith equation input variables used the estimates derived from the new zealand virtual climate stations network vcs which are based on the spatial interpolation of actual data observations made at climate stations located around the country tait et al 2006 we assume that 65 δ p e t δ p e t int where δpet int l is the interception potential evaporation depth which is the potential evaporation from a wet canopy the remaining energy that is not used to evaporate water from a wet canopy e g periods with no rainfall allows the potential evapotranspiration depth δpet et l to be computed as 66 δ p e t et δ p e t δ e v a p int where δevap int l is derived from the actual energy used to evaporate water from a wet canopy the potential transpiration depth of vegetation δpet transp l and potential evaporation depth of soil δpet evap l is partitioned from δpet et by using the beer lambert law which uses as parameters the leaf area index lai lai can be derived from remote sensing béland et al 2014 the beer lambert law assumes that the net radiation inside the canopy decreases exponentially therefore the partitioning of δpet et is given by 67 δ p e t evap δ p e t et e k g l a i 68 δ p e t transp δ p e t et δ p e t evap where the extinction coefficient for solar radiation k g is set to 0 5 e g varado et al 2006 rainfall interception the parsimonious physically based interception model is an improvement made by pollacco et al 2013a the following interception model uses potential evaporation of a wet canopy δpet int eq 65 lai and extinction coefficient for solar radiation k g set to 0 5 the gross precipitation depth that falls on top of a canopy δpr l is partitioned following rutter et al 1971 as 69 δ p r δ p r int δ p r ground where δ p r ground l is the fraction of precipitation reaching the soil surface through gaps in the canopy and δ p r int l is the intercepted precipitation depth they are computed as 70 δ p r ground g apfrac δ p r δ p r int 1 g apfrac δ p r where the gap fraction g apfrac is calculated similarly to eq 67 71 g apfrac 1 e k g l a i the foliage of the canopy is considered as water storage filled up to depth sint l with a saturated storage capacity s i n t sat l when the canopy is fully saturated s i n t s i n t sat then any excess of δ p r int overflows δ p r over l to the soil surface the amount of water that reaches the soil surface is the throughfall precipitation l 72 δ p r through δ p r ground δ p r over the water storage of the canopy is first computed as 73 s i n t t s i n t t 1 δ p r int a fraction of the water from sint will be evaporated at the rate of the actual evaporation depth δ e v a p int l during and after a rainfall event the maximum quantity of water that can be evaporated from a wet canopy during a time step is computed according to deardorff 1978 which assumes that δ e v a p int is proportional to the fraction of the canopy that is wet 74 δ e v a p int δ p e t int min s i n t t s i n t sat s i n t sat p e v a p int where pevap int is a constant parameter for which deardorff 1978 gives a constant value of 2 3 δ p r over is computed as 75 δ p r over m i n s i n t t 1 δ p r int δ e v a p int s sat 0 s i n t t m i n s i n t t 1 δ p r int δ e v a p int δ p r over 0 rainfall interception of gross rainfall loss i n t e r c e p t i o n l o s s 0 1 is computed by 76 i n t e r c e p t i o n l o s s 1 t 1 n t δ p r through t t 1 n t δ p r t in the hypix model the rainfall interception module is run first followed by the computation of δpet transp and δpet evap as described in appendix sink term the sink term δsink described in eq 5 is a function of the soil evaporation depth δ e v a p l eq 78 and the root water uptake depth of the vegetation δ r w u l eq 79 77 δ s i n k δ e v a p δ r w u evaporation δevap the evaporation model based on romano and giudici 2009 and adapted by pollacco and mohanty 2012 is computed as 78 δ e v a p δ p e t evap s e 1 where se 1 0 1 refers to the effective soil water content defined in eq 1 for the top cell and δ p e t evap l is the potential evaporation depth computed with the beer lambert law eq 67 root water uptake δrwu the root water uptake computes the volume of water removed per unit time from a unit volume of soil in the root zone and is computed for each cell i 79 δ r w u i min k c δ p e t transp δ r d f i f w a t e r s t r e s s i r o o t c o m p i δ z θ i t θ r i t where δrwu l is the root water uptake depth k c is the crop coefficient δ p e t transp l corresponds to the potential transpiration depth eq 68 δrdf refers to the percentage of roots per cell fwaterstress is the water stress function per cell which computes the reduction of transpiration based on ψ and rootcomp is the root compensation by enabling water uptake from deeper layers when the upper layers are depleted root density function δrdf the percentage of roots per cell i is given by δrdf i which defines the general shape of the roots as given by the example provided in fig 5 the root distribution is based on an improved empirical function of gale and grigal 1987 which was modified by pollacco et al 2008 the model requires as parameters solely the maximum rooting depth z nroot l and the percentage of roots in the top 30 cm other values can be taken δrdf top the model compared to gale and grigal 1987 guarantees that the sum of δrdf i 1 the fraction of roots δrdf i for each cell i is computed as 80 δ r d f i r d z i 1 2 r d z i 1 2 1 r d z n root with i 1 i n root δ r d f i 1 where z i 1 2 and z i 1 2 l are respectively the depth of the top and the bottom of cell i as described in fig 1 r d is the routing distribution parameter computed numerically from z nroot and δrdf top r d varies between 0 7000 and 0 9999 such that when r d is close to 0 7 all the roots are distributed at the top and when r d is close to 1 the roots are evenly distributed within the root zone the value of r d is computed by solving the following equation 81 δ r d f top r d 0 r d 30 1 r d z n root 1 r d 30 1 r d z n root an example of δrdf is provided in fig 5a for a soil that has equal discretization water stress response function f waterstress the water stress response function f waterstress shown in fig 5b is a prescribed dimensionless function of ψ where 0 f w a t e r s t r e s s 1 following feddes et al 1978 f waterstress is defined by using four soil water pressure values leading to a trapezoidal curve so that f waterstress 0 close to saturation at a pressure greater than ψ feddes 1 and also above the permanent wilting point soil water pressure ψ feddes 4 f waterstress 1 between soil water pressures ψ feddes 2 and ψ feddes 3 for soil water pressure between ψ feddes 1 and ψ feddes 2 f waterstress increases linearly for soil water pressure between ψ feddes 3 and ψ feddes 4 f waterstress decreases linearly a schematic plot of this stress response function is depicted in fig 5b compensation mechanism root comp a root water uptake compensation mechanism is introduced to improve the prediction of transpiration by enabling water uptake from deeper layers when the upper layers are depleted although the percentage of roots at deeper depth is limited the compensation mechanism of li et al 2001 validated by braud et al 2005 is introduced the model requires the compensation mechanism parameter c which accounts for the general soil water content profile before computing the water uptake from individual cell i and is derived as 82 δ r o o t c o m p i f w a t e r s t r e s s i δ r d f i c 1 i 1 i n root f w a t e r s t r e s s i δ r d f i c where δ r d f i eq 80 is the vertical fraction of the root density function for each i cell f waterstress is the reduction of root water uptake at pressure head ψ for every cell and c is a parameter such that when c 1 the model is not compensated and when c 0 the δ r d f i becomes constant throughout the whole root zone depth i n root in hypix c 0 5 as suggested by li et al 2001 and braud et al 2005 
