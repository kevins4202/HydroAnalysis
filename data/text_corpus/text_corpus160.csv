index,text
800,we explore how x ray computed microtomography can be used to generate highly resolved 3d biofilm datasets on length scales that span multiple pore bodies the data is integrated into a study of the effects of flow rate on three dimensional growth of biofilm in porous media three flow rates were investigated in model packed bed columns biofilm growth was monitored during an 11 day growth period using a combination of differential pressure and effluent dissolved oxygen measurements at the end of the growth period all columns were scanned using x ray computed microtomography and a barium sulfate based contrast agent the resulting images were prepared for quantitative analysis using a novel image processing workflow that was tailored to this specific system the reduction in permeability due to biofilm growth was studied using both transducer based pressure drop measurements and image based calculations using the kozeny carman model in addition a set of structural measures related to the spatial distribution of biofilms were computed and analyzed for the different flow rates we generally observed 1 to 2 orders of magnitude decrease in permeability as a result of bioclogging for all columns i e across flow rates the greatest average permeability and porosity reduction was observed for the intermediate flow rate 4 5 ml h a combination of results from different measurements all suggest that biofilm growth was oxygen limited at the lowest flow rate and affected by shear stresses at the highest flow rate we hypothesize that the interplay between these two factors drives the spatial distribution and quantity of biofilm growth in the class of porous media studied here our approach opens the way to more systematic studies of the structure function relationships involved in biofilm growth in porous media and the impact that such growth may have on physical properties such as hydraulic conductivity keywords biofilms granular porous media x ray computed microtomography image processing statistical learning fluid phase topology nomenclature φ porosity ρ fluid density vs vz stream wise superficial darcy velocity d pore radius characteristic length scale μ fluid viscosity re reynolds number q volumetric flow rate a cross sectional area κzz stream wise component of the permeability tensor p hydrodynamic pressure g acceleration due to gravity k column hydraulic conductivity φ hubbert s potential hydraulic head l column length δp net pressure difference across column τ tortuosity s interfacial area to volume ratio β constant in the kozeny carman model i total number of evaluated images n total number of voxels evaluated at coordinate x π set of all pairs of neighboring voxels c x class label of voxel at point x μ c λ class mean in image λ σ 2 class variance in image λ g i x gray value of voxel x in image i χ euler characteristic n number of isolated objects in a material of interest l number of redundant connections within all material clusters o number of cavities in a material of interest dα average pore diameter in phase α eα average distance within phase α ci the connectivity index psi the pore size index sdi the solid distance index 1 introduction the interaction of hydrodynamics and biofilm growth in media with tortuous geometries is of great scientific interest because of its prevalence in many natural and engineered systems drescher et al 2013 as examples biofilm growth in porous media has been both directly observed and indirectly hypothesized with substantial supporting evidence in a wide variety of natural and engineered systems these include examples such as anaerobic reactors e g young and dahab 1983 microbially enhanced oil recovery e g armstrong and wildenschild 2012 sen 2008 micromodel experiments e g kim and fogler 2000 stewart and fogler 2001 laboratory porous media experiments e g vogt et al 2013 and slow sand filter beds e g li et al 2013 although there are ongoing discussions regarding the ubiquity of biofilms baveye and darnault 2017 coyte et al 2017 these studies offer significant and often direct evidence that biofilm formation in porous media is an important component for many processes of relevance and interest in natural and synthetic porous media biofilm growth at the pore scale affects various transport processes by altering the structure of interfaces connectivity of the pore space and bulk geometric properties of the medium baveye et al 1998 cunningham et al 1991 drescher et al 2013 rittmann 1993 in turn cellular growth and mesoscale structural evolution of biofilms are highly interconnected with various aspects of transport including shear and mass transfer non destructive imaging of biofilms is essential to understanding the physics of these processes and their broader impacts on design control and prediction in disciplines that are concerned with natural porous media e g hydrology petroleum engineering the ability to visualize biofilm growth under flow on the scale of millimeters to meters has been of great interest e g thullner 2010 yarwood et al 2002 visualization is gaining even more significance with the increasing complexity and fidelity of the mathematical and computational approaches to modeling biofilm growth in porous media e g von der schulenburg et al 2009 the challenges associated with non intrusive visualization of 3d systems often forces direct comparison between models and experiments to rely on bulk aggregate laboratory or field measurements i e evaluations on scales where pore scale structural information detrimental to transport is lost to the averaging inherent to measurements thullner 2010 magnetic resonance microscopy mrm and nuclear magnetic resonance imaging nmr have been successfully applied to elucidate the global structure of biofilms in porous media and pore fluid velocities in media altered by microbial growth manz et al 2003 seymour et al 2004 2007 albeit with some resolution limitations confocal laser scanning microscopy clsm and more recently optical coherence tomography oct have been successfully applied to the visualization of the 3d structure of biofilms on smaller scales with higher resolutions davit et al 2013 dreszer et al 2014 neu and lawrence 2015 wagner et al 2010 xi et al 2006 both methods enable temporal studies of growth in flow environments and provide highly resolved reproductions of the internal structure of the biofilm matrix a popular approach to direct visualization of biofilm structure in porous media at the pore scale has been to adopt these techniques to study growth in optically transparent leis et al 2005 2d and pseudo 3d micro models e g beyenal et al 2004 kim and fogler 2000 rodríguez and bishop 2007 stoodley et al 1999 a limitation in extending this methodology to study biomass formation in 3d porous media is that experimental systems must be optically transparent small enough to fit onto the microscope stage and in the case of clsm thin enough to fit within the focal range of the device conversely 3d porous systems are opaque and deep whether or not the conclusions drawn for 2d systems can be extended to 3d is an unanswered question topologically the two are not equivalent e g diffusions in 2 and 3 dimensions are fundamentally different so one would not expect 2 dimensional experiments to capture the range of physical behaviors thus the literature s prevailing answer to this question seems to be negative e g see the discussion by baveye 2010 thullner 2010 x ray computed microtomography cmt is emerging as an alternative that enables visualization of biofilms in 3d in opaque media davit et al 2011 iltis et al 2011 wildenschild and sheppard 2013 on the pore scale though still in its infancy the method was originally developed and explored using both polychromatic davit et al 2011 and monochromatic synchrotron based systems iltis 2013 iltis et al 2011 users can expect voxel resolutions on the order of 1 2 microns to be easily achieved the technique relies on the use of contrast agents to facilitate the adsorption based detection of different phases within an opaque sample using x rays central to the method is creating a physical mechanism that through the use of advanced image processing techniques allow for differentiation between the fluid and biofilm phases the natural attenuation photon cross section of which are almost identical use of different contrast agents added to the aqueous phase such as silver coated hollow microspheres iltis et al 2011 barium sulfate suspensions davit et al 2011 iltis 2013 and 1 chloronaphtalene ivankovic et al 2017 du roscoat et al 2014 have shown promise similarly adding feso4 as a contrast agent to the biofilm phase and using the free space propagation of x rays to bring out additional refractive effects carrel et al 2017 were also able to image biofilms in opaque porous media the latter study compared the feso4 to the baso4 method and found differences in the amount of biofilm imaged with a significantly larger amount of biofilm identified using the feso4 method the authors pointed out three possible reasons for the discrepancy i partial volume effects eliminated from consideration ii uncertainty related to the segmentation caused by the significant heterogeneity of the biofilm phase and poor contrast of said phase and iii interaction between the baso4 and the biofilm causing suspended biomass and loosely attached components of the biofilm to be washed out of the columns the potential for detachment of biofilm during addition of a denser and more viscous aqueous phase contrast agent has been discussed by davit et al 2011 and du roscoat et al 2014 in a thorough study of the problem ivankovic et al 2017 found that this effect can be eliminated by using smaller beads in their case less than 2 mm and by making measurements after longer periods of biofilm growth 7 days such that a more compact and tightly attached biofilm was formed this allowed for reliable studies on biofilms that presented similar and reproducible spatial structure and allowed for quantitative evaluation of a number of different environmental variables in their study growth periods of less than 3 days and larger pore sizes resulted in less resilient biofilms exhibiting streamers and other weakly attached components that may be subject to detachment shear by a more viscous contrast agent such as baso4 or 1 chloronaphtalene for the 1 chloronaphtalene cn an additional challenge was caused by the oily nature of the contrast agent which caused pendular rings of cn to be left behind at bead contacts the exact growth period and pore size that will produce repeatable experiments will vary somewhat with organism nutrient supply flow rate all factors contributing to the production of more or less dense biofilms and the viscosity of the injected contrast agent if relevant the past studies using aqueous phase contrast agents serve as promising proof of the concept as long as the risk of viscous interaction with the biofilm is considered in the design of the experiments while there is less risk of detachment using a contrast agent in the biofilm itself carrel et al 2017 the resulting weak contrast between the various phases makes reliable and objective quantitative evaluation difficult in this study we present a systematic study on the correspondence between physical quantities derived from ct data and physical measurements of biofilm growth such a comparison has yet to be reported in the literature our data consists of duplicate columns grown for 11 days to ensure a dense and resilient biofilm the resulting image histograms exhibit distinct separation of the intensity peaks indicative of effective phase separation and we use advanced image processing methods to allow for objective measurements of a number of biofilm features as a function of reynolds number re when possible we cross validate the results obtained via microimage analysis with those obtained via direct bulk measurements numerous studies conducted on bioclogging in porous media under various conditions have reported significant reductions in hydraulic conductivity often up to 2 3 orders of magnitude or more bielefeldt et al 2002 cunningham et al 1991 seifert and engesgaard 2007 thullner 2010 vandevivere and baveye 1992 due mainly to limitations in measuring or imaging the spatial distribution of biomass however only a few reports have attempted to associate changes in pore morphology with changes in hydraulic conductivity in 3d mostly indirectly or via destructive sampling a number of authors have observed that a majority of the biomass and associated clogging occurred within the first several centimeters of the experimental apparatus e g seifert and engesgaard 2007 others have argued that bioclogging should be attributed primarily to blockage of pore throats by biomass as opposed to uniform continuous films on solid surfaces e g vandevivere et al 1995 2 methods by building on the work of davit et al 2011 we study flow rates that span three orders of magnitude corresponding to initial pore scale re of 0 1 1 0 and 10 covering creeping to mildly laminar flows we are particularly interested in characterizing the global biofilm structure grown under the stipulated flow conditions and tracing these variations to bulk measurements the work introduces a simple analysis of biofilm growth within opaque porous media based on 3d structural measures along with correlation to i bulk pressure drop measurements and ii dissolved oxygen consumption to evaluate potential nutrient limitations imparted by the applied flow rates our analysis relies on a novel image processing workflow that addresses some of the limitations associated with inhomogeneous distribution of the contrast agent in the pore space 2 1 model porous medium packed bead column reactors measuring 6 3 mm in diameter 42 mm in length with a 25 mm clear window were constructed of polycarbonate tubing the porous medium consisted of soda lime silica glass beads with particle diameter within the range 1 4 1 7 mm and specific gravity of 2 5 a total of 6 growth reactors were used in this study so that there were duplicate columns examined at each flow rate initial column porosities were measured gravimetrically prior to the experiments and initial flow testing was conducted to measure the hydraulic conductivity of the models as described below 2 2 microbial species the bacterium used in this study is shewanella oneidensis mr 1 a metal reducing strain originally isolated from sediment from lake oneida in new york s oneidensis mr 1 is a gram negative highly piliated polarly flagellated facultative anaerobe capable of dissimilatory metal reduction and biofilm formation majors et al 2005 venkateswaran et al 1999 the bacterium is motile the presence of pili are critical to initial adhesion and the flagella have been identified as being critical for development of effective biofilm structure thormann et al 2004 the bacterium has also been shown to be motile in response to low oxygen tensions thormann et al 2005 this strain has been used successfully in previous biofilm imaging studies conducted by our group iltis et al 2011 2 3 growth media and conditions inocula were grown from frozen stock for two growth cycles initially frozen stock was thawed and 0 5 ml stock culture was added to 30 ml sterile 100 30 g l tryptic soy broth tsb batch cultures were grown on an incubated shaker table at 250 rpm and 30 c for 20 h at which point the second growth cycle was started by adding 1 ml of batch culture from the first growth cycle to 30 ml fresh sterile 100 tsb growth media batch cultures were then incubated for another 20 h cycle at the conclusion of the second growth cycle batch cultures were centrifuged at 6000 rpm for 10 min the supernatant was poured off and the cell pellets were resuspended in 5 ml 100 tsb 30 g l growth media for column inoculation all column growth reactors and tubing were sterilized prior to inoculation by flushing a 90 ethanol solution through the test apparatus for 30 min at which point a growth media flush commenced to ensure that all ethanol was removed from the system prior to inoculation the sterile 10 tsb saturated columns were then injected with 1 ml of the concentrated cell inoculum a 24 h no flow period was allowed to promote biofilm nucleation after which flow of sterile oxygenated growth media was started at the prescribed flow rates inocula for the initial growth period were prepared in 100 30 g l tryptic soy broth tsb solutions the medium was diluted down to 10 3 g l for the flow experiments all growth media were sterilized prior to injection and continuously aerated using 0 22 µm filtered ambient air a consistently oxygen saturated injection with an average influent o 2 concentration of 8 05 0 29 mg l was maintained in the flow experiments three flow rates in the creeping and mildly laminar regimes were targeted for investigation the corresponding initial re were 0 1 1 and 10 where the re is evaluated for a packed bed using gunjal et al 2005 1 r e 1 1 φ ρ v s d μ here ρ g ml is the density of the fluid phase d cm is a characteristic pore length for the porous medium taken to be the average grain size μ g cm h is the dynamic viscosity of the fluid phase and φ is the bulk porosity and vs cm h is the superficial darcy velocity defined as 2 v s q a where q ml h is the fluid flow rate a cm2 is the cross sectional area without the porous medium note that φ changes during the course of the experiments so the above values represent reynolds numbers at the onset of growth for the model systems used in this study these values correspond to flow rates of 4 5 45 and 450 ml h these values are referred to as the lowest intermediate and highest flow rates throughout the text continuous flow was provided to each column growth reactor using continuous cycle syringe pumps check valves were used to ensure that flow through the reactor columns was always unidirectional a schematic of the experimental setup is provided in fig 1 a growth media reservoirs were replaced at approximately 36 h intervals and all influent lines were replaced every two days to minimize biofilm growth upstream of the experimental columns biofilm growth was allowed to continue under constant flow conditions for 11 days at which point the columns were disconnected and prepared for imaging 2 4 differential pressure measurement differential pressure transducers honeywell sensing and control 24pc series columbus oh usa were affixed to each experimental column at the column entrance and exit in order to allow for measurement of differential pressure across each column length continuous differential pressure measurements were collected by an automated data acquisition system personal daq 50 measurement computing corp norton ma 2 5 dissolved oxygen measurement periodic measurements of dissolved oxygen do were performed on the influent and effluent sides of each column for the duration of the biofilm growth phase of the experiment effluent do was measured using flow through oxygen microprobes model 16 730 microelectrodes inc beadford nh usa influent do measurements were made using a separate probe symphony vwr international on samples extracted from the sterile media reservoirs the equipment for measuring influent and effluent dissolved oxygen were kept separate for the duration of the experiment in order to prevent contamination dissolved oxygen probes were cleaned using a tergazyme alconox inc white plains ny usa protein removal solution after every set of measurements 2 6 computed x ray microtomography imaging x ray cmt imaging was conducted at the advanced photon source aps facility at argonne national laboratory using beamline 13bmd at gsecars geosoilenviro consortium for advanced radiation sources immediately prior to imaging sample columns were disconnected from influent and effluent lines and injected with the contrast agent solution the contrast agent consisted of a medical grade barium sulfate baso4 suspension micropaque guerbet mixed with sterile growth media the 1 0 g ml stock suspension was diluted down to a usable concentration of 0 33 g ml the contrast agent was injected into the sample columns using a syringe pump at a rate of 1 2 ml h for the r e 0 1 and 1 0 columns and 5 ml h for the r e 10 columns a total of 2 ml of contrast agent solution was injected into each column the average pore volume prior to column inoculation is approximately 0 5 ml so approximately 4 pore volumes of contrast agent was added to each column the diluted solution 0 33 g ml was selected to balance the absorption of x ray through the columns with the saturation limit of the x ray detector ccd camera interested readers are referred to iltis 2013 for a thorough discussion of barium sulfate concentration ranges for synchrotron based x ray cmt of biofilms where it was reported that the useful range of barium concentration for columns 5 7 mm in diameter is 33 0 33 g ml to 50 0 5 g ml barium sulfate the k shell absorption edge for barium is 37 4 kev so each column section was scanned at two energies one above 37 54 kev and one below 37 34 kev this edge the entire length of each column was scanned by moving the sample stage vertically and generating a series of overlapping scan sections volumetric reconstruction of each section was obtained from a series of two dimensional scans that are obtained via a 180 rotation of the sample stage over 720 increments at each height the choice of 720 angles is based on experience with the instrumentation at this particular beam line the theoretical number of projection angles required is the number of pixels the area of interest covers as the sample rotates 360 multiplied by 1 5 or 540 angles by oversampling with 720 angles blur is reduced and the resulting images are of a higher quality this allows more accurate segmentation and subsequent quantitative analyses 2 7 image processing and quantitative analysis the reconstructed datasets have dimensions of 695 695 470 voxels a voxel resolution of 10 5 µm and are stored with 16 bit precision as a first preprocessing step a cylindrical region of interest roi inside the core was extracted a total variation filter was applied for denoising and an unsharp mask filter used for edge enhancement schlüter et al 2014 image segmentation of the grayscale data focused on isolating three phases the biofilm the baso4 suspension representing the aqueous phase and the solid phase glass beads for these data proper segmentation required the development of a novel segmentation algorithm that incorporated complementary information from various image sources direct isolation of the baso4 was facilitated using the increased absorption in the above ba edge vs below ba edge data sets which is reflected by high intensity in a difference image however the baso4 suspension had small scale heterogeneity due to locally varying barium concentrations likely a side effect of using a barium concentration on the low end of the applicable concentration range of 33 50 segmentation of the baso4 suspension even in low concentration regions can therefore be improved further by directly evaluating the degree of small scale heterogeneity in a gradient image the beads and the biofilm exhibited homogeneous and independently distinguishable x ray absorption at both the above and below edge scanning energies since one image suffices isolation of the beads and biofilm was accomplished using the below edge image data sets a markov random field mrf segmentation algorithm kulkarni et al 2012 schlüter et al 2014 was extended to allow for multiple class statistics from various image sources at the core of this method a combinatorial optimization problem is solved in order to find a labeling c that satisfies 3 c argmin i 1 i j 1 n α i ln 2 π σ c i 2 g i x j μ c i 2 2 σ c i 2 class statistics x j y j π γ c x j c y j class boundaries with 4 γ c x j c y j 1 c x j c y j 1 c x j c y j here i is the total number of evaluated images below edge image gradient image and difference image n is the total number of voxels evaluated with coordinate x j π is the population of all pairs of neighboring voxels at coordinates x and y c x j is the class label at x j beads biofilm or baso4 suspension μ c i and σ c i 2 are class mean and variance in a specific image i gi x j is the gray value at the coordinate x j in image i and αi is a user defined image specific weighting factor that determines the contribution of each likelihood term for a given class relative to the penalty term for class boundaries in other words a class label at a certain location is very likely if i the local gray values in all images is close to the specific class mean for these images and if ii the majority of neighbors already belong to the same class class updating was achieved in a deterministic order denoted as iterative conditional modes icm i e starting at one corner of the image the label for each voxel was replaced by the class that minimizes the contribution to eq 3 the algorithm was stopped after three loops values for μ c i and σ c i 2 have to be determined prior to segmentation which was done by evaluating the joint probabilities as explained in the appendix classification errors in the mrf segmentation results due to partial volume effects were removed via post processing which is also explained in the appendix the entire workflow from preprocessing to image segmentation and post processing is based on the quantim image processing library schlüter et al 2014 vogel et al 2010 the vertical series of eight segmented volumes is subsequently merged into one column via landmark registration in avizo fire 8 3 that is two consecutive volumes overlapping by 25 and pairs of identical coordinates within these overlap regions have to be identified by tracking easily identifiable features fig 1 e depicts the merged column for a sample grown under high flow rate conditions 450 ml h r e 10 after segmentation the columns are analyzed for each vertical section individually in order to detect changes with respect to inlet distance the investigated properties comprise standard properties like porosity biofilm volume biofilm surface area biofilm thickness and volume percentage attached to sidewalls in addition the spatial patterns of growth and attachment are characterized with three normalized indexes that cover different aspects of biofilm configurations as demonstrated for a small subset in fig 2 the connectivity index ci characterizes whether the biofilm is well or poorly connected by means of the euler characteristic χ this topological measure is defined as vogel et al 2010 5 χ n l o where n is the number of isolated objects of the material of interest l is the number of redundant connections within all material clusters and o is the number of cavities e g isolated background clusters completely enclosed by the material the euler characteristic of the entire pore space in a bead pack χps is usually negative because it is well connected with a high number of redundant loops around the beads l a normalized connectivity index for the biofilm can be computed as from the euler characteristic of the biofilm χbf herring et al 2015 as 6 c i χ b f χ p s here ci 1 indicates an impairment in biofilm connectivity due to the presence of flow channels of barium sulfate solution whereas ci 1 implies that the coexistence of biofilm and baso4 solution within the pore space even increases the number of redundant loops within the biofilm network the pore size index psi is based on the analysis of pore diameters by the maximum inscribed sphere method fig 2 b the psi is the ratio of the average pore diameter occupied by biofilm dbf divided by the average pore diameter of the entire pore space dps 7 p s i d b f d p s for this metric psi 1 indicates preference of biofilm to occupy pore constrictions and avoid larger pore bodies the solid distance index sdi is based on the analysis of euclidean distances from any location in the pore space to the closest solid phase voxel fig 2 c the sdi is constructed by normalizing the average distance within the region occupied by the biofilm ebf by the average distance of the entire pore space eps 8 s d i e b f e p s for this metric sdi 1 indicates preference of biofilm to attach to solid surfaces and avoid pore centers all quantitative analyses were carried out with avizo fire 8 3 and quantim 2 8 hydraulic conductivity transducer based hydraulic conductivities were calculated using darcy s law written for unidirectional axial flow bear 2013 9 v z κ z z μ p z ρ g where vz is the superficial velocity m s κzz the axial component of the permeability tensor m2 g the gravitational constant m s2 and p z the pressure gradient pa m eq 9 can be written in the following simplified form for the experimental system 10 q a k δ φ l here δφ is the net hydraulic head change across the column m l the total length of the column m and k the hydraulic conductivity m s that is related to permeability by k κ z z ρ g μ note that the hydraulic head is defined by hubbert s potential φ z z p z ρ g so that δφ simply represents the change in the hydraulic head between the inlet and the outlet of the columns δ φ φ o u t l e t φ i n l e t transducer based hydraulic conductivities for sample porous media are usually estimated by scanning a range of flow rates and producing a linear fit to the corresponding pressure drops here in order to reduce uncertainties introduced by transducer noise in the fit a wide range of flow rates 0 2500 ml h were applied this interval extends slightly beyond where eq 10 is valid into a transitional regime where pressure drop and flow rate are nonlinearly correlated bear 2013 to accommodate for this non linearity the darcy forchheimer equation with a quadratic in velocity correction was used instead in calculating the pre growth conductivities post biofilm growth hydraulic conductivities and uncertainties were calculated using eq 10 a potential cause of uncertainty in the measurement was biofilm growing in the inlet tubing despite significant efforts to prevent such growth this leading to a decrease of pressure drop δptubing when the inlet tubing was changed section 2 3 we therefore calculated a lower bound of the permeability using the values of pressure drop averaged over the last 10 h of each experiment and an upper bound by subtracting the corresponding δptubing from the average pressure drop image based hydraulic conductivities were calculated using the following kozeny carman relationship bear 2013 to compare it to transducer based estimates 11 k ρ g μ 1 β τ 2 1 s 2 φ 3 1 φ 2 in this expression the parameters are defined as previously in addition s is the specific surface area the interfacial surface area to volume ratio of the solid phase τ is the tortuosity of the medium and β is a constant for simple granular media the prefactor 1 βτ 2 is usually assumed to be equal to 1 5 bear 2013 we calculated the pre growth s directly from the 3d images using values obtained for the glass bead phase in the dry scans the post growth value of s was calculated by considering the biofilm and glass beads as the solid phase the sum of the interfacial areas of biofilm and glass beads that were exposed to the pore space was used for this purpose one way to calculate k using eq 11 is to compute the global values for φ and s as width weighted averages of all the sections however averaging tends to eliminate quite a lot of pore scale information especially when the biofilm phase is non uniformly distributed axially instead eq 11 was used to compute the hydraulic conductivity of each column section independently and in analogy with thermal or electrical resistance the equivalent effective hydraulic conductivity keq of a column was calculated as the harmonic mean of the constituent sections bear 2013 12 l k e q i 1 n l i k i where l is the total length of the evaluated region cm li is the length of section i cm n is the total number of sections and ki is the hydraulic conductivity of section i treating each imaged section as an independent layer li allows for a more realistic way of accounting for non uniform spatial distribution of biofilms and their effect on k 3 results 3 1 porous media characterization bulk characterization of the porous media prior to flow experiments provides a simple first check on the self consistency of imaging and the post processing workflow to compare with gravimetric results global image based porosity was calculated as a weighted average of the values for different column sections the bulk and image based initial column porosities were 0 4000 0 0075 and 0 4000 0 0089 respectively this excellent match is rather surprising and a strong argument for the adequacy and robustness of the developed image processing workflow the pre growth bulk and image based hydraulic conductivities k were 0 0181 0 cm s and 0 0207 0 0019 cm s respectively demonstrating very good agreement between the two methods these values are consistent with the general range of values reported for simple granular media bear 2013 the average surface area to volume ratio of the media s prior to growth was calculated to be 4 22 1 mm 3 2 oxygen utilization the measured effluent dissolved oxygen concentrations normalized by the influent concentration are reproduced in fig 3 influent do concentrations remained stable around the saturation limit for oxygen in the growth media for the duration of the experiment the estimated saturation limit was 8 05 0 29 mg l which was used to normalize the values in fig 3 oxygen distribution showed a marked sensitivity to flow rate the columns subjected to the lowest flow rate maintained almost negligible effluent oxygen concentrations the intermediate flow rate produced a similar curve but showed late time recovery for at least one of the columns in sharp contrast the highest flow rate columns produced a more dynamic response and maintained an average effluent concentration around half the magnitude of the influent concentration throughout the growth phase fluctuations are bound by 1 5 6 mg l 3 3 structural evolution of the pore space in order to characterize the nature of biofilm growth at different flow rates the axial distributions of a number of structural measures were studied spatial profiles for these measures along the flow direction are plotted in fig 4 the change in porosity in a column before and after growth is the most obvious metric to indicate the amount of bioclogging fig 4 a shows that the intermediate flowrate r e 1 0 resulted in the largest reduction in porosity followed by the highest r e 10 and lowest flowrates r e 0 1 respectively the profiles in fig 4 further show that the extent of porosity reduction varied along the axial direction z in all six test cases but less extensively so at the lowest flow rate the three dimensional visualizations shown in fig 4 are in clear agreement with these findings as a significantly lesser amount of biofilm is observed in the r e 0 1 columns and a denser and greater volume of biofilm is observed in the r e 1 0 columns it is also worth noting that we are able to distinguish the direction of flow upwards from the images and observe less rigorously attached features such as streamers drescher et al 2013 despite the concern mentioned in the introduction that the baso4 method may scour or detach such more weakly attached biofilm components when the contrast agent is added to the columns we further examined the biofilm solid and biofilm fluid interfacial areas per unit volume figs 4 b and c show that these measures are fairly similar for the r e 1 0 and r e 10 columns but slightly larger for r e 0 1 columns in order to assess biofilm formation in planes transverse to the flow direction we calculated the percentage of the total attachment surface area which is associated with the biofilm that is fixed on the sidewalls of each column section as opposed to being attached to the surface of glass beads within the same section this measure provides some indication of the lateral distribution of biofilm and the degree of penetration of biofilm into the glass bead matrix the results indicate that a significantly larger fraction of biofilm was attached to the column sidewalls at the highest flow rate 35 in the first 10 mm of the test section compared with the intermediate flow rate columns 27 in the first 10 mm of column elevation fig 6 a this difference was observed for total average biofilm volumes of 0 061 cm3 and 0 085 cm3 for the highest and intermediate flow rates respectively in the first 10 mm of the columns percent sidewall attachment for the lowest flow rate was relatively invariant in the axial direction in contrast the values for the intermediate and highest flow rates show a consistent decrease 10 toward the outlet the three structure indices highlight different aspects of changing biofilm configurations with changing flow rates there was a consistent trend towards higher connectivity indices ci with increasing re fig 6 b at r e 0 1 biofilm connectivity was lowest ci 1 because the volume fraction of biofilm was also lowest biomass being distributed in smaller isolated patches at intermediate flow rates r e 1 the biofilm had a much higher connectivity 1 ci 3 because the biofilm occupied the pore space almost completely lowest porosity in fig 4 b there was a gradual reduction in connectivity with inlet distance because the biofilm gets more compact that is since flow paths occupied by baso4 solution decreased with inlet distance there were less redundant loops in the biofilm around these flow paths this ci reduction with inlet distance is in line with decreasing porosity and decreasing reactive surface area fig 4 b and c the r e 10 columns exhibited the opposite trend of increasing connectivity starting at small isolated patches directly at the inlet ci 1 and ending with the highest connectivity of all columns in the upper part ci 3 because biofilm and flow channels of baso4 for complex intermingled structures also exhibited the highest reactive surface area fig 4 c the differences in the solid distance indices were less pronounced fig 6 c in general sdi 1 because biofilm growth was always initiated on solid surfaces so that biofilm had a tendency to be located close to solid interfaces the sdi was highest at intermediate flow rates because the biofilm occupied the largest part of the pore space so that the average distance of the biofilm ebf approached that of the pore space eps both the highest r e 10 and lowest r e 0 1 flow rate exhibited a gradual increase in sdi from the inlet towards the outlet in both cases biofilm clusters directly at the inlet were small and directly attached to grain surfaces with increasing inlet distance the volume fraction and surface area also increased and so did the growth into pore centers fig 4 b and c directly at the outlet there was a consistent increase in sdi among all columns that might be caused by accumulation of biomass the pore size index psi exhibited very similar behavior and therefore carried redundant information at least for the investigated glass bead medium fig 6 d there was a tendency of the biofilm to occupy smaller pore constrictions for all flow rates which was less pronounced at intermediate flow rates r e 1 because at these high volume fractions the average pore diameter covered by the biofilm dbf approached that of the entire pore space dps at the highest flow rate r e 10 there was again a gradual increase in psi with inlet distance because in the upper part of the column biofilm growth or accumulation extended more towards bigger pore bodies 3 4 bioclogging fig 7 shows the comparison between transducer based and image based hydraulic conductivities before and after bacterial growth the shaded areas in the figure represent the uncertainty bounds of the transducer based measurements due to potential growth in the inlet tubing computed as described in section 2 8 the transducer measured change in hydraulic conductivity varied between 1 to 2 orders of magnitude for all columns values that are comparable to the range reported in other investigations e g cunningham et al 1991 seifert and engesgaard 2007 thullner 2010 the largest mean decrease in k was observed for the r e 1 0 columns while the lowest flow rate columns r e 0 1 produced the smallest mean decrease in hydraulic conductivity fig 7 a shows that the kozeny carman relationship with 1 β τ 2 1 5 model a predicted the trend of reduction in k at the different flow rate but tended to systematically underestimate the magnitudes compared with transducer based measurements despite the prefactor being representative at the onset of the experiments a potential cause of the observed deviation between the two methods is an increase in the tortuosity of the media after bacterial growth we calculated the pre and post growth tortuosities directly from the images using the centroid path tortuosity module in avizo fire 8 3 this module computes the tortuosity of a path formed by the centroids on each plane along the z axis of a binary 3d image the biofilm and solid phases were combined in the image and then the image was binarized before the tortuosity was calculated for each stack of images an average of the two columns for each flow rate is presented in fig 7 b values are normalized by pre growth tortuosities computed using the same method the computed values were then used to correct the prefactor in the kozeny carman relationship model b fig 7 c shows that accounting for an increase in tortuosity significantly improved the comparison between transducer based and image based computations of post growth hydraulic conductivity for all flow rates the observed increase in tortuosity is slightly larger than the range of values obtained via simulations of 2d random media for φ 0 3 hyman et al 2012 matyka et al 2008 4 discussion a combination of results from different measurements supports the hypothesis that growth under r e 0 1 was significantly nutrient limited the almost complete depletion of dissolved oxygen at this flowrate fig 3 supports this picture although biofilm growing in the inlet tubing could have contributed to the consumption of inlet do and thereby have contributed to the recorded pressure drops limited growth at r e 0 1 is also reflected in the markedly lower reduction in porosity figs 4 d and 5 a and hydraulic conductivity when compared with higher flow rates the average biofilm volume at this flow rate is relatively uniform axially with low connectivity among dispersely distributed biofilm clusters that are preferentially attached to grain boundaries and pore constrictions sensitivity of biofilm structure to the availability of oxygen has been reported previously e g chang et al 2015 in contrast biofilm growth is improved at the intermediate and highest flow rates compare fig 5 a c we observed a gradient in average biofilm volume that increased toward the top of the columns at r e 1 0 and 10 a likely indication of shear induced sloughing of cells and subsequent accumulation near the outlet an 1 8 inch narrow opening that connects the porous section to external tubing interestingly other gradients in biofilm configurations showed opposite trends for r e 0 1 and r e 10 at intermediate flow rates the biofilm growth was more evenly distributed within the pore space in terms of occupied pore sizes and grain distances the reactive surface area and connectivity decreased slightly towards the outlet at the highest flow rate in turn there was a distinct shift towards growth in pore constrictions and along grain surfaces especially close to the inlet as well as a distinct increase in biofilm volume reactive surface and connectivity with inlet distance a more subtle form of heterogeneity is evident in the average percent sidewall attachment which decreased significantly beyond the first few sections for r e 1 0 and 10 and is invariant for r e 0 1 these trends suggest that especially under the higher shear flows biofilm growth undergoes a transition where regions near the sidewall are increasingly less occupied by biofilm toward the outlet this is because pores along the sidewalls are wider than pores between glass beads due to sub optimal packing and they therefore impose a lower resistance to flow the inhomogeneities in the spatial distribution of biofilms appear to be linked to regions where dramatic changes in flow take place the three examples observed here are i increased tendency of biofilms to form in the sidewall regions near the inlet this tendency could be a consequence of the generally higher concentrations of dissolved oxygen near the inlet and the flow field still being affected by the converging diverging nozzle like structure of the column inlet ii accumulation of biofilm near the outlet where flow is converging into a more constricted opening as discussed above and iii at the highest flow rate the tendency of biofilm to occupy pore constrictions and grain surfaces directly close the inlet an effect that disappears again at greater inlet distances this indicates that higher shear flows in the main flow paths near the inlet hinders the biofilm from occupying the center of bigger pore bodies in the vicinity of the inlet the fact that correcting for tortuosity significantly improves the comparison between transducer and image based post growth permeabilities supports the notion that biofilm growth can completely transform the structure of pore scale flow drescher et al 2013 the image based measurements for r e 0 1 and r e 10 can potentially be further improved by using other pore space attributes than the harmonic mean of porosities one way forward would be to compute critical path conductivities friedman and seaton 1996 by searching for the lowest conductivity along the path of lowest flow resistance which in our study would likely be situated close to the outlet were biofilm was accumulating although the volume fraction and associated porosity of this type of local growth is small it can impose a dominant impact on effective permeability similar results have been reported by bielefeldt et al 2002 where decreases in hydraulic conductivity of up to 3 orders of magnitude were observed despite a mere 3 8 percent decrease in porosity due to biofilm growth we should note that the transducer derived post growth permeabilities carry some uncertainty as well because observed fluctuations make it difficult to obtain an accurate value for pressure drop immediately before the termination of the experiment implementing an averaging window adjacent to the end of the experiment can stabilize the reading but introduces information from earlier times that might not necessarily represent the snapshot studied after imaging considering this and the simplicity of the kozeny carman model image based calculations demonstrate very good accuracy once actual tortuosities were used to predict the reduction in hydraulic conductivity the trend with re was very well matched model b in fig 7 based on the overall pattern of reduction in hydraulic conductivity at different flow rates we hypothesize that the bioclogging was influenced by a trade off between the availability of nutrients mainly dissolved oxygen and shear induced sloughing biofilms grown under an initial re of 1 0 resulted in a slightly larger average reduction in hydraulic conductivity and porosity both parameters decreased as flow rate increased in the current round of experiments our interpretation of this trend is that as flow rate increased a threshold was crossed at which point oxygen is no longer a limiting factor in biofilm growth and continuous growth was promoted until shear stress induced by the increasingly restricted flow initiates sloughing 5 limitations and future work balancing complete coverage of the pore space by the contrast agent while minimizing sloughing of biomass is the primary challenge during imaging the image processing workflow implemented here enabled a significant improvement in the accuracy of phase segmentation over previous efforts by accounting for the heterogeneities in the spatial distribution of the barium sulfate contrast agent development of more sophisticated contrast agents and tailored image processing algorithms could further improve the resolution of the method and reduce its intrusivity because we use microimaging as a model driven predictor the sensitivity of image based measurements depends on the complexity of the models used to deduce them we would expect that using models that carry more information on the morphology of the pore space significantly improve the accuracy of the method perhaps beyond what is possible using transducer measurements for instance one could directly take into account local variations in velocity and pressure and their effect on permeability in a direct numerical simulation of the post growth flow field e g peszynska et al 2015 regardless computations of permeability hydraulic conductivity using the kozeny carman model and the measured surface area to volume ratios porosity and tortuosity all purely image based measurements demonstrated very promising fidelity another step toward better understanding the morphology distribution and quantity of biomass growing within porous structures is to systematically study a broader range of flow rate and nutrient conditions with each condition replicated several times in this perspective the present results show great promise for future use of the method in understanding the reported heterogeneities in physical properties of porous media subject to microbial growth e g acoustic signatures complex conductivity etc and the post growth 3d structure of the pore space abdel aal et al 2010 atekwana and slater 2009 davis et al 2006 2009 2010 imaging of relatively large samples was achieved here enabling the study of bulk growth indicators in response to a prescribed flow rate as well as local variations in growth in the model systems new structural indices were introduced in this study that cover very different aspects of biofilm configurations these new indices should help facilitate systematic studies in the future the degree to which these results are generalizable inevitably depends on the choices made during the design of the experimental system regardless this work has helped to establish effective protocols so that future work can focus on more complex pore structures and exploring a broader range of replicated conditions 6 conclusions 3d visualization of biofilm structure was achieved for three distinct hydrodynamic conditions in opaque porous media microimaging was used to track the structural changes of the pore spaces due to biofilm growth which were cross referenced with bulk measurements of pressure drop and oxygen utilization distinct growth and local morphological patterns were observed for growth in columns subject to different flow rates excellent agreement was found between transducer derived hydraulic conductivities and image based estimates using a simple porosity permeability relationship prior to growth post growth permeabilities proved more challenging to predict due possibly to the development of heterogeneities in pore morphology yet very good agreement was observed between the trends of hydraulic conductivity reduction at different flow rates using the two methods and the results improved when the increased actual post growth tortuosity of the pore space was accounted for bioclogging was found to depend non trivially on flow rate likely a function of competing mass transfer dissolved oxygen delivery and shear stress the use of a barium sulfate suspension as a contrast agent was further fine tuned by implementing a novel image processing workflow that accounts for inhomogeneities in the attenuation of the fluid phase the results demonstrate the utility of microimaging using x ray ct in studies of transformation of porous media subject to biofilm growth acknowledgments this work was supported by the environmental remediation science program de fg02 09er64734 under the department of energy office of biological and environmental research ber grant er64734 1032845 0014978 this research used resources of the advanced photon source a u s department of energy doe office of science user facility operated for the doe office of science by argonne national laboratory under contract no de ac02 06ch11357 we acknowledge the support of geosoilenvirocars sector 13 which is supported by the national science foundation earth sciences ear 1128799 and the department of energy geosciences de fg02 94er14466 we would like to thank mark rivers at gsecars at the aps for assistance with ct imaging so and bw were supported in part by the national science foundation under grant ear 1141488 ss is grateful to the alexander von humboldt foundation for granting a feodor lynen scholarship the image processing library quantim is accessible free of charge at http www quantim ufz de appendix a a1 segmentation of biofilm data the challenge in segmenting biofilm images is that the baso4 particles are non uniformly distributed in the pore space that is not occupied by the biofilm fig a 1 a this results in broad range of intensities for the baso4 phase as a consequence it cannot be identified as a third mode in the corresponding histogram fig a 1 d in turn the difference between above edge and below edge intensity fig a 1 b is low for biofilm and beads since in both phases the electron adsorption does not change with a small change in beam energy yet the difference is high for the baso4 phase and varies with barium concentration this results in a single peak for beads and biofilm and a long tailing for baso4 in the corresponding histogram fig a 1 e the joint frequency distribution of the below edge and the difference intensities fig a 1 g is already sufficient to identify beads as an isolated cluster in the feature space but there is a gradual transition from biofilm to baso4 due to the variation in barium concentration this variation however can be assessed by the local image gradient fig a 1 b which is low in the homogeneous beads and biofilm and has a broad range of intensities in the baso4 filled pore space this leads to a joint peak at zero in the gradient histogram for biofilm and beads fig a 1 e and a long tail for baso4 and the transition voxels at phase boundaries the joint frequency distribution of the below edge and the gradient intensities fig a 1 h exhibits two clusters at low gradient intensities one for beads and one for biofilm which are connected by an arch of partial volume voxels at the boundaries between the two phases and extensive scattering for baso4 the two joint probabilities fig a 1 g and h are now used to estimate the class statistics in eq 3 with the following workflow 1 unimodal thresholding rosin 2001 schlüter et al 2014 is applied to separate the peak biofilm and beads from the tail baso4 and phase boundaries in the gradient histogram note that this threshold corresponds to the horizontal line in fig a 1 h a roi of voxels that belong to the peak class is created 2 the histogram of below edge intensities within this roi is evaluated by a minimum search schlüter et al 2014 tsai 1995 to detect the threshold between beads and biofilm this corresponds to a vertical line in fig a 1 h 3 a bead label is assigned to all voxels that fulfill both threshold requirements and whose joint frequency exceeds a user defined threshold e g 1 10 3 in fig a 1 h biofilm voxels are labeled in the same way 4 noise objects in the label image are removed with a size exclusion filter and the remaining labels are dilated with a spherical structure element of radius r 4 the dilated areas are considered as phase boundaries and the rest is assigned to baso4 5 steps 1 4 are repeated with the difference image instead of the gradient image as vertical axis in the feature space fig a 1 g 6 the final label image fig a 2 d is obtained by merging the label images from steps 4 and 5 together i e labels that coincide in both images are kept and voxels with different labels are set back to unassigned 7 the class statistics μ c λ and σ c λ 2 in eq 3 can then be estimated from label specific histograms in each input image note that the automated threshold detection methods in the presented workflow may fail when the volume fraction of biofilm or baso4 becomes too low in that case that values have to be adapted manually we are currently improving the workflow by substituting the iterative threshold detection for single source images with multi dimensional clustering techniques that allow for irregular threshold surfaces in the feature space during markov random field mrf segmentation each voxel is assigned a class label according to the penalty term for phase boundaries and the sum of likelihood terms of each class in eq 3 fig a 2 a c due to reformulation the smallest value for the likelihood term is considered optimal the likelihood term is multiplied with the user defined weighting factor for each image source which is set to a low value of α λ 0 1 λ 1 2 3 to increase the penalty on phase boundaries and thus invoke smooth boundaries the mrf segmentation results fig a 2 e are not optimal yet due to partial volume effects that is voxels along the bead boundaries are partially filled with biofilm which leads to a false assignment to baso4 postprocessing has to be applied to remove this unwanted effect to do so a cubic kernel with 73 voxels loops through the image detects boundaries as neighborhoods with more than one label and sets the central value to unassigned subsequently the labels are iteratively dilated back into unassigned areas by a simple majority rule i e the most representative label in a cubic 73 kernel is assigned to the central voxel until no unassigned voxel is left the result after postprocessing is depicted in fig a 2 f supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2018 03 018 appendix b supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
800,we explore how x ray computed microtomography can be used to generate highly resolved 3d biofilm datasets on length scales that span multiple pore bodies the data is integrated into a study of the effects of flow rate on three dimensional growth of biofilm in porous media three flow rates were investigated in model packed bed columns biofilm growth was monitored during an 11 day growth period using a combination of differential pressure and effluent dissolved oxygen measurements at the end of the growth period all columns were scanned using x ray computed microtomography and a barium sulfate based contrast agent the resulting images were prepared for quantitative analysis using a novel image processing workflow that was tailored to this specific system the reduction in permeability due to biofilm growth was studied using both transducer based pressure drop measurements and image based calculations using the kozeny carman model in addition a set of structural measures related to the spatial distribution of biofilms were computed and analyzed for the different flow rates we generally observed 1 to 2 orders of magnitude decrease in permeability as a result of bioclogging for all columns i e across flow rates the greatest average permeability and porosity reduction was observed for the intermediate flow rate 4 5 ml h a combination of results from different measurements all suggest that biofilm growth was oxygen limited at the lowest flow rate and affected by shear stresses at the highest flow rate we hypothesize that the interplay between these two factors drives the spatial distribution and quantity of biofilm growth in the class of porous media studied here our approach opens the way to more systematic studies of the structure function relationships involved in biofilm growth in porous media and the impact that such growth may have on physical properties such as hydraulic conductivity keywords biofilms granular porous media x ray computed microtomography image processing statistical learning fluid phase topology nomenclature φ porosity ρ fluid density vs vz stream wise superficial darcy velocity d pore radius characteristic length scale μ fluid viscosity re reynolds number q volumetric flow rate a cross sectional area κzz stream wise component of the permeability tensor p hydrodynamic pressure g acceleration due to gravity k column hydraulic conductivity φ hubbert s potential hydraulic head l column length δp net pressure difference across column τ tortuosity s interfacial area to volume ratio β constant in the kozeny carman model i total number of evaluated images n total number of voxels evaluated at coordinate x π set of all pairs of neighboring voxels c x class label of voxel at point x μ c λ class mean in image λ σ 2 class variance in image λ g i x gray value of voxel x in image i χ euler characteristic n number of isolated objects in a material of interest l number of redundant connections within all material clusters o number of cavities in a material of interest dα average pore diameter in phase α eα average distance within phase α ci the connectivity index psi the pore size index sdi the solid distance index 1 introduction the interaction of hydrodynamics and biofilm growth in media with tortuous geometries is of great scientific interest because of its prevalence in many natural and engineered systems drescher et al 2013 as examples biofilm growth in porous media has been both directly observed and indirectly hypothesized with substantial supporting evidence in a wide variety of natural and engineered systems these include examples such as anaerobic reactors e g young and dahab 1983 microbially enhanced oil recovery e g armstrong and wildenschild 2012 sen 2008 micromodel experiments e g kim and fogler 2000 stewart and fogler 2001 laboratory porous media experiments e g vogt et al 2013 and slow sand filter beds e g li et al 2013 although there are ongoing discussions regarding the ubiquity of biofilms baveye and darnault 2017 coyte et al 2017 these studies offer significant and often direct evidence that biofilm formation in porous media is an important component for many processes of relevance and interest in natural and synthetic porous media biofilm growth at the pore scale affects various transport processes by altering the structure of interfaces connectivity of the pore space and bulk geometric properties of the medium baveye et al 1998 cunningham et al 1991 drescher et al 2013 rittmann 1993 in turn cellular growth and mesoscale structural evolution of biofilms are highly interconnected with various aspects of transport including shear and mass transfer non destructive imaging of biofilms is essential to understanding the physics of these processes and their broader impacts on design control and prediction in disciplines that are concerned with natural porous media e g hydrology petroleum engineering the ability to visualize biofilm growth under flow on the scale of millimeters to meters has been of great interest e g thullner 2010 yarwood et al 2002 visualization is gaining even more significance with the increasing complexity and fidelity of the mathematical and computational approaches to modeling biofilm growth in porous media e g von der schulenburg et al 2009 the challenges associated with non intrusive visualization of 3d systems often forces direct comparison between models and experiments to rely on bulk aggregate laboratory or field measurements i e evaluations on scales where pore scale structural information detrimental to transport is lost to the averaging inherent to measurements thullner 2010 magnetic resonance microscopy mrm and nuclear magnetic resonance imaging nmr have been successfully applied to elucidate the global structure of biofilms in porous media and pore fluid velocities in media altered by microbial growth manz et al 2003 seymour et al 2004 2007 albeit with some resolution limitations confocal laser scanning microscopy clsm and more recently optical coherence tomography oct have been successfully applied to the visualization of the 3d structure of biofilms on smaller scales with higher resolutions davit et al 2013 dreszer et al 2014 neu and lawrence 2015 wagner et al 2010 xi et al 2006 both methods enable temporal studies of growth in flow environments and provide highly resolved reproductions of the internal structure of the biofilm matrix a popular approach to direct visualization of biofilm structure in porous media at the pore scale has been to adopt these techniques to study growth in optically transparent leis et al 2005 2d and pseudo 3d micro models e g beyenal et al 2004 kim and fogler 2000 rodríguez and bishop 2007 stoodley et al 1999 a limitation in extending this methodology to study biomass formation in 3d porous media is that experimental systems must be optically transparent small enough to fit onto the microscope stage and in the case of clsm thin enough to fit within the focal range of the device conversely 3d porous systems are opaque and deep whether or not the conclusions drawn for 2d systems can be extended to 3d is an unanswered question topologically the two are not equivalent e g diffusions in 2 and 3 dimensions are fundamentally different so one would not expect 2 dimensional experiments to capture the range of physical behaviors thus the literature s prevailing answer to this question seems to be negative e g see the discussion by baveye 2010 thullner 2010 x ray computed microtomography cmt is emerging as an alternative that enables visualization of biofilms in 3d in opaque media davit et al 2011 iltis et al 2011 wildenschild and sheppard 2013 on the pore scale though still in its infancy the method was originally developed and explored using both polychromatic davit et al 2011 and monochromatic synchrotron based systems iltis 2013 iltis et al 2011 users can expect voxel resolutions on the order of 1 2 microns to be easily achieved the technique relies on the use of contrast agents to facilitate the adsorption based detection of different phases within an opaque sample using x rays central to the method is creating a physical mechanism that through the use of advanced image processing techniques allow for differentiation between the fluid and biofilm phases the natural attenuation photon cross section of which are almost identical use of different contrast agents added to the aqueous phase such as silver coated hollow microspheres iltis et al 2011 barium sulfate suspensions davit et al 2011 iltis 2013 and 1 chloronaphtalene ivankovic et al 2017 du roscoat et al 2014 have shown promise similarly adding feso4 as a contrast agent to the biofilm phase and using the free space propagation of x rays to bring out additional refractive effects carrel et al 2017 were also able to image biofilms in opaque porous media the latter study compared the feso4 to the baso4 method and found differences in the amount of biofilm imaged with a significantly larger amount of biofilm identified using the feso4 method the authors pointed out three possible reasons for the discrepancy i partial volume effects eliminated from consideration ii uncertainty related to the segmentation caused by the significant heterogeneity of the biofilm phase and poor contrast of said phase and iii interaction between the baso4 and the biofilm causing suspended biomass and loosely attached components of the biofilm to be washed out of the columns the potential for detachment of biofilm during addition of a denser and more viscous aqueous phase contrast agent has been discussed by davit et al 2011 and du roscoat et al 2014 in a thorough study of the problem ivankovic et al 2017 found that this effect can be eliminated by using smaller beads in their case less than 2 mm and by making measurements after longer periods of biofilm growth 7 days such that a more compact and tightly attached biofilm was formed this allowed for reliable studies on biofilms that presented similar and reproducible spatial structure and allowed for quantitative evaluation of a number of different environmental variables in their study growth periods of less than 3 days and larger pore sizes resulted in less resilient biofilms exhibiting streamers and other weakly attached components that may be subject to detachment shear by a more viscous contrast agent such as baso4 or 1 chloronaphtalene for the 1 chloronaphtalene cn an additional challenge was caused by the oily nature of the contrast agent which caused pendular rings of cn to be left behind at bead contacts the exact growth period and pore size that will produce repeatable experiments will vary somewhat with organism nutrient supply flow rate all factors contributing to the production of more or less dense biofilms and the viscosity of the injected contrast agent if relevant the past studies using aqueous phase contrast agents serve as promising proof of the concept as long as the risk of viscous interaction with the biofilm is considered in the design of the experiments while there is less risk of detachment using a contrast agent in the biofilm itself carrel et al 2017 the resulting weak contrast between the various phases makes reliable and objective quantitative evaluation difficult in this study we present a systematic study on the correspondence between physical quantities derived from ct data and physical measurements of biofilm growth such a comparison has yet to be reported in the literature our data consists of duplicate columns grown for 11 days to ensure a dense and resilient biofilm the resulting image histograms exhibit distinct separation of the intensity peaks indicative of effective phase separation and we use advanced image processing methods to allow for objective measurements of a number of biofilm features as a function of reynolds number re when possible we cross validate the results obtained via microimage analysis with those obtained via direct bulk measurements numerous studies conducted on bioclogging in porous media under various conditions have reported significant reductions in hydraulic conductivity often up to 2 3 orders of magnitude or more bielefeldt et al 2002 cunningham et al 1991 seifert and engesgaard 2007 thullner 2010 vandevivere and baveye 1992 due mainly to limitations in measuring or imaging the spatial distribution of biomass however only a few reports have attempted to associate changes in pore morphology with changes in hydraulic conductivity in 3d mostly indirectly or via destructive sampling a number of authors have observed that a majority of the biomass and associated clogging occurred within the first several centimeters of the experimental apparatus e g seifert and engesgaard 2007 others have argued that bioclogging should be attributed primarily to blockage of pore throats by biomass as opposed to uniform continuous films on solid surfaces e g vandevivere et al 1995 2 methods by building on the work of davit et al 2011 we study flow rates that span three orders of magnitude corresponding to initial pore scale re of 0 1 1 0 and 10 covering creeping to mildly laminar flows we are particularly interested in characterizing the global biofilm structure grown under the stipulated flow conditions and tracing these variations to bulk measurements the work introduces a simple analysis of biofilm growth within opaque porous media based on 3d structural measures along with correlation to i bulk pressure drop measurements and ii dissolved oxygen consumption to evaluate potential nutrient limitations imparted by the applied flow rates our analysis relies on a novel image processing workflow that addresses some of the limitations associated with inhomogeneous distribution of the contrast agent in the pore space 2 1 model porous medium packed bead column reactors measuring 6 3 mm in diameter 42 mm in length with a 25 mm clear window were constructed of polycarbonate tubing the porous medium consisted of soda lime silica glass beads with particle diameter within the range 1 4 1 7 mm and specific gravity of 2 5 a total of 6 growth reactors were used in this study so that there were duplicate columns examined at each flow rate initial column porosities were measured gravimetrically prior to the experiments and initial flow testing was conducted to measure the hydraulic conductivity of the models as described below 2 2 microbial species the bacterium used in this study is shewanella oneidensis mr 1 a metal reducing strain originally isolated from sediment from lake oneida in new york s oneidensis mr 1 is a gram negative highly piliated polarly flagellated facultative anaerobe capable of dissimilatory metal reduction and biofilm formation majors et al 2005 venkateswaran et al 1999 the bacterium is motile the presence of pili are critical to initial adhesion and the flagella have been identified as being critical for development of effective biofilm structure thormann et al 2004 the bacterium has also been shown to be motile in response to low oxygen tensions thormann et al 2005 this strain has been used successfully in previous biofilm imaging studies conducted by our group iltis et al 2011 2 3 growth media and conditions inocula were grown from frozen stock for two growth cycles initially frozen stock was thawed and 0 5 ml stock culture was added to 30 ml sterile 100 30 g l tryptic soy broth tsb batch cultures were grown on an incubated shaker table at 250 rpm and 30 c for 20 h at which point the second growth cycle was started by adding 1 ml of batch culture from the first growth cycle to 30 ml fresh sterile 100 tsb growth media batch cultures were then incubated for another 20 h cycle at the conclusion of the second growth cycle batch cultures were centrifuged at 6000 rpm for 10 min the supernatant was poured off and the cell pellets were resuspended in 5 ml 100 tsb 30 g l growth media for column inoculation all column growth reactors and tubing were sterilized prior to inoculation by flushing a 90 ethanol solution through the test apparatus for 30 min at which point a growth media flush commenced to ensure that all ethanol was removed from the system prior to inoculation the sterile 10 tsb saturated columns were then injected with 1 ml of the concentrated cell inoculum a 24 h no flow period was allowed to promote biofilm nucleation after which flow of sterile oxygenated growth media was started at the prescribed flow rates inocula for the initial growth period were prepared in 100 30 g l tryptic soy broth tsb solutions the medium was diluted down to 10 3 g l for the flow experiments all growth media were sterilized prior to injection and continuously aerated using 0 22 µm filtered ambient air a consistently oxygen saturated injection with an average influent o 2 concentration of 8 05 0 29 mg l was maintained in the flow experiments three flow rates in the creeping and mildly laminar regimes were targeted for investigation the corresponding initial re were 0 1 1 and 10 where the re is evaluated for a packed bed using gunjal et al 2005 1 r e 1 1 φ ρ v s d μ here ρ g ml is the density of the fluid phase d cm is a characteristic pore length for the porous medium taken to be the average grain size μ g cm h is the dynamic viscosity of the fluid phase and φ is the bulk porosity and vs cm h is the superficial darcy velocity defined as 2 v s q a where q ml h is the fluid flow rate a cm2 is the cross sectional area without the porous medium note that φ changes during the course of the experiments so the above values represent reynolds numbers at the onset of growth for the model systems used in this study these values correspond to flow rates of 4 5 45 and 450 ml h these values are referred to as the lowest intermediate and highest flow rates throughout the text continuous flow was provided to each column growth reactor using continuous cycle syringe pumps check valves were used to ensure that flow through the reactor columns was always unidirectional a schematic of the experimental setup is provided in fig 1 a growth media reservoirs were replaced at approximately 36 h intervals and all influent lines were replaced every two days to minimize biofilm growth upstream of the experimental columns biofilm growth was allowed to continue under constant flow conditions for 11 days at which point the columns were disconnected and prepared for imaging 2 4 differential pressure measurement differential pressure transducers honeywell sensing and control 24pc series columbus oh usa were affixed to each experimental column at the column entrance and exit in order to allow for measurement of differential pressure across each column length continuous differential pressure measurements were collected by an automated data acquisition system personal daq 50 measurement computing corp norton ma 2 5 dissolved oxygen measurement periodic measurements of dissolved oxygen do were performed on the influent and effluent sides of each column for the duration of the biofilm growth phase of the experiment effluent do was measured using flow through oxygen microprobes model 16 730 microelectrodes inc beadford nh usa influent do measurements were made using a separate probe symphony vwr international on samples extracted from the sterile media reservoirs the equipment for measuring influent and effluent dissolved oxygen were kept separate for the duration of the experiment in order to prevent contamination dissolved oxygen probes were cleaned using a tergazyme alconox inc white plains ny usa protein removal solution after every set of measurements 2 6 computed x ray microtomography imaging x ray cmt imaging was conducted at the advanced photon source aps facility at argonne national laboratory using beamline 13bmd at gsecars geosoilenviro consortium for advanced radiation sources immediately prior to imaging sample columns were disconnected from influent and effluent lines and injected with the contrast agent solution the contrast agent consisted of a medical grade barium sulfate baso4 suspension micropaque guerbet mixed with sterile growth media the 1 0 g ml stock suspension was diluted down to a usable concentration of 0 33 g ml the contrast agent was injected into the sample columns using a syringe pump at a rate of 1 2 ml h for the r e 0 1 and 1 0 columns and 5 ml h for the r e 10 columns a total of 2 ml of contrast agent solution was injected into each column the average pore volume prior to column inoculation is approximately 0 5 ml so approximately 4 pore volumes of contrast agent was added to each column the diluted solution 0 33 g ml was selected to balance the absorption of x ray through the columns with the saturation limit of the x ray detector ccd camera interested readers are referred to iltis 2013 for a thorough discussion of barium sulfate concentration ranges for synchrotron based x ray cmt of biofilms where it was reported that the useful range of barium concentration for columns 5 7 mm in diameter is 33 0 33 g ml to 50 0 5 g ml barium sulfate the k shell absorption edge for barium is 37 4 kev so each column section was scanned at two energies one above 37 54 kev and one below 37 34 kev this edge the entire length of each column was scanned by moving the sample stage vertically and generating a series of overlapping scan sections volumetric reconstruction of each section was obtained from a series of two dimensional scans that are obtained via a 180 rotation of the sample stage over 720 increments at each height the choice of 720 angles is based on experience with the instrumentation at this particular beam line the theoretical number of projection angles required is the number of pixels the area of interest covers as the sample rotates 360 multiplied by 1 5 or 540 angles by oversampling with 720 angles blur is reduced and the resulting images are of a higher quality this allows more accurate segmentation and subsequent quantitative analyses 2 7 image processing and quantitative analysis the reconstructed datasets have dimensions of 695 695 470 voxels a voxel resolution of 10 5 µm and are stored with 16 bit precision as a first preprocessing step a cylindrical region of interest roi inside the core was extracted a total variation filter was applied for denoising and an unsharp mask filter used for edge enhancement schlüter et al 2014 image segmentation of the grayscale data focused on isolating three phases the biofilm the baso4 suspension representing the aqueous phase and the solid phase glass beads for these data proper segmentation required the development of a novel segmentation algorithm that incorporated complementary information from various image sources direct isolation of the baso4 was facilitated using the increased absorption in the above ba edge vs below ba edge data sets which is reflected by high intensity in a difference image however the baso4 suspension had small scale heterogeneity due to locally varying barium concentrations likely a side effect of using a barium concentration on the low end of the applicable concentration range of 33 50 segmentation of the baso4 suspension even in low concentration regions can therefore be improved further by directly evaluating the degree of small scale heterogeneity in a gradient image the beads and the biofilm exhibited homogeneous and independently distinguishable x ray absorption at both the above and below edge scanning energies since one image suffices isolation of the beads and biofilm was accomplished using the below edge image data sets a markov random field mrf segmentation algorithm kulkarni et al 2012 schlüter et al 2014 was extended to allow for multiple class statistics from various image sources at the core of this method a combinatorial optimization problem is solved in order to find a labeling c that satisfies 3 c argmin i 1 i j 1 n α i ln 2 π σ c i 2 g i x j μ c i 2 2 σ c i 2 class statistics x j y j π γ c x j c y j class boundaries with 4 γ c x j c y j 1 c x j c y j 1 c x j c y j here i is the total number of evaluated images below edge image gradient image and difference image n is the total number of voxels evaluated with coordinate x j π is the population of all pairs of neighboring voxels at coordinates x and y c x j is the class label at x j beads biofilm or baso4 suspension μ c i and σ c i 2 are class mean and variance in a specific image i gi x j is the gray value at the coordinate x j in image i and αi is a user defined image specific weighting factor that determines the contribution of each likelihood term for a given class relative to the penalty term for class boundaries in other words a class label at a certain location is very likely if i the local gray values in all images is close to the specific class mean for these images and if ii the majority of neighbors already belong to the same class class updating was achieved in a deterministic order denoted as iterative conditional modes icm i e starting at one corner of the image the label for each voxel was replaced by the class that minimizes the contribution to eq 3 the algorithm was stopped after three loops values for μ c i and σ c i 2 have to be determined prior to segmentation which was done by evaluating the joint probabilities as explained in the appendix classification errors in the mrf segmentation results due to partial volume effects were removed via post processing which is also explained in the appendix the entire workflow from preprocessing to image segmentation and post processing is based on the quantim image processing library schlüter et al 2014 vogel et al 2010 the vertical series of eight segmented volumes is subsequently merged into one column via landmark registration in avizo fire 8 3 that is two consecutive volumes overlapping by 25 and pairs of identical coordinates within these overlap regions have to be identified by tracking easily identifiable features fig 1 e depicts the merged column for a sample grown under high flow rate conditions 450 ml h r e 10 after segmentation the columns are analyzed for each vertical section individually in order to detect changes with respect to inlet distance the investigated properties comprise standard properties like porosity biofilm volume biofilm surface area biofilm thickness and volume percentage attached to sidewalls in addition the spatial patterns of growth and attachment are characterized with three normalized indexes that cover different aspects of biofilm configurations as demonstrated for a small subset in fig 2 the connectivity index ci characterizes whether the biofilm is well or poorly connected by means of the euler characteristic χ this topological measure is defined as vogel et al 2010 5 χ n l o where n is the number of isolated objects of the material of interest l is the number of redundant connections within all material clusters and o is the number of cavities e g isolated background clusters completely enclosed by the material the euler characteristic of the entire pore space in a bead pack χps is usually negative because it is well connected with a high number of redundant loops around the beads l a normalized connectivity index for the biofilm can be computed as from the euler characteristic of the biofilm χbf herring et al 2015 as 6 c i χ b f χ p s here ci 1 indicates an impairment in biofilm connectivity due to the presence of flow channels of barium sulfate solution whereas ci 1 implies that the coexistence of biofilm and baso4 solution within the pore space even increases the number of redundant loops within the biofilm network the pore size index psi is based on the analysis of pore diameters by the maximum inscribed sphere method fig 2 b the psi is the ratio of the average pore diameter occupied by biofilm dbf divided by the average pore diameter of the entire pore space dps 7 p s i d b f d p s for this metric psi 1 indicates preference of biofilm to occupy pore constrictions and avoid larger pore bodies the solid distance index sdi is based on the analysis of euclidean distances from any location in the pore space to the closest solid phase voxel fig 2 c the sdi is constructed by normalizing the average distance within the region occupied by the biofilm ebf by the average distance of the entire pore space eps 8 s d i e b f e p s for this metric sdi 1 indicates preference of biofilm to attach to solid surfaces and avoid pore centers all quantitative analyses were carried out with avizo fire 8 3 and quantim 2 8 hydraulic conductivity transducer based hydraulic conductivities were calculated using darcy s law written for unidirectional axial flow bear 2013 9 v z κ z z μ p z ρ g where vz is the superficial velocity m s κzz the axial component of the permeability tensor m2 g the gravitational constant m s2 and p z the pressure gradient pa m eq 9 can be written in the following simplified form for the experimental system 10 q a k δ φ l here δφ is the net hydraulic head change across the column m l the total length of the column m and k the hydraulic conductivity m s that is related to permeability by k κ z z ρ g μ note that the hydraulic head is defined by hubbert s potential φ z z p z ρ g so that δφ simply represents the change in the hydraulic head between the inlet and the outlet of the columns δ φ φ o u t l e t φ i n l e t transducer based hydraulic conductivities for sample porous media are usually estimated by scanning a range of flow rates and producing a linear fit to the corresponding pressure drops here in order to reduce uncertainties introduced by transducer noise in the fit a wide range of flow rates 0 2500 ml h were applied this interval extends slightly beyond where eq 10 is valid into a transitional regime where pressure drop and flow rate are nonlinearly correlated bear 2013 to accommodate for this non linearity the darcy forchheimer equation with a quadratic in velocity correction was used instead in calculating the pre growth conductivities post biofilm growth hydraulic conductivities and uncertainties were calculated using eq 10 a potential cause of uncertainty in the measurement was biofilm growing in the inlet tubing despite significant efforts to prevent such growth this leading to a decrease of pressure drop δptubing when the inlet tubing was changed section 2 3 we therefore calculated a lower bound of the permeability using the values of pressure drop averaged over the last 10 h of each experiment and an upper bound by subtracting the corresponding δptubing from the average pressure drop image based hydraulic conductivities were calculated using the following kozeny carman relationship bear 2013 to compare it to transducer based estimates 11 k ρ g μ 1 β τ 2 1 s 2 φ 3 1 φ 2 in this expression the parameters are defined as previously in addition s is the specific surface area the interfacial surface area to volume ratio of the solid phase τ is the tortuosity of the medium and β is a constant for simple granular media the prefactor 1 βτ 2 is usually assumed to be equal to 1 5 bear 2013 we calculated the pre growth s directly from the 3d images using values obtained for the glass bead phase in the dry scans the post growth value of s was calculated by considering the biofilm and glass beads as the solid phase the sum of the interfacial areas of biofilm and glass beads that were exposed to the pore space was used for this purpose one way to calculate k using eq 11 is to compute the global values for φ and s as width weighted averages of all the sections however averaging tends to eliminate quite a lot of pore scale information especially when the biofilm phase is non uniformly distributed axially instead eq 11 was used to compute the hydraulic conductivity of each column section independently and in analogy with thermal or electrical resistance the equivalent effective hydraulic conductivity keq of a column was calculated as the harmonic mean of the constituent sections bear 2013 12 l k e q i 1 n l i k i where l is the total length of the evaluated region cm li is the length of section i cm n is the total number of sections and ki is the hydraulic conductivity of section i treating each imaged section as an independent layer li allows for a more realistic way of accounting for non uniform spatial distribution of biofilms and their effect on k 3 results 3 1 porous media characterization bulk characterization of the porous media prior to flow experiments provides a simple first check on the self consistency of imaging and the post processing workflow to compare with gravimetric results global image based porosity was calculated as a weighted average of the values for different column sections the bulk and image based initial column porosities were 0 4000 0 0075 and 0 4000 0 0089 respectively this excellent match is rather surprising and a strong argument for the adequacy and robustness of the developed image processing workflow the pre growth bulk and image based hydraulic conductivities k were 0 0181 0 cm s and 0 0207 0 0019 cm s respectively demonstrating very good agreement between the two methods these values are consistent with the general range of values reported for simple granular media bear 2013 the average surface area to volume ratio of the media s prior to growth was calculated to be 4 22 1 mm 3 2 oxygen utilization the measured effluent dissolved oxygen concentrations normalized by the influent concentration are reproduced in fig 3 influent do concentrations remained stable around the saturation limit for oxygen in the growth media for the duration of the experiment the estimated saturation limit was 8 05 0 29 mg l which was used to normalize the values in fig 3 oxygen distribution showed a marked sensitivity to flow rate the columns subjected to the lowest flow rate maintained almost negligible effluent oxygen concentrations the intermediate flow rate produced a similar curve but showed late time recovery for at least one of the columns in sharp contrast the highest flow rate columns produced a more dynamic response and maintained an average effluent concentration around half the magnitude of the influent concentration throughout the growth phase fluctuations are bound by 1 5 6 mg l 3 3 structural evolution of the pore space in order to characterize the nature of biofilm growth at different flow rates the axial distributions of a number of structural measures were studied spatial profiles for these measures along the flow direction are plotted in fig 4 the change in porosity in a column before and after growth is the most obvious metric to indicate the amount of bioclogging fig 4 a shows that the intermediate flowrate r e 1 0 resulted in the largest reduction in porosity followed by the highest r e 10 and lowest flowrates r e 0 1 respectively the profiles in fig 4 further show that the extent of porosity reduction varied along the axial direction z in all six test cases but less extensively so at the lowest flow rate the three dimensional visualizations shown in fig 4 are in clear agreement with these findings as a significantly lesser amount of biofilm is observed in the r e 0 1 columns and a denser and greater volume of biofilm is observed in the r e 1 0 columns it is also worth noting that we are able to distinguish the direction of flow upwards from the images and observe less rigorously attached features such as streamers drescher et al 2013 despite the concern mentioned in the introduction that the baso4 method may scour or detach such more weakly attached biofilm components when the contrast agent is added to the columns we further examined the biofilm solid and biofilm fluid interfacial areas per unit volume figs 4 b and c show that these measures are fairly similar for the r e 1 0 and r e 10 columns but slightly larger for r e 0 1 columns in order to assess biofilm formation in planes transverse to the flow direction we calculated the percentage of the total attachment surface area which is associated with the biofilm that is fixed on the sidewalls of each column section as opposed to being attached to the surface of glass beads within the same section this measure provides some indication of the lateral distribution of biofilm and the degree of penetration of biofilm into the glass bead matrix the results indicate that a significantly larger fraction of biofilm was attached to the column sidewalls at the highest flow rate 35 in the first 10 mm of the test section compared with the intermediate flow rate columns 27 in the first 10 mm of column elevation fig 6 a this difference was observed for total average biofilm volumes of 0 061 cm3 and 0 085 cm3 for the highest and intermediate flow rates respectively in the first 10 mm of the columns percent sidewall attachment for the lowest flow rate was relatively invariant in the axial direction in contrast the values for the intermediate and highest flow rates show a consistent decrease 10 toward the outlet the three structure indices highlight different aspects of changing biofilm configurations with changing flow rates there was a consistent trend towards higher connectivity indices ci with increasing re fig 6 b at r e 0 1 biofilm connectivity was lowest ci 1 because the volume fraction of biofilm was also lowest biomass being distributed in smaller isolated patches at intermediate flow rates r e 1 the biofilm had a much higher connectivity 1 ci 3 because the biofilm occupied the pore space almost completely lowest porosity in fig 4 b there was a gradual reduction in connectivity with inlet distance because the biofilm gets more compact that is since flow paths occupied by baso4 solution decreased with inlet distance there were less redundant loops in the biofilm around these flow paths this ci reduction with inlet distance is in line with decreasing porosity and decreasing reactive surface area fig 4 b and c the r e 10 columns exhibited the opposite trend of increasing connectivity starting at small isolated patches directly at the inlet ci 1 and ending with the highest connectivity of all columns in the upper part ci 3 because biofilm and flow channels of baso4 for complex intermingled structures also exhibited the highest reactive surface area fig 4 c the differences in the solid distance indices were less pronounced fig 6 c in general sdi 1 because biofilm growth was always initiated on solid surfaces so that biofilm had a tendency to be located close to solid interfaces the sdi was highest at intermediate flow rates because the biofilm occupied the largest part of the pore space so that the average distance of the biofilm ebf approached that of the pore space eps both the highest r e 10 and lowest r e 0 1 flow rate exhibited a gradual increase in sdi from the inlet towards the outlet in both cases biofilm clusters directly at the inlet were small and directly attached to grain surfaces with increasing inlet distance the volume fraction and surface area also increased and so did the growth into pore centers fig 4 b and c directly at the outlet there was a consistent increase in sdi among all columns that might be caused by accumulation of biomass the pore size index psi exhibited very similar behavior and therefore carried redundant information at least for the investigated glass bead medium fig 6 d there was a tendency of the biofilm to occupy smaller pore constrictions for all flow rates which was less pronounced at intermediate flow rates r e 1 because at these high volume fractions the average pore diameter covered by the biofilm dbf approached that of the entire pore space dps at the highest flow rate r e 10 there was again a gradual increase in psi with inlet distance because in the upper part of the column biofilm growth or accumulation extended more towards bigger pore bodies 3 4 bioclogging fig 7 shows the comparison between transducer based and image based hydraulic conductivities before and after bacterial growth the shaded areas in the figure represent the uncertainty bounds of the transducer based measurements due to potential growth in the inlet tubing computed as described in section 2 8 the transducer measured change in hydraulic conductivity varied between 1 to 2 orders of magnitude for all columns values that are comparable to the range reported in other investigations e g cunningham et al 1991 seifert and engesgaard 2007 thullner 2010 the largest mean decrease in k was observed for the r e 1 0 columns while the lowest flow rate columns r e 0 1 produced the smallest mean decrease in hydraulic conductivity fig 7 a shows that the kozeny carman relationship with 1 β τ 2 1 5 model a predicted the trend of reduction in k at the different flow rate but tended to systematically underestimate the magnitudes compared with transducer based measurements despite the prefactor being representative at the onset of the experiments a potential cause of the observed deviation between the two methods is an increase in the tortuosity of the media after bacterial growth we calculated the pre and post growth tortuosities directly from the images using the centroid path tortuosity module in avizo fire 8 3 this module computes the tortuosity of a path formed by the centroids on each plane along the z axis of a binary 3d image the biofilm and solid phases were combined in the image and then the image was binarized before the tortuosity was calculated for each stack of images an average of the two columns for each flow rate is presented in fig 7 b values are normalized by pre growth tortuosities computed using the same method the computed values were then used to correct the prefactor in the kozeny carman relationship model b fig 7 c shows that accounting for an increase in tortuosity significantly improved the comparison between transducer based and image based computations of post growth hydraulic conductivity for all flow rates the observed increase in tortuosity is slightly larger than the range of values obtained via simulations of 2d random media for φ 0 3 hyman et al 2012 matyka et al 2008 4 discussion a combination of results from different measurements supports the hypothesis that growth under r e 0 1 was significantly nutrient limited the almost complete depletion of dissolved oxygen at this flowrate fig 3 supports this picture although biofilm growing in the inlet tubing could have contributed to the consumption of inlet do and thereby have contributed to the recorded pressure drops limited growth at r e 0 1 is also reflected in the markedly lower reduction in porosity figs 4 d and 5 a and hydraulic conductivity when compared with higher flow rates the average biofilm volume at this flow rate is relatively uniform axially with low connectivity among dispersely distributed biofilm clusters that are preferentially attached to grain boundaries and pore constrictions sensitivity of biofilm structure to the availability of oxygen has been reported previously e g chang et al 2015 in contrast biofilm growth is improved at the intermediate and highest flow rates compare fig 5 a c we observed a gradient in average biofilm volume that increased toward the top of the columns at r e 1 0 and 10 a likely indication of shear induced sloughing of cells and subsequent accumulation near the outlet an 1 8 inch narrow opening that connects the porous section to external tubing interestingly other gradients in biofilm configurations showed opposite trends for r e 0 1 and r e 10 at intermediate flow rates the biofilm growth was more evenly distributed within the pore space in terms of occupied pore sizes and grain distances the reactive surface area and connectivity decreased slightly towards the outlet at the highest flow rate in turn there was a distinct shift towards growth in pore constrictions and along grain surfaces especially close to the inlet as well as a distinct increase in biofilm volume reactive surface and connectivity with inlet distance a more subtle form of heterogeneity is evident in the average percent sidewall attachment which decreased significantly beyond the first few sections for r e 1 0 and 10 and is invariant for r e 0 1 these trends suggest that especially under the higher shear flows biofilm growth undergoes a transition where regions near the sidewall are increasingly less occupied by biofilm toward the outlet this is because pores along the sidewalls are wider than pores between glass beads due to sub optimal packing and they therefore impose a lower resistance to flow the inhomogeneities in the spatial distribution of biofilms appear to be linked to regions where dramatic changes in flow take place the three examples observed here are i increased tendency of biofilms to form in the sidewall regions near the inlet this tendency could be a consequence of the generally higher concentrations of dissolved oxygen near the inlet and the flow field still being affected by the converging diverging nozzle like structure of the column inlet ii accumulation of biofilm near the outlet where flow is converging into a more constricted opening as discussed above and iii at the highest flow rate the tendency of biofilm to occupy pore constrictions and grain surfaces directly close the inlet an effect that disappears again at greater inlet distances this indicates that higher shear flows in the main flow paths near the inlet hinders the biofilm from occupying the center of bigger pore bodies in the vicinity of the inlet the fact that correcting for tortuosity significantly improves the comparison between transducer and image based post growth permeabilities supports the notion that biofilm growth can completely transform the structure of pore scale flow drescher et al 2013 the image based measurements for r e 0 1 and r e 10 can potentially be further improved by using other pore space attributes than the harmonic mean of porosities one way forward would be to compute critical path conductivities friedman and seaton 1996 by searching for the lowest conductivity along the path of lowest flow resistance which in our study would likely be situated close to the outlet were biofilm was accumulating although the volume fraction and associated porosity of this type of local growth is small it can impose a dominant impact on effective permeability similar results have been reported by bielefeldt et al 2002 where decreases in hydraulic conductivity of up to 3 orders of magnitude were observed despite a mere 3 8 percent decrease in porosity due to biofilm growth we should note that the transducer derived post growth permeabilities carry some uncertainty as well because observed fluctuations make it difficult to obtain an accurate value for pressure drop immediately before the termination of the experiment implementing an averaging window adjacent to the end of the experiment can stabilize the reading but introduces information from earlier times that might not necessarily represent the snapshot studied after imaging considering this and the simplicity of the kozeny carman model image based calculations demonstrate very good accuracy once actual tortuosities were used to predict the reduction in hydraulic conductivity the trend with re was very well matched model b in fig 7 based on the overall pattern of reduction in hydraulic conductivity at different flow rates we hypothesize that the bioclogging was influenced by a trade off between the availability of nutrients mainly dissolved oxygen and shear induced sloughing biofilms grown under an initial re of 1 0 resulted in a slightly larger average reduction in hydraulic conductivity and porosity both parameters decreased as flow rate increased in the current round of experiments our interpretation of this trend is that as flow rate increased a threshold was crossed at which point oxygen is no longer a limiting factor in biofilm growth and continuous growth was promoted until shear stress induced by the increasingly restricted flow initiates sloughing 5 limitations and future work balancing complete coverage of the pore space by the contrast agent while minimizing sloughing of biomass is the primary challenge during imaging the image processing workflow implemented here enabled a significant improvement in the accuracy of phase segmentation over previous efforts by accounting for the heterogeneities in the spatial distribution of the barium sulfate contrast agent development of more sophisticated contrast agents and tailored image processing algorithms could further improve the resolution of the method and reduce its intrusivity because we use microimaging as a model driven predictor the sensitivity of image based measurements depends on the complexity of the models used to deduce them we would expect that using models that carry more information on the morphology of the pore space significantly improve the accuracy of the method perhaps beyond what is possible using transducer measurements for instance one could directly take into account local variations in velocity and pressure and their effect on permeability in a direct numerical simulation of the post growth flow field e g peszynska et al 2015 regardless computations of permeability hydraulic conductivity using the kozeny carman model and the measured surface area to volume ratios porosity and tortuosity all purely image based measurements demonstrated very promising fidelity another step toward better understanding the morphology distribution and quantity of biomass growing within porous structures is to systematically study a broader range of flow rate and nutrient conditions with each condition replicated several times in this perspective the present results show great promise for future use of the method in understanding the reported heterogeneities in physical properties of porous media subject to microbial growth e g acoustic signatures complex conductivity etc and the post growth 3d structure of the pore space abdel aal et al 2010 atekwana and slater 2009 davis et al 2006 2009 2010 imaging of relatively large samples was achieved here enabling the study of bulk growth indicators in response to a prescribed flow rate as well as local variations in growth in the model systems new structural indices were introduced in this study that cover very different aspects of biofilm configurations these new indices should help facilitate systematic studies in the future the degree to which these results are generalizable inevitably depends on the choices made during the design of the experimental system regardless this work has helped to establish effective protocols so that future work can focus on more complex pore structures and exploring a broader range of replicated conditions 6 conclusions 3d visualization of biofilm structure was achieved for three distinct hydrodynamic conditions in opaque porous media microimaging was used to track the structural changes of the pore spaces due to biofilm growth which were cross referenced with bulk measurements of pressure drop and oxygen utilization distinct growth and local morphological patterns were observed for growth in columns subject to different flow rates excellent agreement was found between transducer derived hydraulic conductivities and image based estimates using a simple porosity permeability relationship prior to growth post growth permeabilities proved more challenging to predict due possibly to the development of heterogeneities in pore morphology yet very good agreement was observed between the trends of hydraulic conductivity reduction at different flow rates using the two methods and the results improved when the increased actual post growth tortuosity of the pore space was accounted for bioclogging was found to depend non trivially on flow rate likely a function of competing mass transfer dissolved oxygen delivery and shear stress the use of a barium sulfate suspension as a contrast agent was further fine tuned by implementing a novel image processing workflow that accounts for inhomogeneities in the attenuation of the fluid phase the results demonstrate the utility of microimaging using x ray ct in studies of transformation of porous media subject to biofilm growth acknowledgments this work was supported by the environmental remediation science program de fg02 09er64734 under the department of energy office of biological and environmental research ber grant er64734 1032845 0014978 this research used resources of the advanced photon source a u s department of energy doe office of science user facility operated for the doe office of science by argonne national laboratory under contract no de ac02 06ch11357 we acknowledge the support of geosoilenvirocars sector 13 which is supported by the national science foundation earth sciences ear 1128799 and the department of energy geosciences de fg02 94er14466 we would like to thank mark rivers at gsecars at the aps for assistance with ct imaging so and bw were supported in part by the national science foundation under grant ear 1141488 ss is grateful to the alexander von humboldt foundation for granting a feodor lynen scholarship the image processing library quantim is accessible free of charge at http www quantim ufz de appendix a a1 segmentation of biofilm data the challenge in segmenting biofilm images is that the baso4 particles are non uniformly distributed in the pore space that is not occupied by the biofilm fig a 1 a this results in broad range of intensities for the baso4 phase as a consequence it cannot be identified as a third mode in the corresponding histogram fig a 1 d in turn the difference between above edge and below edge intensity fig a 1 b is low for biofilm and beads since in both phases the electron adsorption does not change with a small change in beam energy yet the difference is high for the baso4 phase and varies with barium concentration this results in a single peak for beads and biofilm and a long tailing for baso4 in the corresponding histogram fig a 1 e the joint frequency distribution of the below edge and the difference intensities fig a 1 g is already sufficient to identify beads as an isolated cluster in the feature space but there is a gradual transition from biofilm to baso4 due to the variation in barium concentration this variation however can be assessed by the local image gradient fig a 1 b which is low in the homogeneous beads and biofilm and has a broad range of intensities in the baso4 filled pore space this leads to a joint peak at zero in the gradient histogram for biofilm and beads fig a 1 e and a long tail for baso4 and the transition voxels at phase boundaries the joint frequency distribution of the below edge and the gradient intensities fig a 1 h exhibits two clusters at low gradient intensities one for beads and one for biofilm which are connected by an arch of partial volume voxels at the boundaries between the two phases and extensive scattering for baso4 the two joint probabilities fig a 1 g and h are now used to estimate the class statistics in eq 3 with the following workflow 1 unimodal thresholding rosin 2001 schlüter et al 2014 is applied to separate the peak biofilm and beads from the tail baso4 and phase boundaries in the gradient histogram note that this threshold corresponds to the horizontal line in fig a 1 h a roi of voxels that belong to the peak class is created 2 the histogram of below edge intensities within this roi is evaluated by a minimum search schlüter et al 2014 tsai 1995 to detect the threshold between beads and biofilm this corresponds to a vertical line in fig a 1 h 3 a bead label is assigned to all voxels that fulfill both threshold requirements and whose joint frequency exceeds a user defined threshold e g 1 10 3 in fig a 1 h biofilm voxels are labeled in the same way 4 noise objects in the label image are removed with a size exclusion filter and the remaining labels are dilated with a spherical structure element of radius r 4 the dilated areas are considered as phase boundaries and the rest is assigned to baso4 5 steps 1 4 are repeated with the difference image instead of the gradient image as vertical axis in the feature space fig a 1 g 6 the final label image fig a 2 d is obtained by merging the label images from steps 4 and 5 together i e labels that coincide in both images are kept and voxels with different labels are set back to unassigned 7 the class statistics μ c λ and σ c λ 2 in eq 3 can then be estimated from label specific histograms in each input image note that the automated threshold detection methods in the presented workflow may fail when the volume fraction of biofilm or baso4 becomes too low in that case that values have to be adapted manually we are currently improving the workflow by substituting the iterative threshold detection for single source images with multi dimensional clustering techniques that allow for irregular threshold surfaces in the feature space during markov random field mrf segmentation each voxel is assigned a class label according to the penalty term for phase boundaries and the sum of likelihood terms of each class in eq 3 fig a 2 a c due to reformulation the smallest value for the likelihood term is considered optimal the likelihood term is multiplied with the user defined weighting factor for each image source which is set to a low value of α λ 0 1 λ 1 2 3 to increase the penalty on phase boundaries and thus invoke smooth boundaries the mrf segmentation results fig a 2 e are not optimal yet due to partial volume effects that is voxels along the bead boundaries are partially filled with biofilm which leads to a false assignment to baso4 postprocessing has to be applied to remove this unwanted effect to do so a cubic kernel with 73 voxels loops through the image detects boundaries as neighborhoods with more than one label and sets the central value to unassigned subsequently the labels are iteratively dilated back into unassigned areas by a simple majority rule i e the most representative label in a cubic 73 kernel is assigned to the central voxel until no unassigned voxel is left the result after postprocessing is depicted in fig a 2 f supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2018 03 018 appendix b supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
801,this study expands the metastatistical extreme value mev framework to sub daily rainfall frequency analysis and compares it to extreme value theory methods in presence of short records and measurement errors ordinary events are identified based on the temporal autocorrelation of hourly data and modeled with a weibull distribution mev is compared to extreme value theory methods in the estimation of long return period quantiles from actual data 160 rain gauges with at least 60 year record in the contiguous united states and on synthetic data perturbed with measurement errors typical of remote sensing rainfall estimation mev tends to underestimate the 100 year return period quantiles of hourly rainfall when 5 20 years of actual data are used but presents diminished uncertainty when a good model of the ordinary events and adequate number of events per year are available mev is able to provide information on the 100 year return period quantiles from 10 20 or even 5 years of data with significantly reduced uncertainty 30 uncertainty for 5 year records mev estimates of 100 year return period quantiles from short records are much less sensitive than extreme value theory methods to additive multiplicative errors presence of cap values in the estimates and missing of extreme values results from this study strongly support the use of mev for rainfall frequency analyses based on remotely sensed datasets keywords sub daily rainfall frequency metastatistical extreme value long return period quantile estimation uncertainty short records dependence on data record and measurement errors 1 introduction the standard approach for the analysis of extreme rainfall frequency lies on the statistical theory of extreme values maximal rainfall amounts occurred during fixed length periods generally annual maxima series ams or values exceeding a large enough threshold peaks over threshold pot are extracted from long series of data and are statistically analyzed to characterize the distribution of the extremes coles et al 2001 extreme value theory requires the availability of large samples from independent and identically distributed data i e the number of events per year n should be n in each year and the hypothesis of convergence to a limit distribution in order to have the ams or pot to asymptotically converge to the generalized extreme value gev or the generalized pareto gp distributions respectively fischer and tippett 1928 gnedenko 1943 in common practice the identical distribution is often implicitly assumed as well as the convergence to the limit distribution while the independence of data is ensured by imposing a minimum temporal distance between events e g fukutome et al 2015 conversely the asymptotic assumption is hardly verified since the number of independent rainfall events in a year is far from being infinite koutsoyiannis 2004 in addition to this long data records are required in order to get sufficient sample of the climate and to derive accurate parameters of the sought extreme value distribution regionalization approaches in which selected properties of extreme rainfall are assumed uniform within pre defined regions and data from multiple locations within the regions are pooled together are often adopted to decrease the uncertainties related to short record lengths buishand 1991 however their application can be limited by the homogeneity requirements over wide enough regions paixao et al 2015 record length limitations are particularly emphasized when considering rainfall extremes at sub daily durations or using precipitation data derived from remote sensing observations satellite or weather radars to date records of sub daily rainfall are available from a small number of recording stations and are often short in length libertino et al 2018 from the perspective of sub daily rainfall frequency analysis vast regions of the earth are to be considered ungauged bardossy and pegram 2017 kidd et al 2017 therefore the distribution of sub daily rainfall extremes is largely unknown worldwide in great contrast to the actual need for this information in a number of real world applications information on sub daily rainfall extremes is crucial for hydrological design and risk management in fast responding systems such as mountainous urban and arid watersheds and small catchments in general morin et al 2002 ashley and ashley 2008 borga et al 2014 cristiano et al 2017 high resolution radar and satellite precipitation datasets have recently advanced in terms of resolution and accuracy and represent a potential to addressing the data gap issue of sub daily extreme rainfall analysis e g overeem et al 2009 eldardiry et al 2015 marra and morin 2015 panziera et al 2016 gado et al 2017 marra et al 2017 demirdjian et al 2018 thus far works on this aspect have highlighted important quantitative mismatches between quantile values derived from remotely sensed datasets and benchmark ground estimates particularly for long return periods this was generally associated to the short records of these datasets and to uncertainties in the remote sensing quantitative estimates in fact records from these datasets reach 30 years at most but for the recent most advanced products usually span 12 17 years this calls for new methods able to better estimate high quantiles from short data records the metastatistical extreme value mev framework recently proposed by marani and ignaccolo 2015 relaxes some of the assumptions of extreme value theory and exploits the full data record rather than a small subsample of its tail an empirical extreme value distribution is derived as a sample average of the distributions of the ordinary events occurred in each year which are sampled a varying number of times each year tested on daily rainfall records the mev method was shown to outperform extreme value theory when used to estimate return periods longer than the data record length zorzetto et al 2016 this diminishes the limitations of extreme value analysis from short data records but at present the method was only tested on daily rainfall data and its applicability to sub daily rainfall amounts still needs to be checked moreover its sensitivity to measurement errors needs to be properly investigated and understood before operational applications can be developed objective of this study is to advance knowledge and improve methodological tools for the analysis of sub daily rainfall frequency from short data records specifically we will 1 analyze the characteristics of sub daily ordinary events 2 expand the mev framework to the analysis of sub daily data 3 test the accuracy of mev in comparison to classical approaches in the estimation of long return period quantiles from short records and 4 quantify the impact of measurement errors typical of sub daily rainfall estimation and of remote sensing estimates the paper is organized as follows section 2 provides information on the study area and the used dataset section 3 describes the methods used for extreme value analysis with different approaches and the simulation of measurement errors section 4 describes the results of the study in section 5 a thorough discussion of the implications of these findings is presented together with some recommendations for future research and applications section 6 provides the main conclusions of the study 2 study area and data this study is based on hourly precipitation observations collected over the contiguous united states conus thus involving analysis of precipitation regimes with distinctly different climatologic characteristics with respect to the frequency events year seasonality and diurnal variability of precipitation brooks and stensrud 2000 hitchens et al 2013 in terms of data availability of hourly precipitation the conus constitutes an exception since a large number of in situ stations with long term hourly observations is available data in this study were collected from the cooperative observers program hourly precipitation dataset of noaa national centers for environmental information 2017 and include hourly precipitation records from more than 1900 stations covering conus since 1948 in addition to the quality check from noaa rain gauge data were further examined to exclude cases in which rainfall from multiple hours was reportedly accumulated to a single hourly interval for each rain gauge years with less than 80 available data were removed barbero et al 2017 and rain gauges with less than 60 years of quality controlled data were excluded from the analysis further quality control revealed that for many gauges the sampling resolution changed over time and data were reported over different periods based on either 0 254 or 2 54 mm h 1 i e 0 01 or 0 1 in h 1 as the minimum available resolution the presence of coarser resolution values is expected to impact the use of pot langousis et al 2016 and mev thus the years in which the coarser resolution was observed were flagged and the rain gauges with less than 30 years of high resolution i e 0 254 mm h 1 data were removed from the dataset the final dataset fig 1 consists of 160 rain gauges for which at least a 60 years of quality controlled data and b 30 years of high sampling resolution quality controlled data are available the available dataset was further divided into different climate groups fig 1 according to the koppen geiger climatic classification developed by peel et al 2007 specifically five main classes were considered and the final dataset climate group number of gauges was divided as follows bw bs desert and steppe 36 rain gauges cs mediterranean 17 rain gauges cf temperate 56 rain gauges dfa cold hot summer 32 rain gauges and dfb cold warm summer 16 rain gauges three rain gauges which each belong to a different class were grouped apart 3 methods the analysis presented in this study is organized in two parts first rain gauge data are analyzed to identify and model the hourly rainfall ordinary events and to derive rainfall frequency analysis by means of ams pot and mev the focus of this part is to evaluate these methods regarding the estimation of high quantiles from short records of actual rain gauge data in the second part a synthetic experiment is devised to quantify the impact of measurement errors and inaccurate assumptions on the estimation of long return period quantiles using ams pot and mev 3 1 identification and modeling of ordinary events ordinary events constitute the basis for the statistical modeling of rainfall frequency with mev and represent the data from which a sub sample will be used in the pot method they are defined as maximal non zero rainfall amounts observed in statistically independent rainy periods the statistical independence of ordinary events is a crucial hypothesis behind both pot langousis et al 2016 and mev zorzetto et al 2016 to ensure its validity a prudent separation of the events is developed as follows for each year of each rain gauge see fig 2 for reference i the temporal autocorrelation of the time series is calculated for time lags up to 15 days this time lag was found to be long enough to allow the autocorrelation to drop to very low values permitting to exclude any statistical and or meteorological correlation ii for each time lag the long lag noise is defined as the 75th quantile of the empirical autocorrelations observed for longer lags iii the running parameter i e the minimum time distance allowed between independent events fukutome et al 2015 is set as the time lag at which the temporal autocorrelation first becomes comparable to the long lag noise fig 2 in this way one running parameter is identified for each year of each rain gauge ordinary events are then defined as non zero rainfall peaks separated by time intervals longer or equal to the running parameter the independence of ordinary events across consecutive years is ensured requesting the first ordinary event of each year to be separated from the last of the previous year by a time distance equal to the running parameter calculated for the previous year once the ordinary events are defined their statistical properties need to be modeled marani and ignaccolo 2015 and zorzetto et al 2016 in developing the mev framework used a weibull distribution weibull 1951 to model their ordinary events simply defined as non zero daily rainfall amounts no separation was sought previous studies showed that the gamma distribution provides a good representation of sub daily rainfall variability but owing to its light tail it is not able to reproduce rainfall extremes leading to systematic errors in the estimation of long return period quantiles katz et al 2002 vrac and naveau 2007 naveau et al 2016 conversely the heavier tail of the weibull distribution is expected to be more representative of extremes also for sub daily rainfall amounts with the advantages of a parsimonious two parameter distribution wilson and tuomi 2005 the weibull cumulative distribution function can be written as 1 w x λ κ 1 e x λ κ where λ 0 is the scale parameter and κ 0 the shape parameter the representativeness of the weibull distribution for hourly rainfall ordinary events needs to be checked to do so we i identify the ordinary events in each year of each rain gauge ii fit a weibull distribution to these data series using the method of the l moments hosking 1990 that with respect to the maximum likelihood method weights more the tail of the distribution and is less sensitive to the use of small data samples sornette 2003 and iii check the goodness fit of the weibull distribution for the yearly ordinary events using the χ2 goodness of fit test at 5 significance level 3 2 rainfall frequency analysis methods this section describes the methods used for rainfall frequency analysis using extreme value theory ams and pot and the mev framework the ordinary events identified in years for which data is available with high sampling resolution 30 years records constitute the basis for frequency analyses with pot and mev whereas the ams approach is used both on the full 60 years records to define the reference for long return period quantiles and on the 30 years high sampling resolution records to check its performance on short records it should be noted that the rain gauge records are at least 80 complete within each year but gaps between years can be present 3 2 1 annual maxima series ams a gev distribution is fitted to the ams using the method of the l moments hosking 1990 the l moments method provides improved estimates of the distribution parameters in presence of short data records and is less sensitive to outliers when compared to the maximum likelihood method martins and stedinger 2000 owing to its simple application and to the requirement of records of annual maxima alone the ams is among the most used approaches for frequency analysis and provided the assumptions behind extreme value theory are verified and the data record is long enough is expected to provide accurate estimates of the long return period quantiles without the need for threshold identification of the pot 3 2 2 peaks over threshold pot the pot approach e g pickland 1975 davison and smith 1990 consists in fitting a gp distribution to the independent events exceeding a predefined high threshold independence of the ordinary events is granted by the separation procedure described above in theory the threshold should be large enough to verify the extreme value theory assumptions and at the same time small enough to provide a sufficient data sample dealing with short data records this is a particularly difficult task fukutome et al 2015 langousis et al 2016 and given the large number of applications in a monte carlo framework an automatic threshold selection is sought we chose a goodness of fit approach e g ben zvi 2016 langousis et al 2016 solari et al 2017 exploring thresholds starting from the 95th quantile of the ordinary events the threshold should be large enough and stopping before the number of pot becomes equal to the number of ams in this case the advantages of a pot approach would be lost a gp distribution is fitted to the corresponding pot using the l moments method and is tested using the anderson darling goodness of fit anderson and darling 1954 the threshold providing the best fit is selected and the corresponding gp distribution is used as a model solari et al 2017 3 2 3 metastatistical extreme value mev the mev framework derives an approximate expression for the extreme value distribution as a sample average of the yearly distributions of ordinary events the parameters of the ordinary events distributions are allowed to vary in time as well as the number of times the distributions are sampled i e the number of ordinary events in each year it is worth mentioning that the gev distribution can be obtained as a particular case of the mev zorzetto et al 2016 following the formalism by zorzetto et al 2016 the mev cumulative distribution function can be written as 2 ζ x 1 m j 1 m w x λ j κ j n j where x is the hourly rain intensity m is the number of years in the record and w x λ j κ j is the weibull cumulative distribution function see eq 1 fitted to the nj ordinary events of the j th year practically i a weibull distribution is fitted to each yearly record of ordinary events using the method of the l moments ii the mev cumulative distribution function is calculated using eq 2 iii the desired quantile is calculated numerically inverting eq 2 for a detailed description of the mev framework the reader is referred to marani and ignaccolo 2015 and zorzetto et al 2016 3 3 rainfall extremes estimation error metrics in this study we are interested in the estimation of high quantiles of hourly rainfall from short data records extreme rainfall is represented by the quantile values of the 100 year return period while 60 years of data are available only 30 years correspond to data at high gauge sampling resolution 0 254 mm h 1 change in the gauge sampling resolution affects the distribution of the ordinary events and thus does not permit the application of mev to the full available record on the other hand differences in sampling resolution have practically no effect on the annual maximum values therefore in order to obtain a reference estimate of quantiles for 100 year return period we considered the classic extreme value theory approach i e the gev fit of the ams applied to the full rain gauge records 60 years it is noted that the violation of the asymptotic assumption for the estimation of 100 year return period quantiles from records of similar characteristics was shown to be negligible by marani and ignaccolo 2015 in using this reference values one also needs to assume that the available data record is representative of the long term climatology of extremes for the sake of consistency the reference values are calculated fitting a gev distribution to the ams using the l moments method however the use of the maximum likelihood method preferable in presence of long records was tested with no appreciable impact on the results and at the price of significantly increased computation time uncertainty in the reference quantiles is quantified by bootstrapping with replacement 1000 bootstrap repetitions m random years from the full record where m is the number of available years in the record of each rain gauge overeem et al 2008 short record quantiles are estimated by randomly sampling with replacement l years with l 5 10 20 out of the 30 high sampling resolution years of the rain gauge record 1000 bootstrap repetitions the 100 year return period quantiles are then computed using the three methods two widely used non dimensional normalized metrics are used to quantify the 100 year return period quantiles estimation error the estimation error of a single iteration i is quantified using the multiplicative bias between the estimated quantile x est i and the corresponding reference x ref 3 bia s i x est i x ref where bias 0 with 1 representing the perfect match is defined for each iteration of each rain gauge the error of the 1000 iterations of each rain gauge is measured using the fractional standard error fse 4 fse 1 1000 i 1 1000 x est i x ref 2 x ref where fse 0 with 0 indicating no error is defined for each rain gauge 3 4 application to daily data application of the methods to daily data is tested in order to confirm the findings of previous works on the effectiveness of the mev method and provide an indirect validation of the method used to separate the ordinary events in fact no direct validation of the separation method can be performed on hourly rainfall hourly rainfall amounts are highly correlated in time and some kind of separation is anyway required to reasonably process the data conversely temporal correlation of daily amounts is small and often neglected hourly amounts are summed to daily blocks and ordinary events are defined in two different ways a ordinary events are defined as all the non zero daily amounts temporal correlation of daily amounts is neglected following the method by zorzetto et al 2016 b ordinary events are defined using the separation method based on temporal autocorrelation described above temporal independence is ensured following the method proposed here the 100 year return period quantiles of daily rainfall are then estimated using these two datasets 3 5 simulation of multisource uncertainty impacts aim of this synthetic experiment is to quantify the impact of a use of short records b presence of measurement errors and c presence of ordinary events coming from multiple distributions on the estimation of 100 year return period quantiles using ams pot and mev approaches the synthetic ordinary events are simulated as independent and identically weibull distributed to meet the assumptions of extreme value theory and of the mev framework it should be recalled that the extreme value theorem also assumes the convergence of the limit distribution of ams pot however this assumption cannot be directly checked or reproduced in real or synthetic data and is generally taken as granted in real applications 3 5 1 use of short records each synthetic year is simulated to have n ordinary events with n following a normal distribution with mean n µ and standard deviation n σ these parameters were modeled using the information gathered from real data as shown in the next section fig 3 with mean number of events per year n µ set to 10 50 and 100 thus representing the full range of observations and standard deviation set to n σ 0 3 n µ following the observed coefficient of variation ordinary events are randomly generated to follow a weibull distribution with shape parameter κ set to 0 8 and 1 25 representing the typical range of variability of the observed data see next section fig 4 to permit an easy interpretation of the results a standard scale parameter λ 1 with arbitrary units is used the performance of the three methods under ideal conditions is checked randomly generating 1000 repetitions records of synthetic data of varying lengths and calculating the multiplicative bias eq 3 between the 100 year return period quantiles derived from the three methods and the ones empirically obtained from an extremely long record 105 years 3 5 2 presence of measurement errors the series of synthetic ordinary events are then perturbed with i additive measurement errors ii multiplicative measurement errors iii upper cap value to the measurements iv removal of extremely high values and v removal of low values errors i and ii are among the most common models for rainfall estimation errors with ii multiplicative errors being considered the most representative for high resolution rainfall data and remote sensing estimates tian et al 2013 tang et al 2015 conversely errors iii iv and v are typical of remote sensing estimation errors iii and iv in particular are considered among the main limitations in the use of remotely sensed precipitation estimates in the analysis of extreme rainfall e g krajewski and smith 2002 examples of errors with these characteristics are the upper limit posed to weather radar estimates to avoid problems related to the extremely large reflectivity of hail stones e g marra and morin 2015 the intrinsic estimation upper and lower limits typical of satellite retrieval algorithms and the missing of extreme events due to temporal hiatuses between satellite overpasses kidd and levizzani 2011 additive errors are simulated as independent and normally distributed with mean zero and standard deviations of 5 10 and 25 of the scale parameter λ here λ 1 multiplicative errors are simulated as log normally distributed with median 1 and standard deviations of 5 10 and 25 the presence of an upper cap to the measurements is simulated choosing a high cap 99 9th 99 5th and 99th quantile of the full series of ordinary events and saturating to this cap value all the ordinary events exceeding it the same quantiles are used to simulate the missing of extreme values all the ordinary events exceeding the given quantile are removed from the dataset the same is done on the other tail of the dataset to simulate the missing of low values removing all the ordinary events lower than the 0 1th 0 5th and 5th quantiles the impact of these perturbations is quantified as relative difference δ with respect to the 100 year return period quantiles obtained using the corresponding unperturbed dataset and the corresponding extreme value method 5 δ i x est mth i x ref mth where x est mth i is the i th estimate of the 100 year return period quantile calculated using a given method ams pot or mev and x ref mth is the 100 year return period quantile calculated using the corresponding unperturbed dataset and method this allows us to quantify the net impact of the perturbations on the quantification of long return period quantiles using the three extreme value methods 3 5 3 presence of ordinary events coming from multiple distributions identical distribution of the ordinary events is among the main assumptions behind extreme value theory and mev to test the response of the three methods to the presence of ordinary events coming from multiple distributions such as rainfall seasonality or events generate by different weather types we synthetically simulate datasets of varying length in which the ordinary events are picked with varying proportions from two different weibull distributions and we calculate the 100 year return period quantiles using the three extreme value methods we examine two cases namely i uniform shape κ 1 25 and varying scale λ 1 and λ 2 and ii uniform scale λ 1 and varying shape κ 0 8 and κ 1 25 and different proportions in the number of ordinary events coming from the two distributions i e 1 99 5 95 10 90 15 85 25 75 and 50 50 in addition to the already explored 0 100 each simulation is repeated 1000 times and the impact of having multiple distributions of ordinary events on the performance of the three methods is checked using empirical quantiles extracted from an extremely long record 105 years as a reference 4 results 4 1 estimation of long return period quantiles from rain gauge records 4 1 1 ordinary events fig 3 shows the distribution among the rain gauges of a the running parameters observed for hourly data median b the number of ordinary events per year median and c the variability of the number of events per year coefficient of variation the spatial distribution of the median number of events per year is shown in d the running parameter generally ranges between 12 and 32 h but can in rare cases reach and exceed 2 days the median number of ordinary events per year ranges between 10 and 100 events year with two peaks at 30 40 and 60 75 events year the geographical distribution shows a clear sw ne gradient with low number of events per year in the sw regions 40 gradually increasing going towards ne to 60 80 events per year the number of events per year is however variable within each rain gauge data record with a coefficient of variation generally 0 2 0 4 mostly around 0 3 fig 3c no noteworthy geographic trend is observed for the coefficient of variation not shown fig 4 reports information of the weibull fit to the ordinary events a the fraction of years in which the null hypothesis of data coming from a weibull distribution was not rejected at the 5 significance level using the χ2 fit test good fit hereinafter the b scale parameters and c shape parameters obtained and d the geographical distribution of the fraction of years with good fit the weibull distribution is a good model for the yearly data in 88 of the examined years with increased proportions of goodness of fit in the sw regions with respect to the ne this distribution roughly follows the number of ordinary events per year the scale parameters of the distribution generally range up to 10 mm h 1 whereas the shape parameters range between 0 7 and 1 5 90 of the cases and rarely exceed 0 5 or 2 fig 4c the same analysis conducted with the gamma distribution not reported here for brevity showed a total fraction of good fits 84 i e 250 additional years for which the selected distribution was rejected at the 5 significance level thus pointing to the weibull as better representing hourly ordinary events 4 1 2 daily rainfall quantiles fig 5 evaluates the 100 year return period quantiles of daily rainfall as estimated using ams pot mev based on all non zero daily amounts i e method by zorzetto et al 2016 and using mev based on statistically independent ordinary events i e defined as described in this study mev clearly outperforms extreme value theory methods with largely reduced bias and fse when all the non zero daily measurements are used as ordinary events magenta the fse observed for mev estimates is significantly smaller than the one from ams and pot fig 5b confirming the value of mev in estimating return periods longer than the record length found by zorzetto et al 2016 using a rmse based metric however when this dataset is used a systematic tendency towards underestimation of the 100 year return period quantiles can be noticed fig 5a it should be recalled here that no true reference for the 100 year return period quantiles is available so the presented results rely on the 60 ams estimates considered as reference conversely when independent ordinary events are used i e using the here presented separation method mev estimates red are quantitatively improved and able to provide improved estimates of the 100 year return period daily quantiles even from 5 year data records with distribution of biases largely overlapping the one obtained resampling the full 60 year data records black the advantage of using mev with respect to ams and pot becomes even more pronounced as the record length decreases bias in the estimation of 100 year return period quantiles from 5 year of data range in 0 6 1 3 versus the 0 45 2 of ams and pot 4 1 3 hourly rainfall quantiles the evaluation metrics obtained for the estimation of 100 year return period quantiles from short records are reported in fig 6 we recall that the bias statistics are shown for each of the 1000 repetitions done for each rain gauge while one fse is calculated for each rain gauge as a measure of the standard error of the 1000 repetitions in general the estimates from ams and pot show very similar patterns of bias and fse whereas important differences are observed for mev focusing on the full dataset all the bias of the full record ranges between 0 8 and 1 1 indicating that roughly 30 uncertainty is to be expected on the 100 year return period quantiles even when the ams method is used on the full 60 years rain gauge record using short records estimates from ams and pot are characterized by wide distributions of multiplicative bias roughly centered around 1 conversely mev tends to underestimate reference values but is characterized by narrower estimation error distributions for 5 and 10 year records this underestimation slightly decreases increasing the record length similar results are reported for the fse which for 5 and 10 year records is smaller for the mev than for ams and pot conversely large variability is visible for 20 year mev estimates looking at the results for different climates one notes that mev severely underestimates the 100 year return period quantiles i e the 5 95 interval does not include 1 for the dfb climatic class cold warm summer 10 of the gauges and underestimates the 100 year return period quantiles on bw bs cs and dfa climatic classes arid semiarid mediterranean cold hot summer 53 good quantitative estimates from the mev are reported for the cf climatic class temperate 35 it should be noted how the performance of ams and pot remains similar among different climates when using short records the bias on 100 year return period quantiles derived from these methods typically range between 0 5 and 2 for 5 year 0 6 1 6 for 10 year and 0 7 1 3 for 20 year records despite the systematic underestimation related to mev estimates in most of the climates the method is able to estimate the 100 year return period quantiles within the accuracy range of the extreme value theory methods with the exception of dfb climates in general the bias on 100 year return period quantiles derived from mev ranges between 0 45 and 1 2 even for 5 year records it is worth noting the cs mediterranean climatic class in which also ams estimates are underestimated this can potentially be related to differences in rainfall distribution between the short record 30 records and the reference 60 records but investigating possible temporal trends in the data is beyond of the scope of this study 4 2 numerical experiment results 4 2 1 estimation of long return period quantiles from short synthetic records we present here the results of the synthetic simulation run under ideal conditions for the assumptions of extreme value theory and mev independence identical weibull distribution of the ordinary events convergence a total of 1000 randomly generated series of ordinary events of varying lengths from 3 to 50 years are used to estimate the 100 year return period quantiles in this experiment the reference is provided by the 100 year return period quantiles empirically obtained from 105 years of data fig 7 reports the multiplicative bias 5 95th quantile interval between the quantiles obtained using the three methods and the empirical reference important variability emerges for ams and pot in particular for heavier tailed distributions of the ordinary events 40 50 uncertainty for κ 0 8 even when 50 year records are available mev tends to systematically overestimate the 100 year return period quantiles with respect to the empirical quantiles derived from 105 years of data but presents a largely reduced variability in particular for larger average n the overestimation is due to uncertain estimation of the weight of the tail of the ordinary events distribution when few data points are used for the fit sornette 2003 this is confirmed in fig 7 d h in which for large number of events per year 1000 the mev estimates are shown to converge to the 105 year reference despite this systematic behavior mev is shown to outperform the extreme value theory methods when the number of events per year is large enough e g 50 events per year uncertainty is largely reduced and even 3 years of data are able to provide information comparable to 50 years of data of extreme value theory methods 4 2 2 impact of measurement errors the impact of measurement errors typical of remote sensing rainfall estimation additive and multiplicative errors upper cap value missing of extreme high events missing of low intensity events on the estimation of the 100 year return period quantiles of hourly rainfall 5 95th quantile interval of the 1000 repetitions is presented in fig 8 we recall that the impact is presented here with respect to the corresponding method on the error free data as reported in eq 5 results are reported for record lengths of 5 and 20 years it is noted that the methods based on extreme value theory ams pot show similar responses to measurement errors thus except when explicitly stated will be discussed together the impact of additive errors on extreme value theory methods consists in a random dispersion of the estimates around the reference value fig 8 a b unexpectedly no clear dependence on the magnitude of the error is observed a minor decrease of the dispersion with a larger number of events per year can be noted nevertheless the width of the dispersion is larger for heavier tailed distributions of the ordinary events smaller κ in general the dispersion of pot estimates is slightly wider than the one of ams estimates conversely the impact of additive errors on mev estimates shows a systematic tendency towards underestimation that increases with increased error magnitudes and that is larger for heavier tailed distributions of the ordinary events the dispersion is larger for smaller number of events per year and seems not to depend on the error magnitude as for multiplicative errors a systematic tendency towards overestimation is reported for all the methods when the errors are large enough 25 fig 8 c d it is interesting to notice that the mev is less sensitive to this kind of errors than extreme value theory methods showing smaller systematic and random components completely different responses are observed when upper cap values are imposed to the data fig 8 e f or when extreme values are removed from the data series fig 8 g h extreme value theory methods are highly sensitive to these errors with immediate systematic underestimations already for very high caps limit values heavier tailed distributions of ordinary events are more affected mev estimates are almost not sensitive to this kind of errors with the worst case scenario being 20 underestimation when the top 1 values of the data series are missed in climates with an average of 10 events per year conversely mev estimates can be sensitive to the missing of low values from in the data series whereas extreme value theory methods are obviously almost untouched by this kind of estimation error fig 8 i l heavier tailed distributions of ordinary events are more affected with up to 30 systematic underestimation in case the lowest 5 of the ordinary events are missed it should be here noted that the simulations were carried out for a larger number of shapes of the weibull distribution namely 0 5 0 7 1 1 5 and 2 and for small variability in the number of events per year i e using n σ 0 05 n µ the results not reported here for brevity showed no appreciable dependence on n σ and a monotonic dependence on the shape parameter so that information on distributions characterized by different shapes can be easily derived from the here presented results 4 2 3 multiple distributions of ordinary events the impact of the presence of multiple distributions among the ordinary events is presented in fig 9 we should recall that this situation explicitly violates the assumptions of extreme value theory and mev even if the mev formulation provides the potential to include multiple distributions in the analysis fig 9 a c show the different estimates of the 100 year return period quantiles obtained when the ordinary events are sampled in varying proportions from two distributions characterized by the same shape parameter and different scales whereas fig 9 d f show the results from two distributions characterized by the same scale parameter and different shapes the figure shows a different response between extreme value theory methods and mev in particular for situations in which the majority of the events come from a lighter tailed or lower scaled distribution left side of the panels when a large number of events is observed in a year fig 9 c f the presence of just 1 of events from a heavier tailed or higher scaled distribution i e on average 1 event every year immediately affects the 100 year return period quantiles estimated by extreme value theory and when 25 of heavier tailed distribution events are present the heavier tailed distribution fully dominates the estimation of extremes from extreme value theory conversely in the mev case a much slower response is observed with a rather smooth transition from the light tail scale to the heavy tail scale estimation of the high quantiles as shown by the different under and overestimation biases observed with respect to the reference quantiles these differences are expected to affect the estimation of high quantiles both from extreme value theory and mev in situations in which the ordinary events are sampled from multiple distributions in particular some proportions of the parameters actually lead to underestimated quantiles from the mev estimation despite the proneness to overestimation reported in fig 7 moreover it should be noted that extreme value theory methods are sensitive to the presence of multiple distributions of ordinary events also in terms of uncertainty i e the length of the 5 95th quantile interval bars with large uncertainties rising from the presence of only 5 of the events from a heavier tailed or higher scaled distribution 5 discussion the estimation of long return period rainfall amounts is a challenging task particularly for hourly time scales even in ideal conditions in which the validity of the assumptions of extreme value theory independence and identical distribution of rainfall events long records are ensured methods based on extreme value theory show large uncertainties in the estimation of long return period quantiles fig 7 despite the use of different baseline periods for the short record sampling 30 years dataset and for the reference 60 years dataset the estimates from extreme value methods were consistent within the large uncertainties associated to the short record estimates when dealing with actual data 160 quality controlled rain gauges within conus fig 1 roughly 30 uncertainty is exhibited on the 100 year return period quantiles of hourly rainfall derived from 60 year data records and extreme value theory fig 6 this uncertainty is slightly larger 35 for daily rainfall quantiles fig 5 when dealing with short data records only a small number of data points is available to fit the extreme value distributions so that very large uncertainties characterize extreme value theory methods on short records figs 5 and 6 this study also points out how the results obtained for ams and pot are basically indistinguishable throughout the analyses this is quite unexpected since an optimal use of pot is expected to improve the accuracy in the estimates of high quantiles from shorter records madsen et al 1997 but was already reported by other studies schlögl and laaha 2017 the pot method even after application of state of the art procedures for the threshold selection laugousis et al 2016 solari et al 2017 did not outperform the ams approach we claim that at the price of augmented data pre processing and increased computational complexity the mev framework does represent a viable method for the estimation of long return period quantiles from short data records fig 7 the results of zorzetto et al 2016 showing that mev outperforms extreme value theory methods when applied to a wide set of daily rainfall observations are here further improved by granting the statistical independence of ordinary events fig 5 application of the mev method to 5 years of actual daily data will provide an estimate of the 100 year return period quantiles with less than 20 40 error in more than 50 90 of the cases in light of these results we contrast the common approach to frequency analysis claiming that when the distribution of ordinary events is known and the number of ordinary events per year is large enough 50 events per year reasonable information on 100 year return period quantiles can be provided by 10 20 or in some cases even 5 years of data nevertheless synthetic simulations based on ideal conditions show a systematic overestimation of the 100 year return period quantiles derived using the mev fig 7 this is due to an overestimation of the tail of the distribution of the ordinary events within the weibull fit and is shown to decrease when the number of events per year is large enough fig 7 unfortunately dealing with sub daily rainfall amounts the amount of independent ordinary events per year is limited to numbers usually lower than 100 so that this problem needs to be considered when using this method different results were reported by marani and ignaccolo 2015 who in a similar experiment showed no systematic bias in the mev estimates however the authors in that study derived the weibull parameters using the full data record rather than the yearly series so the data sample used to estimate the parameters in marani and ignaccolo 2015 always exceeded 1000 this suggests that aggregating data from multiple years to obtain the parameters for the ordinary events distributions represents a viable way to decrease this systematic effect when exploring large quantiles of hourly rainfall from real datasets the mev performance is characterized by larger inaccuracies than the ones observed with synthetic data in fact despite what reported for ideal conditions application of the mev framework to actual data tends to underestimate the 100 year return period quantiles fig 6a in this sense a strong dependency on the examined climatic conditions is noticed fig 6 an important role in shaping this behavior could be played by the assumption of identical distribution of the ordinary events the assumption is required by both mev and extreme value theory however the response of the different methods to violations of this assumption is shown to be largely diverse fig 9 in fact the co presence of ordinary events sampled from multiple distributions causes a mismatch between the high quantiles estimated by extreme value theory methods and by mev this mismatch depends on the proportion of events from the different distributions on the average number of ordinary events per year as well as on the characteristics of the ordinary event distributions moreover the co presence of ordinary events sampled from multiple distributions causes large uncertainties in the long return period quantiles derived from extreme value theory methods this is particularly enhanced in the case of varying scale parameter in general the co presence of ordinary events sampled from multiple distributions can be caused by the occurrence of different meteorological synoptic conditions on the studied location a classic example of this is the seasonality of precipitation as a proof of concept fig 10 shows the bias on the 100 year return period quantiles of summer june july august jja hourly rainfall for two climates in which the underestimation reported in the hourly quantiles fig 6 was particularly important i e bw bs arid and dfb cold warm summer when considering the summer season alone the underestimation almost disappears this confirms the idea that seasonality and more in general the presence of multiple meteorological conditions generating rainfall over the location of interest are aspects that need to be carefully considered in the application of the mev framework these aspects need to be adequately considered also when examining possible non stationarity in rainfall extremes caused by varying proportions of ordinary events generated from different meteorological conditions thus potentially coming from different distributions e g serinaldi and kilsby 2015 sarhadi and soulis 2017 thombiano et al 2017 despite the inaccuracies in the quantitative estimation of 100 year return period hourly quantiles a consistently decreased uncertainty characterizes the mev estimates with respect to extreme value theory methods when short data records are used fig 6 in addition to this mev shows a much lower sensitivity to multiplicative errors presence of cap values in the estimates and missing of extreme values fig 8 in fact multiplicative errors represent the typical error models for remote sensing datasets tian et al 2013 and were shown to largely impact extreme value analyses marra and morin 2015 at the same time the presence of cap values in the estimates is commonly expected to severely limit extreme value analysis krajewsky and smith 2002 eldardiry et al 2015 marra and morin 2015 as well as the missing of extreme values that can be very common in satellite precipitation products due to limitations in the retrieval algorithms kidd and levizzani 2011 and to the missing of rain events due to temporal sampling issues marra et al 2017 these results strongly support the use of mev for rainfall frequency analysis based on remotely sensed datasets to our opinion however some aspects need to be taken into account before application on remote sensing datasets first the presence of estimation bias in any of the ordinary events not just on the extremes will translate into inaccuracies in the estimated quantiles fig 8 h i this means that accurate bias adjustments of the full data record would be required conversely bias in single extreme values will have only minor impact on the estimated quantiles fig 8 e h meaning that the specific adjustment of high quantiles currently adopted e g gado et al 2017 are expected to be less relevant second the seasonality meteorology of ordinary events within the wide areas covered by remote sensing precipitation datasets should be carefully investigated and the characteristics of the ordinary events should be described to ensure the use of the appropriate models as recalled in the introduction availability of long records of complete sub daily rainfall data as the ones required by mev is quite rare worldwide however the potential of the method in extracting information from short records somehow compensates for this making mev a recommended choice for all those situations in which a the record lengths are short even 10 20 years if interested in 100 year return period quantiles and b the ordinary events can be reasonably modeled known distribution more than 50 events per year in general this study underlined an increased uncertainty in mev estimates for the situations in which a small number of events per year is observed e g arid climates in principle the structure of the mev framework allows to separately consider ordinary events belonging to multiple distributions different weather types or more simply seasonality and to fully exploit the information from different distributions in the frequency analysis this would require a correct separation of the events belonging to different distributions not easy task to be done automatically and would provide groups with a smaller number of events per year thus decreasing the accuracy of the method however a careful examination of fig 9 suggests that aggregating information from multiple years into multi year blocks to produce a smaller number of largely populated blocks can potentially provide improved estimates in fact even if the available statistical information remains unchanged the operation of fitting the ordinary events distribution to a larger number of data points is subject to smaller systematic uncertainties a limit case is represented by the use of the full record to estimate the parameters of the distribution of ordinary events under the assumption of stationary conditions as shown by the results by marani and ignaccolo 2015 the analyses presented in this study are limited to weibull distributions of the ordinary events with varying scale and shape parameters further possibilities should be explored including the presence of multiple distribution types in the description of the ordinary events examination of these dependencies together with careful analysis of the characteristics of the distributions modeling ordinary events and of the yield of such distributions in terms of extremes would provide direct impact in future applications of the mev method 6 conclusions this study expands the metastatistical extreme value mev framework to the analysis of sub daily hourly rainfall using a weibull distribution to model the hourly ordinary events and ensuring their statistical independence a numerical experiment is conducted to compare the response of mev and extreme value theory methods to the use of short records the presence of measurement errors and the presence of multiple distributions of ordinary events the mev was tested on 160 hourly rain gauges representing different climates in the conus at least 60 year data records and compared to methods based on extreme value theory in the estimation of long return period 100 year quantiles from short data records 5 20 years the mev tends to underestimate the 100 year return period quantiles of hourly rainfall when 5 20 years of data are used median bias 0 75 0 85 but presents diminished uncertainties important aspects in the application of the mev are the availability of i a good model for the ordinary events here assumed after test on real data as weibull distributed and ii an adequate number of events per year in order for the ordinary events fit to be reliable when these are available the mev is able to provide information on the 100 year return period quantiles from 10 20 or even 5 years of data with significantly reduced uncertainty compared to extreme value methods at the price of a slightly augmented computational complexity thus the mev represents a viable method for the estimation of long return period quantiles from short records the synthetic experiment revealed that under ideal conditions the mev tends instead to overestimate the long return period quantiles when the number of ordinary events per year is limited the presence of ordinary events coming from multiple distributions may cause a mismatch between the mev and the extreme value theory estimates of long return period quantiles and in these situations extreme value theory estimates are characterized by extremely large uncertainties even when only 1 5 of the events comes from a different distribution in general the mev is much less sensitive than the extreme value theory methods to measurement errors both additive and multiplicative presence of cap values in the estimates such as saturations in the satellite retrieval algorithms or hail filters in weather radar based estimates and missing of extreme values these error sources together with the short data records are currently among the most challenging problems preventing remote sensing precipitation dataset from being fruitfully used for rainfall frequency analysis this study demonstrated the robustness of mev to all these sources of error strongly supporting the use of mev for rainfall frequency analysis based on remotely sensed datasets future research in this direction should focus on the aspects limiting the quantitative accuracy of mev namely the adequate modeling of ordinary events the limited number of ordinary events per year the presence of multiple distributions among the ordinary events and the sensitivity of mev to the missing of low values data availability the hourly precipitation data files used in this study were obtained from the national centers for environmental information 2017 cooperative observers program hourly precipitation dataset c hpd version 2 0 beta noaa national centers for environmental information accessed june 6 2017 competing interests the authors declare that they have no conflict of interest acknowledgments the study was partially funded by the lady davis fellowship trust project rainfreq by the israel science foundation grant no 1007 15 and by nsf bsfgrant bsf 2016953 efthymios nikolopoulos and emmanouil anagnostou were supported by eversource energy center at the university of connecticut the authors acknowledge davide zoccatelli for the helpful discussions 
801,this study expands the metastatistical extreme value mev framework to sub daily rainfall frequency analysis and compares it to extreme value theory methods in presence of short records and measurement errors ordinary events are identified based on the temporal autocorrelation of hourly data and modeled with a weibull distribution mev is compared to extreme value theory methods in the estimation of long return period quantiles from actual data 160 rain gauges with at least 60 year record in the contiguous united states and on synthetic data perturbed with measurement errors typical of remote sensing rainfall estimation mev tends to underestimate the 100 year return period quantiles of hourly rainfall when 5 20 years of actual data are used but presents diminished uncertainty when a good model of the ordinary events and adequate number of events per year are available mev is able to provide information on the 100 year return period quantiles from 10 20 or even 5 years of data with significantly reduced uncertainty 30 uncertainty for 5 year records mev estimates of 100 year return period quantiles from short records are much less sensitive than extreme value theory methods to additive multiplicative errors presence of cap values in the estimates and missing of extreme values results from this study strongly support the use of mev for rainfall frequency analyses based on remotely sensed datasets keywords sub daily rainfall frequency metastatistical extreme value long return period quantile estimation uncertainty short records dependence on data record and measurement errors 1 introduction the standard approach for the analysis of extreme rainfall frequency lies on the statistical theory of extreme values maximal rainfall amounts occurred during fixed length periods generally annual maxima series ams or values exceeding a large enough threshold peaks over threshold pot are extracted from long series of data and are statistically analyzed to characterize the distribution of the extremes coles et al 2001 extreme value theory requires the availability of large samples from independent and identically distributed data i e the number of events per year n should be n in each year and the hypothesis of convergence to a limit distribution in order to have the ams or pot to asymptotically converge to the generalized extreme value gev or the generalized pareto gp distributions respectively fischer and tippett 1928 gnedenko 1943 in common practice the identical distribution is often implicitly assumed as well as the convergence to the limit distribution while the independence of data is ensured by imposing a minimum temporal distance between events e g fukutome et al 2015 conversely the asymptotic assumption is hardly verified since the number of independent rainfall events in a year is far from being infinite koutsoyiannis 2004 in addition to this long data records are required in order to get sufficient sample of the climate and to derive accurate parameters of the sought extreme value distribution regionalization approaches in which selected properties of extreme rainfall are assumed uniform within pre defined regions and data from multiple locations within the regions are pooled together are often adopted to decrease the uncertainties related to short record lengths buishand 1991 however their application can be limited by the homogeneity requirements over wide enough regions paixao et al 2015 record length limitations are particularly emphasized when considering rainfall extremes at sub daily durations or using precipitation data derived from remote sensing observations satellite or weather radars to date records of sub daily rainfall are available from a small number of recording stations and are often short in length libertino et al 2018 from the perspective of sub daily rainfall frequency analysis vast regions of the earth are to be considered ungauged bardossy and pegram 2017 kidd et al 2017 therefore the distribution of sub daily rainfall extremes is largely unknown worldwide in great contrast to the actual need for this information in a number of real world applications information on sub daily rainfall extremes is crucial for hydrological design and risk management in fast responding systems such as mountainous urban and arid watersheds and small catchments in general morin et al 2002 ashley and ashley 2008 borga et al 2014 cristiano et al 2017 high resolution radar and satellite precipitation datasets have recently advanced in terms of resolution and accuracy and represent a potential to addressing the data gap issue of sub daily extreme rainfall analysis e g overeem et al 2009 eldardiry et al 2015 marra and morin 2015 panziera et al 2016 gado et al 2017 marra et al 2017 demirdjian et al 2018 thus far works on this aspect have highlighted important quantitative mismatches between quantile values derived from remotely sensed datasets and benchmark ground estimates particularly for long return periods this was generally associated to the short records of these datasets and to uncertainties in the remote sensing quantitative estimates in fact records from these datasets reach 30 years at most but for the recent most advanced products usually span 12 17 years this calls for new methods able to better estimate high quantiles from short data records the metastatistical extreme value mev framework recently proposed by marani and ignaccolo 2015 relaxes some of the assumptions of extreme value theory and exploits the full data record rather than a small subsample of its tail an empirical extreme value distribution is derived as a sample average of the distributions of the ordinary events occurred in each year which are sampled a varying number of times each year tested on daily rainfall records the mev method was shown to outperform extreme value theory when used to estimate return periods longer than the data record length zorzetto et al 2016 this diminishes the limitations of extreme value analysis from short data records but at present the method was only tested on daily rainfall data and its applicability to sub daily rainfall amounts still needs to be checked moreover its sensitivity to measurement errors needs to be properly investigated and understood before operational applications can be developed objective of this study is to advance knowledge and improve methodological tools for the analysis of sub daily rainfall frequency from short data records specifically we will 1 analyze the characteristics of sub daily ordinary events 2 expand the mev framework to the analysis of sub daily data 3 test the accuracy of mev in comparison to classical approaches in the estimation of long return period quantiles from short records and 4 quantify the impact of measurement errors typical of sub daily rainfall estimation and of remote sensing estimates the paper is organized as follows section 2 provides information on the study area and the used dataset section 3 describes the methods used for extreme value analysis with different approaches and the simulation of measurement errors section 4 describes the results of the study in section 5 a thorough discussion of the implications of these findings is presented together with some recommendations for future research and applications section 6 provides the main conclusions of the study 2 study area and data this study is based on hourly precipitation observations collected over the contiguous united states conus thus involving analysis of precipitation regimes with distinctly different climatologic characteristics with respect to the frequency events year seasonality and diurnal variability of precipitation brooks and stensrud 2000 hitchens et al 2013 in terms of data availability of hourly precipitation the conus constitutes an exception since a large number of in situ stations with long term hourly observations is available data in this study were collected from the cooperative observers program hourly precipitation dataset of noaa national centers for environmental information 2017 and include hourly precipitation records from more than 1900 stations covering conus since 1948 in addition to the quality check from noaa rain gauge data were further examined to exclude cases in which rainfall from multiple hours was reportedly accumulated to a single hourly interval for each rain gauge years with less than 80 available data were removed barbero et al 2017 and rain gauges with less than 60 years of quality controlled data were excluded from the analysis further quality control revealed that for many gauges the sampling resolution changed over time and data were reported over different periods based on either 0 254 or 2 54 mm h 1 i e 0 01 or 0 1 in h 1 as the minimum available resolution the presence of coarser resolution values is expected to impact the use of pot langousis et al 2016 and mev thus the years in which the coarser resolution was observed were flagged and the rain gauges with less than 30 years of high resolution i e 0 254 mm h 1 data were removed from the dataset the final dataset fig 1 consists of 160 rain gauges for which at least a 60 years of quality controlled data and b 30 years of high sampling resolution quality controlled data are available the available dataset was further divided into different climate groups fig 1 according to the koppen geiger climatic classification developed by peel et al 2007 specifically five main classes were considered and the final dataset climate group number of gauges was divided as follows bw bs desert and steppe 36 rain gauges cs mediterranean 17 rain gauges cf temperate 56 rain gauges dfa cold hot summer 32 rain gauges and dfb cold warm summer 16 rain gauges three rain gauges which each belong to a different class were grouped apart 3 methods the analysis presented in this study is organized in two parts first rain gauge data are analyzed to identify and model the hourly rainfall ordinary events and to derive rainfall frequency analysis by means of ams pot and mev the focus of this part is to evaluate these methods regarding the estimation of high quantiles from short records of actual rain gauge data in the second part a synthetic experiment is devised to quantify the impact of measurement errors and inaccurate assumptions on the estimation of long return period quantiles using ams pot and mev 3 1 identification and modeling of ordinary events ordinary events constitute the basis for the statistical modeling of rainfall frequency with mev and represent the data from which a sub sample will be used in the pot method they are defined as maximal non zero rainfall amounts observed in statistically independent rainy periods the statistical independence of ordinary events is a crucial hypothesis behind both pot langousis et al 2016 and mev zorzetto et al 2016 to ensure its validity a prudent separation of the events is developed as follows for each year of each rain gauge see fig 2 for reference i the temporal autocorrelation of the time series is calculated for time lags up to 15 days this time lag was found to be long enough to allow the autocorrelation to drop to very low values permitting to exclude any statistical and or meteorological correlation ii for each time lag the long lag noise is defined as the 75th quantile of the empirical autocorrelations observed for longer lags iii the running parameter i e the minimum time distance allowed between independent events fukutome et al 2015 is set as the time lag at which the temporal autocorrelation first becomes comparable to the long lag noise fig 2 in this way one running parameter is identified for each year of each rain gauge ordinary events are then defined as non zero rainfall peaks separated by time intervals longer or equal to the running parameter the independence of ordinary events across consecutive years is ensured requesting the first ordinary event of each year to be separated from the last of the previous year by a time distance equal to the running parameter calculated for the previous year once the ordinary events are defined their statistical properties need to be modeled marani and ignaccolo 2015 and zorzetto et al 2016 in developing the mev framework used a weibull distribution weibull 1951 to model their ordinary events simply defined as non zero daily rainfall amounts no separation was sought previous studies showed that the gamma distribution provides a good representation of sub daily rainfall variability but owing to its light tail it is not able to reproduce rainfall extremes leading to systematic errors in the estimation of long return period quantiles katz et al 2002 vrac and naveau 2007 naveau et al 2016 conversely the heavier tail of the weibull distribution is expected to be more representative of extremes also for sub daily rainfall amounts with the advantages of a parsimonious two parameter distribution wilson and tuomi 2005 the weibull cumulative distribution function can be written as 1 w x λ κ 1 e x λ κ where λ 0 is the scale parameter and κ 0 the shape parameter the representativeness of the weibull distribution for hourly rainfall ordinary events needs to be checked to do so we i identify the ordinary events in each year of each rain gauge ii fit a weibull distribution to these data series using the method of the l moments hosking 1990 that with respect to the maximum likelihood method weights more the tail of the distribution and is less sensitive to the use of small data samples sornette 2003 and iii check the goodness fit of the weibull distribution for the yearly ordinary events using the χ2 goodness of fit test at 5 significance level 3 2 rainfall frequency analysis methods this section describes the methods used for rainfall frequency analysis using extreme value theory ams and pot and the mev framework the ordinary events identified in years for which data is available with high sampling resolution 30 years records constitute the basis for frequency analyses with pot and mev whereas the ams approach is used both on the full 60 years records to define the reference for long return period quantiles and on the 30 years high sampling resolution records to check its performance on short records it should be noted that the rain gauge records are at least 80 complete within each year but gaps between years can be present 3 2 1 annual maxima series ams a gev distribution is fitted to the ams using the method of the l moments hosking 1990 the l moments method provides improved estimates of the distribution parameters in presence of short data records and is less sensitive to outliers when compared to the maximum likelihood method martins and stedinger 2000 owing to its simple application and to the requirement of records of annual maxima alone the ams is among the most used approaches for frequency analysis and provided the assumptions behind extreme value theory are verified and the data record is long enough is expected to provide accurate estimates of the long return period quantiles without the need for threshold identification of the pot 3 2 2 peaks over threshold pot the pot approach e g pickland 1975 davison and smith 1990 consists in fitting a gp distribution to the independent events exceeding a predefined high threshold independence of the ordinary events is granted by the separation procedure described above in theory the threshold should be large enough to verify the extreme value theory assumptions and at the same time small enough to provide a sufficient data sample dealing with short data records this is a particularly difficult task fukutome et al 2015 langousis et al 2016 and given the large number of applications in a monte carlo framework an automatic threshold selection is sought we chose a goodness of fit approach e g ben zvi 2016 langousis et al 2016 solari et al 2017 exploring thresholds starting from the 95th quantile of the ordinary events the threshold should be large enough and stopping before the number of pot becomes equal to the number of ams in this case the advantages of a pot approach would be lost a gp distribution is fitted to the corresponding pot using the l moments method and is tested using the anderson darling goodness of fit anderson and darling 1954 the threshold providing the best fit is selected and the corresponding gp distribution is used as a model solari et al 2017 3 2 3 metastatistical extreme value mev the mev framework derives an approximate expression for the extreme value distribution as a sample average of the yearly distributions of ordinary events the parameters of the ordinary events distributions are allowed to vary in time as well as the number of times the distributions are sampled i e the number of ordinary events in each year it is worth mentioning that the gev distribution can be obtained as a particular case of the mev zorzetto et al 2016 following the formalism by zorzetto et al 2016 the mev cumulative distribution function can be written as 2 ζ x 1 m j 1 m w x λ j κ j n j where x is the hourly rain intensity m is the number of years in the record and w x λ j κ j is the weibull cumulative distribution function see eq 1 fitted to the nj ordinary events of the j th year practically i a weibull distribution is fitted to each yearly record of ordinary events using the method of the l moments ii the mev cumulative distribution function is calculated using eq 2 iii the desired quantile is calculated numerically inverting eq 2 for a detailed description of the mev framework the reader is referred to marani and ignaccolo 2015 and zorzetto et al 2016 3 3 rainfall extremes estimation error metrics in this study we are interested in the estimation of high quantiles of hourly rainfall from short data records extreme rainfall is represented by the quantile values of the 100 year return period while 60 years of data are available only 30 years correspond to data at high gauge sampling resolution 0 254 mm h 1 change in the gauge sampling resolution affects the distribution of the ordinary events and thus does not permit the application of mev to the full available record on the other hand differences in sampling resolution have practically no effect on the annual maximum values therefore in order to obtain a reference estimate of quantiles for 100 year return period we considered the classic extreme value theory approach i e the gev fit of the ams applied to the full rain gauge records 60 years it is noted that the violation of the asymptotic assumption for the estimation of 100 year return period quantiles from records of similar characteristics was shown to be negligible by marani and ignaccolo 2015 in using this reference values one also needs to assume that the available data record is representative of the long term climatology of extremes for the sake of consistency the reference values are calculated fitting a gev distribution to the ams using the l moments method however the use of the maximum likelihood method preferable in presence of long records was tested with no appreciable impact on the results and at the price of significantly increased computation time uncertainty in the reference quantiles is quantified by bootstrapping with replacement 1000 bootstrap repetitions m random years from the full record where m is the number of available years in the record of each rain gauge overeem et al 2008 short record quantiles are estimated by randomly sampling with replacement l years with l 5 10 20 out of the 30 high sampling resolution years of the rain gauge record 1000 bootstrap repetitions the 100 year return period quantiles are then computed using the three methods two widely used non dimensional normalized metrics are used to quantify the 100 year return period quantiles estimation error the estimation error of a single iteration i is quantified using the multiplicative bias between the estimated quantile x est i and the corresponding reference x ref 3 bia s i x est i x ref where bias 0 with 1 representing the perfect match is defined for each iteration of each rain gauge the error of the 1000 iterations of each rain gauge is measured using the fractional standard error fse 4 fse 1 1000 i 1 1000 x est i x ref 2 x ref where fse 0 with 0 indicating no error is defined for each rain gauge 3 4 application to daily data application of the methods to daily data is tested in order to confirm the findings of previous works on the effectiveness of the mev method and provide an indirect validation of the method used to separate the ordinary events in fact no direct validation of the separation method can be performed on hourly rainfall hourly rainfall amounts are highly correlated in time and some kind of separation is anyway required to reasonably process the data conversely temporal correlation of daily amounts is small and often neglected hourly amounts are summed to daily blocks and ordinary events are defined in two different ways a ordinary events are defined as all the non zero daily amounts temporal correlation of daily amounts is neglected following the method by zorzetto et al 2016 b ordinary events are defined using the separation method based on temporal autocorrelation described above temporal independence is ensured following the method proposed here the 100 year return period quantiles of daily rainfall are then estimated using these two datasets 3 5 simulation of multisource uncertainty impacts aim of this synthetic experiment is to quantify the impact of a use of short records b presence of measurement errors and c presence of ordinary events coming from multiple distributions on the estimation of 100 year return period quantiles using ams pot and mev approaches the synthetic ordinary events are simulated as independent and identically weibull distributed to meet the assumptions of extreme value theory and of the mev framework it should be recalled that the extreme value theorem also assumes the convergence of the limit distribution of ams pot however this assumption cannot be directly checked or reproduced in real or synthetic data and is generally taken as granted in real applications 3 5 1 use of short records each synthetic year is simulated to have n ordinary events with n following a normal distribution with mean n µ and standard deviation n σ these parameters were modeled using the information gathered from real data as shown in the next section fig 3 with mean number of events per year n µ set to 10 50 and 100 thus representing the full range of observations and standard deviation set to n σ 0 3 n µ following the observed coefficient of variation ordinary events are randomly generated to follow a weibull distribution with shape parameter κ set to 0 8 and 1 25 representing the typical range of variability of the observed data see next section fig 4 to permit an easy interpretation of the results a standard scale parameter λ 1 with arbitrary units is used the performance of the three methods under ideal conditions is checked randomly generating 1000 repetitions records of synthetic data of varying lengths and calculating the multiplicative bias eq 3 between the 100 year return period quantiles derived from the three methods and the ones empirically obtained from an extremely long record 105 years 3 5 2 presence of measurement errors the series of synthetic ordinary events are then perturbed with i additive measurement errors ii multiplicative measurement errors iii upper cap value to the measurements iv removal of extremely high values and v removal of low values errors i and ii are among the most common models for rainfall estimation errors with ii multiplicative errors being considered the most representative for high resolution rainfall data and remote sensing estimates tian et al 2013 tang et al 2015 conversely errors iii iv and v are typical of remote sensing estimation errors iii and iv in particular are considered among the main limitations in the use of remotely sensed precipitation estimates in the analysis of extreme rainfall e g krajewski and smith 2002 examples of errors with these characteristics are the upper limit posed to weather radar estimates to avoid problems related to the extremely large reflectivity of hail stones e g marra and morin 2015 the intrinsic estimation upper and lower limits typical of satellite retrieval algorithms and the missing of extreme events due to temporal hiatuses between satellite overpasses kidd and levizzani 2011 additive errors are simulated as independent and normally distributed with mean zero and standard deviations of 5 10 and 25 of the scale parameter λ here λ 1 multiplicative errors are simulated as log normally distributed with median 1 and standard deviations of 5 10 and 25 the presence of an upper cap to the measurements is simulated choosing a high cap 99 9th 99 5th and 99th quantile of the full series of ordinary events and saturating to this cap value all the ordinary events exceeding it the same quantiles are used to simulate the missing of extreme values all the ordinary events exceeding the given quantile are removed from the dataset the same is done on the other tail of the dataset to simulate the missing of low values removing all the ordinary events lower than the 0 1th 0 5th and 5th quantiles the impact of these perturbations is quantified as relative difference δ with respect to the 100 year return period quantiles obtained using the corresponding unperturbed dataset and the corresponding extreme value method 5 δ i x est mth i x ref mth where x est mth i is the i th estimate of the 100 year return period quantile calculated using a given method ams pot or mev and x ref mth is the 100 year return period quantile calculated using the corresponding unperturbed dataset and method this allows us to quantify the net impact of the perturbations on the quantification of long return period quantiles using the three extreme value methods 3 5 3 presence of ordinary events coming from multiple distributions identical distribution of the ordinary events is among the main assumptions behind extreme value theory and mev to test the response of the three methods to the presence of ordinary events coming from multiple distributions such as rainfall seasonality or events generate by different weather types we synthetically simulate datasets of varying length in which the ordinary events are picked with varying proportions from two different weibull distributions and we calculate the 100 year return period quantiles using the three extreme value methods we examine two cases namely i uniform shape κ 1 25 and varying scale λ 1 and λ 2 and ii uniform scale λ 1 and varying shape κ 0 8 and κ 1 25 and different proportions in the number of ordinary events coming from the two distributions i e 1 99 5 95 10 90 15 85 25 75 and 50 50 in addition to the already explored 0 100 each simulation is repeated 1000 times and the impact of having multiple distributions of ordinary events on the performance of the three methods is checked using empirical quantiles extracted from an extremely long record 105 years as a reference 4 results 4 1 estimation of long return period quantiles from rain gauge records 4 1 1 ordinary events fig 3 shows the distribution among the rain gauges of a the running parameters observed for hourly data median b the number of ordinary events per year median and c the variability of the number of events per year coefficient of variation the spatial distribution of the median number of events per year is shown in d the running parameter generally ranges between 12 and 32 h but can in rare cases reach and exceed 2 days the median number of ordinary events per year ranges between 10 and 100 events year with two peaks at 30 40 and 60 75 events year the geographical distribution shows a clear sw ne gradient with low number of events per year in the sw regions 40 gradually increasing going towards ne to 60 80 events per year the number of events per year is however variable within each rain gauge data record with a coefficient of variation generally 0 2 0 4 mostly around 0 3 fig 3c no noteworthy geographic trend is observed for the coefficient of variation not shown fig 4 reports information of the weibull fit to the ordinary events a the fraction of years in which the null hypothesis of data coming from a weibull distribution was not rejected at the 5 significance level using the χ2 fit test good fit hereinafter the b scale parameters and c shape parameters obtained and d the geographical distribution of the fraction of years with good fit the weibull distribution is a good model for the yearly data in 88 of the examined years with increased proportions of goodness of fit in the sw regions with respect to the ne this distribution roughly follows the number of ordinary events per year the scale parameters of the distribution generally range up to 10 mm h 1 whereas the shape parameters range between 0 7 and 1 5 90 of the cases and rarely exceed 0 5 or 2 fig 4c the same analysis conducted with the gamma distribution not reported here for brevity showed a total fraction of good fits 84 i e 250 additional years for which the selected distribution was rejected at the 5 significance level thus pointing to the weibull as better representing hourly ordinary events 4 1 2 daily rainfall quantiles fig 5 evaluates the 100 year return period quantiles of daily rainfall as estimated using ams pot mev based on all non zero daily amounts i e method by zorzetto et al 2016 and using mev based on statistically independent ordinary events i e defined as described in this study mev clearly outperforms extreme value theory methods with largely reduced bias and fse when all the non zero daily measurements are used as ordinary events magenta the fse observed for mev estimates is significantly smaller than the one from ams and pot fig 5b confirming the value of mev in estimating return periods longer than the record length found by zorzetto et al 2016 using a rmse based metric however when this dataset is used a systematic tendency towards underestimation of the 100 year return period quantiles can be noticed fig 5a it should be recalled here that no true reference for the 100 year return period quantiles is available so the presented results rely on the 60 ams estimates considered as reference conversely when independent ordinary events are used i e using the here presented separation method mev estimates red are quantitatively improved and able to provide improved estimates of the 100 year return period daily quantiles even from 5 year data records with distribution of biases largely overlapping the one obtained resampling the full 60 year data records black the advantage of using mev with respect to ams and pot becomes even more pronounced as the record length decreases bias in the estimation of 100 year return period quantiles from 5 year of data range in 0 6 1 3 versus the 0 45 2 of ams and pot 4 1 3 hourly rainfall quantiles the evaluation metrics obtained for the estimation of 100 year return period quantiles from short records are reported in fig 6 we recall that the bias statistics are shown for each of the 1000 repetitions done for each rain gauge while one fse is calculated for each rain gauge as a measure of the standard error of the 1000 repetitions in general the estimates from ams and pot show very similar patterns of bias and fse whereas important differences are observed for mev focusing on the full dataset all the bias of the full record ranges between 0 8 and 1 1 indicating that roughly 30 uncertainty is to be expected on the 100 year return period quantiles even when the ams method is used on the full 60 years rain gauge record using short records estimates from ams and pot are characterized by wide distributions of multiplicative bias roughly centered around 1 conversely mev tends to underestimate reference values but is characterized by narrower estimation error distributions for 5 and 10 year records this underestimation slightly decreases increasing the record length similar results are reported for the fse which for 5 and 10 year records is smaller for the mev than for ams and pot conversely large variability is visible for 20 year mev estimates looking at the results for different climates one notes that mev severely underestimates the 100 year return period quantiles i e the 5 95 interval does not include 1 for the dfb climatic class cold warm summer 10 of the gauges and underestimates the 100 year return period quantiles on bw bs cs and dfa climatic classes arid semiarid mediterranean cold hot summer 53 good quantitative estimates from the mev are reported for the cf climatic class temperate 35 it should be noted how the performance of ams and pot remains similar among different climates when using short records the bias on 100 year return period quantiles derived from these methods typically range between 0 5 and 2 for 5 year 0 6 1 6 for 10 year and 0 7 1 3 for 20 year records despite the systematic underestimation related to mev estimates in most of the climates the method is able to estimate the 100 year return period quantiles within the accuracy range of the extreme value theory methods with the exception of dfb climates in general the bias on 100 year return period quantiles derived from mev ranges between 0 45 and 1 2 even for 5 year records it is worth noting the cs mediterranean climatic class in which also ams estimates are underestimated this can potentially be related to differences in rainfall distribution between the short record 30 records and the reference 60 records but investigating possible temporal trends in the data is beyond of the scope of this study 4 2 numerical experiment results 4 2 1 estimation of long return period quantiles from short synthetic records we present here the results of the synthetic simulation run under ideal conditions for the assumptions of extreme value theory and mev independence identical weibull distribution of the ordinary events convergence a total of 1000 randomly generated series of ordinary events of varying lengths from 3 to 50 years are used to estimate the 100 year return period quantiles in this experiment the reference is provided by the 100 year return period quantiles empirically obtained from 105 years of data fig 7 reports the multiplicative bias 5 95th quantile interval between the quantiles obtained using the three methods and the empirical reference important variability emerges for ams and pot in particular for heavier tailed distributions of the ordinary events 40 50 uncertainty for κ 0 8 even when 50 year records are available mev tends to systematically overestimate the 100 year return period quantiles with respect to the empirical quantiles derived from 105 years of data but presents a largely reduced variability in particular for larger average n the overestimation is due to uncertain estimation of the weight of the tail of the ordinary events distribution when few data points are used for the fit sornette 2003 this is confirmed in fig 7 d h in which for large number of events per year 1000 the mev estimates are shown to converge to the 105 year reference despite this systematic behavior mev is shown to outperform the extreme value theory methods when the number of events per year is large enough e g 50 events per year uncertainty is largely reduced and even 3 years of data are able to provide information comparable to 50 years of data of extreme value theory methods 4 2 2 impact of measurement errors the impact of measurement errors typical of remote sensing rainfall estimation additive and multiplicative errors upper cap value missing of extreme high events missing of low intensity events on the estimation of the 100 year return period quantiles of hourly rainfall 5 95th quantile interval of the 1000 repetitions is presented in fig 8 we recall that the impact is presented here with respect to the corresponding method on the error free data as reported in eq 5 results are reported for record lengths of 5 and 20 years it is noted that the methods based on extreme value theory ams pot show similar responses to measurement errors thus except when explicitly stated will be discussed together the impact of additive errors on extreme value theory methods consists in a random dispersion of the estimates around the reference value fig 8 a b unexpectedly no clear dependence on the magnitude of the error is observed a minor decrease of the dispersion with a larger number of events per year can be noted nevertheless the width of the dispersion is larger for heavier tailed distributions of the ordinary events smaller κ in general the dispersion of pot estimates is slightly wider than the one of ams estimates conversely the impact of additive errors on mev estimates shows a systematic tendency towards underestimation that increases with increased error magnitudes and that is larger for heavier tailed distributions of the ordinary events the dispersion is larger for smaller number of events per year and seems not to depend on the error magnitude as for multiplicative errors a systematic tendency towards overestimation is reported for all the methods when the errors are large enough 25 fig 8 c d it is interesting to notice that the mev is less sensitive to this kind of errors than extreme value theory methods showing smaller systematic and random components completely different responses are observed when upper cap values are imposed to the data fig 8 e f or when extreme values are removed from the data series fig 8 g h extreme value theory methods are highly sensitive to these errors with immediate systematic underestimations already for very high caps limit values heavier tailed distributions of ordinary events are more affected mev estimates are almost not sensitive to this kind of errors with the worst case scenario being 20 underestimation when the top 1 values of the data series are missed in climates with an average of 10 events per year conversely mev estimates can be sensitive to the missing of low values from in the data series whereas extreme value theory methods are obviously almost untouched by this kind of estimation error fig 8 i l heavier tailed distributions of ordinary events are more affected with up to 30 systematic underestimation in case the lowest 5 of the ordinary events are missed it should be here noted that the simulations were carried out for a larger number of shapes of the weibull distribution namely 0 5 0 7 1 1 5 and 2 and for small variability in the number of events per year i e using n σ 0 05 n µ the results not reported here for brevity showed no appreciable dependence on n σ and a monotonic dependence on the shape parameter so that information on distributions characterized by different shapes can be easily derived from the here presented results 4 2 3 multiple distributions of ordinary events the impact of the presence of multiple distributions among the ordinary events is presented in fig 9 we should recall that this situation explicitly violates the assumptions of extreme value theory and mev even if the mev formulation provides the potential to include multiple distributions in the analysis fig 9 a c show the different estimates of the 100 year return period quantiles obtained when the ordinary events are sampled in varying proportions from two distributions characterized by the same shape parameter and different scales whereas fig 9 d f show the results from two distributions characterized by the same scale parameter and different shapes the figure shows a different response between extreme value theory methods and mev in particular for situations in which the majority of the events come from a lighter tailed or lower scaled distribution left side of the panels when a large number of events is observed in a year fig 9 c f the presence of just 1 of events from a heavier tailed or higher scaled distribution i e on average 1 event every year immediately affects the 100 year return period quantiles estimated by extreme value theory and when 25 of heavier tailed distribution events are present the heavier tailed distribution fully dominates the estimation of extremes from extreme value theory conversely in the mev case a much slower response is observed with a rather smooth transition from the light tail scale to the heavy tail scale estimation of the high quantiles as shown by the different under and overestimation biases observed with respect to the reference quantiles these differences are expected to affect the estimation of high quantiles both from extreme value theory and mev in situations in which the ordinary events are sampled from multiple distributions in particular some proportions of the parameters actually lead to underestimated quantiles from the mev estimation despite the proneness to overestimation reported in fig 7 moreover it should be noted that extreme value theory methods are sensitive to the presence of multiple distributions of ordinary events also in terms of uncertainty i e the length of the 5 95th quantile interval bars with large uncertainties rising from the presence of only 5 of the events from a heavier tailed or higher scaled distribution 5 discussion the estimation of long return period rainfall amounts is a challenging task particularly for hourly time scales even in ideal conditions in which the validity of the assumptions of extreme value theory independence and identical distribution of rainfall events long records are ensured methods based on extreme value theory show large uncertainties in the estimation of long return period quantiles fig 7 despite the use of different baseline periods for the short record sampling 30 years dataset and for the reference 60 years dataset the estimates from extreme value methods were consistent within the large uncertainties associated to the short record estimates when dealing with actual data 160 quality controlled rain gauges within conus fig 1 roughly 30 uncertainty is exhibited on the 100 year return period quantiles of hourly rainfall derived from 60 year data records and extreme value theory fig 6 this uncertainty is slightly larger 35 for daily rainfall quantiles fig 5 when dealing with short data records only a small number of data points is available to fit the extreme value distributions so that very large uncertainties characterize extreme value theory methods on short records figs 5 and 6 this study also points out how the results obtained for ams and pot are basically indistinguishable throughout the analyses this is quite unexpected since an optimal use of pot is expected to improve the accuracy in the estimates of high quantiles from shorter records madsen et al 1997 but was already reported by other studies schlögl and laaha 2017 the pot method even after application of state of the art procedures for the threshold selection laugousis et al 2016 solari et al 2017 did not outperform the ams approach we claim that at the price of augmented data pre processing and increased computational complexity the mev framework does represent a viable method for the estimation of long return period quantiles from short data records fig 7 the results of zorzetto et al 2016 showing that mev outperforms extreme value theory methods when applied to a wide set of daily rainfall observations are here further improved by granting the statistical independence of ordinary events fig 5 application of the mev method to 5 years of actual daily data will provide an estimate of the 100 year return period quantiles with less than 20 40 error in more than 50 90 of the cases in light of these results we contrast the common approach to frequency analysis claiming that when the distribution of ordinary events is known and the number of ordinary events per year is large enough 50 events per year reasonable information on 100 year return period quantiles can be provided by 10 20 or in some cases even 5 years of data nevertheless synthetic simulations based on ideal conditions show a systematic overestimation of the 100 year return period quantiles derived using the mev fig 7 this is due to an overestimation of the tail of the distribution of the ordinary events within the weibull fit and is shown to decrease when the number of events per year is large enough fig 7 unfortunately dealing with sub daily rainfall amounts the amount of independent ordinary events per year is limited to numbers usually lower than 100 so that this problem needs to be considered when using this method different results were reported by marani and ignaccolo 2015 who in a similar experiment showed no systematic bias in the mev estimates however the authors in that study derived the weibull parameters using the full data record rather than the yearly series so the data sample used to estimate the parameters in marani and ignaccolo 2015 always exceeded 1000 this suggests that aggregating data from multiple years to obtain the parameters for the ordinary events distributions represents a viable way to decrease this systematic effect when exploring large quantiles of hourly rainfall from real datasets the mev performance is characterized by larger inaccuracies than the ones observed with synthetic data in fact despite what reported for ideal conditions application of the mev framework to actual data tends to underestimate the 100 year return period quantiles fig 6a in this sense a strong dependency on the examined climatic conditions is noticed fig 6 an important role in shaping this behavior could be played by the assumption of identical distribution of the ordinary events the assumption is required by both mev and extreme value theory however the response of the different methods to violations of this assumption is shown to be largely diverse fig 9 in fact the co presence of ordinary events sampled from multiple distributions causes a mismatch between the high quantiles estimated by extreme value theory methods and by mev this mismatch depends on the proportion of events from the different distributions on the average number of ordinary events per year as well as on the characteristics of the ordinary event distributions moreover the co presence of ordinary events sampled from multiple distributions causes large uncertainties in the long return period quantiles derived from extreme value theory methods this is particularly enhanced in the case of varying scale parameter in general the co presence of ordinary events sampled from multiple distributions can be caused by the occurrence of different meteorological synoptic conditions on the studied location a classic example of this is the seasonality of precipitation as a proof of concept fig 10 shows the bias on the 100 year return period quantiles of summer june july august jja hourly rainfall for two climates in which the underestimation reported in the hourly quantiles fig 6 was particularly important i e bw bs arid and dfb cold warm summer when considering the summer season alone the underestimation almost disappears this confirms the idea that seasonality and more in general the presence of multiple meteorological conditions generating rainfall over the location of interest are aspects that need to be carefully considered in the application of the mev framework these aspects need to be adequately considered also when examining possible non stationarity in rainfall extremes caused by varying proportions of ordinary events generated from different meteorological conditions thus potentially coming from different distributions e g serinaldi and kilsby 2015 sarhadi and soulis 2017 thombiano et al 2017 despite the inaccuracies in the quantitative estimation of 100 year return period hourly quantiles a consistently decreased uncertainty characterizes the mev estimates with respect to extreme value theory methods when short data records are used fig 6 in addition to this mev shows a much lower sensitivity to multiplicative errors presence of cap values in the estimates and missing of extreme values fig 8 in fact multiplicative errors represent the typical error models for remote sensing datasets tian et al 2013 and were shown to largely impact extreme value analyses marra and morin 2015 at the same time the presence of cap values in the estimates is commonly expected to severely limit extreme value analysis krajewsky and smith 2002 eldardiry et al 2015 marra and morin 2015 as well as the missing of extreme values that can be very common in satellite precipitation products due to limitations in the retrieval algorithms kidd and levizzani 2011 and to the missing of rain events due to temporal sampling issues marra et al 2017 these results strongly support the use of mev for rainfall frequency analysis based on remotely sensed datasets to our opinion however some aspects need to be taken into account before application on remote sensing datasets first the presence of estimation bias in any of the ordinary events not just on the extremes will translate into inaccuracies in the estimated quantiles fig 8 h i this means that accurate bias adjustments of the full data record would be required conversely bias in single extreme values will have only minor impact on the estimated quantiles fig 8 e h meaning that the specific adjustment of high quantiles currently adopted e g gado et al 2017 are expected to be less relevant second the seasonality meteorology of ordinary events within the wide areas covered by remote sensing precipitation datasets should be carefully investigated and the characteristics of the ordinary events should be described to ensure the use of the appropriate models as recalled in the introduction availability of long records of complete sub daily rainfall data as the ones required by mev is quite rare worldwide however the potential of the method in extracting information from short records somehow compensates for this making mev a recommended choice for all those situations in which a the record lengths are short even 10 20 years if interested in 100 year return period quantiles and b the ordinary events can be reasonably modeled known distribution more than 50 events per year in general this study underlined an increased uncertainty in mev estimates for the situations in which a small number of events per year is observed e g arid climates in principle the structure of the mev framework allows to separately consider ordinary events belonging to multiple distributions different weather types or more simply seasonality and to fully exploit the information from different distributions in the frequency analysis this would require a correct separation of the events belonging to different distributions not easy task to be done automatically and would provide groups with a smaller number of events per year thus decreasing the accuracy of the method however a careful examination of fig 9 suggests that aggregating information from multiple years into multi year blocks to produce a smaller number of largely populated blocks can potentially provide improved estimates in fact even if the available statistical information remains unchanged the operation of fitting the ordinary events distribution to a larger number of data points is subject to smaller systematic uncertainties a limit case is represented by the use of the full record to estimate the parameters of the distribution of ordinary events under the assumption of stationary conditions as shown by the results by marani and ignaccolo 2015 the analyses presented in this study are limited to weibull distributions of the ordinary events with varying scale and shape parameters further possibilities should be explored including the presence of multiple distribution types in the description of the ordinary events examination of these dependencies together with careful analysis of the characteristics of the distributions modeling ordinary events and of the yield of such distributions in terms of extremes would provide direct impact in future applications of the mev method 6 conclusions this study expands the metastatistical extreme value mev framework to the analysis of sub daily hourly rainfall using a weibull distribution to model the hourly ordinary events and ensuring their statistical independence a numerical experiment is conducted to compare the response of mev and extreme value theory methods to the use of short records the presence of measurement errors and the presence of multiple distributions of ordinary events the mev was tested on 160 hourly rain gauges representing different climates in the conus at least 60 year data records and compared to methods based on extreme value theory in the estimation of long return period 100 year quantiles from short data records 5 20 years the mev tends to underestimate the 100 year return period quantiles of hourly rainfall when 5 20 years of data are used median bias 0 75 0 85 but presents diminished uncertainties important aspects in the application of the mev are the availability of i a good model for the ordinary events here assumed after test on real data as weibull distributed and ii an adequate number of events per year in order for the ordinary events fit to be reliable when these are available the mev is able to provide information on the 100 year return period quantiles from 10 20 or even 5 years of data with significantly reduced uncertainty compared to extreme value methods at the price of a slightly augmented computational complexity thus the mev represents a viable method for the estimation of long return period quantiles from short records the synthetic experiment revealed that under ideal conditions the mev tends instead to overestimate the long return period quantiles when the number of ordinary events per year is limited the presence of ordinary events coming from multiple distributions may cause a mismatch between the mev and the extreme value theory estimates of long return period quantiles and in these situations extreme value theory estimates are characterized by extremely large uncertainties even when only 1 5 of the events comes from a different distribution in general the mev is much less sensitive than the extreme value theory methods to measurement errors both additive and multiplicative presence of cap values in the estimates such as saturations in the satellite retrieval algorithms or hail filters in weather radar based estimates and missing of extreme values these error sources together with the short data records are currently among the most challenging problems preventing remote sensing precipitation dataset from being fruitfully used for rainfall frequency analysis this study demonstrated the robustness of mev to all these sources of error strongly supporting the use of mev for rainfall frequency analysis based on remotely sensed datasets future research in this direction should focus on the aspects limiting the quantitative accuracy of mev namely the adequate modeling of ordinary events the limited number of ordinary events per year the presence of multiple distributions among the ordinary events and the sensitivity of mev to the missing of low values data availability the hourly precipitation data files used in this study were obtained from the national centers for environmental information 2017 cooperative observers program hourly precipitation dataset c hpd version 2 0 beta noaa national centers for environmental information accessed june 6 2017 competing interests the authors declare that they have no conflict of interest acknowledgments the study was partially funded by the lady davis fellowship trust project rainfreq by the israel science foundation grant no 1007 15 and by nsf bsfgrant bsf 2016953 efthymios nikolopoulos and emmanouil anagnostou were supported by eversource energy center at the university of connecticut the authors acknowledge davide zoccatelli for the helpful discussions 
802,the pollution pressures on coastal waters predominantly come from the river freshwater transport and loadings of contaminants into the estuary this study presents the probabilistic model of the near field solute transport in an estuary based on the spatially integrated concentration statistics a methodology is presented for quantifying the degree of dilution within the surface layer in terms of expected mass and volume fraction functions as a simple alternative to the point concentration probability density function the theoretical prediction is experimentally validated using the salinity dilution as an inverse process in the field case of river žrnovnica near the city of split a novel dilution measure is presented as combination of expected mass and volume fraction indicating the area of an estuary where dilution process will attenuate the concentration of a passive contaminant below any selected environmental limits introduced dilution measure directly corresponds to different catchment loadings through the river as a hydrological pathway of mass transport and can be used for assessing water quality status for transitional water bodies and to guide future efforts for monitoring potential eutrophication hot spots in the coastal area keywords dilution measure solute transport in estuary expected mass and volume fraction 1 introduction the problem addressed in this paper is the river freshwater transport and mass loadings in an estuary or coastal waters environments reflecting the entire upstream catchment anthropogenic activities the pollution pressures of the coastal waters by the river discharge of contaminants into the estuary and their impact on the marine ecosystem has become a growing problem throughout the world destouni et al 2008 riddle and lewis 2000 tseng 2002 rivers are considered as one of the most influential hydrological pathways for the waterborne mass flows of nutrients and pollutants to the estuaries these environmental flows are in a turbulent state of motion generally unsteady and spatially inhomogeneous playing a dominant role during the mixing and dilution of contaminants chatwin and allen 1985 gurka et al 2010 the mixing is mainly generated by the river discharges creating a seaward transport which tends to float over the denser seawater under the stratified condition most mixing activities are restricted to the upper layer ji et al 2007 close to the river mouth the turbulent eddies in the horizontal plane cause a contaminant to spread with time more rapidly in the seaward direction since the current along the river discharge is greater than transverse shear across the flow during the time of a weak stratification the contaminants may also be transported into greater depths bringing additional vertical mixing to the contaminant plume moving away from the river mouth the wind induced currents tides and internal density variations provide additional mixing mechanisms contributing to the reduction of the freshwater inflow velocity and causing even faster dilution in the porous media the quantification of dilution process for solute clouds as opposite of spreading was proposed by kitanidis 1994 using an entropy based metric denoted as a dilution index the dilution index gives a measure of the volume defined by the concentration spatial variance occupied by the solute cloud as it evolves due to the advection and diffusion processes several other studies followed the work by kitanidis 1994 analyzing different impacts on the dilution index coming from geologic heterogeneity flow topology and reactive transport characteristics chiogna et al 2011 2012 de barros et al 2015 kapoor and kitanidis 1998 rolle et al 2009 for environmental flows in general one would investigate the probability density function pdf of concentration as it evolves in time at each location in space to quantify the concentration field however this is a difficult task since the equations that govern pdf evolution are intractable in even the simplest turbulent flows and its measurement in environmental flows is challenging gurka et al 2010 sarathi et al 2010 the main problem with the conventional measure of dilution is requirement of a large number of realizations for a point pdf and or its lower order moments estimation when relying on numerical solutions therefore a measure which would converge with fewer realizations and be less sensitive to experimental numerical spatial and temporal resolution is desired in the atmospheric turbulent diffusion problems the concept of expected mass fraction emf was introduced by sullivan and ye in sullivan and ye 1993 by performing a spatial integration of the point concentration pdf heagy 1994 introduced the concept of the expected mass fraction as a function of the spatial coordinates after performing temporal integration of the concentration pdf andricevic et al 2012 implemented the emf as a function of spatial coordinates in the subsurface transport with its application to the human health risk assessment problem in the case of spatial integration the emf expresses the distribution of release mass over different concentrations at a given time this can be seen as the state of a cloud plume in terms of contaminant concentration values as it evolves in time this study addresses the problem of near field mixing and dilution process nearby the river mouth where pollution pressure may affect the water quality of marine ecosystem subject of an assessment required by the eu water framework directive european 2000 this paper is presenting the extension of the emf to the expected volume fraction evf concept and introduce a new dilution measure for the river transported pollutants in estuaries as a methodology to assess the dilution process of passive contaminants the theoretical development is demonstrated in the field case of an estuary in the vicinity of the city of split in section 2 we present the emf background concept and demonstrate key features of its possible application in the considered problem in section 3 we introduce the concept of expected volume fraction to augment the emf with additional information for the dilution process and in section 4 we derive the spatially integrated concentration moments needed for the evaluation of the emf and evf with a demonstration in an illustrative example finally section 5 presents the field case study of the river žrnovnica estuary and demonstrates the application of the developed methodology with introduction of a dilution measure which can be used to assess the water quality status in estuaries and coastal waters 2 the emf background the concept of emf sullivan and ye 1993 can be simply described by considering a contaminant cloud at time t with conserved release mass m the finite range of concentration between 0 and source concentration c 0 is divided into a number of non overlapping discrete intervals the mass c x t d v x is found by summing all volume elements d v x of the cloud with concentration values within a given interval the sum of the mass found in all intervals is equal to m an average is obtained by repeating this procedure for the release of many clouds the average mass found in each interval is divided by the concentration interval to make this a density function the expected mass fraction f c t or a cloud averaged dilution pdf sullivan and ye 1993 is therefore defined by 1 f c t 1 m v c p c x t d v where v denotes all space m v c x t d v is the conserved mass and p c x t stands for p r o b c c x t c d c it is easily shown that f c t behaves as a pdf and has its absolute moments 2 m n t 0 c n f c t d c 1 m m n 1 x t d v which are related to the spatially integrated absolute moments m n c n p c x t d c the emf f c t can be obtained by inversion of lower order moments m n t f c t dc is the expected fraction of the release mass found in the concentration interval c to c d c at time t since there is no spatial reference in f c t one expects significantly fewer realizations for its convergence than for the distributed measure such as m n x t for each cloud release in numerical or field tests a mass fraction can be determined as follows 3 f c t 1 m v c x t δ c x t c d v such that ensemble average of f c t equals f c t variations of f c t about f c t is expected to be reasonably small since in each realization concentration values throughout the entire cloud are used in the compilation of f c t ye 1995 the f c t can account for any particular flow conditions e g buoyancy effects unsteadiness or irregular boundaries or the type of scalar contaminant the only requirement is that release mass m be conserved in a case where release mass is not conserved for example where continuous release or chemical reactions are present one would simply replace m with m t smith 2004 very important interpretation of the emf is in the environmental flow where pollution is discharged into the environment e g air pollution or discharge into coastal zone and estuaries the fraction of release mass that exceeds an environmental threshold c on average at time t can be defined as 4 f c t c f c t d c this fraction of the release mass above some threshold is reduced with time indicating the dilution mechanism of the environment the another aspect of the dilution process would be the volume occupied with f c t 3 expected volume fraction evf cloud averaged pdf introduced in chatwin and sullivan 1990 defines a total distribution indicating the problem of thresholding and the fact that c 0 for all x and t 0 to overcome the threshold issue we introduce a practical approximation by introducing the estimated volume containing the most of the released mass such that the expected volume fraction can be defined as 5 g c t 1 v c v c p c x t d v where vc is selected to be sufficiently large that v c m 1 x t d v m and can be estimated on average using the multiples of the concentration spatial variance g c t behaves as a pdf and has the absolute moments 6 m n t 0 c n g c t d c 1 v c 0 c n p c x t d v d c 1 v c m n x t d v which are related to the spatially integrated absolute moments of the point concentration pdf the evf like emf can be obtained by inversion of the lower order moments m n t unlike emf the evf moments are related to the same order with absolute moments of the point concentration pdf the interpretation of the evf is related to the volume in the environment occupied with the source solute above some concentration threshold c as 7 g c t c g c t d c thus the state of the solute concentration within the cloud or plume in terms of occupied volume can be readily found for any concentration level desired this information together with emf can be combined to estimate temporal dilution process measured through the volume fraction that remains still endangered above a certain concentration level in case of accidental spills and the risk assessment studies this can be used to estimate the self purification time needed to satisfy some environmental limits in order to evaluate the emf and evf through 2 and 6 we need to perform the spatial integration of point concentration pdf absolute moments 4 spatially integrated statistics most environmental flows are in a turbulent state of motion unsteady and inhomogeneous these features are playing a dominant role in mixing and spreading of contaminants spatial integration of different concentrations statistics eliminates spatial reference resulting in fewer realizations needed for the ensemble averaging integrating the point pdf over all space and using a center of mass reference frame avoids some closure pitfalls along with problems of velocity field variations performing the spatial integration of the concentration absolute moments derived from the advection diffusion equation andricevic 1998 chatwin and sullivan 1990 smith et al 1999 sullivan 2004 the exact equation for all types of environmental flows is 8 t v m n 1 x t d v n n 1 e m v c n 1 x t c x t 2 d v n 1 where overbar denotes ensemble averaging and velocity field does not appear explicitly in 8 the integral on the right hand side is intrinsically positive and clearly shows that molecular diffusion em is the only means by which the concentration is reduced and thus the only mechanism contributing to the dilution process the closure condition on the term c n 1 c 2 that appears under the integral over all space is expected to be less sensitive to approximation than closures commonly used in the partial differential equations that govern p c x t since the significant values of c 2 occurs predominantly at the surface areas of thin sheets and strands within which the most of the source mass is located the geometrical approximation moseley 1991 has been widely used 9 c 2 c c t λ 2 2 where concentration dependence on x t is suppressed from hereafter and λ is an effective small scale representing sheets and strands in the porous media it represents a macroscopic scale larger than pore scale but smaller than heterogeneity scale andricevic 1998 while in other environmental flows under high reynolds number it represents a small length scale also known as conduction cut off length of order 10 4 m for rivers and estuaries chatwin and sullivan 1979 the threshold concentration ct is behaving in the limit as ct 0 as t 0 and c t c m as t where c m is the largest value of the mean concentration using 9 the spatially integrated moment equation for n 1 becomes 10 t v m n 1 d v n n 1 e m λ 2 v c n 1 2 c n c t c n 1 c t 2 d v denoting k n t v m n x t d v and introducing the non dimensional time scale τ e m λ 2 t equation 10 becomes first order differential equation for spatially integrated concentration moments 11 k n 1 τ τ k k n 1 τ k 2 k n τ c t τ k n 1 τ c t 2 τ n 1 where k n n 1 eq 11 can be solved recursively as 12 k n 1 τ e k τ k 0 τ 2 k n τ c t τ k n 1 τ c t 2 τ e k τ d τ k n 1 0 n 1 by setting n 1 in 12 and using c t c one obtains 13 τ k 2 2 k 2 2 c 2 d v which by splitting k 2 σ c 2 d v c 2 d v yields the total concentration fluctuation equation also used in porous media in andricevic 1998 eq 16 4 1 an illustrative example consider the case of a line source like in river dominated estuary with a steady uniform mean flow velocity u in the stream wise direction x and with the across plume direction y fig 1 the modified emf sarathi et al 2010 and evf are 14 f c x l 1 c p c x y d y g c x v c 1 p c x y d y where l c x y d y is a steady mass loading of the solute through the plane normal to the flow direction x and v c 2 κ σ y where σ y 2 is a spatial transversal concentration variance and κ denotes the multiple integer selected to satisfy l we assume the gaussian one dimensional distribution for cross sectional profiles commonly considered to wakes jets and plumes andricevic 1998 fischer et al 1979 sawford and sullivan 1995 sullivan 2004 and also used for the river discharges to the estuary galesic et al 2016 15 c y x l σ y 2 π e y 2 2 σ y 2 where σ y 2 2 e t t σ y 0 2 x u t et is the constant spatial variance growth rate equivalent to a turbulent diffusivity and σ y 0 2 represents the initial variance at x 0 using 11 we now define cross sectionally integrated concentration moments k n τ v m n x τ d v where τ e m x λ 2 u and d v d x d y d z is available volume as depth integrated surface slice which is δx wide in the stream flow direction x and 2κσy wide in a transversal direction y thus the first two spatially integrated moments are k 0 τ 2 κ σ y δ x and k 1 τ l the next few moments can be easily evaluated using a recursive solution in 12 fig 2 a shows the behavior of the first three moments of the expected mass fraction m n τ while fig 2 b compares the second third and fourth spatially integrated moments kn as a function of dimensionless time τ in both cases the moments are showing the expected diminishing behavior as τ increases the obtained emf and evf moments are further used for illustrative purposes to construct f and g using two parameters beta distribution de barros and fiori 2014 bellin and tonina 2007 mole 2010 sawford and sullivan 1995 smith 2004 sullivan 2004 fig 3 a and b exhibits their behavior for the considered illustrative example the mass fraction pdf shows the shift from the initial time near source cross sections where most of the mass is around the source maximum concentration towards the lower concentration values as a result of the stronger dilution process when τ increases for example the cross section corresponding to τ 2 0 has most of the mass with the concentration values around one tenth of the initial value similar behavior can be seen from fig 3 b where the volume fraction shows the similar shift as τ increases when looking the volume fraction occupied with the released mass flux it is interesting to note that at the early time or close to the source cross sections the evf exhibits u shaped pdf indicating that diffusion is very weak near the source and the mass is predominantly concentrated in stretched sheets and strands advection dominated process at farther cross sections from the source the evf shows that volume occupied with the source solute will exhibit lower concentration values 5 the žrnovnica river estuary field case to demonstrate the comparison of our theoretical results and estimate dilution process in the field situation we select the žrnovnica river estuary located near the city of split where we have conducted several monitoring sessions measuring salinity temperature density and sea currents fig 4 just upstream from the river mouth there is an uncontrolled landfill creating a severe pollution hazard for the žrnovnica estuary which is more pronounced with a rather small river discharge annual average 2 m3 s this area has already recorded pollution events due to the anthropogenic activity which makes this estuary a vulnerable ecosystem margeta and barić 2001 more details about morphology and bathimetry of the žrnovnica estuary is given in galesic et al 2016 in the near field of river dominated stratified estuaries savenije 2005 the mixing is mainly generated by the river discharge creating a seaward transport which tends to float over the more dense seawater away from the river mouth the tides and wind induced currents start to influence mixing processes and reduce the freshwater inflow velocity we are investigating the žrnovnica discharge to the coastal water as a river dominated estuary with a non uniform mean velocity in x direction u x u 0 e ν x where u 0 is the cross sectionally averaged velocity at the river mouth and ν m 1 is an attenuation coefficient representing different mechanisms that combined progressively reduce u in the seaward direction galesic et al 2016 using t x u u u x 0 0 eq 8 for n 1 becomes 16 x u o e ν x v m n 1 d v n n 1 e m λ 2 v c n 1 2 c n c t c n 1 c t 2 d v applying the notation k n x v m n x x u d v 16 is expressed for n 1 as 17 k n 1 x x k α u o e ν x k n 1 x k α u o e ν x 2 k n x c t x k n 1 x c t 2 x which has a recursive solution in the form 18 k n 1 x e k α u o ν e ν x 1 k α u 0 0 x 2 k n x c t x k n 1 x c t 2 x e k α u o ν e ν x 1 ν x d x k n 1 0 where α e m λ 2 and initial values for cross sectionally integrated concentration moments for n 1 are defined as see appendix a for details 19 k n 1 0 l n 1 σ y 0 2 π n e r f κ 2 where l m b u 0 is defined by steady mass flux m river mouth width b and the initial velocity u 0 analyzing the current anthropogenic activity and future planned development in the žrnovnica catchment we have estimated the averaged mass flux of a total nitrogen delivered by river to the estuary to be around 50 grams per second g s with an annual average flow rate of 2 m3 s other parameters used are based on the previous hydrodynamic analysis of the river žrnovnica galesic et al 2016 as follows b 14 m u 0 0 4 m s and ν 0 002 m 1 in fig 5 a and b the emf and evf are presented respectively both expected fraction characteristics of the mass and volume are showing a shift towards lower concentration values moving away from the river mouth to the cross sections up to the 800 m from the source it is interesting to examine the emf in fig 6 where the effect of considering a non uniform mean velocity is shown close to the river mouth the attenuation of the mean velocity is very small and dilution is predominantly due to the molecular and turbulent diffusivity however moving in the seaward direction the wind induced currents are reducing the river discharge velocity which is contributing to the dilution process by further lowering concentration values at farther cross sections in contrast to the uniform mean velocity solution the estimated degree of mean velocity reduction by the attenuation coefficient for the river žrnovnica has been given in galesic et al 2016 for the thorough verification of our probabilistic approach one would need a large number of realizations of the tracer tests although much less than in the case of the point concentration pdf in order to verify spatially integrated concentration moments here we made an attempt to use the salinity measurements on two cross sections from the river mouth see fig 4 and compare the sea water dilution as an inverse process to the river transport by the freshwater discharge this inverse analogy is introduced due to the salinity being effectively reduced at the river mouth and then gradually increased back to the initial sea salinity level at some distance seaward while passive solute concentration exhibits the highest value at the river mouth and then gradually reduces in the seaward direction salinity measurements were collected with the sbe 37 si microcat probe on 30th of december 2015 at low tide 0 06 m amplitude at wind speed around 3 m s wind blowing from ne direction and the river discharge flow rate was 0 7 m3 s the probe was fixed in the surface layer 10 20 cm for 10 min with 6 s sampling resolution resulting in 100 measurements per sampling point fig 4 defines positions and number of salinity measurements the salinity measurements were inversely used as a proxy for a normalized concentration in the surface layer as 20 c p x t 1 s x t s m i n s m a x s m i n where s x t is the measured salinity at sampling points smin is the salinity measured at the river mouth and smax represents the sea salinity in the estuary the standard point moments of proxy concentration are calculated from 100 samples over the 10 min sampling interval at each spatial sampling point and then spatially integrated along the cross sections 93 m and 200 m see fig 4 away from the river mouth to deliver corresponding k 2 and k 3 fig 7 a and b show the comparison of the emf pdf evaluated using proxy concentration measurements with the emf pdf evaluated from analytically obtained moments although much more transversal points of salinity data would be more preferable our results indicate very good agreement with the analytical expected mass fraction pdf corresponding to the conduction cut off length λ 3 10 3 m since today s technology is available for detailed salinity measurements at reasonable cost this might be an interesting substitute for expensive and tedious attempts to perform equally probable large number of tracer tests based on our knowledge this is a first time that the salinity dilution process is used inversely to verify the concentration statistics of the river transport in the estuaries the fact that dilution process is increasing in a seaward direction e g farther distances from the river mouth is not surprising however the description of different mechanisms affecting the dilution process is a rather important contribution molecular diffusion is slow acting process and mean velocity attenuation at least for estuaries may also need some distance from the river mouth to start its action this can be more clear when we consider the total nitrogen concentration limit of 1 0 mg l lemley et al 2015 and evaluate f c x which is presented in fig 8 up to the 200 m from the river mouth there will be no major change between constant mean velocity results and dilution is predominantly due to the molecular diffusion and turbulent diffusivity at later cross sections the hydrodynamics of the open waters take over and further increase the dilution mechanism the expected mass fraction above the considered limit is being rapidly reduced for a non uniform mean velocity case 5 1 dilution measure by taking the ratio between f c x and g c x normalized with the mass loading of the contaminant crossing the plane normal to x direction and with the estimated cross section volume through which the mass is passing we introduce a new dilution measure for the case of the river discharging passive contaminant in an estuary as 21 η c x f c x g c x l v c x where vc x is estimated using multiples of spatial concentration variance with the spatial variance growth rate in terms of turbulent diffusivity et this dilution measure may be used to assess the distance from the river mouth where on average the concentration will be reduced below some environmental limits fig 9 shows the behavior of η c x for the uniform and non uniform mean velocity for concentration limit of 1 0 mg l the mean velocity attenuation due to the wind induced currents speeds up the dilution process by reducing the concentration values below the limit sooner the presented dilution measure has an additional advantage when being used for assessing future scenarios of freshwater transport and loadings of excess nutrients and pollutants in estuaries and coastal zone in the case of well established stratification the surface layer receives a nutrient supply creating potentially the main eutrophication hot spots druon et al 2004 lemley et al 2015 in such case the presented dilution measure may indicate the estuary area needed for dilution process to lower the concentration below the environmental limit in fig 10 we analyze some reasonable estimates of the river loadings based on different scenarios of anthropogenic activities that might occur in the future and present the cross section lines corresponding to the dilution of a dissolved total nitrogen concentration below 1 0 mg l 6 concluding remarks this study presented and analyzed the dilution process of the contaminant plume generated by river loading in the near field of an estuary under the stratified condition the most mixing activities are restricted in the surface layer which is receiving a pollutant supply from a freshwater input the spatially integrated statistics of passive contaminant concentration have been presented and summarized as a methodology to deliver a description of a key dilution processes present in a river dominated stratified estuary when combined the concept of emf sullivan and ye 1993 and its extension to evf provide a tool for analyzing the dilution process of contaminant plume in estuaries expressions given in 4 and 7 are indicating the dilution mechanism in the environmental flows in terms of the expected mass and volume fraction that is above some environmental limits the žrnovnica river estuary field case demonstrated the possibility of using emf and evf to address the dilution process which is close to the river mouth predominantly influenced by the molecular and turbulent diffusion in the surface layer under the stratified condition away from the river mouth the wind induced currents tides and internal density variations provide additional mixing mechanisms causing the concentration to attenuate as a combined effect of physical diffusion and sea related processes the introduction of the velocity attenuation coefficient resulting in the freshwater velocity reduction has important impact on the dilution process which is captured in fig 8 the use of salinity measurements of a sea water dilution during the stable stratified condition as an inverse process of a pollutant transport by the river discharge in the near field showed very good comparison with the expected mass fraction the ideal verification would be to perform large number of repeated tracer field tests and compare the actual concentration statistics with the relative salinity data however due to the practical difficulty of such experiments perhaps this restriction could eventually be overcome by designed laboratory experiments the other possibility could be to perform some numerical simulations of transport over different realization of the velocity fields in the estuary nevertheless the results from salinity measurements may be encouraging for future studies in verifying probabilistic models and reinforce the fact that application of spatially integrated statistics requires significantly fewer realizations to achieve convergence than distributed probabilistic measures finally we presented a novel dilution measure as combination of expected mass and volume fraction to be a useful tool for quantifying the area of an estuary where dilution process within the surface layer will attenuate the concentration of a passive contaminant below any selected environmental limits as an alternative to the dilution index kitanidis 1994 in porous media which provides a measure of the volume occupied by the entire solute cloud and attenuation rate of the concentration within the cloud the dilution measure η gives the fraction of the release mass emf and corresponding volume evf with concentration above any selected threshold however the proposed dilution measure assumes the river dominated and stratified estuaries while other processes like wind induced currents strong tides and sea upwelling would further increase the dilution process in the case of river žrnovnica example we were able to show the different dilution areas see fig 10 corresponding to different catchment loadings through the river as a hydrological pathway of mass transport for the case of a total nitrogen pollution supply into the estuary the presented dilution measure may be used to assess the water quality status and risk assessment of many transitional water bodies as required through the implementation of the eu water framework directive european 2000 acknowledgement this research was partially supported by the stim rei project funded by the european structural and investment funds 2014 2020 contract number kk 01 1 1 01 0003 appendix a following the zero molecular diffusion assumption the concentration absolute moments are defined sullivan 2004 a 1 m n 1 x t c 0 n m 1 x t choosing the simple gaussian distribution to represent the solution for a uniform initial concentration over a finite line source we conveniently write c 0 c 0 0 and initial absolute concentration moments are a 2 m n 1 0 0 l σ y 0 2 π n 1 e y 2 2 σ y 0 2 integrating the point moments over the gaussian source we obtain a 3 k n 1 0 v m n 1 0 d v v l σ y 0 2 π n 1 e y 2 2 σ y 0 2 d y the integral on the right side is solved by substitution and erf function yielding a 4 k n 1 0 l σ y 0 2 π n 1 σ y 0 2 π e r f κ 2 l n 1 σ y 0 2 π n e r f κ 2 
802,the pollution pressures on coastal waters predominantly come from the river freshwater transport and loadings of contaminants into the estuary this study presents the probabilistic model of the near field solute transport in an estuary based on the spatially integrated concentration statistics a methodology is presented for quantifying the degree of dilution within the surface layer in terms of expected mass and volume fraction functions as a simple alternative to the point concentration probability density function the theoretical prediction is experimentally validated using the salinity dilution as an inverse process in the field case of river žrnovnica near the city of split a novel dilution measure is presented as combination of expected mass and volume fraction indicating the area of an estuary where dilution process will attenuate the concentration of a passive contaminant below any selected environmental limits introduced dilution measure directly corresponds to different catchment loadings through the river as a hydrological pathway of mass transport and can be used for assessing water quality status for transitional water bodies and to guide future efforts for monitoring potential eutrophication hot spots in the coastal area keywords dilution measure solute transport in estuary expected mass and volume fraction 1 introduction the problem addressed in this paper is the river freshwater transport and mass loadings in an estuary or coastal waters environments reflecting the entire upstream catchment anthropogenic activities the pollution pressures of the coastal waters by the river discharge of contaminants into the estuary and their impact on the marine ecosystem has become a growing problem throughout the world destouni et al 2008 riddle and lewis 2000 tseng 2002 rivers are considered as one of the most influential hydrological pathways for the waterborne mass flows of nutrients and pollutants to the estuaries these environmental flows are in a turbulent state of motion generally unsteady and spatially inhomogeneous playing a dominant role during the mixing and dilution of contaminants chatwin and allen 1985 gurka et al 2010 the mixing is mainly generated by the river discharges creating a seaward transport which tends to float over the denser seawater under the stratified condition most mixing activities are restricted to the upper layer ji et al 2007 close to the river mouth the turbulent eddies in the horizontal plane cause a contaminant to spread with time more rapidly in the seaward direction since the current along the river discharge is greater than transverse shear across the flow during the time of a weak stratification the contaminants may also be transported into greater depths bringing additional vertical mixing to the contaminant plume moving away from the river mouth the wind induced currents tides and internal density variations provide additional mixing mechanisms contributing to the reduction of the freshwater inflow velocity and causing even faster dilution in the porous media the quantification of dilution process for solute clouds as opposite of spreading was proposed by kitanidis 1994 using an entropy based metric denoted as a dilution index the dilution index gives a measure of the volume defined by the concentration spatial variance occupied by the solute cloud as it evolves due to the advection and diffusion processes several other studies followed the work by kitanidis 1994 analyzing different impacts on the dilution index coming from geologic heterogeneity flow topology and reactive transport characteristics chiogna et al 2011 2012 de barros et al 2015 kapoor and kitanidis 1998 rolle et al 2009 for environmental flows in general one would investigate the probability density function pdf of concentration as it evolves in time at each location in space to quantify the concentration field however this is a difficult task since the equations that govern pdf evolution are intractable in even the simplest turbulent flows and its measurement in environmental flows is challenging gurka et al 2010 sarathi et al 2010 the main problem with the conventional measure of dilution is requirement of a large number of realizations for a point pdf and or its lower order moments estimation when relying on numerical solutions therefore a measure which would converge with fewer realizations and be less sensitive to experimental numerical spatial and temporal resolution is desired in the atmospheric turbulent diffusion problems the concept of expected mass fraction emf was introduced by sullivan and ye in sullivan and ye 1993 by performing a spatial integration of the point concentration pdf heagy 1994 introduced the concept of the expected mass fraction as a function of the spatial coordinates after performing temporal integration of the concentration pdf andricevic et al 2012 implemented the emf as a function of spatial coordinates in the subsurface transport with its application to the human health risk assessment problem in the case of spatial integration the emf expresses the distribution of release mass over different concentrations at a given time this can be seen as the state of a cloud plume in terms of contaminant concentration values as it evolves in time this study addresses the problem of near field mixing and dilution process nearby the river mouth where pollution pressure may affect the water quality of marine ecosystem subject of an assessment required by the eu water framework directive european 2000 this paper is presenting the extension of the emf to the expected volume fraction evf concept and introduce a new dilution measure for the river transported pollutants in estuaries as a methodology to assess the dilution process of passive contaminants the theoretical development is demonstrated in the field case of an estuary in the vicinity of the city of split in section 2 we present the emf background concept and demonstrate key features of its possible application in the considered problem in section 3 we introduce the concept of expected volume fraction to augment the emf with additional information for the dilution process and in section 4 we derive the spatially integrated concentration moments needed for the evaluation of the emf and evf with a demonstration in an illustrative example finally section 5 presents the field case study of the river žrnovnica estuary and demonstrates the application of the developed methodology with introduction of a dilution measure which can be used to assess the water quality status in estuaries and coastal waters 2 the emf background the concept of emf sullivan and ye 1993 can be simply described by considering a contaminant cloud at time t with conserved release mass m the finite range of concentration between 0 and source concentration c 0 is divided into a number of non overlapping discrete intervals the mass c x t d v x is found by summing all volume elements d v x of the cloud with concentration values within a given interval the sum of the mass found in all intervals is equal to m an average is obtained by repeating this procedure for the release of many clouds the average mass found in each interval is divided by the concentration interval to make this a density function the expected mass fraction f c t or a cloud averaged dilution pdf sullivan and ye 1993 is therefore defined by 1 f c t 1 m v c p c x t d v where v denotes all space m v c x t d v is the conserved mass and p c x t stands for p r o b c c x t c d c it is easily shown that f c t behaves as a pdf and has its absolute moments 2 m n t 0 c n f c t d c 1 m m n 1 x t d v which are related to the spatially integrated absolute moments m n c n p c x t d c the emf f c t can be obtained by inversion of lower order moments m n t f c t dc is the expected fraction of the release mass found in the concentration interval c to c d c at time t since there is no spatial reference in f c t one expects significantly fewer realizations for its convergence than for the distributed measure such as m n x t for each cloud release in numerical or field tests a mass fraction can be determined as follows 3 f c t 1 m v c x t δ c x t c d v such that ensemble average of f c t equals f c t variations of f c t about f c t is expected to be reasonably small since in each realization concentration values throughout the entire cloud are used in the compilation of f c t ye 1995 the f c t can account for any particular flow conditions e g buoyancy effects unsteadiness or irregular boundaries or the type of scalar contaminant the only requirement is that release mass m be conserved in a case where release mass is not conserved for example where continuous release or chemical reactions are present one would simply replace m with m t smith 2004 very important interpretation of the emf is in the environmental flow where pollution is discharged into the environment e g air pollution or discharge into coastal zone and estuaries the fraction of release mass that exceeds an environmental threshold c on average at time t can be defined as 4 f c t c f c t d c this fraction of the release mass above some threshold is reduced with time indicating the dilution mechanism of the environment the another aspect of the dilution process would be the volume occupied with f c t 3 expected volume fraction evf cloud averaged pdf introduced in chatwin and sullivan 1990 defines a total distribution indicating the problem of thresholding and the fact that c 0 for all x and t 0 to overcome the threshold issue we introduce a practical approximation by introducing the estimated volume containing the most of the released mass such that the expected volume fraction can be defined as 5 g c t 1 v c v c p c x t d v where vc is selected to be sufficiently large that v c m 1 x t d v m and can be estimated on average using the multiples of the concentration spatial variance g c t behaves as a pdf and has the absolute moments 6 m n t 0 c n g c t d c 1 v c 0 c n p c x t d v d c 1 v c m n x t d v which are related to the spatially integrated absolute moments of the point concentration pdf the evf like emf can be obtained by inversion of the lower order moments m n t unlike emf the evf moments are related to the same order with absolute moments of the point concentration pdf the interpretation of the evf is related to the volume in the environment occupied with the source solute above some concentration threshold c as 7 g c t c g c t d c thus the state of the solute concentration within the cloud or plume in terms of occupied volume can be readily found for any concentration level desired this information together with emf can be combined to estimate temporal dilution process measured through the volume fraction that remains still endangered above a certain concentration level in case of accidental spills and the risk assessment studies this can be used to estimate the self purification time needed to satisfy some environmental limits in order to evaluate the emf and evf through 2 and 6 we need to perform the spatial integration of point concentration pdf absolute moments 4 spatially integrated statistics most environmental flows are in a turbulent state of motion unsteady and inhomogeneous these features are playing a dominant role in mixing and spreading of contaminants spatial integration of different concentrations statistics eliminates spatial reference resulting in fewer realizations needed for the ensemble averaging integrating the point pdf over all space and using a center of mass reference frame avoids some closure pitfalls along with problems of velocity field variations performing the spatial integration of the concentration absolute moments derived from the advection diffusion equation andricevic 1998 chatwin and sullivan 1990 smith et al 1999 sullivan 2004 the exact equation for all types of environmental flows is 8 t v m n 1 x t d v n n 1 e m v c n 1 x t c x t 2 d v n 1 where overbar denotes ensemble averaging and velocity field does not appear explicitly in 8 the integral on the right hand side is intrinsically positive and clearly shows that molecular diffusion em is the only means by which the concentration is reduced and thus the only mechanism contributing to the dilution process the closure condition on the term c n 1 c 2 that appears under the integral over all space is expected to be less sensitive to approximation than closures commonly used in the partial differential equations that govern p c x t since the significant values of c 2 occurs predominantly at the surface areas of thin sheets and strands within which the most of the source mass is located the geometrical approximation moseley 1991 has been widely used 9 c 2 c c t λ 2 2 where concentration dependence on x t is suppressed from hereafter and λ is an effective small scale representing sheets and strands in the porous media it represents a macroscopic scale larger than pore scale but smaller than heterogeneity scale andricevic 1998 while in other environmental flows under high reynolds number it represents a small length scale also known as conduction cut off length of order 10 4 m for rivers and estuaries chatwin and sullivan 1979 the threshold concentration ct is behaving in the limit as ct 0 as t 0 and c t c m as t where c m is the largest value of the mean concentration using 9 the spatially integrated moment equation for n 1 becomes 10 t v m n 1 d v n n 1 e m λ 2 v c n 1 2 c n c t c n 1 c t 2 d v denoting k n t v m n x t d v and introducing the non dimensional time scale τ e m λ 2 t equation 10 becomes first order differential equation for spatially integrated concentration moments 11 k n 1 τ τ k k n 1 τ k 2 k n τ c t τ k n 1 τ c t 2 τ n 1 where k n n 1 eq 11 can be solved recursively as 12 k n 1 τ e k τ k 0 τ 2 k n τ c t τ k n 1 τ c t 2 τ e k τ d τ k n 1 0 n 1 by setting n 1 in 12 and using c t c one obtains 13 τ k 2 2 k 2 2 c 2 d v which by splitting k 2 σ c 2 d v c 2 d v yields the total concentration fluctuation equation also used in porous media in andricevic 1998 eq 16 4 1 an illustrative example consider the case of a line source like in river dominated estuary with a steady uniform mean flow velocity u in the stream wise direction x and with the across plume direction y fig 1 the modified emf sarathi et al 2010 and evf are 14 f c x l 1 c p c x y d y g c x v c 1 p c x y d y where l c x y d y is a steady mass loading of the solute through the plane normal to the flow direction x and v c 2 κ σ y where σ y 2 is a spatial transversal concentration variance and κ denotes the multiple integer selected to satisfy l we assume the gaussian one dimensional distribution for cross sectional profiles commonly considered to wakes jets and plumes andricevic 1998 fischer et al 1979 sawford and sullivan 1995 sullivan 2004 and also used for the river discharges to the estuary galesic et al 2016 15 c y x l σ y 2 π e y 2 2 σ y 2 where σ y 2 2 e t t σ y 0 2 x u t et is the constant spatial variance growth rate equivalent to a turbulent diffusivity and σ y 0 2 represents the initial variance at x 0 using 11 we now define cross sectionally integrated concentration moments k n τ v m n x τ d v where τ e m x λ 2 u and d v d x d y d z is available volume as depth integrated surface slice which is δx wide in the stream flow direction x and 2κσy wide in a transversal direction y thus the first two spatially integrated moments are k 0 τ 2 κ σ y δ x and k 1 τ l the next few moments can be easily evaluated using a recursive solution in 12 fig 2 a shows the behavior of the first three moments of the expected mass fraction m n τ while fig 2 b compares the second third and fourth spatially integrated moments kn as a function of dimensionless time τ in both cases the moments are showing the expected diminishing behavior as τ increases the obtained emf and evf moments are further used for illustrative purposes to construct f and g using two parameters beta distribution de barros and fiori 2014 bellin and tonina 2007 mole 2010 sawford and sullivan 1995 smith 2004 sullivan 2004 fig 3 a and b exhibits their behavior for the considered illustrative example the mass fraction pdf shows the shift from the initial time near source cross sections where most of the mass is around the source maximum concentration towards the lower concentration values as a result of the stronger dilution process when τ increases for example the cross section corresponding to τ 2 0 has most of the mass with the concentration values around one tenth of the initial value similar behavior can be seen from fig 3 b where the volume fraction shows the similar shift as τ increases when looking the volume fraction occupied with the released mass flux it is interesting to note that at the early time or close to the source cross sections the evf exhibits u shaped pdf indicating that diffusion is very weak near the source and the mass is predominantly concentrated in stretched sheets and strands advection dominated process at farther cross sections from the source the evf shows that volume occupied with the source solute will exhibit lower concentration values 5 the žrnovnica river estuary field case to demonstrate the comparison of our theoretical results and estimate dilution process in the field situation we select the žrnovnica river estuary located near the city of split where we have conducted several monitoring sessions measuring salinity temperature density and sea currents fig 4 just upstream from the river mouth there is an uncontrolled landfill creating a severe pollution hazard for the žrnovnica estuary which is more pronounced with a rather small river discharge annual average 2 m3 s this area has already recorded pollution events due to the anthropogenic activity which makes this estuary a vulnerable ecosystem margeta and barić 2001 more details about morphology and bathimetry of the žrnovnica estuary is given in galesic et al 2016 in the near field of river dominated stratified estuaries savenije 2005 the mixing is mainly generated by the river discharge creating a seaward transport which tends to float over the more dense seawater away from the river mouth the tides and wind induced currents start to influence mixing processes and reduce the freshwater inflow velocity we are investigating the žrnovnica discharge to the coastal water as a river dominated estuary with a non uniform mean velocity in x direction u x u 0 e ν x where u 0 is the cross sectionally averaged velocity at the river mouth and ν m 1 is an attenuation coefficient representing different mechanisms that combined progressively reduce u in the seaward direction galesic et al 2016 using t x u u u x 0 0 eq 8 for n 1 becomes 16 x u o e ν x v m n 1 d v n n 1 e m λ 2 v c n 1 2 c n c t c n 1 c t 2 d v applying the notation k n x v m n x x u d v 16 is expressed for n 1 as 17 k n 1 x x k α u o e ν x k n 1 x k α u o e ν x 2 k n x c t x k n 1 x c t 2 x which has a recursive solution in the form 18 k n 1 x e k α u o ν e ν x 1 k α u 0 0 x 2 k n x c t x k n 1 x c t 2 x e k α u o ν e ν x 1 ν x d x k n 1 0 where α e m λ 2 and initial values for cross sectionally integrated concentration moments for n 1 are defined as see appendix a for details 19 k n 1 0 l n 1 σ y 0 2 π n e r f κ 2 where l m b u 0 is defined by steady mass flux m river mouth width b and the initial velocity u 0 analyzing the current anthropogenic activity and future planned development in the žrnovnica catchment we have estimated the averaged mass flux of a total nitrogen delivered by river to the estuary to be around 50 grams per second g s with an annual average flow rate of 2 m3 s other parameters used are based on the previous hydrodynamic analysis of the river žrnovnica galesic et al 2016 as follows b 14 m u 0 0 4 m s and ν 0 002 m 1 in fig 5 a and b the emf and evf are presented respectively both expected fraction characteristics of the mass and volume are showing a shift towards lower concentration values moving away from the river mouth to the cross sections up to the 800 m from the source it is interesting to examine the emf in fig 6 where the effect of considering a non uniform mean velocity is shown close to the river mouth the attenuation of the mean velocity is very small and dilution is predominantly due to the molecular and turbulent diffusivity however moving in the seaward direction the wind induced currents are reducing the river discharge velocity which is contributing to the dilution process by further lowering concentration values at farther cross sections in contrast to the uniform mean velocity solution the estimated degree of mean velocity reduction by the attenuation coefficient for the river žrnovnica has been given in galesic et al 2016 for the thorough verification of our probabilistic approach one would need a large number of realizations of the tracer tests although much less than in the case of the point concentration pdf in order to verify spatially integrated concentration moments here we made an attempt to use the salinity measurements on two cross sections from the river mouth see fig 4 and compare the sea water dilution as an inverse process to the river transport by the freshwater discharge this inverse analogy is introduced due to the salinity being effectively reduced at the river mouth and then gradually increased back to the initial sea salinity level at some distance seaward while passive solute concentration exhibits the highest value at the river mouth and then gradually reduces in the seaward direction salinity measurements were collected with the sbe 37 si microcat probe on 30th of december 2015 at low tide 0 06 m amplitude at wind speed around 3 m s wind blowing from ne direction and the river discharge flow rate was 0 7 m3 s the probe was fixed in the surface layer 10 20 cm for 10 min with 6 s sampling resolution resulting in 100 measurements per sampling point fig 4 defines positions and number of salinity measurements the salinity measurements were inversely used as a proxy for a normalized concentration in the surface layer as 20 c p x t 1 s x t s m i n s m a x s m i n where s x t is the measured salinity at sampling points smin is the salinity measured at the river mouth and smax represents the sea salinity in the estuary the standard point moments of proxy concentration are calculated from 100 samples over the 10 min sampling interval at each spatial sampling point and then spatially integrated along the cross sections 93 m and 200 m see fig 4 away from the river mouth to deliver corresponding k 2 and k 3 fig 7 a and b show the comparison of the emf pdf evaluated using proxy concentration measurements with the emf pdf evaluated from analytically obtained moments although much more transversal points of salinity data would be more preferable our results indicate very good agreement with the analytical expected mass fraction pdf corresponding to the conduction cut off length λ 3 10 3 m since today s technology is available for detailed salinity measurements at reasonable cost this might be an interesting substitute for expensive and tedious attempts to perform equally probable large number of tracer tests based on our knowledge this is a first time that the salinity dilution process is used inversely to verify the concentration statistics of the river transport in the estuaries the fact that dilution process is increasing in a seaward direction e g farther distances from the river mouth is not surprising however the description of different mechanisms affecting the dilution process is a rather important contribution molecular diffusion is slow acting process and mean velocity attenuation at least for estuaries may also need some distance from the river mouth to start its action this can be more clear when we consider the total nitrogen concentration limit of 1 0 mg l lemley et al 2015 and evaluate f c x which is presented in fig 8 up to the 200 m from the river mouth there will be no major change between constant mean velocity results and dilution is predominantly due to the molecular diffusion and turbulent diffusivity at later cross sections the hydrodynamics of the open waters take over and further increase the dilution mechanism the expected mass fraction above the considered limit is being rapidly reduced for a non uniform mean velocity case 5 1 dilution measure by taking the ratio between f c x and g c x normalized with the mass loading of the contaminant crossing the plane normal to x direction and with the estimated cross section volume through which the mass is passing we introduce a new dilution measure for the case of the river discharging passive contaminant in an estuary as 21 η c x f c x g c x l v c x where vc x is estimated using multiples of spatial concentration variance with the spatial variance growth rate in terms of turbulent diffusivity et this dilution measure may be used to assess the distance from the river mouth where on average the concentration will be reduced below some environmental limits fig 9 shows the behavior of η c x for the uniform and non uniform mean velocity for concentration limit of 1 0 mg l the mean velocity attenuation due to the wind induced currents speeds up the dilution process by reducing the concentration values below the limit sooner the presented dilution measure has an additional advantage when being used for assessing future scenarios of freshwater transport and loadings of excess nutrients and pollutants in estuaries and coastal zone in the case of well established stratification the surface layer receives a nutrient supply creating potentially the main eutrophication hot spots druon et al 2004 lemley et al 2015 in such case the presented dilution measure may indicate the estuary area needed for dilution process to lower the concentration below the environmental limit in fig 10 we analyze some reasonable estimates of the river loadings based on different scenarios of anthropogenic activities that might occur in the future and present the cross section lines corresponding to the dilution of a dissolved total nitrogen concentration below 1 0 mg l 6 concluding remarks this study presented and analyzed the dilution process of the contaminant plume generated by river loading in the near field of an estuary under the stratified condition the most mixing activities are restricted in the surface layer which is receiving a pollutant supply from a freshwater input the spatially integrated statistics of passive contaminant concentration have been presented and summarized as a methodology to deliver a description of a key dilution processes present in a river dominated stratified estuary when combined the concept of emf sullivan and ye 1993 and its extension to evf provide a tool for analyzing the dilution process of contaminant plume in estuaries expressions given in 4 and 7 are indicating the dilution mechanism in the environmental flows in terms of the expected mass and volume fraction that is above some environmental limits the žrnovnica river estuary field case demonstrated the possibility of using emf and evf to address the dilution process which is close to the river mouth predominantly influenced by the molecular and turbulent diffusion in the surface layer under the stratified condition away from the river mouth the wind induced currents tides and internal density variations provide additional mixing mechanisms causing the concentration to attenuate as a combined effect of physical diffusion and sea related processes the introduction of the velocity attenuation coefficient resulting in the freshwater velocity reduction has important impact on the dilution process which is captured in fig 8 the use of salinity measurements of a sea water dilution during the stable stratified condition as an inverse process of a pollutant transport by the river discharge in the near field showed very good comparison with the expected mass fraction the ideal verification would be to perform large number of repeated tracer field tests and compare the actual concentration statistics with the relative salinity data however due to the practical difficulty of such experiments perhaps this restriction could eventually be overcome by designed laboratory experiments the other possibility could be to perform some numerical simulations of transport over different realization of the velocity fields in the estuary nevertheless the results from salinity measurements may be encouraging for future studies in verifying probabilistic models and reinforce the fact that application of spatially integrated statistics requires significantly fewer realizations to achieve convergence than distributed probabilistic measures finally we presented a novel dilution measure as combination of expected mass and volume fraction to be a useful tool for quantifying the area of an estuary where dilution process within the surface layer will attenuate the concentration of a passive contaminant below any selected environmental limits as an alternative to the dilution index kitanidis 1994 in porous media which provides a measure of the volume occupied by the entire solute cloud and attenuation rate of the concentration within the cloud the dilution measure η gives the fraction of the release mass emf and corresponding volume evf with concentration above any selected threshold however the proposed dilution measure assumes the river dominated and stratified estuaries while other processes like wind induced currents strong tides and sea upwelling would further increase the dilution process in the case of river žrnovnica example we were able to show the different dilution areas see fig 10 corresponding to different catchment loadings through the river as a hydrological pathway of mass transport for the case of a total nitrogen pollution supply into the estuary the presented dilution measure may be used to assess the water quality status and risk assessment of many transitional water bodies as required through the implementation of the eu water framework directive european 2000 acknowledgement this research was partially supported by the stim rei project funded by the european structural and investment funds 2014 2020 contract number kk 01 1 1 01 0003 appendix a following the zero molecular diffusion assumption the concentration absolute moments are defined sullivan 2004 a 1 m n 1 x t c 0 n m 1 x t choosing the simple gaussian distribution to represent the solution for a uniform initial concentration over a finite line source we conveniently write c 0 c 0 0 and initial absolute concentration moments are a 2 m n 1 0 0 l σ y 0 2 π n 1 e y 2 2 σ y 0 2 integrating the point moments over the gaussian source we obtain a 3 k n 1 0 v m n 1 0 d v v l σ y 0 2 π n 1 e y 2 2 σ y 0 2 d y the integral on the right side is solved by substitution and erf function yielding a 4 k n 1 0 l σ y 0 2 π n 1 σ y 0 2 π e r f κ 2 l n 1 σ y 0 2 π n e r f κ 2 
803,coastal lagoons channels and wetlands are sensitive ecosystems with high productivity and biodiversity these systems often provide society with the valuable freshwater resources and many ecosystem services in the subtropics the hydrological systems inherit the typically high climatic and weather variability characteristics of these zones therefore knowing the natural variability of these characteristics is crucial for the sustainable use of the water resources of these systems in the present paper we investigated the hydrodynamics of the mirim são gonçalo system which comprises a large shallow coastal lake a 78 km long channel and their adjacent floodplains and wetlands with a focus on water level oscillations we used a combination of numerical simulations gauge station data and synthetic aperture radar imaging to evaluate the influence of the incident winds and the discharges of the main tributaries on the system s water levels and the establishment of barotropic gradients we analyzed the water level variability of the mirim lagoon and the são gonçalo channel and their overflows to the adjacent floodplains the simulations are five years long and cover the period starting in january 2000 to december 2004 the analysis indicates that the discharge of the tributaries mainly governs the system s temporal patterns wind action has two distinct influences on the systems first the wind dams the water at the southern portion of the mirim lagoon which creates a persistent barotropic gradient in the surface this gradient is often destroyed and dislocated northwards in a rotational fashion when the wind blows from the southern quadrant second the wind perturbs the temporal variability patterns resulting in high frequency oscillations of the water level temporal signal flooding is frequent in the lands adjacent to the lagoon and the channel and results from the combination of the geomorphological and climatic settings of the region the system is surrounded by ancient lagoon deposits with an extremely flat and low lying topography which favors the flooding of large extents the large catchment area and the high precipitation rate over this region result in significant water level oscillations causing the system to overflow and leading to subsequent floods keywords hydrodynamic telemac2d flooding surface hydrology coastal lagoon natural channel floodplain wetlands 1 introduction lakes lagoons and rivers provide several ecosystem services and are vital sources of freshwater for human consumption and economic activities such water bodies and their adjacent floodplains are part of the same dynamic system junk et al 1989 tockner et al 2000 the ecosystems of which are adapted to natural water level fluctuations and impacted by human water use leira and cantonati 2008 understanding the water level variability of these environments is socioeconomically relevant water body hydrodynamics directly influence water quality and availability navigability conditions the residence time of pollutants sediment deposition patterns and dredging operations on the other hand human interventions and uses of the water can modify the natural variability in water levels often leading to the degradation of environmental quality in the extreme south of brazil lies the patos mirim lagoon complex which is the largest lagoon system in latin america fig 1 this system comprises the patos and mirim lagoons and the são gonçalo channel sgc a 78 km long channel that connects both lagoons the mirim lagoon waters are mostly drained towards the são gonçalo channel which in turn discharges in the patos lagoon estuary the mirim são gonçalo waters are part of the same drainage basin which is partially located in the south of brazil and partly lies on uruguayan lands this bi national hydrological system also has enormous environmental and socio economic importance surrounding the lagoon and the channel highly productive wetlands shelter a rich biodiversity asmus 1998 and are protected by national laws from the global point of view wetlands play a part in the carbon biogeochemical cycle representing the largest source of methane for the atmosphere meng et al 2016 whang et al 1996 since 2007 atmospheric methane levels began growing again after years of stable concentrations meng et al 2016 this trend has raised concerns about the positive climatic feedback between methane emissions from wetlands and increasing air temperatures however the wetlands surrounding the mirim são gonçalo system have been the subject of only a limited number of studies mostly focused on the taim wetlands area in the past the patos lagoon exported brackish waters to the mirim lagoon during low river discharge periods hirata et al 2010 in 1977 a sluice gate and a subsurface dam were built to prevent the salinization of the mirim lagoon and the são gonçalo channel because these features supply rio grande city with water for human consumption and provide several rice farms with water for irrigation these two activities have accounted for the primary water use of the mirim são gonçalo system msgs for many years at present there is increasing discussion about the establishment of a bi national brazil uruguay waterway and increasing the industrial uses of the msgs water however the mirim lagoon hydrodynamics have been the subject of only a few studies hirata et al 2010 oliveira et al 2015 and the são gonçalo channel and its adjacent floodplains and protected wetlands remain virtually unexamined hence the natural hydrological variability of the system is not well documented or investigated in fact the present state of the system is already modified by human interventions namely the rice crop irrigation channels a road landfill crossing the taim wetlands and the sluice gate the present paper aims to investigate the hydrodynamics of the mirim lagoon the são gonçalo channel and the adjacent floodplains using the telemac 2d hydrodynamic model and synthetic aperture radar imagery acquired by the european remote sensing 2 ers 2 mission the analysis focuses on water level fluctuations and the variability thereof in response to river discharge and wind action and estimates the flood extent of the sgc floodplain 1 1 physical aspects of the study area the msgs fig 1 lies on a broad coastal plain that developed during the quaternary in response to sea level oscillations tomazelli et al 2000 the deposition of an alluvial fan system and four subsequent barrier lagoon systems evolved from west to east and resulted in a very flat terrain on which higher elevations are spatially related with the oldest deposits rosa et al 2016 such as the alluvial fan deposits and the preserved parts of the ancient barriers dunes are also prominent topographic features the very flat geomorphology of the surrounding lands coupled with the shallowness of the water bodies and the high precipitation rates on the drainage basin imply that the msgs often overflows the sgc flows over an extensive and continuous and ancient holocene and pleistocene lacustrine deposit tomazelli et al 2000 surrounded by a perennial wetland and floods frequently duarte 2013 the drainage basin of the msgs covers 62 250 km2 when considering the tributaries and adjacent wetlands the mirim lagoon is the third largest south american lacustrine water body with 3749 km2 santos et al 2004 the climate is mesothermal with annual average temperatures between 14 o c and 18 o c and annual precipitation between 1 250 mm and 2 000 mm the prevailing winds are from the northeast yet during the autumn and the winter there is an increased incidence of winds from the southern quadrant compared to during summer and spring the anticyclonic atmospheric circulation over the south atlantic ocean determines that the predominant winds are from the northeast fig 2 however winds from the southern quadrant are also frequent during the passage of cold air masses and extra tropical cyclones parise et al 2009 these winds occur more often in the winter in response to the northward displacement of the polar front despite the strategic importance of the msgs to the brazilian and uruguayan economies national border controls and waterway systems this system lacks hydro graphical measurements such measures are restricted to water level time series from two gauge stations and to four years of nearly continuous river discharge data on the main tributaries the cebollati tacuari and jaguarão rivers covering a period from 2000 2004 fig 1 2 methods we investigated the mirim são gonçalo water level oscillations using a two dimensional hydrodynamic simulation the simulations were carried for a five year period and the model was forced by the river discharge and winds broadly accepted concepts such as the flood pulse concept and river continuum concept state that floodplains are part of the same dynamic system of the water body that they fringe and that the two features are linked by hydrological and ecological processes junk et al 1989 tockner et al 2000 in this sense we included the low lying lands fringing the mirim lagoon and the são gonçalo channel in the numerical domain a polygon that delineates a belt surrounding the lagoon and the channel with an elevation lower than 5 m defines the extent of the numerical domain this artificial polygon is coincident with a nearly continuous line with a slightly higher terrain slope and with an old map of the flooding areas in the vicinity of the msgs vieira 1982 2 1 hydrodynamic modeling we performed a five year hydrodynamic simulation of the msgs and its adjacent floodplains using the telemac 2d http www opentelemac org model this model uses the finite element technique and the characteristic curves method to solve the saint venant equations these equations are obtained by depth averaging the navier stokes equations when assuming the hydrostatic approximation the negligibility of the vertical velocities and the impermeability of the free surface and the bottom hervouet 2007 this approach has been widely employed in the modeling of rivers lakes and floodplains and achieves satisfactory results when the depth wise variability of the water properties can be neglected e g bates et al 1999 fernandes et al 2001 horritt and bates 2002 teng et al 2017 the computational domain considers four open liquid boundaries the jaguarão tacuari and cebollati rivers and the mouth of the são gonçalo channel the boundaries are forced with discharge data measured in gauge stations placed in the three most important tributaries and with water level measurements carried out near the sgc mouth fig 1 the brazilian national water agency distributes these data through its website http www hidroweb ana gov br the simulation covers the period from 1 january 2000 31 december 2004 the simulation period corresponds to the longest continuous record of the discharges of the main tributaries fig 3 the atmospheric boundaries are forced by wind data from the era interim reanalysis project http www ecmwf int and these data are provided by the european center of medium range weather forecast dee et al 2011 simmons et al 2006 once the initial conditions of the system are unknown we forced the boundaries with average time series of discharge and winds for one year previous to the year 2000 to warm up the simulation the bathymetry of the mirim lagoon and the são gonçalo channel were obtained by combining digitalized navigation charts produced by the brazilian navy with data acquired by partners to represent the topography of the water bodies adjacent floodplains we used the shuttle radar topographic mission srtm digital elevation model dem the srtm is a global dem and the data are available from the united states geological survey usgs at a spatial resolution of 90 m https www earthexplorer usgs gov however srtm data for the brazilian territory are available at the topodata project website http www dsr inpe br topodata the project is developed by the brazilian national institute for space research inpe and provides a geomorphometric database for the brazilian territory the srtm topographical data provided are post processed and interpolated to a 30 m grid 2 2 flood detection using ers 2 data synthetic aperture radar sar systems provide an appropriate dataset for investigating the presence of liquid water on the earth s surface and these systems are employed in many flood detection studies clement et al 2017 hahmann thomas wessel 2010 horritt et al 2010 pierdicca et al 2013 the liquid water specular backscatters the microwaves emitted by the sar systems decreasing the radiative energy that returns to the sensor in the images inundated areas result in darker pixels compared to those for dry surfaces especially in the absence of trees smith 1997 ulaby et al 1986 many techniques have been applied in the identification of flooded areas in sar imagery such as visual interpretation thresholding change detection and active contouring each of the approaches has different pros and cons related to the automation degree of the process and their computational costs martinis et al 2015 in this work we used a thresholding method that was developed specifically for the study area and is based on image histogram analysis and visual inspection of the ers 2 imagery in combination with a landsat etm image duarte 2013 the pixels located on the floodplain with backscattering values lower than 8 db and higher than 12 db are classified as wet while those presenting backscattering values smaller than 12 db are classified as flooded duarte 2013 six synthetic aperture radar sar images obtained by the ers 2 platform are used in the present study to retrieve information on the sgc floodplain flooded area we performed the calibration geometric correction and speckle filtering using the snap software the water bodies are masked out and the pixels are then classified as either flooded or not flooded using the regional algorithm which was developed specifically for the study area by duarte 2013 such images are employed in the present work to assess the performance of the model in simulating the flooding extent 3 calibration and validation of the hydrodynamic model the mirim lagoon is an elongated basin whose longest axis azimuth is nearly parallel to the preferential wind directions ne and sw thereafter it was expected that winds would be a major forcing determining water level oscillations of the msgs hence we calibrated the coefficient of wind influence by performing three simulations covering the year 2000 setting this paramether to 10 6 105 and 5 10 5 the results of each calibration experiment were compared to water level measurements acquired in the south of the mirim lagoon ml são vitória do palmar station svp and in the south of the sgc santa izabel station si the gauge stations data is distributed by the agency for development of the mirim lagoon http www wp ufpel edu br alm table 1 presents the time series obtained using each coefficient of wind influence we adopted the coefficient of wind influence of 105 because it provided the best combination of rmse bias and correlation coefficient with the observed time series additionally the 106 coefficient produced a wl time series with smoothed short term variability whereas the 5 10 5 coefficient resulted in amplified short term wl oscillations the similar correlation coefficients obtained between the observed time series and the simulated time series using different coefficients of wind influence suggests that the river discharge is the primary factor controlling the water level however the wl oscillations that occur with short periodicities are determined by the wind action we validate the hydrodynamic model by comparing the simulated water level against two water level time series acquired in the same gauge stations svp and si for the entire period of simulation 2000 2004 we perform the comparisons between the measured and simulated data for each gauge station the simulated and measured time series are presented in fig 4 the time series show good agreement but the simulated water levels increase and decrease faster than the measured data this observation may indicate the importance of the exchanges between the msgs and other water bodies such as the mangueira lake the connection between both systems occurs through the taim wetland a flat land lying over an interruption of the ancient coastal barrier that isolates the water bodies under high precipitation and consequently high water levels exchanges can occur from one lake to another da paz et al 2003 these processes are neglected in the present study due to the lack of bathymetric data available on the mangueira lake a road crosses the taim wetland reducing the exchanges between the mirim lagoon and the mangueira lake however exchanges still occur through a pipe system passing the road which also serves as a corridor for local fauna the correlation coefficients of the time series are r 0 84 for the svp and r 0 83 for the si gauge stations and these results are significant at the 95 level these results show that the hydrodynamic model is successful in representing the temporal variability of the water level time series the maximum minimum water level anomalies calculated by the model in si are 3 3 m 1 8 m and 3 8 m 2 2 m in svp the maximum minimum measured water levels are 2 4 m 2 2 m in si and 2 3 m 2 4 m in svp additionally it is worth noting that the largest discrepancies occur in 2002 which was a year of very high precipitation in the region 4 results and discussion 4 1 water level oscillations the water level wl oscillations are presented in fig 3 for each compartment separately lagoon channel and floodplains higher water levels are observed from late autumn to early spring reflecting the typical seasonal signal of precipitation and river discharge of the study region in the patos lagoon drainage basin the discharge peaks occur in winter and spring moller et al 1996 whereas the la plata river has discharge peaks in the autumn and spring piola et al 2005 hence the mirim são gonçalo system shows temporal patterns that are intermediate relative to the northern and southwest neighboring drainage basins although the ml resembles the patos lagoon in geomorphological terms the amplitude of wl variation of the patos lagoon is within 1 5 m to 2 m marques 2012 which the wl variation in the ml greatly exceeds in this sense the ml behavior better approximates its western neighbor basins such as the lower paraná and uruguay portions of the plata basin where the water level can show oscillations up to 6 m maheu 2003 the different amplitude wl variability amplitude found between both basins are possibly related to disctict precipitation patterns occurring on their drainage basins maier et al 2016 additionally the passage of cold fronts and extratropical cyclones are the main atmospheric processes that cause precipitation such cold fronts reach the ml s drainage basin before reaching the pl s usually causing more severe precipitation events in the first moreover the main tributaries of the pl are longer and larger order rivers with floodplains that damp the flood pulse on the other hand ml tributaries are lower order rivers that drain the adjacent highlands more directly towards the lagoon thereafter the ml drainage basin s geomorphology imply that flood pulses arrive in the lagoon body less damped when compared to the patos lagoon the temporal pattern indicates that the wl signal is dominated by the river discharge which is typical of semi enclosed basins worldwide umgiesser et al 2014 compared the hydrodynamics of 10 mediterranean lagoons showing that those with a single inlet have exchange processes with the sea that are not significantly influenced by the wind however the wind forcing is responsible for increasing internal mixing and inducing wl set ups a comparison of two estuaries in the gulf of mexico showed that the water level response to increased river runoff is more pronounced in the closest estuary schroeder et al 1990 studies regarding the pl hydrodynamics agree on the dominance of the river discharge on determining the water level variability with scales longer than a monthly frequency barros and marques 2012 marques 2012 moller et al 2001 1996 on the other hand for time scales shorter than two weeks the water levels and circulation processes of the patos lagoon are dominated by winds fernandes et al 2005 the ml has been previously regarded as a water reservoir hirata et al 2010 oliveira et al 2015 three factors contribute to this treatment of the ml the high runoff of the tributaries during part of the year the choked configuration of the ml connection with the sgc and the prevailing incidence of northeasterly winds these factors increase the residence time of the water in the ml but also contribute to the establishment of an average slope on its surface during the study period the simulated water level of the mirim lagoon is always higher than that of the são gonçalo channel fig 5 the barotropic gradient between both compartments favors predominantly northward water flow the average wl and its maximum and minimum values are substantially different among the compartments the ml average wl is 4 5 m above the bathymetric reference level ranging between 2 7 m and 8 m for the sgc the average wl is 3 8 m ranging from 1 8 m to 7 m while the floodplains average water depth is 1 8 m and ranges from 0 6 m to 4 5 m however the temporal variability is similar for the three sites investigated in some situations the wl in both compartments become very close the reduced gradient favors the inversion of the flow direction which may occur in response to local wind forcing additionally the internal variations in wl of each compartment are not represented in fig 5 and such internal variability may create smaller scale and complex circulation patterns which are not investigated in this work the wl of the floodplains is possibly overestimated due to the simplified representation of their drainage because in this study the water can only leave the system through the sgc however there are at least three other water sinks in this system at the northern part of the floodplain there is a complex channel system called barra falsa that leads the water to another connection to the patos lagoon fig 1 these channels are not perennially active at the southern part of the sgc once the water overflows from the ml and the sgc eventually it can flow towards the taim wetlands and to the mangueira lake thereafter the road that crosses the taim wetlands partially obstructs this connection however a pipe system prevents their complete isolation in addition to these two superficial underrepresented paths there is also evidence of significant groundwater flow from the floodplains and irrigated areas towards the mangueira lake approximately 2 of the atmospheric inputs and the ocean in this region andrade et al 2012 attisano et al 2013 santos et al 2008 hence it is expected that part of the water that the model considers to be stocked in the system eventually finds other ways out of the system although the validation results are satisfactory such limitations on the representation of the msgs geomorphology imply that the interpretation of the floodplain results should be conducted with caution a wavelet analysis was carried out to identify the major temporal scales on which the processes occur in the wl time series for the northern part of the ml fig 6 shows the local and the global power spectra for the cross correlation between the wl river discharge and the wind intensity during the entire simulation there are processes with periodicities between 64 and 300 days indicating that the river discharge controls the variations in the wl at intra seasonal seasonal and annual timescales fig 6 b the global power spectrum corroborates these results indicating that processes longer than 64 days are dominant and control the wl variability of the ml fig 6 c on the other hand there are processes occurring with periods between 2 and 16 days indicating that the winds can modulate the variations in the wl at synoptic time scales fig 6 e the global power spectrum fig 6 f indicates that processes shorter than 16 days are dominant and contribute to the wl variability of the ml in shorter timescales the wavelet analysis suggests that the msgs behaves as a semi enclosed system and is dominated by the river discharge on longer time scales and is modulated by the wind action on shorter timescales the global power spectrum corroborates these findings with more energy for the processes occurring on longer timescales barros and marques 2012 and barros et al 2014 observed similar patterns when studying the patos lagoon river discharge the shorter time scale processes correspond to frontal system passages over the study region the presence of the south atlantic anticyclone and mobile cyclones with polar origins contribute to the high spatial and temporal variability of the wind circulation previous studies marques 2011 2012 also showed the influence of wind driven circulation over the study region with cycles with periods from 3 16 days 4 2 spatial patterns of the mirim lagoon water level the average water level of the ml is higher in the southern part this wind set up is a consequence of the dominance of winds from the northeastern quadrant fig 2 which dam the water discharged by the rivers creating a water bulk in the southern part of the lagoon the results show a wl that is approximately 0 10 m higher in the southern region of the ml compared to that in the north part additionally the wl at the western border is higher than that at the eastern border when analyzing the same latitudinal band and this finding corresponds to the prevailing westward zonal component of the winds the wl slope varies seasonally as the winds from the southern quadrant can temporarily modify this set up and even dislocate it northward fig 7 shows that the difference between the ml water level of northern and south regions is highly attenuated during the austral winter and autumn when the frequency of winds from the southern quadrant considerably increases the results suggest that although the river discharge dominates the water level variability on longer timescales the wind action modulates the water level spatial variability within the ml the increased incidence of winds from the northeast during austral spring and summer increases the average difference in wl between the northern and southern region of the ml to 0 18 m on the other hand the increased wind incidence from southern quadrant during austral autumn and winter lowers the average wl difference to 0 10 m however when considering single events instead of temporal averages the wind set up can reach wl values of up to 1 m the analysis of eventual cold front passages when the wind direction changes abruptly highlights the ability of the wind to induce set ups and set downs in the ml on this time scale the wl exhibits a broad range of values and induces the formation of barotropic gradients that change direction over periods shorter than a day the wl set up that is typically developed in the southern section of the lagoon is dislocated northwards in a rotational fashion around the basin center according to local wind direction oscillations the spatial response of the mirim lagoon wl to the local wind action is similar to that observed in the patos lagoon however the magnitude of the barotropic gradients created in the ml during these events is considerably higher despite the very similar orientation of both lagoons and the same wind regimes presiding over them other factors should explain such a difference firstly the spatial distribution of the main tributaries in relation to the wind is opposite in both lagoons in other words the inputs to the mirim lagoon come from the south while in the patos lagoon the main rivers are in the north it turns out that in the patos lagoon the damming winds in the tributaries are from the southern quadrant whereas the prevailing northeast winds favor runoff the effects of northeasterly winds on the patos lagoon also imply a lower wl in the coastal area which also favors lagoon runoff moller et al 2001 the residual velocities found for the 2000 2004 period is represented in fig 8 higher current intensities are observed in the sgc in the ml natural channel and in the eastern margin of the ml s wider region high velocities in the sgc are related to its narrow width and to the combination of the gravitational force and the barotropic gradient force caused by higher wl in the ml both directed towards the pl however the spatially homogeneous vectors and high velocities observed in the sgc floodplain are probably artificially generated by the coarse representation of the topography the spatial patterns in ml suggest that the residual circulation in the deeper areas is strongly influenced by the assymetric water level height found between the northern and southern region of the lagoon this slope in the water surface develops a barotropic gradient force directed upwind which is aligned with the direction of the gravitational force a large single gyre is developed where the ml is sufficiently wide and shallow to allow the formation of downwind currents by direct transference of momentum from the wind there the stress between upwind and downwind currents create the observed circulation cell during synoptic events the depth integrated velocity fields present large variability changes of wind direction cause changes in the barotropic gradient force direction similar wl and currents periodic changes on spatial patterns are likely to be found in other subtropical lagoons over the world as most of the subtropical regions have the wind variability highly influenced by the passage of cold fronts the orientation in regard to the wind direction combined with the spatial distribution of the tributaries amplify the ability of the wind to create set ups on the msgs influencing the circulation patterns the typical multiple circulation cells observed in elongated lakes and lagoons csanady 1973 1975 are different of the residual circulation of ml this is likely caused by a combination of a the alignment of ml s longest axis with preferential wind directions b the wind induced barotropic gradient force acting mostly in the same direction of the gravitational force and c the narrow and deeper geometry of the basin at its southern portion that reduces the development of downwind currents these observations show that the typical development of multiple gyres within elongated lakes and lagoons may be limited when the gravitational force is aligned with a well established barotropic gradient force in narrow water bodies as the sum of both forces may overcome the direct transference of momentum by the wind stress 4 3 flooding areas validating the hydrodynamic model in the floodplain was not possible through direct comparisons with measured water level data as there are no records for this compartment we therefore compared the simulated flooded area against ers2 derived data for six different days the differences between both are shown in fig 9 the yellow color indicates agreement the dark purple indicates a false positive i e the pixel is flooded in the simulation and dry or wet in the image and the bright purple indicates an omission i e the pixel is flooded in the image and wet or dry in the simulation we assumed that the element is flooded when under a water level greater than 0 10 m the higher false positive rate may be attributed to the limited representation of topography provided by the srtm dem the 90 m spatial resolution of the srtm data does not allow for an accurate representation of the complex terrain and the channels present on the floodplain which are better addressed by the 10 m spatial resolution of the ers 2 imagery in fact we observed more contiguously distributed flooded elements in the simulation results than in the images this result indicates that the actual terrain has elevation variations at a spatial scale that is not well represented in the srtm dem which may be of relevance for the determination of flood propagation paths comparing the total extent of the flooded area as estimated by the simulation and the ers2 imagery we observed that both series show similar behavior until august after august the ers 2 derived flooded area stabilizes and decreases while the simulated flooded area further increases fig 8 similarly vu et al 2015 simulated the hydrodynamics of the mekong river and its floodplain using the telemac 2d model and compared their results against flood maps derived from remote sensing data these authors also found a good correspondence between both datasets yet the model achieved its best performance in the flooding areas during the flooding periods furthermore medeiros and hagen 2013 showed that the wetting and drying algorithm class utilized in telemac 2d i e the element removal technique tends to perform better for advancing flooding waves than for retreating flooding waves which helps to explain the slower drying of the flooded elements nevertheless the same authors found that the element removal algorithm is the wetting and drying algorithm class that better captures the physics of the flooding and wetting process fig 10 shows a map with the number of days for which each element was flooded during the simulated period the western border of the floodplain is bounded by a region that never floods which does not happen at the eastern border this result indicates that the sgs overflows can reach a larger area eastward which may result from the terrain geomorphology and perhaps the wind action however the highest number of days flooded per year is related to the duration of the high water level in the lagoon and the channel rosa et al 2016 suggested that in the south of the ml geologically younger areas show higher risk to flooding hazards when compared to older areas which agrees with our results as the number of days that the element is flooded can be interpreted as an indicator of flood risk the terrain that extends westward of the sgc and the ml is bounded by the alluvial fan system which is the oldest depositional system on the rio grande do sul coastal plain tomazelli and villwock 2000 the currently active barrier system serves as the eastern border of the sgc floodplain the flood persistence map indicates that the adjacencies of the ml have nearly perennial flooded wetlands predominantly extending in the northeast southwest direction this wind set up may be related to that on the southern borders of the lagoon which leads to fluxes towards the flat areas and the embayments and concavities which can increase the terrain s erosion and lower the topography as the floodplain vegetation is damaged or even removed by the currents this effect is often observed in the north american great lakes especially after the incidence of storms bedford 1992 in this sense the larger wetlands surrounding the msgs when compared to the patos lagoon may be related to the larger wind set up occurring in the ml and to the inherited topography future works will include the patos lagoon and the mangueira lake in the simulation domain to quantify the exchanges between these water bodies additionally we hope to improve the floodplain representation with tandem x topographic data to which we were recently granted access through a deutsche luft und raumfahrt dlr announcement of opportunity 5 conclusions in the present paper we analyzed the results of a five year two dimensional hydrodynamic simulation of the mirim são gonçalo complex the water level variability is dominated by the river discharge from intra seasonal to annual timescales though the wind action is responsible for the temporal variations in the synoptic time scales although the geomorphological settings of the study area are closely linked to those of the patos lagoon drainage basin the system variability also resembles the plata basin regarding the amplitude and timing of the water level oscillations our results showed that the wind action is responsible for modulating the average water level set up in the southern part of the ml the water level assymetry between the southern and northern ml is persistent over all seasons although it is higher in the austral summer and spring and lower in the austral winter and autumn however the spatial patterns of water level quickly respond to changes in the wind direction which can occur in periods shorter than a day additionally depth integrated velocity fields respond to the barotropic gradient force developed by the water level slope over the lagoon the floodplain water levels exhibit temporal variability that is controlled by the water level of the são gonçalo channel and the mirim lagoon despite the typically higher water level in the southern region of the mirim lagoon the spatial distribution of the wetlands around its margins suggests that the inherited terrain elevation is the main factor controlling their occurrence the flooding persistence in the wetlands is related to the persistence of positive water level anomalies in the lagoon and the channel showing that water level variability is linked to the hydroperiod of the wetlands and highlighting the importance of maintaining the water variability within its natural patterns acknowledgments the authors are grateful to the coordenação de aperfeiçoamento de pessoal de nível superior capes the programa nacional de pós doutorado pnpd the conselho nacional de desenvolvimento científico e tecnológico cnpq under contract 304227 2016 1 and the fundação de amparo a pesquisa do estado do rio grande do sul fapergs for the grant no 17 2551 0001 159 7 further acknowledgments go to the brazilian navy for providing the bathymetric data to the brazilian national water agency and the agency for development of the mirim lagoon for supplying the fluvial discharge data to the open telemac mascaret consortium for freely distributing the telemac system and to the european space agency for making the ers sar data available for the study esa category 1 proposal no 6537 finally the authors are thankful to the supercomputing center of the federal university of rio grande do sul cesup ufrgs and to the national laboratory for scientific computing lncc where most of the computational work was carried out 
803,coastal lagoons channels and wetlands are sensitive ecosystems with high productivity and biodiversity these systems often provide society with the valuable freshwater resources and many ecosystem services in the subtropics the hydrological systems inherit the typically high climatic and weather variability characteristics of these zones therefore knowing the natural variability of these characteristics is crucial for the sustainable use of the water resources of these systems in the present paper we investigated the hydrodynamics of the mirim são gonçalo system which comprises a large shallow coastal lake a 78 km long channel and their adjacent floodplains and wetlands with a focus on water level oscillations we used a combination of numerical simulations gauge station data and synthetic aperture radar imaging to evaluate the influence of the incident winds and the discharges of the main tributaries on the system s water levels and the establishment of barotropic gradients we analyzed the water level variability of the mirim lagoon and the são gonçalo channel and their overflows to the adjacent floodplains the simulations are five years long and cover the period starting in january 2000 to december 2004 the analysis indicates that the discharge of the tributaries mainly governs the system s temporal patterns wind action has two distinct influences on the systems first the wind dams the water at the southern portion of the mirim lagoon which creates a persistent barotropic gradient in the surface this gradient is often destroyed and dislocated northwards in a rotational fashion when the wind blows from the southern quadrant second the wind perturbs the temporal variability patterns resulting in high frequency oscillations of the water level temporal signal flooding is frequent in the lands adjacent to the lagoon and the channel and results from the combination of the geomorphological and climatic settings of the region the system is surrounded by ancient lagoon deposits with an extremely flat and low lying topography which favors the flooding of large extents the large catchment area and the high precipitation rate over this region result in significant water level oscillations causing the system to overflow and leading to subsequent floods keywords hydrodynamic telemac2d flooding surface hydrology coastal lagoon natural channel floodplain wetlands 1 introduction lakes lagoons and rivers provide several ecosystem services and are vital sources of freshwater for human consumption and economic activities such water bodies and their adjacent floodplains are part of the same dynamic system junk et al 1989 tockner et al 2000 the ecosystems of which are adapted to natural water level fluctuations and impacted by human water use leira and cantonati 2008 understanding the water level variability of these environments is socioeconomically relevant water body hydrodynamics directly influence water quality and availability navigability conditions the residence time of pollutants sediment deposition patterns and dredging operations on the other hand human interventions and uses of the water can modify the natural variability in water levels often leading to the degradation of environmental quality in the extreme south of brazil lies the patos mirim lagoon complex which is the largest lagoon system in latin america fig 1 this system comprises the patos and mirim lagoons and the são gonçalo channel sgc a 78 km long channel that connects both lagoons the mirim lagoon waters are mostly drained towards the são gonçalo channel which in turn discharges in the patos lagoon estuary the mirim são gonçalo waters are part of the same drainage basin which is partially located in the south of brazil and partly lies on uruguayan lands this bi national hydrological system also has enormous environmental and socio economic importance surrounding the lagoon and the channel highly productive wetlands shelter a rich biodiversity asmus 1998 and are protected by national laws from the global point of view wetlands play a part in the carbon biogeochemical cycle representing the largest source of methane for the atmosphere meng et al 2016 whang et al 1996 since 2007 atmospheric methane levels began growing again after years of stable concentrations meng et al 2016 this trend has raised concerns about the positive climatic feedback between methane emissions from wetlands and increasing air temperatures however the wetlands surrounding the mirim são gonçalo system have been the subject of only a limited number of studies mostly focused on the taim wetlands area in the past the patos lagoon exported brackish waters to the mirim lagoon during low river discharge periods hirata et al 2010 in 1977 a sluice gate and a subsurface dam were built to prevent the salinization of the mirim lagoon and the são gonçalo channel because these features supply rio grande city with water for human consumption and provide several rice farms with water for irrigation these two activities have accounted for the primary water use of the mirim são gonçalo system msgs for many years at present there is increasing discussion about the establishment of a bi national brazil uruguay waterway and increasing the industrial uses of the msgs water however the mirim lagoon hydrodynamics have been the subject of only a few studies hirata et al 2010 oliveira et al 2015 and the são gonçalo channel and its adjacent floodplains and protected wetlands remain virtually unexamined hence the natural hydrological variability of the system is not well documented or investigated in fact the present state of the system is already modified by human interventions namely the rice crop irrigation channels a road landfill crossing the taim wetlands and the sluice gate the present paper aims to investigate the hydrodynamics of the mirim lagoon the são gonçalo channel and the adjacent floodplains using the telemac 2d hydrodynamic model and synthetic aperture radar imagery acquired by the european remote sensing 2 ers 2 mission the analysis focuses on water level fluctuations and the variability thereof in response to river discharge and wind action and estimates the flood extent of the sgc floodplain 1 1 physical aspects of the study area the msgs fig 1 lies on a broad coastal plain that developed during the quaternary in response to sea level oscillations tomazelli et al 2000 the deposition of an alluvial fan system and four subsequent barrier lagoon systems evolved from west to east and resulted in a very flat terrain on which higher elevations are spatially related with the oldest deposits rosa et al 2016 such as the alluvial fan deposits and the preserved parts of the ancient barriers dunes are also prominent topographic features the very flat geomorphology of the surrounding lands coupled with the shallowness of the water bodies and the high precipitation rates on the drainage basin imply that the msgs often overflows the sgc flows over an extensive and continuous and ancient holocene and pleistocene lacustrine deposit tomazelli et al 2000 surrounded by a perennial wetland and floods frequently duarte 2013 the drainage basin of the msgs covers 62 250 km2 when considering the tributaries and adjacent wetlands the mirim lagoon is the third largest south american lacustrine water body with 3749 km2 santos et al 2004 the climate is mesothermal with annual average temperatures between 14 o c and 18 o c and annual precipitation between 1 250 mm and 2 000 mm the prevailing winds are from the northeast yet during the autumn and the winter there is an increased incidence of winds from the southern quadrant compared to during summer and spring the anticyclonic atmospheric circulation over the south atlantic ocean determines that the predominant winds are from the northeast fig 2 however winds from the southern quadrant are also frequent during the passage of cold air masses and extra tropical cyclones parise et al 2009 these winds occur more often in the winter in response to the northward displacement of the polar front despite the strategic importance of the msgs to the brazilian and uruguayan economies national border controls and waterway systems this system lacks hydro graphical measurements such measures are restricted to water level time series from two gauge stations and to four years of nearly continuous river discharge data on the main tributaries the cebollati tacuari and jaguarão rivers covering a period from 2000 2004 fig 1 2 methods we investigated the mirim são gonçalo water level oscillations using a two dimensional hydrodynamic simulation the simulations were carried for a five year period and the model was forced by the river discharge and winds broadly accepted concepts such as the flood pulse concept and river continuum concept state that floodplains are part of the same dynamic system of the water body that they fringe and that the two features are linked by hydrological and ecological processes junk et al 1989 tockner et al 2000 in this sense we included the low lying lands fringing the mirim lagoon and the são gonçalo channel in the numerical domain a polygon that delineates a belt surrounding the lagoon and the channel with an elevation lower than 5 m defines the extent of the numerical domain this artificial polygon is coincident with a nearly continuous line with a slightly higher terrain slope and with an old map of the flooding areas in the vicinity of the msgs vieira 1982 2 1 hydrodynamic modeling we performed a five year hydrodynamic simulation of the msgs and its adjacent floodplains using the telemac 2d http www opentelemac org model this model uses the finite element technique and the characteristic curves method to solve the saint venant equations these equations are obtained by depth averaging the navier stokes equations when assuming the hydrostatic approximation the negligibility of the vertical velocities and the impermeability of the free surface and the bottom hervouet 2007 this approach has been widely employed in the modeling of rivers lakes and floodplains and achieves satisfactory results when the depth wise variability of the water properties can be neglected e g bates et al 1999 fernandes et al 2001 horritt and bates 2002 teng et al 2017 the computational domain considers four open liquid boundaries the jaguarão tacuari and cebollati rivers and the mouth of the são gonçalo channel the boundaries are forced with discharge data measured in gauge stations placed in the three most important tributaries and with water level measurements carried out near the sgc mouth fig 1 the brazilian national water agency distributes these data through its website http www hidroweb ana gov br the simulation covers the period from 1 january 2000 31 december 2004 the simulation period corresponds to the longest continuous record of the discharges of the main tributaries fig 3 the atmospheric boundaries are forced by wind data from the era interim reanalysis project http www ecmwf int and these data are provided by the european center of medium range weather forecast dee et al 2011 simmons et al 2006 once the initial conditions of the system are unknown we forced the boundaries with average time series of discharge and winds for one year previous to the year 2000 to warm up the simulation the bathymetry of the mirim lagoon and the são gonçalo channel were obtained by combining digitalized navigation charts produced by the brazilian navy with data acquired by partners to represent the topography of the water bodies adjacent floodplains we used the shuttle radar topographic mission srtm digital elevation model dem the srtm is a global dem and the data are available from the united states geological survey usgs at a spatial resolution of 90 m https www earthexplorer usgs gov however srtm data for the brazilian territory are available at the topodata project website http www dsr inpe br topodata the project is developed by the brazilian national institute for space research inpe and provides a geomorphometric database for the brazilian territory the srtm topographical data provided are post processed and interpolated to a 30 m grid 2 2 flood detection using ers 2 data synthetic aperture radar sar systems provide an appropriate dataset for investigating the presence of liquid water on the earth s surface and these systems are employed in many flood detection studies clement et al 2017 hahmann thomas wessel 2010 horritt et al 2010 pierdicca et al 2013 the liquid water specular backscatters the microwaves emitted by the sar systems decreasing the radiative energy that returns to the sensor in the images inundated areas result in darker pixels compared to those for dry surfaces especially in the absence of trees smith 1997 ulaby et al 1986 many techniques have been applied in the identification of flooded areas in sar imagery such as visual interpretation thresholding change detection and active contouring each of the approaches has different pros and cons related to the automation degree of the process and their computational costs martinis et al 2015 in this work we used a thresholding method that was developed specifically for the study area and is based on image histogram analysis and visual inspection of the ers 2 imagery in combination with a landsat etm image duarte 2013 the pixels located on the floodplain with backscattering values lower than 8 db and higher than 12 db are classified as wet while those presenting backscattering values smaller than 12 db are classified as flooded duarte 2013 six synthetic aperture radar sar images obtained by the ers 2 platform are used in the present study to retrieve information on the sgc floodplain flooded area we performed the calibration geometric correction and speckle filtering using the snap software the water bodies are masked out and the pixels are then classified as either flooded or not flooded using the regional algorithm which was developed specifically for the study area by duarte 2013 such images are employed in the present work to assess the performance of the model in simulating the flooding extent 3 calibration and validation of the hydrodynamic model the mirim lagoon is an elongated basin whose longest axis azimuth is nearly parallel to the preferential wind directions ne and sw thereafter it was expected that winds would be a major forcing determining water level oscillations of the msgs hence we calibrated the coefficient of wind influence by performing three simulations covering the year 2000 setting this paramether to 10 6 105 and 5 10 5 the results of each calibration experiment were compared to water level measurements acquired in the south of the mirim lagoon ml são vitória do palmar station svp and in the south of the sgc santa izabel station si the gauge stations data is distributed by the agency for development of the mirim lagoon http www wp ufpel edu br alm table 1 presents the time series obtained using each coefficient of wind influence we adopted the coefficient of wind influence of 105 because it provided the best combination of rmse bias and correlation coefficient with the observed time series additionally the 106 coefficient produced a wl time series with smoothed short term variability whereas the 5 10 5 coefficient resulted in amplified short term wl oscillations the similar correlation coefficients obtained between the observed time series and the simulated time series using different coefficients of wind influence suggests that the river discharge is the primary factor controlling the water level however the wl oscillations that occur with short periodicities are determined by the wind action we validate the hydrodynamic model by comparing the simulated water level against two water level time series acquired in the same gauge stations svp and si for the entire period of simulation 2000 2004 we perform the comparisons between the measured and simulated data for each gauge station the simulated and measured time series are presented in fig 4 the time series show good agreement but the simulated water levels increase and decrease faster than the measured data this observation may indicate the importance of the exchanges between the msgs and other water bodies such as the mangueira lake the connection between both systems occurs through the taim wetland a flat land lying over an interruption of the ancient coastal barrier that isolates the water bodies under high precipitation and consequently high water levels exchanges can occur from one lake to another da paz et al 2003 these processes are neglected in the present study due to the lack of bathymetric data available on the mangueira lake a road crosses the taim wetland reducing the exchanges between the mirim lagoon and the mangueira lake however exchanges still occur through a pipe system passing the road which also serves as a corridor for local fauna the correlation coefficients of the time series are r 0 84 for the svp and r 0 83 for the si gauge stations and these results are significant at the 95 level these results show that the hydrodynamic model is successful in representing the temporal variability of the water level time series the maximum minimum water level anomalies calculated by the model in si are 3 3 m 1 8 m and 3 8 m 2 2 m in svp the maximum minimum measured water levels are 2 4 m 2 2 m in si and 2 3 m 2 4 m in svp additionally it is worth noting that the largest discrepancies occur in 2002 which was a year of very high precipitation in the region 4 results and discussion 4 1 water level oscillations the water level wl oscillations are presented in fig 3 for each compartment separately lagoon channel and floodplains higher water levels are observed from late autumn to early spring reflecting the typical seasonal signal of precipitation and river discharge of the study region in the patos lagoon drainage basin the discharge peaks occur in winter and spring moller et al 1996 whereas the la plata river has discharge peaks in the autumn and spring piola et al 2005 hence the mirim são gonçalo system shows temporal patterns that are intermediate relative to the northern and southwest neighboring drainage basins although the ml resembles the patos lagoon in geomorphological terms the amplitude of wl variation of the patos lagoon is within 1 5 m to 2 m marques 2012 which the wl variation in the ml greatly exceeds in this sense the ml behavior better approximates its western neighbor basins such as the lower paraná and uruguay portions of the plata basin where the water level can show oscillations up to 6 m maheu 2003 the different amplitude wl variability amplitude found between both basins are possibly related to disctict precipitation patterns occurring on their drainage basins maier et al 2016 additionally the passage of cold fronts and extratropical cyclones are the main atmospheric processes that cause precipitation such cold fronts reach the ml s drainage basin before reaching the pl s usually causing more severe precipitation events in the first moreover the main tributaries of the pl are longer and larger order rivers with floodplains that damp the flood pulse on the other hand ml tributaries are lower order rivers that drain the adjacent highlands more directly towards the lagoon thereafter the ml drainage basin s geomorphology imply that flood pulses arrive in the lagoon body less damped when compared to the patos lagoon the temporal pattern indicates that the wl signal is dominated by the river discharge which is typical of semi enclosed basins worldwide umgiesser et al 2014 compared the hydrodynamics of 10 mediterranean lagoons showing that those with a single inlet have exchange processes with the sea that are not significantly influenced by the wind however the wind forcing is responsible for increasing internal mixing and inducing wl set ups a comparison of two estuaries in the gulf of mexico showed that the water level response to increased river runoff is more pronounced in the closest estuary schroeder et al 1990 studies regarding the pl hydrodynamics agree on the dominance of the river discharge on determining the water level variability with scales longer than a monthly frequency barros and marques 2012 marques 2012 moller et al 2001 1996 on the other hand for time scales shorter than two weeks the water levels and circulation processes of the patos lagoon are dominated by winds fernandes et al 2005 the ml has been previously regarded as a water reservoir hirata et al 2010 oliveira et al 2015 three factors contribute to this treatment of the ml the high runoff of the tributaries during part of the year the choked configuration of the ml connection with the sgc and the prevailing incidence of northeasterly winds these factors increase the residence time of the water in the ml but also contribute to the establishment of an average slope on its surface during the study period the simulated water level of the mirim lagoon is always higher than that of the são gonçalo channel fig 5 the barotropic gradient between both compartments favors predominantly northward water flow the average wl and its maximum and minimum values are substantially different among the compartments the ml average wl is 4 5 m above the bathymetric reference level ranging between 2 7 m and 8 m for the sgc the average wl is 3 8 m ranging from 1 8 m to 7 m while the floodplains average water depth is 1 8 m and ranges from 0 6 m to 4 5 m however the temporal variability is similar for the three sites investigated in some situations the wl in both compartments become very close the reduced gradient favors the inversion of the flow direction which may occur in response to local wind forcing additionally the internal variations in wl of each compartment are not represented in fig 5 and such internal variability may create smaller scale and complex circulation patterns which are not investigated in this work the wl of the floodplains is possibly overestimated due to the simplified representation of their drainage because in this study the water can only leave the system through the sgc however there are at least three other water sinks in this system at the northern part of the floodplain there is a complex channel system called barra falsa that leads the water to another connection to the patos lagoon fig 1 these channels are not perennially active at the southern part of the sgc once the water overflows from the ml and the sgc eventually it can flow towards the taim wetlands and to the mangueira lake thereafter the road that crosses the taim wetlands partially obstructs this connection however a pipe system prevents their complete isolation in addition to these two superficial underrepresented paths there is also evidence of significant groundwater flow from the floodplains and irrigated areas towards the mangueira lake approximately 2 of the atmospheric inputs and the ocean in this region andrade et al 2012 attisano et al 2013 santos et al 2008 hence it is expected that part of the water that the model considers to be stocked in the system eventually finds other ways out of the system although the validation results are satisfactory such limitations on the representation of the msgs geomorphology imply that the interpretation of the floodplain results should be conducted with caution a wavelet analysis was carried out to identify the major temporal scales on which the processes occur in the wl time series for the northern part of the ml fig 6 shows the local and the global power spectra for the cross correlation between the wl river discharge and the wind intensity during the entire simulation there are processes with periodicities between 64 and 300 days indicating that the river discharge controls the variations in the wl at intra seasonal seasonal and annual timescales fig 6 b the global power spectrum corroborates these results indicating that processes longer than 64 days are dominant and control the wl variability of the ml fig 6 c on the other hand there are processes occurring with periods between 2 and 16 days indicating that the winds can modulate the variations in the wl at synoptic time scales fig 6 e the global power spectrum fig 6 f indicates that processes shorter than 16 days are dominant and contribute to the wl variability of the ml in shorter timescales the wavelet analysis suggests that the msgs behaves as a semi enclosed system and is dominated by the river discharge on longer time scales and is modulated by the wind action on shorter timescales the global power spectrum corroborates these findings with more energy for the processes occurring on longer timescales barros and marques 2012 and barros et al 2014 observed similar patterns when studying the patos lagoon river discharge the shorter time scale processes correspond to frontal system passages over the study region the presence of the south atlantic anticyclone and mobile cyclones with polar origins contribute to the high spatial and temporal variability of the wind circulation previous studies marques 2011 2012 also showed the influence of wind driven circulation over the study region with cycles with periods from 3 16 days 4 2 spatial patterns of the mirim lagoon water level the average water level of the ml is higher in the southern part this wind set up is a consequence of the dominance of winds from the northeastern quadrant fig 2 which dam the water discharged by the rivers creating a water bulk in the southern part of the lagoon the results show a wl that is approximately 0 10 m higher in the southern region of the ml compared to that in the north part additionally the wl at the western border is higher than that at the eastern border when analyzing the same latitudinal band and this finding corresponds to the prevailing westward zonal component of the winds the wl slope varies seasonally as the winds from the southern quadrant can temporarily modify this set up and even dislocate it northward fig 7 shows that the difference between the ml water level of northern and south regions is highly attenuated during the austral winter and autumn when the frequency of winds from the southern quadrant considerably increases the results suggest that although the river discharge dominates the water level variability on longer timescales the wind action modulates the water level spatial variability within the ml the increased incidence of winds from the northeast during austral spring and summer increases the average difference in wl between the northern and southern region of the ml to 0 18 m on the other hand the increased wind incidence from southern quadrant during austral autumn and winter lowers the average wl difference to 0 10 m however when considering single events instead of temporal averages the wind set up can reach wl values of up to 1 m the analysis of eventual cold front passages when the wind direction changes abruptly highlights the ability of the wind to induce set ups and set downs in the ml on this time scale the wl exhibits a broad range of values and induces the formation of barotropic gradients that change direction over periods shorter than a day the wl set up that is typically developed in the southern section of the lagoon is dislocated northwards in a rotational fashion around the basin center according to local wind direction oscillations the spatial response of the mirim lagoon wl to the local wind action is similar to that observed in the patos lagoon however the magnitude of the barotropic gradients created in the ml during these events is considerably higher despite the very similar orientation of both lagoons and the same wind regimes presiding over them other factors should explain such a difference firstly the spatial distribution of the main tributaries in relation to the wind is opposite in both lagoons in other words the inputs to the mirim lagoon come from the south while in the patos lagoon the main rivers are in the north it turns out that in the patos lagoon the damming winds in the tributaries are from the southern quadrant whereas the prevailing northeast winds favor runoff the effects of northeasterly winds on the patos lagoon also imply a lower wl in the coastal area which also favors lagoon runoff moller et al 2001 the residual velocities found for the 2000 2004 period is represented in fig 8 higher current intensities are observed in the sgc in the ml natural channel and in the eastern margin of the ml s wider region high velocities in the sgc are related to its narrow width and to the combination of the gravitational force and the barotropic gradient force caused by higher wl in the ml both directed towards the pl however the spatially homogeneous vectors and high velocities observed in the sgc floodplain are probably artificially generated by the coarse representation of the topography the spatial patterns in ml suggest that the residual circulation in the deeper areas is strongly influenced by the assymetric water level height found between the northern and southern region of the lagoon this slope in the water surface develops a barotropic gradient force directed upwind which is aligned with the direction of the gravitational force a large single gyre is developed where the ml is sufficiently wide and shallow to allow the formation of downwind currents by direct transference of momentum from the wind there the stress between upwind and downwind currents create the observed circulation cell during synoptic events the depth integrated velocity fields present large variability changes of wind direction cause changes in the barotropic gradient force direction similar wl and currents periodic changes on spatial patterns are likely to be found in other subtropical lagoons over the world as most of the subtropical regions have the wind variability highly influenced by the passage of cold fronts the orientation in regard to the wind direction combined with the spatial distribution of the tributaries amplify the ability of the wind to create set ups on the msgs influencing the circulation patterns the typical multiple circulation cells observed in elongated lakes and lagoons csanady 1973 1975 are different of the residual circulation of ml this is likely caused by a combination of a the alignment of ml s longest axis with preferential wind directions b the wind induced barotropic gradient force acting mostly in the same direction of the gravitational force and c the narrow and deeper geometry of the basin at its southern portion that reduces the development of downwind currents these observations show that the typical development of multiple gyres within elongated lakes and lagoons may be limited when the gravitational force is aligned with a well established barotropic gradient force in narrow water bodies as the sum of both forces may overcome the direct transference of momentum by the wind stress 4 3 flooding areas validating the hydrodynamic model in the floodplain was not possible through direct comparisons with measured water level data as there are no records for this compartment we therefore compared the simulated flooded area against ers2 derived data for six different days the differences between both are shown in fig 9 the yellow color indicates agreement the dark purple indicates a false positive i e the pixel is flooded in the simulation and dry or wet in the image and the bright purple indicates an omission i e the pixel is flooded in the image and wet or dry in the simulation we assumed that the element is flooded when under a water level greater than 0 10 m the higher false positive rate may be attributed to the limited representation of topography provided by the srtm dem the 90 m spatial resolution of the srtm data does not allow for an accurate representation of the complex terrain and the channels present on the floodplain which are better addressed by the 10 m spatial resolution of the ers 2 imagery in fact we observed more contiguously distributed flooded elements in the simulation results than in the images this result indicates that the actual terrain has elevation variations at a spatial scale that is not well represented in the srtm dem which may be of relevance for the determination of flood propagation paths comparing the total extent of the flooded area as estimated by the simulation and the ers2 imagery we observed that both series show similar behavior until august after august the ers 2 derived flooded area stabilizes and decreases while the simulated flooded area further increases fig 8 similarly vu et al 2015 simulated the hydrodynamics of the mekong river and its floodplain using the telemac 2d model and compared their results against flood maps derived from remote sensing data these authors also found a good correspondence between both datasets yet the model achieved its best performance in the flooding areas during the flooding periods furthermore medeiros and hagen 2013 showed that the wetting and drying algorithm class utilized in telemac 2d i e the element removal technique tends to perform better for advancing flooding waves than for retreating flooding waves which helps to explain the slower drying of the flooded elements nevertheless the same authors found that the element removal algorithm is the wetting and drying algorithm class that better captures the physics of the flooding and wetting process fig 10 shows a map with the number of days for which each element was flooded during the simulated period the western border of the floodplain is bounded by a region that never floods which does not happen at the eastern border this result indicates that the sgs overflows can reach a larger area eastward which may result from the terrain geomorphology and perhaps the wind action however the highest number of days flooded per year is related to the duration of the high water level in the lagoon and the channel rosa et al 2016 suggested that in the south of the ml geologically younger areas show higher risk to flooding hazards when compared to older areas which agrees with our results as the number of days that the element is flooded can be interpreted as an indicator of flood risk the terrain that extends westward of the sgc and the ml is bounded by the alluvial fan system which is the oldest depositional system on the rio grande do sul coastal plain tomazelli and villwock 2000 the currently active barrier system serves as the eastern border of the sgc floodplain the flood persistence map indicates that the adjacencies of the ml have nearly perennial flooded wetlands predominantly extending in the northeast southwest direction this wind set up may be related to that on the southern borders of the lagoon which leads to fluxes towards the flat areas and the embayments and concavities which can increase the terrain s erosion and lower the topography as the floodplain vegetation is damaged or even removed by the currents this effect is often observed in the north american great lakes especially after the incidence of storms bedford 1992 in this sense the larger wetlands surrounding the msgs when compared to the patos lagoon may be related to the larger wind set up occurring in the ml and to the inherited topography future works will include the patos lagoon and the mangueira lake in the simulation domain to quantify the exchanges between these water bodies additionally we hope to improve the floodplain representation with tandem x topographic data to which we were recently granted access through a deutsche luft und raumfahrt dlr announcement of opportunity 5 conclusions in the present paper we analyzed the results of a five year two dimensional hydrodynamic simulation of the mirim são gonçalo complex the water level variability is dominated by the river discharge from intra seasonal to annual timescales though the wind action is responsible for the temporal variations in the synoptic time scales although the geomorphological settings of the study area are closely linked to those of the patos lagoon drainage basin the system variability also resembles the plata basin regarding the amplitude and timing of the water level oscillations our results showed that the wind action is responsible for modulating the average water level set up in the southern part of the ml the water level assymetry between the southern and northern ml is persistent over all seasons although it is higher in the austral summer and spring and lower in the austral winter and autumn however the spatial patterns of water level quickly respond to changes in the wind direction which can occur in periods shorter than a day additionally depth integrated velocity fields respond to the barotropic gradient force developed by the water level slope over the lagoon the floodplain water levels exhibit temporal variability that is controlled by the water level of the são gonçalo channel and the mirim lagoon despite the typically higher water level in the southern region of the mirim lagoon the spatial distribution of the wetlands around its margins suggests that the inherited terrain elevation is the main factor controlling their occurrence the flooding persistence in the wetlands is related to the persistence of positive water level anomalies in the lagoon and the channel showing that water level variability is linked to the hydroperiod of the wetlands and highlighting the importance of maintaining the water variability within its natural patterns acknowledgments the authors are grateful to the coordenação de aperfeiçoamento de pessoal de nível superior capes the programa nacional de pós doutorado pnpd the conselho nacional de desenvolvimento científico e tecnológico cnpq under contract 304227 2016 1 and the fundação de amparo a pesquisa do estado do rio grande do sul fapergs for the grant no 17 2551 0001 159 7 further acknowledgments go to the brazilian navy for providing the bathymetric data to the brazilian national water agency and the agency for development of the mirim lagoon for supplying the fluvial discharge data to the open telemac mascaret consortium for freely distributing the telemac system and to the european space agency for making the ers sar data available for the study esa category 1 proposal no 6537 finally the authors are thankful to the supercomputing center of the federal university of rio grande do sul cesup ufrgs and to the national laboratory for scientific computing lncc where most of the computational work was carried out 
804,discretisation of the friction source terms 3 4 solution procedure 3 5 stability criterion 4 model validation 4 1 two dimensional uniform flow 4 2 overland flow on an idealised v shaped catchment 5 application to a real world rainfall flooding event 6 conclusions acknowledgements audusse 2004 2050 2065 e berger 2011 1195 1206 m bermudez 1994 1049 1071 a burguete 2008 403 425 j busaman 2015 a cea 2015 5464 5486 l cea 2010 88 102 l chow 1959 v openchannelhydraulics costabile 2013 554 569 p digiammarco 1996 267 291 p fiedler 2000 219 240 f hou 2013 107 131 j juez 2014 142 163 c juez 2013 166 204 c kao 2012 232 244 h liang 2006 1833 1845 d liang 2007 811 826 d liang 2009 873 884 q murillo 2012 6861 6906 j murillo 2012 1963 2001 j rousseau 2015 4015012 m sanders 2010 1456 1467 b simons 2014 375 391 f singh 2015 4014089 j song 2011 960 980 l toro 2001 e shockcapturingmethodsforfreesurfaceshallowflow xia 2018 174 191 x xia 2017 3730 3759 x xing 2011 339 349 y yu 2017 1 12 c yu 2014 1 13 c xiax2018x87 xiax2018x87x97 xiax2018x87xx xiax2018x87x97xx full 2018 05 09t10 36 30z fundingbody natural environment research council http creativecommons org licenses by 4 0 hefce 2019 05 17t00 00 00 000z http creativecommons org licenses by nc nd 4 0 this is an open access article under the cc by license 2018 the authors published by elsevier ltd 2019 03 03t05 00 00 951z http vtw elsevier com data voc addontypes 50 7 nlp s0309170818302124 nerc sinatra ne k008781 1 this work is funded by the nerc sinatra and tenderly projects grant no ne k008781 1 and flood prepared project grant no ne p017134 1 item s0309 1708 18 30212 4 s0309170818302124 1 s2 0 s0309170818302124 10 1016 j advwatres 2018 05 004 271718 2019 12 31t11 09 48 628609z 2018 07 01 2018 07 31 unlimited nerc 1 s2 0 s0309170818302124 main pdf https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 main application pdf 5a3136fbbd2afa1fc08a348053563d6f main pdf main pdf pdf true 2150545 main 11 1 s2 0 s0309170818302124 main 1 png https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 preview image png 50975270190a9a9f998b536ba56e4660 main 1 png main 1 png png 52785 849 656 image web pdf 1 1 s2 0 s0309170818302124 gr1 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr1 thumbnail image gif 2e5eed042e48c3df7f762caf25417aa0 gr1 sml gr1 gr1 sml sml 9920 164 204 image thumbnail 1 s2 0 s0309170818302124 gr2 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr2 thumbnail image gif 0901b0d573368746d2bb49d297ba3cd2 gr2 sml gr2 gr2 sml sml 7161 163 155 image thumbnail 1 s2 0 s0309170818302124 gr3 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr3 thumbnail image gif 10295289f9f94bacce1353fa54bce76a gr3 sml gr3 gr3 sml sml 3217 164 210 image thumbnail 1 s2 0 s0309170818302124 gr4 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr4 thumbnail image gif e91d3cc3163b49a2d558f9aafec7a481 gr4 sml gr4 gr4 sml sml 4549 83 219 image thumbnail 1 s2 0 s0309170818302124 gr5 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr5 thumbnail image gif 2ec0b83d1e5bf0f7397258e53362be89 gr5 sml gr5 gr5 sml sml 16863 156 219 image thumbnail 1 s2 0 s0309170818302124 gr6 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr6 thumbnail image gif 7bf4e3942492bec70ce88cd7ec2a7c0d gr6 sml gr6 gr6 sml sml 3619 94 219 image thumbnail 1 s2 0 s0309170818302124 gr7 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr7 thumbnail image gif 44ecab3f1eb0153c2eeecb3387eff524 gr7 sml gr7 gr7 sml sml 20517 156 219 image thumbnail 1 s2 0 s0309170818302124 gr8 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr8 thumbnail image gif 0b803ff9b4308c54a3a0793d3c26419a gr8 sml gr8 gr8 sml sml 15415 127 219 image thumbnail 1 s2 0 s0309170818302124 gr9 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr9 thumbnail image gif 7ed1f649b2776a5197832457c23ef57c gr9 sml gr9 gr9 sml sml 5400 164 216 image thumbnail 1 s2 0 s0309170818302124 gr1 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr1 downsampled image jpeg fba60279499141fd01256df9f6d7b138 gr1 jpg gr1 gr1 jpg jpg 82430 478 596 image downsampled 1 s2 0 s0309170818302124 gr2 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr2 downsampled image jpeg 6d111f043f09340458ed543c838ac3ea gr2 jpg gr2 gr2 jpg jpg 76941 594 563 image downsampled 1 s2 0 s0309170818302124 gr3 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr3 downsampled image jpeg a12bad38501859a91cb967d65942c1d9 gr3 jpg gr3 gr3 jpg jpg 12532 243 311 image downsampled 1 s2 0 s0309170818302124 gr4 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr4 downsampled image jpeg 0b76d21c43e5aaf63890cae6b8c5aea1 gr4 jpg gr4 gr4 jpg jpg 29614 215 565 image downsampled 1 s2 0 s0309170818302124 gr5 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr5 downsampled image jpeg ed060d4c3861bcd76acee8a0c6eb546d gr5 jpg gr5 gr5 jpg jpg 55878 323 452 image downsampled 1 s2 0 s0309170818302124 gr6 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr6 downsampled image jpeg 03cd17277cbdf19249389415592ab270 gr6 jpg gr6 gr6 jpg jpg 21542 210 489 image downsampled 1 s2 0 s0309170818302124 gr7 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr7 downsampled image jpeg 938a4af4418718c77dbb9dcd23dd2d54 gr7 jpg gr7 gr7 jpg jpg 83173 322 452 image downsampled 1 s2 0 s0309170818302124 gr8 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr8 downsampled image jpeg 662522f37beb671eaf71671dc958131f gr8 jpg gr8 gr8 jpg jpg 113562 460 791 image downsampled 1 s2 0 s0309170818302124 gr9 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr9 downsampled image jpeg f8fd7773bc21983a53a1aaa98628ec94 gr9 jpg gr9 gr9 jpg jpg 22690 296 391 image downsampled 1 s2 0 s0309170818302124 gr1 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr1 highres image jpeg bf0de6e158e3f6faa3dffafc5f96c912 gr1 lrg jpg gr1 gr1 lrg jpg jpg 866851 2540 3168 image high res 1 s2 0 s0309170818302124 gr2 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr2 highres image jpeg 4c2f7fcd3921ca86f20976c33fc8e0ab gr2 lrg jpg gr2 gr2 lrg jpg jpg 783508 3153 2990 image high res 1 s2 0 s0309170818302124 gr3 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr3 highres image jpeg 04c4b0fb1aac74ed4b443b93915b0e0f gr3 lrg jpg gr3 gr3 lrg jpg jpg 128694 1292 1654 image high res 1 s2 0 s0309170818302124 gr4 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr4 highres image jpeg 48179f88ffec986fa7aaa327d3c86fa1 gr4 lrg jpg gr4 gr4 lrg jpg jpg 229657 950 2500 image high res 1 s2 0 s0309170818302124 gr5 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr5 highres image jpeg 2d97573ae01851adce627309c053aba6 gr5 lrg jpg gr5 gr5 lrg jpg jpg 443750 1427 2000 image high res 1 s2 0 s0309170818302124 gr6 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr6 highres image jpeg 0e61c315289a473ef78efe12f3ca51ea gr6 lrg jpg gr6 gr6 lrg jpg jpg 227817 1119 2600 image high res 1 s2 0 s0309170818302124 gr7 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr7 highres image jpeg 69d16c01437889226fc5817d24b9b71f gr7 lrg jpg gr7 gr7 lrg jpg jpg 811844 1426 2000 image high res 1 s2 0 s0309170818302124 gr8 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr8 highres image jpeg 9c9b3c0ac5f4b6d1f957abd3c1f0ba44 gr8 lrg jpg gr8 gr8 lrg jpg jpg 967052 2035 3500 image high res 1 s2 0 s0309170818302124 gr9 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr9 highres image jpeg 71233a46afd50b65f3c44a96573fa47c gr9 lrg jpg gr9 gr9 lrg jpg jpg 229243 1576 2080 image high res 1 s2 0 s0309170818302124 si1 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 167b71711c1a9d7597ceecdd3eedffcf si1 gif si1 si1 gif gif 740 40 120 altimg 1 s2 0 s0309170818302124 si10 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 69afa682129d974177cb36d377a00f20 si10 gif si10 si10 gif gif 2082 55 418 altimg 1 s2 0 s0309170818302124 si11 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 0a7fe3cf1354fa60c2d27f5b640ccf75 si11 gif si11 si11 gif gif 1392 23 394 altimg 1 s2 0 s0309170818302124 si12 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif d1c52fcf2e4c8d93425aebe9da51a169 si12 gif si12 si12 gif gif 1464 23 412 altimg 1 s2 0 s0309170818302124 si13 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif b6bdb1b48c5c13783ac2e13b711a2174 si13 gif si13 si13 gif gif 634 19 182 altimg 1 s2 0 s0309170818302124 si14 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif e048c1bb801c38f4466062385d3a29e4 si14 gif si14 si14 gif gif 1340 19 407 altimg 1 s2 0 s0309170818302124 si15 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 0d6e56dbe50b8638574129bf79a040e5 si15 gif si15 si15 gif gif 869 44 157 altimg 1 s2 0 s0309170818302124 si16 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 99b98ed25096b0c2573ca035f150963e si16 gif si16 si16 gif gif 713 19 147 altimg 1 s2 0 s0309170818302124 si17 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 589bb9ed7702f41da41c1c623ef54da6 si17 gif si17 si17 gif gif 1513 45 214 altimg 1 s2 0 s0309170818302124 si18 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 39251782cfd14fa3c88715efa09c38e9 si18 gif si18 si18 gif gif 1846 44 323 altimg 1 s2 0 s0309170818302124 si19 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif ea7f695a71ce60986953aff07b67d4f4 si19 gif si19 si19 gif gif 1991 68 342 altimg 1 s2 0 s0309170818302124 si2 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif d274787128980bd6c72578d5b6b7ad4b si2 gif si2 si2 gif gif 1412 44 295 altimg 1 s2 0 s0309170818302124 si20 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 8245fc6dbf08b3ce04e751401e8c05c3 si20 gif si20 si20 gif gif 242 22 29 altimg 1 s2 0 s0309170818302124 si21 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 8696614207f4658e919576ac5c480161 si21 gif si21 si21 gif gif 460 23 115 altimg 1 s2 0 s0309170818302124 si22 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 692ce5c9363353bddbe5e2e8939d4689 si22 gif si22 si22 gif gif 2331 45 404 altimg 1 s2 0 s0309170818302124 si23 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 70a9c215d56ec78ad0409e7578d846c9 si23 gif si23 si23 gif gif 1995 34 458 altimg 1 s2 0 s0309170818302124 si24 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 4cc22f1144c58aa7088836607414c614 si24 gif si24 si24 gif gif 1965 34 458 altimg 1 s2 0 s0309170818302124 si25 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 2f3a5f3b16ad894ceeab806fefffc3c9 si25 gif si25 si25 gif gif 956 27 192 altimg 1 s2 0 s0309170818302124 si26 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif e9890b23cc33a89d6f30379b5435746a si26 gif si26 si26 gif gif 253 21 34 altimg 1 s2 0 s0309170818302124 si27 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 92f7d85624083f01dac879b6e2cd58a1 si27 gif si27 si27 gif gif 262 24 34 altimg 1 s2 0 s0309170818302124 si28 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 22df886f10faafd3b96a56b57a4c8f02 si28 gif si28 si28 gif gif 1941 34 444 altimg 1 s2 0 s0309170818302124 si29 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif f2d3b2d80c34e7e2969d2510dd154de0 si29 gif si29 si29 gif gif 1961 34 443 altimg 1 s2 0 s0309170818302124 si3 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 1bd49c4407375f860e1265cac9705df8 si3 gif si3 si3 gif gif 652 24 130 altimg 1 s2 0 s0309170818302124 si30 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 12221b44dd1542c9ef3dfbc21b171c9d si30 gif si30 si30 gif gif 1110 50 154 altimg 1 s2 0 s0309170818302124 si31 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 2479452678437fd27e06d531c008889d si31 gif si31 si31 gif gif 2524 70 459 altimg 1 s2 0 s0309170818302124 si32 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif c20468093fa97eab3ad5dc8e50b76e9c si32 gif si32 si32 gif gif 1161 22 302 altimg 1 s2 0 s0309170818302124 si33 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 7ced4d658da6695e042ebc5801866761 si33 gif si33 si33 gif gif 1955 58 374 altimg 1 s2 0 s0309170818302124 si34 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif ebb454593b6dcad3700b4a53fc65ac8c si34 gif si34 si34 gif gif 1934 58 374 altimg 1 s2 0 s0309170818302124 si35 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 15509b18983582d7d23d00d6e06dffd1 si35 gif si35 si35 gif gif 2927 109 373 altimg 1 s2 0 s0309170818302124 si36 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 7d59efcc3318ff64835ffc8d9aa07490 si36 gif si36 si36 gif gif 2903 109 373 altimg 1 s2 0 s0309170818302124 si37 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif d59ab6175552297b06be45de8706eaf3 si37 gif si37 si37 gif gif 2868 109 373 altimg 1 s2 0 s0309170818302124 si38 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 2250fe1be74a413ff8287bd560954ed7 si38 gif si38 si38 gif gif 2844 109 373 altimg 1 s2 0 s0309170818302124 si39 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif ee11e04479dbf7145c3d66e158a1f655 si39 gif si39 si39 gif gif 364 21 70 altimg 1 s2 0 s0309170818302124 si4 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 72311005f3260280fd757ae5da32ec20 si4 gif si4 si4 gif gif 1117 51 239 altimg 1 s2 0 s0309170818302124 si40 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 95e5d6da6b55d0448f5f382f06852cbd si40 gif si40 si40 gif gif 361 21 70 altimg 1 s2 0 s0309170818302124 si41 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 2ea7480bfa7c53cffebec7ceba84d29e si41 gif si41 si41 gif gif 2658 87 375 altimg 1 s2 0 s0309170818302124 si42 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 0e81767d3f258a381e2dbf4de7eda5bf si42 gif si42 si42 gif gif 321 21 51 altimg 1 s2 0 s0309170818302124 si43 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 33d6fb07f9627dd8ccf23fc364846963 si43 gif si43 si43 gif gif 3115 87 411 altimg 1 s2 0 s0309170818302124 si44 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif e48607c7ba9f3f92b1d344cfd542c7e7 si44 gif si44 si44 gif gif 371 21 81 altimg 1 s2 0 s0309170818302124 si45 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 9803dcc68521b6644220a63612d8fb54 si45 gif si45 si45 gif gif 5129 94 668 altimg 1 s2 0 s0309170818302124 si46 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 8372589e228046baa9acb656c56758a8 si46 gif si46 si46 gif gif 5217 94 664 altimg 1 s2 0 s0309170818302124 si47 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif db8edcada0695764231895635dcde801 si47 gif si47 si47 gif gif 1723 70 288 altimg 1 s2 0 s0309170818302124 si48 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 48a9d2a3b6fe2358e7c81be993cf570c si48 gif si48 si48 gif gif 1742 70 288 altimg 1 s2 0 s0309170818302124 si49 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 60563a04c48826ed5a1730f5442e1a60 si49 gif si49 si49 gif gif 504 21 108 altimg 1 s2 0 s0309170818302124 si5 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 998ed3d347ba4d6a9b46a1e1498781c9 si5 gif si5 si5 gif gif 1132 44 205 altimg 1 s2 0 s0309170818302124 si50 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 0ecff4f1a45948b1fc9a619b515ca434 si50 gif si50 si50 gif gif 518 24 108 altimg 1 s2 0 s0309170818302124 si51 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif a99318182202b90721c1acede5e42cce si51 gif si51 si51 gif gif 199 18 18 altimg 1 s2 0 s0309170818302124 si52 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif ce8361ef426b0c3a38c884f7b7505781 si52 gif si52 si52 gif gif 211 21 18 altimg 1 s2 0 s0309170818302124 si53 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 614bc71a40824704300ebdd6d79985e9 si53 gif si53 si53 gif gif 935 44 170 altimg 1 s2 0 s0309170818302124 si54 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 849ab1cf125b582c47f125b3cb1ec977 si54 gif si54 si54 gif gif 1582 44 322 altimg 1 s2 0 s0309170818302124 si55 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 29197ce822330c9ece82858e76048abc si55 gif si55 si55 gif gif 1578 44 322 altimg 1 s2 0 s0309170818302124 si56 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 9f5a9fe5edceedc7e04b1ca84b33743a si56 gif si56 si56 gif gif 1380 57 219 altimg 1 s2 0 s0309170818302124 si57 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif d6628bfba3d0c593634afa50b841ed31 si57 gif si57 si57 gif gif 209 18 21 altimg 1 s2 0 s0309170818302124 si58 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif be000a58cedb2f08a31a910888b417d9 si58 gif si58 si58 gif gif 195 18 21 altimg 1 s2 0 s0309170818302124 si59 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 4668b83f270fa8746f087484e4bf6981 si59 gif si59 si59 gif gif 2845 82 508 altimg 1 s2 0 s0309170818302124 si6 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 142e037d98ab2324a121933a8021c6e3 si6 gif si6 si6 gif gif 2674 70 489 altimg 1 s2 0 s0309170818302124 si60 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 06cba6dee4b405dd7a887f54ad39afa0 si60 gif si60 si60 gif gif 1512 55 226 altimg 1 s2 0 s0309170818302124 si61 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif df5185174a792d3562c2a9ddfdca263c si61 gif si61 si61 gif gif 234 18 21 altimg 1 s2 0 s0309170818302124 si62 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 6df51f226fbfa55ab97c4168a8c987d1 si62 gif si62 si62 gif gif 252 18 24 altimg 1 s2 0 s0309170818302124 si63 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif c31e56c20a266d823f9cfebddbc29e6f si63 gif si63 si63 gif gif 213 20 20 altimg 1 s2 0 s0309170818302124 si7 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 7df857a7a3111a0c66ba5e7a4bd9c974 si7 gif si7 si7 gif gif 2039 95 245 altimg 1 s2 0 s0309170818302124 si8 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif bbb051ad8f1e8ef4d7b142fc2351327d si8 gif si8 si8 gif gif 1307 26 345 altimg 1 s2 0 s0309170818302124 si9 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif f507dc5c493ccaa253f2d0cb95f46846 si9 gif si9 si9 gif gif 522 46 81 altimg adwr 3137 s0309 1708 18 30212 4 10 1016 j advwatres 2018 05 004 the authors fig 1 comparison of flow velocities predicted by different numerical schemes on different grids a x direction velocity for case a b y direction velocity for case a c x direction velocity for case b d y direction velocity for case b the plotted velocities are normalised against the steady state velocities fig 1 fig 2 time steps used by different numerical schemes on different grids a case a b case b the time steps are normalised against δt calculated from u and v with cfl 1 0 fig 2 fig 3 geometry of the v shaped catchment fig 3 fig 4 rainfall induced discharge hydrographs obtained a on one of the hillside b at the channel outlet fig 4 fig 5 topographic map of the upper lee catchment fig 5 fig 6 time series of the mean rainfall intensity over the catchment fig 6 fig 7 land use map of the upper lee catchment fig 7 fig 8 predicted flood maps at a t 48 h b t 72 h c t 96 h d t 120 h fig 8 fig 9 comparison between the simulated and observed discharge hydrographs at the catchment outlet fig 9 table 1 rmses of the predicted velocities against the steady state solutions table 1 u u for case a v v for case a u u for case b v v for case b δx 1 m efm 1 16e 00 1 15e 00 4 32e 00 4 31e 00 δx 10 m efm 3 47e 00 3 47e 00 4 27e 00 4 27e 00 δx 100 m efm 4 48e 00 4 48e 00 4 60e 00 4 60e 00 δx 1 m current 4 50e 02 2 09e 01 2 26e 01 5 79e 01 δx 10 m current 3 98e 03 2 80e 02 8 97e 03 3 59e 02 δx 100 m current 3 85e 04 2 92e 03 8 94e 04 3 46e 03 δx 1 m ifm 4 50e 02 2 09e 01 2 26e 01 5 79e 01 δx 10 m ifm 3 98e 03 2 80e 02 8 97e 03 3 59e 02 δx 100 m ifm 3 85e 04 2 92e 03 8 94e 04 3 46e 03 table 2 discharge rmses calculated by different friction term discretisation schemes table 2 hillside discharge m3 s channel outlet discharge m3 s efm 0 0474 0 2391 ifm 0 0464 0 2377 current 0 0464 0 2377 table 3 the adopted manning coefficients for different types of land use table 3 land use type manning coefficient sm 1 3 mountain 0 15 sub urban 0 13 arable 0 125 grassland 0 075 woodland 0 16 urban 0 03 fresh water 0 015 table 4 runtimes consumed by the two friction term discretisation schemes table 4 model total runtime runtime for friction calculation current 153 0 min 4 3 min ifm 159 5 min 10 1 min ratio 1 041 2 35 a new efficient implicit scheme for discretising the stiff friction terms in the shallow water equations xia xilin b c liang qiuhua a b c a hebei university of engineering handan china hebei university of engineering handan china b school of engineering newcastle university newcastle upon tyne uk school of engineering newcastle university newcastle upon tyne uk c school of architecture building and civil engineering loughborough university loughborough uk school of architecture building and civil engineering loughborough university loughborough uk corresponding author discretisation of the friction terms to ensure numerical stability and accuracy remains to be challenging for the development of robust numerical schemes to solve the shallow water equations swes particularly for applications involving very shallow flows e g overland flows and wet dry fronts over complex domain topography the key challenge is to ensure relaxation of the flow towards an equilibrium state characterised by the balance between friction and gravity in a computationally efficient way to overcome this numerical challenge this paper proposes a novel approach for discretising the friction source terms in the swes in the context of an explicit finite volume method the overall numerical scheme adopts the hllc riemann solver and surface reconstruction method srm to explicitly discretise the flux and bed slope source terms whilst a fully implicit scheme is used to handle the friction source terms solution to the implicit formulation is analytically derived to explicitly update the flow variables compared with the existing approaches the proposed scheme effectively resolves the issue associated with stiff relaxation without necessity to use an iteration method and it supports efficient simulation using time steps controlled only by the courant friedrichs levy cfl condition the current friction term discretisation scheme is not coupled with flux and bed slope calculation and therefore may be readily implemented in any other explicit finite volume swe models after being successfully validated against two benchmark tests with analytical solutions the resulting new swe model is applied to reproduce a rainfall flooding event in the upper lee catchment in the uk keywords shallow water equations friction source terms implicit scheme stiff relaxation overland flow finite volume method 1 introduction many real world examples of surface water flows such as river flows overland flows flood waves and tsunamis can be simulated by numerical models solving the shallow water equations swes berger et al 2011 di giammarco et al 1996 kao and chang 2012 sanders et al 2010 in the past three decades substantial progress has been made in developing numerical models to solve the swes and numerous robust numerical schemes have been developed and reported to address different issues related to real world applications for example capturing the shock like flow discontinuities e g toro 2001 ensuring positivity of water depth for wetting and drying e g audusse et al 2004 liang and marche 2009 and preserving still water solutions i e c property e g bermudez and vazquez 1994 audusse et al 2004 hou et al 2013 murillo and garcía navarro 2012a xing et al 2011 zhou et al 2001 however proper discretisation of the friction source terms remains to be a challenge for developing numerically accurate and stable schemes to solve the swes for simulating very shallow flows as found in the applications involving overland flows and wet dry fronts as pointed out in xia et al 2017 inappropriate discretisation of the friction source terms may result in 1 numerical instability that leads to the use of prohibitive small time steps and 2 inaccurate prediction of flow velocities in the swe formulation the friction terms are normally expressed as a non linear function of velocity and flow depth the manning and chezy formulae provide examples of the most commonly used friction laws chow 1959 for example the 1d swes may be formulated as 1 h t h u x 0 2 h u t h u 2 1 2 g h 2 x g h s b s f where h is the flow depth u is the flow velocity in the x direction g is the acceleration due to gravity sb is the bed slope and s f g n 2 h 1 3 u u is the friction source term expressed in the form of the manning formula in which n is the manning coefficient it is the non linear nature of the friction source terms and their interactions with other source terms that bring in the major difficulty for developing robust discretisation schemes we may consider a simple example of uniform flow on a slope to illustrate the physical behaviour of the friction terms the direction of the friction is always opposite to the velocity flow direction if the friction is larger than the gravity component along the bed slope the flow will be decelerated to have a reduced velocity subsequently the friction a function of flow velocity and depth will also be reduced until a new balance is reached between the friction and gravity component on the other hand if the friction is smaller than the gravity component the flow velocity and hence the friction will increase until a new balance is reached therefore the friction source terms always take effect to relax the flow towards an equilibrium steady state characterised by the balance between the friction and gravity along the flow direction the timescale of the friction relaxation towards the equilibrium steady state may be estimated from the jacobian matrix of the friction terms for the 1d swes in eqs 1 and 2 it is given as xia et al 2017 3 t f 1 h 1 s f u 1 2 g n 2 h 4 3 u eq 3 reveals that the relaxation time becomes small when the water depth is small which may become much smaller than the time step determined by the courant friedrichs levy cfl condition in an explicit swe model such a quick relaxation is often referred to as stiff relaxation and linked to the so called stiff friction source terms to resolve the numerical issue related to stiff relaxation a simple way would be to restrict the time step length however this may lead to the use of prohibitive small time steps and subsequently unrealistic long simulation time therefore the specific challenge is to develop an effective numerical scheme for the friction source terms that can relax the flow towards the correct steady state using time steps solely determined by the cfl condition without further constraints in the past three decades numerous attempts have been made to develop friction term discretisation schemes to achieve better numerical stability but much less attention has been given to improving numerical accuracy and predicting the correct equilibrium state of the flows to provide stable simulations implicit schemes have been widely used to discretise the friction source terms e g fiedler and ramirez 2000 liang et al 2007 cea et al 2010 song et al 2011 costabile et al 2013 simons et al 2014 busaman et al 2015 cea and blade 2015 rousseau et al 2015 singh et al 2015 unlike the explicit schemes implicit schemes use the velocities at the new time step to evaluate the friction terms in other words the velocities are assumed to have the values after relaxation in this way the implicit schemes intrinsically enforce the relaxation of the friction terms to take effect in the current time step effectively removing the stiffness of the friction terms in order to simplify the numerical implementation of an implicit friction discretisation scheme a popular way is to reformulate the friction terms into explicit formulations for example the schemes reported in fiedler and ramirez 2000 and simons et al 2014 expand the friction terms using the taylor s series and omit the higher order terms to obtain an explicit formulation other researchers e g liang et al 2007 cea et al 2010 song et al 2011 costabile et al 2013 busaman et al 2015 cea and blade 2015 rousseau et al 2015 singh et al 2015 express the friction terms as the product of the velocity in the current time step and that in the new time step to obtain an explicit formula although these schemes may effectively avoid the numerical instability caused by the stiff friction terms they commonly relax the flows to a wrong steady state which may consequently lead to incorrect simulation results xia et al 2017 based on the fact that the maximum effect of friction is to fully stop the flow certain friction discretisation schemes burguete et al 2008 liang and marche 2009 also impose an upper bound on the friction so that it can only reduce the velocity to zero but not change its sign to reverse the flow these schemes effectively force the friction to relax the flow velocity to zero which is not necessarily the physically correct steady state the value of the physically correct steady state velocity depends on the bed slope and is generally not zero furthermore the flow direction may be reversed during a single time step under certain conditions taking the example of a flow moving uphill the combined effect of friction and gravity will firstly decelerate the flow until it stops and then the gravity will accelerate the flow downhill until it is balanced by the friction the flow direction has actually been reversed and this process may theoretically happen in a single time step through a different approach the scheme proposed by murillo and garcía navarro 2012b integrates the discretisation of friction terms into the adopted riemann solver this approach essentially linearizes the friction terms when integrating them over the time since the approach does not explicitly consider the non linear relaxation imposed by the friction terms an additional fix must be implemented to ensure numerical stability and convergence to the steady state another disadvantage of this approach is that the discretisation of the friction source terms and flux terms are fully coupled and cannot be easily applied in other finite volume models that adopt different flux discretisation schemes attempts have also been reported recently to develop numerical methods for proper relaxation of the stiff friction terms in swe models in yu and duan 2014 the flow velocity is adaptively set to a theoretical steady state value determined by the balance between the bed and friction slopes when the so called kinematic wave number is larger than a threshold this method was further improved by also considering the pressure gradient terms when determining the steady state velocity yu and duan 2017 however the threshold for imposing steady state velocity i e the kinematic wave number is a case dependent parameter which restricts the robustness of the method for wider applications more recently xia et al 2017 introduced a fully implicit friction discretisation scheme that can effectively relax the flow towards the correct steady state and allow the use of cfl time step even when it is much bigger than the relaxation time scale different from the aforementioned schemes that reformulate the equations into an explicit form xia et al 2017 directly solved the implicit friction equations using a newton raphson iteration method this however inevitably complicates the numerical implementation and potentially increases the computational cost due to the various limitations of the existing approaches this paper proposes a novel implicit scheme for discretising the friction source terms of the swes in the context of a finite volume method the new scheme is able to relax the flow velocity towards the correct equilibrium steady state using a normal time step determined by the cfl condition even when it is much bigger than the relaxation time scale meanwhile the new scheme calculates the friction terms explicitly without using an iteration method it is therefore straightforward to implement and computationally more efficient the rest of the paper is organised as follows section 2 presents the governing equations section 3 presents the numerical scheme with an emphasis on friction source term discretisation section 4 validates the resulting swe model using carefully selected test cases before it is applied to reproduce a real world rainfall event in section 5 and finally brief conclusions are drawn in section 6 2 governing equations the vectorised form of the 2d shallow water equations swes may be written as 4 q t f x g y s b s f where q contains the conserved flow variables f and g are the x and y direction flux vector terms and s b and s f are the source terms representing respectively the bed slope and friction effects these vector terms are given by 5 q h h u h v f u h u 2 h 1 2 g h 2 u v h g v h u v h v 2 h 1 2 g h 2 6 s b 0 g h b x g h b y s f 0 τ b x ρ τ b y ρ where v is the depth averaged velocity component in the y directions ρ is the water density and τ bx and τ by are the friction stresses calculated using the manning equation 7 τ b x ρ c f u u 2 v 2 τ b y ρ c f v u 2 v 2 with 8 c f g n 2 h 1 3 it is worth noting that the swes are generally not applicable to flows on steep slopes and modifications to the original formulation have been proposed to resolve this issue e g juez et al 2013 2014 xia and liang 2018 the friction term discretisation scheme proposed in this work can be trivially adapted for use in these modified swes 3 numerical scheme the above 2d swes are solved using a first order godunov type finite volume method the adopted numerical scheme is presented in this section with an emphasis on the introduction of the proposed new discretisation scheme for the friction source terms 3 1 first order godunov type finite volume method the time marching scheme for the finite volume method is given as follows 9 q n 1 q n δ t ω i k 1 n f k q n l k δ t r i n s b i n s f i n 1 in which subscripts i and k are the indices of a cell and the cell edges superscript n denotes the time level f k q contains the fluxes normal to cell edge k lk is the length of the cell edge k ω i is the cell area and δt is the time step in the current numerical scheme the flux and slope source terms are discretised explicitly based on the flow variables at time level n but the friction source terms are discretised implicitly using the flow variables at time level n 1 3 2 calculation of flux and bed slope source terms in this work the flux term f k q is calculated using an hllc riemann solver for which the details can be found in toro 2001 the required riemann states are obtained using the surface reconstruction method srm as proposed by xia et al 2017 srm firstly reconstructs the water surface elevations at the left and right hand sides of a given cell interface considering two adjacent cells i and i 1 the reconstructed water surface elevations denoted by η are 10 η l η i max 0 min b i 1 b i δ b η i 1 η i 11 η r η i 1 max 0 min b i b i 1 δ b η i η i 1 with 12 δ b b i 1 2 b i 1 2 in which b i 1 2 and b i 1 2 are the bed elevations at the left and right hand sides of the cell interface which are interpolated from the corresponding cell centre values using a slope limited method as 13 b i 1 2 b i r i b i and b i 1 2 b i 1 r i 1 b i 1 where r is the distance vector from the cell centre to the cell interface and b is the slope limited gradient of bed elevation in this work the widely used minmod slope limiter is adopted for numerically stable simulations the bed elevations at the left and right hand sides of the cell interface are then redefined using the corresponding reconstructed water surface elevations and water depths as 14 b l η l h i b r η r h i 1 which are then used to define a single bed elevation at the cell interface as 15 b f max b l b r based on which the riemann states of the flow depth are defined 16 h l max 0 η l b f h r max 0 η r b f the riemann states of the discharges are subsequently deduced 17 h u l h l u i h u r h r u i 1 h v l h l v i h v r h r v i 1 where ui hu i hi and vi hv i hi similarly u i 1 and v i 1 are the depth averaged velocities calculated at the cell centres these riemann states are then used to calculate the numerical fluxes in eq 9 using an hllc riemann solver in the context of the first order godunov type finite volume method as adopted in this work the bed slope source terms are calculated as 18 s b i 0 1 ω i 1 2 g h i h l k b i b f k n k l k where h l k is the left riemann state of the flow depth at cell edge k and b f k is defined as 19 b f b f δ b 20 δ b max 0 b f η i if h i 1 ɛ h δ b max 0 min δ b b f η i if h i 1 ɛ h in which ε h 10 10 is a small value to define a dry cell the present flux and slope discretisation schemes automatically ensure non negative water depth and preserve still water solutions i e c property for simulations involving wetting and drying over rough terrain with complex topography xia et al 2017 3 3 discretisation of the friction source terms in the current godunov type finite volume scheme the friction source terms in eq 9 are discretised implicitly but the actual calculation is carried out explicitly through derivation of an effective explicit formulation to derive the required explicit formulation the momentum components in eq 9 are firstly expanded into a scalar form as 21 q x n 1 q x n δ t a x δ t g n 2 h n 7 3 q x n 1 q x n 1 2 q y n 1 2 22 q y n 1 q y n δ t a y δ t g n 2 h n 7 3 q y n 1 q x n 1 2 q y n 1 2 in which qx hu and qy hv are the x and y direction components of the unit width discharge and ax and ay represent the momentum components of 1 ω i k 1 n f k q n l k s b i n respectively in the x and y directions eqs 21 and 22 are obviously non linear functions of q x n 1 and q y n 1 to find the roots for q x n 1 and q y n 1 a new approach is proposed and implemented in this work to analytically solve eqs 21 and 22 instead of using the newton raphson iteration method as reported in xia et al 2017 firstly eqs 21 and 22 are reformulated into 23 q x n 1 1 δ t g n 2 h n 7 3 q x n 1 2 q y n 1 2 q x n δ t a x 24 q y n 1 1 δ t g n 2 h n 7 3 q x n 1 2 q y n 1 2 q y n δ t a y dividing eq 23 by eq 24 leads to 25 q x n 1 q y n 1 q x n δ t a x q y n δ t a y then by substituting 25 into 23 we can obtain 26 q x n 1 1 δ t g n 2 h n 7 3 q x n 1 2 m y m x 2 q x n 1 2 m x in which 27 m x q x n δ t a x and m y q y n δ t a y if q x n 1 is positive eq 26 may be rewritten as 28 q x n 1 q x n 1 2 δ t g n 2 h n 7 3 1 m y m x 2 m x otherwise 29 q x n 1 q x n 1 2 δ t g n 2 h n 7 3 1 m y m x 2 m x eqs 28 and 29 are quadratic equations in terms of q x n 1 and each of them has two roots therefore mathematically there may be as many as four roots for eq 26 two for the positive q x n 1 and two for the non positive q x n 1 however only one of these roots is physically meaningful for hydrodynamic modelling which must be correctly identified the two roots for eq 28 i e the positive q x n 1 are 30 q x n 1 1 1 4 δ t g n 2 h n 7 3 m x 1 m y m x 2 2 δ t g n 2 h n 7 3 1 m y m x 2 and 31 q x n 1 1 1 4 δ t g n 2 h n 7 3 m x 1 m y m x 2 2 δ t g n 2 h n 7 3 1 m y m x 2 and the two roots for eq 29 i e the non positive q x n 1 are 32 q x n 1 1 1 4 δ t g n 2 h n 7 3 m x 1 m y m x 2 2 δ t g n 2 h n 7 3 1 m y m x 2 and 33 q x n 1 1 1 4 δ t g n 2 h n 7 3 m x 1 m y m x 2 2 δ t g n 2 h n 7 3 1 m y m x 2 which one of the above four roots is physically admissible for hydrodynamic modelling depends on mx if mx is positive eq 30 is negative which contradicts to the prescribed assumption of positive q x n 1 i e q x n 1 0 on the other hand eq 31 is positive which is consistent with assumption of q x n 1 0 meanwhile eqs 32 and 33 are both positive as long as they are real which are clearly not consistent with the assumption of q x n 1 0 therefore eq 31 provides the only physically correct root for eq 29 if mx 0 similarly we can prove that eq 33 gives the only admissible root for eq 29 if mx 0 these two admissible roots can be combined into one analytical expression as 34 q x n 1 m x m x 1 4 δ t g n 2 h n 7 3 m x 2 m y 2 2 δ t g n 2 h n 7 3 m x 2 m y 2 if hn is excessively small e g near to the wet dry front the term h n 7 3 may return an exaggerating big value 1020 depending on the value water depth that may exceed the maximum machine precision and thus create machine error leading to numerical stability to avoid this part of h n 7 3 is cast into the square root operators to facilitate stable numerical implementation and the final expression for q x n 1 is given as 35 q x n 1 m x m x 1 4 δ t g n 2 h n 4 3 m x h n 2 m y h n 2 2 δ t g n 2 h n 4 3 m x h n 2 m y h n 2 it is also possible that the denominator may return a zero making eq 35 to become singular in such a case q x n 1 m x is effectively the root to 29 to avoid singularity in the numerical calculation eq 34 is slightly modified to become 36 q x n 1 m x if δ t g n 2 h n 4 3 m x h n 2 m y h n 2 10 10 m x m x 1 4 δ t g n 2 h n 4 3 m x h n 2 m y h n 2 2 δ t g n 2 h n 4 3 m x h n 2 m y h n 2 if δ t g n 2 h n 4 3 m x h n 2 m y h n 2 10 10 similarly the physically admissible root for eq 24 and the final expression for q y n 1 can be derived and given as follows 37 q y n 1 m y if δ t g n 2 h n 4 3 m x h n 2 m y h n 2 10 10 m y m y 1 4 δ t g n 2 h n 4 3 m x h n 2 m y h n 2 2 δ t g n 2 h n 4 3 m x h n 2 m y h n 2 if δ t g n 2 h n 4 3 m x h n 2 m y h n 2 10 10 therefore the explicit expressions of q x n 1 and q y n 1 accounting for the friction effects are given by eq 36 and eq 37 which can be explicitly calculated and incorporated into the adopted godunov type scheme to develop a new swe model in order to mathematically prove that the proposed numerical scheme can effectively relax the flow velocity to the correct equilibrium steady state we consider δt in eq 36 and eq 37 by assuming δt we effectively impose that the cfl determined time step is much bigger than the relaxation time scale the resulting expressions for q x n 1 and q y n 1 become 38 lim δ t q x n 1 a x g n 2 h n 7 3 a x 2 a y 2 39 lim δ t q y n 1 a y g n 2 h n 7 3 a x 2 a y 2 apparently lim δ t q x n 1 and lim δ t q y n 1 are the unit width discharges determined by the balance between the friction and other terms i e the flux and bed slope terms in the swes therefore the physically correct equilibrium steady state can be properly recovered by the proposed friction discretisation scheme it should be also noted that lim δ t q x n 1 and lim δ t q y n 1 do not necessarily have the same signs as q x n and q y n this defies the assumption adopted by burguete et al 2008 and liang and marche 2009 where the flow direction cannot be reversed within a single time step in the current friction discretisation scheme the flow can theoretically be reversed during a time step 3 4 solution procedure at each time step the solution procedure of the resulting swe model may be summarised as follows 1 explicitly evaluate the flux terms and bed slope source terms using srm as described in section 3 2 2 integrate the mass flux term in eq 9 to obtain h n 1 3 integrate the momentum flux terms and the bed slope source terms in eq 27 to obtain mx and my 4 integrate the friction source terms in eqs 36 and 37 to respectively obtain q x n 1 and q y n 1 5 update the flow variables and move to the next time step 3 5 stability criterion for the resulting swe model as introduced in the previous sub sections the time step length for numerically stable simulations is solely determined by the courant friedrichs levy cfl condition given as 40 δ t cfl d i u i g h where di is the minimum distance from the cell centre to the corresponding cell edges and cfl denotes the cfl number that takes a non zero value between 0 and 1 cfl 1 0 is used in all of the simulations in this work the stability criterion for the overall explicit swe model is irrelevant to the friction term discretisation this is because the flux and bed source terms and the friction source terms are treated separately the new implicit friction term integration method proposed in this work relaxes the flow velocity to the correct equilibrium state even when the time step is large δt which effectively avoids further constraint on the time step length therefore the time step of the overall model is only controlled by the cfl condition 4 model validation two analytical test cases are considered in this section to validate the new friction term discretisation scheme both test cases involve very small water depth to highlight the need of a proper numerical scheme to discretise the friction source terms for stable and accurate simulations it is noteworthy that the discretisation scheme for flux and slope source terms have already been intensively tested and verified in our previous work xia et al 2017 in particular the scheme has been proven to perfectly preserve the lake at rest resolutions and ensure the positivity of water depths for applications involving complex topography and wetting and drying repeating these tests is deemed to be unnecessary and will not be considered herein to demonstrate the advantages of the new implicit friction discretisation scheme the simulation results are compared with the analytical solutions and also numerical solutions obtained using two alternative schemes 1 the iterative implicit scheme proposed by xia et al 2017 referred to as iterative friction model ifm herein and 2 a popular implicit scheme adopted by many researchers e g busaman et al 2015 cea and blade 2015 liang et al 2006 song et al 2011 named as explicit friction model efm from now on the convergence criterion of ifm is chosen to be the same as that in xia et al 2017 i e the iteration stops when the relative difference between the solutions in two iterations is less than 0 001 efm reformulates the implicit friction discretisation scheme into an explicit form as 41 q x n 1 m x 1 δ t g n 2 h n 4 3 u n 2 v n 2 and 42 q y n 1 m y 1 δ t g n 2 h n 4 3 u n 2 v n 2 to quantitatively assess the accuracy of the numerical simulation results the root mean square error rmse is defined and calculated by 43 rmse 1 n f m n f t n 2 n where n is the total number of time steps f m n is the simulated results and f t n is the reference solutions for a specific flow variable f at t n analytical solutions are available for comparison for both of the test cases considered in this section 4 1 two dimensional uniform flow the first test case to consdier is a 2d uniform flow with constant depth and velocity over a slope the water depth is 0 001 m and the bed slopes in the x and y directions i e sbx and sby are both 0 05 the manning coefficient is taken as 0 035 sm 1 3 and is constant over the entire domain according to xia et al 2017 the steady state velocity components determined by the balance between friction and gravity are given by 44 u s b x g n 2 h 1 3 s b x 2 s b y 2 and v s b y g n 2 h 1 3 s b x 2 s b y 2 which give u 0 0537 m s and v 0 0537 m s based on the parameters as provided herein two sets of initial velocities are considered i e case a u 0 5u v 0 10v and case b u 0 5u v 0 10v the two sets of initial velocities have opposite signs to confirm the correct solutions to the two different quadratic equations resulting from eq 26 three different grid sizes i e δx 1 m 10 m and 100 m are used in the simulations the velocities predicted by the three different friction discretisation schemes are normalised by the theoretical steady state velocity and compared with each other in fig 1 the current scheme and ifm are both able to relax the flow velocity towards the correct steady state velocity monotonically in one or two time steps in all three simulations with different grid resolutions it is worth noting that for case b the signs of both of the x and y direction steady state velocities are different from the initial conditions i e the steady state velocities are positive while the initial velocities are negative which can be clearly seen in fig 1 c and d the change of the signs of the velocities subsequently the reversal of the flow is predicted within a single time step by the current scheme and ifm for the coarse grid simulations δx 10 m and 100 m this confirms the previous statement that the flow direction can be theoretically reversed within a single time step the time steps used in the simulations are also plotted in fig 2 and comparable with δt calculated from u and v with cfl 1 0 this effectively demonstrates that stable and accurate simulations are achieved using time steps determined solely by the cfl condition the current scheme provides numerical predictions identical to those by ifm which is as expected and confirms the validity of the explicit friction formulae derived in the previous section however the flow velocities predicted by efm fail to converge to the correct steady state on all three grid configurations the prediction accuracy of the three different schemes is quantified by calculating rmses which are listed in table 1 for all of the simulations the rmses predicted by the current scheme and ifm are much smaller than those resulting from efm for the current scheme and ifm the rmses decrease as the grid cell size increases indicating that the flow is relaxed to the steady state with fewer time steps on coarser grids this is consistent with the mathematical property of the manning s friction terms the relaxation scale is independent of the cell size as indicated by eq 3 but the time step length increases as the cell size increases therefore fewer time steps are required to converge the flow to the steady state 4 2 overland flow on an idealised v shaped catchment the current friction discretisation scheme is further tested through simulating overland flow on an idealised v shaped catchment the catchment comprises of two hillsides with a 0 05 slope and a channel with a 0 02 slope as shown in fig 3 the manning coefficients for the hillslopes and channel are 0 015 sm 1 3 and 0 15 sm 1 3 respectively constant and uniform rainfall with an intensity of 10 8 mm h falls on the whole catchment for 1 5 h from the beginning except for the channel outlet where open boundary conditions are imposed all other boundaries are closed a uniform grid of 10 m resolution is used for all of the simulations fig 4 presents the discharge hydrographs predicted by all of the three friction term discretisation schemes at the hillsides and channel outlet which are compared with the analytical solutions derived based on the kinematic wave assumptions see di giammarco et al 1996 for details the results produced by the current scheme and ifm are identical which are all in good agreement with the analytical solutions however the hillside discharge predicted by the efm scheme presents unphysical oscillations at the onset stage this is directly caused by the small relaxation time for the very shallow overland flow on the hillside in such a case efm cannot properly relax the flow velocity towards the correct steady state the superiority of the current scheme and ifm is further confirmed by the calculated rmses listed in table 2 the rmses resulting from the current scheme and ifm are slightly smaller than efm for both the hillside and channel outlet discharges 5 application to a real world rainfall flooding event in this section the model implemented with the new friction discretisation scheme is applied to reproduce a rainfall flooding event in the upper lee catchment at north london uk the catchment covers an area of 1180 km2 as shown in fig 5 the records of catchment outlet discharge are available from a gauge station installed at the river lee heavy rainfall was recorded between 5th and 11th feb 2014 which directly triggered a flood event the time series of the mean rainfall intensity over the whole catchment is presented in fig 6 showing several rainfall peaks although various uncertainties exist when assessing accuracy of a model for real world applications this test case is considered to validate the numerical stability and efficiency of the proposed numerical scheme for complex problems the simulation is carried out for a total of 120 h from 00 00 on 5th feb 2014 the whole catchment is discretised using a uniform grid of 20 m resolution leading to 2 95 million computational cells zero infiltration is assumed due to antecedent rainfall and saturated soil condition the manning coefficients are set to be spatially varying according to the land use types as shown in fig 7 the manning coefficients for different land use types are summarised in table 3 selected based on the commonly used values as suggested in chow 1959 since the purpose of this case study is to test the numerical stability and efficiency of the current scheme the model is not calibrated for the simulations and the used parameters may not represent an optimal parameter set the models implemented respectively with the current friction discretisation scheme and ifm are used to simulate this event similar to the previous test cases the two models predict identical simulation results which is as expected the predicted flood maps at different output times are presented in fig 8 at t 48 h streams and river channels inside the catchments have already been filled with water significant inundation can be observed in the downstream areas at t 72 h the flood water has been further routed into the main rivers as indicated by the extended inundation areas and the retreat of water in the upland streams at t 96 h the flood peak has passed and smaller inundated areas are observed compared with 24 h ago the reduced water depth at t 120 h suggests further retreat of the flood overall the simulated flood process is consistent with the rainfall pattern in which most of rain has fallen before t 96 h the predicted discharge hydrograph at the catchment outlet is compared with the observation in fig 9 overall good agreement is achieved between the numerical prediction and the observation except for the slightly over estimated rising limb at the initial stage the nash sutcliffe efficiency nse has been adopted herein to quantitatively confirm the accuracy of the numerical prediction the nse is defined as 45 n s e 1 1 n q m n q o n 1 n q m n q o where n is the total number of time steps q o n is the observed discharge at t n q m n is the simulated discharge at t n and q o is the mean observed discharge nse 1 suggests perfect agreement between the prediction and the observation for this simulation the nse is calculated to be 0 91 indicating that the observed discharge has been successfully reproduced with high accuracy by the current model to compare the computational efficiency both of the numerical schemes i e the current scheme and ifm are implemented in the same gpu accelerated codebase which are run in parallel on 4 nvidia tesla k40 gpus and 2 nvidia tesla k80 gpus the runtimes are summarised in table 4 considering only the runtime for friction calculation the current scheme is 2 35 times faster than the ifm this confirms that the friction discretisation scheme based on the explicit formulae derived in this work is computationally more efficient than ifm embedded with a newton raphson iteration method 6 conclusions this work presents and validates a novel implicit scheme for discretising the stiff friction terms in the 2d swes the scheme features with the following two key properties 1 the scheme is able to resolve the relaxation of flow velocities towards the exact steady state determined by the balance between friction and gravity along the flow direction using time steps controlled only by the cfl condition for the overall explicit swe model 2 the scheme can be implemented explicitly without necessity of using any iteration methods these properties are crucial to ensure numerically stable efficient and accurate simulation of very shallow flows such as overland flows and wet dry fronts and the associated processes including soil erosion and solute transport however existing friction discretisation schemes usually do not simultaneously possess both of these properties the current scheme has been successfully validated against two benchmark tests with satisfactory results confirming its superior numerical stability and accuracy in comparison with the existing mainstream approaches the resulting swe model is then further applied to simulate a rainfall flooding event in the upper lee catchment uk to further confirm its numerical stability and computational efficiency for the simulation of overland flows and flooding over complex real world topography although the current scheme is proposed in the context of a godunov type finite volume method in principle it can also be used in other numerical methods e g finite difference method and finite element method acknowledgements this work is funded by the nerc sinatra and tenderly projects grant no ne k008781 1 and flood prepared project grant no ne p017134 1 
804,discretisation of the friction source terms 3 4 solution procedure 3 5 stability criterion 4 model validation 4 1 two dimensional uniform flow 4 2 overland flow on an idealised v shaped catchment 5 application to a real world rainfall flooding event 6 conclusions acknowledgements audusse 2004 2050 2065 e berger 2011 1195 1206 m bermudez 1994 1049 1071 a burguete 2008 403 425 j busaman 2015 a cea 2015 5464 5486 l cea 2010 88 102 l chow 1959 v openchannelhydraulics costabile 2013 554 569 p digiammarco 1996 267 291 p fiedler 2000 219 240 f hou 2013 107 131 j juez 2014 142 163 c juez 2013 166 204 c kao 2012 232 244 h liang 2006 1833 1845 d liang 2007 811 826 d liang 2009 873 884 q murillo 2012 6861 6906 j murillo 2012 1963 2001 j rousseau 2015 4015012 m sanders 2010 1456 1467 b simons 2014 375 391 f singh 2015 4014089 j song 2011 960 980 l toro 2001 e shockcapturingmethodsforfreesurfaceshallowflow xia 2018 174 191 x xia 2017 3730 3759 x xing 2011 339 349 y yu 2017 1 12 c yu 2014 1 13 c xiax2018x87 xiax2018x87x97 xiax2018x87xx xiax2018x87x97xx full 2018 05 09t10 36 30z fundingbody natural environment research council http creativecommons org licenses by 4 0 hefce 2019 05 17t00 00 00 000z http creativecommons org licenses by nc nd 4 0 this is an open access article under the cc by license 2018 the authors published by elsevier ltd 2019 03 03t05 00 00 951z http vtw elsevier com data voc addontypes 50 7 nlp s0309170818302124 nerc sinatra ne k008781 1 this work is funded by the nerc sinatra and tenderly projects grant no ne k008781 1 and flood prepared project grant no ne p017134 1 item s0309 1708 18 30212 4 s0309170818302124 1 s2 0 s0309170818302124 10 1016 j advwatres 2018 05 004 271718 2019 12 31t11 09 48 628609z 2018 07 01 2018 07 31 unlimited nerc 1 s2 0 s0309170818302124 main pdf https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 main application pdf 5a3136fbbd2afa1fc08a348053563d6f main pdf main pdf pdf true 2150545 main 11 1 s2 0 s0309170818302124 main 1 png https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 preview image png 50975270190a9a9f998b536ba56e4660 main 1 png main 1 png png 52785 849 656 image web pdf 1 1 s2 0 s0309170818302124 gr1 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr1 thumbnail image gif 2e5eed042e48c3df7f762caf25417aa0 gr1 sml gr1 gr1 sml sml 9920 164 204 image thumbnail 1 s2 0 s0309170818302124 gr2 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr2 thumbnail image gif 0901b0d573368746d2bb49d297ba3cd2 gr2 sml gr2 gr2 sml sml 7161 163 155 image thumbnail 1 s2 0 s0309170818302124 gr3 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr3 thumbnail image gif 10295289f9f94bacce1353fa54bce76a gr3 sml gr3 gr3 sml sml 3217 164 210 image thumbnail 1 s2 0 s0309170818302124 gr4 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr4 thumbnail image gif e91d3cc3163b49a2d558f9aafec7a481 gr4 sml gr4 gr4 sml sml 4549 83 219 image thumbnail 1 s2 0 s0309170818302124 gr5 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr5 thumbnail image gif 2ec0b83d1e5bf0f7397258e53362be89 gr5 sml gr5 gr5 sml sml 16863 156 219 image thumbnail 1 s2 0 s0309170818302124 gr6 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr6 thumbnail image gif 7bf4e3942492bec70ce88cd7ec2a7c0d gr6 sml gr6 gr6 sml sml 3619 94 219 image thumbnail 1 s2 0 s0309170818302124 gr7 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr7 thumbnail image gif 44ecab3f1eb0153c2eeecb3387eff524 gr7 sml gr7 gr7 sml sml 20517 156 219 image thumbnail 1 s2 0 s0309170818302124 gr8 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr8 thumbnail image gif 0b803ff9b4308c54a3a0793d3c26419a gr8 sml gr8 gr8 sml sml 15415 127 219 image thumbnail 1 s2 0 s0309170818302124 gr9 sml https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr9 thumbnail image gif 7ed1f649b2776a5197832457c23ef57c gr9 sml gr9 gr9 sml sml 5400 164 216 image thumbnail 1 s2 0 s0309170818302124 gr1 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr1 downsampled image jpeg fba60279499141fd01256df9f6d7b138 gr1 jpg gr1 gr1 jpg jpg 82430 478 596 image downsampled 1 s2 0 s0309170818302124 gr2 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr2 downsampled image jpeg 6d111f043f09340458ed543c838ac3ea gr2 jpg gr2 gr2 jpg jpg 76941 594 563 image downsampled 1 s2 0 s0309170818302124 gr3 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr3 downsampled image jpeg a12bad38501859a91cb967d65942c1d9 gr3 jpg gr3 gr3 jpg jpg 12532 243 311 image downsampled 1 s2 0 s0309170818302124 gr4 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr4 downsampled image jpeg 0b76d21c43e5aaf63890cae6b8c5aea1 gr4 jpg gr4 gr4 jpg jpg 29614 215 565 image downsampled 1 s2 0 s0309170818302124 gr5 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr5 downsampled image jpeg ed060d4c3861bcd76acee8a0c6eb546d gr5 jpg gr5 gr5 jpg jpg 55878 323 452 image downsampled 1 s2 0 s0309170818302124 gr6 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr6 downsampled image jpeg 03cd17277cbdf19249389415592ab270 gr6 jpg gr6 gr6 jpg jpg 21542 210 489 image downsampled 1 s2 0 s0309170818302124 gr7 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr7 downsampled image jpeg 938a4af4418718c77dbb9dcd23dd2d54 gr7 jpg gr7 gr7 jpg jpg 83173 322 452 image downsampled 1 s2 0 s0309170818302124 gr8 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr8 downsampled image jpeg 662522f37beb671eaf71671dc958131f gr8 jpg gr8 gr8 jpg jpg 113562 460 791 image downsampled 1 s2 0 s0309170818302124 gr9 jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr9 downsampled image jpeg f8fd7773bc21983a53a1aaa98628ec94 gr9 jpg gr9 gr9 jpg jpg 22690 296 391 image downsampled 1 s2 0 s0309170818302124 gr1 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr1 highres image jpeg bf0de6e158e3f6faa3dffafc5f96c912 gr1 lrg jpg gr1 gr1 lrg jpg jpg 866851 2540 3168 image high res 1 s2 0 s0309170818302124 gr2 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr2 highres image jpeg 4c2f7fcd3921ca86f20976c33fc8e0ab gr2 lrg jpg gr2 gr2 lrg jpg jpg 783508 3153 2990 image high res 1 s2 0 s0309170818302124 gr3 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr3 highres image jpeg 04c4b0fb1aac74ed4b443b93915b0e0f gr3 lrg jpg gr3 gr3 lrg jpg jpg 128694 1292 1654 image high res 1 s2 0 s0309170818302124 gr4 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr4 highres image jpeg 48179f88ffec986fa7aaa327d3c86fa1 gr4 lrg jpg gr4 gr4 lrg jpg jpg 229657 950 2500 image high res 1 s2 0 s0309170818302124 gr5 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr5 highres image jpeg 2d97573ae01851adce627309c053aba6 gr5 lrg jpg gr5 gr5 lrg jpg jpg 443750 1427 2000 image high res 1 s2 0 s0309170818302124 gr6 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr6 highres image jpeg 0e61c315289a473ef78efe12f3ca51ea gr6 lrg jpg gr6 gr6 lrg jpg jpg 227817 1119 2600 image high res 1 s2 0 s0309170818302124 gr7 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr7 highres image jpeg 69d16c01437889226fc5817d24b9b71f gr7 lrg jpg gr7 gr7 lrg jpg jpg 811844 1426 2000 image high res 1 s2 0 s0309170818302124 gr8 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr8 highres image jpeg 9c9b3c0ac5f4b6d1f957abd3c1f0ba44 gr8 lrg jpg gr8 gr8 lrg jpg jpg 967052 2035 3500 image high res 1 s2 0 s0309170818302124 gr9 lrg jpg https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 gr9 highres image jpeg 71233a46afd50b65f3c44a96573fa47c gr9 lrg jpg gr9 gr9 lrg jpg jpg 229243 1576 2080 image high res 1 s2 0 s0309170818302124 si1 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 167b71711c1a9d7597ceecdd3eedffcf si1 gif si1 si1 gif gif 740 40 120 altimg 1 s2 0 s0309170818302124 si10 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 69afa682129d974177cb36d377a00f20 si10 gif si10 si10 gif gif 2082 55 418 altimg 1 s2 0 s0309170818302124 si11 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 0a7fe3cf1354fa60c2d27f5b640ccf75 si11 gif si11 si11 gif gif 1392 23 394 altimg 1 s2 0 s0309170818302124 si12 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif d1c52fcf2e4c8d93425aebe9da51a169 si12 gif si12 si12 gif gif 1464 23 412 altimg 1 s2 0 s0309170818302124 si13 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif b6bdb1b48c5c13783ac2e13b711a2174 si13 gif si13 si13 gif gif 634 19 182 altimg 1 s2 0 s0309170818302124 si14 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif e048c1bb801c38f4466062385d3a29e4 si14 gif si14 si14 gif gif 1340 19 407 altimg 1 s2 0 s0309170818302124 si15 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 0d6e56dbe50b8638574129bf79a040e5 si15 gif si15 si15 gif gif 869 44 157 altimg 1 s2 0 s0309170818302124 si16 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 99b98ed25096b0c2573ca035f150963e si16 gif si16 si16 gif gif 713 19 147 altimg 1 s2 0 s0309170818302124 si17 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 589bb9ed7702f41da41c1c623ef54da6 si17 gif si17 si17 gif gif 1513 45 214 altimg 1 s2 0 s0309170818302124 si18 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 39251782cfd14fa3c88715efa09c38e9 si18 gif si18 si18 gif gif 1846 44 323 altimg 1 s2 0 s0309170818302124 si19 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif ea7f695a71ce60986953aff07b67d4f4 si19 gif si19 si19 gif gif 1991 68 342 altimg 1 s2 0 s0309170818302124 si2 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif d274787128980bd6c72578d5b6b7ad4b si2 gif si2 si2 gif gif 1412 44 295 altimg 1 s2 0 s0309170818302124 si20 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 8245fc6dbf08b3ce04e751401e8c05c3 si20 gif si20 si20 gif gif 242 22 29 altimg 1 s2 0 s0309170818302124 si21 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 8696614207f4658e919576ac5c480161 si21 gif si21 si21 gif gif 460 23 115 altimg 1 s2 0 s0309170818302124 si22 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 692ce5c9363353bddbe5e2e8939d4689 si22 gif si22 si22 gif gif 2331 45 404 altimg 1 s2 0 s0309170818302124 si23 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 70a9c215d56ec78ad0409e7578d846c9 si23 gif si23 si23 gif gif 1995 34 458 altimg 1 s2 0 s0309170818302124 si24 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 4cc22f1144c58aa7088836607414c614 si24 gif si24 si24 gif gif 1965 34 458 altimg 1 s2 0 s0309170818302124 si25 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 2f3a5f3b16ad894ceeab806fefffc3c9 si25 gif si25 si25 gif gif 956 27 192 altimg 1 s2 0 s0309170818302124 si26 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif e9890b23cc33a89d6f30379b5435746a si26 gif si26 si26 gif gif 253 21 34 altimg 1 s2 0 s0309170818302124 si27 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 92f7d85624083f01dac879b6e2cd58a1 si27 gif si27 si27 gif gif 262 24 34 altimg 1 s2 0 s0309170818302124 si28 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 22df886f10faafd3b96a56b57a4c8f02 si28 gif si28 si28 gif gif 1941 34 444 altimg 1 s2 0 s0309170818302124 si29 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif f2d3b2d80c34e7e2969d2510dd154de0 si29 gif si29 si29 gif gif 1961 34 443 altimg 1 s2 0 s0309170818302124 si3 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 1bd49c4407375f860e1265cac9705df8 si3 gif si3 si3 gif gif 652 24 130 altimg 1 s2 0 s0309170818302124 si30 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 12221b44dd1542c9ef3dfbc21b171c9d si30 gif si30 si30 gif gif 1110 50 154 altimg 1 s2 0 s0309170818302124 si31 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 2479452678437fd27e06d531c008889d si31 gif si31 si31 gif gif 2524 70 459 altimg 1 s2 0 s0309170818302124 si32 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif c20468093fa97eab3ad5dc8e50b76e9c si32 gif si32 si32 gif gif 1161 22 302 altimg 1 s2 0 s0309170818302124 si33 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 7ced4d658da6695e042ebc5801866761 si33 gif si33 si33 gif gif 1955 58 374 altimg 1 s2 0 s0309170818302124 si34 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif ebb454593b6dcad3700b4a53fc65ac8c si34 gif si34 si34 gif gif 1934 58 374 altimg 1 s2 0 s0309170818302124 si35 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 15509b18983582d7d23d00d6e06dffd1 si35 gif si35 si35 gif gif 2927 109 373 altimg 1 s2 0 s0309170818302124 si36 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 7d59efcc3318ff64835ffc8d9aa07490 si36 gif si36 si36 gif gif 2903 109 373 altimg 1 s2 0 s0309170818302124 si37 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif d59ab6175552297b06be45de8706eaf3 si37 gif si37 si37 gif gif 2868 109 373 altimg 1 s2 0 s0309170818302124 si38 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 2250fe1be74a413ff8287bd560954ed7 si38 gif si38 si38 gif gif 2844 109 373 altimg 1 s2 0 s0309170818302124 si39 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif ee11e04479dbf7145c3d66e158a1f655 si39 gif si39 si39 gif gif 364 21 70 altimg 1 s2 0 s0309170818302124 si4 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 72311005f3260280fd757ae5da32ec20 si4 gif si4 si4 gif gif 1117 51 239 altimg 1 s2 0 s0309170818302124 si40 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 95e5d6da6b55d0448f5f382f06852cbd si40 gif si40 si40 gif gif 361 21 70 altimg 1 s2 0 s0309170818302124 si41 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 2ea7480bfa7c53cffebec7ceba84d29e si41 gif si41 si41 gif gif 2658 87 375 altimg 1 s2 0 s0309170818302124 si42 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 0e81767d3f258a381e2dbf4de7eda5bf si42 gif si42 si42 gif gif 321 21 51 altimg 1 s2 0 s0309170818302124 si43 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 33d6fb07f9627dd8ccf23fc364846963 si43 gif si43 si43 gif gif 3115 87 411 altimg 1 s2 0 s0309170818302124 si44 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif e48607c7ba9f3f92b1d344cfd542c7e7 si44 gif si44 si44 gif gif 371 21 81 altimg 1 s2 0 s0309170818302124 si45 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 9803dcc68521b6644220a63612d8fb54 si45 gif si45 si45 gif gif 5129 94 668 altimg 1 s2 0 s0309170818302124 si46 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 8372589e228046baa9acb656c56758a8 si46 gif si46 si46 gif gif 5217 94 664 altimg 1 s2 0 s0309170818302124 si47 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif db8edcada0695764231895635dcde801 si47 gif si47 si47 gif gif 1723 70 288 altimg 1 s2 0 s0309170818302124 si48 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 48a9d2a3b6fe2358e7c81be993cf570c si48 gif si48 si48 gif gif 1742 70 288 altimg 1 s2 0 s0309170818302124 si49 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 60563a04c48826ed5a1730f5442e1a60 si49 gif si49 si49 gif gif 504 21 108 altimg 1 s2 0 s0309170818302124 si5 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 998ed3d347ba4d6a9b46a1e1498781c9 si5 gif si5 si5 gif gif 1132 44 205 altimg 1 s2 0 s0309170818302124 si50 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 0ecff4f1a45948b1fc9a619b515ca434 si50 gif si50 si50 gif gif 518 24 108 altimg 1 s2 0 s0309170818302124 si51 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif a99318182202b90721c1acede5e42cce si51 gif si51 si51 gif gif 199 18 18 altimg 1 s2 0 s0309170818302124 si52 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif ce8361ef426b0c3a38c884f7b7505781 si52 gif si52 si52 gif gif 211 21 18 altimg 1 s2 0 s0309170818302124 si53 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 614bc71a40824704300ebdd6d79985e9 si53 gif si53 si53 gif gif 935 44 170 altimg 1 s2 0 s0309170818302124 si54 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 849ab1cf125b582c47f125b3cb1ec977 si54 gif si54 si54 gif gif 1582 44 322 altimg 1 s2 0 s0309170818302124 si55 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 29197ce822330c9ece82858e76048abc si55 gif si55 si55 gif gif 1578 44 322 altimg 1 s2 0 s0309170818302124 si56 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 9f5a9fe5edceedc7e04b1ca84b33743a si56 gif si56 si56 gif gif 1380 57 219 altimg 1 s2 0 s0309170818302124 si57 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif d6628bfba3d0c593634afa50b841ed31 si57 gif si57 si57 gif gif 209 18 21 altimg 1 s2 0 s0309170818302124 si58 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif be000a58cedb2f08a31a910888b417d9 si58 gif si58 si58 gif gif 195 18 21 altimg 1 s2 0 s0309170818302124 si59 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 4668b83f270fa8746f087484e4bf6981 si59 gif si59 si59 gif gif 2845 82 508 altimg 1 s2 0 s0309170818302124 si6 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 142e037d98ab2324a121933a8021c6e3 si6 gif si6 si6 gif gif 2674 70 489 altimg 1 s2 0 s0309170818302124 si60 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 06cba6dee4b405dd7a887f54ad39afa0 si60 gif si60 si60 gif gif 1512 55 226 altimg 1 s2 0 s0309170818302124 si61 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif df5185174a792d3562c2a9ddfdca263c si61 gif si61 si61 gif gif 234 18 21 altimg 1 s2 0 s0309170818302124 si62 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 6df51f226fbfa55ab97c4168a8c987d1 si62 gif si62 si62 gif gif 252 18 24 altimg 1 s2 0 s0309170818302124 si63 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif c31e56c20a266d823f9cfebddbc29e6f si63 gif si63 si63 gif gif 213 20 20 altimg 1 s2 0 s0309170818302124 si7 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif 7df857a7a3111a0c66ba5e7a4bd9c974 si7 gif si7 si7 gif gif 2039 95 245 altimg 1 s2 0 s0309170818302124 si8 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif bbb051ad8f1e8ef4d7b142fc2351327d si8 gif si8 si8 gif gif 1307 26 345 altimg 1 s2 0 s0309170818302124 si9 gif https s3 amazonaws com prod ucs content store us east content pii s0309170818302124 stripin image gif f507dc5c493ccaa253f2d0cb95f46846 si9 gif si9 si9 gif gif 522 46 81 altimg adwr 3137 s0309 1708 18 30212 4 10 1016 j advwatres 2018 05 004 the authors fig 1 comparison of flow velocities predicted by different numerical schemes on different grids a x direction velocity for case a b y direction velocity for case a c x direction velocity for case b d y direction velocity for case b the plotted velocities are normalised against the steady state velocities fig 1 fig 2 time steps used by different numerical schemes on different grids a case a b case b the time steps are normalised against δt calculated from u and v with cfl 1 0 fig 2 fig 3 geometry of the v shaped catchment fig 3 fig 4 rainfall induced discharge hydrographs obtained a on one of the hillside b at the channel outlet fig 4 fig 5 topographic map of the upper lee catchment fig 5 fig 6 time series of the mean rainfall intensity over the catchment fig 6 fig 7 land use map of the upper lee catchment fig 7 fig 8 predicted flood maps at a t 48 h b t 72 h c t 96 h d t 120 h fig 8 fig 9 comparison between the simulated and observed discharge hydrographs at the catchment outlet fig 9 table 1 rmses of the predicted velocities against the steady state solutions table 1 u u for case a v v for case a u u for case b v v for case b δx 1 m efm 1 16e 00 1 15e 00 4 32e 00 4 31e 00 δx 10 m efm 3 47e 00 3 47e 00 4 27e 00 4 27e 00 δx 100 m efm 4 48e 00 4 48e 00 4 60e 00 4 60e 00 δx 1 m current 4 50e 02 2 09e 01 2 26e 01 5 79e 01 δx 10 m current 3 98e 03 2 80e 02 8 97e 03 3 59e 02 δx 100 m current 3 85e 04 2 92e 03 8 94e 04 3 46e 03 δx 1 m ifm 4 50e 02 2 09e 01 2 26e 01 5 79e 01 δx 10 m ifm 3 98e 03 2 80e 02 8 97e 03 3 59e 02 δx 100 m ifm 3 85e 04 2 92e 03 8 94e 04 3 46e 03 table 2 discharge rmses calculated by different friction term discretisation schemes table 2 hillside discharge m3 s channel outlet discharge m3 s efm 0 0474 0 2391 ifm 0 0464 0 2377 current 0 0464 0 2377 table 3 the adopted manning coefficients for different types of land use table 3 land use type manning coefficient sm 1 3 mountain 0 15 sub urban 0 13 arable 0 125 grassland 0 075 woodland 0 16 urban 0 03 fresh water 0 015 table 4 runtimes consumed by the two friction term discretisation schemes table 4 model total runtime runtime for friction calculation current 153 0 min 4 3 min ifm 159 5 min 10 1 min ratio 1 041 2 35 a new efficient implicit scheme for discretising the stiff friction terms in the shallow water equations xia xilin b c liang qiuhua a b c a hebei university of engineering handan china hebei university of engineering handan china b school of engineering newcastle university newcastle upon tyne uk school of engineering newcastle university newcastle upon tyne uk c school of architecture building and civil engineering loughborough university loughborough uk school of architecture building and civil engineering loughborough university loughborough uk corresponding author discretisation of the friction terms to ensure numerical stability and accuracy remains to be challenging for the development of robust numerical schemes to solve the shallow water equations swes particularly for applications involving very shallow flows e g overland flows and wet dry fronts over complex domain topography the key challenge is to ensure relaxation of the flow towards an equilibrium state characterised by the balance between friction and gravity in a computationally efficient way to overcome this numerical challenge this paper proposes a novel approach for discretising the friction source terms in the swes in the context of an explicit finite volume method the overall numerical scheme adopts the hllc riemann solver and surface reconstruction method srm to explicitly discretise the flux and bed slope source terms whilst a fully implicit scheme is used to handle the friction source terms solution to the implicit formulation is analytically derived to explicitly update the flow variables compared with the existing approaches the proposed scheme effectively resolves the issue associated with stiff relaxation without necessity to use an iteration method and it supports efficient simulation using time steps controlled only by the courant friedrichs levy cfl condition the current friction term discretisation scheme is not coupled with flux and bed slope calculation and therefore may be readily implemented in any other explicit finite volume swe models after being successfully validated against two benchmark tests with analytical solutions the resulting new swe model is applied to reproduce a rainfall flooding event in the upper lee catchment in the uk keywords shallow water equations friction source terms implicit scheme stiff relaxation overland flow finite volume method 1 introduction many real world examples of surface water flows such as river flows overland flows flood waves and tsunamis can be simulated by numerical models solving the shallow water equations swes berger et al 2011 di giammarco et al 1996 kao and chang 2012 sanders et al 2010 in the past three decades substantial progress has been made in developing numerical models to solve the swes and numerous robust numerical schemes have been developed and reported to address different issues related to real world applications for example capturing the shock like flow discontinuities e g toro 2001 ensuring positivity of water depth for wetting and drying e g audusse et al 2004 liang and marche 2009 and preserving still water solutions i e c property e g bermudez and vazquez 1994 audusse et al 2004 hou et al 2013 murillo and garcía navarro 2012a xing et al 2011 zhou et al 2001 however proper discretisation of the friction source terms remains to be a challenge for developing numerically accurate and stable schemes to solve the swes for simulating very shallow flows as found in the applications involving overland flows and wet dry fronts as pointed out in xia et al 2017 inappropriate discretisation of the friction source terms may result in 1 numerical instability that leads to the use of prohibitive small time steps and 2 inaccurate prediction of flow velocities in the swe formulation the friction terms are normally expressed as a non linear function of velocity and flow depth the manning and chezy formulae provide examples of the most commonly used friction laws chow 1959 for example the 1d swes may be formulated as 1 h t h u x 0 2 h u t h u 2 1 2 g h 2 x g h s b s f where h is the flow depth u is the flow velocity in the x direction g is the acceleration due to gravity sb is the bed slope and s f g n 2 h 1 3 u u is the friction source term expressed in the form of the manning formula in which n is the manning coefficient it is the non linear nature of the friction source terms and their interactions with other source terms that bring in the major difficulty for developing robust discretisation schemes we may consider a simple example of uniform flow on a slope to illustrate the physical behaviour of the friction terms the direction of the friction is always opposite to the velocity flow direction if the friction is larger than the gravity component along the bed slope the flow will be decelerated to have a reduced velocity subsequently the friction a function of flow velocity and depth will also be reduced until a new balance is reached between the friction and gravity component on the other hand if the friction is smaller than the gravity component the flow velocity and hence the friction will increase until a new balance is reached therefore the friction source terms always take effect to relax the flow towards an equilibrium steady state characterised by the balance between the friction and gravity along the flow direction the timescale of the friction relaxation towards the equilibrium steady state may be estimated from the jacobian matrix of the friction terms for the 1d swes in eqs 1 and 2 it is given as xia et al 2017 3 t f 1 h 1 s f u 1 2 g n 2 h 4 3 u eq 3 reveals that the relaxation time becomes small when the water depth is small which may become much smaller than the time step determined by the courant friedrichs levy cfl condition in an explicit swe model such a quick relaxation is often referred to as stiff relaxation and linked to the so called stiff friction source terms to resolve the numerical issue related to stiff relaxation a simple way would be to restrict the time step length however this may lead to the use of prohibitive small time steps and subsequently unrealistic long simulation time therefore the specific challenge is to develop an effective numerical scheme for the friction source terms that can relax the flow towards the correct steady state using time steps solely determined by the cfl condition without further constraints in the past three decades numerous attempts have been made to develop friction term discretisation schemes to achieve better numerical stability but much less attention has been given to improving numerical accuracy and predicting the correct equilibrium state of the flows to provide stable simulations implicit schemes have been widely used to discretise the friction source terms e g fiedler and ramirez 2000 liang et al 2007 cea et al 2010 song et al 2011 costabile et al 2013 simons et al 2014 busaman et al 2015 cea and blade 2015 rousseau et al 2015 singh et al 2015 unlike the explicit schemes implicit schemes use the velocities at the new time step to evaluate the friction terms in other words the velocities are assumed to have the values after relaxation in this way the implicit schemes intrinsically enforce the relaxation of the friction terms to take effect in the current time step effectively removing the stiffness of the friction terms in order to simplify the numerical implementation of an implicit friction discretisation scheme a popular way is to reformulate the friction terms into explicit formulations for example the schemes reported in fiedler and ramirez 2000 and simons et al 2014 expand the friction terms using the taylor s series and omit the higher order terms to obtain an explicit formulation other researchers e g liang et al 2007 cea et al 2010 song et al 2011 costabile et al 2013 busaman et al 2015 cea and blade 2015 rousseau et al 2015 singh et al 2015 express the friction terms as the product of the velocity in the current time step and that in the new time step to obtain an explicit formula although these schemes may effectively avoid the numerical instability caused by the stiff friction terms they commonly relax the flows to a wrong steady state which may consequently lead to incorrect simulation results xia et al 2017 based on the fact that the maximum effect of friction is to fully stop the flow certain friction discretisation schemes burguete et al 2008 liang and marche 2009 also impose an upper bound on the friction so that it can only reduce the velocity to zero but not change its sign to reverse the flow these schemes effectively force the friction to relax the flow velocity to zero which is not necessarily the physically correct steady state the value of the physically correct steady state velocity depends on the bed slope and is generally not zero furthermore the flow direction may be reversed during a single time step under certain conditions taking the example of a flow moving uphill the combined effect of friction and gravity will firstly decelerate the flow until it stops and then the gravity will accelerate the flow downhill until it is balanced by the friction the flow direction has actually been reversed and this process may theoretically happen in a single time step through a different approach the scheme proposed by murillo and garcía navarro 2012b integrates the discretisation of friction terms into the adopted riemann solver this approach essentially linearizes the friction terms when integrating them over the time since the approach does not explicitly consider the non linear relaxation imposed by the friction terms an additional fix must be implemented to ensure numerical stability and convergence to the steady state another disadvantage of this approach is that the discretisation of the friction source terms and flux terms are fully coupled and cannot be easily applied in other finite volume models that adopt different flux discretisation schemes attempts have also been reported recently to develop numerical methods for proper relaxation of the stiff friction terms in swe models in yu and duan 2014 the flow velocity is adaptively set to a theoretical steady state value determined by the balance between the bed and friction slopes when the so called kinematic wave number is larger than a threshold this method was further improved by also considering the pressure gradient terms when determining the steady state velocity yu and duan 2017 however the threshold for imposing steady state velocity i e the kinematic wave number is a case dependent parameter which restricts the robustness of the method for wider applications more recently xia et al 2017 introduced a fully implicit friction discretisation scheme that can effectively relax the flow towards the correct steady state and allow the use of cfl time step even when it is much bigger than the relaxation time scale different from the aforementioned schemes that reformulate the equations into an explicit form xia et al 2017 directly solved the implicit friction equations using a newton raphson iteration method this however inevitably complicates the numerical implementation and potentially increases the computational cost due to the various limitations of the existing approaches this paper proposes a novel implicit scheme for discretising the friction source terms of the swes in the context of a finite volume method the new scheme is able to relax the flow velocity towards the correct equilibrium steady state using a normal time step determined by the cfl condition even when it is much bigger than the relaxation time scale meanwhile the new scheme calculates the friction terms explicitly without using an iteration method it is therefore straightforward to implement and computationally more efficient the rest of the paper is organised as follows section 2 presents the governing equations section 3 presents the numerical scheme with an emphasis on friction source term discretisation section 4 validates the resulting swe model using carefully selected test cases before it is applied to reproduce a real world rainfall event in section 5 and finally brief conclusions are drawn in section 6 2 governing equations the vectorised form of the 2d shallow water equations swes may be written as 4 q t f x g y s b s f where q contains the conserved flow variables f and g are the x and y direction flux vector terms and s b and s f are the source terms representing respectively the bed slope and friction effects these vector terms are given by 5 q h h u h v f u h u 2 h 1 2 g h 2 u v h g v h u v h v 2 h 1 2 g h 2 6 s b 0 g h b x g h b y s f 0 τ b x ρ τ b y ρ where v is the depth averaged velocity component in the y directions ρ is the water density and τ bx and τ by are the friction stresses calculated using the manning equation 7 τ b x ρ c f u u 2 v 2 τ b y ρ c f v u 2 v 2 with 8 c f g n 2 h 1 3 it is worth noting that the swes are generally not applicable to flows on steep slopes and modifications to the original formulation have been proposed to resolve this issue e g juez et al 2013 2014 xia and liang 2018 the friction term discretisation scheme proposed in this work can be trivially adapted for use in these modified swes 3 numerical scheme the above 2d swes are solved using a first order godunov type finite volume method the adopted numerical scheme is presented in this section with an emphasis on the introduction of the proposed new discretisation scheme for the friction source terms 3 1 first order godunov type finite volume method the time marching scheme for the finite volume method is given as follows 9 q n 1 q n δ t ω i k 1 n f k q n l k δ t r i n s b i n s f i n 1 in which subscripts i and k are the indices of a cell and the cell edges superscript n denotes the time level f k q contains the fluxes normal to cell edge k lk is the length of the cell edge k ω i is the cell area and δt is the time step in the current numerical scheme the flux and slope source terms are discretised explicitly based on the flow variables at time level n but the friction source terms are discretised implicitly using the flow variables at time level n 1 3 2 calculation of flux and bed slope source terms in this work the flux term f k q is calculated using an hllc riemann solver for which the details can be found in toro 2001 the required riemann states are obtained using the surface reconstruction method srm as proposed by xia et al 2017 srm firstly reconstructs the water surface elevations at the left and right hand sides of a given cell interface considering two adjacent cells i and i 1 the reconstructed water surface elevations denoted by η are 10 η l η i max 0 min b i 1 b i δ b η i 1 η i 11 η r η i 1 max 0 min b i b i 1 δ b η i η i 1 with 12 δ b b i 1 2 b i 1 2 in which b i 1 2 and b i 1 2 are the bed elevations at the left and right hand sides of the cell interface which are interpolated from the corresponding cell centre values using a slope limited method as 13 b i 1 2 b i r i b i and b i 1 2 b i 1 r i 1 b i 1 where r is the distance vector from the cell centre to the cell interface and b is the slope limited gradient of bed elevation in this work the widely used minmod slope limiter is adopted for numerically stable simulations the bed elevations at the left and right hand sides of the cell interface are then redefined using the corresponding reconstructed water surface elevations and water depths as 14 b l η l h i b r η r h i 1 which are then used to define a single bed elevation at the cell interface as 15 b f max b l b r based on which the riemann states of the flow depth are defined 16 h l max 0 η l b f h r max 0 η r b f the riemann states of the discharges are subsequently deduced 17 h u l h l u i h u r h r u i 1 h v l h l v i h v r h r v i 1 where ui hu i hi and vi hv i hi similarly u i 1 and v i 1 are the depth averaged velocities calculated at the cell centres these riemann states are then used to calculate the numerical fluxes in eq 9 using an hllc riemann solver in the context of the first order godunov type finite volume method as adopted in this work the bed slope source terms are calculated as 18 s b i 0 1 ω i 1 2 g h i h l k b i b f k n k l k where h l k is the left riemann state of the flow depth at cell edge k and b f k is defined as 19 b f b f δ b 20 δ b max 0 b f η i if h i 1 ɛ h δ b max 0 min δ b b f η i if h i 1 ɛ h in which ε h 10 10 is a small value to define a dry cell the present flux and slope discretisation schemes automatically ensure non negative water depth and preserve still water solutions i e c property for simulations involving wetting and drying over rough terrain with complex topography xia et al 2017 3 3 discretisation of the friction source terms in the current godunov type finite volume scheme the friction source terms in eq 9 are discretised implicitly but the actual calculation is carried out explicitly through derivation of an effective explicit formulation to derive the required explicit formulation the momentum components in eq 9 are firstly expanded into a scalar form as 21 q x n 1 q x n δ t a x δ t g n 2 h n 7 3 q x n 1 q x n 1 2 q y n 1 2 22 q y n 1 q y n δ t a y δ t g n 2 h n 7 3 q y n 1 q x n 1 2 q y n 1 2 in which qx hu and qy hv are the x and y direction components of the unit width discharge and ax and ay represent the momentum components of 1 ω i k 1 n f k q n l k s b i n respectively in the x and y directions eqs 21 and 22 are obviously non linear functions of q x n 1 and q y n 1 to find the roots for q x n 1 and q y n 1 a new approach is proposed and implemented in this work to analytically solve eqs 21 and 22 instead of using the newton raphson iteration method as reported in xia et al 2017 firstly eqs 21 and 22 are reformulated into 23 q x n 1 1 δ t g n 2 h n 7 3 q x n 1 2 q y n 1 2 q x n δ t a x 24 q y n 1 1 δ t g n 2 h n 7 3 q x n 1 2 q y n 1 2 q y n δ t a y dividing eq 23 by eq 24 leads to 25 q x n 1 q y n 1 q x n δ t a x q y n δ t a y then by substituting 25 into 23 we can obtain 26 q x n 1 1 δ t g n 2 h n 7 3 q x n 1 2 m y m x 2 q x n 1 2 m x in which 27 m x q x n δ t a x and m y q y n δ t a y if q x n 1 is positive eq 26 may be rewritten as 28 q x n 1 q x n 1 2 δ t g n 2 h n 7 3 1 m y m x 2 m x otherwise 29 q x n 1 q x n 1 2 δ t g n 2 h n 7 3 1 m y m x 2 m x eqs 28 and 29 are quadratic equations in terms of q x n 1 and each of them has two roots therefore mathematically there may be as many as four roots for eq 26 two for the positive q x n 1 and two for the non positive q x n 1 however only one of these roots is physically meaningful for hydrodynamic modelling which must be correctly identified the two roots for eq 28 i e the positive q x n 1 are 30 q x n 1 1 1 4 δ t g n 2 h n 7 3 m x 1 m y m x 2 2 δ t g n 2 h n 7 3 1 m y m x 2 and 31 q x n 1 1 1 4 δ t g n 2 h n 7 3 m x 1 m y m x 2 2 δ t g n 2 h n 7 3 1 m y m x 2 and the two roots for eq 29 i e the non positive q x n 1 are 32 q x n 1 1 1 4 δ t g n 2 h n 7 3 m x 1 m y m x 2 2 δ t g n 2 h n 7 3 1 m y m x 2 and 33 q x n 1 1 1 4 δ t g n 2 h n 7 3 m x 1 m y m x 2 2 δ t g n 2 h n 7 3 1 m y m x 2 which one of the above four roots is physically admissible for hydrodynamic modelling depends on mx if mx is positive eq 30 is negative which contradicts to the prescribed assumption of positive q x n 1 i e q x n 1 0 on the other hand eq 31 is positive which is consistent with assumption of q x n 1 0 meanwhile eqs 32 and 33 are both positive as long as they are real which are clearly not consistent with the assumption of q x n 1 0 therefore eq 31 provides the only physically correct root for eq 29 if mx 0 similarly we can prove that eq 33 gives the only admissible root for eq 29 if mx 0 these two admissible roots can be combined into one analytical expression as 34 q x n 1 m x m x 1 4 δ t g n 2 h n 7 3 m x 2 m y 2 2 δ t g n 2 h n 7 3 m x 2 m y 2 if hn is excessively small e g near to the wet dry front the term h n 7 3 may return an exaggerating big value 1020 depending on the value water depth that may exceed the maximum machine precision and thus create machine error leading to numerical stability to avoid this part of h n 7 3 is cast into the square root operators to facilitate stable numerical implementation and the final expression for q x n 1 is given as 35 q x n 1 m x m x 1 4 δ t g n 2 h n 4 3 m x h n 2 m y h n 2 2 δ t g n 2 h n 4 3 m x h n 2 m y h n 2 it is also possible that the denominator may return a zero making eq 35 to become singular in such a case q x n 1 m x is effectively the root to 29 to avoid singularity in the numerical calculation eq 34 is slightly modified to become 36 q x n 1 m x if δ t g n 2 h n 4 3 m x h n 2 m y h n 2 10 10 m x m x 1 4 δ t g n 2 h n 4 3 m x h n 2 m y h n 2 2 δ t g n 2 h n 4 3 m x h n 2 m y h n 2 if δ t g n 2 h n 4 3 m x h n 2 m y h n 2 10 10 similarly the physically admissible root for eq 24 and the final expression for q y n 1 can be derived and given as follows 37 q y n 1 m y if δ t g n 2 h n 4 3 m x h n 2 m y h n 2 10 10 m y m y 1 4 δ t g n 2 h n 4 3 m x h n 2 m y h n 2 2 δ t g n 2 h n 4 3 m x h n 2 m y h n 2 if δ t g n 2 h n 4 3 m x h n 2 m y h n 2 10 10 therefore the explicit expressions of q x n 1 and q y n 1 accounting for the friction effects are given by eq 36 and eq 37 which can be explicitly calculated and incorporated into the adopted godunov type scheme to develop a new swe model in order to mathematically prove that the proposed numerical scheme can effectively relax the flow velocity to the correct equilibrium steady state we consider δt in eq 36 and eq 37 by assuming δt we effectively impose that the cfl determined time step is much bigger than the relaxation time scale the resulting expressions for q x n 1 and q y n 1 become 38 lim δ t q x n 1 a x g n 2 h n 7 3 a x 2 a y 2 39 lim δ t q y n 1 a y g n 2 h n 7 3 a x 2 a y 2 apparently lim δ t q x n 1 and lim δ t q y n 1 are the unit width discharges determined by the balance between the friction and other terms i e the flux and bed slope terms in the swes therefore the physically correct equilibrium steady state can be properly recovered by the proposed friction discretisation scheme it should be also noted that lim δ t q x n 1 and lim δ t q y n 1 do not necessarily have the same signs as q x n and q y n this defies the assumption adopted by burguete et al 2008 and liang and marche 2009 where the flow direction cannot be reversed within a single time step in the current friction discretisation scheme the flow can theoretically be reversed during a time step 3 4 solution procedure at each time step the solution procedure of the resulting swe model may be summarised as follows 1 explicitly evaluate the flux terms and bed slope source terms using srm as described in section 3 2 2 integrate the mass flux term in eq 9 to obtain h n 1 3 integrate the momentum flux terms and the bed slope source terms in eq 27 to obtain mx and my 4 integrate the friction source terms in eqs 36 and 37 to respectively obtain q x n 1 and q y n 1 5 update the flow variables and move to the next time step 3 5 stability criterion for the resulting swe model as introduced in the previous sub sections the time step length for numerically stable simulations is solely determined by the courant friedrichs levy cfl condition given as 40 δ t cfl d i u i g h where di is the minimum distance from the cell centre to the corresponding cell edges and cfl denotes the cfl number that takes a non zero value between 0 and 1 cfl 1 0 is used in all of the simulations in this work the stability criterion for the overall explicit swe model is irrelevant to the friction term discretisation this is because the flux and bed source terms and the friction source terms are treated separately the new implicit friction term integration method proposed in this work relaxes the flow velocity to the correct equilibrium state even when the time step is large δt which effectively avoids further constraint on the time step length therefore the time step of the overall model is only controlled by the cfl condition 4 model validation two analytical test cases are considered in this section to validate the new friction term discretisation scheme both test cases involve very small water depth to highlight the need of a proper numerical scheme to discretise the friction source terms for stable and accurate simulations it is noteworthy that the discretisation scheme for flux and slope source terms have already been intensively tested and verified in our previous work xia et al 2017 in particular the scheme has been proven to perfectly preserve the lake at rest resolutions and ensure the positivity of water depths for applications involving complex topography and wetting and drying repeating these tests is deemed to be unnecessary and will not be considered herein to demonstrate the advantages of the new implicit friction discretisation scheme the simulation results are compared with the analytical solutions and also numerical solutions obtained using two alternative schemes 1 the iterative implicit scheme proposed by xia et al 2017 referred to as iterative friction model ifm herein and 2 a popular implicit scheme adopted by many researchers e g busaman et al 2015 cea and blade 2015 liang et al 2006 song et al 2011 named as explicit friction model efm from now on the convergence criterion of ifm is chosen to be the same as that in xia et al 2017 i e the iteration stops when the relative difference between the solutions in two iterations is less than 0 001 efm reformulates the implicit friction discretisation scheme into an explicit form as 41 q x n 1 m x 1 δ t g n 2 h n 4 3 u n 2 v n 2 and 42 q y n 1 m y 1 δ t g n 2 h n 4 3 u n 2 v n 2 to quantitatively assess the accuracy of the numerical simulation results the root mean square error rmse is defined and calculated by 43 rmse 1 n f m n f t n 2 n where n is the total number of time steps f m n is the simulated results and f t n is the reference solutions for a specific flow variable f at t n analytical solutions are available for comparison for both of the test cases considered in this section 4 1 two dimensional uniform flow the first test case to consdier is a 2d uniform flow with constant depth and velocity over a slope the water depth is 0 001 m and the bed slopes in the x and y directions i e sbx and sby are both 0 05 the manning coefficient is taken as 0 035 sm 1 3 and is constant over the entire domain according to xia et al 2017 the steady state velocity components determined by the balance between friction and gravity are given by 44 u s b x g n 2 h 1 3 s b x 2 s b y 2 and v s b y g n 2 h 1 3 s b x 2 s b y 2 which give u 0 0537 m s and v 0 0537 m s based on the parameters as provided herein two sets of initial velocities are considered i e case a u 0 5u v 0 10v and case b u 0 5u v 0 10v the two sets of initial velocities have opposite signs to confirm the correct solutions to the two different quadratic equations resulting from eq 26 three different grid sizes i e δx 1 m 10 m and 100 m are used in the simulations the velocities predicted by the three different friction discretisation schemes are normalised by the theoretical steady state velocity and compared with each other in fig 1 the current scheme and ifm are both able to relax the flow velocity towards the correct steady state velocity monotonically in one or two time steps in all three simulations with different grid resolutions it is worth noting that for case b the signs of both of the x and y direction steady state velocities are different from the initial conditions i e the steady state velocities are positive while the initial velocities are negative which can be clearly seen in fig 1 c and d the change of the signs of the velocities subsequently the reversal of the flow is predicted within a single time step by the current scheme and ifm for the coarse grid simulations δx 10 m and 100 m this confirms the previous statement that the flow direction can be theoretically reversed within a single time step the time steps used in the simulations are also plotted in fig 2 and comparable with δt calculated from u and v with cfl 1 0 this effectively demonstrates that stable and accurate simulations are achieved using time steps determined solely by the cfl condition the current scheme provides numerical predictions identical to those by ifm which is as expected and confirms the validity of the explicit friction formulae derived in the previous section however the flow velocities predicted by efm fail to converge to the correct steady state on all three grid configurations the prediction accuracy of the three different schemes is quantified by calculating rmses which are listed in table 1 for all of the simulations the rmses predicted by the current scheme and ifm are much smaller than those resulting from efm for the current scheme and ifm the rmses decrease as the grid cell size increases indicating that the flow is relaxed to the steady state with fewer time steps on coarser grids this is consistent with the mathematical property of the manning s friction terms the relaxation scale is independent of the cell size as indicated by eq 3 but the time step length increases as the cell size increases therefore fewer time steps are required to converge the flow to the steady state 4 2 overland flow on an idealised v shaped catchment the current friction discretisation scheme is further tested through simulating overland flow on an idealised v shaped catchment the catchment comprises of two hillsides with a 0 05 slope and a channel with a 0 02 slope as shown in fig 3 the manning coefficients for the hillslopes and channel are 0 015 sm 1 3 and 0 15 sm 1 3 respectively constant and uniform rainfall with an intensity of 10 8 mm h falls on the whole catchment for 1 5 h from the beginning except for the channel outlet where open boundary conditions are imposed all other boundaries are closed a uniform grid of 10 m resolution is used for all of the simulations fig 4 presents the discharge hydrographs predicted by all of the three friction term discretisation schemes at the hillsides and channel outlet which are compared with the analytical solutions derived based on the kinematic wave assumptions see di giammarco et al 1996 for details the results produced by the current scheme and ifm are identical which are all in good agreement with the analytical solutions however the hillside discharge predicted by the efm scheme presents unphysical oscillations at the onset stage this is directly caused by the small relaxation time for the very shallow overland flow on the hillside in such a case efm cannot properly relax the flow velocity towards the correct steady state the superiority of the current scheme and ifm is further confirmed by the calculated rmses listed in table 2 the rmses resulting from the current scheme and ifm are slightly smaller than efm for both the hillside and channel outlet discharges 5 application to a real world rainfall flooding event in this section the model implemented with the new friction discretisation scheme is applied to reproduce a rainfall flooding event in the upper lee catchment at north london uk the catchment covers an area of 1180 km2 as shown in fig 5 the records of catchment outlet discharge are available from a gauge station installed at the river lee heavy rainfall was recorded between 5th and 11th feb 2014 which directly triggered a flood event the time series of the mean rainfall intensity over the whole catchment is presented in fig 6 showing several rainfall peaks although various uncertainties exist when assessing accuracy of a model for real world applications this test case is considered to validate the numerical stability and efficiency of the proposed numerical scheme for complex problems the simulation is carried out for a total of 120 h from 00 00 on 5th feb 2014 the whole catchment is discretised using a uniform grid of 20 m resolution leading to 2 95 million computational cells zero infiltration is assumed due to antecedent rainfall and saturated soil condition the manning coefficients are set to be spatially varying according to the land use types as shown in fig 7 the manning coefficients for different land use types are summarised in table 3 selected based on the commonly used values as suggested in chow 1959 since the purpose of this case study is to test the numerical stability and efficiency of the current scheme the model is not calibrated for the simulations and the used parameters may not represent an optimal parameter set the models implemented respectively with the current friction discretisation scheme and ifm are used to simulate this event similar to the previous test cases the two models predict identical simulation results which is as expected the predicted flood maps at different output times are presented in fig 8 at t 48 h streams and river channels inside the catchments have already been filled with water significant inundation can be observed in the downstream areas at t 72 h the flood water has been further routed into the main rivers as indicated by the extended inundation areas and the retreat of water in the upland streams at t 96 h the flood peak has passed and smaller inundated areas are observed compared with 24 h ago the reduced water depth at t 120 h suggests further retreat of the flood overall the simulated flood process is consistent with the rainfall pattern in which most of rain has fallen before t 96 h the predicted discharge hydrograph at the catchment outlet is compared with the observation in fig 9 overall good agreement is achieved between the numerical prediction and the observation except for the slightly over estimated rising limb at the initial stage the nash sutcliffe efficiency nse has been adopted herein to quantitatively confirm the accuracy of the numerical prediction the nse is defined as 45 n s e 1 1 n q m n q o n 1 n q m n q o where n is the total number of time steps q o n is the observed discharge at t n q m n is the simulated discharge at t n and q o is the mean observed discharge nse 1 suggests perfect agreement between the prediction and the observation for this simulation the nse is calculated to be 0 91 indicating that the observed discharge has been successfully reproduced with high accuracy by the current model to compare the computational efficiency both of the numerical schemes i e the current scheme and ifm are implemented in the same gpu accelerated codebase which are run in parallel on 4 nvidia tesla k40 gpus and 2 nvidia tesla k80 gpus the runtimes are summarised in table 4 considering only the runtime for friction calculation the current scheme is 2 35 times faster than the ifm this confirms that the friction discretisation scheme based on the explicit formulae derived in this work is computationally more efficient than ifm embedded with a newton raphson iteration method 6 conclusions this work presents and validates a novel implicit scheme for discretising the stiff friction terms in the 2d swes the scheme features with the following two key properties 1 the scheme is able to resolve the relaxation of flow velocities towards the exact steady state determined by the balance between friction and gravity along the flow direction using time steps controlled only by the cfl condition for the overall explicit swe model 2 the scheme can be implemented explicitly without necessity of using any iteration methods these properties are crucial to ensure numerically stable efficient and accurate simulation of very shallow flows such as overland flows and wet dry fronts and the associated processes including soil erosion and solute transport however existing friction discretisation schemes usually do not simultaneously possess both of these properties the current scheme has been successfully validated against two benchmark tests with satisfactory results confirming its superior numerical stability and accuracy in comparison with the existing mainstream approaches the resulting swe model is then further applied to simulate a rainfall flooding event in the upper lee catchment uk to further confirm its numerical stability and computational efficiency for the simulation of overland flows and flooding over complex real world topography although the current scheme is proposed in the context of a godunov type finite volume method in principle it can also be used in other numerical methods e g finite difference method and finite element method acknowledgements this work is funded by the nerc sinatra and tenderly projects grant no ne k008781 1 and flood prepared project grant no ne p017134 1 
