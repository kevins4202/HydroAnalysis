index,text
7345,arsenic as contaminated groundwater is a global concern with potential detrimental effects on the health of hundreds of millions of people worldwide however the extent of this problem may be more severe than anticipated as many wells have not been tested and may contain unsafe level of as an optimized statistical regression model was developed to predict the probability of geogenic high as groundwater as 10 μg l in this study easily obtained hydrogeochemical and geological parameters that are significantly related to as geochemical behaviors were selected as explanatory variables in the model the results indicate that ph cl hco3 so4 2 and no3 concentrations stratigraphic information and well depth are excellent predictors of as exposure in the datong basin china predicted unsafe wells correspond well with the known distribution of high as groundwater in the datong basin the successful application of a data set from bangladesh also demonstrated the applicability and credibility of this proposed method keywords groundwater arsenic contamination risk prediction logistic regression model 1 introduction the contamination of groundwater by arsenic as is a global environmental health issue and the long term intake of as can cause various forms of arsenism chen and ahsan 2004 chowdhury et al 2000 nickson et al 1998 in the last decades great efforts have been made to investigate and understand the temporal spatial occurrence of groundwater containing high levels 10 μg l of as around the world especially in south and south east asia chowdhury et al 2000 nickson et al 1998 smith et al 2000 many of wells that may contain high level of as were not yet monitored due to the high cost of the regular monitoring of drinking water wells it follows that drinking water from these wells may trigger as poisoning of local residents therefore it is urgent to develop methods to predict the as concentration or the probability that the as concentration exceeds the safety standard to allow prioritization of monitoring of drinking water wells with higher predicted as concentration or as contamination probability so as to minimize potential health impacts geostatistical interpolation to identify data spatial distribution patterns has been used to predict groundwater as contamination gaus et al 2003 goovaerts et al 2005 roy and hossain 2014 however as indiacted by hossain et al 2007 geostatistical interpolation approaches require a large amount of data to obtain accurate evaluation results which limits the application of this method for areas lacking sufficient groundwater as concentration data statistical regression provides a promising alternative to geostatistical interpolation with this method only a relatively small number of training data are required to establish a predictive model several statistical regression models have previously been built to predict the risk of geogenic groundwater as contamination ahn and cho 2013 amini et al 2008 ayotte et al 2006 rodríguez lado et al 2013 winkel et al 2008 yang et al 2014 in general the sedimentary environment soil properties climate condition geological setting and hydrogeological and geomorphological conditions were selected as explanatory variables to underpin large scale predictions for locations where hydrochemical data are not available however at the resolution of these models adjacent wells may have the same surface parameters but totally different as concentrations mainly due to the heterogeneity of the geochemical and hydrodynamic conditions fendorf et al 2010 polizzotto et al 2008 stute et al 2007 van geen et al 2008 the low resolution makes it difficult to predict groundwater as concentrations at individual wells from surface parameters alone in fact the groundwater as concentration often co varies with the local hydrogeochemical compositions e g fe2 so4 2 due to physical e g pumping and or geochemical e g dissolution of as bearing fes2 processes even though these components are not necessarily directly responsible for the release of as the correlation between selected hydrochemical parameters and as can be used to predict groundwater as concentrations as the hydrochemical composition of groundwater in adjacent wells can differ substantially using hydrochemical parameters to predict as concentration at the single well resolution has the potential to further improve as risk predictions for this reason hydrochemical variables that are relevant to as mobilization mechanisms should be combined into a risk predictive model such models may be established for regions that are uniformly governed by specific as release mechanisms it is widely accepted that the reduction of iron fe oxides oxyhydroxides is one of the main geochemical processes that cause the release of as from the solid phase into groundwater campbell et al 2006 islam et al 2004 oremland and stolz 2003 tufano et al 2008 however pyrite oxidation may also result in the release of as under some conditions jones and pichler 2007 pili et al 2013 rathi et al 2017 in addition desorption processes can cause the mobilization of as in groundwater under certain conditions acharyya et al 2000 tufano et al 2008 competitive adsorption between co existing ions and as can promotethe enrichment of as in groundwater acharyya et al 2000 anawar et al 2004 appelo et al 2002 furthermore recent studies have addressed the pivotal roles of sediment age and well depth on as migration in groundwater mcarthur et al 2010 postma et al 2007 2012 fendorf et al 2010 the objective of this study was to establish a reliable logistic regression model for the prediction of as exposure risk by using conventional hydrochemical and geological parameters as explanatory variables that are relevant to as mobilization logistic regression models were separately established for the datong basin of china and a selected study area of bangladesh bgs and dphe 2001 2 materials and methods 2 1 study area the datong basin fig 1 is an arid semi arid region in northern china the central part of the basin is an alluvial lacustrine plain composed of quaternary unconsolidated sediments with a thickness that is generally 200 m and a maximal thickness of 1000 m high as groundwater is mainly found in the central part of the basin and shallow semi confined aquifer depth 10 50 m is the main aquifer showing elevated as concentrations the groundwater as concentration range from 0 1 to several hundred μg l with as mainly occurring as arsenate in the study area the mobilization of as is clearly related to the reductive dissolution of fe oxides oxyhydroxides and or desorption from fe oxides oxyhydroxides at high ph xie et al 2008 2 2 variable selection the selection of explanatory variables was based on the simplest possible model and formation mechanism of high as groundwater in the datong basin arsenate the predominating as species in groundwaters of the datong basin is easily adsorbed by colloids and minerals with positive charges stollenwerk 2003 the high ph increases the negative charges on these colloids and minerals and adsorption of arsenate is less favorable park et al 2006 smedley and kinniburgh 2002 stollenwerk 2003 high as groundwater often contains high concentrations of bicarbonate hco3 which may result from the microbial oxidation of organic matter coupled to the reduction of fe and or manganese mn oxyhydroxides mcarthur et al 2001 postma et al 2010 román ross et al 2006 xie et al 2013 competitive absorption between as and hco3 may contributes to the release of as from mineral surfaces appelo et al 2002 guo et al 2011 however some experimental results do not support this competition displacement theory meng et al 2000 radu et al 2005 stachowicz et al 2007 in an environment where an organic carbon is available to induce the reductive dissolution of fe oxide oxyhydroxides sulfate so4 2 and nitrate no3 where present are also likely to be consumed by microbial respiration borch et al 2010 massmann et al 2003 sanford et al 2004 in large basins chloride cl concentrations gradually increase in most cases along the groundwater flow direction and groundwaters in the discharge area are characterised by higher cl concentrations adams et al 2001 guo and wang 2004 plummer et al 1990 sikdar et al 2001 sluggish groundwater movement favours the accumulation of as in the central part of the basin guo et al 2014 stute et al 2007 weinman et al 2008 therefore the concentrations of cl and as may show similar trends from the margin areas to the central section of the basin and cl may also serve as an indicator of as concentrations in groundwater in accordance with the discussed mechanisms ph cl hco3 so4 2 and no3 were selected as explanatory variables to represent key hydrochemical characteristics the reactivity and availability of organic carbon utilized as electron donor for the reductive dissolution of as bearing fe oxides oxyhydroxides may be be the overall determinant of the release of as to groundwater postma et al 2012 fendorf et al 2010 rowland et al 2007 younger shallower sediments often show more reactive organic carbon and more rapid release of as harvey et al 2002 horneman et al 2004 papacostas et al 2008 postma et al 2012 however the impact of biogeochemical processes triggered by typically higher reactivity of organic carbon in shallow groundwater on as mobilization may be offset by the often stronger flushing in these aquifers which then results in lower as concentrations in groundwater stute et al 2007 van geen et al 2008 therefore stratigraphic information values 1 2 and 3 were respectively assigned to the holocene pleistocene and other strata to represent increasing age and well depth were also considered as explanatory variables in this predictive model in this study the dependent variable is the binary variable of as concentration based on a threshold of 10 μg l 1 and 0 indicate an as concentration 10 μg l and less than or equal to 10 μg l respectively 2 3 data capture and processing the hydrochemical data used to establish the predictive model for the datong basin were drawn from the previous hydrogeochemical investigations of the datong basin performed by li et al 2012 table s1 supplementary information in this dataset there are about ten times more of both the high as samples and low as samples than the number of explanatory variables godfrey and orme 1994 the validation dataset consisted of published research data xie et al 2013 from the datong basin the map of the strata distribution of the datong basin fig 1 was adapted from the geological map of the shanxi province available from the official website of the china geology survey http www cgs gov cn the logistic regression can be used to analyze a binary dependent variable and explore the relationship between the probability of a response exceeding a threshold value and explanatory variables the model generally takes the following form eqs 1 3 1 logit ln p 1 p b 0 i 1 n b i x i 2 p e logit 1 e logit 3 b i b i s xi s logit r where p is the probability of response variable exceeding a given threshold value b 0 is a constant and bi and bi are the standardized regression coefficient and the non standardized coefficient respectively xi represents the explanatory variables sxi is the standard deviation of the explanatory variable xi s logit is the standard deviation of the computed values of logit r is the correlation coefficient between the predicted and observed values of p i e 0 or 1 and n is the number of explanatory variables the basis of logistic regression is the existence of linear relationships between logit and the explanatory variables hosmer et al 2013 postma et al 2012 any deviation from linearity will result in the deviation of the regression coefficients the method proposed by hosmer et al 2013 can be utilized to reveal the non linearity forms a non linear relationship can be represented as a piecewise function that is composed of two elementary functions and this piecewise function can be expressed as a single expression eq 4 4 f x p x x x 0 q x x x 0 1 2 p x q x 1 2 p x q x x x 0 x x 0 where f x is the piecewise function p x and q x are two elementary functions and x 0 is the piecewise point this single expression can be used to fit a non linear relationship logistic regression also does not require a perfect multicollinearity between explanatory variables hahn 2006 hosmer et al 2013 menard 2001 the extent of multicollinearity can be evaluated by multiple methods such as tolerance tol menard 2001 and the maximum condition index test stewart 1996 the robustness of the regression model is an essential prerequisite to assess relationships between explanatory variables and the response variable therefore a residual analysis is required to identify the points with obvious impact on model robustness cook s distance variation of pearson chi square δχi 2 and deviance residual δdi are the main diagnostic statistics of a logistic regression model menard 2001 points with greater cook s distance δχ2 and δd values are suspected points affecting model robustness logistic regression modeling and all other related calculations were performed using spss statistical software ibm corp released 2013 ibm spss statistics for windows version 22 0 armonk ny ibm corp 3 results 3 1 nonlinear detection the relationships of logit and the explanatory variables other than ph stratigraphy and well depth were nonlinear fig s1 the concentrations of cl hco3 so4 2 and no3 were converted using a fitting formula to ensure a linear relationship between logit and each explanatory variable to simulate the original trends between logit and the explanatory variables after linearization logit was positively correlated with cl and hco3 and negatively correlated with so4 2 and no3 3 2 multicollinearity detection as a general rule a maximum condition index value 30 belsley 1991 and a tol value less than 0 2 menard 2001 indicate high multicollinearity the results indicated that there was not high multicollinearity between independent variables table s3 3 3 regression analysis a backward stepwise likelihood ratio method appelo et al 2002 was used to filter the statistically significant explanatory variables the significance level was set to 0 10 rather than the typical value of 0 05 to prevent the risk of not finding any significant explanatory variable bendel and afifi 1977 the final logistic regression model includes all seven explanatory variables table 1 3 4 robustness detection scatter plots of the diagnostic statistics versus the calculated probabilities were generated show that only three data points have an obvious influence on the fitted values and estimated coefficients of the model fig s2 though these data points appear to be outliers there is no evidence that they are affected by unnatural factors so these points were not excluded from the model development 4 discussion 4 1 interpretation of the regression coefficient as listed in table 1 the concentrations of so4 2 no3 and the stratigraphy were negatively correlated with logit while ph cl hco3 and well depth were positively correlated with logit previous research showed that the holocene strata in the datong basin are generally rich in organic carbon wang et al 2010 xie et al 2013 during organic matter degradation fe can be consumed as electron acceptors leading to dissimilatory reduction of fe oxides oxyhydroxides and the subsequent release of co existing as postma et al 2012 fendorf et al 2010 rowland et al 2007 low concentrations of so4 2 and no3 often characterise a reducing environment that facilitates the dissolution of as bearing fe oxides oxyhydroxides guo et al 2014 xie et al 2013 the positive correlation between logit and ph indicates that a high ph is usually an indicator of as enrichment in groundwater the adsorption of arsenate the predominate as species in groundwater in the datong basin is greatest at low ph and decreases with increasing ph stollenwerk 2003 also the reduction of as bearing fe oxides oxyhydroxides is often associated with an increase in ph hansel et al 2003 mcarthur et al 2004 nickson et al 2000 xie et al 2008 as a result these two processes result in a positive correlation between logit and ph the positive coefficient of hco3 may reflect the oxidation of organic matter that is accompanying the reduction of as bearing fe oxides oxyhydroxides mcarthur et al 2004 nickson et al 2000 or the competitive adsorption between as and hco3 appelo et al 2002 or both processes the positive coefficient of cl indicates a higher risk of groundwater as concentration exceeding the safe level along the groundwater flow close to the discharge area and this pattern has also been found in other high as areas around the world guo et al 2014 stute et al 2007 weinman et al 2008 the positive coefficient for the well depth indicates that within the sampling depth range the probability of high as groundwater increases with increasing depth this result may seem to contradict with the general observation that the groundwater as concentration declines with depth fendorf et al 2010 postma et al 2012 however as shown in fig s3 although as concentrations obviously decrease with increasing depth the fraction of wells with as 10 μg l increases with increasing well depth it is the latter trend that causes the positive coefficient for well depth the standardized regression coefficient b evaluates the importance of each explanatory variable hosmer et al 2013 menard 2001 and a larger absolute value of b implies a greater effect of the explanatory variable on the response variable according to these results the concentration of so4 2 stratigraphy and ph show to be the three most important indicators for the occurrence of geogenic high as groundwater table 1 4 2 probability map and verification of the predictions the p value of the hosmer lemeshow goodness of fit test hl test table s4 statistic was 0 919 suggesting that the model fits quite well with the measured results and the model classification using different probability cutoffs is shown in fig 2 a a probability cutoff of 0 20 was chosen for maximum overall classification resulting in a model with higher sensitivity i e the model s ability to identify high as groundwater and higher specificity i e the model s ability to identify low as groundwater using this cutoff the proportion of total correct classification sensitivity and specificity were 87 8 88 1 and 87 8 respectively table 2 the area under the receiver operating characteristic curve auc table s5 was 0 951 indicating excellent model discrimination to visualize the model predicted distribution and the actual distribution of high as groundwater a predictive continuous probability map fig 3 a based on calculated probability values and an actual continuous probability map fig 3b based on the measured concentration of as of groundwater wells exceeding 10 μg l as in the datong basin were constructed using universal kriging interpolation table s6 and indicator kriging interpolation table s7 respectively the predicted high risk regions probability 0 20 mainly are located in the central basin and northeastern basin a finding that is in good agreement with the measurements a good fit of the logistic regression model does not automatically guarantee a good predictive performance and the ability of the model to be more generally applicable needs to be validated using a test dataset because the described relationship between as and the explanatory variables is only valid for the characteristic reaction mechanism governing as mobilization in the datong basin the applicability of the model is restricted to this area accordingly to test the validity of the model a new dataset xie et al 2013 table s8 was created from previously published data for the datong basin and then was substituted into the final model to calculate the probabilities of as concentration exceeding 10 μg l the test results show that the proportion of total correct classifications false negatives and false positives were 91 4 5 and 4 5 respectively fig 4 a small prediction errors indicate that our modeling method can be used to accurately predict groundwater as levels in the datong basin however if application of the final logistic regression model results in calculated probabilities greater than the probability threshold of 0 20 the as concentrations at the corresponding monitoring locations should be checked to avoid potential health risks 4 3 application of the predictive method to a dataset from bangladesh in bangladesh the holocene alluvial aquifers used for the public water supply contain naturally occurring as which like in the case of china affects the health of tens of millions of people nickson et al 1998 the prediction of high as groundwater in southeast asia including bangladesh was already performed earlier by winkel et al 2008 using spatially continuous data e g sedimentary information and soil maps as explanatory variables application of their model to bangladesh gave the calculated proportion of total correct classification false negative and false positive as 71 13 and 17 respectively table 3 winkel et al 2008 then verified the predicted risk in south sumatra and found that the classification results were comparable to those calculated for bangladesh table 3 furthermore they concluded that the probability maps could be further improved with the inclusion of data with higher spatial resolution or in three dimensions to compare this approach the work of winkel et al 2008 our prediction method was applied in bangladesh to establish a predictive model for groundwater as contamination detailed hydrogeological hydrochemical and sedimentological studies were previously conducted in nawabganj and shibganj bangladesh bgs and dphe 2001 therefore this dataset fig s4 and table s9 including hydrochemical data and related geological information barind clay and residuum alluvial sand and alluvial silt were represented as 1 2 and 3 respectively to ensure a linear relationship between logit and stratigraphy was used to predict groundwater as concentration and to verify the applicability of our prediction approach 90 of the dataset randomly selected was used for model development and the remaining 10 was used for model validation the data were processed identically to the process described above for the data from the datong basin our final predictive model table s10 contains only five variables namely ph b 0 998 stratigraphy b 0 259 hco3 b 0 167 so4 2 b 0 162 and well depth b 0 096 the classification results of the training dataset table 3 hl test 0 202 table s11 and auc value 0 933 table s12 of our model combined with the results of model verification fig 4b and table 3 indicate that our model can reasonably predict geogenic high as groundwater contamination in nawabganj and shibganj bangladesh and that our proposed method is applicable 5 conclusion to predict the probability of groundwater as concentration exceeding human health benchmarks logistic regression models were established for the datong basin before applying them to a selected study area in bangladesh the accuracies of the model predictions for the datong basin and for bangladesh were 91 0 and 82 9 respectively which verified the reliability of our new modeling approach regression analysis is a causality based prediction method that can help to establish the cause of a particular effect which is a crucial step to successful prediction of the effect the enrichment of as in groundwater is the consequence of water rock interactions using simple and targeted hydrochemical and geological datas as indicators of water rock interactions relevant to as mobilization may be an effective way to predict as levels in groundwater as demonstrated in the preceding sections the hydrochemical and geological indicators can be used as explanatory variables to establish a reliable predictive model and the variation of as concentrations between adjacent wells can be identified therefore an important implication is that our proposed method can predict the risk of high as exposure at single well resolution however the predictive model based on limited number of explanatory variables and training data can express most but not all the variability in as concentrations in a region thus the accuracy of the predictions is very high but some residual discrepancies exist this stems from the fact that the relationships between as and the explanatory variables differ for different types of groundwater that means this method can be reliably used to predict as levels in groundwater within specific regions that are characterised by the same hydrogeochemical mechanisms governing as accumulation in groundwater in practice samples collected from known endemic as poisoning areas in an area can be utilized to establish a predictive model that can be applied to search for other undiscovered locations of high as groundwater in this area or in other areas with similar hydrogeological and hydrogeochemical conditions though the number of high as samples required for modeling is generally much less than 100 aldrich and nelson 1984 godfrey and orme 1994 the application of this method will be restricted in areas where sufficient high as samples cannot be collected a common problem for almost all predictive methods an additional potential limitation of widespread application of this predictive method is that conventional hydrochemical data are required which may not always be available overall if conventional hydrochemical data are available the risk predictions of as concentration made by our proposed method can provide reliable guidance for field investigation and sample analysis to minimize potential health impacts acknowledgements this research was financially supported by the national natural science foundation of china nos 41772255 41521001 and 41372254 appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 03 007 appendix a supplementary data supplementary data 1 supplementary data 2 supplementary data 3 
7345,arsenic as contaminated groundwater is a global concern with potential detrimental effects on the health of hundreds of millions of people worldwide however the extent of this problem may be more severe than anticipated as many wells have not been tested and may contain unsafe level of as an optimized statistical regression model was developed to predict the probability of geogenic high as groundwater as 10 μg l in this study easily obtained hydrogeochemical and geological parameters that are significantly related to as geochemical behaviors were selected as explanatory variables in the model the results indicate that ph cl hco3 so4 2 and no3 concentrations stratigraphic information and well depth are excellent predictors of as exposure in the datong basin china predicted unsafe wells correspond well with the known distribution of high as groundwater in the datong basin the successful application of a data set from bangladesh also demonstrated the applicability and credibility of this proposed method keywords groundwater arsenic contamination risk prediction logistic regression model 1 introduction the contamination of groundwater by arsenic as is a global environmental health issue and the long term intake of as can cause various forms of arsenism chen and ahsan 2004 chowdhury et al 2000 nickson et al 1998 in the last decades great efforts have been made to investigate and understand the temporal spatial occurrence of groundwater containing high levels 10 μg l of as around the world especially in south and south east asia chowdhury et al 2000 nickson et al 1998 smith et al 2000 many of wells that may contain high level of as were not yet monitored due to the high cost of the regular monitoring of drinking water wells it follows that drinking water from these wells may trigger as poisoning of local residents therefore it is urgent to develop methods to predict the as concentration or the probability that the as concentration exceeds the safety standard to allow prioritization of monitoring of drinking water wells with higher predicted as concentration or as contamination probability so as to minimize potential health impacts geostatistical interpolation to identify data spatial distribution patterns has been used to predict groundwater as contamination gaus et al 2003 goovaerts et al 2005 roy and hossain 2014 however as indiacted by hossain et al 2007 geostatistical interpolation approaches require a large amount of data to obtain accurate evaluation results which limits the application of this method for areas lacking sufficient groundwater as concentration data statistical regression provides a promising alternative to geostatistical interpolation with this method only a relatively small number of training data are required to establish a predictive model several statistical regression models have previously been built to predict the risk of geogenic groundwater as contamination ahn and cho 2013 amini et al 2008 ayotte et al 2006 rodríguez lado et al 2013 winkel et al 2008 yang et al 2014 in general the sedimentary environment soil properties climate condition geological setting and hydrogeological and geomorphological conditions were selected as explanatory variables to underpin large scale predictions for locations where hydrochemical data are not available however at the resolution of these models adjacent wells may have the same surface parameters but totally different as concentrations mainly due to the heterogeneity of the geochemical and hydrodynamic conditions fendorf et al 2010 polizzotto et al 2008 stute et al 2007 van geen et al 2008 the low resolution makes it difficult to predict groundwater as concentrations at individual wells from surface parameters alone in fact the groundwater as concentration often co varies with the local hydrogeochemical compositions e g fe2 so4 2 due to physical e g pumping and or geochemical e g dissolution of as bearing fes2 processes even though these components are not necessarily directly responsible for the release of as the correlation between selected hydrochemical parameters and as can be used to predict groundwater as concentrations as the hydrochemical composition of groundwater in adjacent wells can differ substantially using hydrochemical parameters to predict as concentration at the single well resolution has the potential to further improve as risk predictions for this reason hydrochemical variables that are relevant to as mobilization mechanisms should be combined into a risk predictive model such models may be established for regions that are uniformly governed by specific as release mechanisms it is widely accepted that the reduction of iron fe oxides oxyhydroxides is one of the main geochemical processes that cause the release of as from the solid phase into groundwater campbell et al 2006 islam et al 2004 oremland and stolz 2003 tufano et al 2008 however pyrite oxidation may also result in the release of as under some conditions jones and pichler 2007 pili et al 2013 rathi et al 2017 in addition desorption processes can cause the mobilization of as in groundwater under certain conditions acharyya et al 2000 tufano et al 2008 competitive adsorption between co existing ions and as can promotethe enrichment of as in groundwater acharyya et al 2000 anawar et al 2004 appelo et al 2002 furthermore recent studies have addressed the pivotal roles of sediment age and well depth on as migration in groundwater mcarthur et al 2010 postma et al 2007 2012 fendorf et al 2010 the objective of this study was to establish a reliable logistic regression model for the prediction of as exposure risk by using conventional hydrochemical and geological parameters as explanatory variables that are relevant to as mobilization logistic regression models were separately established for the datong basin of china and a selected study area of bangladesh bgs and dphe 2001 2 materials and methods 2 1 study area the datong basin fig 1 is an arid semi arid region in northern china the central part of the basin is an alluvial lacustrine plain composed of quaternary unconsolidated sediments with a thickness that is generally 200 m and a maximal thickness of 1000 m high as groundwater is mainly found in the central part of the basin and shallow semi confined aquifer depth 10 50 m is the main aquifer showing elevated as concentrations the groundwater as concentration range from 0 1 to several hundred μg l with as mainly occurring as arsenate in the study area the mobilization of as is clearly related to the reductive dissolution of fe oxides oxyhydroxides and or desorption from fe oxides oxyhydroxides at high ph xie et al 2008 2 2 variable selection the selection of explanatory variables was based on the simplest possible model and formation mechanism of high as groundwater in the datong basin arsenate the predominating as species in groundwaters of the datong basin is easily adsorbed by colloids and minerals with positive charges stollenwerk 2003 the high ph increases the negative charges on these colloids and minerals and adsorption of arsenate is less favorable park et al 2006 smedley and kinniburgh 2002 stollenwerk 2003 high as groundwater often contains high concentrations of bicarbonate hco3 which may result from the microbial oxidation of organic matter coupled to the reduction of fe and or manganese mn oxyhydroxides mcarthur et al 2001 postma et al 2010 román ross et al 2006 xie et al 2013 competitive absorption between as and hco3 may contributes to the release of as from mineral surfaces appelo et al 2002 guo et al 2011 however some experimental results do not support this competition displacement theory meng et al 2000 radu et al 2005 stachowicz et al 2007 in an environment where an organic carbon is available to induce the reductive dissolution of fe oxide oxyhydroxides sulfate so4 2 and nitrate no3 where present are also likely to be consumed by microbial respiration borch et al 2010 massmann et al 2003 sanford et al 2004 in large basins chloride cl concentrations gradually increase in most cases along the groundwater flow direction and groundwaters in the discharge area are characterised by higher cl concentrations adams et al 2001 guo and wang 2004 plummer et al 1990 sikdar et al 2001 sluggish groundwater movement favours the accumulation of as in the central part of the basin guo et al 2014 stute et al 2007 weinman et al 2008 therefore the concentrations of cl and as may show similar trends from the margin areas to the central section of the basin and cl may also serve as an indicator of as concentrations in groundwater in accordance with the discussed mechanisms ph cl hco3 so4 2 and no3 were selected as explanatory variables to represent key hydrochemical characteristics the reactivity and availability of organic carbon utilized as electron donor for the reductive dissolution of as bearing fe oxides oxyhydroxides may be be the overall determinant of the release of as to groundwater postma et al 2012 fendorf et al 2010 rowland et al 2007 younger shallower sediments often show more reactive organic carbon and more rapid release of as harvey et al 2002 horneman et al 2004 papacostas et al 2008 postma et al 2012 however the impact of biogeochemical processes triggered by typically higher reactivity of organic carbon in shallow groundwater on as mobilization may be offset by the often stronger flushing in these aquifers which then results in lower as concentrations in groundwater stute et al 2007 van geen et al 2008 therefore stratigraphic information values 1 2 and 3 were respectively assigned to the holocene pleistocene and other strata to represent increasing age and well depth were also considered as explanatory variables in this predictive model in this study the dependent variable is the binary variable of as concentration based on a threshold of 10 μg l 1 and 0 indicate an as concentration 10 μg l and less than or equal to 10 μg l respectively 2 3 data capture and processing the hydrochemical data used to establish the predictive model for the datong basin were drawn from the previous hydrogeochemical investigations of the datong basin performed by li et al 2012 table s1 supplementary information in this dataset there are about ten times more of both the high as samples and low as samples than the number of explanatory variables godfrey and orme 1994 the validation dataset consisted of published research data xie et al 2013 from the datong basin the map of the strata distribution of the datong basin fig 1 was adapted from the geological map of the shanxi province available from the official website of the china geology survey http www cgs gov cn the logistic regression can be used to analyze a binary dependent variable and explore the relationship between the probability of a response exceeding a threshold value and explanatory variables the model generally takes the following form eqs 1 3 1 logit ln p 1 p b 0 i 1 n b i x i 2 p e logit 1 e logit 3 b i b i s xi s logit r where p is the probability of response variable exceeding a given threshold value b 0 is a constant and bi and bi are the standardized regression coefficient and the non standardized coefficient respectively xi represents the explanatory variables sxi is the standard deviation of the explanatory variable xi s logit is the standard deviation of the computed values of logit r is the correlation coefficient between the predicted and observed values of p i e 0 or 1 and n is the number of explanatory variables the basis of logistic regression is the existence of linear relationships between logit and the explanatory variables hosmer et al 2013 postma et al 2012 any deviation from linearity will result in the deviation of the regression coefficients the method proposed by hosmer et al 2013 can be utilized to reveal the non linearity forms a non linear relationship can be represented as a piecewise function that is composed of two elementary functions and this piecewise function can be expressed as a single expression eq 4 4 f x p x x x 0 q x x x 0 1 2 p x q x 1 2 p x q x x x 0 x x 0 where f x is the piecewise function p x and q x are two elementary functions and x 0 is the piecewise point this single expression can be used to fit a non linear relationship logistic regression also does not require a perfect multicollinearity between explanatory variables hahn 2006 hosmer et al 2013 menard 2001 the extent of multicollinearity can be evaluated by multiple methods such as tolerance tol menard 2001 and the maximum condition index test stewart 1996 the robustness of the regression model is an essential prerequisite to assess relationships between explanatory variables and the response variable therefore a residual analysis is required to identify the points with obvious impact on model robustness cook s distance variation of pearson chi square δχi 2 and deviance residual δdi are the main diagnostic statistics of a logistic regression model menard 2001 points with greater cook s distance δχ2 and δd values are suspected points affecting model robustness logistic regression modeling and all other related calculations were performed using spss statistical software ibm corp released 2013 ibm spss statistics for windows version 22 0 armonk ny ibm corp 3 results 3 1 nonlinear detection the relationships of logit and the explanatory variables other than ph stratigraphy and well depth were nonlinear fig s1 the concentrations of cl hco3 so4 2 and no3 were converted using a fitting formula to ensure a linear relationship between logit and each explanatory variable to simulate the original trends between logit and the explanatory variables after linearization logit was positively correlated with cl and hco3 and negatively correlated with so4 2 and no3 3 2 multicollinearity detection as a general rule a maximum condition index value 30 belsley 1991 and a tol value less than 0 2 menard 2001 indicate high multicollinearity the results indicated that there was not high multicollinearity between independent variables table s3 3 3 regression analysis a backward stepwise likelihood ratio method appelo et al 2002 was used to filter the statistically significant explanatory variables the significance level was set to 0 10 rather than the typical value of 0 05 to prevent the risk of not finding any significant explanatory variable bendel and afifi 1977 the final logistic regression model includes all seven explanatory variables table 1 3 4 robustness detection scatter plots of the diagnostic statistics versus the calculated probabilities were generated show that only three data points have an obvious influence on the fitted values and estimated coefficients of the model fig s2 though these data points appear to be outliers there is no evidence that they are affected by unnatural factors so these points were not excluded from the model development 4 discussion 4 1 interpretation of the regression coefficient as listed in table 1 the concentrations of so4 2 no3 and the stratigraphy were negatively correlated with logit while ph cl hco3 and well depth were positively correlated with logit previous research showed that the holocene strata in the datong basin are generally rich in organic carbon wang et al 2010 xie et al 2013 during organic matter degradation fe can be consumed as electron acceptors leading to dissimilatory reduction of fe oxides oxyhydroxides and the subsequent release of co existing as postma et al 2012 fendorf et al 2010 rowland et al 2007 low concentrations of so4 2 and no3 often characterise a reducing environment that facilitates the dissolution of as bearing fe oxides oxyhydroxides guo et al 2014 xie et al 2013 the positive correlation between logit and ph indicates that a high ph is usually an indicator of as enrichment in groundwater the adsorption of arsenate the predominate as species in groundwater in the datong basin is greatest at low ph and decreases with increasing ph stollenwerk 2003 also the reduction of as bearing fe oxides oxyhydroxides is often associated with an increase in ph hansel et al 2003 mcarthur et al 2004 nickson et al 2000 xie et al 2008 as a result these two processes result in a positive correlation between logit and ph the positive coefficient of hco3 may reflect the oxidation of organic matter that is accompanying the reduction of as bearing fe oxides oxyhydroxides mcarthur et al 2004 nickson et al 2000 or the competitive adsorption between as and hco3 appelo et al 2002 or both processes the positive coefficient of cl indicates a higher risk of groundwater as concentration exceeding the safe level along the groundwater flow close to the discharge area and this pattern has also been found in other high as areas around the world guo et al 2014 stute et al 2007 weinman et al 2008 the positive coefficient for the well depth indicates that within the sampling depth range the probability of high as groundwater increases with increasing depth this result may seem to contradict with the general observation that the groundwater as concentration declines with depth fendorf et al 2010 postma et al 2012 however as shown in fig s3 although as concentrations obviously decrease with increasing depth the fraction of wells with as 10 μg l increases with increasing well depth it is the latter trend that causes the positive coefficient for well depth the standardized regression coefficient b evaluates the importance of each explanatory variable hosmer et al 2013 menard 2001 and a larger absolute value of b implies a greater effect of the explanatory variable on the response variable according to these results the concentration of so4 2 stratigraphy and ph show to be the three most important indicators for the occurrence of geogenic high as groundwater table 1 4 2 probability map and verification of the predictions the p value of the hosmer lemeshow goodness of fit test hl test table s4 statistic was 0 919 suggesting that the model fits quite well with the measured results and the model classification using different probability cutoffs is shown in fig 2 a a probability cutoff of 0 20 was chosen for maximum overall classification resulting in a model with higher sensitivity i e the model s ability to identify high as groundwater and higher specificity i e the model s ability to identify low as groundwater using this cutoff the proportion of total correct classification sensitivity and specificity were 87 8 88 1 and 87 8 respectively table 2 the area under the receiver operating characteristic curve auc table s5 was 0 951 indicating excellent model discrimination to visualize the model predicted distribution and the actual distribution of high as groundwater a predictive continuous probability map fig 3 a based on calculated probability values and an actual continuous probability map fig 3b based on the measured concentration of as of groundwater wells exceeding 10 μg l as in the datong basin were constructed using universal kriging interpolation table s6 and indicator kriging interpolation table s7 respectively the predicted high risk regions probability 0 20 mainly are located in the central basin and northeastern basin a finding that is in good agreement with the measurements a good fit of the logistic regression model does not automatically guarantee a good predictive performance and the ability of the model to be more generally applicable needs to be validated using a test dataset because the described relationship between as and the explanatory variables is only valid for the characteristic reaction mechanism governing as mobilization in the datong basin the applicability of the model is restricted to this area accordingly to test the validity of the model a new dataset xie et al 2013 table s8 was created from previously published data for the datong basin and then was substituted into the final model to calculate the probabilities of as concentration exceeding 10 μg l the test results show that the proportion of total correct classifications false negatives and false positives were 91 4 5 and 4 5 respectively fig 4 a small prediction errors indicate that our modeling method can be used to accurately predict groundwater as levels in the datong basin however if application of the final logistic regression model results in calculated probabilities greater than the probability threshold of 0 20 the as concentrations at the corresponding monitoring locations should be checked to avoid potential health risks 4 3 application of the predictive method to a dataset from bangladesh in bangladesh the holocene alluvial aquifers used for the public water supply contain naturally occurring as which like in the case of china affects the health of tens of millions of people nickson et al 1998 the prediction of high as groundwater in southeast asia including bangladesh was already performed earlier by winkel et al 2008 using spatially continuous data e g sedimentary information and soil maps as explanatory variables application of their model to bangladesh gave the calculated proportion of total correct classification false negative and false positive as 71 13 and 17 respectively table 3 winkel et al 2008 then verified the predicted risk in south sumatra and found that the classification results were comparable to those calculated for bangladesh table 3 furthermore they concluded that the probability maps could be further improved with the inclusion of data with higher spatial resolution or in three dimensions to compare this approach the work of winkel et al 2008 our prediction method was applied in bangladesh to establish a predictive model for groundwater as contamination detailed hydrogeological hydrochemical and sedimentological studies were previously conducted in nawabganj and shibganj bangladesh bgs and dphe 2001 therefore this dataset fig s4 and table s9 including hydrochemical data and related geological information barind clay and residuum alluvial sand and alluvial silt were represented as 1 2 and 3 respectively to ensure a linear relationship between logit and stratigraphy was used to predict groundwater as concentration and to verify the applicability of our prediction approach 90 of the dataset randomly selected was used for model development and the remaining 10 was used for model validation the data were processed identically to the process described above for the data from the datong basin our final predictive model table s10 contains only five variables namely ph b 0 998 stratigraphy b 0 259 hco3 b 0 167 so4 2 b 0 162 and well depth b 0 096 the classification results of the training dataset table 3 hl test 0 202 table s11 and auc value 0 933 table s12 of our model combined with the results of model verification fig 4b and table 3 indicate that our model can reasonably predict geogenic high as groundwater contamination in nawabganj and shibganj bangladesh and that our proposed method is applicable 5 conclusion to predict the probability of groundwater as concentration exceeding human health benchmarks logistic regression models were established for the datong basin before applying them to a selected study area in bangladesh the accuracies of the model predictions for the datong basin and for bangladesh were 91 0 and 82 9 respectively which verified the reliability of our new modeling approach regression analysis is a causality based prediction method that can help to establish the cause of a particular effect which is a crucial step to successful prediction of the effect the enrichment of as in groundwater is the consequence of water rock interactions using simple and targeted hydrochemical and geological datas as indicators of water rock interactions relevant to as mobilization may be an effective way to predict as levels in groundwater as demonstrated in the preceding sections the hydrochemical and geological indicators can be used as explanatory variables to establish a reliable predictive model and the variation of as concentrations between adjacent wells can be identified therefore an important implication is that our proposed method can predict the risk of high as exposure at single well resolution however the predictive model based on limited number of explanatory variables and training data can express most but not all the variability in as concentrations in a region thus the accuracy of the predictions is very high but some residual discrepancies exist this stems from the fact that the relationships between as and the explanatory variables differ for different types of groundwater that means this method can be reliably used to predict as levels in groundwater within specific regions that are characterised by the same hydrogeochemical mechanisms governing as accumulation in groundwater in practice samples collected from known endemic as poisoning areas in an area can be utilized to establish a predictive model that can be applied to search for other undiscovered locations of high as groundwater in this area or in other areas with similar hydrogeological and hydrogeochemical conditions though the number of high as samples required for modeling is generally much less than 100 aldrich and nelson 1984 godfrey and orme 1994 the application of this method will be restricted in areas where sufficient high as samples cannot be collected a common problem for almost all predictive methods an additional potential limitation of widespread application of this predictive method is that conventional hydrochemical data are required which may not always be available overall if conventional hydrochemical data are available the risk predictions of as concentration made by our proposed method can provide reliable guidance for field investigation and sample analysis to minimize potential health impacts acknowledgements this research was financially supported by the national natural science foundation of china nos 41772255 41521001 and 41372254 appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 03 007 appendix a supplementary data supplementary data 1 supplementary data 2 supplementary data 3 
7346,bias correction is usually implemented prior to using climate model outputs for impact studies however bias correction methods that are commonly used treat climate variables independently and often ignore inter variable dependencies the effects of ignoring such dependencies on impact studies need to be investigated this study aims to assess the impacts of correcting the inter variable correlation of climate model outputs on hydrological modeling to this end a joint bias correction jbc method which corrects the joint distribution of two variables as a whole is compared with an independent bias correction ibc method this is considered in terms of correcting simulations of precipitation and temperature from 26 climate models for hydrological modeling over 12 watersheds located in various climate regimes the results show that the simulated precipitation and temperature are considerably biased not only in the individual distributions but also in their correlations which in turn result in biased hydrological simulations in addition to reducing the biases of the individual characteristics of precipitation and temperature the jbc method can also reduce the bias in precipitation temperature p t correlations in terms of hydrological modeling the jbc method performs significantly better than the ibc method for 11 out of the 12 watersheds over the calibration period for the validation period the advantages of the jbc method are greatly reduced as the performance becomes dependent on the watershed gcm and hydrological metric considered for arid tropical and snowfall rainfall mixed watersheds jbc performs better than ibc for snowfall or rainfall dominated watersheds however the two methods behave similarly with ibc performing somewhat better than jbc overall the results emphasize the advantages of correcting the p t correlation when using climate model simulated precipitation and temperature to assess the impact of climate change on watershed hydrology however a thorough validation and a comparison with other methods are recommended before using the jbc method since it may perform worse than the ibc method for some cases due to bias nonstationarity of climate model outputs keywords climate change impacts bias correction inter variable correlation climate model hydrology 1 introduction the outputs of general circulation models gcms have commonly been used to assess the impacts of climate change e g wilby and harris 2006 sharma et al 2007 minville et al 2008 chen et al 2011a b however outputs from state of the art climate models are usually too biased to be used as direct inputs to impact models climate model output bias is reflected in multiple aspects such as the mean standard deviation and inter variable correlation to address this issue in part several bias correction methods have been developed to correct the critical characteristics of climate model outputs e g mean standard deviation in particular the distribution mapping methods have been found to be better than the mean based methods for both climate simulation and hydrological modeling teutschbein and seibert 2012 2013 chen et al 2013a bias correction methods were initially developed to correct biases of rcms but they are now widely used for gcms e g li et al 2014 cannon 2016 chen et al 2016 2017 without a downscaling step in such cases the bias correction accounts for the gcm biases and the difference between the gcm and local scales however the commonly used bias correction methods correct climate variables independently in other words the interactions among climate variables are not specifically corrected as a result independent bias correction can produce non physical corrections and may fail to capture critical multivariate relationships the misrepresented inter variable correlations may lead to biased results in climate change impacts in a likely scenario the lack of inherent correlations between precipitation and temperature could result in biased hydrological simulations buishand and brandsma 2001 maurer et al 2010 mueller and seneviratne 2014 immerzeel et al 2014 this is not surprising because the precipitation temperature p t correlations may affect evapotranspiration snowmelt and possibly runoff generation li et al 2014 even though biases in the inter variable correlations of climate model outputs have been pointed out by several studies only a few of them have corrected correlation bias prior to use in climate change impact studies for example thrasher et al 2012 applied a quantile mapping method for correcting daily maximum and minimum temperatures this method first corrects both the maximum or minimum temperature and the diurnal temperature range and then calculates the minimum or maximum temperature by subtracting or adding the corrected diurnal range however this approach is not suitable for climate variables such as precipitation and temperature which do not have deterministic relationships in addition piani and haerter 2012 proposed a two dimensional bias correction method for correcting p t correlation through the following three steps 1 correct the temperature 2 group precipitation and temperature pairs into a number of bins and 3 correct the precipitation within each temperature bin since the p t correlation was not specifically considered the benefits of this method could not be determined by assessing the p t correlation coefficients li et al 2014 also proposed a method for specifically correcting the joint distribution of gcm simulated precipitation and temperature this method can be seen as a bivariate extension of the commonly used univariate distribution mapping method and has been found to be satisfactory in reducing the bias of gcm simulated p t correlation fields cannon et al 2015 gennaretti et al 2015 more recently vrac and friederichs 2015 and cannon 2016 also proposed multivariate methods to correct climate model outputs for example vrac and friederichs 2015 proposed a copula based bias correction method combining univariate bias correction with a shuffling method reproducing the empirical multivariate copula cannon 2016 proposed a multivariate analog of the quantile mapping method for correcting the correlation dependence structure of climate variables one of the ultimate goals of using bias corrected climate simulations is to assess the climate change impacts for example on hydrology while it may appear reasonable to conclude that limited benefits will be translated to the hydrological variables small changes in p and t can sometimes results in much larger changes once the non linear rainfall runoff filter has been applied since most hydrological climate change impact studies have not taken into consideration the inter variable dependence the potential impacts of this omission should be studied there are currently no study that investigates the advantages of using multivariate bias correction for hydrological climate change impact studies if the benefits of multivariate method are translated to hydrological variables are they consistent across watersheds climate zones or hydrological metrics accordingly this paper aims at answering these questions by evaluating the effect of simultaneously correcting multiple variables including precipitation and temperature on hydrological modeling to this end we first correct the simulated precipitation and temperature simultaneously using the joint bias correction jbc method of li et al 2014 since the jbc method can be considered as a bivariate extension of the commonly used univariate distribution mapping method it is feasible to compare the independent distribution mapping method in terms of hydrological modeling we then compare the impacts of jbc on hydrological modeling over 12 watersheds covering various climate conditions with those of the commonly used distribution mapping method which corrects precipitation and temperature independently since both methods only differ in correcting inter variable correlations any difference in hydrological simulations can be directly attributed to inter variable correlation 2 study area and data 2 1 study area this study was conducted over 12 watersheds located in four countries across the globe table 1 ten of the watersheds located in the united states seven and canada three were also used in a previous study by chen et al 2013a for assessing the performance of various bias correction methods these ten watersheds were selected from different climate zones and topographic conditions in terms of climate conditions the 10 watersheds can be classified into five snowfall dominated manic 5 1 carrot 2 nation 3 yampa 9 and yellowstone 10 three rainfall dominated chickasawhay 4 grand 5 and umpqua 7 and two rainfall snowfall mixed sacandaga 6 and wolf 8 watersheds although the three watersheds in canada manic 5 carrot and nation are all snow dominated they have very different annual precipitation and temperature rates manic 5 is the coldest watershed with abundant precipitation while carrot and nation are located in arid regions three of the united states watersheds umpqua yampa and yellowstone are located in westerly mountainous areas and the other four chickasawhay grand sacandaga and wolf in the centrally and easterly flatter terrain the hydrological regime of the umpqua can be divided into contrasting wet and dry seasons two watersheds xiangjiang 11 and oueme 12 with different climates subtropical monsoon and tropical were also selected from china and benin respectively the xiangjiang watershed located in the central south region of china is a large sub basin of the yangtze river watershed it has a subtropical monsoon climate and a mean annual precipitation of about 1570 mm most of the precipitation occurs between april and june resulting in high flows over this period while little occurs in the winter which is defined as a low flow period the oueme watershed located in the republic of benin west africa is characterized by two different climates a subequatorial climate to the south and a sudanian climate to the north the temperature is high all the year round and so there is no snow occurring in the winter heavy rainfall mainly occurs between april and october accounts for 92 with minimal amounts during the other months 2 2 data the observed meteorological data daily precipitation and temperature for the three canadian watersheds studied were drawn from the hutchinson et al 2009 gridded dataset which was obtained by interpolating station data to a 10 km grid using a thin plate smoothing spline surface fitting method for the seven watersheds in the united states the 5 km santa clara dataset was used maurer et al 2002 livneh et al 2013 to run a lumped hydrological model as will be introduced section 3 b all grid points within the watersheds were averaged to one for both the precipitation and temperature time series the gauge measured precipitation and temperature time series were used for the xiangjiang and oueme watersheds the mean precipitation and temperature of the xiangjiang watershed were obtained by averaging the precipitation and temperature over 100 rain gauges and 8 temperature gauges within or surrounding the watershed respectively based on weights calculated using the thiessen polygon method rhynsburger 1973 the same averaging method was also used for the oueme watershed based on 18 rain gauges and 3 temperature gauges discharge data for manic 5 1 were provided by hydro québec drawn from mass balance calculations at the dam for the other two canadian watersheds carrot 2 and nation 3 they were obtained from environment canada the discharge data for the united states watersheds were obtained from the model parameter estimation experiment mopex database duan et al 2006 discharge data for xiangjiang and oueme were respectively obtained from the department of water resource of hunan province china and direction générale de l eau dg eau benin the climate model simulations were taken from the coupled model intercomparison project phase 5 cmip5 database twenty six gcms id 1 26 in table 2 from 16 modeling centres were selected to adequately represent the climate model uncertainty table 2 depending on their surface areas some watersheds may include only one or even no gcm grid box to obtain the mean watershed precipitation and temperature data from several gcm grids more than four depending on the size of the watersheds within or surrounding the watersheds were averaged using the thiessen polygon method the dataset covers the period of 1975 2004 for the xiangjiang watershed and of 1961 2000 for the other 11 watersheds the first half of each period was used to calibrate the bias correction methods and the second half for validation 3 methodology 3 1 bias correction methods the jbc method of li et al 2014 was used to jointly correct precipitation and temperature simulated by 26 gcms since the original jbc method was developed for bivariate correction only daily precipitation and mean temperature were considered the daily mean temperature was obtained by averaging the daily maximum and minimum temperatures for both observed and gcm simulated data a previous study by chen and brissette 2015 showed that daily mean temperature estimated using this method is as good as that estimated by averaging hourly temperature 24 values per day to investigate the benefits of the joint correction of precipitation and temperature on hydrological modeling the results obtained from jbc were compared with those obtained from an independent bias correction ibc method prior to using jbc and ibc methods the wet day frequency of gcm simulated precipitation was corrected using the local intensity scaling loci method of schmidli et al 2006 with the loci method a wet day threshold was first determined using the gcm daily precipitation time series for each month such that the threshold exceedance matched the wet day frequency of the observed time series for the calibration period this threshold was then used to correct the wet day frequency of gcm simulated precipitation for the validation period this threshold value varies from one gcm to the other and ranged between 0 and 6 6 mm after the wet day frequency correction precipitation amounts were respectively corrected using the ibc and jbc methods the ibc method used in this study is a distribution mapping method with a gamma distribution modeling precipitation and gaussian distribution for temperature this method has been used in several other studies e g chen et al 2013a b ines and hansen 2006 piani et al 2010 to produce climate simulation for hydrological modeling and climate change impact studies the jbc method is a bivariate extension of the ibc method and it is only briefly described here more details can be found in li et al 2014 when using the jbc method a joint cumulative distribution function cdf must first be built for precipitation and temperature the gamma and gaussian distributions are used to model the marginal distributions of precipitation and temperature respectively with the joint cdf the marginal and conditional distributions are then derived which are then used to sequentially correct the precipitation and temperature jbc can be performed by first correcting either the precipitation or the temperature in this study we start by correcting the precipitation and then go on to the temperature both ibc and jbc were conducted at the monthly basis 3 2 hydrology modeling the hydrological modeling was carried out using a lumped conceptual rainfall runoff model hmets developed by école de technologie supérieure the model structure is detailed in martel et al 2017 the hmets source code interface and user guide are freely available on the mathworks file exchange site hmets has been used in several flow forecasting and climate change impact studies e g chen et al 2011b essou and brissette 2013 arsenault et al 2015 2017 arsenault and brissette 2016 the model has up to 21 free parameters one for evapotranspiration ten for snow accumulation and snowmelt four for vertical water balance and six for horizontal water movement information about each parameter is presented in table 3 the calculation of potential evapotranspiration pet follows the work of oudin et al 2005 a constant parameter is used during optimization to adjust pet to a specific watershed actual evapotranspiration depends on water present in the vadose zone reservoir of the hydrological model the snowmelt model is based on the work of vehvilainen 1992 which is a degree day model that allows for melting and refreezing process within the snowpack the model works in three steps including the overnight refreezing process snowmelt and snowpack water retention capacity the vertical water balance takes into account all the exchanges made between the surface vadose and saturated zones depending on the water level in the vadose zone reservoir available surface water is partitioned between runoff and infiltration once the actual evapotranspiration has been taken out the saturated zone is represented by a linear reservoir releasing groundwater flow outlet streamflow is calculated based on four horizontal transfer components for surface and delayed runoff two unit hydrographs based on the two parameter gamma distribution density function are used to transfer water at the outlet total outlet streamflow is ultimately computed by summing up all four horizontal flow components for purely rainfall driven watersheds e g oueme 12 the hmets snow module was not used and the model reverted to its 11 parameter version model calibration was done automatically using the covariance matrix adaptation evolution strategy cmaes hansen and ostermeier 1996 2001 which was shown to be most efficient for this type of optimization class arsenault et al 2013 hmets requires the daily mean temperature and precipitation as inputs if the maximum and minimum temperatures are input to the model they are automatically averaged to the mean temperature a natural flow or discharge time series is also needed for model calibration and validation hmets structure is fairly typical of this class of hydrological models the use of a lumped conceptual model was based upon several considerations even though distributed hydrological models do have advantages in studying the spatial variability of hydrological response to climate and land use changes when the goal is streamflow simulation prediction at watershed outlets lumped models have been shown to be just as good as their more complex distributed counterparts in several inter comparison studies e g reed et al 2004 smith et al 2012 streamflow generation at a watershed outlet is the result of various spatially integrated processes and this explains why lumped model excel at this task and can do very well on very large watersheds the observed precipitation temperature and discharge were used to calibrate and validate hmets for all 12 watersheds to ensure a robust calibration both the calibration and validation periods were longer than 10 years for all the watersheds the optimal combination of parameters was chosen based on the nash sutcliffe coefficient nse nash and sutcliffe 1970 the chosen set of parameters yielded nse values ranging between 0 766 grand and 0 924 xiangjiang for calibration and between 0 724 carrot and 0 892 chickasawhay for validation across all 12 watersheds indicating the good performance of hmets for these watersheds table 4 and the suitability of using a lumped model for this study the observed and simulated mean hydrographs presented in fig 1 also outline the good performance of hmets for these watersheds 3 3 data analysis this study first evaluated the performance of both bias correction methods ibc and jbc in correcting gcm simulated precipitation and temperature and then for hydrological modeling the corrected results from both methods were each compared to the other as well as with the raw gcm outputs in order to show the benefits of bias correction since the performance of distribution mapping methods in terms of correcting individual variables has been thoroughly evaluated in several studies e g piani et al 2010 teutschbein and seibert 2012 chen et al 2013a li et al 2014 this study only compares the performance of these two methods in terms of correcting p t correlation the absolute error ae was calculated for the p t correlation coefficient for raw and corrected data the difference between raw corrected gcm and observed correlation coefficient since precipitation and temperature may not necessarily be linearly correlated the kendall s tau coefficient kendall 1970 was used in this study to investigate the impacts of the jbc method on hydrological modeling the raw and bias corrected simulations of precipitation and temperature were used to drive hmets for hydrological simulations over both the calibration and validation periods discharges simulated using ibc and jbc corrected simulations were compared with those simulated using observations according to 46 evaluation metrics table 5 these evaluation metrics capture the mean 13 metrics standard deviation 13 metrics and distribution 11 metrics characteristics of the observed hydrology the other 9 of the 46 metrics represent the timing variables e g time to peak discharge annual maximum flood and time to the beginning and to the end of annual maximum flood and the frequency of high and low flows 10 year 20 year and 50 year return periods of high flow 0 95 quantile and low flow 0 05 quantile time to the beginning and to the end of flood are determined based on a cumulative annual hydrograph chen et al 2011b four breakpoints in the cumulative annual hydrograph are fitted and connected by straight lines minimizing the root mean square error with the cumulative annual hydrograph the time to the first breakpoint is defined as the beginning of flood and the time to the second is defined as the end of flood to obtain the return periods the annual high and low flows are modeled using the log pearson type iii distribution usgs 1982 the time periods used to calculate the high and low flows are watershed dependent as presented in table 4 the performance of the ibc and jbc methods with respect to reproducing climate simulations for hydrological modeling was evaluated with the following three steps 1 the re was first calculated for all 46 metrics and two bias correction methods 2 the absolute value of the relative error are was then calculated for all metrics and both bias correction methods the relative error re was calculated for hydrological metrics as the difference between raw corrected and observed data simulated values divided by the observed data simulated values and 3 the difference in are dare over two bias correction methods was calculated at the last step using eq 1 1 d are m ibc m obs m obs m jbc m obs m obs where m represents a hydrological metric mibc mobs mobs and mjbc mobs mobs are res of each hydrological metric simulated by ibc and jbc corrected simulations respectively to avoid biases resulting from the hydrological modeling process the observed streamflow time series is represented by modeled discharge using observed precipitation and temperature rather than the gauged observation the dare values were presented using portrait diagrams following the work of gleckler et al 2008 the paired t test was used to test the equality of the are of the ibc and jbc methods for all 46 metrics 46 pairs a right tailed paired t test was first applied at a significance level of 5 if the p value of the paired t test was 0 05 the jbc method is significantly better than the ibc method in contrast if the p value is greater than 0 05 the performance of the jbc method is not statistically better than the ibc method to test if the ibc method is better than the jbc method a left tailed paired t test was further applied at the p 0 05 level if ibc is not statistically better than jbc both methods are then considered as statistically identical in addition the mean absolute relative error mare was calculated by averaging 26 gcms 46 metrics ares across all 26 gcms and across all 46 hydrological metrics for both ibc and jbc corrected simulations over the calibration and validation periods the relative difference of mare rd mare between ibc and jbc corrected simulations was then calculated a positive rd mare implies that the jbc method performs better than the ibc method and vice versa averaging ares across gcms reflects the overall performance of both bias correction methods in terms of hydrological metrics while averaging ares across all 46 metrics outlines the overall performance of both bias correction methods in terms of gcms 4 results 4 1 precipitation and temperature correlation the ae of the p t correlation coefficients of raw and ibc and jbc corrected data are calculated for all 26 gcms and 12 watersheds over both the calibration and validation periods results of two typical months july and november are presented in fig 2 for illustration the results show that all gcms are considerably biased in preserving the observed p t correlation however the sign and magnitude of biases are dependent on multiple factors watershed location gcm and month for example the p t correlations for the three canadian watersheds are overestimated by most gcms in both july and november however they are underestimated for other watersheds in july the ibc method correcting precipitation and temperature distributions independently retain the p t dependencies of gcms the correlation coefficient is almost identical to that in raw gcm simulations the jbc method performs reasonably well in reducing the bias of gcm p t correlations for all months and watersheds over the calibration period however its performance in the validation period is monthly dependent for example the p t correlation biases are considerably reduced for july but not for november results for other months range somewhere between july and november 4 2 hydrological modeling the raw and bias corrected daily precipitation and temperature time series were used as inputs of hmets to simulate streamflows over all 12 watersheds figs 3 and 4 respectively present the mean hydrographs of all the watersheds over the calibration and validation periods all gcms results without raw and with bias correction ibc and jbc are shown as envelopes and hydrographs simulated by canesm2 simulations are presented as a typical example the mean hydrographs simulated by the observed precipitation and temperature are also presented for comparison figs 3 and 4 show that the mean hydrographs are poorly represented by raw gcm simulations as shown by the wide envelope in particular the annual cycle of streamflows simulated by canesm2 simulations cannot be captured for the yampa 9 and yellowstone 10 watersheds both the ibc and jbc methods are capable of reducing the biases of gcm simulations and better representing the mean hydrograph over both the calibration and validation periods however when all simulations are plotted together the difference between the ibc and jbc methods is difficult to notice even though a slight advantage of the jbc method can be observed in some cases e g sacandaga 6 and oueme 12 watersheds in other words both bias correction methods perform similarly with respect to reproducing mean hydrological conditions as represented by the mean annual hydrograph in order to investigate the impacts of correcting gcm p t correlation on hydrological modeling in greater detail the ibc and jbc methods were further compared with respect to reproducing 46 hydrological metrics figs 5 and 6 present the portrait diagrams of the dare of 46 metrics for the calibration and validation periods respectively the warm color red in the portrait diagrams indicates that the ibc method performs better than the jbc method while the cool color blue indicates that the jbc method is better overall the jbc method performs better than the ibc method for most watersheds and gcms over the calibration period as illustrated by the fact that there are more blue than red indications in fig 5 the paired t test shows that the jbc method performs significantly better than the ibc method for 11 out of the 12 watersheds at the 5 significance level table 6 indicating the importance of correcting the p t correlation of gcm simulations in hydrological impact studies table 6 however for the manic 5 watershed both methods perform similarly for the validation period the portrait diagram mixes blue and red colors fig 6 over the validation period it is hard to identify the advantage of one method over the other the paired t test shows that the jbc method performs significantly better than the ibc method for 6 out of the 12 watersheds at the 5 level however both methods show similar performance for 3 watersheds and ibc performs significantly better than jbc for 3 watersheds the performance of both methods is also compared using mare as a criterion figs 7 and 8 show the rd mare between the ibc and jbc methods in terms of 26 gcms over the calibration and validation periods in line with results presented in fig 5 the rd mare shows that the jbc method consistently performs better than the ibc method for most gcms over the calibration period this applies to all watersheds with the exception of manic 5 1 in particular the jbc method performs better for all gcms over the carrot watershed 2 for the validation period the jbc method performs better than the ibc method for 6 out of 12 watersheds for these 6 watersheds the jbc method performs better for most gcms but not all over the 3 watersheds where both methods perform similarly 1 5 and 11 relative performance depends on the gcm for the remaining 3 watersheds the ibc methods performs better for most gcms reasons of these behaviors will be discussed later performance is also dependent on the choice of hydrological metric figs 9 and 10 show that the performance of the jbc method depends on hydrological metrics overall the jbc method consistently performs better than the ibc method for most metrics for 10 out of 12 watersheds over the calibration period for the manic 5 watershed 1 the jbc method performs worse for mean and standard deviation of winter discharge as well as some metrics about extreme flows however it performs better for other metrics this is not surprising as precipitation accumulates as snow over the winter and consequently correlation between precipitation and temperature is less relevant to streamflow generation for the oueme watershed 12 the jbc method performs better for wet season metrics but worse for dry season metrics indicating that complex methods may be detrimental in such cases for the validation period differences between both methods are small with the exception of the nation and oueme watersheds the jbc method is clearly better over 3 watersheds 3 6 and 12 while the ibc method is better over watersheds 4 9 and 10 5 discussion and conclusion bias correction methods applied to climate model outputs usually act on each climate variable separately thus there are concerns regarding whether inter variable dependencies of climate model outputs are distorted and whether the bias of inter variable dependencies affects the reliable assessment of climate change impacts in this study the impacts of correcting the p t correlations of gcm simulations on hydrological modeling were investigated specifically the performance of a jbc method was compared with the commonly used ibc method in terms of hydrological modeling over 12 watersheds located in various climate regimes the results show that gcms are considerably biased in terms of modeling p t dependencies even though the ibc method largely improves the simulation of individual variables simulated by gcms the inter variable dependencies are mostly retained similar results were also obtained in other studies e g wilcke et al 2013 li et al 2014 the jbc method performs reasonably well in reducing the biases of the gcm simulated p t correlation for the calibration period however for the validation period its performance is monthly dependent for example the p t correlation bias is considerably reduced in july but not so much in november the different performance of jbc between the calibration and validation periods is mostly due to the fact that the biases of the gcm p t correlation are not constant in time more on this below all bias correction methods are based on an assumption that climate model biases are stationary over time hewitson and crane 2006 piani et al 2010 maraun 2012 maurer et al 2013 chen et al 2015 however this is not necessarily so in practice even over two adjacent time periods due to the natural climate variability chen et al 2015 if the stationary assumption is not verified there is little hope that a bias correction method can work equally well over calibration and validation periods in terms of hydrological modeling the jbc method performs significantly better than the ibc method for 11 out of the 12 watersheds over the calibration period this highlights the importance of correcting the inter variable dependencies of gcms in hydrological modeling for the coldest snowfall dominated watershed manic 5 1 the advantage of jbc is not evident this is as expected because the water availability of this northern watershed is dominated by snowfall in the winter as about 45 precipitation occurs as snow evaporation which is determined by temperature is not important for this watershed as the temperature is relative low all the year round the temperature mainly affects the snow melt time in the spring in other words the hydrology of the northern watershed may not be sensitive to the p t dependencies especially when taking into account the fact that the bias of the gcm p t correlation is relatively small for this watershed unlike for the calibration period the jbc method does not perform consistently better than the ibc method for the validation period in particular it performs significantly better or comparably to the ibc method for 9 out of the 12 watersheds but exhibit worse performance over the other 3 watersheds the 6 watersheds where the jbc method exhibit advantage can be classified into two groups arid or tropical watersheds carrot 2 nation 3 and oueme 12 and snowfall rainfall mixed watersheds sacandaga 6 and wolf 8 for arid or tropical watersheds the evaporation determined by temperature represents a considerable amount of water loss and precipitation determines the available water that can be evaporated thus the relationship between precipitation and temperature is tight the tropical oueme 12 watershed is a good example over which the jbc method performs much better than the ibc method for most hydrological metrics even though the umpqua watershed cannot be labeled as having an arid climate its hydrological regimes nonetheless displays contrasting dry and wet seasons the use of jbc is also important for snowfall rainfall mixed watersheds as the temperature determines the proportion of precipitation that occurs as rain or snow as well as the proportion of snow to melt li et al 2014 however for snowfall dominated watersheds manic 5 1 yampa 9 and yellowstone 10 the advantage of the jbc method is not obvious as mentioned earlier this is because the temperature is very low for these watersheds in the winter and a slight fluctuation in temperature would likely have little effect on snowmelt and evapotranspiration similarly the advantage of the jbc method is also not significant for rainfall dominated watersheds grand 5 xiangjiang 11 and chickasawhay 4 due to the unsynchronized wet and heat seasons besides the reasons mentioned above the bias nonstationarity of gcm simulations may ultimately be the main culprit because of the nonstationary p t correlations partly arisen from natural climate variability the jbc method may have little advantage over the ibc method in terms of correcting the gcm p t correlation and may even induce additional biases for some months e g november this is especially true for the three watersheds where the ibc method performs better than its counterpart for hydrological simulations to understand these results more clearly the assumption of bias stationarity in p t correlations is verified for the yampa 9 and yellowstone 10 watersheds fig 11 presents the difference in biases between the validation and calibration periods validation calibration for the monthly p t correlations for all 26 gcms the observed monthly p t correlations for all 12 watersheds are also presented for comparison fig 12 the bias is defined as the difference in monthly p t correlation between observations and gcm time series the difference in bias is equivalent to the future bias remaining after a bias correction based on the calibration period has been performed the results show that the bias of p t correlations is clearly not stationary for these two watersheds especially when taking into account the fact that the difference in bias between the calibration and validation periods is greater than the observed p t correlations lines 9 and 10 in fig 12 due to the bias nonstationarity of the biases the jbc method deteriorates the original p t correlations simulated by gcms this explains why the ibc method performs significantly better than the jbc method for 3 out of 12 watersheds increasing the length of the calibration period so as to more comprehensively sample the natural climate variability may be able to improve the jbc performance to some extent in addition even though all gcms are capable of appropriately simulating the climate at the global scale their performance vary at the regional and watershed scales thus potentially explaining some of the differences the observed p t correlation may be another factor which affects the performance of the jbc method as presented in fig 12 correlations can be positive and negative or even absent depending on the month if the observed correlation is very small a slight perturbation may result in large biases in p t corrections especially when the bias of p t corrections is not stationary this may be why the jbc method can deteriorate the original p t correlations in some cases overall this study emphasizes the importance of correcting the inter variable dependencies of gcm simulations when using them for hydrological climate change impact studies the jbc method is able to achieve this goal depending on hydrological simulations the performance of the jbc method varies across watershed locations and hydrological metrics the method may perform better than the ibc method for one hydrological metric but may not for the other this study only looked at the overall impacts of jbc using 46 hydrological metrics for example the paired t test was conducted based on 46 pairs of hydrological metrics a careful validation should always be performed for specific impact studies for example the impact of the jbc method on streamflow for specific seasons in addition the hydrological simulation carried out in the study was based on only one hydrological model while the uncertainty of hydrological models was not considered however previous studies e g wilby and harris 2006 chen et al 2011a have shown that the uncertainty due to hydrological models is much less important than that related to climate models therefore it is unlikely that the conclusions drawn from this paper would change when using other hydrological models finally this study only investigates the impact of jbc on hydrological modeling the advantage of jbc may be more significant for other impact studies such as those relating to agriculture as the concurrent changes in precipitation and temperature are of greater interest than independent projections of each variable tebaldi and lobell 2008 acknowledgements this work was partially supported by the national natural science foundation of china grant no 51779176 51539009 51339004 the thousand youth talents plan from the organization department of ccp central committee wuhan university china the natural science and engineering research council of canada nserc hydro québec and the ouranos consortium on regional climatology and adaption to climate change chao li was also supported by the national science foundation under grant 1313897 the authors would like to acknowledge the contribution of the world climate research program working group on coupled modelling and all climate modeling groups listed in table 2 for making available their respective model outputs 
7346,bias correction is usually implemented prior to using climate model outputs for impact studies however bias correction methods that are commonly used treat climate variables independently and often ignore inter variable dependencies the effects of ignoring such dependencies on impact studies need to be investigated this study aims to assess the impacts of correcting the inter variable correlation of climate model outputs on hydrological modeling to this end a joint bias correction jbc method which corrects the joint distribution of two variables as a whole is compared with an independent bias correction ibc method this is considered in terms of correcting simulations of precipitation and temperature from 26 climate models for hydrological modeling over 12 watersheds located in various climate regimes the results show that the simulated precipitation and temperature are considerably biased not only in the individual distributions but also in their correlations which in turn result in biased hydrological simulations in addition to reducing the biases of the individual characteristics of precipitation and temperature the jbc method can also reduce the bias in precipitation temperature p t correlations in terms of hydrological modeling the jbc method performs significantly better than the ibc method for 11 out of the 12 watersheds over the calibration period for the validation period the advantages of the jbc method are greatly reduced as the performance becomes dependent on the watershed gcm and hydrological metric considered for arid tropical and snowfall rainfall mixed watersheds jbc performs better than ibc for snowfall or rainfall dominated watersheds however the two methods behave similarly with ibc performing somewhat better than jbc overall the results emphasize the advantages of correcting the p t correlation when using climate model simulated precipitation and temperature to assess the impact of climate change on watershed hydrology however a thorough validation and a comparison with other methods are recommended before using the jbc method since it may perform worse than the ibc method for some cases due to bias nonstationarity of climate model outputs keywords climate change impacts bias correction inter variable correlation climate model hydrology 1 introduction the outputs of general circulation models gcms have commonly been used to assess the impacts of climate change e g wilby and harris 2006 sharma et al 2007 minville et al 2008 chen et al 2011a b however outputs from state of the art climate models are usually too biased to be used as direct inputs to impact models climate model output bias is reflected in multiple aspects such as the mean standard deviation and inter variable correlation to address this issue in part several bias correction methods have been developed to correct the critical characteristics of climate model outputs e g mean standard deviation in particular the distribution mapping methods have been found to be better than the mean based methods for both climate simulation and hydrological modeling teutschbein and seibert 2012 2013 chen et al 2013a bias correction methods were initially developed to correct biases of rcms but they are now widely used for gcms e g li et al 2014 cannon 2016 chen et al 2016 2017 without a downscaling step in such cases the bias correction accounts for the gcm biases and the difference between the gcm and local scales however the commonly used bias correction methods correct climate variables independently in other words the interactions among climate variables are not specifically corrected as a result independent bias correction can produce non physical corrections and may fail to capture critical multivariate relationships the misrepresented inter variable correlations may lead to biased results in climate change impacts in a likely scenario the lack of inherent correlations between precipitation and temperature could result in biased hydrological simulations buishand and brandsma 2001 maurer et al 2010 mueller and seneviratne 2014 immerzeel et al 2014 this is not surprising because the precipitation temperature p t correlations may affect evapotranspiration snowmelt and possibly runoff generation li et al 2014 even though biases in the inter variable correlations of climate model outputs have been pointed out by several studies only a few of them have corrected correlation bias prior to use in climate change impact studies for example thrasher et al 2012 applied a quantile mapping method for correcting daily maximum and minimum temperatures this method first corrects both the maximum or minimum temperature and the diurnal temperature range and then calculates the minimum or maximum temperature by subtracting or adding the corrected diurnal range however this approach is not suitable for climate variables such as precipitation and temperature which do not have deterministic relationships in addition piani and haerter 2012 proposed a two dimensional bias correction method for correcting p t correlation through the following three steps 1 correct the temperature 2 group precipitation and temperature pairs into a number of bins and 3 correct the precipitation within each temperature bin since the p t correlation was not specifically considered the benefits of this method could not be determined by assessing the p t correlation coefficients li et al 2014 also proposed a method for specifically correcting the joint distribution of gcm simulated precipitation and temperature this method can be seen as a bivariate extension of the commonly used univariate distribution mapping method and has been found to be satisfactory in reducing the bias of gcm simulated p t correlation fields cannon et al 2015 gennaretti et al 2015 more recently vrac and friederichs 2015 and cannon 2016 also proposed multivariate methods to correct climate model outputs for example vrac and friederichs 2015 proposed a copula based bias correction method combining univariate bias correction with a shuffling method reproducing the empirical multivariate copula cannon 2016 proposed a multivariate analog of the quantile mapping method for correcting the correlation dependence structure of climate variables one of the ultimate goals of using bias corrected climate simulations is to assess the climate change impacts for example on hydrology while it may appear reasonable to conclude that limited benefits will be translated to the hydrological variables small changes in p and t can sometimes results in much larger changes once the non linear rainfall runoff filter has been applied since most hydrological climate change impact studies have not taken into consideration the inter variable dependence the potential impacts of this omission should be studied there are currently no study that investigates the advantages of using multivariate bias correction for hydrological climate change impact studies if the benefits of multivariate method are translated to hydrological variables are they consistent across watersheds climate zones or hydrological metrics accordingly this paper aims at answering these questions by evaluating the effect of simultaneously correcting multiple variables including precipitation and temperature on hydrological modeling to this end we first correct the simulated precipitation and temperature simultaneously using the joint bias correction jbc method of li et al 2014 since the jbc method can be considered as a bivariate extension of the commonly used univariate distribution mapping method it is feasible to compare the independent distribution mapping method in terms of hydrological modeling we then compare the impacts of jbc on hydrological modeling over 12 watersheds covering various climate conditions with those of the commonly used distribution mapping method which corrects precipitation and temperature independently since both methods only differ in correcting inter variable correlations any difference in hydrological simulations can be directly attributed to inter variable correlation 2 study area and data 2 1 study area this study was conducted over 12 watersheds located in four countries across the globe table 1 ten of the watersheds located in the united states seven and canada three were also used in a previous study by chen et al 2013a for assessing the performance of various bias correction methods these ten watersheds were selected from different climate zones and topographic conditions in terms of climate conditions the 10 watersheds can be classified into five snowfall dominated manic 5 1 carrot 2 nation 3 yampa 9 and yellowstone 10 three rainfall dominated chickasawhay 4 grand 5 and umpqua 7 and two rainfall snowfall mixed sacandaga 6 and wolf 8 watersheds although the three watersheds in canada manic 5 carrot and nation are all snow dominated they have very different annual precipitation and temperature rates manic 5 is the coldest watershed with abundant precipitation while carrot and nation are located in arid regions three of the united states watersheds umpqua yampa and yellowstone are located in westerly mountainous areas and the other four chickasawhay grand sacandaga and wolf in the centrally and easterly flatter terrain the hydrological regime of the umpqua can be divided into contrasting wet and dry seasons two watersheds xiangjiang 11 and oueme 12 with different climates subtropical monsoon and tropical were also selected from china and benin respectively the xiangjiang watershed located in the central south region of china is a large sub basin of the yangtze river watershed it has a subtropical monsoon climate and a mean annual precipitation of about 1570 mm most of the precipitation occurs between april and june resulting in high flows over this period while little occurs in the winter which is defined as a low flow period the oueme watershed located in the republic of benin west africa is characterized by two different climates a subequatorial climate to the south and a sudanian climate to the north the temperature is high all the year round and so there is no snow occurring in the winter heavy rainfall mainly occurs between april and october accounts for 92 with minimal amounts during the other months 2 2 data the observed meteorological data daily precipitation and temperature for the three canadian watersheds studied were drawn from the hutchinson et al 2009 gridded dataset which was obtained by interpolating station data to a 10 km grid using a thin plate smoothing spline surface fitting method for the seven watersheds in the united states the 5 km santa clara dataset was used maurer et al 2002 livneh et al 2013 to run a lumped hydrological model as will be introduced section 3 b all grid points within the watersheds were averaged to one for both the precipitation and temperature time series the gauge measured precipitation and temperature time series were used for the xiangjiang and oueme watersheds the mean precipitation and temperature of the xiangjiang watershed were obtained by averaging the precipitation and temperature over 100 rain gauges and 8 temperature gauges within or surrounding the watershed respectively based on weights calculated using the thiessen polygon method rhynsburger 1973 the same averaging method was also used for the oueme watershed based on 18 rain gauges and 3 temperature gauges discharge data for manic 5 1 were provided by hydro québec drawn from mass balance calculations at the dam for the other two canadian watersheds carrot 2 and nation 3 they were obtained from environment canada the discharge data for the united states watersheds were obtained from the model parameter estimation experiment mopex database duan et al 2006 discharge data for xiangjiang and oueme were respectively obtained from the department of water resource of hunan province china and direction générale de l eau dg eau benin the climate model simulations were taken from the coupled model intercomparison project phase 5 cmip5 database twenty six gcms id 1 26 in table 2 from 16 modeling centres were selected to adequately represent the climate model uncertainty table 2 depending on their surface areas some watersheds may include only one or even no gcm grid box to obtain the mean watershed precipitation and temperature data from several gcm grids more than four depending on the size of the watersheds within or surrounding the watersheds were averaged using the thiessen polygon method the dataset covers the period of 1975 2004 for the xiangjiang watershed and of 1961 2000 for the other 11 watersheds the first half of each period was used to calibrate the bias correction methods and the second half for validation 3 methodology 3 1 bias correction methods the jbc method of li et al 2014 was used to jointly correct precipitation and temperature simulated by 26 gcms since the original jbc method was developed for bivariate correction only daily precipitation and mean temperature were considered the daily mean temperature was obtained by averaging the daily maximum and minimum temperatures for both observed and gcm simulated data a previous study by chen and brissette 2015 showed that daily mean temperature estimated using this method is as good as that estimated by averaging hourly temperature 24 values per day to investigate the benefits of the joint correction of precipitation and temperature on hydrological modeling the results obtained from jbc were compared with those obtained from an independent bias correction ibc method prior to using jbc and ibc methods the wet day frequency of gcm simulated precipitation was corrected using the local intensity scaling loci method of schmidli et al 2006 with the loci method a wet day threshold was first determined using the gcm daily precipitation time series for each month such that the threshold exceedance matched the wet day frequency of the observed time series for the calibration period this threshold was then used to correct the wet day frequency of gcm simulated precipitation for the validation period this threshold value varies from one gcm to the other and ranged between 0 and 6 6 mm after the wet day frequency correction precipitation amounts were respectively corrected using the ibc and jbc methods the ibc method used in this study is a distribution mapping method with a gamma distribution modeling precipitation and gaussian distribution for temperature this method has been used in several other studies e g chen et al 2013a b ines and hansen 2006 piani et al 2010 to produce climate simulation for hydrological modeling and climate change impact studies the jbc method is a bivariate extension of the ibc method and it is only briefly described here more details can be found in li et al 2014 when using the jbc method a joint cumulative distribution function cdf must first be built for precipitation and temperature the gamma and gaussian distributions are used to model the marginal distributions of precipitation and temperature respectively with the joint cdf the marginal and conditional distributions are then derived which are then used to sequentially correct the precipitation and temperature jbc can be performed by first correcting either the precipitation or the temperature in this study we start by correcting the precipitation and then go on to the temperature both ibc and jbc were conducted at the monthly basis 3 2 hydrology modeling the hydrological modeling was carried out using a lumped conceptual rainfall runoff model hmets developed by école de technologie supérieure the model structure is detailed in martel et al 2017 the hmets source code interface and user guide are freely available on the mathworks file exchange site hmets has been used in several flow forecasting and climate change impact studies e g chen et al 2011b essou and brissette 2013 arsenault et al 2015 2017 arsenault and brissette 2016 the model has up to 21 free parameters one for evapotranspiration ten for snow accumulation and snowmelt four for vertical water balance and six for horizontal water movement information about each parameter is presented in table 3 the calculation of potential evapotranspiration pet follows the work of oudin et al 2005 a constant parameter is used during optimization to adjust pet to a specific watershed actual evapotranspiration depends on water present in the vadose zone reservoir of the hydrological model the snowmelt model is based on the work of vehvilainen 1992 which is a degree day model that allows for melting and refreezing process within the snowpack the model works in three steps including the overnight refreezing process snowmelt and snowpack water retention capacity the vertical water balance takes into account all the exchanges made between the surface vadose and saturated zones depending on the water level in the vadose zone reservoir available surface water is partitioned between runoff and infiltration once the actual evapotranspiration has been taken out the saturated zone is represented by a linear reservoir releasing groundwater flow outlet streamflow is calculated based on four horizontal transfer components for surface and delayed runoff two unit hydrographs based on the two parameter gamma distribution density function are used to transfer water at the outlet total outlet streamflow is ultimately computed by summing up all four horizontal flow components for purely rainfall driven watersheds e g oueme 12 the hmets snow module was not used and the model reverted to its 11 parameter version model calibration was done automatically using the covariance matrix adaptation evolution strategy cmaes hansen and ostermeier 1996 2001 which was shown to be most efficient for this type of optimization class arsenault et al 2013 hmets requires the daily mean temperature and precipitation as inputs if the maximum and minimum temperatures are input to the model they are automatically averaged to the mean temperature a natural flow or discharge time series is also needed for model calibration and validation hmets structure is fairly typical of this class of hydrological models the use of a lumped conceptual model was based upon several considerations even though distributed hydrological models do have advantages in studying the spatial variability of hydrological response to climate and land use changes when the goal is streamflow simulation prediction at watershed outlets lumped models have been shown to be just as good as their more complex distributed counterparts in several inter comparison studies e g reed et al 2004 smith et al 2012 streamflow generation at a watershed outlet is the result of various spatially integrated processes and this explains why lumped model excel at this task and can do very well on very large watersheds the observed precipitation temperature and discharge were used to calibrate and validate hmets for all 12 watersheds to ensure a robust calibration both the calibration and validation periods were longer than 10 years for all the watersheds the optimal combination of parameters was chosen based on the nash sutcliffe coefficient nse nash and sutcliffe 1970 the chosen set of parameters yielded nse values ranging between 0 766 grand and 0 924 xiangjiang for calibration and between 0 724 carrot and 0 892 chickasawhay for validation across all 12 watersheds indicating the good performance of hmets for these watersheds table 4 and the suitability of using a lumped model for this study the observed and simulated mean hydrographs presented in fig 1 also outline the good performance of hmets for these watersheds 3 3 data analysis this study first evaluated the performance of both bias correction methods ibc and jbc in correcting gcm simulated precipitation and temperature and then for hydrological modeling the corrected results from both methods were each compared to the other as well as with the raw gcm outputs in order to show the benefits of bias correction since the performance of distribution mapping methods in terms of correcting individual variables has been thoroughly evaluated in several studies e g piani et al 2010 teutschbein and seibert 2012 chen et al 2013a li et al 2014 this study only compares the performance of these two methods in terms of correcting p t correlation the absolute error ae was calculated for the p t correlation coefficient for raw and corrected data the difference between raw corrected gcm and observed correlation coefficient since precipitation and temperature may not necessarily be linearly correlated the kendall s tau coefficient kendall 1970 was used in this study to investigate the impacts of the jbc method on hydrological modeling the raw and bias corrected simulations of precipitation and temperature were used to drive hmets for hydrological simulations over both the calibration and validation periods discharges simulated using ibc and jbc corrected simulations were compared with those simulated using observations according to 46 evaluation metrics table 5 these evaluation metrics capture the mean 13 metrics standard deviation 13 metrics and distribution 11 metrics characteristics of the observed hydrology the other 9 of the 46 metrics represent the timing variables e g time to peak discharge annual maximum flood and time to the beginning and to the end of annual maximum flood and the frequency of high and low flows 10 year 20 year and 50 year return periods of high flow 0 95 quantile and low flow 0 05 quantile time to the beginning and to the end of flood are determined based on a cumulative annual hydrograph chen et al 2011b four breakpoints in the cumulative annual hydrograph are fitted and connected by straight lines minimizing the root mean square error with the cumulative annual hydrograph the time to the first breakpoint is defined as the beginning of flood and the time to the second is defined as the end of flood to obtain the return periods the annual high and low flows are modeled using the log pearson type iii distribution usgs 1982 the time periods used to calculate the high and low flows are watershed dependent as presented in table 4 the performance of the ibc and jbc methods with respect to reproducing climate simulations for hydrological modeling was evaluated with the following three steps 1 the re was first calculated for all 46 metrics and two bias correction methods 2 the absolute value of the relative error are was then calculated for all metrics and both bias correction methods the relative error re was calculated for hydrological metrics as the difference between raw corrected and observed data simulated values divided by the observed data simulated values and 3 the difference in are dare over two bias correction methods was calculated at the last step using eq 1 1 d are m ibc m obs m obs m jbc m obs m obs where m represents a hydrological metric mibc mobs mobs and mjbc mobs mobs are res of each hydrological metric simulated by ibc and jbc corrected simulations respectively to avoid biases resulting from the hydrological modeling process the observed streamflow time series is represented by modeled discharge using observed precipitation and temperature rather than the gauged observation the dare values were presented using portrait diagrams following the work of gleckler et al 2008 the paired t test was used to test the equality of the are of the ibc and jbc methods for all 46 metrics 46 pairs a right tailed paired t test was first applied at a significance level of 5 if the p value of the paired t test was 0 05 the jbc method is significantly better than the ibc method in contrast if the p value is greater than 0 05 the performance of the jbc method is not statistically better than the ibc method to test if the ibc method is better than the jbc method a left tailed paired t test was further applied at the p 0 05 level if ibc is not statistically better than jbc both methods are then considered as statistically identical in addition the mean absolute relative error mare was calculated by averaging 26 gcms 46 metrics ares across all 26 gcms and across all 46 hydrological metrics for both ibc and jbc corrected simulations over the calibration and validation periods the relative difference of mare rd mare between ibc and jbc corrected simulations was then calculated a positive rd mare implies that the jbc method performs better than the ibc method and vice versa averaging ares across gcms reflects the overall performance of both bias correction methods in terms of hydrological metrics while averaging ares across all 46 metrics outlines the overall performance of both bias correction methods in terms of gcms 4 results 4 1 precipitation and temperature correlation the ae of the p t correlation coefficients of raw and ibc and jbc corrected data are calculated for all 26 gcms and 12 watersheds over both the calibration and validation periods results of two typical months july and november are presented in fig 2 for illustration the results show that all gcms are considerably biased in preserving the observed p t correlation however the sign and magnitude of biases are dependent on multiple factors watershed location gcm and month for example the p t correlations for the three canadian watersheds are overestimated by most gcms in both july and november however they are underestimated for other watersheds in july the ibc method correcting precipitation and temperature distributions independently retain the p t dependencies of gcms the correlation coefficient is almost identical to that in raw gcm simulations the jbc method performs reasonably well in reducing the bias of gcm p t correlations for all months and watersheds over the calibration period however its performance in the validation period is monthly dependent for example the p t correlation biases are considerably reduced for july but not for november results for other months range somewhere between july and november 4 2 hydrological modeling the raw and bias corrected daily precipitation and temperature time series were used as inputs of hmets to simulate streamflows over all 12 watersheds figs 3 and 4 respectively present the mean hydrographs of all the watersheds over the calibration and validation periods all gcms results without raw and with bias correction ibc and jbc are shown as envelopes and hydrographs simulated by canesm2 simulations are presented as a typical example the mean hydrographs simulated by the observed precipitation and temperature are also presented for comparison figs 3 and 4 show that the mean hydrographs are poorly represented by raw gcm simulations as shown by the wide envelope in particular the annual cycle of streamflows simulated by canesm2 simulations cannot be captured for the yampa 9 and yellowstone 10 watersheds both the ibc and jbc methods are capable of reducing the biases of gcm simulations and better representing the mean hydrograph over both the calibration and validation periods however when all simulations are plotted together the difference between the ibc and jbc methods is difficult to notice even though a slight advantage of the jbc method can be observed in some cases e g sacandaga 6 and oueme 12 watersheds in other words both bias correction methods perform similarly with respect to reproducing mean hydrological conditions as represented by the mean annual hydrograph in order to investigate the impacts of correcting gcm p t correlation on hydrological modeling in greater detail the ibc and jbc methods were further compared with respect to reproducing 46 hydrological metrics figs 5 and 6 present the portrait diagrams of the dare of 46 metrics for the calibration and validation periods respectively the warm color red in the portrait diagrams indicates that the ibc method performs better than the jbc method while the cool color blue indicates that the jbc method is better overall the jbc method performs better than the ibc method for most watersheds and gcms over the calibration period as illustrated by the fact that there are more blue than red indications in fig 5 the paired t test shows that the jbc method performs significantly better than the ibc method for 11 out of the 12 watersheds at the 5 significance level table 6 indicating the importance of correcting the p t correlation of gcm simulations in hydrological impact studies table 6 however for the manic 5 watershed both methods perform similarly for the validation period the portrait diagram mixes blue and red colors fig 6 over the validation period it is hard to identify the advantage of one method over the other the paired t test shows that the jbc method performs significantly better than the ibc method for 6 out of the 12 watersheds at the 5 level however both methods show similar performance for 3 watersheds and ibc performs significantly better than jbc for 3 watersheds the performance of both methods is also compared using mare as a criterion figs 7 and 8 show the rd mare between the ibc and jbc methods in terms of 26 gcms over the calibration and validation periods in line with results presented in fig 5 the rd mare shows that the jbc method consistently performs better than the ibc method for most gcms over the calibration period this applies to all watersheds with the exception of manic 5 1 in particular the jbc method performs better for all gcms over the carrot watershed 2 for the validation period the jbc method performs better than the ibc method for 6 out of 12 watersheds for these 6 watersheds the jbc method performs better for most gcms but not all over the 3 watersheds where both methods perform similarly 1 5 and 11 relative performance depends on the gcm for the remaining 3 watersheds the ibc methods performs better for most gcms reasons of these behaviors will be discussed later performance is also dependent on the choice of hydrological metric figs 9 and 10 show that the performance of the jbc method depends on hydrological metrics overall the jbc method consistently performs better than the ibc method for most metrics for 10 out of 12 watersheds over the calibration period for the manic 5 watershed 1 the jbc method performs worse for mean and standard deviation of winter discharge as well as some metrics about extreme flows however it performs better for other metrics this is not surprising as precipitation accumulates as snow over the winter and consequently correlation between precipitation and temperature is less relevant to streamflow generation for the oueme watershed 12 the jbc method performs better for wet season metrics but worse for dry season metrics indicating that complex methods may be detrimental in such cases for the validation period differences between both methods are small with the exception of the nation and oueme watersheds the jbc method is clearly better over 3 watersheds 3 6 and 12 while the ibc method is better over watersheds 4 9 and 10 5 discussion and conclusion bias correction methods applied to climate model outputs usually act on each climate variable separately thus there are concerns regarding whether inter variable dependencies of climate model outputs are distorted and whether the bias of inter variable dependencies affects the reliable assessment of climate change impacts in this study the impacts of correcting the p t correlations of gcm simulations on hydrological modeling were investigated specifically the performance of a jbc method was compared with the commonly used ibc method in terms of hydrological modeling over 12 watersheds located in various climate regimes the results show that gcms are considerably biased in terms of modeling p t dependencies even though the ibc method largely improves the simulation of individual variables simulated by gcms the inter variable dependencies are mostly retained similar results were also obtained in other studies e g wilcke et al 2013 li et al 2014 the jbc method performs reasonably well in reducing the biases of the gcm simulated p t correlation for the calibration period however for the validation period its performance is monthly dependent for example the p t correlation bias is considerably reduced in july but not so much in november the different performance of jbc between the calibration and validation periods is mostly due to the fact that the biases of the gcm p t correlation are not constant in time more on this below all bias correction methods are based on an assumption that climate model biases are stationary over time hewitson and crane 2006 piani et al 2010 maraun 2012 maurer et al 2013 chen et al 2015 however this is not necessarily so in practice even over two adjacent time periods due to the natural climate variability chen et al 2015 if the stationary assumption is not verified there is little hope that a bias correction method can work equally well over calibration and validation periods in terms of hydrological modeling the jbc method performs significantly better than the ibc method for 11 out of the 12 watersheds over the calibration period this highlights the importance of correcting the inter variable dependencies of gcms in hydrological modeling for the coldest snowfall dominated watershed manic 5 1 the advantage of jbc is not evident this is as expected because the water availability of this northern watershed is dominated by snowfall in the winter as about 45 precipitation occurs as snow evaporation which is determined by temperature is not important for this watershed as the temperature is relative low all the year round the temperature mainly affects the snow melt time in the spring in other words the hydrology of the northern watershed may not be sensitive to the p t dependencies especially when taking into account the fact that the bias of the gcm p t correlation is relatively small for this watershed unlike for the calibration period the jbc method does not perform consistently better than the ibc method for the validation period in particular it performs significantly better or comparably to the ibc method for 9 out of the 12 watersheds but exhibit worse performance over the other 3 watersheds the 6 watersheds where the jbc method exhibit advantage can be classified into two groups arid or tropical watersheds carrot 2 nation 3 and oueme 12 and snowfall rainfall mixed watersheds sacandaga 6 and wolf 8 for arid or tropical watersheds the evaporation determined by temperature represents a considerable amount of water loss and precipitation determines the available water that can be evaporated thus the relationship between precipitation and temperature is tight the tropical oueme 12 watershed is a good example over which the jbc method performs much better than the ibc method for most hydrological metrics even though the umpqua watershed cannot be labeled as having an arid climate its hydrological regimes nonetheless displays contrasting dry and wet seasons the use of jbc is also important for snowfall rainfall mixed watersheds as the temperature determines the proportion of precipitation that occurs as rain or snow as well as the proportion of snow to melt li et al 2014 however for snowfall dominated watersheds manic 5 1 yampa 9 and yellowstone 10 the advantage of the jbc method is not obvious as mentioned earlier this is because the temperature is very low for these watersheds in the winter and a slight fluctuation in temperature would likely have little effect on snowmelt and evapotranspiration similarly the advantage of the jbc method is also not significant for rainfall dominated watersheds grand 5 xiangjiang 11 and chickasawhay 4 due to the unsynchronized wet and heat seasons besides the reasons mentioned above the bias nonstationarity of gcm simulations may ultimately be the main culprit because of the nonstationary p t correlations partly arisen from natural climate variability the jbc method may have little advantage over the ibc method in terms of correcting the gcm p t correlation and may even induce additional biases for some months e g november this is especially true for the three watersheds where the ibc method performs better than its counterpart for hydrological simulations to understand these results more clearly the assumption of bias stationarity in p t correlations is verified for the yampa 9 and yellowstone 10 watersheds fig 11 presents the difference in biases between the validation and calibration periods validation calibration for the monthly p t correlations for all 26 gcms the observed monthly p t correlations for all 12 watersheds are also presented for comparison fig 12 the bias is defined as the difference in monthly p t correlation between observations and gcm time series the difference in bias is equivalent to the future bias remaining after a bias correction based on the calibration period has been performed the results show that the bias of p t correlations is clearly not stationary for these two watersheds especially when taking into account the fact that the difference in bias between the calibration and validation periods is greater than the observed p t correlations lines 9 and 10 in fig 12 due to the bias nonstationarity of the biases the jbc method deteriorates the original p t correlations simulated by gcms this explains why the ibc method performs significantly better than the jbc method for 3 out of 12 watersheds increasing the length of the calibration period so as to more comprehensively sample the natural climate variability may be able to improve the jbc performance to some extent in addition even though all gcms are capable of appropriately simulating the climate at the global scale their performance vary at the regional and watershed scales thus potentially explaining some of the differences the observed p t correlation may be another factor which affects the performance of the jbc method as presented in fig 12 correlations can be positive and negative or even absent depending on the month if the observed correlation is very small a slight perturbation may result in large biases in p t corrections especially when the bias of p t corrections is not stationary this may be why the jbc method can deteriorate the original p t correlations in some cases overall this study emphasizes the importance of correcting the inter variable dependencies of gcm simulations when using them for hydrological climate change impact studies the jbc method is able to achieve this goal depending on hydrological simulations the performance of the jbc method varies across watershed locations and hydrological metrics the method may perform better than the ibc method for one hydrological metric but may not for the other this study only looked at the overall impacts of jbc using 46 hydrological metrics for example the paired t test was conducted based on 46 pairs of hydrological metrics a careful validation should always be performed for specific impact studies for example the impact of the jbc method on streamflow for specific seasons in addition the hydrological simulation carried out in the study was based on only one hydrological model while the uncertainty of hydrological models was not considered however previous studies e g wilby and harris 2006 chen et al 2011a have shown that the uncertainty due to hydrological models is much less important than that related to climate models therefore it is unlikely that the conclusions drawn from this paper would change when using other hydrological models finally this study only investigates the impact of jbc on hydrological modeling the advantage of jbc may be more significant for other impact studies such as those relating to agriculture as the concurrent changes in precipitation and temperature are of greater interest than independent projections of each variable tebaldi and lobell 2008 acknowledgements this work was partially supported by the national natural science foundation of china grant no 51779176 51539009 51339004 the thousand youth talents plan from the organization department of ccp central committee wuhan university china the natural science and engineering research council of canada nserc hydro québec and the ouranos consortium on regional climatology and adaption to climate change chao li was also supported by the national science foundation under grant 1313897 the authors would like to acknowledge the contribution of the world climate research program working group on coupled modelling and all climate modeling groups listed in table 2 for making available their respective model outputs 
7347,urmia lake once the second largest saline lake in the world is on the verge of complete desiccation it has been suggested that the desiccation is caused by intensified human activities especially irrigation and prolonged droughts in the lake basin but there is a lack of quantitative analysis to attribute the observed water level decline to natural and anthropogenic causes in this study we use remote sensing data ground observations and a hydrological model with human impact assessment capabilities higw mat to investigate the natural and human induced changes in the hydrology of urmia lake basin from 1980 to 2010 based on the analysis of remote sensing data we find a 98 and 180 increase in agricultural lands and urban areas respectively from 1987 through 2016 with a corresponding shrinkage in lake area by 86 further we use model results to examine the changes in terrestrial water storage tws over the basin including the lake results indicate that tws declined over the lake region and the lake lost water at a faster rate than the watershed did comparison of river inflow to the lake from two simulations one with and the other without human activities suggests that human water management activities caused a reduction in streamflow of 1 74 km3 year from 1995 to 2010 which accounts for 86 of the total depletion in lake volume during the same period it is also found that irrigation water requirement almost tripled causing high withdrawals from rivers these results demonstrate that the on going depletion of urmia lake is not solely due to prolonged droughts but also due to direct anthropogenic alterations which caused significant changes in land use streamflow and water storage within the basin this study provides important insights on the natural and human induced changes in the hydrology of urmia lake and highlights the need for a high resolution regional scale modeling approach for better understanding potential future changes toward restoring the lake and putting forth a course of action to stop further desiccation and avoid a major environmental catastrophe keywords urmia lake human impacts land use land cover change terrestrial water storage 1 introduction there are increasing evidences from ground and satellite based observations that human land water management activities have profoundly impacted the natural pattern of water flows and storages over large scales carpenter et al 2011 halpern et al 2008 meybeck 2003 newbold et al 2016 nilsson et al 2005 vitousek et al 1997 vörösmarty et al 2010 these evidences clearly indicate that today more than 40 of the natural landscape has been heavily modified foley et al 2005 ramankutty et al 2008 most of the large river systems around the world remain largely fragmented dynesius and nilsson 1994 gleick 2003 nilsson et al 2005 groundwater storage in the world s largest aquifer systems are declining at an alarming rate long et al 2013 pokhrel et al 2015 2012b rodell et al 2009 scanlon et al 2012 wada et al 2010 and some of the largest inland water bodies are fast disappearing aghakouchak et al 2015 micklin 2010 1988 pokhrel et al 2017 climate change and variability is inarguably an important driver of these changes donohue et al 2011 2010 irmak et al 2012 liu and mcvicar 2012 mcvicar et al 2012 milly and dunne 2016 2011 scheff and frierson 2014 wild 2014 willett et al 2008 but there is a growing consensus that human activities now rival natural climatic factors and hence are the major drivers of the observed changes in many regions carpenter et al 2011 rockström et al 2009 sanderson et al 2002 steffen et al 2007 wisser et al 2010 flow regulation by dams and water use for irrigation are amongst many human water management activities that cause significant alterations in natural flow regimes through changes in the magnitude duration timing and rate of flow döll et al 2009 haddeland et al 2014 lorenz et al 2014 lytle and poff 2004 poff et al 1997 pokhrel et al 2017 veldkamp et al 2017 wurtsbaugh et al 2017 in river basins that drain to a terminal inland water body e g a lake or sea such alterations in flow regimes not only affect the downstream hydrological and ecological systems but also impact the long term water balance of the terminal water body one of the prominent examples of such human induced alterations in the water balance of an inland sea is of the aral sea in eurasia stone 2015 wurtsbaugh et al 2017 where a net loss of 1000 km3 92 of sea volume of water was observed in a four decade period micklin 1988 pokhrel et al 2017 which has been attributed to large scale river diversion and an increase in consumptive water use for irrigation within the drainage basins aghakouchak et al 2015 micklin 2010 1988 pokhrel et al 2017 tan et al 2017 as the desiccation of the aral sea remains to be one of the very greatest ecological problems of the twentieth century micklin 1988 water levels in many other inland water bodies around the world are in a persistent decline anda et al 1998 carrera hernandez 2017 coe et al 2009 fao 2011 gross 2017 li et al 2007 macías and lind 1990 swenson and wahr 2009 wurtsbaugh et al 2017 one of such endangered system is the urmia lake in iran which is at an imminent risk of falling victim to the same syndrome that desiccated the aral sea aghakouchak et al 2015 there is a growing body of literature contributing to the ever growing debate on the shrinkage of the urmia lake and its ultimate fate suggesting that the observed depletion of the lake can be attributed to various climatic and anthropogenic factors abbaspour and nazaridoust 2007 aghakouchak et al 2015 arkian et al 2016 delavar et al 2007 delju et al 2013 fathian et al 2014 hassanzadeh et al 2012 madani 2014 zeinoddini et al 2015 while some studies have considered the impacts of growing human land water management activities aghakouchak et al 2015 alizade et al 2018 hassanzadeh et al 2012 shadkam et al 2016 zeinoddini et al 2015 most others have focused only on the climatic factors particularly precipitation and temperature arkian et al 2016 delavar et al 2007 delju et al 2013 fathian et al 2014 hence leaving a gap in the thorough understanding of the combined effects of climatic and human factors arkian et al 2016 investigated the climate data from four meteorological stations in the lake basin for 1965 2010 period and found a correlation of 0 69 between the changes in precipitation and lake level this correlation was found to be even higher during the period of 1990 2005 a similar study conducted by delju et al 2013 showed that mean precipitation decreased by 9 2 and average maximum temperature increased by 0 8 c from 1964 to 2005 likewise using water budget multiple regression and artificial neural networks approaches on a monthly scale delavar et al 2007 concluded that the decrease in precipitation had larger effects on urmia lake s water level variation than the decrease in input discharge fathian et al 2014 studied the trends in the time series of hydro climatic variables of urmia lake basin for the period of 1960 2007 and suggested that lake depletion can be connected to both the temperature increase in the basin and the over exploitation of the water resources some other studies have examined the impacts of anthropogenic factors on the depletion of urmia lake which are not considered in the aforementioned studies that focused on the climatic factors for example hassanzadeh et al 2012 simulated the basin hydrology using a system dynamics model and suggested that the changes in inflows due to climate change and surface water exploitation construction of four dams in the upstream watersheds and reduced precipitation are responsible for 65 25 and 10 of the total desiccation of the lake respectively abbaspour and nazaridoust 2007 also highlighted the importance of river discharge to the lake s water balance using a hydrodynamic model likewise alizade et al 2018 investigated the water budget of the lake and concluded that anthropogenic factors contributed to 80 of lake volume decline whereas shadkam et al 2016 showed climate change as the main contributor to the depletion suggesting that anthropogenic factors such as irrigation withdrawal played a relatively minor role the aforementioned studies have provided crucial insights on the ongoing changes in the water balance of urmia lake and its basin but river flow which accounts for the majority of water input to the terminal lake has not yet been thoroughly investigated previous studies such as aghakouchak et al 2015 have emphasized the need for direct water budget assessment and quantification of the anthropogenic influence on the water cycle rather than relying on the attribution to prolonged droughts and climate change to fill this gap here we provide a comprehensive analysis of the combined effects of climatic and anthropogenic factors on the water balance of urmia lake with a particular focus on the changes in water use within the basin and the resulting impacts on the river inflow to the lake specifically this study presents how climate change and anthropogenic exploitation of land and water resources in the watershed contributed to the desiccation of urmia lake over the modeling period of 1980 2010 it contributes to the debate on the anthropogenic impact on urmia lake watershed by interpreting the scale of impact from medium resolution land use land cover lulc maps and a global land surface model lsm which accounts for human water management activities the results from the lsm provide a comparative study of urmia lake basin with and without human activities the specific objectives are to 1 investigate the changes in meteorological conditions and its impact on the lake 2 map the changes in land use patterns due to expanding agricultural activities within the watershed 3 assess the changes in terrestrial water storage tws within the basin and its impact on the shrinkage of the lake and 4 examine how the increase in irrigation water requirement affected the inflow to the lake these objectives provide the structural sub headings used in the following methods results and discussions sections 2 study site data and model 2 1 study site urmia lake located in northwestern iran is one of the largest hypersaline lakes in the world until it began rapidly desiccating in the late 20th century ghaheri et al 1999 it was the world s second largest hypersaline lake alizade et al 2017 and the 20th largest lake by area emdadi et al 2016 several aspects of urmia lake such as chemistry and morphology are analogous to that of the great salt lake in the united states and the dead sea in the middle east alizade et al 2017 the lake surface area varied between 5200 and 6000 km2 during the last few decades of the 20th century tourian et al 2015 based on the precipitation data from 1973 to 2011 the average annual mean precipitation over the basin is 352 mm year farajzadeh et al 2014 and the air temperature usually ranges between 0 and 20 c in winter and up to 40 c in summer eimanifar and mohebbi 2007 the lake has the maximum and average depth of 16 m and 5 m respectively alesheikh et al 2004 the drainage basin with a total area of 52 000 km2 is home to several metropolitan cities in iran such as tabriz urmia and miandoab alipour 2006 the basin drains into the lake through thirteen main rivers alipour 2006 ghaheri et al 1999 more than three dozen dams have been built on these river systems to divert water for agricultural and other uses within the basin the alavian mahabad nahand and zarrinehrood are some of the major dams which have a combined total capacity of 1076 million m3 hassanzadeh et al 2012 the lake is a home to artemia known as brine shrimp the lake s most important creature and a food source for thousands of migratory birds abbaspour and nazaridoust 2007 eimanifar and mohebbi 2007 2 2 meteorological data we obtained the weather station data of air temperature and precipitation from the islamic republic of iran meteorological organization irimo for four stations within the watershed namely tabriz urmia maragheh and sarab as the ground observation data was obtained only for four weather stations the spatial distribution of the data was limited to overcome this data gap and achieve the desired spatial distribution required for further analysis we obtained satellite based and gauge satellite merged global precipitation data from various sources including the precipitation estimation from remotely sensed information using artificial neural networks persiann sorooshian et al 2014 global precipitation climatology project gpcp adler et al 2003 and global precipitation climatology center gpcc becker et al 2011 and compared them with the available weather station data to select the most reliable satellite products for the region among the examined global precipitation products we found the gpcc data to be of the highest compatibility with the precipitation record for four weather stations mentioned above therefore we use the gpcc data for our analysis for air temperature we use the data from the irimo weather stations because no other reliable datasets are available at the desired spatial scale 2 3 landsat imagery and modis landcover product the land use change analysis in this study is done using the satellite imageries from landsat 5 tm and landsat 8 oli obtained from the earth explorer interface of united states geological survey usgs in total eight images are required to cover the entire urmia lake watershed due to limited data availability and high number of images per year lulc maps are generated only for years 1987 1998 2006 2011 and 2016 landsat 5 tm imagery is used for the years 1987 1998 2006 and 2011 and landsat 8 oli for 2016 since the focus of this study is on the changes in agricultural land use than on other land use types it is important to carry out the land cover change analysis during the crop growing season therefore to ensure that the agricultural intensification is captured in the time series of land use and land cover change we use the landsat imagery only for the month of september when the crops are completely matured in the study region all the images obtained were raw images consisting of digital number dn the modis land cover type product mcd12q1 was used to independently evaluate the land use maps obtained from the classification of landsat imagery explained above this land cover product is derived from observations spanning over a year s input of terra and aqua modis data and was downloaded from the land processes distributed active archive center lpdaac website https lpdaac usgs gov at 500 m resolution the original files were re projected from sinusoidal projection system to geographical co ordinate system gcs 2 4 grace data gravity recovery and climate experiment grace derived tws variations are used to validate the trend in the simulated tws change as well as the seasonal cycle of tws variations we use grace solutions of equivalent water height thickness provided by 3 processing centers namely i jet propulsion lab jpl at california institute of technology ii the center for space research csr at university of texas at austin and iii the german research center for geoscience gfz http grace jpl nasa gov data get data for model evaluation landerer and swenson 2012 we also use two mascon products from csr and gfz which have been suggested to better capture tws signals in many regions save et al 2016 scanlon et al 2016 watkins et al 2015 various corrections are needed to isolate the tws signal from grace measurements but the data obtained was already corrected including atmospheric mass changes removal glacial isostatic adjustment gia truncation of spherical harmonic coefficients and application of destriping filter alongside with a 300 km gaussian smoother hence eliminating the need for further processing as the data are in 1 degree resolution with varying grid cell area an area weighted arithmetic mean is calculated following felfelani et al 2017 2 5 hydrological model the model we use is an integrated global land surface model called the higw mat which simulates all vegetation soil and runoff processes on a physical basis pokhrel et al 2015 it incorporates human impact hi and a groundwater pumping scheme gw into the process based global lsm minimal advanced treatments of surface interaction and runoff matsiro takata et al 2003 higw mat routes the runoff generated from each grid cell through the river network using the total runoff integrating pathways trip oki and sud 1998 four anthropogenic water regulation modules namely the crop growth and irrigation scheme reservoir operation module hanasaki et al 2006 water withdrawal module and environmental flow requirement module have been integrated into higw mat which are described in detail in pokhrel et al 2012a higw mat also includes a dynamic groundwater scheme koirala et al 2014 and a pumping scheme pokhrel et al 2015 details of the latest version of the model can be found in pokhrel et al 2016 2015 the simulations we use in this study are based on pokhrel et al 2015 and felfelani et al 2017 conducted at the global scale 3 methods the methodology used in this study employs analysis of remote sensing data and the results from an integrated hydrological model with human impact assessment capabilities the remote sensing data and model are described in sections 2 3 and 2 5 respectively the trends in the simulated tws and river flow and the observed lake volume are examined by using linear regression we use mann kendall statistics ʈ and p values at 5 significance level to determine the significance of the trend in these variables kendall 1975 mann 1955 the methods employed for each of the analyses are described in the following subsections 3 1 climate variations and lake dynamics the contribution of climate variations to lake dynamics is examined by conducting a correlation analysis between the meteorological variables i e precipitation and temperature data from weather stations and the observed lake level we use the standardized precipitation index spi mckee et al 1993 to examine climate change and variability during the period of 1980 2010 3 2 land cover change analysis we perform a pixel classification on the obtained imagery to generate historical land use maps of the region which is a widely used approach alves et al 1996 comber et al 2012 congalton et al 1983 rhemtulla et al 2007 valeriano et al 2004 vogelmann et al 2001 necessary radiometric corrections which include converting dn to radiance and radiance to surface reflectance using parameters such as earth sun distance zenith angle low gain and high gain values are applied individually before performing pixel classification five years of clear and almost cloud free landsat images are selected to classify the study area the classification scheme used in this study comprised of seven classes shown in table 1 an unsupervised classification approach using the isodata algorithm is used to classify each imagery into seven classes post classification corrections are applied to the produced lulc maps to reduce the classification errors due to spectral similarities using a rule based models in erdas software and manual inspection for example the pixels within the city limit classified as agricultural areas are changed to natural vegetation and the pixels which comprised of cloud shadows are changed to bare soil due to the lack of field data for the accuracy analysis of the above mentioned classification approach reference data is obtained from google earth random points are created and assigned to the 7 classes using the high resolution imagery in google earth accuracy is measured for each classification using a statistical analysis software package in envi that performs a pixel by pixel comparison of the classifications with the reference data the result is a confusion matrix which identifies percentage correct errors of commission pixels assigned to a specific class to which they do not belong and errors of omission pixels that should have been assigned into a specific class and were not in addition to a standard pixel by pixel accuracy assessment the khat or kappa statistic is also calculated which has been proven to be a strong estimator of classification accuracy conese et al 1993 stehman 1996 vogelmann et al 1998 3 3 terrestrial water storage and streamflow analysis the newly developed model in the fully integrated mode simulates surface and subsurface water flows by considering the processes of runoff routing reservoir operation irrigation water withdrawals environmental flow requirements groundwater table dynamics and well pumping the model employs a 1 1 spatial resolution for the entire study area and quantifies the impact of human activities on streamflow generated in the watershed which is a major source of water for urmia lake hence quantifying the human influence on the lake level dynamics the model results have been extensively validated at different temporal scales and locations in previous studies koirala et al 2014 pokhrel et al 2017 2015 2012a 2012b but as the hydrological model performance is known to vary by geographic location here we briefly evaluate some of the hydrological fluxes such as tws and streamflow for the urmia lake region we use the tws data derived from grace satellite mission see section 2 4 and the surface water inflow to lake from hassanzadeh et al 2012 since urmia lake basin has an area of 52 000 km2 which is smaller than the grace footprint of 200 000 km2 longuevergne et al 2010 we use a larger domain to conduct the tws comparison with grace we use the domain size with an area of 355 500 km2 by including the areas on all sides of the basin note that the choice of a larger domain for this purpose doesn t alter our analysis because 1 these results are only used to evaluate model results over urmia lake basin and 2 as noted by lorenz et al 2014 and yi et al 2017 the spatial resolution is not the only factor to be considered in grace while studying smaller catchments but the signal strength is also a major one in tws variations thus we use grace data for evaluating the tws signal over a larger domain and employ model results for the detection of long term trend in tws only for the urmia lake basin 3 4 historical irrigation water requirement the higw mat model simulates irrigation water requirements iwr however the irrigation scheme uses global datasets for crop parameters and irrigated attributes meaning that the results may contain uncertainties when used for specific regions therefore to add further confidence on our finding that irrigation which is the major human activity affecting the water balance in the urmia lake basin increased substantially over the period of 1980 2010 we use a process based approach to independently estimate historical irrigation water requirements the approach to estimate iwr is based on the formulations provided in allen et al 1998 in which crop evapotranspiration is calculated using the widely used fao penman monteith approach cai et al 2007 yang et al 2016 yoo et al 2008 this approach employs procedures for calculating reference crop evapotranspiration and crop water requirements and allows the simulation of crop water use under various climate and crop conditions the following water balance equation is used to calculate the irrigation water requirement for the identified irrigated regions from the land use maps developed in this study 1 niwr et r k c p eff where niwr is the net irrigation water requirement mm year etr is the reference crop evapotranspiration mm year kc is the crop co efficient and peff is the effective precipitation mm year calculation of etr using the fao penman monteith method requires meteorological variables including air temperature humidity shortwave radiation net longwave radiation wind speed as well as the latitude and elevation defined per mcvicar and körner 2013 due to the lack of high resolution and temporally complete meteorological data for the study region we use 6 h atmospheric reanalysis data provided by japanese meteorological agency jma climate data assimilation system jcdas we interpolate the jma reanalysis data into 900 m 900 m grids to compute irrigation water requirement we use the elevation data derived from the srtm 1 arc second dataset https earthexplorer usgs gov effective precipitation is computed using the usda soil conservation service scs method the model is run with an assumption that all the irrigated areas have the same crop at a time only wheat and barley with their standard crop coefficients are considered as they are known to be the major crops grown in the region bannayan et al 2011 beheshti tabar et al 2010 4 results 4 1 climate variation and lake dynamics the analysis of precipitation time series over urmia lake region indicates a decreasing trend in annual precipitation during the period of 1980 2010 fig 1 a the highest annual precipitation over the region occurred in 1993 and 1994 which amounted to 612 mm year and 605 mm year respectively which is followed by relatively dry years minimum precipitation recorded is 300 mm year in years 1999 and 2008 similarly low precipitation spells of around 350 mm year are observed in years 1989 and 1990 as well the spi values indicate the severity of the precipitation events with the index of 2 6 for the year 2008 and that of 2 3 for the year 1999 fig 2 the peaks in precipitation over the region before 1995 fairly match with the peaks in lake levels with a slight delay which can be attributed to the time required for the water from the entire basin to reach the lake fig 1b for example the effect of high precipitation during year 1994 is reflected in the lake level in year 1995 4 2 land cover change analysis next we examine the historical changes in land use pattern particularly focusing on agricultural expansion within the watershed and the decline in lake area fig 3 displays the spatial and temporal changes in six major land cover types in the urmia lake region at the spatial resolution of 30 m for years 1987 1998 2006 2011 and 2016 along with a general comparison with other land use datasets such as history database of the global environment hyde 3 1 klein goldewijk et al 2011 and the land cover product from modis imagery section 2 3 each map consists of eight landsat scenes mosaicked and clipped to the watershed boundary major transitions between different land cover types are observed in the urmia lake watershed between 1987 and 2016 the decline in surface water in the entire lake basin is found to be 77 out of which 86 is caused by urmia lake itself between 1998 and 2016 fig 4 the rate of this decline is found to be consistent with the rate reported by other studies aghakouchak et al 2015 as seen in fig 4 both cropland and urban classes show a steep positive trend from 1987 to 2016 which can be directly correlated to the anthropogenic activities within the watershed urban areas in the watershed have increased by 180 with a corresponding increment of 98 in the agricultural land further an accuracy assessment of the generated lulc maps is performed using point data derived from google earth for year 2016 a pixel by pixel comparison resulted into a confusion matrix shown in table 1 a total of 1170 reference points is used for accuracy assessment the overall accuracy is found to be of 81 62 and kappa coefficient of agreement khat of 0 76 is achieved for this classification this assessment is only conducted for year 2016 due to lack high resolution google earth imagery for the previous years further the classification accuracy for all the years can be expected to be in the same range as the methodology used for classifying all imagery in this study has been consistent throughout 4 3 terrestrial water storage and streamflow analysis fig 5 a shows the comparison of anomalies of tws obtained from grace and simulated by higw mat model it is evident from the figure that the model captures the long term trend of tws within plausible limits with a generally good agreement for most years underestimations during the first few years and overestimations during the last years can be attributed to the uncertainty in the forcing data and the human impact simulations the results for the preceding years could not be validated due to the lack of tws data fig 5b shows a rather accurate comparison between the seasonal variations of simulated and grace based tws while the model grace agreement varied over time between the spherical harmonics and mascon products fig 5a the model compared better with mascon products for the seasonal cycle fig 5b fig 6 shows the temporal tws variations from the model for the entire modeling period i e 1980 2010 annual tws in the urmia lake basin is highly variable and as the lake is the largest water body in the basin tws has a strong dependence on the changes in lake volume the peaks in simulated tws and lake volume match very well in the first half of the modeling period as shown in fig 6 but for the later years tws variations show less dependency on the changes of lake volume this behavior points toward an external influence causing the lake to dry faster than the entire basin in 1995 the time series shows the highest amount of tws over the watershed which corresponds to the highest precipitation and lake volume during the modeling period in the years before 1995 the lake gained water steadily at a rate of 0 58 0 15 km3 year ʈ 0 55 p 0 002 due to high precipitation and less human influence causing tws to show an increasing trend of 1 10 0 17 km3 year ʈ 0 7 p 0 0001 in those years the difference between the trends in lake volume and tws before 1995 also indicates the presence of a major water storage component apart from the lake body however after 1995 both the lake volume and tws over the region continue to decrease at a rate of 1 81 0 22 km3 year ʈ 0 983 p 0 0001 and 2 21 0 21 km3 year ʈ 0 733 p 0 0001 respectively in 2003 tws trend shows a considerable increase in magnitude which can be attributed to high precipitation however no changes are seen in the trend of lake volume during the same period overall for the entire modeling period tws shows a decreasing linear trend of 0 32 0 14 km3 year ʈ 0 226 p 0 072 to add further confidence in the model results we compare the simulated river flow with the streamflow data obtained from hassanzadeh et al 2012 because no long term flow observations are available hassanzadeh et al 2012 carried out a water balance analysis to estimate the streamflow data the simulated river flow compares well with the estimated values for the period of 1980 2010 fig 7 the primary objective of this comparison is to ensure that model simulates the river flow within the plausible limits for the urmia lake watershed the slight discrepancies between the declining trend in the estimated i e 0 10 0 04 km3 year hassanzadeh et al 2012 and simulated i e 0 07 0 04 km3 year river flows can be attributed to the lack of detailed irrigation parameterization in the global lsm the simulated river inflow into urmia lake with and without human impacts from higw mat model is displayed in fig 8 in both simulations the inter annual variability of river flow is largely governed by the changes in the meteorological factors high inflow values for both the simulations are in years 1988 and 1995 because of high precipitation and lower temperatures fig 1b and remained low in 1990 and 1999 due to a severe drought period in 1998 the difference in inflow from the two simulations is found to be high in the years after 1998 corresponding to the increased anthropogenic activity namely agricultural activities and dam constructions in the watershed during the earlier years less agricultural activities and favorable climatic conditions resulted in a relatively small difference between the inflows from the two simulations indicating less water withdrawal from rivers however in the latter half the difference is found to be very high compared to the preceding years indicating heavy human influence on river discharge this change can be attributed to the changes in irrigation demand and dam construction in the basin 4 4 historical irrigation water requirement as noted in section 3 4 the results displayed in the previous section are from a global model that used global datasets for the simulation of human impacts on streamflow including the estimation of irrigation water use which could have contained uncertainties due to the use of coarse resolution input datasets thus to independently verify the historical irrigation water use we estimated and examined the irrigation water requirement over the basin at the grid resolution of 900 m 900 m section 3 4 the computed annual net irrigation requirement niwr for the entire basin is shown in fig 9 the results are in general agreement with other estimates obtained from previous studies for example hesami and amini 2016 estimated the irrigation water requirement of the miandoab alluvial plain using the cropwat model as 0 67 km3 and 0 89 km3 for the year 1989 and 2000 whereas from this study the estimates are 0 73 km3 and 1 02 km3 respectively also the average niwr for the region is estimated as 760 mm year which falls in the range of 400 800 mm year as categorized by döll and siebert 2002 the difference in niwr values reported in this study and the previous studies can be attributed to the use of different input data and irrigated areas as well as the uncertainties in these datasets the results further confirm that niwr increased consistently in urmia lake region over the modeling period which can be attributed to the increase in irrigated areas with low irrigation efficiency a prominent increase in niwr can be seen during the 2007 2008 period which corresponds to the period of low precipitation and high temperatures overall niwr almost tripled during the period of 1980 2010 5 discussion 5 1 climate variation and lake dynamics it is evident from the time series correlation of precipitation over the entire basin and the variations in the lake level that the abrupt decline in urmia lake level is consistent with the decrease in precipitation in the year 1995 fig 1b it should be noted that the correlation is calculated using the mean lake level during the particular year the correlation of annual change in lake levels with precipitation and temperature are 0 15 and 0 36 respectively for the entire modeling period the annual lake level variations appear to be governed by the precipitation only for half of the modeling period i e until year 1995 with a correlation coefficient of 0 5 after 1995 the lake level shows rather weak correlation of 0 12 with precipitation despite considerable increase in precipitation in the year 2003 and 2006 the lake level continues to drop abruptly as opposed to precipitation the correlation between temperature and lake level improves from 0 15 to 0 28 in the period of 1995 2010 given the increase in observed temperature after 1995 fig 1 higher rates of evaporation over the lake can be expected however these changes in evaporation and other meteorological variables are already incorporated in the simulated river flow as discussed in section 5 3 further trends in the forcing data used to drive the hydrological model section 2 5 corroborates the declining trend in wind speed discussed in arkian et al 2016 and indicates no trend in specific humidity over the same period this indicates the dominance of other governing factors on water level of urmia lake which could be due to the major human influence on the hydrology of the lake basin 5 2 land cover change analysis the land cover change analysis suggests that anthropogenic activity in urmia lake basin increased considerably during the period from 1987 to 2016 especially in the form of agricultural expansion some previous studies have estimated the change in agricultural and irrigated areas in urmia lake region but a direct comparison pixel to pixel cannot be made due to the differences in the methodology used for estimation for example alizade et al 2017 used an ndvi based classification to map the irrigated areas in the basin but their estimates were validated over a larger region than the lake basin considered in this study the agricultural expansion which is in line with the findings from previous studies alizade et al 2017 and the changes in precipitation and temperature resulted in an increased water demands that led to the development of many dams and diversion projects in the basin hassanzadeh et al 2012 the increase in man made reservoirs can be clearly seen in fig 3 left column increasing open water areas over the basin 5 3 terrestrial water storage and streamflow analysis the simulated tws trend fig 6 suggests that the rate of loss of water from the lake was much higher than the rate of change in tws during 1995 2010 as urmia lake is a major water body in the watershed these results indicate that 0 4 0 01 km3 of water is being stored somewhere else in the watershed other than the lake every year the possible reasons for this trend behavior might be because of an increased leakage of lake water to the underlying aquifer or the ongoing water resources management activities in the watershed such as the construction of new dams here we discuss the second scenario consisting the impact of increased water management activities on streamflow any water management activity such as dam construction or diversion of surface water for irrigation purposes would prevent a normal inflow into the lake causing lake depletion this appears to be the most probable case given the rate of depletion and the increase in agricultural activity in the watershed storage of water behind dams can explain the difference between the depletion rate of lake and tws of the region the cumulative difference in inflows fig 8 between the two simulations after 1995 is found to be 28 km3 which suggests 86 of the change in lake volume is due to direct human influence on river flow in the basin based on model results before 1995 the difference between the two simulations is found to be 12 km3 indicating the presence of human influence even before the catastrophic depletion in the urmia lake however favorable climatic conditions and less water withdrawals may have offset this human influence avoiding a major depletion in lake volume in the absence of the major precipitation events in 1993 and 1994 the depletion in lake volume would have been observed much before than 1995 it should be noted that higw mat model computes all the water balance components on a physical basis hence the river flow simulated by the model provides an integrated effect of changes in all the meteorological variables along with human impacts there could be some discrepancy in the quantification of human influence caused by the uncertainty in the forcing datasets and human impact modules further it should be noted that the model used is an offline lsm which does not account for human influence on regional land atmosphere interactions a fully coupled high resolution model with human impact assessment capability is needed to better attribute the observed changes in lake volume to different factors improving human impact simulations by better representing the source of water use e g hanasaki et al 2018 is also an important future research direction for studying such depleted systems despite certain limitations arising from the use of a global model our results provide important insights on the direct human influence on river flow and the resulting consequences on lake level decline 5 4 historical irrigation water requirement the results from an independent and fine grid i e 900 m simulations of irrigation water requirements indicate that niwr almost tripled between 1980 and 2010 fig 9 it should be noted that these estimates are that of the net irrigation water requirements given the low irrigation efficiency in the region as reported by previous studies ahmadzadeh et al 2015 hassanzadeh et al 2012 hoseinpour 2010 the actual withdrawals per year could have been significantly higher than the calculated niwr the increase in total irrigated area in lake basin fig 4 and the corresponding increase in niwr fig 9 created a high demand for development of water resources management activities in the basin and increased consumptive withdrawals mainly for irrigation purpose this increase in niwr explains the difference between inflow to the lake under natural and human impacted condition as shown in fig 8 however the irrigation withdrawals before 1995 did not significantly impact the inflow to the lake because the irrigation water use was offset by higher precipitation rates fig 1 after 1995 however the expansion in the irrigated areas and a precipitous decline in precipitation in the region caused an increase in withdrawals hence reducing the river discharge considerably although the niwr values from this study compare well with the ones reported in previous studies döll and siebert 2002 hesami and amini 2016 they may contain uncertainties due to the uncertainties in different input datasets further we note that our irrigation water use analysis section 4 4 was carried out assuming that all agricultural lands were irrigated because detecting irrigation attributes using remote sensing data was beyond the scope of the present study future studies should consider more advanced remote sensing algorithms e g chen et al 2018 to detect time series irrigated areas for the better estimation of irrigation water use and its spatio temporal dynamics 6 conclusion our results suggest that both climate and anthropogenic factors played roles in the changes in volume of urmia lake during 1980 to 2010 but the abrupt decline in lake volume from 1995 to 2010 was primarily caused by the accelerated human water management activities land use land cover change analysis for 1987 to 2016 indicates that the acceleration in human activity in the basin is primarily due to an expansion of agricultural lands which increased by 98 causing a 3 fold increase in irrigation water needs further using the results from two versions of the hydrological model one with and the other without human activities it is found that human induced changes in river inflow to the lake accounts for 86 i e 28 km3 of lake volume decline during 1995 2010 period since the human land water management activities are expected to further expand in the future and climate change is likely to adversely impact water supplies it can be anticipated that the desiccation could further accelerate unless certain restoration measures are taken therefore sustainable management of water resources within the watershed is the key for the sustainability of the lake in the coming decades recognizing the need to take immediate actions the recently established urmia lake restoration program ulrp has put forth a plan on policies and course of action required for the stabilization and restoration of the lake toward reaching the ecological level in 10 years see http ulrp sharif ir page urmia lake level although these actions have been proven beneficial for the short term further measures such as reduction in water withdrawals and increase in irrigation efficiency are indispensable to bring the lake back to the long term equilibrium conditions results of this study provide important insights on the key mechanisms that caused the observed depletion in the past which have important implications for future actions to achieve sustainability in the region since the hydrologic results we used are from a global model we highlight the need to carry out regional scale modeling at finer resolution and with better constrained human impact modules to better assess the effects of current restoration program and project future changes under different climate change and water resource management scenarios acknowledgements we thank the editor associate editor and the three anonymous reviewers for providing highly constructive comments that helped tremendously in improving the quality of the paper this study was partially supported by the asian studies center at michigan state university we thank shu guang li and kyla dahlin for their invaluable comments and suggestions on the analyses 
7347,urmia lake once the second largest saline lake in the world is on the verge of complete desiccation it has been suggested that the desiccation is caused by intensified human activities especially irrigation and prolonged droughts in the lake basin but there is a lack of quantitative analysis to attribute the observed water level decline to natural and anthropogenic causes in this study we use remote sensing data ground observations and a hydrological model with human impact assessment capabilities higw mat to investigate the natural and human induced changes in the hydrology of urmia lake basin from 1980 to 2010 based on the analysis of remote sensing data we find a 98 and 180 increase in agricultural lands and urban areas respectively from 1987 through 2016 with a corresponding shrinkage in lake area by 86 further we use model results to examine the changes in terrestrial water storage tws over the basin including the lake results indicate that tws declined over the lake region and the lake lost water at a faster rate than the watershed did comparison of river inflow to the lake from two simulations one with and the other without human activities suggests that human water management activities caused a reduction in streamflow of 1 74 km3 year from 1995 to 2010 which accounts for 86 of the total depletion in lake volume during the same period it is also found that irrigation water requirement almost tripled causing high withdrawals from rivers these results demonstrate that the on going depletion of urmia lake is not solely due to prolonged droughts but also due to direct anthropogenic alterations which caused significant changes in land use streamflow and water storage within the basin this study provides important insights on the natural and human induced changes in the hydrology of urmia lake and highlights the need for a high resolution regional scale modeling approach for better understanding potential future changes toward restoring the lake and putting forth a course of action to stop further desiccation and avoid a major environmental catastrophe keywords urmia lake human impacts land use land cover change terrestrial water storage 1 introduction there are increasing evidences from ground and satellite based observations that human land water management activities have profoundly impacted the natural pattern of water flows and storages over large scales carpenter et al 2011 halpern et al 2008 meybeck 2003 newbold et al 2016 nilsson et al 2005 vitousek et al 1997 vörösmarty et al 2010 these evidences clearly indicate that today more than 40 of the natural landscape has been heavily modified foley et al 2005 ramankutty et al 2008 most of the large river systems around the world remain largely fragmented dynesius and nilsson 1994 gleick 2003 nilsson et al 2005 groundwater storage in the world s largest aquifer systems are declining at an alarming rate long et al 2013 pokhrel et al 2015 2012b rodell et al 2009 scanlon et al 2012 wada et al 2010 and some of the largest inland water bodies are fast disappearing aghakouchak et al 2015 micklin 2010 1988 pokhrel et al 2017 climate change and variability is inarguably an important driver of these changes donohue et al 2011 2010 irmak et al 2012 liu and mcvicar 2012 mcvicar et al 2012 milly and dunne 2016 2011 scheff and frierson 2014 wild 2014 willett et al 2008 but there is a growing consensus that human activities now rival natural climatic factors and hence are the major drivers of the observed changes in many regions carpenter et al 2011 rockström et al 2009 sanderson et al 2002 steffen et al 2007 wisser et al 2010 flow regulation by dams and water use for irrigation are amongst many human water management activities that cause significant alterations in natural flow regimes through changes in the magnitude duration timing and rate of flow döll et al 2009 haddeland et al 2014 lorenz et al 2014 lytle and poff 2004 poff et al 1997 pokhrel et al 2017 veldkamp et al 2017 wurtsbaugh et al 2017 in river basins that drain to a terminal inland water body e g a lake or sea such alterations in flow regimes not only affect the downstream hydrological and ecological systems but also impact the long term water balance of the terminal water body one of the prominent examples of such human induced alterations in the water balance of an inland sea is of the aral sea in eurasia stone 2015 wurtsbaugh et al 2017 where a net loss of 1000 km3 92 of sea volume of water was observed in a four decade period micklin 1988 pokhrel et al 2017 which has been attributed to large scale river diversion and an increase in consumptive water use for irrigation within the drainage basins aghakouchak et al 2015 micklin 2010 1988 pokhrel et al 2017 tan et al 2017 as the desiccation of the aral sea remains to be one of the very greatest ecological problems of the twentieth century micklin 1988 water levels in many other inland water bodies around the world are in a persistent decline anda et al 1998 carrera hernandez 2017 coe et al 2009 fao 2011 gross 2017 li et al 2007 macías and lind 1990 swenson and wahr 2009 wurtsbaugh et al 2017 one of such endangered system is the urmia lake in iran which is at an imminent risk of falling victim to the same syndrome that desiccated the aral sea aghakouchak et al 2015 there is a growing body of literature contributing to the ever growing debate on the shrinkage of the urmia lake and its ultimate fate suggesting that the observed depletion of the lake can be attributed to various climatic and anthropogenic factors abbaspour and nazaridoust 2007 aghakouchak et al 2015 arkian et al 2016 delavar et al 2007 delju et al 2013 fathian et al 2014 hassanzadeh et al 2012 madani 2014 zeinoddini et al 2015 while some studies have considered the impacts of growing human land water management activities aghakouchak et al 2015 alizade et al 2018 hassanzadeh et al 2012 shadkam et al 2016 zeinoddini et al 2015 most others have focused only on the climatic factors particularly precipitation and temperature arkian et al 2016 delavar et al 2007 delju et al 2013 fathian et al 2014 hence leaving a gap in the thorough understanding of the combined effects of climatic and human factors arkian et al 2016 investigated the climate data from four meteorological stations in the lake basin for 1965 2010 period and found a correlation of 0 69 between the changes in precipitation and lake level this correlation was found to be even higher during the period of 1990 2005 a similar study conducted by delju et al 2013 showed that mean precipitation decreased by 9 2 and average maximum temperature increased by 0 8 c from 1964 to 2005 likewise using water budget multiple regression and artificial neural networks approaches on a monthly scale delavar et al 2007 concluded that the decrease in precipitation had larger effects on urmia lake s water level variation than the decrease in input discharge fathian et al 2014 studied the trends in the time series of hydro climatic variables of urmia lake basin for the period of 1960 2007 and suggested that lake depletion can be connected to both the temperature increase in the basin and the over exploitation of the water resources some other studies have examined the impacts of anthropogenic factors on the depletion of urmia lake which are not considered in the aforementioned studies that focused on the climatic factors for example hassanzadeh et al 2012 simulated the basin hydrology using a system dynamics model and suggested that the changes in inflows due to climate change and surface water exploitation construction of four dams in the upstream watersheds and reduced precipitation are responsible for 65 25 and 10 of the total desiccation of the lake respectively abbaspour and nazaridoust 2007 also highlighted the importance of river discharge to the lake s water balance using a hydrodynamic model likewise alizade et al 2018 investigated the water budget of the lake and concluded that anthropogenic factors contributed to 80 of lake volume decline whereas shadkam et al 2016 showed climate change as the main contributor to the depletion suggesting that anthropogenic factors such as irrigation withdrawal played a relatively minor role the aforementioned studies have provided crucial insights on the ongoing changes in the water balance of urmia lake and its basin but river flow which accounts for the majority of water input to the terminal lake has not yet been thoroughly investigated previous studies such as aghakouchak et al 2015 have emphasized the need for direct water budget assessment and quantification of the anthropogenic influence on the water cycle rather than relying on the attribution to prolonged droughts and climate change to fill this gap here we provide a comprehensive analysis of the combined effects of climatic and anthropogenic factors on the water balance of urmia lake with a particular focus on the changes in water use within the basin and the resulting impacts on the river inflow to the lake specifically this study presents how climate change and anthropogenic exploitation of land and water resources in the watershed contributed to the desiccation of urmia lake over the modeling period of 1980 2010 it contributes to the debate on the anthropogenic impact on urmia lake watershed by interpreting the scale of impact from medium resolution land use land cover lulc maps and a global land surface model lsm which accounts for human water management activities the results from the lsm provide a comparative study of urmia lake basin with and without human activities the specific objectives are to 1 investigate the changes in meteorological conditions and its impact on the lake 2 map the changes in land use patterns due to expanding agricultural activities within the watershed 3 assess the changes in terrestrial water storage tws within the basin and its impact on the shrinkage of the lake and 4 examine how the increase in irrigation water requirement affected the inflow to the lake these objectives provide the structural sub headings used in the following methods results and discussions sections 2 study site data and model 2 1 study site urmia lake located in northwestern iran is one of the largest hypersaline lakes in the world until it began rapidly desiccating in the late 20th century ghaheri et al 1999 it was the world s second largest hypersaline lake alizade et al 2017 and the 20th largest lake by area emdadi et al 2016 several aspects of urmia lake such as chemistry and morphology are analogous to that of the great salt lake in the united states and the dead sea in the middle east alizade et al 2017 the lake surface area varied between 5200 and 6000 km2 during the last few decades of the 20th century tourian et al 2015 based on the precipitation data from 1973 to 2011 the average annual mean precipitation over the basin is 352 mm year farajzadeh et al 2014 and the air temperature usually ranges between 0 and 20 c in winter and up to 40 c in summer eimanifar and mohebbi 2007 the lake has the maximum and average depth of 16 m and 5 m respectively alesheikh et al 2004 the drainage basin with a total area of 52 000 km2 is home to several metropolitan cities in iran such as tabriz urmia and miandoab alipour 2006 the basin drains into the lake through thirteen main rivers alipour 2006 ghaheri et al 1999 more than three dozen dams have been built on these river systems to divert water for agricultural and other uses within the basin the alavian mahabad nahand and zarrinehrood are some of the major dams which have a combined total capacity of 1076 million m3 hassanzadeh et al 2012 the lake is a home to artemia known as brine shrimp the lake s most important creature and a food source for thousands of migratory birds abbaspour and nazaridoust 2007 eimanifar and mohebbi 2007 2 2 meteorological data we obtained the weather station data of air temperature and precipitation from the islamic republic of iran meteorological organization irimo for four stations within the watershed namely tabriz urmia maragheh and sarab as the ground observation data was obtained only for four weather stations the spatial distribution of the data was limited to overcome this data gap and achieve the desired spatial distribution required for further analysis we obtained satellite based and gauge satellite merged global precipitation data from various sources including the precipitation estimation from remotely sensed information using artificial neural networks persiann sorooshian et al 2014 global precipitation climatology project gpcp adler et al 2003 and global precipitation climatology center gpcc becker et al 2011 and compared them with the available weather station data to select the most reliable satellite products for the region among the examined global precipitation products we found the gpcc data to be of the highest compatibility with the precipitation record for four weather stations mentioned above therefore we use the gpcc data for our analysis for air temperature we use the data from the irimo weather stations because no other reliable datasets are available at the desired spatial scale 2 3 landsat imagery and modis landcover product the land use change analysis in this study is done using the satellite imageries from landsat 5 tm and landsat 8 oli obtained from the earth explorer interface of united states geological survey usgs in total eight images are required to cover the entire urmia lake watershed due to limited data availability and high number of images per year lulc maps are generated only for years 1987 1998 2006 2011 and 2016 landsat 5 tm imagery is used for the years 1987 1998 2006 and 2011 and landsat 8 oli for 2016 since the focus of this study is on the changes in agricultural land use than on other land use types it is important to carry out the land cover change analysis during the crop growing season therefore to ensure that the agricultural intensification is captured in the time series of land use and land cover change we use the landsat imagery only for the month of september when the crops are completely matured in the study region all the images obtained were raw images consisting of digital number dn the modis land cover type product mcd12q1 was used to independently evaluate the land use maps obtained from the classification of landsat imagery explained above this land cover product is derived from observations spanning over a year s input of terra and aqua modis data and was downloaded from the land processes distributed active archive center lpdaac website https lpdaac usgs gov at 500 m resolution the original files were re projected from sinusoidal projection system to geographical co ordinate system gcs 2 4 grace data gravity recovery and climate experiment grace derived tws variations are used to validate the trend in the simulated tws change as well as the seasonal cycle of tws variations we use grace solutions of equivalent water height thickness provided by 3 processing centers namely i jet propulsion lab jpl at california institute of technology ii the center for space research csr at university of texas at austin and iii the german research center for geoscience gfz http grace jpl nasa gov data get data for model evaluation landerer and swenson 2012 we also use two mascon products from csr and gfz which have been suggested to better capture tws signals in many regions save et al 2016 scanlon et al 2016 watkins et al 2015 various corrections are needed to isolate the tws signal from grace measurements but the data obtained was already corrected including atmospheric mass changes removal glacial isostatic adjustment gia truncation of spherical harmonic coefficients and application of destriping filter alongside with a 300 km gaussian smoother hence eliminating the need for further processing as the data are in 1 degree resolution with varying grid cell area an area weighted arithmetic mean is calculated following felfelani et al 2017 2 5 hydrological model the model we use is an integrated global land surface model called the higw mat which simulates all vegetation soil and runoff processes on a physical basis pokhrel et al 2015 it incorporates human impact hi and a groundwater pumping scheme gw into the process based global lsm minimal advanced treatments of surface interaction and runoff matsiro takata et al 2003 higw mat routes the runoff generated from each grid cell through the river network using the total runoff integrating pathways trip oki and sud 1998 four anthropogenic water regulation modules namely the crop growth and irrigation scheme reservoir operation module hanasaki et al 2006 water withdrawal module and environmental flow requirement module have been integrated into higw mat which are described in detail in pokhrel et al 2012a higw mat also includes a dynamic groundwater scheme koirala et al 2014 and a pumping scheme pokhrel et al 2015 details of the latest version of the model can be found in pokhrel et al 2016 2015 the simulations we use in this study are based on pokhrel et al 2015 and felfelani et al 2017 conducted at the global scale 3 methods the methodology used in this study employs analysis of remote sensing data and the results from an integrated hydrological model with human impact assessment capabilities the remote sensing data and model are described in sections 2 3 and 2 5 respectively the trends in the simulated tws and river flow and the observed lake volume are examined by using linear regression we use mann kendall statistics ʈ and p values at 5 significance level to determine the significance of the trend in these variables kendall 1975 mann 1955 the methods employed for each of the analyses are described in the following subsections 3 1 climate variations and lake dynamics the contribution of climate variations to lake dynamics is examined by conducting a correlation analysis between the meteorological variables i e precipitation and temperature data from weather stations and the observed lake level we use the standardized precipitation index spi mckee et al 1993 to examine climate change and variability during the period of 1980 2010 3 2 land cover change analysis we perform a pixel classification on the obtained imagery to generate historical land use maps of the region which is a widely used approach alves et al 1996 comber et al 2012 congalton et al 1983 rhemtulla et al 2007 valeriano et al 2004 vogelmann et al 2001 necessary radiometric corrections which include converting dn to radiance and radiance to surface reflectance using parameters such as earth sun distance zenith angle low gain and high gain values are applied individually before performing pixel classification five years of clear and almost cloud free landsat images are selected to classify the study area the classification scheme used in this study comprised of seven classes shown in table 1 an unsupervised classification approach using the isodata algorithm is used to classify each imagery into seven classes post classification corrections are applied to the produced lulc maps to reduce the classification errors due to spectral similarities using a rule based models in erdas software and manual inspection for example the pixels within the city limit classified as agricultural areas are changed to natural vegetation and the pixels which comprised of cloud shadows are changed to bare soil due to the lack of field data for the accuracy analysis of the above mentioned classification approach reference data is obtained from google earth random points are created and assigned to the 7 classes using the high resolution imagery in google earth accuracy is measured for each classification using a statistical analysis software package in envi that performs a pixel by pixel comparison of the classifications with the reference data the result is a confusion matrix which identifies percentage correct errors of commission pixels assigned to a specific class to which they do not belong and errors of omission pixels that should have been assigned into a specific class and were not in addition to a standard pixel by pixel accuracy assessment the khat or kappa statistic is also calculated which has been proven to be a strong estimator of classification accuracy conese et al 1993 stehman 1996 vogelmann et al 1998 3 3 terrestrial water storage and streamflow analysis the newly developed model in the fully integrated mode simulates surface and subsurface water flows by considering the processes of runoff routing reservoir operation irrigation water withdrawals environmental flow requirements groundwater table dynamics and well pumping the model employs a 1 1 spatial resolution for the entire study area and quantifies the impact of human activities on streamflow generated in the watershed which is a major source of water for urmia lake hence quantifying the human influence on the lake level dynamics the model results have been extensively validated at different temporal scales and locations in previous studies koirala et al 2014 pokhrel et al 2017 2015 2012a 2012b but as the hydrological model performance is known to vary by geographic location here we briefly evaluate some of the hydrological fluxes such as tws and streamflow for the urmia lake region we use the tws data derived from grace satellite mission see section 2 4 and the surface water inflow to lake from hassanzadeh et al 2012 since urmia lake basin has an area of 52 000 km2 which is smaller than the grace footprint of 200 000 km2 longuevergne et al 2010 we use a larger domain to conduct the tws comparison with grace we use the domain size with an area of 355 500 km2 by including the areas on all sides of the basin note that the choice of a larger domain for this purpose doesn t alter our analysis because 1 these results are only used to evaluate model results over urmia lake basin and 2 as noted by lorenz et al 2014 and yi et al 2017 the spatial resolution is not the only factor to be considered in grace while studying smaller catchments but the signal strength is also a major one in tws variations thus we use grace data for evaluating the tws signal over a larger domain and employ model results for the detection of long term trend in tws only for the urmia lake basin 3 4 historical irrigation water requirement the higw mat model simulates irrigation water requirements iwr however the irrigation scheme uses global datasets for crop parameters and irrigated attributes meaning that the results may contain uncertainties when used for specific regions therefore to add further confidence on our finding that irrigation which is the major human activity affecting the water balance in the urmia lake basin increased substantially over the period of 1980 2010 we use a process based approach to independently estimate historical irrigation water requirements the approach to estimate iwr is based on the formulations provided in allen et al 1998 in which crop evapotranspiration is calculated using the widely used fao penman monteith approach cai et al 2007 yang et al 2016 yoo et al 2008 this approach employs procedures for calculating reference crop evapotranspiration and crop water requirements and allows the simulation of crop water use under various climate and crop conditions the following water balance equation is used to calculate the irrigation water requirement for the identified irrigated regions from the land use maps developed in this study 1 niwr et r k c p eff where niwr is the net irrigation water requirement mm year etr is the reference crop evapotranspiration mm year kc is the crop co efficient and peff is the effective precipitation mm year calculation of etr using the fao penman monteith method requires meteorological variables including air temperature humidity shortwave radiation net longwave radiation wind speed as well as the latitude and elevation defined per mcvicar and körner 2013 due to the lack of high resolution and temporally complete meteorological data for the study region we use 6 h atmospheric reanalysis data provided by japanese meteorological agency jma climate data assimilation system jcdas we interpolate the jma reanalysis data into 900 m 900 m grids to compute irrigation water requirement we use the elevation data derived from the srtm 1 arc second dataset https earthexplorer usgs gov effective precipitation is computed using the usda soil conservation service scs method the model is run with an assumption that all the irrigated areas have the same crop at a time only wheat and barley with their standard crop coefficients are considered as they are known to be the major crops grown in the region bannayan et al 2011 beheshti tabar et al 2010 4 results 4 1 climate variation and lake dynamics the analysis of precipitation time series over urmia lake region indicates a decreasing trend in annual precipitation during the period of 1980 2010 fig 1 a the highest annual precipitation over the region occurred in 1993 and 1994 which amounted to 612 mm year and 605 mm year respectively which is followed by relatively dry years minimum precipitation recorded is 300 mm year in years 1999 and 2008 similarly low precipitation spells of around 350 mm year are observed in years 1989 and 1990 as well the spi values indicate the severity of the precipitation events with the index of 2 6 for the year 2008 and that of 2 3 for the year 1999 fig 2 the peaks in precipitation over the region before 1995 fairly match with the peaks in lake levels with a slight delay which can be attributed to the time required for the water from the entire basin to reach the lake fig 1b for example the effect of high precipitation during year 1994 is reflected in the lake level in year 1995 4 2 land cover change analysis next we examine the historical changes in land use pattern particularly focusing on agricultural expansion within the watershed and the decline in lake area fig 3 displays the spatial and temporal changes in six major land cover types in the urmia lake region at the spatial resolution of 30 m for years 1987 1998 2006 2011 and 2016 along with a general comparison with other land use datasets such as history database of the global environment hyde 3 1 klein goldewijk et al 2011 and the land cover product from modis imagery section 2 3 each map consists of eight landsat scenes mosaicked and clipped to the watershed boundary major transitions between different land cover types are observed in the urmia lake watershed between 1987 and 2016 the decline in surface water in the entire lake basin is found to be 77 out of which 86 is caused by urmia lake itself between 1998 and 2016 fig 4 the rate of this decline is found to be consistent with the rate reported by other studies aghakouchak et al 2015 as seen in fig 4 both cropland and urban classes show a steep positive trend from 1987 to 2016 which can be directly correlated to the anthropogenic activities within the watershed urban areas in the watershed have increased by 180 with a corresponding increment of 98 in the agricultural land further an accuracy assessment of the generated lulc maps is performed using point data derived from google earth for year 2016 a pixel by pixel comparison resulted into a confusion matrix shown in table 1 a total of 1170 reference points is used for accuracy assessment the overall accuracy is found to be of 81 62 and kappa coefficient of agreement khat of 0 76 is achieved for this classification this assessment is only conducted for year 2016 due to lack high resolution google earth imagery for the previous years further the classification accuracy for all the years can be expected to be in the same range as the methodology used for classifying all imagery in this study has been consistent throughout 4 3 terrestrial water storage and streamflow analysis fig 5 a shows the comparison of anomalies of tws obtained from grace and simulated by higw mat model it is evident from the figure that the model captures the long term trend of tws within plausible limits with a generally good agreement for most years underestimations during the first few years and overestimations during the last years can be attributed to the uncertainty in the forcing data and the human impact simulations the results for the preceding years could not be validated due to the lack of tws data fig 5b shows a rather accurate comparison between the seasonal variations of simulated and grace based tws while the model grace agreement varied over time between the spherical harmonics and mascon products fig 5a the model compared better with mascon products for the seasonal cycle fig 5b fig 6 shows the temporal tws variations from the model for the entire modeling period i e 1980 2010 annual tws in the urmia lake basin is highly variable and as the lake is the largest water body in the basin tws has a strong dependence on the changes in lake volume the peaks in simulated tws and lake volume match very well in the first half of the modeling period as shown in fig 6 but for the later years tws variations show less dependency on the changes of lake volume this behavior points toward an external influence causing the lake to dry faster than the entire basin in 1995 the time series shows the highest amount of tws over the watershed which corresponds to the highest precipitation and lake volume during the modeling period in the years before 1995 the lake gained water steadily at a rate of 0 58 0 15 km3 year ʈ 0 55 p 0 002 due to high precipitation and less human influence causing tws to show an increasing trend of 1 10 0 17 km3 year ʈ 0 7 p 0 0001 in those years the difference between the trends in lake volume and tws before 1995 also indicates the presence of a major water storage component apart from the lake body however after 1995 both the lake volume and tws over the region continue to decrease at a rate of 1 81 0 22 km3 year ʈ 0 983 p 0 0001 and 2 21 0 21 km3 year ʈ 0 733 p 0 0001 respectively in 2003 tws trend shows a considerable increase in magnitude which can be attributed to high precipitation however no changes are seen in the trend of lake volume during the same period overall for the entire modeling period tws shows a decreasing linear trend of 0 32 0 14 km3 year ʈ 0 226 p 0 072 to add further confidence in the model results we compare the simulated river flow with the streamflow data obtained from hassanzadeh et al 2012 because no long term flow observations are available hassanzadeh et al 2012 carried out a water balance analysis to estimate the streamflow data the simulated river flow compares well with the estimated values for the period of 1980 2010 fig 7 the primary objective of this comparison is to ensure that model simulates the river flow within the plausible limits for the urmia lake watershed the slight discrepancies between the declining trend in the estimated i e 0 10 0 04 km3 year hassanzadeh et al 2012 and simulated i e 0 07 0 04 km3 year river flows can be attributed to the lack of detailed irrigation parameterization in the global lsm the simulated river inflow into urmia lake with and without human impacts from higw mat model is displayed in fig 8 in both simulations the inter annual variability of river flow is largely governed by the changes in the meteorological factors high inflow values for both the simulations are in years 1988 and 1995 because of high precipitation and lower temperatures fig 1b and remained low in 1990 and 1999 due to a severe drought period in 1998 the difference in inflow from the two simulations is found to be high in the years after 1998 corresponding to the increased anthropogenic activity namely agricultural activities and dam constructions in the watershed during the earlier years less agricultural activities and favorable climatic conditions resulted in a relatively small difference between the inflows from the two simulations indicating less water withdrawal from rivers however in the latter half the difference is found to be very high compared to the preceding years indicating heavy human influence on river discharge this change can be attributed to the changes in irrigation demand and dam construction in the basin 4 4 historical irrigation water requirement as noted in section 3 4 the results displayed in the previous section are from a global model that used global datasets for the simulation of human impacts on streamflow including the estimation of irrigation water use which could have contained uncertainties due to the use of coarse resolution input datasets thus to independently verify the historical irrigation water use we estimated and examined the irrigation water requirement over the basin at the grid resolution of 900 m 900 m section 3 4 the computed annual net irrigation requirement niwr for the entire basin is shown in fig 9 the results are in general agreement with other estimates obtained from previous studies for example hesami and amini 2016 estimated the irrigation water requirement of the miandoab alluvial plain using the cropwat model as 0 67 km3 and 0 89 km3 for the year 1989 and 2000 whereas from this study the estimates are 0 73 km3 and 1 02 km3 respectively also the average niwr for the region is estimated as 760 mm year which falls in the range of 400 800 mm year as categorized by döll and siebert 2002 the difference in niwr values reported in this study and the previous studies can be attributed to the use of different input data and irrigated areas as well as the uncertainties in these datasets the results further confirm that niwr increased consistently in urmia lake region over the modeling period which can be attributed to the increase in irrigated areas with low irrigation efficiency a prominent increase in niwr can be seen during the 2007 2008 period which corresponds to the period of low precipitation and high temperatures overall niwr almost tripled during the period of 1980 2010 5 discussion 5 1 climate variation and lake dynamics it is evident from the time series correlation of precipitation over the entire basin and the variations in the lake level that the abrupt decline in urmia lake level is consistent with the decrease in precipitation in the year 1995 fig 1b it should be noted that the correlation is calculated using the mean lake level during the particular year the correlation of annual change in lake levels with precipitation and temperature are 0 15 and 0 36 respectively for the entire modeling period the annual lake level variations appear to be governed by the precipitation only for half of the modeling period i e until year 1995 with a correlation coefficient of 0 5 after 1995 the lake level shows rather weak correlation of 0 12 with precipitation despite considerable increase in precipitation in the year 2003 and 2006 the lake level continues to drop abruptly as opposed to precipitation the correlation between temperature and lake level improves from 0 15 to 0 28 in the period of 1995 2010 given the increase in observed temperature after 1995 fig 1 higher rates of evaporation over the lake can be expected however these changes in evaporation and other meteorological variables are already incorporated in the simulated river flow as discussed in section 5 3 further trends in the forcing data used to drive the hydrological model section 2 5 corroborates the declining trend in wind speed discussed in arkian et al 2016 and indicates no trend in specific humidity over the same period this indicates the dominance of other governing factors on water level of urmia lake which could be due to the major human influence on the hydrology of the lake basin 5 2 land cover change analysis the land cover change analysis suggests that anthropogenic activity in urmia lake basin increased considerably during the period from 1987 to 2016 especially in the form of agricultural expansion some previous studies have estimated the change in agricultural and irrigated areas in urmia lake region but a direct comparison pixel to pixel cannot be made due to the differences in the methodology used for estimation for example alizade et al 2017 used an ndvi based classification to map the irrigated areas in the basin but their estimates were validated over a larger region than the lake basin considered in this study the agricultural expansion which is in line with the findings from previous studies alizade et al 2017 and the changes in precipitation and temperature resulted in an increased water demands that led to the development of many dams and diversion projects in the basin hassanzadeh et al 2012 the increase in man made reservoirs can be clearly seen in fig 3 left column increasing open water areas over the basin 5 3 terrestrial water storage and streamflow analysis the simulated tws trend fig 6 suggests that the rate of loss of water from the lake was much higher than the rate of change in tws during 1995 2010 as urmia lake is a major water body in the watershed these results indicate that 0 4 0 01 km3 of water is being stored somewhere else in the watershed other than the lake every year the possible reasons for this trend behavior might be because of an increased leakage of lake water to the underlying aquifer or the ongoing water resources management activities in the watershed such as the construction of new dams here we discuss the second scenario consisting the impact of increased water management activities on streamflow any water management activity such as dam construction or diversion of surface water for irrigation purposes would prevent a normal inflow into the lake causing lake depletion this appears to be the most probable case given the rate of depletion and the increase in agricultural activity in the watershed storage of water behind dams can explain the difference between the depletion rate of lake and tws of the region the cumulative difference in inflows fig 8 between the two simulations after 1995 is found to be 28 km3 which suggests 86 of the change in lake volume is due to direct human influence on river flow in the basin based on model results before 1995 the difference between the two simulations is found to be 12 km3 indicating the presence of human influence even before the catastrophic depletion in the urmia lake however favorable climatic conditions and less water withdrawals may have offset this human influence avoiding a major depletion in lake volume in the absence of the major precipitation events in 1993 and 1994 the depletion in lake volume would have been observed much before than 1995 it should be noted that higw mat model computes all the water balance components on a physical basis hence the river flow simulated by the model provides an integrated effect of changes in all the meteorological variables along with human impacts there could be some discrepancy in the quantification of human influence caused by the uncertainty in the forcing datasets and human impact modules further it should be noted that the model used is an offline lsm which does not account for human influence on regional land atmosphere interactions a fully coupled high resolution model with human impact assessment capability is needed to better attribute the observed changes in lake volume to different factors improving human impact simulations by better representing the source of water use e g hanasaki et al 2018 is also an important future research direction for studying such depleted systems despite certain limitations arising from the use of a global model our results provide important insights on the direct human influence on river flow and the resulting consequences on lake level decline 5 4 historical irrigation water requirement the results from an independent and fine grid i e 900 m simulations of irrigation water requirements indicate that niwr almost tripled between 1980 and 2010 fig 9 it should be noted that these estimates are that of the net irrigation water requirements given the low irrigation efficiency in the region as reported by previous studies ahmadzadeh et al 2015 hassanzadeh et al 2012 hoseinpour 2010 the actual withdrawals per year could have been significantly higher than the calculated niwr the increase in total irrigated area in lake basin fig 4 and the corresponding increase in niwr fig 9 created a high demand for development of water resources management activities in the basin and increased consumptive withdrawals mainly for irrigation purpose this increase in niwr explains the difference between inflow to the lake under natural and human impacted condition as shown in fig 8 however the irrigation withdrawals before 1995 did not significantly impact the inflow to the lake because the irrigation water use was offset by higher precipitation rates fig 1 after 1995 however the expansion in the irrigated areas and a precipitous decline in precipitation in the region caused an increase in withdrawals hence reducing the river discharge considerably although the niwr values from this study compare well with the ones reported in previous studies döll and siebert 2002 hesami and amini 2016 they may contain uncertainties due to the uncertainties in different input datasets further we note that our irrigation water use analysis section 4 4 was carried out assuming that all agricultural lands were irrigated because detecting irrigation attributes using remote sensing data was beyond the scope of the present study future studies should consider more advanced remote sensing algorithms e g chen et al 2018 to detect time series irrigated areas for the better estimation of irrigation water use and its spatio temporal dynamics 6 conclusion our results suggest that both climate and anthropogenic factors played roles in the changes in volume of urmia lake during 1980 to 2010 but the abrupt decline in lake volume from 1995 to 2010 was primarily caused by the accelerated human water management activities land use land cover change analysis for 1987 to 2016 indicates that the acceleration in human activity in the basin is primarily due to an expansion of agricultural lands which increased by 98 causing a 3 fold increase in irrigation water needs further using the results from two versions of the hydrological model one with and the other without human activities it is found that human induced changes in river inflow to the lake accounts for 86 i e 28 km3 of lake volume decline during 1995 2010 period since the human land water management activities are expected to further expand in the future and climate change is likely to adversely impact water supplies it can be anticipated that the desiccation could further accelerate unless certain restoration measures are taken therefore sustainable management of water resources within the watershed is the key for the sustainability of the lake in the coming decades recognizing the need to take immediate actions the recently established urmia lake restoration program ulrp has put forth a plan on policies and course of action required for the stabilization and restoration of the lake toward reaching the ecological level in 10 years see http ulrp sharif ir page urmia lake level although these actions have been proven beneficial for the short term further measures such as reduction in water withdrawals and increase in irrigation efficiency are indispensable to bring the lake back to the long term equilibrium conditions results of this study provide important insights on the key mechanisms that caused the observed depletion in the past which have important implications for future actions to achieve sustainability in the region since the hydrologic results we used are from a global model we highlight the need to carry out regional scale modeling at finer resolution and with better constrained human impact modules to better assess the effects of current restoration program and project future changes under different climate change and water resource management scenarios acknowledgements we thank the editor associate editor and the three anonymous reviewers for providing highly constructive comments that helped tremendously in improving the quality of the paper this study was partially supported by the asian studies center at michigan state university we thank shu guang li and kyla dahlin for their invaluable comments and suggestions on the analyses 
7348,over the past few decades urban floods have been gaining more attention due to their increase in frequency to provide reliable flooding predictions in urban areas various numerical models have been developed to perform high resolution flood simulations however the use of high resolution meshes across the whole computational domain causes a high computational burden in this paper a 2d control volume and finite element flood model using adaptive unstructured mesh technology has been developed this adaptive unstructured mesh technique enables meshes to be adapted optimally in time and space in response to the evolving flow features thus providing sufficient mesh resolution where and when it is required it has the advantage of capturing the details of local flows and wetting and drying front while reducing the computational cost complex topographic features are represented accurately during the flooding process for example the high resolution meshes around the buildings and steep regions are placed when the flooding water reaches these regions in this work a flooding event that happened in 2002 in glasgow scotland united kingdom has been simulated to demonstrate the capability of the adaptive unstructured mesh flooding model the simulations have been performed using both fixed and adaptive unstructured meshes and then results have been compared with those published 2d and 3d results the presented method shows that the 2d adaptive mesh model provides accurate results while having a low computational cost keywords unstructured adaptive mesh urban flood modelling finite element control volume 1 introduction flood disaster is one of the most influential natural hazards in history mascarenhas et al 2005 over the past few decades the frequency of urban flooding has increased due to the increasing urbanization aging sewer networks and climate change threats semadeni davies et al 2008 this has drawn more attention in urban flooding research hence increasing the effort in flood modelling schmitt et al 2004 van dijk et al 2014 borsche and klar 2014 son et al 2016 to provide reliable flooding predictions in urban areas high resolution simulation is essential in order to resolve the complex urban topographic features for example buildings streets and embankments however the high computational burden associated with full hydrodynamic models has restricted their wider applications to real time urban flood modelling for efficient and accurate flood inundation modelling numerous methods including grid coarsening methods hartnack et al 2009 cellular automata approach dottori and todini 2011 and speeding up strategies e g parallel processing have been developed chen et al 2012 used a building coverage ratio bcr and the conveyance reduction factor crf parameters to simplify the key features of building within a coarse grid leandro et al 2014 developed a parallelized two dimensional diffusive wave model p dwave with an adaptive time step using the matlab parallel computing toolbox and fortran openmp application programming smith et al 2015 presented a new hydrodynamic modelling framework and described how a robust finite volume godunov type scheme was implemented and applied it to urban flooding with a high resolution grid parallel computation was achieved with either central processing units cpu or graphics processing units gpu devices the use of a uniform high resolution mesh across the whole computational domain may cause the simulation to run in an unacceptably slow speed chen et al 2007 it is desirable to apply fine meshes only in specific regions for example where complex dynamical flows shock waves eddies etc occur while coarse meshes are used in the rest of the computational domain especially in the area where inundation has not yet occurred zhou et al 2013 adaptive mesh refinement amr a fine structured mesh nested within a coarse mesh technique was developed by berger and oliger 1984 and berger and colella 1989 george 2011 applied the amr technique to dam break flow modelling an extension of amr using the adaptive quadtree grids approach was proposed and tested using different numerical schemes liang et al 2004 liang 2012 wang and liang 2011 popinet 2012 huang et al 2015 further applied amr to coupled flood and sediment transport modelling in this work we have introduced an advanced optimization based adaptive mesh technique pain et al 2001 to flooding modelling in comparison to amr locally nested static mesh methods this adaptive unstructured mesh technique can dynamically modify and adapt the mesh to achieve a desired level thus better capturing transient and complex flow dynamics as the flow evolves using the optimization based adaptive technique the mesh nodes can either be increased or decreased locally in time and space h adaptive technique with a good solution accuracy piggott et al 2005 or optimally relocated r adaptive technique to resolve the small scale flow features in a domain of interest e g features of flow around buildings this dynamically adaptive mesh technique has been applied to idealistic oceanic cases without real bathymetry and topography air pollution multiphase flows and reservoir modelling du et al 2016 zheng et al 2015 su et al 2015 xie et al 2017 jackson et al 2015 this is the first time to apply this optimization based adaptive mesh technique to flooding modelling unstructured meshes are used for optimal representation of complex domain geometries and boundaries one of key issues in flooding modelling is the representation of wetting drying wd fronts as reviewed in medeiros and hagen 2013 simulating the wd front over a real domain is still nontrivial due to the fact that accurate solutions requiring high spatial and temporal resolutions are unstable and computationally expensive the use of adaptive meshes enables the models to capture the physics of an advancing or receding wetting front better while keeping the computational cost low in this work our newly developed 2d double control volume finite element cv fe shallow water model together with the adaptive unstructured mesh technique has been successfully applied to the glasgow s urban flooding event of 2002 the performance of adaptive unstructured meshes in flood modelling has been evaluated the adaptive mesh simulations provide comparable results to the higher resolution 2d 3d fixed mesh simulations whilst reducing a 20 84 the computational cost the structure of this paper is presented as follows in section 2 the flooding model and the adaptive unstructured mesh techniques are introduced section 3 demonstrates the application of the model to a flooding event in glasgow scotland united kingdom in detail it describes the study site and geospatial data used for modelling and specifies boundary conditions and parameter settings section 4 presents and discusses the 2d adaptive mesh modelling results by comparing with 2d fixed mesh results and 2d 3d published results finally some conclusions and future work are given in section 5 2 methodology 2 1 governing equations 2 1 1 shallow water equations in flooding modelling the water depth is much smaller than the horizontal dimensions of the water body therefore the hydrodynamics of flooding flows can be suitably described by the shallow water equations swes in a matrix form the swes may be written as follows 1 q t f x w y s where t is the time x and y the cartesian coordinates q the vector representing the flow variables f and w the fluxes in the two cartesian directions and s is the source term vector the vector terms are given by liang and borthwick 2009 2 q η uh vh f uh u 2 h g η 2 2 η z b 2 uvh 3 w vh uvh v 2 h g η 2 2 η z b 2 and s 0 τ bx ρ g η z b x τ by ρ g η z b y where η denotes the water level and z b is the bed elevation above datum h η z b is the water depth u h is the velocity vector and u and v are the two depth averaged velocity components g is the constant gravitational acceleration ρ is the water density z b x and z b y define the bed slopes in the x and y directions τ bx and τ by are bed friction stresses calculated by 4 τ bx ρ c f u u h and τ by ρ c f v u h where c f is the bed roughness coefficient drag coefficient the numerical method used here is based on the double control volume finite element method presented in salinas et al 2017 here a cv free surface height is used this is mass conserving and robust to highly distorted elements this method is a variation of the well known control volume finite element method jackson et al 2015 gomes et al 2016 forsyth 1989 geiger et al 2004 matthai et al 2007 for the time discretization an implicit θ method is considered here θ varies between 0 5 crank nicholson and 1 implicit euler based on a tvd scheme total variation diminishing to stabilize the shallow water momentum equations we use a non linear petrov galerkin method which introduces a diffusion term proportional to the residual of the momentum equations however since it is a residual scheme petrov galerkin scheme it is mathematically consistent and converges to the governing equations as the grid and time step size are refined this provides for example the robustness needed when there are sharp changes in the velocity fields that can occur near wetting and drying fronts 2 1 2 drag coefficient a commonly used bottom stress parameterization is the manning strickler formulation 5 n ν u h n m 2 g u h u h h 1 3 on γ bottom in which n is the unit normal to the bottom surface γ bottom ν is the kinematic viscosity h is the water depth and n m is the manning coefficient the formulation for the volumetric drag coefficient c f is 6 c f n m 2 g u h max h h min 1 3 to avoid divisions by zero a minimum depth h min needs to be specified in our numerical experiments we tested values ranging from 10 8 to 10 3 without very significant differences between them finally the value of 10 5 was chosen this value was chosen as we wanted to reduce the non linear behaviour that using h min in the denominator introduces in this way 10 8 was the value that may introduce more numerical issues on the other hand using 10 3 meant that we would be considering a layer of 1 mm of water in dry areas which seemed unphysical thus 10 5 was the best option as considering a layer of water of 0 01 mm in the dry areas is physically plausible just with the moisture of the air while also reducing the non linearity introduced by a number such as 10 8 2 2 adaptive mesh techniques the dynamically adaptive unstructured mesh technique developed by pain et al 2001 is utilized here this method has the advantage of capturing details of surface and local flows wetting drying front during the process of flooding modelling it can efficiently provide a high mesh resolution where and when it is needed that is finer meshes are placed only in specific regions where the variations of flow variable solutions are relatively large e g flow around buildings and along the flooding paths while coarser meshes are used in areas far from these regions where inundation has not yet occurred for example the optimization based adaptive mesh technique used here relies on the derivation of appropriate error measures which dictate how the mesh is to be modified pain et al 2001 the error measure employed is based on the curvature of variable solutions and provides a directional measure by using a riemannian metric to calculate the element size and shape the mesh is adapted to have a uniform interpolation error in any direction this mesh optimization method requires an error measure in the form of a defined metric tensor the metric is derived from a solution field variable and an error norm based on the interpolation error pain et al 2001 thus the metric m defined as 7 m γ h where γ is a scalar constant and γ 1 is used here is a required interpolation error and h is the hessian matrix for a specified field ψ ω here the field of water depth 8 h 2 ψ x 2 2 ψ y x 2 ψ x y 2 ψ y 2 the desired edge length h i in the direction of the i th eigenvector e i of the metric m is defined as h i 1 λ i where λ i is the eigenvalue associated with e i power et al 2006 to take into account maximum and minimum element sizes m is modified and defined as 9 m v t λ v where the rotation matrix v contains the eigenvectors of the metric m given by eq 7 the eigenvalues are modified as follows pain et al 2001 10 λ j max λ j 1 a 2 max i 1 2 3 λ i j 1 2 3 where 11 λ j min 1 h min 2 max λ j 1 h max 2 j 1 2 3 in which a is the maximum aspect ratio h min and h max are the minimum and maximum element sizes in this metric space a functional which is used to gauge the shape and size quality of elements is defined a series of the mesh connectivity and node position searches are performed to optimize this functional the mesh modification thus fits the solution field s in an optimal manner the galerkin interpolation technique farrell and maddison 2011 is used for interpolating the solutions from the previous mesh onto the newly adapted mesh however the interpolation error may destroy the conservation of quantities important to the physical accuracy of simulations for example density and water height to keep the conservation of quantities the conservative interpolation operator with an intermediate supermesh is used for details see farrell and maddison 2011 davies et al 2011 shows that adapting every 5 time steps incurs in a 2 extra cost for their simulation since this value slightly varies when solving different problems e g up to 8 the rough figure is that the cost of adapting the mesh is around the same as doing one time step therefore adapting every 10 times steps means an approximate 10 extra cost based on heuristics for this case the mesh is adapted every 10 time steps for the adaptive simulation due to fact that the courant number is never big enough such as the water front leaves the high quality region of the mesh before the mesh is re adapted in general the mesh is adapted more frequently if the flow feature is changed rapidly 3 model application 3 1 descriptions of study site and data to assess the performance of adaptive meshes in flooding modeling the new flooding model has been applied to an urban area located within the city of glasgow scotland uk where a flood event occurred in july 2002 the whole computational domain is 1 0 km by 0 4 km fig 1 this flood is observed as a result of flow exceeding the capacity of the culvert during the period of prolonged or heavy rainfall the culvert is located at the northeast corner of the domain see location q in fig 1 once the capacity of the culvert is exceeded water overspills from the culvert and spreads over the west and south urban area along the main roads the details of hydrographic data can be found in literatures hunter et al 2008 liang et al 2007 the raw lidar data was originally collected by infoterra ltd leicester uk for glasgow city council for hydraulic modelling infoterra aggregated the lidar data and reinserted buildings kerbs and roads to obtain a 2m dem with realistic representation of urban morphologic characteristics hunter et al 2008 the time series of flooding water depth at four detector locations fig 1 obtained by hunter et al 2008 are utilized for model verification in this study fig 2 shows the unstructured meshes created as 2d triangle elements by gmsh geuzaine and remacle 2009 zhang et al 2016 a free finite element grid generator with a build in cad engine and post processor it can be seen how the surrounding mesh of the main street and the branches is refined 3 2 model applications a series of model simulations using both the fixed and adaptive unstructured meshes have been carried out to assess the performance of the new flooding model developed here in these simulations water enters the densely urbanized area from a culvert at location q fig 1 the flood condition has been described earlier as specified by the hydrographic data used in previous studies hunter et al 2008 liang et al 2007 the inflow discharge from the culvert started at t 5 min peaked between 22 and 24 min and ended at t 40 min a fixed time step size δ t 0 15 s is used in all simulations no normal flow boundary condition is enforced at all the external boundaries for mesh adaptivity the aspect ratio of the elements in the adapted mesh is set to 5 for mesh size constraints the maximum and minimum element sizes are 50 and 2 m respectively the mesh is adapted considering the solutions of both the water depth and velocity being the absolute interpolation errors set to 0 05 and 0 14 for the water depth and velocity respectively 4 results and discussion 4 1 water depth and velocity for comparison purposes 3d results from zhang et al 2016 are used as a reference solution in this study these 3d results have been proved to be consistent with 2d published results hunter et al 2008 in the region where the impact of 3d flow structures can be ignored figs 3 and 4 show the results of water depth and velocity from our newly developed 2d flooding model with both the fixed and adaptive unstructured meshes at time levels t 20 30 40 60 min in comparison to those results from 3d modelling zhang et al 2016 they show the flood propagation process over the urban area it can be observed that in most of the inundation area the solutions of water depth and velocity obtained from both 2d fixed and adaptive mesh modelling are in good agreement with those of 3d modelling as seen in fig 4 the flood propagation process is accelerating during 22 24 min when the inflow discharge at location q peaks the water spreads along the main street and branches when t 30 min during the flood recession after t 40 min water accumulates in the low lying areas especially in the southern street area marked with a yellow rectangle in fig 3 the variation of results in the speed and extent of flooding is relatively small after 45 min we therefore discontinue adapting the mesh from this time level and run it with the mesh already generated at this point until the end of the simulation this helps us to save the overhead and extra computational cost introduced during the adaptive mesh procedure generally speaking the 2d adaptive mesh model provides promising results while the number of nodes elements used during the simulation period is significantly reduced by up to 80 of that used by 2d fixed mesh modelling thus reducing the computational cost considerably 4 2 accurate representation of topography using the adaptive mesh technique using 2d adaptive mesh technology the mesh is dynamically adjusted during the process of flood propagation right column in fig 5 finer meshes are placed only in specific regions where the gradients of the flow variables are relatively steep e g flow around buildings fig 7 while coarser meshes are used in areas away from these regions where inundation has not yet occurred it enables the mesh based computing to be efficient and have low computational complexity in this case the topographical data a combination of airborne laser altimeter lidar and digital map data is available with a high resolution of 2 m the availability of high resolution topographical data is important for the accurate numerical simulation of urban food inundation however high resolution topographical data requires a high computational burden thus resulting in a computationally demanding flood modelling using the adaptive mesh technology the resolution of the topographical data can be dynamically adjusted during the process of flood propagation the topographical data over the domain is obtained by interpolating the high resolution 2 m data onto the adapted mesh at each time level therefore the high resolution topographical data is only used in the flooded region while the low resolution data is used in the rest of the domain one of the advantages of 2d adaptive unstructured mesh modelling is that the buildings can be represented accurately when where needed during the flooding process fig 5 shows how buildings gradually appear as the flooding water spreads across the domain fig 6 indicates the error in bathymetries during the simulation period when using adaptive meshes it is seen that the high resolution low error data is used only over the regions along the flood pathway 4 3 comparison with published results at detector locations to further validate our 2d fixed and adaptive unstructured mesh flooding models the time series of water depth at detector locations sta1 sta2 sta3 and sta4 are compared with those of six 2d hydraulic models divast divast tvd jflow lisflood fp trent and tuflow from hunter et al 2008 and the 3d model zhang et al 2016 fig 8 shows the time series of water depth predicted by these models sta1 represents a flat area with surrounding buildings where water accumulates fast but releases slowly during the flood process sta2 is placed in the middle of the main road where the flood water is shallow and moving fast sta3 is located in the low lying area in the southern part of the domain as marked with a yellow rectangle in fig 3 water from the east west oriented main street converges and ponds there in the latter part of the simulation sta4 is sited at the side of the road where the ponding water comes from both north and south directions model performance has been assessed through comparison of the results at these detector locations in fig 8 the black and red lines represent the time series of water depth predicted by the new 2d unstructured mesh flooding model with fixed and adaptive meshes respectively it can be seen that a good agreement is achieved between the results from our 2d adaptive and fixed unstructured mesh models and those from other 2d models at all the detector locations the results of our 2d unstructured mesh modelling results especially with adaptive meshes are very close to the 3d results zhang et al 2016 at sta 1 a flat and ponding area where the vertical velocity is relatively small however there is a large difference between 2d and 3d modelling results at sta 2 where the vertical inertial and non hydrostatic pressure terms are large the impact of 3d flow cannot be ignored zhang et al 2016 compared with the results when using 2d fixed meshes 2d adaptive mesh modelling results at sta 3 match well with those from other 2d models and are closer to the 3d results in general the results between both of our 2d fixed and adaptive mesh models are in a good agreement during t 1 40 min until the flooding peak there is then a difference between them at stas 3 and 4 during the flooding recession after t 40 min compared with the 3d results the time series of water depth using 2d adaptive unstructured meshes is more accurate than that using 2d fixed unstructured meshes at stas 1 3 the main reason for this is that the adaptive mesh is optimised in response to the evolving flow features while the fixed mesh is designed based on the main road network see zhang et al 2016 for both fixed and adaptive mesh modelling a high mesh resolution of 2 m is placed along the main road routes where the dominant flow features are observed however for fixed mesh modelling the meshes are coarser around the building areas than that of adaptive mesh modelling what s more mesh adaptivity ensures a certain precision it is thus seen in fig 8 that at stas 1 3 the time series of water depth using 2d adaptive unstructured meshes is more accurate than that using 2d fixed unstructured meshes while a smaller number of nodes is used during the simulation in general both results of using adaptive and fixed meshes are consistent with those from other 2d models 4 4 performance of 2d fixed and 2d adaptive unstructured mesh flood modelling as seen in table 1 and fig 9 a multi scale unstructured mesh with 2 m 5 m 20 m resolution generated by gmsh fig 2 consists of 28 508 nodes and 56 862 unstructured triangle elements this mesh is used during the whole simulation period for 2d fixed unstructured mesh modelling and used as the initial mesh for 2d adaptive unstructured mesh modelling after first adapting the mesh the numbers of nodes and elements used for 2d adaptive mesh are reduced by 84 and then gradually increased during t 10 45 min as the flooding water spreads over the domain at time level t 40 min the inflow at location q ends and recession of water starts as a result the water accumulates in low areas and the water velocity remains small to avoid the overhead and extra computational cost introduced during the adaptive mesh procedure the mesh is fixed from t 45 min using our 2d unstructured mesh model the cpu time of 300 5 h is required for the fixed mesh simulation and 153 5 h for the adaptive mesh simulation which is only half of the former moreover adapting the mesh dynamically means that there is no need to perform a priori calculations with its corresponding computational cost to estimate the key regions of the domain to place more resolution in those areas above all 2d adaptive unstructured mesh modelling is less computational expensive than 2d fixed unstructured mesh modelling the use of 2d adaptive unstructured meshes improves the computational efficiency to further reduce the computational cost various numerical techniques can be adopted in our flood model for example an adaptive time step scheme and or parallel computing using mpi 5 conclusions a 2d cv fe flooding model with the adaptive unstructured mesh technique has been developed this dynamically adaptive unstructured mesh technique is able to modify and adapt unstructured meshes to better capture the features of flooding flows local flows around the buildings or the wetting and drying front for example while reducing computational cost without sacrificing accuracy of flooding simulations to assess the performance of the adaptive meshes in flooding simulations the new 2d flooding model has been applied to a flooding event that happened in 2002 in glasgow scotland united kingdom where the flood is induced by a stream flow from a culvert at the northeast corner of the domain a comparison between 2d adaptive and fixed mesh models as well as 3d model has been undertaken it has been found that using the 2d adaptive mesh model it is able to provide accurate results while the computational cost is reduced by 20 84 in comparison to 2d fixed mesh models another advantage of 2d adaptive unstructured mesh modelling is that urban topography can be accurately represented when where needed by increasing the mesh resolution around the buildings for example dynamically when the flooding water spreads over the urban area this is the first time to use the dynamically adaptive mesh technique in flooding modelling and assess its performance in a relatively simple flooding event our future work on flood modelling development will focus on complex realistic cases where flooding may occur from more than one source furthermore to reduce the computational cost numerical techniques such as adaptive time step scheme and parallel computing will be investigated acknowledgments the authors acknowledge the support of funding from the european union seventh framework programme fp7 20072013 under grant agreement no 603663 for the research project pearl preparing for extreme and rare events in coastal regions and the epsrc memphis multi phase flow programme grant ep k003976 1 funding for salinas from exxonmobil and epsrc smart geowells grant ep r005761 1 is gratefully acknowledged the authors would like to thank dr ting zhang for providing advice and help in this research no data was generated in the course of this work 
7348,over the past few decades urban floods have been gaining more attention due to their increase in frequency to provide reliable flooding predictions in urban areas various numerical models have been developed to perform high resolution flood simulations however the use of high resolution meshes across the whole computational domain causes a high computational burden in this paper a 2d control volume and finite element flood model using adaptive unstructured mesh technology has been developed this adaptive unstructured mesh technique enables meshes to be adapted optimally in time and space in response to the evolving flow features thus providing sufficient mesh resolution where and when it is required it has the advantage of capturing the details of local flows and wetting and drying front while reducing the computational cost complex topographic features are represented accurately during the flooding process for example the high resolution meshes around the buildings and steep regions are placed when the flooding water reaches these regions in this work a flooding event that happened in 2002 in glasgow scotland united kingdom has been simulated to demonstrate the capability of the adaptive unstructured mesh flooding model the simulations have been performed using both fixed and adaptive unstructured meshes and then results have been compared with those published 2d and 3d results the presented method shows that the 2d adaptive mesh model provides accurate results while having a low computational cost keywords unstructured adaptive mesh urban flood modelling finite element control volume 1 introduction flood disaster is one of the most influential natural hazards in history mascarenhas et al 2005 over the past few decades the frequency of urban flooding has increased due to the increasing urbanization aging sewer networks and climate change threats semadeni davies et al 2008 this has drawn more attention in urban flooding research hence increasing the effort in flood modelling schmitt et al 2004 van dijk et al 2014 borsche and klar 2014 son et al 2016 to provide reliable flooding predictions in urban areas high resolution simulation is essential in order to resolve the complex urban topographic features for example buildings streets and embankments however the high computational burden associated with full hydrodynamic models has restricted their wider applications to real time urban flood modelling for efficient and accurate flood inundation modelling numerous methods including grid coarsening methods hartnack et al 2009 cellular automata approach dottori and todini 2011 and speeding up strategies e g parallel processing have been developed chen et al 2012 used a building coverage ratio bcr and the conveyance reduction factor crf parameters to simplify the key features of building within a coarse grid leandro et al 2014 developed a parallelized two dimensional diffusive wave model p dwave with an adaptive time step using the matlab parallel computing toolbox and fortran openmp application programming smith et al 2015 presented a new hydrodynamic modelling framework and described how a robust finite volume godunov type scheme was implemented and applied it to urban flooding with a high resolution grid parallel computation was achieved with either central processing units cpu or graphics processing units gpu devices the use of a uniform high resolution mesh across the whole computational domain may cause the simulation to run in an unacceptably slow speed chen et al 2007 it is desirable to apply fine meshes only in specific regions for example where complex dynamical flows shock waves eddies etc occur while coarse meshes are used in the rest of the computational domain especially in the area where inundation has not yet occurred zhou et al 2013 adaptive mesh refinement amr a fine structured mesh nested within a coarse mesh technique was developed by berger and oliger 1984 and berger and colella 1989 george 2011 applied the amr technique to dam break flow modelling an extension of amr using the adaptive quadtree grids approach was proposed and tested using different numerical schemes liang et al 2004 liang 2012 wang and liang 2011 popinet 2012 huang et al 2015 further applied amr to coupled flood and sediment transport modelling in this work we have introduced an advanced optimization based adaptive mesh technique pain et al 2001 to flooding modelling in comparison to amr locally nested static mesh methods this adaptive unstructured mesh technique can dynamically modify and adapt the mesh to achieve a desired level thus better capturing transient and complex flow dynamics as the flow evolves using the optimization based adaptive technique the mesh nodes can either be increased or decreased locally in time and space h adaptive technique with a good solution accuracy piggott et al 2005 or optimally relocated r adaptive technique to resolve the small scale flow features in a domain of interest e g features of flow around buildings this dynamically adaptive mesh technique has been applied to idealistic oceanic cases without real bathymetry and topography air pollution multiphase flows and reservoir modelling du et al 2016 zheng et al 2015 su et al 2015 xie et al 2017 jackson et al 2015 this is the first time to apply this optimization based adaptive mesh technique to flooding modelling unstructured meshes are used for optimal representation of complex domain geometries and boundaries one of key issues in flooding modelling is the representation of wetting drying wd fronts as reviewed in medeiros and hagen 2013 simulating the wd front over a real domain is still nontrivial due to the fact that accurate solutions requiring high spatial and temporal resolutions are unstable and computationally expensive the use of adaptive meshes enables the models to capture the physics of an advancing or receding wetting front better while keeping the computational cost low in this work our newly developed 2d double control volume finite element cv fe shallow water model together with the adaptive unstructured mesh technique has been successfully applied to the glasgow s urban flooding event of 2002 the performance of adaptive unstructured meshes in flood modelling has been evaluated the adaptive mesh simulations provide comparable results to the higher resolution 2d 3d fixed mesh simulations whilst reducing a 20 84 the computational cost the structure of this paper is presented as follows in section 2 the flooding model and the adaptive unstructured mesh techniques are introduced section 3 demonstrates the application of the model to a flooding event in glasgow scotland united kingdom in detail it describes the study site and geospatial data used for modelling and specifies boundary conditions and parameter settings section 4 presents and discusses the 2d adaptive mesh modelling results by comparing with 2d fixed mesh results and 2d 3d published results finally some conclusions and future work are given in section 5 2 methodology 2 1 governing equations 2 1 1 shallow water equations in flooding modelling the water depth is much smaller than the horizontal dimensions of the water body therefore the hydrodynamics of flooding flows can be suitably described by the shallow water equations swes in a matrix form the swes may be written as follows 1 q t f x w y s where t is the time x and y the cartesian coordinates q the vector representing the flow variables f and w the fluxes in the two cartesian directions and s is the source term vector the vector terms are given by liang and borthwick 2009 2 q η uh vh f uh u 2 h g η 2 2 η z b 2 uvh 3 w vh uvh v 2 h g η 2 2 η z b 2 and s 0 τ bx ρ g η z b x τ by ρ g η z b y where η denotes the water level and z b is the bed elevation above datum h η z b is the water depth u h is the velocity vector and u and v are the two depth averaged velocity components g is the constant gravitational acceleration ρ is the water density z b x and z b y define the bed slopes in the x and y directions τ bx and τ by are bed friction stresses calculated by 4 τ bx ρ c f u u h and τ by ρ c f v u h where c f is the bed roughness coefficient drag coefficient the numerical method used here is based on the double control volume finite element method presented in salinas et al 2017 here a cv free surface height is used this is mass conserving and robust to highly distorted elements this method is a variation of the well known control volume finite element method jackson et al 2015 gomes et al 2016 forsyth 1989 geiger et al 2004 matthai et al 2007 for the time discretization an implicit θ method is considered here θ varies between 0 5 crank nicholson and 1 implicit euler based on a tvd scheme total variation diminishing to stabilize the shallow water momentum equations we use a non linear petrov galerkin method which introduces a diffusion term proportional to the residual of the momentum equations however since it is a residual scheme petrov galerkin scheme it is mathematically consistent and converges to the governing equations as the grid and time step size are refined this provides for example the robustness needed when there are sharp changes in the velocity fields that can occur near wetting and drying fronts 2 1 2 drag coefficient a commonly used bottom stress parameterization is the manning strickler formulation 5 n ν u h n m 2 g u h u h h 1 3 on γ bottom in which n is the unit normal to the bottom surface γ bottom ν is the kinematic viscosity h is the water depth and n m is the manning coefficient the formulation for the volumetric drag coefficient c f is 6 c f n m 2 g u h max h h min 1 3 to avoid divisions by zero a minimum depth h min needs to be specified in our numerical experiments we tested values ranging from 10 8 to 10 3 without very significant differences between them finally the value of 10 5 was chosen this value was chosen as we wanted to reduce the non linear behaviour that using h min in the denominator introduces in this way 10 8 was the value that may introduce more numerical issues on the other hand using 10 3 meant that we would be considering a layer of 1 mm of water in dry areas which seemed unphysical thus 10 5 was the best option as considering a layer of water of 0 01 mm in the dry areas is physically plausible just with the moisture of the air while also reducing the non linearity introduced by a number such as 10 8 2 2 adaptive mesh techniques the dynamically adaptive unstructured mesh technique developed by pain et al 2001 is utilized here this method has the advantage of capturing details of surface and local flows wetting drying front during the process of flooding modelling it can efficiently provide a high mesh resolution where and when it is needed that is finer meshes are placed only in specific regions where the variations of flow variable solutions are relatively large e g flow around buildings and along the flooding paths while coarser meshes are used in areas far from these regions where inundation has not yet occurred for example the optimization based adaptive mesh technique used here relies on the derivation of appropriate error measures which dictate how the mesh is to be modified pain et al 2001 the error measure employed is based on the curvature of variable solutions and provides a directional measure by using a riemannian metric to calculate the element size and shape the mesh is adapted to have a uniform interpolation error in any direction this mesh optimization method requires an error measure in the form of a defined metric tensor the metric is derived from a solution field variable and an error norm based on the interpolation error pain et al 2001 thus the metric m defined as 7 m γ h where γ is a scalar constant and γ 1 is used here is a required interpolation error and h is the hessian matrix for a specified field ψ ω here the field of water depth 8 h 2 ψ x 2 2 ψ y x 2 ψ x y 2 ψ y 2 the desired edge length h i in the direction of the i th eigenvector e i of the metric m is defined as h i 1 λ i where λ i is the eigenvalue associated with e i power et al 2006 to take into account maximum and minimum element sizes m is modified and defined as 9 m v t λ v where the rotation matrix v contains the eigenvectors of the metric m given by eq 7 the eigenvalues are modified as follows pain et al 2001 10 λ j max λ j 1 a 2 max i 1 2 3 λ i j 1 2 3 where 11 λ j min 1 h min 2 max λ j 1 h max 2 j 1 2 3 in which a is the maximum aspect ratio h min and h max are the minimum and maximum element sizes in this metric space a functional which is used to gauge the shape and size quality of elements is defined a series of the mesh connectivity and node position searches are performed to optimize this functional the mesh modification thus fits the solution field s in an optimal manner the galerkin interpolation technique farrell and maddison 2011 is used for interpolating the solutions from the previous mesh onto the newly adapted mesh however the interpolation error may destroy the conservation of quantities important to the physical accuracy of simulations for example density and water height to keep the conservation of quantities the conservative interpolation operator with an intermediate supermesh is used for details see farrell and maddison 2011 davies et al 2011 shows that adapting every 5 time steps incurs in a 2 extra cost for their simulation since this value slightly varies when solving different problems e g up to 8 the rough figure is that the cost of adapting the mesh is around the same as doing one time step therefore adapting every 10 times steps means an approximate 10 extra cost based on heuristics for this case the mesh is adapted every 10 time steps for the adaptive simulation due to fact that the courant number is never big enough such as the water front leaves the high quality region of the mesh before the mesh is re adapted in general the mesh is adapted more frequently if the flow feature is changed rapidly 3 model application 3 1 descriptions of study site and data to assess the performance of adaptive meshes in flooding modeling the new flooding model has been applied to an urban area located within the city of glasgow scotland uk where a flood event occurred in july 2002 the whole computational domain is 1 0 km by 0 4 km fig 1 this flood is observed as a result of flow exceeding the capacity of the culvert during the period of prolonged or heavy rainfall the culvert is located at the northeast corner of the domain see location q in fig 1 once the capacity of the culvert is exceeded water overspills from the culvert and spreads over the west and south urban area along the main roads the details of hydrographic data can be found in literatures hunter et al 2008 liang et al 2007 the raw lidar data was originally collected by infoterra ltd leicester uk for glasgow city council for hydraulic modelling infoterra aggregated the lidar data and reinserted buildings kerbs and roads to obtain a 2m dem with realistic representation of urban morphologic characteristics hunter et al 2008 the time series of flooding water depth at four detector locations fig 1 obtained by hunter et al 2008 are utilized for model verification in this study fig 2 shows the unstructured meshes created as 2d triangle elements by gmsh geuzaine and remacle 2009 zhang et al 2016 a free finite element grid generator with a build in cad engine and post processor it can be seen how the surrounding mesh of the main street and the branches is refined 3 2 model applications a series of model simulations using both the fixed and adaptive unstructured meshes have been carried out to assess the performance of the new flooding model developed here in these simulations water enters the densely urbanized area from a culvert at location q fig 1 the flood condition has been described earlier as specified by the hydrographic data used in previous studies hunter et al 2008 liang et al 2007 the inflow discharge from the culvert started at t 5 min peaked between 22 and 24 min and ended at t 40 min a fixed time step size δ t 0 15 s is used in all simulations no normal flow boundary condition is enforced at all the external boundaries for mesh adaptivity the aspect ratio of the elements in the adapted mesh is set to 5 for mesh size constraints the maximum and minimum element sizes are 50 and 2 m respectively the mesh is adapted considering the solutions of both the water depth and velocity being the absolute interpolation errors set to 0 05 and 0 14 for the water depth and velocity respectively 4 results and discussion 4 1 water depth and velocity for comparison purposes 3d results from zhang et al 2016 are used as a reference solution in this study these 3d results have been proved to be consistent with 2d published results hunter et al 2008 in the region where the impact of 3d flow structures can be ignored figs 3 and 4 show the results of water depth and velocity from our newly developed 2d flooding model with both the fixed and adaptive unstructured meshes at time levels t 20 30 40 60 min in comparison to those results from 3d modelling zhang et al 2016 they show the flood propagation process over the urban area it can be observed that in most of the inundation area the solutions of water depth and velocity obtained from both 2d fixed and adaptive mesh modelling are in good agreement with those of 3d modelling as seen in fig 4 the flood propagation process is accelerating during 22 24 min when the inflow discharge at location q peaks the water spreads along the main street and branches when t 30 min during the flood recession after t 40 min water accumulates in the low lying areas especially in the southern street area marked with a yellow rectangle in fig 3 the variation of results in the speed and extent of flooding is relatively small after 45 min we therefore discontinue adapting the mesh from this time level and run it with the mesh already generated at this point until the end of the simulation this helps us to save the overhead and extra computational cost introduced during the adaptive mesh procedure generally speaking the 2d adaptive mesh model provides promising results while the number of nodes elements used during the simulation period is significantly reduced by up to 80 of that used by 2d fixed mesh modelling thus reducing the computational cost considerably 4 2 accurate representation of topography using the adaptive mesh technique using 2d adaptive mesh technology the mesh is dynamically adjusted during the process of flood propagation right column in fig 5 finer meshes are placed only in specific regions where the gradients of the flow variables are relatively steep e g flow around buildings fig 7 while coarser meshes are used in areas away from these regions where inundation has not yet occurred it enables the mesh based computing to be efficient and have low computational complexity in this case the topographical data a combination of airborne laser altimeter lidar and digital map data is available with a high resolution of 2 m the availability of high resolution topographical data is important for the accurate numerical simulation of urban food inundation however high resolution topographical data requires a high computational burden thus resulting in a computationally demanding flood modelling using the adaptive mesh technology the resolution of the topographical data can be dynamically adjusted during the process of flood propagation the topographical data over the domain is obtained by interpolating the high resolution 2 m data onto the adapted mesh at each time level therefore the high resolution topographical data is only used in the flooded region while the low resolution data is used in the rest of the domain one of the advantages of 2d adaptive unstructured mesh modelling is that the buildings can be represented accurately when where needed during the flooding process fig 5 shows how buildings gradually appear as the flooding water spreads across the domain fig 6 indicates the error in bathymetries during the simulation period when using adaptive meshes it is seen that the high resolution low error data is used only over the regions along the flood pathway 4 3 comparison with published results at detector locations to further validate our 2d fixed and adaptive unstructured mesh flooding models the time series of water depth at detector locations sta1 sta2 sta3 and sta4 are compared with those of six 2d hydraulic models divast divast tvd jflow lisflood fp trent and tuflow from hunter et al 2008 and the 3d model zhang et al 2016 fig 8 shows the time series of water depth predicted by these models sta1 represents a flat area with surrounding buildings where water accumulates fast but releases slowly during the flood process sta2 is placed in the middle of the main road where the flood water is shallow and moving fast sta3 is located in the low lying area in the southern part of the domain as marked with a yellow rectangle in fig 3 water from the east west oriented main street converges and ponds there in the latter part of the simulation sta4 is sited at the side of the road where the ponding water comes from both north and south directions model performance has been assessed through comparison of the results at these detector locations in fig 8 the black and red lines represent the time series of water depth predicted by the new 2d unstructured mesh flooding model with fixed and adaptive meshes respectively it can be seen that a good agreement is achieved between the results from our 2d adaptive and fixed unstructured mesh models and those from other 2d models at all the detector locations the results of our 2d unstructured mesh modelling results especially with adaptive meshes are very close to the 3d results zhang et al 2016 at sta 1 a flat and ponding area where the vertical velocity is relatively small however there is a large difference between 2d and 3d modelling results at sta 2 where the vertical inertial and non hydrostatic pressure terms are large the impact of 3d flow cannot be ignored zhang et al 2016 compared with the results when using 2d fixed meshes 2d adaptive mesh modelling results at sta 3 match well with those from other 2d models and are closer to the 3d results in general the results between both of our 2d fixed and adaptive mesh models are in a good agreement during t 1 40 min until the flooding peak there is then a difference between them at stas 3 and 4 during the flooding recession after t 40 min compared with the 3d results the time series of water depth using 2d adaptive unstructured meshes is more accurate than that using 2d fixed unstructured meshes at stas 1 3 the main reason for this is that the adaptive mesh is optimised in response to the evolving flow features while the fixed mesh is designed based on the main road network see zhang et al 2016 for both fixed and adaptive mesh modelling a high mesh resolution of 2 m is placed along the main road routes where the dominant flow features are observed however for fixed mesh modelling the meshes are coarser around the building areas than that of adaptive mesh modelling what s more mesh adaptivity ensures a certain precision it is thus seen in fig 8 that at stas 1 3 the time series of water depth using 2d adaptive unstructured meshes is more accurate than that using 2d fixed unstructured meshes while a smaller number of nodes is used during the simulation in general both results of using adaptive and fixed meshes are consistent with those from other 2d models 4 4 performance of 2d fixed and 2d adaptive unstructured mesh flood modelling as seen in table 1 and fig 9 a multi scale unstructured mesh with 2 m 5 m 20 m resolution generated by gmsh fig 2 consists of 28 508 nodes and 56 862 unstructured triangle elements this mesh is used during the whole simulation period for 2d fixed unstructured mesh modelling and used as the initial mesh for 2d adaptive unstructured mesh modelling after first adapting the mesh the numbers of nodes and elements used for 2d adaptive mesh are reduced by 84 and then gradually increased during t 10 45 min as the flooding water spreads over the domain at time level t 40 min the inflow at location q ends and recession of water starts as a result the water accumulates in low areas and the water velocity remains small to avoid the overhead and extra computational cost introduced during the adaptive mesh procedure the mesh is fixed from t 45 min using our 2d unstructured mesh model the cpu time of 300 5 h is required for the fixed mesh simulation and 153 5 h for the adaptive mesh simulation which is only half of the former moreover adapting the mesh dynamically means that there is no need to perform a priori calculations with its corresponding computational cost to estimate the key regions of the domain to place more resolution in those areas above all 2d adaptive unstructured mesh modelling is less computational expensive than 2d fixed unstructured mesh modelling the use of 2d adaptive unstructured meshes improves the computational efficiency to further reduce the computational cost various numerical techniques can be adopted in our flood model for example an adaptive time step scheme and or parallel computing using mpi 5 conclusions a 2d cv fe flooding model with the adaptive unstructured mesh technique has been developed this dynamically adaptive unstructured mesh technique is able to modify and adapt unstructured meshes to better capture the features of flooding flows local flows around the buildings or the wetting and drying front for example while reducing computational cost without sacrificing accuracy of flooding simulations to assess the performance of the adaptive meshes in flooding simulations the new 2d flooding model has been applied to a flooding event that happened in 2002 in glasgow scotland united kingdom where the flood is induced by a stream flow from a culvert at the northeast corner of the domain a comparison between 2d adaptive and fixed mesh models as well as 3d model has been undertaken it has been found that using the 2d adaptive mesh model it is able to provide accurate results while the computational cost is reduced by 20 84 in comparison to 2d fixed mesh models another advantage of 2d adaptive unstructured mesh modelling is that urban topography can be accurately represented when where needed by increasing the mesh resolution around the buildings for example dynamically when the flooding water spreads over the urban area this is the first time to use the dynamically adaptive mesh technique in flooding modelling and assess its performance in a relatively simple flooding event our future work on flood modelling development will focus on complex realistic cases where flooding may occur from more than one source furthermore to reduce the computational cost numerical techniques such as adaptive time step scheme and parallel computing will be investigated acknowledgments the authors acknowledge the support of funding from the european union seventh framework programme fp7 20072013 under grant agreement no 603663 for the research project pearl preparing for extreme and rare events in coastal regions and the epsrc memphis multi phase flow programme grant ep k003976 1 funding for salinas from exxonmobil and epsrc smart geowells grant ep r005761 1 is gratefully acknowledged the authors would like to thank dr ting zhang for providing advice and help in this research no data was generated in the course of this work 
7349,coupling global climate models hydrologic models and extreme value analysis provides a method to forecast streamflow maxima however the elusive variance structure of the results hinders confidence in application directly correcting the bias of forecasts using the relative change between forecast and control simulations has been shown to marginalize hydrologic uncertainty reduce model bias and remove systematic variance when predicting mean monthly and mean annual streamflow prompting our investigation for maxima streamflow we assess the variance structure of streamflow maxima using realizations of emission scenario global climate model type and project phase downscaling methods bias correction extreme value methods and hydrologic model inputs and parameterization results show that the relative change of streamflow maxima was not dependent on systematic variance from the annual maxima versus peak over threshold method applied albeit we stress that researchers strictly adhere to rules from extreme value theory when applying the peak over threshold method regardless of which method is applied extreme value model fitting does add variance to the projection and the variance is an increasing function of the return period unlike the relative change of mean streamflow results show that the variance of the maxima s relative change was dependent on all climate model factors tested as well as hydrologic model inputs and calibration ensemble projections forecast an increase of streamflow maxima for 2050 with pronounced forecast standard error including an increase of 30 21 38 34 and 51 85 for 2 20 and 100 year streamflow events for the wet temperate region studied the variance of maxima projections was dominated by climate model factors and extreme value analyses keywords extreme streamflow variance structure 1 introduction streamflow maxima is one of the most sought after response variables within hydrologic research and application coles et al 2001 begueria and vicente serrano 2006 reiss and thomas 2007 streamflow extreme maxima re contours the morphology of the fluvial system leopold et al 2012 partially controls the stream biogeochemical function ford et al 2015 can destroy human infrastructure melillo et al 2014 and resupplies human water stores for consumption food production and energy generation rosenzweig et al 2001 mirza 2003 mcmichael et al 2007 the complex earth system for which streamflow maxima responds is no less encompassing of hydrology than streamflow itself and includes components such as the climates ability to produce precipitation and weather patterns the watershed s physiogeographic configuration and ability to respond to precipitation and human s influence on both the watershed and climate despite hydrologists long historical emphasis upon study of streamflow extreme maxima current disparity is prevalent in terms of both streamflow maxima s current estimations and its gradient as we forecast into the future khaliq et al 2006 scientific gaps associated with estimating and forecasting current and future streamflow maxima is qualitatively attributed to scientific uncertainty surrounding human s economic behavior and influence on the earth system representation of the climate and its changes hydrologic representation of streamflow and scalar coupling of a changing climate within a hydrologic representation of the earth madsen et al 2014 ipcc 2013 the difficulty of streamflow extreme maxima estimation and forecasting in a non stationary earth system has challenged hydrologists to consider the potential use of new methodologies for investigating and forecasting streamflow one methodology for which streamflow maxima investigation and forecasting has received some recent attention is through the use of non stationary projection with global climate models that can be used to drive hydrologic and statistical forecasting prudhomme et al 2003 dankers and feyen 2008 mantua et al 2010 lawrence and hisdal 2011 zhang et al 2014 this method involves application of the non stationarity form of long term climate change projected using global climate models as a means to provide a physics based guideline for extrapolation lima et al 2015 shamir et al 2015 the global climate model results are post processed for scalar considerations and then propagated through hydrologic models for predicting multi year streamflow time series thereafter the extreme value theorem is adopted to study streamflow extremes because the theory provides a mathematical basis for the definition of extremes and has been used to prove that the distribution of extremes follow similarity at their limit e g coles et al 2001 somewhat analogous to the central limit theorem the extreme value theorem focuses on the statistical distribution and behavior of maxima that may arise from an unknown distribution for a population of a sequence of values measured over many time units in this manner hydrologists can statistically investigate current and forecast extreme value extreme maxima such as 2 20 and 100 year events via time series generated from the mentioned hydrologic modeling the coupling of global climate and hydrologic models for forecasting streamflow extreme maxima has been recently criticized for water infrastructure planning in some engineering and management circuits moradkhani 2017 and we tend to agree that use of the methodology in a infrastructure design capacity is a bit preliminary given that published applications and results of the method is still in its infancy yet we argue that the time is ripe for elucidating the variance structure of streamflow maxima forecasted with global climate models we offer several reasons for this contention first highlighting the variance structure of forecasted streamflow maxima provides hydrologic and climate researchers with knowledge of highly sensitive factors and parameters of streamflow forecasting that systemically increase the size of the solution space so that researchers might focus their attention towards improving model structure and parameterization second the variance structure of forecasted streamflow maxima allows researchers to see what extent the previous results of forecasted mean streamflow might be adopted and extrapolated for forecasting extremes there is a plethora of studies that forecast mean streamflow with global climate models chen et al 2011 al aamery et al 2016 fatichi et al 2014 and there is a question as to what extent results from these mean focused studies might be relevant to the study of extreme streamflow especially in light of the extra level of uncertainty that is introduced to forecasting maxima during application of the extreme value theorem third a reason for investigating the variance structure of forecasted streamflow maxima is to help provide balanced forecasts that can be compared with a meta analysis of trends in existing literature results such as in wet temperate regions while variance analysis of streamflow extreme maxima is sparse in the literature global climate model research and forecasting of mean annual and mean monthly streamflow tends to suggest that climate models are different in their structures and parametrizations randall et al 2007 downscaling methods are distinct in their structure and results to re scale global results wilby and dawson 2007 warner 2010 mearns et al 2013 emission scenarios address the uncertainty of future economic and co2 conditions ipcc 2007 ipcc 2013 the version of climate model projects are different in their structures and the newer version cmip5 is distinct relative older versions of models cmip3 brekke et al 2013 and the bias implementation of climate results is a source for variance presence in hydrologic models teutschbein and seibert 2012 al aamery et al 2016 and therefore all such components could have the potential to impact the variance structure of forecasted streamflow maxima the few studies that have forecasted streamflow maxima with global climate models see table 1 have results that tend to corroborate some findings from mean focused studies and suggest the type of global climate model applied caused differences in streamflow extreme forecasts prudhomme et al 2003 lawrence and hisdal 2011 and emission scenario can also shift extreme predictions dankers and feyen 2008 mantua et al 2010 zhang et al 2014 applications of extreme value theory suggest the statistical analysis associated with the choice of extreme value analysis method has the potential to impact the variance of forecasted streamflow maxima and the annual maxima method is criticized for its neglect of multiple extremes per annum while the peak over threshold method has been criticized for subjectivity of threshold selection svensson et al 2005 scarrott and macdonald 2012 bezak et al 2014 fischer and schumann 2016 beyond uncertainty surrounding the global climate model projections and extreme value methods there are additional uncertainty considerations with respect to the future hydrologic balance and its simulation when forecasting streamflow maxima as one example future changes in the hydrologic cycle and in turn streamflow are primarily driven by changes in precipitation and evapotranspiration studies that forecast streamflow maxima with global climate models have focused on precipitation and temperature differences within simulation of future periods mantua et al 2010 zhang et al 2014 however it is now recognized that evaporative demand is physically controlled by net radiation vapor pressure and wind speed as well as air temperature donohue et al 2010 future projections of these additional variables suggest decreases in wind speed and net radiation and an increase in relative humidity for some regions willett et al 2008 wild 2009 mcvicar et al 2012 the directions of the projected shifts would decrease evapotranspiration and in turn could potentially increase variability when forecasting streamflow maxima as a second example hydrologic model fit and modeling uncertainty when simulating the water balance has the potential to increase the variability of projected streamflow maxima al aamery et al 2016 recent study has tended to marginalize the importance of hydrologic model calibration and uncertainty for mean streamflow projections when considering relative future changes niraula et al 2015 however streamflow maxima has not yet been tested in this context to our knowledge our objectives were to 1 perform coupled climate hydrologic and statistical model simulation and evaluation to build realizations of streamflow maxima 2 perform variance analysis to test for systematic uncertainty from climate and extreme modeling factors potentially controlling streamflow maxima forecasting 3 perform uncertainty analysis to quantify variance from hydrologic modeling and 4 forecast streamflow maxima for the wet temperate region studied herein and provide literature comparison these objectives provide the structural sub headings used in the following methods results and discussion sections 2 theoretical background the variance structure of forecasted streamflow maxima can be decomposed as a function of potentially controlling modeling factors the conceptual model of factors that have the potential impact forecasted streamflow maxima variance is shown in fig 1 as can be seen in the figure modeling factors that may impact the variance structure can be grouped into those associated with climate modeling cmfs in fig 1 including global climate model gcm type hydrologic modeling hmfs and uncertainty in inputs and parameterization and statistical modeling of extremes smfs associated with different fitting methods and distributions land use and management modeling is not shown in the figure and was treated as static in this study but it is also recognized to potentially control future streamflow the response variables are streamflow maxima associated with different return periods including 2 20 and 100 year return periods so the distribution of extremes can be quantified lawrence and hisdal 2011 we consider response of the future relative change in streamflow equal to the percent difference of gcm forecasted streamflow maxima relative to gcm hindcast maxima δqf h x where x indicates the return period the future streamflow maxima can be related to the real streamflow maxima by using the relative changes derived from the forecast projections and hindcast control projections coupled with the observations such as using the delta method directly applied to streamflow model results the relative change approach has become rather popular in climate change studies that emphasize gcm forecasted streamflow chien et al 2013 harding et al 2012 fatichi et al 2014 niraula et al 2015 al aamery et al 2016 the approach has been suggested to remove seasonal spatial and or inter annual biases of gcms or statistical artifacts from the downscaling method that are not accounted for in bias correction methods harding et al 2012 in addition application of the relative change has recently shown no significant dependence upon calibrated versus un calibrated hydrologic model simulation thus suggesting the response variable does not require model calibration to see the projected direction of future streamflow niraula et al 2015 the approach has also shown less dependence upon climate modeling factors i e cmfs in fig 1 as compared to the absolute forecasted streamflow suggesting that biases specific to a model structure could be accounted al aamery et al 2016 while the relative change approach has shown potential in past studies these studies have tended to focus on the mean forecasting of streamflow in the present study we consider the method for streamflow maxima which is one contribution of this paper realizations of the relative change in streamflow maxima can be simulated as a function of climate hydrologic and statistical modeling factors within a variance analysis ensemble al aamery et al 2016 in the present study we included permutations using seven emission scenarios i e emission factor cmf1 propagated through eight different gcms associated with phase three and four climate projects i e cmip3 cmip5 i e gcm type and version factors cmf2 3 that were downscaled using two statistical downscaling methods and four dynamical downscaling methods i e downscaling factor cmf4 further our post processing and hydrologic analyses of downscaled hindcast 1983 2000 and forecast 2048 2065 climate model results considered bias correction i e bias factor smf1 propagated through a continuous simulation hydrologic model we performed both annual maxima and peak over threshold extreme value analyses i e extreme value factor smf1 2 of hydrologic model results given recent debate in the literature over the best method we also investigated additional uncertainty considerations with respect to additional hydrologic inputs and hydrologic uncertainty hmf 1 3 3 study site and materials the study site was south elkhorn watershed in lexington kentucky usa see fig 2 this watershed is within a wet and temperate region where a future change in climate including an increase in precipitation and temperature is projected melillo et al 2014 according to melillo et al 2014 a 20 30 increase in annual maximum precipitation is projected under rcp 8 5 emission scenario for the end of the century additionally at least 80 of the models used in melillo et al 2014 are in agreement for this region the watershed covers an area of 478 6 km2 with surface elevations ranging between 197 and 325 m asl the land use is dominated by agricultural equal to 72 the remaining land uses are urban suburban equal to 13 forest equal to 14 and open water and wetlands equal to 1 the results of eight gcms were implemented in this analysis the gcm models reflected four different gcm model types and two versions of each model including a version from cmip3 and the newer version from cmip5 brekke et al 2013 al aamery et al 2016 the gcms included the canadian global climate model including cgcm3 from cmip3 and canesm2 from cmip5 flato 2005 the national center for atmospheric research community climate model including ccsm3 from cmip3 and ccsm4 from cmip5 collins et al 2006 the geophysical fluid dynamics laboratory including gfdl cm2 1 from cmip3 and cm3 from cmip5 delworth et al 2006 and the united kingdom hadley centre climate model including hadcm3 from cmip3 and hadgem2 es from cmip5 gordon et al 2000 these gcms were chosen for their representation in different climate projects including cmip3 cmip5 and narccap projects and their available archives of climate results for the current and future periods focused on in this study brekke et al 2013 mearns et al 2013 al aamery et al 2016 statistical downscaling and dynamical downscaling results were included in this analysis the statistical downscaling results were used from the coupled model inter comparison project phase three cmip3 and phase five cmip5 brekke et al 2013 the dynamical downscaling results were used from the north american regional climate change assessment program narccap mearns et al 2013 these downscaling methods represent two distinct approaches for downscaling gcm results from their coarse scale to a finer watershed scale the statistical downscaling method is statistically based and adopts empirical statistical relationships to estimate the small scale climate variables based on the large scale atmospheric variables wilby and dawson 2007 the statistical downscaling method implemented in cmip3 and cmip5 projects adopt two schemes including bias correction and spatial disaggregation bcsd and bias correction and constructed analogs bcca brekke et al 2013 the dynamical downscaling method is physically based and uses regional climate models rcms whose boundary conditions are forced by the results of the parent gcm to simulate the atmospheric physical processes on a regional scale warner 2010 six regional climate models were implemented through the narccap project including the canadian regional climate model crcm plummer et al 2006 the experimental climate prediction center ecpc model juang et al 1997 the hadley regional model 3 hrm3 jones et al 2004 the mm5 psu ncar mesoscale model mm5i chen and dudhia 2001 the reginal climate model version 3 rcm3 giorgi et al 1993 and the weather research and forecasting model wrfp skamarock et al 2005 4 methods 4 1 modeling simulations and evaluation the soil and water assessment tool swat the version was arcswat 2012 10 1 13 model was applied to simulate the hydrology of south elkhorn watershed this model is physically based and was applied successfully in this region and many other regions around the world palanisamy and workman 2014 gassman et al 2007 arnold et al 1998 the model was evaluated over 1981 2000 using the observed climate and streamflow data and applied for the hindcast period 1981 2000 and forecast period 2046 2065 using the gcms results of daily precipitation and maximum and minimum temperature see fig 3 in al aamery et al 2016 for evaluation methods of swat we obtained all the data required by swat including topography soil and landuse data from publically available databases the topography and streamlines data were obtained from the national map website http viewer nationalmap gov viewer and the soil data was obtained from the data gateway website http websoilsurvey sc egov usda gov app websoilsurvey aspx the landuse data of 1992 was used from the usgs website http www mrlc gov nlcd2011 php the observed climate data of daily precipitation and maximum and minimum temperature were obtained from bluegrass airport meteorological gage station the model was evaluated using four usgs streamflow gage stations within the watershed including south elkhorn creek at fort spring usgs03289000 town branch at yarnallton road usgs03289200 south elkhorn creek near midway usgs03289300 and elkhorn creek near frankfort usgs03289500 results for the south elkhorn creek near midway station were analyzed for the relative change in streamflow maxima model evaluation including calibration validation and sensitivity analysis was performed semi automatically via swat cup software for sequential uncertainty fitting sufi2 for the four gage stations in the watershed abbaspour et al 2007 the first two years was left as a spin up period for swat arnold et al 2010 as input to the hydrologic modeling the scaling of precipitation and temperature method of lenderink et al 2007 was applied to correct the bias in the climate data the method operates with monthly correction values based on the difference between observed and current period simulated values as 1 p sc d p sc d μ m p obs d μ m p sc d 2 p sf d p sf d μ m p obs d μ m p sc d 3 t sc d t sc d μ m t obs d μ m t sc d and 4 t sf d t sf d μ m t obs d μ m t sc d where p sc ast d and t sc d are the corrected daily precipitation and temperature for the simulated current period p sf d and t sf d are the corrected daily precipitation and temperature for the simulated future period p sc d and t sc d are the uncorrected daily precipitation and temperature for the simulated current period p sf d and t sf d are the uncorrected daily precipitation and temperature for the simulated future period μ m p obs d is the average of observed daily precipitation values for a given month μ m p sc d is the average daily precipitation for the current simulated values μ m t obs d is the average of observed daily temperature values μ m t sc d is the average of daily temperature for the current simulated period and m stands for within monthly time step the annual maxima am and peak over threshold pot methods were carried out for each realization from the hydrologic modeling results in order to analyze the extremes see fig 3 the am series is constructed by selecting one value per a specific time over the sample size in streamflow studies such as herein this value is the maximum water discharge value selected over one year from the daily time series data khaliq et al 2006 haan 2002 thereby the am series replaces the flow series q1 q2 q365 of a year j by the largest flood value qm j where 1 m total number of days in year j 1 j n and n is the number of years according to the extreme theorem the probability of the rescaled m n is approaching the general extreme value gev family when n the gev family distribution is expressed as follows 5 g q exp 1 ξ q μ σ 1 ξ where q 1 ξ q μ σ 0 the location parameter μ the scale parameter σ 0 and the shape parameter ξ depending on the value of the shape parameter ξ the gev family has three distinct probability distributions the light tail gumbel type when ξ 0 the heavy tail fréchet type when ξ 0 and the bounded upper tail weibull type when ξ 0 the extreme quantiles of the return level t when ξ 0 are then calculated as follows 6 q t μ σ ξ 1 log 1 1 t ξ and when ξ 0 7 q t μ σ log log 1 1 t the pot series was constructed by selecting all independent and identically distributed values q1 q2 that are higher than a specific and carefully chosen value called threshold point qo see example in fig 4 according to extreme value theory for large enough qo the distribution function of y q qo conditioned by q qo is approximated by the generalized pareto gp family as follows coles et al 2001 8 h y 1 1 ξ y σ 1 ξ where y y 0 and 1 ξ y σ 0 and σ σ ξ q o μ q is a specific value in the sequence q1 q2 and σ μ and ξ are the scale location and shape parameters depending on the value of the shape factor the gp family consists of three probability distribution functions as follows the heavy tail pareto type when ξ 0 the light tail exponential type when ξ 0 and bounded upper tail beta type when ξ 0 to calculate the extreme quantile q t of the return period t the probability ζ q o pr q q o is calculated first and then the return period when ξ 0 is given by 9 q t q o σ ξ ζ q o t ξ 1 when ξ 0 the return level of a period t is given by 10 q t q o σ log t ζ q o threshold point choice we adopted the parameter stabilization method explained by coles et al 2001 to choose threshold points used within the pot method the method is based on fitting the general pareto distribution across a range of different threshold points when fitting the model parameters including the shape parameter ξ and scale parameter σ were estimated for each point across the range the shape parameter should be approximately constant and the scale parameter should be linear in q when the gp distribution is valid above the qo coles et al 2001 fig 4 shows an example of fitting the gp model using the maximum likelihood method over a range of 1 40 for the threshold point as observed the shape and the reparametrized scale parameters are nearly stable until reaching the point 21 we therefore specified the point 21 cms as the threshold point for the pot series of the observed daily streamflow series in this example and the method was repeated for each model hydrologic realization performed in our study in order to support our choice of the threshold we compared our final results of threshold selection using the parameter stabilization method with three rules of thumb presented by scarrott and macdonald 2012 using general order statistics convergence properties methods including the upper 10 rule square root rule k 1 n and k 2 n 2 3 log log n rule were developed see scarrott and macdonald 2012 fig 4 shows that our choices compared well to the three methods temporal independency in the pot series the values of the pot series in the sense of extreme theorem should admit to the temporal independence condition by only selecting all values that are higher than the threshold point we will obviously violate this condition within a streamflow time series therefore to identify and remove the time dependency in the pot series values de clustering of the pot series was adopted the de clustering was performed by calculating the extremal index θ as follows coles et al 2001 11 θ limiting mean clustering size 1 where θ equal to one indicates an independent series therefore the objective was to minimize the size of the clusters until θ reaches one our approach was to make manual iteration for each pot series to select the number of threshold deficits r used to define a cluster moreover to support our independent choices of pot series we performed the auto tail dependence function plots for the data series reiss and thomas 2007 to test the dependency of the events in the series trend analysis we analyzed the pot and the am series with respect to the non stationarity explained by trend analysis we used the mann kendall nonparametric test to identify the presence of trends in each independent pot and am series haan 2002 if the trend was present we removed the trend from the series although as will be discussed in the results very few series exhibited a significant mean trend likelihood ratio test the likelihood ratio test was used to test the null hypothesis of the shape factor ξ to be zero this test is used in statistics to test the goodness of fit of two distributions when one of them is a special case of the other i e nested models hogg et al 2014 coles et al 2001 in our case the gumbel distribution is nested within the gev distribution and the exponential distribution is nested within the gp distribution currently the am and pot series are the only two types of flood peak series that can be used for flood frequency analysis and further discussion of a comprehensive comparison between the two series is provided in the literature in bezak et al 2014 and madsen et al 1997 to perform all the methods described in the extreme analysis methods section and shown in fig 3 we have applied the r package extremes version 2 0 described in gilleland and katz 2016 4 2 uncertainty from climate and extreme modeling factors our results from the coupled climate hydrologic and extreme modeling methods produced 226 realizations of model runs available for variance analysis based on a factorial design that considered emission type gcm type and version downscaling type bias correction and extreme value method type each factor was divided within variance decomposition as follows the gcm type factor was divided into four levels for the four parent models mentioned previously the gcm version factor was divided into two levels indicating cmip3 and cmip5 project phases of the models the downscaling factor was divided into two levels for statistical and dynamical methods the emission factor was divided into seven levels including the sres type used in cmip3 a1b a2 and b1 and the rcps type used in cmip5 rcp2 6 rcp4 5 rcp6 0 and rcp8 5 the bias factor was divided into two levels indicating inclusion of methods in eqs 1 4 or lack thereof and the extreme value factor was divided into two levels for am and pot methods further details of the factorial levels for each of the 226 realizations are provided in the supplementary on line table we simulated variance analysis following both more traditional linear methods and more recently published nonlinear methods in order to maintain robustness of the analyses linear analysis of variance anova we performed statistical analysis through fitting the linear analysis of variance model anova to the results of the maxima extreme analysis anova was applied separately for each streamflow maxima quantile the extreme quantiles represent the response variables of 2 year 20 year and 100 year return periods δqf h 2 year me δqf h 20 year me and δqf h 100 year me respectively via the general linear model univariate procedure in spss 22 software pallant 2005 anova explores the effect of different factors on the variance of the response using the p value of the statistical test and ranking factor importance by using the f value the f value of each factor was divided by the summation of f values in a single model to determine how much variance that factor explains from the total predictable variance several considerations were determined when applying anova methods first because the datasets were not represented in the climate factors equally we applied four separate models that balanced a set of factors the reason for the multiple models is attributed to our climate datasets where the cmip3 project has both statistically and dynamically downscaled results while the cmip5 project has only statistically downscaled results we also have different emission scenarios between the two projects cmip3 has sres emission scenarios and cmip5 has rcps emission scenarios we built therefore four way anova models as the highest possible order to constrain the balanced and nested models fig 5 shows four possible 4 way anova models that we built from our factorial design second we analyzed the factors across the models using the highest possible order however if a factor was found to be unimportant we omitted the factor to maximize repetitions anova assumes that the population is normally distributed although the violation of this assumption should not cause major problems when the sample size is greater than 30 pallant 2005 gravetter and wallnau 2000 stevens 1996 in our factorial design the least sample size was recorded in anova model 3 where the sample size was 56 therefore our concern about the normality assumption is limited the homogeneity of variance assumption was treated by using the levene test for the equality of variance pallant 2005 if the data failed in this test the significant level by which we compare the variances of the different groups in the anova models was 0 01 which overcomes the violation of this assumption pallant 2005 nonlinear artificial neural network ann ann models on the other hand were considered in this study to reinforce our robustness of the variance analysis anns provides a model framework based on a set of multivariate nonlinear functions and therefore could account for nonlinearity between factors controlling variance and the streamflow response variable if it exists in this manner anns could overcome the underlying multivariate linear model limitation that anova is based on we used the ann model to examine the climate factors importance on streamflow maxima projections through spss 22 software ibm 2012 tufféry 2011 the input layer represented the climate and the statistical factors with nominal variables and the output layer represented the relative change in streamflow maxima we used one hidden layer with a randomly generated number of neurons we used supervised training with multilayer perceptron and feedforward architecture all values of the input and output layers were normalized so that all values ranged between 0 and 1 the hyperbolic tangent activation function was considered in the hidden layer we used the same four models proposed in the anova analysis to perform the ann analysis the dataset partitioning was performed with spss ann to divide the data into training and testing datasets however through generation of random numbers within spss ann the partitioning values of training and testing will swing around the 70 and 30 marks for each run of many runs performed for each model the values of training partitioning ranged between 60 and 80 affecting the testing portion and providing a new relative error value for both training and testing parts accordingly the smallest relative error provides the best results for the ann model ibm 2012 therefore our approach was to use an initial 70 of the dataset for training and the rest for testing and then rerun the model until obtaining the minimum possible relative errors across the training and testing data 4 3 uncertainty from hydrologic modeling additional uncertainty from the future hydrologic balance and its simulation were also quantified as part of our study future projections of net radiation vapor pressure and wind speed were tested in simulation for the study region with the premise that decreases in wind speed and net radiation and an increase in relative humidity could decrease future evapotranspiration and in turn increase streamflow maxima while at the same time increase uncertainty of forecasts future projections that consider hydrologic model fit and hydrologic parameter uncertainty were also tested to assess the potential to increase the variability of projected streamflow maxima future climate change of wind speed net radiation and relative humidity were tested within hydrologic simulation by considering projected shifts reported in the literature the average monthly wind speed in the study site ranges between 3 and 5 m s according to mcvicar et al 2012 the possible stilling in the middle of the current century is approximately 0 5 m s for the study site region when assuming a linear trend of their observations reported therein in turn the percent climate change of wind speed is between 10 and 17 for the future period in the study region wild 2009 indicates that the surface solar radiation has a decadal variation and that the absolute trend was observed as 6 w m 2 per decade and 8 w m 2 per decade for the periods of 1961 1990 and 1995 2007 respectively over the united states we recognized that increasing radiation would offset decreasing wind speed when estimating evapotranspiration and therefore we considered the decreasing trend of 6 w m 2 per decade for the future period in order to test its sensitivity the mean daily solar radiation ranges throughout the year between 81 w m 2 1 9 kw h m 2d 1 and 300 w m 2 7 2 kw h m 2d 1 considering the mentioned net decrease produces a change in the solar radiation reaching the surface to be between 4 and 15 regarding the relative humidity willett et al 2008 shows data that suggests an increase in the relative humidity for the northern hemisphere the net increase shown was 0 07 for the 10 year period of investigation we assumed the same change for the future period which resulted in a range between 0 4 and 0 5 for the study region donohue et al 2010 showed that the penman equation produced the most reasonable estimation of evaporation demand and this method is included within the hydrologic model used in the present study therefore we considered a number of scenarios in hydrologic modeling that test the mentioned ranges of wind speed net radiation and relative humidity concurrently to see their added impact on streamflow maxima we also tested the variables independently to see their individual sensitivity upon the streamflow maxima future projections that consider hydrologic model fit and hydrologic modeling uncertainty were also tested with the hydrologic model to investigate their impact on forecasted streamflow maxima recent literature results have marginalized the importance of model fit when forecasting the relative change in future mean streamflow niraula et al 2015 and we tested this concept for future streamflow maxima the future streamflow maxima produced from the calibrated hydrologic model simulation for a set of gcm realizations was compared against the future streamflow maxima produced using the un calibrated i e default parameterization of the hydrologic model for the same climate realizations additionally the impact of hydrologic model uncertainty was considered by carrying forward uncertainty projections from the hydrologic model parameterization to the extreme value methods and thereafter to compute the relative change in future streamflow the swat cup software provides parameter sets and solutions used to create uncertainty bounds during the model simulation realizations of all parameter sets that meet the objective function criteria were chosen and extreme value methods were performed for hindcast and forecast global climate pairs to compute the relative change in streamflow maxima 4 4 forecast of streamflow maxima for wet temperate regions after quantifying the climate hydrologic and extreme modeling factors controlling variability of the projections an ensemble was created to forecast the relative change in the streamflow maxima for the wet temperate study region al aamery et al 2016 the extreme forecasts for this study calculated the net effect on the mean and variance of the balanced ensemble from variation of climate modeling factors and extreme modeling factors the added uncertainty from hydrologic model parameterization and the added mean shift and its variance from climate change shifts in net radiation vapor pressure and wind speed results were compared with other studies reported in the literature of streamflow maxima see table 1 that fell within wet temperate regions 5 results and discussion 5 1 modeling simulations and evaluation results from the model evaluation showed that the hydrologic model performed within an acceptable range and the simulated and observed daily streamflow signals showed close agreement see fig 6 the four quantitative matrics including coefficient of determination r2 percent bias pbias nash sutcliff efficiency ns and the ratio of the root mean square error to the standard deviation of measured data rsr showed results within the acceptable range moriasi et al 2007 donigan 2002 gassman et al 2007 in both calibration and validation periods for the majority of the four observation sites for which the model was compared against see compiled metrics in table 2 although one of the four sites showed values just below or equal to the acceptable range boundary during validation overall 53 out of the 56 metrics that compared observations with model results were above the acceptable range showing that the model simulated streamflow well according to moriasi et al 2007 the monthly time step model performance is considered satisfactory if the ns 0 5 rsr 0 7 and pbias 25 the model performance on finer time steps e g daily is usually poorer than the coarser time steps model e g monthly in terms of the statistical matrices e g ns rst pbias moriasi et al 2007 engel et al 2007 for instance while the monthly ns was 0 656 for the calibration period in fernandez et al 2005 the daily one was 0 395 moreover moriasi et al 2007 indicated that when reviewing previous studies ns and pbias were as expected lower in the validation period than the calibration period for streamflow note that the midway station was our primary calibration since all of the model s streamflow forecasts occurred from this location the model we established for south elkhorn watershed showed results for the midway gage station to have ns values equal to 0 9 and 0 66 for the monthly and daily time steps respectively for the calibration period and ns values equal to 0 88 and 0 46 for the monthly and daily time steps respectively for the validation period in summary the metrics showed adequate performance considering the above information and results results from fitting both the am and pot extreme series methods to the streamflow results showed that in general the extreme series results had little mean trend and were dominated by the two parameter probability distributions see supplementary on line table the mann kendall test results showed that only 2 of the am series included a mean trend that required removal and only 4 of pot series results had a mean trend that required removal a regression approach was also carried out and provided identical results as the mann kendall tests the results highlight that although non stationarity is exhibited when comparing extremes from the hindcast to the forecast periods little significant non stationarity is exhibited within the simulation periods statistical results showed that 91 of the am series best followed the two parameter gumbel distribution while 85 of the pot series best followed the exponential distribution the results tend to agree with the results of dankers and feyen 2008 who also found that a two parameter distribution was most adequate when fitting distributions from extreme value theory to streamflow results derived from global climate modeling additional results from the extreme value analyses is also compiled in the supplemental on line table and includes threshold selections the value of the extremal index θ before de clustering the value of r required to make the extremal index θ equal to unity the p value of mann kendall non parametric test and the resultant sample size n we found less than 10 difference between observed and simulated maxima for all return periods i e 2 20 and 100 year return periods for both am and pot methods both observed and simulated maxima followed exponential distributions for the pot method and both followed the gumbel distribution for the am method donigan 2002 indicates that an absolute hydrologic model calibration validation target of less than 10 difference between the simulated and the observed hydrology flow is considered a very good target and that the range of such target should be applied on the mean and the individual events may show larger differences while still acceptable with this criteria in mind our swat evaluation results for the extremes were deemed adequate extreme quantiles for 2 20 and 100 year maxima streamflow levels showed that forecast results were in general greater than hindcast results for simulation pairs with the same climate modeling factors highlighting the non stationarity of extremes mentioned previously fig 7 illustrates hindcast simulations corresponding to pot extreme series method and all simulation results are shown in the supplementary on line table statistical downscaling of the hindcast gcm realizations in general under predicted hydrologic model results analyzed with the extreme series method and the under prediction was especially true for streamflow levels from the 100 year return period results from the dynamical downscaling hindcast realizations better bound the observed extremes the result supports the idea that regional climate models can capture small scale climate features e g strong fronts and realistically simulate extreme events fowler et al 2007 warner 2010 which would suggest a better choice for extreme streamflow forecasting fowler et al 2007 pointed out that the statistical downscaling methods poorly represent the extreme events and underestimate variance which reflects the fact that both bcsd and bcca methods use the distribution of precipitation from historical climate records to create the future distributions warner 2010 compared the statistical and dynamical downscaling with respect to their advantages and disadvantages and he indicated that dynamical downscaling methods could better capture extreme events and variance sunyer et al 2015 shows that the rcm gcm projections are the main source of variability in their results and between 30 and 50 of the total variance is explained by statistical downscaling in several catchments in their study tryhorn and degaetano 2011 compared several different downscaling methods for rainfall extremes over the northeastern united states and their results suggest that regional climate models overestimate the observed extremes aside from the tryhorn and degaetano 2011 results literature results and this study generally support the idea that hindcast extremes from dynamic downscaling agree better with observed extremes as compared to statistical downscaling results we also examined specific results of individual climate models and downscaling methods in order to provide insight on how climate model structure may be impacting forecasted streamflow maxima the four gcms from cmip3 all illustrate differences when comparing across the 2 20 and 100 year return periods fig 7 the result was not surprising given that gcm has been found as a significant factor in studies of forecasted mean streamflow and precipitation and climate scientists highlight variability of gcms due to the differences in the models structures and parameterizations randall et al 2007 weart 2010 mearns et al 2013 melillo et al 2014 al aamery et al 2016 given the many differences between the four gcms it is difficult to discern specific processes represented within the climate models that might be controlling the extreme streamflow forecasts however direct comparison of cmip3 and cmip5 model versions provided some discussion fig 7 reveals that ccsm has a pronounced difference between cmip3 and cmip5 forecasted streamflow maxima while the other gcms had gfdl and cgcm do not show differences between model versions for our analyses the reason is perhaps attributed to the newer version ccsm4 that produces el nino southern oscillation enso variability in a more realistic frequency distribution than ccsm3 by changing the deep convection scheme the had gfdl and cgcm models also made changes from cmip3 to cmip5 but these tend to have little differences in terms of streamflow extremes fig 7 the hadgem2 of cmip5 improved the performance of enso northern continent land surface temperature biases ssts and wind stress compared to the previous models however collins et al 2008 suggests that the power spectrum of el nino was not a substantial improvement gfdl version 3 cm3 used in cmip5 made minimal changes to the ocean and sea ice models compared to those used in cm2 1 version of cmip3 however the newer version is extensively developed the atmosphere and land model components griffies et al 2011 canesm2 of cmip5 combines the fourth generation atmospheric general circulation model cancm4 with terrestrial carbon cycle model ctem compared to the third generation of cancm3 that was used in cgcm3 1 of cmip3 cancm4 is different in many aspects such as the finer resolution and the addition of new schemes such as shallow convection scheme see chylek et al 2011 taken together of all the changes to the four different gcms between cmip3 and cmip5 only augmenting enso within the gcm seems to have a substantial impact on forecasted streamflow maxima the suggestion is reasonable given that enso has been suggested to show significant impacts on precipitation in this region of north america gabler et al 2009 results suggest that the el nino southern oscillation and its representation within climate modeling may exhibit a substantial control on forecasting streamflow maxima for the wet temperate study region and additional emphasis upon oscillations when forecasting streamflow maxima in wet temperate regions may be fruitful 5 2 uncertainty from climate and extreme modeling factors variance analysis results determined via anova showed that the variance structure of forecasted streamflow maxima exhibits some dependence on all of the climate modeling considered factors but does not exhibit dependence upon the extreme value method applied see fig 8 the results are interesting due the fact that previous variance analysis of mean streamflow forecasted from gcms only showed dependence on a subset of the climate modeling factors while debate in the literature suggests that am and pot methods would give different results scarrott and macdonald 2012 bezak et al 2014 al aamery et al 2016 specifically results of the anova fig 8 show that variance of the 2 year and 20 year streamflow maxima are significantly dependent upon gcm type downscaling method emission scenario gcm project phase and bias implementation and variance of the 100 year streamflow maxima is significantly dependent upon gcm type gcm project phase and bias implementation for reference results of forecasted mean streamflow are included in fig 8 and show dependence on gcm type and phase and downscaling the climate modeling factors that significantly influenced the forecasted streamflow maxima variances were ranked using the weighted f value according to their variance contribution see fig 8 as gcm type downscaling method bias implementation gcm version associated with the climate project phase and the emission scenario input to the gcm results of the ann non linear variance analysis compared well with linear analysis via anova see comparisons in fig 9 providing further confidence in our ranking results in addition to the variance breakdown the total variance of the forecasted extremes also displays pertinent information the total variance of streamflow extremes increased substantially with return period a result most easily observed with the standard error bars in fig 10 in addition the proportion of the variance that was predictable with the climate modeling factors tended to decrease with return period the result suggests a propagation of unexplainable variance throughout the analysis that becomes more pronounced with the higher order extremes associated with higher return periods we at least partially attribute the pronounced growth of uncertainty with return period to fitting the extreme value distributions to the hydrologic results the 100 year return period falls at the tail end of the gev and gp distributions i e f 0 99 and therefore uncertainty introduced in fitting the distributions will be most pronounced for the highest return periods to illustrate the point we performed sensitivity of the extreme value parameterization method by assuming a known parent gumbel distribution for mn drawing sets of realizations consistent with the years of data in our analyses and fitting the extreme value distribution consistent with the maximum likelihood method of our analyses as well as typically performed by others e g gilleland and katz 2016 results from the sensitivity show that the variance associated with the 100 year streamflow is about five times greater than that of the 2 year streamflow event see table 3 the result highlights one reason for pronounced increases in unexplainable variance within forecasted streamflow maxima on the other hand factorial comparison between the am and pot series fitted by the general extreme value gev and general pareto gp distributions did not show significance within the analysis of variance results the result is surprising given recent debate and critique of each method e g am is criticized for its neglect of multiple extremes per annum while pot has been criticized for subjectivity of threshold selection svensson et al 2005 scarrott and macdonald 2012 bezak et al 2014 fischer and schumann 2016 however further investigation of the literature suggests that the variance analysis result is consistent with fundamental theory and that the methods might be used interchangeably as needed so long as care is taken in their application fundamentally coles et al 2001 shows that the gev distribution provides the base that can be used to derive the gp distribution so long as the threshold point is sufficiently large and the events are independent and random in this manner we recommend that future coupled hydrologic and climate research studies that apply the pot method should strive for relatively high threshold values that fall within the rules of thumb outlined by scarrott and macdonald 2012 and ensure that the extremal index is not less than one see fig 3 one noteworthy comparison of the present study s results with previously published results is that the variance of forecasted streamflow maxima is even more sensitive to climate modeling factors as compared to the variance of mean forecasted streamflow specifically the variance of streamflow maxima showed significant dependence upon the choice of emission scenario and bias correction approach see fig 8 while the variance of mean streamflow did not exhibit significant dependence upon emission and bias see al aamery et al 2016 and results summarized in fig 8 the streamflow maxima s dependence upon emission scenario is worthy of mentioning given that the mean atmospheric co2 concentration projected for the emission scenarios varies by just 50 ppm for 2050 ipcc 2001 meinshausen et al 2011 further the mean annual temperature has a total range of just 1 5 c for 2050 across emission scenarios projected within the gcms applied in this study and the mean streamflow study of al aamery et al 2016 the subtle mean changes in co2 and mat for 2050 appear to mask temporal anomalies captured within the gcms the potential of emissions to help control streamflow maxima is somewhat corroborated by the work of mantua et al 2010 where they show streamflow maxima differences among two emission scenarios significance of emission scenario within variance analysis of forecasted streamflow maxima suggests that hydrologic and climate research is needed that examines how models might be coupled at a higher temporal resolution rather than the more prevalent emphasis on mean coupling e g see review table 1 in al aamery et al 2016 similarly the significance of bias correction upon the variance of forecasted streamflow maxima reflects the boundary between climate and hydrologic models that has emphasized mean coupling and thus linear shifts in rainfall and temperature data to show agreement with observations lenderink et al 2007 more sophisticated bias correction methods are available teutschbein and seibert 2012 but typically come with the added conundrum of forcing functional constraints on climate model results that are sought after due to their non stationarity surely research might consider higher resolution model coupling to understand anomalies that control maxima streamflow 5 3 uncertainty from hydrologic modeling future climate change of wind speed net radiation and relative humidity were tested within hydrologic simulation by considering projected shifts reported in the literature results suggest that the net impact of wind speed net radiation and relative humidity could provide an additional 1 5 increase in streamflow maxima for 2 20 and 100 year return periods for the wet temperate study region and future period considered see table 4 average daily change in evapotranspiration ranged from 0 5 to 5 decreases streamflow maxima increases and standard error associated with the wind speed radiation and relative humidity shifts were 3 2 1 7 2 2 1 6 and 1 9 1 6 for 2 20 and 100 year events relative to the increases of 27 21 36 34 and 49 85 for streamflow maxima associated with gcm projection of precipitation and temperature from ensemble analysis see fig 10 the effect of wind speed net radiation and relative humidity were small for this region nevertheless the effect is non zero and the variables may be more substantial in other regions or for forecasting to 2100 future projections that considered hydrologic model fit and hydrologic modeling uncertainty were also tested to investigate their impact on the relative change of streamflow maxima the future streamflow maxima produced from the calibrated hydrologic model simulation was compared against the future streamflow maxima produced using the un calibrated i e default parameterization of the hydrologic model for the realization pairs for the am extreme value analysis method n 74 results for the uncalibrated hydrologic analysis of the relative change in streamflow maxima were 19 28 20 35 and 24 59 for 2 20 and 100 year events in comparison to the calibrated model results equal to 27 23 35 30 and 49 92 for 2 20 and 100 year events results show that the uncalibrated model gives a much lower increase in future streamflow maxima compared to the calibrated model results especially for the 100 year extreme note that the default model simulations tended to under predict streamflow during peak events the simulation bias is carried forward to the extreme modeling results and is not removed when considering the relative change in this manner the variance of the streamflow maxima was dependent on hydrologic model parameterization these results contrast the work of niraula et al 2015 where we showed that the relative change in mean forecasted streamflow was not dependent on parameter selection during calibration the results further highlight the variance structure s sensitivity when forecasting streamflow extremes given the dependence on hydrologic calibration the hydrologic uncertainty realizations were also performed results suggest that hydrologic model parameter sets generated during uncertainty analysis also impart variance upon relative changes in streamflow maxima we calculated the error associated with the relative change in streamflow maxima using the parameter sets within swat cup that met model objective function criteria standard error was 3 1 3 3 and 3 6 for the relative change of 2 20 and 100 year events standard error is small in comparison to the error produced from climate and extreme modeling factors nevertheless the error is nonzero and may be larger for other regions we also calculated the standard error from absolute forecasted streamflow maxima and found values of 11 21 and 27 cms for 2 20 and 100 year events we compared these values with the standard error from direct bias correction of the streamflow maxima via the relative change approach and the standard error was 3 6 and 9 cms for 2 20 and 100 year events the results highlight that the delta method applied to the direct observed streamflow via the relative change does reduce hydrologic uncertainty relative to the absolute forecasts 5 4 forecast of streamflow maxima for wet temperate regions one corollary of variance analysis is inclusion of significant factors impacting prediction and thus forecasting of future streamflow the relative change in streamflow maxima were increases of 30 21 38 34 and 51 85 for the study region for 2 20 and 100 year events the increases are substantially larger than the 11 increases found for mean streamflow and mean precipitation for the study region al aamery et al 2016 additionally streamflow maxima increases as a function of return period the variability of the projections is pronounced and the uncertainty from climate and extreme model factors dominates the variance see table 5 the forecasted results of increased maxima streamflow in 2050 for the wet temperate region of north america 1120 mm y 1 is in agreement with scientific sentiment and forecasting that wet regions will get wetter and wet time periods will be wetter melillo et al 2014 we performed analysis of published maxima streamflow forecasts in wet regions of europe and their comparison corroborated the finding that maxima streamflow increases as a function of return period analysis of the results from lawrence and hisdal 2011 show an increase of maxima streamflow as a function of return period for norway 760 2250 mm y 1 also analysis of the results from dankers and feyen 2008 show an increase of maxima streamflow as a function of return period for their european sites studied where the mean annual precipitation was greater than 500 mm per year and is projected to be less in the end of this century the finding that forecasted maxima streamflow may show further increases as a function of return period further supports general scientific agreement that the most extreme flooding events will get even more extreme for wet temperate climates melillo et al 2014 this concept is reflected in the timing of streamflow increases and extremities in the present study and table 6 shows that the months of the year with the highest future changes in mean precipitation and streamflow tend to also account for the majority of forecasted streamflow maxima events during the study period the results also reflect the fundamental scientific consequences of climate change that is increased precipitation in wet regions is expected due to higher amounts of moisture in the atmosphere due to warmer atmospheric temperatures and expansion of the high sub tropical belt as the air temperature increases and moist air is transported to higher and lower latitudes gabler et al 2009 melillo et al 2014 in turn climate change in wet temperate region may increase precipitation temperature and relative humidity while decreasing wind speed and net radiation and the net effect both individually and cumulatively of all these shifts is an increase in streamflow maxima 6 conclusion the main conclusions of our work are described as follows 1 model simulation and evaluation results from comparison of different global climate model downscaling methods suggests that dynamic downscaling results more closely align with observations presumably due to the explicit simulation of small scale features such as strong fronts comparison of streamflow maxima forecasted with paired climate models from cmip3 versus cmip5 projects suggest that the el nino southern oscillation representation within modeling exhibits a control on forecasting streamflow maxima for the wet temperate region studied 2 uncertainty from climate and extreme modeling factors was evaluated and showed that the relative change of streamflow maxima was not dependent on systematic variance from the annual maxima versus peak over threshold method applied we find that the variance of streamflow maxima is an increasing function of the return period which is at least partly attributed to fitting the extreme value distributions to the hydrologic model results the variance of the relative change in streamflow maxima is dependent upon global climate model emission scenario project phase downscaling and bias correction 3 uncertainty from hydrologic modeling was analyzed and unlike results from previous research focused on the relative change of mean streamflow the relative change of streamflow maxima was dependent on hydrologic model fit and modeling uncertainty the streamflow maxima also showed some dependence on climate projections of wind speed net radiation and relative humidity 4 ensemble projections forecast an increase of streamflow maxima for 2050 with pronounced forecast standard error including 30 21 38 34 and 51 85 for 2 20 and 100 year events for the wet temperate region studied the variance of maxima projections was dominated by climate model factors and extreme value analyses with lesser control from hydrologic inputs and hydrologic model parameterization acknowledgements we thank editor mcvicar associate editor yongqiang zhang and anonymous reviewers for their excellent input and comments which in turn helped improve the quality of this paper we acknowledge partial support from nsf award number 1632888 to assist with study of the watershed and river system appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 03 038 appendix a supplementary data supplementary data 1 
7349,coupling global climate models hydrologic models and extreme value analysis provides a method to forecast streamflow maxima however the elusive variance structure of the results hinders confidence in application directly correcting the bias of forecasts using the relative change between forecast and control simulations has been shown to marginalize hydrologic uncertainty reduce model bias and remove systematic variance when predicting mean monthly and mean annual streamflow prompting our investigation for maxima streamflow we assess the variance structure of streamflow maxima using realizations of emission scenario global climate model type and project phase downscaling methods bias correction extreme value methods and hydrologic model inputs and parameterization results show that the relative change of streamflow maxima was not dependent on systematic variance from the annual maxima versus peak over threshold method applied albeit we stress that researchers strictly adhere to rules from extreme value theory when applying the peak over threshold method regardless of which method is applied extreme value model fitting does add variance to the projection and the variance is an increasing function of the return period unlike the relative change of mean streamflow results show that the variance of the maxima s relative change was dependent on all climate model factors tested as well as hydrologic model inputs and calibration ensemble projections forecast an increase of streamflow maxima for 2050 with pronounced forecast standard error including an increase of 30 21 38 34 and 51 85 for 2 20 and 100 year streamflow events for the wet temperate region studied the variance of maxima projections was dominated by climate model factors and extreme value analyses keywords extreme streamflow variance structure 1 introduction streamflow maxima is one of the most sought after response variables within hydrologic research and application coles et al 2001 begueria and vicente serrano 2006 reiss and thomas 2007 streamflow extreme maxima re contours the morphology of the fluvial system leopold et al 2012 partially controls the stream biogeochemical function ford et al 2015 can destroy human infrastructure melillo et al 2014 and resupplies human water stores for consumption food production and energy generation rosenzweig et al 2001 mirza 2003 mcmichael et al 2007 the complex earth system for which streamflow maxima responds is no less encompassing of hydrology than streamflow itself and includes components such as the climates ability to produce precipitation and weather patterns the watershed s physiogeographic configuration and ability to respond to precipitation and human s influence on both the watershed and climate despite hydrologists long historical emphasis upon study of streamflow extreme maxima current disparity is prevalent in terms of both streamflow maxima s current estimations and its gradient as we forecast into the future khaliq et al 2006 scientific gaps associated with estimating and forecasting current and future streamflow maxima is qualitatively attributed to scientific uncertainty surrounding human s economic behavior and influence on the earth system representation of the climate and its changes hydrologic representation of streamflow and scalar coupling of a changing climate within a hydrologic representation of the earth madsen et al 2014 ipcc 2013 the difficulty of streamflow extreme maxima estimation and forecasting in a non stationary earth system has challenged hydrologists to consider the potential use of new methodologies for investigating and forecasting streamflow one methodology for which streamflow maxima investigation and forecasting has received some recent attention is through the use of non stationary projection with global climate models that can be used to drive hydrologic and statistical forecasting prudhomme et al 2003 dankers and feyen 2008 mantua et al 2010 lawrence and hisdal 2011 zhang et al 2014 this method involves application of the non stationarity form of long term climate change projected using global climate models as a means to provide a physics based guideline for extrapolation lima et al 2015 shamir et al 2015 the global climate model results are post processed for scalar considerations and then propagated through hydrologic models for predicting multi year streamflow time series thereafter the extreme value theorem is adopted to study streamflow extremes because the theory provides a mathematical basis for the definition of extremes and has been used to prove that the distribution of extremes follow similarity at their limit e g coles et al 2001 somewhat analogous to the central limit theorem the extreme value theorem focuses on the statistical distribution and behavior of maxima that may arise from an unknown distribution for a population of a sequence of values measured over many time units in this manner hydrologists can statistically investigate current and forecast extreme value extreme maxima such as 2 20 and 100 year events via time series generated from the mentioned hydrologic modeling the coupling of global climate and hydrologic models for forecasting streamflow extreme maxima has been recently criticized for water infrastructure planning in some engineering and management circuits moradkhani 2017 and we tend to agree that use of the methodology in a infrastructure design capacity is a bit preliminary given that published applications and results of the method is still in its infancy yet we argue that the time is ripe for elucidating the variance structure of streamflow maxima forecasted with global climate models we offer several reasons for this contention first highlighting the variance structure of forecasted streamflow maxima provides hydrologic and climate researchers with knowledge of highly sensitive factors and parameters of streamflow forecasting that systemically increase the size of the solution space so that researchers might focus their attention towards improving model structure and parameterization second the variance structure of forecasted streamflow maxima allows researchers to see what extent the previous results of forecasted mean streamflow might be adopted and extrapolated for forecasting extremes there is a plethora of studies that forecast mean streamflow with global climate models chen et al 2011 al aamery et al 2016 fatichi et al 2014 and there is a question as to what extent results from these mean focused studies might be relevant to the study of extreme streamflow especially in light of the extra level of uncertainty that is introduced to forecasting maxima during application of the extreme value theorem third a reason for investigating the variance structure of forecasted streamflow maxima is to help provide balanced forecasts that can be compared with a meta analysis of trends in existing literature results such as in wet temperate regions while variance analysis of streamflow extreme maxima is sparse in the literature global climate model research and forecasting of mean annual and mean monthly streamflow tends to suggest that climate models are different in their structures and parametrizations randall et al 2007 downscaling methods are distinct in their structure and results to re scale global results wilby and dawson 2007 warner 2010 mearns et al 2013 emission scenarios address the uncertainty of future economic and co2 conditions ipcc 2007 ipcc 2013 the version of climate model projects are different in their structures and the newer version cmip5 is distinct relative older versions of models cmip3 brekke et al 2013 and the bias implementation of climate results is a source for variance presence in hydrologic models teutschbein and seibert 2012 al aamery et al 2016 and therefore all such components could have the potential to impact the variance structure of forecasted streamflow maxima the few studies that have forecasted streamflow maxima with global climate models see table 1 have results that tend to corroborate some findings from mean focused studies and suggest the type of global climate model applied caused differences in streamflow extreme forecasts prudhomme et al 2003 lawrence and hisdal 2011 and emission scenario can also shift extreme predictions dankers and feyen 2008 mantua et al 2010 zhang et al 2014 applications of extreme value theory suggest the statistical analysis associated with the choice of extreme value analysis method has the potential to impact the variance of forecasted streamflow maxima and the annual maxima method is criticized for its neglect of multiple extremes per annum while the peak over threshold method has been criticized for subjectivity of threshold selection svensson et al 2005 scarrott and macdonald 2012 bezak et al 2014 fischer and schumann 2016 beyond uncertainty surrounding the global climate model projections and extreme value methods there are additional uncertainty considerations with respect to the future hydrologic balance and its simulation when forecasting streamflow maxima as one example future changes in the hydrologic cycle and in turn streamflow are primarily driven by changes in precipitation and evapotranspiration studies that forecast streamflow maxima with global climate models have focused on precipitation and temperature differences within simulation of future periods mantua et al 2010 zhang et al 2014 however it is now recognized that evaporative demand is physically controlled by net radiation vapor pressure and wind speed as well as air temperature donohue et al 2010 future projections of these additional variables suggest decreases in wind speed and net radiation and an increase in relative humidity for some regions willett et al 2008 wild 2009 mcvicar et al 2012 the directions of the projected shifts would decrease evapotranspiration and in turn could potentially increase variability when forecasting streamflow maxima as a second example hydrologic model fit and modeling uncertainty when simulating the water balance has the potential to increase the variability of projected streamflow maxima al aamery et al 2016 recent study has tended to marginalize the importance of hydrologic model calibration and uncertainty for mean streamflow projections when considering relative future changes niraula et al 2015 however streamflow maxima has not yet been tested in this context to our knowledge our objectives were to 1 perform coupled climate hydrologic and statistical model simulation and evaluation to build realizations of streamflow maxima 2 perform variance analysis to test for systematic uncertainty from climate and extreme modeling factors potentially controlling streamflow maxima forecasting 3 perform uncertainty analysis to quantify variance from hydrologic modeling and 4 forecast streamflow maxima for the wet temperate region studied herein and provide literature comparison these objectives provide the structural sub headings used in the following methods results and discussion sections 2 theoretical background the variance structure of forecasted streamflow maxima can be decomposed as a function of potentially controlling modeling factors the conceptual model of factors that have the potential impact forecasted streamflow maxima variance is shown in fig 1 as can be seen in the figure modeling factors that may impact the variance structure can be grouped into those associated with climate modeling cmfs in fig 1 including global climate model gcm type hydrologic modeling hmfs and uncertainty in inputs and parameterization and statistical modeling of extremes smfs associated with different fitting methods and distributions land use and management modeling is not shown in the figure and was treated as static in this study but it is also recognized to potentially control future streamflow the response variables are streamflow maxima associated with different return periods including 2 20 and 100 year return periods so the distribution of extremes can be quantified lawrence and hisdal 2011 we consider response of the future relative change in streamflow equal to the percent difference of gcm forecasted streamflow maxima relative to gcm hindcast maxima δqf h x where x indicates the return period the future streamflow maxima can be related to the real streamflow maxima by using the relative changes derived from the forecast projections and hindcast control projections coupled with the observations such as using the delta method directly applied to streamflow model results the relative change approach has become rather popular in climate change studies that emphasize gcm forecasted streamflow chien et al 2013 harding et al 2012 fatichi et al 2014 niraula et al 2015 al aamery et al 2016 the approach has been suggested to remove seasonal spatial and or inter annual biases of gcms or statistical artifacts from the downscaling method that are not accounted for in bias correction methods harding et al 2012 in addition application of the relative change has recently shown no significant dependence upon calibrated versus un calibrated hydrologic model simulation thus suggesting the response variable does not require model calibration to see the projected direction of future streamflow niraula et al 2015 the approach has also shown less dependence upon climate modeling factors i e cmfs in fig 1 as compared to the absolute forecasted streamflow suggesting that biases specific to a model structure could be accounted al aamery et al 2016 while the relative change approach has shown potential in past studies these studies have tended to focus on the mean forecasting of streamflow in the present study we consider the method for streamflow maxima which is one contribution of this paper realizations of the relative change in streamflow maxima can be simulated as a function of climate hydrologic and statistical modeling factors within a variance analysis ensemble al aamery et al 2016 in the present study we included permutations using seven emission scenarios i e emission factor cmf1 propagated through eight different gcms associated with phase three and four climate projects i e cmip3 cmip5 i e gcm type and version factors cmf2 3 that were downscaled using two statistical downscaling methods and four dynamical downscaling methods i e downscaling factor cmf4 further our post processing and hydrologic analyses of downscaled hindcast 1983 2000 and forecast 2048 2065 climate model results considered bias correction i e bias factor smf1 propagated through a continuous simulation hydrologic model we performed both annual maxima and peak over threshold extreme value analyses i e extreme value factor smf1 2 of hydrologic model results given recent debate in the literature over the best method we also investigated additional uncertainty considerations with respect to additional hydrologic inputs and hydrologic uncertainty hmf 1 3 3 study site and materials the study site was south elkhorn watershed in lexington kentucky usa see fig 2 this watershed is within a wet and temperate region where a future change in climate including an increase in precipitation and temperature is projected melillo et al 2014 according to melillo et al 2014 a 20 30 increase in annual maximum precipitation is projected under rcp 8 5 emission scenario for the end of the century additionally at least 80 of the models used in melillo et al 2014 are in agreement for this region the watershed covers an area of 478 6 km2 with surface elevations ranging between 197 and 325 m asl the land use is dominated by agricultural equal to 72 the remaining land uses are urban suburban equal to 13 forest equal to 14 and open water and wetlands equal to 1 the results of eight gcms were implemented in this analysis the gcm models reflected four different gcm model types and two versions of each model including a version from cmip3 and the newer version from cmip5 brekke et al 2013 al aamery et al 2016 the gcms included the canadian global climate model including cgcm3 from cmip3 and canesm2 from cmip5 flato 2005 the national center for atmospheric research community climate model including ccsm3 from cmip3 and ccsm4 from cmip5 collins et al 2006 the geophysical fluid dynamics laboratory including gfdl cm2 1 from cmip3 and cm3 from cmip5 delworth et al 2006 and the united kingdom hadley centre climate model including hadcm3 from cmip3 and hadgem2 es from cmip5 gordon et al 2000 these gcms were chosen for their representation in different climate projects including cmip3 cmip5 and narccap projects and their available archives of climate results for the current and future periods focused on in this study brekke et al 2013 mearns et al 2013 al aamery et al 2016 statistical downscaling and dynamical downscaling results were included in this analysis the statistical downscaling results were used from the coupled model inter comparison project phase three cmip3 and phase five cmip5 brekke et al 2013 the dynamical downscaling results were used from the north american regional climate change assessment program narccap mearns et al 2013 these downscaling methods represent two distinct approaches for downscaling gcm results from their coarse scale to a finer watershed scale the statistical downscaling method is statistically based and adopts empirical statistical relationships to estimate the small scale climate variables based on the large scale atmospheric variables wilby and dawson 2007 the statistical downscaling method implemented in cmip3 and cmip5 projects adopt two schemes including bias correction and spatial disaggregation bcsd and bias correction and constructed analogs bcca brekke et al 2013 the dynamical downscaling method is physically based and uses regional climate models rcms whose boundary conditions are forced by the results of the parent gcm to simulate the atmospheric physical processes on a regional scale warner 2010 six regional climate models were implemented through the narccap project including the canadian regional climate model crcm plummer et al 2006 the experimental climate prediction center ecpc model juang et al 1997 the hadley regional model 3 hrm3 jones et al 2004 the mm5 psu ncar mesoscale model mm5i chen and dudhia 2001 the reginal climate model version 3 rcm3 giorgi et al 1993 and the weather research and forecasting model wrfp skamarock et al 2005 4 methods 4 1 modeling simulations and evaluation the soil and water assessment tool swat the version was arcswat 2012 10 1 13 model was applied to simulate the hydrology of south elkhorn watershed this model is physically based and was applied successfully in this region and many other regions around the world palanisamy and workman 2014 gassman et al 2007 arnold et al 1998 the model was evaluated over 1981 2000 using the observed climate and streamflow data and applied for the hindcast period 1981 2000 and forecast period 2046 2065 using the gcms results of daily precipitation and maximum and minimum temperature see fig 3 in al aamery et al 2016 for evaluation methods of swat we obtained all the data required by swat including topography soil and landuse data from publically available databases the topography and streamlines data were obtained from the national map website http viewer nationalmap gov viewer and the soil data was obtained from the data gateway website http websoilsurvey sc egov usda gov app websoilsurvey aspx the landuse data of 1992 was used from the usgs website http www mrlc gov nlcd2011 php the observed climate data of daily precipitation and maximum and minimum temperature were obtained from bluegrass airport meteorological gage station the model was evaluated using four usgs streamflow gage stations within the watershed including south elkhorn creek at fort spring usgs03289000 town branch at yarnallton road usgs03289200 south elkhorn creek near midway usgs03289300 and elkhorn creek near frankfort usgs03289500 results for the south elkhorn creek near midway station were analyzed for the relative change in streamflow maxima model evaluation including calibration validation and sensitivity analysis was performed semi automatically via swat cup software for sequential uncertainty fitting sufi2 for the four gage stations in the watershed abbaspour et al 2007 the first two years was left as a spin up period for swat arnold et al 2010 as input to the hydrologic modeling the scaling of precipitation and temperature method of lenderink et al 2007 was applied to correct the bias in the climate data the method operates with monthly correction values based on the difference between observed and current period simulated values as 1 p sc d p sc d μ m p obs d μ m p sc d 2 p sf d p sf d μ m p obs d μ m p sc d 3 t sc d t sc d μ m t obs d μ m t sc d and 4 t sf d t sf d μ m t obs d μ m t sc d where p sc ast d and t sc d are the corrected daily precipitation and temperature for the simulated current period p sf d and t sf d are the corrected daily precipitation and temperature for the simulated future period p sc d and t sc d are the uncorrected daily precipitation and temperature for the simulated current period p sf d and t sf d are the uncorrected daily precipitation and temperature for the simulated future period μ m p obs d is the average of observed daily precipitation values for a given month μ m p sc d is the average daily precipitation for the current simulated values μ m t obs d is the average of observed daily temperature values μ m t sc d is the average of daily temperature for the current simulated period and m stands for within monthly time step the annual maxima am and peak over threshold pot methods were carried out for each realization from the hydrologic modeling results in order to analyze the extremes see fig 3 the am series is constructed by selecting one value per a specific time over the sample size in streamflow studies such as herein this value is the maximum water discharge value selected over one year from the daily time series data khaliq et al 2006 haan 2002 thereby the am series replaces the flow series q1 q2 q365 of a year j by the largest flood value qm j where 1 m total number of days in year j 1 j n and n is the number of years according to the extreme theorem the probability of the rescaled m n is approaching the general extreme value gev family when n the gev family distribution is expressed as follows 5 g q exp 1 ξ q μ σ 1 ξ where q 1 ξ q μ σ 0 the location parameter μ the scale parameter σ 0 and the shape parameter ξ depending on the value of the shape parameter ξ the gev family has three distinct probability distributions the light tail gumbel type when ξ 0 the heavy tail fréchet type when ξ 0 and the bounded upper tail weibull type when ξ 0 the extreme quantiles of the return level t when ξ 0 are then calculated as follows 6 q t μ σ ξ 1 log 1 1 t ξ and when ξ 0 7 q t μ σ log log 1 1 t the pot series was constructed by selecting all independent and identically distributed values q1 q2 that are higher than a specific and carefully chosen value called threshold point qo see example in fig 4 according to extreme value theory for large enough qo the distribution function of y q qo conditioned by q qo is approximated by the generalized pareto gp family as follows coles et al 2001 8 h y 1 1 ξ y σ 1 ξ where y y 0 and 1 ξ y σ 0 and σ σ ξ q o μ q is a specific value in the sequence q1 q2 and σ μ and ξ are the scale location and shape parameters depending on the value of the shape factor the gp family consists of three probability distribution functions as follows the heavy tail pareto type when ξ 0 the light tail exponential type when ξ 0 and bounded upper tail beta type when ξ 0 to calculate the extreme quantile q t of the return period t the probability ζ q o pr q q o is calculated first and then the return period when ξ 0 is given by 9 q t q o σ ξ ζ q o t ξ 1 when ξ 0 the return level of a period t is given by 10 q t q o σ log t ζ q o threshold point choice we adopted the parameter stabilization method explained by coles et al 2001 to choose threshold points used within the pot method the method is based on fitting the general pareto distribution across a range of different threshold points when fitting the model parameters including the shape parameter ξ and scale parameter σ were estimated for each point across the range the shape parameter should be approximately constant and the scale parameter should be linear in q when the gp distribution is valid above the qo coles et al 2001 fig 4 shows an example of fitting the gp model using the maximum likelihood method over a range of 1 40 for the threshold point as observed the shape and the reparametrized scale parameters are nearly stable until reaching the point 21 we therefore specified the point 21 cms as the threshold point for the pot series of the observed daily streamflow series in this example and the method was repeated for each model hydrologic realization performed in our study in order to support our choice of the threshold we compared our final results of threshold selection using the parameter stabilization method with three rules of thumb presented by scarrott and macdonald 2012 using general order statistics convergence properties methods including the upper 10 rule square root rule k 1 n and k 2 n 2 3 log log n rule were developed see scarrott and macdonald 2012 fig 4 shows that our choices compared well to the three methods temporal independency in the pot series the values of the pot series in the sense of extreme theorem should admit to the temporal independence condition by only selecting all values that are higher than the threshold point we will obviously violate this condition within a streamflow time series therefore to identify and remove the time dependency in the pot series values de clustering of the pot series was adopted the de clustering was performed by calculating the extremal index θ as follows coles et al 2001 11 θ limiting mean clustering size 1 where θ equal to one indicates an independent series therefore the objective was to minimize the size of the clusters until θ reaches one our approach was to make manual iteration for each pot series to select the number of threshold deficits r used to define a cluster moreover to support our independent choices of pot series we performed the auto tail dependence function plots for the data series reiss and thomas 2007 to test the dependency of the events in the series trend analysis we analyzed the pot and the am series with respect to the non stationarity explained by trend analysis we used the mann kendall nonparametric test to identify the presence of trends in each independent pot and am series haan 2002 if the trend was present we removed the trend from the series although as will be discussed in the results very few series exhibited a significant mean trend likelihood ratio test the likelihood ratio test was used to test the null hypothesis of the shape factor ξ to be zero this test is used in statistics to test the goodness of fit of two distributions when one of them is a special case of the other i e nested models hogg et al 2014 coles et al 2001 in our case the gumbel distribution is nested within the gev distribution and the exponential distribution is nested within the gp distribution currently the am and pot series are the only two types of flood peak series that can be used for flood frequency analysis and further discussion of a comprehensive comparison between the two series is provided in the literature in bezak et al 2014 and madsen et al 1997 to perform all the methods described in the extreme analysis methods section and shown in fig 3 we have applied the r package extremes version 2 0 described in gilleland and katz 2016 4 2 uncertainty from climate and extreme modeling factors our results from the coupled climate hydrologic and extreme modeling methods produced 226 realizations of model runs available for variance analysis based on a factorial design that considered emission type gcm type and version downscaling type bias correction and extreme value method type each factor was divided within variance decomposition as follows the gcm type factor was divided into four levels for the four parent models mentioned previously the gcm version factor was divided into two levels indicating cmip3 and cmip5 project phases of the models the downscaling factor was divided into two levels for statistical and dynamical methods the emission factor was divided into seven levels including the sres type used in cmip3 a1b a2 and b1 and the rcps type used in cmip5 rcp2 6 rcp4 5 rcp6 0 and rcp8 5 the bias factor was divided into two levels indicating inclusion of methods in eqs 1 4 or lack thereof and the extreme value factor was divided into two levels for am and pot methods further details of the factorial levels for each of the 226 realizations are provided in the supplementary on line table we simulated variance analysis following both more traditional linear methods and more recently published nonlinear methods in order to maintain robustness of the analyses linear analysis of variance anova we performed statistical analysis through fitting the linear analysis of variance model anova to the results of the maxima extreme analysis anova was applied separately for each streamflow maxima quantile the extreme quantiles represent the response variables of 2 year 20 year and 100 year return periods δqf h 2 year me δqf h 20 year me and δqf h 100 year me respectively via the general linear model univariate procedure in spss 22 software pallant 2005 anova explores the effect of different factors on the variance of the response using the p value of the statistical test and ranking factor importance by using the f value the f value of each factor was divided by the summation of f values in a single model to determine how much variance that factor explains from the total predictable variance several considerations were determined when applying anova methods first because the datasets were not represented in the climate factors equally we applied four separate models that balanced a set of factors the reason for the multiple models is attributed to our climate datasets where the cmip3 project has both statistically and dynamically downscaled results while the cmip5 project has only statistically downscaled results we also have different emission scenarios between the two projects cmip3 has sres emission scenarios and cmip5 has rcps emission scenarios we built therefore four way anova models as the highest possible order to constrain the balanced and nested models fig 5 shows four possible 4 way anova models that we built from our factorial design second we analyzed the factors across the models using the highest possible order however if a factor was found to be unimportant we omitted the factor to maximize repetitions anova assumes that the population is normally distributed although the violation of this assumption should not cause major problems when the sample size is greater than 30 pallant 2005 gravetter and wallnau 2000 stevens 1996 in our factorial design the least sample size was recorded in anova model 3 where the sample size was 56 therefore our concern about the normality assumption is limited the homogeneity of variance assumption was treated by using the levene test for the equality of variance pallant 2005 if the data failed in this test the significant level by which we compare the variances of the different groups in the anova models was 0 01 which overcomes the violation of this assumption pallant 2005 nonlinear artificial neural network ann ann models on the other hand were considered in this study to reinforce our robustness of the variance analysis anns provides a model framework based on a set of multivariate nonlinear functions and therefore could account for nonlinearity between factors controlling variance and the streamflow response variable if it exists in this manner anns could overcome the underlying multivariate linear model limitation that anova is based on we used the ann model to examine the climate factors importance on streamflow maxima projections through spss 22 software ibm 2012 tufféry 2011 the input layer represented the climate and the statistical factors with nominal variables and the output layer represented the relative change in streamflow maxima we used one hidden layer with a randomly generated number of neurons we used supervised training with multilayer perceptron and feedforward architecture all values of the input and output layers were normalized so that all values ranged between 0 and 1 the hyperbolic tangent activation function was considered in the hidden layer we used the same four models proposed in the anova analysis to perform the ann analysis the dataset partitioning was performed with spss ann to divide the data into training and testing datasets however through generation of random numbers within spss ann the partitioning values of training and testing will swing around the 70 and 30 marks for each run of many runs performed for each model the values of training partitioning ranged between 60 and 80 affecting the testing portion and providing a new relative error value for both training and testing parts accordingly the smallest relative error provides the best results for the ann model ibm 2012 therefore our approach was to use an initial 70 of the dataset for training and the rest for testing and then rerun the model until obtaining the minimum possible relative errors across the training and testing data 4 3 uncertainty from hydrologic modeling additional uncertainty from the future hydrologic balance and its simulation were also quantified as part of our study future projections of net radiation vapor pressure and wind speed were tested in simulation for the study region with the premise that decreases in wind speed and net radiation and an increase in relative humidity could decrease future evapotranspiration and in turn increase streamflow maxima while at the same time increase uncertainty of forecasts future projections that consider hydrologic model fit and hydrologic parameter uncertainty were also tested to assess the potential to increase the variability of projected streamflow maxima future climate change of wind speed net radiation and relative humidity were tested within hydrologic simulation by considering projected shifts reported in the literature the average monthly wind speed in the study site ranges between 3 and 5 m s according to mcvicar et al 2012 the possible stilling in the middle of the current century is approximately 0 5 m s for the study site region when assuming a linear trend of their observations reported therein in turn the percent climate change of wind speed is between 10 and 17 for the future period in the study region wild 2009 indicates that the surface solar radiation has a decadal variation and that the absolute trend was observed as 6 w m 2 per decade and 8 w m 2 per decade for the periods of 1961 1990 and 1995 2007 respectively over the united states we recognized that increasing radiation would offset decreasing wind speed when estimating evapotranspiration and therefore we considered the decreasing trend of 6 w m 2 per decade for the future period in order to test its sensitivity the mean daily solar radiation ranges throughout the year between 81 w m 2 1 9 kw h m 2d 1 and 300 w m 2 7 2 kw h m 2d 1 considering the mentioned net decrease produces a change in the solar radiation reaching the surface to be between 4 and 15 regarding the relative humidity willett et al 2008 shows data that suggests an increase in the relative humidity for the northern hemisphere the net increase shown was 0 07 for the 10 year period of investigation we assumed the same change for the future period which resulted in a range between 0 4 and 0 5 for the study region donohue et al 2010 showed that the penman equation produced the most reasonable estimation of evaporation demand and this method is included within the hydrologic model used in the present study therefore we considered a number of scenarios in hydrologic modeling that test the mentioned ranges of wind speed net radiation and relative humidity concurrently to see their added impact on streamflow maxima we also tested the variables independently to see their individual sensitivity upon the streamflow maxima future projections that consider hydrologic model fit and hydrologic modeling uncertainty were also tested with the hydrologic model to investigate their impact on forecasted streamflow maxima recent literature results have marginalized the importance of model fit when forecasting the relative change in future mean streamflow niraula et al 2015 and we tested this concept for future streamflow maxima the future streamflow maxima produced from the calibrated hydrologic model simulation for a set of gcm realizations was compared against the future streamflow maxima produced using the un calibrated i e default parameterization of the hydrologic model for the same climate realizations additionally the impact of hydrologic model uncertainty was considered by carrying forward uncertainty projections from the hydrologic model parameterization to the extreme value methods and thereafter to compute the relative change in future streamflow the swat cup software provides parameter sets and solutions used to create uncertainty bounds during the model simulation realizations of all parameter sets that meet the objective function criteria were chosen and extreme value methods were performed for hindcast and forecast global climate pairs to compute the relative change in streamflow maxima 4 4 forecast of streamflow maxima for wet temperate regions after quantifying the climate hydrologic and extreme modeling factors controlling variability of the projections an ensemble was created to forecast the relative change in the streamflow maxima for the wet temperate study region al aamery et al 2016 the extreme forecasts for this study calculated the net effect on the mean and variance of the balanced ensemble from variation of climate modeling factors and extreme modeling factors the added uncertainty from hydrologic model parameterization and the added mean shift and its variance from climate change shifts in net radiation vapor pressure and wind speed results were compared with other studies reported in the literature of streamflow maxima see table 1 that fell within wet temperate regions 5 results and discussion 5 1 modeling simulations and evaluation results from the model evaluation showed that the hydrologic model performed within an acceptable range and the simulated and observed daily streamflow signals showed close agreement see fig 6 the four quantitative matrics including coefficient of determination r2 percent bias pbias nash sutcliff efficiency ns and the ratio of the root mean square error to the standard deviation of measured data rsr showed results within the acceptable range moriasi et al 2007 donigan 2002 gassman et al 2007 in both calibration and validation periods for the majority of the four observation sites for which the model was compared against see compiled metrics in table 2 although one of the four sites showed values just below or equal to the acceptable range boundary during validation overall 53 out of the 56 metrics that compared observations with model results were above the acceptable range showing that the model simulated streamflow well according to moriasi et al 2007 the monthly time step model performance is considered satisfactory if the ns 0 5 rsr 0 7 and pbias 25 the model performance on finer time steps e g daily is usually poorer than the coarser time steps model e g monthly in terms of the statistical matrices e g ns rst pbias moriasi et al 2007 engel et al 2007 for instance while the monthly ns was 0 656 for the calibration period in fernandez et al 2005 the daily one was 0 395 moreover moriasi et al 2007 indicated that when reviewing previous studies ns and pbias were as expected lower in the validation period than the calibration period for streamflow note that the midway station was our primary calibration since all of the model s streamflow forecasts occurred from this location the model we established for south elkhorn watershed showed results for the midway gage station to have ns values equal to 0 9 and 0 66 for the monthly and daily time steps respectively for the calibration period and ns values equal to 0 88 and 0 46 for the monthly and daily time steps respectively for the validation period in summary the metrics showed adequate performance considering the above information and results results from fitting both the am and pot extreme series methods to the streamflow results showed that in general the extreme series results had little mean trend and were dominated by the two parameter probability distributions see supplementary on line table the mann kendall test results showed that only 2 of the am series included a mean trend that required removal and only 4 of pot series results had a mean trend that required removal a regression approach was also carried out and provided identical results as the mann kendall tests the results highlight that although non stationarity is exhibited when comparing extremes from the hindcast to the forecast periods little significant non stationarity is exhibited within the simulation periods statistical results showed that 91 of the am series best followed the two parameter gumbel distribution while 85 of the pot series best followed the exponential distribution the results tend to agree with the results of dankers and feyen 2008 who also found that a two parameter distribution was most adequate when fitting distributions from extreme value theory to streamflow results derived from global climate modeling additional results from the extreme value analyses is also compiled in the supplemental on line table and includes threshold selections the value of the extremal index θ before de clustering the value of r required to make the extremal index θ equal to unity the p value of mann kendall non parametric test and the resultant sample size n we found less than 10 difference between observed and simulated maxima for all return periods i e 2 20 and 100 year return periods for both am and pot methods both observed and simulated maxima followed exponential distributions for the pot method and both followed the gumbel distribution for the am method donigan 2002 indicates that an absolute hydrologic model calibration validation target of less than 10 difference between the simulated and the observed hydrology flow is considered a very good target and that the range of such target should be applied on the mean and the individual events may show larger differences while still acceptable with this criteria in mind our swat evaluation results for the extremes were deemed adequate extreme quantiles for 2 20 and 100 year maxima streamflow levels showed that forecast results were in general greater than hindcast results for simulation pairs with the same climate modeling factors highlighting the non stationarity of extremes mentioned previously fig 7 illustrates hindcast simulations corresponding to pot extreme series method and all simulation results are shown in the supplementary on line table statistical downscaling of the hindcast gcm realizations in general under predicted hydrologic model results analyzed with the extreme series method and the under prediction was especially true for streamflow levels from the 100 year return period results from the dynamical downscaling hindcast realizations better bound the observed extremes the result supports the idea that regional climate models can capture small scale climate features e g strong fronts and realistically simulate extreme events fowler et al 2007 warner 2010 which would suggest a better choice for extreme streamflow forecasting fowler et al 2007 pointed out that the statistical downscaling methods poorly represent the extreme events and underestimate variance which reflects the fact that both bcsd and bcca methods use the distribution of precipitation from historical climate records to create the future distributions warner 2010 compared the statistical and dynamical downscaling with respect to their advantages and disadvantages and he indicated that dynamical downscaling methods could better capture extreme events and variance sunyer et al 2015 shows that the rcm gcm projections are the main source of variability in their results and between 30 and 50 of the total variance is explained by statistical downscaling in several catchments in their study tryhorn and degaetano 2011 compared several different downscaling methods for rainfall extremes over the northeastern united states and their results suggest that regional climate models overestimate the observed extremes aside from the tryhorn and degaetano 2011 results literature results and this study generally support the idea that hindcast extremes from dynamic downscaling agree better with observed extremes as compared to statistical downscaling results we also examined specific results of individual climate models and downscaling methods in order to provide insight on how climate model structure may be impacting forecasted streamflow maxima the four gcms from cmip3 all illustrate differences when comparing across the 2 20 and 100 year return periods fig 7 the result was not surprising given that gcm has been found as a significant factor in studies of forecasted mean streamflow and precipitation and climate scientists highlight variability of gcms due to the differences in the models structures and parameterizations randall et al 2007 weart 2010 mearns et al 2013 melillo et al 2014 al aamery et al 2016 given the many differences between the four gcms it is difficult to discern specific processes represented within the climate models that might be controlling the extreme streamflow forecasts however direct comparison of cmip3 and cmip5 model versions provided some discussion fig 7 reveals that ccsm has a pronounced difference between cmip3 and cmip5 forecasted streamflow maxima while the other gcms had gfdl and cgcm do not show differences between model versions for our analyses the reason is perhaps attributed to the newer version ccsm4 that produces el nino southern oscillation enso variability in a more realistic frequency distribution than ccsm3 by changing the deep convection scheme the had gfdl and cgcm models also made changes from cmip3 to cmip5 but these tend to have little differences in terms of streamflow extremes fig 7 the hadgem2 of cmip5 improved the performance of enso northern continent land surface temperature biases ssts and wind stress compared to the previous models however collins et al 2008 suggests that the power spectrum of el nino was not a substantial improvement gfdl version 3 cm3 used in cmip5 made minimal changes to the ocean and sea ice models compared to those used in cm2 1 version of cmip3 however the newer version is extensively developed the atmosphere and land model components griffies et al 2011 canesm2 of cmip5 combines the fourth generation atmospheric general circulation model cancm4 with terrestrial carbon cycle model ctem compared to the third generation of cancm3 that was used in cgcm3 1 of cmip3 cancm4 is different in many aspects such as the finer resolution and the addition of new schemes such as shallow convection scheme see chylek et al 2011 taken together of all the changes to the four different gcms between cmip3 and cmip5 only augmenting enso within the gcm seems to have a substantial impact on forecasted streamflow maxima the suggestion is reasonable given that enso has been suggested to show significant impacts on precipitation in this region of north america gabler et al 2009 results suggest that the el nino southern oscillation and its representation within climate modeling may exhibit a substantial control on forecasting streamflow maxima for the wet temperate study region and additional emphasis upon oscillations when forecasting streamflow maxima in wet temperate regions may be fruitful 5 2 uncertainty from climate and extreme modeling factors variance analysis results determined via anova showed that the variance structure of forecasted streamflow maxima exhibits some dependence on all of the climate modeling considered factors but does not exhibit dependence upon the extreme value method applied see fig 8 the results are interesting due the fact that previous variance analysis of mean streamflow forecasted from gcms only showed dependence on a subset of the climate modeling factors while debate in the literature suggests that am and pot methods would give different results scarrott and macdonald 2012 bezak et al 2014 al aamery et al 2016 specifically results of the anova fig 8 show that variance of the 2 year and 20 year streamflow maxima are significantly dependent upon gcm type downscaling method emission scenario gcm project phase and bias implementation and variance of the 100 year streamflow maxima is significantly dependent upon gcm type gcm project phase and bias implementation for reference results of forecasted mean streamflow are included in fig 8 and show dependence on gcm type and phase and downscaling the climate modeling factors that significantly influenced the forecasted streamflow maxima variances were ranked using the weighted f value according to their variance contribution see fig 8 as gcm type downscaling method bias implementation gcm version associated with the climate project phase and the emission scenario input to the gcm results of the ann non linear variance analysis compared well with linear analysis via anova see comparisons in fig 9 providing further confidence in our ranking results in addition to the variance breakdown the total variance of the forecasted extremes also displays pertinent information the total variance of streamflow extremes increased substantially with return period a result most easily observed with the standard error bars in fig 10 in addition the proportion of the variance that was predictable with the climate modeling factors tended to decrease with return period the result suggests a propagation of unexplainable variance throughout the analysis that becomes more pronounced with the higher order extremes associated with higher return periods we at least partially attribute the pronounced growth of uncertainty with return period to fitting the extreme value distributions to the hydrologic results the 100 year return period falls at the tail end of the gev and gp distributions i e f 0 99 and therefore uncertainty introduced in fitting the distributions will be most pronounced for the highest return periods to illustrate the point we performed sensitivity of the extreme value parameterization method by assuming a known parent gumbel distribution for mn drawing sets of realizations consistent with the years of data in our analyses and fitting the extreme value distribution consistent with the maximum likelihood method of our analyses as well as typically performed by others e g gilleland and katz 2016 results from the sensitivity show that the variance associated with the 100 year streamflow is about five times greater than that of the 2 year streamflow event see table 3 the result highlights one reason for pronounced increases in unexplainable variance within forecasted streamflow maxima on the other hand factorial comparison between the am and pot series fitted by the general extreme value gev and general pareto gp distributions did not show significance within the analysis of variance results the result is surprising given recent debate and critique of each method e g am is criticized for its neglect of multiple extremes per annum while pot has been criticized for subjectivity of threshold selection svensson et al 2005 scarrott and macdonald 2012 bezak et al 2014 fischer and schumann 2016 however further investigation of the literature suggests that the variance analysis result is consistent with fundamental theory and that the methods might be used interchangeably as needed so long as care is taken in their application fundamentally coles et al 2001 shows that the gev distribution provides the base that can be used to derive the gp distribution so long as the threshold point is sufficiently large and the events are independent and random in this manner we recommend that future coupled hydrologic and climate research studies that apply the pot method should strive for relatively high threshold values that fall within the rules of thumb outlined by scarrott and macdonald 2012 and ensure that the extremal index is not less than one see fig 3 one noteworthy comparison of the present study s results with previously published results is that the variance of forecasted streamflow maxima is even more sensitive to climate modeling factors as compared to the variance of mean forecasted streamflow specifically the variance of streamflow maxima showed significant dependence upon the choice of emission scenario and bias correction approach see fig 8 while the variance of mean streamflow did not exhibit significant dependence upon emission and bias see al aamery et al 2016 and results summarized in fig 8 the streamflow maxima s dependence upon emission scenario is worthy of mentioning given that the mean atmospheric co2 concentration projected for the emission scenarios varies by just 50 ppm for 2050 ipcc 2001 meinshausen et al 2011 further the mean annual temperature has a total range of just 1 5 c for 2050 across emission scenarios projected within the gcms applied in this study and the mean streamflow study of al aamery et al 2016 the subtle mean changes in co2 and mat for 2050 appear to mask temporal anomalies captured within the gcms the potential of emissions to help control streamflow maxima is somewhat corroborated by the work of mantua et al 2010 where they show streamflow maxima differences among two emission scenarios significance of emission scenario within variance analysis of forecasted streamflow maxima suggests that hydrologic and climate research is needed that examines how models might be coupled at a higher temporal resolution rather than the more prevalent emphasis on mean coupling e g see review table 1 in al aamery et al 2016 similarly the significance of bias correction upon the variance of forecasted streamflow maxima reflects the boundary between climate and hydrologic models that has emphasized mean coupling and thus linear shifts in rainfall and temperature data to show agreement with observations lenderink et al 2007 more sophisticated bias correction methods are available teutschbein and seibert 2012 but typically come with the added conundrum of forcing functional constraints on climate model results that are sought after due to their non stationarity surely research might consider higher resolution model coupling to understand anomalies that control maxima streamflow 5 3 uncertainty from hydrologic modeling future climate change of wind speed net radiation and relative humidity were tested within hydrologic simulation by considering projected shifts reported in the literature results suggest that the net impact of wind speed net radiation and relative humidity could provide an additional 1 5 increase in streamflow maxima for 2 20 and 100 year return periods for the wet temperate study region and future period considered see table 4 average daily change in evapotranspiration ranged from 0 5 to 5 decreases streamflow maxima increases and standard error associated with the wind speed radiation and relative humidity shifts were 3 2 1 7 2 2 1 6 and 1 9 1 6 for 2 20 and 100 year events relative to the increases of 27 21 36 34 and 49 85 for streamflow maxima associated with gcm projection of precipitation and temperature from ensemble analysis see fig 10 the effect of wind speed net radiation and relative humidity were small for this region nevertheless the effect is non zero and the variables may be more substantial in other regions or for forecasting to 2100 future projections that considered hydrologic model fit and hydrologic modeling uncertainty were also tested to investigate their impact on the relative change of streamflow maxima the future streamflow maxima produced from the calibrated hydrologic model simulation was compared against the future streamflow maxima produced using the un calibrated i e default parameterization of the hydrologic model for the realization pairs for the am extreme value analysis method n 74 results for the uncalibrated hydrologic analysis of the relative change in streamflow maxima were 19 28 20 35 and 24 59 for 2 20 and 100 year events in comparison to the calibrated model results equal to 27 23 35 30 and 49 92 for 2 20 and 100 year events results show that the uncalibrated model gives a much lower increase in future streamflow maxima compared to the calibrated model results especially for the 100 year extreme note that the default model simulations tended to under predict streamflow during peak events the simulation bias is carried forward to the extreme modeling results and is not removed when considering the relative change in this manner the variance of the streamflow maxima was dependent on hydrologic model parameterization these results contrast the work of niraula et al 2015 where we showed that the relative change in mean forecasted streamflow was not dependent on parameter selection during calibration the results further highlight the variance structure s sensitivity when forecasting streamflow extremes given the dependence on hydrologic calibration the hydrologic uncertainty realizations were also performed results suggest that hydrologic model parameter sets generated during uncertainty analysis also impart variance upon relative changes in streamflow maxima we calculated the error associated with the relative change in streamflow maxima using the parameter sets within swat cup that met model objective function criteria standard error was 3 1 3 3 and 3 6 for the relative change of 2 20 and 100 year events standard error is small in comparison to the error produced from climate and extreme modeling factors nevertheless the error is nonzero and may be larger for other regions we also calculated the standard error from absolute forecasted streamflow maxima and found values of 11 21 and 27 cms for 2 20 and 100 year events we compared these values with the standard error from direct bias correction of the streamflow maxima via the relative change approach and the standard error was 3 6 and 9 cms for 2 20 and 100 year events the results highlight that the delta method applied to the direct observed streamflow via the relative change does reduce hydrologic uncertainty relative to the absolute forecasts 5 4 forecast of streamflow maxima for wet temperate regions one corollary of variance analysis is inclusion of significant factors impacting prediction and thus forecasting of future streamflow the relative change in streamflow maxima were increases of 30 21 38 34 and 51 85 for the study region for 2 20 and 100 year events the increases are substantially larger than the 11 increases found for mean streamflow and mean precipitation for the study region al aamery et al 2016 additionally streamflow maxima increases as a function of return period the variability of the projections is pronounced and the uncertainty from climate and extreme model factors dominates the variance see table 5 the forecasted results of increased maxima streamflow in 2050 for the wet temperate region of north america 1120 mm y 1 is in agreement with scientific sentiment and forecasting that wet regions will get wetter and wet time periods will be wetter melillo et al 2014 we performed analysis of published maxima streamflow forecasts in wet regions of europe and their comparison corroborated the finding that maxima streamflow increases as a function of return period analysis of the results from lawrence and hisdal 2011 show an increase of maxima streamflow as a function of return period for norway 760 2250 mm y 1 also analysis of the results from dankers and feyen 2008 show an increase of maxima streamflow as a function of return period for their european sites studied where the mean annual precipitation was greater than 500 mm per year and is projected to be less in the end of this century the finding that forecasted maxima streamflow may show further increases as a function of return period further supports general scientific agreement that the most extreme flooding events will get even more extreme for wet temperate climates melillo et al 2014 this concept is reflected in the timing of streamflow increases and extremities in the present study and table 6 shows that the months of the year with the highest future changes in mean precipitation and streamflow tend to also account for the majority of forecasted streamflow maxima events during the study period the results also reflect the fundamental scientific consequences of climate change that is increased precipitation in wet regions is expected due to higher amounts of moisture in the atmosphere due to warmer atmospheric temperatures and expansion of the high sub tropical belt as the air temperature increases and moist air is transported to higher and lower latitudes gabler et al 2009 melillo et al 2014 in turn climate change in wet temperate region may increase precipitation temperature and relative humidity while decreasing wind speed and net radiation and the net effect both individually and cumulatively of all these shifts is an increase in streamflow maxima 6 conclusion the main conclusions of our work are described as follows 1 model simulation and evaluation results from comparison of different global climate model downscaling methods suggests that dynamic downscaling results more closely align with observations presumably due to the explicit simulation of small scale features such as strong fronts comparison of streamflow maxima forecasted with paired climate models from cmip3 versus cmip5 projects suggest that the el nino southern oscillation representation within modeling exhibits a control on forecasting streamflow maxima for the wet temperate region studied 2 uncertainty from climate and extreme modeling factors was evaluated and showed that the relative change of streamflow maxima was not dependent on systematic variance from the annual maxima versus peak over threshold method applied we find that the variance of streamflow maxima is an increasing function of the return period which is at least partly attributed to fitting the extreme value distributions to the hydrologic model results the variance of the relative change in streamflow maxima is dependent upon global climate model emission scenario project phase downscaling and bias correction 3 uncertainty from hydrologic modeling was analyzed and unlike results from previous research focused on the relative change of mean streamflow the relative change of streamflow maxima was dependent on hydrologic model fit and modeling uncertainty the streamflow maxima also showed some dependence on climate projections of wind speed net radiation and relative humidity 4 ensemble projections forecast an increase of streamflow maxima for 2050 with pronounced forecast standard error including 30 21 38 34 and 51 85 for 2 20 and 100 year events for the wet temperate region studied the variance of maxima projections was dominated by climate model factors and extreme value analyses with lesser control from hydrologic inputs and hydrologic model parameterization acknowledgements we thank editor mcvicar associate editor yongqiang zhang and anonymous reviewers for their excellent input and comments which in turn helped improve the quality of this paper we acknowledge partial support from nsf award number 1632888 to assist with study of the watershed and river system appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 03 038 appendix a supplementary data supplementary data 1 
