index,text
5460,in this paper we evaluate the performance of 8 statistical and machine learning methods driven by atmospheric synoptic patterns for long term daily rainfall prediction in a semi arid climate tenerife spain cross validation is used to reconstruct 36 years of daily rainfall data at 17 gauges prediction is independent for each gauge the reconstructed series are compared with the observed records in order to select the optimal hyperparameters within each family of models the predictive performance of the models is evaluated using several metrics and statistics related with rainfall intensity and occurrence at daily monthly and annual aggregation scales multivariate and univariate analysis of variance are used to evaluate the differences among models the results of our work demonstrate that the performance of most machine learning models is very sensitive to the selected hyperparameters neural networks are found to perform best to predict rainfall occurrence and intensity all methods underestimate the variance of the observed series at daily time scales generalized linear models using gamma distributed errors perform best for predicting rainfall extremes however their performance limits its practical applications results improve significatively at larger temporal aggregations monthly or annual making statistical and machine learning methods more valuable for water resources studies keywords rainfall prediction regression machine learning extremes statistical downscaling 1 introduction today the most reliable measure of the intensity of precipitation at a specific point continues to be that obtained from meteorological stations located on the ground i e instrumental data adeyewa and nakamura 2003 hasan et al 2016 wang et al 2019 this kind of information with a sufficient temporal coverage usually of several decades is not commonly available in most areas of the world buytaert et al 2012 however on site rainfall information with such a temporal coverage is essential in many fields such as water resources management flood risk assessment and climatological analysis for instance to detect possible climatic trends in rainfall series among others nkiaka et al 2017 sun et al 2018 altunkaynak and nigussie 2015 pumo et al 2017 aryal 2018 park et al 2019 historical rainfall data to complement instrumental records can also be obtain from other sources such as satellites huffman et al 2010 radars austin and seed 2005 and numerical models pfeifroth et al 2013 satellites and radars provide short precipitation time series that start in the best case scenario in the 1990s pfeifroth et al 2013 burlando et al 1996 chen et al 2020 li et al 2020 reanalysis models however are able to provide more than 50 years of continuous data throughout the globe kalnay et al 1996 saha et al 2010a dee et al 2011 in spite of their long time coverage reanalysis databases present some other limitations such as a large bias especially in mountainous areas an overestimation of rain events with small and medium intensities an underestimation of the most intense events and serious difficulties to simulate small scale physical processes wang et al 2019 bosilovich et al 2008 nkiaka et al 2017 moreover rainfall data from reanalysis databases cannot be directly compared to point records since model results are equivalent to spatial averages over fixed areas pixels del jesus et al 2015 diez sierra and del jesus 2019 several authors have investigated different techniques to predict long time series of historical rainfall covering decades in the past to overcome the aforementioned limitations of the different sources of information this predicted rainfall time series strengthen the robustness of technical analysis and help managers and decision makers to implement optimal strategies to problems in the fields of water resources li et al 2020 this discipline is known as long term rainfall prediction gupta and ghose 2015 and it normally relies on regression techniques of which a varied plethora can be found in literature including parametric and nonparametric methods linear and non linear ones qiu et al 2016 pérez rodríguez et al 2012 kannan and ghosh 2013 he et al 2015 yu et al 2017 he et al 2015 generalized linear models logistic regression and support vector machines with linear kernels are parametric models with a limited number of parameters while k nearest neighbors decision trees support vector machines with radial basis function kernels and neural networks are nonparametric models where the number of parameters can grow with the size of the training set sheskin 2003 the increase in computational capacity has favored the use of machine learning techniques over other regression methods hong 2008 zhao et al 2020 in part because the form of the relationship between the variables does not need to be known or assumed a priori besides linear regressions are meant to describe linear relationships abbot and marohasy 2017 and rely on some hypothesis normality of errors homoscedasticity etcetera which may be relaxed with the use of machine learning methods in this paper generalized linear models and several machine learning methods support vector machines k nearest neighbors random forests k means clustering and neural networks are analyzed for long term daily rainfall prediction using atmospheric synoptic patterns from reanalysis databases the main motivation of the present study is to compare the skill of the methods mentioned above to extend the temporal coverage of rainfall time series to several decades in the past using shorter historical records and atmospheric synoptic patterns from reanalysis database as predictors the atmospheric patterns present a greater temporal coverage than instrumental data allowing to effectively extend the rainfall information several studies have investigated this topic in the past olsson et al 2004 sumi et al 2012 valverde ramírez et al 2005 showing that all algorithms seem to have their advantages and limitations making the selection of the best overall algorithm difficult gupta and ghose 2015 however none of the studies made to date performed a comparison as exhaustive as the one presented here making use of the main methods found in literature for rainfall prediction besides unlike most studies we analyze the results not only in order to preserve some evaluation metrics but also including several rainfall statistics such as daily variance duration of the dry and wet spells spatial correlation and some extremal indexes among others which are very important for hydrological response characterization serrano notivoli et al 2018 furthermore in our study all comparisons among models are made on the basis of robust statistical tests and not merely on an analysis of differences which may not be statistically robust the methods presented herein can be applied worldwide as long as instrumental precipitation data is available in the area as reanalysis databases do normally have global coverage and could also be extrapolated for their use in climate change studies however our analysis is carried out in a semi arid climate tenerife spain where rainfall scarcity and heterogeneity complicates the generation of accurate predictions 17 gauges and more than 36 years of daily data are used to evaluate our methods predictions are done independently for each station in our analysis we make use of open license open source standard tools pedregosa et al 2011 r core team 2017 that are cross platform easily installable and deployable in any hardware system for any application some methods found in literature have been further developed for specific applications however they have not been considered in the analysis as their use is not widespread and are not fully cross platform yet sharma et al 2016 adnan et al 2019 2 study area and data sources 2 1 description of the study area tenerife is one of the seven islands that form the spanish archipelago of the canary islands tenerife is located in the atlantic ocean 300 km west of the african coast between parallels 28 n and 29 n and between meridians 16 w and 17 w tenerife displays a strong topographic gradient from the coast to the central part of the island the central region of the island is a mountain range where el teide 3 718 m is the highest peak that separates the island in two well differentiated climatic areas a northern region relatively wet due to the effect of the trade winds and a southern region drier due to the blocking induced by the orography see fig 1 climatic spatial heterogeneities are also present within each region configuring a widely varied range of climates within a relatively small area diez sierra and del jesus 2017 2 2 rainfall data rainfall data is provided by consejo insular de agua de tenerife ciatf 2018 the water planning and managing agency for tenerife island ciatf maintains a database of rainfall observations melián et al 2011 that includes the observation network of agencia estatal de meteorología aemet 2018 the spanish national meteorological agency and of agrocabildo agrocabildo 2018 a local agency for agriculture development the ciatf database contains information for 125 gauges combining daily and sub daily values with an average coverage of 15 years although the longest series start in 1890 only the gauges containing the best information were included in the analysis three criteria were considered during gauge selection 1 gauges should cover as long a time period as possible 2 all gauges should cover the same reference period to reduce the uncertainty associated with using different climatic time periods in the fitting procedure and 3 all climatic regions of the island should be covered by the selection to compare the predictive skill of the models under different conditions following these considerations all stations with at least 25 years of data in the period 1979 2015 were selected fig 1 shows the location white dots and the identifier four digit white numbers of the 17 rainfall gauges selected for the analysis which are representative of the climate of the island rain gauges were selected to cover as much territory as possible with the longest and most complete rainfall records for the period 1979 2015 as we show in table 1 precipitation in tenerife is very scarce with an annual average of 371 mm and 45 rainy days for the 17 gauges selected temporal and spatial distribution of rainfall is very heterogeneous since a very high percentage of precipitation falls in short periods of time and with a great spatial heterogeneity largely due to the topography of the island seasonality is very remarkable rainy season takes place mostly during the boreal winter november december and january while the dry season covers most of the boreal summer june july and august 2 3 atmospheric data atmospheric variables inform statistical and machine learning methods about the state of the atmosphere thus they constitute the main predictor for rainfall the state of the atmosphere for tenerife island is properly captured as described in previous analysis found in literature by herrera et al 2001 and tullot 1959 by the combined fields of sea level pressure slp elevation of the 500 hpa geopotential surface gh500 and elevation of the 850 hpa geopotential surface gh850 these fields cover the area between 45 w and 5 e and 20 n and 50 n see fig 2 spatial atmospheric information is obtained from the global reanalysis ncep climate forecast system reanalysis cfsr saha et al 2010b developed by the national oceanic and atmospheric administration noaa cfsr is a third generation reanalysis database generated with a global high resolution land ocean atmosphere model coupled with an ice sheet model cfsr provides 6 hourly data the spatial resolution of the atmospheric model is 38 km horizontally with 64 vertical levels the spatial resolution of the oceanic model is approximately 0 25 near the equator and 0 5 beyond the tropics with 40 vertical levels the land model counts 4 soil levels and the ice model 3 levels cfsr covers the period 1979 2015 3 methods statistical and machine learning methods will be trained or fitted to predict daily rainfall using atmospheric predictors data from 17 rain gauges will be used for the analysis keeping 80 of the data of each station for fitting the models training and the remaining 20 for evaluating their prediction skill testing 36 years long original time series for each rainfall gauge are split in two sets the training set containing 30 years of data and the testing containing the remaining 6 models are trained independently for each station machine learning techniques can be fine tuned through hyperparameters that control their behavior hyperparameters may select the optimization routine used for fitting the regularization scheme used and the non linear transformation applied to the input data among other things the training set is used to determine the optimal hyperparameters by k fold cross validation markatou et al 2005 the optimal hyperparameters are selected from a factorial grid the 30 years of the training set are thus further subdivided into k subsets k 1 sets are used to train the model and the kth one is used to evaluate the performance of those hyperparameters in unseen data validation for each set of candidate hyperparameters the process is repeated k times determining an average performance of the hyperparameters and selecting the best performing set predictive performance is evaluated over the test set that was not used for training neither for selecting the optimal hyperparameters of each method see fig 3 predictive performance for rainfall occurrence and rainfall intensity is considered different loss functions will be used to explore their capabilities to capture different rainfall statistics 3 1 construction of the predictors to construct the atmospheric fields used as predictors in this paper cfsr data is aggregated into daily time scale 13 514 days for the whole period of analysis over a 0 5 0 5 mesh forming a 60 100 elements matrix for each day the atmospheric information consists of three 3 60 100 elements matrices in total one for slp one for gh500 and one for gh850 each number in the matrix represents the value of the field at a specified location it is the component of the field on a basis vector that takes a value of one for that location and zero everywhere else the matrices for each day can be combined and rearranged as a vector of 1800 components 60 100 3 that are stacked together to form a matrix of 1 800 13 514 elements containing all the atmospheric information for the whole period of analysis the atmospheric information for each day could be interpreted as a data point in a 1 800 dimensional space however the correlations existing among the values of a variable at different locations or among different variables at the same or at different locations makes many of these dimensions redundant and uninformative these correlations may disturb and even spoil the fitting procedure of the regression and machine learning models gutiérrez et al 2004 to reduce these correlations while maintaining their discriminant power the atmospheric patterns are standardized and then transformed through principal components analysis pca abdi and williams 2010 the pca method constructs an alternative basis to represent the original data that is optimal in the sense that each basis vector captures as much variation of the original data not captured by previous basis vectors as possible the first basis vector generated by the pca method is thus aligned with the direction of maximum variation of the original data each successive basis vector is orthogonal to all the previous ones it does not capture variability in the direction of previous basis vectors and captures as much variation as possible for a single vector the application of the pca method renders a more workable representation of the original data as some dimensions in the new basis may be dropped with a reduced impact in the amount of information lost in addition the pca method significantly reduces the number of predictors thus reducing also the computational cost derived from training the different statistical and machine learning models many climate studies have explored different configurations of the predictors one including direct information from the predictors from neighboring grid points another including principal components as predictors and a last one including both preisendorfer 1988 san martín et al 2017 all configurations including principal components exhibit a similar overall performance while the one that only included information of the predictor from the closest reanalysis grid box suffered from a large seasonal variability of the bias and worse predictions gutiérrez et al 2013 these results indicate that the principal components from pca constitute better predictors than the variables alone most probably because the principal components aggregate spatial information from all the domain of the spatial predictor after application of the pca method to the original matrix 1 800 13 514 elements 95 of the variance of the original data set can be captured by keeping only the first 14 principal components the components over the first 14 basis vectors generated by pca the atmospheric information predictor is thus a matrix with 14 13 514 elements representing the time series of 13 514 days for 14 predictors pca components in addition to the atmospheric variables we incorporate seasonality as a predictor seasonality introduces a non stationarity in the distribution of rainfall that must be considered for accurate predictions a simple way to include this non stationarity is to use as predictor some function that mimics the shape of the average monthly rainfall throughout the year the simplest analytical function able to reproduce that shape is a combination of a sine y 1 sin 2 π t and a cosine y 2 cos 2 π t of period t 12 months the sine and cosine functions y 1 and y 2 will be two additional predictors given to the statistical and machine learning techniques informing these methods about the differences existing among months méndez et al 2007 3 2 statistical and machine learning methods statistical methods traditionally used to predict precipitation are based on classical linear regression models lrm and generalized linear models glm that allow for response variables presenting non gaussian error distributions coe and stern 1982 stern and coe 1984 however with increasing computational power machine learning approaches have extended the options of rainfall prediction techniques qiu et al 2016 machine learning techniques have two major advantages they do not normally require any assumption about the distribution of errors and the form of the relationships between predictors and predictands does not need to be known a priori appelhans et al 2015 the intermittency of rainfall at daily time scales the succession of wet and dry intervals of finite duration makes it more convenient to split the prediction problem into two steps thus rainfall occurrence and rainfall intensity are modeled separately olsson et al 2004 for this reason statistical and machine learning techniques are separated into two categories classifiers that deal with categorical data rain and no rain aimed at predicting rainfall occurrence and regressors that deal with continuous data aimed at predicting rainfall intensity table 2 enumerates all the statistical and machine learning models used in this analysis the first column shows the model name the second column corresponds to the abbreviation abbr the third column shows whether the method is used for classification c regression r or both c r the forth column enumerates the hyperparameters optimized during the analysis and finally the fifth column lists the values of the hyperparameters explored in the model optimization step the implementation of the methods found in the stats library r core team 2017 and the scikit learn library pedregosa et al 2011 were used in this work in the present work two statistical glms methods are used on the one hand glm l which corresponds to classical lineal regression but assuming a logarithmic relation between predictor and predictand the logarithm link function transforms the data to increase their similarity to a gaussian distribution improving the quality of the fit on the other hand glm g which assumes that errors follow a gamma distribution the gamma distribution is commonly used to model rainfall because the distributions of precipitation amount tend to be strongly skewed at daily time scales ben alaya et al 2017 stephenson et al 1999 yang et al 2005 six different machine learning methods are used in the analysis random forest rf is an ensemble learning method that constructs a multitude of decision trees at training time and predicts the mode of the predicted classes classification or the mean of the predictions regression of the individual trees two hyperparameters are analyzed for optimization n estimators that corresponds to the total number of trees in the forest and min samples leaf that is the minimum number of samples required to be at a leaf node a node over which the mode or the mean are computed k nearest neighbors k nn is a non linear method whose predictions are computed through the weighted mode classification or the weighted mean regression of the k nearest points to the one being predicted two hyperparameters are analyzed for optimization n neighbors that corresponds to the number of neighbors used in the prediction and weights that is the weight function used in prediction uniform means that all points in the neighborhood are equally weighted while distance means that points are weighted by the inverse of their distance neural networks nn learns a mapping between a series of input features input layer and an output output layer through linear combinations and non linear transformations of the inputs received by every neuron in the network hidden layer three hyperparameters are analyzed for optimization hidden layer sizes that is the number of neurons and layer used activation that defines the non linear function that each neuron uses to transform the linear combination of inputs it receives and alpha a term controlling regularization strength by penalizing weights with large magnitudes support vector machines svm perform classification and regression tasks by finding the hyperplanes that maximize the margins the minimum gap separating samples belonging to different groups the closest values to the classification margin are known as support vectors radial basis function rbf kernels are used to ensure separation is possible in non linear spaces three hyperparameters are analyzed for optimization γ that is the radius of the area of influence of the support vectors c that can be seen as the inverse of the regularization strength and ε which defines a margin of tolerance where no penalty is given to errors logistic regression lr classifies binary outcomes modeling the logit transformed probability of occurrence through linear regression three hyperparameters are analyzed for optimization solver that is the algorithm used in the optimization problem penalty that is the regulation function applied to the weights of the regression and c that can be seen as the inverse of the regularization strength like in svm finally weather typing wt which divides the input space into regions and uses the mode or mean of the region in which the candidate point lies to solve the classification or regression problem in this specific application weather types are computed using the k means algorithm camus et al 2011 turning weather types into representative synoptic atmospheric patterns diez sierra and del jesus 2017 wt is the only method in which predictions are done simultaneously for all the gauges a more detailed description of the hyperparameter selection as well as the sensitivity of the models to each of them can be found at scikit learn 2019 3 3 loss functions a loss function measures the distance between the value estimated by a statistical or machine learning method and the objective value the model is supposed to predict the fitting procedure of any statistical or machine learning method involves finding the values of the parameters that optimize the value of the loss function in most cases the loss function used to fit regression models is the sum of squared errors either with a focus on bias or variance an advantage of machine learning methods is that the loss function can be easily customized so that values predicted by the model may minimize any convenient function in the present work two different loss functions are used depending on the objective of the fitting procedure classifiers used mainly to predict rainfall occurrence or probability are fitted using f score 1 f score 2 precision recall precision recall with precision being defined as 2 precision tp tp fp and recall as 3 recall tp tp fn where tp means true positives the number of observed rainy days correctly predicted as rainy days by the model fp means false positives the number of observed non rainy days predicted as rainy days by the model and fn means false negatives the number of observed rainy days predicted as non rainy days by the model precision measures the probability that a predicted rainy day by the model corresponds with a real rainy day a true positive while recall measures the probability that a real rainy day is correctly predicted by the model a true positive a value of one 1 in both measures represents a perfect score while zero 0 is the minimum value for both metrics a model that only predicts rainy days when rainfall really occurs but misses some observed rainy days predicting a non rainy day would have a perfect precision a value of 1 but would have a recall smaller than one 1 as some events would have not been properly recognized false negatives exist a model that predicts rainy days when rainy days really occur but also in some non rainy days would have a perfect recall but a precision smaller than one 1 as false positives are present in the prediction the f score metric is very useful to compare the skill of model predictions when working with imbalanced datasets datasets in which one class is much more frequent than the others this is the case of rainfall in tenerife where rainy days are rare with an average value for the 17 gauges of 15 of the days however the proportion of rainy days can vary from 25 for some gauges located in the north of the island to 5 for other gauges located in the south regressors which aim to predict the intensity of rain are evaluated using the root mean squared error rmse as loss function 4 rmse t 1 n x 1 t x 2 t 2 n where x 1 and x 2 correspond to the observed and the simulated rainfall series respectively although not used as a loss function bias bias and pearson correlation r as defined in eqs 5 and 6 respectively are also used as evaluation metrics for the models 5 bias t 1 n x 1 t x 2 t n 6 r t 1 n x 1 t x 2 t n x 1 x 2 t 1 n x 1 t 2 n x 1 2 t 1 n x 2 t 2 n x 2 2 in eqs 5 and 6 x 1 t and x 2 t correspond to the observed and the simulated rainfall series respectively and n is the sample size 3 4 grid search before evaluating the predictive performance on the original test set the optimal hyperparameters for each class of models shown in table 2 are determined hyperparameters are chosen from a factorial grid the fourth column of table 2 shows the hyperparameters tuned for each model and the fifth column shows the explored values the specified model is trained with different hyperparameters and evaluated over the training set using k fold cross validation markatou et al 2005 the k fold cross validation approach avoids overfitting and the appearance of spurious effects of any particular partition of the input data k fold cross validation implies dividing the training set in k equal sized subsets using k 1 subsets to train the model and evaluating the performance on the kth subset the one not used for model training the procedure is repeated k times using each of the k subsets one time to evaluate performance the average performance of the k trainings is assigned to the hyperparameters and the optimal hyperparameters are the ones that maximize the performance of the model in this study k is taken equal to 5 so that 80 of the original training data are used for training and the remaining 20 used for validating the hyperparameters each training set is thus split in five subsets using 4 sets for fitting the model and 1 for validation grid search involves in the present study fitting over 25 000 different models the number 25 000 results from the combination of different models regressors and classifiers with their respective hyperparameters and the 17 gauges 3 5 model evaluation as we mentioned in the subsection 3 2 rainfall occurrences and rainfall intensity are modeled separately on the one hand the models defined as classifiers in table 2 are used to reconstruct the entire time series of rainfall occurrence for the 17 gauges independently to this end the continuous time series of precipitation are transformed into binary series 0 norain 1 rain before training f score is the loss function applied for all classifiers eq 1 on the other hand the models defined as regressors in table 2 are used to reconstruct the entire time series of rainfall for the 17 gauges independently all values larger than 0 1 mm day are used in the analysis the loss function in this case is rmse see eq 4 seasonality sine and cosine functions is included as a predictor for the rainfall occurrence and intensity 4 results 4 1 hyperparameter sensitivity analysis during the cross validation procedure several sets of hyperparameters are tested to find the optimal one the performance of all the tested hyperparameters sets both for classifiers and regressors are shown in fig 4 the left hand panel of the figure shows the classifier s performance through f score while the right hand panel shows the regressor s performance through the pearson correlation coefficient r the figure shows the distribution of f score and r values for the different models and for every rainfall station by means of histograms and kernel density estimates of the probability density function both f score and r have a range of values from 0 to 1 the vertical dashed line represents the middle of the range the value of 0 5 an analysis of the distributions for the classifiers reveals that the performance of logistic regression lr and support vector machines svm does not depend much on the value of the hyperparameters used indeed the distributions of f score for these two models are almost dirac s deltas these models will therefore present a skill mostly dependent on the characteristics of the covariates and the predicted series but cannot be easily adapted by tuning their hyperparameters a similar case although not so extreme would be weather typing wt that shows little sensitivity to hyperparameter selection however its performance tends to be lower than the two previous methods on the opposite side of the spectrum neural networks nn presents a widely spread distribution indicating a high sensitivity to hyperparameter tuning nn performance is highly dependent on the hyperparameter values used during training indeed their performance may be the worst of all models as can be seen by the amount of probability concentrated around zero skill but with a proper hyperparameter calibration they can provide the best predictions over all models finally random forests rf and k nearest neighbors k nn constitute a middle ground among models their performance is sensitive to the values of the hyperparameters but their spread is narrower than for nn the right hand side of fig 4 shows that in general regressors are more sensitive to hyperparameters values than classifiers except for wt that shows a smaller variation on performance as hyperparameters are varied all the other models present wide distributions indicating a high sensitivity to hyperparameter tuning another important result of this analysis is that the optimal hyperparameter set for a given method changes for each gauge see tables a 11 and a 12 in supplementary materials the only exception being wt for which the same number of clusters maximized the dunn index criterion baarsch and celebi 2012 for all gauges despite this variability some conclusions can be derived from the analysis regression requires more complicated models than classification as it could be expected for instance rf requires a higher number of trees n estimators and a higher minimum number of samples in each leaf node min samples leaf to predict rainfall intensity than rainfall occurrence a similar result is observed with the number of neighbors required in the prediction n neighbors for k nn a higher number of neighbors is required to predict rainfall intensity than rainfall occurrence in the case of svm two properties are pursued a hyperplane with the largest minimum margin c and a hyperplane that correctly separates as many instances as possible for large values of the regularization term c the optimization will choose a smaller margin hyperplane while a lower c will encourage a larger margin and a simpler decision function cherkassky and ma 2004 suggests that with an optimal choice of the hyperparameter ε which defines the margin of tolerance where no penalty is given to errors the value of c has negligible effects on the performance as long as c is larger than a certain threshold determined from the training data thus we recommend to first define the threshold of c and then set the value of hyperparameter ε svm in scikit learn presents a default value of ε equal to 0 1 however the magnitude of ε must be increased to reduce bias larger values of ε are normally required especially for very large and or noisy training sets mattera and haykin 1999 nn uses parameter α for regularization which helps in avoiding over fitting by penalizing weights with large magnitudes as in svm nn in scikit learn presents a default value of α equal to 0 0001 we found that the hyperparameter α must be increased several orders of magnitude to avoid over fitting in some of the gauges hyperparameter hidden layer sizes in nn defines the number of neurons and layers used the values in the parenthesis correspond to the number of neurons and layers respectively see tables a 11 and a 12 as we can see the number of layers required are 1 for all the gauges except in 2 of the cases in contrast the number of neurons can vary from 2 to 20 activation functions in nn introduce non linear properties to our model rectified linear units relu f x max 0 x and hyperbolic tangent tahn f x tanh x activation functions are selected in most of the gauges identity activation function that establishes linear relationships is only selected twice tables 3 and 4 show the average skill during training and testing for all methods results are calculated as the average result of the 17 gauges as expected most models present better skill in training that in testing as mentioned in section 3 in order to avoid over fitting we apply cross validation on 80 of the original training set cross validation serves to select the best hyperparameters then we check that the skill of the methods remains similar in the remaining 20 of unseen data test despite this decomposition of the original data rf and k nn over fit as seen by the difference of the skill between training and testing in the case of k nn this fact can be explained because the optimal number of neighbors selected for prediction is equal to 1 for several gauges for these gauges the k nn model selects from the training set the rainfall value associated to the most similar atmospheric synoptic pattern for each prediction reaching a perfect fit during training something similar happens with rf and the hyperparameter min samples leaf when the value selected in the cross validation is too small rf predicts values very similar to those seen during training to avoid over fitting the hyperparameters n estimators and min samples leaf in the case of rf and n neighbors for k nn should be forced to take higher values even when the training skill is degraded however attention must be paid in order not to force the model to under fit the high variability showed in fig 4 demonstrates that it is essential to calibrate the hyperparameters prior to any application 4 2 modeling rainfall occurrence the average performance of every model for predicting rainfall occurrence is shown in table 3 nn with an average f score close to 0 4 appears as the best performing model closely followed by lr and svm the complete set of f scores for every gauge can be found in table a13 in supplementary materials rf and k nn provide worse results whereas the wt based method shows the worst predictive performance far below the rest of the models the skill of the prediction is substantially better for gauges located in the north of tenerife that in the south see table 1 this is probably because classifiers are more able to capture the underlying relationship in frontal precipitations which dominates in the north of the island than the convective processes prevailing in the south in general the performance of nn classifiers seems superior on all gauges except for a few cases like gauge id 2115 where svm did a better job than nn in order to verify the hypothesis of the superior skill of nn classifiers a test of significance was carried out multiple t tests were carried out to verify which models presented significant differences among them making use of the holm correction method holm 1979 in order to counteract the problem of multiplicity t tests were carried out over the f score metric table 5 shows the results of these tests indicating where the differences in these two model comparisons were significant it can be seen that nn presents significantly better results than the other models allowing us to conclude that nn are the best performing model for predicting rainfall occurrence lr and svm are placed second presenting significantly better results than rf k nn and wt another important metric to evaluate is the performance of a model predicting exceedances over a threshold as this will indicate the skill of the model predicting the most intense rainfall events rainfall occurrence over four thresholds 0 1 5 20 and 40 mm day is analyzed recall measures how many of the positive samples observed rainy days with an intensity larger than a specific thresholds are captured by the positive predictions simulated rainy day recall has the advantage of not involving the false positives type i errors values in the analysis table 6 shows the average recall metric for the 17 gauges and the selected thresholds the table shows that the recall metric is higher for all classifiers as the value of the threshold increases reaching 0 63 for the nn classifier for the threshold of 40 mm day the increase of the recall metric with the increasing thresholds indicates that larger rainfall events are easier to predict as they are more dependent on atmospheric synoptic situations rainfall persistence is another important characteristic linked to rainfall occurrence it can measured by transition probabilities that indicate the probability of having a dry day followed by another dry day ϕ dd and having a wet day followed by another wet day ϕ ww table 7 shows the mean μ median m and the 25th q 1 and 75th q 3 percentiles calculated from the 17 gauges the statistics give us an idea of the distribution of values for the 17 stations although the mean μ and median m might seem redundant we decided to show both statistics because the median m is more robust in the presence of outliers than the mean as we can see in table 7 all methods are able to preserve the observed obs ϕ dd with very small errors however they underestimate the observed values of ϕ ww if fact some of them give large errors when comparing the predicted and the observed values of ϕ ww such as wt k nn and rf methods nn lr and svm again present the best average results however they still underestimate ϕ ww in approximately 25 of the observed values nn presents the smallest error predicting ϕ ww mainly due to its better ability to predict rainy days as table 7 demonstrates all the statistics μ m q 1 and q 3 calculated from the simulated series underestimate the observed ones which implies that the simulated distribution of ϕ ww is displaced to lower values the complete set of observed and simulated transition probabilities ϕ dd and ϕ ww for every gauge can be found in table a 14 in supplementary materials interesting results are found when the skill of classifiers to reproduce the number of wet days per month and year is analyzed fig 5 shows a scatter plot of the observed and simulated number of wet days per month for all classifiers and gauges as we can observe nn lr and svm present on average for all the gauges the best skill with values of r close to 0 83 rf and k nn show slightly worse results while wt presents the worst skill with a value of r equal to 0 65 nn lr and svm are the only methods able to simulate months with more than 20 wet days which is exceptionally unusual in tenerife although possible besides they show less biased distributions with more similar shapes to the observed ones similarly fig 6 shows a scatter plot of the observed and simulated number of wet days per year for all classifiers and gauges as we can observe the skill of the models improves when the results are evaluated at annual temporal aggregation all models except wt present values of r higher or very close to 0 9 all models also are able to predict properly the extremes of the distribution which correspond to years with more than 100 rainy days and less than 20 respectively the results shown in figs 5 and 6 indicate that even when the daily time series of rainfall occurrence is not perfectly predicted using machine learning methods and synoptic patterns the prediction is acceptable and even good when aggregated over larger time scales the prediction is consistent in statistical terms and therefore is more useful for those applications where the prediction of the exact timing of rainfall is less relevant 4 3 modeling rainfall intensity table 8 shows the result of the pearson correlation coefficient r and root mean square error rmse for all regressors both r and rmse were computed on the subset of wet days prcp 0 1 mm in order to reduce the effects of the varying occurrence frequencies the statistics mean μ median m and the 25th q 1 and 75th q 3 percentiles calculated from the 17 gauges are summarized in the table the results for the 17 gauges are shown in table a 15 in supplementary materials nn shows the highest average value of r 0 37 and the smallest average value of rmse 12 6 mm day svm k nn and rf give slightly worse values of r and rmse than nn while wt presents the worst result statistical methods glm l and glm g perform in general worse than machine learning models with the exception of the wt approach glm l and glm g show higher values of r for the median m than for the mean μ which means that in those stations with lower values of r the statistical methods present less skill if we observe the results for the percentiles q 1 and q 3 we can see that nn presents again the best results of all the regressors r exceeds the value of 0 44 for 25 of the gauges when we analyze the results for the 17 stations separately see table a 15 in supplementary materials we can see that as in the case of the rainfall occurrence and pretty much for the same reasons most of the gauges with the best results higher values of r and lower rmse are located in the north of the island id 2241 2173 2081 2204 1940 it is interesting to note that some stations separated by a few kilometers present very different values of r such as the stations 2173 and 2135 these differences however might be explained by local conditions specifically by the difference in elevation between them around 400 m which results in separate rainfall regimes the hypothesis of the superior skill of nn predicting average rainfall intensity is tested using a multivariate anova manova test muller and peterson 1984 for paired samples under the null hypothesis that all models provided equally good predictions when measured through r and rmse metrics combined the null hypothesis was rejected at a 95 significance level providing additional evidence that some models perform better than others having rejected the null hypothesis the procedure stated in the previous section is followed multiple t tests with the holm correction are carried out to verify which models present significant differences among them the results of the multiple t tests are shown in table 9 it can be seen that nn performance is significantly different to the rest of the models allowing us to conclude that nn are the best performing model for average rainfall intensity prediction the performance of the models reproducing some important rainfall statistics and indices such as daily mean μ daily variance σ 2 r20 number of days with precipitation over 20 mm and rx1 maximum 1 day precipitation is also evaluated see table 10 as with r and rmse scores the statistics shown in table 10 were computed on the subset of wet days prcp 0 1 mm as shown in table 10 the simulated series show bias values very close to 0 for all models k nn and svm are the most biased ones with an average error for all stations equal to 0 7 mm day which corresponds to approximately 8 of rainfall intensity for the 17 gauges the results of bias fall below 2 of rainfall intensity for glm g nn rf and wt methods the σ 2 r20 and rx1 statistics are underestimated by all methods nevertheless we must bear in mind that extreme events in tenerife present values extremely high 5 of the 17 gauges analyzed present values of rx1 above 180 mm day during the period 1979 2015 glm g presents smaller errors when predicting σ 2 r20 and rx1 however it is still below the observed values nn performs better when reproducing the statistics σ 2 rx20 and rx1 than all other machine learning methods with the exception of wt which presents very similar results in contrast nn are not able to simulate events with rainfall intensities greater than 20 mm day see rx5 statistic in table 10 for most of the gauges located in the northeast of the island id 2010 2112 2115 2118 and 2135 most of the gauges present values of rx1 above 100 mm day only the statistical models glms reach that intensity for a few of the gauges glm g is the method that best represent the extreme events with an average error of 86 mm day for rx1 statistic table 10 shows that simulated values of σ 2 are smaller than those observed this is mainly because models underestimate the intensity of the most extreme values of rainfall this effect can be appreciated more clearly when the distribution of precipitation is separated in two regimes one for values below 20 mm day and another for values above fig 7 compares the observed and simulated distributions for rainfall intensities below 20 mm day hexagons with larger number of data present darker colors these 2d density plots allow us to appreciate that the hexagons with the largest number of data are not located in the bisector for most of the models the figure shows that observed distributions shapes are positively skewed with fewer data toward the larger numeric values the mode is located close to 0 2 mm day only the distribution shapes simulated by nn and svm models mimic the observed ones for the rest of the models the mode is located between 2 5 mm day and 5 mm day on the other side fig 8 compares the observed and simulated rainfall distribution for rainfall intensities above 20 mm day red color bands mark those values not represented in the histograms prcp 20 mm day it can be seen that the most extreme values are greatly underestimated by all models only the generalized linear models glm l and glm g are able to simulate values above 100 mm day however as shown in table 10 the performance for the rx1 and r20 indices is not satisfactory the results shown in fig 8 and in table 10 demonstrate that regressors vastly underestimate the intensity of the most extreme events recorded in tenerife during the period 1979 2015 most of these events correspond to isolated depressions at high levels also known as gota fría in spanish some examples of gota fría include the events than happened on 1993 03 17 1999 01 07 2001 03 13 2001 11 20 2002 03 31 2002 12 12 2005 12 19 if we analyze their predictors slp gh500 and gh850 variables from the cfsr database we realize that the majority of these events present very similar atmospheric synoptic patterns however the intensity of precipitation and their spatial distribution is completely different this could mean 1 that there are other explanatory variables disregarded in the analysis or 2 that the cfsr reanalysis database with a resolution of 0 25 does not capture the local processes that take place in tenerife in this context we investigated if other explanatory variables such as surface air temperature relative humidity and zonal wind speed could explain the difference in rainfall patterns for those dates however the atmospheric spatial patterns turned out to be also very similar therefore in our opinion the lack of spatial resolution might explain why the models are not able to predict the intensity of extreme events the results improve when the comparison is carried out at larger temporal aggregations fig 9 shows the skill of the models simulating the observed rainfall series at monthly aggregation all models except wt present values of r very close to 0 8 however nn again presents the best skill glm g and glm l are the only methods able to simulate months with cumulative rainfall values above 500 mm the simulated distribution shapes reproduce adequately the observed ones with a mode located at 50 mm and very few values above 500 mm fig 10 shows the skill of the models simulating the observed rainfall series at annual aggregation all models show values of r very close to 0 8 k nn and above all svm underestimate the most intense values of the distribution they are precisely the models that show higher bias values see table 10 ensemble methods like rf k nn and wt rarely simulate years with accumulated precipitation values above 800 mm if we investigate now the skill of the methods to predict the average rainfall intensity for the whole island at daily scale we appreciate that the results improve significatively with respect to those obtained for each gauge we achieve for example for the nn method a value of r equal to 0 61 when we compare observations and simulations for the 17 gauges aggregated in a single one finally it is important to note that none of the regressors used in this analysis considered location explicitly in the analysis however a verification was carried out to check if the spatial correlation among rainfall gauges was conserved based only on the information provided by synoptic patterns fig 11 shows the spatial correlation of the observed and the predicted rainfall at daily monthly and annual aggregations from left to right the panels shows the cross correlation to a daily monthly and annual aggregation respectively panels located in the upper part of the figure show the observed spatial correlation while those located at the bottom show the quotient between simulated and observed spatial correlation for all the regressors it can be seen that observed spatial correlation presents more pronounced curvatures at daily and annual temporal aggregations than at the monthly scale observed spatial correlation is slightly overestimated by most of the models with the exception of glm l and wt models for distances greater than 10 km at daily resolution all models present successful results at the monthly scale svm k nn and rf simulate time series with higher values of spatial correlation than the observed ones at annual resolution this happens because this methods show distributions with less variance than the observed at this resolution see fig 10 only the wt method is able to preserve the observed spatial correlation for all temporal aggregations which is expected since it is the only method in which predictions are done simultaneously for all the gauges the differences between the observed and simulated results for the rest of the methods is determined mainly because of probabilities being involved in the reconstructed time series and pair wise correlations not explicitly considered in the analysis 5 discussion and conclusions a comparison of 8 statistical and machine learning methods for long term rainfall prediction has been presented all methods use atmospheric synoptic patterns for the variables slp gh500 and gh850 as predictors the analysis was carried out for 17 gauges along the island of tenerife spain that presents a semi arid climate the quality of the predictions was evaluated using different metrics on rainfall occurrence and on rainfall intensity comparing modeled and observed values at different temporal aggregations by cross validation we show that most machine learning methods are very sensitive to the hyperparameters chosen wrong parameterization could lead to models without any predictive capability it may also lead to models that overfit the training data rf and k nn methods tend to over fit in order to avoid over fitting the hyperparameters n estimators and min samples leaf in the case of rf and n neighbors for k nn should take higher values even when doing so degrades their training skill hyperparameters that result in the best predictions changed considerably from one rainfall station to the others our work demonstrates that it is essential to determine the optimal hyperparameters before any application instead of resourcing to any predefined recommendation to minimize the computational cost we recommend starting with a wide search range and then center the search around the hyperparameters that offered better results in the first search the results show that nn with an average f score close to 0 4 for daily rainfall prediction is the best method for predicting rainfall occurrence closely followed by lr and svm all models are able to preserve ϕ dd however they underestimate the observed values of ϕ ww nn also presents less error when predicting the transition probabilities mainly due to its high skill predicting rainfall occurrence the increased in recall metric when prediction threshold is raised demonstrates that more intense rainfall events are easier to predict all models except wt reach values of r above 0 8 when tested simulating the number of wet days per month and per year nn svm and lr however are the only methods able to simulate months with more than 20 wet days which is exceptionally unusual in tenerife nn presents significantly better results than the rest of the models when predicting the intensity of rainfall svm k nn and rf rank second with slightly worse values of r and rmse than nn wt presents the worst results only rainfall intensity distribution shapes simulated by nn and svm models mimic the observed ones simulated series show bias values very close to 0 for all models all methods underestimate the variance of the observed series they are not able to simulate events with accumulated daily rainfall values as high as the observed ones glm g is the model that best reproduces the extreme indices rx1 and r20 however the results are still improvables most of the extreme events correspond to isolate high altitude depression also known as gota fría in spanish we realized that in these situations the atmospheric synoptic patterns for variables slp gh500 and gh850 were indistinguishable however the intensity of the precipitation and their spatial distribution were completely different it might indicate that local processes in tenerife island are not well capture by the cfsr database when comparing the observed and simulated series for larger temporal aggregations the skill of the methods improve significantly all models except wt present values of r close to 0 8 predicting rainfall intensity nn again presents the best skill glm g is the only method able to simulate months with cumulative rainfall values above 500 mm ensemble methods like rf k nn and wt rarely simulate years with accumulated precipitation values above 800 mm though regression is done independently for each gauge the atmospheric predictors allow most of the models to preserve the observed spatial correlation at daily monthly and annual aggregations a small error appears for distances greater than 10 km at daily scale the methods that show less variance at an annual temporal aggregation svm k nn and rf simulate series with higher values of spatial correlation than the observed ones only the wt method is able to preserve the observed spatial correlation for all temporal aggregations which is expected since it is the only method in which predictions are done for all the gauges simultaneously the incorporation of conceptual spatio temporal rainfall models using copulas or deep learning techniques stehlík and bárdossy 2002 yang et al 2005 will be considered in future works our results are in line with other studies performed in the past gupta and ghose 2015 olsson et al 2004 valverde ramírez et al 2005 however none of these studies carried out a significance analysis to demonstrate the best predictive capacity of some methods against others gupta and ghose 2015 found that nn provides better results than any of the other discussed algorithms decision tree naive bayes approach k nearest neighbor for predicting rainfall occurrence in new delhi from june to september rainfall period weather predictors including mean temperature dew point temperature humidity sea level pressure and wind speed according to the results achieved by gupta and ghose 2015 nn achieved a value of f score equal to 0 6 however their analysis was carried out only at a single location gauge and furthermore methods were fitted and validated only during rainfall period which probably facilitates the prediction in our analysis we obtain an average f score of 0 4 for the 17 gauges however it can vary from 0 24 to 0 54 depending on the gauge olsson et al 2004 used nn for predicting 12 h mean rainfall in kyushu island southern japan from values of wind speeds at 850 hpa and precipitable water in a 100x100 km grid surrounding the island in their study olsson et al 2004 employ a classification of intensities into four categories zero low high and extreme intensity they achieved a result of r equal to 0 63 for the entire island in our analysis we achieve an average result of 0 37 for the 17 gauges we have to bear in mind that in their analysis olsson et al 2004 use atmospheric instrumental data from the gauges we instead use large scale atmospheric reanalysis data it is expected that including atmospheric instrumental data in our analysis will improve the predictions in addition olsson et al 2004 predict the average precipitation in a cell of 100x100 km if we compare their results with those obtained when we aggregate rainfall intensity for all the gauges in the study area we realize that the results are very similar in our case we obtained a value of r closet to 0 61 valverde ramírez et al 2005 compared nn with a multiple linear regression model to predict daily rainfall using as predictors output data from a regional climatic model they use the variables potential temperature vertical component of the wind specific humidity air temperature precipitable water relative vorticity and moisture divergence flux in their analysis the test was performed for six locations in são paulo state brazil during the austral summer and winter for the period 1997 2002 the results show that nn forecasts were superior to the ones obtained by the linear regression model nn achieves results of r between 0 1 and 0 8 depending on the month and gauge analyzed the results obtained in our article also indicate that nn is the best method to predict rainfall occurrence and rainfall intensity at the daily scale however to verify this hypothesis we carried out a multivariate and univariate analysis of variance to evaluate the difference among models furthermore we demonstrate that none of the models is able to reproduce the variance and the intensity of the highest values of the distribution which suggests that these methods are not appropriate to reproduce the extreme events that took place in the past the underestimation of variance could have been addressed by including aggregate predictors in the simulation context or by using nonparametric methods based on kernel density estimation mehrotra et al 2006 mehrotra et al 2004 sharma and lall 1999 by using mixed distributions mínguez et al 2013 jeffries and pfeiffer 2001 or by testing other minimization function all these approaches will be investigated in future works the good results achieved at temporal aggregations above the day indicate that these methods may be very useful tools for water resources studies credit authorship contribution statement javier diez sierra methodology investigation visualization manuel del jesus conceptualization methodology supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to thank 1 consejo insular de aguas de tenerife ciatf for granting permission to use their rainfall database for this work 2 agencia estatal de investigación aei from the spanish ministry of economy industry and competitiveness and the european regional development fund erdf for the funding provided through grant bia2016 78397 p aei feder ue and 3 project indecis which is part of era4cs an era net initiated by jpi climate and funded by formas se dlr de bmwfw at ifd dk mineco es anr fr with co funding by the european union grant 690462 appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2020 124789 supplementary data the following are the supplementary data to this article supplementary data 1 
5460,in this paper we evaluate the performance of 8 statistical and machine learning methods driven by atmospheric synoptic patterns for long term daily rainfall prediction in a semi arid climate tenerife spain cross validation is used to reconstruct 36 years of daily rainfall data at 17 gauges prediction is independent for each gauge the reconstructed series are compared with the observed records in order to select the optimal hyperparameters within each family of models the predictive performance of the models is evaluated using several metrics and statistics related with rainfall intensity and occurrence at daily monthly and annual aggregation scales multivariate and univariate analysis of variance are used to evaluate the differences among models the results of our work demonstrate that the performance of most machine learning models is very sensitive to the selected hyperparameters neural networks are found to perform best to predict rainfall occurrence and intensity all methods underestimate the variance of the observed series at daily time scales generalized linear models using gamma distributed errors perform best for predicting rainfall extremes however their performance limits its practical applications results improve significatively at larger temporal aggregations monthly or annual making statistical and machine learning methods more valuable for water resources studies keywords rainfall prediction regression machine learning extremes statistical downscaling 1 introduction today the most reliable measure of the intensity of precipitation at a specific point continues to be that obtained from meteorological stations located on the ground i e instrumental data adeyewa and nakamura 2003 hasan et al 2016 wang et al 2019 this kind of information with a sufficient temporal coverage usually of several decades is not commonly available in most areas of the world buytaert et al 2012 however on site rainfall information with such a temporal coverage is essential in many fields such as water resources management flood risk assessment and climatological analysis for instance to detect possible climatic trends in rainfall series among others nkiaka et al 2017 sun et al 2018 altunkaynak and nigussie 2015 pumo et al 2017 aryal 2018 park et al 2019 historical rainfall data to complement instrumental records can also be obtain from other sources such as satellites huffman et al 2010 radars austin and seed 2005 and numerical models pfeifroth et al 2013 satellites and radars provide short precipitation time series that start in the best case scenario in the 1990s pfeifroth et al 2013 burlando et al 1996 chen et al 2020 li et al 2020 reanalysis models however are able to provide more than 50 years of continuous data throughout the globe kalnay et al 1996 saha et al 2010a dee et al 2011 in spite of their long time coverage reanalysis databases present some other limitations such as a large bias especially in mountainous areas an overestimation of rain events with small and medium intensities an underestimation of the most intense events and serious difficulties to simulate small scale physical processes wang et al 2019 bosilovich et al 2008 nkiaka et al 2017 moreover rainfall data from reanalysis databases cannot be directly compared to point records since model results are equivalent to spatial averages over fixed areas pixels del jesus et al 2015 diez sierra and del jesus 2019 several authors have investigated different techniques to predict long time series of historical rainfall covering decades in the past to overcome the aforementioned limitations of the different sources of information this predicted rainfall time series strengthen the robustness of technical analysis and help managers and decision makers to implement optimal strategies to problems in the fields of water resources li et al 2020 this discipline is known as long term rainfall prediction gupta and ghose 2015 and it normally relies on regression techniques of which a varied plethora can be found in literature including parametric and nonparametric methods linear and non linear ones qiu et al 2016 pérez rodríguez et al 2012 kannan and ghosh 2013 he et al 2015 yu et al 2017 he et al 2015 generalized linear models logistic regression and support vector machines with linear kernels are parametric models with a limited number of parameters while k nearest neighbors decision trees support vector machines with radial basis function kernels and neural networks are nonparametric models where the number of parameters can grow with the size of the training set sheskin 2003 the increase in computational capacity has favored the use of machine learning techniques over other regression methods hong 2008 zhao et al 2020 in part because the form of the relationship between the variables does not need to be known or assumed a priori besides linear regressions are meant to describe linear relationships abbot and marohasy 2017 and rely on some hypothesis normality of errors homoscedasticity etcetera which may be relaxed with the use of machine learning methods in this paper generalized linear models and several machine learning methods support vector machines k nearest neighbors random forests k means clustering and neural networks are analyzed for long term daily rainfall prediction using atmospheric synoptic patterns from reanalysis databases the main motivation of the present study is to compare the skill of the methods mentioned above to extend the temporal coverage of rainfall time series to several decades in the past using shorter historical records and atmospheric synoptic patterns from reanalysis database as predictors the atmospheric patterns present a greater temporal coverage than instrumental data allowing to effectively extend the rainfall information several studies have investigated this topic in the past olsson et al 2004 sumi et al 2012 valverde ramírez et al 2005 showing that all algorithms seem to have their advantages and limitations making the selection of the best overall algorithm difficult gupta and ghose 2015 however none of the studies made to date performed a comparison as exhaustive as the one presented here making use of the main methods found in literature for rainfall prediction besides unlike most studies we analyze the results not only in order to preserve some evaluation metrics but also including several rainfall statistics such as daily variance duration of the dry and wet spells spatial correlation and some extremal indexes among others which are very important for hydrological response characterization serrano notivoli et al 2018 furthermore in our study all comparisons among models are made on the basis of robust statistical tests and not merely on an analysis of differences which may not be statistically robust the methods presented herein can be applied worldwide as long as instrumental precipitation data is available in the area as reanalysis databases do normally have global coverage and could also be extrapolated for their use in climate change studies however our analysis is carried out in a semi arid climate tenerife spain where rainfall scarcity and heterogeneity complicates the generation of accurate predictions 17 gauges and more than 36 years of daily data are used to evaluate our methods predictions are done independently for each station in our analysis we make use of open license open source standard tools pedregosa et al 2011 r core team 2017 that are cross platform easily installable and deployable in any hardware system for any application some methods found in literature have been further developed for specific applications however they have not been considered in the analysis as their use is not widespread and are not fully cross platform yet sharma et al 2016 adnan et al 2019 2 study area and data sources 2 1 description of the study area tenerife is one of the seven islands that form the spanish archipelago of the canary islands tenerife is located in the atlantic ocean 300 km west of the african coast between parallels 28 n and 29 n and between meridians 16 w and 17 w tenerife displays a strong topographic gradient from the coast to the central part of the island the central region of the island is a mountain range where el teide 3 718 m is the highest peak that separates the island in two well differentiated climatic areas a northern region relatively wet due to the effect of the trade winds and a southern region drier due to the blocking induced by the orography see fig 1 climatic spatial heterogeneities are also present within each region configuring a widely varied range of climates within a relatively small area diez sierra and del jesus 2017 2 2 rainfall data rainfall data is provided by consejo insular de agua de tenerife ciatf 2018 the water planning and managing agency for tenerife island ciatf maintains a database of rainfall observations melián et al 2011 that includes the observation network of agencia estatal de meteorología aemet 2018 the spanish national meteorological agency and of agrocabildo agrocabildo 2018 a local agency for agriculture development the ciatf database contains information for 125 gauges combining daily and sub daily values with an average coverage of 15 years although the longest series start in 1890 only the gauges containing the best information were included in the analysis three criteria were considered during gauge selection 1 gauges should cover as long a time period as possible 2 all gauges should cover the same reference period to reduce the uncertainty associated with using different climatic time periods in the fitting procedure and 3 all climatic regions of the island should be covered by the selection to compare the predictive skill of the models under different conditions following these considerations all stations with at least 25 years of data in the period 1979 2015 were selected fig 1 shows the location white dots and the identifier four digit white numbers of the 17 rainfall gauges selected for the analysis which are representative of the climate of the island rain gauges were selected to cover as much territory as possible with the longest and most complete rainfall records for the period 1979 2015 as we show in table 1 precipitation in tenerife is very scarce with an annual average of 371 mm and 45 rainy days for the 17 gauges selected temporal and spatial distribution of rainfall is very heterogeneous since a very high percentage of precipitation falls in short periods of time and with a great spatial heterogeneity largely due to the topography of the island seasonality is very remarkable rainy season takes place mostly during the boreal winter november december and january while the dry season covers most of the boreal summer june july and august 2 3 atmospheric data atmospheric variables inform statistical and machine learning methods about the state of the atmosphere thus they constitute the main predictor for rainfall the state of the atmosphere for tenerife island is properly captured as described in previous analysis found in literature by herrera et al 2001 and tullot 1959 by the combined fields of sea level pressure slp elevation of the 500 hpa geopotential surface gh500 and elevation of the 850 hpa geopotential surface gh850 these fields cover the area between 45 w and 5 e and 20 n and 50 n see fig 2 spatial atmospheric information is obtained from the global reanalysis ncep climate forecast system reanalysis cfsr saha et al 2010b developed by the national oceanic and atmospheric administration noaa cfsr is a third generation reanalysis database generated with a global high resolution land ocean atmosphere model coupled with an ice sheet model cfsr provides 6 hourly data the spatial resolution of the atmospheric model is 38 km horizontally with 64 vertical levels the spatial resolution of the oceanic model is approximately 0 25 near the equator and 0 5 beyond the tropics with 40 vertical levels the land model counts 4 soil levels and the ice model 3 levels cfsr covers the period 1979 2015 3 methods statistical and machine learning methods will be trained or fitted to predict daily rainfall using atmospheric predictors data from 17 rain gauges will be used for the analysis keeping 80 of the data of each station for fitting the models training and the remaining 20 for evaluating their prediction skill testing 36 years long original time series for each rainfall gauge are split in two sets the training set containing 30 years of data and the testing containing the remaining 6 models are trained independently for each station machine learning techniques can be fine tuned through hyperparameters that control their behavior hyperparameters may select the optimization routine used for fitting the regularization scheme used and the non linear transformation applied to the input data among other things the training set is used to determine the optimal hyperparameters by k fold cross validation markatou et al 2005 the optimal hyperparameters are selected from a factorial grid the 30 years of the training set are thus further subdivided into k subsets k 1 sets are used to train the model and the kth one is used to evaluate the performance of those hyperparameters in unseen data validation for each set of candidate hyperparameters the process is repeated k times determining an average performance of the hyperparameters and selecting the best performing set predictive performance is evaluated over the test set that was not used for training neither for selecting the optimal hyperparameters of each method see fig 3 predictive performance for rainfall occurrence and rainfall intensity is considered different loss functions will be used to explore their capabilities to capture different rainfall statistics 3 1 construction of the predictors to construct the atmospheric fields used as predictors in this paper cfsr data is aggregated into daily time scale 13 514 days for the whole period of analysis over a 0 5 0 5 mesh forming a 60 100 elements matrix for each day the atmospheric information consists of three 3 60 100 elements matrices in total one for slp one for gh500 and one for gh850 each number in the matrix represents the value of the field at a specified location it is the component of the field on a basis vector that takes a value of one for that location and zero everywhere else the matrices for each day can be combined and rearranged as a vector of 1800 components 60 100 3 that are stacked together to form a matrix of 1 800 13 514 elements containing all the atmospheric information for the whole period of analysis the atmospheric information for each day could be interpreted as a data point in a 1 800 dimensional space however the correlations existing among the values of a variable at different locations or among different variables at the same or at different locations makes many of these dimensions redundant and uninformative these correlations may disturb and even spoil the fitting procedure of the regression and machine learning models gutiérrez et al 2004 to reduce these correlations while maintaining their discriminant power the atmospheric patterns are standardized and then transformed through principal components analysis pca abdi and williams 2010 the pca method constructs an alternative basis to represent the original data that is optimal in the sense that each basis vector captures as much variation of the original data not captured by previous basis vectors as possible the first basis vector generated by the pca method is thus aligned with the direction of maximum variation of the original data each successive basis vector is orthogonal to all the previous ones it does not capture variability in the direction of previous basis vectors and captures as much variation as possible for a single vector the application of the pca method renders a more workable representation of the original data as some dimensions in the new basis may be dropped with a reduced impact in the amount of information lost in addition the pca method significantly reduces the number of predictors thus reducing also the computational cost derived from training the different statistical and machine learning models many climate studies have explored different configurations of the predictors one including direct information from the predictors from neighboring grid points another including principal components as predictors and a last one including both preisendorfer 1988 san martín et al 2017 all configurations including principal components exhibit a similar overall performance while the one that only included information of the predictor from the closest reanalysis grid box suffered from a large seasonal variability of the bias and worse predictions gutiérrez et al 2013 these results indicate that the principal components from pca constitute better predictors than the variables alone most probably because the principal components aggregate spatial information from all the domain of the spatial predictor after application of the pca method to the original matrix 1 800 13 514 elements 95 of the variance of the original data set can be captured by keeping only the first 14 principal components the components over the first 14 basis vectors generated by pca the atmospheric information predictor is thus a matrix with 14 13 514 elements representing the time series of 13 514 days for 14 predictors pca components in addition to the atmospheric variables we incorporate seasonality as a predictor seasonality introduces a non stationarity in the distribution of rainfall that must be considered for accurate predictions a simple way to include this non stationarity is to use as predictor some function that mimics the shape of the average monthly rainfall throughout the year the simplest analytical function able to reproduce that shape is a combination of a sine y 1 sin 2 π t and a cosine y 2 cos 2 π t of period t 12 months the sine and cosine functions y 1 and y 2 will be two additional predictors given to the statistical and machine learning techniques informing these methods about the differences existing among months méndez et al 2007 3 2 statistical and machine learning methods statistical methods traditionally used to predict precipitation are based on classical linear regression models lrm and generalized linear models glm that allow for response variables presenting non gaussian error distributions coe and stern 1982 stern and coe 1984 however with increasing computational power machine learning approaches have extended the options of rainfall prediction techniques qiu et al 2016 machine learning techniques have two major advantages they do not normally require any assumption about the distribution of errors and the form of the relationships between predictors and predictands does not need to be known a priori appelhans et al 2015 the intermittency of rainfall at daily time scales the succession of wet and dry intervals of finite duration makes it more convenient to split the prediction problem into two steps thus rainfall occurrence and rainfall intensity are modeled separately olsson et al 2004 for this reason statistical and machine learning techniques are separated into two categories classifiers that deal with categorical data rain and no rain aimed at predicting rainfall occurrence and regressors that deal with continuous data aimed at predicting rainfall intensity table 2 enumerates all the statistical and machine learning models used in this analysis the first column shows the model name the second column corresponds to the abbreviation abbr the third column shows whether the method is used for classification c regression r or both c r the forth column enumerates the hyperparameters optimized during the analysis and finally the fifth column lists the values of the hyperparameters explored in the model optimization step the implementation of the methods found in the stats library r core team 2017 and the scikit learn library pedregosa et al 2011 were used in this work in the present work two statistical glms methods are used on the one hand glm l which corresponds to classical lineal regression but assuming a logarithmic relation between predictor and predictand the logarithm link function transforms the data to increase their similarity to a gaussian distribution improving the quality of the fit on the other hand glm g which assumes that errors follow a gamma distribution the gamma distribution is commonly used to model rainfall because the distributions of precipitation amount tend to be strongly skewed at daily time scales ben alaya et al 2017 stephenson et al 1999 yang et al 2005 six different machine learning methods are used in the analysis random forest rf is an ensemble learning method that constructs a multitude of decision trees at training time and predicts the mode of the predicted classes classification or the mean of the predictions regression of the individual trees two hyperparameters are analyzed for optimization n estimators that corresponds to the total number of trees in the forest and min samples leaf that is the minimum number of samples required to be at a leaf node a node over which the mode or the mean are computed k nearest neighbors k nn is a non linear method whose predictions are computed through the weighted mode classification or the weighted mean regression of the k nearest points to the one being predicted two hyperparameters are analyzed for optimization n neighbors that corresponds to the number of neighbors used in the prediction and weights that is the weight function used in prediction uniform means that all points in the neighborhood are equally weighted while distance means that points are weighted by the inverse of their distance neural networks nn learns a mapping between a series of input features input layer and an output output layer through linear combinations and non linear transformations of the inputs received by every neuron in the network hidden layer three hyperparameters are analyzed for optimization hidden layer sizes that is the number of neurons and layer used activation that defines the non linear function that each neuron uses to transform the linear combination of inputs it receives and alpha a term controlling regularization strength by penalizing weights with large magnitudes support vector machines svm perform classification and regression tasks by finding the hyperplanes that maximize the margins the minimum gap separating samples belonging to different groups the closest values to the classification margin are known as support vectors radial basis function rbf kernels are used to ensure separation is possible in non linear spaces three hyperparameters are analyzed for optimization γ that is the radius of the area of influence of the support vectors c that can be seen as the inverse of the regularization strength and ε which defines a margin of tolerance where no penalty is given to errors logistic regression lr classifies binary outcomes modeling the logit transformed probability of occurrence through linear regression three hyperparameters are analyzed for optimization solver that is the algorithm used in the optimization problem penalty that is the regulation function applied to the weights of the regression and c that can be seen as the inverse of the regularization strength like in svm finally weather typing wt which divides the input space into regions and uses the mode or mean of the region in which the candidate point lies to solve the classification or regression problem in this specific application weather types are computed using the k means algorithm camus et al 2011 turning weather types into representative synoptic atmospheric patterns diez sierra and del jesus 2017 wt is the only method in which predictions are done simultaneously for all the gauges a more detailed description of the hyperparameter selection as well as the sensitivity of the models to each of them can be found at scikit learn 2019 3 3 loss functions a loss function measures the distance between the value estimated by a statistical or machine learning method and the objective value the model is supposed to predict the fitting procedure of any statistical or machine learning method involves finding the values of the parameters that optimize the value of the loss function in most cases the loss function used to fit regression models is the sum of squared errors either with a focus on bias or variance an advantage of machine learning methods is that the loss function can be easily customized so that values predicted by the model may minimize any convenient function in the present work two different loss functions are used depending on the objective of the fitting procedure classifiers used mainly to predict rainfall occurrence or probability are fitted using f score 1 f score 2 precision recall precision recall with precision being defined as 2 precision tp tp fp and recall as 3 recall tp tp fn where tp means true positives the number of observed rainy days correctly predicted as rainy days by the model fp means false positives the number of observed non rainy days predicted as rainy days by the model and fn means false negatives the number of observed rainy days predicted as non rainy days by the model precision measures the probability that a predicted rainy day by the model corresponds with a real rainy day a true positive while recall measures the probability that a real rainy day is correctly predicted by the model a true positive a value of one 1 in both measures represents a perfect score while zero 0 is the minimum value for both metrics a model that only predicts rainy days when rainfall really occurs but misses some observed rainy days predicting a non rainy day would have a perfect precision a value of 1 but would have a recall smaller than one 1 as some events would have not been properly recognized false negatives exist a model that predicts rainy days when rainy days really occur but also in some non rainy days would have a perfect recall but a precision smaller than one 1 as false positives are present in the prediction the f score metric is very useful to compare the skill of model predictions when working with imbalanced datasets datasets in which one class is much more frequent than the others this is the case of rainfall in tenerife where rainy days are rare with an average value for the 17 gauges of 15 of the days however the proportion of rainy days can vary from 25 for some gauges located in the north of the island to 5 for other gauges located in the south regressors which aim to predict the intensity of rain are evaluated using the root mean squared error rmse as loss function 4 rmse t 1 n x 1 t x 2 t 2 n where x 1 and x 2 correspond to the observed and the simulated rainfall series respectively although not used as a loss function bias bias and pearson correlation r as defined in eqs 5 and 6 respectively are also used as evaluation metrics for the models 5 bias t 1 n x 1 t x 2 t n 6 r t 1 n x 1 t x 2 t n x 1 x 2 t 1 n x 1 t 2 n x 1 2 t 1 n x 2 t 2 n x 2 2 in eqs 5 and 6 x 1 t and x 2 t correspond to the observed and the simulated rainfall series respectively and n is the sample size 3 4 grid search before evaluating the predictive performance on the original test set the optimal hyperparameters for each class of models shown in table 2 are determined hyperparameters are chosen from a factorial grid the fourth column of table 2 shows the hyperparameters tuned for each model and the fifth column shows the explored values the specified model is trained with different hyperparameters and evaluated over the training set using k fold cross validation markatou et al 2005 the k fold cross validation approach avoids overfitting and the appearance of spurious effects of any particular partition of the input data k fold cross validation implies dividing the training set in k equal sized subsets using k 1 subsets to train the model and evaluating the performance on the kth subset the one not used for model training the procedure is repeated k times using each of the k subsets one time to evaluate performance the average performance of the k trainings is assigned to the hyperparameters and the optimal hyperparameters are the ones that maximize the performance of the model in this study k is taken equal to 5 so that 80 of the original training data are used for training and the remaining 20 used for validating the hyperparameters each training set is thus split in five subsets using 4 sets for fitting the model and 1 for validation grid search involves in the present study fitting over 25 000 different models the number 25 000 results from the combination of different models regressors and classifiers with their respective hyperparameters and the 17 gauges 3 5 model evaluation as we mentioned in the subsection 3 2 rainfall occurrences and rainfall intensity are modeled separately on the one hand the models defined as classifiers in table 2 are used to reconstruct the entire time series of rainfall occurrence for the 17 gauges independently to this end the continuous time series of precipitation are transformed into binary series 0 norain 1 rain before training f score is the loss function applied for all classifiers eq 1 on the other hand the models defined as regressors in table 2 are used to reconstruct the entire time series of rainfall for the 17 gauges independently all values larger than 0 1 mm day are used in the analysis the loss function in this case is rmse see eq 4 seasonality sine and cosine functions is included as a predictor for the rainfall occurrence and intensity 4 results 4 1 hyperparameter sensitivity analysis during the cross validation procedure several sets of hyperparameters are tested to find the optimal one the performance of all the tested hyperparameters sets both for classifiers and regressors are shown in fig 4 the left hand panel of the figure shows the classifier s performance through f score while the right hand panel shows the regressor s performance through the pearson correlation coefficient r the figure shows the distribution of f score and r values for the different models and for every rainfall station by means of histograms and kernel density estimates of the probability density function both f score and r have a range of values from 0 to 1 the vertical dashed line represents the middle of the range the value of 0 5 an analysis of the distributions for the classifiers reveals that the performance of logistic regression lr and support vector machines svm does not depend much on the value of the hyperparameters used indeed the distributions of f score for these two models are almost dirac s deltas these models will therefore present a skill mostly dependent on the characteristics of the covariates and the predicted series but cannot be easily adapted by tuning their hyperparameters a similar case although not so extreme would be weather typing wt that shows little sensitivity to hyperparameter selection however its performance tends to be lower than the two previous methods on the opposite side of the spectrum neural networks nn presents a widely spread distribution indicating a high sensitivity to hyperparameter tuning nn performance is highly dependent on the hyperparameter values used during training indeed their performance may be the worst of all models as can be seen by the amount of probability concentrated around zero skill but with a proper hyperparameter calibration they can provide the best predictions over all models finally random forests rf and k nearest neighbors k nn constitute a middle ground among models their performance is sensitive to the values of the hyperparameters but their spread is narrower than for nn the right hand side of fig 4 shows that in general regressors are more sensitive to hyperparameters values than classifiers except for wt that shows a smaller variation on performance as hyperparameters are varied all the other models present wide distributions indicating a high sensitivity to hyperparameter tuning another important result of this analysis is that the optimal hyperparameter set for a given method changes for each gauge see tables a 11 and a 12 in supplementary materials the only exception being wt for which the same number of clusters maximized the dunn index criterion baarsch and celebi 2012 for all gauges despite this variability some conclusions can be derived from the analysis regression requires more complicated models than classification as it could be expected for instance rf requires a higher number of trees n estimators and a higher minimum number of samples in each leaf node min samples leaf to predict rainfall intensity than rainfall occurrence a similar result is observed with the number of neighbors required in the prediction n neighbors for k nn a higher number of neighbors is required to predict rainfall intensity than rainfall occurrence in the case of svm two properties are pursued a hyperplane with the largest minimum margin c and a hyperplane that correctly separates as many instances as possible for large values of the regularization term c the optimization will choose a smaller margin hyperplane while a lower c will encourage a larger margin and a simpler decision function cherkassky and ma 2004 suggests that with an optimal choice of the hyperparameter ε which defines the margin of tolerance where no penalty is given to errors the value of c has negligible effects on the performance as long as c is larger than a certain threshold determined from the training data thus we recommend to first define the threshold of c and then set the value of hyperparameter ε svm in scikit learn presents a default value of ε equal to 0 1 however the magnitude of ε must be increased to reduce bias larger values of ε are normally required especially for very large and or noisy training sets mattera and haykin 1999 nn uses parameter α for regularization which helps in avoiding over fitting by penalizing weights with large magnitudes as in svm nn in scikit learn presents a default value of α equal to 0 0001 we found that the hyperparameter α must be increased several orders of magnitude to avoid over fitting in some of the gauges hyperparameter hidden layer sizes in nn defines the number of neurons and layers used the values in the parenthesis correspond to the number of neurons and layers respectively see tables a 11 and a 12 as we can see the number of layers required are 1 for all the gauges except in 2 of the cases in contrast the number of neurons can vary from 2 to 20 activation functions in nn introduce non linear properties to our model rectified linear units relu f x max 0 x and hyperbolic tangent tahn f x tanh x activation functions are selected in most of the gauges identity activation function that establishes linear relationships is only selected twice tables 3 and 4 show the average skill during training and testing for all methods results are calculated as the average result of the 17 gauges as expected most models present better skill in training that in testing as mentioned in section 3 in order to avoid over fitting we apply cross validation on 80 of the original training set cross validation serves to select the best hyperparameters then we check that the skill of the methods remains similar in the remaining 20 of unseen data test despite this decomposition of the original data rf and k nn over fit as seen by the difference of the skill between training and testing in the case of k nn this fact can be explained because the optimal number of neighbors selected for prediction is equal to 1 for several gauges for these gauges the k nn model selects from the training set the rainfall value associated to the most similar atmospheric synoptic pattern for each prediction reaching a perfect fit during training something similar happens with rf and the hyperparameter min samples leaf when the value selected in the cross validation is too small rf predicts values very similar to those seen during training to avoid over fitting the hyperparameters n estimators and min samples leaf in the case of rf and n neighbors for k nn should be forced to take higher values even when the training skill is degraded however attention must be paid in order not to force the model to under fit the high variability showed in fig 4 demonstrates that it is essential to calibrate the hyperparameters prior to any application 4 2 modeling rainfall occurrence the average performance of every model for predicting rainfall occurrence is shown in table 3 nn with an average f score close to 0 4 appears as the best performing model closely followed by lr and svm the complete set of f scores for every gauge can be found in table a13 in supplementary materials rf and k nn provide worse results whereas the wt based method shows the worst predictive performance far below the rest of the models the skill of the prediction is substantially better for gauges located in the north of tenerife that in the south see table 1 this is probably because classifiers are more able to capture the underlying relationship in frontal precipitations which dominates in the north of the island than the convective processes prevailing in the south in general the performance of nn classifiers seems superior on all gauges except for a few cases like gauge id 2115 where svm did a better job than nn in order to verify the hypothesis of the superior skill of nn classifiers a test of significance was carried out multiple t tests were carried out to verify which models presented significant differences among them making use of the holm correction method holm 1979 in order to counteract the problem of multiplicity t tests were carried out over the f score metric table 5 shows the results of these tests indicating where the differences in these two model comparisons were significant it can be seen that nn presents significantly better results than the other models allowing us to conclude that nn are the best performing model for predicting rainfall occurrence lr and svm are placed second presenting significantly better results than rf k nn and wt another important metric to evaluate is the performance of a model predicting exceedances over a threshold as this will indicate the skill of the model predicting the most intense rainfall events rainfall occurrence over four thresholds 0 1 5 20 and 40 mm day is analyzed recall measures how many of the positive samples observed rainy days with an intensity larger than a specific thresholds are captured by the positive predictions simulated rainy day recall has the advantage of not involving the false positives type i errors values in the analysis table 6 shows the average recall metric for the 17 gauges and the selected thresholds the table shows that the recall metric is higher for all classifiers as the value of the threshold increases reaching 0 63 for the nn classifier for the threshold of 40 mm day the increase of the recall metric with the increasing thresholds indicates that larger rainfall events are easier to predict as they are more dependent on atmospheric synoptic situations rainfall persistence is another important characteristic linked to rainfall occurrence it can measured by transition probabilities that indicate the probability of having a dry day followed by another dry day ϕ dd and having a wet day followed by another wet day ϕ ww table 7 shows the mean μ median m and the 25th q 1 and 75th q 3 percentiles calculated from the 17 gauges the statistics give us an idea of the distribution of values for the 17 stations although the mean μ and median m might seem redundant we decided to show both statistics because the median m is more robust in the presence of outliers than the mean as we can see in table 7 all methods are able to preserve the observed obs ϕ dd with very small errors however they underestimate the observed values of ϕ ww if fact some of them give large errors when comparing the predicted and the observed values of ϕ ww such as wt k nn and rf methods nn lr and svm again present the best average results however they still underestimate ϕ ww in approximately 25 of the observed values nn presents the smallest error predicting ϕ ww mainly due to its better ability to predict rainy days as table 7 demonstrates all the statistics μ m q 1 and q 3 calculated from the simulated series underestimate the observed ones which implies that the simulated distribution of ϕ ww is displaced to lower values the complete set of observed and simulated transition probabilities ϕ dd and ϕ ww for every gauge can be found in table a 14 in supplementary materials interesting results are found when the skill of classifiers to reproduce the number of wet days per month and year is analyzed fig 5 shows a scatter plot of the observed and simulated number of wet days per month for all classifiers and gauges as we can observe nn lr and svm present on average for all the gauges the best skill with values of r close to 0 83 rf and k nn show slightly worse results while wt presents the worst skill with a value of r equal to 0 65 nn lr and svm are the only methods able to simulate months with more than 20 wet days which is exceptionally unusual in tenerife although possible besides they show less biased distributions with more similar shapes to the observed ones similarly fig 6 shows a scatter plot of the observed and simulated number of wet days per year for all classifiers and gauges as we can observe the skill of the models improves when the results are evaluated at annual temporal aggregation all models except wt present values of r higher or very close to 0 9 all models also are able to predict properly the extremes of the distribution which correspond to years with more than 100 rainy days and less than 20 respectively the results shown in figs 5 and 6 indicate that even when the daily time series of rainfall occurrence is not perfectly predicted using machine learning methods and synoptic patterns the prediction is acceptable and even good when aggregated over larger time scales the prediction is consistent in statistical terms and therefore is more useful for those applications where the prediction of the exact timing of rainfall is less relevant 4 3 modeling rainfall intensity table 8 shows the result of the pearson correlation coefficient r and root mean square error rmse for all regressors both r and rmse were computed on the subset of wet days prcp 0 1 mm in order to reduce the effects of the varying occurrence frequencies the statistics mean μ median m and the 25th q 1 and 75th q 3 percentiles calculated from the 17 gauges are summarized in the table the results for the 17 gauges are shown in table a 15 in supplementary materials nn shows the highest average value of r 0 37 and the smallest average value of rmse 12 6 mm day svm k nn and rf give slightly worse values of r and rmse than nn while wt presents the worst result statistical methods glm l and glm g perform in general worse than machine learning models with the exception of the wt approach glm l and glm g show higher values of r for the median m than for the mean μ which means that in those stations with lower values of r the statistical methods present less skill if we observe the results for the percentiles q 1 and q 3 we can see that nn presents again the best results of all the regressors r exceeds the value of 0 44 for 25 of the gauges when we analyze the results for the 17 stations separately see table a 15 in supplementary materials we can see that as in the case of the rainfall occurrence and pretty much for the same reasons most of the gauges with the best results higher values of r and lower rmse are located in the north of the island id 2241 2173 2081 2204 1940 it is interesting to note that some stations separated by a few kilometers present very different values of r such as the stations 2173 and 2135 these differences however might be explained by local conditions specifically by the difference in elevation between them around 400 m which results in separate rainfall regimes the hypothesis of the superior skill of nn predicting average rainfall intensity is tested using a multivariate anova manova test muller and peterson 1984 for paired samples under the null hypothesis that all models provided equally good predictions when measured through r and rmse metrics combined the null hypothesis was rejected at a 95 significance level providing additional evidence that some models perform better than others having rejected the null hypothesis the procedure stated in the previous section is followed multiple t tests with the holm correction are carried out to verify which models present significant differences among them the results of the multiple t tests are shown in table 9 it can be seen that nn performance is significantly different to the rest of the models allowing us to conclude that nn are the best performing model for average rainfall intensity prediction the performance of the models reproducing some important rainfall statistics and indices such as daily mean μ daily variance σ 2 r20 number of days with precipitation over 20 mm and rx1 maximum 1 day precipitation is also evaluated see table 10 as with r and rmse scores the statistics shown in table 10 were computed on the subset of wet days prcp 0 1 mm as shown in table 10 the simulated series show bias values very close to 0 for all models k nn and svm are the most biased ones with an average error for all stations equal to 0 7 mm day which corresponds to approximately 8 of rainfall intensity for the 17 gauges the results of bias fall below 2 of rainfall intensity for glm g nn rf and wt methods the σ 2 r20 and rx1 statistics are underestimated by all methods nevertheless we must bear in mind that extreme events in tenerife present values extremely high 5 of the 17 gauges analyzed present values of rx1 above 180 mm day during the period 1979 2015 glm g presents smaller errors when predicting σ 2 r20 and rx1 however it is still below the observed values nn performs better when reproducing the statistics σ 2 rx20 and rx1 than all other machine learning methods with the exception of wt which presents very similar results in contrast nn are not able to simulate events with rainfall intensities greater than 20 mm day see rx5 statistic in table 10 for most of the gauges located in the northeast of the island id 2010 2112 2115 2118 and 2135 most of the gauges present values of rx1 above 100 mm day only the statistical models glms reach that intensity for a few of the gauges glm g is the method that best represent the extreme events with an average error of 86 mm day for rx1 statistic table 10 shows that simulated values of σ 2 are smaller than those observed this is mainly because models underestimate the intensity of the most extreme values of rainfall this effect can be appreciated more clearly when the distribution of precipitation is separated in two regimes one for values below 20 mm day and another for values above fig 7 compares the observed and simulated distributions for rainfall intensities below 20 mm day hexagons with larger number of data present darker colors these 2d density plots allow us to appreciate that the hexagons with the largest number of data are not located in the bisector for most of the models the figure shows that observed distributions shapes are positively skewed with fewer data toward the larger numeric values the mode is located close to 0 2 mm day only the distribution shapes simulated by nn and svm models mimic the observed ones for the rest of the models the mode is located between 2 5 mm day and 5 mm day on the other side fig 8 compares the observed and simulated rainfall distribution for rainfall intensities above 20 mm day red color bands mark those values not represented in the histograms prcp 20 mm day it can be seen that the most extreme values are greatly underestimated by all models only the generalized linear models glm l and glm g are able to simulate values above 100 mm day however as shown in table 10 the performance for the rx1 and r20 indices is not satisfactory the results shown in fig 8 and in table 10 demonstrate that regressors vastly underestimate the intensity of the most extreme events recorded in tenerife during the period 1979 2015 most of these events correspond to isolated depressions at high levels also known as gota fría in spanish some examples of gota fría include the events than happened on 1993 03 17 1999 01 07 2001 03 13 2001 11 20 2002 03 31 2002 12 12 2005 12 19 if we analyze their predictors slp gh500 and gh850 variables from the cfsr database we realize that the majority of these events present very similar atmospheric synoptic patterns however the intensity of precipitation and their spatial distribution is completely different this could mean 1 that there are other explanatory variables disregarded in the analysis or 2 that the cfsr reanalysis database with a resolution of 0 25 does not capture the local processes that take place in tenerife in this context we investigated if other explanatory variables such as surface air temperature relative humidity and zonal wind speed could explain the difference in rainfall patterns for those dates however the atmospheric spatial patterns turned out to be also very similar therefore in our opinion the lack of spatial resolution might explain why the models are not able to predict the intensity of extreme events the results improve when the comparison is carried out at larger temporal aggregations fig 9 shows the skill of the models simulating the observed rainfall series at monthly aggregation all models except wt present values of r very close to 0 8 however nn again presents the best skill glm g and glm l are the only methods able to simulate months with cumulative rainfall values above 500 mm the simulated distribution shapes reproduce adequately the observed ones with a mode located at 50 mm and very few values above 500 mm fig 10 shows the skill of the models simulating the observed rainfall series at annual aggregation all models show values of r very close to 0 8 k nn and above all svm underestimate the most intense values of the distribution they are precisely the models that show higher bias values see table 10 ensemble methods like rf k nn and wt rarely simulate years with accumulated precipitation values above 800 mm if we investigate now the skill of the methods to predict the average rainfall intensity for the whole island at daily scale we appreciate that the results improve significatively with respect to those obtained for each gauge we achieve for example for the nn method a value of r equal to 0 61 when we compare observations and simulations for the 17 gauges aggregated in a single one finally it is important to note that none of the regressors used in this analysis considered location explicitly in the analysis however a verification was carried out to check if the spatial correlation among rainfall gauges was conserved based only on the information provided by synoptic patterns fig 11 shows the spatial correlation of the observed and the predicted rainfall at daily monthly and annual aggregations from left to right the panels shows the cross correlation to a daily monthly and annual aggregation respectively panels located in the upper part of the figure show the observed spatial correlation while those located at the bottom show the quotient between simulated and observed spatial correlation for all the regressors it can be seen that observed spatial correlation presents more pronounced curvatures at daily and annual temporal aggregations than at the monthly scale observed spatial correlation is slightly overestimated by most of the models with the exception of glm l and wt models for distances greater than 10 km at daily resolution all models present successful results at the monthly scale svm k nn and rf simulate time series with higher values of spatial correlation than the observed ones at annual resolution this happens because this methods show distributions with less variance than the observed at this resolution see fig 10 only the wt method is able to preserve the observed spatial correlation for all temporal aggregations which is expected since it is the only method in which predictions are done simultaneously for all the gauges the differences between the observed and simulated results for the rest of the methods is determined mainly because of probabilities being involved in the reconstructed time series and pair wise correlations not explicitly considered in the analysis 5 discussion and conclusions a comparison of 8 statistical and machine learning methods for long term rainfall prediction has been presented all methods use atmospheric synoptic patterns for the variables slp gh500 and gh850 as predictors the analysis was carried out for 17 gauges along the island of tenerife spain that presents a semi arid climate the quality of the predictions was evaluated using different metrics on rainfall occurrence and on rainfall intensity comparing modeled and observed values at different temporal aggregations by cross validation we show that most machine learning methods are very sensitive to the hyperparameters chosen wrong parameterization could lead to models without any predictive capability it may also lead to models that overfit the training data rf and k nn methods tend to over fit in order to avoid over fitting the hyperparameters n estimators and min samples leaf in the case of rf and n neighbors for k nn should take higher values even when doing so degrades their training skill hyperparameters that result in the best predictions changed considerably from one rainfall station to the others our work demonstrates that it is essential to determine the optimal hyperparameters before any application instead of resourcing to any predefined recommendation to minimize the computational cost we recommend starting with a wide search range and then center the search around the hyperparameters that offered better results in the first search the results show that nn with an average f score close to 0 4 for daily rainfall prediction is the best method for predicting rainfall occurrence closely followed by lr and svm all models are able to preserve ϕ dd however they underestimate the observed values of ϕ ww nn also presents less error when predicting the transition probabilities mainly due to its high skill predicting rainfall occurrence the increased in recall metric when prediction threshold is raised demonstrates that more intense rainfall events are easier to predict all models except wt reach values of r above 0 8 when tested simulating the number of wet days per month and per year nn svm and lr however are the only methods able to simulate months with more than 20 wet days which is exceptionally unusual in tenerife nn presents significantly better results than the rest of the models when predicting the intensity of rainfall svm k nn and rf rank second with slightly worse values of r and rmse than nn wt presents the worst results only rainfall intensity distribution shapes simulated by nn and svm models mimic the observed ones simulated series show bias values very close to 0 for all models all methods underestimate the variance of the observed series they are not able to simulate events with accumulated daily rainfall values as high as the observed ones glm g is the model that best reproduces the extreme indices rx1 and r20 however the results are still improvables most of the extreme events correspond to isolate high altitude depression also known as gota fría in spanish we realized that in these situations the atmospheric synoptic patterns for variables slp gh500 and gh850 were indistinguishable however the intensity of the precipitation and their spatial distribution were completely different it might indicate that local processes in tenerife island are not well capture by the cfsr database when comparing the observed and simulated series for larger temporal aggregations the skill of the methods improve significantly all models except wt present values of r close to 0 8 predicting rainfall intensity nn again presents the best skill glm g is the only method able to simulate months with cumulative rainfall values above 500 mm ensemble methods like rf k nn and wt rarely simulate years with accumulated precipitation values above 800 mm though regression is done independently for each gauge the atmospheric predictors allow most of the models to preserve the observed spatial correlation at daily monthly and annual aggregations a small error appears for distances greater than 10 km at daily scale the methods that show less variance at an annual temporal aggregation svm k nn and rf simulate series with higher values of spatial correlation than the observed ones only the wt method is able to preserve the observed spatial correlation for all temporal aggregations which is expected since it is the only method in which predictions are done for all the gauges simultaneously the incorporation of conceptual spatio temporal rainfall models using copulas or deep learning techniques stehlík and bárdossy 2002 yang et al 2005 will be considered in future works our results are in line with other studies performed in the past gupta and ghose 2015 olsson et al 2004 valverde ramírez et al 2005 however none of these studies carried out a significance analysis to demonstrate the best predictive capacity of some methods against others gupta and ghose 2015 found that nn provides better results than any of the other discussed algorithms decision tree naive bayes approach k nearest neighbor for predicting rainfall occurrence in new delhi from june to september rainfall period weather predictors including mean temperature dew point temperature humidity sea level pressure and wind speed according to the results achieved by gupta and ghose 2015 nn achieved a value of f score equal to 0 6 however their analysis was carried out only at a single location gauge and furthermore methods were fitted and validated only during rainfall period which probably facilitates the prediction in our analysis we obtain an average f score of 0 4 for the 17 gauges however it can vary from 0 24 to 0 54 depending on the gauge olsson et al 2004 used nn for predicting 12 h mean rainfall in kyushu island southern japan from values of wind speeds at 850 hpa and precipitable water in a 100x100 km grid surrounding the island in their study olsson et al 2004 employ a classification of intensities into four categories zero low high and extreme intensity they achieved a result of r equal to 0 63 for the entire island in our analysis we achieve an average result of 0 37 for the 17 gauges we have to bear in mind that in their analysis olsson et al 2004 use atmospheric instrumental data from the gauges we instead use large scale atmospheric reanalysis data it is expected that including atmospheric instrumental data in our analysis will improve the predictions in addition olsson et al 2004 predict the average precipitation in a cell of 100x100 km if we compare their results with those obtained when we aggregate rainfall intensity for all the gauges in the study area we realize that the results are very similar in our case we obtained a value of r closet to 0 61 valverde ramírez et al 2005 compared nn with a multiple linear regression model to predict daily rainfall using as predictors output data from a regional climatic model they use the variables potential temperature vertical component of the wind specific humidity air temperature precipitable water relative vorticity and moisture divergence flux in their analysis the test was performed for six locations in são paulo state brazil during the austral summer and winter for the period 1997 2002 the results show that nn forecasts were superior to the ones obtained by the linear regression model nn achieves results of r between 0 1 and 0 8 depending on the month and gauge analyzed the results obtained in our article also indicate that nn is the best method to predict rainfall occurrence and rainfall intensity at the daily scale however to verify this hypothesis we carried out a multivariate and univariate analysis of variance to evaluate the difference among models furthermore we demonstrate that none of the models is able to reproduce the variance and the intensity of the highest values of the distribution which suggests that these methods are not appropriate to reproduce the extreme events that took place in the past the underestimation of variance could have been addressed by including aggregate predictors in the simulation context or by using nonparametric methods based on kernel density estimation mehrotra et al 2006 mehrotra et al 2004 sharma and lall 1999 by using mixed distributions mínguez et al 2013 jeffries and pfeiffer 2001 or by testing other minimization function all these approaches will be investigated in future works the good results achieved at temporal aggregations above the day indicate that these methods may be very useful tools for water resources studies credit authorship contribution statement javier diez sierra methodology investigation visualization manuel del jesus conceptualization methodology supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to thank 1 consejo insular de aguas de tenerife ciatf for granting permission to use their rainfall database for this work 2 agencia estatal de investigación aei from the spanish ministry of economy industry and competitiveness and the european regional development fund erdf for the funding provided through grant bia2016 78397 p aei feder ue and 3 project indecis which is part of era4cs an era net initiated by jpi climate and funded by formas se dlr de bmwfw at ifd dk mineco es anr fr with co funding by the european union grant 690462 appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2020 124789 supplementary data the following are the supplementary data to this article supplementary data 1 
5461,this study evaluates eight satellite derived precipitation estimate spe datasets which include uncorrected spe and gauge corrected spe products from tropical rainfall measurement mission multi satellite precipitation analysis tmpa global precipitation measurement gpm climate hazards group infrared precipitation chirp and precipitation estimation form remotely sensed information using artificial neural networks persiann these datasets are utilized with six representative river basins corresponding to six sub climate zones in vietnam during the period 2002 2017 the evaluations were carried out in two parts 1 inter comparison of the spe products with rain gauges for the six basins 2 comparison of streamflow simulations using the soil and water assessment tool swat forced by precipitation from rain gauge and spe products the results indicated that the gauge corrected spe datasets exhibited slightly better over the uncorrected datasets in comparison with rain gauges but showed much higher performances as inputs in hydrological simulations the gpm integrated multi satellite retrievals for gpm imerg final run version 06b gpm imergf v6 exhibited the best overall performances among spe products in comparison with the rain gauges for the simulation of streamflow this study is the first of its kind to validate gpm imerg products in vietnam indicating the strong capability of the new imerg retrieval algorithms the chirp with stations chirps dataset demonstrates a relatively low bias could benefit long term water resources planning for droughts in monthly streamflow simulations the spe driven simulations outperformed rain gauge driven simulations in a larger basin north west region which has low rain gauge density the results of this study could be a guide to determine the suitability of different spe products for hydrological simulations keywords satellite derived precipitation estimate gpm swat vietnam 1 introduction the major uncertainties in hydrological modeling are associated with incorrect precipitation patterns over space sangati and borga 2009 several studies indicated that a better representation of the spatial variability in precipitation could improve model performances emmanuel et al 2012 lobligeois et al 2014 zhao et al 2013 rain gauge radar and satellite based products are popular methods to estimate precipitation across the globe rain gauges are the primary approach to obtain precipitation information as they measure rainfall directly on the ground and thus do not need transformation into any type of signal nor need to be corrected kidd 2001 however rain gauge networks are often sparse with irregular spatial coverage in many parts of the world they are nonexistent mondal et al 2018 rana et al 2015 moreover it is often challenging to obtain rain gauge data especially in developing countries and transboundary river basins for technical and administrative reasons gerlak et al 2011 plengsaeng et al 2014 ground based radar systems are useful and provide data with high temporal and spatial resolution however radar systems frequently have a limited spatial range michaelides et al 2009 and are thus most useful for rapid events typically in urban hydrology thorndahl et al 2017 in addition radar sensors are often not feasible in developing countries due to high installment costs and complex maintenance demands in an effort to cover large areas over long periods regionally and globally satellite derived precipitation estimate spe products emerge as promising approaches to reflect the spatial pattern and temporal variability of rainfall several gridded spe products have been developed over the last few decades including persiann precipitation estimation from remotely sensed information using artificial neural networks sorooshian et al 2000 cmorph climate prediction center cpc morphing technique joyce et al 2004 gsmap global satellite mapping of precipitation ushio et al 2009 tmpa trmm multi satellite precipitation analysis huffman et al 2007 and gpm global precipitation mission hou et al 2014 moreover several promising datasets incorporating gauge satellite and re analysis observations such as chirps climate hazards group infrared precipitation with station data funk et al 2015 and mswep multi source weighted ensemble precipitation beck et al 2017 have also been released many studies have shown that gauge based hydrological models outperform spe based models in terms of streamflow simulation duan et al 2018 li et al 2018 nguyen et al 2018 however spe driven hydrological simulations exhibit better performance in simulating streamflow than rain gauge driven hydrological simulations for example in the luanhe river ren et al 2018 and lower mekong river basins luo et al 2019 mohammed et al 2018 this is likely associated with the low density of rain gauges and poor quality of ground rainfall data for example a low rain gauge density was observed at the upper yangtze river basin of china where stations were located approximately every 30 000 km2 liu et al 2017 also le and pricope 2017 reported the case of the nzioa basin western kenya where rain gauge data was missing 30 65 records interpolating that data resulted in a poorer performance than that of the climate forecast system reanalysis saha et al 2010 and the chirps funk et al 2015 datasets in terms of streamflow simulation wang et al 2016 indicated that satellite based rainfall could be more suitable for driving distributed hydrologic models particularly in basins with poor rain gauge conditions the superiority of remote sensing in deriving precipitation products has become more pronounced as advanced algorithms have been developed for example the tmpa 3b42v7 has proven to be better compared to its previous version tmpa 3b42v6 zhang et al 2019 the increased spatial and temporal resolution of gpm imerg follow the successes of tmpa hou et al 2014 with an increase from 0 25 and 3 h to 0 1 and half hour furthermore a fine spatial scale of chirps 0 05 5 km has been developed funk et al 2015 these developments enable spe to better characterize the spatial and temporal variability of precipitation each of the spe products contains various versions often divided into two groups gauge adjusted gauge corrected spe and gauge unadjusted gauge uncorrected spe gauged corrected spe datasets use measured rain gauges or re analysis data to adjust precipitation estimates at the locations of the gauges correction factors used at those rain gauge locations are then applied to the entire dataset leading to a decrease or increase in rainfall estimates so that the dataset fits the directly measured more precise rain gauge data beck et al 2018 however the gauge networks used for corrections e g gpcc global precipitation climatology centre cpc climate prediction center were sparse in many areas typical in developing countries therefore rigorous comparisons between gauge corrected spe products and uncorrected spe products should be performed specifically in regions where few gauges are used for creating the adjusted spe in this study eight spe products were evaluated including the uncorrected spe products i e gpm imerge v6 tmpa 3b42rt chirp v2 0 persiann and the gauge corrected spe products i e gpm imergf v6 tmpa 3b42v7 chirps v2 0 and persiann cdr on various climate regions of vietnam a hydrological model assessment of the spe was performed using the swat soil water assessment tool hydrological model this model has demonstrated strong capabilities in hydrologic assessment throughout vietnam in many studies ha et al 2018 vu et al 2012 vu et al 2017 the primary goal of this study is to obtain insight into the performances between uncorrected and gauge corrected spe products in 1 comparisons to the rain gauge data and 2 simulations of the monthly stream flow in this paper section 2 introduces the case study section 3 presents material and methods section 4 presents the results and discussions and the conclusions are presented in section 5 2 watersheds in this study six basins with areas ranging from 684 km2 to 6042 km2 were selected fig 1 based on the following criteria firstly headwater basins were selected to reduce the impact of human activities on the flow regime secondly each basin is located entirely within a single climatological region of vietnam it allows to thoroughly examine the performance of spe datasets over vietnam these sub climatological regions include north west s1 north east s2 north delta s3 north central s4 south central s5 and central highland s6 these regions were classified based on the duration of the rainy season the three heaviest rainfall months differences in solar radiation and temperature nguyen and nguyen 2004 and are widely accepted by the climatological community nguyen xuan et al 2016 phan and ngo duc 2009 trinh tuan et al 2019b annual precipitation across basins ranges from 1400 to 3800 mm there is a seasonal variability in precipitation in each basin with 70 85 total rainfall during may august mjja or september december sond for example in the rainy season mjja in the s1 region is highly influenced by the summer monsoon whereas the s4 region is dominated by the winter monsoon nguyen le et al 2015 the average elevations of selected basins are also diverse ranging from 3 m to more than 2000 m above mean sea level 3 data and methods the chosen approach contains two steps 1 an inter comparison of spe products with in situ rain gauge data and 2 an evaluation of a hydrological model for monthly streamflow simulation driven by rain gauge precipitation measurements and spe products below we describe the data and methodology used for these two steps 3 1 ground hydro meteorological data the hydro meteorological data used in this study were obtained from the vietnam meteorological and hydrological administration vmha http kttvqg gov vn and national central for water resources planning and investigation nawapi http nawapi gov vn the data were recorded and have undergone quality control at regional meteorological and hydrological services before the post processed version was delivered to the vmha this process depends on region and data types which are varied from several days to several months personal communication the daily 2002 2017 runoff data at six hydrological stations were collected corresponding to different climatological regions xala xl of ma river langson ls of kycung river hungthi ht of boi river nghiakhanh nk of hieu river anchi ac of ve river and giangson gs of krong ana river the data quality of the streamflow was checked and assured with no gaps during the given study period averaged monthly streamflow at different climate zones in vietnam exhibits high variability in both time and space fig 2 examining fig 2 as we move from the northern part of vietnam to the south that is from climate zone s1 to s6 we observe that the peak of the monthly runoff shifts from august zones s1 and s2 to september zones s3 and s4 to november zones s5 and s6 we also observe that the ac ve river basin of zone s5 has the largest runoff by a factor of two as compared to the other river basins we collected daily 2000 2017 precipitation data from 31 rain gauge stations across six basins see supplementary data s1 there are several rain gauges in each of these basins and their number ranges from three to seven the average missing values across all rain gauges were approximately 1 0 the long term mean values were used to substitute for the missing data the rain gauge data were tested for homogeneity using the double mass curve to exclude systematic errors over time in the datasets annual rainfall at each station was compared with the average annual rainfall of surrounding stations to detect inconsistencies the results indicated no significant difference between the two curves at all rain gauge stations ensuring consistency through recorded precipitation besides at each basin one to three air temperature datasets minimum and maximum variables were collected at meteorological stations with the same duration as that of precipitation measured by the rain gauges since air temperature is less varied than precipitation a small number of air temperature stations are adequate to represent temperature profiles throughout the basins in conclusion the data from rain gauges used in this study serve two purposes 1 as a benchmark to compare with the spe datasets and 2 together with air temperature data as inputs to the swat hydrological model for the simulations of streamflow 3 2 satellite precipitation estimation spe products 3 2 1 tmpa precipitation datasets the tropical rainfall measurement mission trmm multi satellite precipitation analysis tmpa launched in late 1997 is a collaboration between the national aeronautics and space administration nasa and the japan aerospace exploration agency jaxa it is the first space mission to measure rainfall in tropical regions the trmm is a low earth orbit satellite equipped with precipitation radar pr trmm microwave imager tmi visible and infrared scanner virs and lighting imaging sensor lis huffman et al 2007 the two tmpa products used in this study are the near real time version tmpa 3b42rt hereafter 3b42rt and an adjusted version using monthly gauge precipitation tmpa 3b42v7 hereafter 3b42v7 huffman and bolvin 2013 huffman et al 2007 the three hours 0 25 grid tmpa products were accessed from nasa s goddard space flight center website https pmm nasa gov data access downloads trmm then accumulated to a daily time step 3 2 2 gpm imerg precipitation datasets the global precipitation measurement gpm mission was developed as a continuation and improvement of the trmm mission the integrated multi satellite retrievals for gpm imerg product is the level 3 multi satellite precipitation algorithm of gpm which combines all of the microwave sensors in the constellation and infrared based observations from geosynchronous satellites hou et al 2014 the two latest products of gpm imerg used in this study are gpm imerg early run version 6 hereafter imerge v6 and imerg final run version 6 hereafter imergf v6 the half hour 0 1 gridded gpm imerg products were accessed from nasa s goddard space flight center website https pmm nasa gov data access downloads gpm then accumulated to a daily time step 3 2 3 chirps precipitation datasets university of california santa barbara s climate hazards group developed the climate hazards group infrared precipitation chirp and the climate hazards group infrared precipitation with stations chirps datasets which each provides a more than 30 years quasi global rainfall dataset these products aim to support the united states agency for international development famine early warning system network fews net the chirp dataset estimates rainfall from infrared cold cloud duration ccd regression calibrated by 2000 2013 tmpa pentadal precipitation product funk et al 2015 the gauge corrected grid chirps dataset uses rain gauge station observations from various datasets mainly in the usa central america south america and sub saharan africa funk et al 2015 this study obtained the daily 0 05 grid chirp v2 0 hereafter chirp and chirps v2 0 hereafter chirps datasets from the climate hazards group website http chg geog ucsb edu data chirps 3 2 4 persiann precipitation datasets precipitation estimation from remotely sensed information using artificial neural networks persiann is developed at the center for hydrometeorology and remote sensing chrs at the university of california irvine this product uses artificial neural networks anns to estimate rainfall rates from cloud top temperature measured by long wave infrared imagery at a spatial resolution of 0 25 sorooshian et al 2000 the precipitation estimation from remotely sensed information using artificial neural networks climate data record persiann cdr is persiann s adjusted version using global precipitation climatology project gpcp monthly product version 2 2 persiann cdr has a long term data set with more than 30 years of data from 1983 to the near present however this dataset degrades the temporal resolution to daily scale ashouri et al 2015 nguyen et al 2019 this study acquired the daily 0 25 gridded persiann and persiann cdr datasets from chrs portal website https chrsdata eng uci edu a summary of spe is listed in table 1 and monthly rainfall distributions of spe at each basin are presented in fig 2 the rainfall for the ac ve river basin of zone s5 is nearly two to three times of the other five river basins this is reflected in the monthly runoff which is twice as large in the ac ve river basin compared to the other five basins 3 3 swat model and setup swat soil and water assessment tool is a physically based semi distributed eco hydrological model that operates at various time steps i e daily monthly yearly to simulate the streamflow sediment and water quality of large complex river basins arnold et al 1998 in the swat model the smallest spatial unit is the hydrologic response unit hru runoff is supposed to be predicted separately for each hru then routed to estimate the runoff for each sub basin as well as that of the entire basin a detailed description of the swat model can be found in neitsch et al 2011 determining hrus requires data on elevation land use and soil properties the 30 m shuttle radar topographic mission digital elevation model srtm dem was used to estimate slope and delineate the basin boundary it was obtained from united states geological survey usgs earth explorer https earthexplorer usgs gov the basin boundaries delineated by srtm dem were validated using a reference from the vietnamese national basin database the average error between areas delineated from the srtm dem and those from the database was 3 indicating reliable basin boundaries from the srtm dem the 30 m spatial resolution land use map representing the year 2010 was obtained from the land use portal for lower mekong basin which was maintained by servir mekong https rlcms servir adpc net en landcover a soil map developed by the vietnam national institute for soil and fertilizers at 1 1 000 000 scale national institute for soils and fertilizers 2002 was used in this study resampled from polygons to a 30 m raster file to prepare associated information of soil properties required in swat a soil database using soil water characteristics equations following the work of saxton and rawls 2006 was created statistical descriptions of elevation land use and soil used for the swat input are described in supplementary data s2 generally evergreen forests mixed forests and orchards dominate land use while acrisols acf acu ferralsols frr and fluvisols fld are the dominant soil types across basins in this study the watershed networks sub basins and hrus were generated by the qswat version 1 7 plug in in quantum geographical information system qgis version 2 6 1 dile et al 2016 several advantages of these software systems have been observed compared to the commonly used arc swat plug in on the arcgis software mohammed et al 2018 tuo et al 2016 the advantages are that qswat and qgis are open source software and qswat has additional features such as merging small sub basins and static and dynamically visualizing the outputs a contributing area over a threshold of 25 km2 was applied for all basins resulting in ranges from 15 ht to 145 xl sub basins to create hrus the method of the filter by land use soil and slope was used with a threshold of 10 percent of sub basins chosen for each feature see supplementary data s2 because solar radiation is not well observed we used the simple hargreaves method hargreaves and samani 1982 which requires only air temperature data to calculate potential evapotranspiration to simulate surface runoff processes the scs curve number usda soil conservation service 1972 and variable storage routing method williams 1969 were used by changing precipitation input datasets including rain gauges 3b42rt imerge v6 chirp persiann 3b42v7 imergf v6 chirps and persiann cdr for the swat model seven simulation scenarios were established for each basin to investigate the effects of different rainfall inputs on monthly streamflow simulation this study ran the swat model on both daily and monthly time scale selecting the first two years 2000 2001 as the warm up period the next eight years 2002 2009 as the calibration period and the last eight years 2010 2017 as the validation period the calibration procedure was performed separately for each precipitation dataset the automatic calibration was performed for streamflow simulation based on the sequential uncertainty fitting algorithm version 2 sufi 2 abbaspour et al 2007 using the swat cup tool abbaspour et al 2015 fifteen sensitive parameters were identified and set up for the same initial range for all scenarios see supplementary data s3 for each scenario a total of 1000 simulations were generated for the calibration process using the nash sutcliffe efficiency nse nash and sutcliffe 1970 as the objective function 3 4 performance metrics to compare spe datasets and ground observations we considered the following three performance metrics in terms of rainfall detection 1 probability of detection pod 2 false alarm ratio far and 3 critical success index csi to evaluate the spe datasets in terms of temporal dynamics we considered the following three performance metrics 1 correlation coefficient cc 2 relative bias rb and 3 root mean square error rmse to evaluate hydrological model performance we considered performance metrics including nash sutcliffe efficiency nse and percentage bias pbias moriasi et al 2015 the pod provides the ratio of the total precipitation events which spe products detect among the actual precipitation events the far evaluates the fraction of false rainfall events detected by spe products from the total rainfall events the csi which is a function of pod and far is the most balanced and accurate detection metric the rainfall day threshold in this study was set as 0 6 mm day 1 nchmf 2000 the cc is a score of the similarity between the spe products and ground observations while the rb and rmse demonstrate the bias and error of satellite estimates the nse indicates how well the observed streamflow and the simulated streamflow fits the 1 1 line the pbias measures the average tendency of the simulated streamflow to be larger or smaller than its observed counterpart the formulae and perfect scores for each performance metric are given in table 2 this study aims to assess the quality of spe in seasonal water balance therefore we used one way analysis of variance anova and dunnett s test ott and longnecker 2015 to compare mean values of spe with that of the rain gauges the one way anova test was first applied to determine whether significant differences exist between the means of rainfall datasets if the difference was significant dunnett s test was used by comparing each spe dataset with a single control rain gauge it was possible to specify which spe dataset was significantly different from that of the rain gauge 4 results and discussion 4 1 inter comparison between rain gauges and satellite precipitation estimate spe datasets to assess the statistical characteristics of spe the precipitation data from the eight spe products 3b42rt imerge v6 chirp persiann 3b42v7 imergf v6 chirps and persiann cdr were directly compared to the precipitation data from rain gauges in the six river basins we matched precipitation values extracted from spe s grids to the rain gauge locations if there were more than one rain gauge located in a grid we averaged values from those gauges before the comparison as we examined the gpcc gauges in vietnam 27 31 90 rain gauges in our study were not used in the generation of the gpcc product therefore our comparisons between spe datasets and rain gauges are considered as an independent evaluation 4 1 1 detection metrics assessment regarding rainfall detection metrics the gauge corrected imergf v6 exhibited the best overall performance for the entire period median pod of 0 718 rank 2 median far of 0 391 rank 1 median csi of 0 505 rank 1 see fig 3 and table 3 the second best dataset for the entire period was imerge v6 median pod of 0 699 rank 4 median far of 0 403 rank 3 median csi of 0 497 rank 2 reflecting the quality of the new imerg retrieval algorithms on both real time and research products huffman et al 2014 huffman et al 2018 note that uncorrected chirp obtained the highest pod score median pod of 0 878 but the poorest far score median far of 0 546 reflecting the imbalance of this rainfall retrieval algorithm all spe products exhibited better rainfall detection scores in the wet season than the dry season which is in line with previous studies le et al 2018 li et al 2019 wang and lu 2016 the average median values during the dry season for pod far and csi were 0 486 0 555 and 0 264 respectively the average median values during the wet season for pod far and csi were 0 797 0 388 and 0 509 respectively see fig 3 and table 3 in conclusion the newly released imerg v6 dataset outperformed other spe datasets in terms of rainfall detection the worst spe performance was observed in the persiann dataset 4 1 2 temporal dynamic metrics assessment in the assessment of temporal dynamic metrics see fig 4 and table 3 the best overall correlation coefficient for the entire period was demonstrated by imergf v6 median cc of 0 650 followed by imerge v6 median cc of 0 605 other spe datasets exhibited moderate cc scores ranging from 0 296 to 0 472 the chirps and its uncorrected chirp product exhibited the best overall rb scores for the entire period median rb of 0 0 for each product in line with beck et al 2018 these were followed by the imerge v6 and imergf v6 datasets with moderate rb scores the best overall rmse score for the entire period was achieved by imergf v6 median rmse of 12 0 mm d 1 followed by imerge v6 and chirps median rmse of 12 4 mm d 1 and 13 0 mm d 1 regarding seasonal assessment the difference between the dry and wet seasons in terms of temporal dynamic metrics was not significant the average median values during the dry season for cc and rb were 0 373 and 0 066 respectively the average median values during the wet season for cc and rb were 0 409 and 0 054 respectively see fig 4 and table 3 the average median value of rmse during the dry season was 7 01 mm d 1 which was lower than the rmse figure during the wet season 18 03 mm d 1 this reflects less variability in rainfall during the dry season compared to the wet season the ac basin south central exhibited the largest negative rb and extremely high rmse values of all spe products this is attributed to the greater spatial temporal rainfall variation of this region trinh tuan et al 2019a 4 1 3 rain no rain detection assessment rain no rain detection is an important aspect to assess the quality of spe products the 3b42v7 and 3b42rt exhibited the most similar figures in terms of the number of rainy days compared to the observations from rain gauges for the entire period fig 5 specifically 32 of observations across six basins had rainfall events over the entire period those figures from 3b42v7 and 3b42rt comprised 33 of the entire period the rainy days detected by persiann chirps imergf v6 imerge v6 accounted for 30 27 36 and 37 of the entire period respectively chirp exhibited a large overestimation of rainy days as 62 of its entire period measured rainfall events respectively reflecting the impact of intercept values in its algorithm funk et al 2015 the gauge corrected persiann cdr also highly overestimated the rainy days as these days accounted for 42 of its entire period during the dry season apart from chirp all spe datasets underestimated rainy days reflecting the difficulty of spe in terms of detecting short term rainfall events however imerg products exhibited significant improvement over the other spe products during 19 of the dry period rain gauge data observed rainfall events while those estimations from imergf v6 and imegre v6 were only 2 less 17 of the dry period suggesting frequently temporal rainfall sampling every 30 min could benefit in capturing short term rainfall events on the other hand the imerg retrieval algorithm highly overestimated rainfall events during the wet season suggesting a re evaluation for this algorithm during this period 4 1 4 mean annual rainfall assessment fig 6 compares average 2002 2017 rainfall values annually during the wet season and the dry season between rain gauge and spe products it was found that chirps product exhibited the most statistically equal mean with rain gauges among spe products 78 6 agreeing cases during the entire period the following spe products which demonstrated significantly similar means with those from rain gauges were chirp imergf v6 imerge v6 overall agreement 70 2 67 5 and 59 5 respectively this finding is in line with the low rb scores of chirps and its uncorrected counterpart previously described reflecting that chirps retrieval algorithm is suitable for trend analysis and drought assessment from another perspective all spe products achieved better agreement during the dry season than the wet season the worst mean estimation was observed at the persiann dataset 4 2 hydrological simulation driven by different precipitation data inputs 4 2 1 daily simulations fig 7 represents the performance measures for daily streamflow swat simulation driven by different precipitation datasets for the nse scores fig 7a rain gauge driven simulations exhibited the best overall performance median nse of 0 720 two spe based models had moderate performances in simulating daily streamflow these are imergf v6 driven simulations imerge v6 driven simulations with median nse scores of 0 600 and 0 500 respectively overall based on the median nse scores the rain gauge based models exhibited good performances in a daily simulation two spe based models imerf v6 and imere v6 demonstrated satisfactory performances while other spes driven simulations performed at unsatisfactory levels moriasi et al 2015 the daily spe driven simulations performed better in terms of the pbias score fig 7b the median pbias of imerg f v6 driven simulations was 1 95 followed by chirps driven simulations 2 05 3b42rt driven simulations 2 50 and rain gauge driven simulations 4 65 these performances were at very good levels moriasi et al 2015 the daily simulation using rainfall inputs from persiann cdr exhibited at good levels based on the pbias score median pbias of 6 85 the pbias scores of chirp and 3b42v7 driven simulations were at satisfactory levels median pbias of 10 10 and 10 25 respectively with the median pbias scores greater than 15 imerge v6 and persiann driven simulations were at unsatisfactory levels moriasi et al 2015 details of the daily simulation results can be found at supplementary data s4 4 2 2 monthly simulations fig 8 presents the performance measures for monthly streamflow swat simulation imposed with different precipitation datasets regarding the nse scores fig 8a the best overall performance was gained by rain gauge driven simulations median nse of 0 875 the gauge corrected spe based models had comparable performances in simulating monthly streamflow the median nse values of imergf v6 driven simulations 3b42v7 driven simulations chirps driven simulations persiann cdr driven simulations were 0 770 0 740 0 705 and 0 645 respectively apart from persiann driven simulations the uncorrected spe based model produced monthly streamflow at moderate levels the median nse values of imerge v6 driven simulations 3b42rt driven simulations and chirp driven simulations were 0 680 0 545 and 0 540 respectively overall based on the median nse scores the rain gauge based models exhibited very good performances the gauge corrected spe based models demonstrated good imergf v6 chrip 3b42v7 and satisfactory persiann cdr performances and uncorrected spe based models performed at satisfactory imerge v6 3b42rt chirp and unsatisfactory persiann levels moriasi et al 2015 in terms of the pbias score fig 8b the median pbias of rain gauge driven simulations was 1 25 followed by 3b42v7 driven simulations 1 55 chirps driven simulations 1 70 and imergf v6 driven simulations 2 60 these performances were at very good levels moriasi et al 2015 the models using rainfall inputs from uncorrected 3b42rt and chirp datasets exhibited at good levels median pbias of 6 25 for 3b42rt and 8 10 for chirp the pbias scores of imerge v6 driven simulations were at satisfactory levels mean pbias of 11 2 the median pbias of persiann driven simulations 24 95 indicated that these simulations performed at unsatisfactory level details of the monthly simulation results can be found at supplementary data s5 4 2 3 spe driven simulations in a large basin although rain gauge driven simulations exhibited the best overall performance compared to spe datasets the number of cases in which the pbias scores at unsatisfactory level pbias greater than 15 from rain gauge driven simulations were high these unsatisfactory pbias scores were found at five and three cases in the daily time step and monthly time step respectively this reflects an insufficient estimation at the spatial scale from the rain gauge on the other hand the pbias s unsatisfactory figures for the imergf v6 based model were observed at two simulations daily time step fig 7b and one simulation monthly time step fig 8b only in daily streamflow simulations at the large xl basin gauge corrected spe driven simulations exhibited comparable in performance as rain gauge driven simulations the daily nse scores of rain gauge driven simulations during the calibration and validation period at the xl basin were 0 64 and 0 69 respectively fig 9 a those figures from imergf v6 were nearly similar with the scores of 0 63 and 0 69 respectively fig 9c interestingly in monthly streamflow simulation at the xl basin the spe based models were even slightly better than rain gauge driven simulation the daily nse scores of rain gauge driven simulations during the calibration and validation period at the xl basin were 0 80 and 0 74 respectively fig 10 a those from the imergf v6 driven simulations were 0 84 and 0 91 respectively fig 10c we also examined the exceedance probability of both daily and monthly streamflow from observations and simulations driven by different precipitation datasets at the xl basin figs 11 and 12 overall the flow curves from simulated results followed the observation curves well at low exceedance levels at high exceedance level flow the simulated curves began to look different from the observed curve chirps and chirp driven simulations produced accurate curves than that from rain gauge driven simulation up to exceedance of around 85 flow for daily streamflow data and around 75 flow for monthly streamflow data suggesting the capability of those products in terms of low flow simulation 4 2 4 spe driven simulations in basin frequently affected by typhoon and tropical storm many poor scores were reported for the ac ve river basin when we used spe datasets as inputs to the swat model whereas the rain gauge driven simulations exhibited good to very good performances in daily streamflow simulation and monthly streamflow simulation daily nse for validation 0 72 monthly nse for validation 0 88 see supplementary data s4 5 we initially expected that when the swat model was recalibrated with satellite precipitation data the problem of underestimation would be mitigated however since the underestimations of the spe products were extremely large at this basin the re calibrated swat model did not perform well this large underestimation can be seen in fig 13 we used violin plots to examine the distribution of monthly basin rainfall monthly streamflow from spe driven simulations without re calibration i e using rain gauge calibration parameters and monthly streamflow from spe driven simulations with re calibration from each spe dataset although spe products demonstrated similar distribution at low to medium rainfall 500 mm month 1 a large discrepancy was found with high rainfall the maximum rainfall per month measured by the rain gauge was up to 2250 mm month 1 while the figures from spe datasets ranged from only 800 to 1500 mm month 1 when we used the rain gauge s calibrated parameters for models using spe rainfall inputs the distributions of simulated streamflow were significantly different from that of observed streamflow fig 13b on the other hand by using re calibrated parameters in each spe dataset the distributions of simulated streamflow were more similar to observed streamflow however a large dissimilarity between high streamflow distribution from models and observed data has been identified fig 13c in short from the simulation results at the ac basin we suggest a re evaluation for spe datasets at regions that are heavily influenced by the tropical cyclone and monsoon systems the simulated results of spe based models without re calibrated parameters were even worse compared to the models using re calibration parameters which is in line with previous studies alazzy et al 2017 li et al 2018 4 3 gauge corrected and uncorrected spe products table 4 presents the differences in the median between gauge corrected and uncorrected versions of spe datasets in terms of precipitation and streamflow performance metrics the gauge corrected products incorporated five day gauge data chirps and monthly gauge data 3b42v7 imergf v6 and persiann cdr datasets we expected that the late release of gauge corrected products often in several months latency would result in these products outperforming the uncorrected products however by using various precipitation metrics we detected that the gauge corrected products exhibited little improvement or even worse performances e g chirps chirp for pod 0 254 persiann cdr persian for rb 0 230 in a daily time step this suggests the necessity of incorporating daily gauge observations to improve precipitation performance at this time step the monthly streamflow performance metrics indicated a considerable improvement on the nse scores in both daily and monthly simulation averaged 0 13 for daily simulation and 0 20 for monthly simulation and a significant reduction in the pbias scores 10 3 for daily simulation and 8 6 for monthly simulation this reflects that corrections provide more benefits to hydrological applications note that in principle higher spatial resolution is better however chirps uses only infrared data and typically this dataset did not capture well the variability in precipitation in space therefore the theoretical higher spatial resolution might not provide any practical benefit previous studies comparing tmpa and chirps performance luo et al 2019 wu et al 2018 reached largely similar conclusions persiann precipitation datasets seem to not be comparable with other spe products used in this study probably because these datasets 1 also use infrared data as the chirps dataset 2 have a relative coarse spatial resolution 4 4 the relative performance of spe to rain gauge for swat simulation it is worth highlighting the rationale of relative performance when considering the gauge based model as a benchmark to investigate the adequacy of spe in driving hydrological modeling we found evidence that the performances of spe based models relative to the rain gauge based models prelative nsespe nserg nsergx100 were to some degree functions of elevation range and rain gauge network density fig 14 larger basins tended to be poorly gauged and streamflow simulations imposed with spe at large basins had comparable simulation results with those using precipitation from rain gauges the 3d surface fitted from elevation range rain gauge density and prelative suggested that high prelative values were observed at basins with a low rain gauge density on the other hand several studies blöschl 2013 indicated that hydrological simulations are performed better in large storage of watersheds because the relative variation in streamflow at these watersheds is small it leads to better simulation results compared to smaller watersheds 4 5 limitations and further study in this study we utilized the spe products for monthly streamflow simulation using their finest grid however we did not use the same grid size for different precipitation inputs this is due to two factors firstly bai et al 2018 revealed that the correlation of spe with rain gauges is different from various spatial resolutions secondly the lack of advantage of gpm imerg on streamflow simulation compared to 3b42v7 at the ganjiang river basin might be due to the resampling of the grid size from 0 1 to 0 25 of gpm imerg zhang et al 2019 spe driven simulations did not perform well in our simulations at a daily time step further study should apply a bias correction scheme for the spe products on this time step the study would greatly benefit examination of extreme analysis and disaster management 5 conclusions this study evaluated the performances of eight satellite precipitation estimation spe datasets including uncorrected versions imerge v06 tmpa 3b42rt chirp and persiann and gauge corrected versions imergf v6 tmpa 3b42v7 chirps and persiann cdr regarding six sub climate zones of vietnam the work consists of two parts 1 comparisons of the spe products to rain gauges and 2 using hydrological swat models to simulate monthly streamflow at the six basins representative of the six climate zones our findings can be summarized as follows 1 the spe products exhibited a slightly better performance during the wet season compared to the dry season in terms of rainfall detection metric pod far and csi however the temporal dynamic performance cc and rb did not show any significant difference between the two seasons 2 imergf v6 exhibited the best overall performance among spe products in comparison with rain gauges and as inputs to the swat models for streamflow simulations our study is the first attempt to evaluate the performance of gpm imerg in vietnam suggesting strong capability for this product in hydrological application purposes 3 chirps achieved the smallest bias among spe products compared to rain gauge data reflecting the aim of this product as a drought warning system and for trend analysis 4 gauge corrected versions of spe products exhibited slightly better over the uncorrected versions of spe products in terms of precipitation performance metrics this suggests that the use of sub monthly and monthly rain gauges did not significantly benefit spe s improvement at the daily time step however the gauge corrected spe products performed better than their uncorrected counterparts in both daily and monthly streamflow simulation 5 spe products can serve as alternative inputs to enhance the performance of hydrological models in basins with a low rain gauge density this study determines the ability of spe products to estimate rainfall and produce input data for streamflow simulations in vietnam our findings could be used as a guide to select which spe products are suitable for hydrological applications although this study is specific for hydro climatic conditions in the river basins of vietnam the methodology can be applied to watersheds in other regions of the world credit authorship contribution statement manh hung le conceptualization methodology software validation formal analysis investigation resources data curation writing original draft writing review editing visualization venkataraman lakshmi supervision project administration funding acquisition writing review editing john bolten investigation resources project administration funding acquisition duong du bui data curation writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is funded by the national aeronautics and space administration nasa project grant number nnx16at86g and vingroup innovation foundation vinif annual research support program grant number vinif 2019 da17 we would like to express our sincere gratitude to the institutions for providing us with the required hydro meteorological measurements that enabled this study these include vietnam hydrology and meteorological administration and national central for water resources planning and investigation special acknowledgment also goes to nasa university of california santa barbara s climate hazards group and servir mekong for providing easy access to the spe products and land cover data respectively we would also like to thank dr r srinivasan and dr yihun dele texas a m univ for their kind help and fruitful discussion regarding the application of swat and dr vu manh quyet sfri for sharing soil map of vietnam we also acknowledge mr truong sinh do nawapi for sharing the ls basin kycung river dataset appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124820 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5461,this study evaluates eight satellite derived precipitation estimate spe datasets which include uncorrected spe and gauge corrected spe products from tropical rainfall measurement mission multi satellite precipitation analysis tmpa global precipitation measurement gpm climate hazards group infrared precipitation chirp and precipitation estimation form remotely sensed information using artificial neural networks persiann these datasets are utilized with six representative river basins corresponding to six sub climate zones in vietnam during the period 2002 2017 the evaluations were carried out in two parts 1 inter comparison of the spe products with rain gauges for the six basins 2 comparison of streamflow simulations using the soil and water assessment tool swat forced by precipitation from rain gauge and spe products the results indicated that the gauge corrected spe datasets exhibited slightly better over the uncorrected datasets in comparison with rain gauges but showed much higher performances as inputs in hydrological simulations the gpm integrated multi satellite retrievals for gpm imerg final run version 06b gpm imergf v6 exhibited the best overall performances among spe products in comparison with the rain gauges for the simulation of streamflow this study is the first of its kind to validate gpm imerg products in vietnam indicating the strong capability of the new imerg retrieval algorithms the chirp with stations chirps dataset demonstrates a relatively low bias could benefit long term water resources planning for droughts in monthly streamflow simulations the spe driven simulations outperformed rain gauge driven simulations in a larger basin north west region which has low rain gauge density the results of this study could be a guide to determine the suitability of different spe products for hydrological simulations keywords satellite derived precipitation estimate gpm swat vietnam 1 introduction the major uncertainties in hydrological modeling are associated with incorrect precipitation patterns over space sangati and borga 2009 several studies indicated that a better representation of the spatial variability in precipitation could improve model performances emmanuel et al 2012 lobligeois et al 2014 zhao et al 2013 rain gauge radar and satellite based products are popular methods to estimate precipitation across the globe rain gauges are the primary approach to obtain precipitation information as they measure rainfall directly on the ground and thus do not need transformation into any type of signal nor need to be corrected kidd 2001 however rain gauge networks are often sparse with irregular spatial coverage in many parts of the world they are nonexistent mondal et al 2018 rana et al 2015 moreover it is often challenging to obtain rain gauge data especially in developing countries and transboundary river basins for technical and administrative reasons gerlak et al 2011 plengsaeng et al 2014 ground based radar systems are useful and provide data with high temporal and spatial resolution however radar systems frequently have a limited spatial range michaelides et al 2009 and are thus most useful for rapid events typically in urban hydrology thorndahl et al 2017 in addition radar sensors are often not feasible in developing countries due to high installment costs and complex maintenance demands in an effort to cover large areas over long periods regionally and globally satellite derived precipitation estimate spe products emerge as promising approaches to reflect the spatial pattern and temporal variability of rainfall several gridded spe products have been developed over the last few decades including persiann precipitation estimation from remotely sensed information using artificial neural networks sorooshian et al 2000 cmorph climate prediction center cpc morphing technique joyce et al 2004 gsmap global satellite mapping of precipitation ushio et al 2009 tmpa trmm multi satellite precipitation analysis huffman et al 2007 and gpm global precipitation mission hou et al 2014 moreover several promising datasets incorporating gauge satellite and re analysis observations such as chirps climate hazards group infrared precipitation with station data funk et al 2015 and mswep multi source weighted ensemble precipitation beck et al 2017 have also been released many studies have shown that gauge based hydrological models outperform spe based models in terms of streamflow simulation duan et al 2018 li et al 2018 nguyen et al 2018 however spe driven hydrological simulations exhibit better performance in simulating streamflow than rain gauge driven hydrological simulations for example in the luanhe river ren et al 2018 and lower mekong river basins luo et al 2019 mohammed et al 2018 this is likely associated with the low density of rain gauges and poor quality of ground rainfall data for example a low rain gauge density was observed at the upper yangtze river basin of china where stations were located approximately every 30 000 km2 liu et al 2017 also le and pricope 2017 reported the case of the nzioa basin western kenya where rain gauge data was missing 30 65 records interpolating that data resulted in a poorer performance than that of the climate forecast system reanalysis saha et al 2010 and the chirps funk et al 2015 datasets in terms of streamflow simulation wang et al 2016 indicated that satellite based rainfall could be more suitable for driving distributed hydrologic models particularly in basins with poor rain gauge conditions the superiority of remote sensing in deriving precipitation products has become more pronounced as advanced algorithms have been developed for example the tmpa 3b42v7 has proven to be better compared to its previous version tmpa 3b42v6 zhang et al 2019 the increased spatial and temporal resolution of gpm imerg follow the successes of tmpa hou et al 2014 with an increase from 0 25 and 3 h to 0 1 and half hour furthermore a fine spatial scale of chirps 0 05 5 km has been developed funk et al 2015 these developments enable spe to better characterize the spatial and temporal variability of precipitation each of the spe products contains various versions often divided into two groups gauge adjusted gauge corrected spe and gauge unadjusted gauge uncorrected spe gauged corrected spe datasets use measured rain gauges or re analysis data to adjust precipitation estimates at the locations of the gauges correction factors used at those rain gauge locations are then applied to the entire dataset leading to a decrease or increase in rainfall estimates so that the dataset fits the directly measured more precise rain gauge data beck et al 2018 however the gauge networks used for corrections e g gpcc global precipitation climatology centre cpc climate prediction center were sparse in many areas typical in developing countries therefore rigorous comparisons between gauge corrected spe products and uncorrected spe products should be performed specifically in regions where few gauges are used for creating the adjusted spe in this study eight spe products were evaluated including the uncorrected spe products i e gpm imerge v6 tmpa 3b42rt chirp v2 0 persiann and the gauge corrected spe products i e gpm imergf v6 tmpa 3b42v7 chirps v2 0 and persiann cdr on various climate regions of vietnam a hydrological model assessment of the spe was performed using the swat soil water assessment tool hydrological model this model has demonstrated strong capabilities in hydrologic assessment throughout vietnam in many studies ha et al 2018 vu et al 2012 vu et al 2017 the primary goal of this study is to obtain insight into the performances between uncorrected and gauge corrected spe products in 1 comparisons to the rain gauge data and 2 simulations of the monthly stream flow in this paper section 2 introduces the case study section 3 presents material and methods section 4 presents the results and discussions and the conclusions are presented in section 5 2 watersheds in this study six basins with areas ranging from 684 km2 to 6042 km2 were selected fig 1 based on the following criteria firstly headwater basins were selected to reduce the impact of human activities on the flow regime secondly each basin is located entirely within a single climatological region of vietnam it allows to thoroughly examine the performance of spe datasets over vietnam these sub climatological regions include north west s1 north east s2 north delta s3 north central s4 south central s5 and central highland s6 these regions were classified based on the duration of the rainy season the three heaviest rainfall months differences in solar radiation and temperature nguyen and nguyen 2004 and are widely accepted by the climatological community nguyen xuan et al 2016 phan and ngo duc 2009 trinh tuan et al 2019b annual precipitation across basins ranges from 1400 to 3800 mm there is a seasonal variability in precipitation in each basin with 70 85 total rainfall during may august mjja or september december sond for example in the rainy season mjja in the s1 region is highly influenced by the summer monsoon whereas the s4 region is dominated by the winter monsoon nguyen le et al 2015 the average elevations of selected basins are also diverse ranging from 3 m to more than 2000 m above mean sea level 3 data and methods the chosen approach contains two steps 1 an inter comparison of spe products with in situ rain gauge data and 2 an evaluation of a hydrological model for monthly streamflow simulation driven by rain gauge precipitation measurements and spe products below we describe the data and methodology used for these two steps 3 1 ground hydro meteorological data the hydro meteorological data used in this study were obtained from the vietnam meteorological and hydrological administration vmha http kttvqg gov vn and national central for water resources planning and investigation nawapi http nawapi gov vn the data were recorded and have undergone quality control at regional meteorological and hydrological services before the post processed version was delivered to the vmha this process depends on region and data types which are varied from several days to several months personal communication the daily 2002 2017 runoff data at six hydrological stations were collected corresponding to different climatological regions xala xl of ma river langson ls of kycung river hungthi ht of boi river nghiakhanh nk of hieu river anchi ac of ve river and giangson gs of krong ana river the data quality of the streamflow was checked and assured with no gaps during the given study period averaged monthly streamflow at different climate zones in vietnam exhibits high variability in both time and space fig 2 examining fig 2 as we move from the northern part of vietnam to the south that is from climate zone s1 to s6 we observe that the peak of the monthly runoff shifts from august zones s1 and s2 to september zones s3 and s4 to november zones s5 and s6 we also observe that the ac ve river basin of zone s5 has the largest runoff by a factor of two as compared to the other river basins we collected daily 2000 2017 precipitation data from 31 rain gauge stations across six basins see supplementary data s1 there are several rain gauges in each of these basins and their number ranges from three to seven the average missing values across all rain gauges were approximately 1 0 the long term mean values were used to substitute for the missing data the rain gauge data were tested for homogeneity using the double mass curve to exclude systematic errors over time in the datasets annual rainfall at each station was compared with the average annual rainfall of surrounding stations to detect inconsistencies the results indicated no significant difference between the two curves at all rain gauge stations ensuring consistency through recorded precipitation besides at each basin one to three air temperature datasets minimum and maximum variables were collected at meteorological stations with the same duration as that of precipitation measured by the rain gauges since air temperature is less varied than precipitation a small number of air temperature stations are adequate to represent temperature profiles throughout the basins in conclusion the data from rain gauges used in this study serve two purposes 1 as a benchmark to compare with the spe datasets and 2 together with air temperature data as inputs to the swat hydrological model for the simulations of streamflow 3 2 satellite precipitation estimation spe products 3 2 1 tmpa precipitation datasets the tropical rainfall measurement mission trmm multi satellite precipitation analysis tmpa launched in late 1997 is a collaboration between the national aeronautics and space administration nasa and the japan aerospace exploration agency jaxa it is the first space mission to measure rainfall in tropical regions the trmm is a low earth orbit satellite equipped with precipitation radar pr trmm microwave imager tmi visible and infrared scanner virs and lighting imaging sensor lis huffman et al 2007 the two tmpa products used in this study are the near real time version tmpa 3b42rt hereafter 3b42rt and an adjusted version using monthly gauge precipitation tmpa 3b42v7 hereafter 3b42v7 huffman and bolvin 2013 huffman et al 2007 the three hours 0 25 grid tmpa products were accessed from nasa s goddard space flight center website https pmm nasa gov data access downloads trmm then accumulated to a daily time step 3 2 2 gpm imerg precipitation datasets the global precipitation measurement gpm mission was developed as a continuation and improvement of the trmm mission the integrated multi satellite retrievals for gpm imerg product is the level 3 multi satellite precipitation algorithm of gpm which combines all of the microwave sensors in the constellation and infrared based observations from geosynchronous satellites hou et al 2014 the two latest products of gpm imerg used in this study are gpm imerg early run version 6 hereafter imerge v6 and imerg final run version 6 hereafter imergf v6 the half hour 0 1 gridded gpm imerg products were accessed from nasa s goddard space flight center website https pmm nasa gov data access downloads gpm then accumulated to a daily time step 3 2 3 chirps precipitation datasets university of california santa barbara s climate hazards group developed the climate hazards group infrared precipitation chirp and the climate hazards group infrared precipitation with stations chirps datasets which each provides a more than 30 years quasi global rainfall dataset these products aim to support the united states agency for international development famine early warning system network fews net the chirp dataset estimates rainfall from infrared cold cloud duration ccd regression calibrated by 2000 2013 tmpa pentadal precipitation product funk et al 2015 the gauge corrected grid chirps dataset uses rain gauge station observations from various datasets mainly in the usa central america south america and sub saharan africa funk et al 2015 this study obtained the daily 0 05 grid chirp v2 0 hereafter chirp and chirps v2 0 hereafter chirps datasets from the climate hazards group website http chg geog ucsb edu data chirps 3 2 4 persiann precipitation datasets precipitation estimation from remotely sensed information using artificial neural networks persiann is developed at the center for hydrometeorology and remote sensing chrs at the university of california irvine this product uses artificial neural networks anns to estimate rainfall rates from cloud top temperature measured by long wave infrared imagery at a spatial resolution of 0 25 sorooshian et al 2000 the precipitation estimation from remotely sensed information using artificial neural networks climate data record persiann cdr is persiann s adjusted version using global precipitation climatology project gpcp monthly product version 2 2 persiann cdr has a long term data set with more than 30 years of data from 1983 to the near present however this dataset degrades the temporal resolution to daily scale ashouri et al 2015 nguyen et al 2019 this study acquired the daily 0 25 gridded persiann and persiann cdr datasets from chrs portal website https chrsdata eng uci edu a summary of spe is listed in table 1 and monthly rainfall distributions of spe at each basin are presented in fig 2 the rainfall for the ac ve river basin of zone s5 is nearly two to three times of the other five river basins this is reflected in the monthly runoff which is twice as large in the ac ve river basin compared to the other five basins 3 3 swat model and setup swat soil and water assessment tool is a physically based semi distributed eco hydrological model that operates at various time steps i e daily monthly yearly to simulate the streamflow sediment and water quality of large complex river basins arnold et al 1998 in the swat model the smallest spatial unit is the hydrologic response unit hru runoff is supposed to be predicted separately for each hru then routed to estimate the runoff for each sub basin as well as that of the entire basin a detailed description of the swat model can be found in neitsch et al 2011 determining hrus requires data on elevation land use and soil properties the 30 m shuttle radar topographic mission digital elevation model srtm dem was used to estimate slope and delineate the basin boundary it was obtained from united states geological survey usgs earth explorer https earthexplorer usgs gov the basin boundaries delineated by srtm dem were validated using a reference from the vietnamese national basin database the average error between areas delineated from the srtm dem and those from the database was 3 indicating reliable basin boundaries from the srtm dem the 30 m spatial resolution land use map representing the year 2010 was obtained from the land use portal for lower mekong basin which was maintained by servir mekong https rlcms servir adpc net en landcover a soil map developed by the vietnam national institute for soil and fertilizers at 1 1 000 000 scale national institute for soils and fertilizers 2002 was used in this study resampled from polygons to a 30 m raster file to prepare associated information of soil properties required in swat a soil database using soil water characteristics equations following the work of saxton and rawls 2006 was created statistical descriptions of elevation land use and soil used for the swat input are described in supplementary data s2 generally evergreen forests mixed forests and orchards dominate land use while acrisols acf acu ferralsols frr and fluvisols fld are the dominant soil types across basins in this study the watershed networks sub basins and hrus were generated by the qswat version 1 7 plug in in quantum geographical information system qgis version 2 6 1 dile et al 2016 several advantages of these software systems have been observed compared to the commonly used arc swat plug in on the arcgis software mohammed et al 2018 tuo et al 2016 the advantages are that qswat and qgis are open source software and qswat has additional features such as merging small sub basins and static and dynamically visualizing the outputs a contributing area over a threshold of 25 km2 was applied for all basins resulting in ranges from 15 ht to 145 xl sub basins to create hrus the method of the filter by land use soil and slope was used with a threshold of 10 percent of sub basins chosen for each feature see supplementary data s2 because solar radiation is not well observed we used the simple hargreaves method hargreaves and samani 1982 which requires only air temperature data to calculate potential evapotranspiration to simulate surface runoff processes the scs curve number usda soil conservation service 1972 and variable storage routing method williams 1969 were used by changing precipitation input datasets including rain gauges 3b42rt imerge v6 chirp persiann 3b42v7 imergf v6 chirps and persiann cdr for the swat model seven simulation scenarios were established for each basin to investigate the effects of different rainfall inputs on monthly streamflow simulation this study ran the swat model on both daily and monthly time scale selecting the first two years 2000 2001 as the warm up period the next eight years 2002 2009 as the calibration period and the last eight years 2010 2017 as the validation period the calibration procedure was performed separately for each precipitation dataset the automatic calibration was performed for streamflow simulation based on the sequential uncertainty fitting algorithm version 2 sufi 2 abbaspour et al 2007 using the swat cup tool abbaspour et al 2015 fifteen sensitive parameters were identified and set up for the same initial range for all scenarios see supplementary data s3 for each scenario a total of 1000 simulations were generated for the calibration process using the nash sutcliffe efficiency nse nash and sutcliffe 1970 as the objective function 3 4 performance metrics to compare spe datasets and ground observations we considered the following three performance metrics in terms of rainfall detection 1 probability of detection pod 2 false alarm ratio far and 3 critical success index csi to evaluate the spe datasets in terms of temporal dynamics we considered the following three performance metrics 1 correlation coefficient cc 2 relative bias rb and 3 root mean square error rmse to evaluate hydrological model performance we considered performance metrics including nash sutcliffe efficiency nse and percentage bias pbias moriasi et al 2015 the pod provides the ratio of the total precipitation events which spe products detect among the actual precipitation events the far evaluates the fraction of false rainfall events detected by spe products from the total rainfall events the csi which is a function of pod and far is the most balanced and accurate detection metric the rainfall day threshold in this study was set as 0 6 mm day 1 nchmf 2000 the cc is a score of the similarity between the spe products and ground observations while the rb and rmse demonstrate the bias and error of satellite estimates the nse indicates how well the observed streamflow and the simulated streamflow fits the 1 1 line the pbias measures the average tendency of the simulated streamflow to be larger or smaller than its observed counterpart the formulae and perfect scores for each performance metric are given in table 2 this study aims to assess the quality of spe in seasonal water balance therefore we used one way analysis of variance anova and dunnett s test ott and longnecker 2015 to compare mean values of spe with that of the rain gauges the one way anova test was first applied to determine whether significant differences exist between the means of rainfall datasets if the difference was significant dunnett s test was used by comparing each spe dataset with a single control rain gauge it was possible to specify which spe dataset was significantly different from that of the rain gauge 4 results and discussion 4 1 inter comparison between rain gauges and satellite precipitation estimate spe datasets to assess the statistical characteristics of spe the precipitation data from the eight spe products 3b42rt imerge v6 chirp persiann 3b42v7 imergf v6 chirps and persiann cdr were directly compared to the precipitation data from rain gauges in the six river basins we matched precipitation values extracted from spe s grids to the rain gauge locations if there were more than one rain gauge located in a grid we averaged values from those gauges before the comparison as we examined the gpcc gauges in vietnam 27 31 90 rain gauges in our study were not used in the generation of the gpcc product therefore our comparisons between spe datasets and rain gauges are considered as an independent evaluation 4 1 1 detection metrics assessment regarding rainfall detection metrics the gauge corrected imergf v6 exhibited the best overall performance for the entire period median pod of 0 718 rank 2 median far of 0 391 rank 1 median csi of 0 505 rank 1 see fig 3 and table 3 the second best dataset for the entire period was imerge v6 median pod of 0 699 rank 4 median far of 0 403 rank 3 median csi of 0 497 rank 2 reflecting the quality of the new imerg retrieval algorithms on both real time and research products huffman et al 2014 huffman et al 2018 note that uncorrected chirp obtained the highest pod score median pod of 0 878 but the poorest far score median far of 0 546 reflecting the imbalance of this rainfall retrieval algorithm all spe products exhibited better rainfall detection scores in the wet season than the dry season which is in line with previous studies le et al 2018 li et al 2019 wang and lu 2016 the average median values during the dry season for pod far and csi were 0 486 0 555 and 0 264 respectively the average median values during the wet season for pod far and csi were 0 797 0 388 and 0 509 respectively see fig 3 and table 3 in conclusion the newly released imerg v6 dataset outperformed other spe datasets in terms of rainfall detection the worst spe performance was observed in the persiann dataset 4 1 2 temporal dynamic metrics assessment in the assessment of temporal dynamic metrics see fig 4 and table 3 the best overall correlation coefficient for the entire period was demonstrated by imergf v6 median cc of 0 650 followed by imerge v6 median cc of 0 605 other spe datasets exhibited moderate cc scores ranging from 0 296 to 0 472 the chirps and its uncorrected chirp product exhibited the best overall rb scores for the entire period median rb of 0 0 for each product in line with beck et al 2018 these were followed by the imerge v6 and imergf v6 datasets with moderate rb scores the best overall rmse score for the entire period was achieved by imergf v6 median rmse of 12 0 mm d 1 followed by imerge v6 and chirps median rmse of 12 4 mm d 1 and 13 0 mm d 1 regarding seasonal assessment the difference between the dry and wet seasons in terms of temporal dynamic metrics was not significant the average median values during the dry season for cc and rb were 0 373 and 0 066 respectively the average median values during the wet season for cc and rb were 0 409 and 0 054 respectively see fig 4 and table 3 the average median value of rmse during the dry season was 7 01 mm d 1 which was lower than the rmse figure during the wet season 18 03 mm d 1 this reflects less variability in rainfall during the dry season compared to the wet season the ac basin south central exhibited the largest negative rb and extremely high rmse values of all spe products this is attributed to the greater spatial temporal rainfall variation of this region trinh tuan et al 2019a 4 1 3 rain no rain detection assessment rain no rain detection is an important aspect to assess the quality of spe products the 3b42v7 and 3b42rt exhibited the most similar figures in terms of the number of rainy days compared to the observations from rain gauges for the entire period fig 5 specifically 32 of observations across six basins had rainfall events over the entire period those figures from 3b42v7 and 3b42rt comprised 33 of the entire period the rainy days detected by persiann chirps imergf v6 imerge v6 accounted for 30 27 36 and 37 of the entire period respectively chirp exhibited a large overestimation of rainy days as 62 of its entire period measured rainfall events respectively reflecting the impact of intercept values in its algorithm funk et al 2015 the gauge corrected persiann cdr also highly overestimated the rainy days as these days accounted for 42 of its entire period during the dry season apart from chirp all spe datasets underestimated rainy days reflecting the difficulty of spe in terms of detecting short term rainfall events however imerg products exhibited significant improvement over the other spe products during 19 of the dry period rain gauge data observed rainfall events while those estimations from imergf v6 and imegre v6 were only 2 less 17 of the dry period suggesting frequently temporal rainfall sampling every 30 min could benefit in capturing short term rainfall events on the other hand the imerg retrieval algorithm highly overestimated rainfall events during the wet season suggesting a re evaluation for this algorithm during this period 4 1 4 mean annual rainfall assessment fig 6 compares average 2002 2017 rainfall values annually during the wet season and the dry season between rain gauge and spe products it was found that chirps product exhibited the most statistically equal mean with rain gauges among spe products 78 6 agreeing cases during the entire period the following spe products which demonstrated significantly similar means with those from rain gauges were chirp imergf v6 imerge v6 overall agreement 70 2 67 5 and 59 5 respectively this finding is in line with the low rb scores of chirps and its uncorrected counterpart previously described reflecting that chirps retrieval algorithm is suitable for trend analysis and drought assessment from another perspective all spe products achieved better agreement during the dry season than the wet season the worst mean estimation was observed at the persiann dataset 4 2 hydrological simulation driven by different precipitation data inputs 4 2 1 daily simulations fig 7 represents the performance measures for daily streamflow swat simulation driven by different precipitation datasets for the nse scores fig 7a rain gauge driven simulations exhibited the best overall performance median nse of 0 720 two spe based models had moderate performances in simulating daily streamflow these are imergf v6 driven simulations imerge v6 driven simulations with median nse scores of 0 600 and 0 500 respectively overall based on the median nse scores the rain gauge based models exhibited good performances in a daily simulation two spe based models imerf v6 and imere v6 demonstrated satisfactory performances while other spes driven simulations performed at unsatisfactory levels moriasi et al 2015 the daily spe driven simulations performed better in terms of the pbias score fig 7b the median pbias of imerg f v6 driven simulations was 1 95 followed by chirps driven simulations 2 05 3b42rt driven simulations 2 50 and rain gauge driven simulations 4 65 these performances were at very good levels moriasi et al 2015 the daily simulation using rainfall inputs from persiann cdr exhibited at good levels based on the pbias score median pbias of 6 85 the pbias scores of chirp and 3b42v7 driven simulations were at satisfactory levels median pbias of 10 10 and 10 25 respectively with the median pbias scores greater than 15 imerge v6 and persiann driven simulations were at unsatisfactory levels moriasi et al 2015 details of the daily simulation results can be found at supplementary data s4 4 2 2 monthly simulations fig 8 presents the performance measures for monthly streamflow swat simulation imposed with different precipitation datasets regarding the nse scores fig 8a the best overall performance was gained by rain gauge driven simulations median nse of 0 875 the gauge corrected spe based models had comparable performances in simulating monthly streamflow the median nse values of imergf v6 driven simulations 3b42v7 driven simulations chirps driven simulations persiann cdr driven simulations were 0 770 0 740 0 705 and 0 645 respectively apart from persiann driven simulations the uncorrected spe based model produced monthly streamflow at moderate levels the median nse values of imerge v6 driven simulations 3b42rt driven simulations and chirp driven simulations were 0 680 0 545 and 0 540 respectively overall based on the median nse scores the rain gauge based models exhibited very good performances the gauge corrected spe based models demonstrated good imergf v6 chrip 3b42v7 and satisfactory persiann cdr performances and uncorrected spe based models performed at satisfactory imerge v6 3b42rt chirp and unsatisfactory persiann levels moriasi et al 2015 in terms of the pbias score fig 8b the median pbias of rain gauge driven simulations was 1 25 followed by 3b42v7 driven simulations 1 55 chirps driven simulations 1 70 and imergf v6 driven simulations 2 60 these performances were at very good levels moriasi et al 2015 the models using rainfall inputs from uncorrected 3b42rt and chirp datasets exhibited at good levels median pbias of 6 25 for 3b42rt and 8 10 for chirp the pbias scores of imerge v6 driven simulations were at satisfactory levels mean pbias of 11 2 the median pbias of persiann driven simulations 24 95 indicated that these simulations performed at unsatisfactory level details of the monthly simulation results can be found at supplementary data s5 4 2 3 spe driven simulations in a large basin although rain gauge driven simulations exhibited the best overall performance compared to spe datasets the number of cases in which the pbias scores at unsatisfactory level pbias greater than 15 from rain gauge driven simulations were high these unsatisfactory pbias scores were found at five and three cases in the daily time step and monthly time step respectively this reflects an insufficient estimation at the spatial scale from the rain gauge on the other hand the pbias s unsatisfactory figures for the imergf v6 based model were observed at two simulations daily time step fig 7b and one simulation monthly time step fig 8b only in daily streamflow simulations at the large xl basin gauge corrected spe driven simulations exhibited comparable in performance as rain gauge driven simulations the daily nse scores of rain gauge driven simulations during the calibration and validation period at the xl basin were 0 64 and 0 69 respectively fig 9 a those figures from imergf v6 were nearly similar with the scores of 0 63 and 0 69 respectively fig 9c interestingly in monthly streamflow simulation at the xl basin the spe based models were even slightly better than rain gauge driven simulation the daily nse scores of rain gauge driven simulations during the calibration and validation period at the xl basin were 0 80 and 0 74 respectively fig 10 a those from the imergf v6 driven simulations were 0 84 and 0 91 respectively fig 10c we also examined the exceedance probability of both daily and monthly streamflow from observations and simulations driven by different precipitation datasets at the xl basin figs 11 and 12 overall the flow curves from simulated results followed the observation curves well at low exceedance levels at high exceedance level flow the simulated curves began to look different from the observed curve chirps and chirp driven simulations produced accurate curves than that from rain gauge driven simulation up to exceedance of around 85 flow for daily streamflow data and around 75 flow for monthly streamflow data suggesting the capability of those products in terms of low flow simulation 4 2 4 spe driven simulations in basin frequently affected by typhoon and tropical storm many poor scores were reported for the ac ve river basin when we used spe datasets as inputs to the swat model whereas the rain gauge driven simulations exhibited good to very good performances in daily streamflow simulation and monthly streamflow simulation daily nse for validation 0 72 monthly nse for validation 0 88 see supplementary data s4 5 we initially expected that when the swat model was recalibrated with satellite precipitation data the problem of underestimation would be mitigated however since the underestimations of the spe products were extremely large at this basin the re calibrated swat model did not perform well this large underestimation can be seen in fig 13 we used violin plots to examine the distribution of monthly basin rainfall monthly streamflow from spe driven simulations without re calibration i e using rain gauge calibration parameters and monthly streamflow from spe driven simulations with re calibration from each spe dataset although spe products demonstrated similar distribution at low to medium rainfall 500 mm month 1 a large discrepancy was found with high rainfall the maximum rainfall per month measured by the rain gauge was up to 2250 mm month 1 while the figures from spe datasets ranged from only 800 to 1500 mm month 1 when we used the rain gauge s calibrated parameters for models using spe rainfall inputs the distributions of simulated streamflow were significantly different from that of observed streamflow fig 13b on the other hand by using re calibrated parameters in each spe dataset the distributions of simulated streamflow were more similar to observed streamflow however a large dissimilarity between high streamflow distribution from models and observed data has been identified fig 13c in short from the simulation results at the ac basin we suggest a re evaluation for spe datasets at regions that are heavily influenced by the tropical cyclone and monsoon systems the simulated results of spe based models without re calibrated parameters were even worse compared to the models using re calibration parameters which is in line with previous studies alazzy et al 2017 li et al 2018 4 3 gauge corrected and uncorrected spe products table 4 presents the differences in the median between gauge corrected and uncorrected versions of spe datasets in terms of precipitation and streamflow performance metrics the gauge corrected products incorporated five day gauge data chirps and monthly gauge data 3b42v7 imergf v6 and persiann cdr datasets we expected that the late release of gauge corrected products often in several months latency would result in these products outperforming the uncorrected products however by using various precipitation metrics we detected that the gauge corrected products exhibited little improvement or even worse performances e g chirps chirp for pod 0 254 persiann cdr persian for rb 0 230 in a daily time step this suggests the necessity of incorporating daily gauge observations to improve precipitation performance at this time step the monthly streamflow performance metrics indicated a considerable improvement on the nse scores in both daily and monthly simulation averaged 0 13 for daily simulation and 0 20 for monthly simulation and a significant reduction in the pbias scores 10 3 for daily simulation and 8 6 for monthly simulation this reflects that corrections provide more benefits to hydrological applications note that in principle higher spatial resolution is better however chirps uses only infrared data and typically this dataset did not capture well the variability in precipitation in space therefore the theoretical higher spatial resolution might not provide any practical benefit previous studies comparing tmpa and chirps performance luo et al 2019 wu et al 2018 reached largely similar conclusions persiann precipitation datasets seem to not be comparable with other spe products used in this study probably because these datasets 1 also use infrared data as the chirps dataset 2 have a relative coarse spatial resolution 4 4 the relative performance of spe to rain gauge for swat simulation it is worth highlighting the rationale of relative performance when considering the gauge based model as a benchmark to investigate the adequacy of spe in driving hydrological modeling we found evidence that the performances of spe based models relative to the rain gauge based models prelative nsespe nserg nsergx100 were to some degree functions of elevation range and rain gauge network density fig 14 larger basins tended to be poorly gauged and streamflow simulations imposed with spe at large basins had comparable simulation results with those using precipitation from rain gauges the 3d surface fitted from elevation range rain gauge density and prelative suggested that high prelative values were observed at basins with a low rain gauge density on the other hand several studies blöschl 2013 indicated that hydrological simulations are performed better in large storage of watersheds because the relative variation in streamflow at these watersheds is small it leads to better simulation results compared to smaller watersheds 4 5 limitations and further study in this study we utilized the spe products for monthly streamflow simulation using their finest grid however we did not use the same grid size for different precipitation inputs this is due to two factors firstly bai et al 2018 revealed that the correlation of spe with rain gauges is different from various spatial resolutions secondly the lack of advantage of gpm imerg on streamflow simulation compared to 3b42v7 at the ganjiang river basin might be due to the resampling of the grid size from 0 1 to 0 25 of gpm imerg zhang et al 2019 spe driven simulations did not perform well in our simulations at a daily time step further study should apply a bias correction scheme for the spe products on this time step the study would greatly benefit examination of extreme analysis and disaster management 5 conclusions this study evaluated the performances of eight satellite precipitation estimation spe datasets including uncorrected versions imerge v06 tmpa 3b42rt chirp and persiann and gauge corrected versions imergf v6 tmpa 3b42v7 chirps and persiann cdr regarding six sub climate zones of vietnam the work consists of two parts 1 comparisons of the spe products to rain gauges and 2 using hydrological swat models to simulate monthly streamflow at the six basins representative of the six climate zones our findings can be summarized as follows 1 the spe products exhibited a slightly better performance during the wet season compared to the dry season in terms of rainfall detection metric pod far and csi however the temporal dynamic performance cc and rb did not show any significant difference between the two seasons 2 imergf v6 exhibited the best overall performance among spe products in comparison with rain gauges and as inputs to the swat models for streamflow simulations our study is the first attempt to evaluate the performance of gpm imerg in vietnam suggesting strong capability for this product in hydrological application purposes 3 chirps achieved the smallest bias among spe products compared to rain gauge data reflecting the aim of this product as a drought warning system and for trend analysis 4 gauge corrected versions of spe products exhibited slightly better over the uncorrected versions of spe products in terms of precipitation performance metrics this suggests that the use of sub monthly and monthly rain gauges did not significantly benefit spe s improvement at the daily time step however the gauge corrected spe products performed better than their uncorrected counterparts in both daily and monthly streamflow simulation 5 spe products can serve as alternative inputs to enhance the performance of hydrological models in basins with a low rain gauge density this study determines the ability of spe products to estimate rainfall and produce input data for streamflow simulations in vietnam our findings could be used as a guide to select which spe products are suitable for hydrological applications although this study is specific for hydro climatic conditions in the river basins of vietnam the methodology can be applied to watersheds in other regions of the world credit authorship contribution statement manh hung le conceptualization methodology software validation formal analysis investigation resources data curation writing original draft writing review editing visualization venkataraman lakshmi supervision project administration funding acquisition writing review editing john bolten investigation resources project administration funding acquisition duong du bui data curation writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is funded by the national aeronautics and space administration nasa project grant number nnx16at86g and vingroup innovation foundation vinif annual research support program grant number vinif 2019 da17 we would like to express our sincere gratitude to the institutions for providing us with the required hydro meteorological measurements that enabled this study these include vietnam hydrology and meteorological administration and national central for water resources planning and investigation special acknowledgment also goes to nasa university of california santa barbara s climate hazards group and servir mekong for providing easy access to the spe products and land cover data respectively we would also like to thank dr r srinivasan and dr yihun dele texas a m univ for their kind help and fruitful discussion regarding the application of swat and dr vu manh quyet sfri for sharing soil map of vietnam we also acknowledge mr truong sinh do nawapi for sharing the ls basin kycung river dataset appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124820 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5462,turbulent burst plays a key role in momentum transfer and sediment movement in large shallow lakes this study addresses the quantitative influence of ship wave on turbulent structures momentum and sediment fluxes in lake taihu a large shallow eutrophic lake that experiences heavy shipping traffic acoustic doppler velocimeter adv and optical backscatter sensor obs were used to obtain high frequency flow velocities and suspended sediment concentration ssc data before and when a cargo ship passed by we found that ship waves mainly propagate along the horizontal direction the near bed turbulent bursting events with ship disturbance increased by 8 42 consequently the vertical momentum and sediment fluxes were increased by 3 4 times and 8 times respectively in terms of bursting processes ejection and sweep possess much stronger capacity in carrying sediment and are largely controlled by the disturbance in the vertical direction while inward and outward interactions are mainly affected by horizontal disturbance these findings represent an important step towards understanding the mechanism and effect of turbulent bursting under ship disturbance and pave the way to future research in order to manipulate turbulent dynamics keywords turbulent burst ship disturbance quadrant analysis turbulent reynolds stress sediment resuspension 1 introduction eutrophication and harmful algal blooms have become major environmental problems in aquatic ecosystems paerl and huisman 2008 much research addressing this issue has confirmed that in addition to controlling external nutrient input endogenous pollution should also be taken into account carrick et al 1993 hoeg and kohler 2000 qin 2009 by releasing internal nutrients and stimulating the growth of cyanobacteria sediment resuspension may lead to harmful algal blooms which severely smother aquatic plants suppress invertebrate and fish habitats and cause fatal human diseases paerl and huisman 2008 sediment resuspension in water column may be driven by either natural forces such as wind or high speed flow and artificial disturbances including dredging trawling and navigation these factors may be combined with each other and jointly determine the dynamic characteristics of sediment resuspension obviously sediment resuspension and its consequent impacts are more evident in shallow water such as lake taihu china qin 2009 qin et al 2006 zhu et al 2013 turbulent bursting events including ejection sweep inward interaction and outward interaction can impose rapid and significant pressure fluctuations on the bed the interaction between these events and bed surface may substantially contribute to sediment suspension and transport in water column cuthbertson and ervine 2005 numerous case studies have confirmed that turbulent bursting events determine sediment suspension and transport to a large extent based on observations in typical areas of lake taihu li et al 2018 reported that the bursting events could explain approximately 85 of sediment suspension flux although they occupied only 20 of the observation duration chen et al 2013 utilized turbulent bursting to explain the nonlocal dispersal of sediment they observed in las vegas wash and laboratories duan et al 2011 analyzed the coherent structures around a spur dike and indicated that the bursting events of ejection and sweep drove most of the particles in the scour hole ninto and garcia 1996 used high speed video to study the sediment entrainment in the near wall region and found that the vertically moving particles are responding to flow ejection events nelson et al 1995 investigated the interaction between turbulence events and bed load transport and indicated that the sweep and outward interactions contribute to sediment flux much more than other events despite the lack of sufficient evidence some laboratory e g cellino and lemmin 2004 and field e g heathershaw and thorne 1985 works revealed that the transport of the coarser bed load was primarily controlled by sweeps while the finer suspended load was mainly entrained by ejections lake taihu the third largest freshwater lake in china is well known as a large 2338 km2 shallow mean depth 1 9 m and hyper eutrophic lake over the past several decades lake taihu has been plagued by algal blooms due to excessive nutrient loadings which is exacerbated by endogenous release associated with sediment resuspension zhu et al 2013 qin 2009 qin et al 2006 taihu is also a lake with busy navigation more than 2 million ships sail in taihu basin each year fig 1 serving waterway carriage tourism and fishery functions ship induced waves may exert a dramatic effect on sediment resuspension and nutrient release hofmann et al 2011 yousef et al 1980 investigated the impacts of motorboats on the substance concentration in three lakes in florida and found that the boat disturbance remarkably increased the concentrations of sediment phosphorus and toxic chloride schoellhamer 1996 found that the mass of resuspended sediments in hillsborough bay due to ship disturbance was an order of magnitude higher than that caused by wind waves some of those anthropogenic suspension can last at least 8 h rapaglia et al 2011 reported that ship disturbance increased the concentration of suspended matter in venice lagoon in italy by about 30 times reaching 400 mg l goransson et al 2014 investigated the impacts of ship generated waves in the göta älv river sweden on bed and bank erosion and found that the drawdown and vessel sinkage are key parameters for turbidity increase vilmin et al 2015 observed pluri annual sediment budget in the seine river and indicated that ship generated waves contribute 20 of total sediment resuspension on average or even over 50 within low flow periods rapaglia et al 2015 estimated that an annual amount of 1 2 106 metric tons of sediment is remobilized in venice lagoon due to ship wakes in spite of extensive research regarding the relationship between ship disturbance and sediment movement on a broader scope few studies have been performed on a micro scale to interpret the role of turbulent bursting in the processes of momentum transfer and sediment resuspension the main objectives of the present study are 1 to compare the turbulent characteristics with and without ship disturbance 2 to illuminate the different mechanisms of turbulent bursting during the ship passages and 3 to explore the relationships between ship disturbance turbulent bursting momentum and sediment exchanges susceptible to both wind and ship generated waves lake taihu is ideally suited for this study 2 materials and methods 2 1 field experiments the field experiments were conducted on july 26 2018 at the outlet of meiliang bay 31 22 56 n 120 9 38 e fig 1 which is the most seriously polluted area in lake taihu the water depth h of the observation point is 2 85 m and remains constant during the experiment the lake bottom sediment consists of clay silt multimodal with a median grain size of d50 12 µm the three dimensional instantaneous flow velocities were measured using a sontek acoustic doppler velocimeter adv with a sampling frequency of 100 hz synchronous data of turbidity were obtained from a campbell optical backscatter sensor obs 3a with a bursting interval of 1 min both adv and obs 3a were placed 5 cm above the lakebed water samples at the same depth were collected for suspended sediment concentration ssc assay wind data were acquired with the ph ii handheld weather station the freighters are the most common ship in lake taihu according to our initial investigation a 300 ton cargo ship with a length of 32 0 m a width of 6 1 m and a height of 2 3 m was hired for the field experiment fig 1 we tested several scenarios and focused on the worst case i e the fully loaded ship with a draught of 1 8 m passed 20 m away from the monitoring point fig 2 with its maximum speed i e 5 4 knots or 10 km h the depth based froude number is frd 0 53 to minimize the wind disturbance as much as possible we chose a day with little wind vwind 1 9 m s when the cargo ship passed by high frequency flow velocity and turbidity at the monitoring point were recorded by adv and obs 3a respectively 2 2 data analysis techniques the adv data were pre processed by removing the outliers with low correlation coefficients 70 or low signal to noise ratios 40 db to fill the missing data gaps the time fraction of missing data was 1 linear interpolation was used reynolds decomposition was used to extract high frequency 100 hz velocity components in time series records fox et al 2004 the instantaneous flow velocity was assumed to consist of mean velocity and fluctuating velocity 1 u u u v v v w w w where u v w denote the instantaneous velocity components in the horizontal lateral and vertical coordinates respectively and u v w are the corresponding velocity fluctuations the mean velocity components u v w are obtained by applying a moving average as a low pass filter kassem et al 2015 turbulence intensity is an important parameter of turbulent flow the distribution of turbulence intensity has been used to investigate turbulent processes song and chiew 2001 the horizontal and vertical turbulence intensities are expressed as the root mean square of the corresponding velocity fluctuations 2 σ u u 2 σ w w 2 to further character turbulent bursting quadrant analysis has been carried out following the works by heathershaw 1974 and lu and willmarth 1973 four types of bursting events have been identified in the u w plane fig 3 i e ejection u 0 w 0 sweep u 0 w 0 inward interaction u 0 w 0 and outward interaction u 0 w 0 heathershaw and thorne 1985 schmeeckle 2015 thorne 2014 the conditional statistics exclude the event of small fluctuations which balance each other out and are less important in momentum flux processes mohajeri et al 2016 the hyperbolic threshold hole was used to distinguish the effective events from the small scale turbulence the criteria are given as follows 3 xq 1 u w h σ u σ w 0 otherwise where h is known as hole size we assume h 0 95 in present study based on previous research bogard and tiederman 1986 duan et al 2011 mohajeri et al 2016 wei et al 2019 h σ u σ w is the threshold for extracting turbulent bursting events the turbulent momentum flux turbulent reynolds stress and sediment flux were estimated near the bed as fox et al 2004 thorne 2014 4 τ r e ρ u w φ w c where c denotes the fluctuation in concentration of suspended sediment echo intensity ei recorded by adv was used as a representation of ssc according to the following equation fugate and friedrichs 2002 voulgaris and meyers 2004 5 ei a l o g 10 ssc b the collected water samples were used to convert obs turbidity ntu to ssc mg l and the ssc data then were used to calibrate ei fig 4 manifests strong relationships between turbidity ssc r 0 9375 and ei log10 ssc r 0 847 high frequency ssc data were calculated 3 results and discussion 3 1 turbulent characteristics time series records of u w c and their fluctuations u w c before and during the ship s crossing can be compared in fig 5 and fig 6 what stands out in these figures is the significant change in the value of each parameter during the ship passage as fig 5 shows the horizontal flow velocity u reached up to 15 14 cm s as the ship passed by while it only varied from 0 01 cm s to 4 42 cm s before the ship s crossing the flow velocity in wall normal direction w experienced a short term rapid change between 3 56 cm s and 2 73 cm s during the crossing whereas it changed very little 1 29 0 13 cm s over the before period in response to flow velocity ssc kept increasing and reached as high as 712 mg l after remaining at a low value about 46 mg l and barely fluctuating for a long period of time the single most striking observation emerging from the data comparison was the difference in the duration of the ship s influence on horizontal u and vertical flow velocities w the ship passage affected the horizontal flow velocity u for about 1 min while the vertical flow velocity w only fluctuated significantly for less than 10 s which indicates that ship induced waves contribute more energy in the horizontal direction than in the vertical direction the sediment was also suspended in large quantities and lasted approximately 30 s before it settled compared with previous research under natural disturbance of lake taihu li et al 2017 wang et al 2015 the ship disturbance is even greater than the disturbance caused by the wind at 12 m s in addition strong oscillations can be observed near the peak of each series which also indicate that the energy generated by ship is significant similar results can be derived from the fluctuations of velocity components and ssc fig 6 the fluctuation of the horizontal flow velocity u during the ship passage 2 97 3 02 cm s was about 3 times as strong as that before the arrival of the ship 1 16 0 93 cm s however the intensity of flow velocity fluctuation in the vertical direction w did not show much difference as the ship passed by this was probably because the response time of the vertical flow velocity w to the ship disturbance was very short fig 5 making the fluctuation of vertical velocity w less distinct furthermore before the ship passage the fluctuation of ssc c varied by 10 mg l which was an order of magnitude lower than the fluctuation during the ship passage 97 66 117 77 mg l 3 2 turbulent reynolds stress threshold and turbulence intensity the turbulent reynolds stress high frequency of 100 hz the threshold for turbulent bursts statistical analysis every 5 s and the turbulence intensity statistical analysis every 5 s in the horizontal and vertical directions are calculated based on eq 2 3 4 as can be seen from fig 7 the turbulent reynolds stress τ re fluctuates irregularly and is interrupted by salient peaks which confirms that turbulent bursts are quasi periodic motions that are characterized by intermittent and multiple orders of magnitude events occurring in random space and time duan et al 2011 godard et al 2009 it can also be found that the instantaneous reynolds stress τ re during the ship s crossing is about 3 4 times greater than without ship disturbance the threshold red solid line for identifying turbulent bursting events presents the same trend with turbulent reynolds stress it keeps a low value and is relatively stable in the first 2 min statistical value 0 015 cm2 s2 while it increases and decreases rapidly in the last 2 min with a statistical value of 0 046 cm2 s2 interestingly the ship waves show no obvious effect on the turbulence intensity in the vertical direction blue dashed line as the intensity w varies from 0 034 to 0 084 cm s fig 7 this is somewhat counterintuitive but further supports the result that the ship passage endows the horizontal flow with most of the energy combined with eq 3 the turbulence intensity in the horizontal direction yellow dashed line presents a high correlation with the threshold the intensity u fluctuates slowly with a statistical value of 0 277 cm s before the disturbance of the ship then increases continuously during the ship passage and peaks at 1 628 cm s before going down the peak of turbulence intensity u is approximately 6 times stronger than when it is undisturbed by the ship the statistical value for the last 2 min is 0 737 cm s which is about 3 times stronger 3 3 turbulent bursting and sediment exchange table 1 compares the summary statistics for the numbers of bursting events eq 3 the momentum and sediment fluxes eq 4 before and during the ship passage the fractions of these parameters are also set out in fig 8 it is seen that the occurrence probabilities of the four types of bursting events ejection sweep inward interaction and outward interaction are very low their time fractions are only 4 10 4 18 3 27 and 2 88 before ship disturbance and 2 59 2 62 8 80 and 8 84 during disturbance in a total of 12 000 flow velocity signals 2 min there are 1731 bursting events 14 43 over the before period and 2742 bursting events 22 85 in the period of during the occurrence probability of turbulent bursting increases by 8 42 this is because the external disturbance becomes more violent due to the impact from the ship which will decrease the average period of turbulent bursting in the water column near the boundary wei et al 2019 i e the ship disturbance increases the occurrence probability of bursting events in spite of an increase of more than 1000 bursting events the bursting types of ejection and sweep declined table 1 this rather surprising finding could be explained by the physical meanings of these events fig 3 as the results obtained above ship disturbance contributes almost all the energy to the horizontal rather than the vertical direction making the flow velocity in the horizontal direction extraordinary large the flow oscillates less in the vertical direction this enhances the stability of the streak structure in the turbulent boundary layer i e it reduces the breakdown of velocity streaks the bursting processes of ejection and sweep cannot be produced without this breakdown fig 3 corino and brodkey 1969 kim et al 1971 but the events of inward interaction and outward interaction keep increasing this is why the time fractions of inward and outward interactions are more than 3 times that of ejection and sweep during ship disturbance while ejection and sweep are the dominant bursting types before the ship passage fig 8 the result over the during period is contrary to previous studies which have suggested that ejection and sweep overwhelm other processes and are the main contributors to stress duan et al 2011 jain et al 2015 maity and mazumder 2012 yuan et al 2009 it is also opposite to the results obtained in the central zone but consistent with that of east taihu bay fig 1 based on our previous research conducted under natural disturbance li et al 2018 combined with the different hydrodynamic conditions between the central zone wind waves and east bay lake current it is possible to hypothesise that the bursting processes of ejection and sweep are usually dominant due to vertical disturbance while inward and outward interactions become more important when the turbulence intensity in the horizontal direction increases to a certain extent this is a rather encouraging finding as well as an important issue for future research despite the low time fractions of turbulent bursts they have made large contributions of 49 02 before and 72 04 during to the turbulent reynolds stress and 28 88 before and 61 64 during to the sediment flux respectively fig 8 this confirms the widely known theory that intermittent coherent events control the momentum and sediment fluxes to a large extent from table 1 the momentum fluxes of ejection 3 42 n m2 and sweep 3 39 n m2 during the ship passage are more than twice larger than without ship disturbance although the numbers of events have declined the fluxes of inward interaction 10 97 n m2 and outward interaction 10 94 n m2 increase about an order of magnitude and the total momentum flux 39 86 n m2 is 3 4 times greater for the sediment flux the value of each event has increased remarkably more than an order of magnitude and the total sediment flux 30086 55 mg m2s is about 8 times of before the sediment suspension 2023 93 mg m2s and settling 1835 33 mg m2s under natural disturbance do not possess a significant difference which indicates a long term balance however a suspension rate of more than 4000 mg m2s can be seen during the ship passage comparing the fractions of momentum flux and sediment flux fig 8 although the momentum flux fractions of inward 27 51 and outward interactions 27 44 are more than 3 times higher than those of ejection 8 58 and sweep 8 51 their sediment flux fractions are almost the same around 15 this suggests that the sediment carrying capacity of ejection and sweep is much stronger than that of inward and outward interactions which is also supported by the physical meanings of these events fig 3 and previous studies cao 1997 keylock 2007 yuan et al 2009 compared the three types of fractions fig 8 of turbulent bursts during ship disturbance with the results obtained in our previous observation conducted in central zone and east taihu bay under natural disturbance vwind 3 0 2 m s li et al 2018 we found that the values of their time fractions around 20 and momentum flux fractions around 70 are very close to each other however their fractions in sediment flux are significantly different and follow the order of central zone 90 0 wind waves east bay 78 6 lake current meiliang bay 61 64 ship disturbance the reasons for this are that their bursting types with stronger sediment carrying capacity ejection and sweep decrease in turn reducing the effect of turbulent bursts on sediment flux their flow velocities in horizontal direction and the stabilities of the streak structures in the turbulent boundary layer increase in turn prompting non bursting events to contribute more to sediment exchange 4 conclusions the present study set out to explore the quantitative influence of a ship s crossing on turbulent structures and sediment exchange in a eutrophic lake with heavy shipping traffic a huge impact of the ship passage on turbulent reynolds stress and sediment resuspension was found several conclusions can be drawn from this research ship disturbance contribute most of the energy to the horizontal rather than the vertical direction which has been manifested by both a longer more than 6 times duration of influence and a stronger about 3 times turbulence intensity in the horizontal direction the occurrence probability of turbulent bursting increased by 8 42 with the ship passage and the fractions of bursting events in momentum and sediment fluxes have also increased by 23 02 and 32 76 respectively four types of bursting events contributed 72 04 to momentum flux and 61 64 to sediment flux with only 22 85 to time fraction which strengthens the idea that both momentum transfer and sediment resuspension are mainly controlled by short bursts with large amplitude the total momentum and sediment fluxes under ship disturbance were about 3 4 times and 8 times greater than those under natural disturbance the rate of sediment suspension reached up to 4000 mg m2s while it is near zero suspension balances out settling under natural disturbance the bursting types of ejection and sweep own much stronger sediment carrying capacity than inward and outward interactions ejection and sweep dominate the turbulent processes under natural disturbance while inward and outward interactions become the dominant events under ship disturbance ejection and sweep are largely controlled by the disturbance in the vertical direction while inward and outward interactions are mainly determined by horizontal disturbance this research has provided a deeper insight from a micro scale into the turbulent bursting under man made disturbance although these findings are limited by the specific monitoring site and experimental regime in lake taihu the current study has raised a few generalizable points future work needs to be carried out in order to validate and systematize these principles credit authorship contribution statement jin wei conceptualization data curation formal analysis investigation methodology writing original draft yiping li conceptualization data curation formal analysis funding acquisition supervision writing review editing dong chen conceptualization data curation formal analysis investigation writing review editing amechi s nwankwegu investigation writing review editing chunyan tang investigation writing review editing minsheng bu investigation shuangshuang zhang investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the research was supported by national key research and development program of china 2017yfc0405203 the fundamental research funds for the central universities 2018b48214 2017b20514 and papd national science funds for creative research groups of china 51421006 chinese national science foundation 51809102 51779072 51579071 41323001 and 51539003 the postgraduate research practice innovation program of jiangsu province 2018b672x14 the program of dual innovative talents plan and innovative research team in jiangsu province and the priority academic program development of jiangsu higher education institutions 
5462,turbulent burst plays a key role in momentum transfer and sediment movement in large shallow lakes this study addresses the quantitative influence of ship wave on turbulent structures momentum and sediment fluxes in lake taihu a large shallow eutrophic lake that experiences heavy shipping traffic acoustic doppler velocimeter adv and optical backscatter sensor obs were used to obtain high frequency flow velocities and suspended sediment concentration ssc data before and when a cargo ship passed by we found that ship waves mainly propagate along the horizontal direction the near bed turbulent bursting events with ship disturbance increased by 8 42 consequently the vertical momentum and sediment fluxes were increased by 3 4 times and 8 times respectively in terms of bursting processes ejection and sweep possess much stronger capacity in carrying sediment and are largely controlled by the disturbance in the vertical direction while inward and outward interactions are mainly affected by horizontal disturbance these findings represent an important step towards understanding the mechanism and effect of turbulent bursting under ship disturbance and pave the way to future research in order to manipulate turbulent dynamics keywords turbulent burst ship disturbance quadrant analysis turbulent reynolds stress sediment resuspension 1 introduction eutrophication and harmful algal blooms have become major environmental problems in aquatic ecosystems paerl and huisman 2008 much research addressing this issue has confirmed that in addition to controlling external nutrient input endogenous pollution should also be taken into account carrick et al 1993 hoeg and kohler 2000 qin 2009 by releasing internal nutrients and stimulating the growth of cyanobacteria sediment resuspension may lead to harmful algal blooms which severely smother aquatic plants suppress invertebrate and fish habitats and cause fatal human diseases paerl and huisman 2008 sediment resuspension in water column may be driven by either natural forces such as wind or high speed flow and artificial disturbances including dredging trawling and navigation these factors may be combined with each other and jointly determine the dynamic characteristics of sediment resuspension obviously sediment resuspension and its consequent impacts are more evident in shallow water such as lake taihu china qin 2009 qin et al 2006 zhu et al 2013 turbulent bursting events including ejection sweep inward interaction and outward interaction can impose rapid and significant pressure fluctuations on the bed the interaction between these events and bed surface may substantially contribute to sediment suspension and transport in water column cuthbertson and ervine 2005 numerous case studies have confirmed that turbulent bursting events determine sediment suspension and transport to a large extent based on observations in typical areas of lake taihu li et al 2018 reported that the bursting events could explain approximately 85 of sediment suspension flux although they occupied only 20 of the observation duration chen et al 2013 utilized turbulent bursting to explain the nonlocal dispersal of sediment they observed in las vegas wash and laboratories duan et al 2011 analyzed the coherent structures around a spur dike and indicated that the bursting events of ejection and sweep drove most of the particles in the scour hole ninto and garcia 1996 used high speed video to study the sediment entrainment in the near wall region and found that the vertically moving particles are responding to flow ejection events nelson et al 1995 investigated the interaction between turbulence events and bed load transport and indicated that the sweep and outward interactions contribute to sediment flux much more than other events despite the lack of sufficient evidence some laboratory e g cellino and lemmin 2004 and field e g heathershaw and thorne 1985 works revealed that the transport of the coarser bed load was primarily controlled by sweeps while the finer suspended load was mainly entrained by ejections lake taihu the third largest freshwater lake in china is well known as a large 2338 km2 shallow mean depth 1 9 m and hyper eutrophic lake over the past several decades lake taihu has been plagued by algal blooms due to excessive nutrient loadings which is exacerbated by endogenous release associated with sediment resuspension zhu et al 2013 qin 2009 qin et al 2006 taihu is also a lake with busy navigation more than 2 million ships sail in taihu basin each year fig 1 serving waterway carriage tourism and fishery functions ship induced waves may exert a dramatic effect on sediment resuspension and nutrient release hofmann et al 2011 yousef et al 1980 investigated the impacts of motorboats on the substance concentration in three lakes in florida and found that the boat disturbance remarkably increased the concentrations of sediment phosphorus and toxic chloride schoellhamer 1996 found that the mass of resuspended sediments in hillsborough bay due to ship disturbance was an order of magnitude higher than that caused by wind waves some of those anthropogenic suspension can last at least 8 h rapaglia et al 2011 reported that ship disturbance increased the concentration of suspended matter in venice lagoon in italy by about 30 times reaching 400 mg l goransson et al 2014 investigated the impacts of ship generated waves in the göta älv river sweden on bed and bank erosion and found that the drawdown and vessel sinkage are key parameters for turbidity increase vilmin et al 2015 observed pluri annual sediment budget in the seine river and indicated that ship generated waves contribute 20 of total sediment resuspension on average or even over 50 within low flow periods rapaglia et al 2015 estimated that an annual amount of 1 2 106 metric tons of sediment is remobilized in venice lagoon due to ship wakes in spite of extensive research regarding the relationship between ship disturbance and sediment movement on a broader scope few studies have been performed on a micro scale to interpret the role of turbulent bursting in the processes of momentum transfer and sediment resuspension the main objectives of the present study are 1 to compare the turbulent characteristics with and without ship disturbance 2 to illuminate the different mechanisms of turbulent bursting during the ship passages and 3 to explore the relationships between ship disturbance turbulent bursting momentum and sediment exchanges susceptible to both wind and ship generated waves lake taihu is ideally suited for this study 2 materials and methods 2 1 field experiments the field experiments were conducted on july 26 2018 at the outlet of meiliang bay 31 22 56 n 120 9 38 e fig 1 which is the most seriously polluted area in lake taihu the water depth h of the observation point is 2 85 m and remains constant during the experiment the lake bottom sediment consists of clay silt multimodal with a median grain size of d50 12 µm the three dimensional instantaneous flow velocities were measured using a sontek acoustic doppler velocimeter adv with a sampling frequency of 100 hz synchronous data of turbidity were obtained from a campbell optical backscatter sensor obs 3a with a bursting interval of 1 min both adv and obs 3a were placed 5 cm above the lakebed water samples at the same depth were collected for suspended sediment concentration ssc assay wind data were acquired with the ph ii handheld weather station the freighters are the most common ship in lake taihu according to our initial investigation a 300 ton cargo ship with a length of 32 0 m a width of 6 1 m and a height of 2 3 m was hired for the field experiment fig 1 we tested several scenarios and focused on the worst case i e the fully loaded ship with a draught of 1 8 m passed 20 m away from the monitoring point fig 2 with its maximum speed i e 5 4 knots or 10 km h the depth based froude number is frd 0 53 to minimize the wind disturbance as much as possible we chose a day with little wind vwind 1 9 m s when the cargo ship passed by high frequency flow velocity and turbidity at the monitoring point were recorded by adv and obs 3a respectively 2 2 data analysis techniques the adv data were pre processed by removing the outliers with low correlation coefficients 70 or low signal to noise ratios 40 db to fill the missing data gaps the time fraction of missing data was 1 linear interpolation was used reynolds decomposition was used to extract high frequency 100 hz velocity components in time series records fox et al 2004 the instantaneous flow velocity was assumed to consist of mean velocity and fluctuating velocity 1 u u u v v v w w w where u v w denote the instantaneous velocity components in the horizontal lateral and vertical coordinates respectively and u v w are the corresponding velocity fluctuations the mean velocity components u v w are obtained by applying a moving average as a low pass filter kassem et al 2015 turbulence intensity is an important parameter of turbulent flow the distribution of turbulence intensity has been used to investigate turbulent processes song and chiew 2001 the horizontal and vertical turbulence intensities are expressed as the root mean square of the corresponding velocity fluctuations 2 σ u u 2 σ w w 2 to further character turbulent bursting quadrant analysis has been carried out following the works by heathershaw 1974 and lu and willmarth 1973 four types of bursting events have been identified in the u w plane fig 3 i e ejection u 0 w 0 sweep u 0 w 0 inward interaction u 0 w 0 and outward interaction u 0 w 0 heathershaw and thorne 1985 schmeeckle 2015 thorne 2014 the conditional statistics exclude the event of small fluctuations which balance each other out and are less important in momentum flux processes mohajeri et al 2016 the hyperbolic threshold hole was used to distinguish the effective events from the small scale turbulence the criteria are given as follows 3 xq 1 u w h σ u σ w 0 otherwise where h is known as hole size we assume h 0 95 in present study based on previous research bogard and tiederman 1986 duan et al 2011 mohajeri et al 2016 wei et al 2019 h σ u σ w is the threshold for extracting turbulent bursting events the turbulent momentum flux turbulent reynolds stress and sediment flux were estimated near the bed as fox et al 2004 thorne 2014 4 τ r e ρ u w φ w c where c denotes the fluctuation in concentration of suspended sediment echo intensity ei recorded by adv was used as a representation of ssc according to the following equation fugate and friedrichs 2002 voulgaris and meyers 2004 5 ei a l o g 10 ssc b the collected water samples were used to convert obs turbidity ntu to ssc mg l and the ssc data then were used to calibrate ei fig 4 manifests strong relationships between turbidity ssc r 0 9375 and ei log10 ssc r 0 847 high frequency ssc data were calculated 3 results and discussion 3 1 turbulent characteristics time series records of u w c and their fluctuations u w c before and during the ship s crossing can be compared in fig 5 and fig 6 what stands out in these figures is the significant change in the value of each parameter during the ship passage as fig 5 shows the horizontal flow velocity u reached up to 15 14 cm s as the ship passed by while it only varied from 0 01 cm s to 4 42 cm s before the ship s crossing the flow velocity in wall normal direction w experienced a short term rapid change between 3 56 cm s and 2 73 cm s during the crossing whereas it changed very little 1 29 0 13 cm s over the before period in response to flow velocity ssc kept increasing and reached as high as 712 mg l after remaining at a low value about 46 mg l and barely fluctuating for a long period of time the single most striking observation emerging from the data comparison was the difference in the duration of the ship s influence on horizontal u and vertical flow velocities w the ship passage affected the horizontal flow velocity u for about 1 min while the vertical flow velocity w only fluctuated significantly for less than 10 s which indicates that ship induced waves contribute more energy in the horizontal direction than in the vertical direction the sediment was also suspended in large quantities and lasted approximately 30 s before it settled compared with previous research under natural disturbance of lake taihu li et al 2017 wang et al 2015 the ship disturbance is even greater than the disturbance caused by the wind at 12 m s in addition strong oscillations can be observed near the peak of each series which also indicate that the energy generated by ship is significant similar results can be derived from the fluctuations of velocity components and ssc fig 6 the fluctuation of the horizontal flow velocity u during the ship passage 2 97 3 02 cm s was about 3 times as strong as that before the arrival of the ship 1 16 0 93 cm s however the intensity of flow velocity fluctuation in the vertical direction w did not show much difference as the ship passed by this was probably because the response time of the vertical flow velocity w to the ship disturbance was very short fig 5 making the fluctuation of vertical velocity w less distinct furthermore before the ship passage the fluctuation of ssc c varied by 10 mg l which was an order of magnitude lower than the fluctuation during the ship passage 97 66 117 77 mg l 3 2 turbulent reynolds stress threshold and turbulence intensity the turbulent reynolds stress high frequency of 100 hz the threshold for turbulent bursts statistical analysis every 5 s and the turbulence intensity statistical analysis every 5 s in the horizontal and vertical directions are calculated based on eq 2 3 4 as can be seen from fig 7 the turbulent reynolds stress τ re fluctuates irregularly and is interrupted by salient peaks which confirms that turbulent bursts are quasi periodic motions that are characterized by intermittent and multiple orders of magnitude events occurring in random space and time duan et al 2011 godard et al 2009 it can also be found that the instantaneous reynolds stress τ re during the ship s crossing is about 3 4 times greater than without ship disturbance the threshold red solid line for identifying turbulent bursting events presents the same trend with turbulent reynolds stress it keeps a low value and is relatively stable in the first 2 min statistical value 0 015 cm2 s2 while it increases and decreases rapidly in the last 2 min with a statistical value of 0 046 cm2 s2 interestingly the ship waves show no obvious effect on the turbulence intensity in the vertical direction blue dashed line as the intensity w varies from 0 034 to 0 084 cm s fig 7 this is somewhat counterintuitive but further supports the result that the ship passage endows the horizontal flow with most of the energy combined with eq 3 the turbulence intensity in the horizontal direction yellow dashed line presents a high correlation with the threshold the intensity u fluctuates slowly with a statistical value of 0 277 cm s before the disturbance of the ship then increases continuously during the ship passage and peaks at 1 628 cm s before going down the peak of turbulence intensity u is approximately 6 times stronger than when it is undisturbed by the ship the statistical value for the last 2 min is 0 737 cm s which is about 3 times stronger 3 3 turbulent bursting and sediment exchange table 1 compares the summary statistics for the numbers of bursting events eq 3 the momentum and sediment fluxes eq 4 before and during the ship passage the fractions of these parameters are also set out in fig 8 it is seen that the occurrence probabilities of the four types of bursting events ejection sweep inward interaction and outward interaction are very low their time fractions are only 4 10 4 18 3 27 and 2 88 before ship disturbance and 2 59 2 62 8 80 and 8 84 during disturbance in a total of 12 000 flow velocity signals 2 min there are 1731 bursting events 14 43 over the before period and 2742 bursting events 22 85 in the period of during the occurrence probability of turbulent bursting increases by 8 42 this is because the external disturbance becomes more violent due to the impact from the ship which will decrease the average period of turbulent bursting in the water column near the boundary wei et al 2019 i e the ship disturbance increases the occurrence probability of bursting events in spite of an increase of more than 1000 bursting events the bursting types of ejection and sweep declined table 1 this rather surprising finding could be explained by the physical meanings of these events fig 3 as the results obtained above ship disturbance contributes almost all the energy to the horizontal rather than the vertical direction making the flow velocity in the horizontal direction extraordinary large the flow oscillates less in the vertical direction this enhances the stability of the streak structure in the turbulent boundary layer i e it reduces the breakdown of velocity streaks the bursting processes of ejection and sweep cannot be produced without this breakdown fig 3 corino and brodkey 1969 kim et al 1971 but the events of inward interaction and outward interaction keep increasing this is why the time fractions of inward and outward interactions are more than 3 times that of ejection and sweep during ship disturbance while ejection and sweep are the dominant bursting types before the ship passage fig 8 the result over the during period is contrary to previous studies which have suggested that ejection and sweep overwhelm other processes and are the main contributors to stress duan et al 2011 jain et al 2015 maity and mazumder 2012 yuan et al 2009 it is also opposite to the results obtained in the central zone but consistent with that of east taihu bay fig 1 based on our previous research conducted under natural disturbance li et al 2018 combined with the different hydrodynamic conditions between the central zone wind waves and east bay lake current it is possible to hypothesise that the bursting processes of ejection and sweep are usually dominant due to vertical disturbance while inward and outward interactions become more important when the turbulence intensity in the horizontal direction increases to a certain extent this is a rather encouraging finding as well as an important issue for future research despite the low time fractions of turbulent bursts they have made large contributions of 49 02 before and 72 04 during to the turbulent reynolds stress and 28 88 before and 61 64 during to the sediment flux respectively fig 8 this confirms the widely known theory that intermittent coherent events control the momentum and sediment fluxes to a large extent from table 1 the momentum fluxes of ejection 3 42 n m2 and sweep 3 39 n m2 during the ship passage are more than twice larger than without ship disturbance although the numbers of events have declined the fluxes of inward interaction 10 97 n m2 and outward interaction 10 94 n m2 increase about an order of magnitude and the total momentum flux 39 86 n m2 is 3 4 times greater for the sediment flux the value of each event has increased remarkably more than an order of magnitude and the total sediment flux 30086 55 mg m2s is about 8 times of before the sediment suspension 2023 93 mg m2s and settling 1835 33 mg m2s under natural disturbance do not possess a significant difference which indicates a long term balance however a suspension rate of more than 4000 mg m2s can be seen during the ship passage comparing the fractions of momentum flux and sediment flux fig 8 although the momentum flux fractions of inward 27 51 and outward interactions 27 44 are more than 3 times higher than those of ejection 8 58 and sweep 8 51 their sediment flux fractions are almost the same around 15 this suggests that the sediment carrying capacity of ejection and sweep is much stronger than that of inward and outward interactions which is also supported by the physical meanings of these events fig 3 and previous studies cao 1997 keylock 2007 yuan et al 2009 compared the three types of fractions fig 8 of turbulent bursts during ship disturbance with the results obtained in our previous observation conducted in central zone and east taihu bay under natural disturbance vwind 3 0 2 m s li et al 2018 we found that the values of their time fractions around 20 and momentum flux fractions around 70 are very close to each other however their fractions in sediment flux are significantly different and follow the order of central zone 90 0 wind waves east bay 78 6 lake current meiliang bay 61 64 ship disturbance the reasons for this are that their bursting types with stronger sediment carrying capacity ejection and sweep decrease in turn reducing the effect of turbulent bursts on sediment flux their flow velocities in horizontal direction and the stabilities of the streak structures in the turbulent boundary layer increase in turn prompting non bursting events to contribute more to sediment exchange 4 conclusions the present study set out to explore the quantitative influence of a ship s crossing on turbulent structures and sediment exchange in a eutrophic lake with heavy shipping traffic a huge impact of the ship passage on turbulent reynolds stress and sediment resuspension was found several conclusions can be drawn from this research ship disturbance contribute most of the energy to the horizontal rather than the vertical direction which has been manifested by both a longer more than 6 times duration of influence and a stronger about 3 times turbulence intensity in the horizontal direction the occurrence probability of turbulent bursting increased by 8 42 with the ship passage and the fractions of bursting events in momentum and sediment fluxes have also increased by 23 02 and 32 76 respectively four types of bursting events contributed 72 04 to momentum flux and 61 64 to sediment flux with only 22 85 to time fraction which strengthens the idea that both momentum transfer and sediment resuspension are mainly controlled by short bursts with large amplitude the total momentum and sediment fluxes under ship disturbance were about 3 4 times and 8 times greater than those under natural disturbance the rate of sediment suspension reached up to 4000 mg m2s while it is near zero suspension balances out settling under natural disturbance the bursting types of ejection and sweep own much stronger sediment carrying capacity than inward and outward interactions ejection and sweep dominate the turbulent processes under natural disturbance while inward and outward interactions become the dominant events under ship disturbance ejection and sweep are largely controlled by the disturbance in the vertical direction while inward and outward interactions are mainly determined by horizontal disturbance this research has provided a deeper insight from a micro scale into the turbulent bursting under man made disturbance although these findings are limited by the specific monitoring site and experimental regime in lake taihu the current study has raised a few generalizable points future work needs to be carried out in order to validate and systematize these principles credit authorship contribution statement jin wei conceptualization data curation formal analysis investigation methodology writing original draft yiping li conceptualization data curation formal analysis funding acquisition supervision writing review editing dong chen conceptualization data curation formal analysis investigation writing review editing amechi s nwankwegu investigation writing review editing chunyan tang investigation writing review editing minsheng bu investigation shuangshuang zhang investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the research was supported by national key research and development program of china 2017yfc0405203 the fundamental research funds for the central universities 2018b48214 2017b20514 and papd national science funds for creative research groups of china 51421006 chinese national science foundation 51809102 51779072 51579071 41323001 and 51539003 the postgraduate research practice innovation program of jiangsu province 2018b672x14 the program of dual innovative talents plan and innovative research team in jiangsu province and the priority academic program development of jiangsu higher education institutions 
5463,in the design of hydraulic structures cutoff walls are needed to reduce uplift force u and the exit hydraulic gradient gr usually two cutoff walls are required an upstream cutoff wall is used to reduce the resultant of uplift force and a downstream cutoff wall is used to reduce the exit hydraulic gradient this study numerically investigates double cutoff walls beneath hydraulic structures with variations in their location and depth governing equations with specified boundary conditions are solved using the finite element method fem results show that if the downstream cutoff wall is deeper than the upstream cutoff wall the resultant of uplift force will increase compared to the no cutoff wall case with a constant hydraulic structure width b decreasing the distance between the two cutoffs l results in a reduction of uplift force for l b 0 7 the change in the slope of the uplift force is large increases in the permeable depth d and reductions of b will lower the uplift forces increases in the downstream cutoff depth d2 and l result in a reduction in the exit hydraulic gradient gr when the two cutoffs are located at the end of the hydraulic structure gr is lower than when the downstream cutoff wall is located at a more downstream location comparisons between the available analytical solutions and computational results for two equal cutoffs show that the fem can predict u and gr with a maximum of 5 error keywords cutoff wall uplift force exit hydraulic gradient hydraulic structures nomenclature b hydraulic structure apron width m d permeable layer depth m gr exit hydraulic gradient or hydraulic gradient at key point r with cutoff walls m m gro exit hydraulic gradient or hydraulic gradient at key point r without cutoff walls m m d 1 upstream cutoff depth m d 2 downstream cutoff depth m h upstream pressure head of hydraulic structure m l distance between two cutoffs walls m n number of elements a area of the solution domain m2 b distance between the two end boundaries of the domain from the hydraulic structure m q discharge seepage beneath the hydraulic structure with cutoff walls m3 s m q0 discharge seepage beneath the hydraulic structure without cutoff walls m3 s m h total head m t time s u o resultant uplift force under the apron without cutoff wall kn m u resultant uplift force under the apron with cutoff wall kn m ρ water density kg m3 g acceleration due to gravity m2 s k soil hydraulic conductivity m s g d1 e c d2 and r key points under the hydraulic structure rmse root mean square errors r2 determination coefficient re percent of relative error o i value obtained from the numerical solution p i predicted value from the regression models o average of calculated values p average of predicted values n number of data x y and z cartesian coordinates 1 introduction a hydraulic structure such as a gravity dam a diversion dam or a stilling basin should be resistant to uplift force and exit hydraulic gradient uplift force occurs under the hydraulic structures due to water infiltration at the foundation and this force can break aprons or overturn a hydraulic structure on the other hand high exit hydraulic gradients cause movement of foundation soil and with progression can undermine a foundation thus designers try to minimize both the uplift force and the exit hydraulic gradients the two earliest methods to control uplift force and exit hydraulic gradient are related to bligh s 1910 creep theory and lane s 1935 weighted creep theory these methods are empirical procedures khosla et al 1936 presented a theoretical method based on complex number analysis to determine uplift force and exit hydraulic gradient for an apron of a hydraulic structure due to complexity of the equations and their solutions they presented some charts to facilitate the design process malhotra 1936 provided a method to analyze an apron with two equal depth upstream and downstream cutoff walls malhotra 1936 assumed that the apron foundation has infinite depth this is not generally found in practice because most permeable foundations have a finite depth also many aprons may consist of unequal cutoff depths chawla and kumar 1983 presented an analytical solution for flat aprons including two cutoff walls with a finite permeable foundation goel and pillai 2010 developed a method for controlling the exit hydraulic gradient with stone protection rip rap in aprons comprising an infinite permeable depth of foundation they assumed an end cutoff wall in their study najjar and naouss 1999 studied seepage rates and hydraulic gradients under a single cutoff in non homogeneous soil they used the finite element method fem in their numerical simulation jain and reddi 2011 provided a closed form solution to estimate uplift force and hydraulic gradient at key points under an apron the limitation in their study was the assumption of equal depth of sheet piles at the ends of the apron salmasi et al 2015 used relief wells downstream of embankment dams to reduce uplift force these wells collect the seeped water below the dam foundation and thus prevent the formation of excess pore water pressure this helps to stop the piping phenomenon at the toe of a dam some researchers have used upstream semi impervious blankets to reduce uplift force and seepage discharge salmasi and nouri 2017 this blanket is usually made from compacted clay and increases creep length seepage path this results in greater energy loss compared to the case without blankets at the upstream of the hydraulic structure nourani et al 2017 investigated the optimum location for vertical drains in gravity dams they used the finite element method fem to predict uplift force u with and without vertical drains in the foundation of gravity dams in the dam design process it is necessary to obtain a minimum total value for uplift force lowered uplift forces enable a dam layout with greater stability against loads and also makes an economical design installation of vertical drains can collect most of the infiltrated waters in dam foundation design of irrigation canals can be considered from two viewpoints i seepage amount in unlined earthen canals and ii uplift force in lined canals hosseinzadeh asl et al 2020 salmasi et al 2017 reduced uplift by employing longitudinal drains with underlined canals these longitudinal drains reduce the phreatic line in the ground water and prevent the formation of cracks in the lining the depth and diameter of these drains are important parameters to consider in design the researchers presented charts along with regression equations to help in the design of canals with high ground water levels jafari et al 2019 applied a filter envelope around drain pipes under concrete lined canal bottoms this reduces the uplift force under the canal and increases the canal lining lifetime the present study investigates the effect of double cutoff walls on uplift force exit hydraulic gradient and seepage rate the depth of the two cutoffs may not be equal and they can be moved to different locations under the apron different configurations of double cutoff walls are considered with variable depths and positions solutions of the governing equations are found using fem validation of the results was performed by comparison with the closed form solution presented by jain and reddi 2011 2 material and methods 2 1 governing equations flow through a porous medium can be represented by eq 1 that is a combination of continuity and darcy s law geo studio 2012 1 t ρ θ x ρ k x h x y ρ k y h y z ρ k z h z where h is the total head m kx is the hydraulic conductivity in the x direction m s ky is the hydraulic conductivity in the y direction m s kz is the hydraulic conductivity in the z direction m s ρ is water density kg m3 θ is the volumetric water content m3 m3 and t is time s this equation states that the difference between the flow entering and leaving an elemental volume is equal to the change in storage of the soil systems eq 1 is a combination of the continuity equation and darcy s law or richards equation in a homogenous anisotropic unsaturated and incompressible porous medium this equation is written as follows 2 x k x h x y k y h y z k z h z θ t for a homogenous isotropic kx ky kz k saturated θ t 0 porous medium richards equation is written as follows also known as the laplace equation 3 2 h x 2 2 h y 2 2 h z 2 0 a graphical solution to this equation is known as a flow net a flow net in essence is map of contours of equal potential crossed with flow lines for the flow net to represent a correct solution to the laplace equation the equipotential lines and flow lines must follow certain rules the flow lines must for example cross the equipotential lines at right angles also the area between two adjacent flow lines is called a flow channel and the flow through any flow channel is equal to the flow through any other flow channel in the present study the foundation of the structure was considered homogeneous and isotropic and the medium was considered saturated the foundation was considered to be a single porous medium with a saturated hydraulic conductivity of 0 00001 m s k 10 5 m s as the foundation of hydraulic structure is saturated only the specified saturated conductivity is used in the numerical solution the current study is carried out using geo studio software pack the seep w software solves the governing equations in porous media richards or laplace equations with boundary conditions using the finite element method fem 2 2 numerical simulation using finite element method fem fig 1 provides different arrangements of double cutoff walls under the hydraulic structure where d1 is the upstream cutoff depth d2 is the downstream cutoff depth l is the distance between the two cutoffs d is the depth of permeable foundation b is the width of the apron and h is upstream water head in fig 1 upper left two key points c and e are important for calculation of the resultant uplift pressure location c is behind left of the downstream cutoff wall and key point e is just to the right of the upstream cutoff wall in fact the two key points c and e comprise the hydraulic structure bottom apron based on the parameters listed in table 1 a total of 330 numerical models are included in the analysis from these models 324 simulated models are comprised for aprons with two cutoff walls and 6 simulated models are included for aprons without cutoff walls fig 2 represents the specification of boundary conditions bcs for the numerical simulation at the upstream end the bc is defined as the pressure head and is designated by h the head at the downstream apron is specified as zero h 0 cutoff walls the apron bottom and the impermeable foundation of depth d are defined with impermeable bcs q 0 where the symbol q denotes the seepage discharge the numerical simulation is carried out in a two dimensional 2d cross section the porous medium is assumed to be saturated θ t 0 and isotropic kx ky mesh generation was accomplished with quadrilateral and triangular shapes and were deployed to result in high accuracy a mesh independence test was performed to determine the number of elements required for accurate fem calculations for this purpose the percent of relative error re was obtained for simulations using different numbers of elements the results show fig 2 that by increasing number of elements up to 15000 the percent of relative error re becomes 5 it can be noted that the calculation of re are based on pressure head at key point c that is the difference between the pressure head at location c from the numerical simulation compared to the analytical solutions of jain and reddi 2011 is defined as an error and this error is computed for different meshes it is seen that the re was almost constant when the number of elements was 15 000 and above therefore this number of elements is selected for further numerical simulations in the following analysis fig 3 illustrates the boundary conditions for the numerical simulation with l b 1 b d 2 4 and d2 d1 1 the close up view of the mesh around the upstream cutoff is provided for ease of viewing it can be noted that in this circumstance the dimensions of the quadrilateral and triangular elements are 0 3 m and the total number of elements and nodes are 15 038 and 15348 respectively two vertical cutoffs can be seen in fig 3 upstream at 30 m and the other downstream of the apron in fig 4 the simulation steps required for the finite element method fem are shown this process comprises the following steps geometric model building mesh generation definition of material properties designation of boundary conditions solution of the governing equations along with boundary conditions and visualization and interpretation of the results if there is a suitable agreement between numerical simulation results with the observed data or analytical solution for a simple case then the process of numerical simulation is accepted during the simulation process a modeler can refine the numerical simulation outputs by performing the following steps fig 4 i using a finer mesh ii changing material properties in this study the k values iii changing boundary conditions 2 3 determination of the minimum distance between the two end boundaries for independent solutions checking the total horizontal length of the computational domain b 2b in this study is 90 m with a height of 15 m d 15 m also the minimum distance between the two end boundaries of the domain from the structure was investigated before completing the simulations that is by increasing the distance of the upstream and downstream boundaries b it was found that the position of these boundaries did not influence the results in all numerical simulation the number of elements per unit area of the solution domain n a was fixed and is equal to 11 n a 11 in this case all simulations were performed with the same mesh density the minimum distance required for the two ends of the computational domain are shown in figs 5 and 6 2 4 criteria performance assessment regression equations are developed to provide a means for engineers to make sound design decisions in order to measure the accuracy of the regression equations three statistical metrics namely the determination coefficient r 2 the root mean square errors rmse and the percent of relative error re were used these metrics are defined in eqs 4 6 4 r 2 i 1 n o i o p i p 2 i 1 n o i o 2 i 1 n p i p 2 5 rmse i 1 n p i o i 2 n 6 re i n p i o i i n p i 100 where o i is the value obtained from the numerical solution p i is the predicted value from the regression models o is the average of calculated values p is the average of predicted values and n is the number of data 3 results and discussion fig 7 provides the flow net under the apron with and without cutoff walls beneath the hydraulic structure these flow nets include flow lines and equipotential lines derived from numerical simulations in fig 7a flow paths are ellipsoid shaped while equipotential curves are hyperbola shaped equipotential curves show energy drop between each curve fig 7b shows the flow net under the apron with two cutoff walls for d2 d1 0 66 flow lines are encountered further upstream and downstream of the apron compared to the no cutoff wall case fig 7a and this causes greater energy loss the concentration of equipotential curves near the cutoff walls is greater than for the no cutoff wall case this finding is also valid for the two other cases i e fig 7c and d the values of the seepage flow rate under the 22 5 m or b d 1 5 concrete apron is shown just below the apron for all cases for example in fig 7a this value is equal to 0 00012637 m3 s per unit width of the hydraulic structure fig 8 provides flow lines and velocity vectors under the apron with two cutoff walls having equal depth d 2 d 1 1 curved velocity vectors upstream and downstream of the cutoff walls result in a greater flow distance creep length in fig 8 the seepage discharge is 8 683 10 5 m3 s m the end of each cutoff experiences greater water velocity due to the contraction in the cross sectional area fig 9 shows the uplift pressure distribution beneath the apron with and without cutoff walls these cutoffs are located at the end points of the apron and with different depths d 2 d 1 0 66 1 and 2 use of cutoff walls under the apron changes the uplift force distribution with respect to an apron without a cutoff it can be seen that the uplift force with a cutoff is less than the uplift force without cutoffs at some apron bottom locations however this condition is reversed at other locations the uplift force distribution shows lower values for the case of d 2 d 1 0 66 compared to the apron with cutoffs for cases of d 2 d 1 1 and 2 the area under the uplift force distribution curves provides the resultant of the uplift force the resultant uplift force is 337 5 kn m for an apron without a cutoff wall uo 337 5 kn m 366 9 kn m for two aprons at the heel and toe with a relative depth of d 2 d 1 2 326 57 kn m for two aprons with a relative depth of d 2 d 1 1 and 285 5 kn m for two aprons with a relative depth of d 2 d 1 0 66 this shows the relative resultant uplift force u uo 1 087 0 967 and 0 846 for d 2 d 1 0 66 1 and 2 respectively the symbol u is the resultant uplift force for the case with a cutoff wall and uo is the resultant uplift force for the no cutoff wall situation thus to decrease the uplift force the designer should select the deeper cutoff wall at the upstream end to verify the calculations a comparison of the numerical simulation with the analytical solutions of jain and reddi 2011 was carried out fig 10 the comparison shows that a satisfactory agreement exists between the current numerical results and the analytical solution the differences between the two methods being 5 in fig 10 a pc is the percent relative pressure head defined as pc p h 100 p is pressure head at location c and h is upstream pressure head or the water depth at the upstream of dam in fig 10 b gc is the hydraulic gradient at key point c in fig 10 c k is the hydraulic conductivity of soil under the dam foundation m s and q is the seepage flow rate per unit width of the hydraulic structure m2 s in fig 11 a b and c the variation of the relative uplift force u uo is presented in fig 11 l b 1 0 66 and 0 33 for the case with two equal depth walls d 2 d 1 as mentioned earlier u o is resultant of the uplift force without a cutoff wall and u is the resultant uplift force with two cutoff walls fig 11 a shows that for l b 1 with increasing cutoff wall depth upstream and downstream of the hydraulic structure the uplift force is relatively constant and there is very little variation in u uo in addition with increase of the permeable layer depth d the relative uplift force decreases fig 11 b and c show the variation of the uplift force with cutoff wall depths and hydraulic structure width b for the two cases of l b 0 66 and 0 3 respectively with increasing cutoff wall depth the relative uplift force decreases for a specified b and this reduction in u uo will be greater when the two cutoff walls are positioned more closely together comparison of fig 11 b with c fig 12 provides the variation of the relative uplift force u uo with the hydraulic structure width over the cutoff wall depth b d 2 for b d 2 it is clear that with equal cutoff wall depths at the upstream and downstream ends of the hydraulic structure increasing or decreasing the depth of cutoffs has no significant effect on the uplift force but when the downstream cutoff moves nearer to the upstream cutoff the uplift force is reduced in addition when d 1 d 2 increasing the cutoff wall depths reduces the uplift force however for d 1 d 2 increasing the cutoff wall depths increases the uplift force fig 13 a and b provides the variation of the relative uplift force u uo with the distance between the two cutoff walls l over the hydraulic structure width b the figure shows that for constant b decreasing l results in a reduction of the relative uplift force for l b 0 7 the slope of the relative uplift force shows a rapid change in other words l b 0 7 is not suitable condition for hydraulic structures due to high u uo values fig 14 a b presents the variation of the relative uplift force u uo versus the variation of the relative cutoff depths for the condition of l b 1 cutoffs are located at the ends of the hydraulic structure fig 14 shows that with increasing downstream cutoff wall depth the relative uplift force increases in order to reduce u uo it is necessary to have d 1 d 2 in addition for b d 0 7 the relative uplift force is much less than for the case of b d 1 75 and for the smaller width of the hydraulic structure or deeper permeable foundation the value of u uo is reduced in fig 15 the changes of the exit hydraulic gradient gr with the hydraulic structure width b over the downstream cutoff depth d2 are provided fig 15 shows that with decreasing cutoff wall distance l or decreasing in downstream cutoff wall depth d2 the value of gr increases in addition for the case of l b 1 the value of gr is lower than that for the case where the downstream cutoff located one third or two thirds downstream from the upstream cutoff therefore it can be concluded that the existence of a cutoff wall in the downstream portion of the hydraulic structure allows control of gr in fig 16 the changes of the relative discharge seepage beneath the hydraulic structure q qo are presented the figure shows that with the increasing downstream cutoff depth d2 the value of q qo decreases for d 2 d 1 1 the reduction of q qo increases fig 17a shows contour lines of u uo vs the d2 d1 and b d the contour associated with u uo 1 is a boundary that can be used to distinguish between economic and non economic designs of hydraulic structures in other words the contours for u uo 1 would be a viable design fig 17b presents contours for gr gro against d2 d1 and b d the isoline gr gro 1 is another boundary used to separate economically viable and non economically viable designs in fig 18 the four separated regions of economic and non economic designs in the hydraulic structures considering both uplift force and exit hydraulic gradient criteria are shown another representation of u uo is provided in fig 19 this figure shows contours of u uo as a function of d2 d1 and l b the region for the satisfactory values for the u uo is denoted in the figure fig 20 shows gr gro as a function of d2 d1 and l b the area for acceptable values for gr gro is indicated in fig 20 fig 21 shows the intersection of the relative uplift forces and the relative exit hydraulic gradient the variations of u uo and gr gro are in inverse directions i e when b d increases u uo decreases while gr gro increases fig 21 shows that if b d 1 35 for b d 2 20 and b d 1 38 for b d 2 4 both u u0 and gr gro are less than unity and this represents an optimal location for design of hydraulic structures with respect to uplift force and exit hydraulic gradient fig 22 provides another representation for variations of u uo and gr gro with d 2 d 1 based on fig 22 it is seen that for d 2 d 1 1 a minimum value of u uo occurs this figure is valid for the range 0 33 l b 1 and for b d 2 6 b d 0 7 for d 2 d 1 1 the value of gr gro takes on its highest value but the relative exit hydraulic gradient gr gro is less than unity 3 1 regression equation for predicting uplift force start here based on the data obtained from the numerical simulations an attempt was carried out to find regression equations for predicting the uplift force exerted under a hydraulic structure two cutoff walls are incorporated under these hydraulic structures the location l and the depths d1 d2 of the two cutoff walls as well as the hydraulic structure width b and the permeable layer depth under the hydraulic structure d are variables the metrics used to quantify the accuracy of the regressions are root mean squared error rmse determination coefficient r 2 and the relative error percent re table 2 provides the results for the non linear equation coefficients see eq 7 nine separate equations were derived to estimate u uo as a dependent variable where d2 d1 b d b d2 and l b are independent variables 7 u u o a b b d c b d 2 1 e b d f b d 2 fig 23 shows a scatter plot of u uo using the regression equation and the numerical simulation in fig 23 the two ellipsoid shapes refer to economic and non economic designs i e u uo 1 would be economically viable and u uo 1 would not be economically viable 4 regression equation for predicting exit hydraulic gradient like uplift force attempts were made to derive a regression equation for predicting exit hydraulic gradient in its dimensionless form gr gro a regression formula similar to eq 7 was used to estimate gr gro as a dependent variable with d2 d1 b d b d2 and l b as independent variables see eq 8 the accuracy metrics rmse r2 and re were computed and their values are provided in table 3 8 g r g ro a b b d c b d 2 1 e b d f b d 2 fig 24 shows the scatter plot of gr gro using the regression equation and the numerical simulation in fig 24 the two ellipsoid shapes refer to economic and non economic designs i e gr gro 1 would be economically viable and gr gro 1 would not be economically viable 5 conclusions to the best knowledge of the authors the effect of the combination of two cutoff walls under a hydraulic structure has not been fully studied until now most prior research comprises a single cutoff wall some existing studies have considered the two cutoff walls with equal depth and with fixed locations one in the upstream portion and the other in the downstream region of a hydraulic structure the present study has investigated the simultaneous effects of two cutoff walls under a hydraulic structure and their combined influence on uplift force u and exit hydraulic gradient gr cutoff depths d1 and d2 as well as their location were variable parameters in addition a hydraulic structure width b and permeable layer depth d were also varied governing equations with specified boundary conditions were solved using the finite element method fem the results were compared with existing analytical solutions that considered only two cutoff walls with equal depth located at the two ends of a hydraulic structure the simulation results were compared with existing analytical solutions the maximum error between the computational and analytical solution was 5 several numerical models were simulated to investigate the effects of d1 d2 l b and d on u and gr these effects were presented to help the designers make reasonable design choices the main outcomes of the present study are summarized below a deeper upstream cutoff wall has a positive effect on uplift force reduces u meanwhile the deeper downstream cutoff has a negative effect on uplift force increases u on the other hand deeper downstream cutoff walls have a positive effect on exit hydraulic gradient decreases gr and vice versa economic designs are provided based on the values of on u and gr in terms of l b d2 d2 b d and b d2 with b d 1 35 for b d 2 20 and b d 1 38 for b d 2 4 both u u0 and gr gro are less than unity and this represents an optimal location for design of hydraulic structures with respect to both uplift force and exit hydraulic gradient relative uplift force u uo is a function of b d2 b d l b and d2 d2 and presentation of this function with a single regression equation was not available perhaps more sophisticated methods like artificial intelligence ai models may handle this difficulties credit authorship contribution statement farzin salmasi conceptualization writing original draft investigation methodology administration bahram nourani investigation methodology software validation visualization john abraham conceptualization writing review editing writing original draft declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this paper is the outcome of a research project supported by the university of tabriz research affairs office 
5463,in the design of hydraulic structures cutoff walls are needed to reduce uplift force u and the exit hydraulic gradient gr usually two cutoff walls are required an upstream cutoff wall is used to reduce the resultant of uplift force and a downstream cutoff wall is used to reduce the exit hydraulic gradient this study numerically investigates double cutoff walls beneath hydraulic structures with variations in their location and depth governing equations with specified boundary conditions are solved using the finite element method fem results show that if the downstream cutoff wall is deeper than the upstream cutoff wall the resultant of uplift force will increase compared to the no cutoff wall case with a constant hydraulic structure width b decreasing the distance between the two cutoffs l results in a reduction of uplift force for l b 0 7 the change in the slope of the uplift force is large increases in the permeable depth d and reductions of b will lower the uplift forces increases in the downstream cutoff depth d2 and l result in a reduction in the exit hydraulic gradient gr when the two cutoffs are located at the end of the hydraulic structure gr is lower than when the downstream cutoff wall is located at a more downstream location comparisons between the available analytical solutions and computational results for two equal cutoffs show that the fem can predict u and gr with a maximum of 5 error keywords cutoff wall uplift force exit hydraulic gradient hydraulic structures nomenclature b hydraulic structure apron width m d permeable layer depth m gr exit hydraulic gradient or hydraulic gradient at key point r with cutoff walls m m gro exit hydraulic gradient or hydraulic gradient at key point r without cutoff walls m m d 1 upstream cutoff depth m d 2 downstream cutoff depth m h upstream pressure head of hydraulic structure m l distance between two cutoffs walls m n number of elements a area of the solution domain m2 b distance between the two end boundaries of the domain from the hydraulic structure m q discharge seepage beneath the hydraulic structure with cutoff walls m3 s m q0 discharge seepage beneath the hydraulic structure without cutoff walls m3 s m h total head m t time s u o resultant uplift force under the apron without cutoff wall kn m u resultant uplift force under the apron with cutoff wall kn m ρ water density kg m3 g acceleration due to gravity m2 s k soil hydraulic conductivity m s g d1 e c d2 and r key points under the hydraulic structure rmse root mean square errors r2 determination coefficient re percent of relative error o i value obtained from the numerical solution p i predicted value from the regression models o average of calculated values p average of predicted values n number of data x y and z cartesian coordinates 1 introduction a hydraulic structure such as a gravity dam a diversion dam or a stilling basin should be resistant to uplift force and exit hydraulic gradient uplift force occurs under the hydraulic structures due to water infiltration at the foundation and this force can break aprons or overturn a hydraulic structure on the other hand high exit hydraulic gradients cause movement of foundation soil and with progression can undermine a foundation thus designers try to minimize both the uplift force and the exit hydraulic gradients the two earliest methods to control uplift force and exit hydraulic gradient are related to bligh s 1910 creep theory and lane s 1935 weighted creep theory these methods are empirical procedures khosla et al 1936 presented a theoretical method based on complex number analysis to determine uplift force and exit hydraulic gradient for an apron of a hydraulic structure due to complexity of the equations and their solutions they presented some charts to facilitate the design process malhotra 1936 provided a method to analyze an apron with two equal depth upstream and downstream cutoff walls malhotra 1936 assumed that the apron foundation has infinite depth this is not generally found in practice because most permeable foundations have a finite depth also many aprons may consist of unequal cutoff depths chawla and kumar 1983 presented an analytical solution for flat aprons including two cutoff walls with a finite permeable foundation goel and pillai 2010 developed a method for controlling the exit hydraulic gradient with stone protection rip rap in aprons comprising an infinite permeable depth of foundation they assumed an end cutoff wall in their study najjar and naouss 1999 studied seepage rates and hydraulic gradients under a single cutoff in non homogeneous soil they used the finite element method fem in their numerical simulation jain and reddi 2011 provided a closed form solution to estimate uplift force and hydraulic gradient at key points under an apron the limitation in their study was the assumption of equal depth of sheet piles at the ends of the apron salmasi et al 2015 used relief wells downstream of embankment dams to reduce uplift force these wells collect the seeped water below the dam foundation and thus prevent the formation of excess pore water pressure this helps to stop the piping phenomenon at the toe of a dam some researchers have used upstream semi impervious blankets to reduce uplift force and seepage discharge salmasi and nouri 2017 this blanket is usually made from compacted clay and increases creep length seepage path this results in greater energy loss compared to the case without blankets at the upstream of the hydraulic structure nourani et al 2017 investigated the optimum location for vertical drains in gravity dams they used the finite element method fem to predict uplift force u with and without vertical drains in the foundation of gravity dams in the dam design process it is necessary to obtain a minimum total value for uplift force lowered uplift forces enable a dam layout with greater stability against loads and also makes an economical design installation of vertical drains can collect most of the infiltrated waters in dam foundation design of irrigation canals can be considered from two viewpoints i seepage amount in unlined earthen canals and ii uplift force in lined canals hosseinzadeh asl et al 2020 salmasi et al 2017 reduced uplift by employing longitudinal drains with underlined canals these longitudinal drains reduce the phreatic line in the ground water and prevent the formation of cracks in the lining the depth and diameter of these drains are important parameters to consider in design the researchers presented charts along with regression equations to help in the design of canals with high ground water levels jafari et al 2019 applied a filter envelope around drain pipes under concrete lined canal bottoms this reduces the uplift force under the canal and increases the canal lining lifetime the present study investigates the effect of double cutoff walls on uplift force exit hydraulic gradient and seepage rate the depth of the two cutoffs may not be equal and they can be moved to different locations under the apron different configurations of double cutoff walls are considered with variable depths and positions solutions of the governing equations are found using fem validation of the results was performed by comparison with the closed form solution presented by jain and reddi 2011 2 material and methods 2 1 governing equations flow through a porous medium can be represented by eq 1 that is a combination of continuity and darcy s law geo studio 2012 1 t ρ θ x ρ k x h x y ρ k y h y z ρ k z h z where h is the total head m kx is the hydraulic conductivity in the x direction m s ky is the hydraulic conductivity in the y direction m s kz is the hydraulic conductivity in the z direction m s ρ is water density kg m3 θ is the volumetric water content m3 m3 and t is time s this equation states that the difference between the flow entering and leaving an elemental volume is equal to the change in storage of the soil systems eq 1 is a combination of the continuity equation and darcy s law or richards equation in a homogenous anisotropic unsaturated and incompressible porous medium this equation is written as follows 2 x k x h x y k y h y z k z h z θ t for a homogenous isotropic kx ky kz k saturated θ t 0 porous medium richards equation is written as follows also known as the laplace equation 3 2 h x 2 2 h y 2 2 h z 2 0 a graphical solution to this equation is known as a flow net a flow net in essence is map of contours of equal potential crossed with flow lines for the flow net to represent a correct solution to the laplace equation the equipotential lines and flow lines must follow certain rules the flow lines must for example cross the equipotential lines at right angles also the area between two adjacent flow lines is called a flow channel and the flow through any flow channel is equal to the flow through any other flow channel in the present study the foundation of the structure was considered homogeneous and isotropic and the medium was considered saturated the foundation was considered to be a single porous medium with a saturated hydraulic conductivity of 0 00001 m s k 10 5 m s as the foundation of hydraulic structure is saturated only the specified saturated conductivity is used in the numerical solution the current study is carried out using geo studio software pack the seep w software solves the governing equations in porous media richards or laplace equations with boundary conditions using the finite element method fem 2 2 numerical simulation using finite element method fem fig 1 provides different arrangements of double cutoff walls under the hydraulic structure where d1 is the upstream cutoff depth d2 is the downstream cutoff depth l is the distance between the two cutoffs d is the depth of permeable foundation b is the width of the apron and h is upstream water head in fig 1 upper left two key points c and e are important for calculation of the resultant uplift pressure location c is behind left of the downstream cutoff wall and key point e is just to the right of the upstream cutoff wall in fact the two key points c and e comprise the hydraulic structure bottom apron based on the parameters listed in table 1 a total of 330 numerical models are included in the analysis from these models 324 simulated models are comprised for aprons with two cutoff walls and 6 simulated models are included for aprons without cutoff walls fig 2 represents the specification of boundary conditions bcs for the numerical simulation at the upstream end the bc is defined as the pressure head and is designated by h the head at the downstream apron is specified as zero h 0 cutoff walls the apron bottom and the impermeable foundation of depth d are defined with impermeable bcs q 0 where the symbol q denotes the seepage discharge the numerical simulation is carried out in a two dimensional 2d cross section the porous medium is assumed to be saturated θ t 0 and isotropic kx ky mesh generation was accomplished with quadrilateral and triangular shapes and were deployed to result in high accuracy a mesh independence test was performed to determine the number of elements required for accurate fem calculations for this purpose the percent of relative error re was obtained for simulations using different numbers of elements the results show fig 2 that by increasing number of elements up to 15000 the percent of relative error re becomes 5 it can be noted that the calculation of re are based on pressure head at key point c that is the difference between the pressure head at location c from the numerical simulation compared to the analytical solutions of jain and reddi 2011 is defined as an error and this error is computed for different meshes it is seen that the re was almost constant when the number of elements was 15 000 and above therefore this number of elements is selected for further numerical simulations in the following analysis fig 3 illustrates the boundary conditions for the numerical simulation with l b 1 b d 2 4 and d2 d1 1 the close up view of the mesh around the upstream cutoff is provided for ease of viewing it can be noted that in this circumstance the dimensions of the quadrilateral and triangular elements are 0 3 m and the total number of elements and nodes are 15 038 and 15348 respectively two vertical cutoffs can be seen in fig 3 upstream at 30 m and the other downstream of the apron in fig 4 the simulation steps required for the finite element method fem are shown this process comprises the following steps geometric model building mesh generation definition of material properties designation of boundary conditions solution of the governing equations along with boundary conditions and visualization and interpretation of the results if there is a suitable agreement between numerical simulation results with the observed data or analytical solution for a simple case then the process of numerical simulation is accepted during the simulation process a modeler can refine the numerical simulation outputs by performing the following steps fig 4 i using a finer mesh ii changing material properties in this study the k values iii changing boundary conditions 2 3 determination of the minimum distance between the two end boundaries for independent solutions checking the total horizontal length of the computational domain b 2b in this study is 90 m with a height of 15 m d 15 m also the minimum distance between the two end boundaries of the domain from the structure was investigated before completing the simulations that is by increasing the distance of the upstream and downstream boundaries b it was found that the position of these boundaries did not influence the results in all numerical simulation the number of elements per unit area of the solution domain n a was fixed and is equal to 11 n a 11 in this case all simulations were performed with the same mesh density the minimum distance required for the two ends of the computational domain are shown in figs 5 and 6 2 4 criteria performance assessment regression equations are developed to provide a means for engineers to make sound design decisions in order to measure the accuracy of the regression equations three statistical metrics namely the determination coefficient r 2 the root mean square errors rmse and the percent of relative error re were used these metrics are defined in eqs 4 6 4 r 2 i 1 n o i o p i p 2 i 1 n o i o 2 i 1 n p i p 2 5 rmse i 1 n p i o i 2 n 6 re i n p i o i i n p i 100 where o i is the value obtained from the numerical solution p i is the predicted value from the regression models o is the average of calculated values p is the average of predicted values and n is the number of data 3 results and discussion fig 7 provides the flow net under the apron with and without cutoff walls beneath the hydraulic structure these flow nets include flow lines and equipotential lines derived from numerical simulations in fig 7a flow paths are ellipsoid shaped while equipotential curves are hyperbola shaped equipotential curves show energy drop between each curve fig 7b shows the flow net under the apron with two cutoff walls for d2 d1 0 66 flow lines are encountered further upstream and downstream of the apron compared to the no cutoff wall case fig 7a and this causes greater energy loss the concentration of equipotential curves near the cutoff walls is greater than for the no cutoff wall case this finding is also valid for the two other cases i e fig 7c and d the values of the seepage flow rate under the 22 5 m or b d 1 5 concrete apron is shown just below the apron for all cases for example in fig 7a this value is equal to 0 00012637 m3 s per unit width of the hydraulic structure fig 8 provides flow lines and velocity vectors under the apron with two cutoff walls having equal depth d 2 d 1 1 curved velocity vectors upstream and downstream of the cutoff walls result in a greater flow distance creep length in fig 8 the seepage discharge is 8 683 10 5 m3 s m the end of each cutoff experiences greater water velocity due to the contraction in the cross sectional area fig 9 shows the uplift pressure distribution beneath the apron with and without cutoff walls these cutoffs are located at the end points of the apron and with different depths d 2 d 1 0 66 1 and 2 use of cutoff walls under the apron changes the uplift force distribution with respect to an apron without a cutoff it can be seen that the uplift force with a cutoff is less than the uplift force without cutoffs at some apron bottom locations however this condition is reversed at other locations the uplift force distribution shows lower values for the case of d 2 d 1 0 66 compared to the apron with cutoffs for cases of d 2 d 1 1 and 2 the area under the uplift force distribution curves provides the resultant of the uplift force the resultant uplift force is 337 5 kn m for an apron without a cutoff wall uo 337 5 kn m 366 9 kn m for two aprons at the heel and toe with a relative depth of d 2 d 1 2 326 57 kn m for two aprons with a relative depth of d 2 d 1 1 and 285 5 kn m for two aprons with a relative depth of d 2 d 1 0 66 this shows the relative resultant uplift force u uo 1 087 0 967 and 0 846 for d 2 d 1 0 66 1 and 2 respectively the symbol u is the resultant uplift force for the case with a cutoff wall and uo is the resultant uplift force for the no cutoff wall situation thus to decrease the uplift force the designer should select the deeper cutoff wall at the upstream end to verify the calculations a comparison of the numerical simulation with the analytical solutions of jain and reddi 2011 was carried out fig 10 the comparison shows that a satisfactory agreement exists between the current numerical results and the analytical solution the differences between the two methods being 5 in fig 10 a pc is the percent relative pressure head defined as pc p h 100 p is pressure head at location c and h is upstream pressure head or the water depth at the upstream of dam in fig 10 b gc is the hydraulic gradient at key point c in fig 10 c k is the hydraulic conductivity of soil under the dam foundation m s and q is the seepage flow rate per unit width of the hydraulic structure m2 s in fig 11 a b and c the variation of the relative uplift force u uo is presented in fig 11 l b 1 0 66 and 0 33 for the case with two equal depth walls d 2 d 1 as mentioned earlier u o is resultant of the uplift force without a cutoff wall and u is the resultant uplift force with two cutoff walls fig 11 a shows that for l b 1 with increasing cutoff wall depth upstream and downstream of the hydraulic structure the uplift force is relatively constant and there is very little variation in u uo in addition with increase of the permeable layer depth d the relative uplift force decreases fig 11 b and c show the variation of the uplift force with cutoff wall depths and hydraulic structure width b for the two cases of l b 0 66 and 0 3 respectively with increasing cutoff wall depth the relative uplift force decreases for a specified b and this reduction in u uo will be greater when the two cutoff walls are positioned more closely together comparison of fig 11 b with c fig 12 provides the variation of the relative uplift force u uo with the hydraulic structure width over the cutoff wall depth b d 2 for b d 2 it is clear that with equal cutoff wall depths at the upstream and downstream ends of the hydraulic structure increasing or decreasing the depth of cutoffs has no significant effect on the uplift force but when the downstream cutoff moves nearer to the upstream cutoff the uplift force is reduced in addition when d 1 d 2 increasing the cutoff wall depths reduces the uplift force however for d 1 d 2 increasing the cutoff wall depths increases the uplift force fig 13 a and b provides the variation of the relative uplift force u uo with the distance between the two cutoff walls l over the hydraulic structure width b the figure shows that for constant b decreasing l results in a reduction of the relative uplift force for l b 0 7 the slope of the relative uplift force shows a rapid change in other words l b 0 7 is not suitable condition for hydraulic structures due to high u uo values fig 14 a b presents the variation of the relative uplift force u uo versus the variation of the relative cutoff depths for the condition of l b 1 cutoffs are located at the ends of the hydraulic structure fig 14 shows that with increasing downstream cutoff wall depth the relative uplift force increases in order to reduce u uo it is necessary to have d 1 d 2 in addition for b d 0 7 the relative uplift force is much less than for the case of b d 1 75 and for the smaller width of the hydraulic structure or deeper permeable foundation the value of u uo is reduced in fig 15 the changes of the exit hydraulic gradient gr with the hydraulic structure width b over the downstream cutoff depth d2 are provided fig 15 shows that with decreasing cutoff wall distance l or decreasing in downstream cutoff wall depth d2 the value of gr increases in addition for the case of l b 1 the value of gr is lower than that for the case where the downstream cutoff located one third or two thirds downstream from the upstream cutoff therefore it can be concluded that the existence of a cutoff wall in the downstream portion of the hydraulic structure allows control of gr in fig 16 the changes of the relative discharge seepage beneath the hydraulic structure q qo are presented the figure shows that with the increasing downstream cutoff depth d2 the value of q qo decreases for d 2 d 1 1 the reduction of q qo increases fig 17a shows contour lines of u uo vs the d2 d1 and b d the contour associated with u uo 1 is a boundary that can be used to distinguish between economic and non economic designs of hydraulic structures in other words the contours for u uo 1 would be a viable design fig 17b presents contours for gr gro against d2 d1 and b d the isoline gr gro 1 is another boundary used to separate economically viable and non economically viable designs in fig 18 the four separated regions of economic and non economic designs in the hydraulic structures considering both uplift force and exit hydraulic gradient criteria are shown another representation of u uo is provided in fig 19 this figure shows contours of u uo as a function of d2 d1 and l b the region for the satisfactory values for the u uo is denoted in the figure fig 20 shows gr gro as a function of d2 d1 and l b the area for acceptable values for gr gro is indicated in fig 20 fig 21 shows the intersection of the relative uplift forces and the relative exit hydraulic gradient the variations of u uo and gr gro are in inverse directions i e when b d increases u uo decreases while gr gro increases fig 21 shows that if b d 1 35 for b d 2 20 and b d 1 38 for b d 2 4 both u u0 and gr gro are less than unity and this represents an optimal location for design of hydraulic structures with respect to uplift force and exit hydraulic gradient fig 22 provides another representation for variations of u uo and gr gro with d 2 d 1 based on fig 22 it is seen that for d 2 d 1 1 a minimum value of u uo occurs this figure is valid for the range 0 33 l b 1 and for b d 2 6 b d 0 7 for d 2 d 1 1 the value of gr gro takes on its highest value but the relative exit hydraulic gradient gr gro is less than unity 3 1 regression equation for predicting uplift force start here based on the data obtained from the numerical simulations an attempt was carried out to find regression equations for predicting the uplift force exerted under a hydraulic structure two cutoff walls are incorporated under these hydraulic structures the location l and the depths d1 d2 of the two cutoff walls as well as the hydraulic structure width b and the permeable layer depth under the hydraulic structure d are variables the metrics used to quantify the accuracy of the regressions are root mean squared error rmse determination coefficient r 2 and the relative error percent re table 2 provides the results for the non linear equation coefficients see eq 7 nine separate equations were derived to estimate u uo as a dependent variable where d2 d1 b d b d2 and l b are independent variables 7 u u o a b b d c b d 2 1 e b d f b d 2 fig 23 shows a scatter plot of u uo using the regression equation and the numerical simulation in fig 23 the two ellipsoid shapes refer to economic and non economic designs i e u uo 1 would be economically viable and u uo 1 would not be economically viable 4 regression equation for predicting exit hydraulic gradient like uplift force attempts were made to derive a regression equation for predicting exit hydraulic gradient in its dimensionless form gr gro a regression formula similar to eq 7 was used to estimate gr gro as a dependent variable with d2 d1 b d b d2 and l b as independent variables see eq 8 the accuracy metrics rmse r2 and re were computed and their values are provided in table 3 8 g r g ro a b b d c b d 2 1 e b d f b d 2 fig 24 shows the scatter plot of gr gro using the regression equation and the numerical simulation in fig 24 the two ellipsoid shapes refer to economic and non economic designs i e gr gro 1 would be economically viable and gr gro 1 would not be economically viable 5 conclusions to the best knowledge of the authors the effect of the combination of two cutoff walls under a hydraulic structure has not been fully studied until now most prior research comprises a single cutoff wall some existing studies have considered the two cutoff walls with equal depth and with fixed locations one in the upstream portion and the other in the downstream region of a hydraulic structure the present study has investigated the simultaneous effects of two cutoff walls under a hydraulic structure and their combined influence on uplift force u and exit hydraulic gradient gr cutoff depths d1 and d2 as well as their location were variable parameters in addition a hydraulic structure width b and permeable layer depth d were also varied governing equations with specified boundary conditions were solved using the finite element method fem the results were compared with existing analytical solutions that considered only two cutoff walls with equal depth located at the two ends of a hydraulic structure the simulation results were compared with existing analytical solutions the maximum error between the computational and analytical solution was 5 several numerical models were simulated to investigate the effects of d1 d2 l b and d on u and gr these effects were presented to help the designers make reasonable design choices the main outcomes of the present study are summarized below a deeper upstream cutoff wall has a positive effect on uplift force reduces u meanwhile the deeper downstream cutoff has a negative effect on uplift force increases u on the other hand deeper downstream cutoff walls have a positive effect on exit hydraulic gradient decreases gr and vice versa economic designs are provided based on the values of on u and gr in terms of l b d2 d2 b d and b d2 with b d 1 35 for b d 2 20 and b d 1 38 for b d 2 4 both u u0 and gr gro are less than unity and this represents an optimal location for design of hydraulic structures with respect to both uplift force and exit hydraulic gradient relative uplift force u uo is a function of b d2 b d l b and d2 d2 and presentation of this function with a single regression equation was not available perhaps more sophisticated methods like artificial intelligence ai models may handle this difficulties credit authorship contribution statement farzin salmasi conceptualization writing original draft investigation methodology administration bahram nourani investigation methodology software validation visualization john abraham conceptualization writing review editing writing original draft declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this paper is the outcome of a research project supported by the university of tabriz research affairs office 
5464,the parameters of bioretention facilities have important effects on their operations however previous studies have either examined the regulation effects of these parameters or conducted scenario simulations whereas very few studies have attempted to optimize the key parameters of low impact development lid facilities to fill this gap the key parameters of bioretention facilities were optimized in this work to improve the operation of these facilities simulated rainfall experiments were also conducted in a school test field to monitor the regulation effect of bioretention tanks on water quantity and quality under different scenarios the operation of bioretention facilities in other scenarios compared with the experimental scenario was simulated by using the hydraus 1d model on the basis of the experimental data the key parameters that greatly influence the regulation effect of bioretention facilities were defined by using the morris classification screening method and were optimized by using the simulation results and the response surface methodology results show that the water reduction rate ranges from 80 to 85 and that the thickness of the medium layer ranges from 25 cm to 120 cm under a high influent concentration meanwhile the bioretention tanks with an artificial filler of fly ash sand or planting soil can treat more scenario rainfall recurrence period of 2 years confluence ratio of 10 1 20 1 recurrence period of 5 years confluence ratio of 10 1 15 1 and recurrence period of 10 years confluence ratio of 10 1 whereas the bioretention tank with artificial filler of blast furnace slag can deal with less scenario rainfall recurrence period of 2 years 5 years 10 years confluence ratio of 10 1 and recurrence period of 2 years confluence ratio of 15 1 keywords bioretention parameter optimization hydrus 1d response surface methodology 1 introduction the accelerating urbanization has gradually decreased the supply of land resources in cities ma et al 2017 urban green spaces are constantly being replaced by impervious ground surfaces and rooves of houses and the increasing area of impervious ground surfaces introduces various problems such as nonpoint source pollution doubled increase in surface runoff reduced rainwater infiltration and frequent urban waterlogging all of which challenge the existing urban infrastructure li and davis 2016 low impact development lid technology is an engineering measure adopted by the us environmental resources agency in the 1990s to solve the problems in urban rainwater and nonpoint source pollution askarizadeh et al 2015 lid employs decentralized miniaturized diversified and localized technologies to reduce rainwater in situ at the source of rainwater runoff thereby maintaining the hydrological characteristics including total runoff and peak flow and time before and after development maniquiz redillas and kim 2016 lid has been widely used worldwide and has been intensively studied by relevant experts and scholars mangangka et al 2015 guo et al 2015 roypoirier et al 2015 however previous studies have largely focused on regulation effects or scenario simulations whereas only few have examined the optimization of key parameters of lid facilities the key parameters of these facilities are optimized using a large amount of data that are obtained through time consuming and laborious tests the effects of bioretention facilities on the regulation of stormwater runoff are also affected by many uncontrollable factors such as temperature air humidity and weather conditions the accuracy of the test data cannot also be well guaranteed a large number of data with improved accuracy and convenience can be obtained by using few experimental data with high accuracy and an lid single facility model to simulate the regulation effects of bioretention facilities across different situations wang et al 2018 recarga drainmod and hydrus are the most widely used models for simulating lid facilities dussaiuant a r developed recarga specifically for analyzing the hydrologic performance and design of biological detention facilities however this model can only simulate water transport meanwhile drainmod is a field drainage model developed by professor r w skaggs of the department of biological and agricultural engineering in north carolina state university in the 1970s this model was initially applied to investigate the performance of drainage and underground irrigation systems and the effects of nitrogen and salt transport on crops in recent years drainmod has been gradually applied in biological retention yet is only able to simulate water nitrogen and salt transport hydrus is a soil physical simulation software developed by the salt soil laboratory of the us department of agriculture to model water movement solute transport heat transfer and water absorption of plant roots in saturated and unsaturated media this model can also be used for a comprehensive simulation of water and solute transport li et al 2018 the response surface methodology is an optimization method for comprehensive experimental design and mathematical modeling mason et al 2003 that requires few trials and achieves high precision qin and lv 2003 this method has been applied in the chemical environmental and food science fields for instance the response surface methodology was used along with the residual mushroom of hypsizygus marmoreus to extract polysaccharides li 2018 this same methodology was employed to test the removal efficiency of three types of materials chen et al 2018 and to optimize the process of a heterogeneous fenton like system xu et al 2016 following these considerations this study aims to 1 simulate and analyze the regulation effect of bioretention tanks on rainwater runoff volume and quality under the influence of different internal and external factors by using the hydraus 1d model 2 determine the degree of influence of the model parameters on the operation effects of bioretention tanks and 3 optimize the key parameters of bioretention facilities by using the response surface methodology the novelty of this paper lies in its application of the response surface methodology to optimize the parameters of bioretention facilities specifically this paper proposes a method for optimizing the parameters of bioretention facilities and guaranteeing the scientific and reasonable construction of these facilities 2 materials and methods 2 1 natural survey of the study area as a representative city in northwest china xi an is located in the guanzhong basin which lies at in the middle of the yellow river basin fig 1a this city has a greatly varying altitude while its geomorphology is largely defined by the demarcated qinling mountains and weihe plain the city is part of the east asian warm temperate zone with cold and dry weather in winter and spring respectively and a large amount of rainfall in summer and autumn the highest and lowest annual temperatures recorded in xi an were approximately 40 c and 8 c respectively whereas the average annual temperature ranges from 6 4 c to 13 4 c the city has an annual average humidity of 70 to 73 annual sunshine hours of 1983 4 to 2267 3 h annual average precipitation of 537 5 mm to 1028 4 mm and average annual precipitation days of 88 to 105 days the precipitation intensity in xi an is obviously seasonal the interannual variation in its rainfall is significant the precipitation in this area is unevenly distributed throughout the year and the precipitation from july to october accounts for more than 60 of the city s annual precipitation li et al 2016 2 2 experiment devices and schemes the experiment device used in this work can be found in the sponge city technology test site of xi an university of technology figs 1b and 1c this device comprised 10 bioretention tanks with each tank having the same dimensions of 2 m 0 5 m 1 05 m length width height and sharing the same pool with an effective volume of 2 7 m3 from top to bottom these bioretention tanks comprised a 15 cm aquifer 30 cm planting soil 40 cm artificial filling layer and 15 cm gravel drainage layer please refer to fig 2 for the profile of bioretention tank a perforated drainage pipe was arranged at the bottom of the gravel drainage layer and the drainage pipe was wrapped with permeable geotextile to prevent sediments from entering and clogging it triangular weirs of 30 were installed at the inlet outlet and overflow of the system and the water level in front of these weirs was monitored and measured by using xthj recorders they are the instruments for measuring water level they were manufactured by teng hui temperature control instrument and meter plant in yuyao zhejiang province china the accuracy of this recorders were 0 001 m the corresponding flow can be calculated depending on the measured water level the experiments were conducted from may 2015 to august 2015 three impervious bioretention tanks namely 7 9 and 10 were selected as the research objects the corresponding artificial fillers were fly ash sand fs volume ratio of 1 1 blast furnace slag g and planting soil z these bioretention tanks are shown in fig 2c and 2d while their layout and vertical structure are presented in fig 2a and 2b respectively two recurrence periods of 2 and 5 years were designed the rainfall duration was set to 120 min and the confluence ratio confluence ratio refers to the ratio of the confluence area to the infiltration area of the bioretention facility was set to 17 1 table 1 shows the calculations for water volume chemical oxygen demand cod nitrate nitrogen no3 n ammonia nitrogen nh3 n total nitrogen tn total phosphorus tp and heavy metals cu zn and cd were selected as research objects the influent concentration was set according to the monitoring results for urban rainwater runoff du 2012 dong 2013 zhang 2014 rainwater was classified into high initial rainwater and low concentration middle and late rainwater the pollutant concentration was kept constant in the process of influent table 2 shows the specific concentration of water distribution following the recommendations specified in technical guidelines for the formulation and design of urban rainstorm intensity formulas mohurd 2014a the chicago rain type was used in the experiments for the artificial simulation of rainfall the rain peak coefficient was set to 0 3 and the rainfall process was designed with a time step of 1 min please see fig 3 for the rainfall process lines the internal and external factors that influence the regulation effects of bioretention facilities on rainwater runoff were considered in designing the experimental scheme the external factors included influent water concentration and interval whereas the internal factors included the type of artificial filler and height of flood area which was controlled by opening the faucet at different heights on the side of the bioretention tank the influence of bioretention tanks on rainwater runoff under different internal and external conditions was studied by testing the effects of these influencing factors the device should be wetted with clear water before conducting the experiment table 3 shows the experiment scheme 2 3 optimization of model parameters the hydrus software was combined with response surface methodology to optimize the parameters the optimization process is conducted in the following steps first the experimental data were used and the empirical values were collected to build an initial model second a sensitivity analysis on the model parameters was performed and the sensitive parameters were determined third the experimental data were used to calibrate and validate the model parameters fourth simulation solutions were designed by using a design expert software design expert is an experimental design software system developed by the stat ease company in the united states that can be applied to the design and analysis of various multi factor experiments it can perform statistical analysis and curve fitting on test data and can also establish mathematical models to predict test results and based on the prediction results the optimal parameter combination for the test is further obtained duangjit et al 2015 design expert software includes multiple methods one of which is response surface methodology the response surface methodology is the product of a combination of mathematical and statistical methods it is used to model and analyze a problem whose response is affected by multiple variables the purpose is to optimize the response when the functional relationship between the test results and the known parameters is implicit the relationship between the test results and the parameter variables can be designed by the response surface methodology and the specified set of design points can be continuously performed on the basis of experimental measurements or numerical analysis experiments to find the coefficient of the parameter variable and finally establish the functional relationship between the response and the parameter variable and then optimize based on this to solve the complexity problem in actual operation response surface methodology is to express implicit function by constructing a polynomial with explicit expression form essentially the response surface methodology is a set of statistical methods that uses this method to find the best response value after considering the variation or uncertainty of the value of the input variable if there are many factors a screening test is needed first to remove the unimportant factors li 2010 fifth the adjusted model parameters were inputted into the software and the operation of bioretention tanks under different scenarios was simulated according to the simulation scheme finally the simulation results were inputted into the software and the constraints and optimization goals were set the software optimizes the target factor by using the response surface methodology on the basis of the simulation results and constraints the goal of optimization is that the comprehensive load reduction rate of pollutants is the largest when the reduction rate of water quantity is 80 85 and the thickness of medium layer is 25 120 cm 2 4 simulation method 2 4 1 model principle the hydrus 1d software can be used to simulate 1d vertical water movement solute movement and heat transfer this software not only considers the hysteresis of root water adsorption and water content but also involves the evapotranspiration meteorological module therefore this model can be used under various conditions such as fixed and variable head constant and variable flow and atmospheric boundary boivin et al 2006 hydrus 1d considers the saturated unsaturated darcy flow state and ignores the effects of air flow movement in soil whitaker 1986 the governing water flow equation is solved by using the modified richards equation boivin et al 2006 which is formulated as 1 θ t z k h z h z cos ϕ s k h z k s z k r h z where θ is the moisture volume percentage cm3 cm 3 t is the time variable s z is the spatial variable cm k h z is the unsaturated infiltration coefficient cm day 1 h is the hydraulic head or matric potential cm φ is the water flow direction and angle of the vertical direction s is the source and sink items g cm 3 s 1 ks is the saturated infiltration coefficient cm day 1 and kr is the relative infiltration coefficient cm day 1 the van genuchten model van 1980 which is the most widely used single pore model was selected for the simulation and is formulated as 2 θ h θ r θ s θ r 1 α h n m h 0 θ s h 0 and 3 k h k s s e l 1 1 s e 1 m m 2 s e θ θ r θ s θ r m 1 1 n n 1 where θ s and θ r are the saturated water capacity and retained water content of the media respectively cm3 cm 3 h is the hydraulic head or matric potential cm α is the air admission suction reciprocal cm 1 k s is the saturation conductivity coefficient cm day 1 s e is the effective water content cm3 cm 3 l is the connectivity of media pores usually 0 5 and n is the index of pore volume size distribution the van genuchten model can flexibly handle different flow boundaries and can be used for homogeneous or heterogeneous soil structures saâdi et al 2018 the solute transport equation is solved numerically by using the traditional convection dispersion equation and the galerkin linear finite element method boivin et al 2006 which are formulated as 4 θ c t ρ s t z θ d c z q c z φ where c and s are the liquid and solid concentrations of the solute g cm 3 and g g 1 respectively ρ is the volume weight g cm 3 d is the combined dispersion coefficient cm2 day 1 q is the moisture darcy flow velocity cm s 1 and φ is the source and sink items g cm 3 s 1 the value range of each parameter is shown in table 4 2 4 2 initial and boundary conditions the regulating effects of bioretention facilities on rainwater runoff under the simulated rainfall conditions were also studied given that the water storage capacity above the filler layer of these facilities should be considered the upper boundary conditions of water transport should be atmospheric boundary with surface layer the moisture content was considered as the initial condition the initial water contents in the planted soil and artificial filling layers were set to 15 and 19 respectively and free drainage boundary was set as the lower boundary condition for solute transport the concentration flux boundary and zero concentration gradient boundary were used as the upper and lower boundary conditions respectively and liquid phase concentration was selected as the initial condition the water supply concentration remained constant throughout the rainfall simulation process the longitudinal dispersion was 1 10 of the packing layer thickness the molecular diffusion coefficients of solutes in water dw were calculated as dw 2 71 10 4 m0 71 where m is the molar mass of the solute li et al 2013 the following assumptions were made in accordance to the actual situation the artificial filler was homogeneous no uneven mixing was applied the structure of filler would not change during infiltration the hysteresis of water was ignored the effects of root water uptake on water and solute transport were neglected and the effect of temperature was disregarded the model can simulate 1d vertical water and solute transport while ignoring lateral transport the basic information of the model is shown in fig 4 2 4 3 sensitivity of model parameters morris classification screening method was selected as the method of parameter sensitivity analysis ketema and langergraber 2014 sensitivity analysis of parameters required for each bioretention tank this article uses the tn experimental data of 9 bioretention tank as an example to illustrate the analysis was performed on the basis of the data obtained from tests 5 7 and 9 additional details can be found in table a 1 in supplementary information for water reduction rates influent water showed the greatest degree of influence followed by planting soil permeability coefficient filler layer saturated water content planting soil saturated water content and planting soil and filler layer thickness for concentration removal rates soil layer permeability coefficient produced the greatest influence followed by planting soil layer thickness filler layer thickness influent water volume filler layer saturated water content influent concentration planting soil saturated water content aquifer thickness soil layer adsorption coefficient packing layer adsorption coefficient and packing layer bulk density for pollutant load reduction rates influent quantity showed the greatest influence followed by planting soil permeability coefficient filler layer thickness filler layer saturated water content influent concentration planting soil thickness planting soil saturated moisture content packing layer adsorption coefficient and planting soil adsorption coefficient 2 4 4 model calibration and verification the hydraulic and water quality parameters of the bioretention tanks were calibrated and validated on the basis of the parameter sensitivity analysis results the calibration and verification of parameters were divided into nine steps the first step was to preset a set of parameters based on similar regional literature reports the second step is to analyze the sensitivity of the parameters by using the morris classification and screening method to distinguish the sensitive parameters the third step is to divide the experimental data into two parts the data used in the calibration period groups 1 4 and the data used in the verification period groups 5 9 the fourth step is to input the water inflow conditions corresponding to the first set of experimental data into the hydrus 1d model adjust the parameters based on the analysis results of the second step and the first set of experimental data and run the model to obtain simulation data in the fifth step the simulated data and experimental data are input into the calculation formulas of the nash efficiency coefficient nse and the determination coefficient r2 in the sixth step when nse 0 5 and r2 0 6 the parameters have met the requirements in the seventh step when any of nse and r2 does not meet the requirements of step 6 repeat steps 4 and 5 until the requirements of step 6 are met in the eighth step the first set of experimental data and the corresponding water inflow conditions in the fourth step are replaced with the second set of experimental data and the corresponding water inflow conditions and the fourth to sixth steps are repeated in the ninth step after the second set of data meets the requirements of the sixth step replace the second set of experimental data and its corresponding water inlet conditions with the first set of experimental data and its corresponding water inlet conditions and repeat the fourth step to the sixth step until the parameters can make the first group of simulation data and experimental data and the second group of simulation data and experimental data can meet the requirements of the sixth step the target was the quantity of effluent and the concentration of pollutants in the effluent since the test effluent information was in steps of 15 min the step used in the model was consistent with the test two judgment indicators namely the determination coefficient r2 and nash efficiency coefficient nse were adopted to evaluate the applicability of the model li et al 2012 the r2 values of water quantity and quality during the calibration and verification were all above 0 6 whereas their nse were above 0 5 the simulated and measured values showed high fitting and matching degrees table 5 show the r2 and nse of water quality and quantity in calibration and verification period tables 6 and 7 show the water quantity and quality parameters of the bioretention tanks after the calibration and verification 2 4 5 simulation scheme several key parameters such as recurrence period convergence ratio filler type and planting layer artificial filler layer and aquifer thicknesses were studied on the basis of the model characteristics and the ranges of these parameters were determined following the requirements specified in sponge city construction technical guide low impact development rainwater system construction trial mohurd 2014b issued by the ministry of housing and urban rural development of the people s republic of china the ratio of the bioretention area facilities to the catchment area usually ranges from 5 to 10 which can be converted into a confluence ratio of 10 1 20 1 the aquifer thickness generally ranges from 10 cm to 30 cm whereas that of the soil exchange layer usually ranges from 25 cm to 120 cm however the thicknesses of the planting soil and filling layer in the stratified bioretention facilities were not clearly specified in consideration of the needs for plant growth the thickness of planting soil layer was set above 20 cm whereas the total thickness of planting soil and filling layer ranged from 25 cm to 120 cm the influent concentration was consistent with that shown in table 2 the recurrence period of outdoor drainage design in general areas is usually 0 5 3 years whereas that in important areas is usually 3 5 years given the differences in the service areas and the importance of bioretention facilities three recurrence periods namely 2a 5a and 10a were considered in this work and the rainfall duration was fixed at 120 min table a 2 in the supplementary information presents the simulation schemes the fillers were distinguished on the basis of their adsorption capacity factor which is computed by dividing the adsorption capacity of fillers by their infiltration rate the adsorption capacity factors of fly ash sand planting soil and blast furnace slag were set to 0 324 0 28 and 0 16 d m respectively zhang 2014 3 results and discussion 3 1 test results the bioretention tanks showed a better performance under low load than under high load regardless of the influent loads the bioretention tank with artificial filler fly ash sand showed greater effects on water volume and pollutant load reduction compared with the two other retention tanks relative to the 3 7 day interval the 15 day interval demonstrated an obvious decrease in the removal effect of no3 n and highlighted the highly unstable removal effects of tn and nh3 n yet had no significant influence on the removal effects of cod tp and heavy metals when the submerged area was 150 mm the average load reduction rates of no3 n tn and cd were all higher than those recorded in the non submerged area cod nh3 n and tp were not evident in the two cases cu and zn showed good removal effects when no submerged zone was present the results are shown in modeling the effects of parameter optimization on three bioretention tanks using the hydrus 1d model li et al 2018 3 2 simulation results the hydrus 1d model was used in the simulation the water and load reduction rates of the pollutants were calculated from the model output table a 3 in the supplementary information shows the simulation results which suggest that fly ash sand outperforms the two other fillers in regulating rainwater runoff under the same internal and external factors the reduction rates of rainfall runoff and pollutant load in the retention tank decreased along with an increased water inflow increasing the influent concentration reduced the pollutant removal rates to a certain extent increasing the planting soil or artificial filling layer increased the water and pollutant load reduction rates and increasing the aquifer thickness increased the water and pollutant load reduction rates to a certain extent yet its influence was minimal 3 3 optimized results the various pollutants accumulated in the urban surface during the dry period will be transferred from the surface accumulation to the rainwater runoff under the action of rainfall scouring usually the concentration of pollutants in the initial rainwater is higher than that in the middle and late rainwater therefore controlling the initial rainwater is important accordingly the limited condition of influent concentration in parameter optimization was set as high influent concentration initial rainwater the runoff reduction rate was limited between 80 and 85 whereas the thickness of the medium layer was set between 25 cm and 120 cm the goal of the optimization was to maximize the comprehensive load reduction rate of pollutants the total thickness of the dielectric layer was computed as the sum of the planting soil and filler layer thicknesses whereas the total height of the facility involved in the optimization was computed as the sum of the aquifer planting soil and filler layer thicknesses the optimization results obtained under different water recurrence periods tables 8 10 were compared and the results suggested that the aquifer thicknesses optimized for three different fillers were similar under the same convergence ratio in the same recurrence period when the recurrence period was 2a and the convergence ratio was 10 1 the aquifer thickness should be 20 cm when the recurrence period was 5a and the convergence ratio was 10 1 the aquifer thickness should be approximately 25 cm in other cases the aquifer thickness should be 30 cm if the combination of fly ash sand was used as the artificial filler under the same water inflow then the thickness of this filler layer was the smallest whereas the thickness of the blast furnace slag was the largest the difference between these two thicknesses ranged from 20 cm to 35 cm and could be mainly ascribed to the permeability and water retention performance of the artificial filler in terms of permeability blast furnace slag showed the best performance followed by planting soil and fly ash sand in terms of water retention fly ash sand showed the best performance followed by planting soil and blast furnace slag li et al 2018 the bioretention tanks with fly ash sand or planting soil could treat the influent water with recurrence period of 2a confluence ratio of 10 1 20 1 recurrence period of 5a confluence ratio of 10 1 15 1 or recurrence period of 10a confluence ratio of 10 1 meanwhile the bioretention tank with blast furnace slag could treat the influent water with recurrence period of 2a confluence ratio of 10 1 15 1 recurrence period of 5a confluence ratio of 10 1 or recurrence period of 10a confluence ratio of 10 1 the three bioretention tanks could meet the filler layer thickness and water reduction rate requirements of 25 cm 120 cm and 80 85 under the aforementioned conditions if the influent water with recurrence period of 10a confluence ratio of 20 1 was treated then the three bioretention tanks required 167 cm fly ash sand 178 cm planted soil and 201 cm blast slag media 4 conclusions the pilot test results showed that the bioretention tanks perform better under low load than under high load regardless of the influent loads the bioretention tank with fly ash sand as artificial filler showed a greater effect on water volume and pollutant load reduction compared with the other tanks compared with the 3 7 day interval the 15 day interval demonstrated an obvious decrease in the removal effect of no3 n and highlighted the unstable removal effects for tn and nh3 n yet had an insignificant influence on the removal effects of cod tp and heavy metals when the submerged area was 150 mm the average load reduction rates of no3 n tn and cd were higher than those reported in a non submerged area cod nh3 n and tp did not show any significant changes in these two situations a good removal effect was reported when cu and zn were in the non submerged area the regulation effects of fly ash sand on stormwater runoff were better than those of the two other fillers under the same internal and external factors increasing the influent water decreased the water and pollutant load reduction rates of the bioretention tank to rainwater runoff increasing the influent concentration reduced the removal rate of pollutants to some extent increasing the planting soil or artificial filler layers increased the water and pollutant load reduction rates and increasing the aquifer thickness increased the water and pollutant load reduction rates to a certain extent yet produced a minimal degree of influence the optimization results showed that the internal factors such as permeability coefficient saturated water content and thickness of the media layer and the external factor such as influent water quantity greatly influenced the water reduction the internal factors such as influent water quantity and quality and the external factors such as permeability saturated water content thickness and adsorptivity of filler layer greatly influenced the pollutant concentration removal and load reduction when the recurrence period was 2a and the convergence ratio was 10 1 the aquifer thickness should be approximately 20 cm when the recurrence period was 5a and the convergence ratio was 10 1 the aquifer thickness should be approximately 25 cm in other cases the thickness of aquifer should be 30 cm the bioretention tank with fly ash sand or planting soil could treat the influent water with recurrence period of 2a confluence ratio of 10 1 20 1 recurrence period of 5a confluence ratio of 10 1 15 1 or recurrence period of 10a confluence ratio of 10 1 meanwhile the bioretention tank with blast furnace slag could treat the influent water with recurrence period of 2a confluence ratio of 10 1 15 1 recurrence period of 5a confluence ratio 10 1 or recurrence period of 10a confluence ratio of 10 1 the three bioretention tanks could meet the filler layer thickness and water reduction rate requirements of 25 cm 120 cm and 80 85 under the aforementioned conditions author contributions jiake li and ruisong zhao designed the research scheme calculated the results and wrote the manuscript yajiao li processed the data analyzed the results and wrote part of the manuscript huaien li improved the results analysis declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was financially supported by the natural science foundation of shaanxi province 2019jm 347 the national natural science foundation of china no 51879215 and the key research and development project of shaanxi province 2017zdxm sf 073 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124813 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5464,the parameters of bioretention facilities have important effects on their operations however previous studies have either examined the regulation effects of these parameters or conducted scenario simulations whereas very few studies have attempted to optimize the key parameters of low impact development lid facilities to fill this gap the key parameters of bioretention facilities were optimized in this work to improve the operation of these facilities simulated rainfall experiments were also conducted in a school test field to monitor the regulation effect of bioretention tanks on water quantity and quality under different scenarios the operation of bioretention facilities in other scenarios compared with the experimental scenario was simulated by using the hydraus 1d model on the basis of the experimental data the key parameters that greatly influence the regulation effect of bioretention facilities were defined by using the morris classification screening method and were optimized by using the simulation results and the response surface methodology results show that the water reduction rate ranges from 80 to 85 and that the thickness of the medium layer ranges from 25 cm to 120 cm under a high influent concentration meanwhile the bioretention tanks with an artificial filler of fly ash sand or planting soil can treat more scenario rainfall recurrence period of 2 years confluence ratio of 10 1 20 1 recurrence period of 5 years confluence ratio of 10 1 15 1 and recurrence period of 10 years confluence ratio of 10 1 whereas the bioretention tank with artificial filler of blast furnace slag can deal with less scenario rainfall recurrence period of 2 years 5 years 10 years confluence ratio of 10 1 and recurrence period of 2 years confluence ratio of 15 1 keywords bioretention parameter optimization hydrus 1d response surface methodology 1 introduction the accelerating urbanization has gradually decreased the supply of land resources in cities ma et al 2017 urban green spaces are constantly being replaced by impervious ground surfaces and rooves of houses and the increasing area of impervious ground surfaces introduces various problems such as nonpoint source pollution doubled increase in surface runoff reduced rainwater infiltration and frequent urban waterlogging all of which challenge the existing urban infrastructure li and davis 2016 low impact development lid technology is an engineering measure adopted by the us environmental resources agency in the 1990s to solve the problems in urban rainwater and nonpoint source pollution askarizadeh et al 2015 lid employs decentralized miniaturized diversified and localized technologies to reduce rainwater in situ at the source of rainwater runoff thereby maintaining the hydrological characteristics including total runoff and peak flow and time before and after development maniquiz redillas and kim 2016 lid has been widely used worldwide and has been intensively studied by relevant experts and scholars mangangka et al 2015 guo et al 2015 roypoirier et al 2015 however previous studies have largely focused on regulation effects or scenario simulations whereas only few have examined the optimization of key parameters of lid facilities the key parameters of these facilities are optimized using a large amount of data that are obtained through time consuming and laborious tests the effects of bioretention facilities on the regulation of stormwater runoff are also affected by many uncontrollable factors such as temperature air humidity and weather conditions the accuracy of the test data cannot also be well guaranteed a large number of data with improved accuracy and convenience can be obtained by using few experimental data with high accuracy and an lid single facility model to simulate the regulation effects of bioretention facilities across different situations wang et al 2018 recarga drainmod and hydrus are the most widely used models for simulating lid facilities dussaiuant a r developed recarga specifically for analyzing the hydrologic performance and design of biological detention facilities however this model can only simulate water transport meanwhile drainmod is a field drainage model developed by professor r w skaggs of the department of biological and agricultural engineering in north carolina state university in the 1970s this model was initially applied to investigate the performance of drainage and underground irrigation systems and the effects of nitrogen and salt transport on crops in recent years drainmod has been gradually applied in biological retention yet is only able to simulate water nitrogen and salt transport hydrus is a soil physical simulation software developed by the salt soil laboratory of the us department of agriculture to model water movement solute transport heat transfer and water absorption of plant roots in saturated and unsaturated media this model can also be used for a comprehensive simulation of water and solute transport li et al 2018 the response surface methodology is an optimization method for comprehensive experimental design and mathematical modeling mason et al 2003 that requires few trials and achieves high precision qin and lv 2003 this method has been applied in the chemical environmental and food science fields for instance the response surface methodology was used along with the residual mushroom of hypsizygus marmoreus to extract polysaccharides li 2018 this same methodology was employed to test the removal efficiency of three types of materials chen et al 2018 and to optimize the process of a heterogeneous fenton like system xu et al 2016 following these considerations this study aims to 1 simulate and analyze the regulation effect of bioretention tanks on rainwater runoff volume and quality under the influence of different internal and external factors by using the hydraus 1d model 2 determine the degree of influence of the model parameters on the operation effects of bioretention tanks and 3 optimize the key parameters of bioretention facilities by using the response surface methodology the novelty of this paper lies in its application of the response surface methodology to optimize the parameters of bioretention facilities specifically this paper proposes a method for optimizing the parameters of bioretention facilities and guaranteeing the scientific and reasonable construction of these facilities 2 materials and methods 2 1 natural survey of the study area as a representative city in northwest china xi an is located in the guanzhong basin which lies at in the middle of the yellow river basin fig 1a this city has a greatly varying altitude while its geomorphology is largely defined by the demarcated qinling mountains and weihe plain the city is part of the east asian warm temperate zone with cold and dry weather in winter and spring respectively and a large amount of rainfall in summer and autumn the highest and lowest annual temperatures recorded in xi an were approximately 40 c and 8 c respectively whereas the average annual temperature ranges from 6 4 c to 13 4 c the city has an annual average humidity of 70 to 73 annual sunshine hours of 1983 4 to 2267 3 h annual average precipitation of 537 5 mm to 1028 4 mm and average annual precipitation days of 88 to 105 days the precipitation intensity in xi an is obviously seasonal the interannual variation in its rainfall is significant the precipitation in this area is unevenly distributed throughout the year and the precipitation from july to october accounts for more than 60 of the city s annual precipitation li et al 2016 2 2 experiment devices and schemes the experiment device used in this work can be found in the sponge city technology test site of xi an university of technology figs 1b and 1c this device comprised 10 bioretention tanks with each tank having the same dimensions of 2 m 0 5 m 1 05 m length width height and sharing the same pool with an effective volume of 2 7 m3 from top to bottom these bioretention tanks comprised a 15 cm aquifer 30 cm planting soil 40 cm artificial filling layer and 15 cm gravel drainage layer please refer to fig 2 for the profile of bioretention tank a perforated drainage pipe was arranged at the bottom of the gravel drainage layer and the drainage pipe was wrapped with permeable geotextile to prevent sediments from entering and clogging it triangular weirs of 30 were installed at the inlet outlet and overflow of the system and the water level in front of these weirs was monitored and measured by using xthj recorders they are the instruments for measuring water level they were manufactured by teng hui temperature control instrument and meter plant in yuyao zhejiang province china the accuracy of this recorders were 0 001 m the corresponding flow can be calculated depending on the measured water level the experiments were conducted from may 2015 to august 2015 three impervious bioretention tanks namely 7 9 and 10 were selected as the research objects the corresponding artificial fillers were fly ash sand fs volume ratio of 1 1 blast furnace slag g and planting soil z these bioretention tanks are shown in fig 2c and 2d while their layout and vertical structure are presented in fig 2a and 2b respectively two recurrence periods of 2 and 5 years were designed the rainfall duration was set to 120 min and the confluence ratio confluence ratio refers to the ratio of the confluence area to the infiltration area of the bioretention facility was set to 17 1 table 1 shows the calculations for water volume chemical oxygen demand cod nitrate nitrogen no3 n ammonia nitrogen nh3 n total nitrogen tn total phosphorus tp and heavy metals cu zn and cd were selected as research objects the influent concentration was set according to the monitoring results for urban rainwater runoff du 2012 dong 2013 zhang 2014 rainwater was classified into high initial rainwater and low concentration middle and late rainwater the pollutant concentration was kept constant in the process of influent table 2 shows the specific concentration of water distribution following the recommendations specified in technical guidelines for the formulation and design of urban rainstorm intensity formulas mohurd 2014a the chicago rain type was used in the experiments for the artificial simulation of rainfall the rain peak coefficient was set to 0 3 and the rainfall process was designed with a time step of 1 min please see fig 3 for the rainfall process lines the internal and external factors that influence the regulation effects of bioretention facilities on rainwater runoff were considered in designing the experimental scheme the external factors included influent water concentration and interval whereas the internal factors included the type of artificial filler and height of flood area which was controlled by opening the faucet at different heights on the side of the bioretention tank the influence of bioretention tanks on rainwater runoff under different internal and external conditions was studied by testing the effects of these influencing factors the device should be wetted with clear water before conducting the experiment table 3 shows the experiment scheme 2 3 optimization of model parameters the hydrus software was combined with response surface methodology to optimize the parameters the optimization process is conducted in the following steps first the experimental data were used and the empirical values were collected to build an initial model second a sensitivity analysis on the model parameters was performed and the sensitive parameters were determined third the experimental data were used to calibrate and validate the model parameters fourth simulation solutions were designed by using a design expert software design expert is an experimental design software system developed by the stat ease company in the united states that can be applied to the design and analysis of various multi factor experiments it can perform statistical analysis and curve fitting on test data and can also establish mathematical models to predict test results and based on the prediction results the optimal parameter combination for the test is further obtained duangjit et al 2015 design expert software includes multiple methods one of which is response surface methodology the response surface methodology is the product of a combination of mathematical and statistical methods it is used to model and analyze a problem whose response is affected by multiple variables the purpose is to optimize the response when the functional relationship between the test results and the known parameters is implicit the relationship between the test results and the parameter variables can be designed by the response surface methodology and the specified set of design points can be continuously performed on the basis of experimental measurements or numerical analysis experiments to find the coefficient of the parameter variable and finally establish the functional relationship between the response and the parameter variable and then optimize based on this to solve the complexity problem in actual operation response surface methodology is to express implicit function by constructing a polynomial with explicit expression form essentially the response surface methodology is a set of statistical methods that uses this method to find the best response value after considering the variation or uncertainty of the value of the input variable if there are many factors a screening test is needed first to remove the unimportant factors li 2010 fifth the adjusted model parameters were inputted into the software and the operation of bioretention tanks under different scenarios was simulated according to the simulation scheme finally the simulation results were inputted into the software and the constraints and optimization goals were set the software optimizes the target factor by using the response surface methodology on the basis of the simulation results and constraints the goal of optimization is that the comprehensive load reduction rate of pollutants is the largest when the reduction rate of water quantity is 80 85 and the thickness of medium layer is 25 120 cm 2 4 simulation method 2 4 1 model principle the hydrus 1d software can be used to simulate 1d vertical water movement solute movement and heat transfer this software not only considers the hysteresis of root water adsorption and water content but also involves the evapotranspiration meteorological module therefore this model can be used under various conditions such as fixed and variable head constant and variable flow and atmospheric boundary boivin et al 2006 hydrus 1d considers the saturated unsaturated darcy flow state and ignores the effects of air flow movement in soil whitaker 1986 the governing water flow equation is solved by using the modified richards equation boivin et al 2006 which is formulated as 1 θ t z k h z h z cos ϕ s k h z k s z k r h z where θ is the moisture volume percentage cm3 cm 3 t is the time variable s z is the spatial variable cm k h z is the unsaturated infiltration coefficient cm day 1 h is the hydraulic head or matric potential cm φ is the water flow direction and angle of the vertical direction s is the source and sink items g cm 3 s 1 ks is the saturated infiltration coefficient cm day 1 and kr is the relative infiltration coefficient cm day 1 the van genuchten model van 1980 which is the most widely used single pore model was selected for the simulation and is formulated as 2 θ h θ r θ s θ r 1 α h n m h 0 θ s h 0 and 3 k h k s s e l 1 1 s e 1 m m 2 s e θ θ r θ s θ r m 1 1 n n 1 where θ s and θ r are the saturated water capacity and retained water content of the media respectively cm3 cm 3 h is the hydraulic head or matric potential cm α is the air admission suction reciprocal cm 1 k s is the saturation conductivity coefficient cm day 1 s e is the effective water content cm3 cm 3 l is the connectivity of media pores usually 0 5 and n is the index of pore volume size distribution the van genuchten model can flexibly handle different flow boundaries and can be used for homogeneous or heterogeneous soil structures saâdi et al 2018 the solute transport equation is solved numerically by using the traditional convection dispersion equation and the galerkin linear finite element method boivin et al 2006 which are formulated as 4 θ c t ρ s t z θ d c z q c z φ where c and s are the liquid and solid concentrations of the solute g cm 3 and g g 1 respectively ρ is the volume weight g cm 3 d is the combined dispersion coefficient cm2 day 1 q is the moisture darcy flow velocity cm s 1 and φ is the source and sink items g cm 3 s 1 the value range of each parameter is shown in table 4 2 4 2 initial and boundary conditions the regulating effects of bioretention facilities on rainwater runoff under the simulated rainfall conditions were also studied given that the water storage capacity above the filler layer of these facilities should be considered the upper boundary conditions of water transport should be atmospheric boundary with surface layer the moisture content was considered as the initial condition the initial water contents in the planted soil and artificial filling layers were set to 15 and 19 respectively and free drainage boundary was set as the lower boundary condition for solute transport the concentration flux boundary and zero concentration gradient boundary were used as the upper and lower boundary conditions respectively and liquid phase concentration was selected as the initial condition the water supply concentration remained constant throughout the rainfall simulation process the longitudinal dispersion was 1 10 of the packing layer thickness the molecular diffusion coefficients of solutes in water dw were calculated as dw 2 71 10 4 m0 71 where m is the molar mass of the solute li et al 2013 the following assumptions were made in accordance to the actual situation the artificial filler was homogeneous no uneven mixing was applied the structure of filler would not change during infiltration the hysteresis of water was ignored the effects of root water uptake on water and solute transport were neglected and the effect of temperature was disregarded the model can simulate 1d vertical water and solute transport while ignoring lateral transport the basic information of the model is shown in fig 4 2 4 3 sensitivity of model parameters morris classification screening method was selected as the method of parameter sensitivity analysis ketema and langergraber 2014 sensitivity analysis of parameters required for each bioretention tank this article uses the tn experimental data of 9 bioretention tank as an example to illustrate the analysis was performed on the basis of the data obtained from tests 5 7 and 9 additional details can be found in table a 1 in supplementary information for water reduction rates influent water showed the greatest degree of influence followed by planting soil permeability coefficient filler layer saturated water content planting soil saturated water content and planting soil and filler layer thickness for concentration removal rates soil layer permeability coefficient produced the greatest influence followed by planting soil layer thickness filler layer thickness influent water volume filler layer saturated water content influent concentration planting soil saturated water content aquifer thickness soil layer adsorption coefficient packing layer adsorption coefficient and packing layer bulk density for pollutant load reduction rates influent quantity showed the greatest influence followed by planting soil permeability coefficient filler layer thickness filler layer saturated water content influent concentration planting soil thickness planting soil saturated moisture content packing layer adsorption coefficient and planting soil adsorption coefficient 2 4 4 model calibration and verification the hydraulic and water quality parameters of the bioretention tanks were calibrated and validated on the basis of the parameter sensitivity analysis results the calibration and verification of parameters were divided into nine steps the first step was to preset a set of parameters based on similar regional literature reports the second step is to analyze the sensitivity of the parameters by using the morris classification and screening method to distinguish the sensitive parameters the third step is to divide the experimental data into two parts the data used in the calibration period groups 1 4 and the data used in the verification period groups 5 9 the fourth step is to input the water inflow conditions corresponding to the first set of experimental data into the hydrus 1d model adjust the parameters based on the analysis results of the second step and the first set of experimental data and run the model to obtain simulation data in the fifth step the simulated data and experimental data are input into the calculation formulas of the nash efficiency coefficient nse and the determination coefficient r2 in the sixth step when nse 0 5 and r2 0 6 the parameters have met the requirements in the seventh step when any of nse and r2 does not meet the requirements of step 6 repeat steps 4 and 5 until the requirements of step 6 are met in the eighth step the first set of experimental data and the corresponding water inflow conditions in the fourth step are replaced with the second set of experimental data and the corresponding water inflow conditions and the fourth to sixth steps are repeated in the ninth step after the second set of data meets the requirements of the sixth step replace the second set of experimental data and its corresponding water inlet conditions with the first set of experimental data and its corresponding water inlet conditions and repeat the fourth step to the sixth step until the parameters can make the first group of simulation data and experimental data and the second group of simulation data and experimental data can meet the requirements of the sixth step the target was the quantity of effluent and the concentration of pollutants in the effluent since the test effluent information was in steps of 15 min the step used in the model was consistent with the test two judgment indicators namely the determination coefficient r2 and nash efficiency coefficient nse were adopted to evaluate the applicability of the model li et al 2012 the r2 values of water quantity and quality during the calibration and verification were all above 0 6 whereas their nse were above 0 5 the simulated and measured values showed high fitting and matching degrees table 5 show the r2 and nse of water quality and quantity in calibration and verification period tables 6 and 7 show the water quantity and quality parameters of the bioretention tanks after the calibration and verification 2 4 5 simulation scheme several key parameters such as recurrence period convergence ratio filler type and planting layer artificial filler layer and aquifer thicknesses were studied on the basis of the model characteristics and the ranges of these parameters were determined following the requirements specified in sponge city construction technical guide low impact development rainwater system construction trial mohurd 2014b issued by the ministry of housing and urban rural development of the people s republic of china the ratio of the bioretention area facilities to the catchment area usually ranges from 5 to 10 which can be converted into a confluence ratio of 10 1 20 1 the aquifer thickness generally ranges from 10 cm to 30 cm whereas that of the soil exchange layer usually ranges from 25 cm to 120 cm however the thicknesses of the planting soil and filling layer in the stratified bioretention facilities were not clearly specified in consideration of the needs for plant growth the thickness of planting soil layer was set above 20 cm whereas the total thickness of planting soil and filling layer ranged from 25 cm to 120 cm the influent concentration was consistent with that shown in table 2 the recurrence period of outdoor drainage design in general areas is usually 0 5 3 years whereas that in important areas is usually 3 5 years given the differences in the service areas and the importance of bioretention facilities three recurrence periods namely 2a 5a and 10a were considered in this work and the rainfall duration was fixed at 120 min table a 2 in the supplementary information presents the simulation schemes the fillers were distinguished on the basis of their adsorption capacity factor which is computed by dividing the adsorption capacity of fillers by their infiltration rate the adsorption capacity factors of fly ash sand planting soil and blast furnace slag were set to 0 324 0 28 and 0 16 d m respectively zhang 2014 3 results and discussion 3 1 test results the bioretention tanks showed a better performance under low load than under high load regardless of the influent loads the bioretention tank with artificial filler fly ash sand showed greater effects on water volume and pollutant load reduction compared with the two other retention tanks relative to the 3 7 day interval the 15 day interval demonstrated an obvious decrease in the removal effect of no3 n and highlighted the highly unstable removal effects of tn and nh3 n yet had no significant influence on the removal effects of cod tp and heavy metals when the submerged area was 150 mm the average load reduction rates of no3 n tn and cd were all higher than those recorded in the non submerged area cod nh3 n and tp were not evident in the two cases cu and zn showed good removal effects when no submerged zone was present the results are shown in modeling the effects of parameter optimization on three bioretention tanks using the hydrus 1d model li et al 2018 3 2 simulation results the hydrus 1d model was used in the simulation the water and load reduction rates of the pollutants were calculated from the model output table a 3 in the supplementary information shows the simulation results which suggest that fly ash sand outperforms the two other fillers in regulating rainwater runoff under the same internal and external factors the reduction rates of rainfall runoff and pollutant load in the retention tank decreased along with an increased water inflow increasing the influent concentration reduced the pollutant removal rates to a certain extent increasing the planting soil or artificial filling layer increased the water and pollutant load reduction rates and increasing the aquifer thickness increased the water and pollutant load reduction rates to a certain extent yet its influence was minimal 3 3 optimized results the various pollutants accumulated in the urban surface during the dry period will be transferred from the surface accumulation to the rainwater runoff under the action of rainfall scouring usually the concentration of pollutants in the initial rainwater is higher than that in the middle and late rainwater therefore controlling the initial rainwater is important accordingly the limited condition of influent concentration in parameter optimization was set as high influent concentration initial rainwater the runoff reduction rate was limited between 80 and 85 whereas the thickness of the medium layer was set between 25 cm and 120 cm the goal of the optimization was to maximize the comprehensive load reduction rate of pollutants the total thickness of the dielectric layer was computed as the sum of the planting soil and filler layer thicknesses whereas the total height of the facility involved in the optimization was computed as the sum of the aquifer planting soil and filler layer thicknesses the optimization results obtained under different water recurrence periods tables 8 10 were compared and the results suggested that the aquifer thicknesses optimized for three different fillers were similar under the same convergence ratio in the same recurrence period when the recurrence period was 2a and the convergence ratio was 10 1 the aquifer thickness should be 20 cm when the recurrence period was 5a and the convergence ratio was 10 1 the aquifer thickness should be approximately 25 cm in other cases the aquifer thickness should be 30 cm if the combination of fly ash sand was used as the artificial filler under the same water inflow then the thickness of this filler layer was the smallest whereas the thickness of the blast furnace slag was the largest the difference between these two thicknesses ranged from 20 cm to 35 cm and could be mainly ascribed to the permeability and water retention performance of the artificial filler in terms of permeability blast furnace slag showed the best performance followed by planting soil and fly ash sand in terms of water retention fly ash sand showed the best performance followed by planting soil and blast furnace slag li et al 2018 the bioretention tanks with fly ash sand or planting soil could treat the influent water with recurrence period of 2a confluence ratio of 10 1 20 1 recurrence period of 5a confluence ratio of 10 1 15 1 or recurrence period of 10a confluence ratio of 10 1 meanwhile the bioretention tank with blast furnace slag could treat the influent water with recurrence period of 2a confluence ratio of 10 1 15 1 recurrence period of 5a confluence ratio of 10 1 or recurrence period of 10a confluence ratio of 10 1 the three bioretention tanks could meet the filler layer thickness and water reduction rate requirements of 25 cm 120 cm and 80 85 under the aforementioned conditions if the influent water with recurrence period of 10a confluence ratio of 20 1 was treated then the three bioretention tanks required 167 cm fly ash sand 178 cm planted soil and 201 cm blast slag media 4 conclusions the pilot test results showed that the bioretention tanks perform better under low load than under high load regardless of the influent loads the bioretention tank with fly ash sand as artificial filler showed a greater effect on water volume and pollutant load reduction compared with the other tanks compared with the 3 7 day interval the 15 day interval demonstrated an obvious decrease in the removal effect of no3 n and highlighted the unstable removal effects for tn and nh3 n yet had an insignificant influence on the removal effects of cod tp and heavy metals when the submerged area was 150 mm the average load reduction rates of no3 n tn and cd were higher than those reported in a non submerged area cod nh3 n and tp did not show any significant changes in these two situations a good removal effect was reported when cu and zn were in the non submerged area the regulation effects of fly ash sand on stormwater runoff were better than those of the two other fillers under the same internal and external factors increasing the influent water decreased the water and pollutant load reduction rates of the bioretention tank to rainwater runoff increasing the influent concentration reduced the removal rate of pollutants to some extent increasing the planting soil or artificial filler layers increased the water and pollutant load reduction rates and increasing the aquifer thickness increased the water and pollutant load reduction rates to a certain extent yet produced a minimal degree of influence the optimization results showed that the internal factors such as permeability coefficient saturated water content and thickness of the media layer and the external factor such as influent water quantity greatly influenced the water reduction the internal factors such as influent water quantity and quality and the external factors such as permeability saturated water content thickness and adsorptivity of filler layer greatly influenced the pollutant concentration removal and load reduction when the recurrence period was 2a and the convergence ratio was 10 1 the aquifer thickness should be approximately 20 cm when the recurrence period was 5a and the convergence ratio was 10 1 the aquifer thickness should be approximately 25 cm in other cases the thickness of aquifer should be 30 cm the bioretention tank with fly ash sand or planting soil could treat the influent water with recurrence period of 2a confluence ratio of 10 1 20 1 recurrence period of 5a confluence ratio of 10 1 15 1 or recurrence period of 10a confluence ratio of 10 1 meanwhile the bioretention tank with blast furnace slag could treat the influent water with recurrence period of 2a confluence ratio of 10 1 15 1 recurrence period of 5a confluence ratio 10 1 or recurrence period of 10a confluence ratio of 10 1 the three bioretention tanks could meet the filler layer thickness and water reduction rate requirements of 25 cm 120 cm and 80 85 under the aforementioned conditions author contributions jiake li and ruisong zhao designed the research scheme calculated the results and wrote the manuscript yajiao li processed the data analyzed the results and wrote part of the manuscript huaien li improved the results analysis declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was financially supported by the natural science foundation of shaanxi province 2019jm 347 the national natural science foundation of china no 51879215 and the key research and development project of shaanxi province 2017zdxm sf 073 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124813 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
