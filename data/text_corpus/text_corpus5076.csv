index,text
25380,in this manuscript we describe the implementation of the terrain following version of quic urb into quic fire and a demonstration of the impacts of terrain influenced winds on quic fire simulated fire spread no changes to the underlying quic fire fire spread algorithm were made other than what was required to correctly account for the inclusion of terrain this paper summarizes simulations used to understand how the quic urb terrain influenced winds affect upslope fire behavior without additional changes to the quic fire fire spread algorithm previously published firetec results are compared to simulation results from the modified quic fire incorporating terrain influenced winds that use the same topographies and fuels quic fire results showed overall similar behaviors in terms of how the topographies affected fire shapes and trends in spread rates due to the terrain following version of quic urb being unable to generate flow separations at the crest of hills fire spread rates in these regions across all non flat topographies were over predicted when compared to firetec lateral fire growth showed similar trends with firetec between topographies but did not capture the increase in spread due to a diagonal interface between grassland and forested fuel regions in the test domain these simulations suggest possible refinements that are necessary to improve quic fire and thus guide ongoing efforts related to how flame tilt angle is accounted for the incorporation of non local drag effects and the inclusion of the wake eddy parameterizations that are used in quic urb keywords terrain influenced flow terrain following wind solver fast running fire model quic fire firetec data availability data will be made available on request 1 introduction topography can significantly influence wind flows and affect the propagation and behavior of wildland fires linn et al 2010 sharples et al 2012 in particular topography influences wind flow dynamics through mechanisms occurring at a wide range of length and time scales serafin et al 2018 that can be a key component to the spread behavior of a fire topography impacts not only fire behavior but also the fate and transport of smoke as it rises above the fire and is transported downwind accounting for terrain induced effects on winds and thus fire and smoke behavior is an important aspect of predictive fire and smoke modeling in complex terrain solving the full navier stokes equations to capture the dynamic and heterogeneous influences of terrain on winds is one approach to resolve the flow at scales of both the topographic features and fireline this is done in models such as firetec linn and cunningham 2005 and wfds mell et al 2013 another technique is to parameterize the fine scale impacts of topography on fire spread using empirical fire spread models and capture the topographic influences on the larger scales winds using large eddy simulation les tools such as in cawfe coen 2013 wrf sfire mandel et al 2011 and wrf fire coen et al 2013 for real time forecast modeling models like firetec and wfds are currently too computationally time intensive the coupled empirical spread les based tools use simplified fire spread models and too coarse of vegetation variability limiting their generality and applicability for fire scenarios that lack large scale drivers for instance prescribed fires depend on the interaction between multiple firelines and can be heavily influenced by the heterogeneity of the vegetation les empirical spread based tools do not resolve the fine scale processes and three dimensional fuel structure required to capture these dynamics the development of quic fire linn et al 2020a was intended to provide an alternative to computational fluid dynamics cfd based tools that would be much more computationally efficient while still representing some of the most important processes or phenomena and three dimensional structure of the fuel at the fireline scale i e meter scale however the wind solver in the original prototype version of quic fire linn et al 2020a did not account for the influences of topography due to the 2020 version of quic fire s wind solver the quick urban industrial complex quic urb solver not including the influences of terrain on either the winds or the fire behavior in robinson et al 2023 the initial work is described that enables the background ambient wind fields to reflect many of the influences of topography in quic urb wind fields this effort set the stage for quic fire to be extended to capture the influences of topography on fire behavior the complex terrain capable extended version of quic fire described in this paper leverages the terrain following version of quic urb presented in robinson et al 2023 this version of quic urb is a diagnostic wind model that produces mass consistent wind fields the advantages of a diagnostic wind solver approach over prognostic models is their speed and minimal memory requirements for instance quic urb can generate wind fields for complex environments in less than 1 min with a common laptop not requiring super computing capabilities for calculation the disadvantage is that standard quic urb simulations treat winds as quasi steady state solutions to current forcing conditions and thus implicitly assume that wind fields are in equilibrium this means it cannot capture some of the effects of strong transients or unsteady aspects of the flow since 2015 quic urb has been dynamically integrated with a fire model fire ca with a focus on modeling prescribed fire resulting in the model quic fire linn et al 2020a williams et al 2004 therefore the addition of quic urb s complex terrain capability robinson et al 2023 has opened the door for quic fire to be extended to complex terrain as well it should be highlighted that the fire component in quic fire was designed to depend on the fire influenced local wind field that reflects the combined effects of the quasi steady state winds of quic urb and evolving fire induced modifications to the wind field the winds in quic urb are initialized based on measurements or user values at one or more locations within the computational domain the vertical profile can follow a power law or a log law or alternatively a set of wind values at multiple heights can be provided the mesoscale weather research and forecasting model wrf outputs usually at 1 5 km horizontal resolution can also be ingested kochanski et al 2015 nelson et al 2016 carvalho et al 2012 quic urb interpolates the provided wind measurements or wrf outputs over its domain using the barnes scheme powers et al 2017 then the localized impacts of vegetative canopies and buildings are parameterized and superimposed over the background wind linn et al 2020a and finally mass consistency is imposed wind measurements at different times can be provided to follow the temporal variation of the background wind field the resulting wind field is time wise smoothed typical domain sizes range from hundreds of meters to 100 kilometers at horizontal resolutions typically varying from 1 200 m singh et al 2008 in this manuscript we will discuss the 1 coupling of a terrain following version of quic urb to fire ca and 2 the implications of using terrain influenced winds to drive upslope wildland fire spread with essentially the preexisting fire spread algorithm in quic fire the changes to fire ca were limited only to what is necessary to correctly include the complex terrain version of quic urb this is a first step in accounting for the effects terrain has on a propagating fire through this study which avoids changes to the fire ca model we are able isolate the effects of resolved terrain driven winds on fire behavior and isolate the driver of changing fire behavior between quic fire versions this also allows us to identify dynamics that this version is currently not capturing to focus ongoing model refinement efforts we describe the extent of the new capabilities modifications required to integrate the terrain following version of quic urb and discuss some of the shortcomings of this extension as it is currently formulated we provide demonstration of some of the current capabilities through comparison against published simulations using higrad firetec in the following when referring to quic fire we are considering the new version with the terrain following winds and the modified fire spreading algorithms to account for terrain 2 quic fire overview quic fire was specifically designed to be able to be to simulate a wide range of wildland fire scenarios including prescribed fire without requiring extensive computational resources while still capturing the coupled fire atmosphere interactions necessary for accurately predicting fire behavior quic fire achieves this coupling by linking the fast running quic urb wind field solver to the fire ca fire spread algorithm quic urb was adapted to incorporate buoyant updrafts generated from the energy release of combusting fuel which is calculated by fire ca by enforcing mass consistency on a background wind field perturbed by these buoyant updrafts quic urb generates indrafts close to the fireline thus allowing the fire ca algorithm to account for buoyancy induced entrainment this two way coupling forms the basis of the fire spread dynamics captured by the quic fire model it is important to highlight the differences in methodologies between quic fire and a full physics model like firetec firetec resolves wind flow directly at fireline scales by solving the full navier stokes equations and models the combustion of fuels by tracking temperature and chemistry of an evolving fire quic fire models the propagation of fire by discretizing the amount of energy released by combusting fuel into energy packets eps the generated eps are transported based on local fire modified winds fire intensity approximations and stochastic modifications via turbulence approximations that are based on calculated wind shear around each cell the eps can contribute to the drying of fuel the combustion of dried fuel and if they do not land on fuel the generation of buoyant updrafts the regions of dried burning and depleted fuels within each cell are tracked and oxygen availability is approximated based on local conditions the details of the coupling and explicit equations of quic fire can be found in linn et al 2020b both quic fire and firetec are full 3d simulations that are sensitive to both vertical and horizontal fuel heterogeneity the 3d fuel grid allows for these models to track when a fire transitions from surface fire to a crown fire and the mechanisms for which that happens whether it be due to ladder fuels or high surface loading 3 effect of topography on winds and fire spread changes implemented to the fire ca algorithm were limited to those required to correctly incorporate the wind fields generated by terrain following version of quic urb to investigate how terrain influenced winds change the fire behavior of the fire ca algorithm this involved implementing the successive over relaxation sor solver to work on a terrain following grid choosing a fuel grid geometry and accounting for terrain induced flow on the transport of the buoyant updrafts 3 1 terrain influenced winds the first step was to generate terrain influenced background winds which is a crucial component to predicting fire behavior on a landscape characterized by topographical features terrain can cause complex three dimensional patterns including channeling in canyons and valleys and flow blocking or diverting uchida and sugitani 2020 serafin et al 2018 which can have nonlocal influences on wind fields these terrain induced wind patterns have been shown to drive drastic changes in fire behavior that terrain slope cannot account for alone sharples et al 2012 close 2005 to incorporate terrain induced winds while also retaining the low computational cost of quic fire it was decided to modify the original cartesian grid of quic urb into a terrain following coordinate system to capture the wind gradients close to the ground with a fine grid resolution meter scale and allow for grid stretching as one moves higher in the atmosphere where less pronounced changes in wind speed and direction are expected a detailed description of that effort can be found in robinson et al 2023 in its current state quic urb wind fields do not contain momentum effects e g separations or thermodynamically driven effects e g drainage flows but future work is planned to address these shortcomings in robinson et al 2023 it can be seen that this effort allowed capturing terrain induced effects like wind speed up over terrain features and stagnation points at the base of large features hence it can be useful to analyze fire spread over varying terrain configurations and wind conditions where separations and drainage flows are not expected to be significant factors 3 2 fire ca grid for terrain effects while wind gradients tend to become more smooth as one moves upwards in the atmosphere allowing for a terrain following stretched grid the importance of the three dimensional fuel structure and its gradients remain from the surface to the top of the canopy it was therefore decided to use a draped grid to capture the vertical fuel structure in which the height of cells in the fuel grid do not stretch with the varying elevation of a topography the draped fuel grid has the advantage of simplifying the computation of the fate and transport of energy in fire ca and generation of 3d fuels inputs as fuel voxels can be generated while only considering height above ground unfortunately a consequence of this choice is that a non trivial interpolation needs to be carried out between the terrain following wind grid and the draped fuel grid each time step as the deformation of the wind grid is dependent on the terrain height at each cell position see fig 1 this is necessary as the fire ca algorithm requires the local wind speed in each cell to calculate fire spread energy that is released by the combustion process in quic fire is carried either upward by strong updrafts or parallel to the surface based on the local fire influenced wind fields at the terrain surface to separate the proportion of eps that are carried vertically by updrafts versus being transported parallel to the surface the local wind velocity v u v w is transformed into a component parallel to the local slope v and a perpendicular component v such that v v 0 the vectors v and v are then projected onto the local slope vectors in the x and y directions respectively resulting in the surface winds 1 v h x u h x w 1 h x 2 2 v h y v h y w 1 h y 2 3 v w h x u h y v 1 h x 2 h y 2 where h x and h y are local terrain derivatives in the x and y direction respectively the ratio of v over v determines the chance that an ep will separate from the surface and travel upward into midstory and canopy fuel cells a schematic of this decomposition can be seen in fig 2 these decomposed winds also define the length scale that the eps travel over another adjustment to account for the draped grid and horizontally launched eps is to multiply the resulting ep travel distance from the fire ca algorithm by cos θ where θ is the local elevation angle of the fuel cell in the direction the ep is traveling this is done as distances traveled in the fuel grid are not calculated by integrating along the terrain surface 3 3 buoyant plume transport in complex terrain the buoyant plume model in the original quic fire considered only flat terrain the horizontal motion of the plumes in the model is governed by background wind whereas the vertical loft and lateral expansion are parameterized with the briggs theory davidson 1989 the implementation of this is done by recalculating the plume radius and centerline updraft at each point on the trajectory however this model is derived for a plume traveling over a flat surface and vertical background wind was not considered the quic fire plume rise scheme was modified to account for the topographically influenced background winds where plumes are now advected vertically with the background winds vertical component in addition to following the briggs trajectory this was motivated by simulations carried out with firetec in order to analyze the buoyancy induced flow without the complications of a moving fire we used a modified version of firetec where the fuel combustion routines were disabled and a constant heat source of 2000 kwm 1 could be placed across a single cell the constant heat source raises the temperature of surrounding air and generates a buoyant plume and emulates a cell emitting constant heat or releasing constant eps to the atmosphere two firetec simulations one with flat terrain and another with a prominent hill with the same logarithmic wind profile for initialization were used to compare the influence of a downwind obstruction on plume trajectories quic fire was also modified in the same way with the same heat source in a single cell fig 3 shows results from these simulations and results in fig 3 comparisons between firetec simulations a b and d e illustrate that the plumes are transported vertically with the background wind field when comparing trajectories between plumes when comparing b c and e f the modification of advecting plume segments vertically with the background wind in quic fire results in similar plume profiles as the full cfd code firetec quic fire results underestimate the upward boundary of the plume but capture the intensity of the updraft at the ground where most of the fire activity occurs 4 comparison of firetec and quic fire on ideal terrain configurations due to the complexity of measuring all variables involved in a propagating fire front 3d fuel loads local wind conditions fuel moisture temporal evolution of fire intensity heat released to the atmosphere it is difficult to adequately characterize real world fire scenarios to fully understand the abilities of a coupled fire atmosphere fire model like quic fire to capture the influences of topography on fire spread one alternative is to examine the fire behavior predicted by quic fire to published topographically influenced fire scenarios that have been simulated using higher fidelity models thus to test how responsive the current version of quic fire is to multiple idealized topographies and winds ten simulations were carried out to compare to firetec simulations described in linn et al 2007 4 1 description of the simulation domains the extent of the domain in the simulations is 640 m 320 m 700 m with a horizontal grid spacing of 2 m in x and y the quic urb grid was a stretched vertical grid with a spacing of 1 5 m near the ground and growing to 200 m at the top of the domain the fuel grid vertical resolution is 1 m over the entire horizontal extent of the domain and defined from the ground to the top of the canopy the statistical properties of the tree distributions are the same as in the previous firetec based study linn et al 2007 meaning the placement of the individual trees are not the same in the two sets of simulations but the overall forest fuel distribution was captured the fuel setup consists of one region of homogeneous grass 0 7 m tall with a fuel load of 0 7 kg m 2 and another region where the vegetation resembles a ponderosa pine forest with inhomogeneous grass and litter surface fuels these two regions transition across a line tilted at 45 to the ambient wind fig 4 the fuel bed was generated using the same methodology used in linn et al 2007 and described in linn et al 2005 the pine forest section uses over 8000 ponderosa pine trees where the discrete fuel elements used to model trees are based on data collected by the usda forest service rocky mountain research station and northern arizona university as part of the joint fire sciences program fire and fire surrogate treatment project the canopy bulk density over the forested area is 0 12 kgm 3 with an average tree height of 13 8 m minimum of 7 3 m maximum of 19 9 m and an average height to live crown of 8 7 m minimum of 3 9 m maximum of 13 4 m the moisture fraction of the grass fuel bed is 0 05 kg water mass kg dry fuel mass and the canopy moisture fraction is 0 80 of the dry fuel mass linn et al 2007 a 60 m long and 8 m wide fireline was ignited instantaneously 300 m from the upstream domain boundary such that it is split length wise at the interface between the forested and un forested fuel regions the wind is oriented in the direction of the positive x axis so that the fire will be blown into the forested area the background wind flow for the quic fire runs are generated via the process described in robinson et al 2023 where a background logarithmic profile is set throughout the domain and then mass conservation is enforced to account for terrain effects the topographies consist of a flat topography that will be referred to as the flat case the remaining topographies are all unique but share a common centerline downwind of the ignition line along the y 160 m transect with a common centerline these topographies share the same elevation gradient along the center allowing for studying effects of variations in the topography in the lateral and upwind directions the four non flat topographies share the same base topography elevation b a s e which provides the shared centerline profile b a s e 55 40 tan 1 x 300 140 60 where x is downwind direction and it propagates to all crosswind coordinates this topography is labeled as hill in table 1 the change in elevation from the ignition line x 320 m and outlet of the domain at x 640 m is 106 m the other topographies explicit functions provided in table 1 are modulated forms of the hill topography the canyon topography introduces a mirror of the hill in the upwind direction this results in a canyon that is perpendicular to the background wind direction with an inlet height of 103 m the upcan upward canyon topography modifies the topography by increasing the height of the hill symmetrically with distance from the centerline while leaving the centerline profile unmodified the elevation of the upcan case rises to 211 m at the y edges of the domain for the ridge topography the modification that is added to the base topography to generate the upcan case is instead subtracted from the base topography this generates downward slopes in the lateral directions where elevations drop to 1 m at the y edges of the domain to generate background winds like those used in linn et al 2007 similar boundary conditions on the x and y boundaries needed to be enforced in quic fire the wind fields used in linn et al 2007 were ramped up over 12 s of simulation time from no wind to 6 or 12 ms 1 while nudging the winds at the boundaries to the background values this resulted in an inlet with a wind profile with similar values of the specified wind speed in the x direction and no flow through the y boundaries to attain a similar background wind with quic fire homogeneous neumann boundary conditions were enforced across the inlet interface x 0 and lateral interfaces y 0 and y 320 m this keeps the wind profile at the inlet interface static and velocities at the lateral interfaces in line with the boundary edges where slopes in the y direction are zero hill and canyon cases in cases where slopes in the y direction are not zero at the domain boundaries upcan and ridge cases the boundary condition does not require winds to being aligned with the x direction the wind solutions generated at the boundaries are easiest to understand by substituting the boundary conditions into the velocity update equations from robinson et al 2023 rearranging and looking at the two limiting cases δ v h x h y δ u η 2 h y 2 at z 0 and δ v 0 at top of domain where z 0 corresponds to the terrain surface δ u and δ v are the adjustments made to the initial wind field for mass conservation h x and h y are partial derivatives of the terrain elevation h in the x and y directions and η is a weighting parameter that equals one when generating background winds given that quic fire generates speed up of winds as they are pushed up hill δ u 0 for inflow from y 0 m this boundary facilitates the channeling of winds from the boundary seen in the upcan case background wind fields table 1 the outlet x 640 m is an open boundary the same naming convention for test cases was adopted from linn et al 2007 to make comparison easier for example a case where a 6 ms 1 background wind is imposed in input to the hill topography will be referred to as the hill6 case this convention will be used for the remainder of the paper 5 results and discussion 5 1 fire spread rates figs 5 6 7 8 and 9 show fire shape of firetec and quic fire for the 6 ms 1 and 12 ms 1 simulations propagation distances in the x direction ambient wind direction are shown in fig 10 where the distance is measured in the horizontal x direction instead of along the terrain surface to make comparison between cases easier the extent of the fire was determined by finding the furthest downwind cell that had lost fuel for a given time the computation of the fire propagation distance was stopped once the fire front was within 20 m of the edge of the domain to avoid any edge effects altering results hence results refer to either 100 s or 150 s after ignition depending on the case see captions fig 10 compares the front propagation profiles between firetec and quic fire and demonstrates similar grouping between cases with identical centerline profiles group 1 hill upcan and ridge group 2 flat and canyon for both the 6 and 12 ms 1 cases the grouping is tighter in firetec but the similarity in the fire spread profiles can still be seen for quic fire results arrival times at the downwind edge of the domain are also similar between firetec and quic fire although the ordering of which case arrived first is reversed between the two groups in the quic fire results a trend that is clear between all of the quic fire terrain cases is the acceleration in fire spread once a propagation distance of 100 m is reached the increase in spread rate is due to the fire front reaching the location where the terrain gradient in the downwind direction along the centerline increases substantially this coincides with where background wind speeds begin increasing significantly in the quic fire generated wind fields the flat6 and flat12 cases propagate at a fairly constant rate after the initial forming of the fire front after ignition an interesting feature to point out in figs 5 9 is the similar lack of canopy fuel consumption along the fuel interface just downwind of the ignition line in both firetec and quic fire followed by substantial canopy consumption further downwind there are drastic differences between the propagation rates in the hill and canyon cases in quic fire even though they share identical downwind topographies this shows that the effect of having an upwind topography feature is captured in the quic fire background wind field seen by the slow spread rates at the beginning of the canyon case results a similar slow starting spread is seen for the upcan case in the quic fire results this is due to the quic fire winds at the base of the hill being affected by the much larger elevation height of this case the canyon sides work as a downwind obstruction which retards wind strengths more than in the hill case reducing the strengths of winds where the ignition begins since there are no momentum effects in quic fire generated winds there is no pulling effect generated from the channeled winds at the center of the upcan case that would increase wind strengths along the centerline upwind of the canyon this may be the cause of the earlier increase in spread rates in the firetec results for the upcan case but it is impossible to confirm this as no wind data from the simulations are reported in linn et al 2007 the ridge6 and ridge12 cases show the fastest spread rates in quic fire due to the reduced size of the downwind obstacle seen by the quic fire the cross sectional area of the ridge terrain with respect to the background wind direction is smallest when compared to the other nonzero terrains this leads to stronger winds starting at the base of the ridge as winds are stagnated less from not being obstructed and increase in strength into the upslope region of the domain these differences in wind can be seen by looking at the vectors overlaid on the topographies shown in table 1 quantitative spread rates over three regions for each domain can be seen in table 2 the three spread rate observation regions are located at the base of the upslope portion region 1 across the steepest section of each topography region 2 and at the crest of the centerline where the slope levels off region 3 two clear general and expected trends in the spread rates are that the flat simulations are typically slower than all the other simulations and spread rates increase between the 6 ms 1 and 12 ms 1 simulations the propagation rates for flat quic fire are similar to the firetec results although there are variations in rates for both models even though no terrain is present this is not surprising since fire spread is an non steady process average spread rates for the two sets of results show an average spread rate of 0 8 ms 1 for firetec and 0 9 ms 1 for quic fire in the flat6 case and 1 8 ms 1 for firetec and 1 9 ms 1 for quic fire in the flat12 case averaging helps account for the stochasticity of quic fire and the fine scale perturbations of firetec the similarity between rates shows a good basis point for comparing varying terrain driven behavior between the two codes 5 2 fire spread rates in region 1 region 1 is located 40 70 m downwind of the ignition line in an area at the base of the upslope region for all non flat cases across the cases with topography the canyon and upcan cases show the slowest spread rates in this region due to quic fire generating stagnant winds at the base of the slope for the canyon cases this stagnation is driven by the upwind terrain acting as an obstacle while for the upcan cases the stagnation is driven by the downwind feature being much larger than the other cases in region 1 quic fire spread rates are comparable with those from firetec the quic fire upcan cases show slower spread rates than firetec likely because of flow channeling in firetec as described before the hill and ridge cases show the fastest spread rates in this region for both quic fire and firetec results 5 3 fire spread rates in region 2 region 2 is located 110 160 m downwind of the ignition line where slopes are steepest for all non flat cases for all quic fire cases an increase in spread rates is seen between the region 1 and region 2 results this is increase in spread rate is consistent with the firetec results although these increases and thus resulting region 2 spread rates are significantly lower for quic fire one possible source of this difference is the fact that fire ca does not currently the capture the fine scale slope influences on flame tilt forward heat transfer associated with local entrainment imbalances experiments show that in low to no wind cases flame tilt angle the angle from vertical increases with slope and is correlated with an increase in spread rate and in some cases the flame attaches to the sloped surface weise and biging 1996 dupuy et al 2011 without accounting for this factor which will be accomplished through modifications to fire ca and will be described in subsequent works the forward heat transfer to unburned fuel and thus the influences of steep slopes are underestimated in this region for both the 6 and 12 ms 1 quic fire shows the fastest spread rate for the ridge cases and the slowest for the canyon cases the ridge cases show the fastest spread in this region as quic fire generates faster winds when compared to the other terrains due to the reduced profile of the ridge terrain and thus less blocking effect at the y extents of the domain 5 4 fire spread rates in region 3 region 3 is located 200 280 m downwind of the ignition line where centerline slopes approach zero this region shows an overall trend in non flat cases where quic fire has greater spread rates than the firetec spread rates the firetec rates decrease from region 2 to region 3 is believed to be caused by momentum driven effects creating turbulence and separations in the flow from the surface at the crest of the hill this creates eddies and can even reverse flow near the surface that can stagnate fire spread simpson et al 2013 the current version of quic fire cannot generate these flow separation features this is a focus of future publications in its wind field as there is no conservation of momentum in the solver instead the solver tends to generate increased wind speeds as elevations increase this tendency is evidenced by all non flat quic fire rates from region 3 being greater than their region 2 counterparts 5 5 lateral fire spread fig 11 shows the lateral spread extent to the left and right of the initial ignition line of both firetec and quic fire for the 6 and 12 ms 1 simulations the left and right directions are in reference to the ambient wind direction where left is in the positive y direction and right is in the negative y direction the left distance is calculated by the difference between the burning cell with the greatest y position and the top most cell position of the initial ignition line and the right distance is calculated using the burning cell with the lowest y position and the bottom most cell y position of the initial ignition for example positive values for the left spread represent lateral growth along the left flank of the headfire whereas negative right values show growth along the right flank the two curves for each case in fig 11 show how the width of the burning region is evolving through a simulation lateral spread results show a couple of general trends when comparing quic fire results to firetec results one obvious trend is that firetec shows much greater lateral spread about a factor of two but almost exclusively on the left side one contributing factor to the larger lateral spread in firetec is that firetec resolves a more significant effect of the asymmetrical diagonal fuel interface between the flat grass and forested regions on the wind field where winds at the interface align with the fuel interface this alignment of the winds causes the portion of the initial ignition line to immediately spread laterally in the left direction in firetec while it does not in quic fire also due to the fire consuming the majority of the canopy in these fuels the fire at the left flank is mostly being fed by winds coming from the open grass region unlike the right flank of the fire which always has a forested section obstructing winds upwind of the fire the simplified drag model in quic fire which is also a topic of ongoing improvement is only a local approximation where winds are sped up as fuel is consumed but no effects from downwind or upwind vegetation are realized in the flow fields due to this current way of handling the attenuation of winds by vegetation in quic fire the winds at the interface are not as strongly diverted leftward moreover in quic fire the turbulence approximation is based on a local wind shear calculation which is increased in cells where nearby fuel cells contain consumed and unconsumed canopy fuels this is due to the way fuels are linearly interpolated between the cionco profile and background winds as fuels are depleted linn et al 2020a this causes the stochastic component of an ep s trajectory to be a larger factor in the direction realized leading to more flanking spread occurring on the right side in the quic fire simulations when we look past the effects of the diagonal leading edge of the vegetation the overall trend in lateral spread behavior is similar between quic fire and firetec in the 6 ms 1 results the flat6 and ridge6 have the greatest lateral spread while the canyon6 case shows minimal lateral spread the hill6 and upcan6 fall in between the lack of lateral spread in the canyon6 case is due to the indrafts generated by the buoyant plumes dominating the slower low elevation wind velocities at the base of the canyon drawing in the flanks of the fire and restricting outward spread these plume dominated winds degrade as the fire propagates up the canyon and begins to experience stronger winds where it then broadens slightly this effect can also be seen in the canyon12 results the hill6 and upcan6 cases show less lateral spread in the left direction than the ridge6 and flat6 cases where stronger background winds lessen the indraft dominance seen in the canyon6 case but still appears present slightly less spread than the ridge6 case in the right direction is seen for the hill6 and upcan6 cases and the similarity of results is due to the turbulence drag model interaction described above the 12 ms 1 results for quic fire show a few outliers from the firetec simulations the flat12 lateral spread on the left side is not greater than the ridge12 spread and is also a third of the lateral spread seen in the firetec results however the right spread is similar in extent and profile to the ridge12 right spread this shows that flanking behavior under strong winds is underrepresented by the code and is seen in a majority of the lateral spread results for quic fire when compared firetec results one contributing factor to this lower lateral spread in quic fire when compared to the simulations with firetec is the fact that firetec explicitly represents the interaction between the winds and the forest canopy the lateral components of the variations or turbulence in the wind fields contribute significantly to the lateral spread in firetec simulations however the current canopy representation serves to suppress the wind and turbulence and does not induce as significant of lateral components that might drive the lateral spread the sudden growth seen in the right spread of the hill12 and upcan12 simulations happens when the fire is traversing region 2 this increase may be due to a sudden intensity increase driven by winds strengthening and pushing strong buoyant plumes ahead of the fire promoting rapid fire spread the upcan case also has the added factor that slope gradients tend to the y boundaries promoting fire spread in those directions the canyon12 case shows similar behavior to the canyon6 case where lateral spread restricted by indrafts although some lateral spread occurs at 70 s into the simulation this time coincides with the slowdown in spread rate seen in fig 10 suggesting that the decrease in spread rate due to buoyant plumes not being pushed downwind as suddenly as other cases and restricting fire spread in the downwind direction this promotes flanking spread as turbulent contributions to ep travel direction become comparable to the ambient wind s directional influence table 3 shows average rates of lateral spreads for both firetec and quic fire results the rates shown in this table show the trend discussed above where lateral spread in the left direction is much less in the quic fire results when compared to the firetec results the absence of significant left lateral spread in conjunction with the spread in the right direction being more comparable to the firetec results shows that the solution for the lacking left lateral spread is not a simple scaling of the turbulence a more sophisticated drag model is more likely the remedy for the lacking growth of flanks at the fuel interface 6 conclusions a total of 10 simulations using quic fire were compared to firetec simulation results over identical inhomogeneous topography which had sections of steep slopes and 3d fuels with the same landscape level fuel characteristics these cases were aimed at investigating the influences of topography on fire behavior while also keeping similarities between topographies to separate different terrain effects on fire behavior an idealized hill formed the base topography that the other topographies were derived from the other topographies consisted of the base hill where lateral gradients were increased which resulted in a downwind canyon like feature parallel to the ambient wind direction the base hill with decreased lateral gradients resulting in a ridge and the base hill with an identical base hill reflected about the ignition line creating a canyon oriented perpendicular to the ambient wind direction the modifications made to the base hill kept the centerline profile of the terrains downwind of the ignition identical these topographies formed a variety of topographic features to evaluate the validity of the quic fire wind solver being used in conjunction with the fire ca fire spread algorithm two ambient wind speeds 6 and 12 ms 1 were used to generate background wind fields that show the influence of terrain on these fields results from these simulations were compared with results reported from the more detailed cfd based firetec code by computing the same metrics and looking at effects these topographies had on fire shapes and their growth see fig 12 quic fire showed similar overall fire behavior when compared to firetec results in regard to the narrowing of fire shape in the canyon hill and upcanyon cases and the overall trends in spread rates across all topographies simulated the comparison here is seen as a success as quic fire is competing with a code that is fully physical and taking timesteps that are one hundredth the size further work is needed but quic fire is a needed contribution for simulating wildland fire behavior using readily available computational resources results between quic fire and firetec highlighted three places where the quic fire code could use attention results in fig 10 and table 2 show that quic fire has similar average spread rates to firetec but does not capture some of the nuances seen in the firetec results specifically spread rates in quic fire results tend to show less sensitivity to the position on the topography compared to the firetec results which show more obvious increases and decreases to spread rates depending on local slope and non local wind effects quic fire showed slower spread rates compared to firetec results in the region of these topographies with the strongest terrain gradients which could be helped by making modifications to the flame angle portion of the fire ca algorithm improving the way quic fire is accounting for the way the flame is tilting due to local topography influenced wind conditions and its orientation with respect to the terrain surface can have substantial effects on fire behavior on varying slopes and wind conditions weise and biging 1996 anon 2001 fire ca does account for tilt angle but bifurcates the behavior between lofting and traveling along the surface the purpose of this paper s comparison to firetec was to examine the influence of the terrain following wind on quic fires fire spread so flame tilt modifications to fire ca were not implemented but are planned for subsequent publications another shortcoming observed in the results was the continued fast fire spread as the slopes reduced near the top of the hill compared with the retardation of fire spread seen in firetec near the top of the hill when the slopes diminished and the flow began to separate this is mostly driven by momentum effects in the wind field as the flow separates from the surface and creates eddies and recirculations that tend to stagnate fire behavior as winds in these regions can reverse direction from the ambient wind quic fire has no incorporation of momentum in its wind field solutions so in its current state it is impossible to capture these dynamics work is planned to map the wake eddy parameterizations from pardyjak and brown 2003 designed for urban environments to the quic fire solver to capture this behavior the last place where quic fire did not capture fire dynamics ideally was in flanking fire behavior the firetec results showed that winds near the fuel interface between grass and forested regions aligned with the interface promoting fire growth at the left flank of the fire the current drag model implemented in quic fire is a local approximation and includes no information from the upwind and downwind directions updating the drag model to incorporate this nonlocal information would help fire ca fire behavior at these fuel interfaces and also change dynamics when fuel upwind of a burning cell has already been consumed increasing incoming wind speeds and increasing fire intensity these changes require careful thought in implementation due to the desire to retain the computational speed of quic fire and may require novel solutions the results from quic fire reported in this manuscript on average were computed in about half of the real time simulated declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments research presented in this article was supported by the laboratory directed research and development program of los alamos national laboratory lanl under project number 20220024dr as well a funds share with lanl by usda forest service southern research station and rocky mountain research station united states under interagency agreements images from linn et al 2007 shown in figs 5 through 11 were used with permission of csiro publishing from coupled influences of topography and wind on wildland fire behaviour rodman linn et al international journal of wildland fire 16 2 2007 permission conveyed through copyright clearance center inc 
25380,in this manuscript we describe the implementation of the terrain following version of quic urb into quic fire and a demonstration of the impacts of terrain influenced winds on quic fire simulated fire spread no changes to the underlying quic fire fire spread algorithm were made other than what was required to correctly account for the inclusion of terrain this paper summarizes simulations used to understand how the quic urb terrain influenced winds affect upslope fire behavior without additional changes to the quic fire fire spread algorithm previously published firetec results are compared to simulation results from the modified quic fire incorporating terrain influenced winds that use the same topographies and fuels quic fire results showed overall similar behaviors in terms of how the topographies affected fire shapes and trends in spread rates due to the terrain following version of quic urb being unable to generate flow separations at the crest of hills fire spread rates in these regions across all non flat topographies were over predicted when compared to firetec lateral fire growth showed similar trends with firetec between topographies but did not capture the increase in spread due to a diagonal interface between grassland and forested fuel regions in the test domain these simulations suggest possible refinements that are necessary to improve quic fire and thus guide ongoing efforts related to how flame tilt angle is accounted for the incorporation of non local drag effects and the inclusion of the wake eddy parameterizations that are used in quic urb keywords terrain influenced flow terrain following wind solver fast running fire model quic fire firetec data availability data will be made available on request 1 introduction topography can significantly influence wind flows and affect the propagation and behavior of wildland fires linn et al 2010 sharples et al 2012 in particular topography influences wind flow dynamics through mechanisms occurring at a wide range of length and time scales serafin et al 2018 that can be a key component to the spread behavior of a fire topography impacts not only fire behavior but also the fate and transport of smoke as it rises above the fire and is transported downwind accounting for terrain induced effects on winds and thus fire and smoke behavior is an important aspect of predictive fire and smoke modeling in complex terrain solving the full navier stokes equations to capture the dynamic and heterogeneous influences of terrain on winds is one approach to resolve the flow at scales of both the topographic features and fireline this is done in models such as firetec linn and cunningham 2005 and wfds mell et al 2013 another technique is to parameterize the fine scale impacts of topography on fire spread using empirical fire spread models and capture the topographic influences on the larger scales winds using large eddy simulation les tools such as in cawfe coen 2013 wrf sfire mandel et al 2011 and wrf fire coen et al 2013 for real time forecast modeling models like firetec and wfds are currently too computationally time intensive the coupled empirical spread les based tools use simplified fire spread models and too coarse of vegetation variability limiting their generality and applicability for fire scenarios that lack large scale drivers for instance prescribed fires depend on the interaction between multiple firelines and can be heavily influenced by the heterogeneity of the vegetation les empirical spread based tools do not resolve the fine scale processes and three dimensional fuel structure required to capture these dynamics the development of quic fire linn et al 2020a was intended to provide an alternative to computational fluid dynamics cfd based tools that would be much more computationally efficient while still representing some of the most important processes or phenomena and three dimensional structure of the fuel at the fireline scale i e meter scale however the wind solver in the original prototype version of quic fire linn et al 2020a did not account for the influences of topography due to the 2020 version of quic fire s wind solver the quick urban industrial complex quic urb solver not including the influences of terrain on either the winds or the fire behavior in robinson et al 2023 the initial work is described that enables the background ambient wind fields to reflect many of the influences of topography in quic urb wind fields this effort set the stage for quic fire to be extended to capture the influences of topography on fire behavior the complex terrain capable extended version of quic fire described in this paper leverages the terrain following version of quic urb presented in robinson et al 2023 this version of quic urb is a diagnostic wind model that produces mass consistent wind fields the advantages of a diagnostic wind solver approach over prognostic models is their speed and minimal memory requirements for instance quic urb can generate wind fields for complex environments in less than 1 min with a common laptop not requiring super computing capabilities for calculation the disadvantage is that standard quic urb simulations treat winds as quasi steady state solutions to current forcing conditions and thus implicitly assume that wind fields are in equilibrium this means it cannot capture some of the effects of strong transients or unsteady aspects of the flow since 2015 quic urb has been dynamically integrated with a fire model fire ca with a focus on modeling prescribed fire resulting in the model quic fire linn et al 2020a williams et al 2004 therefore the addition of quic urb s complex terrain capability robinson et al 2023 has opened the door for quic fire to be extended to complex terrain as well it should be highlighted that the fire component in quic fire was designed to depend on the fire influenced local wind field that reflects the combined effects of the quasi steady state winds of quic urb and evolving fire induced modifications to the wind field the winds in quic urb are initialized based on measurements or user values at one or more locations within the computational domain the vertical profile can follow a power law or a log law or alternatively a set of wind values at multiple heights can be provided the mesoscale weather research and forecasting model wrf outputs usually at 1 5 km horizontal resolution can also be ingested kochanski et al 2015 nelson et al 2016 carvalho et al 2012 quic urb interpolates the provided wind measurements or wrf outputs over its domain using the barnes scheme powers et al 2017 then the localized impacts of vegetative canopies and buildings are parameterized and superimposed over the background wind linn et al 2020a and finally mass consistency is imposed wind measurements at different times can be provided to follow the temporal variation of the background wind field the resulting wind field is time wise smoothed typical domain sizes range from hundreds of meters to 100 kilometers at horizontal resolutions typically varying from 1 200 m singh et al 2008 in this manuscript we will discuss the 1 coupling of a terrain following version of quic urb to fire ca and 2 the implications of using terrain influenced winds to drive upslope wildland fire spread with essentially the preexisting fire spread algorithm in quic fire the changes to fire ca were limited only to what is necessary to correctly include the complex terrain version of quic urb this is a first step in accounting for the effects terrain has on a propagating fire through this study which avoids changes to the fire ca model we are able isolate the effects of resolved terrain driven winds on fire behavior and isolate the driver of changing fire behavior between quic fire versions this also allows us to identify dynamics that this version is currently not capturing to focus ongoing model refinement efforts we describe the extent of the new capabilities modifications required to integrate the terrain following version of quic urb and discuss some of the shortcomings of this extension as it is currently formulated we provide demonstration of some of the current capabilities through comparison against published simulations using higrad firetec in the following when referring to quic fire we are considering the new version with the terrain following winds and the modified fire spreading algorithms to account for terrain 2 quic fire overview quic fire was specifically designed to be able to be to simulate a wide range of wildland fire scenarios including prescribed fire without requiring extensive computational resources while still capturing the coupled fire atmosphere interactions necessary for accurately predicting fire behavior quic fire achieves this coupling by linking the fast running quic urb wind field solver to the fire ca fire spread algorithm quic urb was adapted to incorporate buoyant updrafts generated from the energy release of combusting fuel which is calculated by fire ca by enforcing mass consistency on a background wind field perturbed by these buoyant updrafts quic urb generates indrafts close to the fireline thus allowing the fire ca algorithm to account for buoyancy induced entrainment this two way coupling forms the basis of the fire spread dynamics captured by the quic fire model it is important to highlight the differences in methodologies between quic fire and a full physics model like firetec firetec resolves wind flow directly at fireline scales by solving the full navier stokes equations and models the combustion of fuels by tracking temperature and chemistry of an evolving fire quic fire models the propagation of fire by discretizing the amount of energy released by combusting fuel into energy packets eps the generated eps are transported based on local fire modified winds fire intensity approximations and stochastic modifications via turbulence approximations that are based on calculated wind shear around each cell the eps can contribute to the drying of fuel the combustion of dried fuel and if they do not land on fuel the generation of buoyant updrafts the regions of dried burning and depleted fuels within each cell are tracked and oxygen availability is approximated based on local conditions the details of the coupling and explicit equations of quic fire can be found in linn et al 2020b both quic fire and firetec are full 3d simulations that are sensitive to both vertical and horizontal fuel heterogeneity the 3d fuel grid allows for these models to track when a fire transitions from surface fire to a crown fire and the mechanisms for which that happens whether it be due to ladder fuels or high surface loading 3 effect of topography on winds and fire spread changes implemented to the fire ca algorithm were limited to those required to correctly incorporate the wind fields generated by terrain following version of quic urb to investigate how terrain influenced winds change the fire behavior of the fire ca algorithm this involved implementing the successive over relaxation sor solver to work on a terrain following grid choosing a fuel grid geometry and accounting for terrain induced flow on the transport of the buoyant updrafts 3 1 terrain influenced winds the first step was to generate terrain influenced background winds which is a crucial component to predicting fire behavior on a landscape characterized by topographical features terrain can cause complex three dimensional patterns including channeling in canyons and valleys and flow blocking or diverting uchida and sugitani 2020 serafin et al 2018 which can have nonlocal influences on wind fields these terrain induced wind patterns have been shown to drive drastic changes in fire behavior that terrain slope cannot account for alone sharples et al 2012 close 2005 to incorporate terrain induced winds while also retaining the low computational cost of quic fire it was decided to modify the original cartesian grid of quic urb into a terrain following coordinate system to capture the wind gradients close to the ground with a fine grid resolution meter scale and allow for grid stretching as one moves higher in the atmosphere where less pronounced changes in wind speed and direction are expected a detailed description of that effort can be found in robinson et al 2023 in its current state quic urb wind fields do not contain momentum effects e g separations or thermodynamically driven effects e g drainage flows but future work is planned to address these shortcomings in robinson et al 2023 it can be seen that this effort allowed capturing terrain induced effects like wind speed up over terrain features and stagnation points at the base of large features hence it can be useful to analyze fire spread over varying terrain configurations and wind conditions where separations and drainage flows are not expected to be significant factors 3 2 fire ca grid for terrain effects while wind gradients tend to become more smooth as one moves upwards in the atmosphere allowing for a terrain following stretched grid the importance of the three dimensional fuel structure and its gradients remain from the surface to the top of the canopy it was therefore decided to use a draped grid to capture the vertical fuel structure in which the height of cells in the fuel grid do not stretch with the varying elevation of a topography the draped fuel grid has the advantage of simplifying the computation of the fate and transport of energy in fire ca and generation of 3d fuels inputs as fuel voxels can be generated while only considering height above ground unfortunately a consequence of this choice is that a non trivial interpolation needs to be carried out between the terrain following wind grid and the draped fuel grid each time step as the deformation of the wind grid is dependent on the terrain height at each cell position see fig 1 this is necessary as the fire ca algorithm requires the local wind speed in each cell to calculate fire spread energy that is released by the combustion process in quic fire is carried either upward by strong updrafts or parallel to the surface based on the local fire influenced wind fields at the terrain surface to separate the proportion of eps that are carried vertically by updrafts versus being transported parallel to the surface the local wind velocity v u v w is transformed into a component parallel to the local slope v and a perpendicular component v such that v v 0 the vectors v and v are then projected onto the local slope vectors in the x and y directions respectively resulting in the surface winds 1 v h x u h x w 1 h x 2 2 v h y v h y w 1 h y 2 3 v w h x u h y v 1 h x 2 h y 2 where h x and h y are local terrain derivatives in the x and y direction respectively the ratio of v over v determines the chance that an ep will separate from the surface and travel upward into midstory and canopy fuel cells a schematic of this decomposition can be seen in fig 2 these decomposed winds also define the length scale that the eps travel over another adjustment to account for the draped grid and horizontally launched eps is to multiply the resulting ep travel distance from the fire ca algorithm by cos θ where θ is the local elevation angle of the fuel cell in the direction the ep is traveling this is done as distances traveled in the fuel grid are not calculated by integrating along the terrain surface 3 3 buoyant plume transport in complex terrain the buoyant plume model in the original quic fire considered only flat terrain the horizontal motion of the plumes in the model is governed by background wind whereas the vertical loft and lateral expansion are parameterized with the briggs theory davidson 1989 the implementation of this is done by recalculating the plume radius and centerline updraft at each point on the trajectory however this model is derived for a plume traveling over a flat surface and vertical background wind was not considered the quic fire plume rise scheme was modified to account for the topographically influenced background winds where plumes are now advected vertically with the background winds vertical component in addition to following the briggs trajectory this was motivated by simulations carried out with firetec in order to analyze the buoyancy induced flow without the complications of a moving fire we used a modified version of firetec where the fuel combustion routines were disabled and a constant heat source of 2000 kwm 1 could be placed across a single cell the constant heat source raises the temperature of surrounding air and generates a buoyant plume and emulates a cell emitting constant heat or releasing constant eps to the atmosphere two firetec simulations one with flat terrain and another with a prominent hill with the same logarithmic wind profile for initialization were used to compare the influence of a downwind obstruction on plume trajectories quic fire was also modified in the same way with the same heat source in a single cell fig 3 shows results from these simulations and results in fig 3 comparisons between firetec simulations a b and d e illustrate that the plumes are transported vertically with the background wind field when comparing trajectories between plumes when comparing b c and e f the modification of advecting plume segments vertically with the background wind in quic fire results in similar plume profiles as the full cfd code firetec quic fire results underestimate the upward boundary of the plume but capture the intensity of the updraft at the ground where most of the fire activity occurs 4 comparison of firetec and quic fire on ideal terrain configurations due to the complexity of measuring all variables involved in a propagating fire front 3d fuel loads local wind conditions fuel moisture temporal evolution of fire intensity heat released to the atmosphere it is difficult to adequately characterize real world fire scenarios to fully understand the abilities of a coupled fire atmosphere fire model like quic fire to capture the influences of topography on fire spread one alternative is to examine the fire behavior predicted by quic fire to published topographically influenced fire scenarios that have been simulated using higher fidelity models thus to test how responsive the current version of quic fire is to multiple idealized topographies and winds ten simulations were carried out to compare to firetec simulations described in linn et al 2007 4 1 description of the simulation domains the extent of the domain in the simulations is 640 m 320 m 700 m with a horizontal grid spacing of 2 m in x and y the quic urb grid was a stretched vertical grid with a spacing of 1 5 m near the ground and growing to 200 m at the top of the domain the fuel grid vertical resolution is 1 m over the entire horizontal extent of the domain and defined from the ground to the top of the canopy the statistical properties of the tree distributions are the same as in the previous firetec based study linn et al 2007 meaning the placement of the individual trees are not the same in the two sets of simulations but the overall forest fuel distribution was captured the fuel setup consists of one region of homogeneous grass 0 7 m tall with a fuel load of 0 7 kg m 2 and another region where the vegetation resembles a ponderosa pine forest with inhomogeneous grass and litter surface fuels these two regions transition across a line tilted at 45 to the ambient wind fig 4 the fuel bed was generated using the same methodology used in linn et al 2007 and described in linn et al 2005 the pine forest section uses over 8000 ponderosa pine trees where the discrete fuel elements used to model trees are based on data collected by the usda forest service rocky mountain research station and northern arizona university as part of the joint fire sciences program fire and fire surrogate treatment project the canopy bulk density over the forested area is 0 12 kgm 3 with an average tree height of 13 8 m minimum of 7 3 m maximum of 19 9 m and an average height to live crown of 8 7 m minimum of 3 9 m maximum of 13 4 m the moisture fraction of the grass fuel bed is 0 05 kg water mass kg dry fuel mass and the canopy moisture fraction is 0 80 of the dry fuel mass linn et al 2007 a 60 m long and 8 m wide fireline was ignited instantaneously 300 m from the upstream domain boundary such that it is split length wise at the interface between the forested and un forested fuel regions the wind is oriented in the direction of the positive x axis so that the fire will be blown into the forested area the background wind flow for the quic fire runs are generated via the process described in robinson et al 2023 where a background logarithmic profile is set throughout the domain and then mass conservation is enforced to account for terrain effects the topographies consist of a flat topography that will be referred to as the flat case the remaining topographies are all unique but share a common centerline downwind of the ignition line along the y 160 m transect with a common centerline these topographies share the same elevation gradient along the center allowing for studying effects of variations in the topography in the lateral and upwind directions the four non flat topographies share the same base topography elevation b a s e which provides the shared centerline profile b a s e 55 40 tan 1 x 300 140 60 where x is downwind direction and it propagates to all crosswind coordinates this topography is labeled as hill in table 1 the change in elevation from the ignition line x 320 m and outlet of the domain at x 640 m is 106 m the other topographies explicit functions provided in table 1 are modulated forms of the hill topography the canyon topography introduces a mirror of the hill in the upwind direction this results in a canyon that is perpendicular to the background wind direction with an inlet height of 103 m the upcan upward canyon topography modifies the topography by increasing the height of the hill symmetrically with distance from the centerline while leaving the centerline profile unmodified the elevation of the upcan case rises to 211 m at the y edges of the domain for the ridge topography the modification that is added to the base topography to generate the upcan case is instead subtracted from the base topography this generates downward slopes in the lateral directions where elevations drop to 1 m at the y edges of the domain to generate background winds like those used in linn et al 2007 similar boundary conditions on the x and y boundaries needed to be enforced in quic fire the wind fields used in linn et al 2007 were ramped up over 12 s of simulation time from no wind to 6 or 12 ms 1 while nudging the winds at the boundaries to the background values this resulted in an inlet with a wind profile with similar values of the specified wind speed in the x direction and no flow through the y boundaries to attain a similar background wind with quic fire homogeneous neumann boundary conditions were enforced across the inlet interface x 0 and lateral interfaces y 0 and y 320 m this keeps the wind profile at the inlet interface static and velocities at the lateral interfaces in line with the boundary edges where slopes in the y direction are zero hill and canyon cases in cases where slopes in the y direction are not zero at the domain boundaries upcan and ridge cases the boundary condition does not require winds to being aligned with the x direction the wind solutions generated at the boundaries are easiest to understand by substituting the boundary conditions into the velocity update equations from robinson et al 2023 rearranging and looking at the two limiting cases δ v h x h y δ u η 2 h y 2 at z 0 and δ v 0 at top of domain where z 0 corresponds to the terrain surface δ u and δ v are the adjustments made to the initial wind field for mass conservation h x and h y are partial derivatives of the terrain elevation h in the x and y directions and η is a weighting parameter that equals one when generating background winds given that quic fire generates speed up of winds as they are pushed up hill δ u 0 for inflow from y 0 m this boundary facilitates the channeling of winds from the boundary seen in the upcan case background wind fields table 1 the outlet x 640 m is an open boundary the same naming convention for test cases was adopted from linn et al 2007 to make comparison easier for example a case where a 6 ms 1 background wind is imposed in input to the hill topography will be referred to as the hill6 case this convention will be used for the remainder of the paper 5 results and discussion 5 1 fire spread rates figs 5 6 7 8 and 9 show fire shape of firetec and quic fire for the 6 ms 1 and 12 ms 1 simulations propagation distances in the x direction ambient wind direction are shown in fig 10 where the distance is measured in the horizontal x direction instead of along the terrain surface to make comparison between cases easier the extent of the fire was determined by finding the furthest downwind cell that had lost fuel for a given time the computation of the fire propagation distance was stopped once the fire front was within 20 m of the edge of the domain to avoid any edge effects altering results hence results refer to either 100 s or 150 s after ignition depending on the case see captions fig 10 compares the front propagation profiles between firetec and quic fire and demonstrates similar grouping between cases with identical centerline profiles group 1 hill upcan and ridge group 2 flat and canyon for both the 6 and 12 ms 1 cases the grouping is tighter in firetec but the similarity in the fire spread profiles can still be seen for quic fire results arrival times at the downwind edge of the domain are also similar between firetec and quic fire although the ordering of which case arrived first is reversed between the two groups in the quic fire results a trend that is clear between all of the quic fire terrain cases is the acceleration in fire spread once a propagation distance of 100 m is reached the increase in spread rate is due to the fire front reaching the location where the terrain gradient in the downwind direction along the centerline increases substantially this coincides with where background wind speeds begin increasing significantly in the quic fire generated wind fields the flat6 and flat12 cases propagate at a fairly constant rate after the initial forming of the fire front after ignition an interesting feature to point out in figs 5 9 is the similar lack of canopy fuel consumption along the fuel interface just downwind of the ignition line in both firetec and quic fire followed by substantial canopy consumption further downwind there are drastic differences between the propagation rates in the hill and canyon cases in quic fire even though they share identical downwind topographies this shows that the effect of having an upwind topography feature is captured in the quic fire background wind field seen by the slow spread rates at the beginning of the canyon case results a similar slow starting spread is seen for the upcan case in the quic fire results this is due to the quic fire winds at the base of the hill being affected by the much larger elevation height of this case the canyon sides work as a downwind obstruction which retards wind strengths more than in the hill case reducing the strengths of winds where the ignition begins since there are no momentum effects in quic fire generated winds there is no pulling effect generated from the channeled winds at the center of the upcan case that would increase wind strengths along the centerline upwind of the canyon this may be the cause of the earlier increase in spread rates in the firetec results for the upcan case but it is impossible to confirm this as no wind data from the simulations are reported in linn et al 2007 the ridge6 and ridge12 cases show the fastest spread rates in quic fire due to the reduced size of the downwind obstacle seen by the quic fire the cross sectional area of the ridge terrain with respect to the background wind direction is smallest when compared to the other nonzero terrains this leads to stronger winds starting at the base of the ridge as winds are stagnated less from not being obstructed and increase in strength into the upslope region of the domain these differences in wind can be seen by looking at the vectors overlaid on the topographies shown in table 1 quantitative spread rates over three regions for each domain can be seen in table 2 the three spread rate observation regions are located at the base of the upslope portion region 1 across the steepest section of each topography region 2 and at the crest of the centerline where the slope levels off region 3 two clear general and expected trends in the spread rates are that the flat simulations are typically slower than all the other simulations and spread rates increase between the 6 ms 1 and 12 ms 1 simulations the propagation rates for flat quic fire are similar to the firetec results although there are variations in rates for both models even though no terrain is present this is not surprising since fire spread is an non steady process average spread rates for the two sets of results show an average spread rate of 0 8 ms 1 for firetec and 0 9 ms 1 for quic fire in the flat6 case and 1 8 ms 1 for firetec and 1 9 ms 1 for quic fire in the flat12 case averaging helps account for the stochasticity of quic fire and the fine scale perturbations of firetec the similarity between rates shows a good basis point for comparing varying terrain driven behavior between the two codes 5 2 fire spread rates in region 1 region 1 is located 40 70 m downwind of the ignition line in an area at the base of the upslope region for all non flat cases across the cases with topography the canyon and upcan cases show the slowest spread rates in this region due to quic fire generating stagnant winds at the base of the slope for the canyon cases this stagnation is driven by the upwind terrain acting as an obstacle while for the upcan cases the stagnation is driven by the downwind feature being much larger than the other cases in region 1 quic fire spread rates are comparable with those from firetec the quic fire upcan cases show slower spread rates than firetec likely because of flow channeling in firetec as described before the hill and ridge cases show the fastest spread rates in this region for both quic fire and firetec results 5 3 fire spread rates in region 2 region 2 is located 110 160 m downwind of the ignition line where slopes are steepest for all non flat cases for all quic fire cases an increase in spread rates is seen between the region 1 and region 2 results this is increase in spread rate is consistent with the firetec results although these increases and thus resulting region 2 spread rates are significantly lower for quic fire one possible source of this difference is the fact that fire ca does not currently the capture the fine scale slope influences on flame tilt forward heat transfer associated with local entrainment imbalances experiments show that in low to no wind cases flame tilt angle the angle from vertical increases with slope and is correlated with an increase in spread rate and in some cases the flame attaches to the sloped surface weise and biging 1996 dupuy et al 2011 without accounting for this factor which will be accomplished through modifications to fire ca and will be described in subsequent works the forward heat transfer to unburned fuel and thus the influences of steep slopes are underestimated in this region for both the 6 and 12 ms 1 quic fire shows the fastest spread rate for the ridge cases and the slowest for the canyon cases the ridge cases show the fastest spread in this region as quic fire generates faster winds when compared to the other terrains due to the reduced profile of the ridge terrain and thus less blocking effect at the y extents of the domain 5 4 fire spread rates in region 3 region 3 is located 200 280 m downwind of the ignition line where centerline slopes approach zero this region shows an overall trend in non flat cases where quic fire has greater spread rates than the firetec spread rates the firetec rates decrease from region 2 to region 3 is believed to be caused by momentum driven effects creating turbulence and separations in the flow from the surface at the crest of the hill this creates eddies and can even reverse flow near the surface that can stagnate fire spread simpson et al 2013 the current version of quic fire cannot generate these flow separation features this is a focus of future publications in its wind field as there is no conservation of momentum in the solver instead the solver tends to generate increased wind speeds as elevations increase this tendency is evidenced by all non flat quic fire rates from region 3 being greater than their region 2 counterparts 5 5 lateral fire spread fig 11 shows the lateral spread extent to the left and right of the initial ignition line of both firetec and quic fire for the 6 and 12 ms 1 simulations the left and right directions are in reference to the ambient wind direction where left is in the positive y direction and right is in the negative y direction the left distance is calculated by the difference between the burning cell with the greatest y position and the top most cell position of the initial ignition line and the right distance is calculated using the burning cell with the lowest y position and the bottom most cell y position of the initial ignition for example positive values for the left spread represent lateral growth along the left flank of the headfire whereas negative right values show growth along the right flank the two curves for each case in fig 11 show how the width of the burning region is evolving through a simulation lateral spread results show a couple of general trends when comparing quic fire results to firetec results one obvious trend is that firetec shows much greater lateral spread about a factor of two but almost exclusively on the left side one contributing factor to the larger lateral spread in firetec is that firetec resolves a more significant effect of the asymmetrical diagonal fuel interface between the flat grass and forested regions on the wind field where winds at the interface align with the fuel interface this alignment of the winds causes the portion of the initial ignition line to immediately spread laterally in the left direction in firetec while it does not in quic fire also due to the fire consuming the majority of the canopy in these fuels the fire at the left flank is mostly being fed by winds coming from the open grass region unlike the right flank of the fire which always has a forested section obstructing winds upwind of the fire the simplified drag model in quic fire which is also a topic of ongoing improvement is only a local approximation where winds are sped up as fuel is consumed but no effects from downwind or upwind vegetation are realized in the flow fields due to this current way of handling the attenuation of winds by vegetation in quic fire the winds at the interface are not as strongly diverted leftward moreover in quic fire the turbulence approximation is based on a local wind shear calculation which is increased in cells where nearby fuel cells contain consumed and unconsumed canopy fuels this is due to the way fuels are linearly interpolated between the cionco profile and background winds as fuels are depleted linn et al 2020a this causes the stochastic component of an ep s trajectory to be a larger factor in the direction realized leading to more flanking spread occurring on the right side in the quic fire simulations when we look past the effects of the diagonal leading edge of the vegetation the overall trend in lateral spread behavior is similar between quic fire and firetec in the 6 ms 1 results the flat6 and ridge6 have the greatest lateral spread while the canyon6 case shows minimal lateral spread the hill6 and upcan6 fall in between the lack of lateral spread in the canyon6 case is due to the indrafts generated by the buoyant plumes dominating the slower low elevation wind velocities at the base of the canyon drawing in the flanks of the fire and restricting outward spread these plume dominated winds degrade as the fire propagates up the canyon and begins to experience stronger winds where it then broadens slightly this effect can also be seen in the canyon12 results the hill6 and upcan6 cases show less lateral spread in the left direction than the ridge6 and flat6 cases where stronger background winds lessen the indraft dominance seen in the canyon6 case but still appears present slightly less spread than the ridge6 case in the right direction is seen for the hill6 and upcan6 cases and the similarity of results is due to the turbulence drag model interaction described above the 12 ms 1 results for quic fire show a few outliers from the firetec simulations the flat12 lateral spread on the left side is not greater than the ridge12 spread and is also a third of the lateral spread seen in the firetec results however the right spread is similar in extent and profile to the ridge12 right spread this shows that flanking behavior under strong winds is underrepresented by the code and is seen in a majority of the lateral spread results for quic fire when compared firetec results one contributing factor to this lower lateral spread in quic fire when compared to the simulations with firetec is the fact that firetec explicitly represents the interaction between the winds and the forest canopy the lateral components of the variations or turbulence in the wind fields contribute significantly to the lateral spread in firetec simulations however the current canopy representation serves to suppress the wind and turbulence and does not induce as significant of lateral components that might drive the lateral spread the sudden growth seen in the right spread of the hill12 and upcan12 simulations happens when the fire is traversing region 2 this increase may be due to a sudden intensity increase driven by winds strengthening and pushing strong buoyant plumes ahead of the fire promoting rapid fire spread the upcan case also has the added factor that slope gradients tend to the y boundaries promoting fire spread in those directions the canyon12 case shows similar behavior to the canyon6 case where lateral spread restricted by indrafts although some lateral spread occurs at 70 s into the simulation this time coincides with the slowdown in spread rate seen in fig 10 suggesting that the decrease in spread rate due to buoyant plumes not being pushed downwind as suddenly as other cases and restricting fire spread in the downwind direction this promotes flanking spread as turbulent contributions to ep travel direction become comparable to the ambient wind s directional influence table 3 shows average rates of lateral spreads for both firetec and quic fire results the rates shown in this table show the trend discussed above where lateral spread in the left direction is much less in the quic fire results when compared to the firetec results the absence of significant left lateral spread in conjunction with the spread in the right direction being more comparable to the firetec results shows that the solution for the lacking left lateral spread is not a simple scaling of the turbulence a more sophisticated drag model is more likely the remedy for the lacking growth of flanks at the fuel interface 6 conclusions a total of 10 simulations using quic fire were compared to firetec simulation results over identical inhomogeneous topography which had sections of steep slopes and 3d fuels with the same landscape level fuel characteristics these cases were aimed at investigating the influences of topography on fire behavior while also keeping similarities between topographies to separate different terrain effects on fire behavior an idealized hill formed the base topography that the other topographies were derived from the other topographies consisted of the base hill where lateral gradients were increased which resulted in a downwind canyon like feature parallel to the ambient wind direction the base hill with decreased lateral gradients resulting in a ridge and the base hill with an identical base hill reflected about the ignition line creating a canyon oriented perpendicular to the ambient wind direction the modifications made to the base hill kept the centerline profile of the terrains downwind of the ignition identical these topographies formed a variety of topographic features to evaluate the validity of the quic fire wind solver being used in conjunction with the fire ca fire spread algorithm two ambient wind speeds 6 and 12 ms 1 were used to generate background wind fields that show the influence of terrain on these fields results from these simulations were compared with results reported from the more detailed cfd based firetec code by computing the same metrics and looking at effects these topographies had on fire shapes and their growth see fig 12 quic fire showed similar overall fire behavior when compared to firetec results in regard to the narrowing of fire shape in the canyon hill and upcanyon cases and the overall trends in spread rates across all topographies simulated the comparison here is seen as a success as quic fire is competing with a code that is fully physical and taking timesteps that are one hundredth the size further work is needed but quic fire is a needed contribution for simulating wildland fire behavior using readily available computational resources results between quic fire and firetec highlighted three places where the quic fire code could use attention results in fig 10 and table 2 show that quic fire has similar average spread rates to firetec but does not capture some of the nuances seen in the firetec results specifically spread rates in quic fire results tend to show less sensitivity to the position on the topography compared to the firetec results which show more obvious increases and decreases to spread rates depending on local slope and non local wind effects quic fire showed slower spread rates compared to firetec results in the region of these topographies with the strongest terrain gradients which could be helped by making modifications to the flame angle portion of the fire ca algorithm improving the way quic fire is accounting for the way the flame is tilting due to local topography influenced wind conditions and its orientation with respect to the terrain surface can have substantial effects on fire behavior on varying slopes and wind conditions weise and biging 1996 anon 2001 fire ca does account for tilt angle but bifurcates the behavior between lofting and traveling along the surface the purpose of this paper s comparison to firetec was to examine the influence of the terrain following wind on quic fires fire spread so flame tilt modifications to fire ca were not implemented but are planned for subsequent publications another shortcoming observed in the results was the continued fast fire spread as the slopes reduced near the top of the hill compared with the retardation of fire spread seen in firetec near the top of the hill when the slopes diminished and the flow began to separate this is mostly driven by momentum effects in the wind field as the flow separates from the surface and creates eddies and recirculations that tend to stagnate fire behavior as winds in these regions can reverse direction from the ambient wind quic fire has no incorporation of momentum in its wind field solutions so in its current state it is impossible to capture these dynamics work is planned to map the wake eddy parameterizations from pardyjak and brown 2003 designed for urban environments to the quic fire solver to capture this behavior the last place where quic fire did not capture fire dynamics ideally was in flanking fire behavior the firetec results showed that winds near the fuel interface between grass and forested regions aligned with the interface promoting fire growth at the left flank of the fire the current drag model implemented in quic fire is a local approximation and includes no information from the upwind and downwind directions updating the drag model to incorporate this nonlocal information would help fire ca fire behavior at these fuel interfaces and also change dynamics when fuel upwind of a burning cell has already been consumed increasing incoming wind speeds and increasing fire intensity these changes require careful thought in implementation due to the desire to retain the computational speed of quic fire and may require novel solutions the results from quic fire reported in this manuscript on average were computed in about half of the real time simulated declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments research presented in this article was supported by the laboratory directed research and development program of los alamos national laboratory lanl under project number 20220024dr as well a funds share with lanl by usda forest service southern research station and rocky mountain research station united states under interagency agreements images from linn et al 2007 shown in figs 5 through 11 were used with permission of csiro publishing from coupled influences of topography and wind on wildland fire behaviour rodman linn et al international journal of wildland fire 16 2 2007 permission conveyed through copyright clearance center inc 
25381,with the increasing application of machine learning ml in hydrometeorology we face the urge to demystify the ml s black box nature because it usually does not provide physically interpretable information to users here we demonstrate multiple post hoc interpretation methods to evaluate feature effects for hydrometeorological prediction these methods were integrated and applied to soil moisture sm as an example and random forest was used to establish a prediction model based on a fluxnet site in haibei china different views of interpretability feature importance shapley values partial dependence plot individual conditional expectation and accumulated local effect were used to investigate how features affect the prediction the result shows that a comprehensive understanding can be achieved of the relationship between predicted sm and affecting variables including lagged sm precipitation and soil temperature thus we advocated integrated interpretation tools to enhance the practicability of ml for hydrologists and other physical scientists a toolbox named explainai is provided keywords interpretability hydrometeorological forecast machine learning feature effects explainable artificial intelligence data availability the data that has been used is confidential 1 introduction hydrometeorological forecast which estimates future catchment conditions based on recent and forecasted meteorological conditions and hydrological observations sene 2015 has gained importance in recent decades due to increasing demand for agricultural economic development and meteorological risk management generally the forecasts include precipitation evapotranspiration runoff and soil moisture sm these factors mutually affect each other and constitute the natural cycle of water the potential applications of hydrometeorological forecast cover the following fields a extreme event forecasting such as flood roux et al 2020 and drought warning sutanto et al 2020 b water usage such as hydropower operations anghileri et al 2019 irrigation giuliani et al 2020 and river basin management georgakakos et al 2014 c climate change impact assessments millán 2014 due to the non linear and chaotic nature of the atmosphere forecasting the hydrometeorological variables is challenging to achieve precise hydrometeorological forecasts many efforts have been made to two groups of model improvement i e process based models and data driven models generally process based models are also referred to as mechanistic models or physical models they are based on the mechanism of the hydrological process which are white box models of high interpretability such as weather research and forecasting model liu et al 2021 and continuous hydrological model sheikh et al 2009 however process based models have some limitations shen 2018 the relatively low accuracy of process based models is the most significant barrier to hydrometeorological forecast moosavi et al 2019 alternatively with the flourishing development of artificial intelligence ai in recent decades data driven models i e machine learning and deep learning can efficiently reduce the errors from the insufficient process based models or land data assimilation systems efficiently dikshit et al 2021 q li et al 2021 used a convolutional neural network cnn and long short term memory lstm to improve the 3 h local precipitation forecast further the lstm network was combined with complex process based and attention based models such as soil and water assessment tools majeske et al 2022 deep learning also has a preferable performance to extreme precipitation davenport and diffenbaugh 2021 ghaith et al 2022 considered a synchronized precipitation module in a cnn lstm model that enhances the accuracy of complex flood forecasting machine learning can also be applied in evapotranspiration prediction enhancing the accuracy in short term forecasts talib et al 2021 moreover many machine learning studies have focused on sm prediction in our previous work we used three data driven methods bayesian linear regression random forest rf and gradient boosting regression tree to predict sm based on the fluxnet site data the best r2 values ranged from 50 to 95 pan et al 2019 deep learning has also achieved high performance in sm prediction for example w li et al 2021 improved daily soil moisture active and passive satellite soil moisture prediction using transfer convolutional lstm learning with the lowest root mean squared error rmse ranging from 0 0239 to 0 0247 for 3 5 and 7 days lead times however machine learning is usually considered as a black box models meaning that it is an end to end method without physically interpretable information to the user although the ai models provide more accurate predictions of hydrometeorological variables their black box nature and their lack of explanation pose practical challenges for establishing data driven models guidotti et al 2019 furthermore judea pearl who received the turing award argued that any pure data driven model should combine with the real world process because reality reflects the processes that generate the data pearl 2021 in addition the bridge between them is explainability and interpretability doshi velez and kim 2017 in general there is a well known trade off between explainability and accuracy in the hydrometeorological field prodhan et al 2022 explainable artificial intelligence xai aims to facilitate communication between ai models and human understandings and to build trust in non transparent models gunning et al 2017 miller 2019 razavi 2021 suggested that acquiring of underlying mechanism of ai models can help us better explain the model behavior summarily explainability and interpretability are crucial for applying machine learning in the policy relevant area of climate and earth science as the models decision making requires explanation the lack of xai is a major drawback in critical decision making processes recently the xai techniques have been applied in many fields such as credit score bücker et al 2021 insurances risk mehdiyev and fettke 2020 health status stiglic et al 2020 vellido 2019 etc with ai techniques advancing in the field of hydrometeorological forecast the demand for xai has also increased mcgovern et al 2019 in the field of practical hydrometeorological forecast lack of explanation would result in the following barriers a because of the lack of specialized knowledge of hydrometeorological processes the result is questionable ebrahimi khusfi et al 2020 b the conventional models only provide a hydrometeorological forecast outcome and the effects of predicting factors should be examined which is significance for preventing drought and flood liu et al 2020 c the model inferred from the data may have inherent biases hidden in the black box schmidt et al 2020 d hydrometeorological variables e g sm precipitation exhibit inevitable spatial temporal heterogeneity implying that different models would perform differently at various times and locations pan et al 2019 numerous techniques have been developed to overcome the interpretability challenge of black box models they can be classified as intrinsically interpretable models interpretable machine learning and post hoc interpretation methods explainable machine learning molnar 2022 typically intrinsically interpretable models are model specific for example a conceptual knowledge based truly transparent model that combines real time machine learning can forecast the flood and manage the flood risk process agresta et al 2014 the model requires a huge amount of inferred knowledge however in hydrometeorology there are still inevitable gaps between prior mechanisms and real word processes the post hoc interpretation methods also called model agnostic methods have gained popularity in earth system science furthermore these methods can help scientists to better incorporate physical knowledge into machine learning i e physics informed machine learning discover new science and assist in theoretical advances irrgang et al 2021 in the future in a quest for achieving true xai an integrated model that merges physical knowledge data and machine learning architecture will provide a more transparent and understandable insight into real world processes in earth system science donalek et al 2014 reichstein et al 2019 after exquisite training the post hoc interpretation methods were expected to meet the interpretability challenge of black box models improving their transparency these methods were classified into importance evaluation and feature effect visualization the methods to evaluate feature importance include permutation feature importance algorithm fisher et al 2018 impurity importance louppe et al 2013 sequential backward selection sbs or sequential forward selection sfs that are related to mean squared error based feature importance mfi and shapely value sv shapley 1953 alternatively the visualization for feature effects was achieved by partial dependence plot pdp friedman 2001 individual conditional expectation ice goldstein et al 2015 and accumulated local effects plot ale apley and zhu 2019 mcgovern et al 2019 applied sbs sfs and pdp in meteorological prediction at different spatio temporal scales and achieved rational interpretations sv was applied to conduct the target sensitivity analysis in a flood model il idrissi et al 2021 however among the above methods each can provide interoperation in specific aspects but neither can explain the prediction model comprehensively to our knowledge no study explored multiple post hoc interpretation methods in hydrometeorological prediction thus this study aims to investigate an integrated post hoc approach to evaluate the feature effect of the hydrometeorological machine learning model here we take the sm prediction as an example in the hydrometeorological forecast to illustrate the integrated post hoc xai tools the reasons we choose sm include a sm is an essential variable in the process of the global hydrological cycle which determines the water and soil resources management surface energy and natural cycle of water kato and nishimura 2016 b sm is very sensitive to many factors like the soil properties e g sand and clay content vegetation especially the meteorological factor including precipitation air temperature topsoil temperature koster et al 2017 thus it is convenient to show the comprehensive relationships between sm and related factors using xai tools noticeably sm generation is a highly nonlinear system which causes difficulty in estimating sm thus in this study several post hoc xai tools were utilized to form an integrated approach that can reveal the interpretability of the sm prediction model from different viewpoints primarily the sm prediction model was established using rf as a demonstrating black box model based on observations from the ha2 site of fluxnet subsequently the integrated xai framework was applied to evaluate the interpretability of sm prediction from the following aspects a mfi to assess the importance of each feature s impact on the sm prediction result b sv to evaluate each feature s contribution to the difference between real time sm prediction and average sm value c pdp and one dimensional 1d ale to reflect how the sm prediction varies with each feature and to show the evolution of feature effects on sm in different periods d ice and derivative ice dice to represent how each feature affects the sm in each event especially in extremes e two dimensional 2d ale to show the interaction effect of two features on sm prediction in this way the integrated post hoc xai approach we proposed can improve the transparency of the black box machine learning models from the following aspects a the tool can help to improve the reliability of the predicted results the prediction can be trusted if relations revealed by the xai tool can correspond to the prior knowledge of hydrometeorological processes thus the reliability and robustness of the model can be improved b the xai tool can provide much evidence i e important factors feature effects to support the prediction which helps to make countermeasures in advance c the inherent bias in data might lead to defeats in the black box model which can be figured out by the xai tool to sum up with the interpretability of ai models brought by the xai tool the application of ai techniques will be promoted this work can contribute to building a more intelligent and accurate hydrometeorological forecast 2 methods in this study in order to illustrate the proposed integrated xai approach applied in hydrometeorological forecast taking sm prediction as an example the framework is shown in fig 1 first we used observations from the fluxnet site named ha2 and the raw data were collected and divided into the predictors features and the target surface sm second the feature selection was carried out including the contrived work and sbs then we trained the rf model and assessed the precision with statistical metrics after the above procedures the essential work was to evaluate the feature effects the shapley values pdp and 1d ale ice and dice 2d ale were embedded in the integrated xai approach 2 1 study site the study used data from haibei national field research station named ha2 qinghai china 37 37 n 101 19 e which is located on the northeastern qinghai tibet plateau at an elevation of 3200 m above sea level ha2 was situated along the datong river tributary a branch of the yellow river close to the upper reaches of the heihe river watershed the site belongs to ecosystem surface classification of permanent wetlands from the international geosphere biosphere programme land with a permanent mixture of water and herbaceous vegetation that covers extensive areas http sites fluxdata org cn ha2 means permanent wetlands the most common land use is shrubland mainly irrigated by the river stream and with limited rainfall as a plateau continental monsoon climate region the place near ha2 has well developed seasonally frozen ground according to the fifth generation of european reanalysis the meteorological factors were provided from 1980 to 2014 hersbach et al 2020 during the 35 year period the average daily long term air temperature shortwave radiation longwave radiation vapor pressure deficit pressure precipitation and wind speed are shown in table 1 the reasons that we chose the ha2 site as a case study are as follows a at this site it is more difficult to predict sm due to the great sm variability under complex hydrological processes in winters the frozen soil can be characterized by unidirectional freezing and bi directional thawing and in summers the increasing precipitation and climbing evaporation can affect the sm in opposite ways moreover the soil is clay loam with high permeability water holding capacity and low heat conductivity yang et al 2014 these characteristics are likely to cause a strong land atmosphere coupling b qinghai tibet plateau is one of the most climate sensitive regions in the globe and the ecosystem is vulnerable and easily affected by the climate change with many natural ecological processes and feedbacks still intact predicting and analyzing soil moisture at ha2 is very important to understand climate induced environmental changes chen et al 2013 2 2 data collection and processing site data were obtained through the fluxnet2015 full set data product fluxnet doi 10 18140 flx 1440211 variables include time variables micrometeorological observation energy processing and net ecosystem exchange their description is given in table 2 the raw data from fluxnet2015 contain 320 variables including information from different quality control protocols the uncertainty of observation and standard deviations we chose timekeeping dd which means the average of half hourly data in a day since soil moisture has a certified with relatively strong time memory and usually has a small diurnal change the dd of timekeeping is appropriate for sm prediction before feature selection the data processing was conducted to ensure the data quality here according to the quality flag of each feature determined by fluxnet details found in pastorello et al 2020 a 3 step data preprocessing scheme was conducted follows i removing the records with missing sm ii deleting features with over 30 missing records and iii deleting low quality data quality flag 1 according to the quality control from fluxnet in addition to the observed variables we used time variables including year and day of year doy as inputs which corresponded to the inter annual change and seasonal cycle of sm pan et al 2019 generally numerous variables would cause massive computation and even leading to the degradation of the machine learning model hence the feature selection should be conducted the feature selection consisted of two steps contrived work and sbs which have been deemed feasible in many fields in the contrived work we eliminated the statistical indicators such as uncertainty standard deviation and quantiles then in sbs to evaluate the importance of each feature the remaining variables were treated as the input of the rf model for training sbs sequentially eliminates features from the complete feature set until the model s predictive accuracy is optimized to a stable level in more intuitive terms at each training time we removed the feature that caused the most negligible performance loss after removal details of the selected variables by sbs are given in section 3 1 2 3 hydrometeorological forecast by black box machine learning hydrometeorological factors generally are known for their high non linearities and complex interactions with the atmosphere in this case the sm is extremely sensitive to the land surface variables in previous research rf was considered a convenient method for describing the complex interactions between sm and land surface variables compared with bayesian linear regression rf also has better performance in predicting sm in the tests from fluxnet sites pan et al 2019 here we predicted sm based on the known conditions i e micrometeorological observation energy processing and net ecosystem exchange for the same day which is a regression task rf algorithm is an ensemble learning method based on decision tree models which integrates multiple trees and obtains the optimal predictions by averaging the results of numerous functioning trees for regression tasks belgiu and drăguţ 2016 rf often passes through three steps to ensure optimal results as follows a the raw data is divided into several parts randomly with parts of features b each part of the data is treated as the input data of a decision tree and each decision tree is applied to provide its optimized result c the result produced by each tree is ensembled and the mean value is deemed as the optimal output the amount of full dataset we used is 1096 daily observations from 2003 to 2005 here we used the first 70 of the time series data set from january 1st 2003 to february 5th 2005 as the training set meanwhile the last 30 of data from february 6th 2005 to december 31st 2005 were used as the testing set taking the computation and precision into account we set the number of decision trees in rf to 100 and the number of nodes to the default 1 3 of the number of features a time stratified selection of training and test sets as used in this work may lead the models to operate in the inference phase outside the features training envelope causing loss of accuracy though significant difference may exist in the training performance and test performance the difference in this study was not significant see section 3 1 furthermore wrapper feature selection schemes may be fooled by this behavior and pointing to eliminate a predictive feature which possible range is not fully covered in the training set thus the time stratified selection of training and test sets may have some effects on the results of xai 2 4 statistical metrics in order to fully evaluate the performance of the rf prediction model the four most popular metrics were used explained variance r2 mean absolute error mae mean squared error mse and rmse the r2 represented the model s ability to capture the non linear variation and the mae quantified the errors between actual data and the predictions from the model similarly the mse and rmse are the two commonly used metrics in most research which can help to compare with other results the statistical metrics are calculated as follows 1 r 2 y y ˆ 1 i 1 n y i y ˆ i 2 i 1 n y i y 2 2 m a e i 1 n y i y ˆ i n 3 m s e i 1 n y i y ˆ i 2 n 4 r m s e i 1 n y i y ˆ i 2 n where y i is the measured value of the i t h sample y ˆ i is the corresponding predicted value n is the sample size and y is the average value of predicted samples 2 5 evaluate feature effects via interpretable visualization interpreting machine learning models is essential for researchers and model developers because many different approaches have been attempted among the different ways to open the black box of machine learning models these approaches have been categorized into two types intrinsic and post hoc interpretability du et al 2019 based on self explanatory models the intrinsic methods can directly reflect the causality of the input features and the output results khoda bakhshi and ahmed 2020 however these methods are model specific which limits the application especially for complicated models such as rf and deep learning models therefore intrinsic methods cannot always work serving as analysis methods independent of the machine learning models from the perspective of the evaluation of feature effects the post hoc interpreting methods can be considered as a practical and refined approach to explaining the prediction models in a post hoc manner yang et al 2019 in this study to investigate the feature effects of the hydrometeorological forecast model we integrated several post hoc interpretability methods into an advanced system here we chose sm prediction as an example to illustrate the system on this point the steps to integrate the utilized interpretability methods are as follows a mfi for tree based model was used to eliminate the redundant features in the feature selection and to sequence the features by statistical mse importance evaluation b sv was applied to assess feature importance with both positive and negative effects c 1d pdp and 1d ale were used to explore the average predicted sm evolution with one feature variation in overall range d ice and dice were used to show the predicted sm evolution of each instance with one feature variation in the overall range e 2d ale visualized the interaction effects of two features on predicted sm a python module named explainai is under development for all the above post hoc interpretability methods for the convenience of hydrometeorological forecast and other widespread applications the source code is also available at https github com huangfeini explainai 2 5 1 mse based feature importance mfi as one of the most pragmatic methods to quantify feature importance the python package scikit learn provides a specified evaluation for rf model note that the r package named randomforest also provides similar functions this method computes the importance by permuting out of bag data first the mse from the prediction model on the out of bag portion of the training data is recorded for each tree next this procedure is repeated for each feature thus the decreased mse compared to the optimal model is treated as the importance of the feature 2 5 2 shapley values similar to mfi for the evaluation of feature importance a sensitivity analysis based explaining method has been invented štrumbelj and kononenko 2013 unlike the mse based feature importance specific for tree based models sv can be applied for prediction models of any type and any subset of data considering all possible interactions and redundancies between features all combinations of features are tested sv method can be applied on any data subset or even a single instance the sv of a feature value x i j is its contribution to the predicted result weighted and summed over all possible feature value combinations 5 φ ˆ i j v a l s x i 1 x i p x i j s p s 1 p v a l s x i j v a l s where s is a subset of the features used in an alliance x i is the vector of feature value of the interest of instance j p donates the number of features and v a l is the prediction for feature values in subset s that are marginalized over features that are not included in subset s the calculation procedures of sv are shown in fig s1 unlike mse based feature importance sv can be negative which indicates a feature s negative effect and vice versa initially this method was derived from coalitional game theory assuming each feature plays a specific role in the game molnar 2022 the features will form different alliances in a game then in each alliance how much a feature contributes to the predicted result is quantified afterward the average of the marginal contributions from different alliances is the sv for this feature notably the shapley value of each feature can be obtained particularly it can be utilized to analyze the typical or extreme events in the hydrometeorological forecast by evaluating feature contribution 2 5 3 partial dependence plot the pdp demonstrates the relationships between the features and the prediction friedman 2001 the pdp for regression is defined as 6 p ˆ x s j x s j 1 n i 1 n f ˆ x s j x c i where x s j is the set of the feature of interest as j th feature for which the partial dependence function should be plotted p ˆ x s j is the partial dependence value of j th feature n is the number of elements in x s and x c is subset of other actual features values pdp estimates the average marginal effect of predictors on the predicted sm which can be a determined value in regression aiming to visualize the feature effects the pdp can be conducted by the following steps fig s2 a the predictors p x 1 x 2 x k x p are divided into two subsets including the feature of interest s x k and other features c x 1 x 2 x k 1 x k 1 x p wherein the s subset involves possible values of x k which can be described as x s x s 1 x s 2 x s j x s m b using each element of x s subset to replace the x k successively is the essential step for pdp in order to find the response feature at a specific given value of x s pdp generates synthetic observations where the values of the feature of interest are permuted by the x s across all actual observations c the trained rf model outputs the predicted sm with a synthetic observation which is the marginal output of the feature of interest called marginal effect then the marginal effect values are obtained by averaging the predicted sm over all the synthetic observations however one assumption made for pdp is that the features in x c are irrelevant with x s that we focused on this assumption leads to the limitation of its application therefore the ale can compensate for this drawback 2 5 4 individual conditional expectation and derivative individual conditional expectation since the pdp only draws the averaged marginal effect of a predictor heterogeneity of the dataset is neglected leading to insufficient insight into different instances to address this ice was proposed by goldstein et al 2015 the ice concept is given by equation 7 7 p ˆ x s j x s j f ˆ x s j x c for a feature of interest ice plots highlight the variation in the fitted values across the covariate range in other words the ice provides the plots of dependence of the predicted response on a feature for each instance separately the calculation procedures of ice are shown in fig s3 similar to pdp keeping all other features constant the partial dependence values for a line or an instance can be computed creating variants of this instance by replacing the feature s value with values in a grid ice repeats this procedure for all the observations therefore via ice plots feature effects on each predicted sm from a black box machine learning model can be illustrated transparently since the ice plot can only demonstrate the feature effects of an instance using individual derivatives of the individual conditional expectation values with respect to the feature of interest dice provides another more distinct visualized approach to further reveal the feature effects from spot heterogeneity goldstein et al 2015 the dice can be expressed by equation 8 8 d p ˆ x s j x s j δ f ˆ x s j x c δ x s j the derivatives of ice can illustrate which direction changes occur or if any occur at all when the derivatives fluctuate to positive values the feature positively affects the predicted sm moreover if there is any scale of feature effect the dice varies fiercely which means that the feature of interest strongly influences the results of dice with the derivative ice plot it is easy to spot value ranges in a feature where the black box s predicted values change for at least some instances 2 5 5 accumulated local effect both pdp and ice however suffer from highly correlated multi dimensional spaces which can lead to unreliable interpretation of prediction models molnar 2022 to fill this gap the ale has been introduced the ale is a more sophisticated method to evaluate the feature effects owing to averaging the differences in the prediction model of the conditional distribution unlike pdp the ale is unbiased and functions even when variables are correlated 1d ale shows the dominant effects with the feature of interest variation 2d ale solely displays the additional effect of an interaction between two features without the main effect of each feature generally hydrometeorological factors always have specific interactions and the 2d ale can estimate the combined effects of each pair of features globally the 1d ale is defined as equation 9 9 f j ˆ x k 1 k j x 1 n j k i x i j n j k f z k j x i j f z k 1 j x i j c where f j ˆ donates the ale values and it visualizes the main effect dependence of modeling on x j x i j x i l l 1 d l j where the subscript j means all feature except the j th similarly n j k z k 1 j z k j k 1 2 k donates a sufficiently fine partition of the sample range of x i j into k intervals and the constant c is chosen so that 1 n i 1 n f j ˆ x 0 the calculation procedures of ale are shown in fig s4 the main idea of the ale is to divide the scales of the feature of interest into k equivalent intervals this division can reduce the interaction of correlated features and effectively avoid the generation of unrealistic synthetic observations apart from these estimating the average values over differences in predictions reflects the pure main effect of feature of interest on predicted sm then based on the separated grids in each grid values of the feature of interest from the grid replace the actual value and the differences of predicted sm values have been estimated thus the ale can be calculated by accumulating the differences among the whole grids and centering the values 3 results 3 1 predicting soil moisture with random forest modeling in this study we aimed to illustrate the integrated xai method for hydrometeorological forecast taking sm prediction as an example rf model was applied as the prediction model before establishing the rf model feature selection was conducted first features were eliminated by manual work and 116 features were left then these 116 features were further selected by the sbs fig 2 shows that r2 changes with the number of features in the sbs the model performance became optimal when the number of features was around 16 thus we chose the top 16 features and precipitation for the final rf prediction which are described in table 2 subsequently the prediction rf model was established the testing set was utilized to verify this model the mae mse rmse and r2 are 1 078 3 365 0 036 and 0 975 respectively fig 3 shows observed and predicted sm obviously the rf model had acceptable performance to predict the low sm content and underestimated the high values sm 30 from april 4th to may 20th in 2005 when an abnormal peak of sm appeared compared to the training dataset 3 2 mse based feature importance fig 4 represents the selected features ranked in order of importance based on mfi lagged precipitation and sm i e p1 sm1 sm2 p2 day and sm3 are the most influential features in the rf model by contrast features related to energy flux such as reco pisw gpp and le are identified as secondary factors in sm prediction 3 3 shapley values this section introduces sv for feature importance evaluation in our integrated xai approach in order to have a comprehensive view of what the model has learned we considered multiple samples simultaneously thus the computation of sv covered the whole collected dataset to explore the feature effects as global explanation furthermore two types of global explanation figs 5 and 6 are provided to enhance interpretability of the sm prediction in the hydrometeorological forecast fig 5 introduces the sv of each feature for global observation with time series the baseline is zero representing the averaged sm value the positive sv of a feature means that in this time slice the feature has the positive effect on the sm prediction and vice versa overall the lagged sms and ts fig 5 a had the dominant impacts on the predicted sm more than 90 of the values moreover the relative contributions of each feature did not vary a lot with the predicted sm indicating that the contribution of each feature in different instances is relatively stable in addition to the sv distribution with feature values the sv distribution of each feature has been explored in fig 6 we can clearly see that in fig 6 a the lagged sms were the main drivers for the sm and the sv magnitude decreased as the lagged days increased in fig 6 b the regular pattern of the distribution can be seen more obviously almost all the instances had low precipitation values red one and the low values tended to provide slight negative sv for sm the other feature effects from sv are shown in fig 6 c the tendencies of ts and ta were similar which showed that sm generally increased as temperature increased 3 4 partial dependence plot and one dimensional accumulated local effect in this section the practical pdp and ale can fill the gap of specific changing characteristics between the features and sm generally pdp and ale can present a feature s marginal effects on the predicted outcome the difference is the computing method pdp assumes that the features should not have the interaction between each other which limits the practical application in the meteorological field but ale does not thus ale performs better to capture the feature effects and the results of pdp are given in the supplementary materials fig s5 fig 7 presents the 1d ale plots of all 16 features by rf model via the 1d ale the established model was identified with the ability to capture the sm variation with feature changes a typical example is the ts of 1d ale see fig 7 e fig 7 e illustrates how the ts changed the sm which can be divided into three sub periods first with the ts increasing from 10 c to 2 c the sm content ascended with a slight slope it is the period that the snow begins to thaw second when the ts was near 0 c the thawing rate became very high and most of the snowmelt leached into soil resulting in the sm increased significantly meanwhile the lagged sms of 1d ale also provided some interpretable examples through the visualization tool in fig 7 i m how the lagged sms affected the sm were presented we can find the following points a similar to the sv display the amplitude of variation of sm decreased with the lagged days b the lagged sms had similar feature effects on sm for example with sm1 increasing sm begins to rise in a relatively high slope until sm1 30 sm became gradually stable this threshold became small as the lagged days increased which is about 18 for sm4 and sm5 distinctly the feature effects of precipitation are interpretable similarly which are given in fig 7 n o and p the influences of p0 p1 and p2 on sm continuously increase with the precipitation level the p1 as the most important factor could change the sm significantly as the immediate cause of sm content the p1 had a positive impacts of sm similar to the lagged sms high precipitation had limited effects on sm once the p0 exceeds 20 mm sm hardly changes however apart from the mentioned examples there are still some plots which are hard to explain for instance the 1d ale decreased with the day variable fig 7 a but there is an increasing trend of sm in observation the unexpected 1d ale plots may reflect the imperfection of the prediction model 3 5 individual conditional expectation extended by the instances from pdp the ice curves can generate complementary explanations that allow examining how the predictions of each observation change when the feature values change fig 8 shows the ice plots of the selected 16 features each curve presents the ice of an instance due to the ice based on the instances the observation heterogeneity is presented making the variations easily understood as an example shown in fig 8 d the ice curves were clearly divided into two branches according to the different trends the first branch lies in the upper part of the entire ice plots corresponding to the positive effect and the other branch is plotted in the bottom related to the negative effect the ice plots of gpp fig 8 g and reco fig 8 h had similar patterns the rf model considers the effects of pisw reco and gpp are not isolated fig 9 shows the results of the dice plots we can more obviously see whether changes occur and in which direction they occur similarly taking precipitation as an example in fig 9 n o and p precipitation has positive effects on most of the instances the dice higher than 0 dice of ts shows there is a surge around 0 c in accordance with the ice and ale however the dice of reco gpp and le stay at zero except for several instances 3 6 two dimensional accumulative local effects pdp and ale commonly present the effect of two features on the response variable using two dimensional plots unlike the mathematical background the 2d ale focuses on the feature interaction combined effect on the prediction due to the feature interactions in the meteorological field being non negligible in this case the 2d ale is more applicable than 2d pdp sun et al 2015 due to a large number of combinations of features only a few two dimensional ale examples are given in fig 10 for further interpretation fig 10 a reflects how the predicted sm varied under the interactions of ts and pisw dramatically while the ts is under 0 c and the pisw is lower than 300 w m2 the sm will become relatively low it accords with the natural phenomenon that in the freezing period heavy snow covers the shrubland and there is little liquid water in the soil causing a drought with the pisw rising the rf model predicted that the sm would become rarer resulting in a dramatic drought the consistency between pisw ts and sm has been identified fig 10 a also shows that two groups of instances existed ts can have both relatively low and high values when the pisw values are similar which corresponds to the first half year during which the ts is increasing and the second half year during which the ts is decreasing respectively another typical example is given in fig 10 b we can see the distribution of instance dots when the ts is higher than 0 c the sm becomes lower as the le and ts increase it can be explained by the combined effect of le and ts of which both have a negative impact on sm 4 discussion the proposed integrated xai framework is able to visualize black box ml models which provides physically interpretable information for hydrologists and climatologists in this study we explore potential applications of the xai tools which focus on physical consistency of ml model outputs via discussing several typical examples beyond this case there is ample scope to apply this tool in other issues like runoff precipitation and evaporation in hydrometeorological prediction based on our initial application of xai tools in one in situ sm prediction several spatio temporal predictions should support such use and future extension 4 1 xai tools can help to improve the reliability of the predicted results primarily rf prediction result indicates the well trained rf model can capture the variation characteristics of sm in the case of ha2 site effectively in the premise of prediction accuracy if the relations revealed by the xai tool can correspond to the prior knowledge of hydrometeorological processes the prediction can be trusted thus the reliability and robustness of the model can be improved 4 1 1 time memory taking an important part in prediction can be reflected the soil in ha2 is of high water capacity because of the alpine region yang et al 2014 and shrubland hu et al 2018 time memory is considered one of the most influential factors in sm maintenance zhang et al 2015 the mfi results demonstrate that in the case of ha2 sm1 sm2 and sm3 are the most critical features which agrees with the common cognitive that the recent 1 3 day lagged sm are the significant factors controlling sm meanwhile sv with time series fig 5 also reveals that the time memory of sm plays an essential role in sm prediction the sv magnitude decreases as the lagged days increase see fig 6 it conforms to the consensus that the effects of lagged sms would diminish with time on the other hand from the sm values distribution basically all the high lagged sms have a positive influence on sm and vice versa conclusively the higher lagged sms have more effects on sm and prolonging the lagged days would weaken the effects these findings agree with the natural hydrometeorological knowledge ale of lagged sms also presents a dramatic influent of lagged sms on sm prediction and gives more detailed information on feature effects when the values of lagged sms are in low states there is a linear relationship between lagged sms e g sm1 and sm2 in fig 7 i m and predicted sm as the values increase the relationships become irrelevant it indicates there is a threshold controlling the sm s dependence on lagged sm this is likely related to the effects of plant or evaporation at high sm which breaks the former water balance on account of the architecture of shrub roots soil microporosity becomes high under shrub patches gao et al 2021 it contributes to preferential water flow into the deep soil layer while the lagged sm is high the water retention in the shallow layer would decrease due to runoff or the water leaching into the deep soil layer in addition high evapotranspiration occurs when sm is high thus very high lagged sms do not lead to a very high predicted sm ice and dice also present the similar characteristics of lagged sms summarily the integrated xai framework including mfi sv ale ice and dice can effectively reflect the importance of time memory in predicting sm the rf model is capable of extracting the time memory of sm it facilitates the trust building of the well trained black box model 4 1 2 dynamics that ts affecting sm can be captured by xai tools the ha2 site is detected with snow cover especially in winters consequently the ts affecting sm is tangible when the temperature increases the thawing of a shallow active soil layer induces a rapid increase in sm you et al 2017 there is a dramatic increment caused by the duplex positive feedback of ts on sm on one hand while the ts increases the snow starts thawing and the surface albedo increases it makes the increased solar radiation received on the land surface further accelerating the snow thawing and the sm increasing rapidly on the other hand due to radiation cooling at night the snowmelt water freezes again this process would enhance the ts and cause increasing sm when the ts rise to a high level evapotranspiration dominates the sm content variation in this period the rising ts leads to the sm declining liu et al 2020 in mfi fig 4 the ts is considered a minor effect however from the sv distribution we can see that the higher ts values accompany higher sm prediction apart from the several high values found in lower sm prediction in ale the tendency of ts affecting sm is quite straightforwardly demonstrated meanwhile this change of instances can be found more explicit in ice fig 8 e and dice fig 9 e following the physical mechanism the above interpretation confirmed by the prior knowledge from the hydrometeorological process can be considered appropriate and reasonable they can help to gain the reliability of the black box model further 4 1 3 pisw s multiple effects on sm can be revealed by xai tools in the hydrometeorological process pisw affecting sm is complex with multiple feedbacks the acknowledged mechanism in heihe river is strategically described as positive feedback and negative feedback zhang et al 2019 positive feedback of pisw on sm is that the hydrothermal interaction is activated while the sm is low thus the sm ascends as the pisw increase on the contrary negative feedback of pisw on sm in detail with the pisw increasing more energy is radiated from the surface which depresses the evapotranspiration and the reduction of sm is inhibited while the rf is well trained it can capture this phenomenon from ice plots the instance curves are separated into two branches which can represent both the positive feedback and negative feedback nevertheless other xai tools are not capable of this function except the ice this interpretation can reveal the change rule found by the black box model helping us users trust the model ice of pisw vividly presented the heterogeneity of instances and the ice of precipitation revealed the limitation of black box model in the unrealistic space summarily the ice is a valuable visualization tool to present the feature effects from the view of each instance 4 2 xai tools can facilitate to make countermeasures in advance currently the methods of artificial hydrometeorological intervention still need to be improved most of the methods are related to artificial precipitation here features referring to the precipitation are discussed including p0 p1 and p2 precipitation is considered a direct cause of the sm increase meng et al 2017 which can be easily found by mfi and sv in the alpine region the precipitation is considered a supply for soil moisture ma et al 2022 the high values of sv corresponding to the p0 p1 and p2 also present physical consistency in fig 5 b the result is in accord with the temporal observation that sm under the alpine tundra shrubland region is far more sensitive to single rainfall events sun et al 2015 notably we found an interesting phenomenon the svs of p1 were the highest followed by those of p0 it can be explained by the interception of the developing plant canopy hao et al 2010 except for sv ale can verify this finding which indicates that the effect of p0 on sm declines when the p0 exceeds 20 mm dai et al 2019 pointed out that in the alpine tundra region the rainfall is inclined to return to the atmosphere via evapotranspiration when precipitation is excessive thus we can obtain the effects of precipitation on sm via xai tools in order to take countermeasures in advance ice can give us some practical information some instances are captured by ice which are not sensitive to the p0 p1 and p2 those instances cannot be intervened in due to the specific conditions on the other hand a particular instance of sm prediction is vulnerable to precipitation which can be enhanced by artificial rainfall to avoid droughts 4 3 xai tools can figure out the inherent bias in data that might lead to the black box model s defeats firstly due to the lack of precipitation in the ha2 site the observed precipitation data is centralized in 0 mm it leads to inherent data bias caused by the observation and the maldistribution data damages the model and results in the inability of grasping the real world relations the ice plots can identify the inherent data bias particularly in the freezing period sm prediction with lower than 12 is inactive to the increasing p0 p1 and p2 in ice plots fig 8 similarly dice is competent to reveal the shortcomings of data bias from precipitation in some instances precipitation leads to the predicted sm decrease indicating the drawbacks another example is the dice of ts in fig 9 e for example dice plots of the le fig 9 f gpp fig 9 g and reco fig 9 h cannot be interpreted well while the le gpp and reco get to high value they have little impact on predicted sm it is unreasonable to refer to the data bias not only can the ice and dice identify the drawbacks of the rf model but 2d ale is also quantitative in fig 10 b there is a distinct blue section meaning that under 0 c with the le climbing the soil turned to humid it was estimated by the rf model basically this rarely happens in nature thus the 2d ale can reveal the estimated mistakes from the established model irrgang et al 2021 conclusively xai tools especially the ice dice and 2d ale are competent in identifying a particular data bias of the black box model 4 4 future work however many problems still need to be investigated by further studies we concluded the problems as follows a the reliability of 2d ale is a tough problem the number of intervals k is essential for leading to this problem when k changes the 2d ale can become very unstable see figs s6 and s7 in the supplementary materials which has also been found in many previous works different levels of k make noticeable differences leading to unreliable interpretation the reason is that 2d ale only shows the interaction effect of the features which is highly sensitive to k for each of the coupled features consequently although 2d ale is a feasible visualization tool for exploring the interaction effects of coupled features on predicted sm it would vary remarkably by changing the number of intervals its practical use can be further explored in future work in the future we aim to enhance the feasibility of 2d ale until the 2d ale can vividly reflect the insight of black box structure b we used rf as the only machine learning model multiple machine learning methods including deep learning models should be compared using the integrated xai tool to see their consistency and difference in capturing feature effects furthermore we also need to answer whether the model with best performance has the best interpretability as trivial coincidences may also lead to good predictions as an example we built a lstm model and compared it with the rf models by using xai methods and the details of results are given in the supplementary material we found some inconsistency of feature effects by xai which could be owe to the poor performance of lstm furthermore variables other than soil moisture should also be studies with xai tools c the prior knowledge used for consistency check in our study was based on articles published in authoritative journals however the natural mechanism is very complicated and changing evaluating the geophysical consistency and making good physical research hypotheses need further efforts with domain specific physical understanding and appropriate experimental design d due to the spatial temporal heterogeneity of hydrometeorological variables it is necessary to apply the xai tools to multiple sites and spatial continuous data i e remote sensing process based model output and reanalysis data in this regard the most valuable and challenging work is to identify general rules across space and time which can lead to new scientific discovery by xai tools e in terms of the discrepancies between the xai result and prior knowledge it is hard to distinguish the origins i e whether they come from the deficient model inherent data bias or novel knowledge this is crucial for interpretation of machine learning models in the future we will concentrate on the discrepancies and further gain the interpretability of black box models 5 conclusions machine learning model become increasingly popular in the field of hydrometeorological forecast due to their black box nature it is urgent to gain the interpretability and practicability of models to address this we integrated xai framework using several exquisite post hoc interpretable methods in this study we chose the sm prediction as an example to illustrate the interpreting tool primarily we chose a fluxnet site located in haibei china which is considered a promoter of climate change in china secondly the black box rf model was conducted to predict sm ultimately mfi sv pdp and 1d ale ice and dice 2d ale were embedded in the integrated xai method to reveal the feature effects from different views a mfi ranks the feature importance through contribution to the precision b sv estimates the feature contribution to the predicted result c 1d ale was used to explore the average predicted sm evolution with one feature variation in the overall range d ice and dice were used to show the predicted sm evolution of each instance with one feature variation e 2d ale visualized the interaction effects of two features on predicted sm the results show that comprehensive understandings of relationship between the predicted sm and its factors can be achieved while the black box model was interpreted by the integrated xai tool the study achieved remarkable results as the following recommendations a gain the reliability of the black box model based on the natural hydrometeorological process as prior knowledge if the result from xai tool can correspond to the knowledge the predicted result can be considered authentic time memory dynamics of ts affecting sm and pisw have the double effects on sm as demonstrated by xai tools it proves that the well trained rf model can grasp this natural characteristic from data and is of high reliability b provide multiple interpretable views the xai tool from different views can support the result significantly for example multiple evidence from mfi fig 4 sv fig 6 and 1d ale fig 7 shows that the intraday precipitation i e p0 has less impact on sm than those of 1 and 2 day lagged precipitation i e p1 and p2 mfi and sv generally show how significant the impact is while ale shows how sm changes with precipitation c the deficiencies of the model from inherent data bias were figured out by the xai tool for example due to the lack of precipitation in the ha2 site the inherent data bias was clearly dictated in the ice plot fig 8 n o and p in general in the field of the hydrometeorological forecast the integrated xai tool helps to prevent the barriers from the nature of black box ai techniques further it promotes a more intelligent ai application in the hydrometeorological forecast meanwhile well posed physical research hypotheses are needed in using these xai tools to aid the integration of scientific knowledge with machine learning and the fusion of process based models and ai reichstein et al 2019 credit authorship contribution statement feini huang methodology programming writing original draft software visualization wei shangguan conceptualization supervision validation qingliang li writing review editing lu li software data duration ye zhang visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we thank bingxue yang from institute of automation chinese academic of sciences for his valuable advices the study was supported by the national natural science foundation of china 41975122 42088101 u1811464 42105144 and 41730962 the national key r d program of china 2017yfa0604300 abbreviations abbreviation description ale accumulated local effects ai artificial intelligence ta average nighttime air temperature day day of the entire dataset doy day of year dice derivative ice reco ecosystem respiration xai explainable artificial intelligence r2 explained variance sm4 four days lagged soil moisture gpp gross primary production ice individual conditional expectation le latent heat flux ml machine learning mae mean absolute error mse mean squared error mfi mean squared error based feature importance mds minimum data set k number of intervals p1 one day lagged precipitation sm1 one day lagged soil moisture sm5 one day lagged soil moisture 1d one dimensional pdp partial dependence plot pisw potential incoming shortwave radiation p0 precipitation rf random forest rmse root mean squared error sbs sequential backward selection sfs sequential forward selection sv shapely value sm soil moisture ts soil temperature sm3 three days lagged soil moisture p2 two days lagged precipitation sm2 two days lagged soil moisture 2d two dimensional vpd vapor pressure deficit appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2023 105762 
25381,with the increasing application of machine learning ml in hydrometeorology we face the urge to demystify the ml s black box nature because it usually does not provide physically interpretable information to users here we demonstrate multiple post hoc interpretation methods to evaluate feature effects for hydrometeorological prediction these methods were integrated and applied to soil moisture sm as an example and random forest was used to establish a prediction model based on a fluxnet site in haibei china different views of interpretability feature importance shapley values partial dependence plot individual conditional expectation and accumulated local effect were used to investigate how features affect the prediction the result shows that a comprehensive understanding can be achieved of the relationship between predicted sm and affecting variables including lagged sm precipitation and soil temperature thus we advocated integrated interpretation tools to enhance the practicability of ml for hydrologists and other physical scientists a toolbox named explainai is provided keywords interpretability hydrometeorological forecast machine learning feature effects explainable artificial intelligence data availability the data that has been used is confidential 1 introduction hydrometeorological forecast which estimates future catchment conditions based on recent and forecasted meteorological conditions and hydrological observations sene 2015 has gained importance in recent decades due to increasing demand for agricultural economic development and meteorological risk management generally the forecasts include precipitation evapotranspiration runoff and soil moisture sm these factors mutually affect each other and constitute the natural cycle of water the potential applications of hydrometeorological forecast cover the following fields a extreme event forecasting such as flood roux et al 2020 and drought warning sutanto et al 2020 b water usage such as hydropower operations anghileri et al 2019 irrigation giuliani et al 2020 and river basin management georgakakos et al 2014 c climate change impact assessments millán 2014 due to the non linear and chaotic nature of the atmosphere forecasting the hydrometeorological variables is challenging to achieve precise hydrometeorological forecasts many efforts have been made to two groups of model improvement i e process based models and data driven models generally process based models are also referred to as mechanistic models or physical models they are based on the mechanism of the hydrological process which are white box models of high interpretability such as weather research and forecasting model liu et al 2021 and continuous hydrological model sheikh et al 2009 however process based models have some limitations shen 2018 the relatively low accuracy of process based models is the most significant barrier to hydrometeorological forecast moosavi et al 2019 alternatively with the flourishing development of artificial intelligence ai in recent decades data driven models i e machine learning and deep learning can efficiently reduce the errors from the insufficient process based models or land data assimilation systems efficiently dikshit et al 2021 q li et al 2021 used a convolutional neural network cnn and long short term memory lstm to improve the 3 h local precipitation forecast further the lstm network was combined with complex process based and attention based models such as soil and water assessment tools majeske et al 2022 deep learning also has a preferable performance to extreme precipitation davenport and diffenbaugh 2021 ghaith et al 2022 considered a synchronized precipitation module in a cnn lstm model that enhances the accuracy of complex flood forecasting machine learning can also be applied in evapotranspiration prediction enhancing the accuracy in short term forecasts talib et al 2021 moreover many machine learning studies have focused on sm prediction in our previous work we used three data driven methods bayesian linear regression random forest rf and gradient boosting regression tree to predict sm based on the fluxnet site data the best r2 values ranged from 50 to 95 pan et al 2019 deep learning has also achieved high performance in sm prediction for example w li et al 2021 improved daily soil moisture active and passive satellite soil moisture prediction using transfer convolutional lstm learning with the lowest root mean squared error rmse ranging from 0 0239 to 0 0247 for 3 5 and 7 days lead times however machine learning is usually considered as a black box models meaning that it is an end to end method without physically interpretable information to the user although the ai models provide more accurate predictions of hydrometeorological variables their black box nature and their lack of explanation pose practical challenges for establishing data driven models guidotti et al 2019 furthermore judea pearl who received the turing award argued that any pure data driven model should combine with the real world process because reality reflects the processes that generate the data pearl 2021 in addition the bridge between them is explainability and interpretability doshi velez and kim 2017 in general there is a well known trade off between explainability and accuracy in the hydrometeorological field prodhan et al 2022 explainable artificial intelligence xai aims to facilitate communication between ai models and human understandings and to build trust in non transparent models gunning et al 2017 miller 2019 razavi 2021 suggested that acquiring of underlying mechanism of ai models can help us better explain the model behavior summarily explainability and interpretability are crucial for applying machine learning in the policy relevant area of climate and earth science as the models decision making requires explanation the lack of xai is a major drawback in critical decision making processes recently the xai techniques have been applied in many fields such as credit score bücker et al 2021 insurances risk mehdiyev and fettke 2020 health status stiglic et al 2020 vellido 2019 etc with ai techniques advancing in the field of hydrometeorological forecast the demand for xai has also increased mcgovern et al 2019 in the field of practical hydrometeorological forecast lack of explanation would result in the following barriers a because of the lack of specialized knowledge of hydrometeorological processes the result is questionable ebrahimi khusfi et al 2020 b the conventional models only provide a hydrometeorological forecast outcome and the effects of predicting factors should be examined which is significance for preventing drought and flood liu et al 2020 c the model inferred from the data may have inherent biases hidden in the black box schmidt et al 2020 d hydrometeorological variables e g sm precipitation exhibit inevitable spatial temporal heterogeneity implying that different models would perform differently at various times and locations pan et al 2019 numerous techniques have been developed to overcome the interpretability challenge of black box models they can be classified as intrinsically interpretable models interpretable machine learning and post hoc interpretation methods explainable machine learning molnar 2022 typically intrinsically interpretable models are model specific for example a conceptual knowledge based truly transparent model that combines real time machine learning can forecast the flood and manage the flood risk process agresta et al 2014 the model requires a huge amount of inferred knowledge however in hydrometeorology there are still inevitable gaps between prior mechanisms and real word processes the post hoc interpretation methods also called model agnostic methods have gained popularity in earth system science furthermore these methods can help scientists to better incorporate physical knowledge into machine learning i e physics informed machine learning discover new science and assist in theoretical advances irrgang et al 2021 in the future in a quest for achieving true xai an integrated model that merges physical knowledge data and machine learning architecture will provide a more transparent and understandable insight into real world processes in earth system science donalek et al 2014 reichstein et al 2019 after exquisite training the post hoc interpretation methods were expected to meet the interpretability challenge of black box models improving their transparency these methods were classified into importance evaluation and feature effect visualization the methods to evaluate feature importance include permutation feature importance algorithm fisher et al 2018 impurity importance louppe et al 2013 sequential backward selection sbs or sequential forward selection sfs that are related to mean squared error based feature importance mfi and shapely value sv shapley 1953 alternatively the visualization for feature effects was achieved by partial dependence plot pdp friedman 2001 individual conditional expectation ice goldstein et al 2015 and accumulated local effects plot ale apley and zhu 2019 mcgovern et al 2019 applied sbs sfs and pdp in meteorological prediction at different spatio temporal scales and achieved rational interpretations sv was applied to conduct the target sensitivity analysis in a flood model il idrissi et al 2021 however among the above methods each can provide interoperation in specific aspects but neither can explain the prediction model comprehensively to our knowledge no study explored multiple post hoc interpretation methods in hydrometeorological prediction thus this study aims to investigate an integrated post hoc approach to evaluate the feature effect of the hydrometeorological machine learning model here we take the sm prediction as an example in the hydrometeorological forecast to illustrate the integrated post hoc xai tools the reasons we choose sm include a sm is an essential variable in the process of the global hydrological cycle which determines the water and soil resources management surface energy and natural cycle of water kato and nishimura 2016 b sm is very sensitive to many factors like the soil properties e g sand and clay content vegetation especially the meteorological factor including precipitation air temperature topsoil temperature koster et al 2017 thus it is convenient to show the comprehensive relationships between sm and related factors using xai tools noticeably sm generation is a highly nonlinear system which causes difficulty in estimating sm thus in this study several post hoc xai tools were utilized to form an integrated approach that can reveal the interpretability of the sm prediction model from different viewpoints primarily the sm prediction model was established using rf as a demonstrating black box model based on observations from the ha2 site of fluxnet subsequently the integrated xai framework was applied to evaluate the interpretability of sm prediction from the following aspects a mfi to assess the importance of each feature s impact on the sm prediction result b sv to evaluate each feature s contribution to the difference between real time sm prediction and average sm value c pdp and one dimensional 1d ale to reflect how the sm prediction varies with each feature and to show the evolution of feature effects on sm in different periods d ice and derivative ice dice to represent how each feature affects the sm in each event especially in extremes e two dimensional 2d ale to show the interaction effect of two features on sm prediction in this way the integrated post hoc xai approach we proposed can improve the transparency of the black box machine learning models from the following aspects a the tool can help to improve the reliability of the predicted results the prediction can be trusted if relations revealed by the xai tool can correspond to the prior knowledge of hydrometeorological processes thus the reliability and robustness of the model can be improved b the xai tool can provide much evidence i e important factors feature effects to support the prediction which helps to make countermeasures in advance c the inherent bias in data might lead to defeats in the black box model which can be figured out by the xai tool to sum up with the interpretability of ai models brought by the xai tool the application of ai techniques will be promoted this work can contribute to building a more intelligent and accurate hydrometeorological forecast 2 methods in this study in order to illustrate the proposed integrated xai approach applied in hydrometeorological forecast taking sm prediction as an example the framework is shown in fig 1 first we used observations from the fluxnet site named ha2 and the raw data were collected and divided into the predictors features and the target surface sm second the feature selection was carried out including the contrived work and sbs then we trained the rf model and assessed the precision with statistical metrics after the above procedures the essential work was to evaluate the feature effects the shapley values pdp and 1d ale ice and dice 2d ale were embedded in the integrated xai approach 2 1 study site the study used data from haibei national field research station named ha2 qinghai china 37 37 n 101 19 e which is located on the northeastern qinghai tibet plateau at an elevation of 3200 m above sea level ha2 was situated along the datong river tributary a branch of the yellow river close to the upper reaches of the heihe river watershed the site belongs to ecosystem surface classification of permanent wetlands from the international geosphere biosphere programme land with a permanent mixture of water and herbaceous vegetation that covers extensive areas http sites fluxdata org cn ha2 means permanent wetlands the most common land use is shrubland mainly irrigated by the river stream and with limited rainfall as a plateau continental monsoon climate region the place near ha2 has well developed seasonally frozen ground according to the fifth generation of european reanalysis the meteorological factors were provided from 1980 to 2014 hersbach et al 2020 during the 35 year period the average daily long term air temperature shortwave radiation longwave radiation vapor pressure deficit pressure precipitation and wind speed are shown in table 1 the reasons that we chose the ha2 site as a case study are as follows a at this site it is more difficult to predict sm due to the great sm variability under complex hydrological processes in winters the frozen soil can be characterized by unidirectional freezing and bi directional thawing and in summers the increasing precipitation and climbing evaporation can affect the sm in opposite ways moreover the soil is clay loam with high permeability water holding capacity and low heat conductivity yang et al 2014 these characteristics are likely to cause a strong land atmosphere coupling b qinghai tibet plateau is one of the most climate sensitive regions in the globe and the ecosystem is vulnerable and easily affected by the climate change with many natural ecological processes and feedbacks still intact predicting and analyzing soil moisture at ha2 is very important to understand climate induced environmental changes chen et al 2013 2 2 data collection and processing site data were obtained through the fluxnet2015 full set data product fluxnet doi 10 18140 flx 1440211 variables include time variables micrometeorological observation energy processing and net ecosystem exchange their description is given in table 2 the raw data from fluxnet2015 contain 320 variables including information from different quality control protocols the uncertainty of observation and standard deviations we chose timekeeping dd which means the average of half hourly data in a day since soil moisture has a certified with relatively strong time memory and usually has a small diurnal change the dd of timekeeping is appropriate for sm prediction before feature selection the data processing was conducted to ensure the data quality here according to the quality flag of each feature determined by fluxnet details found in pastorello et al 2020 a 3 step data preprocessing scheme was conducted follows i removing the records with missing sm ii deleting features with over 30 missing records and iii deleting low quality data quality flag 1 according to the quality control from fluxnet in addition to the observed variables we used time variables including year and day of year doy as inputs which corresponded to the inter annual change and seasonal cycle of sm pan et al 2019 generally numerous variables would cause massive computation and even leading to the degradation of the machine learning model hence the feature selection should be conducted the feature selection consisted of two steps contrived work and sbs which have been deemed feasible in many fields in the contrived work we eliminated the statistical indicators such as uncertainty standard deviation and quantiles then in sbs to evaluate the importance of each feature the remaining variables were treated as the input of the rf model for training sbs sequentially eliminates features from the complete feature set until the model s predictive accuracy is optimized to a stable level in more intuitive terms at each training time we removed the feature that caused the most negligible performance loss after removal details of the selected variables by sbs are given in section 3 1 2 3 hydrometeorological forecast by black box machine learning hydrometeorological factors generally are known for their high non linearities and complex interactions with the atmosphere in this case the sm is extremely sensitive to the land surface variables in previous research rf was considered a convenient method for describing the complex interactions between sm and land surface variables compared with bayesian linear regression rf also has better performance in predicting sm in the tests from fluxnet sites pan et al 2019 here we predicted sm based on the known conditions i e micrometeorological observation energy processing and net ecosystem exchange for the same day which is a regression task rf algorithm is an ensemble learning method based on decision tree models which integrates multiple trees and obtains the optimal predictions by averaging the results of numerous functioning trees for regression tasks belgiu and drăguţ 2016 rf often passes through three steps to ensure optimal results as follows a the raw data is divided into several parts randomly with parts of features b each part of the data is treated as the input data of a decision tree and each decision tree is applied to provide its optimized result c the result produced by each tree is ensembled and the mean value is deemed as the optimal output the amount of full dataset we used is 1096 daily observations from 2003 to 2005 here we used the first 70 of the time series data set from january 1st 2003 to february 5th 2005 as the training set meanwhile the last 30 of data from february 6th 2005 to december 31st 2005 were used as the testing set taking the computation and precision into account we set the number of decision trees in rf to 100 and the number of nodes to the default 1 3 of the number of features a time stratified selection of training and test sets as used in this work may lead the models to operate in the inference phase outside the features training envelope causing loss of accuracy though significant difference may exist in the training performance and test performance the difference in this study was not significant see section 3 1 furthermore wrapper feature selection schemes may be fooled by this behavior and pointing to eliminate a predictive feature which possible range is not fully covered in the training set thus the time stratified selection of training and test sets may have some effects on the results of xai 2 4 statistical metrics in order to fully evaluate the performance of the rf prediction model the four most popular metrics were used explained variance r2 mean absolute error mae mean squared error mse and rmse the r2 represented the model s ability to capture the non linear variation and the mae quantified the errors between actual data and the predictions from the model similarly the mse and rmse are the two commonly used metrics in most research which can help to compare with other results the statistical metrics are calculated as follows 1 r 2 y y ˆ 1 i 1 n y i y ˆ i 2 i 1 n y i y 2 2 m a e i 1 n y i y ˆ i n 3 m s e i 1 n y i y ˆ i 2 n 4 r m s e i 1 n y i y ˆ i 2 n where y i is the measured value of the i t h sample y ˆ i is the corresponding predicted value n is the sample size and y is the average value of predicted samples 2 5 evaluate feature effects via interpretable visualization interpreting machine learning models is essential for researchers and model developers because many different approaches have been attempted among the different ways to open the black box of machine learning models these approaches have been categorized into two types intrinsic and post hoc interpretability du et al 2019 based on self explanatory models the intrinsic methods can directly reflect the causality of the input features and the output results khoda bakhshi and ahmed 2020 however these methods are model specific which limits the application especially for complicated models such as rf and deep learning models therefore intrinsic methods cannot always work serving as analysis methods independent of the machine learning models from the perspective of the evaluation of feature effects the post hoc interpreting methods can be considered as a practical and refined approach to explaining the prediction models in a post hoc manner yang et al 2019 in this study to investigate the feature effects of the hydrometeorological forecast model we integrated several post hoc interpretability methods into an advanced system here we chose sm prediction as an example to illustrate the system on this point the steps to integrate the utilized interpretability methods are as follows a mfi for tree based model was used to eliminate the redundant features in the feature selection and to sequence the features by statistical mse importance evaluation b sv was applied to assess feature importance with both positive and negative effects c 1d pdp and 1d ale were used to explore the average predicted sm evolution with one feature variation in overall range d ice and dice were used to show the predicted sm evolution of each instance with one feature variation in the overall range e 2d ale visualized the interaction effects of two features on predicted sm a python module named explainai is under development for all the above post hoc interpretability methods for the convenience of hydrometeorological forecast and other widespread applications the source code is also available at https github com huangfeini explainai 2 5 1 mse based feature importance mfi as one of the most pragmatic methods to quantify feature importance the python package scikit learn provides a specified evaluation for rf model note that the r package named randomforest also provides similar functions this method computes the importance by permuting out of bag data first the mse from the prediction model on the out of bag portion of the training data is recorded for each tree next this procedure is repeated for each feature thus the decreased mse compared to the optimal model is treated as the importance of the feature 2 5 2 shapley values similar to mfi for the evaluation of feature importance a sensitivity analysis based explaining method has been invented štrumbelj and kononenko 2013 unlike the mse based feature importance specific for tree based models sv can be applied for prediction models of any type and any subset of data considering all possible interactions and redundancies between features all combinations of features are tested sv method can be applied on any data subset or even a single instance the sv of a feature value x i j is its contribution to the predicted result weighted and summed over all possible feature value combinations 5 φ ˆ i j v a l s x i 1 x i p x i j s p s 1 p v a l s x i j v a l s where s is a subset of the features used in an alliance x i is the vector of feature value of the interest of instance j p donates the number of features and v a l is the prediction for feature values in subset s that are marginalized over features that are not included in subset s the calculation procedures of sv are shown in fig s1 unlike mse based feature importance sv can be negative which indicates a feature s negative effect and vice versa initially this method was derived from coalitional game theory assuming each feature plays a specific role in the game molnar 2022 the features will form different alliances in a game then in each alliance how much a feature contributes to the predicted result is quantified afterward the average of the marginal contributions from different alliances is the sv for this feature notably the shapley value of each feature can be obtained particularly it can be utilized to analyze the typical or extreme events in the hydrometeorological forecast by evaluating feature contribution 2 5 3 partial dependence plot the pdp demonstrates the relationships between the features and the prediction friedman 2001 the pdp for regression is defined as 6 p ˆ x s j x s j 1 n i 1 n f ˆ x s j x c i where x s j is the set of the feature of interest as j th feature for which the partial dependence function should be plotted p ˆ x s j is the partial dependence value of j th feature n is the number of elements in x s and x c is subset of other actual features values pdp estimates the average marginal effect of predictors on the predicted sm which can be a determined value in regression aiming to visualize the feature effects the pdp can be conducted by the following steps fig s2 a the predictors p x 1 x 2 x k x p are divided into two subsets including the feature of interest s x k and other features c x 1 x 2 x k 1 x k 1 x p wherein the s subset involves possible values of x k which can be described as x s x s 1 x s 2 x s j x s m b using each element of x s subset to replace the x k successively is the essential step for pdp in order to find the response feature at a specific given value of x s pdp generates synthetic observations where the values of the feature of interest are permuted by the x s across all actual observations c the trained rf model outputs the predicted sm with a synthetic observation which is the marginal output of the feature of interest called marginal effect then the marginal effect values are obtained by averaging the predicted sm over all the synthetic observations however one assumption made for pdp is that the features in x c are irrelevant with x s that we focused on this assumption leads to the limitation of its application therefore the ale can compensate for this drawback 2 5 4 individual conditional expectation and derivative individual conditional expectation since the pdp only draws the averaged marginal effect of a predictor heterogeneity of the dataset is neglected leading to insufficient insight into different instances to address this ice was proposed by goldstein et al 2015 the ice concept is given by equation 7 7 p ˆ x s j x s j f ˆ x s j x c for a feature of interest ice plots highlight the variation in the fitted values across the covariate range in other words the ice provides the plots of dependence of the predicted response on a feature for each instance separately the calculation procedures of ice are shown in fig s3 similar to pdp keeping all other features constant the partial dependence values for a line or an instance can be computed creating variants of this instance by replacing the feature s value with values in a grid ice repeats this procedure for all the observations therefore via ice plots feature effects on each predicted sm from a black box machine learning model can be illustrated transparently since the ice plot can only demonstrate the feature effects of an instance using individual derivatives of the individual conditional expectation values with respect to the feature of interest dice provides another more distinct visualized approach to further reveal the feature effects from spot heterogeneity goldstein et al 2015 the dice can be expressed by equation 8 8 d p ˆ x s j x s j δ f ˆ x s j x c δ x s j the derivatives of ice can illustrate which direction changes occur or if any occur at all when the derivatives fluctuate to positive values the feature positively affects the predicted sm moreover if there is any scale of feature effect the dice varies fiercely which means that the feature of interest strongly influences the results of dice with the derivative ice plot it is easy to spot value ranges in a feature where the black box s predicted values change for at least some instances 2 5 5 accumulated local effect both pdp and ice however suffer from highly correlated multi dimensional spaces which can lead to unreliable interpretation of prediction models molnar 2022 to fill this gap the ale has been introduced the ale is a more sophisticated method to evaluate the feature effects owing to averaging the differences in the prediction model of the conditional distribution unlike pdp the ale is unbiased and functions even when variables are correlated 1d ale shows the dominant effects with the feature of interest variation 2d ale solely displays the additional effect of an interaction between two features without the main effect of each feature generally hydrometeorological factors always have specific interactions and the 2d ale can estimate the combined effects of each pair of features globally the 1d ale is defined as equation 9 9 f j ˆ x k 1 k j x 1 n j k i x i j n j k f z k j x i j f z k 1 j x i j c where f j ˆ donates the ale values and it visualizes the main effect dependence of modeling on x j x i j x i l l 1 d l j where the subscript j means all feature except the j th similarly n j k z k 1 j z k j k 1 2 k donates a sufficiently fine partition of the sample range of x i j into k intervals and the constant c is chosen so that 1 n i 1 n f j ˆ x 0 the calculation procedures of ale are shown in fig s4 the main idea of the ale is to divide the scales of the feature of interest into k equivalent intervals this division can reduce the interaction of correlated features and effectively avoid the generation of unrealistic synthetic observations apart from these estimating the average values over differences in predictions reflects the pure main effect of feature of interest on predicted sm then based on the separated grids in each grid values of the feature of interest from the grid replace the actual value and the differences of predicted sm values have been estimated thus the ale can be calculated by accumulating the differences among the whole grids and centering the values 3 results 3 1 predicting soil moisture with random forest modeling in this study we aimed to illustrate the integrated xai method for hydrometeorological forecast taking sm prediction as an example rf model was applied as the prediction model before establishing the rf model feature selection was conducted first features were eliminated by manual work and 116 features were left then these 116 features were further selected by the sbs fig 2 shows that r2 changes with the number of features in the sbs the model performance became optimal when the number of features was around 16 thus we chose the top 16 features and precipitation for the final rf prediction which are described in table 2 subsequently the prediction rf model was established the testing set was utilized to verify this model the mae mse rmse and r2 are 1 078 3 365 0 036 and 0 975 respectively fig 3 shows observed and predicted sm obviously the rf model had acceptable performance to predict the low sm content and underestimated the high values sm 30 from april 4th to may 20th in 2005 when an abnormal peak of sm appeared compared to the training dataset 3 2 mse based feature importance fig 4 represents the selected features ranked in order of importance based on mfi lagged precipitation and sm i e p1 sm1 sm2 p2 day and sm3 are the most influential features in the rf model by contrast features related to energy flux such as reco pisw gpp and le are identified as secondary factors in sm prediction 3 3 shapley values this section introduces sv for feature importance evaluation in our integrated xai approach in order to have a comprehensive view of what the model has learned we considered multiple samples simultaneously thus the computation of sv covered the whole collected dataset to explore the feature effects as global explanation furthermore two types of global explanation figs 5 and 6 are provided to enhance interpretability of the sm prediction in the hydrometeorological forecast fig 5 introduces the sv of each feature for global observation with time series the baseline is zero representing the averaged sm value the positive sv of a feature means that in this time slice the feature has the positive effect on the sm prediction and vice versa overall the lagged sms and ts fig 5 a had the dominant impacts on the predicted sm more than 90 of the values moreover the relative contributions of each feature did not vary a lot with the predicted sm indicating that the contribution of each feature in different instances is relatively stable in addition to the sv distribution with feature values the sv distribution of each feature has been explored in fig 6 we can clearly see that in fig 6 a the lagged sms were the main drivers for the sm and the sv magnitude decreased as the lagged days increased in fig 6 b the regular pattern of the distribution can be seen more obviously almost all the instances had low precipitation values red one and the low values tended to provide slight negative sv for sm the other feature effects from sv are shown in fig 6 c the tendencies of ts and ta were similar which showed that sm generally increased as temperature increased 3 4 partial dependence plot and one dimensional accumulated local effect in this section the practical pdp and ale can fill the gap of specific changing characteristics between the features and sm generally pdp and ale can present a feature s marginal effects on the predicted outcome the difference is the computing method pdp assumes that the features should not have the interaction between each other which limits the practical application in the meteorological field but ale does not thus ale performs better to capture the feature effects and the results of pdp are given in the supplementary materials fig s5 fig 7 presents the 1d ale plots of all 16 features by rf model via the 1d ale the established model was identified with the ability to capture the sm variation with feature changes a typical example is the ts of 1d ale see fig 7 e fig 7 e illustrates how the ts changed the sm which can be divided into three sub periods first with the ts increasing from 10 c to 2 c the sm content ascended with a slight slope it is the period that the snow begins to thaw second when the ts was near 0 c the thawing rate became very high and most of the snowmelt leached into soil resulting in the sm increased significantly meanwhile the lagged sms of 1d ale also provided some interpretable examples through the visualization tool in fig 7 i m how the lagged sms affected the sm were presented we can find the following points a similar to the sv display the amplitude of variation of sm decreased with the lagged days b the lagged sms had similar feature effects on sm for example with sm1 increasing sm begins to rise in a relatively high slope until sm1 30 sm became gradually stable this threshold became small as the lagged days increased which is about 18 for sm4 and sm5 distinctly the feature effects of precipitation are interpretable similarly which are given in fig 7 n o and p the influences of p0 p1 and p2 on sm continuously increase with the precipitation level the p1 as the most important factor could change the sm significantly as the immediate cause of sm content the p1 had a positive impacts of sm similar to the lagged sms high precipitation had limited effects on sm once the p0 exceeds 20 mm sm hardly changes however apart from the mentioned examples there are still some plots which are hard to explain for instance the 1d ale decreased with the day variable fig 7 a but there is an increasing trend of sm in observation the unexpected 1d ale plots may reflect the imperfection of the prediction model 3 5 individual conditional expectation extended by the instances from pdp the ice curves can generate complementary explanations that allow examining how the predictions of each observation change when the feature values change fig 8 shows the ice plots of the selected 16 features each curve presents the ice of an instance due to the ice based on the instances the observation heterogeneity is presented making the variations easily understood as an example shown in fig 8 d the ice curves were clearly divided into two branches according to the different trends the first branch lies in the upper part of the entire ice plots corresponding to the positive effect and the other branch is plotted in the bottom related to the negative effect the ice plots of gpp fig 8 g and reco fig 8 h had similar patterns the rf model considers the effects of pisw reco and gpp are not isolated fig 9 shows the results of the dice plots we can more obviously see whether changes occur and in which direction they occur similarly taking precipitation as an example in fig 9 n o and p precipitation has positive effects on most of the instances the dice higher than 0 dice of ts shows there is a surge around 0 c in accordance with the ice and ale however the dice of reco gpp and le stay at zero except for several instances 3 6 two dimensional accumulative local effects pdp and ale commonly present the effect of two features on the response variable using two dimensional plots unlike the mathematical background the 2d ale focuses on the feature interaction combined effect on the prediction due to the feature interactions in the meteorological field being non negligible in this case the 2d ale is more applicable than 2d pdp sun et al 2015 due to a large number of combinations of features only a few two dimensional ale examples are given in fig 10 for further interpretation fig 10 a reflects how the predicted sm varied under the interactions of ts and pisw dramatically while the ts is under 0 c and the pisw is lower than 300 w m2 the sm will become relatively low it accords with the natural phenomenon that in the freezing period heavy snow covers the shrubland and there is little liquid water in the soil causing a drought with the pisw rising the rf model predicted that the sm would become rarer resulting in a dramatic drought the consistency between pisw ts and sm has been identified fig 10 a also shows that two groups of instances existed ts can have both relatively low and high values when the pisw values are similar which corresponds to the first half year during which the ts is increasing and the second half year during which the ts is decreasing respectively another typical example is given in fig 10 b we can see the distribution of instance dots when the ts is higher than 0 c the sm becomes lower as the le and ts increase it can be explained by the combined effect of le and ts of which both have a negative impact on sm 4 discussion the proposed integrated xai framework is able to visualize black box ml models which provides physically interpretable information for hydrologists and climatologists in this study we explore potential applications of the xai tools which focus on physical consistency of ml model outputs via discussing several typical examples beyond this case there is ample scope to apply this tool in other issues like runoff precipitation and evaporation in hydrometeorological prediction based on our initial application of xai tools in one in situ sm prediction several spatio temporal predictions should support such use and future extension 4 1 xai tools can help to improve the reliability of the predicted results primarily rf prediction result indicates the well trained rf model can capture the variation characteristics of sm in the case of ha2 site effectively in the premise of prediction accuracy if the relations revealed by the xai tool can correspond to the prior knowledge of hydrometeorological processes the prediction can be trusted thus the reliability and robustness of the model can be improved 4 1 1 time memory taking an important part in prediction can be reflected the soil in ha2 is of high water capacity because of the alpine region yang et al 2014 and shrubland hu et al 2018 time memory is considered one of the most influential factors in sm maintenance zhang et al 2015 the mfi results demonstrate that in the case of ha2 sm1 sm2 and sm3 are the most critical features which agrees with the common cognitive that the recent 1 3 day lagged sm are the significant factors controlling sm meanwhile sv with time series fig 5 also reveals that the time memory of sm plays an essential role in sm prediction the sv magnitude decreases as the lagged days increase see fig 6 it conforms to the consensus that the effects of lagged sms would diminish with time on the other hand from the sm values distribution basically all the high lagged sms have a positive influence on sm and vice versa conclusively the higher lagged sms have more effects on sm and prolonging the lagged days would weaken the effects these findings agree with the natural hydrometeorological knowledge ale of lagged sms also presents a dramatic influent of lagged sms on sm prediction and gives more detailed information on feature effects when the values of lagged sms are in low states there is a linear relationship between lagged sms e g sm1 and sm2 in fig 7 i m and predicted sm as the values increase the relationships become irrelevant it indicates there is a threshold controlling the sm s dependence on lagged sm this is likely related to the effects of plant or evaporation at high sm which breaks the former water balance on account of the architecture of shrub roots soil microporosity becomes high under shrub patches gao et al 2021 it contributes to preferential water flow into the deep soil layer while the lagged sm is high the water retention in the shallow layer would decrease due to runoff or the water leaching into the deep soil layer in addition high evapotranspiration occurs when sm is high thus very high lagged sms do not lead to a very high predicted sm ice and dice also present the similar characteristics of lagged sms summarily the integrated xai framework including mfi sv ale ice and dice can effectively reflect the importance of time memory in predicting sm the rf model is capable of extracting the time memory of sm it facilitates the trust building of the well trained black box model 4 1 2 dynamics that ts affecting sm can be captured by xai tools the ha2 site is detected with snow cover especially in winters consequently the ts affecting sm is tangible when the temperature increases the thawing of a shallow active soil layer induces a rapid increase in sm you et al 2017 there is a dramatic increment caused by the duplex positive feedback of ts on sm on one hand while the ts increases the snow starts thawing and the surface albedo increases it makes the increased solar radiation received on the land surface further accelerating the snow thawing and the sm increasing rapidly on the other hand due to radiation cooling at night the snowmelt water freezes again this process would enhance the ts and cause increasing sm when the ts rise to a high level evapotranspiration dominates the sm content variation in this period the rising ts leads to the sm declining liu et al 2020 in mfi fig 4 the ts is considered a minor effect however from the sv distribution we can see that the higher ts values accompany higher sm prediction apart from the several high values found in lower sm prediction in ale the tendency of ts affecting sm is quite straightforwardly demonstrated meanwhile this change of instances can be found more explicit in ice fig 8 e and dice fig 9 e following the physical mechanism the above interpretation confirmed by the prior knowledge from the hydrometeorological process can be considered appropriate and reasonable they can help to gain the reliability of the black box model further 4 1 3 pisw s multiple effects on sm can be revealed by xai tools in the hydrometeorological process pisw affecting sm is complex with multiple feedbacks the acknowledged mechanism in heihe river is strategically described as positive feedback and negative feedback zhang et al 2019 positive feedback of pisw on sm is that the hydrothermal interaction is activated while the sm is low thus the sm ascends as the pisw increase on the contrary negative feedback of pisw on sm in detail with the pisw increasing more energy is radiated from the surface which depresses the evapotranspiration and the reduction of sm is inhibited while the rf is well trained it can capture this phenomenon from ice plots the instance curves are separated into two branches which can represent both the positive feedback and negative feedback nevertheless other xai tools are not capable of this function except the ice this interpretation can reveal the change rule found by the black box model helping us users trust the model ice of pisw vividly presented the heterogeneity of instances and the ice of precipitation revealed the limitation of black box model in the unrealistic space summarily the ice is a valuable visualization tool to present the feature effects from the view of each instance 4 2 xai tools can facilitate to make countermeasures in advance currently the methods of artificial hydrometeorological intervention still need to be improved most of the methods are related to artificial precipitation here features referring to the precipitation are discussed including p0 p1 and p2 precipitation is considered a direct cause of the sm increase meng et al 2017 which can be easily found by mfi and sv in the alpine region the precipitation is considered a supply for soil moisture ma et al 2022 the high values of sv corresponding to the p0 p1 and p2 also present physical consistency in fig 5 b the result is in accord with the temporal observation that sm under the alpine tundra shrubland region is far more sensitive to single rainfall events sun et al 2015 notably we found an interesting phenomenon the svs of p1 were the highest followed by those of p0 it can be explained by the interception of the developing plant canopy hao et al 2010 except for sv ale can verify this finding which indicates that the effect of p0 on sm declines when the p0 exceeds 20 mm dai et al 2019 pointed out that in the alpine tundra region the rainfall is inclined to return to the atmosphere via evapotranspiration when precipitation is excessive thus we can obtain the effects of precipitation on sm via xai tools in order to take countermeasures in advance ice can give us some practical information some instances are captured by ice which are not sensitive to the p0 p1 and p2 those instances cannot be intervened in due to the specific conditions on the other hand a particular instance of sm prediction is vulnerable to precipitation which can be enhanced by artificial rainfall to avoid droughts 4 3 xai tools can figure out the inherent bias in data that might lead to the black box model s defeats firstly due to the lack of precipitation in the ha2 site the observed precipitation data is centralized in 0 mm it leads to inherent data bias caused by the observation and the maldistribution data damages the model and results in the inability of grasping the real world relations the ice plots can identify the inherent data bias particularly in the freezing period sm prediction with lower than 12 is inactive to the increasing p0 p1 and p2 in ice plots fig 8 similarly dice is competent to reveal the shortcomings of data bias from precipitation in some instances precipitation leads to the predicted sm decrease indicating the drawbacks another example is the dice of ts in fig 9 e for example dice plots of the le fig 9 f gpp fig 9 g and reco fig 9 h cannot be interpreted well while the le gpp and reco get to high value they have little impact on predicted sm it is unreasonable to refer to the data bias not only can the ice and dice identify the drawbacks of the rf model but 2d ale is also quantitative in fig 10 b there is a distinct blue section meaning that under 0 c with the le climbing the soil turned to humid it was estimated by the rf model basically this rarely happens in nature thus the 2d ale can reveal the estimated mistakes from the established model irrgang et al 2021 conclusively xai tools especially the ice dice and 2d ale are competent in identifying a particular data bias of the black box model 4 4 future work however many problems still need to be investigated by further studies we concluded the problems as follows a the reliability of 2d ale is a tough problem the number of intervals k is essential for leading to this problem when k changes the 2d ale can become very unstable see figs s6 and s7 in the supplementary materials which has also been found in many previous works different levels of k make noticeable differences leading to unreliable interpretation the reason is that 2d ale only shows the interaction effect of the features which is highly sensitive to k for each of the coupled features consequently although 2d ale is a feasible visualization tool for exploring the interaction effects of coupled features on predicted sm it would vary remarkably by changing the number of intervals its practical use can be further explored in future work in the future we aim to enhance the feasibility of 2d ale until the 2d ale can vividly reflect the insight of black box structure b we used rf as the only machine learning model multiple machine learning methods including deep learning models should be compared using the integrated xai tool to see their consistency and difference in capturing feature effects furthermore we also need to answer whether the model with best performance has the best interpretability as trivial coincidences may also lead to good predictions as an example we built a lstm model and compared it with the rf models by using xai methods and the details of results are given in the supplementary material we found some inconsistency of feature effects by xai which could be owe to the poor performance of lstm furthermore variables other than soil moisture should also be studies with xai tools c the prior knowledge used for consistency check in our study was based on articles published in authoritative journals however the natural mechanism is very complicated and changing evaluating the geophysical consistency and making good physical research hypotheses need further efforts with domain specific physical understanding and appropriate experimental design d due to the spatial temporal heterogeneity of hydrometeorological variables it is necessary to apply the xai tools to multiple sites and spatial continuous data i e remote sensing process based model output and reanalysis data in this regard the most valuable and challenging work is to identify general rules across space and time which can lead to new scientific discovery by xai tools e in terms of the discrepancies between the xai result and prior knowledge it is hard to distinguish the origins i e whether they come from the deficient model inherent data bias or novel knowledge this is crucial for interpretation of machine learning models in the future we will concentrate on the discrepancies and further gain the interpretability of black box models 5 conclusions machine learning model become increasingly popular in the field of hydrometeorological forecast due to their black box nature it is urgent to gain the interpretability and practicability of models to address this we integrated xai framework using several exquisite post hoc interpretable methods in this study we chose the sm prediction as an example to illustrate the interpreting tool primarily we chose a fluxnet site located in haibei china which is considered a promoter of climate change in china secondly the black box rf model was conducted to predict sm ultimately mfi sv pdp and 1d ale ice and dice 2d ale were embedded in the integrated xai method to reveal the feature effects from different views a mfi ranks the feature importance through contribution to the precision b sv estimates the feature contribution to the predicted result c 1d ale was used to explore the average predicted sm evolution with one feature variation in the overall range d ice and dice were used to show the predicted sm evolution of each instance with one feature variation e 2d ale visualized the interaction effects of two features on predicted sm the results show that comprehensive understandings of relationship between the predicted sm and its factors can be achieved while the black box model was interpreted by the integrated xai tool the study achieved remarkable results as the following recommendations a gain the reliability of the black box model based on the natural hydrometeorological process as prior knowledge if the result from xai tool can correspond to the knowledge the predicted result can be considered authentic time memory dynamics of ts affecting sm and pisw have the double effects on sm as demonstrated by xai tools it proves that the well trained rf model can grasp this natural characteristic from data and is of high reliability b provide multiple interpretable views the xai tool from different views can support the result significantly for example multiple evidence from mfi fig 4 sv fig 6 and 1d ale fig 7 shows that the intraday precipitation i e p0 has less impact on sm than those of 1 and 2 day lagged precipitation i e p1 and p2 mfi and sv generally show how significant the impact is while ale shows how sm changes with precipitation c the deficiencies of the model from inherent data bias were figured out by the xai tool for example due to the lack of precipitation in the ha2 site the inherent data bias was clearly dictated in the ice plot fig 8 n o and p in general in the field of the hydrometeorological forecast the integrated xai tool helps to prevent the barriers from the nature of black box ai techniques further it promotes a more intelligent ai application in the hydrometeorological forecast meanwhile well posed physical research hypotheses are needed in using these xai tools to aid the integration of scientific knowledge with machine learning and the fusion of process based models and ai reichstein et al 2019 credit authorship contribution statement feini huang methodology programming writing original draft software visualization wei shangguan conceptualization supervision validation qingliang li writing review editing lu li software data duration ye zhang visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we thank bingxue yang from institute of automation chinese academic of sciences for his valuable advices the study was supported by the national natural science foundation of china 41975122 42088101 u1811464 42105144 and 41730962 the national key r d program of china 2017yfa0604300 abbreviations abbreviation description ale accumulated local effects ai artificial intelligence ta average nighttime air temperature day day of the entire dataset doy day of year dice derivative ice reco ecosystem respiration xai explainable artificial intelligence r2 explained variance sm4 four days lagged soil moisture gpp gross primary production ice individual conditional expectation le latent heat flux ml machine learning mae mean absolute error mse mean squared error mfi mean squared error based feature importance mds minimum data set k number of intervals p1 one day lagged precipitation sm1 one day lagged soil moisture sm5 one day lagged soil moisture 1d one dimensional pdp partial dependence plot pisw potential incoming shortwave radiation p0 precipitation rf random forest rmse root mean squared error sbs sequential backward selection sfs sequential forward selection sv shapely value sm soil moisture ts soil temperature sm3 three days lagged soil moisture p2 two days lagged precipitation sm2 two days lagged soil moisture 2d two dimensional vpd vapor pressure deficit appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2023 105762 
25382,weather radars produce high spatial and temporal resolution observations of precipitation events over the years weather radar operators have updated their radar networks to exploit the latest technological advancements one of the most significant improvements in this matter was providing the radars with polarimetric capabilities as this allows the radars to gather more detailed information about the precipitation targets shape size phase and orientation the radar research community has been working along with these advancements to develop robust algorithms that boost the radar data applications such as radar quantitative precipitation estimation qpe rain microphysics analysis nowcasting of precipitation or numerical weather prediction based on radar measurements some of these algorithms have been implemented in open source toolboxes that aim to facilitate the processing and quality control of radar data produced by different radar systems however these open source toolboxes have not yet included a chain process tailored to the uk radar research context this paper presents a toolbox to process weather radar data in python towerpy towerpy can read process and display polarimetric radar data from different radar systems but it is specially customised for data produced by the uk met office radar network towerpy is built upon robust algorithms that cover various aspects of the radar data quality control e g calibration of radar measurements identification of non meteorological echoes attenuation correction among others and the computation of radar rainfall rates additionally a radar processing chain was devised using the towerpy modules to produce radar rainfall estimates raw polarimetric radar measurements collected by the uk met office radar network throughout the uk s wettest day on record were used as input for this processing chain the results confirm that towerpy is a powerful radar research tool and demonstrate its ability to generate functional radar qpe that can be used to improve operational radar rainfall products keywords weather radar polarimetry radar qpe radar research applications open source data availability chenies c band rain radar dual polarisation products are available at https catalogue ceda ac uk uuid bb3c55e36b4a4dc8866f0a06be3d475b met office 2013 jersey c band rain radar dual polarisation products are available at https catalogue ceda ac uk uuid 231b2448a02a45dfa810739f8d6abbe3 met office 2022 other met office s c band rain radar dual polarisation products are available at https catalogue ceda ac uk uuid 82adec1f896af6169112d09cc1174499 met office 2003 the latest release of towerpy and supporting data can be downloaded from https github com uobwatergroup towerpy software availability software name towerpy toolbox for processing weather radar data in python developers daniel sanchez rivas and miguel angel rico ramirez year of first official release 2022 hardware requirements pc system requirements linux windows program language python program size 10 mb availability https github com uobwatergroup towerpy license gpl 3 0 documentation readme in the github repository and project documentation that includes a collection of references tutorials and examples in interactive jupyter notebooks 1 background weather radar applications are diverse meteorologists hydrologists and scientists from different fields exploit the radar s high spatial and temporal resolution information to probe the atmosphere research studies by borga 2002 einfalt et al 2004 athanasiadis et al 2009 zhang and srinivasan 2010 liguori and rico ramirez 2014 thorndahl et al 2017 ochoa rodriguez et al 2019 sivasubramaniam et al 2019 wijayarathne and coulibaly 2020 provide an in depth review of different meteorological and hydrological applications of weather radar such as forecast of precipitation events monitoring meteorological conditions that lead to flash floods in near real time or for radar qpe among several other applications indeed meteorologists exploit weather radar data for precipitation forecasting especially to predict heavy rainfall events with a lead time of a couple of hours ahead e g for nowcasting applications which in turn are indispensable for triggering flash flood warnings for example price et al 2012 described the implementation of a distributed hydrological model based on short term radar rainfall forecasts and nwp numerical weather prediction forecasts used in england and wales their results showed how the model could help to predict developing flood risk over longer lead times and over gauged and ungauged catchments gourley et al 2014 assessed different tools used in operational flash flood forecasting in the usa they concluded that hydrological models driven by radar observations are more skilful in identifying flood producing discharges mainly due to the ability of radars to provide rainfall measurements and forecasts in near real time seo and krajewski 2020 developed a real time qpe system capable of retrieving data from operational radars and nwp models and generate reliable products for flood prediction in iowa usa this system uses a variety of algorithms to quality check the data and accounts for uncertainties in radar qpe imhoff et al 2020 used radar derived rain fields to compare the efficacy of different nowcasting methods with respect to the duration of precipitation events season radar location and type of catchment their results demonstrated the utility of radar nowcasting products especially for winter stratiform precipitation events where errors in the nowcasting were three times lower than in convective summer precipitation events however they stress that improvements in radar rainfall products are needed to forecast longer lead times likewise dance et al 2019 stein et al 2020 exploited data collected by the uk met office radar network to improve the forecasting of extreme precipitation and flooding events in the uk they combined radar data with rain gauge data and nwp forecasts to provide decision makers and emergency responders with flood risk forecasts especially during heavy rain events the results of these projects emphasise the importance of weather radar information to characterise extreme rain events forecast short term precipitation events nowcasting and consequently issue timely flash flood early warnings the literature presented above recognises radars as a great asset for monitoring flood producing storms however these studies also stress the importance of controlling the quality of radar data to ensure the reliability of radar rainfall estimates weather radar does not measure rain rates directly but these are derived from the electromagnetic properties of hydrometeors instead increasing the uncertainty in radar rainfall products battan 1973 illingworth et al 2000 marshall and palmer 1948 ryzhkov et al 2005b it is well known that weather radar measurements can be affected by different error sources such as radar miscalibration atlas 2002 borowska and zrnic 2012 collier 1996 gabella and leuenberger 2017 blockage of the radar beam bech et al 2003 gou and chen 2021 hong and gourley 2015 problems with beam propagation such as ground clutter torres and zrnic 1999 rico ramirez and cluckie 2008 steiner and smith 2002 torres and zrnic 1999 anomalous propagation grecu and krajewski 2000 rico ramirez and cluckie 2008 seo et al 2015 or degradation of radar quality with range krajewski et al 2010 kumjian 2013 ryzhkov 2007 variation of the vertical profile of reflectivity kitchen et al 1994 smyth and illingworth 1998b or attenuation of the radar signal bringi and chandrasekar 2001 fabry et al 1994 smyth and illingworth 1998a the radar community has been working for the last forty years or so to develop algorithms that aim to minimise the impact of such error sources and improve rainfall estimation based on radar measurements however despite all the progress made in this matter residual errors in radar rainfall estimates are still present and can propagate through other models that use radar rainfall products for flood forecasting applications with the development of radar polarimetry and its implementation in many weather radar networks around the world in recent years radars gather more details about the shape size phase and orientation of precipitation targets hence radar users and researchers have focused on developing polarimetric algorithms that improve the quality of radar rainfall estimates for example testud et al 2000 presented the so called self consistent approach to monitor radar calibration using the relationship between reflectivity z h differential reflectivity z d r and the differential propagation phase φ d p this method has been tested in various radar campaigns to calibrate z h see e g frech et al 2017 gourley et al 2009 gorgucci et al 1992 ryzhkov and zrnić 1996 several methodologies developed for identifying non meteorological echoes based on polarimetric measurements have shown the added value of polarimetric radar in improving data quality gourley et al 2007 lepetit et al 2021 rico ramirez and cluckie 2008 on the other hand brandes and ikeda 2004 boodoo et al 2010 matrosov et al 2007 wolfensberger et al 2016 demonstrated that using polarimetric measurements especially the correlation coefficient ρ h v improves the detection of the melting layer an essential atmosphere s feature for differentiating between solid and liquid hydrometeors besic et al 2016 lukach et al 2021 park et al 2009 presented hydrometeor classifiers to improve the identification of different types of hydrometeors by exploiting polarimetric radar observations additionally polarimetric algorithms have been proposed in the literature for correcting the attenuation of the radar signal power due to rain using differential phase measurements these algorithms incorporate φ d p see e g bringi et al 2001 park et al 2005 rico ramirez 2012 testud et al 2000 or the specific differential phase k d p see e g tabary et al 2009 gourley et al 2009 ryzhkov et al 2014 to correct for radar signal attenuation due to rain these algorithms have proven to be more stable and accurate than those based solely on z h finally different studies have evaluated polarimetric algorithms for the estimation of rainfall rates bringi et al 2011 figueras i ventura et al 2012 gourley et al 2010 husnoo et al 2021 rico ramirez and cluckie 2006 ryzhkov et al 2014 vulpiani et al 2012 these studies provided rainfall algorithms for different radar frequencies and geographical conditions which influence the variability of the drop size distribution dsd and demonstrated that polarimetric rain rate estimators are capable of producing more accurate rain estimates providing the radar measurements are well calibrated however processing raw polarimetric weather radar data to generate radar qpe products is a technically challenging task it involves a basic understanding of the principles of weather radars and the implementation of algorithms to acquire process and display raw radar data given that commercial software is neither suitable nor available for research purposes it takes a considerable amount of time and effort to develop code for reading raw radar data or reproducing existing algorithms therefore it is not surprising that members of the weather radar community have been working on developing open source toolboxes to face these challenges each toolbox has been designed and conceived for specific contexts to meet the needs of different radar networks three of the most popular python toolboxes are summarised hereunder outlining their background and main features 1 wradlib heistermann et al 2013 is a radar library developed by researchers from the university of potsdam and the university of stuttgart germany it provides tools to process polarimetric radar data collected by the c band radar network operated by the german weather service dwd as well as other radar data formats like netcdf or hdf5 standard formats used by other radar processing software wradlib provides algorithms for processing weather radar data like reading common data formats identifying and correcting typical error sources such as clutter or attenuation estimating rainfall rates and visualising radar data 2 py art helmus and collis 2016 is used by the atmospheric radiation measurement arm climate research facility for processing data from nexrad the s band doppler weather radar network operated by the u s national weather service nws but it is also capable of reading other weather radar formats like sigmet iris mdv or cf radial and processing data from other radar frequencies e g c band and x band frequencies py art includes modules to display and correct radar data and the algorithms include attenuation correction of the reflectivity or processing the specific differential phase 3 pyrad is a radar data processing framework developed by meteoswiss figueras i ventura et al 2020 it can be seen as an extension of the py art but tailored to process data from the c band swiss weather radar network pyrad provides tools to produce radar qpe as shown in table 1 including clutter detection hydrometeor classification algorithms attenuation correction and rainfall rate estimation most of these modules incorporate polarimetric radar measurements into the algorithms a summary of the features and capabilities of the toolboxes described above is given in table 1 the above mentioned open source libraries have created a growing community of radar researchers working with radar data worldwide increasing the reproducibility of novel radar algorithms and even contributing to the software used by operational weather radar networks however reading and processing radar data collected by the uk weather radar network remains challenging for open source radar researchers the current binary format used by the met office cannot be read nor further processed by any open source library furthermore it is difficult to find tailor made algorithms that exploit the radar surveillance strategy implemented by the met office for example using linear depolarisation ratio ldr measurements for classifying weather radar clutter echoes this challenge motivates the current study in which we deliver a new research tool to process polarimetric radar data but specifically conceived within the uk radar research context this tool known as towerpy toolbox to process weather radar data in python incorporates standard procedures to process c band polarimetric weather radar data this tool can help radar users to work with the raw radar data test different radar polarimetric algorithms to improve radar qpe and evaluate the impact of each of the different algorithms implemented within the toolbox in this paper we introduce towerpy and the polarimetric algorithms implemented within each module we demonstrate the performance of towerpy by generating radar quantitative precipitation estimates based on polarimetric algorithms the paper is organised as follows in section 2 we describe the configuration and products of the uk radar network as it is the main data source used in this study in section 3 we outline the towerpy toolbox and provide some code examples to work with the modules section 4 shows a radar processing chain designed to process data from the uk radar network to generate the final radar rainfall product finally we summarise the main contributions of this research in section 5 2 uk weather radar network description and product generation the c band weather radar network deployed in the uk consists of 15 doppler polarimetric radars operated by the uk met office 1 doppler polarimetric radar operated by the jersey met services and 2 doppler polarimetric radars operated by met éireann harrison et al 2012 as shown in fig 1 the scanning strategy implemented by the uk met office consists of a series of low elevation scans between 0 5 and 4 every 5 min when the radars are operating on long pulse mode pulse length equal to 2 000 μ s covering a range of 250 kilometres with a gate resolution of 600 metres also when the radars operate on the long pulse mode they generate ldr measurements every five minutes the radars also operate on short pulse mode pulse length equal to 500 μ s producing scans at different elevation angles 1 2 4 6 9 90 every 10 min with a gate resolution of 600 metres and a maximum range of 115 kilometres except for the vertical pointing measurements in which the gate resolution is 75 m and the maximum range height is close to 12 kilometres met office 2003 such scanning strategy enables to collect measurements of reflectivity z h radial velocity v differential reflectivity z d r correlation coefficient ρ h v differential propagation phase φ d p and linear depolarisation ratio l d r met office 2003 note that l d r scans are only produced for the lowest elevation 0 5 further details on the configuration of the uk met office radars are provided in table 2 the radar data are gathered by the met office s cyclops system a fully automated system deployed at each radar site and processed by the radar team at the uk met office to generate weather radar rainfall estimates and short term radar based rainfall forecasts harrison et al 2015 these rainfall products are available across the uk with spatial and temporal resolutions of 1 km and 5 min respectively the radar rainfall products and raw polarimetric data from single sites are available at the centre for environmental data analysis ceda archive in the form of binary files met office 2003 the uk met office has implemented a radar processing chain to generate a radar rainfall product over the uk at 1 km 5 min spatial temporal resolution for hydrological purposes it is based on the lowest usable scan i e the radar scan less contaminated with ground clutter the processing of the raw radar data consists of the following main steps dance et al 2019 harrison et al 2009 2012 1 the noise power of the weather radar receiver is computed following the method proposed by ivić et al 2013 that computes a range independent radial noise estimator met office 2019 2 non meteorological echoes are removed using an approach similar to that proposed by rico ramirez and cluckie 2008 in which a probabilistic naive bayes classifier is applied to radar data to identify spurious echoes dance et al 2019 3 partial beam blockage pbb is corrected only if the beam is 50 blocked or less this value is computed by comparing the reflectivity at each gate over short ranges at two different elevations 0 5 and 2 in widespread rain digital elevation models dem and seasonal variations are also analysed to detect the pbb effects illingworth and thompson 2017 4 the variations of the vertical profile of reflectivity vpr are corrected following the method proposed by kitchen et al 1994 but also gathering information on the melting layer thickness from nwp models and satellite observations harrison et al 2009 husnoo et al 2021 5 attenuation corrections for heavy rain are carried out by following the hitschfeld and borden hereinafter hb approach dance et al 2019 based on single polarisation products however this method is refined using polarimetric data namely φ d p and radiometric emissions tompson et al 2012 by constraining the application of the hb approach darlington et al 2016 6 rain rates are derived from radar reflectivity using the relation given by equation z a r b with the coefficients fixed as a 200 and b 1 6 harrison et al 2012 7 a gauge based adjustment factor is applied to all coverage areas of each radar in real time the number of gauges used to compute the factor varies depending on the radar site whereas the time resolution can vary depending on up to date weather conditions golding 1998 harrison et al 2009 2015 8 finally the precipitation rate composite is generated by processing radar data from all the radar sites the radar rainfall composite is based on a distance weighting method that determines the contribution of each radar bin depending on the locations where data from more than one radar site overlaps harrison et al 2009 it is also worth mentioning that the polarimetric data collected by the uk radar network has been exploited by many researchers to develop polarimetric based weather radar algorithms with the primary goal of improving radar qpe products e g bringi et al 2011 hall et al 2015 jewell and gaussiat 2015 liguori et al 2012 pickering et al 2019 rico ramirez and cluckie 2008 rico ramirez 2012 3 towerpy description capabilities and implementation towerpy is a cross platform software mainly written in python designed to read process and display raw polarimetric data from single radar sites from the uk weather radar network it is built on top of numpy the primary array programming library for the python language harris et al 2020 and matplotlib a python library for creating static animated and interactive visualisations hunter 2007 towerpy provides the essential tools to process weather radar data and achieve accurate radar qpe see fig 2 but each module can be seen as the building blocks of many other applications of weather radar data furthermore the modular design of towerpy enables its compatibility with other open source libraries in the following sections the modules comprising the towerpy toolbox are described along with the algorithms implemented on each module an in depth description of the inputs outputs and arguments of the modules comprising towerpy is provided in the code documentation of each function 3 1 data import io the io module is an interface to read in radar data the function ppi ukmoraw is capable of decoding the binary data files currently used by the uk met office such files store plan position indicator ppi scans in polar data format taken at one of the different elevations comprising the uk radar scanning strategy each file contains different radar measurements such as the radar reflectivity z h the radial velocity v and the polarimetric variables z d r φ d p ρ h v l d r among others taken either at short or long pulses likewise the ppi ncasx function imports data collected by the uk national centre for atmospheric science ncas mobile x band radar network these radars provide doppler and polarimetric rainfall measurements with high spatial resolution this module also provides a function ppi emptylike to create an empty like object listing all the radar fields required to work with other modules of towerpy the generated object can be filled up with radar data from other libraries a comprehensive example of this function is provided on the project documentation as a jupyter notebook 3 2 classification of non meteorological echoes eclass the eclass module comprises algorithms for classifying meteorological and non meteorological echoes first the signalnoiseratio function computes the signal to noise ratio snr in db and discards data using a reference noise value given by the user the snr is given by 1 s n r z h 20 l o g 10 r c where z h is in dbz r is the range of a given radar pixel in km and c is the radar constant in db if the snr for a given pixel is below the minimum snr then that pixel is classified as noise the user defines the minimum snr by trial and error for example selecting a very low value of the minimum snr will classify the noise as signal then the clutter id function is a classifier for meteorological and non meteorological radar echoes it is based on the methodology proposed by rico ramirez and cluckie 2008 in which a bayes classifier is used to detect weather radar clutter such as ground clutter sea clutter and anomalous propagation echoes this novel algorithm incorporates the texture of polarimetric fields and clutter maps to improve classification performance the texture is a measure of how noisy the radar measurements are and it is given by the standard deviation of all pixels within a window centred on a given radar pixel the texture is also a function of the number of independent uncorrelated samples averaged to produce a given radar measurement rico ramirez and cluckie 2008 showed that precipitation echoes have a relatively low texture low noise compared to non meteorological echoes such as those due to ground clutter or anomalous propagation which show higher values of texture especially in z d r and φ d p see fig 3 these textures are represented as membership functions mfs which are calibrated based on past data the mfs are generated using a 3 3 window with a gate size of 600 m a pulse repetition frequency of 300 hz and 1 4 revolutions per minute such functions may also be applied to c band radars with similar characteristics the mfs are provided as two column ascii files that describe the probability of a given variable see table 3 associated with precipitation or clutter echoes fig 3 shows the normalised frequency distributions of these mfs scaled to the range 0 1 for comparison purposes additionally towerpy provides a collection of clutter maps for 4 different elevations 0 5 1 2 3 4 related to the chenies radar site currently only clutter frequency maps for the chenies radar are available but we expect to further expand these functions for the rest of the radar sites many scans taken during dry days were used to derive these clutter frequency maps this traditional method used to detect ground clutter for single polarisation radars can be performed by calculating the number of times or scans that a given pixel shows a value related to the signal not classified as noise when using the signalnoiseratio function and divided by the total number of scans this gives a probability of that pixel being clutter contaminated for a given elevation there are pixels where the probability is high and others where it is relatively low the idea is to use as many radar scans on dry days as possible to capture the most cluttered regions fig 11a shows a clutter map generated using scans taken at 0 5 elevation angle 3 3 polarimetric profiles generation profs the profs module enables the generation of profiles of radar measurements more specifically vertical vp and quasi vertical qvp profiles of polarimetric variables the pol vps function uses measurements taken at vertical incidence to generate vps vps are built by averaging a single 360 scan taken at a 90 elevation angle the vps enable the monitoring of the calibration of radar variables such as z d r or φ d p frech and hubbert 2020 gorgucci et al 1999 moreover the vps are also useful for detecting the melting layer as demonstrated in the literature baldini and gorgucci 2006 brandes and ikeda 2004 sanchez rivas and rico ramirez 2021 on the other hand the pol qvps function provides a tool to generate qvps of radar variables the qvps are built following the procedure proposed by ryzhkov et al 2016 in which a ppi scan taken at a high elevation angle is averaged azimuthally additionally towerpy can also generate range defined quasi vertical profiles rd qvps the function pol rdqvps provides a refined version of the qvp methodology introduced by tobin and kumjian 2017 for this function defining a range from the radar within all available elevation angles is necessary the data is averaged according to the specified range using inverse distance weighting as suggested by tobin and kumjian 2017 qvps have proven to be effective in monitoring the development of precipitation events especially using a height time indicator hti plot and in capturing certain microphysical processes within the atmosphere such as the melting layer griffin et al 2020 sanchez rivas and rico ramirez 2021 trömel et al 2019 the generation process of the vps and qvps can be customised by setting arguments that modify the profiles for example users can set thresholds to the radar variables e g ρ h v 0 6 and z h 10 dbz as specified by ryzhkov et al 2016 and to the number of valid gates for the azimuthal averaging process additionally both the pol vps and pol qvps functions provide statistics related to the averaging process of the rays to enable a comprehensive analysis of the profiles 3 4 melting layer detection ml this module can be used to estimate the height and boundaries of the melting layer ml knowledge of the ml boundaries is essential in radar rainfall estimation as it describes the transition of hydrometeors from a solid to a liquid phase within the ml detection function there is a robust melting layer detection algorithm based on the approach proposed by sanchez rivas and rico ramirez 2021 the algorithm can process vps or qvps built from weather radar scans to detect ml signatures within the polarimetric profiles the logic behind the algorithm is to produce a profile with strong gradients within the ml by combining different polarimetric profiles a peak finder routine is applied to the profiles to detect enhanced maxima related to the ml the parameters described in sanchez rivas and rico ramirez 2021 are set as default arguments for the ml detection function however the user can refine the detection of the ml by modifying such arguments for example the user can define a minimum and maximum height within the profiles for the algorithm to search for the ml signatures or select a different combination of profiles to be used to generate the profile with enhanced peaks 3 5 calibration of polarimetric variables calib the calib module includes different routines to monitor and correct the calibration offsets in z d r and φ d p this module is highly dependent on the polarimetric profiles and the height of the ml for z d r towerpy provides different procedures for detecting the system offset using vps or qvps of polarimetric variables the foundation of these procedures lies in the detection of z d r values that differ from those expected for natural targets such as light rain or dry snow first the zdr offsetdetection vps function contains two of the most popular techniques found in the literature the first method proposed by gorgucci et al 1999 suggests detecting the z d r offset using observations of raindrops collected during light rain as the radar antenna rotates about the vertical values of z d r different from zero found within the rain region of the vps i e below the ml are averaged to estimate the z d r offset the second method proposed by ryzhkov et al 2005a works by detecting dry snow regions within the vps usually found just above the ml values close to zero are expected for this type of target hence the mean of z d r related to dry snow is used to estimate the z d r offset on the other hand the zdr offsetdetection qvps function provides a methodology for computing the z d r offset using qvps as described in sanchez rivas and rico ramirez 2022 as above this method estimates the z d r offset within the qvps by comparing the observed values of z d r during stratiform light rain events to an expected value this intrinsic value is computed from dsd simulations using disdrometer data and is linked to the elevation angle from which the qvps were built the user can customise many parameters to implement these methods and calibrate z d r such as setting the height of the melting layer thresholds in the values of the polarimetric profiles or the number of bins to include in the analysis in addition the phidp offsetdetection vps function provides a method to detect a reference offset introduced by the hardware specifications this offset is typically due to differences between the wave guide lengths of horizontal and vertical pulses frech 2013 and this offset does not represent a problem in radar qpe using k d p as k d p is the derivative of φ d p however it is good to remove this system offset before computing k d p the computation of the φ d p offset using vps follows a similar procedure to that proposed for estimating the z d r offset 3 6 attenuation correction attc this module contains routines for correcting the attenuation of the radar signal due to rain these algorithms compute the attenuation in z h and z d r also it is important to mention that their performance is highly influenced by a proper delimitation of regions within the ppi scans that contain liquid and solid precipitation the zh correction function includes seven algorithms previously proposed in the literature see table 4 each algorithm has its own advantages and disadvantages such as the radar variables used for the attenuation correction their stability and different computational cost these attenuation correction algorithms are described in detail by rico ramirez 2012 and are briefly described next first it is importat to define that the nonattenuated reflectivity can be related to the reflectivity z h h m measured by the radar and to the attenuation a h r by 2 10 l o g z h h r 10 l o g z h h m r 2 r 0 r a h s d s the hitschfeld and bordan 1954 hb algorithm is given by vulpiani et al 2006 3 a h r a z h h m r b 1 j r where a h r is the signal attenuation in db km r is the range in km j r 0 46 b r 0 r a z h h m s b d s and the parameters a and b depend on the radar frequency temperature and dsd r 0 is the initial range of the rain cell in km and s refers to the segmentation of the rays this method is sensitive to radar calibration the final value fv algorithm is based on the method proposed by iguchi and meneghini 1994 where the attenuation is computed by 4 a h r a z h h m r b a f b j r m j r where log a f 0 1 α δ φ d p r 0 r m and δ φ d p represents the total differential propagation phase and r m is the range on the far side of the rain cell the algorithm proposed by testud et al 2000 zphi uses δ φ d p constrained to ranges across a rain cell to estimate the total path integrated attenuation pia for this method the attenuation is expressed as follows 5 a h r z h h m r b a f b 1 i r 0 r m a f b 1 i r r m where i r r m 0 46 b r r m z h h m s b d s and a f is given by the equation defined previously the bri algorithm is an implementation of the method proposed by bringi et al 2011 to correct the attenuation on z h this method is an extension of the zphi method but the derivation of the parameter α affecting the total differential propagation phase δ φ d p is optimised by minimising the differences between the measured φ d p and reconstructed φ d p c from the computed attenuation and is given by 6 φ d p c a b α r 2 r 0 r a h s a b α d s the algorithms mentioned above also calculate the path integrated attenuation pia given by bringi et al 1990 testud et al 2000 7 p i a α δ φ d p towerpy also includes refined versions of the algorithms mentioned above these algorithms follow an adaptive technique to compute the parameters of the methods described above as proposed by rico ramirez 2012 these adaptive techniques minimise the errors in the attenuation correction these algoriths are shown as ahb afv and abri in table 4 on the other hand the adaptive attenuation correction in z d r brizdr is implemented in the function zdr correction which calculates the specific differential attenuation a d p following the method proposed by bringi et al 2001 the correction method computes a d p as 8 a d p r β β α o p t a h r α o p t where a h and α can be estimated using any of the methods described above and β is given by 9 β δ z d r r m φ d p r m φ d p r 0 where δ z d r r m is the difference in db units on the far side of the rain cell between the measured z d r and an intrinsic average value z d r the latter is a theoretical value computed using corrected values of z h then β is adjusted to minimise the error between z d r measured and z d r theoretical there are two ways to calculate z d r implemented in the zdr correction function the first is given by bringi et al 2001 10 z d r r m 0 z h r m 20 d b z a z h r m b 20 z h r m 45 d b z where the parameters a b have default values of 0 048 and 0 774 respectively but they can be modified by the user the second uses the exponential equation 11 z d r r m a z h b r m where parameters a b can be defined by the user in this case the default values are a 0 00012 and b 2 5515 according to gou et al 2019 additional arguments for the zh correction and zdr correction functions are required for the attenuation correction users must define the height of the melting level a window size in φ d p where an averaging process is performed to smooth the signal the number of bins to be averaged at the far range of the rain cell to compute δ z d r r m and other thresholds to constrain the correction algorithm only to echoes corresponding to hydrometeors in the liquid phase 3 7 quantitative precipitation estimation qpe this module provides different algorithms to estimate rain rates using radar data different rain rate estimators are implemented in this module including those that incorporate polarimetric measurements note that the parameters a and b in the equations below are different to those defined in section 3 6 12 z h a r b 13 r z h z d r a z h b z d r c 14 r k d p a k d p b 15 r k d p z d r a k d p b z d r c 16 r a h a a h b where z h 1 0 0 1 z h z d r 1 0 0 1 z d r r is in mm h 1 z h and z d r are in dbz and db respectively z h is in mm 6 m 3 k d p is in deg km 1 and a h is in db km 1 bringi and chandrasekar 2001 bringi et al 2011 hong and gourley 2015 marshall and palmer 1948 rico ramirez and cluckie 2006 ryzhkov et al 2014 among others derived the optimal values of the coefficient in those equations depending on the radar wavelength and different geographical conditions moreover some of these algorithms can be combined depending on adaptable thresholds or parameters these so called hybrid rain rate estimators improve the rain rate estimation by constraining the application of the polarimetric estimators depending on the rain type or intensity for example the estimator based on z h eq 12 can be complemented with other radar variables such as a h as the latter is more efficient for estimating moderate to heavy rain rates due to its less sensitivity to dsd variations ryzhkov et al 2014 e g using eq 12 for values of z h below 40 dbz and then using eq 16 for values equal or above 40 dbz may produce more accurate radar rain estimates table 5 provides examples of the values used for different radar frequencies or precipitation regimes in the radar qpe these parameters are fully customisable and can be modified accordingly within this module 3 8 data georeferencing georad users can apply the functions within this module to generate and process georeferenced data as the radar provides the data in polar coordinates i e in range azimuth format the pol2cart function transforms polar coordinates into rectangular cartesian coordinates this system describes the position of the data in a two dimensional system using the perpendicular axes x and y and using the radar position as the origin of the coordinate system conversely the cart2pol function transforms cartesian coordinates into polar coordinates the osgb2lalo and lalo2osgb functions transform coordinates between the ordnance survey os uk national grid eastings and northings and ellipsoidal coordinates latitude and longitude following the coordinate systems in great britain guide by ordnance survey 2020 this function is important because the os grid is used on most british maps the height beamc and cartesian distance functions are useful to calculate the height of the centre of the radar beam above the earth s surface 3 9 radar data visualisation tools datavis visualising radar imagery is essential for understanding and interpreting weather radar data towerpy provides functions to display and interact with radar data in different ways these modules are built upon matplotlib and are capable of generating specialised and interactive radar displays tailored to radar research applications for instance the rad disp and the interactive disp functions provide routines for visualising and exploring ppi and hti plots plots displaying the results of the methodologies described above are also implemented in these modules for instance fig 4 shows a ppi scan of ρ h v along with the beam s height and the radar variables radial profiles for the selected azimuthal angle these radial profiles can be selected with a mouse click on the ppi scan fig 8 displays several hti plots each of these hti plots is interactive and it is possible to visualise and change with a mouse click the displayed polarimetric profiles of precipitation events and their statistics such as the standard deviation furthermore fig 5 shows step by step ml detection using vps fig 10 and fig 11 shows plots of the snr and clutter classification results 3 10 radar utilities utils this module is a collection of functions helpful for processing and analysing radar data for instance the normalisenan function scales input vectors to the unit norm using given values maf radial smooths a selected radar variable along the radial direction using a moving average filter the xdb2x function can be used to transform reflectivity measurements between linear and dbz units these are just a few examples more functions can be found within this module this section described the modules comprising the towerpy toolbox the following section introduces a radar processing chain that generates radar quantitative precipitation estimates using the modules and functions presented above data generated by the operational uk weather radar network will be used to demonstrate the capabilities of the toolbox 4 use of towerpy to generate radar qpe raw polarimetric data collected by the uk met office s operational radar network throughout the 3rd of october 2020 at different elevation angles and from all the radar sites will be used to demonstrate the capabilities of towerpy according to kendon and mccarthy 2021 this was the uk s wettest day on record where an average of 31 7 mm of rain fell across the entire united kingdom and 100 mm or more in a few locations in the first four days of october storm alex brought widespread heavy rainfall across various regions in europe and the uk causing extreme flooding infrastructure damage and fatalities much of central southern england and aberdeenshire recorded more than the whole month average rainfall in the first four days of the month alone thus this day is a perfect study case to show the performance of towerpy to read process and display radar data met office rain radar data were downloaded from the ceda catalogue from the 3 10 2020 at 00 05 gmt 1 to the 3 10 2020 at 23 59 gmt 1 there were approximately 4 660 ppi scans in the form of binary files on that day from all the radar sites and spanning all possible elevations of the scanning strategy described in section 2 first it is important to monitor the development and evolution of the precipitation event thus hti plots were created to this end using vps and qvps from scans collected at 90 and 9 elevation angles respectively see fig 7 and fig 8 fig 6 shows the python code to initialise a towerpy radar object line 14 read in ppi scans containing uk raw polarimetric data line 15 suppress noise lines 21 23 generate and plot the qvps of polarimetric variables lines 29 34 detect the melting layer lines 40 41 and compute the z d r offset lines 47 48 lines 55 76 plot relevant figures that help interpret the radar data note that the argument exclude vars w m s sqi ci db was used in the ppi ukmoraw function as these variables will not be used at this stage the value of the argument min snr 55 db was defined by trial and error for all radars this value with slight variations was found to work with all radar sites the qvps were then generated using the pol qvps function as mentioned above the qvps are built by averaging the 360 rays of the ppi scan to capture the spatial structure of the storm with a temporal resolution of 10 min note that the argument stats was set as true in this function to generate statistics about the qvps generation such as the standard distribution sd or the standard error of the mean sem these statistics enable the analysis of the dispersion of the averaged values which is helpful in understanding the inherent error structure of the qvps finally the melting layer and z d r offset detection processes were carried out exploiting the information provided by the qvps using the ml detection and offsetdetection qvps functions respectively note that both functions take different arguments to adjust their performance moreover the latter requires the user to define the height of the ml fig 7 shows hti plots of qvps of z h from data collected at all radar sites across the uk the melting layer heights detected using the ml module are also shown as dotted lines it can be seen that this rain event produced high reflectivity values at various radar sites that can be associated with heavy rain rates however the well known bright band bb is also visible on almost every radar site the bb is the radar signature of the melting layer caused by melting particles that yield high values of z h for example for the chenies radar site fig 7 b high values of z h 40 dbz are observable even below the melting layer 1 5 km in height around 21 00 h these plots were made using functions within the datavis module note that single profiles are shown in a separate panel of the plot these panels allow detailed visualisation of the profiles shape and statistics e g the sd it is worth mentioning that data from high elevation angles at the predannack radar site were not available for this particular day only 0 5 elevation scans were available consequently it will be excluded from subsequent analysis as it was not possible to detect both the ml and z d r offset a similar procedure was carried out to read in and process birdbath scans 90 and generate vps of radar variables fig 8 shows hti plots of vps generated from the radar sites mentioned above each vp is generated from birdbath scans produced every 10 min note that the first kilometre is not usable due to the configuration of the radars when the antenna is pointing vertically moreover this issue extends up to 1 5 km in height for some radars e g the munduff hill radar site fig 8 n where the first 1 5 km in height is contaminated with spurious echoes this radar site also depicts one major problem related to the vps relatively low heights of the ml around 10 00 am cause a lack of data below the ml i e no data associated with the rain medium hampering the application of algorithms based on the intrinsic value of light rain this problem can be solved using qvps as these profiles are not affected by this limitation see for example fig 7 n however the vps have some benefits over the qvps for instance the standard deviation is smaller in the vps compared to the standard deviation observed in the qvps due to the inherent generation process of the latter this situation can be seen in fig 7 f where the standard deviation of the qvp blue area in the right panel below the melting layer 2 km is surprisingly high 4 dbz in contrast the vp shown in fig 8 f exhibits a standard deviation of 0 5 dbz below the melting layer bottom it is recommended to use both methods vps and qvps to look at the vertical structure of precipitation because each method reveals specific information about the evolution of the storm the process described in this section enabled the detection of the melting layer and the computation of the z d r offset these steps are necessary to apply other algorithms designed to work in the rain medium use calibrated radar variables as inputs and produce radar qpe next we will show how to use the towerpy functions to generate radar qpe in these examples long pulse scans will be used these scans were taken at 0 5 elevation angle every 5 min from the operational uk weather radar network fig 9 shows the radar processing chain used to process single site radar data which will be described next for this elevation angle the minsnr argument of the function signalnoiseratio takes a value of 35 db this value was checked at all radar sites and proved to be effective in removing noise within the scans fig 10 shows the signal to noise ratio snr in db from the authors experience plotting ρ h v is a good practice to identify the limits of noise and signal in the scan next non meteorological echoes clutter were identified using the clutter id function in this example data from the chenies radar site were used to show the results of the clutter classifier fig 11 a shows the clutter map generated using 0 5 elevation angle scans clutter frequency maps cm help to improve clutter identification as shown in fig 11 b however results from other radar sites confirm the efficacy of the clutter identification algorithm as non meteorological echoes were effectively removed from the scans in the next step the melting layer and the z d r offset computed from high elevation angles are defined using the ml and calib modules these two features are essential in the following steps the attenuation corrections of the radar signal on z h and z d r were carried on using the attc module as described in section 3 6 there are different algorithms implemented in this module but they require the definition of the melting layer to achieve optimal performance for this case study the abri method was selected to correct the attenuation in z h as optimising the parameters in eqs 5 and 6 yields more accurate results as shown by rico ramirez 2012 note that the argument mlyr is related to the melting level i e the melting layer top and the thickness of the melting layer the rest of the parameters pdp pxavr rng pdp pxavr azm pdp dmin are necessary to smooth the φ d p signal within a defined window on the other hand the function zdr correction was applied to correct the attenuation in z d r as mentioned above this method requires the height of the melting level to discriminate between liquid and solid precipitation mlyr argument and to define a window size to smooth the signal i e rhv thld minbins mov avrgf len and p2avrf however it also requires the outputs of the z h attenuation correction i e α a h to compute the specific differential attenuation as shown in eq 8 fig 12 shows the attenuation correction results using data collected at the jersey radar site note that the analysis was constrained to data taken below the melting layer and new variables were computed like a h db km a d p db km φ d p or p i a db as described in section 3 6 the offset corrected φ d p is also shown since this variable is essential due to its immunity to attenuation the attenuated z h shows that heavy rain close to the radar site causes a loss in signal power that produces attenuated values of z h beyond the heavy rain cells especially in the south of the radar scan analogously z d r was also affected by attenuation but this issue was corrected by this function generating relatively high values of a d p 0 1 db km finally rain rate estimators were used to produce radar qpe the qpe algs module contains different rain estimators such as the traditional method based on the z r relation but also other polarimetric based estimators for this case study eqs 12 13 and 16 were used to derive rainfall intensities from radar measurements fig 13 shows the results of the rain estimation for data collected at the jersey radar site fig 13 a shows rain rates computed using eq 12 but z h values were not corrected for attenuation coefficients a b take the values shown in table 5 related to stratiform events and used by the uk met office on the other hand in fig 13 b the rain rates were calculated using the same equation and coefficient values but z h was corrected for attenuation it can be seen that heavy rain cells where the intensity of the rainfall peaks at 32 mm h are present in many areas of the scan compared to the rain rates computed using attenuated z h in fig 13 c the rain rate was calculated applying eq 13 with the coefficients shown in table 5 however no corrections were applied to the data i e z h and z d r are affected by attenuation and the z d r offset was not corrected these values generate unreliable large rainfall intensity values in many regions of the scan that greatly differ from those computed using the traditional z r relation however using corrected values of z h and z d r in this equation with the coefficients proposed by bringi and chandrasekar 2001 improves the accuracy of the rain estimates as shown in fig 13 d fig 13 e shows the rainfall rates estimated using eq 16 this estimator shows a similar performance to the other estimators described above finally fig 13 f shows the results of an hybrid rainfall rate estimator that combines eq 12 and eq 16 i e the former is used for values of z h below 40 dbz and the latter is used when z h is equal or greater than 40 dbz it is important to stress that the algorithms presented above are constrained to the rain region emphasising the importance of detecting the melting layer beforehand note that the results shown in fig 13 are intended to show the potential of the toolbox to look at different radar rainfall algorithms still it is beyond the scope of this paper to validate these algorithms with rain gauge measurements the aforementioned radar processing chain was applied to data collected by all the operational radar sites throughout the uk generating single site radar qpe for the different rain estimators described above for the final step a radar rainfall composite across the uk was produced using the composition module of wradlib heistermann et al 2013 this function weights the sampling volume of each radar i e it considers the distance and volume of the radar beam to create a composite of radar sites fig 14 shows two radar mosaic composites using two different rainfall estimators eqs 12 and 13 in which corrected polarimetric variables were used it can be seen that both methods produce similar results however fig 14 a exhibits slightly higher values of rainfall intensity it is important to keep in mind that the main objective of this paper is to introduce and demonstrate the capabilities of towerpy to process raw polarimetric radar data and that a comprehensive evaluation of the performance of each rain estimator is out of the scope of this chapter moreover the uk met office applies additional algorithms to produce their operational radar rainfall products as described in section 1 and some of those algorithms were not replicated in this analysis 5 summary and outlook this paper presented a novel tool to read process and display polarimetric radar data this open source toolbox towerpy is a cross platform package written in python capable of processing raw polarimetric radar measurements collected by weather radars towerpy provides libraries that are indispensable for quality checking and generating radar rainfall products however its use is not necessarily limited to meteorological or hydrological applications for example biologists can read operational polarimetric weather radar data using towerpy and fine tune the membership functions to classify echoes produced by biological targets like birds or insects a radar processing chain that exploits the towerpy modules to generate radar qpe products was proposed and described this radar processing chain was designed to process polarimetric radar data produced by the operational uk met office radar network and includes essential algorithms required to check the quality control of the raw radar data signal to noise ratio ground clutter and anomalous propagation identification and removal offset detection in z d r and φ d p attenuation correction the generation of vertical and quasi vertical profiles to monitor the temporal evolution of rain events and rain rate estimators based on different combinations of radar variables this processing radar chain was applied to data collected by the met office radar network throughout the united kingdom s wettest day on record 3rd october 2020 which caused heavy rain and flooding in the uk the tool enables the user to read process and display data collected from all radar sites a quality control process was carried out on data from all radar sites the modular design of the toolbox proved effective as the parameters of each function were set depending on the requirements of each radar the results showed that towerpy could generate accurate radar qpe however it is important to stress that more algorithms are required to correct other artefacts in radar measurements to improve the accuracy of the radar qpe product such as beam blockage or vpr corrections these corrections are currently not included in this processing chain but future research will implement and validate additional algorithms and make them available in future toolbox updates credit authorship contribution statement daniel sanchez rivas conceptualization methodology software writing original draft miguel angel rico ramirez conceptualization methodology software writing original draft declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research has been supported by the engineering and physical sciences research council united kingdom epsrc grant no ep i012222 1 this work was carried out using the computational facilities of the advanced computing research centre university of bristol http www bris ac uk acrc 
25382,weather radars produce high spatial and temporal resolution observations of precipitation events over the years weather radar operators have updated their radar networks to exploit the latest technological advancements one of the most significant improvements in this matter was providing the radars with polarimetric capabilities as this allows the radars to gather more detailed information about the precipitation targets shape size phase and orientation the radar research community has been working along with these advancements to develop robust algorithms that boost the radar data applications such as radar quantitative precipitation estimation qpe rain microphysics analysis nowcasting of precipitation or numerical weather prediction based on radar measurements some of these algorithms have been implemented in open source toolboxes that aim to facilitate the processing and quality control of radar data produced by different radar systems however these open source toolboxes have not yet included a chain process tailored to the uk radar research context this paper presents a toolbox to process weather radar data in python towerpy towerpy can read process and display polarimetric radar data from different radar systems but it is specially customised for data produced by the uk met office radar network towerpy is built upon robust algorithms that cover various aspects of the radar data quality control e g calibration of radar measurements identification of non meteorological echoes attenuation correction among others and the computation of radar rainfall rates additionally a radar processing chain was devised using the towerpy modules to produce radar rainfall estimates raw polarimetric radar measurements collected by the uk met office radar network throughout the uk s wettest day on record were used as input for this processing chain the results confirm that towerpy is a powerful radar research tool and demonstrate its ability to generate functional radar qpe that can be used to improve operational radar rainfall products keywords weather radar polarimetry radar qpe radar research applications open source data availability chenies c band rain radar dual polarisation products are available at https catalogue ceda ac uk uuid bb3c55e36b4a4dc8866f0a06be3d475b met office 2013 jersey c band rain radar dual polarisation products are available at https catalogue ceda ac uk uuid 231b2448a02a45dfa810739f8d6abbe3 met office 2022 other met office s c band rain radar dual polarisation products are available at https catalogue ceda ac uk uuid 82adec1f896af6169112d09cc1174499 met office 2003 the latest release of towerpy and supporting data can be downloaded from https github com uobwatergroup towerpy software availability software name towerpy toolbox for processing weather radar data in python developers daniel sanchez rivas and miguel angel rico ramirez year of first official release 2022 hardware requirements pc system requirements linux windows program language python program size 10 mb availability https github com uobwatergroup towerpy license gpl 3 0 documentation readme in the github repository and project documentation that includes a collection of references tutorials and examples in interactive jupyter notebooks 1 background weather radar applications are diverse meteorologists hydrologists and scientists from different fields exploit the radar s high spatial and temporal resolution information to probe the atmosphere research studies by borga 2002 einfalt et al 2004 athanasiadis et al 2009 zhang and srinivasan 2010 liguori and rico ramirez 2014 thorndahl et al 2017 ochoa rodriguez et al 2019 sivasubramaniam et al 2019 wijayarathne and coulibaly 2020 provide an in depth review of different meteorological and hydrological applications of weather radar such as forecast of precipitation events monitoring meteorological conditions that lead to flash floods in near real time or for radar qpe among several other applications indeed meteorologists exploit weather radar data for precipitation forecasting especially to predict heavy rainfall events with a lead time of a couple of hours ahead e g for nowcasting applications which in turn are indispensable for triggering flash flood warnings for example price et al 2012 described the implementation of a distributed hydrological model based on short term radar rainfall forecasts and nwp numerical weather prediction forecasts used in england and wales their results showed how the model could help to predict developing flood risk over longer lead times and over gauged and ungauged catchments gourley et al 2014 assessed different tools used in operational flash flood forecasting in the usa they concluded that hydrological models driven by radar observations are more skilful in identifying flood producing discharges mainly due to the ability of radars to provide rainfall measurements and forecasts in near real time seo and krajewski 2020 developed a real time qpe system capable of retrieving data from operational radars and nwp models and generate reliable products for flood prediction in iowa usa this system uses a variety of algorithms to quality check the data and accounts for uncertainties in radar qpe imhoff et al 2020 used radar derived rain fields to compare the efficacy of different nowcasting methods with respect to the duration of precipitation events season radar location and type of catchment their results demonstrated the utility of radar nowcasting products especially for winter stratiform precipitation events where errors in the nowcasting were three times lower than in convective summer precipitation events however they stress that improvements in radar rainfall products are needed to forecast longer lead times likewise dance et al 2019 stein et al 2020 exploited data collected by the uk met office radar network to improve the forecasting of extreme precipitation and flooding events in the uk they combined radar data with rain gauge data and nwp forecasts to provide decision makers and emergency responders with flood risk forecasts especially during heavy rain events the results of these projects emphasise the importance of weather radar information to characterise extreme rain events forecast short term precipitation events nowcasting and consequently issue timely flash flood early warnings the literature presented above recognises radars as a great asset for monitoring flood producing storms however these studies also stress the importance of controlling the quality of radar data to ensure the reliability of radar rainfall estimates weather radar does not measure rain rates directly but these are derived from the electromagnetic properties of hydrometeors instead increasing the uncertainty in radar rainfall products battan 1973 illingworth et al 2000 marshall and palmer 1948 ryzhkov et al 2005b it is well known that weather radar measurements can be affected by different error sources such as radar miscalibration atlas 2002 borowska and zrnic 2012 collier 1996 gabella and leuenberger 2017 blockage of the radar beam bech et al 2003 gou and chen 2021 hong and gourley 2015 problems with beam propagation such as ground clutter torres and zrnic 1999 rico ramirez and cluckie 2008 steiner and smith 2002 torres and zrnic 1999 anomalous propagation grecu and krajewski 2000 rico ramirez and cluckie 2008 seo et al 2015 or degradation of radar quality with range krajewski et al 2010 kumjian 2013 ryzhkov 2007 variation of the vertical profile of reflectivity kitchen et al 1994 smyth and illingworth 1998b or attenuation of the radar signal bringi and chandrasekar 2001 fabry et al 1994 smyth and illingworth 1998a the radar community has been working for the last forty years or so to develop algorithms that aim to minimise the impact of such error sources and improve rainfall estimation based on radar measurements however despite all the progress made in this matter residual errors in radar rainfall estimates are still present and can propagate through other models that use radar rainfall products for flood forecasting applications with the development of radar polarimetry and its implementation in many weather radar networks around the world in recent years radars gather more details about the shape size phase and orientation of precipitation targets hence radar users and researchers have focused on developing polarimetric algorithms that improve the quality of radar rainfall estimates for example testud et al 2000 presented the so called self consistent approach to monitor radar calibration using the relationship between reflectivity z h differential reflectivity z d r and the differential propagation phase φ d p this method has been tested in various radar campaigns to calibrate z h see e g frech et al 2017 gourley et al 2009 gorgucci et al 1992 ryzhkov and zrnić 1996 several methodologies developed for identifying non meteorological echoes based on polarimetric measurements have shown the added value of polarimetric radar in improving data quality gourley et al 2007 lepetit et al 2021 rico ramirez and cluckie 2008 on the other hand brandes and ikeda 2004 boodoo et al 2010 matrosov et al 2007 wolfensberger et al 2016 demonstrated that using polarimetric measurements especially the correlation coefficient ρ h v improves the detection of the melting layer an essential atmosphere s feature for differentiating between solid and liquid hydrometeors besic et al 2016 lukach et al 2021 park et al 2009 presented hydrometeor classifiers to improve the identification of different types of hydrometeors by exploiting polarimetric radar observations additionally polarimetric algorithms have been proposed in the literature for correcting the attenuation of the radar signal power due to rain using differential phase measurements these algorithms incorporate φ d p see e g bringi et al 2001 park et al 2005 rico ramirez 2012 testud et al 2000 or the specific differential phase k d p see e g tabary et al 2009 gourley et al 2009 ryzhkov et al 2014 to correct for radar signal attenuation due to rain these algorithms have proven to be more stable and accurate than those based solely on z h finally different studies have evaluated polarimetric algorithms for the estimation of rainfall rates bringi et al 2011 figueras i ventura et al 2012 gourley et al 2010 husnoo et al 2021 rico ramirez and cluckie 2006 ryzhkov et al 2014 vulpiani et al 2012 these studies provided rainfall algorithms for different radar frequencies and geographical conditions which influence the variability of the drop size distribution dsd and demonstrated that polarimetric rain rate estimators are capable of producing more accurate rain estimates providing the radar measurements are well calibrated however processing raw polarimetric weather radar data to generate radar qpe products is a technically challenging task it involves a basic understanding of the principles of weather radars and the implementation of algorithms to acquire process and display raw radar data given that commercial software is neither suitable nor available for research purposes it takes a considerable amount of time and effort to develop code for reading raw radar data or reproducing existing algorithms therefore it is not surprising that members of the weather radar community have been working on developing open source toolboxes to face these challenges each toolbox has been designed and conceived for specific contexts to meet the needs of different radar networks three of the most popular python toolboxes are summarised hereunder outlining their background and main features 1 wradlib heistermann et al 2013 is a radar library developed by researchers from the university of potsdam and the university of stuttgart germany it provides tools to process polarimetric radar data collected by the c band radar network operated by the german weather service dwd as well as other radar data formats like netcdf or hdf5 standard formats used by other radar processing software wradlib provides algorithms for processing weather radar data like reading common data formats identifying and correcting typical error sources such as clutter or attenuation estimating rainfall rates and visualising radar data 2 py art helmus and collis 2016 is used by the atmospheric radiation measurement arm climate research facility for processing data from nexrad the s band doppler weather radar network operated by the u s national weather service nws but it is also capable of reading other weather radar formats like sigmet iris mdv or cf radial and processing data from other radar frequencies e g c band and x band frequencies py art includes modules to display and correct radar data and the algorithms include attenuation correction of the reflectivity or processing the specific differential phase 3 pyrad is a radar data processing framework developed by meteoswiss figueras i ventura et al 2020 it can be seen as an extension of the py art but tailored to process data from the c band swiss weather radar network pyrad provides tools to produce radar qpe as shown in table 1 including clutter detection hydrometeor classification algorithms attenuation correction and rainfall rate estimation most of these modules incorporate polarimetric radar measurements into the algorithms a summary of the features and capabilities of the toolboxes described above is given in table 1 the above mentioned open source libraries have created a growing community of radar researchers working with radar data worldwide increasing the reproducibility of novel radar algorithms and even contributing to the software used by operational weather radar networks however reading and processing radar data collected by the uk weather radar network remains challenging for open source radar researchers the current binary format used by the met office cannot be read nor further processed by any open source library furthermore it is difficult to find tailor made algorithms that exploit the radar surveillance strategy implemented by the met office for example using linear depolarisation ratio ldr measurements for classifying weather radar clutter echoes this challenge motivates the current study in which we deliver a new research tool to process polarimetric radar data but specifically conceived within the uk radar research context this tool known as towerpy toolbox to process weather radar data in python incorporates standard procedures to process c band polarimetric weather radar data this tool can help radar users to work with the raw radar data test different radar polarimetric algorithms to improve radar qpe and evaluate the impact of each of the different algorithms implemented within the toolbox in this paper we introduce towerpy and the polarimetric algorithms implemented within each module we demonstrate the performance of towerpy by generating radar quantitative precipitation estimates based on polarimetric algorithms the paper is organised as follows in section 2 we describe the configuration and products of the uk radar network as it is the main data source used in this study in section 3 we outline the towerpy toolbox and provide some code examples to work with the modules section 4 shows a radar processing chain designed to process data from the uk radar network to generate the final radar rainfall product finally we summarise the main contributions of this research in section 5 2 uk weather radar network description and product generation the c band weather radar network deployed in the uk consists of 15 doppler polarimetric radars operated by the uk met office 1 doppler polarimetric radar operated by the jersey met services and 2 doppler polarimetric radars operated by met éireann harrison et al 2012 as shown in fig 1 the scanning strategy implemented by the uk met office consists of a series of low elevation scans between 0 5 and 4 every 5 min when the radars are operating on long pulse mode pulse length equal to 2 000 μ s covering a range of 250 kilometres with a gate resolution of 600 metres also when the radars operate on the long pulse mode they generate ldr measurements every five minutes the radars also operate on short pulse mode pulse length equal to 500 μ s producing scans at different elevation angles 1 2 4 6 9 90 every 10 min with a gate resolution of 600 metres and a maximum range of 115 kilometres except for the vertical pointing measurements in which the gate resolution is 75 m and the maximum range height is close to 12 kilometres met office 2003 such scanning strategy enables to collect measurements of reflectivity z h radial velocity v differential reflectivity z d r correlation coefficient ρ h v differential propagation phase φ d p and linear depolarisation ratio l d r met office 2003 note that l d r scans are only produced for the lowest elevation 0 5 further details on the configuration of the uk met office radars are provided in table 2 the radar data are gathered by the met office s cyclops system a fully automated system deployed at each radar site and processed by the radar team at the uk met office to generate weather radar rainfall estimates and short term radar based rainfall forecasts harrison et al 2015 these rainfall products are available across the uk with spatial and temporal resolutions of 1 km and 5 min respectively the radar rainfall products and raw polarimetric data from single sites are available at the centre for environmental data analysis ceda archive in the form of binary files met office 2003 the uk met office has implemented a radar processing chain to generate a radar rainfall product over the uk at 1 km 5 min spatial temporal resolution for hydrological purposes it is based on the lowest usable scan i e the radar scan less contaminated with ground clutter the processing of the raw radar data consists of the following main steps dance et al 2019 harrison et al 2009 2012 1 the noise power of the weather radar receiver is computed following the method proposed by ivić et al 2013 that computes a range independent radial noise estimator met office 2019 2 non meteorological echoes are removed using an approach similar to that proposed by rico ramirez and cluckie 2008 in which a probabilistic naive bayes classifier is applied to radar data to identify spurious echoes dance et al 2019 3 partial beam blockage pbb is corrected only if the beam is 50 blocked or less this value is computed by comparing the reflectivity at each gate over short ranges at two different elevations 0 5 and 2 in widespread rain digital elevation models dem and seasonal variations are also analysed to detect the pbb effects illingworth and thompson 2017 4 the variations of the vertical profile of reflectivity vpr are corrected following the method proposed by kitchen et al 1994 but also gathering information on the melting layer thickness from nwp models and satellite observations harrison et al 2009 husnoo et al 2021 5 attenuation corrections for heavy rain are carried out by following the hitschfeld and borden hereinafter hb approach dance et al 2019 based on single polarisation products however this method is refined using polarimetric data namely φ d p and radiometric emissions tompson et al 2012 by constraining the application of the hb approach darlington et al 2016 6 rain rates are derived from radar reflectivity using the relation given by equation z a r b with the coefficients fixed as a 200 and b 1 6 harrison et al 2012 7 a gauge based adjustment factor is applied to all coverage areas of each radar in real time the number of gauges used to compute the factor varies depending on the radar site whereas the time resolution can vary depending on up to date weather conditions golding 1998 harrison et al 2009 2015 8 finally the precipitation rate composite is generated by processing radar data from all the radar sites the radar rainfall composite is based on a distance weighting method that determines the contribution of each radar bin depending on the locations where data from more than one radar site overlaps harrison et al 2009 it is also worth mentioning that the polarimetric data collected by the uk radar network has been exploited by many researchers to develop polarimetric based weather radar algorithms with the primary goal of improving radar qpe products e g bringi et al 2011 hall et al 2015 jewell and gaussiat 2015 liguori et al 2012 pickering et al 2019 rico ramirez and cluckie 2008 rico ramirez 2012 3 towerpy description capabilities and implementation towerpy is a cross platform software mainly written in python designed to read process and display raw polarimetric data from single radar sites from the uk weather radar network it is built on top of numpy the primary array programming library for the python language harris et al 2020 and matplotlib a python library for creating static animated and interactive visualisations hunter 2007 towerpy provides the essential tools to process weather radar data and achieve accurate radar qpe see fig 2 but each module can be seen as the building blocks of many other applications of weather radar data furthermore the modular design of towerpy enables its compatibility with other open source libraries in the following sections the modules comprising the towerpy toolbox are described along with the algorithms implemented on each module an in depth description of the inputs outputs and arguments of the modules comprising towerpy is provided in the code documentation of each function 3 1 data import io the io module is an interface to read in radar data the function ppi ukmoraw is capable of decoding the binary data files currently used by the uk met office such files store plan position indicator ppi scans in polar data format taken at one of the different elevations comprising the uk radar scanning strategy each file contains different radar measurements such as the radar reflectivity z h the radial velocity v and the polarimetric variables z d r φ d p ρ h v l d r among others taken either at short or long pulses likewise the ppi ncasx function imports data collected by the uk national centre for atmospheric science ncas mobile x band radar network these radars provide doppler and polarimetric rainfall measurements with high spatial resolution this module also provides a function ppi emptylike to create an empty like object listing all the radar fields required to work with other modules of towerpy the generated object can be filled up with radar data from other libraries a comprehensive example of this function is provided on the project documentation as a jupyter notebook 3 2 classification of non meteorological echoes eclass the eclass module comprises algorithms for classifying meteorological and non meteorological echoes first the signalnoiseratio function computes the signal to noise ratio snr in db and discards data using a reference noise value given by the user the snr is given by 1 s n r z h 20 l o g 10 r c where z h is in dbz r is the range of a given radar pixel in km and c is the radar constant in db if the snr for a given pixel is below the minimum snr then that pixel is classified as noise the user defines the minimum snr by trial and error for example selecting a very low value of the minimum snr will classify the noise as signal then the clutter id function is a classifier for meteorological and non meteorological radar echoes it is based on the methodology proposed by rico ramirez and cluckie 2008 in which a bayes classifier is used to detect weather radar clutter such as ground clutter sea clutter and anomalous propagation echoes this novel algorithm incorporates the texture of polarimetric fields and clutter maps to improve classification performance the texture is a measure of how noisy the radar measurements are and it is given by the standard deviation of all pixels within a window centred on a given radar pixel the texture is also a function of the number of independent uncorrelated samples averaged to produce a given radar measurement rico ramirez and cluckie 2008 showed that precipitation echoes have a relatively low texture low noise compared to non meteorological echoes such as those due to ground clutter or anomalous propagation which show higher values of texture especially in z d r and φ d p see fig 3 these textures are represented as membership functions mfs which are calibrated based on past data the mfs are generated using a 3 3 window with a gate size of 600 m a pulse repetition frequency of 300 hz and 1 4 revolutions per minute such functions may also be applied to c band radars with similar characteristics the mfs are provided as two column ascii files that describe the probability of a given variable see table 3 associated with precipitation or clutter echoes fig 3 shows the normalised frequency distributions of these mfs scaled to the range 0 1 for comparison purposes additionally towerpy provides a collection of clutter maps for 4 different elevations 0 5 1 2 3 4 related to the chenies radar site currently only clutter frequency maps for the chenies radar are available but we expect to further expand these functions for the rest of the radar sites many scans taken during dry days were used to derive these clutter frequency maps this traditional method used to detect ground clutter for single polarisation radars can be performed by calculating the number of times or scans that a given pixel shows a value related to the signal not classified as noise when using the signalnoiseratio function and divided by the total number of scans this gives a probability of that pixel being clutter contaminated for a given elevation there are pixels where the probability is high and others where it is relatively low the idea is to use as many radar scans on dry days as possible to capture the most cluttered regions fig 11a shows a clutter map generated using scans taken at 0 5 elevation angle 3 3 polarimetric profiles generation profs the profs module enables the generation of profiles of radar measurements more specifically vertical vp and quasi vertical qvp profiles of polarimetric variables the pol vps function uses measurements taken at vertical incidence to generate vps vps are built by averaging a single 360 scan taken at a 90 elevation angle the vps enable the monitoring of the calibration of radar variables such as z d r or φ d p frech and hubbert 2020 gorgucci et al 1999 moreover the vps are also useful for detecting the melting layer as demonstrated in the literature baldini and gorgucci 2006 brandes and ikeda 2004 sanchez rivas and rico ramirez 2021 on the other hand the pol qvps function provides a tool to generate qvps of radar variables the qvps are built following the procedure proposed by ryzhkov et al 2016 in which a ppi scan taken at a high elevation angle is averaged azimuthally additionally towerpy can also generate range defined quasi vertical profiles rd qvps the function pol rdqvps provides a refined version of the qvp methodology introduced by tobin and kumjian 2017 for this function defining a range from the radar within all available elevation angles is necessary the data is averaged according to the specified range using inverse distance weighting as suggested by tobin and kumjian 2017 qvps have proven to be effective in monitoring the development of precipitation events especially using a height time indicator hti plot and in capturing certain microphysical processes within the atmosphere such as the melting layer griffin et al 2020 sanchez rivas and rico ramirez 2021 trömel et al 2019 the generation process of the vps and qvps can be customised by setting arguments that modify the profiles for example users can set thresholds to the radar variables e g ρ h v 0 6 and z h 10 dbz as specified by ryzhkov et al 2016 and to the number of valid gates for the azimuthal averaging process additionally both the pol vps and pol qvps functions provide statistics related to the averaging process of the rays to enable a comprehensive analysis of the profiles 3 4 melting layer detection ml this module can be used to estimate the height and boundaries of the melting layer ml knowledge of the ml boundaries is essential in radar rainfall estimation as it describes the transition of hydrometeors from a solid to a liquid phase within the ml detection function there is a robust melting layer detection algorithm based on the approach proposed by sanchez rivas and rico ramirez 2021 the algorithm can process vps or qvps built from weather radar scans to detect ml signatures within the polarimetric profiles the logic behind the algorithm is to produce a profile with strong gradients within the ml by combining different polarimetric profiles a peak finder routine is applied to the profiles to detect enhanced maxima related to the ml the parameters described in sanchez rivas and rico ramirez 2021 are set as default arguments for the ml detection function however the user can refine the detection of the ml by modifying such arguments for example the user can define a minimum and maximum height within the profiles for the algorithm to search for the ml signatures or select a different combination of profiles to be used to generate the profile with enhanced peaks 3 5 calibration of polarimetric variables calib the calib module includes different routines to monitor and correct the calibration offsets in z d r and φ d p this module is highly dependent on the polarimetric profiles and the height of the ml for z d r towerpy provides different procedures for detecting the system offset using vps or qvps of polarimetric variables the foundation of these procedures lies in the detection of z d r values that differ from those expected for natural targets such as light rain or dry snow first the zdr offsetdetection vps function contains two of the most popular techniques found in the literature the first method proposed by gorgucci et al 1999 suggests detecting the z d r offset using observations of raindrops collected during light rain as the radar antenna rotates about the vertical values of z d r different from zero found within the rain region of the vps i e below the ml are averaged to estimate the z d r offset the second method proposed by ryzhkov et al 2005a works by detecting dry snow regions within the vps usually found just above the ml values close to zero are expected for this type of target hence the mean of z d r related to dry snow is used to estimate the z d r offset on the other hand the zdr offsetdetection qvps function provides a methodology for computing the z d r offset using qvps as described in sanchez rivas and rico ramirez 2022 as above this method estimates the z d r offset within the qvps by comparing the observed values of z d r during stratiform light rain events to an expected value this intrinsic value is computed from dsd simulations using disdrometer data and is linked to the elevation angle from which the qvps were built the user can customise many parameters to implement these methods and calibrate z d r such as setting the height of the melting layer thresholds in the values of the polarimetric profiles or the number of bins to include in the analysis in addition the phidp offsetdetection vps function provides a method to detect a reference offset introduced by the hardware specifications this offset is typically due to differences between the wave guide lengths of horizontal and vertical pulses frech 2013 and this offset does not represent a problem in radar qpe using k d p as k d p is the derivative of φ d p however it is good to remove this system offset before computing k d p the computation of the φ d p offset using vps follows a similar procedure to that proposed for estimating the z d r offset 3 6 attenuation correction attc this module contains routines for correcting the attenuation of the radar signal due to rain these algorithms compute the attenuation in z h and z d r also it is important to mention that their performance is highly influenced by a proper delimitation of regions within the ppi scans that contain liquid and solid precipitation the zh correction function includes seven algorithms previously proposed in the literature see table 4 each algorithm has its own advantages and disadvantages such as the radar variables used for the attenuation correction their stability and different computational cost these attenuation correction algorithms are described in detail by rico ramirez 2012 and are briefly described next first it is importat to define that the nonattenuated reflectivity can be related to the reflectivity z h h m measured by the radar and to the attenuation a h r by 2 10 l o g z h h r 10 l o g z h h m r 2 r 0 r a h s d s the hitschfeld and bordan 1954 hb algorithm is given by vulpiani et al 2006 3 a h r a z h h m r b 1 j r where a h r is the signal attenuation in db km r is the range in km j r 0 46 b r 0 r a z h h m s b d s and the parameters a and b depend on the radar frequency temperature and dsd r 0 is the initial range of the rain cell in km and s refers to the segmentation of the rays this method is sensitive to radar calibration the final value fv algorithm is based on the method proposed by iguchi and meneghini 1994 where the attenuation is computed by 4 a h r a z h h m r b a f b j r m j r where log a f 0 1 α δ φ d p r 0 r m and δ φ d p represents the total differential propagation phase and r m is the range on the far side of the rain cell the algorithm proposed by testud et al 2000 zphi uses δ φ d p constrained to ranges across a rain cell to estimate the total path integrated attenuation pia for this method the attenuation is expressed as follows 5 a h r z h h m r b a f b 1 i r 0 r m a f b 1 i r r m where i r r m 0 46 b r r m z h h m s b d s and a f is given by the equation defined previously the bri algorithm is an implementation of the method proposed by bringi et al 2011 to correct the attenuation on z h this method is an extension of the zphi method but the derivation of the parameter α affecting the total differential propagation phase δ φ d p is optimised by minimising the differences between the measured φ d p and reconstructed φ d p c from the computed attenuation and is given by 6 φ d p c a b α r 2 r 0 r a h s a b α d s the algorithms mentioned above also calculate the path integrated attenuation pia given by bringi et al 1990 testud et al 2000 7 p i a α δ φ d p towerpy also includes refined versions of the algorithms mentioned above these algorithms follow an adaptive technique to compute the parameters of the methods described above as proposed by rico ramirez 2012 these adaptive techniques minimise the errors in the attenuation correction these algoriths are shown as ahb afv and abri in table 4 on the other hand the adaptive attenuation correction in z d r brizdr is implemented in the function zdr correction which calculates the specific differential attenuation a d p following the method proposed by bringi et al 2001 the correction method computes a d p as 8 a d p r β β α o p t a h r α o p t where a h and α can be estimated using any of the methods described above and β is given by 9 β δ z d r r m φ d p r m φ d p r 0 where δ z d r r m is the difference in db units on the far side of the rain cell between the measured z d r and an intrinsic average value z d r the latter is a theoretical value computed using corrected values of z h then β is adjusted to minimise the error between z d r measured and z d r theoretical there are two ways to calculate z d r implemented in the zdr correction function the first is given by bringi et al 2001 10 z d r r m 0 z h r m 20 d b z a z h r m b 20 z h r m 45 d b z where the parameters a b have default values of 0 048 and 0 774 respectively but they can be modified by the user the second uses the exponential equation 11 z d r r m a z h b r m where parameters a b can be defined by the user in this case the default values are a 0 00012 and b 2 5515 according to gou et al 2019 additional arguments for the zh correction and zdr correction functions are required for the attenuation correction users must define the height of the melting level a window size in φ d p where an averaging process is performed to smooth the signal the number of bins to be averaged at the far range of the rain cell to compute δ z d r r m and other thresholds to constrain the correction algorithm only to echoes corresponding to hydrometeors in the liquid phase 3 7 quantitative precipitation estimation qpe this module provides different algorithms to estimate rain rates using radar data different rain rate estimators are implemented in this module including those that incorporate polarimetric measurements note that the parameters a and b in the equations below are different to those defined in section 3 6 12 z h a r b 13 r z h z d r a z h b z d r c 14 r k d p a k d p b 15 r k d p z d r a k d p b z d r c 16 r a h a a h b where z h 1 0 0 1 z h z d r 1 0 0 1 z d r r is in mm h 1 z h and z d r are in dbz and db respectively z h is in mm 6 m 3 k d p is in deg km 1 and a h is in db km 1 bringi and chandrasekar 2001 bringi et al 2011 hong and gourley 2015 marshall and palmer 1948 rico ramirez and cluckie 2006 ryzhkov et al 2014 among others derived the optimal values of the coefficient in those equations depending on the radar wavelength and different geographical conditions moreover some of these algorithms can be combined depending on adaptable thresholds or parameters these so called hybrid rain rate estimators improve the rain rate estimation by constraining the application of the polarimetric estimators depending on the rain type or intensity for example the estimator based on z h eq 12 can be complemented with other radar variables such as a h as the latter is more efficient for estimating moderate to heavy rain rates due to its less sensitivity to dsd variations ryzhkov et al 2014 e g using eq 12 for values of z h below 40 dbz and then using eq 16 for values equal or above 40 dbz may produce more accurate radar rain estimates table 5 provides examples of the values used for different radar frequencies or precipitation regimes in the radar qpe these parameters are fully customisable and can be modified accordingly within this module 3 8 data georeferencing georad users can apply the functions within this module to generate and process georeferenced data as the radar provides the data in polar coordinates i e in range azimuth format the pol2cart function transforms polar coordinates into rectangular cartesian coordinates this system describes the position of the data in a two dimensional system using the perpendicular axes x and y and using the radar position as the origin of the coordinate system conversely the cart2pol function transforms cartesian coordinates into polar coordinates the osgb2lalo and lalo2osgb functions transform coordinates between the ordnance survey os uk national grid eastings and northings and ellipsoidal coordinates latitude and longitude following the coordinate systems in great britain guide by ordnance survey 2020 this function is important because the os grid is used on most british maps the height beamc and cartesian distance functions are useful to calculate the height of the centre of the radar beam above the earth s surface 3 9 radar data visualisation tools datavis visualising radar imagery is essential for understanding and interpreting weather radar data towerpy provides functions to display and interact with radar data in different ways these modules are built upon matplotlib and are capable of generating specialised and interactive radar displays tailored to radar research applications for instance the rad disp and the interactive disp functions provide routines for visualising and exploring ppi and hti plots plots displaying the results of the methodologies described above are also implemented in these modules for instance fig 4 shows a ppi scan of ρ h v along with the beam s height and the radar variables radial profiles for the selected azimuthal angle these radial profiles can be selected with a mouse click on the ppi scan fig 8 displays several hti plots each of these hti plots is interactive and it is possible to visualise and change with a mouse click the displayed polarimetric profiles of precipitation events and their statistics such as the standard deviation furthermore fig 5 shows step by step ml detection using vps fig 10 and fig 11 shows plots of the snr and clutter classification results 3 10 radar utilities utils this module is a collection of functions helpful for processing and analysing radar data for instance the normalisenan function scales input vectors to the unit norm using given values maf radial smooths a selected radar variable along the radial direction using a moving average filter the xdb2x function can be used to transform reflectivity measurements between linear and dbz units these are just a few examples more functions can be found within this module this section described the modules comprising the towerpy toolbox the following section introduces a radar processing chain that generates radar quantitative precipitation estimates using the modules and functions presented above data generated by the operational uk weather radar network will be used to demonstrate the capabilities of the toolbox 4 use of towerpy to generate radar qpe raw polarimetric data collected by the uk met office s operational radar network throughout the 3rd of october 2020 at different elevation angles and from all the radar sites will be used to demonstrate the capabilities of towerpy according to kendon and mccarthy 2021 this was the uk s wettest day on record where an average of 31 7 mm of rain fell across the entire united kingdom and 100 mm or more in a few locations in the first four days of october storm alex brought widespread heavy rainfall across various regions in europe and the uk causing extreme flooding infrastructure damage and fatalities much of central southern england and aberdeenshire recorded more than the whole month average rainfall in the first four days of the month alone thus this day is a perfect study case to show the performance of towerpy to read process and display radar data met office rain radar data were downloaded from the ceda catalogue from the 3 10 2020 at 00 05 gmt 1 to the 3 10 2020 at 23 59 gmt 1 there were approximately 4 660 ppi scans in the form of binary files on that day from all the radar sites and spanning all possible elevations of the scanning strategy described in section 2 first it is important to monitor the development and evolution of the precipitation event thus hti plots were created to this end using vps and qvps from scans collected at 90 and 9 elevation angles respectively see fig 7 and fig 8 fig 6 shows the python code to initialise a towerpy radar object line 14 read in ppi scans containing uk raw polarimetric data line 15 suppress noise lines 21 23 generate and plot the qvps of polarimetric variables lines 29 34 detect the melting layer lines 40 41 and compute the z d r offset lines 47 48 lines 55 76 plot relevant figures that help interpret the radar data note that the argument exclude vars w m s sqi ci db was used in the ppi ukmoraw function as these variables will not be used at this stage the value of the argument min snr 55 db was defined by trial and error for all radars this value with slight variations was found to work with all radar sites the qvps were then generated using the pol qvps function as mentioned above the qvps are built by averaging the 360 rays of the ppi scan to capture the spatial structure of the storm with a temporal resolution of 10 min note that the argument stats was set as true in this function to generate statistics about the qvps generation such as the standard distribution sd or the standard error of the mean sem these statistics enable the analysis of the dispersion of the averaged values which is helpful in understanding the inherent error structure of the qvps finally the melting layer and z d r offset detection processes were carried out exploiting the information provided by the qvps using the ml detection and offsetdetection qvps functions respectively note that both functions take different arguments to adjust their performance moreover the latter requires the user to define the height of the ml fig 7 shows hti plots of qvps of z h from data collected at all radar sites across the uk the melting layer heights detected using the ml module are also shown as dotted lines it can be seen that this rain event produced high reflectivity values at various radar sites that can be associated with heavy rain rates however the well known bright band bb is also visible on almost every radar site the bb is the radar signature of the melting layer caused by melting particles that yield high values of z h for example for the chenies radar site fig 7 b high values of z h 40 dbz are observable even below the melting layer 1 5 km in height around 21 00 h these plots were made using functions within the datavis module note that single profiles are shown in a separate panel of the plot these panels allow detailed visualisation of the profiles shape and statistics e g the sd it is worth mentioning that data from high elevation angles at the predannack radar site were not available for this particular day only 0 5 elevation scans were available consequently it will be excluded from subsequent analysis as it was not possible to detect both the ml and z d r offset a similar procedure was carried out to read in and process birdbath scans 90 and generate vps of radar variables fig 8 shows hti plots of vps generated from the radar sites mentioned above each vp is generated from birdbath scans produced every 10 min note that the first kilometre is not usable due to the configuration of the radars when the antenna is pointing vertically moreover this issue extends up to 1 5 km in height for some radars e g the munduff hill radar site fig 8 n where the first 1 5 km in height is contaminated with spurious echoes this radar site also depicts one major problem related to the vps relatively low heights of the ml around 10 00 am cause a lack of data below the ml i e no data associated with the rain medium hampering the application of algorithms based on the intrinsic value of light rain this problem can be solved using qvps as these profiles are not affected by this limitation see for example fig 7 n however the vps have some benefits over the qvps for instance the standard deviation is smaller in the vps compared to the standard deviation observed in the qvps due to the inherent generation process of the latter this situation can be seen in fig 7 f where the standard deviation of the qvp blue area in the right panel below the melting layer 2 km is surprisingly high 4 dbz in contrast the vp shown in fig 8 f exhibits a standard deviation of 0 5 dbz below the melting layer bottom it is recommended to use both methods vps and qvps to look at the vertical structure of precipitation because each method reveals specific information about the evolution of the storm the process described in this section enabled the detection of the melting layer and the computation of the z d r offset these steps are necessary to apply other algorithms designed to work in the rain medium use calibrated radar variables as inputs and produce radar qpe next we will show how to use the towerpy functions to generate radar qpe in these examples long pulse scans will be used these scans were taken at 0 5 elevation angle every 5 min from the operational uk weather radar network fig 9 shows the radar processing chain used to process single site radar data which will be described next for this elevation angle the minsnr argument of the function signalnoiseratio takes a value of 35 db this value was checked at all radar sites and proved to be effective in removing noise within the scans fig 10 shows the signal to noise ratio snr in db from the authors experience plotting ρ h v is a good practice to identify the limits of noise and signal in the scan next non meteorological echoes clutter were identified using the clutter id function in this example data from the chenies radar site were used to show the results of the clutter classifier fig 11 a shows the clutter map generated using 0 5 elevation angle scans clutter frequency maps cm help to improve clutter identification as shown in fig 11 b however results from other radar sites confirm the efficacy of the clutter identification algorithm as non meteorological echoes were effectively removed from the scans in the next step the melting layer and the z d r offset computed from high elevation angles are defined using the ml and calib modules these two features are essential in the following steps the attenuation corrections of the radar signal on z h and z d r were carried on using the attc module as described in section 3 6 there are different algorithms implemented in this module but they require the definition of the melting layer to achieve optimal performance for this case study the abri method was selected to correct the attenuation in z h as optimising the parameters in eqs 5 and 6 yields more accurate results as shown by rico ramirez 2012 note that the argument mlyr is related to the melting level i e the melting layer top and the thickness of the melting layer the rest of the parameters pdp pxavr rng pdp pxavr azm pdp dmin are necessary to smooth the φ d p signal within a defined window on the other hand the function zdr correction was applied to correct the attenuation in z d r as mentioned above this method requires the height of the melting level to discriminate between liquid and solid precipitation mlyr argument and to define a window size to smooth the signal i e rhv thld minbins mov avrgf len and p2avrf however it also requires the outputs of the z h attenuation correction i e α a h to compute the specific differential attenuation as shown in eq 8 fig 12 shows the attenuation correction results using data collected at the jersey radar site note that the analysis was constrained to data taken below the melting layer and new variables were computed like a h db km a d p db km φ d p or p i a db as described in section 3 6 the offset corrected φ d p is also shown since this variable is essential due to its immunity to attenuation the attenuated z h shows that heavy rain close to the radar site causes a loss in signal power that produces attenuated values of z h beyond the heavy rain cells especially in the south of the radar scan analogously z d r was also affected by attenuation but this issue was corrected by this function generating relatively high values of a d p 0 1 db km finally rain rate estimators were used to produce radar qpe the qpe algs module contains different rain estimators such as the traditional method based on the z r relation but also other polarimetric based estimators for this case study eqs 12 13 and 16 were used to derive rainfall intensities from radar measurements fig 13 shows the results of the rain estimation for data collected at the jersey radar site fig 13 a shows rain rates computed using eq 12 but z h values were not corrected for attenuation coefficients a b take the values shown in table 5 related to stratiform events and used by the uk met office on the other hand in fig 13 b the rain rates were calculated using the same equation and coefficient values but z h was corrected for attenuation it can be seen that heavy rain cells where the intensity of the rainfall peaks at 32 mm h are present in many areas of the scan compared to the rain rates computed using attenuated z h in fig 13 c the rain rate was calculated applying eq 13 with the coefficients shown in table 5 however no corrections were applied to the data i e z h and z d r are affected by attenuation and the z d r offset was not corrected these values generate unreliable large rainfall intensity values in many regions of the scan that greatly differ from those computed using the traditional z r relation however using corrected values of z h and z d r in this equation with the coefficients proposed by bringi and chandrasekar 2001 improves the accuracy of the rain estimates as shown in fig 13 d fig 13 e shows the rainfall rates estimated using eq 16 this estimator shows a similar performance to the other estimators described above finally fig 13 f shows the results of an hybrid rainfall rate estimator that combines eq 12 and eq 16 i e the former is used for values of z h below 40 dbz and the latter is used when z h is equal or greater than 40 dbz it is important to stress that the algorithms presented above are constrained to the rain region emphasising the importance of detecting the melting layer beforehand note that the results shown in fig 13 are intended to show the potential of the toolbox to look at different radar rainfall algorithms still it is beyond the scope of this paper to validate these algorithms with rain gauge measurements the aforementioned radar processing chain was applied to data collected by all the operational radar sites throughout the uk generating single site radar qpe for the different rain estimators described above for the final step a radar rainfall composite across the uk was produced using the composition module of wradlib heistermann et al 2013 this function weights the sampling volume of each radar i e it considers the distance and volume of the radar beam to create a composite of radar sites fig 14 shows two radar mosaic composites using two different rainfall estimators eqs 12 and 13 in which corrected polarimetric variables were used it can be seen that both methods produce similar results however fig 14 a exhibits slightly higher values of rainfall intensity it is important to keep in mind that the main objective of this paper is to introduce and demonstrate the capabilities of towerpy to process raw polarimetric radar data and that a comprehensive evaluation of the performance of each rain estimator is out of the scope of this chapter moreover the uk met office applies additional algorithms to produce their operational radar rainfall products as described in section 1 and some of those algorithms were not replicated in this analysis 5 summary and outlook this paper presented a novel tool to read process and display polarimetric radar data this open source toolbox towerpy is a cross platform package written in python capable of processing raw polarimetric radar measurements collected by weather radars towerpy provides libraries that are indispensable for quality checking and generating radar rainfall products however its use is not necessarily limited to meteorological or hydrological applications for example biologists can read operational polarimetric weather radar data using towerpy and fine tune the membership functions to classify echoes produced by biological targets like birds or insects a radar processing chain that exploits the towerpy modules to generate radar qpe products was proposed and described this radar processing chain was designed to process polarimetric radar data produced by the operational uk met office radar network and includes essential algorithms required to check the quality control of the raw radar data signal to noise ratio ground clutter and anomalous propagation identification and removal offset detection in z d r and φ d p attenuation correction the generation of vertical and quasi vertical profiles to monitor the temporal evolution of rain events and rain rate estimators based on different combinations of radar variables this processing radar chain was applied to data collected by the met office radar network throughout the united kingdom s wettest day on record 3rd october 2020 which caused heavy rain and flooding in the uk the tool enables the user to read process and display data collected from all radar sites a quality control process was carried out on data from all radar sites the modular design of the toolbox proved effective as the parameters of each function were set depending on the requirements of each radar the results showed that towerpy could generate accurate radar qpe however it is important to stress that more algorithms are required to correct other artefacts in radar measurements to improve the accuracy of the radar qpe product such as beam blockage or vpr corrections these corrections are currently not included in this processing chain but future research will implement and validate additional algorithms and make them available in future toolbox updates credit authorship contribution statement daniel sanchez rivas conceptualization methodology software writing original draft miguel angel rico ramirez conceptualization methodology software writing original draft declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research has been supported by the engineering and physical sciences research council united kingdom epsrc grant no ep i012222 1 this work was carried out using the computational facilities of the advanced computing research centre university of bristol http www bris ac uk acrc 
25383,hydrologic models are widely used to support evaluation and decision making of nutrient and pesticide impacts on the environment including water quality and sensitive aquatic species yet such tools are typically designed for research purposes that are time consuming to use and require certain expertise data and software in this study a web based tool for the agricultural policy environmental extender apex model with nutrient and pesticide prediction functions was built incorporating gis functionality a spatial and online database automated modeling system and user friendly interface it provides a computation platform for conducting nutrient and pesticide evaluations at small watershed and field scales with commonly used scenarios and management options case studies were conducted and results demonstrate the ability of the tool to identify spatial variability of runoff and sediment nutrient and pesticide losses this tool can also provide rapid and site specific guidance to decision makers for evaluating pesticide related assessments keywords apex web based gis nutrient pesticide environmental assessment data availability data will be made available on request software and data availability name of software geoapex p developers feng pan and qingyu feng platform and operation system apache webserver and ubuntu server operation system programming language php javascript html and python software required internet brower tested on firefox chrome edge safari and internet explorer 1 introduction excess sediment nutrient and pesticide losses to surface water and to groundwater may have potential adverse effects on human and environmental safety zhang and starner 2011 pan et al 2021 agricultural use and application of nutrients and pesticides are the predominant source of such contamination that cause issues such as water quality degradation and potentially impacts sensitive aquatic species liu et al 2008 schulz 2004 specifically studies by u s geological survey usgs of major river basins revealed that pesticides were found in all water and fish samples and these impacts go beyond agricultural land use to urban streams and drinking water aktar et al 2009 related evaluation and identification of mitigation measures need both field experiments and modeling approaches due to the complexity of nutrient and pesticide fate and transport in fields chen et al 2017 in the past two decades hydrologic models with requirements of fast and vast computation are widely applied to support research into the impact of pesticides and nutrients on the environment and decision making processes chen et al 2017 nutrient related studies include evaluating the effectiveness of conservation practices francesconi et al 2014 smith et al 2015 tuppad et al 2010 the simulation of macropore phosphorus loss ford et al 2017 and evaluating evapotranspiration for dryland cropping systems tadesse et al 2018 for pesticide related studies fry et al 2016 used daily gridded weather data to simulate nationwide pesticide exposure lammoglia et al 2018 modeled pesticide leaching uncertainties under climate agricultural practices and soil and pesticide properties to quantify the probability and reliability of pesticide prediction hong and purucker 2018 did sensitivity analysis of model parameters on vertical transport of pesticides and revealed that sensitivity should be examined at a certain spatiotemporal resolution a field scale evaluation of uptake of soil applied pesticide by runoff with two models was conducted by young and fry 2019 and demars et al 2018 integrated sedimentation components to a root zone model for sediment sorbed pesticide modeling compared to field experiments these models are much more cost effective for prediction of nutrient and pesticide transport and fate and they are also capable of evaluating multiple scenarios such as best management practices bmps or other mitigation methods shao et al 2017 there are several types of models including empirical models conceptual models and physically based models implementing these models for field specific runoff simulation and modeling can accurately characterize nutrient loading and pesticide exposure to spatially explicit conditions and inform tailored mitigation measures pan et al 2021 with rapid development of computing power and spatial analysis technology physically based spatially distributed and small watershed field scale models have become available for field specific nutrient loading and pesticide exposure characterizations general development of such modeling tools incorporates several important items such as i online accessibility including tools and the corresponding climate soil and land use data ii ability of remote computation remote control parallel computation and standardized or simplified operation procedures iii inclusion of geographical information system gis capabilities to provide spatially explicit evaluation and iv capability to consider management options efforts in developing models to achieve the above functions have been made and products are promising multiple web based platforms were developed for distinct types of models including lumped hasan karaman et al 2020 semi distributed gan et al 2020 and distributed guo et al 2020 zhang et al 2019 models widely used hydrologic models soil and water assessment tool swat arnold et al 1998 agricultural policy environmental extender apex williams and izaurralde 2005 hydrological simulation program fortran hspf duda et al 2012 and long term hydrologic impact analysis l thia harbor 1994 have gis versions such as arcswat dile et al 2016 arcapex tuppad et al 2009 better assessment science integrating point and nonpoint sources basins us epa 2019 for hspf and arcl thia ryu et al 2018 that can be utilized for spatially explicit simulation only some tools include large or national level databases of spatial and nonspatial data for modeling chen et al 2017 van beusekom et al 2022 zell and sanford 2020 zhang et al 2021 newman et al 2015 among those three tools were recently developed by our research group including the apex web interface feng et al 2019 for user assigned location and location specific properties topography soil management and climate simulation geospatial apex online geoapexol feng et al 2020 for spatially explicit simulation and visualization and apex multi processing apexmp pan et al 2021 for parallel computation and distributed simulation substantial work has been done in terms of general watershed modeling development as mentioned above but such developments are limited for pesticide evaluation especially in complex field or watershed scale models vazquez amabile et al 2006 chen et al 2017 and apex plotkin et al 2013 existing models are not generally integrated with relevant national databases or automated setup functions and thus they require extensive expertise and time to be used in designing and conducting evaluations enhancement of hydrologic models for nutrient loading and pesticide exposure that incorporates the functionalities of web based and real time access to spatial databases is urgently needed by agricultural producers regulators and decision makers gan et al 2020 the apex model is a field and small watershed scale hydrologic model for simulation of runoff sediment transport nutrient and pesticide losses originating from farms or agricultural lands gassman et al 2010 the pesticide module in environmental policy integrated climate epic williams et al 1984 apex and swat are all derived from groundwater loading effects of agricultural management systems gleams leonard et al 1987 therefore the corresponding approaches and functions to track movement of pesticides with percolated water runoff and sediment are remarkably similar at the field scale wang et al 2012 at the watershed scale apex subareas are hydrologically connected through lateral subsurface flow and the surface routing process lateral subsurface flow characterizes the soil water and chemical flow to the adjacent downstream subarea and is added to the soil profile in that subarea the floodplain flow across subareas is considered in the surface routing processes when the actual flow in a reach is larger than the channel capacity therefore apex has a unique capability of simulating effects of conservation practices by specifying certain subareas as bmps e g filter strips grassed waterways and water and sediment basins and it has served as a main nationwide environmental assessment tool in usda nrcs conservation effects assessment project ceap since 2003 johnson et al 2015 the work reported herein is the first apex associated platform that provides sophisticated pesticide prediction functions along with commonly adopted sources of data such as digital elevation model dem land use soil climate and management the primary goal of this study is to develop a web based spatially distributed modeling platform dubbed geographic information based apex for pesticides geoapex p hereinafter the tool that incorporates nutrient loading and pesticide prediction functions with publicly available scenarios specifically three objectives are defined i develop a user friendly online computational platform with gis functions and national database ii enable users to adjust pesticide input data and management operations and iii incorporate publicly recognized scenarios e g epa ecological scenarios used in endangered species assessment esa in the automated platform the results of the developed tool can be used by aquatic or terrestrial simulation models e g vvwm or plant assessment model us epa 2023 for exposure estimations for aquatic or terrestrial habitats 2 methodology as described in the introduction the tool was built upon the platform of the apex web interface and geoapexol with substantial upgrades the apex web interface is the first tool we built for the apex online project by building the national database and developing methods of replacing apex model text input with web input and selections geoapexol enhanced the apex web interface by adding spatial data and the corresponding methods of reading and applying them to text inputs with spatial calculation and visualization functions as shown in table 1 all three previously built tools are equipped with a background geospatial and nonspatial database the apex web interface feng et al 2019 and geoapexol feng et al 2020 are both graphic user interfaces gui the apex web interface can automatically set up input for apex simulation of runoff sediment and nutrients at a farm field scale without spatial processing and map services it is only designed for black box simulation in a virtual field with user selection of location spatial area soil and management which is similar to the epa pesticide simulation model przm of which input data are used for pesticide and management for the tool built in our study geoapexol incorporates online maps web gis technologies and spatial databases and can be easily operated with button clicks for simulation apexmp pan et al 2021 is a modeling platform that can automatically prepare model inputs setup and execute simulations in parallel gather and summarize results and generate graphical outputs which is suitable for large scale and fine resolution simulation the tool was built on these three tools with upgrades and additions of data algorithms functions and software it shares the database and main platform algorithm from geoapexol including national soil topography and land use management and climate data and how to edit or select them were inherited from the apex web interface and apexmp new management including pesticide applications and climate data from an epa database were added key functions were added to our tool including i reading inputs of a pesticide model used by epa e g przm pesticide in water calculator pwc or retrieving study inputs with this interface ii editing or selecting climate management and pesticide inputs and iii displaying results on an annual and daily basis with both tables and graphs algorithms for reading interactive data from the webpage reading geospatial data generating inputs and sorting outputs were all upgraded to serve the objectives of this tool the latest version of the apex model version 1501 geospatial tools server and database management software were updated for this tool together with all these additions and upgrades the tool is fully capable of simulating hydrologic nutrient and pesticide processes at both field and small watershed scales with various locations and scenarios in the contiguous united states 2 1 overview of the tool as shown in fig 1 the tool consists of three major components the front end webpage background database and data processing modules users can operate the system by entering text clicking the buttons and viewing the results the default display maps are provided by arcgis rest services https services arcgisonline com arcgis rest services programming languages include html webpage construction javascript user interactions with openlayers css editing the layout and format of webpages and php user interaction with the server all these are operating on an apache webserver version 2 4 46 http httpd apache org on an ubuntu server operation system version 2004 https ubuntu com the background database includes spatial data such as dem land use crop types specified and soil text data including climate pesticide and management and apex default input detailed description can be found in appendix a the data processing modules include functions for processing gis layers using the gdal library for generating stream networks and watershed boundaries by calling taudem functions tarboton 2015 and for processing input output files of the apex model with python scripts specific methods and processes are listed in appendix b 2 2 processes and algorithms the steps to conduct an apex simulation with the tool as shown in fig 2 are to i generate stream network and then delineate subarea s based on the field boundary drawing ii clip spatial maps and convert them into numerical data for each delineated subarea iii update apex input files with the above data and other user nonspatial data input and iv execute apex executable for simulations and then parse and display the results in the initial page home users can choose to start a new project upload a przm file or upload an old project file by automatically generating default input from the postgresql database and reading and processing uploaded files to input such options make the tool flexible for inexperienced users to access the tool the first time with limited background new or experienced users have epa przm input and want to use them for apex or experienced users who have already built a project with all input for further modifications or that is ready to run once one of the above options is selected users will be directed to the main page with the base map they can either input zip code city and state name or use the mouse to zoom in to the area of interest with basic functions of arcgis rest services next with the drawing function users can easily draw any shapes that fit their fields can redo it by clicking the button again which is very convenient for new or experienced users and has not been applied in other similar online tools in the next step for spatial processing the tool initiates automated delineation clipping and spatial calculation based on the field selected to generate all spatial related input without any user effort which saves substantial amounts of time for users in the input page following the spatial initialization there are three simple input sections for management climate and pesticide users can select from the weather station recorded weather generator created or epa provided climate data based on their needs with simple click selection and simulation year input for pesticide selection users can select from one from the default database that automatically links the properties for all pesticides and if desired they can change those properties manually with input the management page directed from the input page by clicking management button also provides options for users to choose based on what they selected in the initial page if a new project is built they can choose from the default scenarios list and then give a new name for further editing if an epa przm file is uploaded the pesticide properties and applications for the management activities are read and a scenario is created automatically with the information if an old file is uploaded together with all other previous input data the user created management will also be loaded automatically once the user management is generated loaded the interactive online table provides functions to select and input different management activities as the database does not include the pesticide application by default yet users need to pay attention that at least one pesticide application and amount need to be added to their management with all nonspatial input finished users can save the project in the input page or go back to the main page directly at that time the run function is abled and once it is clicked all the spatial and nonspatial information will be converted to apex text input files and the apex executable will be called for simulation the parse function will aggregate all the output to different temporal scale results and then the display function will generate tables maps and graphs to display the results such functions make the results much easier to understand for public users and decision makers with limited knowledge of modeling and data analysis also the download function allows users to download the whole simulation folder with input output apex executable and manual so that professional modelers and scientists can easily modify the input to rerun the model and manipulate the results in desired ways 3 results and discussion 3 1 case study and scenarios to demonstrate the ability of the tool to identify the spatial and temporal variability of runoff sediment and pesticide loss it was applied to eight soybean fields in lasalle county illinois representing a high intensity soybean production area with endangered plants in the county fig 3 each field has an area ranging from 16 to 63 ha the przm scenario selected includes basic input data for simulation but not experimental data for calibration or verification so no comparisons between apex and przm results were made the selected przm scenario epa hq opp 2021 0957 0008 uses the chemical compound named 2 4 d with application rate of 1 12 kg ha per time on april 26 12 days before emergence may 8 emergence day and may 20 12 days after emergence as described in the methods section the tool can achieve automated model setup and execution thus with the same parameter set and input data there would be no difference between the results generated by the tool and the apex standalone model table 2 lists different soil types and properties of the eight fields that are the main driving factors for the differences among the eight fields in runoff and related simulations as they share the same input for climate pesticide properties and applications and crop management nonspatial input as shown in fig 4 such differences in soil properties cause differences in runoff largest range from smallest to largest annual values is about 150 mm in sediment about 13 t ha in pesticide in runoff about 100 g ha and in pesticide in sediment about 2 g ha such differences in results reveal that spatial variation in soils and other geophysical conditions would lead to significant variability in both model simulations and actual runoff related components that can only be captured by a tool equipped with spatial processing and gis functions 3 2 ongoing and future development with the current design and foundation of the tool capable of automated set up of apex simulation for pesticide evaluation considering spatial variability there are plenty of potential future developments to make the tool more comprehensive in various aspects such as crops management pesticides and locations and to serve more users from different areas we also plan to conduct further validation work with more experimental data we are still building i interface optimization including page layout design of tables adding more help and information functions for user convenience ii more pesticide compounds for users to select iii concentration calculations for pesticides in runoff and iv more management scenarios with pesticide information and more crops into our database for future development we are planning to add functions of checking bmps for mitigation of pesticides such as vegetative filter strips cover crops buffer strips grassed waterways and sediment basins also with the required data available the tool can be further extended to other regions with some data modification we will make these bmps as simple selections for users to choose results of different selected bmps will then be compared with the original condition to determine the most efficient approach 4 conclusions in this study a web based spatial modeling system equipped with gis capabilities a us national database and automated set up algorithm were built for nutrient loading and pesticide exposure assessment the tool includes a gui to interact with users gis functions to process spatial data national datasets of elevation land use and soil cropping management scenarios including pesticide data and a climate database and back end functions to prepare model input this is the first online prediction tool with apex that supports rapid site specific modeling of nutrient and pesticide losses in the contiguous us by using nationally available data with some button clicks and selections the tool can set up a simulation of runoff sediment nutrients and pesticides with different management scenarios and climate data automatically with gis functions which could substantially enhance spatial evaluations in addition it can provide field site explicit estimates of nutrient and pesticide runoff to the aquatic or terrestrial models for risk assessment of receiving aquatic or terrestrial habitats for regulatory purposes e g esa agricultural pesticide and nutrient loss evaluation and bmp assessment projects nationwide the proposed work will reduce the corresponding workload significantly most importantly the tool provides field specific pesticide runoff evaluations which lays the foundation of future site specific regulatory risk assessment risk management and stewardship of precision agriculture declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to thank drs jaehak jeong and luca doro at the blackland research center temple texas for providing technical support and apex executable instruction and other bayer environmental exposure modeling group members for providing feedback and comments after testing the tool appendix a database and relevant templates table adata included in geoapex p data data source format resolution dem usgs national map 3dep 1 arc second dem tiff 30 m 30 m cropland data layer cdl national agricultural statistics service nass 2016 tiff 30 m 30 m soil survey geographic database ssurgo soil survey staff nrcs usda 2017 tiff 30 m 30 m climate database cligen ncdc epa text n a 130 km 0 25 management winapex database text n a pesticide apex database text n a the database in the tool as shown in table a includes i raster layers of elevation digital elevation model dem land use cropland data layer cdl and soil survey geographic database ssurgo ii tables of soil database iii climate database iv management files and v pesticide database prepared for apex all raster layers have the same projection and resolution so that they can be extracted and overlapped spatially to update apex input files the land use map includes all crops and other land use types for soil data there is a soil database tabular file that includes soil properties for each soil group in ssurgo climate data includes daily precipitation and minimum maximum temperature observations from over 2700 u s weather stations 1974 2013 of the national climatic data center ncdc https www ncdc noaa gov cdo web the second option for climate input is a database that uses monthly statistics tables information generated by climate generator cligen software zhang and garbrecht 2003 the epa climate database was accessed from the epa models for pesticide risk assessment website https www epa gov pesticide science and assessing pesticide risks models pesticide risk assessment for now management scenario templates were extracted from the winapex steglich and evelyn 2014 database by selecting the common scenarios for midwest states without pesticide applications yet finally the pesticide database was created from the apex default input file named pestcom dat including 285 pesticides serving as templates for further editing the climate management and pesticide data are all stored in a postgresql database appendix b technical settings in the home page after users choose an option to start the project the tool will i read the default json file to load all input data for modification later with php ii read pwc file for pesticide properties and application activities and also read default json file to load the rest of input data and iii read json file for all the input generated for a previous project by the tool all the input data are stored in php temporary memory for now in the main page after a desired site is located by using the zooming icon and an agricultural field is selected by clicking 1 draw a field boundary button and drawing the field the map object of the openlayers library version 4 6 5 https openlayers org generates a polygon feature of the field boundary and saves it to a json file to interact with the server next by clicking 2 spatial initialization button the tool generates a buffer polygon of 0 025 around the field polygon and clips a dem layer with the buffer polygon from the whole dem layer in the database the dem is then used to generate a stream network with the taudem functions based on the stream network the taudem library delineates all the subareas watersheds as large as the whole dem as shown in fig a for each watershed covering part of the field there is are one or more subareas depending on whether the stream has sub streams or not if there are sub streams each subarea from downstream to upstream is given an id in increasing order most downstream as 1 then adding 1 each time the stream diverts and subareas in the same order are given the same ids after determining all subarea ids and watersheds soil and land use layers are extracted for each subarea finally the combinations of soil and land use with the largest area and the average slope in a subarea are identified and then such information is also stored in the json described above in the input page once users select the climate data type from the three options and input simulation period the tool first uses the centroid of the field and an embedded c spatial search tool to find the nearest climate station in the selected climate type for the field then the tool generates structured query language sql inquiry terms for extracting climate data from the postgresql database the pesticide properties are also accessed from the postgresql database with user selection of pesticide name further editing of the properties is recorded in php temporary memory and written into the json file to update the pesticide input text file for apex in the management page there are twenty five operations that can be simulated by apex including agricultural management operations such as planting harvesting fertilizing and applying pesticide under each operation there are multiple types such as different cultivation methods pesticide application methods and fertilizer application methods for each method users can select different fertilizers or pesticides and the amount applied all these data are first read from the postgresql database and then updated and stored with php and json for later writing the management input text file for apex after going back to the main page at this stage all the information is generated and stored in json or php temporary memory once users click 4 run apex model button several python scripts are called to write the values for variables related to location climate pesticide soil management and topography into input text files for apex the apex executable is called right after the all the inputs are prepared for simulations and the output files are generated the simulation results are then extracted and processed with the spatial area weighted method to calculate the final output of the selected field from watershed s covering it by python scripts the annual average results are first illustrated by raster layers with assorted colors supported by the mapserver package version 7 6 https mapserver org finally all the figures in the results page e g annual runoff rate sediment transport load pesticide load in runoff and sediment are provided using google chart https developers google com chart interactive docs appendix c operation procedure as shown in fig a in the home page of the tool users need to determine whether to start a new project by giving a new name and clicking input upload a przm file pwc by clicking choose file to choose a pwc file and clicking upload or upload a previous file json created by last time with the same process as pwc fig a screenshot of geoapex p index page with initiation and file uploading functions fig a the main page of the tool is shown in fig b users first need to zoom in to an area of interest either through the search box by entering a us zip code or text in the format of city name state abbreviation and press the go button alternatively the target field area can be located by the zoom in and out button on the map then users draw the boundary of the target field by using the tracer on the map by clicking 1 draw a field boundary button once 2 spatial initialization button is clicked all areas covered by the field boundary are delineated and all the spatial data for the watersheds are prepared accordingly spatial initialization button after that by clicking 3 edit input button users will be directed to the input page for further editing inputs fig b screenshot of geoapex p main page with interactive map view spatial processing and simulation functions fig b in the input page users can edit or select nonspatial data as shown in fig c the tool assigns default management for the project if json or pwc is uploaded either way users can further edit the management detail button in the management page as displayed in fig d climate data has three options see appendix a and users can choose one of them and input the simulation period input boxes based on their project objectives next in the pesticide section users can select one pesticide from the default list name drop down list and then decide if they want to edit the pesticide properties or keep the default settings input boxes at any time users can save their project save project button to download a json file or go back to the main page fig b for final simulation finish input button fig c screenshot of geoapex p input page with options for management climate and pesticide fig c fig d screenshot of geoapex p management page including default scenarios and creating and editing new scenarios based on default scenarios fig d fig d is a screenshot of the management page to generate user specified management users begin by selecting an existing template then they need to input a new name and click create with selected template button to generate the new management in the management editing table users can then add delete or edit each line and specify the details for the agricultural management options for example users can specify the date application method type and amount for pesticide application after users finish management edits they are redirected to the input page fig c use selected management button from the input page fig c as mentioned above users can save the project or go back to the main page to run apex once users go back to the main page fig e the model simulation function is enabled run apex model button after 4 run apex model button is clicked apex starts the simulation with the user selection and input and once the simulation is done a web notice pops up showing apex run completed at this stage the whole process is done and there are options for users to check the results 1 the annual average results table and the result map of the selected field with distinct colors in subareas representing value ranges of annual average and legend as shown in fig e automatically generated after the simulation 2 results can be downloaded 5 download project folder button as a zip file which contains all the raw input output files apex executable and apex manual 3 5 result figures button leads users to the results page with bar graphs fig f the first option can provide a straightforward illustration of the values of each subarea and difference among subareas and one result table bottom of fig e showing average annual modeling outputs of the selected field and users can switch to different results by clicking layer button in the upper right corner and then check uncheck layers with the second option more advanced modelers and researchers can further modify the input and rerun apex locally or manipulate the results to compare with either monitoring data or other model results i e przm fig e screenshot of the result map and legend of the selected field distinct colors in subareas representing value ranges of annual average and the annual average results table in geoapex p main page fig e fig f screenshot of annual daily graphs in geoapex p result page fig f in the results page four graphs show either annual or daily results by selection simulation results for runoff mm sediment t ha pesticide in runoff g ha and pesticide in sediment g ha for the field can be displayed in two temporal scales users have options to select the annual or daily display 
25383,hydrologic models are widely used to support evaluation and decision making of nutrient and pesticide impacts on the environment including water quality and sensitive aquatic species yet such tools are typically designed for research purposes that are time consuming to use and require certain expertise data and software in this study a web based tool for the agricultural policy environmental extender apex model with nutrient and pesticide prediction functions was built incorporating gis functionality a spatial and online database automated modeling system and user friendly interface it provides a computation platform for conducting nutrient and pesticide evaluations at small watershed and field scales with commonly used scenarios and management options case studies were conducted and results demonstrate the ability of the tool to identify spatial variability of runoff and sediment nutrient and pesticide losses this tool can also provide rapid and site specific guidance to decision makers for evaluating pesticide related assessments keywords apex web based gis nutrient pesticide environmental assessment data availability data will be made available on request software and data availability name of software geoapex p developers feng pan and qingyu feng platform and operation system apache webserver and ubuntu server operation system programming language php javascript html and python software required internet brower tested on firefox chrome edge safari and internet explorer 1 introduction excess sediment nutrient and pesticide losses to surface water and to groundwater may have potential adverse effects on human and environmental safety zhang and starner 2011 pan et al 2021 agricultural use and application of nutrients and pesticides are the predominant source of such contamination that cause issues such as water quality degradation and potentially impacts sensitive aquatic species liu et al 2008 schulz 2004 specifically studies by u s geological survey usgs of major river basins revealed that pesticides were found in all water and fish samples and these impacts go beyond agricultural land use to urban streams and drinking water aktar et al 2009 related evaluation and identification of mitigation measures need both field experiments and modeling approaches due to the complexity of nutrient and pesticide fate and transport in fields chen et al 2017 in the past two decades hydrologic models with requirements of fast and vast computation are widely applied to support research into the impact of pesticides and nutrients on the environment and decision making processes chen et al 2017 nutrient related studies include evaluating the effectiveness of conservation practices francesconi et al 2014 smith et al 2015 tuppad et al 2010 the simulation of macropore phosphorus loss ford et al 2017 and evaluating evapotranspiration for dryland cropping systems tadesse et al 2018 for pesticide related studies fry et al 2016 used daily gridded weather data to simulate nationwide pesticide exposure lammoglia et al 2018 modeled pesticide leaching uncertainties under climate agricultural practices and soil and pesticide properties to quantify the probability and reliability of pesticide prediction hong and purucker 2018 did sensitivity analysis of model parameters on vertical transport of pesticides and revealed that sensitivity should be examined at a certain spatiotemporal resolution a field scale evaluation of uptake of soil applied pesticide by runoff with two models was conducted by young and fry 2019 and demars et al 2018 integrated sedimentation components to a root zone model for sediment sorbed pesticide modeling compared to field experiments these models are much more cost effective for prediction of nutrient and pesticide transport and fate and they are also capable of evaluating multiple scenarios such as best management practices bmps or other mitigation methods shao et al 2017 there are several types of models including empirical models conceptual models and physically based models implementing these models for field specific runoff simulation and modeling can accurately characterize nutrient loading and pesticide exposure to spatially explicit conditions and inform tailored mitigation measures pan et al 2021 with rapid development of computing power and spatial analysis technology physically based spatially distributed and small watershed field scale models have become available for field specific nutrient loading and pesticide exposure characterizations general development of such modeling tools incorporates several important items such as i online accessibility including tools and the corresponding climate soil and land use data ii ability of remote computation remote control parallel computation and standardized or simplified operation procedures iii inclusion of geographical information system gis capabilities to provide spatially explicit evaluation and iv capability to consider management options efforts in developing models to achieve the above functions have been made and products are promising multiple web based platforms were developed for distinct types of models including lumped hasan karaman et al 2020 semi distributed gan et al 2020 and distributed guo et al 2020 zhang et al 2019 models widely used hydrologic models soil and water assessment tool swat arnold et al 1998 agricultural policy environmental extender apex williams and izaurralde 2005 hydrological simulation program fortran hspf duda et al 2012 and long term hydrologic impact analysis l thia harbor 1994 have gis versions such as arcswat dile et al 2016 arcapex tuppad et al 2009 better assessment science integrating point and nonpoint sources basins us epa 2019 for hspf and arcl thia ryu et al 2018 that can be utilized for spatially explicit simulation only some tools include large or national level databases of spatial and nonspatial data for modeling chen et al 2017 van beusekom et al 2022 zell and sanford 2020 zhang et al 2021 newman et al 2015 among those three tools were recently developed by our research group including the apex web interface feng et al 2019 for user assigned location and location specific properties topography soil management and climate simulation geospatial apex online geoapexol feng et al 2020 for spatially explicit simulation and visualization and apex multi processing apexmp pan et al 2021 for parallel computation and distributed simulation substantial work has been done in terms of general watershed modeling development as mentioned above but such developments are limited for pesticide evaluation especially in complex field or watershed scale models vazquez amabile et al 2006 chen et al 2017 and apex plotkin et al 2013 existing models are not generally integrated with relevant national databases or automated setup functions and thus they require extensive expertise and time to be used in designing and conducting evaluations enhancement of hydrologic models for nutrient loading and pesticide exposure that incorporates the functionalities of web based and real time access to spatial databases is urgently needed by agricultural producers regulators and decision makers gan et al 2020 the apex model is a field and small watershed scale hydrologic model for simulation of runoff sediment transport nutrient and pesticide losses originating from farms or agricultural lands gassman et al 2010 the pesticide module in environmental policy integrated climate epic williams et al 1984 apex and swat are all derived from groundwater loading effects of agricultural management systems gleams leonard et al 1987 therefore the corresponding approaches and functions to track movement of pesticides with percolated water runoff and sediment are remarkably similar at the field scale wang et al 2012 at the watershed scale apex subareas are hydrologically connected through lateral subsurface flow and the surface routing process lateral subsurface flow characterizes the soil water and chemical flow to the adjacent downstream subarea and is added to the soil profile in that subarea the floodplain flow across subareas is considered in the surface routing processes when the actual flow in a reach is larger than the channel capacity therefore apex has a unique capability of simulating effects of conservation practices by specifying certain subareas as bmps e g filter strips grassed waterways and water and sediment basins and it has served as a main nationwide environmental assessment tool in usda nrcs conservation effects assessment project ceap since 2003 johnson et al 2015 the work reported herein is the first apex associated platform that provides sophisticated pesticide prediction functions along with commonly adopted sources of data such as digital elevation model dem land use soil climate and management the primary goal of this study is to develop a web based spatially distributed modeling platform dubbed geographic information based apex for pesticides geoapex p hereinafter the tool that incorporates nutrient loading and pesticide prediction functions with publicly available scenarios specifically three objectives are defined i develop a user friendly online computational platform with gis functions and national database ii enable users to adjust pesticide input data and management operations and iii incorporate publicly recognized scenarios e g epa ecological scenarios used in endangered species assessment esa in the automated platform the results of the developed tool can be used by aquatic or terrestrial simulation models e g vvwm or plant assessment model us epa 2023 for exposure estimations for aquatic or terrestrial habitats 2 methodology as described in the introduction the tool was built upon the platform of the apex web interface and geoapexol with substantial upgrades the apex web interface is the first tool we built for the apex online project by building the national database and developing methods of replacing apex model text input with web input and selections geoapexol enhanced the apex web interface by adding spatial data and the corresponding methods of reading and applying them to text inputs with spatial calculation and visualization functions as shown in table 1 all three previously built tools are equipped with a background geospatial and nonspatial database the apex web interface feng et al 2019 and geoapexol feng et al 2020 are both graphic user interfaces gui the apex web interface can automatically set up input for apex simulation of runoff sediment and nutrients at a farm field scale without spatial processing and map services it is only designed for black box simulation in a virtual field with user selection of location spatial area soil and management which is similar to the epa pesticide simulation model przm of which input data are used for pesticide and management for the tool built in our study geoapexol incorporates online maps web gis technologies and spatial databases and can be easily operated with button clicks for simulation apexmp pan et al 2021 is a modeling platform that can automatically prepare model inputs setup and execute simulations in parallel gather and summarize results and generate graphical outputs which is suitable for large scale and fine resolution simulation the tool was built on these three tools with upgrades and additions of data algorithms functions and software it shares the database and main platform algorithm from geoapexol including national soil topography and land use management and climate data and how to edit or select them were inherited from the apex web interface and apexmp new management including pesticide applications and climate data from an epa database were added key functions were added to our tool including i reading inputs of a pesticide model used by epa e g przm pesticide in water calculator pwc or retrieving study inputs with this interface ii editing or selecting climate management and pesticide inputs and iii displaying results on an annual and daily basis with both tables and graphs algorithms for reading interactive data from the webpage reading geospatial data generating inputs and sorting outputs were all upgraded to serve the objectives of this tool the latest version of the apex model version 1501 geospatial tools server and database management software were updated for this tool together with all these additions and upgrades the tool is fully capable of simulating hydrologic nutrient and pesticide processes at both field and small watershed scales with various locations and scenarios in the contiguous united states 2 1 overview of the tool as shown in fig 1 the tool consists of three major components the front end webpage background database and data processing modules users can operate the system by entering text clicking the buttons and viewing the results the default display maps are provided by arcgis rest services https services arcgisonline com arcgis rest services programming languages include html webpage construction javascript user interactions with openlayers css editing the layout and format of webpages and php user interaction with the server all these are operating on an apache webserver version 2 4 46 http httpd apache org on an ubuntu server operation system version 2004 https ubuntu com the background database includes spatial data such as dem land use crop types specified and soil text data including climate pesticide and management and apex default input detailed description can be found in appendix a the data processing modules include functions for processing gis layers using the gdal library for generating stream networks and watershed boundaries by calling taudem functions tarboton 2015 and for processing input output files of the apex model with python scripts specific methods and processes are listed in appendix b 2 2 processes and algorithms the steps to conduct an apex simulation with the tool as shown in fig 2 are to i generate stream network and then delineate subarea s based on the field boundary drawing ii clip spatial maps and convert them into numerical data for each delineated subarea iii update apex input files with the above data and other user nonspatial data input and iv execute apex executable for simulations and then parse and display the results in the initial page home users can choose to start a new project upload a przm file or upload an old project file by automatically generating default input from the postgresql database and reading and processing uploaded files to input such options make the tool flexible for inexperienced users to access the tool the first time with limited background new or experienced users have epa przm input and want to use them for apex or experienced users who have already built a project with all input for further modifications or that is ready to run once one of the above options is selected users will be directed to the main page with the base map they can either input zip code city and state name or use the mouse to zoom in to the area of interest with basic functions of arcgis rest services next with the drawing function users can easily draw any shapes that fit their fields can redo it by clicking the button again which is very convenient for new or experienced users and has not been applied in other similar online tools in the next step for spatial processing the tool initiates automated delineation clipping and spatial calculation based on the field selected to generate all spatial related input without any user effort which saves substantial amounts of time for users in the input page following the spatial initialization there are three simple input sections for management climate and pesticide users can select from the weather station recorded weather generator created or epa provided climate data based on their needs with simple click selection and simulation year input for pesticide selection users can select from one from the default database that automatically links the properties for all pesticides and if desired they can change those properties manually with input the management page directed from the input page by clicking management button also provides options for users to choose based on what they selected in the initial page if a new project is built they can choose from the default scenarios list and then give a new name for further editing if an epa przm file is uploaded the pesticide properties and applications for the management activities are read and a scenario is created automatically with the information if an old file is uploaded together with all other previous input data the user created management will also be loaded automatically once the user management is generated loaded the interactive online table provides functions to select and input different management activities as the database does not include the pesticide application by default yet users need to pay attention that at least one pesticide application and amount need to be added to their management with all nonspatial input finished users can save the project in the input page or go back to the main page directly at that time the run function is abled and once it is clicked all the spatial and nonspatial information will be converted to apex text input files and the apex executable will be called for simulation the parse function will aggregate all the output to different temporal scale results and then the display function will generate tables maps and graphs to display the results such functions make the results much easier to understand for public users and decision makers with limited knowledge of modeling and data analysis also the download function allows users to download the whole simulation folder with input output apex executable and manual so that professional modelers and scientists can easily modify the input to rerun the model and manipulate the results in desired ways 3 results and discussion 3 1 case study and scenarios to demonstrate the ability of the tool to identify the spatial and temporal variability of runoff sediment and pesticide loss it was applied to eight soybean fields in lasalle county illinois representing a high intensity soybean production area with endangered plants in the county fig 3 each field has an area ranging from 16 to 63 ha the przm scenario selected includes basic input data for simulation but not experimental data for calibration or verification so no comparisons between apex and przm results were made the selected przm scenario epa hq opp 2021 0957 0008 uses the chemical compound named 2 4 d with application rate of 1 12 kg ha per time on april 26 12 days before emergence may 8 emergence day and may 20 12 days after emergence as described in the methods section the tool can achieve automated model setup and execution thus with the same parameter set and input data there would be no difference between the results generated by the tool and the apex standalone model table 2 lists different soil types and properties of the eight fields that are the main driving factors for the differences among the eight fields in runoff and related simulations as they share the same input for climate pesticide properties and applications and crop management nonspatial input as shown in fig 4 such differences in soil properties cause differences in runoff largest range from smallest to largest annual values is about 150 mm in sediment about 13 t ha in pesticide in runoff about 100 g ha and in pesticide in sediment about 2 g ha such differences in results reveal that spatial variation in soils and other geophysical conditions would lead to significant variability in both model simulations and actual runoff related components that can only be captured by a tool equipped with spatial processing and gis functions 3 2 ongoing and future development with the current design and foundation of the tool capable of automated set up of apex simulation for pesticide evaluation considering spatial variability there are plenty of potential future developments to make the tool more comprehensive in various aspects such as crops management pesticides and locations and to serve more users from different areas we also plan to conduct further validation work with more experimental data we are still building i interface optimization including page layout design of tables adding more help and information functions for user convenience ii more pesticide compounds for users to select iii concentration calculations for pesticides in runoff and iv more management scenarios with pesticide information and more crops into our database for future development we are planning to add functions of checking bmps for mitigation of pesticides such as vegetative filter strips cover crops buffer strips grassed waterways and sediment basins also with the required data available the tool can be further extended to other regions with some data modification we will make these bmps as simple selections for users to choose results of different selected bmps will then be compared with the original condition to determine the most efficient approach 4 conclusions in this study a web based spatial modeling system equipped with gis capabilities a us national database and automated set up algorithm were built for nutrient loading and pesticide exposure assessment the tool includes a gui to interact with users gis functions to process spatial data national datasets of elevation land use and soil cropping management scenarios including pesticide data and a climate database and back end functions to prepare model input this is the first online prediction tool with apex that supports rapid site specific modeling of nutrient and pesticide losses in the contiguous us by using nationally available data with some button clicks and selections the tool can set up a simulation of runoff sediment nutrients and pesticides with different management scenarios and climate data automatically with gis functions which could substantially enhance spatial evaluations in addition it can provide field site explicit estimates of nutrient and pesticide runoff to the aquatic or terrestrial models for risk assessment of receiving aquatic or terrestrial habitats for regulatory purposes e g esa agricultural pesticide and nutrient loss evaluation and bmp assessment projects nationwide the proposed work will reduce the corresponding workload significantly most importantly the tool provides field specific pesticide runoff evaluations which lays the foundation of future site specific regulatory risk assessment risk management and stewardship of precision agriculture declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to thank drs jaehak jeong and luca doro at the blackland research center temple texas for providing technical support and apex executable instruction and other bayer environmental exposure modeling group members for providing feedback and comments after testing the tool appendix a database and relevant templates table adata included in geoapex p data data source format resolution dem usgs national map 3dep 1 arc second dem tiff 30 m 30 m cropland data layer cdl national agricultural statistics service nass 2016 tiff 30 m 30 m soil survey geographic database ssurgo soil survey staff nrcs usda 2017 tiff 30 m 30 m climate database cligen ncdc epa text n a 130 km 0 25 management winapex database text n a pesticide apex database text n a the database in the tool as shown in table a includes i raster layers of elevation digital elevation model dem land use cropland data layer cdl and soil survey geographic database ssurgo ii tables of soil database iii climate database iv management files and v pesticide database prepared for apex all raster layers have the same projection and resolution so that they can be extracted and overlapped spatially to update apex input files the land use map includes all crops and other land use types for soil data there is a soil database tabular file that includes soil properties for each soil group in ssurgo climate data includes daily precipitation and minimum maximum temperature observations from over 2700 u s weather stations 1974 2013 of the national climatic data center ncdc https www ncdc noaa gov cdo web the second option for climate input is a database that uses monthly statistics tables information generated by climate generator cligen software zhang and garbrecht 2003 the epa climate database was accessed from the epa models for pesticide risk assessment website https www epa gov pesticide science and assessing pesticide risks models pesticide risk assessment for now management scenario templates were extracted from the winapex steglich and evelyn 2014 database by selecting the common scenarios for midwest states without pesticide applications yet finally the pesticide database was created from the apex default input file named pestcom dat including 285 pesticides serving as templates for further editing the climate management and pesticide data are all stored in a postgresql database appendix b technical settings in the home page after users choose an option to start the project the tool will i read the default json file to load all input data for modification later with php ii read pwc file for pesticide properties and application activities and also read default json file to load the rest of input data and iii read json file for all the input generated for a previous project by the tool all the input data are stored in php temporary memory for now in the main page after a desired site is located by using the zooming icon and an agricultural field is selected by clicking 1 draw a field boundary button and drawing the field the map object of the openlayers library version 4 6 5 https openlayers org generates a polygon feature of the field boundary and saves it to a json file to interact with the server next by clicking 2 spatial initialization button the tool generates a buffer polygon of 0 025 around the field polygon and clips a dem layer with the buffer polygon from the whole dem layer in the database the dem is then used to generate a stream network with the taudem functions based on the stream network the taudem library delineates all the subareas watersheds as large as the whole dem as shown in fig a for each watershed covering part of the field there is are one or more subareas depending on whether the stream has sub streams or not if there are sub streams each subarea from downstream to upstream is given an id in increasing order most downstream as 1 then adding 1 each time the stream diverts and subareas in the same order are given the same ids after determining all subarea ids and watersheds soil and land use layers are extracted for each subarea finally the combinations of soil and land use with the largest area and the average slope in a subarea are identified and then such information is also stored in the json described above in the input page once users select the climate data type from the three options and input simulation period the tool first uses the centroid of the field and an embedded c spatial search tool to find the nearest climate station in the selected climate type for the field then the tool generates structured query language sql inquiry terms for extracting climate data from the postgresql database the pesticide properties are also accessed from the postgresql database with user selection of pesticide name further editing of the properties is recorded in php temporary memory and written into the json file to update the pesticide input text file for apex in the management page there are twenty five operations that can be simulated by apex including agricultural management operations such as planting harvesting fertilizing and applying pesticide under each operation there are multiple types such as different cultivation methods pesticide application methods and fertilizer application methods for each method users can select different fertilizers or pesticides and the amount applied all these data are first read from the postgresql database and then updated and stored with php and json for later writing the management input text file for apex after going back to the main page at this stage all the information is generated and stored in json or php temporary memory once users click 4 run apex model button several python scripts are called to write the values for variables related to location climate pesticide soil management and topography into input text files for apex the apex executable is called right after the all the inputs are prepared for simulations and the output files are generated the simulation results are then extracted and processed with the spatial area weighted method to calculate the final output of the selected field from watershed s covering it by python scripts the annual average results are first illustrated by raster layers with assorted colors supported by the mapserver package version 7 6 https mapserver org finally all the figures in the results page e g annual runoff rate sediment transport load pesticide load in runoff and sediment are provided using google chart https developers google com chart interactive docs appendix c operation procedure as shown in fig a in the home page of the tool users need to determine whether to start a new project by giving a new name and clicking input upload a przm file pwc by clicking choose file to choose a pwc file and clicking upload or upload a previous file json created by last time with the same process as pwc fig a screenshot of geoapex p index page with initiation and file uploading functions fig a the main page of the tool is shown in fig b users first need to zoom in to an area of interest either through the search box by entering a us zip code or text in the format of city name state abbreviation and press the go button alternatively the target field area can be located by the zoom in and out button on the map then users draw the boundary of the target field by using the tracer on the map by clicking 1 draw a field boundary button once 2 spatial initialization button is clicked all areas covered by the field boundary are delineated and all the spatial data for the watersheds are prepared accordingly spatial initialization button after that by clicking 3 edit input button users will be directed to the input page for further editing inputs fig b screenshot of geoapex p main page with interactive map view spatial processing and simulation functions fig b in the input page users can edit or select nonspatial data as shown in fig c the tool assigns default management for the project if json or pwc is uploaded either way users can further edit the management detail button in the management page as displayed in fig d climate data has three options see appendix a and users can choose one of them and input the simulation period input boxes based on their project objectives next in the pesticide section users can select one pesticide from the default list name drop down list and then decide if they want to edit the pesticide properties or keep the default settings input boxes at any time users can save their project save project button to download a json file or go back to the main page fig b for final simulation finish input button fig c screenshot of geoapex p input page with options for management climate and pesticide fig c fig d screenshot of geoapex p management page including default scenarios and creating and editing new scenarios based on default scenarios fig d fig d is a screenshot of the management page to generate user specified management users begin by selecting an existing template then they need to input a new name and click create with selected template button to generate the new management in the management editing table users can then add delete or edit each line and specify the details for the agricultural management options for example users can specify the date application method type and amount for pesticide application after users finish management edits they are redirected to the input page fig c use selected management button from the input page fig c as mentioned above users can save the project or go back to the main page to run apex once users go back to the main page fig e the model simulation function is enabled run apex model button after 4 run apex model button is clicked apex starts the simulation with the user selection and input and once the simulation is done a web notice pops up showing apex run completed at this stage the whole process is done and there are options for users to check the results 1 the annual average results table and the result map of the selected field with distinct colors in subareas representing value ranges of annual average and legend as shown in fig e automatically generated after the simulation 2 results can be downloaded 5 download project folder button as a zip file which contains all the raw input output files apex executable and apex manual 3 5 result figures button leads users to the results page with bar graphs fig f the first option can provide a straightforward illustration of the values of each subarea and difference among subareas and one result table bottom of fig e showing average annual modeling outputs of the selected field and users can switch to different results by clicking layer button in the upper right corner and then check uncheck layers with the second option more advanced modelers and researchers can further modify the input and rerun apex locally or manipulate the results to compare with either monitoring data or other model results i e przm fig e screenshot of the result map and legend of the selected field distinct colors in subareas representing value ranges of annual average and the annual average results table in geoapex p main page fig e fig f screenshot of annual daily graphs in geoapex p result page fig f in the results page four graphs show either annual or daily results by selection simulation results for runoff mm sediment t ha pesticide in runoff g ha and pesticide in sediment g ha for the field can be displayed in two temporal scales users have options to select the annual or daily display 
25384,the north american multi model ensemble nmme experiment assembles valuable ensemble forecasts from more than ten global climate models gcms focusing on environmental applications of nmme forecasts this paper develops the pynmme a python based toolkit to implement data retrieval forecast calibration and forecast verification specifically the toolkit is composed of three modules that streamline the processes of retrieving the nmme data for locations and seasons of interest from high dimensional datasets calibrating raw gcm forecasts by the linear scaling quantile mapping and bernoulli gamma gaussian models and verifying predictive performances by twenty verification metrics and six types of diagnostic plots the results show that the characteristics of bias reliability and skill of raw forecasts vary across the globe and that the three calibration models in the pynmme effectively improve raw forecasts to different extents overall the pynmme can serve as a useful tool to exploit valuable nmme precipitation forecasts for environmental modelling and management graphical abstract image 1 keywords global precipitation ensemble forecasts predictive performance data retrieval forecast calibration forecast verification data availability data will be made available on request 1 introduction the north american multi model ensemble nmme experiment launched in 2011 provides valuable ensemble climate forecasts for environmental modelling and management kirtman et al 2014 becker et al 2022 while global climate models gcms are developed by different agencies for climate forecasting the nmme pools more than ten state of the art gcms including the national centers for environmental prediction s climate forecast system version 2 cfsv2 and the geophysical fluid dynamics laboratory s seamless system for prediction and earth system research spear to provide global forecasts of precipitation temperature and geopotential height etc saha et al 2014 bauer et al 2015 delworth et al 2020 lin et al 2020 under the nmme protocol forecasts from different gcms are operationally provided at unified horizontal resolution 1 1 delivery date eighth of each month and lead time at least nine months becker et al 2022 furthermore the nmme forecasts have been widely incorporated into decision support systems for environmental planning flow maintenance and hazards management koppa et al 2019 arsenault et al 2020 muñoz et al 2020 tian et al 2022 there are generally three key steps for the use of gcm precipitation forecasts manubens et al 2018 iturbide et al 2019 wang et al 2019 fernandes et al 2020 firstly sub sets of forecasts for locations and seasons of interest are retrieved from high dimensional global datasets in which a vast amount of gcm forecasts are pooled by their spatial temporal properties kirtman et al 2014 secondly given that raw gcm forecasts are largely biased and unreliable calibration models are set up to correct biases in raw forecasts and quantify forecast uncertainty for practical applications gneiting et al 2007 scheuerer and hamill 2015 li et al 2017 wang et al 2019 thirdly predictive performances i e the correspondence between forecasts and observations murphy 1993 are verified for raw and calibrated forecasts verification metrics and diagnostic plots devised for ensemble deterministic and categorical forecasts are used to yield quantitative and graphical understandings of predictive performances wilks 2011 jolliffe and stephenson 2012 harpham et al 2019 huang and zhao 2022 this paper presents a python toolkit named pynmme to retrieve calibrate and verify precipitation forecasts while the nmme has been extensively used in seasonal precipitation forecasting its environmental applications can be constrained by the complexity of handling massive high dimensional forecast datasets frías et al 2018 khajehei et al 2018 roy et al 2020 becker et al 2022 hazra et al 2023 to bridge the gap the pynmme provides a suite of tools that streamline the entire processes of retrieving forecast data for spatial temporal extents of interest calibrating raw forecasts by formulating statistical models and verifying predictive performances by computing verification metrics and generating diagnostic plots as will be demonstrated through a case study of the cfsv2 precipitation forecasts in the nmme the pynmme facilitates detailed investigations of predictive performances over individual grid cells and at the global scale and illustrates the effectiveness of calibration models in improving raw gcm forecasts 2 toolkit capabilities 2 1 overview of pynmme fig 1 illustrates the three modules of pynmme to investigate precipitation forecasts specifically the module of data retrieval downloads and extracts forecasts of interest along with the corresponding observations from the nmme data server the module of forecast calibration sets up the linear scaling quantile mapping and bernoulli gamma gaussian models to improve raw precipitation forecasts piani et al 2010 zhao et al 2022 huang et al 2022 and the module of forecast verification computes verification metrics and generates diagnostic plots for raw and calibrated forecasts jolliffe and stephenson 2012 huang and zhao 2022 it is noted that the pynmme outputs forecasts and metrics in the network common data form netcdf format and generates plots in the portable network graphics png and other standard formats 2 2 data retrieval the nmme monthly precipitation forecasts and observations are downloaded from the international research institute at columbia university by uniform resource locators urls the forecast dataset f has five dimensions kirtman et al 2014 1 f f s l m y x where f represents forecast values specified by 1 start time s representing the month at which gcms produce forecasts 2 lead time l representing the length of time for which forecasts are generated ahead 3 ensemble member m representing different scenarios of future precipitation 4 latitude y and 5 longitude x the observation dataset o which is sourced from the climate prediction center s unified rain gauge database xie and arkin 1997 has three dimensions 2 o o t y x t s l where o represents observed values specified by 1 target time t which is the sum of start time and lead time in the alignment of forecasts with observations 2 latitude y and 3 longitude x by specifying latitude and longitude precipitation forecasts and observations over an individual grid cell are 3 f j f t m o j o t where f j and o j respectively represent forecasts and observations over a selected grid cell with latitude y j and longitude x j for paired forecasts and observations target times are determined by the sums of start times and lead times eqs 2 and 3 2 3 forecast calibration the linear scaling teutschbein and seibert 2013 crochemore et al 2016 quantile mapping zhao et al 2017 robertson et al 2023 and bernoulli gamma gaussian huang et al 2021 2022 models are set up in the pynmme to calibrate raw precipitation forecasts 1 the linear scaling corrects the difference between the means of forecasts and observations teutschbein and seibert 2013 4 f t m l s c f t m where f t m l s and f t m respectively represent linearly scaled forecasts and raw forecasts the coefficient c is determined by the sums of observations and ensemble members in training samples that is c m t 1 t o t t 1 t m 1 m f t m it is noted that mean values and ensemble spreads of raw forecasts are enlarged reduced when the coefficient is larger smaller than 1 2 the quantile mapping matches the distributions of raw forecasts and observations and converts forecast values into observed values by using the quantile i e cumulative probability wood 2002 piani et al 2010 5 f t m q m c d f o 1 c d f f f t m where f t m q m represents quantile mapped forecasts c d f o 1 represents the inverse cumulative distribution function cdf of observations and c d f f represents the cdf of forecasts it is noted that c d f o 1 and c d f f are implemented by fitting the mixed bernoulli gamma distributions respectively for observations and ensemble members in training samples which accounts for the skewness characteristic and the lower bound of the probability distribution of precipitation amounts piani et al 2010 huang et al 2021 3 the bernoulli gamma gaussian model generates calibrated forecasts by the conditional distribution derived from the bivariate gaussian distribution of ensemble means and observations huang et al 2022 6 o t n ρ f t 1 ρ 2 where o t represents the conditional distribution of observations on a new raw forecast f t and ρ represents the correlation coefficient in the bivariate gaussian distribution the bernoulli gamma gaussian model is built upon the gamma gaussian model the bernoulli gamma distribution is used in the normal quantile transform nqt to normalize ensemble means and observations and the bivariate gaussian distribution is formulated on the derived standard normal variates to generate calibrated forecasts random samples from o t are back transformed by inverse nqt compared with the quantile mapping the bernoulli gamma gaussian model has one additional parameter ρ to measure the strength of association between ensemble means and observations 2 4 forecast verification there are twenty verification metrics available in the pynmme murphy 1993 wilks 2011 jolliffe and stephenson 2012 huang and zhao 2022 herein the spearman s rank correlation coefficient scc relative bias rb alpha index α index and continuous ranked probability skill score crpss are used to evaluate precipitation forecasts the scc measures the association between ensemble means and observations 7 s c c 1 6 t 1 t d t 2 t t 2 1 where t is the number of pairs of forecasts and observations d t represents statistics calculated by ranks of ensemble means f t and observations o t the highest value of scc is 1 indicating a perfect monotonic increasing relationship the rb examines bias by the sums of ensemble means and observations 8 r b t 1 t f t t 1 t o t t 1 t o t 100 as can be seen the rb takes a perfect value of zero while a positive negative value indicates that forecasts are overall larger smaller than observations the α index quantifies reliability based on probability integral transform pit 9 α index 1 2 t t 1 t p i t t t t 1 where p i t t represents the t th order statistic of pit the α index ranges from 0 to 1 and a value of 1 indicates perfectly reliable spreads the crpss measures forecast skill by comparing the performances of ensemble forecasts and reference forecasts 10 c r p s s c r p s r e f c r p s e n s c r p s r e f 100 where crps ref and crps ens respectively represent the crps computed for reference forecasts and the nmme ensemble forecasts a higher value of crpss indicates better predictive performance with a perfect value of 100 in particular a positive negative value indicates that ensemble forecasts outperform underperform reference forecasts there are six types of diagnostic plots available in the pynmme huang and zhao 2022 for ensemble forecasts the time series plot displays forecasts and observations in a time sequence iturbide et al 2019 huang et al 2022 the quantile range plot examines whether ensemble forecasts can capture observations wang et al 2009 zhao et al 2019 and the pit uniform plot indicates forecast reliability by plotting sorted pit against standard uniform variate renard et al 2010 zhao et al 2022 also there are the correlation scatter plot for deterministic forecasts and the reliability diagram and the receiver operating characteristic curve for categorical forecasts furthermore spatial plotting of verification metrics can serve to inspect predictive performances at regional and global scales yuan et al 2011 zhao et al 2020 3 case study the rolling updates of gcm precipitation forecasts are illustrated in fig 2 the first row presents monthly precipitation observations from january 2010 to july 2010 and the last four rows showcase the monthly updated cfsv2 forecasts as can be seen the cfsv2 initializes at the beginning of each month and generates precipitation forecasts for the subsequent months specifically for the second row the cfsv2 is initialized in january 2010 and produces forecasts for january 2010 lead 0 months february 2010 lead 1 month and july 2010 lead 6 months and for the third row the cfsv2 is initialized in february 2010 and produces forecasts for february 2010 lead 0 months march 2010 lead 1 month and july 2010 lead 5 months in the meantime subplots in a column present forecasts targeting at the month of corresponding observations but with different lead times which graphically illustrates relationships among start lead and target times eqs 1 and 2 in high dimensional nmme datasets seasonal forecasts for precipitation in june july august jja are retrieved from the nmme datasets specifically start times are set to be june from 1982 to 2010 hindcast period and the lead times are selected to be 0 1 and 2 months for each year monthly forecasts for the three lead times are summed to form seasonal forecasts targeting at jja precipitation in this way seasonal forecasts for jja precipitation in the 29 years are pooled to consider precipitation seasonality accordingly monthly observed amounts are also summed to form seasonal totals for jja from 1982 to 2010 it is noted that attention is paid to 14 921 land grid cells over which seasonal totals are larger than 0 01 mm robertson et al 2013 huang et al 2023 for each grid cell across the world raw forecasts are calibrated and verified specifically the linear scaling quantile mapping and the bernoulli gamma gaussian models are independently used to calibrate raw forecasts under leave one year out cross validation that is raw forecasts for one year are calibrated by models trained by samples in other years ensuring that the testing sample is not implied by training samples schepen et al 2018 wang et al 2019 li et al 2022 to verify raw and calibrated forecasts the scc rb α index and crpss eqs 7 to 10 are computed and the time series quantile range and pit uniform plots are displayed 4 result analysis 4 1 performances of raw forecasts raw precipitation forecasts over five selected grid cells are illustrated by the time series quantile range and pit uniform plots in fig 3 specifically the five grid cells are respectively selected by 1 the highest scc the first row 2 the lowest scc the second row 3 the highest rb the third row 4 the rb closest to zero the fourth row and 5 the highest α index the fifth row accordingly varying predictive performances are presented 1 the first row showcases raw forecasts that are positively correlated with observations as shown in the time series and quantile range plots a large small forecast value tends to correspond to a large small observed value in the meantime ensemble forecasts are overall smaller than observations owing to negative biases the pit values tend toward one and the pit uniform plot distributes above the 1 1 line indicating limited reliability 2 the second row illustrates a negative correlation between raw forecasts and observations that is a large small forecast value usually coincides with a small large observed value resulting in an scc value of 0 63 also it can be seen that the observed values are overall above ensemble forecasts and that the pit uniform plot deviates from the 1 1 line indicating negative biases and unreliable spreads 3 the third row displays positively biased ensemble forecasts it can be observed that the observations are smaller than 20 mm while the 10 percentiles of ensemble forecasts are above 50 mm the substantial biases make the 29 pit values equal to 0 leading to an α index of 0 and a crpss of 7120 96 the implication is that the raw forecasts underperform climatological reference forecasts due to positive biases and unreliable spreads 4 the fourth row is for unbiased ensemble forecasts the rb nearly takes a perfect value of zero as the mean value of forecasts is similar to that of observations eq 8 although the ensemble spreads tend to capture the observations the quantile range plot suggests that there is a neutral correlation between the ensemble medians and the observations 5 the fifth row shows reliable ensemble forecasts since reliability is a sufficient condition of unbiasedness zhao et al 2022 ensemble forecasts selected by the highest α index are overall unbiased and reliable in the meantime the quantile range plot distributing along the 1 1 line indicates a reasonable correlation between forecasts and observations as a result the raw forecasts outperform climatological forecasts and exhibit a positive crpss 17 84 the four metrics examined in fig 3 are further illustrated at the global scale in fig 4 specifically metrics are computed over each grid cell and displayed by spatial plotting overall the values of metrics exhibit notable spatial variation positive scc can be observed in south america southeast asia and australia indicating reasonable correlations between raw forecasts and observations in fig 4b the values of rb can be smaller than 100 e g northern south america or larger than 100 e g north asia the implication is that raw forecasts usually suffer from substantial biases largely owing to biases the values of α index fig 4c and crpss fig 4d can be respectively smaller than 0 5 and 0 which indicates unreliable spreads and negative skill in addition positive crpss can be observed for a few grid cells in australia and south america as therein forecasts are unbiased and reliable 4 2 performances of calibrated forecasts the linear scaling quantile mapping and bernoulli gamma gaussian models are used to calibrate raw forecasts fig 5 presents quantile range plots for the three types of calibrated forecasts over the five selected grid cells comparing figs 5 and 3 it can be observed that the three calibration models evidently improve the predictive performances to different extents the observations tend to fall within 10 90 inter quantile ranges of calibrated forecasts leading to rb smaller than 2 in particular the values of α index and crpss are notably improved for grid cells a b and c over which raw forecasts suffer from substantial biases and unreliable spreads the rb of linearly scaled forecasts quantile mapped forecasts and bernoulli gamma gaussian calibrated forecasts are illustrated at the global scale in fig 6 specifically the values of rb across the globe are displayed by spatial plotting in figs 6a c and also pooled by the violin plots in fig 6d comparing figs 6 and 4 it can be observed that biases in raw forecasts are considerably corrected as shown by the violin plots the medians of rb for the three types of calibrated forecasts are close to zero the implication is that the three calibration models can effectively correct biases in raw forecasts the α index for the three types of calibrated forecasts are illustrated at the global scale in fig 7 overall the three calibration models can improve forecast reliability by correcting biases fig 6 and the medians of α index become higher than 0 8 it is noted that the quantile mapped forecasts can exhibit better reliability than the linearly scaled forecasts it is because the quantile mapping accounts for the difference in the marginal distributions while the linear scaling focuses on the correction of mean values eqs 4 and 5 furthermore the bernoulli gamma gaussian model leads to the α index mostly higher than 0 8 indicating its better efficacy in improving forecast reliability than the linear scaling and quantile mapping the crpss for the three types of calibrated forecasts are illustrated at the global scale in fig 8 comparing figs 4 and 8 it can be seen that the negative skill prevalent in raw forecasts is considerably eliminated primarily due to the reduced biases and improved reliability in the meantime the linearly scaled forecasts and quantile mapped forecasts can exhibit negative crpss over a number of grid cells by contrast the bernoulli gamma gaussian model generally ensures positive and neutral skill across the world it is generally due to that the bernoulli gamma distribution is effective in characterizing marginal distributions of precipitation data and that the bivariate gaussian distribution is effective in accounting for the dependence between raw forecasts and observations huang et al 2021 2022 5 discussion the pynmme is a python based toolkit that presents detailed investigations of the nmme forecasts in practice the use of forecasts usually requires various technical tasks including formulating calibration models computing verification metrics and visualizing forecast uncertainty wilks 2011 iturbide et al 2019 duan et al 2020 there exist r packages and softwares such as ensemble verification system brown et al 2010 visualizer frías et al 2018 s2dverification manubens et al 2018 and climate4r iturbide et al 2019 developed for verifying the predictive performances of hydroclimatic forecasts in this paper the pynmme supplements the existing toolkits by offering a suite of python tools tailored to the nmme forecasts specifically this toolkit streamlines the processes of data retrieval forecast calibration and forecast verification without the need of coping with varying data requirements in different tools which facilitates efficient analysis of the nmme forecasts the cfsv2 forecasts in the nmme are employed to illustrate the use of pynmme to retrieve calibrate and verify precipitation forecasts as is demonstrated in the case study this toolkit effectively illustrates predictive performances of raw and calibrated forecasts over individual grid cells and at the global scale crochemore et al 2016 huang et al 2021 zhao et al 2022 it is pointed out that the analysis implemented by the pynmme fig 1 can be extended to gcm forecasts of other hydroclimatic variables such as temperature and evaporation strazzo et al 2019 zhao et al 2019 becker et al 2022 specifically raw gcm forecasts are retrieved for locations and seasons of interest and then verified by verification metrics and diagnostic plots given that systematic and random errors are identified in raw forecasts it is necessary to formulate calibration models to correct biases and improve forecast reliability and skill before practical applications slater et al 2016 strazzo et al 2019 roy et al 2020 6 conclusions the pynmme is developed to facilitate detailed investigations of the nmme forecasts the three modules can be readily used to implement data retrieval forecast calibration and forecast verification through a case study of the nmme forecasts the pynmme is used to retrieve seasonal forecasts for jja precipitation from the high dimensional gcm datasets to calibrate raw forecasts by the linear scaling quantile mapping and bernoulli gamma gaussian models and to verify predictive performances by verification metrics and diagnostic plots the results overall show that the pynmme effectively illustrates predictive performances of raw and calibrated forecasts over individual grid cells and at the global scale the linear scaling quantile mapping and bernoulli gamma gaussian models are effective in correcting biases while varying in improving forecast reliability and skill in the future the pynmme can be incorporated into environmental models to exploit valuable nmme precipitation forecasts for environmental modelling and management software availability the pynmme package is submitted as an e component and is publicly available declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is supported by the national key research and development program of china 2021yfc3001000 the national natural science foundation of china 51979295 51861125203 and u1911204 and the guangdong provincial department of science and technology 2019zt08g090 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2023 105732 
25384,the north american multi model ensemble nmme experiment assembles valuable ensemble forecasts from more than ten global climate models gcms focusing on environmental applications of nmme forecasts this paper develops the pynmme a python based toolkit to implement data retrieval forecast calibration and forecast verification specifically the toolkit is composed of three modules that streamline the processes of retrieving the nmme data for locations and seasons of interest from high dimensional datasets calibrating raw gcm forecasts by the linear scaling quantile mapping and bernoulli gamma gaussian models and verifying predictive performances by twenty verification metrics and six types of diagnostic plots the results show that the characteristics of bias reliability and skill of raw forecasts vary across the globe and that the three calibration models in the pynmme effectively improve raw forecasts to different extents overall the pynmme can serve as a useful tool to exploit valuable nmme precipitation forecasts for environmental modelling and management graphical abstract image 1 keywords global precipitation ensemble forecasts predictive performance data retrieval forecast calibration forecast verification data availability data will be made available on request 1 introduction the north american multi model ensemble nmme experiment launched in 2011 provides valuable ensemble climate forecasts for environmental modelling and management kirtman et al 2014 becker et al 2022 while global climate models gcms are developed by different agencies for climate forecasting the nmme pools more than ten state of the art gcms including the national centers for environmental prediction s climate forecast system version 2 cfsv2 and the geophysical fluid dynamics laboratory s seamless system for prediction and earth system research spear to provide global forecasts of precipitation temperature and geopotential height etc saha et al 2014 bauer et al 2015 delworth et al 2020 lin et al 2020 under the nmme protocol forecasts from different gcms are operationally provided at unified horizontal resolution 1 1 delivery date eighth of each month and lead time at least nine months becker et al 2022 furthermore the nmme forecasts have been widely incorporated into decision support systems for environmental planning flow maintenance and hazards management koppa et al 2019 arsenault et al 2020 muñoz et al 2020 tian et al 2022 there are generally three key steps for the use of gcm precipitation forecasts manubens et al 2018 iturbide et al 2019 wang et al 2019 fernandes et al 2020 firstly sub sets of forecasts for locations and seasons of interest are retrieved from high dimensional global datasets in which a vast amount of gcm forecasts are pooled by their spatial temporal properties kirtman et al 2014 secondly given that raw gcm forecasts are largely biased and unreliable calibration models are set up to correct biases in raw forecasts and quantify forecast uncertainty for practical applications gneiting et al 2007 scheuerer and hamill 2015 li et al 2017 wang et al 2019 thirdly predictive performances i e the correspondence between forecasts and observations murphy 1993 are verified for raw and calibrated forecasts verification metrics and diagnostic plots devised for ensemble deterministic and categorical forecasts are used to yield quantitative and graphical understandings of predictive performances wilks 2011 jolliffe and stephenson 2012 harpham et al 2019 huang and zhao 2022 this paper presents a python toolkit named pynmme to retrieve calibrate and verify precipitation forecasts while the nmme has been extensively used in seasonal precipitation forecasting its environmental applications can be constrained by the complexity of handling massive high dimensional forecast datasets frías et al 2018 khajehei et al 2018 roy et al 2020 becker et al 2022 hazra et al 2023 to bridge the gap the pynmme provides a suite of tools that streamline the entire processes of retrieving forecast data for spatial temporal extents of interest calibrating raw forecasts by formulating statistical models and verifying predictive performances by computing verification metrics and generating diagnostic plots as will be demonstrated through a case study of the cfsv2 precipitation forecasts in the nmme the pynmme facilitates detailed investigations of predictive performances over individual grid cells and at the global scale and illustrates the effectiveness of calibration models in improving raw gcm forecasts 2 toolkit capabilities 2 1 overview of pynmme fig 1 illustrates the three modules of pynmme to investigate precipitation forecasts specifically the module of data retrieval downloads and extracts forecasts of interest along with the corresponding observations from the nmme data server the module of forecast calibration sets up the linear scaling quantile mapping and bernoulli gamma gaussian models to improve raw precipitation forecasts piani et al 2010 zhao et al 2022 huang et al 2022 and the module of forecast verification computes verification metrics and generates diagnostic plots for raw and calibrated forecasts jolliffe and stephenson 2012 huang and zhao 2022 it is noted that the pynmme outputs forecasts and metrics in the network common data form netcdf format and generates plots in the portable network graphics png and other standard formats 2 2 data retrieval the nmme monthly precipitation forecasts and observations are downloaded from the international research institute at columbia university by uniform resource locators urls the forecast dataset f has five dimensions kirtman et al 2014 1 f f s l m y x where f represents forecast values specified by 1 start time s representing the month at which gcms produce forecasts 2 lead time l representing the length of time for which forecasts are generated ahead 3 ensemble member m representing different scenarios of future precipitation 4 latitude y and 5 longitude x the observation dataset o which is sourced from the climate prediction center s unified rain gauge database xie and arkin 1997 has three dimensions 2 o o t y x t s l where o represents observed values specified by 1 target time t which is the sum of start time and lead time in the alignment of forecasts with observations 2 latitude y and 3 longitude x by specifying latitude and longitude precipitation forecasts and observations over an individual grid cell are 3 f j f t m o j o t where f j and o j respectively represent forecasts and observations over a selected grid cell with latitude y j and longitude x j for paired forecasts and observations target times are determined by the sums of start times and lead times eqs 2 and 3 2 3 forecast calibration the linear scaling teutschbein and seibert 2013 crochemore et al 2016 quantile mapping zhao et al 2017 robertson et al 2023 and bernoulli gamma gaussian huang et al 2021 2022 models are set up in the pynmme to calibrate raw precipitation forecasts 1 the linear scaling corrects the difference between the means of forecasts and observations teutschbein and seibert 2013 4 f t m l s c f t m where f t m l s and f t m respectively represent linearly scaled forecasts and raw forecasts the coefficient c is determined by the sums of observations and ensemble members in training samples that is c m t 1 t o t t 1 t m 1 m f t m it is noted that mean values and ensemble spreads of raw forecasts are enlarged reduced when the coefficient is larger smaller than 1 2 the quantile mapping matches the distributions of raw forecasts and observations and converts forecast values into observed values by using the quantile i e cumulative probability wood 2002 piani et al 2010 5 f t m q m c d f o 1 c d f f f t m where f t m q m represents quantile mapped forecasts c d f o 1 represents the inverse cumulative distribution function cdf of observations and c d f f represents the cdf of forecasts it is noted that c d f o 1 and c d f f are implemented by fitting the mixed bernoulli gamma distributions respectively for observations and ensemble members in training samples which accounts for the skewness characteristic and the lower bound of the probability distribution of precipitation amounts piani et al 2010 huang et al 2021 3 the bernoulli gamma gaussian model generates calibrated forecasts by the conditional distribution derived from the bivariate gaussian distribution of ensemble means and observations huang et al 2022 6 o t n ρ f t 1 ρ 2 where o t represents the conditional distribution of observations on a new raw forecast f t and ρ represents the correlation coefficient in the bivariate gaussian distribution the bernoulli gamma gaussian model is built upon the gamma gaussian model the bernoulli gamma distribution is used in the normal quantile transform nqt to normalize ensemble means and observations and the bivariate gaussian distribution is formulated on the derived standard normal variates to generate calibrated forecasts random samples from o t are back transformed by inverse nqt compared with the quantile mapping the bernoulli gamma gaussian model has one additional parameter ρ to measure the strength of association between ensemble means and observations 2 4 forecast verification there are twenty verification metrics available in the pynmme murphy 1993 wilks 2011 jolliffe and stephenson 2012 huang and zhao 2022 herein the spearman s rank correlation coefficient scc relative bias rb alpha index α index and continuous ranked probability skill score crpss are used to evaluate precipitation forecasts the scc measures the association between ensemble means and observations 7 s c c 1 6 t 1 t d t 2 t t 2 1 where t is the number of pairs of forecasts and observations d t represents statistics calculated by ranks of ensemble means f t and observations o t the highest value of scc is 1 indicating a perfect monotonic increasing relationship the rb examines bias by the sums of ensemble means and observations 8 r b t 1 t f t t 1 t o t t 1 t o t 100 as can be seen the rb takes a perfect value of zero while a positive negative value indicates that forecasts are overall larger smaller than observations the α index quantifies reliability based on probability integral transform pit 9 α index 1 2 t t 1 t p i t t t t 1 where p i t t represents the t th order statistic of pit the α index ranges from 0 to 1 and a value of 1 indicates perfectly reliable spreads the crpss measures forecast skill by comparing the performances of ensemble forecasts and reference forecasts 10 c r p s s c r p s r e f c r p s e n s c r p s r e f 100 where crps ref and crps ens respectively represent the crps computed for reference forecasts and the nmme ensemble forecasts a higher value of crpss indicates better predictive performance with a perfect value of 100 in particular a positive negative value indicates that ensemble forecasts outperform underperform reference forecasts there are six types of diagnostic plots available in the pynmme huang and zhao 2022 for ensemble forecasts the time series plot displays forecasts and observations in a time sequence iturbide et al 2019 huang et al 2022 the quantile range plot examines whether ensemble forecasts can capture observations wang et al 2009 zhao et al 2019 and the pit uniform plot indicates forecast reliability by plotting sorted pit against standard uniform variate renard et al 2010 zhao et al 2022 also there are the correlation scatter plot for deterministic forecasts and the reliability diagram and the receiver operating characteristic curve for categorical forecasts furthermore spatial plotting of verification metrics can serve to inspect predictive performances at regional and global scales yuan et al 2011 zhao et al 2020 3 case study the rolling updates of gcm precipitation forecasts are illustrated in fig 2 the first row presents monthly precipitation observations from january 2010 to july 2010 and the last four rows showcase the monthly updated cfsv2 forecasts as can be seen the cfsv2 initializes at the beginning of each month and generates precipitation forecasts for the subsequent months specifically for the second row the cfsv2 is initialized in january 2010 and produces forecasts for january 2010 lead 0 months february 2010 lead 1 month and july 2010 lead 6 months and for the third row the cfsv2 is initialized in february 2010 and produces forecasts for february 2010 lead 0 months march 2010 lead 1 month and july 2010 lead 5 months in the meantime subplots in a column present forecasts targeting at the month of corresponding observations but with different lead times which graphically illustrates relationships among start lead and target times eqs 1 and 2 in high dimensional nmme datasets seasonal forecasts for precipitation in june july august jja are retrieved from the nmme datasets specifically start times are set to be june from 1982 to 2010 hindcast period and the lead times are selected to be 0 1 and 2 months for each year monthly forecasts for the three lead times are summed to form seasonal forecasts targeting at jja precipitation in this way seasonal forecasts for jja precipitation in the 29 years are pooled to consider precipitation seasonality accordingly monthly observed amounts are also summed to form seasonal totals for jja from 1982 to 2010 it is noted that attention is paid to 14 921 land grid cells over which seasonal totals are larger than 0 01 mm robertson et al 2013 huang et al 2023 for each grid cell across the world raw forecasts are calibrated and verified specifically the linear scaling quantile mapping and the bernoulli gamma gaussian models are independently used to calibrate raw forecasts under leave one year out cross validation that is raw forecasts for one year are calibrated by models trained by samples in other years ensuring that the testing sample is not implied by training samples schepen et al 2018 wang et al 2019 li et al 2022 to verify raw and calibrated forecasts the scc rb α index and crpss eqs 7 to 10 are computed and the time series quantile range and pit uniform plots are displayed 4 result analysis 4 1 performances of raw forecasts raw precipitation forecasts over five selected grid cells are illustrated by the time series quantile range and pit uniform plots in fig 3 specifically the five grid cells are respectively selected by 1 the highest scc the first row 2 the lowest scc the second row 3 the highest rb the third row 4 the rb closest to zero the fourth row and 5 the highest α index the fifth row accordingly varying predictive performances are presented 1 the first row showcases raw forecasts that are positively correlated with observations as shown in the time series and quantile range plots a large small forecast value tends to correspond to a large small observed value in the meantime ensemble forecasts are overall smaller than observations owing to negative biases the pit values tend toward one and the pit uniform plot distributes above the 1 1 line indicating limited reliability 2 the second row illustrates a negative correlation between raw forecasts and observations that is a large small forecast value usually coincides with a small large observed value resulting in an scc value of 0 63 also it can be seen that the observed values are overall above ensemble forecasts and that the pit uniform plot deviates from the 1 1 line indicating negative biases and unreliable spreads 3 the third row displays positively biased ensemble forecasts it can be observed that the observations are smaller than 20 mm while the 10 percentiles of ensemble forecasts are above 50 mm the substantial biases make the 29 pit values equal to 0 leading to an α index of 0 and a crpss of 7120 96 the implication is that the raw forecasts underperform climatological reference forecasts due to positive biases and unreliable spreads 4 the fourth row is for unbiased ensemble forecasts the rb nearly takes a perfect value of zero as the mean value of forecasts is similar to that of observations eq 8 although the ensemble spreads tend to capture the observations the quantile range plot suggests that there is a neutral correlation between the ensemble medians and the observations 5 the fifth row shows reliable ensemble forecasts since reliability is a sufficient condition of unbiasedness zhao et al 2022 ensemble forecasts selected by the highest α index are overall unbiased and reliable in the meantime the quantile range plot distributing along the 1 1 line indicates a reasonable correlation between forecasts and observations as a result the raw forecasts outperform climatological forecasts and exhibit a positive crpss 17 84 the four metrics examined in fig 3 are further illustrated at the global scale in fig 4 specifically metrics are computed over each grid cell and displayed by spatial plotting overall the values of metrics exhibit notable spatial variation positive scc can be observed in south america southeast asia and australia indicating reasonable correlations between raw forecasts and observations in fig 4b the values of rb can be smaller than 100 e g northern south america or larger than 100 e g north asia the implication is that raw forecasts usually suffer from substantial biases largely owing to biases the values of α index fig 4c and crpss fig 4d can be respectively smaller than 0 5 and 0 which indicates unreliable spreads and negative skill in addition positive crpss can be observed for a few grid cells in australia and south america as therein forecasts are unbiased and reliable 4 2 performances of calibrated forecasts the linear scaling quantile mapping and bernoulli gamma gaussian models are used to calibrate raw forecasts fig 5 presents quantile range plots for the three types of calibrated forecasts over the five selected grid cells comparing figs 5 and 3 it can be observed that the three calibration models evidently improve the predictive performances to different extents the observations tend to fall within 10 90 inter quantile ranges of calibrated forecasts leading to rb smaller than 2 in particular the values of α index and crpss are notably improved for grid cells a b and c over which raw forecasts suffer from substantial biases and unreliable spreads the rb of linearly scaled forecasts quantile mapped forecasts and bernoulli gamma gaussian calibrated forecasts are illustrated at the global scale in fig 6 specifically the values of rb across the globe are displayed by spatial plotting in figs 6a c and also pooled by the violin plots in fig 6d comparing figs 6 and 4 it can be observed that biases in raw forecasts are considerably corrected as shown by the violin plots the medians of rb for the three types of calibrated forecasts are close to zero the implication is that the three calibration models can effectively correct biases in raw forecasts the α index for the three types of calibrated forecasts are illustrated at the global scale in fig 7 overall the three calibration models can improve forecast reliability by correcting biases fig 6 and the medians of α index become higher than 0 8 it is noted that the quantile mapped forecasts can exhibit better reliability than the linearly scaled forecasts it is because the quantile mapping accounts for the difference in the marginal distributions while the linear scaling focuses on the correction of mean values eqs 4 and 5 furthermore the bernoulli gamma gaussian model leads to the α index mostly higher than 0 8 indicating its better efficacy in improving forecast reliability than the linear scaling and quantile mapping the crpss for the three types of calibrated forecasts are illustrated at the global scale in fig 8 comparing figs 4 and 8 it can be seen that the negative skill prevalent in raw forecasts is considerably eliminated primarily due to the reduced biases and improved reliability in the meantime the linearly scaled forecasts and quantile mapped forecasts can exhibit negative crpss over a number of grid cells by contrast the bernoulli gamma gaussian model generally ensures positive and neutral skill across the world it is generally due to that the bernoulli gamma distribution is effective in characterizing marginal distributions of precipitation data and that the bivariate gaussian distribution is effective in accounting for the dependence between raw forecasts and observations huang et al 2021 2022 5 discussion the pynmme is a python based toolkit that presents detailed investigations of the nmme forecasts in practice the use of forecasts usually requires various technical tasks including formulating calibration models computing verification metrics and visualizing forecast uncertainty wilks 2011 iturbide et al 2019 duan et al 2020 there exist r packages and softwares such as ensemble verification system brown et al 2010 visualizer frías et al 2018 s2dverification manubens et al 2018 and climate4r iturbide et al 2019 developed for verifying the predictive performances of hydroclimatic forecasts in this paper the pynmme supplements the existing toolkits by offering a suite of python tools tailored to the nmme forecasts specifically this toolkit streamlines the processes of data retrieval forecast calibration and forecast verification without the need of coping with varying data requirements in different tools which facilitates efficient analysis of the nmme forecasts the cfsv2 forecasts in the nmme are employed to illustrate the use of pynmme to retrieve calibrate and verify precipitation forecasts as is demonstrated in the case study this toolkit effectively illustrates predictive performances of raw and calibrated forecasts over individual grid cells and at the global scale crochemore et al 2016 huang et al 2021 zhao et al 2022 it is pointed out that the analysis implemented by the pynmme fig 1 can be extended to gcm forecasts of other hydroclimatic variables such as temperature and evaporation strazzo et al 2019 zhao et al 2019 becker et al 2022 specifically raw gcm forecasts are retrieved for locations and seasons of interest and then verified by verification metrics and diagnostic plots given that systematic and random errors are identified in raw forecasts it is necessary to formulate calibration models to correct biases and improve forecast reliability and skill before practical applications slater et al 2016 strazzo et al 2019 roy et al 2020 6 conclusions the pynmme is developed to facilitate detailed investigations of the nmme forecasts the three modules can be readily used to implement data retrieval forecast calibration and forecast verification through a case study of the nmme forecasts the pynmme is used to retrieve seasonal forecasts for jja precipitation from the high dimensional gcm datasets to calibrate raw forecasts by the linear scaling quantile mapping and bernoulli gamma gaussian models and to verify predictive performances by verification metrics and diagnostic plots the results overall show that the pynmme effectively illustrates predictive performances of raw and calibrated forecasts over individual grid cells and at the global scale the linear scaling quantile mapping and bernoulli gamma gaussian models are effective in correcting biases while varying in improving forecast reliability and skill in the future the pynmme can be incorporated into environmental models to exploit valuable nmme precipitation forecasts for environmental modelling and management software availability the pynmme package is submitted as an e component and is publicly available declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is supported by the national key research and development program of china 2021yfc3001000 the national natural science foundation of china 51979295 51861125203 and u1911204 and the guangdong provincial department of science and technology 2019zt08g090 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2023 105732 
