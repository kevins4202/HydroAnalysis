index,text
810,anthropogenic activities along streams and rivers may be of major concern for fluvial ecosystems e g abstraction and impoundment of surface water resources may profoundly alter natural streamflow regimes an established approach aimed at preserving the behavior and distribution of fluvial species relies on the definition of ecological flows e flows downstream of dams and diversion structures e flow prescriptions are usually set by basin authorities at regional scale often without a proper assessment of their impact and effectiveness on the contrary we argue that e flows should be identified on the basis of i regional and ii quantitative assessments we focus on central italy and evaluate the effects on habitat suitability of two near threatened fish species i e barbel and chub and an existing hydro power network when shifting from the current time invariant e flow policy to a tighter and seasonally varying soon to be enforced one our example clearly shows that a quantitative regional scale assessments are viable even when streamflow observations are entirely missing at study sites b aprioristic e flows policies may impose releases that exceed natural streamflows for significantly long time intervals weeks or months c unduly tightening e flow policies may heavily impact regional hydro power productivity 15 and 42 losses on annual and seasonal basis respectively yet resulting in either marginal or negligible improvements of fluvial ecosystem keywords water resources management hydro electric production e flow phabsim barbel chub 1 introduction hydro power is the worldwide leading renewable source for electricity production with a capacity increase of more than 30 between 2007 and 2015 wce 2016 despite its economic relevance several environmental concerns are associated with hydro power production indeed hydro power plants are known to severely affect flows downstream of abstraction points over limited time periods person et al 2014 viganó et al 2016 under these conditions the river natural flow regime nfr defined as the river signature in terms of flow magnitude frequency timing duration and rate of change poff et al 1997 is no longer guaranteed nfr is a key driver of ecological and geomorphological processes allan and castillo 2007 bunn and arthington 2002 ceola et al 2014 ceola and pugliese 2014 young et al 2011 and thus any flow disturbance may significantly affect and alter fluvial ecosystem dynamics see e g bradford et al 2011 ceola et al 2013 poff and allan 1995 vanzo et al 2016 as recognized by several water protection policies e g the european water framework directive u 2000 the water laws in act 1998 and china 2002 the australian environment act 1999 ecological flows e flows are commonly defined in order to sustain freshwater ecosystems and the river ecological status the concept of e flows has existed for more than 40 years acreman and dunbar 2004 snelder et al 2014 tharme 2003 and it is widely applied throughout the globe though presenting significant differences across site specific applications e flows can be generally grouped under two main categories based on the methodology they rely upon on one side one may find the classical hydrologically based methods e g minimum flow flow percentiles see tharme 2003 this category embeds easily applicable and simple approaches that can be employed across large areas but do not focus on any ecological variable being thus somehow in contrast with the definition of e flows quite frequently e flows defined within this category are described by constant flows during the year thus disregarding the inter annual flow variability that controls species life stages stromberg et al 2010 on the other side there are the so called micro scale and meso scale physical habitat modeling methods based on in situ and experimental measurements to analyze optimal environmental conditions for target species several habitat suitability models are described in the scientific literature see e g phabsim bovee 1982 rhyhabsim jowett 2010 river2d steffler and blackburn 2002 whyswess yi et al 2010 and casimir munoz mas et al 2012 at the micro scale and mesohabsim parasiewicz 2001 mesocasimir schneider et al 2001 and rhm maddock et al 2001 at the mesoscale among these phabsim and mesohabsim are probably the most widely used and representative ones while mesohabsim refers to specific hydromorphologic units i e hmus bovee et al 1998b parasiewicz 2001 and performs a 2d analysis based on detailed input data phabsim analyzes environmental conditions based on 1d hydraulic variables through the definition of habitat suitability curves within the instream flow incremental methodology ifim bovee et al 1998a framework the ecological variables are key elements of this physical habitat approach which considers specific target species and requires detailed and site specific data in case of limited data availability expert knowledge is a common practice the ifim context allows phabsim to identify improvements in habitat state from different flow regimes thus making predictions and supporting the negotiation of suitable water delivery scenarios booker and dunbar 2004 according to recent e flow prescriptions all flow components from base flow to flood regime are to be included as operational targets for a sustainable water resources management eu 2000 in this respect flow duration curves fdcs a classical hydrological tool that embeds details on streamflow regime which is widely used for flood control water quality management and hydro power purposes represent a meaningful tool for analyzing several ecohydrological issues such as e g the effects of e flow scenarios on riverine habitat vogel and fennessey 1995 the scientific literature collects a plethora of studies investigating the potential impacts of different flow releases downstream of hydro power plants on energy production and riverine ecosystems see e g ayllon et al 2014 hirsch et al 2014 person et al 2014 snelder et al 2014 viganó et al 2016 yi et al 2017 yin et al 2014 though only a few of them has employed fdcs particularly at a regional scale ayllon et al 2012 capra et al 1995 pragana et al 2017 in addition quantitative assessments of e flows impacts are considered to be unviable when the availability of hydrological data is limited i e a frequent condition even for high income countries to overcome this issue fdcs and top kriging are powerful hydrological tools that can be used to reconstruct streamflow regimes at ungauged sites farmer 2016 pugliese et al 2014 thus enabling one to evaluate the hydro power production and ecological status across large catchments and regions see e g cuya et al 2013 popescu et al 2012 in this study we quantitatively analyze the effects of alternative e flow prescriptions on hydro power production and fish habitat suitability for two italian river basins by employing fdcs and top kriging techniques in particular we perform a regional scale analysis by considering two different e flow policies i e current policy and a tighter future one see section 2 4 identified on the basis of empirical methods and set a priori by the local regional authority without any former insight on possible effects on river biota we demonstrate how to cope with a limited availability of streamflow data at locations of interest thus supporting a quantitative assessment of the impacts and the effectiveness of e flows at regional scale our analysis focuses on barbel barbus barbus and chub leuciscus cephalus species which are considered to be near threatened in italy zerunian 2007 and require high protection level at regional scale barbel and chub spawning occurs from april to june and their habitat requirements are well known bicchi et al 2006 rambaldi et al 1997 while it is straightforward to anticipate a decrease in hydro power production for higher e flow releases i e future prescriptions ecological effects on the considered fish species cannot be easily predicted nor were ever assessed for the study area by local authorities in charge of defining e flow policies to this aim we employ different habitat suitability criteria to examine whether a loss or a gain in habitat suitability is associated with a modification in the e flow releases pta 2010 for assessing the ecological effect we employ the classical phabsim approach and we elaborate an analytic approach based on fdcs and on a simpler hydraulic model hereafter labeled as habitat suitability duration curve hsdc which can be easily applied across hydrologically and ecologically homogeneous large catchments and regions and particularly in any ungauged site 2 study area data and e flow scenarios the quantitative assessment of the effectiveness of two alternative e flow scenarios and their impact on hydro power production and fish habitat suitability is applied to hydro power plants located within the potenza and chienti river basins in the marche administrative district in central italy fig 1 and table 1 2 1 river basins description the potenza and chienti river basins with a catchment area of 640 and 1070 km2 respectively flow northeasterly from the apennines to the adriatic sea the elevation ranges between 40 and 1400 m asl above sea level for potenza and 20 and 2000 m asl for chienti in these two catchments agricultural areas 59 forests and semi natural areas 38 share the majority of land covers while human settlements and impervious areas are around 3 eea 2007 two major geological units dominate the study area from a hydro geological perspective the head water catchments are dominated by fractured carbonate limestones with frequently emerging subsurface water see fig 1 while the downstream area mainly presents sandstones and marble calcarenites the study area shows a maritime streamflow regime see castellarin et al 2004a 2004b whose typical hydrologic year is characterized by a maximum monthly discharge during winter and minimum during summer the climate of this area is conditioned by the close presence of both the adriatic sea and the apennines with average annual temperatures ranging from 8 c to 15 c mean annual precipitation map values evaluated at catchment scale are reported in table 2 for the study stream gauges 2 2 hydro power plants in the study area we consider 14 hydro power plants see table 1 operated by the energy multinational power company enel group ltd and located within the potenza and chienti river basins see fig 1 in particular as illustrated in table 1 we consider three storage dam and eleven run of the river ror hydro power plants that share a common feature i e power houses are located downstream the corresponding dams or barrages and off line relative to the river course hence the water used for hydro power production needs to be diverted and is returned to the river only downstream the abstraction point as a consequence the operation of the hydro power plant alters the natural streamflow regime within the river stretch between the abstraction point and the power plant outlet which in several cases is a few kilometers long several characteristics of the study dams barrages and hydro power plants illustrated in table 1 are accessible from enel group ltd technical reports and publications enel 1992 galeati 2013 2013b observed data on the natural streamflow regime nfr instead is sparse or completely missing for barraged and dammed river cross sections considered in our study we therefore estimate the natural streamflow regime at abstraction points by referring to the streamflow data described in section 2 3 and by applying a geostatistical procedure that interpolates empirical flow duration curves of daily streamflow fdcs along the stream network see farmer 2016 pugliese et al 2014 measurements of stream network hydraulic properties i e river width w water depth d flow velocity v and discharge q are available only for a subset 5 out of 14 of the considered hydro power sites see red filled symbols in fig 1 these features are recorded downstream the hydro power plants in correspondence of four distinct cross sections within a nearly 100 m long river reach 2 3 hydrologic data natural daily streamflow series are available for the study region at 17 stream gauges belonging to the former national hydrographic service of italy simn observed flow series span over the time period 1920 2000 with an observation period ranging from 5 to 40 years average record length 18 years table 2 reports drainage area and mean annual precipitation map of catchments upstream each stream gauge as well as some statistics of daily streamflow series mean annual flow maf minimum and maximum flows 75 50 and 25 exceeded flow values empirical map values relative to each of the 17 catchments are estimated using data collected from a rather dense rain gauge network i e 1 rain gauge per 50km2 on average during the same time interval of daily streamflow records our daily streamflow dataset includes only complete years missing daily streamflow records have been linearly interpolated for time intervals shorter than one week while for longer time intervals of missing observations we have discarded the entire year see castellarin et al 2004a 2 4 regional river regulation e flow prescriptions two alternative e flow scenarios prescribed by the marche administrative district are considered in our study the current time invariant experimental e flow release and the soon to be enforced time variant e flow release based on water protection plan prescriptions pta 2010 hereafter labeled as pilot and wpp respectively pilot e flows will be authorized until dec 31 2019 while from jan 1 2020 the regional authority is going to enforce wpp e flows the pilot e flow release results from an experimental program agreed among the regional administration and enel group ltd which allowed a reduced e flow release compared to wpp this scenario refers to the most common practice in reservoir management namely to consider a constant e flow value across the whole year regardless of the natural intra annual flow variability activities aimed at monitoring the environmental effect of e flows downstream of dams and barrages are still undergoing and at this stage data are not currently available the wpp e flow release by recalling the eu water framework directive u 2000 includes a temporal regulation of e flows thus reproducing natural streamflow regimes of river reaches downstream the abstraction points which supposedly enhances ecosystem conservation wpp e flow releases qwpp m3 s are computed from the following empirical expression 1 q w p p k m a f b e max n i f g t where k is an empirical parameter ranging from 0 05 to 0 1 maf m3 s is the mean annual flow b is a parameter that takes into account the hydrogeologic features of the study area b 2 in upstream river reaches mainly consisting of fractured carbonate limestones b 1 in downstream areas presenting sandstones and marble calcarenites see section 2 1 and fig 1 e represents the river ecological status ranging from 1 to 1 4 for very good or very poor conditions respectively n represents the degree of wilderness of the area around the river reach ranging from 1 3 for protected areas i e natural parks to 1 for urban and rural areas i f represents the river functionality ranging from 1 to 1 2 for very good to very poor river functionality respectively g is geomorphologic parameter related to hydraulic and morphological characteristics of the river reach ranging from 0 9 to 1 1 t is the temporal factor identifying different flow seasons in a year in this context the term season refers to one of the four time intervals identified in the water protection plan of the marche administrative district namely november january total duration 92 days t 1 3 february march total duration 59 days t 1 5 april june total duration 91 days t 1 3 july october total duration 123 days t 1 0 table 3 reports pilot and wpp e flow releases for the 5 hydro power sites see red filled symbols in fig 1 for which both hydro power production and habitat suitability are assessed 2 5 fish species for habitat suitability assessment the study fish species barbel barbus barbus and chub leuciscus cephalus belong to the cyprinidae family and are typical in the study area three different life stages are examined namely juvenile spawning and adult given that the spawning season for both species is between april and june we consider juvenile fish as those small fish hatched from eggs spawned in the same year whereas the adult stage represents individuals older than 1 year by using the wpp e flow seasonality described in section 2 4 we associate each life stage with a specific e flow season as follows juvenile is associated with july october spawning with april june and adult with the whole year from january to december 3 methods 3 1 estimation of natural flow regime at hydro power sites in order to reconstruct the unknown natural inflows to the considered hydro power sites we employ observed streamflow data and apply a geostatistical technique the procedure which was originally proposed and applied by pugliese et al 2014 to the same study region adapts the topological kriging or top kriging see skøien et al 2006 a block kriging with variable support area coinciding with the catchment watershed see skoien et al 2014 and enables the user to predict fdcs in ungauged basins by linearly weighting empirical curves constructed at available stream gauges kriging weights used in the linear weighting scheme take catchment size and nesting structure of the stream network into account using the top kriging adaptation by pugliese et al 2014 we predict long term fdcs of daily streamflows at all 14 abstraction points of interest by interpolating empirical period of record i e constructed on the basis of all available daily streamflow observations fdcs according to the regional river regulation illustrated in section 2 4 minimum streamflow requirements have to be identified on a seasonal basis the term season in this context coincides with one of the four time intervals specified in the regional regulation therefore together with the long term annual fdcs that describe the natural streamflow regime we also predict the long term seasonal fdcs for the four periods of interest as defined in the water protection plan of our study area pta 2010 the prediction of seasonal fdcs represents a novel application of the procedure developed by pugliese et al 2014 the validation is based on the same leave one out cross validation scheme used in pugliese et al 2014 for assessing the accuracy of predicted long term yearly fdcs the results prove the suitability of the selected approach since the accuracy of predicted seasonal fdcs results to be comparable with the accuracy of predicted yearly curves and certainly acceptable for the scopes of the present analysis i e overall nash sutcliffe efficiency computed for predicted log flows in cross validation varies between 0 91 and 0 94 and is equal to 0 96 for yearly curves see also pugliese et al 2014 3 2 computation of hydro power production the present section summarizes the different steps required by the computation of annual and seasonal hydro power productions distinguishing between run of the river and storage power plants see table 1 it is worth emphasizing here that our study neglects the interaction between power plants located along the same stream i e we do not consider the possible effects of streamflow regulation upstream the considered power plant that is we always adopt the nfr as inflow condition this simplifying working hypothesis is correct when only run of the river power plants exist upstream any given river dam barrage but is certainly associated with an approximation when artificial reservoirs with significant storage capacity exist upstream the location of interest nevertheless the hypothesis seems viable in our study given the limited number of hydro power plants located downstream the study dams see fig 1 concerning the eleven run of the river hydro power plants listed in table 1 the assessment of hydro power production under various constraints on e flow release is straightforward when annual and seasonal fdcs relative to the nfr are available for the barraged river cross sections see e g vogel and fennessey 1995 therefore seasonal fdcs of daily streamflow are predicted at all hydro power plants via top kriging see section 3 1 fig 2a provides a graphical example for montefranco hydro power plant see table 1 which clearly shows that for roughly 10 of the season duration the e flow value is higher than natural streamflows concerning the three storage power plants see table 1 since they can store and manage inflow water volumes the assessment of their hydro electric productivity cannot be based solely on fdcs representative of the nfr but it requires continuous and possibly multi annual daily streamflow series and a conceptualization of reservoir management and functioning fig 2b c illustrates reconstructed inflows together with outflows relative to an arbitrarily selected year at polverina dam see table 1 in particular the figure reports the reconstructed daily inflows blue line and the seasonally variable e flow releases red line wpp scenario which are used as inputs and the daily series of simulated outflows downstream the reservoir black line the computation of yearly and seasonal hydro power production for e flow scenarios pilot and wpp for run of the river and storage power plants relies also on i hydro power plant characteristics e g minimum and maximum exploitable discharge see table 1 and ii seasonal e flow values for the considered scenario i e pilot and wpp a detailed description of the computational steps for the evaluation of hydro power production for any given site and season is reported in the appendix 3 3 habitat suitability assessment the potential impact of pilot and wpp e flow scenarios on barbel barbus barbus and chub leuciscus cephalus suitability to the physical habitat within the considered river basins is assessed by coupling the outflows from the hydro power sites with habitat suitability criteria hsc hsc describe species habitat preferences ranging from 0 unsuitable to 1 most suitable by accounting for the effects of hydro morphological variables i e water depth hscd flow velocity hscv and river substrate hscs on species distribution given that habitat suitability of target species changes during a lifetime hsc are generally defined and associated with different life stages see section 2 5 the formulation of hsc should be generally based on field investigations providing detailed ecological information of the target species from the study area however due to the difficulty of collecting sufficient data on species habitat these data are not always available as in the present study when local information are missing expert knowledge is a significant basis and multiple hsc showing similar hydrological morphological and ecological properties to those characterizing the study area should be considered in order to test for consistency and account for the effects of different formulations here we consider two alternative hsc provided by bicchi et al 2006 and rambaldi et al 1997 both referring to the central apennines in italy and therefore suitable for our study area see figure s1 habitat suitability values are then combined together by computing a composite habitat suitability hs as the product of hscd hscv hscs it is worth highlighting here that since the formulation proposed by bicchi et al 2006 neglects the effect of river substrate i e by assuming a constant maximum preference regardless the substrate characteristics hscs 1 for consistency we implement the same condition in the hsc from rambaldi et al 1997 we employ two different methodologies to quantify a synthetic indicator of the habitat quality i e suitable area index sai m2 mathrmm associated with the different release scenarios illustrated in section 2 4 i the classical phabsim procedure and ii an analytic method based on fdcs hereafter labeled habitat suitability duration curve hsdc the habitat quality indicator sai is then estimated for each hydro power site i e a total of 5 sites see red filled symbols in fig 1 each fish species i e 2 species barbel and chub each life stage i e 3 life stages juvenile spawning adult each hsc 2 i e bicchi et al 2006 rambaldi et al 1997 and each flow regime 3 i e nfr pilot wpp due to the limited hydro ecologic data availability we adopt phabsim although more recent alternatives see e g phabsim rhyhabsim river2d whyswess casimir mesohabsim mesocasimir rhm are consolidated across the scientific literature furthermore when analyzing e flows at the micro habitat level within an ifim context bovee et al 1998a different flow scenarios and habitat suitability models are to be considered in order to assess the ecological effects and then negotiate e flows to be prescribed in our case study given that e flow scenarios prescribed by the regional authority were determined a priori without performing any assessment of the effects on river biota a sort of backward application of ifim is performed i e from prescribed e flows the current and the soon to be enforced to ecological and hydro power production effects 3 3 1 estimation of suitability area index from phabsim and hsdc phabsim divides river cross sections into several vertical elements or grid cells each one characterized by given flow velocity and water depth for a given streamflow value more specifically flow velocity and water depth are derived from 4 distinct cross sections within a nearly 100 m long river reach in correspondence of each hydro power site given that phabsim hydraulic modeling can be sometimes controversial dunbar et al 1998 ghanem et al 1996 shirvell 1986 we calibrated the hydraulic model on the basis of concurrent observations of discharge and water level through hec ras simulations brunner 2016 which we then use as inputs to phabsim see e g nikghalb et al 2016 the composite habitat suitability is computed for every grid cell and the weighted usable area wua i e the available habitat area for the target species within a river reach m2 m is then evaluated as a weighted sum of composite suitability and cell area for each flow scenario nfr pilot and wpp we estimate wua values for a given set of discharges i e streamflow values sampled from fdcs and associated with 16 durations within the range 0 005 0 995 and then combine these wua values to quantify sai as the integral of the wua duration curve 2 s a i d 0 d 1 w u a d d d where wua d is the weighted usable area associated with a duration d ranging from 0 to 1 concerning the hsdc approach the composite habitat suitability hs is based on fdcs and on a simpler hydraulic procedure and it is evaluated for the entire river cross section i e without dividing the cross section into computational grid cells by following the procedure proposed by vogel and fennessey 1995 we combine the relation between hs and discharge fig 3b with the predicted fdc fig 3a and define the hsdc as the relationship between the composite habitat suitability and the duration or exceedence probability of the discharge value associated with that hs fig 3c we then compute the habitat suitability index hsi as the integral of the habitat suitability duration curve shaded areas in fig 3c 3 h s i d 0 d 1 h s d c d d d where d represents the duration associated with each composite habitat suitability value finally the suitable area index sai is defined by simply multiplying hsi and the wetted river width w from the equivalent rectangular cross section a detailed description of the 3 step procedure for the computation of hs as a function of discharge values is reported in the appendix 4 results 4 1 computation of hydro power production fig 4shows through a box plot representation the distribution of relative differences of hydro power production for the set of 14 plants belonging to potenza and chienti river basins i e run of the river and storage power plants for each reference period i e the entire year and four sub periods namely nov jan feb mar apr jun and jul oct each value is computed as the difference between the hydro power production associated with pilot i e current e flow releases and with releases that are compliant with the regional water protection plan wpp e flow releases soon to be enforced divided by the former all computations of hydro power production refer to daily inflow series storage hydro power plants or period of record yearly or seasonal fdcs run of the river hydro power plants reconstructed for a multiannual time span roughly extending between 1920 and 2000 hence the resulting hydro power production should be regarded as a long term prediction of the hydro power potential for any given study plant each prediction is necessarily associated with some degree of uncertainty resulting from all simplifying assumptions adopted in our study it is worth noting though that we are mainly interested in comparing different estimates of long term hydro power productivity rather than assessing their absolute values which mitigates the impact of simplifying assumptions one striking feature of fig 4 is that values are all positive meaning that the enforcement of wpp releases will result in losses of hydro power production this result was expected as the current prescriptions on e flows are less stringent than wpp ones see table 3 another feature of fig 4 is the dependence of the reduction of hydro power production on the considered time period average relative differences in are equal to 14 7 13 7 5 8 10 2 and 42 8 for year nov jan feb mar apr jun and jul oct reference time intervals in this order production losses are significant or extremely significant over the study area more than 50 of the plants show a production loss larger than 10 on an annual scale or during the time period between november and january which is one of the two wet seasons for the study catchments the other spanning between march and early june losses become extremely important between july and october with 50 of the plants showing losses larger than 44 and in excess of 58 in 25 of the cases this result is associated with wpp e flow prescriptions during the summer season i e between july and october which are particularly severe during several weeks of the simulation time interval 1920 2000 wpp e flows resulted to be larger than natural streamflows for the majority of study catchments in particular relative to pilot e flow releases and on the basis of the computations performed in our study the enforcement of wpp releases is likely to increase the duration of plant shutdown periods by 61 and 132 days per year on average for the potenza and chienti hydro power plants respectively i e c a two and four months respectively which is an extremely significant amount of time the marked variability of production losses between different hydro power plants e g between 7 and 29 or 20 and 82 for year and jul oct respectively results from the extremely high variability of a few empirical parameters used by the expression adopted in the regional wpp for computing the e flow a noteworthy example is the parameter b which is normally equal to 1 and is set to 2 for all basins that are entirely within with a specific geological unit that mainly consists of fractured carbonate limestones see section 2 1 4 2 habitat suitability assessment suitable area index sai values computed for the 5 hydro power sites are shown in figs 5 and 6 for barbus barbus and leuciscus cephalus respectively in order to examine the regionalized i e average behavior of the study area characterized by comparable hydro geomorphic properties we opted for grouping together the considered river cross sections the outcomes are presented in terms of mean standard deviation for the 2 alternative methodologies namely phabsim and hsdc and the 2 habitat suitability criteria bicchi et al 2006 rambaldi et al 1997 as expected regionalized sai values computed from the hsdc method are generally characterized by a higher variability compared to the phabsim ones indeed while the application of phabsim generally results in at least some a few elementary cells of each river cross section presenting suitable conditions for fish the hsdc approach which assumes an equivalent rectangular cross section under uniform flow conditions may bring forth either totally unsuitable or suitable states thus showing a larger sai range the application of the habitat suitability criteria proposed by bicchi et al 2006 shows a fairly good agreement between sai values from phabsim and hsdc for both fish species figs 5a b c and 6 a b c for the adult life stage figs 5c and 6 c phabsim and hsdc methodologies consistently reveal a preference for the wpp e flow scenario whereas both pilot and wpp e flow scenarios present similar outcomes for juvenile figs 5a and 6 a and spawning figs 5b and 6 b life stages the nfr always presents the lowest sai values compared to pilot and wpp e flow scenarios this result is likely to be associated with the large range of discharge values i e from 10 1 m 3 s to 103m3 s whose extreme conditions i e floods and low flows are mostly unsuitable for fish indeed habitat suitability is usually assessed for low flows thus entirely disregarding high or very high flow conditions booker and dunbar 2004 furthermore the hsdc approach reveals that juvenile figs 5a and 6 a and spawning figs 5b and 6 b life stages which prefer low water depths and flow velocities and thus lower discharges may experience particularly small and even negligible sai values under nfr this condition intimately depends on the discharge values associated with the composite habitat suitability which may lie outside the discharge range gathered from the fdc see fig 3 more specifically when applying hsdc under nfr negligible or even null composite suitability values can be associated with the majority of discharge values sampled from the fdc as a consequence sai values may result in extremely low or even null figures concerning the application of the habitat suitability criteria proposed by rambaldi et al 1997 a satisfactory match between phabsim and hsdc approaches on sai values associated with the different flow regimes is evident only for the adult life stage of both fish species figs 5f and 6 f in this case adult fish reveal an overall preference for nfr conditions with the lowest values for the pilot e flow scenario conversely juvenile figs 5d and 6 d and spawning figs 5e and 6 e life stages show rather contradictory outcomes with divergent sai values evidently the linkage among fdcs and the relationship between hs and discharge plays a key role our analysis reveals that the two habitat suitability criteria employed in this study both referring to apennines rivers with comparable hydrologic regime and water resource availability despite some differences in terms of absolute quantities show a rather consistent trend when comparing the three flow regimes i e nfr pilot and wpp either with the phabsim or the hsdc methodology in particular given that i for juvenile and spawning life stages the two e flow releases present analogous impacts on habitat quality on the considered fish species see figs 5 and 6 and ii the hydro power production losses are significant within the associated sub periods see fig 4 from a practical and operational perspective our analysis may suggest within the ifim framework a review of the wpp e flow releases as prescribed by pta 2010 possibly allowing smaller outflows during the aforementioned seasons interestingly the variability associated with different habitat suitability criteria is reasonably comparable with the overall variability between the proposed methodologies the analytic hsdc approach which is based on relatively few and simple hydraulic properties see also appendix can thus constitute a valid alternative to the more complex and data demanding phabsim approach for a fast and rapid identification of potential ecological impacts of different e flow scenarios at the regional scale this alternative approach can be successfully applied across hydrologically and ecologically homogeneous river networks as our case study furthermore to get more reliable results multiple and possibly site specific habitat suitability criteria should be considered in future studies 5 conclusions in this paper we perform a quantitative analysis of the effects of alternative e flow prescriptions at regional scale in particular we focus on hydro power production and fish habitat suitability barbel and chub fish species across chienti and potenza river basins italy referring to the current time invariant regional e flow prescription pilot versus a new time variant regional prescription wpp which will be enforced from jan 1 2020 we employ natural and altered flow duration curves fdcs to estimate both hydro power production and an index of habitat quality i e suitable area index sai the ecological effects are also assessed for the sake of comparison through the classical phabsim approach the following conclusions are worth summarizing an evident reduction of hydro power production shifting from pilot to wpp e flow releases emerges without any significant uncertainty at the annual time scale average relative differences are equal to 15 higher losses 43 on average characterize the july october time interval in addition we find that wpp e flows are frequently greater than the actual surface water availability at various cross sections within the study river networks thus causing a significant enhancement of shut down periods for hydro power plants located in the upstream part of the study area i e fractured carbonate limestones given the prescription of a stricter e flow scenario i e wpp by the regional authority even though a significant hydro power production loss is found a clear outcome does not emerge from the habitat suitability assessment from the ecological perspective regardless of habitat suitability criteria and the methodology employed for assessing habitat conditions increasing e flow releases does not show a clear and consistent improvement of habitat status for barbel and chub in order to get more accurate indications future studies should preferably consider site specific habitat suitability criteria or alternatively may benefit from adopting multiple i e more than one or two criteria associated with rather homogeneous hydro geomorphic environments and then refer the average behavior when comparing nfr and e flow scenarios for juvenile and spawning life stages our results show a general preference for e flows rather than natural streamflow conditions this result was expected since these life stages tend to prefer low flow conditions whereas high or very high flows are indeed scarcely suitable for them outcomes are not as consistent when it comes to adult life stages different sai values emerge due to the interrelation between fdcs and the composite habitat suitability criteria the variability of our results associated with different habitat suitability criteria is comparable with the variability between phabsim and hsdc approaches the hsdc approach proves indeed to be a valuable alternative method for rapidly assessing habitat suitability at the regional scale when data availability both hydrological and ecological is limited and hydrologically and ecologically homogeneous river networks are considered concluding the proposed research is not intended to substitute site specific and detailed studies but rather to provide regional scale guidance towards the identification of effective and sustainable e flow policies for the conservation of fluvial ecosystems when eco hydrological data availability is limited and streamflow observations are entirely missing at the locations of interest acknowledgments the study is part of the research activities carried out by the working group anthropogenic and climatic controls on water availability accuracy of panta rhei everything flows change in hydrology and society iahs scientific decade 2013 2022 appendix a detailed computational steps of hydro power production a1 run of the river hydro power plants concerning the eleven run of the river hydro power plants listed in table 1 the computation of hydro electric production for any given season consists of the following steps i the production duration i e percentage of time of the season in which the turbine is working is first identified by comparing the seasonal fdc black line in fig 2a with a constant streamflow value equal to the sum of the seasonal e flow for the considered scenario and the minimum turbine discharge red dotted line in fig 2a ii the overall water volume that can be diverted and used for hydro power production identified by the gray shaded area in fig 2a is then computed by integrating the usable discharge blue dashed line in fig 2a over the hydro power duration identified at step i iii finally the summation of four seasonal hydro power productions i e usable water volume returns the yearly hydro power production for the considered plant and e flow scenario this procedure is repeated for all run of the river power plants and both e flow scenarios examined in the study a2 storage hydro power plants as mentioned above for the three storage power plants natural inflows are not available therefore synthetic daily streamflow series are generated for these sites by adapting the methodology that was originally presented in hughes and smakhtin 1996 and briefly outlined here a stream gauge is selected that is nearby to the target ungauged i e dammed in our case cross section for this stream gauge the observed daily streamflow series is continuous no missing data and sufficiently long i e at least five years in this study and the corresponding watershed is hydrologically similar to the target site the observed daily streamflow series is converted into a duration series by referring to the empirical period of record fdc constructed from the observed streamflow series itself the duration series is back transformed into a daily streamflow series for the target ungauged site by using the long term fdc predicted for this site through the geostatistical procedure proposed by pugliese et al see 2014 and described in section 3 1 the synthetic daily natural streamflow series is then used as input to a simplified algorithm that simulates the reservoir management through the following steps i at any given day the daily inflow volume is added to the volume stored during the previous time step which is initially set to zero ii the code checks the compliance between the stored volume and the e flow prescriptions of the scenario i e pilot or wpp a if the stored volume is larger than or equal to the daily e flow volume the latter is subtracted to the stored volume and the computation continues to step iii b the entire stored volume is released otherwise and the calculation moves to the next day step i with an empty storage iii the stored volume is compared with the maximum w max and minimum w min daily volumes that can be exploited for hydro power production i e w max is equal to the maximum turbine discharge over a duration of 24 h while w min is equal to the minimum turbine discharge over a 1 h duration a if the stored volume is larger than w max w max is subtracted from the stored volume and the calculation goes to step iv b if the stored volume is between w min and w max all stored volume is used and the computation moves to the next time day i e step i with an empty reservoir c if the stored volume is less than w min the stored volume is held in the reservoir and the calculation moves to step i iv the stored volume which is left from step iii a is compared with the reservoir capacity a if the stored volume is larger than the reservoir capacity the excess volume is released downstream the stored volume is set to the reservoir capacity and the calculation moves to the next day step i b otherwise the stored volume becomes the initial volume and the computation starts from step i the algorithm described above does not aim at faithfully reproducing the real reservoir management and hydraulic behavior but rather at performing a plausible simulation of reservoir operation at daily timescale which maximizes hydro power production while meeting the e flow prescriptions for the considered scenario our simplified numerical code is run for the multi annual daily inflow time series relative to each one of the three considered storage plants and for all e flow scenarios the code returns as outputs the average seasonal and yearly usable water volumes appendix b computational steps for the estimation of the composite habitat suitability following the hsdc approach concerning the hsdc approach the composite habitat suitability is evaluated for the entire river cross section i e without dividing the cross section into computational grid cells through the following steps i an equivalent rectangular cross section with average water depth and flow velocity derived from river geometry data is first defined more specifically for each of the 4 distinct cross sections describing the river reach downstream any barrage or dam we consider the water depth computed from hec ras simulations and we then evaluate i the wetted area ii the average flow velocity as the ratio between discharge and wetted area iii the wetted river width and iv the water depth associated with an equivalent rectangular cross section as the ratio between wetted area and river width ii the relationships between geomorphic features and discharge v q d q are then computed by applying at a station scaling laws developed by leopold et al 1964 for each of the 4 distinct cross sections downstream each barrage or dam the same 16 discharge values mentioned earlier i e sampled from fdcs and associated with a duration ranging from 0 005 to 0 995 are then regressed against the corresponding average flow velocities and water depths log log regression the regression coefficients computed for the 4 cross sections are then averaged to identify at a station coefficients for the river branch downstream each barrage and dam iii for each discharge value gathered from predicted fdcs the composite habitat suitability hs is finally computed as hsc d q hsc v q 
810,anthropogenic activities along streams and rivers may be of major concern for fluvial ecosystems e g abstraction and impoundment of surface water resources may profoundly alter natural streamflow regimes an established approach aimed at preserving the behavior and distribution of fluvial species relies on the definition of ecological flows e flows downstream of dams and diversion structures e flow prescriptions are usually set by basin authorities at regional scale often without a proper assessment of their impact and effectiveness on the contrary we argue that e flows should be identified on the basis of i regional and ii quantitative assessments we focus on central italy and evaluate the effects on habitat suitability of two near threatened fish species i e barbel and chub and an existing hydro power network when shifting from the current time invariant e flow policy to a tighter and seasonally varying soon to be enforced one our example clearly shows that a quantitative regional scale assessments are viable even when streamflow observations are entirely missing at study sites b aprioristic e flows policies may impose releases that exceed natural streamflows for significantly long time intervals weeks or months c unduly tightening e flow policies may heavily impact regional hydro power productivity 15 and 42 losses on annual and seasonal basis respectively yet resulting in either marginal or negligible improvements of fluvial ecosystem keywords water resources management hydro electric production e flow phabsim barbel chub 1 introduction hydro power is the worldwide leading renewable source for electricity production with a capacity increase of more than 30 between 2007 and 2015 wce 2016 despite its economic relevance several environmental concerns are associated with hydro power production indeed hydro power plants are known to severely affect flows downstream of abstraction points over limited time periods person et al 2014 viganó et al 2016 under these conditions the river natural flow regime nfr defined as the river signature in terms of flow magnitude frequency timing duration and rate of change poff et al 1997 is no longer guaranteed nfr is a key driver of ecological and geomorphological processes allan and castillo 2007 bunn and arthington 2002 ceola et al 2014 ceola and pugliese 2014 young et al 2011 and thus any flow disturbance may significantly affect and alter fluvial ecosystem dynamics see e g bradford et al 2011 ceola et al 2013 poff and allan 1995 vanzo et al 2016 as recognized by several water protection policies e g the european water framework directive u 2000 the water laws in act 1998 and china 2002 the australian environment act 1999 ecological flows e flows are commonly defined in order to sustain freshwater ecosystems and the river ecological status the concept of e flows has existed for more than 40 years acreman and dunbar 2004 snelder et al 2014 tharme 2003 and it is widely applied throughout the globe though presenting significant differences across site specific applications e flows can be generally grouped under two main categories based on the methodology they rely upon on one side one may find the classical hydrologically based methods e g minimum flow flow percentiles see tharme 2003 this category embeds easily applicable and simple approaches that can be employed across large areas but do not focus on any ecological variable being thus somehow in contrast with the definition of e flows quite frequently e flows defined within this category are described by constant flows during the year thus disregarding the inter annual flow variability that controls species life stages stromberg et al 2010 on the other side there are the so called micro scale and meso scale physical habitat modeling methods based on in situ and experimental measurements to analyze optimal environmental conditions for target species several habitat suitability models are described in the scientific literature see e g phabsim bovee 1982 rhyhabsim jowett 2010 river2d steffler and blackburn 2002 whyswess yi et al 2010 and casimir munoz mas et al 2012 at the micro scale and mesohabsim parasiewicz 2001 mesocasimir schneider et al 2001 and rhm maddock et al 2001 at the mesoscale among these phabsim and mesohabsim are probably the most widely used and representative ones while mesohabsim refers to specific hydromorphologic units i e hmus bovee et al 1998b parasiewicz 2001 and performs a 2d analysis based on detailed input data phabsim analyzes environmental conditions based on 1d hydraulic variables through the definition of habitat suitability curves within the instream flow incremental methodology ifim bovee et al 1998a framework the ecological variables are key elements of this physical habitat approach which considers specific target species and requires detailed and site specific data in case of limited data availability expert knowledge is a common practice the ifim context allows phabsim to identify improvements in habitat state from different flow regimes thus making predictions and supporting the negotiation of suitable water delivery scenarios booker and dunbar 2004 according to recent e flow prescriptions all flow components from base flow to flood regime are to be included as operational targets for a sustainable water resources management eu 2000 in this respect flow duration curves fdcs a classical hydrological tool that embeds details on streamflow regime which is widely used for flood control water quality management and hydro power purposes represent a meaningful tool for analyzing several ecohydrological issues such as e g the effects of e flow scenarios on riverine habitat vogel and fennessey 1995 the scientific literature collects a plethora of studies investigating the potential impacts of different flow releases downstream of hydro power plants on energy production and riverine ecosystems see e g ayllon et al 2014 hirsch et al 2014 person et al 2014 snelder et al 2014 viganó et al 2016 yi et al 2017 yin et al 2014 though only a few of them has employed fdcs particularly at a regional scale ayllon et al 2012 capra et al 1995 pragana et al 2017 in addition quantitative assessments of e flows impacts are considered to be unviable when the availability of hydrological data is limited i e a frequent condition even for high income countries to overcome this issue fdcs and top kriging are powerful hydrological tools that can be used to reconstruct streamflow regimes at ungauged sites farmer 2016 pugliese et al 2014 thus enabling one to evaluate the hydro power production and ecological status across large catchments and regions see e g cuya et al 2013 popescu et al 2012 in this study we quantitatively analyze the effects of alternative e flow prescriptions on hydro power production and fish habitat suitability for two italian river basins by employing fdcs and top kriging techniques in particular we perform a regional scale analysis by considering two different e flow policies i e current policy and a tighter future one see section 2 4 identified on the basis of empirical methods and set a priori by the local regional authority without any former insight on possible effects on river biota we demonstrate how to cope with a limited availability of streamflow data at locations of interest thus supporting a quantitative assessment of the impacts and the effectiveness of e flows at regional scale our analysis focuses on barbel barbus barbus and chub leuciscus cephalus species which are considered to be near threatened in italy zerunian 2007 and require high protection level at regional scale barbel and chub spawning occurs from april to june and their habitat requirements are well known bicchi et al 2006 rambaldi et al 1997 while it is straightforward to anticipate a decrease in hydro power production for higher e flow releases i e future prescriptions ecological effects on the considered fish species cannot be easily predicted nor were ever assessed for the study area by local authorities in charge of defining e flow policies to this aim we employ different habitat suitability criteria to examine whether a loss or a gain in habitat suitability is associated with a modification in the e flow releases pta 2010 for assessing the ecological effect we employ the classical phabsim approach and we elaborate an analytic approach based on fdcs and on a simpler hydraulic model hereafter labeled as habitat suitability duration curve hsdc which can be easily applied across hydrologically and ecologically homogeneous large catchments and regions and particularly in any ungauged site 2 study area data and e flow scenarios the quantitative assessment of the effectiveness of two alternative e flow scenarios and their impact on hydro power production and fish habitat suitability is applied to hydro power plants located within the potenza and chienti river basins in the marche administrative district in central italy fig 1 and table 1 2 1 river basins description the potenza and chienti river basins with a catchment area of 640 and 1070 km2 respectively flow northeasterly from the apennines to the adriatic sea the elevation ranges between 40 and 1400 m asl above sea level for potenza and 20 and 2000 m asl for chienti in these two catchments agricultural areas 59 forests and semi natural areas 38 share the majority of land covers while human settlements and impervious areas are around 3 eea 2007 two major geological units dominate the study area from a hydro geological perspective the head water catchments are dominated by fractured carbonate limestones with frequently emerging subsurface water see fig 1 while the downstream area mainly presents sandstones and marble calcarenites the study area shows a maritime streamflow regime see castellarin et al 2004a 2004b whose typical hydrologic year is characterized by a maximum monthly discharge during winter and minimum during summer the climate of this area is conditioned by the close presence of both the adriatic sea and the apennines with average annual temperatures ranging from 8 c to 15 c mean annual precipitation map values evaluated at catchment scale are reported in table 2 for the study stream gauges 2 2 hydro power plants in the study area we consider 14 hydro power plants see table 1 operated by the energy multinational power company enel group ltd and located within the potenza and chienti river basins see fig 1 in particular as illustrated in table 1 we consider three storage dam and eleven run of the river ror hydro power plants that share a common feature i e power houses are located downstream the corresponding dams or barrages and off line relative to the river course hence the water used for hydro power production needs to be diverted and is returned to the river only downstream the abstraction point as a consequence the operation of the hydro power plant alters the natural streamflow regime within the river stretch between the abstraction point and the power plant outlet which in several cases is a few kilometers long several characteristics of the study dams barrages and hydro power plants illustrated in table 1 are accessible from enel group ltd technical reports and publications enel 1992 galeati 2013 2013b observed data on the natural streamflow regime nfr instead is sparse or completely missing for barraged and dammed river cross sections considered in our study we therefore estimate the natural streamflow regime at abstraction points by referring to the streamflow data described in section 2 3 and by applying a geostatistical procedure that interpolates empirical flow duration curves of daily streamflow fdcs along the stream network see farmer 2016 pugliese et al 2014 measurements of stream network hydraulic properties i e river width w water depth d flow velocity v and discharge q are available only for a subset 5 out of 14 of the considered hydro power sites see red filled symbols in fig 1 these features are recorded downstream the hydro power plants in correspondence of four distinct cross sections within a nearly 100 m long river reach 2 3 hydrologic data natural daily streamflow series are available for the study region at 17 stream gauges belonging to the former national hydrographic service of italy simn observed flow series span over the time period 1920 2000 with an observation period ranging from 5 to 40 years average record length 18 years table 2 reports drainage area and mean annual precipitation map of catchments upstream each stream gauge as well as some statistics of daily streamflow series mean annual flow maf minimum and maximum flows 75 50 and 25 exceeded flow values empirical map values relative to each of the 17 catchments are estimated using data collected from a rather dense rain gauge network i e 1 rain gauge per 50km2 on average during the same time interval of daily streamflow records our daily streamflow dataset includes only complete years missing daily streamflow records have been linearly interpolated for time intervals shorter than one week while for longer time intervals of missing observations we have discarded the entire year see castellarin et al 2004a 2 4 regional river regulation e flow prescriptions two alternative e flow scenarios prescribed by the marche administrative district are considered in our study the current time invariant experimental e flow release and the soon to be enforced time variant e flow release based on water protection plan prescriptions pta 2010 hereafter labeled as pilot and wpp respectively pilot e flows will be authorized until dec 31 2019 while from jan 1 2020 the regional authority is going to enforce wpp e flows the pilot e flow release results from an experimental program agreed among the regional administration and enel group ltd which allowed a reduced e flow release compared to wpp this scenario refers to the most common practice in reservoir management namely to consider a constant e flow value across the whole year regardless of the natural intra annual flow variability activities aimed at monitoring the environmental effect of e flows downstream of dams and barrages are still undergoing and at this stage data are not currently available the wpp e flow release by recalling the eu water framework directive u 2000 includes a temporal regulation of e flows thus reproducing natural streamflow regimes of river reaches downstream the abstraction points which supposedly enhances ecosystem conservation wpp e flow releases qwpp m3 s are computed from the following empirical expression 1 q w p p k m a f b e max n i f g t where k is an empirical parameter ranging from 0 05 to 0 1 maf m3 s is the mean annual flow b is a parameter that takes into account the hydrogeologic features of the study area b 2 in upstream river reaches mainly consisting of fractured carbonate limestones b 1 in downstream areas presenting sandstones and marble calcarenites see section 2 1 and fig 1 e represents the river ecological status ranging from 1 to 1 4 for very good or very poor conditions respectively n represents the degree of wilderness of the area around the river reach ranging from 1 3 for protected areas i e natural parks to 1 for urban and rural areas i f represents the river functionality ranging from 1 to 1 2 for very good to very poor river functionality respectively g is geomorphologic parameter related to hydraulic and morphological characteristics of the river reach ranging from 0 9 to 1 1 t is the temporal factor identifying different flow seasons in a year in this context the term season refers to one of the four time intervals identified in the water protection plan of the marche administrative district namely november january total duration 92 days t 1 3 february march total duration 59 days t 1 5 april june total duration 91 days t 1 3 july october total duration 123 days t 1 0 table 3 reports pilot and wpp e flow releases for the 5 hydro power sites see red filled symbols in fig 1 for which both hydro power production and habitat suitability are assessed 2 5 fish species for habitat suitability assessment the study fish species barbel barbus barbus and chub leuciscus cephalus belong to the cyprinidae family and are typical in the study area three different life stages are examined namely juvenile spawning and adult given that the spawning season for both species is between april and june we consider juvenile fish as those small fish hatched from eggs spawned in the same year whereas the adult stage represents individuals older than 1 year by using the wpp e flow seasonality described in section 2 4 we associate each life stage with a specific e flow season as follows juvenile is associated with july october spawning with april june and adult with the whole year from january to december 3 methods 3 1 estimation of natural flow regime at hydro power sites in order to reconstruct the unknown natural inflows to the considered hydro power sites we employ observed streamflow data and apply a geostatistical technique the procedure which was originally proposed and applied by pugliese et al 2014 to the same study region adapts the topological kriging or top kriging see skøien et al 2006 a block kriging with variable support area coinciding with the catchment watershed see skoien et al 2014 and enables the user to predict fdcs in ungauged basins by linearly weighting empirical curves constructed at available stream gauges kriging weights used in the linear weighting scheme take catchment size and nesting structure of the stream network into account using the top kriging adaptation by pugliese et al 2014 we predict long term fdcs of daily streamflows at all 14 abstraction points of interest by interpolating empirical period of record i e constructed on the basis of all available daily streamflow observations fdcs according to the regional river regulation illustrated in section 2 4 minimum streamflow requirements have to be identified on a seasonal basis the term season in this context coincides with one of the four time intervals specified in the regional regulation therefore together with the long term annual fdcs that describe the natural streamflow regime we also predict the long term seasonal fdcs for the four periods of interest as defined in the water protection plan of our study area pta 2010 the prediction of seasonal fdcs represents a novel application of the procedure developed by pugliese et al 2014 the validation is based on the same leave one out cross validation scheme used in pugliese et al 2014 for assessing the accuracy of predicted long term yearly fdcs the results prove the suitability of the selected approach since the accuracy of predicted seasonal fdcs results to be comparable with the accuracy of predicted yearly curves and certainly acceptable for the scopes of the present analysis i e overall nash sutcliffe efficiency computed for predicted log flows in cross validation varies between 0 91 and 0 94 and is equal to 0 96 for yearly curves see also pugliese et al 2014 3 2 computation of hydro power production the present section summarizes the different steps required by the computation of annual and seasonal hydro power productions distinguishing between run of the river and storage power plants see table 1 it is worth emphasizing here that our study neglects the interaction between power plants located along the same stream i e we do not consider the possible effects of streamflow regulation upstream the considered power plant that is we always adopt the nfr as inflow condition this simplifying working hypothesis is correct when only run of the river power plants exist upstream any given river dam barrage but is certainly associated with an approximation when artificial reservoirs with significant storage capacity exist upstream the location of interest nevertheless the hypothesis seems viable in our study given the limited number of hydro power plants located downstream the study dams see fig 1 concerning the eleven run of the river hydro power plants listed in table 1 the assessment of hydro power production under various constraints on e flow release is straightforward when annual and seasonal fdcs relative to the nfr are available for the barraged river cross sections see e g vogel and fennessey 1995 therefore seasonal fdcs of daily streamflow are predicted at all hydro power plants via top kriging see section 3 1 fig 2a provides a graphical example for montefranco hydro power plant see table 1 which clearly shows that for roughly 10 of the season duration the e flow value is higher than natural streamflows concerning the three storage power plants see table 1 since they can store and manage inflow water volumes the assessment of their hydro electric productivity cannot be based solely on fdcs representative of the nfr but it requires continuous and possibly multi annual daily streamflow series and a conceptualization of reservoir management and functioning fig 2b c illustrates reconstructed inflows together with outflows relative to an arbitrarily selected year at polverina dam see table 1 in particular the figure reports the reconstructed daily inflows blue line and the seasonally variable e flow releases red line wpp scenario which are used as inputs and the daily series of simulated outflows downstream the reservoir black line the computation of yearly and seasonal hydro power production for e flow scenarios pilot and wpp for run of the river and storage power plants relies also on i hydro power plant characteristics e g minimum and maximum exploitable discharge see table 1 and ii seasonal e flow values for the considered scenario i e pilot and wpp a detailed description of the computational steps for the evaluation of hydro power production for any given site and season is reported in the appendix 3 3 habitat suitability assessment the potential impact of pilot and wpp e flow scenarios on barbel barbus barbus and chub leuciscus cephalus suitability to the physical habitat within the considered river basins is assessed by coupling the outflows from the hydro power sites with habitat suitability criteria hsc hsc describe species habitat preferences ranging from 0 unsuitable to 1 most suitable by accounting for the effects of hydro morphological variables i e water depth hscd flow velocity hscv and river substrate hscs on species distribution given that habitat suitability of target species changes during a lifetime hsc are generally defined and associated with different life stages see section 2 5 the formulation of hsc should be generally based on field investigations providing detailed ecological information of the target species from the study area however due to the difficulty of collecting sufficient data on species habitat these data are not always available as in the present study when local information are missing expert knowledge is a significant basis and multiple hsc showing similar hydrological morphological and ecological properties to those characterizing the study area should be considered in order to test for consistency and account for the effects of different formulations here we consider two alternative hsc provided by bicchi et al 2006 and rambaldi et al 1997 both referring to the central apennines in italy and therefore suitable for our study area see figure s1 habitat suitability values are then combined together by computing a composite habitat suitability hs as the product of hscd hscv hscs it is worth highlighting here that since the formulation proposed by bicchi et al 2006 neglects the effect of river substrate i e by assuming a constant maximum preference regardless the substrate characteristics hscs 1 for consistency we implement the same condition in the hsc from rambaldi et al 1997 we employ two different methodologies to quantify a synthetic indicator of the habitat quality i e suitable area index sai m2 mathrmm associated with the different release scenarios illustrated in section 2 4 i the classical phabsim procedure and ii an analytic method based on fdcs hereafter labeled habitat suitability duration curve hsdc the habitat quality indicator sai is then estimated for each hydro power site i e a total of 5 sites see red filled symbols in fig 1 each fish species i e 2 species barbel and chub each life stage i e 3 life stages juvenile spawning adult each hsc 2 i e bicchi et al 2006 rambaldi et al 1997 and each flow regime 3 i e nfr pilot wpp due to the limited hydro ecologic data availability we adopt phabsim although more recent alternatives see e g phabsim rhyhabsim river2d whyswess casimir mesohabsim mesocasimir rhm are consolidated across the scientific literature furthermore when analyzing e flows at the micro habitat level within an ifim context bovee et al 1998a different flow scenarios and habitat suitability models are to be considered in order to assess the ecological effects and then negotiate e flows to be prescribed in our case study given that e flow scenarios prescribed by the regional authority were determined a priori without performing any assessment of the effects on river biota a sort of backward application of ifim is performed i e from prescribed e flows the current and the soon to be enforced to ecological and hydro power production effects 3 3 1 estimation of suitability area index from phabsim and hsdc phabsim divides river cross sections into several vertical elements or grid cells each one characterized by given flow velocity and water depth for a given streamflow value more specifically flow velocity and water depth are derived from 4 distinct cross sections within a nearly 100 m long river reach in correspondence of each hydro power site given that phabsim hydraulic modeling can be sometimes controversial dunbar et al 1998 ghanem et al 1996 shirvell 1986 we calibrated the hydraulic model on the basis of concurrent observations of discharge and water level through hec ras simulations brunner 2016 which we then use as inputs to phabsim see e g nikghalb et al 2016 the composite habitat suitability is computed for every grid cell and the weighted usable area wua i e the available habitat area for the target species within a river reach m2 m is then evaluated as a weighted sum of composite suitability and cell area for each flow scenario nfr pilot and wpp we estimate wua values for a given set of discharges i e streamflow values sampled from fdcs and associated with 16 durations within the range 0 005 0 995 and then combine these wua values to quantify sai as the integral of the wua duration curve 2 s a i d 0 d 1 w u a d d d where wua d is the weighted usable area associated with a duration d ranging from 0 to 1 concerning the hsdc approach the composite habitat suitability hs is based on fdcs and on a simpler hydraulic procedure and it is evaluated for the entire river cross section i e without dividing the cross section into computational grid cells by following the procedure proposed by vogel and fennessey 1995 we combine the relation between hs and discharge fig 3b with the predicted fdc fig 3a and define the hsdc as the relationship between the composite habitat suitability and the duration or exceedence probability of the discharge value associated with that hs fig 3c we then compute the habitat suitability index hsi as the integral of the habitat suitability duration curve shaded areas in fig 3c 3 h s i d 0 d 1 h s d c d d d where d represents the duration associated with each composite habitat suitability value finally the suitable area index sai is defined by simply multiplying hsi and the wetted river width w from the equivalent rectangular cross section a detailed description of the 3 step procedure for the computation of hs as a function of discharge values is reported in the appendix 4 results 4 1 computation of hydro power production fig 4shows through a box plot representation the distribution of relative differences of hydro power production for the set of 14 plants belonging to potenza and chienti river basins i e run of the river and storage power plants for each reference period i e the entire year and four sub periods namely nov jan feb mar apr jun and jul oct each value is computed as the difference between the hydro power production associated with pilot i e current e flow releases and with releases that are compliant with the regional water protection plan wpp e flow releases soon to be enforced divided by the former all computations of hydro power production refer to daily inflow series storage hydro power plants or period of record yearly or seasonal fdcs run of the river hydro power plants reconstructed for a multiannual time span roughly extending between 1920 and 2000 hence the resulting hydro power production should be regarded as a long term prediction of the hydro power potential for any given study plant each prediction is necessarily associated with some degree of uncertainty resulting from all simplifying assumptions adopted in our study it is worth noting though that we are mainly interested in comparing different estimates of long term hydro power productivity rather than assessing their absolute values which mitigates the impact of simplifying assumptions one striking feature of fig 4 is that values are all positive meaning that the enforcement of wpp releases will result in losses of hydro power production this result was expected as the current prescriptions on e flows are less stringent than wpp ones see table 3 another feature of fig 4 is the dependence of the reduction of hydro power production on the considered time period average relative differences in are equal to 14 7 13 7 5 8 10 2 and 42 8 for year nov jan feb mar apr jun and jul oct reference time intervals in this order production losses are significant or extremely significant over the study area more than 50 of the plants show a production loss larger than 10 on an annual scale or during the time period between november and january which is one of the two wet seasons for the study catchments the other spanning between march and early june losses become extremely important between july and october with 50 of the plants showing losses larger than 44 and in excess of 58 in 25 of the cases this result is associated with wpp e flow prescriptions during the summer season i e between july and october which are particularly severe during several weeks of the simulation time interval 1920 2000 wpp e flows resulted to be larger than natural streamflows for the majority of study catchments in particular relative to pilot e flow releases and on the basis of the computations performed in our study the enforcement of wpp releases is likely to increase the duration of plant shutdown periods by 61 and 132 days per year on average for the potenza and chienti hydro power plants respectively i e c a two and four months respectively which is an extremely significant amount of time the marked variability of production losses between different hydro power plants e g between 7 and 29 or 20 and 82 for year and jul oct respectively results from the extremely high variability of a few empirical parameters used by the expression adopted in the regional wpp for computing the e flow a noteworthy example is the parameter b which is normally equal to 1 and is set to 2 for all basins that are entirely within with a specific geological unit that mainly consists of fractured carbonate limestones see section 2 1 4 2 habitat suitability assessment suitable area index sai values computed for the 5 hydro power sites are shown in figs 5 and 6 for barbus barbus and leuciscus cephalus respectively in order to examine the regionalized i e average behavior of the study area characterized by comparable hydro geomorphic properties we opted for grouping together the considered river cross sections the outcomes are presented in terms of mean standard deviation for the 2 alternative methodologies namely phabsim and hsdc and the 2 habitat suitability criteria bicchi et al 2006 rambaldi et al 1997 as expected regionalized sai values computed from the hsdc method are generally characterized by a higher variability compared to the phabsim ones indeed while the application of phabsim generally results in at least some a few elementary cells of each river cross section presenting suitable conditions for fish the hsdc approach which assumes an equivalent rectangular cross section under uniform flow conditions may bring forth either totally unsuitable or suitable states thus showing a larger sai range the application of the habitat suitability criteria proposed by bicchi et al 2006 shows a fairly good agreement between sai values from phabsim and hsdc for both fish species figs 5a b c and 6 a b c for the adult life stage figs 5c and 6 c phabsim and hsdc methodologies consistently reveal a preference for the wpp e flow scenario whereas both pilot and wpp e flow scenarios present similar outcomes for juvenile figs 5a and 6 a and spawning figs 5b and 6 b life stages the nfr always presents the lowest sai values compared to pilot and wpp e flow scenarios this result is likely to be associated with the large range of discharge values i e from 10 1 m 3 s to 103m3 s whose extreme conditions i e floods and low flows are mostly unsuitable for fish indeed habitat suitability is usually assessed for low flows thus entirely disregarding high or very high flow conditions booker and dunbar 2004 furthermore the hsdc approach reveals that juvenile figs 5a and 6 a and spawning figs 5b and 6 b life stages which prefer low water depths and flow velocities and thus lower discharges may experience particularly small and even negligible sai values under nfr this condition intimately depends on the discharge values associated with the composite habitat suitability which may lie outside the discharge range gathered from the fdc see fig 3 more specifically when applying hsdc under nfr negligible or even null composite suitability values can be associated with the majority of discharge values sampled from the fdc as a consequence sai values may result in extremely low or even null figures concerning the application of the habitat suitability criteria proposed by rambaldi et al 1997 a satisfactory match between phabsim and hsdc approaches on sai values associated with the different flow regimes is evident only for the adult life stage of both fish species figs 5f and 6 f in this case adult fish reveal an overall preference for nfr conditions with the lowest values for the pilot e flow scenario conversely juvenile figs 5d and 6 d and spawning figs 5e and 6 e life stages show rather contradictory outcomes with divergent sai values evidently the linkage among fdcs and the relationship between hs and discharge plays a key role our analysis reveals that the two habitat suitability criteria employed in this study both referring to apennines rivers with comparable hydrologic regime and water resource availability despite some differences in terms of absolute quantities show a rather consistent trend when comparing the three flow regimes i e nfr pilot and wpp either with the phabsim or the hsdc methodology in particular given that i for juvenile and spawning life stages the two e flow releases present analogous impacts on habitat quality on the considered fish species see figs 5 and 6 and ii the hydro power production losses are significant within the associated sub periods see fig 4 from a practical and operational perspective our analysis may suggest within the ifim framework a review of the wpp e flow releases as prescribed by pta 2010 possibly allowing smaller outflows during the aforementioned seasons interestingly the variability associated with different habitat suitability criteria is reasonably comparable with the overall variability between the proposed methodologies the analytic hsdc approach which is based on relatively few and simple hydraulic properties see also appendix can thus constitute a valid alternative to the more complex and data demanding phabsim approach for a fast and rapid identification of potential ecological impacts of different e flow scenarios at the regional scale this alternative approach can be successfully applied across hydrologically and ecologically homogeneous river networks as our case study furthermore to get more reliable results multiple and possibly site specific habitat suitability criteria should be considered in future studies 5 conclusions in this paper we perform a quantitative analysis of the effects of alternative e flow prescriptions at regional scale in particular we focus on hydro power production and fish habitat suitability barbel and chub fish species across chienti and potenza river basins italy referring to the current time invariant regional e flow prescription pilot versus a new time variant regional prescription wpp which will be enforced from jan 1 2020 we employ natural and altered flow duration curves fdcs to estimate both hydro power production and an index of habitat quality i e suitable area index sai the ecological effects are also assessed for the sake of comparison through the classical phabsim approach the following conclusions are worth summarizing an evident reduction of hydro power production shifting from pilot to wpp e flow releases emerges without any significant uncertainty at the annual time scale average relative differences are equal to 15 higher losses 43 on average characterize the july october time interval in addition we find that wpp e flows are frequently greater than the actual surface water availability at various cross sections within the study river networks thus causing a significant enhancement of shut down periods for hydro power plants located in the upstream part of the study area i e fractured carbonate limestones given the prescription of a stricter e flow scenario i e wpp by the regional authority even though a significant hydro power production loss is found a clear outcome does not emerge from the habitat suitability assessment from the ecological perspective regardless of habitat suitability criteria and the methodology employed for assessing habitat conditions increasing e flow releases does not show a clear and consistent improvement of habitat status for barbel and chub in order to get more accurate indications future studies should preferably consider site specific habitat suitability criteria or alternatively may benefit from adopting multiple i e more than one or two criteria associated with rather homogeneous hydro geomorphic environments and then refer the average behavior when comparing nfr and e flow scenarios for juvenile and spawning life stages our results show a general preference for e flows rather than natural streamflow conditions this result was expected since these life stages tend to prefer low flow conditions whereas high or very high flows are indeed scarcely suitable for them outcomes are not as consistent when it comes to adult life stages different sai values emerge due to the interrelation between fdcs and the composite habitat suitability criteria the variability of our results associated with different habitat suitability criteria is comparable with the variability between phabsim and hsdc approaches the hsdc approach proves indeed to be a valuable alternative method for rapidly assessing habitat suitability at the regional scale when data availability both hydrological and ecological is limited and hydrologically and ecologically homogeneous river networks are considered concluding the proposed research is not intended to substitute site specific and detailed studies but rather to provide regional scale guidance towards the identification of effective and sustainable e flow policies for the conservation of fluvial ecosystems when eco hydrological data availability is limited and streamflow observations are entirely missing at the locations of interest acknowledgments the study is part of the research activities carried out by the working group anthropogenic and climatic controls on water availability accuracy of panta rhei everything flows change in hydrology and society iahs scientific decade 2013 2022 appendix a detailed computational steps of hydro power production a1 run of the river hydro power plants concerning the eleven run of the river hydro power plants listed in table 1 the computation of hydro electric production for any given season consists of the following steps i the production duration i e percentage of time of the season in which the turbine is working is first identified by comparing the seasonal fdc black line in fig 2a with a constant streamflow value equal to the sum of the seasonal e flow for the considered scenario and the minimum turbine discharge red dotted line in fig 2a ii the overall water volume that can be diverted and used for hydro power production identified by the gray shaded area in fig 2a is then computed by integrating the usable discharge blue dashed line in fig 2a over the hydro power duration identified at step i iii finally the summation of four seasonal hydro power productions i e usable water volume returns the yearly hydro power production for the considered plant and e flow scenario this procedure is repeated for all run of the river power plants and both e flow scenarios examined in the study a2 storage hydro power plants as mentioned above for the three storage power plants natural inflows are not available therefore synthetic daily streamflow series are generated for these sites by adapting the methodology that was originally presented in hughes and smakhtin 1996 and briefly outlined here a stream gauge is selected that is nearby to the target ungauged i e dammed in our case cross section for this stream gauge the observed daily streamflow series is continuous no missing data and sufficiently long i e at least five years in this study and the corresponding watershed is hydrologically similar to the target site the observed daily streamflow series is converted into a duration series by referring to the empirical period of record fdc constructed from the observed streamflow series itself the duration series is back transformed into a daily streamflow series for the target ungauged site by using the long term fdc predicted for this site through the geostatistical procedure proposed by pugliese et al see 2014 and described in section 3 1 the synthetic daily natural streamflow series is then used as input to a simplified algorithm that simulates the reservoir management through the following steps i at any given day the daily inflow volume is added to the volume stored during the previous time step which is initially set to zero ii the code checks the compliance between the stored volume and the e flow prescriptions of the scenario i e pilot or wpp a if the stored volume is larger than or equal to the daily e flow volume the latter is subtracted to the stored volume and the computation continues to step iii b the entire stored volume is released otherwise and the calculation moves to the next day step i with an empty storage iii the stored volume is compared with the maximum w max and minimum w min daily volumes that can be exploited for hydro power production i e w max is equal to the maximum turbine discharge over a duration of 24 h while w min is equal to the minimum turbine discharge over a 1 h duration a if the stored volume is larger than w max w max is subtracted from the stored volume and the calculation goes to step iv b if the stored volume is between w min and w max all stored volume is used and the computation moves to the next time day i e step i with an empty reservoir c if the stored volume is less than w min the stored volume is held in the reservoir and the calculation moves to step i iv the stored volume which is left from step iii a is compared with the reservoir capacity a if the stored volume is larger than the reservoir capacity the excess volume is released downstream the stored volume is set to the reservoir capacity and the calculation moves to the next day step i b otherwise the stored volume becomes the initial volume and the computation starts from step i the algorithm described above does not aim at faithfully reproducing the real reservoir management and hydraulic behavior but rather at performing a plausible simulation of reservoir operation at daily timescale which maximizes hydro power production while meeting the e flow prescriptions for the considered scenario our simplified numerical code is run for the multi annual daily inflow time series relative to each one of the three considered storage plants and for all e flow scenarios the code returns as outputs the average seasonal and yearly usable water volumes appendix b computational steps for the estimation of the composite habitat suitability following the hsdc approach concerning the hsdc approach the composite habitat suitability is evaluated for the entire river cross section i e without dividing the cross section into computational grid cells through the following steps i an equivalent rectangular cross section with average water depth and flow velocity derived from river geometry data is first defined more specifically for each of the 4 distinct cross sections describing the river reach downstream any barrage or dam we consider the water depth computed from hec ras simulations and we then evaluate i the wetted area ii the average flow velocity as the ratio between discharge and wetted area iii the wetted river width and iv the water depth associated with an equivalent rectangular cross section as the ratio between wetted area and river width ii the relationships between geomorphic features and discharge v q d q are then computed by applying at a station scaling laws developed by leopold et al 1964 for each of the 4 distinct cross sections downstream each barrage or dam the same 16 discharge values mentioned earlier i e sampled from fdcs and associated with a duration ranging from 0 005 to 0 995 are then regressed against the corresponding average flow velocities and water depths log log regression the regression coefficients computed for the 4 cross sections are then averaged to identify at a station coefficients for the river branch downstream each barrage and dam iii for each discharge value gathered from predicted fdcs the composite habitat suitability hs is finally computed as hsc d q hsc v q 
811,every model to characterise a real world process is affected by uncertainty selecting a suitable model is a vital aspect of engineering planning and design observation or input errors make the prediction of modelled responses more uncertain by way of a recently developed attribution metric this study is aimed at developing a method for analysing variability in model inputs together with model structure variability to quantify their relative contributions in typical hydrological modelling applications the quantile flow deviation qfd metric is used to assess these alternate sources of uncertainty the australian water availability project awap precipitation data for four different australian catchments is used to analyse the impact of spatial rainfall variability on simulated streamflow variability via the qfd the qfd metric attributes the variability in flow ensembles to uncertainty associated with the selection of a model structure and input time series for the case study catchments the relative contribution of input uncertainty due to rainfall is higher than that due to potential evapotranspiration and overall input uncertainty is significant compared to model structure and parameter uncertainty overall this study investigates the propagation of input uncertainty in a daily streamflow modelling scenario and demonstrates how input errors manifest across different streamflow magnitudes keywords input uncertainty quantile flow deviation qfd multi site rainfall model structure 1 introduction every model that characterises a real world process will be subject to uncertainty uncertainty affects the specification and use of hydrologic systems in a range of management planning or design applications quantification of uncertainty in hydrology is the first step to control and eventually to improve the specification of a hydrological model however estimation of uncertainty has been the subject of considerable debate in the hydrological literature beven 2016 carpenter and georgakakos 2004 gong et al 2013 jin et al 2010 montanari and grossi 2008 nearing and gupta 2015 although many uncertainty analysis frameworks have been introduced in the hydrological domain implementing these in an integrated manner remains a challenge for hydrologic modelling exercises liu and gupta 2007 modelling uncertainty is a result of several factors that are frequently interdependent and difficult to explicitly identify attempts to separate the error associated with rainfall inputs for example are complicated by the strong interaction they have with model structural error leading to at times large changes to calibrated parameters and resulting outputs huard and mailhot 2006 kuczera et al 2006 mcmillan et al 2011 renard et al 2010 villarini and krajewski 2008 vrugt et al 2008 as rainfall data is a crucial component in many engineering hydrology applications the existence of input errors in rainfall runoff modelling causes a variety of problems in runoff prediction bárdossy and das 2008 dawdy and bergmann 1969 del giudice et al 2016 georgakakos et al 2004 kavetski et al 2006 a very common source of error in rainfall measurement is due to the spatial variability of precipitation and the lack of a sufficient density of gauges to capture that variability with precision faurès et al 1995 mandapaka et al 2009 singh 1997 even if measurements from a single gauge may be assumed to be representative of overall catchment rainfall in an expected value sense other statistical properties of point rainfall will differ considerably from the corresponding properties of average catchment rainfall the result can be serious errors in runoff prediction and large biases in parameter estimates obtained by calibration of the model arnaud et al 2002 chowdhury and sharma 2007 similarly potential evapotranspiration is an important hydrologic process globally as well as a key component of a catchment s water balance and necessary to represent the model runoff generation processes correctly eagleson 1978 the variability of potential evapotranspiration as an input to hydrologic models has also been identified as requiring further investigation oudin et al 2005 oudin et al 2006 to that end several approaches for quantifying observational and or structural uncertainties in hydrologic predictions exist renard et al 2010 including the i the bayesian total error analysis batea framework kavetski et al 2006 kuczera et al 2006 ii the generalized likelihood uncertainty estimation glue beven and binley 1992 iii standard bayesian approaches and bayesian hierarchical models huard and mailhot 2006 kavetski et al 2006 kuczera et al 2006 marshall et al 2004 2006 iv frequentist approaches montanari and brath 2004 v the integrated bayesian uncertainty estimator ibune ajami et al 2007 and others while there exists a clear realisation that uncertainty is a significant part of hydrological modelling with a magnitude that grows as one proceeds to the use of more complex models in data poor or ungauged situations the issue of attributing uncertainty in outputs to alternate causative sources remains unaddressed a potential solution to this is the use of diagnostic tools that evaluate the variability in hydrologic ensembles produced in typical uncertainty analysis exercises shoaib et al 2016 the primary motivation for the current work is then to evaluate the relative contribution of uncertainty due to model input variability in a typical conceptual hydrologic modelling application that assumes a lumped input due to significant spatial and temporal variability in rainfall fields the rainfall forcing error has the potential to dominate in the uncertainty spectrum of a typical modelling application arnaud et al 2002 singh 1997 most importantly these errors can be significant in many of the catchments that represent the hydrological landscape of a country mcmillan et al 2011 villarini and krajewski 2008 similar phenomena could be observed with the variability of potential evapotranspiration the objective of this paper is therefore to evaluate the relative contribution of potential input uncertainty compared to that associated with the model structure and parameter uncertainty in a typical modelling exercise gridded rainfall and evapotranspiration observations are used to represent the potential spectrum of input variability that might arise in a modelling study using point gauge data we make use of a recently developed metric the quantile flow deviation qfd shoaib et al 2016 to understand the role of alternate model factors that lead to uncertainty in the modelled output woldemeskel et al 2012 2016 focusing on the impact of uncertain rainfall and potential evapotranspiration the metric is calculated by conditioning the estimated variance in streamflow ensembles on one or more model characteristics and as such is able to decompose the variability in model outputs and attribute it to various sources overall this study aims to investigate the following questions how does input uncertainty magnitude affect in the simulated streamflow considering the likely spatial variability of rainfall and potential evapotranspiration within a catchment how does input uncertainty change with a growing number of rain gauges to the more typical case of an individual gauge being used how does input uncertainty diverge between different catchments of varying hydrologic attributes and finally how can one allow for separation of seasonal uncertainty with input uncertainty in an engineering design and planning process this paper is organized as follows after the introduction section 2 describes the data used for the study and catchment properties the next section conceptualizes the method to quantify input uncertainty via the quantile flow deviation the following section presents the outcomes of the simulations and evaluation of the proposed scheme section 5 elaborates on input uncertainty structural identifiability model structure and likelihood with the analysis of the results the final section identifies some important caveats and opportunities for further research 2 data and study area the daily rainfall and potential evapotranspiration data set used in this study is derived from the australian water availability project awap jones et al 2009 khan et al 2015 the dataset is gridded to 0 05 0 05 5 km 5 km for the period 1980 2005 the accuracy of this data set is typically low where gauge density is low as is the case in central west australia for instance jones et al 2009 the original meteorological data used in the awap product were supplied by the bureau of meteorology australia bom the awap platform uses model data fusion methods to combine both measurements and water balance modelling of rainfall and evapotranspiration processes to produce gridded data in the model experiments implemented here we use these rainfall and evapotranspiration fields to represent the natural variability in these processes and the potential error that arises when a single point observation is used in a modelling exercise daily rainfall data is available from 1900 to present temperatures from 1911 to present and solar irradiance from 1990 to present gridded rainfall and potential evapotranspiration data used in this study are available in the following links i for rainfall http www bom gov au web03 ncc www awap rainfall totals daily grid 0 05 history nat startdate enddate grid z ii for potential evapotranspiration ftp ftp eoc csiro au pub awap australia historical run26j fwpt in this study we have selected four different catchments considering the bioregions and climate zones of australia the physical and climatic properties of the selected catchments are diverse to investigate how input uncertainty manifests across distinct hydroclimatic case studies table 1 areas of the catchments vary from 600 km2 to 850 km2 while annual precipitation varies from 890 mm to 1250 mm though the richmond catchment shows the highest annual precipitation among the four catchments the seventeen mile catchment of northern territory shows a higher magnitude of potential evapotranspiration similarly runoff magnitude varies considerably amongst the selected catchments from 84 mm year to 364 mm year table 1 shows the overall catchment features for these catchments articulating the marked differences in important catchment characteristics streamflow q data for the selected catchments is taken from bureau of meteorology australia bom this study investigates the impact of input uncertainty on hydrologic model simulations for these four selected catchments as a function of the spatial variability associated with the observed rainfall and potential evapotranspiration fig 1 a shows the average annual rainfall and fig 1b shows the average potential evapotranspiration for the four catchments on a grid cell basis each grid box represents an approximate square area of 25 km2 0 05 by 0 05 among the four selected catchments the richmond catchment shows the highest spatial variability in rainfall and the seventeen mile catchment shows the lowest spatial variability in rainfall considering the scales for the catchments are different similar patterns of potential evapotranspiration variability are visible among the selected catchments fig 1b 3 methodology a general framework is developed to evaluate the potential impact of uncertain observations on model simulations the approach consists of a factorial modelling experiment that generates multiple model simulations resulting from different model choices then a novel statistical metric is calculated that disaggregates the variability in these simulations to its sources as such variability in model outputs is attributed to different sources of uncertainty here we summarise the general methodology and the sequence of steps used to evaluate our methodology on the case studies 3 1 evaluating uncertainty and the impact of modelling decisions one way in which to evaluate the potential impact of modelling decisions is via the analysis of model ensembles that result from the model uncertainty here we implement a factorial modelling experiment aimed at simulating multiple streamflow time series arising from different modelling choices or decisions we select a single input data series for the study catchment select a single lumped model structure from a suite of available models and generate a single parameter set to simulate the model output this process is repeated to generate ensembles of model simulations we then aim to attribute the variability in the model simulations to these choices considering this a conceptual layout is presented in fig 2 in the first panel each grid cell represents a time series of rainfall observations which may be derived from a gridded rainfall product or a network of rain gauges one or more of these pseudo observation time series are selected and used as an input to a hydrologic model this selected time series represents the potential uncertainty or error that arises when a single point observation is used as an input to a hydrologic model following we select one of a suite of multiple hydrological models that represent structural uncertainty about the processes occurring in the catchment system we optimise the model using best available rainfall data resulting in a set of parameter values by repeating the selection of an input time series a model structure and a parameter set multiple times the results are ensembles of outputs representing uncertainty in the model outputs as a function of the a priori modeller choices then the qfd metric can be applied to evaluate the relative importance of these different model choices similar procedures are followed for considering the variability in potential evapotranspiration to quantify the input uncertainty specific to this study the following steps summarize the experimental methodology that was implemented to evaluate input uncertainty in our study catchments step 1 process input variability rainfall and potential evapotranspiration each catchment is represented with the available awap data by a number of grids according to their catchment area for each model simulation a single grid cell time series rainfall and potential evapotranspiration is randomly selected for the selected case study catchment assuming each grid cell data set is equally likely by selecting an entire time series from a single grid cell and not resampling grid cells within a whole time series the rainfall evapotranspiration temporal characteristics are preserved with each experiment we consider the impact of rainfall uncertainty and potential evapotranspiration uncertainty separately the total number of input ensembles for each catchment can be selected to be the same as the number of awap grids within each catchment boundary note that our analysis considers the impact of selecting a single grid for instance as a surrogate for a single site rain gauge or potential evapotranspiration as well as how uncertainty might change with the availability of a larger gauge density when evaluating the effect of multiple observation sites we simply average the selected rainfall or potential evapotranspiration grid cells to estimate a single lumped input to the model structure therefore inputs also represented averages of multiple randomly selected awap grids for experimental investigations to keep consistency in our analysis we resample gauges 25 times for each selected catchment for example the analysis considered the uncertainty for multiple combinations of two gauges three four gauges five ten gauges etc to adequately illustrate the variability in the rain gauge location as well as potential evapotranspiration measurement location considering the area of the catchment the total number of awap grids varies for each catchment the length of the input rainfall and potential evapotranspiration data is 5 years for each selected catchment step 2 selection of model structure possible model structures could be selected based on knowledge of the catchments underlying processes and reflecting potential structural uncertainty due to incomplete knowledge a range of model structures is selected a priori to reflect the variability in the mathematical description of the hydrologic system four parent model configurations within the framework for understanding structural errors fuse clark et al 2008 are used to represent model structural variability models in fuse are constructed by combining alternate architecture and flux parameterizations we have selected the four parent hydrological models topmodel arnoxvic prms sacramento within the fuse framework to represent a spectrum of the potential model uncertainty more details about the models used are presented in subsequent sections step 3 identifiability characterisation of model structure parameter spectrum in this step we consider multiple possible parameter solutions that may exist due to equifinality or poor identifiability of the model these may be obtained via multiple global optimization runs shin et al 2015 or could be determined from a likelihood based analysis such as glue or bayesian inference each model is thus calibrated using the dynamically dimensioned search dds algorithm tolson and shoemaker 2007 in this study we conducted five dds trials for each model to select the optimized parameter set each with a unique set of randomly selected initial parameter values each dds trial then generates five individual simulations that represent the possible extent of the parameter sets or the parameter identifiability of the system dds calibration runs were restricted to a maximum of 10 000 function evaluations per optimization trial we use only the nash sutcliffe efficiency coefficient nse nash and sutcliffe 1970 as an objective function for the analysis but note that consideration of multiple objectives may allow for a more robust and diagnostic model assessment the nash sutcliffe efficiency has been presented in the scientific literature for model simulations of discharge and widely used to assess the predictive power of hydrological models a sensitivity analysis using other commonly used objective functions was performed for a single catchment with outcomes presented in appendix b as can be noted from these results the overall conclusions drawn here remain unchanged irrespective of the objective functions used step 4 estimation of flow duration curve fdc next the fdc for each model simulation is estimated an fdc is essentially the cumulative distribution function cdf of daily streamflow and comprehensively describes the historical variability of streamflow in a catchment the fdc was derived using the entire time series simulated for the catchment further analysis is then done across individual streamflow percentiles to assess variability in different flow regimes step 5 input uncertainty estimation using qfd metric the relative contribution of input uncertainty is estimated using the qfd metric as the conditional deviation in flow quantiles for a given combination of two of the three attributes rainfall potential evapotranspiration input model structure and structural parameter identifiability that leads to variability in model outcomes this conditional qfd can then be re scaled to ascertain the relative proportion that is assumed for the data at hand further re scaling is possible considering the length of the data set and the presence of extreme events as well 3 2 quantile flow deviation qfd metric the quantile flow deviation or qfd metric was introduced recently to help attribute uncertainty in hydrological modelling and is implemented here to assess the relative uncertainty due to each potential source under a range of conditions the metric works by conditioning on one or more model characteristics and as such is able to decompose the variability in model outputs and attribute it to various sources for each percentile assessment for each percentile allows uncertainty to be expressed as a function of magnitude and time by considering multiple model structures and parameter identifiability it becomes possible to determine the conditions when each of these sources of uncertainty become more important how cross catchment uncertainty changes and as well when uncertainty changes with a change in the length of available observations shoaib et al 2016 an earlier study shoaib et al 2016 demonstrated the importance of model structural selection using the qfd metric here we adapt the original metric to highlight the impact of input uncertainty the strength of the metric is that by generating ensembles for the fdc we are able to examine the time varying nature of model uncertainty the relative contribution of model structural uncertainty parameter identifiability observations input and objective function selection to the total forecast variability can be estimated for low flows peak flows or at any other magnitude of the hydrologic response the quantile deviation of the simulated flow determines the variability of the inputs relative to model structure and parameter uncertainty fig 2 eqs 1 3 are used to calculate the qfd for the selected model structures observation input and parameter identifiability of the model structure at each percentile p denoted as qfd p m qfd p o and qfd p i respectively with eqs 4 6 defining the interactions between these components and the total qfd shoaib et al 2016 1 qfd p m 2 e i o var q p m q p i q p o 1 i o m 1 o 1 o i 1 i m 1 m q p m i o q p i o 2 2 qfd p o 2 e m i var q p o q p m q p i 1 m i o 1 i 1 i m 1 m o 1 o q p o m i q p m i 2 3 qfd p i 2 e o m var q p i q p o q p m 1 o m i 1 m 1 m o 1 o i 1 i q p i o m q p o m 2 4 qfd p t 2 qfd p m 2 qfd p i 2 qfd p o 2 2 qfd p m i 2 qfd p i o 2 qfd p o m 5 qfd p interaction qfd p m i qfd p i o qfd p o m 6 qfd p t 2 qfd p m 2 qfd p i 2 qfd p o 2 2 qfd p interaction 7 qfd p m i e o cov q p m q p i q p o 8 qfd p i o e m cov q p i q p o q p m 9 qfd p o m e i cov q p o q p m q p i in the equations above for each percentile p q p m q p i q p o denotes multiple model fdcs for an optimized parameter set given an observational dataset representing a unique input uncertainty configuration q p o q p m q p i denotes multiple observational fdcs for a given parameter identifiability set and given model structure and q p i q p o q p m denotes the ensemble of optimised fdc s for a given model structure and an observational dataset in addition i m o denote a parameter identifiability set a model structure and an observation ensemble whereas i m o denote the total number of parameter identifiability sets the number of model structures and the number of observation ensembles respectively similarly q p i o q p m i q p o m denotes the average fdc at percentile p conditioned on the model structure observations and parameter identifiability respectively while q p m i o q p o m i q p i o m denote the fdc at percentile p conditioned on the model structure observations and parameter identifiability respectively it should also be noted that the interaction term in 5 is derived using qfd p m i qfd p i o qfd p o m which denote the covariability of the fdc at percentile p conditioned on the observations model structure and parameter identifiability respectively where q p m q p i q p o denote the percentile flow value considering model structure parameter identifiability and observations respectively 3 3 model structure selection a key element in implementing this study is the selection of a suite of models that represent uncertainty about the catchment processes recent research has identified the importance of model structure selection and the need for coherent frameworks that allow objective comparison of different model attributes clark et al 2008 2015 euser et al 2013 shoaib et al 2016 clark et al 2008 present a methodology to diagnose differences in hydrological model structures fuse fuse was used to construct multiple unique model structures that represent the catchment process effectively by combining components of 4 existing hydrological models the possibility for generating an all inclusive multi model set depends on integrating different model components a systematic approach is necessary to implement this process considering the complexity of the problem to make this task feasible several key decisions were made that reduced the complexity of the problem details on the modifications considered are provided in appendix a model parameters used in fuse are shown in table 2 the dds algorithm was used to determine optimal values of these parameters in all cases 4 analysis of results our analysis focuses on the relative contribution of input uncertainty across different flow percentiles under different seasons and with increasingly spatially representative observation data from this we assess the potential impact of input error across our case study catchments when modelling daily streamflow 4 1 relative contribution of input variability compared to model structure and parameter variability a key question in uncertainty analysis studies is how variability in model outputs arises due to certain model choices we aimed to investigate in this study how input uncertainty varied among four different catchments of australia in comparison to other types of model uncertainty fig 3 model structure uncertainty is highest for each of the four catchments parameter structural identifiability and rainfall or evapotranspiration input uncertainties are low compared to model structure however we note that rainfall input uncertainty riu has a higher overall magnitude in the richmond buchan and barambah catchments compared to parameter uncertainty fig 3a sparse gauge density used to derive the gridded rainfall and significant spatial variability in the rainfall process could be the reason behind this disparity as might be expected due to the higher streamflow yield and observed precipitation the relative magnitude of the qfd in the richmond catchment is higher when compared to the other three selected catchments on the contrary potential evapotranspiration input uncertainty eiu is lower in all the selected catchments compared to parameter uncertainty fig 3b although lower the overall magnitude of eiu is not trivial suggesting that it could be an important source of uncertainty to consider in the modelling process given the emphasis in many hydrologic case studies on the potential impact of rainfall errors this result suggests that further emphasis may be warranted in investigating the impact of eiu depending on the model objectives 4 2 how does input variability magnitude differ between catchment case studies generally rainfall uncertainties in hydrological modelling studies are driven by spatial variability in the rainfall process and the location of fixed point rain gauges our experiment attributes the extent of this uncertainty across different case study catchments for example the barambah river catchment has an area of 640 km2 for which the 30 awap grid cells might be considered as 30 different potential rainfall inputs when investigating the variability in model outputs using each of these rainfall inputs and a single model structure it is clear that model simulations can show significant variability in high flow percentiles fig 4 however it is not clear when using a single model structure or parameter set how input uncertainty might compare to the potential uncertainty in the model structure parameter choices in addition while it might be suggested that the richmond catchment shows higher variability in model response due to variability in rainfall inputs it is not clear if this uncertainty is greater than that due to the model structure or selected parameters to address this we estimate the qfd and its components across flow percentiles for each study catchment fig 5 a regardless of the catchment or flow percentile it is immediately clear that the contribution of uncertainty due to model structure dominates in all four catchments although the extent of this changes across different flow percentiles for instance in the buchan river catchment the model structure variability contributes nearly 80 percent to the total qfd in the 30th to 70th flow percentiles and for the barambah river similar pattern can be seen in 10th to 30th percentiles in case of richmond and seventeen mile river the model structure variability had its highest contribution 60 t of the total qfd in the 20th to 50th percentiles fig 5a after model structure variability input rainfall and potential evapotranspiration and parameter uncertainty contribute a reasonable share to the total qfd fig 5a and b the relative contribution of input uncertainty varies distinctly in the four catchments the seventeen mile catchment and richmond catchment show a similar contribution of input uncertainty compared to the other two catchments on other hand the barambah and richmond catchments show similar contributions to the parameter uncertainty domain though the interaction contribution is more prominent in the latter parameter uncertainty in the seventeen mile catchment is significant in 20th to 80th percentiles but for buchan river parameter uncertainty is significant in higher and lower percentiles interestingly considering the relative contribution of input uncertainty buchan river shows a significantly different response as lower percentiles demonstrate nearly zero contribution to the total qfd from variability in model inputs model structure response as well parameter variability with the change of inputs could be a reason for this pattern at the same time in barambah river there is an increase of input uncertainty from lower to higher percentiles considering the selected four catchments it is clear that the response of input variability vary in individual catchments depending on catchment size topography and location consideration of additional catchments and possible regionalisation of results could assist in better understanding how these uncertainties will manifest themselves in other settings it is also not surprising that individual catchments behave similarly in terms of their response but the relative contribution of input uncertainty compared to model structure and parameter identifiability gives a clear signal about the extent of uncertainty that needs to be incorporated in any water management application that relies on such modelled flow values the relative contribution of potential evapotranspiration input uncertainty eiu is lower in all the selected catchments compared rainfall input uncertainty riu and parameter uncertainty the contribution of model structure uncertainty dominates in all cases pointing to the importance it assumes in any modelling application fig 4b 4 3 how does input variability change with averaged multi gauge inputs as compared to use of a single grid input to evaluate the impact of the potential density of the rain gauge network in a typical lumped modelling application we calculate the qfd metric for an increasing number of rainfall grids for the richmond catchment these grids may then be considered a surrogate for potential rainfall gauges in each catchment we randomly sample two gauges or more and take the average of these to attribute the influence of multiple gauges we resample gauges 25 times for each case for example two gauge four gauge ten gauge etc to adequately illustrate the variability in the rain gauge location in this section the relative contribution of model structure parameter and input variability is presented with the total interaction fig 6 as was demonstrated in the preceding analysis the model structural uncertainty contributes a large proportion of the streamflow variability across the four cases compared here however the patterns of input variability are dynamic for instance for a single gauge input variability increases slightly from higher percentiles to lower percentiles the opposite patterns are seen in the four gauges case fig 6a ii where input variability decreases from higher percentiles to lower percentiles in the ten gauge cases a near uniform decrease in variability of input uncertainty exists in higher to lower percentiles interestingly similar magnitude of parameter uncertainty is observed for all percentiles in each of the four different gauge arrangements in addition the interaction term varies in each of the four different cases although in the mid percentile domain the variability is trivial as expected an increasing number of gauges reduce the contribution of uncertainty from inputs thereby increasing the share of model structure uncertainty a similar pattern of variability is observed while changing the input variability as potential evapotranspiration with increasing number of gauges fig 6b it should however be noted that the relative contribution of input uncertainty due to potential evapotranspiration is less compared to rainfall variability 4 4 relative input qfd variability in different catchments with changes in gauge numbers the preceding section raises the question of how dense a rain gauge network should be to see an appreciable drop in the potential uncertainty in model inputs to investigate this we estimate the qfd for an increasing number of gridded rainfall fields for each study catchment fig 7 a we note a linear decrease in the qfd in each catchment with an increasing number of rain gauges for instance the richmond catchment has higher rainfall variability compared to the other selected catchments and hence has higher qfd variability with an increasing number of rain gauges qfd decreases linearly fig 7a left panel for the barambah catchment the qfd decreases relatively sharply with an increasing number of rain gauges compared to buchan and seventeen mile catchments the relative proximity of more gauges catchment could be a reason in this case on the other hand in considering the buchan river catchment the qfd variability with an increasing number of gauges is more consistent in comparison to the other case study catchments the qfd variability converges after averaging a certain number of gauges in all of the selected catchments representation of rainfall variability with an increasing number of gauges shows a reduction in the overall estimated uncertainty fig 7a left panel on the contrary input qfd drops sharply with the increase of number of gauges and goes near to zero fig 7a right panel after a representative number of gauges are included in the selected catchment a relatively lesser variability is observed while changing the input variability to potential evapotranspiration with an increasing number of gauges fig 7b however the magnitudes of input qfd due to potential evapotranspiration drops significantly compared to qfd due to rainfall overall with the aid of the qfd framework we are able to illustrate the extent of variability resulting from different model inputs used in the modelling framework 4 5 seasonal variability and input uncertainty understanding seasonal variability in the changing pattern of input uncertainty may have significant implications in engineering design and planning process such as in assessing yields or environmental flow requirements or the quantification of derived flood quantiles here we disaggregate the input quantile flow deviation qfdi metric for the barambah catchment across the four seasons in australia summer december february autumn march may winter june august spring september november fig 8 a as may be expected input qfd is high in summer and low in winter when considered as an absolute value seasonal variability in terms of input qfd is significant in summer and spring followed by autumn and winter low variability of qfd in winter reflects the reduced quantity of rainfall in this part of the year fig 8a most importantly variability is significant in higher percentiles for all four seasons although the summer season shows relatively high contribution of input uncertainty compared to other three seasons it is related to the higher rainfall variability in the same period higher input uncertainty can have implications for extreme events and affect hydrologic design therefore consideration of seasonal variability of input uncertainty in decision making process and evaluating its magnitude is useful on the other hand the relative percentage of total qfd compared to input qfd demonstrates that higher rainfall magnitude does not necessarily suggest a higher proportion of rainfall uncertainty when compared to other uncertain modelling choices fig 8b this might suggest that when seasonal rainfall is high emphasis should be placed on ensuring appropriate model choices rather than correct model inputs depending on the point of the modelling exercise 4 6 comparing rainfall and evapotranspiration variability concurrently as a final analysis we examine the impact of rainfall uncertainty and potential evapotranspiration uncertainty concurrently by holding each model simulation at a single optimised parameter set fig 9 the analysis highlights the lesser importance of variability in potential evapotranspiration when parameter uncertainty is reduced noting that it still contributes to the total variability seen in model simulations 5 discussion uncertainty is unavoidable but at times reducible when developing a modelling exercise for hydrologic analysis and management uncertainties from each of the decision making process steps must be appropriately managed and communicated the model structure related uncertainties are frequently included in the output analysis yet the extent of input uncertainty is less well known and is infrequently accounted for despite the potential for it to have a big impact on hydrologic model output selecting the best possible true input and suitable model structure based on predictive ability is the aim of all modellers but often not realised due to practical constraints taking advantage of strengths of different models is another aspect of uncertainty quantification however for modelling simulation to be as worthwhile as possible we need to take into account the error associated with uncertainty that may exist in the simulated output we would state that a particular innovation of the approach presented in the paper is the consideration of input uncertainty relative to model structure and parameter uncertainty across a range of modelling scenarios this we believe is vital for any water resources planning and engineering design process assuming even greater importance when input uncertainty becomes even larger say when no gauge exists within the catchment at the same time we have demonstrated how the relative contribution of input uncertainty decreases with increasing spatial density in input observations and analysed the seasonal dimension of input uncertainty in the australian context 5 1 input rainfall uncertainty implications in hydrological modelling in this paper with the aid of the qfd metric and gridded data the extent of input uncertainty is evaluated we have investigated through case studies how input uncertainty varies across four different catchments in australia in comparison to other types of modelling uncertainty analysis of the simulated results show that the relative input qfd due to rainfall variability is larger compared to potential evapotranspiration fig 9 when the variability of rainfall and potential evapotranspiration are considered concurrently in the simulation on the other hand input uncertainty due to rainfall uncertainty is higher than parameter uncertainty fig 3a however input uncertainty due to potential evapotranspiration is lower compared to parameter and model structure uncertainty in all the selected catchments fig 3b expressing the relative contribution of different sources of uncertainty reveals the relative importance of inputs as well it is noted that with low gauge density input uncertainty especially for rainfall could be more important for higher flow percentiles fig 5 this is expected as at higher rainfall and corresponding flow magnitude there is a wider range of potential storm observations depending on how a storm moves through a catchment and its relative proximity to a point observation gauge as gauge density increases input uncertainty is becoming more relevant across all flow values fig 6 this demonstrates the extent to which input uncertainty considering both rainfall and potential evapotranspiration is important to characterise for peak flows when only a single gauge is available fig 9 on other hand the relative contribution of input uncertainty varies noticeably in each of the four selected catchments in our study this indicates that we cannot generalise results across different catchments representing different climates and spatial extents it suggests the importance of undertaking a study such as this that allows us to compare and quantify different sources of uncertainty for example when using a single gauge input uncertainty is consistent across higher percentiles and lower percentiles while it increases from lower percentiles to higher percentiles when aggregating information from four gauges fig 6a ii in the case of ten and twenty gauges identical variability of input uncertainty exists across all percentiles in contrast a fairly similar pattern of parameter uncertainty is evident for all percentiles in four different gauges arrangements fig 6a where parameter uncertainty is maximised at the 70th and 80th percentile indicating the model structure and input uncertainty influence the overall uncertainty in different ways the contribution of input uncertainty due to evapotranspiration is less compared to the relative contribution of parameter uncertainty fig 6b and the response of input uncertainty decreases with an increasing number of gauges with respect to catchment response the relative contribution of input uncertainty varies noticeably across the four different selected catchments the seventeen mile catchment and richmond catchment respond similarly to varying input uncertainty compared to the other two catchments fig 5 a linear decrease in total uncertainty is noted with increase in the number of gauges indicating the importance of using all available information fig 7 when modelling flow processes moreover contribution of input qfd for both rainfall fig 7a and potential evapotranspiration fig 7b demonstrates the importance of adopting more gauge data to reduce the uncertainty to a minimum 5 2 the relative contribution of uncertainty and the model observation linkage a principal challenge in hydrologic modelling is defining model sensitivity to uncertainty a key element of this is input uncertainty and strategies can be developed to reduce this uncertainty through proper utilisation of all input information one of the key innovations of the paper was to show how relative contribution of input uncertainty decreases with increasing number of gauge data gridded data considering most hydrological applications pertain to ungauged basins measurements from a single gauge are all that are usually available and often the single gauge may not be centrally located and may even be located outside the watershed bárdossy and das 2008 dawdy and bergmann 1969 faurès et al 1995 mandapaka et al 2009 mcmillan et al 2011 therefore defining input uncertainty is challenging task in these aspects gridded rainfall datasets are an important source of information to evaluate the potential spatial variability in rainfall for modelling applications while such gridded datasets are becoming increasingly available for use in modelling applications care must be taken to also consider the uncertainty they may also contain ignoring this uncertainty can result in a false sense of reliability for the modelled output as is seen in the results obtained here when a single grid is used as a representative rain gauge for the catchment this is all the more important given the use of automated modelling tools that obtain rainfall from external sources where the information on associated uncertainty may not be readily available an important element to consider in this study is that the use of a gridded rainfall product here interpolated and averaged across multiple grid cells may underestimate the true rainfall uncertainty particularly for extreme events tozer et al 2012 this true rainfall uncertainty can be underestimated because the rainfall observations are smoothed in the interpolation procedure used to derive the gridded rainfall nonetheless gridded rainfall data remain a useful surrogate for the potential spectrum of climate variability that will impact a hydrologic modelling study 6 conclusion and further work quantifying uncertainty in hydrologic models is essential for their effective use and assessment the hydrological modelling implication of using gridded rainfall as well as potential evapotranspiration data as a surrogate for gauged data opens the window to evaluate the relative importance of input uncertainty with respect to other sources of uncertainty this study presents a basis to quantify the relative contribution of input uncertainty for both rainfall and potential evapotranspiration with the aid of the qfd metric shoaib et al 2016 and shows the spectrum of input uncertainty with respect to other important sources of uncertainty model structure and parameter in a more logical way the qfd metric applied here provides a straightforward and novel way to explore the relative variability in outputs due to various modelling choices be they different potential model structures different inputs or different parameter sets that may give similar objective function values a particular innovation of the approach presented in the paper is that in this study we take into consideration input uncertainty relative to model structure and parameter uncertainty results presented in this paper show that the relative contribution of input uncertainty due to rainfall is higher compared to evapotranspiration and overall input uncertainty is noteworthy compared to model structure and parameter uncertainty this study also examines the circumstances whereby input uncertainty plays a significant role given similar climatological conditions how input uncertainty affects forecasts in single to multi gauge catchments is also evaluated seasonal catchment dynamics represented through input uncertainty across different percentiles attribute the significance of uncertainty in quantifying flow extremes which are especially relevant in engineering planning and design the limitations of the presented study are attributing extreme events and their extent in the total uncertainty interpolated average grid cells data could underestimate the uncertainty in the simulated output future work will focus on extending the method presented in this paper to consider extreme events and associated uncertainty across the watershed the inference methodology presented here can easily be extended to include additional uncertainty or errors encountered in other modelling scenarios such as those where water quality concentration is of interest acknowledgements this research is supported by australian research council arc award ft20100269 to dr marshall the australian research council arc discovery award dp170103959 and the unsw postgraduate research fund appendix a as detailed in fig a 1 the following simplifications were made to the model configuration adopted in this study a select between three possible upper layer architectures i single state ss ii separate tension storage st iii cascading buckets cb b choose between three possible lower layer architectures i baseflow reservoir of fixed size brfs ii tension reservoir plus two parallel tanks trtpt iii baseflow reservoir of unlimited size frac rate brusfr iv baseflow reservoir of unlimited size power recession bruspr and their associated base flow parameterizations c select between three possible percolation parameterizations i drainage above field capacity dafc ii gravity drainage gd iii saturated zone control szc d select between three possible surface runoff parameterizations i unsaturated zone pareto uzp ii unsaturated zone linear uzl iii saturated zone topographic szt to compute saturated areas and surface runoff e the sequential and root weighting methods for evaporation were applied model selection will be based on one of these options f options of interflow were computed in some model structures at the same time interflow was denied in some model structures g models were run using a daily time step and hence infiltration excess runoff was not computed by any of the models h a gamma distribution was used to route runoff to the basin outlet in all most all cases and some cases considering type of experiment routing could be denied four parent hydrological models topmodel arnoxvic prms sacramento within the fuse framework to represent the full spectrum of potential model variability in the absence of specific information on the catchment hydrologic processes twenty two 22 model parameters represent the hydrological system within fuse clark et al 2008 some of these parameters are inactive depending on the model configuration of interest fig a 1 outlines the model structure that was considered in the simulation results presented appendix b nash sutcliffe efficiency has been presented in the literature for model simulations of discharge and is widely used to assess the predictive power of hydrological models we have undertaken additional analysis considering alternate objective functions to assess how sensitive our findings are to the objective function used as fig b 1 illustrates the change in the proportion of uncertainty by considering additional objective functions is not significant supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2018 01 022 appendix c supplementary materials image application 1 
811,every model to characterise a real world process is affected by uncertainty selecting a suitable model is a vital aspect of engineering planning and design observation or input errors make the prediction of modelled responses more uncertain by way of a recently developed attribution metric this study is aimed at developing a method for analysing variability in model inputs together with model structure variability to quantify their relative contributions in typical hydrological modelling applications the quantile flow deviation qfd metric is used to assess these alternate sources of uncertainty the australian water availability project awap precipitation data for four different australian catchments is used to analyse the impact of spatial rainfall variability on simulated streamflow variability via the qfd the qfd metric attributes the variability in flow ensembles to uncertainty associated with the selection of a model structure and input time series for the case study catchments the relative contribution of input uncertainty due to rainfall is higher than that due to potential evapotranspiration and overall input uncertainty is significant compared to model structure and parameter uncertainty overall this study investigates the propagation of input uncertainty in a daily streamflow modelling scenario and demonstrates how input errors manifest across different streamflow magnitudes keywords input uncertainty quantile flow deviation qfd multi site rainfall model structure 1 introduction every model that characterises a real world process will be subject to uncertainty uncertainty affects the specification and use of hydrologic systems in a range of management planning or design applications quantification of uncertainty in hydrology is the first step to control and eventually to improve the specification of a hydrological model however estimation of uncertainty has been the subject of considerable debate in the hydrological literature beven 2016 carpenter and georgakakos 2004 gong et al 2013 jin et al 2010 montanari and grossi 2008 nearing and gupta 2015 although many uncertainty analysis frameworks have been introduced in the hydrological domain implementing these in an integrated manner remains a challenge for hydrologic modelling exercises liu and gupta 2007 modelling uncertainty is a result of several factors that are frequently interdependent and difficult to explicitly identify attempts to separate the error associated with rainfall inputs for example are complicated by the strong interaction they have with model structural error leading to at times large changes to calibrated parameters and resulting outputs huard and mailhot 2006 kuczera et al 2006 mcmillan et al 2011 renard et al 2010 villarini and krajewski 2008 vrugt et al 2008 as rainfall data is a crucial component in many engineering hydrology applications the existence of input errors in rainfall runoff modelling causes a variety of problems in runoff prediction bárdossy and das 2008 dawdy and bergmann 1969 del giudice et al 2016 georgakakos et al 2004 kavetski et al 2006 a very common source of error in rainfall measurement is due to the spatial variability of precipitation and the lack of a sufficient density of gauges to capture that variability with precision faurès et al 1995 mandapaka et al 2009 singh 1997 even if measurements from a single gauge may be assumed to be representative of overall catchment rainfall in an expected value sense other statistical properties of point rainfall will differ considerably from the corresponding properties of average catchment rainfall the result can be serious errors in runoff prediction and large biases in parameter estimates obtained by calibration of the model arnaud et al 2002 chowdhury and sharma 2007 similarly potential evapotranspiration is an important hydrologic process globally as well as a key component of a catchment s water balance and necessary to represent the model runoff generation processes correctly eagleson 1978 the variability of potential evapotranspiration as an input to hydrologic models has also been identified as requiring further investigation oudin et al 2005 oudin et al 2006 to that end several approaches for quantifying observational and or structural uncertainties in hydrologic predictions exist renard et al 2010 including the i the bayesian total error analysis batea framework kavetski et al 2006 kuczera et al 2006 ii the generalized likelihood uncertainty estimation glue beven and binley 1992 iii standard bayesian approaches and bayesian hierarchical models huard and mailhot 2006 kavetski et al 2006 kuczera et al 2006 marshall et al 2004 2006 iv frequentist approaches montanari and brath 2004 v the integrated bayesian uncertainty estimator ibune ajami et al 2007 and others while there exists a clear realisation that uncertainty is a significant part of hydrological modelling with a magnitude that grows as one proceeds to the use of more complex models in data poor or ungauged situations the issue of attributing uncertainty in outputs to alternate causative sources remains unaddressed a potential solution to this is the use of diagnostic tools that evaluate the variability in hydrologic ensembles produced in typical uncertainty analysis exercises shoaib et al 2016 the primary motivation for the current work is then to evaluate the relative contribution of uncertainty due to model input variability in a typical conceptual hydrologic modelling application that assumes a lumped input due to significant spatial and temporal variability in rainfall fields the rainfall forcing error has the potential to dominate in the uncertainty spectrum of a typical modelling application arnaud et al 2002 singh 1997 most importantly these errors can be significant in many of the catchments that represent the hydrological landscape of a country mcmillan et al 2011 villarini and krajewski 2008 similar phenomena could be observed with the variability of potential evapotranspiration the objective of this paper is therefore to evaluate the relative contribution of potential input uncertainty compared to that associated with the model structure and parameter uncertainty in a typical modelling exercise gridded rainfall and evapotranspiration observations are used to represent the potential spectrum of input variability that might arise in a modelling study using point gauge data we make use of a recently developed metric the quantile flow deviation qfd shoaib et al 2016 to understand the role of alternate model factors that lead to uncertainty in the modelled output woldemeskel et al 2012 2016 focusing on the impact of uncertain rainfall and potential evapotranspiration the metric is calculated by conditioning the estimated variance in streamflow ensembles on one or more model characteristics and as such is able to decompose the variability in model outputs and attribute it to various sources overall this study aims to investigate the following questions how does input uncertainty magnitude affect in the simulated streamflow considering the likely spatial variability of rainfall and potential evapotranspiration within a catchment how does input uncertainty change with a growing number of rain gauges to the more typical case of an individual gauge being used how does input uncertainty diverge between different catchments of varying hydrologic attributes and finally how can one allow for separation of seasonal uncertainty with input uncertainty in an engineering design and planning process this paper is organized as follows after the introduction section 2 describes the data used for the study and catchment properties the next section conceptualizes the method to quantify input uncertainty via the quantile flow deviation the following section presents the outcomes of the simulations and evaluation of the proposed scheme section 5 elaborates on input uncertainty structural identifiability model structure and likelihood with the analysis of the results the final section identifies some important caveats and opportunities for further research 2 data and study area the daily rainfall and potential evapotranspiration data set used in this study is derived from the australian water availability project awap jones et al 2009 khan et al 2015 the dataset is gridded to 0 05 0 05 5 km 5 km for the period 1980 2005 the accuracy of this data set is typically low where gauge density is low as is the case in central west australia for instance jones et al 2009 the original meteorological data used in the awap product were supplied by the bureau of meteorology australia bom the awap platform uses model data fusion methods to combine both measurements and water balance modelling of rainfall and evapotranspiration processes to produce gridded data in the model experiments implemented here we use these rainfall and evapotranspiration fields to represent the natural variability in these processes and the potential error that arises when a single point observation is used in a modelling exercise daily rainfall data is available from 1900 to present temperatures from 1911 to present and solar irradiance from 1990 to present gridded rainfall and potential evapotranspiration data used in this study are available in the following links i for rainfall http www bom gov au web03 ncc www awap rainfall totals daily grid 0 05 history nat startdate enddate grid z ii for potential evapotranspiration ftp ftp eoc csiro au pub awap australia historical run26j fwpt in this study we have selected four different catchments considering the bioregions and climate zones of australia the physical and climatic properties of the selected catchments are diverse to investigate how input uncertainty manifests across distinct hydroclimatic case studies table 1 areas of the catchments vary from 600 km2 to 850 km2 while annual precipitation varies from 890 mm to 1250 mm though the richmond catchment shows the highest annual precipitation among the four catchments the seventeen mile catchment of northern territory shows a higher magnitude of potential evapotranspiration similarly runoff magnitude varies considerably amongst the selected catchments from 84 mm year to 364 mm year table 1 shows the overall catchment features for these catchments articulating the marked differences in important catchment characteristics streamflow q data for the selected catchments is taken from bureau of meteorology australia bom this study investigates the impact of input uncertainty on hydrologic model simulations for these four selected catchments as a function of the spatial variability associated with the observed rainfall and potential evapotranspiration fig 1 a shows the average annual rainfall and fig 1b shows the average potential evapotranspiration for the four catchments on a grid cell basis each grid box represents an approximate square area of 25 km2 0 05 by 0 05 among the four selected catchments the richmond catchment shows the highest spatial variability in rainfall and the seventeen mile catchment shows the lowest spatial variability in rainfall considering the scales for the catchments are different similar patterns of potential evapotranspiration variability are visible among the selected catchments fig 1b 3 methodology a general framework is developed to evaluate the potential impact of uncertain observations on model simulations the approach consists of a factorial modelling experiment that generates multiple model simulations resulting from different model choices then a novel statistical metric is calculated that disaggregates the variability in these simulations to its sources as such variability in model outputs is attributed to different sources of uncertainty here we summarise the general methodology and the sequence of steps used to evaluate our methodology on the case studies 3 1 evaluating uncertainty and the impact of modelling decisions one way in which to evaluate the potential impact of modelling decisions is via the analysis of model ensembles that result from the model uncertainty here we implement a factorial modelling experiment aimed at simulating multiple streamflow time series arising from different modelling choices or decisions we select a single input data series for the study catchment select a single lumped model structure from a suite of available models and generate a single parameter set to simulate the model output this process is repeated to generate ensembles of model simulations we then aim to attribute the variability in the model simulations to these choices considering this a conceptual layout is presented in fig 2 in the first panel each grid cell represents a time series of rainfall observations which may be derived from a gridded rainfall product or a network of rain gauges one or more of these pseudo observation time series are selected and used as an input to a hydrologic model this selected time series represents the potential uncertainty or error that arises when a single point observation is used as an input to a hydrologic model following we select one of a suite of multiple hydrological models that represent structural uncertainty about the processes occurring in the catchment system we optimise the model using best available rainfall data resulting in a set of parameter values by repeating the selection of an input time series a model structure and a parameter set multiple times the results are ensembles of outputs representing uncertainty in the model outputs as a function of the a priori modeller choices then the qfd metric can be applied to evaluate the relative importance of these different model choices similar procedures are followed for considering the variability in potential evapotranspiration to quantify the input uncertainty specific to this study the following steps summarize the experimental methodology that was implemented to evaluate input uncertainty in our study catchments step 1 process input variability rainfall and potential evapotranspiration each catchment is represented with the available awap data by a number of grids according to their catchment area for each model simulation a single grid cell time series rainfall and potential evapotranspiration is randomly selected for the selected case study catchment assuming each grid cell data set is equally likely by selecting an entire time series from a single grid cell and not resampling grid cells within a whole time series the rainfall evapotranspiration temporal characteristics are preserved with each experiment we consider the impact of rainfall uncertainty and potential evapotranspiration uncertainty separately the total number of input ensembles for each catchment can be selected to be the same as the number of awap grids within each catchment boundary note that our analysis considers the impact of selecting a single grid for instance as a surrogate for a single site rain gauge or potential evapotranspiration as well as how uncertainty might change with the availability of a larger gauge density when evaluating the effect of multiple observation sites we simply average the selected rainfall or potential evapotranspiration grid cells to estimate a single lumped input to the model structure therefore inputs also represented averages of multiple randomly selected awap grids for experimental investigations to keep consistency in our analysis we resample gauges 25 times for each selected catchment for example the analysis considered the uncertainty for multiple combinations of two gauges three four gauges five ten gauges etc to adequately illustrate the variability in the rain gauge location as well as potential evapotranspiration measurement location considering the area of the catchment the total number of awap grids varies for each catchment the length of the input rainfall and potential evapotranspiration data is 5 years for each selected catchment step 2 selection of model structure possible model structures could be selected based on knowledge of the catchments underlying processes and reflecting potential structural uncertainty due to incomplete knowledge a range of model structures is selected a priori to reflect the variability in the mathematical description of the hydrologic system four parent model configurations within the framework for understanding structural errors fuse clark et al 2008 are used to represent model structural variability models in fuse are constructed by combining alternate architecture and flux parameterizations we have selected the four parent hydrological models topmodel arnoxvic prms sacramento within the fuse framework to represent a spectrum of the potential model uncertainty more details about the models used are presented in subsequent sections step 3 identifiability characterisation of model structure parameter spectrum in this step we consider multiple possible parameter solutions that may exist due to equifinality or poor identifiability of the model these may be obtained via multiple global optimization runs shin et al 2015 or could be determined from a likelihood based analysis such as glue or bayesian inference each model is thus calibrated using the dynamically dimensioned search dds algorithm tolson and shoemaker 2007 in this study we conducted five dds trials for each model to select the optimized parameter set each with a unique set of randomly selected initial parameter values each dds trial then generates five individual simulations that represent the possible extent of the parameter sets or the parameter identifiability of the system dds calibration runs were restricted to a maximum of 10 000 function evaluations per optimization trial we use only the nash sutcliffe efficiency coefficient nse nash and sutcliffe 1970 as an objective function for the analysis but note that consideration of multiple objectives may allow for a more robust and diagnostic model assessment the nash sutcliffe efficiency has been presented in the scientific literature for model simulations of discharge and widely used to assess the predictive power of hydrological models a sensitivity analysis using other commonly used objective functions was performed for a single catchment with outcomes presented in appendix b as can be noted from these results the overall conclusions drawn here remain unchanged irrespective of the objective functions used step 4 estimation of flow duration curve fdc next the fdc for each model simulation is estimated an fdc is essentially the cumulative distribution function cdf of daily streamflow and comprehensively describes the historical variability of streamflow in a catchment the fdc was derived using the entire time series simulated for the catchment further analysis is then done across individual streamflow percentiles to assess variability in different flow regimes step 5 input uncertainty estimation using qfd metric the relative contribution of input uncertainty is estimated using the qfd metric as the conditional deviation in flow quantiles for a given combination of two of the three attributes rainfall potential evapotranspiration input model structure and structural parameter identifiability that leads to variability in model outcomes this conditional qfd can then be re scaled to ascertain the relative proportion that is assumed for the data at hand further re scaling is possible considering the length of the data set and the presence of extreme events as well 3 2 quantile flow deviation qfd metric the quantile flow deviation or qfd metric was introduced recently to help attribute uncertainty in hydrological modelling and is implemented here to assess the relative uncertainty due to each potential source under a range of conditions the metric works by conditioning on one or more model characteristics and as such is able to decompose the variability in model outputs and attribute it to various sources for each percentile assessment for each percentile allows uncertainty to be expressed as a function of magnitude and time by considering multiple model structures and parameter identifiability it becomes possible to determine the conditions when each of these sources of uncertainty become more important how cross catchment uncertainty changes and as well when uncertainty changes with a change in the length of available observations shoaib et al 2016 an earlier study shoaib et al 2016 demonstrated the importance of model structural selection using the qfd metric here we adapt the original metric to highlight the impact of input uncertainty the strength of the metric is that by generating ensembles for the fdc we are able to examine the time varying nature of model uncertainty the relative contribution of model structural uncertainty parameter identifiability observations input and objective function selection to the total forecast variability can be estimated for low flows peak flows or at any other magnitude of the hydrologic response the quantile deviation of the simulated flow determines the variability of the inputs relative to model structure and parameter uncertainty fig 2 eqs 1 3 are used to calculate the qfd for the selected model structures observation input and parameter identifiability of the model structure at each percentile p denoted as qfd p m qfd p o and qfd p i respectively with eqs 4 6 defining the interactions between these components and the total qfd shoaib et al 2016 1 qfd p m 2 e i o var q p m q p i q p o 1 i o m 1 o 1 o i 1 i m 1 m q p m i o q p i o 2 2 qfd p o 2 e m i var q p o q p m q p i 1 m i o 1 i 1 i m 1 m o 1 o q p o m i q p m i 2 3 qfd p i 2 e o m var q p i q p o q p m 1 o m i 1 m 1 m o 1 o i 1 i q p i o m q p o m 2 4 qfd p t 2 qfd p m 2 qfd p i 2 qfd p o 2 2 qfd p m i 2 qfd p i o 2 qfd p o m 5 qfd p interaction qfd p m i qfd p i o qfd p o m 6 qfd p t 2 qfd p m 2 qfd p i 2 qfd p o 2 2 qfd p interaction 7 qfd p m i e o cov q p m q p i q p o 8 qfd p i o e m cov q p i q p o q p m 9 qfd p o m e i cov q p o q p m q p i in the equations above for each percentile p q p m q p i q p o denotes multiple model fdcs for an optimized parameter set given an observational dataset representing a unique input uncertainty configuration q p o q p m q p i denotes multiple observational fdcs for a given parameter identifiability set and given model structure and q p i q p o q p m denotes the ensemble of optimised fdc s for a given model structure and an observational dataset in addition i m o denote a parameter identifiability set a model structure and an observation ensemble whereas i m o denote the total number of parameter identifiability sets the number of model structures and the number of observation ensembles respectively similarly q p i o q p m i q p o m denotes the average fdc at percentile p conditioned on the model structure observations and parameter identifiability respectively while q p m i o q p o m i q p i o m denote the fdc at percentile p conditioned on the model structure observations and parameter identifiability respectively it should also be noted that the interaction term in 5 is derived using qfd p m i qfd p i o qfd p o m which denote the covariability of the fdc at percentile p conditioned on the observations model structure and parameter identifiability respectively where q p m q p i q p o denote the percentile flow value considering model structure parameter identifiability and observations respectively 3 3 model structure selection a key element in implementing this study is the selection of a suite of models that represent uncertainty about the catchment processes recent research has identified the importance of model structure selection and the need for coherent frameworks that allow objective comparison of different model attributes clark et al 2008 2015 euser et al 2013 shoaib et al 2016 clark et al 2008 present a methodology to diagnose differences in hydrological model structures fuse fuse was used to construct multiple unique model structures that represent the catchment process effectively by combining components of 4 existing hydrological models the possibility for generating an all inclusive multi model set depends on integrating different model components a systematic approach is necessary to implement this process considering the complexity of the problem to make this task feasible several key decisions were made that reduced the complexity of the problem details on the modifications considered are provided in appendix a model parameters used in fuse are shown in table 2 the dds algorithm was used to determine optimal values of these parameters in all cases 4 analysis of results our analysis focuses on the relative contribution of input uncertainty across different flow percentiles under different seasons and with increasingly spatially representative observation data from this we assess the potential impact of input error across our case study catchments when modelling daily streamflow 4 1 relative contribution of input variability compared to model structure and parameter variability a key question in uncertainty analysis studies is how variability in model outputs arises due to certain model choices we aimed to investigate in this study how input uncertainty varied among four different catchments of australia in comparison to other types of model uncertainty fig 3 model structure uncertainty is highest for each of the four catchments parameter structural identifiability and rainfall or evapotranspiration input uncertainties are low compared to model structure however we note that rainfall input uncertainty riu has a higher overall magnitude in the richmond buchan and barambah catchments compared to parameter uncertainty fig 3a sparse gauge density used to derive the gridded rainfall and significant spatial variability in the rainfall process could be the reason behind this disparity as might be expected due to the higher streamflow yield and observed precipitation the relative magnitude of the qfd in the richmond catchment is higher when compared to the other three selected catchments on the contrary potential evapotranspiration input uncertainty eiu is lower in all the selected catchments compared to parameter uncertainty fig 3b although lower the overall magnitude of eiu is not trivial suggesting that it could be an important source of uncertainty to consider in the modelling process given the emphasis in many hydrologic case studies on the potential impact of rainfall errors this result suggests that further emphasis may be warranted in investigating the impact of eiu depending on the model objectives 4 2 how does input variability magnitude differ between catchment case studies generally rainfall uncertainties in hydrological modelling studies are driven by spatial variability in the rainfall process and the location of fixed point rain gauges our experiment attributes the extent of this uncertainty across different case study catchments for example the barambah river catchment has an area of 640 km2 for which the 30 awap grid cells might be considered as 30 different potential rainfall inputs when investigating the variability in model outputs using each of these rainfall inputs and a single model structure it is clear that model simulations can show significant variability in high flow percentiles fig 4 however it is not clear when using a single model structure or parameter set how input uncertainty might compare to the potential uncertainty in the model structure parameter choices in addition while it might be suggested that the richmond catchment shows higher variability in model response due to variability in rainfall inputs it is not clear if this uncertainty is greater than that due to the model structure or selected parameters to address this we estimate the qfd and its components across flow percentiles for each study catchment fig 5 a regardless of the catchment or flow percentile it is immediately clear that the contribution of uncertainty due to model structure dominates in all four catchments although the extent of this changes across different flow percentiles for instance in the buchan river catchment the model structure variability contributes nearly 80 percent to the total qfd in the 30th to 70th flow percentiles and for the barambah river similar pattern can be seen in 10th to 30th percentiles in case of richmond and seventeen mile river the model structure variability had its highest contribution 60 t of the total qfd in the 20th to 50th percentiles fig 5a after model structure variability input rainfall and potential evapotranspiration and parameter uncertainty contribute a reasonable share to the total qfd fig 5a and b the relative contribution of input uncertainty varies distinctly in the four catchments the seventeen mile catchment and richmond catchment show a similar contribution of input uncertainty compared to the other two catchments on other hand the barambah and richmond catchments show similar contributions to the parameter uncertainty domain though the interaction contribution is more prominent in the latter parameter uncertainty in the seventeen mile catchment is significant in 20th to 80th percentiles but for buchan river parameter uncertainty is significant in higher and lower percentiles interestingly considering the relative contribution of input uncertainty buchan river shows a significantly different response as lower percentiles demonstrate nearly zero contribution to the total qfd from variability in model inputs model structure response as well parameter variability with the change of inputs could be a reason for this pattern at the same time in barambah river there is an increase of input uncertainty from lower to higher percentiles considering the selected four catchments it is clear that the response of input variability vary in individual catchments depending on catchment size topography and location consideration of additional catchments and possible regionalisation of results could assist in better understanding how these uncertainties will manifest themselves in other settings it is also not surprising that individual catchments behave similarly in terms of their response but the relative contribution of input uncertainty compared to model structure and parameter identifiability gives a clear signal about the extent of uncertainty that needs to be incorporated in any water management application that relies on such modelled flow values the relative contribution of potential evapotranspiration input uncertainty eiu is lower in all the selected catchments compared rainfall input uncertainty riu and parameter uncertainty the contribution of model structure uncertainty dominates in all cases pointing to the importance it assumes in any modelling application fig 4b 4 3 how does input variability change with averaged multi gauge inputs as compared to use of a single grid input to evaluate the impact of the potential density of the rain gauge network in a typical lumped modelling application we calculate the qfd metric for an increasing number of rainfall grids for the richmond catchment these grids may then be considered a surrogate for potential rainfall gauges in each catchment we randomly sample two gauges or more and take the average of these to attribute the influence of multiple gauges we resample gauges 25 times for each case for example two gauge four gauge ten gauge etc to adequately illustrate the variability in the rain gauge location in this section the relative contribution of model structure parameter and input variability is presented with the total interaction fig 6 as was demonstrated in the preceding analysis the model structural uncertainty contributes a large proportion of the streamflow variability across the four cases compared here however the patterns of input variability are dynamic for instance for a single gauge input variability increases slightly from higher percentiles to lower percentiles the opposite patterns are seen in the four gauges case fig 6a ii where input variability decreases from higher percentiles to lower percentiles in the ten gauge cases a near uniform decrease in variability of input uncertainty exists in higher to lower percentiles interestingly similar magnitude of parameter uncertainty is observed for all percentiles in each of the four different gauge arrangements in addition the interaction term varies in each of the four different cases although in the mid percentile domain the variability is trivial as expected an increasing number of gauges reduce the contribution of uncertainty from inputs thereby increasing the share of model structure uncertainty a similar pattern of variability is observed while changing the input variability as potential evapotranspiration with increasing number of gauges fig 6b it should however be noted that the relative contribution of input uncertainty due to potential evapotranspiration is less compared to rainfall variability 4 4 relative input qfd variability in different catchments with changes in gauge numbers the preceding section raises the question of how dense a rain gauge network should be to see an appreciable drop in the potential uncertainty in model inputs to investigate this we estimate the qfd for an increasing number of gridded rainfall fields for each study catchment fig 7 a we note a linear decrease in the qfd in each catchment with an increasing number of rain gauges for instance the richmond catchment has higher rainfall variability compared to the other selected catchments and hence has higher qfd variability with an increasing number of rain gauges qfd decreases linearly fig 7a left panel for the barambah catchment the qfd decreases relatively sharply with an increasing number of rain gauges compared to buchan and seventeen mile catchments the relative proximity of more gauges catchment could be a reason in this case on the other hand in considering the buchan river catchment the qfd variability with an increasing number of gauges is more consistent in comparison to the other case study catchments the qfd variability converges after averaging a certain number of gauges in all of the selected catchments representation of rainfall variability with an increasing number of gauges shows a reduction in the overall estimated uncertainty fig 7a left panel on the contrary input qfd drops sharply with the increase of number of gauges and goes near to zero fig 7a right panel after a representative number of gauges are included in the selected catchment a relatively lesser variability is observed while changing the input variability to potential evapotranspiration with an increasing number of gauges fig 7b however the magnitudes of input qfd due to potential evapotranspiration drops significantly compared to qfd due to rainfall overall with the aid of the qfd framework we are able to illustrate the extent of variability resulting from different model inputs used in the modelling framework 4 5 seasonal variability and input uncertainty understanding seasonal variability in the changing pattern of input uncertainty may have significant implications in engineering design and planning process such as in assessing yields or environmental flow requirements or the quantification of derived flood quantiles here we disaggregate the input quantile flow deviation qfdi metric for the barambah catchment across the four seasons in australia summer december february autumn march may winter june august spring september november fig 8 a as may be expected input qfd is high in summer and low in winter when considered as an absolute value seasonal variability in terms of input qfd is significant in summer and spring followed by autumn and winter low variability of qfd in winter reflects the reduced quantity of rainfall in this part of the year fig 8a most importantly variability is significant in higher percentiles for all four seasons although the summer season shows relatively high contribution of input uncertainty compared to other three seasons it is related to the higher rainfall variability in the same period higher input uncertainty can have implications for extreme events and affect hydrologic design therefore consideration of seasonal variability of input uncertainty in decision making process and evaluating its magnitude is useful on the other hand the relative percentage of total qfd compared to input qfd demonstrates that higher rainfall magnitude does not necessarily suggest a higher proportion of rainfall uncertainty when compared to other uncertain modelling choices fig 8b this might suggest that when seasonal rainfall is high emphasis should be placed on ensuring appropriate model choices rather than correct model inputs depending on the point of the modelling exercise 4 6 comparing rainfall and evapotranspiration variability concurrently as a final analysis we examine the impact of rainfall uncertainty and potential evapotranspiration uncertainty concurrently by holding each model simulation at a single optimised parameter set fig 9 the analysis highlights the lesser importance of variability in potential evapotranspiration when parameter uncertainty is reduced noting that it still contributes to the total variability seen in model simulations 5 discussion uncertainty is unavoidable but at times reducible when developing a modelling exercise for hydrologic analysis and management uncertainties from each of the decision making process steps must be appropriately managed and communicated the model structure related uncertainties are frequently included in the output analysis yet the extent of input uncertainty is less well known and is infrequently accounted for despite the potential for it to have a big impact on hydrologic model output selecting the best possible true input and suitable model structure based on predictive ability is the aim of all modellers but often not realised due to practical constraints taking advantage of strengths of different models is another aspect of uncertainty quantification however for modelling simulation to be as worthwhile as possible we need to take into account the error associated with uncertainty that may exist in the simulated output we would state that a particular innovation of the approach presented in the paper is the consideration of input uncertainty relative to model structure and parameter uncertainty across a range of modelling scenarios this we believe is vital for any water resources planning and engineering design process assuming even greater importance when input uncertainty becomes even larger say when no gauge exists within the catchment at the same time we have demonstrated how the relative contribution of input uncertainty decreases with increasing spatial density in input observations and analysed the seasonal dimension of input uncertainty in the australian context 5 1 input rainfall uncertainty implications in hydrological modelling in this paper with the aid of the qfd metric and gridded data the extent of input uncertainty is evaluated we have investigated through case studies how input uncertainty varies across four different catchments in australia in comparison to other types of modelling uncertainty analysis of the simulated results show that the relative input qfd due to rainfall variability is larger compared to potential evapotranspiration fig 9 when the variability of rainfall and potential evapotranspiration are considered concurrently in the simulation on the other hand input uncertainty due to rainfall uncertainty is higher than parameter uncertainty fig 3a however input uncertainty due to potential evapotranspiration is lower compared to parameter and model structure uncertainty in all the selected catchments fig 3b expressing the relative contribution of different sources of uncertainty reveals the relative importance of inputs as well it is noted that with low gauge density input uncertainty especially for rainfall could be more important for higher flow percentiles fig 5 this is expected as at higher rainfall and corresponding flow magnitude there is a wider range of potential storm observations depending on how a storm moves through a catchment and its relative proximity to a point observation gauge as gauge density increases input uncertainty is becoming more relevant across all flow values fig 6 this demonstrates the extent to which input uncertainty considering both rainfall and potential evapotranspiration is important to characterise for peak flows when only a single gauge is available fig 9 on other hand the relative contribution of input uncertainty varies noticeably in each of the four selected catchments in our study this indicates that we cannot generalise results across different catchments representing different climates and spatial extents it suggests the importance of undertaking a study such as this that allows us to compare and quantify different sources of uncertainty for example when using a single gauge input uncertainty is consistent across higher percentiles and lower percentiles while it increases from lower percentiles to higher percentiles when aggregating information from four gauges fig 6a ii in the case of ten and twenty gauges identical variability of input uncertainty exists across all percentiles in contrast a fairly similar pattern of parameter uncertainty is evident for all percentiles in four different gauges arrangements fig 6a where parameter uncertainty is maximised at the 70th and 80th percentile indicating the model structure and input uncertainty influence the overall uncertainty in different ways the contribution of input uncertainty due to evapotranspiration is less compared to the relative contribution of parameter uncertainty fig 6b and the response of input uncertainty decreases with an increasing number of gauges with respect to catchment response the relative contribution of input uncertainty varies noticeably across the four different selected catchments the seventeen mile catchment and richmond catchment respond similarly to varying input uncertainty compared to the other two catchments fig 5 a linear decrease in total uncertainty is noted with increase in the number of gauges indicating the importance of using all available information fig 7 when modelling flow processes moreover contribution of input qfd for both rainfall fig 7a and potential evapotranspiration fig 7b demonstrates the importance of adopting more gauge data to reduce the uncertainty to a minimum 5 2 the relative contribution of uncertainty and the model observation linkage a principal challenge in hydrologic modelling is defining model sensitivity to uncertainty a key element of this is input uncertainty and strategies can be developed to reduce this uncertainty through proper utilisation of all input information one of the key innovations of the paper was to show how relative contribution of input uncertainty decreases with increasing number of gauge data gridded data considering most hydrological applications pertain to ungauged basins measurements from a single gauge are all that are usually available and often the single gauge may not be centrally located and may even be located outside the watershed bárdossy and das 2008 dawdy and bergmann 1969 faurès et al 1995 mandapaka et al 2009 mcmillan et al 2011 therefore defining input uncertainty is challenging task in these aspects gridded rainfall datasets are an important source of information to evaluate the potential spatial variability in rainfall for modelling applications while such gridded datasets are becoming increasingly available for use in modelling applications care must be taken to also consider the uncertainty they may also contain ignoring this uncertainty can result in a false sense of reliability for the modelled output as is seen in the results obtained here when a single grid is used as a representative rain gauge for the catchment this is all the more important given the use of automated modelling tools that obtain rainfall from external sources where the information on associated uncertainty may not be readily available an important element to consider in this study is that the use of a gridded rainfall product here interpolated and averaged across multiple grid cells may underestimate the true rainfall uncertainty particularly for extreme events tozer et al 2012 this true rainfall uncertainty can be underestimated because the rainfall observations are smoothed in the interpolation procedure used to derive the gridded rainfall nonetheless gridded rainfall data remain a useful surrogate for the potential spectrum of climate variability that will impact a hydrologic modelling study 6 conclusion and further work quantifying uncertainty in hydrologic models is essential for their effective use and assessment the hydrological modelling implication of using gridded rainfall as well as potential evapotranspiration data as a surrogate for gauged data opens the window to evaluate the relative importance of input uncertainty with respect to other sources of uncertainty this study presents a basis to quantify the relative contribution of input uncertainty for both rainfall and potential evapotranspiration with the aid of the qfd metric shoaib et al 2016 and shows the spectrum of input uncertainty with respect to other important sources of uncertainty model structure and parameter in a more logical way the qfd metric applied here provides a straightforward and novel way to explore the relative variability in outputs due to various modelling choices be they different potential model structures different inputs or different parameter sets that may give similar objective function values a particular innovation of the approach presented in the paper is that in this study we take into consideration input uncertainty relative to model structure and parameter uncertainty results presented in this paper show that the relative contribution of input uncertainty due to rainfall is higher compared to evapotranspiration and overall input uncertainty is noteworthy compared to model structure and parameter uncertainty this study also examines the circumstances whereby input uncertainty plays a significant role given similar climatological conditions how input uncertainty affects forecasts in single to multi gauge catchments is also evaluated seasonal catchment dynamics represented through input uncertainty across different percentiles attribute the significance of uncertainty in quantifying flow extremes which are especially relevant in engineering planning and design the limitations of the presented study are attributing extreme events and their extent in the total uncertainty interpolated average grid cells data could underestimate the uncertainty in the simulated output future work will focus on extending the method presented in this paper to consider extreme events and associated uncertainty across the watershed the inference methodology presented here can easily be extended to include additional uncertainty or errors encountered in other modelling scenarios such as those where water quality concentration is of interest acknowledgements this research is supported by australian research council arc award ft20100269 to dr marshall the australian research council arc discovery award dp170103959 and the unsw postgraduate research fund appendix a as detailed in fig a 1 the following simplifications were made to the model configuration adopted in this study a select between three possible upper layer architectures i single state ss ii separate tension storage st iii cascading buckets cb b choose between three possible lower layer architectures i baseflow reservoir of fixed size brfs ii tension reservoir plus two parallel tanks trtpt iii baseflow reservoir of unlimited size frac rate brusfr iv baseflow reservoir of unlimited size power recession bruspr and their associated base flow parameterizations c select between three possible percolation parameterizations i drainage above field capacity dafc ii gravity drainage gd iii saturated zone control szc d select between three possible surface runoff parameterizations i unsaturated zone pareto uzp ii unsaturated zone linear uzl iii saturated zone topographic szt to compute saturated areas and surface runoff e the sequential and root weighting methods for evaporation were applied model selection will be based on one of these options f options of interflow were computed in some model structures at the same time interflow was denied in some model structures g models were run using a daily time step and hence infiltration excess runoff was not computed by any of the models h a gamma distribution was used to route runoff to the basin outlet in all most all cases and some cases considering type of experiment routing could be denied four parent hydrological models topmodel arnoxvic prms sacramento within the fuse framework to represent the full spectrum of potential model variability in the absence of specific information on the catchment hydrologic processes twenty two 22 model parameters represent the hydrological system within fuse clark et al 2008 some of these parameters are inactive depending on the model configuration of interest fig a 1 outlines the model structure that was considered in the simulation results presented appendix b nash sutcliffe efficiency has been presented in the literature for model simulations of discharge and is widely used to assess the predictive power of hydrological models we have undertaken additional analysis considering alternate objective functions to assess how sensitive our findings are to the objective function used as fig b 1 illustrates the change in the proportion of uncertainty by considering additional objective functions is not significant supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2018 01 022 appendix c supplementary materials image application 1 
812,in the color gradient lattice boltzmann model cg lbm a fictitious density wetting boundary condition has been widely used because of its ease of implementation however as we show this may lead to inaccurate results in some cases in this paper a new scheme for the wetting boundary condition is proposed which can handle complicated 3d geometries the validity of our method for static problems is demonstrated by comparing the simulated results to analytical solutions in 2d and 3d geometries with curved boundaries then capillary rise simulations are performed to study dynamic problems where the three phase contact line moves the results are compared to experimental results in the literature heshmati and piri 2014 if a constant contact angle is assumed the simulations agree with the analytical solution based on the lucas washburn equation however to match the experiments we need to implement a dynamic contact angle that varies with the flow rate keywords multiphase flow lattice boltzmann method contact angle wettability capillary rise 1 introduction understanding multiphase flow in porous media is important for several industrial applications such as hydrocarbon recovery and subsurface storage of carbon dioxide in these applications at the pore scale the flow is generally very slow and dominated by capillary forces arising from the interfacial tension between fluid phases under these conditions the displacement of one phase by another is strongly influenced by the wettability of the rock surface to compute multiphase flow properties at the pore scale several direct numerical simulation methods have been developed using the volume of fluid method raeini et al 2015 2012 2014 shams et al 2018 the level set method jettestuen et al 2013 prodanović and bryant 2006 and the lattice boltzmann method lbm boek et al 2017 leclaire et al 2017 ramstad et al 2012 2010 tölke et al 2006 several studies have used the lbm to compute flow through pore space images ahrenholz et al 2008 boek et al 2017 leclaire et al 2017 ramstad et al 2012 2010 in these cases a color gradient cg lbm was used the cg lbm was originally developed by gunstensen et al 1991 and it has been improved since then grunau et al 1993 halliday et al 2007 liu et al 2012 in the cg lbm a fictitious density wetting boundary condition proposed by latva kokko and rothman 2005b is most widely used to represent the contact angle in this boundary condition the solid phase is considered as a mixture of fluid phases for which a fictitious density is assigned however a recent study has shown that this boundary condition can be inaccurate because of unphysical mass transfer along the solid boundary leclaire et al 2017 advances in imaging techniques have made it possible to experimentally investigate two phase displacement processes in rocks at the pore scale recent studies have observed that contact angles vary pore by pore as a result of wettability alteration by the sorption of surface active compounds in crude oil alhammadi et al 2017 alratrout et al 2017 khishvand et al 2017 2016 singh et al 2016 however it is still not fully understood how this surface wettability condition affects oil recovery to investigate these phenomena by direct numerical simulation it is necessary to develop an appropriate wetting boundary condition that can handle realistically complex geometries in 3d while assigning precise contact angles freely as a function of space and time in this paper a new scheme for the wetting boundary condition using the cg lbm is proposed the method can accommodate complicated 3d geometries while precisely controlling the contact angle for both static and dynamic problems this paper is organized as follows first a brief explanation of our cg lbm model in 3d is presented then two wetting boundary conditions i e the fictitious density method and our proposed method are described a static 2d simulation is shown to demonstrate the accuracy of our method by comparing the simulated results to the analytical solution 3d static droplet tests on a flat surface and a curved geometry are also presented for validation for 3d problems finally to investigate the applicability of our method to a dynamic problem in which the three phase contact line moves a capillary rise simulation is presented in this test case a dynamic contact angle implementation is also described and the results are compared with experimental data heshmati and piri 2014 2 methodology 2 1 multiphase lattice boltzmann method our 3d immiscible two phase lattice boltzmann method is based on the color gradient approach proposed by halliday et al 2007 in their work the interfacial tension between two fluids is modeled based on the continuum surface force csf model of brackbill et al 1992 for a d2q9 lattice model the only difference from their model is that we employ a d3q19 lattice model a detailed description of our two phase lattice boltzmann method is given in appendix a 2 2 wetting boundary condition 2 2 1 the fictitious density wetting boundary condition the fictitious density boundary condition was originally proposed by latva kokko and rothman 2005b in this method at solid nodes x s the color function given by eq a 12 is computed using a fictitious density assigned at solid lattice nodes the color function at solid nodes ρn x s takes effect when the color gradient ρn of the flow domain next to the solid node is calculated based on the force balance at the contact line the contact angle θ is expressed as 1 θ arccos ρ n x s since this boundary condition is easy to implement several studies using the cg lbm adopted this approach gunde et al 2013 huang et al 2014 liu et al 2014 ramstad et al 2012 2010 however leclaire et al 2016 showed that this method can be inaccurate because of unphyiscal mass transfer of the wetting phase along the solid we will also demonstrate unphysical mass transfer using this approach and quantify the resultant error in contact angle and capillary pressure 2 2 2 imposing a contact angle directly the basic idea of our wetting boundary condition is to modify the direction of the color gradient ρn at the boundary according to a specified contact angle liu et al 2015 showed an implementation of this wetting boundary condition in the 2d cg lbm their approach is based on the geometrical formulation proposed by ding and spelt 2007 this method accurately simulates wetting phenomena on a flat surface huang et al 2014 li et al 2016 liu et al 2015 and can be extended to 3d yu et al 2017 but the implementation for arbitrary surfaces is not obvious leclaire et al 2017 proposed a way to find the proper direction of the color gradient ρn based on the recurrence relation for the secant method however the recurrence relation would in principle require many iterations which could increase computational costs our wetting boundary condition is similar to the one proposed by xu et al 2017 they proposed a wetting boundary condition for 2d problems in their work the direction of the color gradient ρn is enforced so as to match the prescribed contact angle at the boundary the direction is obtained by rotating the normal vector to the boundary by the contact angle θ using the vector transformation equation in 2d however this algorithm is only applicable to 2d problems our wetting boundary condition is an extension of their method to 3d following the work by leclaire et al 2016 and xu et al 2017 lattice sites are divided into four categories i e cfb a list of lattice sites that belong to the fluid domain and are in contact with at least one lattice site in the solid domain cfl a list of lattice sites that belong to the fluid domain but are not in contact with any lattice sites in the solid domain csb a list of lattice sites that belong to the solid domain and are in contact with at least one lattice site in the fluid domain csl a list of lattice sites that belong to the solid domain but are not in contact with any lattice sites in the fluid domain a schematic image of the wetting boundary condition is shown in fig 1 first to define the direction of the wall boundary the unit normal vector of the boundary n s is calculated for the lattice sites belonging to cfb for complex geometries the method presented in xu et al 2017 can be used because the calculation of the color gradient ρn needs to be performed for all the lattice sites belonging to cfb and cfl by the gradient operator defined by eq a 15 the color function ρn at the nodes belonging to csb is required this is estimated by the extrapolation of the color function at neighboring lattice nodes which belong to cfb by the following lattice weighted average scheme 2 ρ n x t i x e i δ t c f b ω i ρ n x e i δ t t i x e i δ t c f b ω i x c s b with the values of ρn at the nodes belonging to csb it is possible to estimate the color gradient ρn for the lattice nodes in cfl this estimated value is denoted as ρ n in the next step the direction of ρ n is modified to match the prescribed contact angle against the wall boundary while keeping the norm of ρ n unchanged the direction of ρ n is given by 3 n ρ n ρ n the unit vector n is understood as the estimated unit normal vector to the red and blue fluid interface at the wall boundary x cfb in the modification step the direction of the color gradient is modified in accordance with the prescribed contact angle θ in the 2d problem xu et al 2017 proposed a vector transformation that rotates n s by the angle θ however in the 3d problem the normal vector that forms an angle θ to n s makes a circle around n s we adopted the method employed in the openfoam finite volume library openfoam 2016 shams et al 2018 in fig 1 two contact lines points in 2d are shown for each contact line there are two possible unit vectors making an angle θ with n s i e the unit vector n which is rotated by an angle θ in a counter clockwise direction from n s and the unit vector n which is rotated by an angle θ in a clockwise direction from n s these two unit vectors n are obtained by the linear combination of n s and n as 4 n cos θ sin θ cos θ sin θ n s sin θ sin θ n θ arccos n s n the euclidean distances between n and n are evaluated then n is replaced with either n or n which has the shorter euclidean distance to n for instance at the left contact line in fig 1 n is replaced with n whereas at the right contact line n is replaced with n with this the modified interface normal vector falls into the plane spanned by the unit vectors n and n s note that up to this point the contact angle is defined as the angle measured through the red fluid to be consistent with the previous literature for instance latva kokko and rothman 2005b however from the next section we refer to the contact angle as the angle measured through the blue fluid since the blue fluid typically represents the denser water phase 3 results and discussion 3 1 2d static contact angle test to investigate the difference in accuracy between the fictitious density boundary condition and our method a 2d static contact angle test is conducted the equilibrium distributions of wetting and non wetting fluid placed in a 2d capillary slit are investigated the simulations are performed in a 2d domain with a mesh containing 101 301 lattice nodes solid walls are placed on both upper and lower boundaries and periodic boundary conditions are applied for both left and right boundaries as shown in fig 2 a blue fluid is initially placed in the center of the domain and red fluid is placed in the rest of the domain the prescribed contact angle varies from 30 to 150 for both the fictitious density boundary condition and our boundary condition the other parameters are fixed as σ 0 1 ρ 0 ρ r ρ b 1 0 β 0 7 and τ r τ b 1 0 the simulations are conducted for 200 000 time steps to achieve an equilibrium state fig 2b then the simulated contact angle is evaluated using the following geometrical relation 5 θ π 2 2 arctan h r where θ is the contact angle r is the half width of the capillary slit and h is the height of the non wetting fluid measured from the contact line point in 2d as shown in fig 2c the comparison between the prescribed contact angle and the resultant simulated contact angle for both wetting boundary conditions is shown in fig 3 to quantify the error between an analytical value x 0 and a simulated value xsim the relative error e x is defined by 6 e x x s i m x 0 x 0 our method shows an excellent agreement between the prescribed and simulated contact angle for the entire range of values with a maximum relative error of e θ 1 5 for θ 30 whereas the fictitious density boundary condition shows a discrepancy especially for contact angles close to 0 and 180 with a maximum relative error of e θ 34 1 for θ 30 fig 4 shows a zoomed in view of the color function around the three phase contact line point in 2d for a 30 prescribed contact angle for the fictitious density boundary condition the interface moves along the wall boundary this unphysical mass transfer of wetting phase makes the simulated contact angle inaccurate we further compare the simulated capillary pressure pc for both wetting boundary conditions the average pressure for each phase is calculated and then the capillary pressure is obtained from the difference because of the inaccuracy in the simulated contact angle the results obtained using the fictitious density boundary condition show a discrepancy from the analytically evaluated capillary pressure with a maximum relative error of e p c 47 5 for θ 120 whereas our method shows an excellent agreement with a maximum relative error of e p c 1 1 for θ 30 fig 5 fig 6 shows the fluid velocity distribution around the three phase contact line with a 60 prescribed contact angle in these figures the fluid fluid interface is indicated by the yellow line and velocity vectors are color coded based on their magnitude vectors whose magnitude is below 10 5 lu ts lattice units per time step are shown in black and vectors above 10 3 lu ts are shown in white in both cases an unphysical spurious current persists around the three phase contact line with our method the spurious current around the three phase contact line is on the order of 10 5 to 10 3 lu ts and the velocity further away is less than 10 5 lu ts in contrast with the fictitious density boundary condition the magnitude of spurious velocity around the three phase contact line is greater than 10 3 lu ts table 1 summarizes the comparison of the static contact angle estimation capillary pressure estimation and the magnitude of the maximum spurious current for both boundary conditions it can be concluded that our method gives a more accurate estimation for both contact angle and capillary pressure with lower spurious velocity compared to the fictitious density boundary condition as we show later these features are important when we consider slow flows where capillary forces are significant 3 2 3d static droplet test to demonstrate the applicability of our wetting boundary condition to a 3d problem a static droplet test in a 3d domain is performed the simulation domain is composed of a mesh consisting of 101 101 101 lattice nodes solid walls are placed on the upper and lower boundaries and periodic boundary conditions are applied for all other boundaries initially a semi spherical shape with a radius of 20 lattice units of the red phase is placed on the lower wall the prescribed contact angle varies from 30 to 150 simulations are conducted until they reach equilibrium conditions 500 000 ts the shapes of the droplet at equilibrium for simulations for different prescribed contact angles are shown in fig 7 based on the shape of the droplet the simulated contact angle is obtained and compared with the prescribed contact angle fig 8 as shown in the figure an excellent agreement with the maximum relative error of e θ 2 3 for θ 60 is also observed for this 3d test case 3 3 3d static droplet placed on a curved geometry in this section we validate our method on a 3d surface with a curved geometry the shape of a red droplet with a radius of curvature r 1 placed on a spherical solid object with radius r 2 can be obtained analytically as shown in fig 9 the simulation domain is composed of a mesh consisting of 101 101 101 lattice nodes a spherical solid object occupies the following region 7 x 50 2 y 50 2 z 30 2 r 2 2 where r 2 is the radius of spherical solid object that is fixed at 40 lattice units the simulations are conducted for contact angles θ 60 and θ 120 initially a known volume of red fluid is placed around the solid object occupying part of a sphere so that the radius of curvature of the red fluid r 1 in equilibrium is 22 5 lattice units the rest of the domain is filled with blue fluid analytical solutions are obtained by calculating r 3 from θ r 1 and r 2 the simulations are conducted until they reach an equilibrium state 30 000 time steps fig 10 shows the results of the simulations in which the analytical solution is shown by the white dotted lines the equilibrium droplet shape agrees with the analytical solution for both θ 60 and θ 120 3 4 capillary rise simulation our boundary condition allows us to modify the direction of the color gradient at the wall boundary according to the prescribed contact angle at each time step therefore at every time step it is possible to assign different contact angles this is particularly useful when we investigate a dynamic contact angle problem as an example capillary rise simulations are conducted capillary rise is a phenomenon in which a dense wetting fluid imbibes up a capillary tube until equilibrium between the capillary force and the gravitational force is achieved washburn first modeled this behavior and proposed an analytical solution washburn 1921 he assumed a constant contact angle however the contact angle during capillary rise does change there have been several experiments that have measured the dynamic contact angles as a function of capillary number for instance hamraoui and nylander 2002 hoffman 1975 rillaerts and joos 1980 in this section we refer to heshmati and piri 2014 s experiment they observed the change of dynamic contact angle during capillary rise with high speed cameras they performed three experiments using an air water system in a glass tube with an internal diameter of 0 75 mm 1 0 mm and 1 3 mm we define a bond number by 8 b o δ ρ g r 2 σ where δρ is the difference in density g is the gravitational acceleration σ is the interfacial tension between two fluids and r is the characteristic length this length r is the tube radius in 3d or the slit width in 2d we also define a capillary number by 9 c a μ w u σ where μw is the dynamic viscosity of water and u is the velocity of the fluid fluid interface the fluid properties and bond numbers corresponding to each diameter of capillary tube are shown in table 2 fig 11 a shows the rise as a function of time and 11b shows the measured dynamic contact angle as a function of capillary number for the three experimental cases sheng and zhou 1992 showed that the relationship between dynamic contact angle and capillary number is approximated well by 10 cos θ d cos θ s c a log k l l s where θs and θd are the static and dynamic contact angle respectively ca is the capillary number k is a constant l is characteristic length and ls is the slip length through least squares fitting of eq 10 to the experimental data θ s 5 59 and log k l l s 39 37 are obtained as shown by the black line in fig 11b in the literature capillary rise simulations using the lattice boltzmann method have been performed latva kokko and rothman 2005b raiskinmäki et al 2002 wolf et al 2010 these simulations considered bond numbers b o 10 1 10 0 based on the definition of eq 8 whereas our simulations are performed using b o 10 2 to compare with the experimental data directly hence compared to previous work the capillary force in our simulations is stronger compared to gravitational effects the other key difference is that the experimentally measured dynamic contact angle is used in our simulations our lbm simulations are conducted for capillary rise in a 2d slit to save computation time and to avoid errors associated with the discretization of the circular cross section of a 3d capillary tube assuming laminar flow of an incompressible newtonian fluids and constant contact angle the capillary rise is analytically described by the lucas washburn equation hamraoui and nylander 2002 11 a t h t h e ln 1 h t h e h e 2 σ cos θ ρ g r a ρ g r 2 k μ where r is a characteristic length for the problem and k is a dimensionless flow conductance k 8 for the 3d capillary tube and k 12 for the 2d capillary slit using the following non dimensional quantities 12 t ρ g r k μ t h 1 r h b o ρ g r 2 σ eq 11 can be rewritten as 13 b o 2 cos θ t b o 2 cos θ h ln 1 b o 2 cos θ h based on this equation we compare our simulation results with heshmati and piri 2014 s experimental data first capillary rise simulations with the constant contact angle implementation are performed in the simulations red and blue fluid represent air and water respectively a 2d capillary slit with a width of 21 lattice units and 3000 lattice units in length is used densities of both red and blue fluids are set at ρ 0 ρ r ρ b 1 0 but the body force is only applied to the blue fluid by adjusting the magnitude of the body force the three bond numbers corresponding to the experiments are considered the relaxation times for the red and blue fluids are set at τ r 0 51 and τ b 1 0 which gives a viscosity ratio similar to the experimental conditions m μ w a t e r μ a i r 50 initially the domain is fully filled with air and water is placed at the inlet with a constant pressure boundary condition p i n l e t p b p 0 the outlet boundary is also controlled by a constant pressure boundary condition p o u t l e t p r p 0 since heshmati and piri 2014 used a high speed camera with a large field of view to detect the position of the meniscus and time stamp the images there is experimental uncertainty in the determination of the start time corresponding to the frame speed of the camera considering this a time shift is applied to the experimental data points so that the first measured time coincides with the simulated time at the first measured height this results in 7 ms of time shift for the experiment with a 0 75 mm capillary tube 5 7 ms for the 1 0 mm capillary tube and 13 ms for the 1 3 mm capillary tube fig 12 shows the simulation results experimental results and analytical predictions based on the lucas washburn equation with a constant contact angle θ s 5 59 the lbm simulations show a good agreement with the analytical prediction by the lucas washburn equation but both of them show a faster rise compared to the experimental data especially in the early time region t 20 next simulations with the dynamic contact angle implementation are conducted at every time step the capillary number is computed based on the average velocity of the moving interface the dynamic contact angle to be imposed as a wetting boundary condition is obtained from eq 10 with θ s 5 59 and log k l l s 39 37 the simulation results are shown in fig 13 compared to the constant contact angle implementation the simulation results are shifted downward and they show good agreement with the experiments albeit with a slight difference in the early time region for the case of b o 5 7 10 3 abu al saud et al 2017 showed a comparison to heshmati and piri 2014 s capillary rise experiment conducted with an air soltrol 170 system in a glass tube with a tube diameter of 1 3 mm using the level set method the dynamic contact angle in their model is implemented based on the cox voinov model cox 1986 voinov 1977 their simulations showed good agreement with the trend of measured rise height with a slight difference in the early time region which is also observed in our simulation they suggested that this discrepancy was due to inertial effects fig 14 shows a comparison between the prescribed contact angle and the resultant simulated contact angle during the capillary rise simulations for both the constant imposed angle and the dynamic angle implementation the simulated contact angles agree with the prescribed values for a wide range of capillary number 10 6 c a 10 2 4 conclusions we have tested a new implementation of the wetting boundary condition in the cg lbm framework our wetting boundary condition changes the direction of the color gradient according to the prescribed contact angle and it can be applied to 2d and 3d geometries therefore it is suitable for studying multiphase flow in porous media which will be the subject of future work using the 2d static contact angle test case the difference in accuracy between the traditional fictitious density wetting boundary condition and our wetting boundary condition was investigated when the widely applied fictitious density boundary condition was used because of the unphysical mass transfer along the wall boundary the simulated contact angle deviated from the prescribed contact angle for contact angles both greater and smaller than 90 this deviation resulted in an inaccurate estimation of capillary pressure in contrast when our wetting boundary condition was applied the simulated contact angle and capillary pressure were accurately simulated in addition our boundary condition gave smaller spurious currents around the three phase contact line than the fictitious density boundary condition moreover we demonstrated that the model worked for a 3d test case of a static droplet on a flat surface and on a curved surface to study the applicability of our method to the dynamic problem where the interface and three phase contact line move capillary rise simulations were conducted the simulations were performed with bond numbers of order 10 2 to make a direct comparison with previously published experimental data heshmati and piri 2014 for the constant contact angle implementation the simulated results agreed with the analytical prediction using the lucas washburn equation this suggests that the balance between capillary and gravitational forces is properly modeled in our model then we demonstrated an implementation of a dynamic contact angle which changes the prescribed contact angle at every time step dependent on the capillary number the simulated results showed good agreement with the experimental data for both the constant and dynamic contact angle implementation the simulated contact angles corresponded to the prescribed values this suggests that our method precisely controls contact angle for dynamic problems regardless of the fluid velocity acknowledgment this work is financially supported by japan oil gas and metals national corporation jogmec appendix a multiphase lattice boltzmann method for the d3q19 lattice model the lattice velocity is given as follows a 1 e i 0 0 0 for i 0 1 0 0 c 0 1 0 c 0 0 1 c for i 1 6 1 1 0 c 1 0 1 c 0 1 1 c for i 7 18 where c δx δt is the lattice speed with δx being the lattice length and δt the time step size for simplicity we set δ x δ t 1 the geometry of the d319q lattice model can be found in for instance hecht and harting 2010 we consider two immiscible fluids labeled red and blue the particle distributions of the fluids at position x and time t are denoted as f i r x t and f i b x t the total particle distribution is given by f i f i r f i b the density of fluid k is given by the first moment of the particle distribution functions a 2 ρ k i f i k x t k r or b the fluid velocity u is obtained from the second moment of the particle distribution a 3 ρ u i f i x t e i where ρ is the total fluid density given by ρ ρ r ρ b the total particle distribution undergoes collisions as a 4 f i x t f i x t ω i x t ϕ i where f i is the post collision total particle distribution ωi is the collision operator which is responsible for the relaxation of the moments towards local equilibrium and ϕi is the source term and has the effect of introducing a body force in the fluid in our model the bhatnagar gross krook bgk collision operator qian et al 1992 is used a 5 ω i 1 τ f i f i e q where τ is the single relaxation time srt and f i e q is the equilibrium distribution function which is obtained by a second order taylor expansion of the maxwell boltzmann distribution with respect to the local fluid velocity u a 6 f i e q ρ ω i 1 e i u c s 2 e i u 2 2 c s 4 u 2 2 c s 2 where cs is the speed of sound and ωi is the weight coefficient which is given by a 7 ω i 1 3 for i 0 1 18 for i 1 6 1 36 for i 7 18 through the chapman enskog expansion analysis of the total particle distribution fi it is confirmed that the collision operator recovers the continuity equation and the navier stokes equation where the following relations are obtained a 8 ν k 1 3 τ k 1 2 k r or b a 9 c s 1 3 c a 10 p ρ c s 2 ρ 3 where νk is the kinetic viscosity of fluid k and p is the hydrodynamic pressure in the fluid in the interface region the relaxation time in eq a 5 is determined by the harmonic average of the viscosity of the fluids a 11 1 ν ρ r ρ r ρ b 1 ν r ρ b ρ r ρ b 1 ν b τ 3 ν 1 2 the interfacial force is modeled by introducing the body force f at the interface of two fluids to trace the fluid interface a color function ρn is defined as a 12 ρ n x t ρ r x t ρ b x t ρ r x t ρ b x t 1 ρ n 1 based on the continuum surface force csf the body force can be expressed as brackbill et al 1992 a 13 f 1 2 σ κ ρ n where ρn is the gradient of color function ρn and it is called the color gradient σ is the interfacial tension and κ is the curvature of the interface which can be calculated by a 14 κ i n n n where n is the unit normal vector defined by n ρ n ρ n in eqs a 13 and a 14 the partial derivatives are calculated using an isotropic finite difference scheme a 15 ψ x x α 3 c 2 i ω i ψ x e i e i α where ψ is any function the calculated body force f which is spatially varying can be imposed through the source term in eq a 4 by the following equation guo et al 2002 a 16 ϕ i ω i 1 1 2 τ 3 e i u 9 e i u e i f where u is the redefined fluid velocity to account for the influence of the spatially varying body force which is given by a 17 u 1 ρ i f i e i 1 2 f although the body force generates the interfacial force at the interface it does not guarantee the immiscibility of the fluids to ensure phase segregation and maintain the sharpness of the interface the recoloring scheme proposed by latva kokko and rothman 2005a is used a 18 f i r ρ r ρ f β ρ r ρ b ρ ω i c o s φ e i f i b ρ b ρ f β ρ r ρ b ρ ω i c o s φ e i where β is the segregation parameter which can take a value in 0 1 and φ is the angle between the color gradient and the lattice vector which can be obtained by a 19 c o s φ e i ρ n e i ρ n after the recoloring step the particle distribution functions stream to the neighboring lattice by a 20 f i k x e i δ t t δ t f i k x t k r or b we briefly describe the boundary conditions used in the paper except for the wetting boundary condition which is described in detail in the main text at the solid boundary the full way bounce back scheme is applied in this scheme the particle distributions at boundary lattice nodes are bounced back into flow domain instead of performing the collision step this is written as a 21 f i k x t f i k x t k r or b where f i k is the distribution function in the opposite direction to e i as for the inlet and outlet boundaries a periodic boundary condition and a constant pressure boundary condition respectively are used in this paper for the periodic boundary condition the outgoing particle distribution from the outlet is re entered into the flow domain from the inlet for the constant pressure boundary condition the method proposed by zou and he 1997 is used 
812,in the color gradient lattice boltzmann model cg lbm a fictitious density wetting boundary condition has been widely used because of its ease of implementation however as we show this may lead to inaccurate results in some cases in this paper a new scheme for the wetting boundary condition is proposed which can handle complicated 3d geometries the validity of our method for static problems is demonstrated by comparing the simulated results to analytical solutions in 2d and 3d geometries with curved boundaries then capillary rise simulations are performed to study dynamic problems where the three phase contact line moves the results are compared to experimental results in the literature heshmati and piri 2014 if a constant contact angle is assumed the simulations agree with the analytical solution based on the lucas washburn equation however to match the experiments we need to implement a dynamic contact angle that varies with the flow rate keywords multiphase flow lattice boltzmann method contact angle wettability capillary rise 1 introduction understanding multiphase flow in porous media is important for several industrial applications such as hydrocarbon recovery and subsurface storage of carbon dioxide in these applications at the pore scale the flow is generally very slow and dominated by capillary forces arising from the interfacial tension between fluid phases under these conditions the displacement of one phase by another is strongly influenced by the wettability of the rock surface to compute multiphase flow properties at the pore scale several direct numerical simulation methods have been developed using the volume of fluid method raeini et al 2015 2012 2014 shams et al 2018 the level set method jettestuen et al 2013 prodanović and bryant 2006 and the lattice boltzmann method lbm boek et al 2017 leclaire et al 2017 ramstad et al 2012 2010 tölke et al 2006 several studies have used the lbm to compute flow through pore space images ahrenholz et al 2008 boek et al 2017 leclaire et al 2017 ramstad et al 2012 2010 in these cases a color gradient cg lbm was used the cg lbm was originally developed by gunstensen et al 1991 and it has been improved since then grunau et al 1993 halliday et al 2007 liu et al 2012 in the cg lbm a fictitious density wetting boundary condition proposed by latva kokko and rothman 2005b is most widely used to represent the contact angle in this boundary condition the solid phase is considered as a mixture of fluid phases for which a fictitious density is assigned however a recent study has shown that this boundary condition can be inaccurate because of unphysical mass transfer along the solid boundary leclaire et al 2017 advances in imaging techniques have made it possible to experimentally investigate two phase displacement processes in rocks at the pore scale recent studies have observed that contact angles vary pore by pore as a result of wettability alteration by the sorption of surface active compounds in crude oil alhammadi et al 2017 alratrout et al 2017 khishvand et al 2017 2016 singh et al 2016 however it is still not fully understood how this surface wettability condition affects oil recovery to investigate these phenomena by direct numerical simulation it is necessary to develop an appropriate wetting boundary condition that can handle realistically complex geometries in 3d while assigning precise contact angles freely as a function of space and time in this paper a new scheme for the wetting boundary condition using the cg lbm is proposed the method can accommodate complicated 3d geometries while precisely controlling the contact angle for both static and dynamic problems this paper is organized as follows first a brief explanation of our cg lbm model in 3d is presented then two wetting boundary conditions i e the fictitious density method and our proposed method are described a static 2d simulation is shown to demonstrate the accuracy of our method by comparing the simulated results to the analytical solution 3d static droplet tests on a flat surface and a curved geometry are also presented for validation for 3d problems finally to investigate the applicability of our method to a dynamic problem in which the three phase contact line moves a capillary rise simulation is presented in this test case a dynamic contact angle implementation is also described and the results are compared with experimental data heshmati and piri 2014 2 methodology 2 1 multiphase lattice boltzmann method our 3d immiscible two phase lattice boltzmann method is based on the color gradient approach proposed by halliday et al 2007 in their work the interfacial tension between two fluids is modeled based on the continuum surface force csf model of brackbill et al 1992 for a d2q9 lattice model the only difference from their model is that we employ a d3q19 lattice model a detailed description of our two phase lattice boltzmann method is given in appendix a 2 2 wetting boundary condition 2 2 1 the fictitious density wetting boundary condition the fictitious density boundary condition was originally proposed by latva kokko and rothman 2005b in this method at solid nodes x s the color function given by eq a 12 is computed using a fictitious density assigned at solid lattice nodes the color function at solid nodes ρn x s takes effect when the color gradient ρn of the flow domain next to the solid node is calculated based on the force balance at the contact line the contact angle θ is expressed as 1 θ arccos ρ n x s since this boundary condition is easy to implement several studies using the cg lbm adopted this approach gunde et al 2013 huang et al 2014 liu et al 2014 ramstad et al 2012 2010 however leclaire et al 2016 showed that this method can be inaccurate because of unphyiscal mass transfer of the wetting phase along the solid we will also demonstrate unphysical mass transfer using this approach and quantify the resultant error in contact angle and capillary pressure 2 2 2 imposing a contact angle directly the basic idea of our wetting boundary condition is to modify the direction of the color gradient ρn at the boundary according to a specified contact angle liu et al 2015 showed an implementation of this wetting boundary condition in the 2d cg lbm their approach is based on the geometrical formulation proposed by ding and spelt 2007 this method accurately simulates wetting phenomena on a flat surface huang et al 2014 li et al 2016 liu et al 2015 and can be extended to 3d yu et al 2017 but the implementation for arbitrary surfaces is not obvious leclaire et al 2017 proposed a way to find the proper direction of the color gradient ρn based on the recurrence relation for the secant method however the recurrence relation would in principle require many iterations which could increase computational costs our wetting boundary condition is similar to the one proposed by xu et al 2017 they proposed a wetting boundary condition for 2d problems in their work the direction of the color gradient ρn is enforced so as to match the prescribed contact angle at the boundary the direction is obtained by rotating the normal vector to the boundary by the contact angle θ using the vector transformation equation in 2d however this algorithm is only applicable to 2d problems our wetting boundary condition is an extension of their method to 3d following the work by leclaire et al 2016 and xu et al 2017 lattice sites are divided into four categories i e cfb a list of lattice sites that belong to the fluid domain and are in contact with at least one lattice site in the solid domain cfl a list of lattice sites that belong to the fluid domain but are not in contact with any lattice sites in the solid domain csb a list of lattice sites that belong to the solid domain and are in contact with at least one lattice site in the fluid domain csl a list of lattice sites that belong to the solid domain but are not in contact with any lattice sites in the fluid domain a schematic image of the wetting boundary condition is shown in fig 1 first to define the direction of the wall boundary the unit normal vector of the boundary n s is calculated for the lattice sites belonging to cfb for complex geometries the method presented in xu et al 2017 can be used because the calculation of the color gradient ρn needs to be performed for all the lattice sites belonging to cfb and cfl by the gradient operator defined by eq a 15 the color function ρn at the nodes belonging to csb is required this is estimated by the extrapolation of the color function at neighboring lattice nodes which belong to cfb by the following lattice weighted average scheme 2 ρ n x t i x e i δ t c f b ω i ρ n x e i δ t t i x e i δ t c f b ω i x c s b with the values of ρn at the nodes belonging to csb it is possible to estimate the color gradient ρn for the lattice nodes in cfl this estimated value is denoted as ρ n in the next step the direction of ρ n is modified to match the prescribed contact angle against the wall boundary while keeping the norm of ρ n unchanged the direction of ρ n is given by 3 n ρ n ρ n the unit vector n is understood as the estimated unit normal vector to the red and blue fluid interface at the wall boundary x cfb in the modification step the direction of the color gradient is modified in accordance with the prescribed contact angle θ in the 2d problem xu et al 2017 proposed a vector transformation that rotates n s by the angle θ however in the 3d problem the normal vector that forms an angle θ to n s makes a circle around n s we adopted the method employed in the openfoam finite volume library openfoam 2016 shams et al 2018 in fig 1 two contact lines points in 2d are shown for each contact line there are two possible unit vectors making an angle θ with n s i e the unit vector n which is rotated by an angle θ in a counter clockwise direction from n s and the unit vector n which is rotated by an angle θ in a clockwise direction from n s these two unit vectors n are obtained by the linear combination of n s and n as 4 n cos θ sin θ cos θ sin θ n s sin θ sin θ n θ arccos n s n the euclidean distances between n and n are evaluated then n is replaced with either n or n which has the shorter euclidean distance to n for instance at the left contact line in fig 1 n is replaced with n whereas at the right contact line n is replaced with n with this the modified interface normal vector falls into the plane spanned by the unit vectors n and n s note that up to this point the contact angle is defined as the angle measured through the red fluid to be consistent with the previous literature for instance latva kokko and rothman 2005b however from the next section we refer to the contact angle as the angle measured through the blue fluid since the blue fluid typically represents the denser water phase 3 results and discussion 3 1 2d static contact angle test to investigate the difference in accuracy between the fictitious density boundary condition and our method a 2d static contact angle test is conducted the equilibrium distributions of wetting and non wetting fluid placed in a 2d capillary slit are investigated the simulations are performed in a 2d domain with a mesh containing 101 301 lattice nodes solid walls are placed on both upper and lower boundaries and periodic boundary conditions are applied for both left and right boundaries as shown in fig 2 a blue fluid is initially placed in the center of the domain and red fluid is placed in the rest of the domain the prescribed contact angle varies from 30 to 150 for both the fictitious density boundary condition and our boundary condition the other parameters are fixed as σ 0 1 ρ 0 ρ r ρ b 1 0 β 0 7 and τ r τ b 1 0 the simulations are conducted for 200 000 time steps to achieve an equilibrium state fig 2b then the simulated contact angle is evaluated using the following geometrical relation 5 θ π 2 2 arctan h r where θ is the contact angle r is the half width of the capillary slit and h is the height of the non wetting fluid measured from the contact line point in 2d as shown in fig 2c the comparison between the prescribed contact angle and the resultant simulated contact angle for both wetting boundary conditions is shown in fig 3 to quantify the error between an analytical value x 0 and a simulated value xsim the relative error e x is defined by 6 e x x s i m x 0 x 0 our method shows an excellent agreement between the prescribed and simulated contact angle for the entire range of values with a maximum relative error of e θ 1 5 for θ 30 whereas the fictitious density boundary condition shows a discrepancy especially for contact angles close to 0 and 180 with a maximum relative error of e θ 34 1 for θ 30 fig 4 shows a zoomed in view of the color function around the three phase contact line point in 2d for a 30 prescribed contact angle for the fictitious density boundary condition the interface moves along the wall boundary this unphysical mass transfer of wetting phase makes the simulated contact angle inaccurate we further compare the simulated capillary pressure pc for both wetting boundary conditions the average pressure for each phase is calculated and then the capillary pressure is obtained from the difference because of the inaccuracy in the simulated contact angle the results obtained using the fictitious density boundary condition show a discrepancy from the analytically evaluated capillary pressure with a maximum relative error of e p c 47 5 for θ 120 whereas our method shows an excellent agreement with a maximum relative error of e p c 1 1 for θ 30 fig 5 fig 6 shows the fluid velocity distribution around the three phase contact line with a 60 prescribed contact angle in these figures the fluid fluid interface is indicated by the yellow line and velocity vectors are color coded based on their magnitude vectors whose magnitude is below 10 5 lu ts lattice units per time step are shown in black and vectors above 10 3 lu ts are shown in white in both cases an unphysical spurious current persists around the three phase contact line with our method the spurious current around the three phase contact line is on the order of 10 5 to 10 3 lu ts and the velocity further away is less than 10 5 lu ts in contrast with the fictitious density boundary condition the magnitude of spurious velocity around the three phase contact line is greater than 10 3 lu ts table 1 summarizes the comparison of the static contact angle estimation capillary pressure estimation and the magnitude of the maximum spurious current for both boundary conditions it can be concluded that our method gives a more accurate estimation for both contact angle and capillary pressure with lower spurious velocity compared to the fictitious density boundary condition as we show later these features are important when we consider slow flows where capillary forces are significant 3 2 3d static droplet test to demonstrate the applicability of our wetting boundary condition to a 3d problem a static droplet test in a 3d domain is performed the simulation domain is composed of a mesh consisting of 101 101 101 lattice nodes solid walls are placed on the upper and lower boundaries and periodic boundary conditions are applied for all other boundaries initially a semi spherical shape with a radius of 20 lattice units of the red phase is placed on the lower wall the prescribed contact angle varies from 30 to 150 simulations are conducted until they reach equilibrium conditions 500 000 ts the shapes of the droplet at equilibrium for simulations for different prescribed contact angles are shown in fig 7 based on the shape of the droplet the simulated contact angle is obtained and compared with the prescribed contact angle fig 8 as shown in the figure an excellent agreement with the maximum relative error of e θ 2 3 for θ 60 is also observed for this 3d test case 3 3 3d static droplet placed on a curved geometry in this section we validate our method on a 3d surface with a curved geometry the shape of a red droplet with a radius of curvature r 1 placed on a spherical solid object with radius r 2 can be obtained analytically as shown in fig 9 the simulation domain is composed of a mesh consisting of 101 101 101 lattice nodes a spherical solid object occupies the following region 7 x 50 2 y 50 2 z 30 2 r 2 2 where r 2 is the radius of spherical solid object that is fixed at 40 lattice units the simulations are conducted for contact angles θ 60 and θ 120 initially a known volume of red fluid is placed around the solid object occupying part of a sphere so that the radius of curvature of the red fluid r 1 in equilibrium is 22 5 lattice units the rest of the domain is filled with blue fluid analytical solutions are obtained by calculating r 3 from θ r 1 and r 2 the simulations are conducted until they reach an equilibrium state 30 000 time steps fig 10 shows the results of the simulations in which the analytical solution is shown by the white dotted lines the equilibrium droplet shape agrees with the analytical solution for both θ 60 and θ 120 3 4 capillary rise simulation our boundary condition allows us to modify the direction of the color gradient at the wall boundary according to the prescribed contact angle at each time step therefore at every time step it is possible to assign different contact angles this is particularly useful when we investigate a dynamic contact angle problem as an example capillary rise simulations are conducted capillary rise is a phenomenon in which a dense wetting fluid imbibes up a capillary tube until equilibrium between the capillary force and the gravitational force is achieved washburn first modeled this behavior and proposed an analytical solution washburn 1921 he assumed a constant contact angle however the contact angle during capillary rise does change there have been several experiments that have measured the dynamic contact angles as a function of capillary number for instance hamraoui and nylander 2002 hoffman 1975 rillaerts and joos 1980 in this section we refer to heshmati and piri 2014 s experiment they observed the change of dynamic contact angle during capillary rise with high speed cameras they performed three experiments using an air water system in a glass tube with an internal diameter of 0 75 mm 1 0 mm and 1 3 mm we define a bond number by 8 b o δ ρ g r 2 σ where δρ is the difference in density g is the gravitational acceleration σ is the interfacial tension between two fluids and r is the characteristic length this length r is the tube radius in 3d or the slit width in 2d we also define a capillary number by 9 c a μ w u σ where μw is the dynamic viscosity of water and u is the velocity of the fluid fluid interface the fluid properties and bond numbers corresponding to each diameter of capillary tube are shown in table 2 fig 11 a shows the rise as a function of time and 11b shows the measured dynamic contact angle as a function of capillary number for the three experimental cases sheng and zhou 1992 showed that the relationship between dynamic contact angle and capillary number is approximated well by 10 cos θ d cos θ s c a log k l l s where θs and θd are the static and dynamic contact angle respectively ca is the capillary number k is a constant l is characteristic length and ls is the slip length through least squares fitting of eq 10 to the experimental data θ s 5 59 and log k l l s 39 37 are obtained as shown by the black line in fig 11b in the literature capillary rise simulations using the lattice boltzmann method have been performed latva kokko and rothman 2005b raiskinmäki et al 2002 wolf et al 2010 these simulations considered bond numbers b o 10 1 10 0 based on the definition of eq 8 whereas our simulations are performed using b o 10 2 to compare with the experimental data directly hence compared to previous work the capillary force in our simulations is stronger compared to gravitational effects the other key difference is that the experimentally measured dynamic contact angle is used in our simulations our lbm simulations are conducted for capillary rise in a 2d slit to save computation time and to avoid errors associated with the discretization of the circular cross section of a 3d capillary tube assuming laminar flow of an incompressible newtonian fluids and constant contact angle the capillary rise is analytically described by the lucas washburn equation hamraoui and nylander 2002 11 a t h t h e ln 1 h t h e h e 2 σ cos θ ρ g r a ρ g r 2 k μ where r is a characteristic length for the problem and k is a dimensionless flow conductance k 8 for the 3d capillary tube and k 12 for the 2d capillary slit using the following non dimensional quantities 12 t ρ g r k μ t h 1 r h b o ρ g r 2 σ eq 11 can be rewritten as 13 b o 2 cos θ t b o 2 cos θ h ln 1 b o 2 cos θ h based on this equation we compare our simulation results with heshmati and piri 2014 s experimental data first capillary rise simulations with the constant contact angle implementation are performed in the simulations red and blue fluid represent air and water respectively a 2d capillary slit with a width of 21 lattice units and 3000 lattice units in length is used densities of both red and blue fluids are set at ρ 0 ρ r ρ b 1 0 but the body force is only applied to the blue fluid by adjusting the magnitude of the body force the three bond numbers corresponding to the experiments are considered the relaxation times for the red and blue fluids are set at τ r 0 51 and τ b 1 0 which gives a viscosity ratio similar to the experimental conditions m μ w a t e r μ a i r 50 initially the domain is fully filled with air and water is placed at the inlet with a constant pressure boundary condition p i n l e t p b p 0 the outlet boundary is also controlled by a constant pressure boundary condition p o u t l e t p r p 0 since heshmati and piri 2014 used a high speed camera with a large field of view to detect the position of the meniscus and time stamp the images there is experimental uncertainty in the determination of the start time corresponding to the frame speed of the camera considering this a time shift is applied to the experimental data points so that the first measured time coincides with the simulated time at the first measured height this results in 7 ms of time shift for the experiment with a 0 75 mm capillary tube 5 7 ms for the 1 0 mm capillary tube and 13 ms for the 1 3 mm capillary tube fig 12 shows the simulation results experimental results and analytical predictions based on the lucas washburn equation with a constant contact angle θ s 5 59 the lbm simulations show a good agreement with the analytical prediction by the lucas washburn equation but both of them show a faster rise compared to the experimental data especially in the early time region t 20 next simulations with the dynamic contact angle implementation are conducted at every time step the capillary number is computed based on the average velocity of the moving interface the dynamic contact angle to be imposed as a wetting boundary condition is obtained from eq 10 with θ s 5 59 and log k l l s 39 37 the simulation results are shown in fig 13 compared to the constant contact angle implementation the simulation results are shifted downward and they show good agreement with the experiments albeit with a slight difference in the early time region for the case of b o 5 7 10 3 abu al saud et al 2017 showed a comparison to heshmati and piri 2014 s capillary rise experiment conducted with an air soltrol 170 system in a glass tube with a tube diameter of 1 3 mm using the level set method the dynamic contact angle in their model is implemented based on the cox voinov model cox 1986 voinov 1977 their simulations showed good agreement with the trend of measured rise height with a slight difference in the early time region which is also observed in our simulation they suggested that this discrepancy was due to inertial effects fig 14 shows a comparison between the prescribed contact angle and the resultant simulated contact angle during the capillary rise simulations for both the constant imposed angle and the dynamic angle implementation the simulated contact angles agree with the prescribed values for a wide range of capillary number 10 6 c a 10 2 4 conclusions we have tested a new implementation of the wetting boundary condition in the cg lbm framework our wetting boundary condition changes the direction of the color gradient according to the prescribed contact angle and it can be applied to 2d and 3d geometries therefore it is suitable for studying multiphase flow in porous media which will be the subject of future work using the 2d static contact angle test case the difference in accuracy between the traditional fictitious density wetting boundary condition and our wetting boundary condition was investigated when the widely applied fictitious density boundary condition was used because of the unphysical mass transfer along the wall boundary the simulated contact angle deviated from the prescribed contact angle for contact angles both greater and smaller than 90 this deviation resulted in an inaccurate estimation of capillary pressure in contrast when our wetting boundary condition was applied the simulated contact angle and capillary pressure were accurately simulated in addition our boundary condition gave smaller spurious currents around the three phase contact line than the fictitious density boundary condition moreover we demonstrated that the model worked for a 3d test case of a static droplet on a flat surface and on a curved surface to study the applicability of our method to the dynamic problem where the interface and three phase contact line move capillary rise simulations were conducted the simulations were performed with bond numbers of order 10 2 to make a direct comparison with previously published experimental data heshmati and piri 2014 for the constant contact angle implementation the simulated results agreed with the analytical prediction using the lucas washburn equation this suggests that the balance between capillary and gravitational forces is properly modeled in our model then we demonstrated an implementation of a dynamic contact angle which changes the prescribed contact angle at every time step dependent on the capillary number the simulated results showed good agreement with the experimental data for both the constant and dynamic contact angle implementation the simulated contact angles corresponded to the prescribed values this suggests that our method precisely controls contact angle for dynamic problems regardless of the fluid velocity acknowledgment this work is financially supported by japan oil gas and metals national corporation jogmec appendix a multiphase lattice boltzmann method for the d3q19 lattice model the lattice velocity is given as follows a 1 e i 0 0 0 for i 0 1 0 0 c 0 1 0 c 0 0 1 c for i 1 6 1 1 0 c 1 0 1 c 0 1 1 c for i 7 18 where c δx δt is the lattice speed with δx being the lattice length and δt the time step size for simplicity we set δ x δ t 1 the geometry of the d319q lattice model can be found in for instance hecht and harting 2010 we consider two immiscible fluids labeled red and blue the particle distributions of the fluids at position x and time t are denoted as f i r x t and f i b x t the total particle distribution is given by f i f i r f i b the density of fluid k is given by the first moment of the particle distribution functions a 2 ρ k i f i k x t k r or b the fluid velocity u is obtained from the second moment of the particle distribution a 3 ρ u i f i x t e i where ρ is the total fluid density given by ρ ρ r ρ b the total particle distribution undergoes collisions as a 4 f i x t f i x t ω i x t ϕ i where f i is the post collision total particle distribution ωi is the collision operator which is responsible for the relaxation of the moments towards local equilibrium and ϕi is the source term and has the effect of introducing a body force in the fluid in our model the bhatnagar gross krook bgk collision operator qian et al 1992 is used a 5 ω i 1 τ f i f i e q where τ is the single relaxation time srt and f i e q is the equilibrium distribution function which is obtained by a second order taylor expansion of the maxwell boltzmann distribution with respect to the local fluid velocity u a 6 f i e q ρ ω i 1 e i u c s 2 e i u 2 2 c s 4 u 2 2 c s 2 where cs is the speed of sound and ωi is the weight coefficient which is given by a 7 ω i 1 3 for i 0 1 18 for i 1 6 1 36 for i 7 18 through the chapman enskog expansion analysis of the total particle distribution fi it is confirmed that the collision operator recovers the continuity equation and the navier stokes equation where the following relations are obtained a 8 ν k 1 3 τ k 1 2 k r or b a 9 c s 1 3 c a 10 p ρ c s 2 ρ 3 where νk is the kinetic viscosity of fluid k and p is the hydrodynamic pressure in the fluid in the interface region the relaxation time in eq a 5 is determined by the harmonic average of the viscosity of the fluids a 11 1 ν ρ r ρ r ρ b 1 ν r ρ b ρ r ρ b 1 ν b τ 3 ν 1 2 the interfacial force is modeled by introducing the body force f at the interface of two fluids to trace the fluid interface a color function ρn is defined as a 12 ρ n x t ρ r x t ρ b x t ρ r x t ρ b x t 1 ρ n 1 based on the continuum surface force csf the body force can be expressed as brackbill et al 1992 a 13 f 1 2 σ κ ρ n where ρn is the gradient of color function ρn and it is called the color gradient σ is the interfacial tension and κ is the curvature of the interface which can be calculated by a 14 κ i n n n where n is the unit normal vector defined by n ρ n ρ n in eqs a 13 and a 14 the partial derivatives are calculated using an isotropic finite difference scheme a 15 ψ x x α 3 c 2 i ω i ψ x e i e i α where ψ is any function the calculated body force f which is spatially varying can be imposed through the source term in eq a 4 by the following equation guo et al 2002 a 16 ϕ i ω i 1 1 2 τ 3 e i u 9 e i u e i f where u is the redefined fluid velocity to account for the influence of the spatially varying body force which is given by a 17 u 1 ρ i f i e i 1 2 f although the body force generates the interfacial force at the interface it does not guarantee the immiscibility of the fluids to ensure phase segregation and maintain the sharpness of the interface the recoloring scheme proposed by latva kokko and rothman 2005a is used a 18 f i r ρ r ρ f β ρ r ρ b ρ ω i c o s φ e i f i b ρ b ρ f β ρ r ρ b ρ ω i c o s φ e i where β is the segregation parameter which can take a value in 0 1 and φ is the angle between the color gradient and the lattice vector which can be obtained by a 19 c o s φ e i ρ n e i ρ n after the recoloring step the particle distribution functions stream to the neighboring lattice by a 20 f i k x e i δ t t δ t f i k x t k r or b we briefly describe the boundary conditions used in the paper except for the wetting boundary condition which is described in detail in the main text at the solid boundary the full way bounce back scheme is applied in this scheme the particle distributions at boundary lattice nodes are bounced back into flow domain instead of performing the collision step this is written as a 21 f i k x t f i k x t k r or b where f i k is the distribution function in the opposite direction to e i as for the inlet and outlet boundaries a periodic boundary condition and a constant pressure boundary condition respectively are used in this paper for the periodic boundary condition the outgoing particle distribution from the outlet is re entered into the flow domain from the inlet for the constant pressure boundary condition the method proposed by zou and he 1997 is used 
813,significant input uncertainty is a major source of error in watershed water quality wwq modeling it remains challenging to address the input uncertainty in a rigorous bayesian framework this study develops the bayesian analysis of input and parametric uncertainties baipu an approach for the joint analysis of input and parametric uncertainties through a tight coupling of markov chain monte carlo mcmc analysis and bayesian model averaging bma the formal likelihood function for this approach is derived considering a lag 1 autocorrelated heteroscedastic and skew exponential power sep distributed error model a series of numerical experiments were performed based on a synthetic nitrate pollution case and on a real study case in the newport bay watershed california the soil and water assessment tool swat and differential evolution adaptive metropolis dream zs were used as the representative wwq model and mcmc algorithm respectively the major findings include the following 1 the baipu can be implemented and used to appropriately identify the uncertain parameters and characterize the predictive uncertainty 2 the compensation effect between the input and parametric uncertainties can seriously mislead the modeling based management decisions if the input uncertainty is not explicitly accounted for 3 the baipu accounts for the interaction between the input and parametric uncertainties and therefore provides more accurate calibration and uncertainty results than a sequential analysis of the uncertainties and 4 the baipu quantifies the credibility of different input assumptions on a statistical basis and can be implemented as an effective inverse modeling approach to the joint inference of parameters and inputs keywords water quality modeling watershed bayesian model averaging markov chain monte carlo input uncertainty bayesian calibration 1 introduction watershed water quality wwq models typically integrate distributed hydrological modeling with water quality modeling and depict the interrelated watershed processes of water heat sediments and chemicals borah and bera 2003 some representative wwq models include the soil and water assessment tool swat arnold et al 1998 neitsch et al 2009 watershed analysis risk management framework warmf chen et al 2004 zheng et al 2011 hydrological simulation program fortran hspf bicknell et al 1997 and annualized agricultural non point source pollution model annagnps young et al 1989 bingner et al 2015 these models have been widely used to address a variety of water and environmental issues including agricultural non point source nps pollution jeon et al 2007 huang and hong 2010 pease et al 2010 volk et al 2016 volk et al 2017 water quality response to climate change cho et al 2016 nguyen et al 2017 food energy water nexus few karabulut et al 2016 psomas et al 2016 low impact development lid her et al 2017 and many others however simulation results of the wwq models often have notable uncertainty zheng and keller 2007 rode et al 2010 first owing to current knowledge gaps the existing models often represent complex water quality processes e g soil erosion heat exchange pollutant transport and chemical reactions in a highly simplified way which leads to significant model structural errors rode et al 2010 beck 1987 van griensven and meixner 2006 second while the quantity and quality of the hydrological forcing data e g precipitation and temperatures have been greatly improved due to the development of remote sensing knoche et al 2014 water quality drivers e g point source ps and nps loadings still lack good data with the required temporal and spatial resolutions han and zheng 2016 which represents a significant input uncertainty in the wwq models third wwq models involve a larger number of model parameters and the parametric uncertainty would be substantial when observational data for model calibration are scarce and or inaccurate the multiple sources of uncertainty significantly hinder the application of wwq models in scientific research and management practices and effective approaches to uncertainty analysis are highly desired for the models bayesian calibration using markov chain monte carlo mcmc sampling gelman et al 2003 robert and casella 2004 is a formal approach for model calibration and uncertainty assessment and has been applied widely in recent years kuczera and parent 1998 bates and campbell 2001 marshall et al 2004 yang et al 2007 smith and marshall 2008 vrugt et al 2008c in the approach model residuals i e the difference between observations and corresponding model outputs are described by a statistical residual error model based on which the likelihood function can be derived box and tiao 1992 when the prior distribution is provided the posterior parameter distribution can be inferred by adopting the bayes rule the approach has explicit assumptions and a rigorous mathematical basis but its effectiveness is dependent on many issues one issue is the appropriateness of the error model for example in hydrological modeling model residuals are often correlated heteroscedastic and not normally distributed kuczera 1983 there are a series of studies which discuss the residual model bates and campbell 2001 yang et al 2007 schaefli et al 2007 schoups and vrugt 2010 smith et al 2010 evin et al 2013 honti et al 2013 another important issue is the consideration of input uncertainty and model structural errors a classic bayesian calibration approach directly addresses the parametric uncertainty and leaves out the other two uncertainty sources which may bias the inference of the posterior distributions our previous study shows that such degradation can be alleviated by including additional model responses that are less impacted by the input and model structural errors in a multiple response bayesian calibration mrbc framework han and zheng 2016 another solution is to jointly assess the input structural and parametric uncertainties although this remains challenging renard et al 2010 hierarchical bayesian approaches such as bayesian total error analysis batea kavetski et al 2006 integrated bayesian uncertainty estimator ibune ajami et al 2007 integrated parameter estimation and uncertainty analysis tool ipeat yen et al 2014 and some others vrugt et al 2008b li et al 2012 have been developed to quantify the model input uncertainty along with model calibration in the existing approaches input errors are usually represented by latent variables e g rainfall multipliers with prescribed hyperdistributions the hierarchical bayesian inference addresses all uncertain model parameters and latent variables as well as all hyperparameters thyer et al 2009 although these approaches can separate the input and parametric uncertainties their hierarchical inference framework can lead to high dimensional posterior distributions and sampling of the posterior distributions can be computationally prohibitive especially for complex wwq models more importantly in wwq modeling it is very difficult to represent the input uncertainty of pollutant loadings in terms of latent variables bayesian model averaging bma has been increasingly used to account for model structural uncertainty ajami et al 2007 raftery et al 2005 duan et al 2007 rojas et al 2008 zhang et al 2009 bastola et al 2011 zeng et al 2016 wellen et al 2014 bma derives an aggregated simulation by averaging the simulations of multiple models based on their posterior probabilities also referred to as the model weights leamer 1978 hoeting et al 1999 bma has also been used for model ranking and selection where the model weights should balance goodness of fit with complexity following the law of parsimony schoniger et al 2015 tsai and li 2008 volpi et al 2017 in hydrological and water quality modeling it is a common situation for multiple plausible datasets or assumptions to be used to prepare a specific model input for example precipitation data can be simulated by a regional climate model interpolated from observations at meteorological stations or estimated based on radar data land cover data can be interpreted from different types of satellite data and different agencies may have different estimates of pollutant loadings in all these cases the input uncertainty can hardly be represented as continuous probability distributions and needs to be addressed in a discrete form bma appears to be an appropriate way to address such input uncertainty for example strauch et al 2012 established four swat models with four different sets of precipitation data and then performed bma to account for the precipitation uncertainty in streamflow modeling some studies have attempted the coupling of bma with bayesian calibration in a sequential manner that is performing bayesian calibration for individual models first and then achieving an aggregated simulation using bma for example zeng et al 2016 sequentially performed mcmc and bma analyses to assess groundwater conceptualization uncertainty however this sequential approach ignores the interaction between the parametric uncertainty and conceptual uncertainty which may lead to inaccurate results under certain circumstances this study aims to develop an approach to investigating parametric and input uncertainties simultaneously through a tight coupling of mcmc and bma the approach is specifically designed for input uncertainty in a discrete form as exemplified above a previously developed swat model for the nitrate pollution in the newport bay watershed southern california u s was used as the study case and a state of art mcmc algorithm the differential evolution adaptive metropolis dream zs vrugt et al 2008b vrugt et al 2009 laloy and vrugt 2012 was employed a series of numerical experiments were designed and implemented to answer the following key questions 1 whether the new approach can effectively address the discrete form input uncertainty in mcmc based bayesian calibration 2 how the discrete form input uncertainty in pollutant loadings would impact the bayesian calibration results and potential water quality management decisions based on the results and 3 what information the joint analysis of input and parametric uncertainties can provide to measure the relative importance of the competing model input assumptions 2 coupling mcmc and bma 2 1 mcmc uncertainty analysis markov chain monte carlo mcmc uncertainty analysis represents a classic bayesian calibration approach in this approach the residual errors i e ε z f are described by a statistical error model where f and z are the model outputs and the observations respectively this lumped error accounts for all sources of uncertainty including model input model structure model parameters and observations for model calibration schoups and vrugt 2010 with the mathematical form of the error model specified the likelihood function of model parameters can be derived and the posterior distributions of the parameters can be obtained based on bayes rule as 1 p θ φ x z p θ p φ l θ φ x z where θ represents model parameters φ denotes the parameters of the error model x denotes the model input p θ and p φ are the prior distributions and l θ φ x z is the likelihood function in an mcmc algorithm samples are obtained by constructing markov chains with desired posterior distributions as their stationary distributions gelman et al 2003 robert and casella 2004 the samples obtained by the markov chains are used to derive the posterior distribution of uncertain parameters p θ φ x z as well as the predictive distribution p y θ φ z where y denotes a vector of quantities to be predicted explanation of the approach to derive the predictive distribution can be found elsewhere zheng and han 2015 this paradigm has been widely used in uncertainty analysis for hydrological modeling kuczera and parent 1998 bates and campbell 2001 marshall et al 2004 yang et al 2007 smith and marshall 2008 vrugt et al 2008c this study considers an autocorrelated heteroscedastic and non gaussian error model han and zheng 2016 zheng and han 2015 the autocorrelation of residuals is depicted by a first order autoregressive model i e ar 1 which involves a parameter lag 1 autoregressive parameter ϕ the heteroscedasticity is reflected by a linear equation σ t b 1 b 2 ft where σ t is the estimated standard deviation ft is the model output at time step t and b 1 and b 2 are the two parameters the skew exponential power sep distribution schoups and vrugt 2010 is employed to represent two typical non gaussian effects i e skewness and kurtosis where the skewness parameter ξ and the kurtosis parameter β are introduced thus the error model has five parameters in this case that is φ ϕ b 1 b 2 ξ β the log likelihood function can be formulated as 2 l o g l θ φ z j l o g 2 σ ξ ω β ξ ξ 1 j 1 j log σ j c β j 1 j a ξ j 2 1 β where j is the data length of z a ξ j ξ s i g n μ ξ σ ξ a j μ ξ σ ξ a j in which aj stands for the independent and identically distributed random errors with a zero mean and unit standard deviation and μξ σξ ωβ and c β are functions of ξ and β more details about the error model and likelihood function can be found elsewhere han and zheng 2016 schoups and vrugt 2010 evin et al 2013 note that this highly complicated likelihood function may lead to an undesired computational burden on the uncertainty analysis to simplify the error model as well as the corresponding likelihood function a trail and error approach can be adopted to examine the fulfillment of the statistical assumptions a posteriori one can gradually increase the complexity of the error model as was done in previous studies han and zheng 2016 zheng and han 2015 differential evolution adaptive metropolis dream zs vrugt et al 2008b vrugt et al 2009 laloy and vrugt 2012 is employed in this study as the mcmc algorithm it is a population evolution mcmc algorithm which runs multiple markov chains in parallel to facilitate the global exploration of the parameter space it automatically tunes the scale and orientation of the proposal distribution in dream zs a candidate point can be generated by using a differential evolution with a randomized subspace sampling strategy which can be described as follows 3 θ i θ i 1 d e d γ δ d j 1 δ u r 1 j n 1 δ u r 2 n є d where θ i is the candidate point θ i is the current point of the ith markov chain e d and ϵ d are two d dimensional random vectors the coefficient γ controls the jumping size and u r 1 j u r 2 n j n 1 δ represents δ pairs of previously sampled points r 1 j r 2 n in high dimension problems it is often not optimal to sample all d dimensions simultaneously in dream zs only d dimensions of θ i which are randomly selected with a crossover probability are updated in each sampling step and the other dimensions remain the same as those of θ i to increase diversity the snooker update is included which is an additional way to generate candidate points the way to propose a candidate point is described as follows 4 θ i θ i γ s θ i u d u r 1 u r 2 where γs is a random variable u u r 1 and u r 2 are three previously sampled points and d is a function of u r 1 and u r 2 both d and γs are used to determine the distance of the jumping more details of the snooker update can be found in ter braak and vrugt 2008 in dream zs both differential evolution and snooker update are used to generate the candidate points in this study we updated the markov chains in a mix of 10 snooker update and 90 differential evolution the r statistics proposed by gelman and rubin 1992 are used to assess the convergence of the markov chains the markov chains are deemed to achieve the convergence when the r values of all dimensions or parameters are below 1 2 computed based on the last 50 points of the markov chains 2 2 loose coupling the sequential approach as mentioned in section 1 mcmc based bayesian calibration can be coupled with bma in a sequential manner to account for input uncertainty hereinafter models with the same model structure but different inputs are considered as different models when k plausible input datasets x 1 x k are collected or assumed for a same model structure k different models m 1 mk can be established respectively which represents the input uncertainty in a discrete form mcmc uncertainty analysis can first be performed for each model to assess the parametric uncertainty next the predictive distributions inferred based on the k models i e p y mk z are averaged into a total predictive distribution representing both parametric and input uncertainties this two step uncertainty analysis is referred to as the sequential bma approach in this paper its mathematical details are provided below bma provides a data driven approach to statistically integrate the predictions of multiple models leamer 1978 hoeting et al 1999 let y y 1 yt yt denote the vector of quantities to be predicted i e the true values and let z denote the observations in bma the predictive distribution of yt based on the kth model mk can be deemed as the posterior distribution of yt conditional on z that is p yt mk z thus the posterior distribution of yt conditional on the entire model ensemble can be written as 5 p y t z k 1 k p y t m k z p m k z where p mk z stands for the posterior probability of mk and p mk z can be interpreted as the likelihood of mk being correct given z because the posterior probabilities of all the models have a sum of one p mk z can also be interpreted as the weight of mk hereinafter p mk z is denoted as wk and w w 1 wk the mean and variance of bma predictions can be computed as 6 e y t z k 1 k w k e y t m k z 7 var y t z k 1 k w k e y t m k z e y t z 2 k 1 k w k var y t m k z the predictive distribution p yt mk z can be computed as 8 p y t m k z ω k p y t m k θ k φ k p θ k φ k m k z d θ k d φ k where θ k denotes the model parameters of mk φ k denotes the error parameters associated with the residual error model θ k φ k ω k p yt mk θ k φ k represents the predictive distribution of yt given the specific values of θ k andφ k and p θ k φ k mk z represents the posterior distribution of θ k andφ k the calculation of the integral in eq 8 is computationally intensive alternatively the integral can be approximated using the posterior samples generated in the mcmc analysis as robert and casella 2004 9 p y t m k z 1 n k n 1 n k p y t m k θ k n φ k n where θ k n and φ k n denote the nth sample of model parameters and error parameters respectively jointly generated by the markov chain and nk is the sample size assuming independence among the residual errors the log likelihood function of the model weights can be derived as 10 l o g l w z j 1 j log k 1 k w k 1 n k n 1 n k p z j m k θ k n φ k n note that the assumption of independence may not be valid for example when lag 1 autocorrelation of the residual errors exists zj should be conditional on z j 1 in such cases p z j m k θ k n φ k n in eq 10 should be replaced by p z j m k θ k n φ k n z j 1 raftery et al 2005 suggested to estimate the weights using the maximum likelihood estimation mle for complex likelihood functions the expectation maximization em algorithm dempster et al 1977 can be employed to find a numerical solution for the mle problem with a small computational cost however the em method only leads to a set of deterministic weight estimates and the results can be unstable when the weights are sensitive to the observations a more reliable way is to perform mcmc simulation vrugt et al 2008a in which the means of the sampled weights can be used as the posterior probabilities of the respective models there are also other options to determine the model weights such as the bayesian model evidence method volpi et al 2017 in this study we adopted dream zs to sample model weights in the sequential bma approach to guarantee a sum of one for the weights of a candidate point i e θ i we modified the original operation of generating candidate points to the following steps step 1 generate a jumping vector by eqs 3 or 4 with at least two elements of being non zero step 2 normalize by subtracting the mean of the updated elements and therefore the sum of the normalized is equal to zero step 3 generate the candidate point θ i θ i the sum of θ i is one as the sum of θ i is one step 4 if θ i is outside of the sampling domain calculate a new point θ i using the returning operation introduced below as θ i may be outside of sampling domain a returning operation was proposed as illustrated in fig 1 when the proposed jump from θ i to θ i hits the boundary i e θ b is reached the jump turns back along the original path and ends at θ i in this case the total jumping distance in its absolute value remains the same because the sum of is zero the sum of θ i remains one similarly a jump from θ i with the same jumping vector will end at θ i it suggests that with the returning operation the conditional probability of a jump from θ i to θ i is equal to that of the reverse jump i e from θ i to θ i thus the detailed balance of dream zs can be guaranteed by accepting the candidate point θ i or θ i based on the metropolis acceptance probability laloy and vrugt 2012 2 3 tight coupling baipu this study develops a new approach to jointly analyze the input and parametric uncertainties by tightly coupling bma with mcmc which is named the bayesian analysis of input and parametric uncertainties baipu fig 2 illustrates the framework of baipu it begins with the preparation of k sets of plausible input data which result in k models as defined in section 2 2 thus given the same model structure one realization of model parameters θ would lead to k sets of model outputs f 1 f k in baipu a shared residual error model with parametersφ is also assumed for the model ensemble hence the multiple models share the same set of uncertain parameters i e θ plusφ the predictive distributions of yt derived based on different models can be further averaged by bma as 11 p y t m 1 k θ φ k 1 k w k θ φ p y t m k θ φ where wk θ φ represents the weight of the kth model given specific values of θ and φ and p yt mk θ φ is the predictive distribution of yt based on the kth model i e the kth input dataset in eq 11 the dependency of the model weights on θ and φ reflects the interaction between the input and parametric uncertainties which is ignored in the sequential bma approach assuming independence among the residual errors the log likelihood function of the model parameters and error parameters can be defined as 12 l o g l θ φ w z j 1 j log k 1 k w k θ φ p z j m k θ φ if lag 1 autocorrelation among the residual errors exists the probability of zj in eq 12 should also be conditional on z j 1 that is p zj mk θ φ z j 1 the mcmc analysis is then performed to derive the posterior distributions of model parameters and predictive variables as discussed in section 2 1 there are different strategies to infer the model weights the framework of baipu accommodates two fig 2 one strategy is to estimate the weights by the em algorithm when a realization of θ andφ is generated in one sampling step the corresponding model weights wk θ φ k 1 k are then determined by maximizing this likelihood function using the em optimization the other strategy is to sample the model weights jointly with the model parameters using mcmc to implement this strategy the returning operation introduced in section 2 2 needs to be incorporated in dream zs such that the model weights in each candidate point add up to one because the mcmc sampling is more reliable than the em optimization all the baipu results presented in this paper were based on the mcmc sampling for comparison we also performed all the baipu analyses using the em approach section 4 1 briefly discusses the comparison and readers are referred to the auxiliary materials for more details one difference between the baipu and sequential bma approach is that the baipu derives a common posterior parameter distribution based on the entire set of plausible model inputs while the sequential approach leads to multiple posterior parameter distributions with respect to different model inputs note that the multiple posterior parameter distributions could be further averaged into a single posterior distribution by resampling the multiple distributions according to their posterior probabilities i e the model weights however although such a posterior distribution is relevant to the parameter calibration it cannot be directly assigned to each model for making predictions which is an advantage of baipu in addition in the baipu because a common posterior parameter distribution can be obtained the model weights solely reflect the model input uncertainty however in the sequential bma approach the input and the parametric uncertainties can compensate for each other in the bayesian calibration therefore the weights are impacted by the parametric uncertainty the error model introduced in section 2 1 is considered for the model ensemble which involves five error parameters that is φ ϕ b 1 b 2 ξ β let ε kt yt fkt denote the residual error of the k th model i e input x k at time step t where fkt is the corresponding model output as mentioned before the standard deviation of ε kt is estimated by σ kt b 1 b 2 fkt and hence the standardized residuals can be calculated as η k t ɛ k t σ k t the ar 1 model is applied to the standardized residuals to account for the lag 1 autocorrelation that is η kt ϕη k t 1 okt it is a standard homoscedastic ar 1 process and variance of okt equals 1 ϕ 2 thus the variance of a k t o k t 1 ϕ 2 should be a unit similarly we assume that akt follows the sep distribution hence given the specific values of θ andφ the predictive probability of yt based on the k th model can be computed as 13 p y t m k θ φ y t 1 1 1 ϕ 2 σ k t 2 σ ξ ω β ξ ξ 1 exp c β a ξ k t 2 1 β where a ξ k t ξ s i g n μ ξ σ ξ a k t μ ξ σ ξ a k t and μξ σξ ωβ and c β are functions of ξ and β schoups and vrugt 2010 according to eq 12 the log likelihood function for this residual error model can be derived as 14 l o g l θ φ w z j 1 j log k 1 k w k θ φ 1 1 ϕ 2 σ k j 2 σ ξ ω β ξ ξ 1 exp c β a ξ k j 2 1 β this likelihood function is quite general and flexible it relaxes the commonly used independent homoscedastic and gaussian assumption about the residual errors and hence is more realistic for environmental modeling as was revealed by han and zheng 2016 when model input errors are very significant the inferred posterior distributions of the model parameters would be prone to notable bias this likelihood function which is based on multiple input datasets rather than one single set of input data is expected to be more accurate and reliable it is worth re emphasizing that baipu was specifically designed to address discrete form input uncertainty if the input uncertainty could be appropriately characterized as continuous probability distributions the bma step in baipu may not be an efficient solution in baipu the sampler dream zs would execute k times more model runs than in a traditional mcmc uncertainty analysis if the chains have the same length in this study the computational cost was largely reduced by parallelizing the sampling process that is making dream zs execute n chain k model runs n chain denotes the number of markov chains simultaneously in parallel similar parallel calculation was adopted for the sequential bma as well 3 data and methods 3 1 study area the newport bay watershed nbw is in orange county southern california it is a highly urbanized watershed with an area of approximately 400 km2 fig 3 as of 2001 approximately 70 of the watershed was residential commercial and industrial areas and agricultural and orchard areas accounted for approximately 8 the nbw has a typical mediterranean climate with warm dry summers and mild wet winters the annual rainfall is approximately 330 mm and occurs mostly between november and april nutrient pollution was a significant water quality issue in this area in the 1990 s excessive loadings of nutrients were delivered into the newport bay through the san diego creek see fig 3 which had caused the eutrophication of the bay and created the recreational and aesthetic nuisance u s environmental protection agency 1998 major sources of nutrients included fertilizer application non point source and commercial nurseries point sources the nbw and san diego creek were included in the 1998 california 303 d list of impaired waters for total maximum daily loads tmdl actions with nutrients as a major pollutant stressor u s environmental protection agency 1999 more details about this watershed can be found in our previous studies zheng and han 2015 zheng and keller 2008 3 2 nitrate pollution modeling swat is a representative wwq model which is semi distributed and runs at a daily time step neitsch et al 2009 a swat model of the nitrate pollution in the nbw has been previously developed han and zheng 2016 zheng and han 2015 in brief the watershed was first delineated into 11 sub basins see fig 3 with a total of 58 hydrologic response units hrus the 90 m digital elevation model dem of the study area was acquired from the u s geological survey usgs to delineate the modeling domain the 30 m land use raster from the national land cover database 2001 nlcd 2001 and the soil type map from the u s state soil geographic statsgo database were referred to in defining the hrus meteorological data from 1998 to 2004 were obtained from u s national climatic data center ncdc and used to drive the model simulations the model was run from july 1998 to june 2004 with the first two years being the warm up period and the last four years being the calibration period observations of daily flow and weekly nitrate concentration at the watershed outlet fig 3 a from july 2000 to june 2004 were collected from the santa ana regional water quality control board reports available at http prg ocpublicworks com docmgmtinternet search aspx last accessed on october 8 2017 and were used for the model calibration in this study nitrate was the water quality parameter of concern and nitrogen source loadings were considered as the uncertain model inputs in the nbw fertilizer application on urban lawns and effluents from commercial nurseries were the two major nitrogen sources u s environmental protection agency 1998 in the swat model bermuda was selected as the representative lawn grass and the nurseries were conceptualized into two point sources a and b see fig 3 a as detailed information of the timing of fertilizer application is not available the heat unit scheduling in swat was chosen which allows the model to schedule operations based on temperature to simulate the stormwater runoff and nitrate pollution in urban areas swat offers two options one is to use a set of linear empirical equations developed by the usgs referred to as the usgs option and the other is to simulate the buildup and washoff processes referred to as the buildup washoff option although the buildup washoff option is conceptually appealing local data to parameterize the equations is often lacking hence the usgs option was chosen in this study in our previous study han and zheng 2016 the nitrate loadings at sources a and b were estimated to be 61 kg n day and 31 kg n day respectively and the fertilizer usage was assumed to be 240 kg n ha year the ps loadings were assumed to be time invariant because no detailed temporal information was available inevitably significant input uncertainty exists in the source loadings which would degrade the calibration of the uncertain model parameters thus this study considers multiple plausible ps and nps loadings instead which will be further discussed in section 3 4 3 3 multiple response bayesian calibration to alleviate the impact of input and model structural errors the streamflow and nitrate concentration at the watershed outlet are calibrated simultaneously by applying the mrbc approach developed in our previous study han and zheng 2016 in the context of the mrbc different error models are required for different responses based on which individual likelihood functions can be established in this study residual errors of streamflow and nitrate concentration are assumed to be independent hence the combined likelihood function is simply the product of their likelihood functions han and zheng 2016 balin talamba et al 2010 15 l m u l t i p l e l h θ φ h z h l n θ φ n z n where lh and ln are the likelihood functions of streamflow and nitrate concentration respectively in this study the likelihood functions of flow and nitrate responses are determined by eqs 2 and 14 in the sequential bma approach and baipu respectively 3 4 numerical experiments in the real situation case five loading scenarios were assumed to account for the input uncertainty which leads to five real situation models rms see table 1 among the five models rm2 is the basic model that was built in our previous study han and zheng 2016 and represents an average loading situation rm1 has 20 lower ps loadings and 10 lower fertilizer usage compared to rm2 while rm3 has 20 higher ps loadings and 10 higher fertilizer usage rm4 and rm5 are two models with temporal variability in the ps loadings while rm4 has a smaller seasonal fluctuation see fig s1 in the auxiliary materials note that the overall loadings in rm4 and rm5 are the same as those in rm2 this ensemble of models effectively embodies a common situation encountered in wwq modeling that is detailed and accurate loading data are often lacking and the modeler may consider different assumptions the selection of random parameters in the bayesian calibration was the same as in our previous study han and zheng 2016 in brief 32 swat parameters that are physically relevant for flow and or nitrate simulations were identified first next 12 most important parameters table 2 were further determined after an initial sensitivity analysis on the 32 parameters using morris screening campolongo et al 2007 each of the 12 parameters ranks top 8 among the 32 initial parameters at least for one of the two responses i e flow and nitrate full details of the selection procedure can be found in our previous study han and zheng 2016 as most of the parameters have spatially distributed values three strategies yang et al 2007 were considered to vary them varying the parameter value directly type i adding a deviation value to the distributed parameters type ii and applying a multiplier to the distributed parameters type iii for parameters of type ii and iii the deviations and multipliers other than the original distributed parameters are treated as uncertain model parameters in subsequent calibration approaches all the uncertain parameters are assumed to be uniformly distributed and their ranges are provided in table 2 initialization of other non random parameters is also the same as in the previous study han and zheng 2016 to investigate the applicability and performance of baipu a synthetic modeling case was also constructed in which a true model denoted as tm with true model parameters true model inputs and true model structure was hypothesized table 1 the true values of the 12 uncertain parameters the last column in table 2 were randomly picked which can yield realistic simulation results true nitrate loadings at sources a and b were assumed to be time variant at the levels of 132 and 68 kg n day respectively see fig s2 in the auxiliary materials the fertilizer usage in tm was assumed to be 240 kg n ha year and scheduled on specific dates the buildup washoff method was selected as the true model structure for the simulation of stormwater pollution from urban areas other model settings were the same as that in the real situation case true model responses of flow and nitrate concentration at the watershed outlet were achieved by running the true model with the above settings in addition to the perfect model i e tm five imperfect models ims with different source loadings were also created denoted as im1 im2 im3 im4 and im5 see table 1 the ps loadings were set to be time invariant which reflects the reality that the temporal information of ps loadings is often unavailable among the models im3 represents the average loading level i e 150 kg day and 75 kg day at sources a and b respectively and im1 im2 im4 and im5 represent the 66 7 83 3 116 7 and 133 3 of the average loading level respectively similarly different fertilizer application rates were hypothesized for the five imperfect models table 1 the five imperfect models collectively represent the hypothetical input uncertainty to better mimic the reality the model structural error was also introduced in the ims the usgs option was used instead of the buildup washoff option daily flow observations and weekly nitrate observations at the outlet were synthesized by corrupting the true model responses with hypothetic observational errors see fig s3 in the auxiliary materials the hypothetic errors were generated from an error model with b 1 h 0 2 b 2 h 0 05 β h 0 5 ξ h 3 φ h 0 2 b 1 n 0 2 b 2 n 0 3 β n 0 5 ξ n 3 and φ n 0 this procedure represents a common strategy to synthesize observational data zheng and keller 2007 schoups and vrugt 2010 smith et al 2010 as in the real situation case the artificial observations were generated for the period from july 2000 to june 2004 and all the models i e the tm and ims were run from july 1998 to june 2004 in both the synthetic and real situation cases the baipu and the sequential bma approach were carried out in the baipu the model weights were jointly sampled with the model and error parameters i e the joint sampling method and in the sequential bma approach the model weights were sampled by dream zs hereinafter baipu ims denotes the baipu analysis on the five imperfect models and mcmc im1 mcmc im2 mcmc im3 mcmc im4 and mcmc im5 denote the mcmc uncertainty analyses for the five individual models respectively these individual mcmc analyses constitute the first step in the sequential bma approach the same terminology is applied to the real situation case the computational efficiency posterior distributions of the uncertain swat parameters and the uncertainty results of the two approaches were evaluated and compared it is worth pointing out that each model e g im1 in the sequential bma approach has its individual error model while the multiple models in the baipu share the same error model in determining the proper error model the complexity of the error models was gradually increased from simple independent homoscedastic and gaussian type to the most complicated type until the posterior checks confirmed that the residual errors are consistent with the error model assumptions the error models for different calibration procedures are summarized in table s1 in the auxiliary materials posterior justification of these error models is illustrated by figs s4 s8 in the auxiliary materials eventually nine error parameters were included in the uncertainty analysis i e φ ϕ h b 1 h b 2 h ξ h β h b 1 n b 2 n ξ n β n in this study the error parameters were jointly inferred with the uncertain swat parameters i e θ in the mcmc sampling to further compare the sequential bma approach and the baipu three future loading scenarios with increased steady and decreased loadings were proposed for the period from july 2004 to june 2008 table 3 the calibrated models were run to predict the nitrate concentration with the proposed future loading scenarios to investigate how the calibration procedure would impact management decisions two management relevant variables average nitrate concentration avc and frequency of exceeding foe the water quality target 6 mg n l were evaluated based on the predictions in the synthetic case the true nitrate concentrations under different loading scenarios were obtained by running the true model i e tm whereby the true values of avc and foe can be achieved in the real situation case the true model was unknown and hence the true avcs and foes were not obtainable 4 results and discussion 4 1 efficiency of dream zs in baipu twelve markov chains were run simultaneously in dream zs and 12 k cpus 2 67 ghz were utilized in parallel to reduce the computing time where k is the size of model ensemble with the parallel computing the cost of implementing dream zs is affordable for example evaluating 200 000 samples in the baipu typically takes one day for the modeling cases the sequential bma approach has two stages of dream zs the second stage is to sample the model weights and the computational cost is only a few minutes because this stage involves no swat runs to ensure that the posterior distributions and uncertainty results were reliable and representative dream zs explored 400 000 and 300 000 samples for the synthetic and real situation cases respectively using the fixed sample numbers can rule out the effect of computational cost when interpreting the analysis results of different models the numbers are large enough to ensure the convergence of markov chains in most of the experiments table 4 shows the number of samples for markov chains to achieve convergence nc and the acceptance rate ar of dream zs in different numerical experiments as indicated by the nc values the convergence speed of markov chains in baipu was comparable to that in the mcmc uncertainty analyses in the real situation case but was moderately slower in the synthetic case one obvious reason for the speed decrease is that baipu leads to a higher dimensional posterior distribution ar is the probability that one candidate point is accepted in stationarity it can be estimated as t t where t and t denote the numbers of all and the accepted candidate points in the second halves of the markov chains respectively a higher ar simply means that it is easier to find an acceptable candidate point with relatively high posterior probability as table 4 shows in the two step sequential bma dream zs obtained one order of magnitude higher ar values in estimating the model weights than in deriving the posterior parameter distributions this is because the likelihood function of the model and error parameters eq 2 is much more complex than that of the model weights eq 10 another interesting finding is that the two baipu analyses yielded several fold higher ar than the respective mcmc uncertainty analyses of individual models this is probably because the multi model ensemble allows a broader range of predictions than a single model making it easier to find an acceptable candidate point overall the results in table 4 indicate that the sampling efficiency of dream zs in baipu was not significantly reduced by the integration with bma as mentioned in section 2 3 we also tested the em strategy to infer the model weights in the baipu it has been found that the em strategy led to a faster convergence of markov chains nc is 363 120 and 105 120 in the synthetic and real situation cases respectively but lower acceptance rates ar is 2 75 and 7 14 in the synthetic and real situation cases respectively the em and joint sampling strategies yielded very similar posterior parameter distributions uncertainty results and future predictions refer to figs s9 s12 in the auxiliary materials yet the model weights are quite different with the two strategies fig s13 in the auxiliary materials these results demonstrate that the joint sampling is more reliable for the weight estimation however if the convergence speed is an important concern and accurate weight estimation is not a goal the em strategy can be desirable 4 2 the synthetic modeling case 4 2 1 posterior parameter distributions fig 4 illustrates the posterior parameter distributions derived by the baipu red lines and the mcmc analyses dotted lines for the individual models in the synthetic case the true values of the model parameters are indicated by the dashed vertical lines in the figure all the parameter values were rescaled to 0 1 by a linear min max normalization the posterior parameter distributions derived by the baipu red lines are relatively narrow and generally embrace the respective true parameter values except for the initial depth of water in the shallow aquifer shallst and the denitrification threshold water content sdnco parameter the posterior distribution of shallst is wide but still embraces the true value while the posterior distribution of sdnco is far off the true value this is probably because the uncertainty of this parameter compensated the model structure error not explicitly accounted for in this study and or the interaction between the two parameters and the input assumptions in the mcmc sampling is significant fig 4 indicates that the model parameters have been appropriately identified by the baipu in general for most parameters the posterior distributions based on the individual mcmc analyses are different from each other as well as from the respective distribution derived by the baipu the difference is most evident for im5 the model with the most significant input error this indicates that the calibration results can be highly dependent on the input assumption therefore an ensemble approach such as baipu is valuable for addressing the parametric uncertainty similar calibration results of the error parameters are presented in fig s14 in the auxiliary materials 4 2 2 model weights fig 5 compares the model weights based on the baipu and the sequential bma approach the weight results in the two approaches are similar in general the lower the input loading the higher the model weights among the five models the input scenario of im2 is closest to the true one see table 1 but it only achieves the second highest weight in both approaches im1 receives the highest weight in both approaches while its input scenario is the third closest to the true one the hypothesized true ps loadings have skew distributions featured by a limited number of loading pulses see fig s2 in the auxiliary materials therefore the mean values of the true nitrate loadings e g 131 95 kg n day at source a are much higher than the respective medians e g 88 58 kg n day at source a this explains why the inference favors the lowest input loading scenario im1s because the constant loadings in im1 are much closer to the medians of the true ps loadings both baipu and sequential bma enable the correlation analysis of the model weights which helps in understanding the tradeoff between different input scenarios it was found that both approaches lead to very similar correlation results see table s2 in the auxiliary materials baipu also allows a correlation analysis between the model weights and the parameters because they are jointly sampled by dream zs as table 5 shows strong correlations exist in many parameter weight pairs especially for shallst and sdnco the two parameters that were not well identified this implies that the significant interaction between the two parameters and the input assumptions in the mcmc sampling may be one reason for the weak identifiability of the two parameters it also confirms the necessity of sampling model parameters and weights jointly in baipu 4 2 3 uncertainty results fig 6 displays the uncertainty results of the nitrate concentration achieved by the baipu and the sequential bma approach the medians and confidence intervals in fig 6 a and b are very similar in both approaches the seasonal variation is well captured by the time series of the median concentrations the nash sutcliffe coefficients of the median predictions by baipu and the sequential bma approach are 0 2932 and 0 2804 respectively the observations are also adequately embraced by the uncertainty bands as demonstrated by fig 6 a and b 48 33 and 50 72 of the observations are within the 50 confidence intervals respectively and 97 13 and 97 61 of the observations are within the 95 confidence intervals respectively fig 6 c and d shows that the means and standard deviations of the predictive distributions derived in the two approaches are very close in the sequential bma approach the predictive means of individual models are first calculated and then the ensemble predictive means are derived based on eq 6 while in the baipu the ensemble predictive means for each sampled realization of uncertainty parameters are first calculated according to eq 6 and then the total predictive means are derived by averaging over all the sampled realizations of uncertainty parameters the standard deviations illustrated in fig 6 d can be derived in a similar way based on eq 7 the quantile quantile qq plots thyer et al 2009 of nitrate concentration in the synthetic case were also produced for the baipu individual mcmc analyses and the sequential bma approach fig 7 a the qq plots can provide intuitive information on the consistency of predictive distribution with observations in a qq plot if all the points are on the 45 degree line the predictive distribution agrees perfectly with the observations in fig 7 a all the predictive distributions demonstrate adequate consistency in general the baipu and the sequential approach perform better than individual mcmc analyses because both approaches account for the input uncertainty among the individual models im2 leads to the best consistency because its loading scenario is closest to the true one it is worth pointing out that although the predictive distributions of different approaches are similar figs 6 and 7 a the corresponding posterior parameter distributions significantly vary which may have a significant impact on future predictions and management decisions based on the stochastic modeling this issue will be discussed further in section 4 2 4 4 2 4 future predictions and management decisions the wwq models are commonly used to assess hypothetical loading scenarios based on which management decisions can be made with a strong scientific basis to investigate the performance of the different approaches in predicting future water quality and therefore supporting decision making three future loading scenarios were assumed in the synthetic case as discussed in section 3 4 and summarized in table 3 the future loading scenarios are free of input errors two management variables average nitrate concentration avc and frequency of exceeding foe the water quality target i e 6 mg n l were evaluated using the true parameter values as well as the parameter values sampled in the bayesian analyses fig 8 illustrates the cumulative frequency curves cfc of avc and foe derived by different approaches note that in the baipu and mcmc analyses for individual models the frequencies of avc and foe were calculated using the parameter realizations in the second halves of the markov chains in the sequential bma approach the frequencies are weighted averages of the corresponding frequencies derived by individual mcmc analyses thus the range of corresponding cfc depends on both the spread of the cfcs by the mcmc analyses and the model weights as fig 8 shows in general the cfcs derived by baipu solid red lines and the sequential bma approach solid blue lines are both close to the respective true values it indicates that the two approaches are relatively effective in reducing the bias caused by the input errors in the calibration stage the cfcs by baipu are relatively narrower because baipu derived a common posterior parameter distribution moreover the baipu demonstrates a better performance than the sequential approach in predicting the management variables which reflects the fact that the interaction between input uncertainty and parametric uncertainty is considered in contrast the five individual models lead to distinct predictions some of which are far away from the respective true values this implies that the potential management decisions based on the bayesian calibration of individual models would be seriously biased if the model inputs have large errors furthermore the impact of the bias on potential decision making could be dependent on the confidence level desired by the decision maker take foe in scenario 3 as an example refer to fig 8 f if a confidence level of 50 is considered the value of foe would be 0 28 according to im5 therefore the discrepancy with the true value is 0 14 however given a confidence level of 95 the discrepancy would instead be 0 07 fig 8 also shows that im1 which underestimates the observations in the calibration stage i e mcmc im1 overpredicts avc and foe im5 which overestimates the observations now underpredicts avc and foe this is because in the bayesian calibration of individual models the model parameters compensate for the effect of the input errors such that the observations can be better matched for example underestimated ps loadings would lead to parameter values prone to overestimate the water quality response i e the case of im1 thus when the model inputs are free of error the compensation in the calibration stage causes an overreaction of the model at the prediction stage similar overreaction behaviors although not as significant have also been observed for other individual models interestingly im3 has the best performance for predicting the two management variables instead of im2 with the smallest input errors which implies the compensation effect is complex and nonlinear all the above results suggest that a bayesian approach accounting for multiple plausible input assumptions can provide a valuable mechanism for alleviating the impact of input uncertainty and therefore enhancing the reliability of decision making in the context of real world management in addition with the interaction between the input and parametric uncertainties systematically accounted for the baipu has an improved performance in predicting management variables under the future loading scenarios compared to the straightforward sequential bma approach it is also worth emphasizing that one needs to carefully make input assumptions based on his her best knowledge when implementing the two approaches this may require extra work such as data collection and compiling field survey literature review etc in theory it is not a problem for baipu to accommodate many inappropriate input assumptions but in practice it may significantly increase the computational burden 4 3 the real situation modeling case the performances of baipu and sequential bma were also examined using the real situation modeling case table 1 fig 9 shows the posterior parameter distributions derived by the baipu red lines and the mcmc analyses for individual models dotted lines compared to the synthetic case fig 4 the difference between the baipu and the individual mcmc analyses is relatively small which implies that the influence of input uncertainty on the parameter calibration is not as significant as that in the synthetic case shallst and sdnco are the two parameters with the most significant difference in the posterior distributions which is also observed in fig 4 in addition the posterior distributions of the error parameters are presented in fig s15 in the auxiliary materials fig 10 illustrates the model weights inferred by the baipu and the sequential bma approach in this case the overall weight patterns derived by the two approaches are similar as introduced in section 3 2 rm2 represents an average estimation of the nitrogen loadings based on the available data while rm1 and rm3 represent a lower loading scenario and a higher loading scenario respectively among the first three models fig 10 a c rm1 receives the largest weights while rm2 and rm3 receive the second and third largest weights in both approaches it suggests that the original loadings in rm2 has a large probability of overestimation on the other hand in rm4 and rm5 the ps loadings are assumed to have small and large seasonal fluctuations respectively the potential seasonal fluctuation could be due to the temporal variability of tailwater discharges from the commercial nurseries as shown in fig 10 d and e both rm4 and rm5 were assigned significant weights which provides a unique evidence of the existence of seasonal variability in the ps loadings table 6 shows the correlations between the model weights and parameters in baipu although statistically significant in general the correlations in the real situation case are not as strong as those in the synthetic case indicating a weaker interaction between the input and parametric uncertainties in addition table s3 in the auxiliary materials shows the correlations between different model weights in this real situation case baipu and the sequential approaches led to slightly different results the predictive uncertainty bands of the nitrate response are shown in fig 11 the median predictions black lines in fig 11 a and b adequately match the observations in the baipu and the sequential approach the 50 confidence intervals encompasses 50 24 and 51 18 of the observations respectively the 95 confidence intervals encompasses 96 21 and 96 68 of the observations respectively fig 11 c and d further compare the predictive means and standard deviations derived by the two approaches in general the baipu produces the same predictive means as the sequential approach but smaller standard deviations this indicates that the baipu reduces the predictive uncertainty in this case compared to the sequential approach the uncertainty results presented in figs 11 and 7 b suggest that the two approaches as well as those individual mcmc analyses have a similar performance during the bayesian calibration however as revealed in the synthetic case the difference could be more substantial in predicting the future water response this real situation modeling case also considers three future loading scenarios as introduced in table 3 fig 12 shows that the baipu and the sequential bma approach only have a slight difference in the frequency distributions which indicates that the interaction between parameters and inputs in the bayesian analysis is not as significant as that in the synthetic case the difference between individual models are more significant but not as significant as that in the synthetic case fig 8 this is because two time variant loading scenarios are considered in this real situation case while the synthetic case considers five scenarios of constant loadings thus in the wwq modeling adequately accounting for the temporal variability of source loadings is critical to the results of stochastic modeling all the above results clearly demonstrate the applicability and usefulness of baipu in the context of real world water quality management 5 conclusions this study develops a new approach baipu for the joint analysis of input and parametric uncertainties through a tight coupling of mcmc and bma the formal likelihood function for this approach is also derived considering a lag 1 autocorrelated heteroscedastic and sep distributed error model input uncertainty in a discrete form is specifically addressed which is commonly encountered in environmental modeling for real world problems a series of numerical experiments were designed and implemented based on a synthetic nitrate pollution case as well as the real pollution case in the newport bay watershed california the major conclusions include the following first with parallel computing the baipu can be implemented with reasonable computational costs and appropriately identify the uncertain parameters and characterize the predictive uncertainty second if significant input uncertainty is not accounted for wwq modeling may seriously mislead management decisions because the input uncertainty must be compensated for by the parametric uncertainty third the baipu accounts for the interaction between the input and parametric uncertainties through joint analysis and is mathematically more rigorous than the sequential approach thus in theory it can provide more accurate calibration and uncertainty results than the sequential approach finally the baipu quantifies the credibility i e the model weights of different input assumptions on a statistical basis and it can be implemented as an inverse modeling approach for joint inference of both model parameters and inputs the baipu was originally designed to address discrete form input uncertainty but future studies may expand the baipu to a joint analysis of model structural input and parametric uncertainties in addition the baipu has a great potential of being applied in fields other than watershed water quality modeling for example in basin scale groundwater modeling boundary conditions of subsurface inflow are often highly uncertain wu et al 2014 which could be addressed in the framework of baipu acknowledgments this work was supported by the national natural science foundation of china no 41622111 no 91647201 and the china postdoctoral science foundation 2017m612505 additional support was provided by the southern university of science and technology no g01296001 we thank dr jasper a vrugt at the university of california irvine for kindly discussing with us on dream zs supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2018 04 006 appendix supplementary materials image application 1 
813,significant input uncertainty is a major source of error in watershed water quality wwq modeling it remains challenging to address the input uncertainty in a rigorous bayesian framework this study develops the bayesian analysis of input and parametric uncertainties baipu an approach for the joint analysis of input and parametric uncertainties through a tight coupling of markov chain monte carlo mcmc analysis and bayesian model averaging bma the formal likelihood function for this approach is derived considering a lag 1 autocorrelated heteroscedastic and skew exponential power sep distributed error model a series of numerical experiments were performed based on a synthetic nitrate pollution case and on a real study case in the newport bay watershed california the soil and water assessment tool swat and differential evolution adaptive metropolis dream zs were used as the representative wwq model and mcmc algorithm respectively the major findings include the following 1 the baipu can be implemented and used to appropriately identify the uncertain parameters and characterize the predictive uncertainty 2 the compensation effect between the input and parametric uncertainties can seriously mislead the modeling based management decisions if the input uncertainty is not explicitly accounted for 3 the baipu accounts for the interaction between the input and parametric uncertainties and therefore provides more accurate calibration and uncertainty results than a sequential analysis of the uncertainties and 4 the baipu quantifies the credibility of different input assumptions on a statistical basis and can be implemented as an effective inverse modeling approach to the joint inference of parameters and inputs keywords water quality modeling watershed bayesian model averaging markov chain monte carlo input uncertainty bayesian calibration 1 introduction watershed water quality wwq models typically integrate distributed hydrological modeling with water quality modeling and depict the interrelated watershed processes of water heat sediments and chemicals borah and bera 2003 some representative wwq models include the soil and water assessment tool swat arnold et al 1998 neitsch et al 2009 watershed analysis risk management framework warmf chen et al 2004 zheng et al 2011 hydrological simulation program fortran hspf bicknell et al 1997 and annualized agricultural non point source pollution model annagnps young et al 1989 bingner et al 2015 these models have been widely used to address a variety of water and environmental issues including agricultural non point source nps pollution jeon et al 2007 huang and hong 2010 pease et al 2010 volk et al 2016 volk et al 2017 water quality response to climate change cho et al 2016 nguyen et al 2017 food energy water nexus few karabulut et al 2016 psomas et al 2016 low impact development lid her et al 2017 and many others however simulation results of the wwq models often have notable uncertainty zheng and keller 2007 rode et al 2010 first owing to current knowledge gaps the existing models often represent complex water quality processes e g soil erosion heat exchange pollutant transport and chemical reactions in a highly simplified way which leads to significant model structural errors rode et al 2010 beck 1987 van griensven and meixner 2006 second while the quantity and quality of the hydrological forcing data e g precipitation and temperatures have been greatly improved due to the development of remote sensing knoche et al 2014 water quality drivers e g point source ps and nps loadings still lack good data with the required temporal and spatial resolutions han and zheng 2016 which represents a significant input uncertainty in the wwq models third wwq models involve a larger number of model parameters and the parametric uncertainty would be substantial when observational data for model calibration are scarce and or inaccurate the multiple sources of uncertainty significantly hinder the application of wwq models in scientific research and management practices and effective approaches to uncertainty analysis are highly desired for the models bayesian calibration using markov chain monte carlo mcmc sampling gelman et al 2003 robert and casella 2004 is a formal approach for model calibration and uncertainty assessment and has been applied widely in recent years kuczera and parent 1998 bates and campbell 2001 marshall et al 2004 yang et al 2007 smith and marshall 2008 vrugt et al 2008c in the approach model residuals i e the difference between observations and corresponding model outputs are described by a statistical residual error model based on which the likelihood function can be derived box and tiao 1992 when the prior distribution is provided the posterior parameter distribution can be inferred by adopting the bayes rule the approach has explicit assumptions and a rigorous mathematical basis but its effectiveness is dependent on many issues one issue is the appropriateness of the error model for example in hydrological modeling model residuals are often correlated heteroscedastic and not normally distributed kuczera 1983 there are a series of studies which discuss the residual model bates and campbell 2001 yang et al 2007 schaefli et al 2007 schoups and vrugt 2010 smith et al 2010 evin et al 2013 honti et al 2013 another important issue is the consideration of input uncertainty and model structural errors a classic bayesian calibration approach directly addresses the parametric uncertainty and leaves out the other two uncertainty sources which may bias the inference of the posterior distributions our previous study shows that such degradation can be alleviated by including additional model responses that are less impacted by the input and model structural errors in a multiple response bayesian calibration mrbc framework han and zheng 2016 another solution is to jointly assess the input structural and parametric uncertainties although this remains challenging renard et al 2010 hierarchical bayesian approaches such as bayesian total error analysis batea kavetski et al 2006 integrated bayesian uncertainty estimator ibune ajami et al 2007 integrated parameter estimation and uncertainty analysis tool ipeat yen et al 2014 and some others vrugt et al 2008b li et al 2012 have been developed to quantify the model input uncertainty along with model calibration in the existing approaches input errors are usually represented by latent variables e g rainfall multipliers with prescribed hyperdistributions the hierarchical bayesian inference addresses all uncertain model parameters and latent variables as well as all hyperparameters thyer et al 2009 although these approaches can separate the input and parametric uncertainties their hierarchical inference framework can lead to high dimensional posterior distributions and sampling of the posterior distributions can be computationally prohibitive especially for complex wwq models more importantly in wwq modeling it is very difficult to represent the input uncertainty of pollutant loadings in terms of latent variables bayesian model averaging bma has been increasingly used to account for model structural uncertainty ajami et al 2007 raftery et al 2005 duan et al 2007 rojas et al 2008 zhang et al 2009 bastola et al 2011 zeng et al 2016 wellen et al 2014 bma derives an aggregated simulation by averaging the simulations of multiple models based on their posterior probabilities also referred to as the model weights leamer 1978 hoeting et al 1999 bma has also been used for model ranking and selection where the model weights should balance goodness of fit with complexity following the law of parsimony schoniger et al 2015 tsai and li 2008 volpi et al 2017 in hydrological and water quality modeling it is a common situation for multiple plausible datasets or assumptions to be used to prepare a specific model input for example precipitation data can be simulated by a regional climate model interpolated from observations at meteorological stations or estimated based on radar data land cover data can be interpreted from different types of satellite data and different agencies may have different estimates of pollutant loadings in all these cases the input uncertainty can hardly be represented as continuous probability distributions and needs to be addressed in a discrete form bma appears to be an appropriate way to address such input uncertainty for example strauch et al 2012 established four swat models with four different sets of precipitation data and then performed bma to account for the precipitation uncertainty in streamflow modeling some studies have attempted the coupling of bma with bayesian calibration in a sequential manner that is performing bayesian calibration for individual models first and then achieving an aggregated simulation using bma for example zeng et al 2016 sequentially performed mcmc and bma analyses to assess groundwater conceptualization uncertainty however this sequential approach ignores the interaction between the parametric uncertainty and conceptual uncertainty which may lead to inaccurate results under certain circumstances this study aims to develop an approach to investigating parametric and input uncertainties simultaneously through a tight coupling of mcmc and bma the approach is specifically designed for input uncertainty in a discrete form as exemplified above a previously developed swat model for the nitrate pollution in the newport bay watershed southern california u s was used as the study case and a state of art mcmc algorithm the differential evolution adaptive metropolis dream zs vrugt et al 2008b vrugt et al 2009 laloy and vrugt 2012 was employed a series of numerical experiments were designed and implemented to answer the following key questions 1 whether the new approach can effectively address the discrete form input uncertainty in mcmc based bayesian calibration 2 how the discrete form input uncertainty in pollutant loadings would impact the bayesian calibration results and potential water quality management decisions based on the results and 3 what information the joint analysis of input and parametric uncertainties can provide to measure the relative importance of the competing model input assumptions 2 coupling mcmc and bma 2 1 mcmc uncertainty analysis markov chain monte carlo mcmc uncertainty analysis represents a classic bayesian calibration approach in this approach the residual errors i e ε z f are described by a statistical error model where f and z are the model outputs and the observations respectively this lumped error accounts for all sources of uncertainty including model input model structure model parameters and observations for model calibration schoups and vrugt 2010 with the mathematical form of the error model specified the likelihood function of model parameters can be derived and the posterior distributions of the parameters can be obtained based on bayes rule as 1 p θ φ x z p θ p φ l θ φ x z where θ represents model parameters φ denotes the parameters of the error model x denotes the model input p θ and p φ are the prior distributions and l θ φ x z is the likelihood function in an mcmc algorithm samples are obtained by constructing markov chains with desired posterior distributions as their stationary distributions gelman et al 2003 robert and casella 2004 the samples obtained by the markov chains are used to derive the posterior distribution of uncertain parameters p θ φ x z as well as the predictive distribution p y θ φ z where y denotes a vector of quantities to be predicted explanation of the approach to derive the predictive distribution can be found elsewhere zheng and han 2015 this paradigm has been widely used in uncertainty analysis for hydrological modeling kuczera and parent 1998 bates and campbell 2001 marshall et al 2004 yang et al 2007 smith and marshall 2008 vrugt et al 2008c this study considers an autocorrelated heteroscedastic and non gaussian error model han and zheng 2016 zheng and han 2015 the autocorrelation of residuals is depicted by a first order autoregressive model i e ar 1 which involves a parameter lag 1 autoregressive parameter ϕ the heteroscedasticity is reflected by a linear equation σ t b 1 b 2 ft where σ t is the estimated standard deviation ft is the model output at time step t and b 1 and b 2 are the two parameters the skew exponential power sep distribution schoups and vrugt 2010 is employed to represent two typical non gaussian effects i e skewness and kurtosis where the skewness parameter ξ and the kurtosis parameter β are introduced thus the error model has five parameters in this case that is φ ϕ b 1 b 2 ξ β the log likelihood function can be formulated as 2 l o g l θ φ z j l o g 2 σ ξ ω β ξ ξ 1 j 1 j log σ j c β j 1 j a ξ j 2 1 β where j is the data length of z a ξ j ξ s i g n μ ξ σ ξ a j μ ξ σ ξ a j in which aj stands for the independent and identically distributed random errors with a zero mean and unit standard deviation and μξ σξ ωβ and c β are functions of ξ and β more details about the error model and likelihood function can be found elsewhere han and zheng 2016 schoups and vrugt 2010 evin et al 2013 note that this highly complicated likelihood function may lead to an undesired computational burden on the uncertainty analysis to simplify the error model as well as the corresponding likelihood function a trail and error approach can be adopted to examine the fulfillment of the statistical assumptions a posteriori one can gradually increase the complexity of the error model as was done in previous studies han and zheng 2016 zheng and han 2015 differential evolution adaptive metropolis dream zs vrugt et al 2008b vrugt et al 2009 laloy and vrugt 2012 is employed in this study as the mcmc algorithm it is a population evolution mcmc algorithm which runs multiple markov chains in parallel to facilitate the global exploration of the parameter space it automatically tunes the scale and orientation of the proposal distribution in dream zs a candidate point can be generated by using a differential evolution with a randomized subspace sampling strategy which can be described as follows 3 θ i θ i 1 d e d γ δ d j 1 δ u r 1 j n 1 δ u r 2 n є d where θ i is the candidate point θ i is the current point of the ith markov chain e d and ϵ d are two d dimensional random vectors the coefficient γ controls the jumping size and u r 1 j u r 2 n j n 1 δ represents δ pairs of previously sampled points r 1 j r 2 n in high dimension problems it is often not optimal to sample all d dimensions simultaneously in dream zs only d dimensions of θ i which are randomly selected with a crossover probability are updated in each sampling step and the other dimensions remain the same as those of θ i to increase diversity the snooker update is included which is an additional way to generate candidate points the way to propose a candidate point is described as follows 4 θ i θ i γ s θ i u d u r 1 u r 2 where γs is a random variable u u r 1 and u r 2 are three previously sampled points and d is a function of u r 1 and u r 2 both d and γs are used to determine the distance of the jumping more details of the snooker update can be found in ter braak and vrugt 2008 in dream zs both differential evolution and snooker update are used to generate the candidate points in this study we updated the markov chains in a mix of 10 snooker update and 90 differential evolution the r statistics proposed by gelman and rubin 1992 are used to assess the convergence of the markov chains the markov chains are deemed to achieve the convergence when the r values of all dimensions or parameters are below 1 2 computed based on the last 50 points of the markov chains 2 2 loose coupling the sequential approach as mentioned in section 1 mcmc based bayesian calibration can be coupled with bma in a sequential manner to account for input uncertainty hereinafter models with the same model structure but different inputs are considered as different models when k plausible input datasets x 1 x k are collected or assumed for a same model structure k different models m 1 mk can be established respectively which represents the input uncertainty in a discrete form mcmc uncertainty analysis can first be performed for each model to assess the parametric uncertainty next the predictive distributions inferred based on the k models i e p y mk z are averaged into a total predictive distribution representing both parametric and input uncertainties this two step uncertainty analysis is referred to as the sequential bma approach in this paper its mathematical details are provided below bma provides a data driven approach to statistically integrate the predictions of multiple models leamer 1978 hoeting et al 1999 let y y 1 yt yt denote the vector of quantities to be predicted i e the true values and let z denote the observations in bma the predictive distribution of yt based on the kth model mk can be deemed as the posterior distribution of yt conditional on z that is p yt mk z thus the posterior distribution of yt conditional on the entire model ensemble can be written as 5 p y t z k 1 k p y t m k z p m k z where p mk z stands for the posterior probability of mk and p mk z can be interpreted as the likelihood of mk being correct given z because the posterior probabilities of all the models have a sum of one p mk z can also be interpreted as the weight of mk hereinafter p mk z is denoted as wk and w w 1 wk the mean and variance of bma predictions can be computed as 6 e y t z k 1 k w k e y t m k z 7 var y t z k 1 k w k e y t m k z e y t z 2 k 1 k w k var y t m k z the predictive distribution p yt mk z can be computed as 8 p y t m k z ω k p y t m k θ k φ k p θ k φ k m k z d θ k d φ k where θ k denotes the model parameters of mk φ k denotes the error parameters associated with the residual error model θ k φ k ω k p yt mk θ k φ k represents the predictive distribution of yt given the specific values of θ k andφ k and p θ k φ k mk z represents the posterior distribution of θ k andφ k the calculation of the integral in eq 8 is computationally intensive alternatively the integral can be approximated using the posterior samples generated in the mcmc analysis as robert and casella 2004 9 p y t m k z 1 n k n 1 n k p y t m k θ k n φ k n where θ k n and φ k n denote the nth sample of model parameters and error parameters respectively jointly generated by the markov chain and nk is the sample size assuming independence among the residual errors the log likelihood function of the model weights can be derived as 10 l o g l w z j 1 j log k 1 k w k 1 n k n 1 n k p z j m k θ k n φ k n note that the assumption of independence may not be valid for example when lag 1 autocorrelation of the residual errors exists zj should be conditional on z j 1 in such cases p z j m k θ k n φ k n in eq 10 should be replaced by p z j m k θ k n φ k n z j 1 raftery et al 2005 suggested to estimate the weights using the maximum likelihood estimation mle for complex likelihood functions the expectation maximization em algorithm dempster et al 1977 can be employed to find a numerical solution for the mle problem with a small computational cost however the em method only leads to a set of deterministic weight estimates and the results can be unstable when the weights are sensitive to the observations a more reliable way is to perform mcmc simulation vrugt et al 2008a in which the means of the sampled weights can be used as the posterior probabilities of the respective models there are also other options to determine the model weights such as the bayesian model evidence method volpi et al 2017 in this study we adopted dream zs to sample model weights in the sequential bma approach to guarantee a sum of one for the weights of a candidate point i e θ i we modified the original operation of generating candidate points to the following steps step 1 generate a jumping vector by eqs 3 or 4 with at least two elements of being non zero step 2 normalize by subtracting the mean of the updated elements and therefore the sum of the normalized is equal to zero step 3 generate the candidate point θ i θ i the sum of θ i is one as the sum of θ i is one step 4 if θ i is outside of the sampling domain calculate a new point θ i using the returning operation introduced below as θ i may be outside of sampling domain a returning operation was proposed as illustrated in fig 1 when the proposed jump from θ i to θ i hits the boundary i e θ b is reached the jump turns back along the original path and ends at θ i in this case the total jumping distance in its absolute value remains the same because the sum of is zero the sum of θ i remains one similarly a jump from θ i with the same jumping vector will end at θ i it suggests that with the returning operation the conditional probability of a jump from θ i to θ i is equal to that of the reverse jump i e from θ i to θ i thus the detailed balance of dream zs can be guaranteed by accepting the candidate point θ i or θ i based on the metropolis acceptance probability laloy and vrugt 2012 2 3 tight coupling baipu this study develops a new approach to jointly analyze the input and parametric uncertainties by tightly coupling bma with mcmc which is named the bayesian analysis of input and parametric uncertainties baipu fig 2 illustrates the framework of baipu it begins with the preparation of k sets of plausible input data which result in k models as defined in section 2 2 thus given the same model structure one realization of model parameters θ would lead to k sets of model outputs f 1 f k in baipu a shared residual error model with parametersφ is also assumed for the model ensemble hence the multiple models share the same set of uncertain parameters i e θ plusφ the predictive distributions of yt derived based on different models can be further averaged by bma as 11 p y t m 1 k θ φ k 1 k w k θ φ p y t m k θ φ where wk θ φ represents the weight of the kth model given specific values of θ and φ and p yt mk θ φ is the predictive distribution of yt based on the kth model i e the kth input dataset in eq 11 the dependency of the model weights on θ and φ reflects the interaction between the input and parametric uncertainties which is ignored in the sequential bma approach assuming independence among the residual errors the log likelihood function of the model parameters and error parameters can be defined as 12 l o g l θ φ w z j 1 j log k 1 k w k θ φ p z j m k θ φ if lag 1 autocorrelation among the residual errors exists the probability of zj in eq 12 should also be conditional on z j 1 that is p zj mk θ φ z j 1 the mcmc analysis is then performed to derive the posterior distributions of model parameters and predictive variables as discussed in section 2 1 there are different strategies to infer the model weights the framework of baipu accommodates two fig 2 one strategy is to estimate the weights by the em algorithm when a realization of θ andφ is generated in one sampling step the corresponding model weights wk θ φ k 1 k are then determined by maximizing this likelihood function using the em optimization the other strategy is to sample the model weights jointly with the model parameters using mcmc to implement this strategy the returning operation introduced in section 2 2 needs to be incorporated in dream zs such that the model weights in each candidate point add up to one because the mcmc sampling is more reliable than the em optimization all the baipu results presented in this paper were based on the mcmc sampling for comparison we also performed all the baipu analyses using the em approach section 4 1 briefly discusses the comparison and readers are referred to the auxiliary materials for more details one difference between the baipu and sequential bma approach is that the baipu derives a common posterior parameter distribution based on the entire set of plausible model inputs while the sequential approach leads to multiple posterior parameter distributions with respect to different model inputs note that the multiple posterior parameter distributions could be further averaged into a single posterior distribution by resampling the multiple distributions according to their posterior probabilities i e the model weights however although such a posterior distribution is relevant to the parameter calibration it cannot be directly assigned to each model for making predictions which is an advantage of baipu in addition in the baipu because a common posterior parameter distribution can be obtained the model weights solely reflect the model input uncertainty however in the sequential bma approach the input and the parametric uncertainties can compensate for each other in the bayesian calibration therefore the weights are impacted by the parametric uncertainty the error model introduced in section 2 1 is considered for the model ensemble which involves five error parameters that is φ ϕ b 1 b 2 ξ β let ε kt yt fkt denote the residual error of the k th model i e input x k at time step t where fkt is the corresponding model output as mentioned before the standard deviation of ε kt is estimated by σ kt b 1 b 2 fkt and hence the standardized residuals can be calculated as η k t ɛ k t σ k t the ar 1 model is applied to the standardized residuals to account for the lag 1 autocorrelation that is η kt ϕη k t 1 okt it is a standard homoscedastic ar 1 process and variance of okt equals 1 ϕ 2 thus the variance of a k t o k t 1 ϕ 2 should be a unit similarly we assume that akt follows the sep distribution hence given the specific values of θ andφ the predictive probability of yt based on the k th model can be computed as 13 p y t m k θ φ y t 1 1 1 ϕ 2 σ k t 2 σ ξ ω β ξ ξ 1 exp c β a ξ k t 2 1 β where a ξ k t ξ s i g n μ ξ σ ξ a k t μ ξ σ ξ a k t and μξ σξ ωβ and c β are functions of ξ and β schoups and vrugt 2010 according to eq 12 the log likelihood function for this residual error model can be derived as 14 l o g l θ φ w z j 1 j log k 1 k w k θ φ 1 1 ϕ 2 σ k j 2 σ ξ ω β ξ ξ 1 exp c β a ξ k j 2 1 β this likelihood function is quite general and flexible it relaxes the commonly used independent homoscedastic and gaussian assumption about the residual errors and hence is more realistic for environmental modeling as was revealed by han and zheng 2016 when model input errors are very significant the inferred posterior distributions of the model parameters would be prone to notable bias this likelihood function which is based on multiple input datasets rather than one single set of input data is expected to be more accurate and reliable it is worth re emphasizing that baipu was specifically designed to address discrete form input uncertainty if the input uncertainty could be appropriately characterized as continuous probability distributions the bma step in baipu may not be an efficient solution in baipu the sampler dream zs would execute k times more model runs than in a traditional mcmc uncertainty analysis if the chains have the same length in this study the computational cost was largely reduced by parallelizing the sampling process that is making dream zs execute n chain k model runs n chain denotes the number of markov chains simultaneously in parallel similar parallel calculation was adopted for the sequential bma as well 3 data and methods 3 1 study area the newport bay watershed nbw is in orange county southern california it is a highly urbanized watershed with an area of approximately 400 km2 fig 3 as of 2001 approximately 70 of the watershed was residential commercial and industrial areas and agricultural and orchard areas accounted for approximately 8 the nbw has a typical mediterranean climate with warm dry summers and mild wet winters the annual rainfall is approximately 330 mm and occurs mostly between november and april nutrient pollution was a significant water quality issue in this area in the 1990 s excessive loadings of nutrients were delivered into the newport bay through the san diego creek see fig 3 which had caused the eutrophication of the bay and created the recreational and aesthetic nuisance u s environmental protection agency 1998 major sources of nutrients included fertilizer application non point source and commercial nurseries point sources the nbw and san diego creek were included in the 1998 california 303 d list of impaired waters for total maximum daily loads tmdl actions with nutrients as a major pollutant stressor u s environmental protection agency 1999 more details about this watershed can be found in our previous studies zheng and han 2015 zheng and keller 2008 3 2 nitrate pollution modeling swat is a representative wwq model which is semi distributed and runs at a daily time step neitsch et al 2009 a swat model of the nitrate pollution in the nbw has been previously developed han and zheng 2016 zheng and han 2015 in brief the watershed was first delineated into 11 sub basins see fig 3 with a total of 58 hydrologic response units hrus the 90 m digital elevation model dem of the study area was acquired from the u s geological survey usgs to delineate the modeling domain the 30 m land use raster from the national land cover database 2001 nlcd 2001 and the soil type map from the u s state soil geographic statsgo database were referred to in defining the hrus meteorological data from 1998 to 2004 were obtained from u s national climatic data center ncdc and used to drive the model simulations the model was run from july 1998 to june 2004 with the first two years being the warm up period and the last four years being the calibration period observations of daily flow and weekly nitrate concentration at the watershed outlet fig 3 a from july 2000 to june 2004 were collected from the santa ana regional water quality control board reports available at http prg ocpublicworks com docmgmtinternet search aspx last accessed on october 8 2017 and were used for the model calibration in this study nitrate was the water quality parameter of concern and nitrogen source loadings were considered as the uncertain model inputs in the nbw fertilizer application on urban lawns and effluents from commercial nurseries were the two major nitrogen sources u s environmental protection agency 1998 in the swat model bermuda was selected as the representative lawn grass and the nurseries were conceptualized into two point sources a and b see fig 3 a as detailed information of the timing of fertilizer application is not available the heat unit scheduling in swat was chosen which allows the model to schedule operations based on temperature to simulate the stormwater runoff and nitrate pollution in urban areas swat offers two options one is to use a set of linear empirical equations developed by the usgs referred to as the usgs option and the other is to simulate the buildup and washoff processes referred to as the buildup washoff option although the buildup washoff option is conceptually appealing local data to parameterize the equations is often lacking hence the usgs option was chosen in this study in our previous study han and zheng 2016 the nitrate loadings at sources a and b were estimated to be 61 kg n day and 31 kg n day respectively and the fertilizer usage was assumed to be 240 kg n ha year the ps loadings were assumed to be time invariant because no detailed temporal information was available inevitably significant input uncertainty exists in the source loadings which would degrade the calibration of the uncertain model parameters thus this study considers multiple plausible ps and nps loadings instead which will be further discussed in section 3 4 3 3 multiple response bayesian calibration to alleviate the impact of input and model structural errors the streamflow and nitrate concentration at the watershed outlet are calibrated simultaneously by applying the mrbc approach developed in our previous study han and zheng 2016 in the context of the mrbc different error models are required for different responses based on which individual likelihood functions can be established in this study residual errors of streamflow and nitrate concentration are assumed to be independent hence the combined likelihood function is simply the product of their likelihood functions han and zheng 2016 balin talamba et al 2010 15 l m u l t i p l e l h θ φ h z h l n θ φ n z n where lh and ln are the likelihood functions of streamflow and nitrate concentration respectively in this study the likelihood functions of flow and nitrate responses are determined by eqs 2 and 14 in the sequential bma approach and baipu respectively 3 4 numerical experiments in the real situation case five loading scenarios were assumed to account for the input uncertainty which leads to five real situation models rms see table 1 among the five models rm2 is the basic model that was built in our previous study han and zheng 2016 and represents an average loading situation rm1 has 20 lower ps loadings and 10 lower fertilizer usage compared to rm2 while rm3 has 20 higher ps loadings and 10 higher fertilizer usage rm4 and rm5 are two models with temporal variability in the ps loadings while rm4 has a smaller seasonal fluctuation see fig s1 in the auxiliary materials note that the overall loadings in rm4 and rm5 are the same as those in rm2 this ensemble of models effectively embodies a common situation encountered in wwq modeling that is detailed and accurate loading data are often lacking and the modeler may consider different assumptions the selection of random parameters in the bayesian calibration was the same as in our previous study han and zheng 2016 in brief 32 swat parameters that are physically relevant for flow and or nitrate simulations were identified first next 12 most important parameters table 2 were further determined after an initial sensitivity analysis on the 32 parameters using morris screening campolongo et al 2007 each of the 12 parameters ranks top 8 among the 32 initial parameters at least for one of the two responses i e flow and nitrate full details of the selection procedure can be found in our previous study han and zheng 2016 as most of the parameters have spatially distributed values three strategies yang et al 2007 were considered to vary them varying the parameter value directly type i adding a deviation value to the distributed parameters type ii and applying a multiplier to the distributed parameters type iii for parameters of type ii and iii the deviations and multipliers other than the original distributed parameters are treated as uncertain model parameters in subsequent calibration approaches all the uncertain parameters are assumed to be uniformly distributed and their ranges are provided in table 2 initialization of other non random parameters is also the same as in the previous study han and zheng 2016 to investigate the applicability and performance of baipu a synthetic modeling case was also constructed in which a true model denoted as tm with true model parameters true model inputs and true model structure was hypothesized table 1 the true values of the 12 uncertain parameters the last column in table 2 were randomly picked which can yield realistic simulation results true nitrate loadings at sources a and b were assumed to be time variant at the levels of 132 and 68 kg n day respectively see fig s2 in the auxiliary materials the fertilizer usage in tm was assumed to be 240 kg n ha year and scheduled on specific dates the buildup washoff method was selected as the true model structure for the simulation of stormwater pollution from urban areas other model settings were the same as that in the real situation case true model responses of flow and nitrate concentration at the watershed outlet were achieved by running the true model with the above settings in addition to the perfect model i e tm five imperfect models ims with different source loadings were also created denoted as im1 im2 im3 im4 and im5 see table 1 the ps loadings were set to be time invariant which reflects the reality that the temporal information of ps loadings is often unavailable among the models im3 represents the average loading level i e 150 kg day and 75 kg day at sources a and b respectively and im1 im2 im4 and im5 represent the 66 7 83 3 116 7 and 133 3 of the average loading level respectively similarly different fertilizer application rates were hypothesized for the five imperfect models table 1 the five imperfect models collectively represent the hypothetical input uncertainty to better mimic the reality the model structural error was also introduced in the ims the usgs option was used instead of the buildup washoff option daily flow observations and weekly nitrate observations at the outlet were synthesized by corrupting the true model responses with hypothetic observational errors see fig s3 in the auxiliary materials the hypothetic errors were generated from an error model with b 1 h 0 2 b 2 h 0 05 β h 0 5 ξ h 3 φ h 0 2 b 1 n 0 2 b 2 n 0 3 β n 0 5 ξ n 3 and φ n 0 this procedure represents a common strategy to synthesize observational data zheng and keller 2007 schoups and vrugt 2010 smith et al 2010 as in the real situation case the artificial observations were generated for the period from july 2000 to june 2004 and all the models i e the tm and ims were run from july 1998 to june 2004 in both the synthetic and real situation cases the baipu and the sequential bma approach were carried out in the baipu the model weights were jointly sampled with the model and error parameters i e the joint sampling method and in the sequential bma approach the model weights were sampled by dream zs hereinafter baipu ims denotes the baipu analysis on the five imperfect models and mcmc im1 mcmc im2 mcmc im3 mcmc im4 and mcmc im5 denote the mcmc uncertainty analyses for the five individual models respectively these individual mcmc analyses constitute the first step in the sequential bma approach the same terminology is applied to the real situation case the computational efficiency posterior distributions of the uncertain swat parameters and the uncertainty results of the two approaches were evaluated and compared it is worth pointing out that each model e g im1 in the sequential bma approach has its individual error model while the multiple models in the baipu share the same error model in determining the proper error model the complexity of the error models was gradually increased from simple independent homoscedastic and gaussian type to the most complicated type until the posterior checks confirmed that the residual errors are consistent with the error model assumptions the error models for different calibration procedures are summarized in table s1 in the auxiliary materials posterior justification of these error models is illustrated by figs s4 s8 in the auxiliary materials eventually nine error parameters were included in the uncertainty analysis i e φ ϕ h b 1 h b 2 h ξ h β h b 1 n b 2 n ξ n β n in this study the error parameters were jointly inferred with the uncertain swat parameters i e θ in the mcmc sampling to further compare the sequential bma approach and the baipu three future loading scenarios with increased steady and decreased loadings were proposed for the period from july 2004 to june 2008 table 3 the calibrated models were run to predict the nitrate concentration with the proposed future loading scenarios to investigate how the calibration procedure would impact management decisions two management relevant variables average nitrate concentration avc and frequency of exceeding foe the water quality target 6 mg n l were evaluated based on the predictions in the synthetic case the true nitrate concentrations under different loading scenarios were obtained by running the true model i e tm whereby the true values of avc and foe can be achieved in the real situation case the true model was unknown and hence the true avcs and foes were not obtainable 4 results and discussion 4 1 efficiency of dream zs in baipu twelve markov chains were run simultaneously in dream zs and 12 k cpus 2 67 ghz were utilized in parallel to reduce the computing time where k is the size of model ensemble with the parallel computing the cost of implementing dream zs is affordable for example evaluating 200 000 samples in the baipu typically takes one day for the modeling cases the sequential bma approach has two stages of dream zs the second stage is to sample the model weights and the computational cost is only a few minutes because this stage involves no swat runs to ensure that the posterior distributions and uncertainty results were reliable and representative dream zs explored 400 000 and 300 000 samples for the synthetic and real situation cases respectively using the fixed sample numbers can rule out the effect of computational cost when interpreting the analysis results of different models the numbers are large enough to ensure the convergence of markov chains in most of the experiments table 4 shows the number of samples for markov chains to achieve convergence nc and the acceptance rate ar of dream zs in different numerical experiments as indicated by the nc values the convergence speed of markov chains in baipu was comparable to that in the mcmc uncertainty analyses in the real situation case but was moderately slower in the synthetic case one obvious reason for the speed decrease is that baipu leads to a higher dimensional posterior distribution ar is the probability that one candidate point is accepted in stationarity it can be estimated as t t where t and t denote the numbers of all and the accepted candidate points in the second halves of the markov chains respectively a higher ar simply means that it is easier to find an acceptable candidate point with relatively high posterior probability as table 4 shows in the two step sequential bma dream zs obtained one order of magnitude higher ar values in estimating the model weights than in deriving the posterior parameter distributions this is because the likelihood function of the model and error parameters eq 2 is much more complex than that of the model weights eq 10 another interesting finding is that the two baipu analyses yielded several fold higher ar than the respective mcmc uncertainty analyses of individual models this is probably because the multi model ensemble allows a broader range of predictions than a single model making it easier to find an acceptable candidate point overall the results in table 4 indicate that the sampling efficiency of dream zs in baipu was not significantly reduced by the integration with bma as mentioned in section 2 3 we also tested the em strategy to infer the model weights in the baipu it has been found that the em strategy led to a faster convergence of markov chains nc is 363 120 and 105 120 in the synthetic and real situation cases respectively but lower acceptance rates ar is 2 75 and 7 14 in the synthetic and real situation cases respectively the em and joint sampling strategies yielded very similar posterior parameter distributions uncertainty results and future predictions refer to figs s9 s12 in the auxiliary materials yet the model weights are quite different with the two strategies fig s13 in the auxiliary materials these results demonstrate that the joint sampling is more reliable for the weight estimation however if the convergence speed is an important concern and accurate weight estimation is not a goal the em strategy can be desirable 4 2 the synthetic modeling case 4 2 1 posterior parameter distributions fig 4 illustrates the posterior parameter distributions derived by the baipu red lines and the mcmc analyses dotted lines for the individual models in the synthetic case the true values of the model parameters are indicated by the dashed vertical lines in the figure all the parameter values were rescaled to 0 1 by a linear min max normalization the posterior parameter distributions derived by the baipu red lines are relatively narrow and generally embrace the respective true parameter values except for the initial depth of water in the shallow aquifer shallst and the denitrification threshold water content sdnco parameter the posterior distribution of shallst is wide but still embraces the true value while the posterior distribution of sdnco is far off the true value this is probably because the uncertainty of this parameter compensated the model structure error not explicitly accounted for in this study and or the interaction between the two parameters and the input assumptions in the mcmc sampling is significant fig 4 indicates that the model parameters have been appropriately identified by the baipu in general for most parameters the posterior distributions based on the individual mcmc analyses are different from each other as well as from the respective distribution derived by the baipu the difference is most evident for im5 the model with the most significant input error this indicates that the calibration results can be highly dependent on the input assumption therefore an ensemble approach such as baipu is valuable for addressing the parametric uncertainty similar calibration results of the error parameters are presented in fig s14 in the auxiliary materials 4 2 2 model weights fig 5 compares the model weights based on the baipu and the sequential bma approach the weight results in the two approaches are similar in general the lower the input loading the higher the model weights among the five models the input scenario of im2 is closest to the true one see table 1 but it only achieves the second highest weight in both approaches im1 receives the highest weight in both approaches while its input scenario is the third closest to the true one the hypothesized true ps loadings have skew distributions featured by a limited number of loading pulses see fig s2 in the auxiliary materials therefore the mean values of the true nitrate loadings e g 131 95 kg n day at source a are much higher than the respective medians e g 88 58 kg n day at source a this explains why the inference favors the lowest input loading scenario im1s because the constant loadings in im1 are much closer to the medians of the true ps loadings both baipu and sequential bma enable the correlation analysis of the model weights which helps in understanding the tradeoff between different input scenarios it was found that both approaches lead to very similar correlation results see table s2 in the auxiliary materials baipu also allows a correlation analysis between the model weights and the parameters because they are jointly sampled by dream zs as table 5 shows strong correlations exist in many parameter weight pairs especially for shallst and sdnco the two parameters that were not well identified this implies that the significant interaction between the two parameters and the input assumptions in the mcmc sampling may be one reason for the weak identifiability of the two parameters it also confirms the necessity of sampling model parameters and weights jointly in baipu 4 2 3 uncertainty results fig 6 displays the uncertainty results of the nitrate concentration achieved by the baipu and the sequential bma approach the medians and confidence intervals in fig 6 a and b are very similar in both approaches the seasonal variation is well captured by the time series of the median concentrations the nash sutcliffe coefficients of the median predictions by baipu and the sequential bma approach are 0 2932 and 0 2804 respectively the observations are also adequately embraced by the uncertainty bands as demonstrated by fig 6 a and b 48 33 and 50 72 of the observations are within the 50 confidence intervals respectively and 97 13 and 97 61 of the observations are within the 95 confidence intervals respectively fig 6 c and d shows that the means and standard deviations of the predictive distributions derived in the two approaches are very close in the sequential bma approach the predictive means of individual models are first calculated and then the ensemble predictive means are derived based on eq 6 while in the baipu the ensemble predictive means for each sampled realization of uncertainty parameters are first calculated according to eq 6 and then the total predictive means are derived by averaging over all the sampled realizations of uncertainty parameters the standard deviations illustrated in fig 6 d can be derived in a similar way based on eq 7 the quantile quantile qq plots thyer et al 2009 of nitrate concentration in the synthetic case were also produced for the baipu individual mcmc analyses and the sequential bma approach fig 7 a the qq plots can provide intuitive information on the consistency of predictive distribution with observations in a qq plot if all the points are on the 45 degree line the predictive distribution agrees perfectly with the observations in fig 7 a all the predictive distributions demonstrate adequate consistency in general the baipu and the sequential approach perform better than individual mcmc analyses because both approaches account for the input uncertainty among the individual models im2 leads to the best consistency because its loading scenario is closest to the true one it is worth pointing out that although the predictive distributions of different approaches are similar figs 6 and 7 a the corresponding posterior parameter distributions significantly vary which may have a significant impact on future predictions and management decisions based on the stochastic modeling this issue will be discussed further in section 4 2 4 4 2 4 future predictions and management decisions the wwq models are commonly used to assess hypothetical loading scenarios based on which management decisions can be made with a strong scientific basis to investigate the performance of the different approaches in predicting future water quality and therefore supporting decision making three future loading scenarios were assumed in the synthetic case as discussed in section 3 4 and summarized in table 3 the future loading scenarios are free of input errors two management variables average nitrate concentration avc and frequency of exceeding foe the water quality target i e 6 mg n l were evaluated using the true parameter values as well as the parameter values sampled in the bayesian analyses fig 8 illustrates the cumulative frequency curves cfc of avc and foe derived by different approaches note that in the baipu and mcmc analyses for individual models the frequencies of avc and foe were calculated using the parameter realizations in the second halves of the markov chains in the sequential bma approach the frequencies are weighted averages of the corresponding frequencies derived by individual mcmc analyses thus the range of corresponding cfc depends on both the spread of the cfcs by the mcmc analyses and the model weights as fig 8 shows in general the cfcs derived by baipu solid red lines and the sequential bma approach solid blue lines are both close to the respective true values it indicates that the two approaches are relatively effective in reducing the bias caused by the input errors in the calibration stage the cfcs by baipu are relatively narrower because baipu derived a common posterior parameter distribution moreover the baipu demonstrates a better performance than the sequential approach in predicting the management variables which reflects the fact that the interaction between input uncertainty and parametric uncertainty is considered in contrast the five individual models lead to distinct predictions some of which are far away from the respective true values this implies that the potential management decisions based on the bayesian calibration of individual models would be seriously biased if the model inputs have large errors furthermore the impact of the bias on potential decision making could be dependent on the confidence level desired by the decision maker take foe in scenario 3 as an example refer to fig 8 f if a confidence level of 50 is considered the value of foe would be 0 28 according to im5 therefore the discrepancy with the true value is 0 14 however given a confidence level of 95 the discrepancy would instead be 0 07 fig 8 also shows that im1 which underestimates the observations in the calibration stage i e mcmc im1 overpredicts avc and foe im5 which overestimates the observations now underpredicts avc and foe this is because in the bayesian calibration of individual models the model parameters compensate for the effect of the input errors such that the observations can be better matched for example underestimated ps loadings would lead to parameter values prone to overestimate the water quality response i e the case of im1 thus when the model inputs are free of error the compensation in the calibration stage causes an overreaction of the model at the prediction stage similar overreaction behaviors although not as significant have also been observed for other individual models interestingly im3 has the best performance for predicting the two management variables instead of im2 with the smallest input errors which implies the compensation effect is complex and nonlinear all the above results suggest that a bayesian approach accounting for multiple plausible input assumptions can provide a valuable mechanism for alleviating the impact of input uncertainty and therefore enhancing the reliability of decision making in the context of real world management in addition with the interaction between the input and parametric uncertainties systematically accounted for the baipu has an improved performance in predicting management variables under the future loading scenarios compared to the straightforward sequential bma approach it is also worth emphasizing that one needs to carefully make input assumptions based on his her best knowledge when implementing the two approaches this may require extra work such as data collection and compiling field survey literature review etc in theory it is not a problem for baipu to accommodate many inappropriate input assumptions but in practice it may significantly increase the computational burden 4 3 the real situation modeling case the performances of baipu and sequential bma were also examined using the real situation modeling case table 1 fig 9 shows the posterior parameter distributions derived by the baipu red lines and the mcmc analyses for individual models dotted lines compared to the synthetic case fig 4 the difference between the baipu and the individual mcmc analyses is relatively small which implies that the influence of input uncertainty on the parameter calibration is not as significant as that in the synthetic case shallst and sdnco are the two parameters with the most significant difference in the posterior distributions which is also observed in fig 4 in addition the posterior distributions of the error parameters are presented in fig s15 in the auxiliary materials fig 10 illustrates the model weights inferred by the baipu and the sequential bma approach in this case the overall weight patterns derived by the two approaches are similar as introduced in section 3 2 rm2 represents an average estimation of the nitrogen loadings based on the available data while rm1 and rm3 represent a lower loading scenario and a higher loading scenario respectively among the first three models fig 10 a c rm1 receives the largest weights while rm2 and rm3 receive the second and third largest weights in both approaches it suggests that the original loadings in rm2 has a large probability of overestimation on the other hand in rm4 and rm5 the ps loadings are assumed to have small and large seasonal fluctuations respectively the potential seasonal fluctuation could be due to the temporal variability of tailwater discharges from the commercial nurseries as shown in fig 10 d and e both rm4 and rm5 were assigned significant weights which provides a unique evidence of the existence of seasonal variability in the ps loadings table 6 shows the correlations between the model weights and parameters in baipu although statistically significant in general the correlations in the real situation case are not as strong as those in the synthetic case indicating a weaker interaction between the input and parametric uncertainties in addition table s3 in the auxiliary materials shows the correlations between different model weights in this real situation case baipu and the sequential approaches led to slightly different results the predictive uncertainty bands of the nitrate response are shown in fig 11 the median predictions black lines in fig 11 a and b adequately match the observations in the baipu and the sequential approach the 50 confidence intervals encompasses 50 24 and 51 18 of the observations respectively the 95 confidence intervals encompasses 96 21 and 96 68 of the observations respectively fig 11 c and d further compare the predictive means and standard deviations derived by the two approaches in general the baipu produces the same predictive means as the sequential approach but smaller standard deviations this indicates that the baipu reduces the predictive uncertainty in this case compared to the sequential approach the uncertainty results presented in figs 11 and 7 b suggest that the two approaches as well as those individual mcmc analyses have a similar performance during the bayesian calibration however as revealed in the synthetic case the difference could be more substantial in predicting the future water response this real situation modeling case also considers three future loading scenarios as introduced in table 3 fig 12 shows that the baipu and the sequential bma approach only have a slight difference in the frequency distributions which indicates that the interaction between parameters and inputs in the bayesian analysis is not as significant as that in the synthetic case the difference between individual models are more significant but not as significant as that in the synthetic case fig 8 this is because two time variant loading scenarios are considered in this real situation case while the synthetic case considers five scenarios of constant loadings thus in the wwq modeling adequately accounting for the temporal variability of source loadings is critical to the results of stochastic modeling all the above results clearly demonstrate the applicability and usefulness of baipu in the context of real world water quality management 5 conclusions this study develops a new approach baipu for the joint analysis of input and parametric uncertainties through a tight coupling of mcmc and bma the formal likelihood function for this approach is also derived considering a lag 1 autocorrelated heteroscedastic and sep distributed error model input uncertainty in a discrete form is specifically addressed which is commonly encountered in environmental modeling for real world problems a series of numerical experiments were designed and implemented based on a synthetic nitrate pollution case as well as the real pollution case in the newport bay watershed california the major conclusions include the following first with parallel computing the baipu can be implemented with reasonable computational costs and appropriately identify the uncertain parameters and characterize the predictive uncertainty second if significant input uncertainty is not accounted for wwq modeling may seriously mislead management decisions because the input uncertainty must be compensated for by the parametric uncertainty third the baipu accounts for the interaction between the input and parametric uncertainties through joint analysis and is mathematically more rigorous than the sequential approach thus in theory it can provide more accurate calibration and uncertainty results than the sequential approach finally the baipu quantifies the credibility i e the model weights of different input assumptions on a statistical basis and it can be implemented as an inverse modeling approach for joint inference of both model parameters and inputs the baipu was originally designed to address discrete form input uncertainty but future studies may expand the baipu to a joint analysis of model structural input and parametric uncertainties in addition the baipu has a great potential of being applied in fields other than watershed water quality modeling for example in basin scale groundwater modeling boundary conditions of subsurface inflow are often highly uncertain wu et al 2014 which could be addressed in the framework of baipu acknowledgments this work was supported by the national natural science foundation of china no 41622111 no 91647201 and the china postdoctoral science foundation 2017m612505 additional support was provided by the southern university of science and technology no g01296001 we thank dr jasper a vrugt at the university of california irvine for kindly discussing with us on dream zs supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2018 04 006 appendix supplementary materials image application 1 
814,existing analytical solutions for the distribution of fresh groundwater in subsea aquifers presume that the overlying offshore aquitard represented implicitly contains seawater here we consider the case where offshore fresh groundwater is the result of freshwater discharge from onshore aquifers and neglect paleo freshwater sources a recent numerical modeling investigation involving explicit simulation of the offshore aquitard demonstrates that offshore aquitards more likely contain freshwater in areas of upward freshwater leakage to the sea we integrate this finding into the existing analytical solutions by providing an alternative formulation for steady interface flow in subsea aquifers whereby the salinity in the offshore aquitard can be chosen the new solution taking the aquitard salinity as that of freshwater provides a closer match to numerical modeling results in which the aquitard is represented explicitly notation respective equation numbers given in brackets α presumed salinity of the offshore aquitard 0 is seawater 1 is freshwater β cubic equation factor 24 δ dimensionless distance from the shoreline to the interface toe ϕ dimensionless freshwater head above sea level 12 ϕ 0 shoreline value of ϕ κ modulus of elliptic integrals 26 λ dimensionless horizontal length to the interface tip λs dimensionless horizontal length of the offshore aquitard 17 γ 0 shoreline value of γu 17 γu dimensionless discharge 16 η vertical thickness of freshwater in the offshore aquifer 7 μ dimensionless discharge 17 θ modular angle of elliptic integrals 26 ρf freshwater density ρs seawater density ξ dimensionless horizontal distance 12 ξ 1 ξ 4 ξ for cases i ii iii and iv see fig 3 for respective origins ζ dimensionless vertical distance from the aquifer base to the interface 12 γ12 γ34 boundary values of μ versus λs distinguishing cases i to iv a integration constant 15 a coefficient of differential equation solution a19 b integration constant 19 b coefficient of differential equation solution a19 c h 1 kv 10 d distance from toe to shoreline e κ complete elliptic integral of the second kind e θ κ incomplete elliptic integral of the second kind 25 f ϕ a β a function 25 f θ κ incomplete elliptic integral of the first kind 25 f 3 f 4 two reference points cases iii and iv of coordinates μ λs g an intermediate variable 26 h head of the freshwater region within the offshore aquifer 3 h l freshwater head of a column of seawater above the top of the aquitard 1 hs freshwater head of a column of seawater above the top of the aquifer 5 h thickness of the offshore aquifer 12 h 1 thickness of the offshore aquitard 3 hs depth of seawater above the offshore aquitard 1 h 1 dimensionless aquitard thickness 13 k aquifer hydraulic conductivity kv vertical hydraulic conductivity of the offshore aquitard k κ complete elliptic integral of the first kind lf leakage factor 12 l horizontal distance from the origin to the interface tip ls offshore aquitard horizontal length m 1 m 6 six reference points of coordinates μ λs along boundaries p root of cubic equation 24 p 4 reference point of coordinates μ λs at the intersection of cases i to iv qz vertical component of specific discharge through the offshore aquitard 3 q 0 shoreline value of qx 17 qx vertically integrated fresh groundwater discharge 8 t integration variable 25 t subscript subscript to indicate a parameter at the transition between cases vs dimensionless seawater freshwater density difference 2 x horizontal spatial coordinate y variable in a cubic form 24 y 0 lower integration limit a25 z vertical spatial coordinate zs elevation of the sea 1 introduction freshwater is known to occur in a multitude of offshore aquifers around the globe post et al 2013 fresh groundwater in offshore aquifers may derive from the continental discharge that occurs under present day conditions and or may have been emplaced during the low sea levels of glacial maxima during the pleistocene epoch cohen et al 2010 methods for the rapid estimation of offshore freshwater extent attributable to continental discharge include the analytical solutions of edelman 1972 kooi and groen 2001 and bakker 2006 bakker et al 2017 provide an extension to bakker s 2006 solution by modifying the landward boundary condition and correcting an error in the graphical representation of the methodology these methods have proven to be beneficial for the initial investigation of offshore freshwater in subsea aquifers including their potential to supplement onshore groundwater pumping for example bakker 2006 found that the hydrogeological conditions near the georgia florida border usa are sufficient to have created an extensive offshore freshwater body in continental shelf aquifers the cross sectional conceptual model for offshore freshwater adopted by bakker 2006 and others is illustrated in fig 1 showing an onshore confined aquifer connected to an offshore leaky aquifer the dual aquifer system in the onshore setting is simplified to an onshore confined aquifer to avoid the mathematical challenge of resolving connected upper and lower aquifers the analytical solutions provided by bakker 2006 and bakker et al 2017 referred to collectively as bakker s solutions in the remainder require an assumption for the salinity in offshore aquitards which overly offshore aquifers and inhibit the freshwater seawater mixing that would otherwise degrade the subsea freshwater they presume that offshore aquitards contain seawater even where they host upward freshwater leakage to the sea from underling aquifers in a concurrent numerical modeling investigation solórzano rivas and werner 2018 show that offshore aquitards are more likely to contain freshwater where upward freshwater leakage occurs they also provide a methodology for correctly simulating offshore aquitards using the implicit approach of the popular seawat code langevin et al 2008 solórzano rivas and werner 2018 conclude that bakker s solutions over predict the offshore extent of freshwater by a factor of approximately two due to the assumption that offshore aquitards contain seawater they recommend that a revision to bakker s solutions is required whereby offshore aquitards are presumed to contain freshwater in areas of upward leakage to the sea the aim of this research is to provide a sharp interface mathematical model under dupuit assumptions for the offshore aquitard containing water with salinity ranging from that of freshwater to seawater thereby incorporating bakker s solutions as a special case we anticipate that this will overcome the discrepancies between analytically derived interface locations and those obtained from numerical simulation such as those of solórzano rivas and werner 2018 the quality of the revised analytical model is demonstrated by comparing with results from seawat 2 mathematical model of semi confined interface flow the aim of the following mathematical development is to determine and calculate a head distance relationship given a confined aquifer onshore and its finite length extension below the sea surface as a semi confined aquifer i e overlain by a leaking aquitard the notation used by bakker 2006 is largely followed the offshore part of the problem is shown schematically in fig 2 the freshwater head h 1 of the sea at the top of the aquitard is given by 1 h 1 z s v s h s where as shown in fig 2 hs is the height of the sea surface above the aquitard and zs is the elevation of the sea the datum for zs is arbitrary but commonly taken as the impermeable base of the aquifer or sea level the dimensionless density difference between seawater and freshwater vs is given by 2 v s ρ s ρ f ρ f with ρf and ρs the respective densities for freshwater and seawater the use of darcy s law to calculate flow across the offshore aquitard to the ocean in regions where the aquifer contains freshwater requires presumption of the aquitard salinity that is 3 q z k v h 1 h h t ρ a ρ f ρ f h is the head in the freshwater region of the aquifer kv is the hydraulic conductivity of the leaking aquitard and ρa is the density of the aquitard fluid bakker s 2006 assumption of seawater in the aquitard leads to ρ a ρ s whereas if the aquitard contains freshwater ρ a ρ f and the buoyancy term of eq 3 disappears we introduce the factor α whereby α 0 represents the seawater assumption of bakker 2006 and bakker et al 2017 α 1 is the freshwater assumption and 0 α 1 is mixed seawater and freshwater rewriting eq 3 in terms of vs and α 4 q z k v h h 1 h 1 1 α v s where h 1 is the aquitard thickness as shown in fig 2 note that we assume that the aquitard overlying the fresh part of the offshore aquifer contains only one salinity type i e there is no salinity spatial variability bakker 2006 writes eq 4 in terms of the freshwater head hs of a column of static seawater at the level of the horizontal top of the aquifer 5 h s z s v s h s h 1 hs is also equal to the head at the top of the aquifer h 1 plus the buoyancy force caused by seawater in the aquitard and is convenient to adopt because freshwater occurs in the aquifer only where h hs werner 2017 combining eqs 5 and 3 and letting ρ a ρ s i e presuming the aquitard contains seawater produces bakker 2006 6 q z k v h 1 h h s the thickness η of the freshwater zone see fig 2 is approximated by the ghyben herzberg formula e g bear 1979 7 η h h s v s assuming darcy s law and the dupuit approximation the vertically integrated freshwater discharge qx at distance x of arbitrary origin see fig 2 is defined by 8 q x k η d h d x with k the constant hydraulic conductivity of the aquifer flow continuity requires 9 d q x d x d d x k η d h d x q z eq 4 becomes on using eqs 1 and 5 and introducing c h 1 k v 10 q z k v h h 1 α h 1 v s h 1 k v v s h h s α h 1 v s c now using eq 7 for η and eq 10 for qz the continuity eq 9 becomes 11 d d x k h h s v s d h d x h h s α h 1 v s c non dimensional variables ϕ ζ and ξ are now defined by 12 ϕ h h s v s h ζ 1 ϕ ξ x l f here ζ is the vertical dimensionless distance from aquifer base to interface h is the depth of the base below the aquitard as in fig 2 and the leakage factor is defined by l f k h c eq 11 now becomes 13 d d ξ ϕ d ϕ d ξ ϕ α h 1 with h 1 h 1 h the quantity α h 1 is to be considered as a single quantity because neither α nor h 1 appear separately in the analysis the introduction of the quantity α h 1 and its ramifications in the ensuing analysis is the generalisation of bakker s original model following the procedure used by bakker 2006 and sikkema and van dam 1982 eq 13 is solved by first multiplying throughout by ϕ 14 ϕ d d ξ ϕ d ϕ d ξ ϕ d d ϕ ϕ d ϕ d ξ d ϕ d ξ 1 2 d d ϕ ϕ d ϕ d ξ 2 ϕ 2 α h 1 ϕ now integrate to obtain 15 ϕ d ϕ d ξ 2 2 3 ϕ 3 3 2 α h 1 ϕ 2 a 3 with a a constant to be determined by boundary conditions at this stage it is convenient to introduce a dimensionless discharge γu by 16 γ u q x l f k h 2 v s ϕ d ϕ d ξ the particular value of γu at the shoreline where qx q 0 and ϕ ϕ 0 is denoted by γ 0 17 γ 0 μ q 0 l f k h 2 v s where μ is one of the three key parameters the others being α h 1 and λ s l s l f the length of the aquitard from the shoreline is denoted by ls taking the square root of both sides of eq 15 and using the negative root of the right side to give a positive γu 18 γ u 2 3 ϕ 3 3 2 α h 1 ϕ 2 a 3 from eq 15 a further integration gives 19 ξ 3 2 ϕ ϕ 3 3 2 α h 1 ϕ 2 a 3 d ϕ b where b is another constant to be determined by boundary conditions bakker 2006 defines four cases of interface problems arising from the above theory these are defined based on whether the toe where the interface meets the impermeable aquifer base is onshore cases i and iii or offshore cases ii and iv and whether the tip where the interface meets the base of the offshore aquitard is landward of the most seaward boundary cases i and ii or the tip reaches the offshore limit cases iii and iv from this point the analysis divides into two sections depending on whether a 0 defining cases i and ii or a 0 defining cases iii and iv another division introduced for simplicity of analysis is to consider different origins for variable ξ depending on the location of the toe for cases i and iii with the toe onshore set ξ ξ 1 for case i and ξ ξ 3 for case iii with ξ 1 ξ 3 and both variables originating at the shoreline although the introduction of the two coordinates having the same origins is mathematically redundant it is useful to have them when focusing on the particular cases similarly with the toe offshore cases ii and iv and the corresponding origin at the toe ξ ξ 2 for case ii ξ ξ 4 for case iv and ξ 2 ξ 4 fig 3 a d shows typical curves of the head and interface for some selected parameter combinations each falling into one of the four cases the numerical values used for constructing these curves are given in table 1 the quantities ϕ 0 and δ represent respectively the head at the shoreline and the distance of the toe from its origin λ is defined in the same way as λs namely λ l l f where l is the length from origin to tip in case i λ λs in case ii λ δ λs in case iii λ λs and in case iv λ δ λs fig 4 illustrates the division of the cases into four zones on the basis of μ and λs the boundaries of the zones are designated γ12 between cases i and ii γ13 between cases i and iii γ24 between cases ii and iv and γ34 between cases iii and iv a number of individual points are shown on the diagram labeled m1 to m6 f3 f4 and p4 these points are used in various parts of the analysis that follows m4 m6 f3 and f4 coincide with the parameter sets see table 1 used to create fig 3a b c and d respectively point p4 is a quadruple point where all four boundaries meet with coincidence of offshore tips and shoreline toes this diagram is essentially one defining zones for cases iii and iv with the horizontal axis as λs classes i and ii are defined solely by the value of μ because their tip values are less than the given non dimensional λs the areas designated as i and ii in the figure have all parameter values constant within them the points m1 to m6 are located on the joined boundaries γ13 γ24 to indicate their shore to tip values less than those at the aquitard seaward end summary of head equations from toe to tip details of the derivations of the following equations are given in the appendix including explicit expressions for ϕ 0 and δ d l f occurring below with d the distance from toe to shoreline for all four cases ϕ 1 ζ 0 at the toe and ϕ 0 ζ 1 at the tip the final expressions are case i 20 from shore to toe ϕ 2 2 μ ξ 1 ϕ 0 2 δ ξ 1 0 21 from shore to tip ϕ 1 6 ξ 1 λ ξ 1 λ 6 α h 1 0 ξ 1 λ case ii beyond the toe eq 21 is also applicable in this case but with ξ 1 replaced by ξ 2 22 ϕ 1 6 ξ 2 λ ξ 2 λ 6 α h 1 0 ξ 2 λ between toe and shoreline 23 ϕ 1 2 1 γ 0 α h 1 e ξ 2 1 2 1 γ 0 α h 1 e ξ 2 α h 1 δ ξ 2 0 with γ 0 2 3 α h 1 case iii the expression from shoreline to tip for ϕ is implicit involving cubic equations and elliptic integrals 24 ξ 3 3 β a 2 f ϕ a β f 0 a β λ s 0 ξ 3 λ s and β p a where p is the dominant and real zero of y 3 3 2 α h 1 y 2 a 3 and 25 f ϕ a β 1 g g f θ κ 2 g e θ κ 2 g sin θ 1 κ 2 sin 2 θ 1 cos θ f θ κ and e θ κ are incomplete elliptic integrals of the first and second kinds e g byrd and friedman 1971 respectively and 26 g 1 2 β 3 κ 1 1 2 β 3 g 2 g θ cos 1 g 1 ϕ β a g 1 ϕ β a the constant a is determined from boundary conditions at the shoreline where ϕ ϕ 0 from shoreline to tip the same expression as case i i e eq 20 holds and ξ 1 ξ 3 27 ϕ 2 2 μ ξ 3 ϕ 0 2 δ ξ 3 0 case iv from toe to tip the same form of equation as in eq 24 holds but with coordinate ξ 4 28 ξ 4 3 β a 2 f ϕ a β f 0 a β λ s 0 ξ 4 λ s with constant a now determined from conditions at the tip where ϕ 1 and ξ 4 λ λ s δ from toe to shoreline 29 ϕ 1 α h 1 cosh δ ξ 4 cosh δ μ sinh ξ 4 cosh δ α h 1 δ ξ 4 0 inland head equations the equation for inland head in the confined aquifer beyond the toe in cases i and iii depicted in fig 3a and b is 30 ϕ μ ξ 1 3 δ 1 whereas inland from the shoreline in cases ii and iv shown in fig 3c and d it is 31 ϕ μ ξ 2 4 δ ϕ 0 eqs 30 and 31 are linear in ϕ and are used when one or two of the parameters μ λs and α h 1 are not known for one unknown values of head and distance at a single point are required the most likely case being to find μ given λs and α h 1 for two parameters unknown values at two inland points are required a third point will not produce any new information for finding three unknowns because of the linear equations for ϕ mathematical details of zone boundaries the specific expressions defining the borders between the regions for the different cases with parameters subscripted by t for transition are defined by border between cases 1 and 2 γ12 32 μ t 2 3 α h 1 with λ s t l s t l f border between cases 1 and 3 γ13 33 λ s t 6 ϕ 0 9 α h 1 3 α h 1 where ϕ 0 in terms of μ is the real solution of the cubic equation 34 ϕ 0 3 3 2 α h 1 ϕ 0 2 3 2 μ t 2 0 border between cases 2 and 4 γ24 35 λ s t 6 9 α h 1 3 α h 1 log μ μ 2 1 γ 0 α h 1 1 γ 0 α h 1 1 γ 0 α h 1 with γ 0 2 3 α h 1 border between cases 3 and 4 γ34 36 3 β a 2 f 1 a t β f 0 a t β λ s t 0 with a t 3 2 μ t 2 α h 1 1 1 3 the coordinates of the quadruple point p4 are 37 λ s 4 μ 4 6 9 α h 1 3 α h 1 2 3 α h 1 3 numerical details iterative procedures are required in calculating a 0 involved in expressions containing elliptic integrals bakker 2006 chose the robust but slowly converging method of bisection this works well because the behavior of a is monotonic in both μ and λs and a 0 we adopt the more rapid muller frank method muller 1956 frank 1958 matthews and fink 2004 neither method requires function derivatives as opposed to newton s method however computational speed is not an issue here with either method for example a grid of 400 400 point values for ϕ 0 δ and a used in constructing the contours of fig 5 a c with α h 1 0 1 needed a few seconds on a personal computer for the bisection method and approximately a sixth of that for the muller frank method all programming was done in fortran using available software for computing incomplete elliptic integrals carlson and notis 1981 the contour plots of fig 5 are provided to show the behaviors of the quantities ϕ 0 and δ necessary for describing the head distance relationships as exemplified in fig 3a d and a the mathematical constant underpinning the calculations of these two quantities superimposed on each of these contour maps are the zonal boundaries of fig 4 in fig 5a the boundary γ13 joined with γ24 defines the line a 0 in fig 5b when the toe coincides with the shoreline the boundary γ12 joined with γ34 defines a line where δ 0 the negative values of δ correspond to the shoreline to inland toe distances for cases i and iii the same joining of boundaries also defines where ϕ 0 ϕ 1 as shown in the contours for ϕ 0 of fig 5c all three contour maps show the expected continuity of values across zonal boundaries and the constancy of values for constant μ outside the joined boundaries γ13 γ24 as shown on fig 4 a contour map of β produces similar contour shapes to those of fig 5a however it is more instructive to consider variations in λs at constant μ and plot values of a β and βa this is done for μ 4 and shown in fig 6 with λs covering the complete ranges of cases iii and iv the interesting results are that as λs γ24 a 0 β but β a 3 2 α h 1 for all α h 1 which in this case is 0 15 other cross sections show the same form of curves and the same limiting values the infinite value of β does not cause numerical problems because it only occurs separately from βa as 1 β in eq 26 additional iterations done by the muller frank method are required in the next section for determining μ values given onshore head and distance values as defined by eqs 30 and 31 fig 7 is included to show the effects of zone changes as α h 1 is increased contour plots analogous to fig 5a 5c show the same general patterns but compressed in accordance with the increasing compression of zones as shown in fig 7 4 comparison with results from seawat an important requirement is to compare the sharp interface analytical solutions with results from a more realistic model such as seawat a limited comparison is made by taking the seawat parameters and results from six models examined by solórzano rivas and werner 2018 the parameter values are hs 20 m h 1 1 m h 10 m h 1 0 1 k 10 m d ls 1 20 m ls 2 3000 m kv 5 1 0 5 0 01 0 001 0 0001 m d corresponding to the six models designated m1 m2 m3 m4 m5 m6 and ν s 0 025 μ and q 0 are determined from inland head eqs 30 or 31 with h 1 m relative to sea level and inland distances x 1 100 m and x 2 490 m table 2 shows comparisons between seawat aquitard with freshwater α 1 α h 1 0 1 designated fresh and bakker s results for α 0 α h 1 0 the meaning of table 2 designations such as 3 1 is model m3 with ls 1 x 1 and kv value of 0 5 m d similarly 6 2 is model m6 with ls 2 x 2 and kv value of 0 0001 m d the λs μ coordinates shown in fig 4 of the six models in sequence m1 to m6 are 0 373 0 062 0 622 0 137 0 756 0 190 0 916 0 267 1 484 0 678 1 963 1 229 fig 8 compares interface distributions from the three approaches for the model 4 2 i e model m4 with ls 2 x 2 and kv value of 1 m d the results in table 2 show that for all six models the assumption of freshwater in the aquitard outperforms the assumption of seawater by comparison to seawat s estimates for the seaward discharge q 0 and the location of the tip the average q 0 discrepancy analytical versus seawat estimates improves from 2 to 0 4 when the aquitard is presumed to contain freshwater instead of seawater the higher q 0 obtained when freshwater is used for the aquitard salinity is the intuitive outcome of the lower head and therefore reduced resistance of the subsea boundary when the water density in the aquitard is lower a marked improvement is obtained in the tip location for which the average discrepancy reduces from 87 to 2 when freshwater rather than seawater is presumed for the aquitard salinity in the case of the seawater assumption the more seaward tip location obtained using bakker s 2006 seawater assumption is again caused by the higher head of the subsea boundary relative to the freshwater case which requires a smaller outflow face the average discrepancy in the analytically derived toe location increases from 11 to 14 when the aquitard is presumed to contain freshwater instead of seawater in contradiction to the tip and q 0 findings both the fresh and bakker analytical toe locations are landward of the seawat toe location with the freshwater model landward of the bakker model the latter trend is caused by the lower head in the aquitard in the fresh model which leads to higher flow rates for a given inland boundary head and therefore greater head losses by darcy s law and more landward toe positions added to this effect dispersion is known to produce toe locations that are seaward of estimates obtained from sharp interface methods e g mehdizadeh et al 2014 werner 2017 applied seawat to seawater intrusion problems with dispersion parameters set to zero in a similar manner to the current methodology and found analytical numerical discrepancies consistent with those encountered here and that could be explained by minor levels of artificial dispersion in seawat we expect similarly that artificial numerical dispersion in the seawat predictions have produced toe locations that are seaward of sharp interface values further investigation is needed to determine the impact of artificial dispersion on toe values produced by seawat to ascertain whether the freshwater or seawater in the aquitard assumption best reproduces the correct toe locations regardless on balance of the results the improvements in both q 0 and the tip location from presuming that aquitard contains freshwater more than offset the reduced accuracy in the toe location 5 concluding remarks previous analytical models of the extent of freshwater in offshore coastal aquifers have presumed that the overlying aquitard contains entirely seawater however this assumption has been challenged in a recent numerical modeling analysis which concludes that revised analytical solutions are needed that accommodate alternative salinities in the offshore aquitard in response the current study presents a revised analytical formulation for the extent of offshore fresh groundwater by including the offshore aquitard salinity as an input variable potentially ranging from freshwater to seawater otherwise the same assumptions as previous formulations apply namely the dupuit approximation steady state conditions homogeneity and geometric uniformity comparison of the new solution against numerical modeling confirms that the assumption of freshwater in the offshore aquitard outperforms the earlier seawater assumption as suggested by solórzano rivas and werner 2018 in particular the interface tip is well matched to the numerical results compared to tip location errors of 100 when the aquitard is presumed to contain seawater the freshwater assumption also produces slightly better estimates of freshwater discharge to the sea analytical values for the interface toe are landward of numerically derived estimates regardless of the presumed salinity in the aquitard the fresh aquitard conditions produces slightly worse matches to numerical modeling relative to the assumption of seawater in the aquitard although the effects of artificial dispersion in numerical estimates is expected to play a role in this comparison further work is needed to account for artificial dispersion in assessing the accuracy of analytically derived toe values application of the proposed methodology requires consideration of coastline geomorphology because in many cases paleo freshwater may occur in offshore aquifers emplaced during historic glacial maxima offshore freshwater extents obtained with the current method neglect these sources of freshwater an extension to the current method might include the evaluation of sea floor sediment stability whereby tidal fluctuations combined with vertical groundwater fluxes impact accretion erosion rates acknowledgments we appreciate the provision of seawat modeling results by cristina solórzano rivas adrian werner is the recipient of an australian research council future fellowship project number ft150100403 the suggestions of three anonymous reviewers are gratefully acknowledged appendix a mathematical analysis cases i and ii at the tip ξ 1 2 λ boundary conditions are a1 ϕ 0 and γ u 0 from eq 18 γu 0 requires a2 a 0 return to eq 19 and evaluate the indefinite integral with a 0 as a3 ϕ ϕ 3 3 2 α h 1 ϕ 2 d ϕ 2 ϕ 3 2 α h 1 then a4 ξ 1 2 6 ϕ 9 α h 1 b from eq 19 a5 b λ 3 α h 1 so that a6 ξ 1 2 6 ϕ 9 α h 1 3 α h 1 λ and from this a7 ϕ 1 6 ξ 1 2 λ ξ 1 2 λ 6 α h 1 0 ξ 1 2 λ for all ϕ 0 eq 18 gives a8 γ u 2 3 ϕ 3 α h 1 ϕ 2 in the transition between cases i and ii with the toe at the shoreline a9 ξ 1 2 0 ϕ 1 γ u μ t eq a8 then provides a10 μ t 2 3 α h 1 case i at the shoreline ξ 1 0 ϕ ϕ 0 and γu μ then eq a8 gives a11 ϕ 0 3 3 2 α h 1 ϕ 0 2 3 2 μ 2 0 a cubic equation in ϕ 0 given α h 1 and μ and providing one real root and two complex conjugate roots eq a6 then gives an expression for λ a12 λ 6 ϕ 0 9 α h 1 3 α h 1 for onshore confined flow with qz 0 eqs 9 and 13 reduce to a13 d d ξ 1 2 ϕ d ϕ d ξ 1 2 0 which integrates to a14 ϕ 2 2 μ ξ 1 2 ϕ 0 2 δ ξ 1 2 0 distance δ from interface to toe where ϕ 1 and ξ 1 2 δ is determined from eq a14 as a15 δ 1 ϕ 0 2 2 μ case ii at the toe ξ 2 0 and ϕ 1 then eq a6 is also an expression for λ as a16 λ 6 9 α h 1 3 α h 1 to find an expression for δ the required differential equation is a17 d 2 k h h d x 2 h h s α h 1 v s c or in dimensionless variables a18 d 2 ϕ d ξ 2 2 ϕ α h 1 the general solution of this equation is a19 ϕ a e ξ 2 b e ξ 2 α h 1 boundary conditions are i ξ 2 0 ϕ 1 and ii ξ 2 0 d ϕ d ξ 2 γ 0 2 3 α h 1 these determine a and b so that a20 ϕ 1 2 1 γ 0 α h 1 e ξ 2 1 2 1 γ 0 α h 1 e ξ 2 α h 1 δ ξ 2 0 with d ϕ d ξ 2 μ at ξ 2 δ an expression for determining δ then follows as a21 1 2 1 γ 0 α h 1 e 2 δ μ e δ 1 2 1 γ 0 α h 1 0 which solves as a22 δ log μ μ 2 1 γ 0 α h 1 1 γ 0 α h 1 1 γ 0 α h 1 with ξ 2 δ eq a20 gives a23 ϕ 0 1 2 1 γ 0 α h 1 e δ 1 2 1 γ 0 α h 1 e δ α h 1 cases iii and iv these cases have α 0 at the seaward end of the aquitard a24 ξ 3 4 λ s ϕ 0 returning to eq 19 the integration is now made explicit in the form a25 ξ 3 4 3 2 y 0 ϕ y y 3 3 2 α h 1 y 2 α 3 d y c o n s t the lower limit y 0 can be changed at will different values being absorbed into const however the square root of the cubic in the denominator suggests the use of standard expressions for elliptic integrals this is achieved by first noting that the cubic can be factored as a26 y 3 3 2 α h 1 y 2 a 3 y p y 2 a 3 p 2 y a 3 p where p is real and the zeros of the quadratic in y are complex conjugates if y 0 is replaced by p there is change of variable y pt and introduction of parameter β p a then a27 ξ 3 4 3 β a 2 ϕ β a 1 t 1 t t 2 t 1 β 3 d t b b is a constant to be determined by boundary conditions the integral is now in standard form for evaluation in terms of elliptic integrals using eqns 243 07 and 341 53 of byrd and friedman 1971 f ϕ a β ϕ β a 1 t 1 t t 2 t 1 β 3 d t a28 1 g g f θ κ 2 g e θ κ 2 g sin θ 1 κ 2 sin 2 θ 1 cos θ where f θ κ and e θ κ are incomplete elliptic integrals of the first and second kinds respectively with normal ranges 0 θ π 2 and 0 κ 1 in this particular mathematical model θ may lie in the range π 2 θ π for which the elliptic integrals are expressed as f θ κ 2k κ f π θ κ and e θ κ 2e κ e π θ κ where k κ and e κ are respective complete elliptic integrals of the first and second kinds e g byrd and friedman 1971 the other quantities in eq a28 are defined by a29 g 1 2 β 3 κ 1 1 2 β 3 g 2 g θ cos 1 g 1 ϕ β a g 1 ϕ β a ξ 3 4 is now expressed in the compact form for 0 ξ 3 4 λ s a30 ξ 3 4 3 β a 2 f ϕ a β b and b is obtained from eq a30 as a31 b λ s 3 β a 2 f 0 a β when α 0 then β 1 and all of the expressions above for ξ 3 4 and f ϕ a β reduce to those of bakker 2006 an important requirement is to determine the transition between cases iii and iv when the toe for each case coincides where ξ 3 4 0 ϕ 1 and a μ and λs are designated at μt and λst respectively the non linear equation for determining at follows from eqs a30 and a31 as a32 3 β a 2 f 1 a t β f 0 a t β λ s t 0 using the relationship between at and μt given by eq a8 with γu μt as eq a10 a33 μ t 2 3 1 a t 3 α h 1 i e a t 3 2 μ t 2 α h 1 1 1 3 which means that given λst then μt is found followed by at or vice versa case iii constant a is determined from the shoreline condition where γ 0 μ ϕ ϕ 0 and from eq 18 ϕ 0 is determined from the real root of the cubic equation a34 ϕ 0 3 3 2 α h 1 ϕ 0 2 a 3 3 2 μ 2 0 together with a35 3 β a 2 f ϕ 0 a β f 0 a β λ s 0 having found a ϕ 0 is then calculated from eq a34 the remaining quantity δ is then found from eq a15 of case i but with this new ϕ 0 a36 δ 1 ϕ 0 2 2 μ for shoreline to toe eq a14 also holds a37 ϕ 2 2 μ ξ 3 ϕ 0 2 δ ξ 3 0 case iv the differential equation defining ϕ is the same as eq a18 of case ii a38 d 2 ϕ d ξ 4 2 ϕ α h 1 with boundary conditions a39 ξ 4 0 ϕ 1 ξ 4 d λ d ϕ d ξ 4 μ providing the solution a40 ϕ 1 α h 1 cosh δ ξ 4 cosh δ μ sinh ξ 4 cosh δ α h 1 δ ξ 4 0 it is now required to find δ this is achieved by first determining an equation for a using two expressions for γ ϕ d ϕ d ξ 4 from eqs 16 and 18 and the derivative of eq a39 at ϕ 1 a41 2 3 1 a 3 α h 1 1 α h 1 tanh δ μ cosh δ solving for a and noting that λ λs δ then substituting in a42 3 β a 2 f 1 a β f 0 a β λ s δ 0 provides a non linear equation for δ an expression for ϕ 0 now follows from eq a40 with ξ 4 δ a43 ϕ 0 1 α h 1 cosh δ μ tanh δ α h 1 
814,existing analytical solutions for the distribution of fresh groundwater in subsea aquifers presume that the overlying offshore aquitard represented implicitly contains seawater here we consider the case where offshore fresh groundwater is the result of freshwater discharge from onshore aquifers and neglect paleo freshwater sources a recent numerical modeling investigation involving explicit simulation of the offshore aquitard demonstrates that offshore aquitards more likely contain freshwater in areas of upward freshwater leakage to the sea we integrate this finding into the existing analytical solutions by providing an alternative formulation for steady interface flow in subsea aquifers whereby the salinity in the offshore aquitard can be chosen the new solution taking the aquitard salinity as that of freshwater provides a closer match to numerical modeling results in which the aquitard is represented explicitly notation respective equation numbers given in brackets α presumed salinity of the offshore aquitard 0 is seawater 1 is freshwater β cubic equation factor 24 δ dimensionless distance from the shoreline to the interface toe ϕ dimensionless freshwater head above sea level 12 ϕ 0 shoreline value of ϕ κ modulus of elliptic integrals 26 λ dimensionless horizontal length to the interface tip λs dimensionless horizontal length of the offshore aquitard 17 γ 0 shoreline value of γu 17 γu dimensionless discharge 16 η vertical thickness of freshwater in the offshore aquifer 7 μ dimensionless discharge 17 θ modular angle of elliptic integrals 26 ρf freshwater density ρs seawater density ξ dimensionless horizontal distance 12 ξ 1 ξ 4 ξ for cases i ii iii and iv see fig 3 for respective origins ζ dimensionless vertical distance from the aquifer base to the interface 12 γ12 γ34 boundary values of μ versus λs distinguishing cases i to iv a integration constant 15 a coefficient of differential equation solution a19 b integration constant 19 b coefficient of differential equation solution a19 c h 1 kv 10 d distance from toe to shoreline e κ complete elliptic integral of the second kind e θ κ incomplete elliptic integral of the second kind 25 f ϕ a β a function 25 f θ κ incomplete elliptic integral of the first kind 25 f 3 f 4 two reference points cases iii and iv of coordinates μ λs g an intermediate variable 26 h head of the freshwater region within the offshore aquifer 3 h l freshwater head of a column of seawater above the top of the aquitard 1 hs freshwater head of a column of seawater above the top of the aquifer 5 h thickness of the offshore aquifer 12 h 1 thickness of the offshore aquitard 3 hs depth of seawater above the offshore aquitard 1 h 1 dimensionless aquitard thickness 13 k aquifer hydraulic conductivity kv vertical hydraulic conductivity of the offshore aquitard k κ complete elliptic integral of the first kind lf leakage factor 12 l horizontal distance from the origin to the interface tip ls offshore aquitard horizontal length m 1 m 6 six reference points of coordinates μ λs along boundaries p root of cubic equation 24 p 4 reference point of coordinates μ λs at the intersection of cases i to iv qz vertical component of specific discharge through the offshore aquitard 3 q 0 shoreline value of qx 17 qx vertically integrated fresh groundwater discharge 8 t integration variable 25 t subscript subscript to indicate a parameter at the transition between cases vs dimensionless seawater freshwater density difference 2 x horizontal spatial coordinate y variable in a cubic form 24 y 0 lower integration limit a25 z vertical spatial coordinate zs elevation of the sea 1 introduction freshwater is known to occur in a multitude of offshore aquifers around the globe post et al 2013 fresh groundwater in offshore aquifers may derive from the continental discharge that occurs under present day conditions and or may have been emplaced during the low sea levels of glacial maxima during the pleistocene epoch cohen et al 2010 methods for the rapid estimation of offshore freshwater extent attributable to continental discharge include the analytical solutions of edelman 1972 kooi and groen 2001 and bakker 2006 bakker et al 2017 provide an extension to bakker s 2006 solution by modifying the landward boundary condition and correcting an error in the graphical representation of the methodology these methods have proven to be beneficial for the initial investigation of offshore freshwater in subsea aquifers including their potential to supplement onshore groundwater pumping for example bakker 2006 found that the hydrogeological conditions near the georgia florida border usa are sufficient to have created an extensive offshore freshwater body in continental shelf aquifers the cross sectional conceptual model for offshore freshwater adopted by bakker 2006 and others is illustrated in fig 1 showing an onshore confined aquifer connected to an offshore leaky aquifer the dual aquifer system in the onshore setting is simplified to an onshore confined aquifer to avoid the mathematical challenge of resolving connected upper and lower aquifers the analytical solutions provided by bakker 2006 and bakker et al 2017 referred to collectively as bakker s solutions in the remainder require an assumption for the salinity in offshore aquitards which overly offshore aquifers and inhibit the freshwater seawater mixing that would otherwise degrade the subsea freshwater they presume that offshore aquitards contain seawater even where they host upward freshwater leakage to the sea from underling aquifers in a concurrent numerical modeling investigation solórzano rivas and werner 2018 show that offshore aquitards are more likely to contain freshwater where upward freshwater leakage occurs they also provide a methodology for correctly simulating offshore aquitards using the implicit approach of the popular seawat code langevin et al 2008 solórzano rivas and werner 2018 conclude that bakker s solutions over predict the offshore extent of freshwater by a factor of approximately two due to the assumption that offshore aquitards contain seawater they recommend that a revision to bakker s solutions is required whereby offshore aquitards are presumed to contain freshwater in areas of upward leakage to the sea the aim of this research is to provide a sharp interface mathematical model under dupuit assumptions for the offshore aquitard containing water with salinity ranging from that of freshwater to seawater thereby incorporating bakker s solutions as a special case we anticipate that this will overcome the discrepancies between analytically derived interface locations and those obtained from numerical simulation such as those of solórzano rivas and werner 2018 the quality of the revised analytical model is demonstrated by comparing with results from seawat 2 mathematical model of semi confined interface flow the aim of the following mathematical development is to determine and calculate a head distance relationship given a confined aquifer onshore and its finite length extension below the sea surface as a semi confined aquifer i e overlain by a leaking aquitard the notation used by bakker 2006 is largely followed the offshore part of the problem is shown schematically in fig 2 the freshwater head h 1 of the sea at the top of the aquitard is given by 1 h 1 z s v s h s where as shown in fig 2 hs is the height of the sea surface above the aquitard and zs is the elevation of the sea the datum for zs is arbitrary but commonly taken as the impermeable base of the aquifer or sea level the dimensionless density difference between seawater and freshwater vs is given by 2 v s ρ s ρ f ρ f with ρf and ρs the respective densities for freshwater and seawater the use of darcy s law to calculate flow across the offshore aquitard to the ocean in regions where the aquifer contains freshwater requires presumption of the aquitard salinity that is 3 q z k v h 1 h h t ρ a ρ f ρ f h is the head in the freshwater region of the aquifer kv is the hydraulic conductivity of the leaking aquitard and ρa is the density of the aquitard fluid bakker s 2006 assumption of seawater in the aquitard leads to ρ a ρ s whereas if the aquitard contains freshwater ρ a ρ f and the buoyancy term of eq 3 disappears we introduce the factor α whereby α 0 represents the seawater assumption of bakker 2006 and bakker et al 2017 α 1 is the freshwater assumption and 0 α 1 is mixed seawater and freshwater rewriting eq 3 in terms of vs and α 4 q z k v h h 1 h 1 1 α v s where h 1 is the aquitard thickness as shown in fig 2 note that we assume that the aquitard overlying the fresh part of the offshore aquifer contains only one salinity type i e there is no salinity spatial variability bakker 2006 writes eq 4 in terms of the freshwater head hs of a column of static seawater at the level of the horizontal top of the aquifer 5 h s z s v s h s h 1 hs is also equal to the head at the top of the aquifer h 1 plus the buoyancy force caused by seawater in the aquitard and is convenient to adopt because freshwater occurs in the aquifer only where h hs werner 2017 combining eqs 5 and 3 and letting ρ a ρ s i e presuming the aquitard contains seawater produces bakker 2006 6 q z k v h 1 h h s the thickness η of the freshwater zone see fig 2 is approximated by the ghyben herzberg formula e g bear 1979 7 η h h s v s assuming darcy s law and the dupuit approximation the vertically integrated freshwater discharge qx at distance x of arbitrary origin see fig 2 is defined by 8 q x k η d h d x with k the constant hydraulic conductivity of the aquifer flow continuity requires 9 d q x d x d d x k η d h d x q z eq 4 becomes on using eqs 1 and 5 and introducing c h 1 k v 10 q z k v h h 1 α h 1 v s h 1 k v v s h h s α h 1 v s c now using eq 7 for η and eq 10 for qz the continuity eq 9 becomes 11 d d x k h h s v s d h d x h h s α h 1 v s c non dimensional variables ϕ ζ and ξ are now defined by 12 ϕ h h s v s h ζ 1 ϕ ξ x l f here ζ is the vertical dimensionless distance from aquifer base to interface h is the depth of the base below the aquitard as in fig 2 and the leakage factor is defined by l f k h c eq 11 now becomes 13 d d ξ ϕ d ϕ d ξ ϕ α h 1 with h 1 h 1 h the quantity α h 1 is to be considered as a single quantity because neither α nor h 1 appear separately in the analysis the introduction of the quantity α h 1 and its ramifications in the ensuing analysis is the generalisation of bakker s original model following the procedure used by bakker 2006 and sikkema and van dam 1982 eq 13 is solved by first multiplying throughout by ϕ 14 ϕ d d ξ ϕ d ϕ d ξ ϕ d d ϕ ϕ d ϕ d ξ d ϕ d ξ 1 2 d d ϕ ϕ d ϕ d ξ 2 ϕ 2 α h 1 ϕ now integrate to obtain 15 ϕ d ϕ d ξ 2 2 3 ϕ 3 3 2 α h 1 ϕ 2 a 3 with a a constant to be determined by boundary conditions at this stage it is convenient to introduce a dimensionless discharge γu by 16 γ u q x l f k h 2 v s ϕ d ϕ d ξ the particular value of γu at the shoreline where qx q 0 and ϕ ϕ 0 is denoted by γ 0 17 γ 0 μ q 0 l f k h 2 v s where μ is one of the three key parameters the others being α h 1 and λ s l s l f the length of the aquitard from the shoreline is denoted by ls taking the square root of both sides of eq 15 and using the negative root of the right side to give a positive γu 18 γ u 2 3 ϕ 3 3 2 α h 1 ϕ 2 a 3 from eq 15 a further integration gives 19 ξ 3 2 ϕ ϕ 3 3 2 α h 1 ϕ 2 a 3 d ϕ b where b is another constant to be determined by boundary conditions bakker 2006 defines four cases of interface problems arising from the above theory these are defined based on whether the toe where the interface meets the impermeable aquifer base is onshore cases i and iii or offshore cases ii and iv and whether the tip where the interface meets the base of the offshore aquitard is landward of the most seaward boundary cases i and ii or the tip reaches the offshore limit cases iii and iv from this point the analysis divides into two sections depending on whether a 0 defining cases i and ii or a 0 defining cases iii and iv another division introduced for simplicity of analysis is to consider different origins for variable ξ depending on the location of the toe for cases i and iii with the toe onshore set ξ ξ 1 for case i and ξ ξ 3 for case iii with ξ 1 ξ 3 and both variables originating at the shoreline although the introduction of the two coordinates having the same origins is mathematically redundant it is useful to have them when focusing on the particular cases similarly with the toe offshore cases ii and iv and the corresponding origin at the toe ξ ξ 2 for case ii ξ ξ 4 for case iv and ξ 2 ξ 4 fig 3 a d shows typical curves of the head and interface for some selected parameter combinations each falling into one of the four cases the numerical values used for constructing these curves are given in table 1 the quantities ϕ 0 and δ represent respectively the head at the shoreline and the distance of the toe from its origin λ is defined in the same way as λs namely λ l l f where l is the length from origin to tip in case i λ λs in case ii λ δ λs in case iii λ λs and in case iv λ δ λs fig 4 illustrates the division of the cases into four zones on the basis of μ and λs the boundaries of the zones are designated γ12 between cases i and ii γ13 between cases i and iii γ24 between cases ii and iv and γ34 between cases iii and iv a number of individual points are shown on the diagram labeled m1 to m6 f3 f4 and p4 these points are used in various parts of the analysis that follows m4 m6 f3 and f4 coincide with the parameter sets see table 1 used to create fig 3a b c and d respectively point p4 is a quadruple point where all four boundaries meet with coincidence of offshore tips and shoreline toes this diagram is essentially one defining zones for cases iii and iv with the horizontal axis as λs classes i and ii are defined solely by the value of μ because their tip values are less than the given non dimensional λs the areas designated as i and ii in the figure have all parameter values constant within them the points m1 to m6 are located on the joined boundaries γ13 γ24 to indicate their shore to tip values less than those at the aquitard seaward end summary of head equations from toe to tip details of the derivations of the following equations are given in the appendix including explicit expressions for ϕ 0 and δ d l f occurring below with d the distance from toe to shoreline for all four cases ϕ 1 ζ 0 at the toe and ϕ 0 ζ 1 at the tip the final expressions are case i 20 from shore to toe ϕ 2 2 μ ξ 1 ϕ 0 2 δ ξ 1 0 21 from shore to tip ϕ 1 6 ξ 1 λ ξ 1 λ 6 α h 1 0 ξ 1 λ case ii beyond the toe eq 21 is also applicable in this case but with ξ 1 replaced by ξ 2 22 ϕ 1 6 ξ 2 λ ξ 2 λ 6 α h 1 0 ξ 2 λ between toe and shoreline 23 ϕ 1 2 1 γ 0 α h 1 e ξ 2 1 2 1 γ 0 α h 1 e ξ 2 α h 1 δ ξ 2 0 with γ 0 2 3 α h 1 case iii the expression from shoreline to tip for ϕ is implicit involving cubic equations and elliptic integrals 24 ξ 3 3 β a 2 f ϕ a β f 0 a β λ s 0 ξ 3 λ s and β p a where p is the dominant and real zero of y 3 3 2 α h 1 y 2 a 3 and 25 f ϕ a β 1 g g f θ κ 2 g e θ κ 2 g sin θ 1 κ 2 sin 2 θ 1 cos θ f θ κ and e θ κ are incomplete elliptic integrals of the first and second kinds e g byrd and friedman 1971 respectively and 26 g 1 2 β 3 κ 1 1 2 β 3 g 2 g θ cos 1 g 1 ϕ β a g 1 ϕ β a the constant a is determined from boundary conditions at the shoreline where ϕ ϕ 0 from shoreline to tip the same expression as case i i e eq 20 holds and ξ 1 ξ 3 27 ϕ 2 2 μ ξ 3 ϕ 0 2 δ ξ 3 0 case iv from toe to tip the same form of equation as in eq 24 holds but with coordinate ξ 4 28 ξ 4 3 β a 2 f ϕ a β f 0 a β λ s 0 ξ 4 λ s with constant a now determined from conditions at the tip where ϕ 1 and ξ 4 λ λ s δ from toe to shoreline 29 ϕ 1 α h 1 cosh δ ξ 4 cosh δ μ sinh ξ 4 cosh δ α h 1 δ ξ 4 0 inland head equations the equation for inland head in the confined aquifer beyond the toe in cases i and iii depicted in fig 3a and b is 30 ϕ μ ξ 1 3 δ 1 whereas inland from the shoreline in cases ii and iv shown in fig 3c and d it is 31 ϕ μ ξ 2 4 δ ϕ 0 eqs 30 and 31 are linear in ϕ and are used when one or two of the parameters μ λs and α h 1 are not known for one unknown values of head and distance at a single point are required the most likely case being to find μ given λs and α h 1 for two parameters unknown values at two inland points are required a third point will not produce any new information for finding three unknowns because of the linear equations for ϕ mathematical details of zone boundaries the specific expressions defining the borders between the regions for the different cases with parameters subscripted by t for transition are defined by border between cases 1 and 2 γ12 32 μ t 2 3 α h 1 with λ s t l s t l f border between cases 1 and 3 γ13 33 λ s t 6 ϕ 0 9 α h 1 3 α h 1 where ϕ 0 in terms of μ is the real solution of the cubic equation 34 ϕ 0 3 3 2 α h 1 ϕ 0 2 3 2 μ t 2 0 border between cases 2 and 4 γ24 35 λ s t 6 9 α h 1 3 α h 1 log μ μ 2 1 γ 0 α h 1 1 γ 0 α h 1 1 γ 0 α h 1 with γ 0 2 3 α h 1 border between cases 3 and 4 γ34 36 3 β a 2 f 1 a t β f 0 a t β λ s t 0 with a t 3 2 μ t 2 α h 1 1 1 3 the coordinates of the quadruple point p4 are 37 λ s 4 μ 4 6 9 α h 1 3 α h 1 2 3 α h 1 3 numerical details iterative procedures are required in calculating a 0 involved in expressions containing elliptic integrals bakker 2006 chose the robust but slowly converging method of bisection this works well because the behavior of a is monotonic in both μ and λs and a 0 we adopt the more rapid muller frank method muller 1956 frank 1958 matthews and fink 2004 neither method requires function derivatives as opposed to newton s method however computational speed is not an issue here with either method for example a grid of 400 400 point values for ϕ 0 δ and a used in constructing the contours of fig 5 a c with α h 1 0 1 needed a few seconds on a personal computer for the bisection method and approximately a sixth of that for the muller frank method all programming was done in fortran using available software for computing incomplete elliptic integrals carlson and notis 1981 the contour plots of fig 5 are provided to show the behaviors of the quantities ϕ 0 and δ necessary for describing the head distance relationships as exemplified in fig 3a d and a the mathematical constant underpinning the calculations of these two quantities superimposed on each of these contour maps are the zonal boundaries of fig 4 in fig 5a the boundary γ13 joined with γ24 defines the line a 0 in fig 5b when the toe coincides with the shoreline the boundary γ12 joined with γ34 defines a line where δ 0 the negative values of δ correspond to the shoreline to inland toe distances for cases i and iii the same joining of boundaries also defines where ϕ 0 ϕ 1 as shown in the contours for ϕ 0 of fig 5c all three contour maps show the expected continuity of values across zonal boundaries and the constancy of values for constant μ outside the joined boundaries γ13 γ24 as shown on fig 4 a contour map of β produces similar contour shapes to those of fig 5a however it is more instructive to consider variations in λs at constant μ and plot values of a β and βa this is done for μ 4 and shown in fig 6 with λs covering the complete ranges of cases iii and iv the interesting results are that as λs γ24 a 0 β but β a 3 2 α h 1 for all α h 1 which in this case is 0 15 other cross sections show the same form of curves and the same limiting values the infinite value of β does not cause numerical problems because it only occurs separately from βa as 1 β in eq 26 additional iterations done by the muller frank method are required in the next section for determining μ values given onshore head and distance values as defined by eqs 30 and 31 fig 7 is included to show the effects of zone changes as α h 1 is increased contour plots analogous to fig 5a 5c show the same general patterns but compressed in accordance with the increasing compression of zones as shown in fig 7 4 comparison with results from seawat an important requirement is to compare the sharp interface analytical solutions with results from a more realistic model such as seawat a limited comparison is made by taking the seawat parameters and results from six models examined by solórzano rivas and werner 2018 the parameter values are hs 20 m h 1 1 m h 10 m h 1 0 1 k 10 m d ls 1 20 m ls 2 3000 m kv 5 1 0 5 0 01 0 001 0 0001 m d corresponding to the six models designated m1 m2 m3 m4 m5 m6 and ν s 0 025 μ and q 0 are determined from inland head eqs 30 or 31 with h 1 m relative to sea level and inland distances x 1 100 m and x 2 490 m table 2 shows comparisons between seawat aquitard with freshwater α 1 α h 1 0 1 designated fresh and bakker s results for α 0 α h 1 0 the meaning of table 2 designations such as 3 1 is model m3 with ls 1 x 1 and kv value of 0 5 m d similarly 6 2 is model m6 with ls 2 x 2 and kv value of 0 0001 m d the λs μ coordinates shown in fig 4 of the six models in sequence m1 to m6 are 0 373 0 062 0 622 0 137 0 756 0 190 0 916 0 267 1 484 0 678 1 963 1 229 fig 8 compares interface distributions from the three approaches for the model 4 2 i e model m4 with ls 2 x 2 and kv value of 1 m d the results in table 2 show that for all six models the assumption of freshwater in the aquitard outperforms the assumption of seawater by comparison to seawat s estimates for the seaward discharge q 0 and the location of the tip the average q 0 discrepancy analytical versus seawat estimates improves from 2 to 0 4 when the aquitard is presumed to contain freshwater instead of seawater the higher q 0 obtained when freshwater is used for the aquitard salinity is the intuitive outcome of the lower head and therefore reduced resistance of the subsea boundary when the water density in the aquitard is lower a marked improvement is obtained in the tip location for which the average discrepancy reduces from 87 to 2 when freshwater rather than seawater is presumed for the aquitard salinity in the case of the seawater assumption the more seaward tip location obtained using bakker s 2006 seawater assumption is again caused by the higher head of the subsea boundary relative to the freshwater case which requires a smaller outflow face the average discrepancy in the analytically derived toe location increases from 11 to 14 when the aquitard is presumed to contain freshwater instead of seawater in contradiction to the tip and q 0 findings both the fresh and bakker analytical toe locations are landward of the seawat toe location with the freshwater model landward of the bakker model the latter trend is caused by the lower head in the aquitard in the fresh model which leads to higher flow rates for a given inland boundary head and therefore greater head losses by darcy s law and more landward toe positions added to this effect dispersion is known to produce toe locations that are seaward of estimates obtained from sharp interface methods e g mehdizadeh et al 2014 werner 2017 applied seawat to seawater intrusion problems with dispersion parameters set to zero in a similar manner to the current methodology and found analytical numerical discrepancies consistent with those encountered here and that could be explained by minor levels of artificial dispersion in seawat we expect similarly that artificial numerical dispersion in the seawat predictions have produced toe locations that are seaward of sharp interface values further investigation is needed to determine the impact of artificial dispersion on toe values produced by seawat to ascertain whether the freshwater or seawater in the aquitard assumption best reproduces the correct toe locations regardless on balance of the results the improvements in both q 0 and the tip location from presuming that aquitard contains freshwater more than offset the reduced accuracy in the toe location 5 concluding remarks previous analytical models of the extent of freshwater in offshore coastal aquifers have presumed that the overlying aquitard contains entirely seawater however this assumption has been challenged in a recent numerical modeling analysis which concludes that revised analytical solutions are needed that accommodate alternative salinities in the offshore aquitard in response the current study presents a revised analytical formulation for the extent of offshore fresh groundwater by including the offshore aquitard salinity as an input variable potentially ranging from freshwater to seawater otherwise the same assumptions as previous formulations apply namely the dupuit approximation steady state conditions homogeneity and geometric uniformity comparison of the new solution against numerical modeling confirms that the assumption of freshwater in the offshore aquitard outperforms the earlier seawater assumption as suggested by solórzano rivas and werner 2018 in particular the interface tip is well matched to the numerical results compared to tip location errors of 100 when the aquitard is presumed to contain seawater the freshwater assumption also produces slightly better estimates of freshwater discharge to the sea analytical values for the interface toe are landward of numerically derived estimates regardless of the presumed salinity in the aquitard the fresh aquitard conditions produces slightly worse matches to numerical modeling relative to the assumption of seawater in the aquitard although the effects of artificial dispersion in numerical estimates is expected to play a role in this comparison further work is needed to account for artificial dispersion in assessing the accuracy of analytically derived toe values application of the proposed methodology requires consideration of coastline geomorphology because in many cases paleo freshwater may occur in offshore aquifers emplaced during historic glacial maxima offshore freshwater extents obtained with the current method neglect these sources of freshwater an extension to the current method might include the evaluation of sea floor sediment stability whereby tidal fluctuations combined with vertical groundwater fluxes impact accretion erosion rates acknowledgments we appreciate the provision of seawat modeling results by cristina solórzano rivas adrian werner is the recipient of an australian research council future fellowship project number ft150100403 the suggestions of three anonymous reviewers are gratefully acknowledged appendix a mathematical analysis cases i and ii at the tip ξ 1 2 λ boundary conditions are a1 ϕ 0 and γ u 0 from eq 18 γu 0 requires a2 a 0 return to eq 19 and evaluate the indefinite integral with a 0 as a3 ϕ ϕ 3 3 2 α h 1 ϕ 2 d ϕ 2 ϕ 3 2 α h 1 then a4 ξ 1 2 6 ϕ 9 α h 1 b from eq 19 a5 b λ 3 α h 1 so that a6 ξ 1 2 6 ϕ 9 α h 1 3 α h 1 λ and from this a7 ϕ 1 6 ξ 1 2 λ ξ 1 2 λ 6 α h 1 0 ξ 1 2 λ for all ϕ 0 eq 18 gives a8 γ u 2 3 ϕ 3 α h 1 ϕ 2 in the transition between cases i and ii with the toe at the shoreline a9 ξ 1 2 0 ϕ 1 γ u μ t eq a8 then provides a10 μ t 2 3 α h 1 case i at the shoreline ξ 1 0 ϕ ϕ 0 and γu μ then eq a8 gives a11 ϕ 0 3 3 2 α h 1 ϕ 0 2 3 2 μ 2 0 a cubic equation in ϕ 0 given α h 1 and μ and providing one real root and two complex conjugate roots eq a6 then gives an expression for λ a12 λ 6 ϕ 0 9 α h 1 3 α h 1 for onshore confined flow with qz 0 eqs 9 and 13 reduce to a13 d d ξ 1 2 ϕ d ϕ d ξ 1 2 0 which integrates to a14 ϕ 2 2 μ ξ 1 2 ϕ 0 2 δ ξ 1 2 0 distance δ from interface to toe where ϕ 1 and ξ 1 2 δ is determined from eq a14 as a15 δ 1 ϕ 0 2 2 μ case ii at the toe ξ 2 0 and ϕ 1 then eq a6 is also an expression for λ as a16 λ 6 9 α h 1 3 α h 1 to find an expression for δ the required differential equation is a17 d 2 k h h d x 2 h h s α h 1 v s c or in dimensionless variables a18 d 2 ϕ d ξ 2 2 ϕ α h 1 the general solution of this equation is a19 ϕ a e ξ 2 b e ξ 2 α h 1 boundary conditions are i ξ 2 0 ϕ 1 and ii ξ 2 0 d ϕ d ξ 2 γ 0 2 3 α h 1 these determine a and b so that a20 ϕ 1 2 1 γ 0 α h 1 e ξ 2 1 2 1 γ 0 α h 1 e ξ 2 α h 1 δ ξ 2 0 with d ϕ d ξ 2 μ at ξ 2 δ an expression for determining δ then follows as a21 1 2 1 γ 0 α h 1 e 2 δ μ e δ 1 2 1 γ 0 α h 1 0 which solves as a22 δ log μ μ 2 1 γ 0 α h 1 1 γ 0 α h 1 1 γ 0 α h 1 with ξ 2 δ eq a20 gives a23 ϕ 0 1 2 1 γ 0 α h 1 e δ 1 2 1 γ 0 α h 1 e δ α h 1 cases iii and iv these cases have α 0 at the seaward end of the aquitard a24 ξ 3 4 λ s ϕ 0 returning to eq 19 the integration is now made explicit in the form a25 ξ 3 4 3 2 y 0 ϕ y y 3 3 2 α h 1 y 2 α 3 d y c o n s t the lower limit y 0 can be changed at will different values being absorbed into const however the square root of the cubic in the denominator suggests the use of standard expressions for elliptic integrals this is achieved by first noting that the cubic can be factored as a26 y 3 3 2 α h 1 y 2 a 3 y p y 2 a 3 p 2 y a 3 p where p is real and the zeros of the quadratic in y are complex conjugates if y 0 is replaced by p there is change of variable y pt and introduction of parameter β p a then a27 ξ 3 4 3 β a 2 ϕ β a 1 t 1 t t 2 t 1 β 3 d t b b is a constant to be determined by boundary conditions the integral is now in standard form for evaluation in terms of elliptic integrals using eqns 243 07 and 341 53 of byrd and friedman 1971 f ϕ a β ϕ β a 1 t 1 t t 2 t 1 β 3 d t a28 1 g g f θ κ 2 g e θ κ 2 g sin θ 1 κ 2 sin 2 θ 1 cos θ where f θ κ and e θ κ are incomplete elliptic integrals of the first and second kinds respectively with normal ranges 0 θ π 2 and 0 κ 1 in this particular mathematical model θ may lie in the range π 2 θ π for which the elliptic integrals are expressed as f θ κ 2k κ f π θ κ and e θ κ 2e κ e π θ κ where k κ and e κ are respective complete elliptic integrals of the first and second kinds e g byrd and friedman 1971 the other quantities in eq a28 are defined by a29 g 1 2 β 3 κ 1 1 2 β 3 g 2 g θ cos 1 g 1 ϕ β a g 1 ϕ β a ξ 3 4 is now expressed in the compact form for 0 ξ 3 4 λ s a30 ξ 3 4 3 β a 2 f ϕ a β b and b is obtained from eq a30 as a31 b λ s 3 β a 2 f 0 a β when α 0 then β 1 and all of the expressions above for ξ 3 4 and f ϕ a β reduce to those of bakker 2006 an important requirement is to determine the transition between cases iii and iv when the toe for each case coincides where ξ 3 4 0 ϕ 1 and a μ and λs are designated at μt and λst respectively the non linear equation for determining at follows from eqs a30 and a31 as a32 3 β a 2 f 1 a t β f 0 a t β λ s t 0 using the relationship between at and μt given by eq a8 with γu μt as eq a10 a33 μ t 2 3 1 a t 3 α h 1 i e a t 3 2 μ t 2 α h 1 1 1 3 which means that given λst then μt is found followed by at or vice versa case iii constant a is determined from the shoreline condition where γ 0 μ ϕ ϕ 0 and from eq 18 ϕ 0 is determined from the real root of the cubic equation a34 ϕ 0 3 3 2 α h 1 ϕ 0 2 a 3 3 2 μ 2 0 together with a35 3 β a 2 f ϕ 0 a β f 0 a β λ s 0 having found a ϕ 0 is then calculated from eq a34 the remaining quantity δ is then found from eq a15 of case i but with this new ϕ 0 a36 δ 1 ϕ 0 2 2 μ for shoreline to toe eq a14 also holds a37 ϕ 2 2 μ ξ 3 ϕ 0 2 δ ξ 3 0 case iv the differential equation defining ϕ is the same as eq a18 of case ii a38 d 2 ϕ d ξ 4 2 ϕ α h 1 with boundary conditions a39 ξ 4 0 ϕ 1 ξ 4 d λ d ϕ d ξ 4 μ providing the solution a40 ϕ 1 α h 1 cosh δ ξ 4 cosh δ μ sinh ξ 4 cosh δ α h 1 δ ξ 4 0 it is now required to find δ this is achieved by first determining an equation for a using two expressions for γ ϕ d ϕ d ξ 4 from eqs 16 and 18 and the derivative of eq a39 at ϕ 1 a41 2 3 1 a 3 α h 1 1 α h 1 tanh δ μ cosh δ solving for a and noting that λ λs δ then substituting in a42 3 β a 2 f 1 a β f 0 a β λ s δ 0 provides a non linear equation for δ an expression for ϕ 0 now follows from eq a40 with ξ 4 δ a43 ϕ 0 1 α h 1 cosh δ μ tanh δ α h 1 
