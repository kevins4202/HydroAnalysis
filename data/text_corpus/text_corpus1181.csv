index,text
5905,groundwater noble gas concentrations are used to model the temperature of aquifer recharge but also may be used to understand geologic influences on water chemistry aquifers in the south fork palouse river basin are hosted within the fractured basalts of the columbia river basalt group and the interbedded sediments of the latah formation the travel time of groundwater and the associated recharge rate in this multiple aquifer system is of primary interest to water resource managers because of declining water levels prior investigations of the deeper groundwater indicated low values of percent modern carbon and elevated alkalinity and δ13c values compared to shallower groundwater the groundwater travel time suggested by the uncorrected carbon 14 ages up to 31 000 bp implies a recharge rate much slower than hypothesized from identified recharge pathways low storativity values and relatively large groundwater withdrawals no sources of dead carbon were previously identified but the disconnect between old groundwater and likely recharge pathways suggest input from a dead carbon source groundwater collected for this study contained elevated alkalinity δ13c he and 3he 4he values deeper in this aquifer system located in this young flood basalt province elevated alkalinity and δ13c values correlate with a mantle co2 source that is reflected in oversaturated he and elevated 3he 4he r ra ratios the flood basalts are miocene expressions of the modern yellowstone hotspot which exudes relatively large concentrations of he with elevated 3he 4he r ra ratios and co2 a deep and 14c free geologic source of co2 helps to explain the low percent modern carbon in the deeper groundwater correction of groundwater ages through incorporation of this dead carbon source produced ages up to 64 smaller than previous age estimates although greater age corrections may be necessary because of differences in sample and analysis methods for alkalinity δ13c and 14c that influence detection of the dead carbon input keywords carbon 14 dating aquifer travel time noble gases mantle co2 1 introduction estimating groundwater travel time in fractured rock aquifers can be difficult due to the complexity of potential travel paths in these highly heterogeneous and anisotropic aquifers the fractured basalt aquifers of the columbia plateau regional aquifer system cpras have been historically productive and supply irrigation and municipal water across the region yet these aquifers are being mined in many areas foxworthy and washburn 1963 beall et al 2011 robischon 2016 these aquifers are located within the columbia river basalt group crbg and are a series of aquifers consisting of permeable interflow zones composed of sediments estimated at 10 of the matrix separated by less permeable basalt interiors burns et al 2012 burns et al 2015 groundwater preferentially travels along pathways developed during lava deposition and post deposition weathering and sedimentation reidel et al 1989 and 2013 burns et al 2015 such flow paths were identified through use of geochemical tracers in this project s study area along the eastern margin of the cpras fig 1 by duckett et al 2019 as part of this combined study the tortuous groundwater pathways in the study area located in the south fork palouse river basin basin have made it difficult for water resource managers to estimate recharge and storativity for development of appropriate management practices to reduce declining water levels 0 3 m yr since 1992 robischon 2016 and ensure future availability of the resource lum et al 1990 beall et al 2011 dhungel and fiedler 2016 attempts to use carbon 14 14c to date groundwater bethke and johnson 2008 in the shallow and deep aquifers of the basin produced ages ranging from 3 300 to 31 000 years before present bp crosby and chatters 1965 douglas et al 2007 brown et al 2010 such long travel times old ages are unexpected given the location of the groundwater from 20 m to 700 m below land surface at well locations within 5 km to 20 km of the mountain front recharge zone duckett et al 2019 the long travel time s suggested by the 14c values would indicate hydraulic conductivity values of 1 m y 10 7 m s which are typical of glacial till or fractured rock freeze and cherry 1979 fetter 2000 but not productive aquifers given the low storativity of the aquifers estimated median of 10 4 piersol and sprenke 2015 median annual pumping volume of 95 mcm 1992 to 2017 robischon 2016 and 14c ages an assumption of complete depletion of the groundwater resource would not be unrealistic under current pumping conditions beall et al 2011 dhungel and fiedler 2016 the old age estimates of the deep groundwater were given credence because of depleted oxygen 18 δ18o values recorded by larson et al 2000 and carey 2011 who concluded late pleistocene and early holocene recharge although carey 2011 found tritium 3h present in certain wells which indicates mixed water sources similar to recent mixing scenarios described by duckett et al 2019 during the indicated age range of the deep groundwater the basin was not covered by the cordilleran ice sheet or impacted by the floodwaters of lake missoula or lake bonneville clarke and waldron 1984 o connor 1993 alho et al 2010 therefore the basin likely received recharge from local precipitation similar to modern times and not large piston flow from basin wide flooding that has been hypothesized to explain the depleted δ18o values goode 1996 varni and carrera 1998 such long travel times and recharge in the late pleistocene and early holocene are counterintuitive to an identified recharge zone along the nearby mountain front interface dijksma et al 2011 candel et al 2016 duckett et al 2019 and substantial groundwater withdrawals that sustain the population dhungel and fiedler 2016 robischon 2016 across this palouse geographic region busacca 1989 such old water suggests aquifers primarily cut off from modern recharge yet periods of stabilized pumping in the deep aquifer have diminished water level fluctuations dijksma et al 2011 moran 2011 robischon 2016 and a gravity analysis by piersol and sprenke 2015 suggested that 90 percent of the water pumped annually from the aquifers is replenished by recharge the 14c groundwater ages determined by douglas et al 2007 were calculated as uncorrected or minimally corrected ages a lack of dead carbon no 14c input was assumed due to a lack of carbonate deposits and findings by bacon 1997 that 14co2 in the local vadose zone contained 100 modern carbon pmc a dead carbon input was considered due to variable δ13c values range of 18 1 to 11 0 that suggested the potential for other carbon inputs in the subsurface but no other carbon source s could be identified it was assumed that the δ13c variation was due to changes in co2 from soil reactions prior to recharge douglas et al 2007 for this study noble gas concentrations in groundwater from the deep and shallow aquifers of the basin were analyzed along with changes in δ13c values and alkalinity to try and identify possible dead carbon inputs the authors hypothesized potential dead carbon sources such as non mineralized wood and peat captured during landslides rapid sedimentation since the miocene bush et al 2018a or co2 inputs from the mantle suggested by relatively higher crustal p wave velocities in the region newell et al 2005 the goal of this study was a reinterpretation of 14c ages if a dead carbon source could be identified and sufficiently resolved 2 study site and methodology the aquifers of the basin consist of miocene sediments of the latah formation interbedded permeable zones and lava flows of the wanapum shallow aquifer and grande ronde deep aquifer formations of the crbg groundwater in the aquifer system latah wanapum grande ronde flows to the west given the westerly tilt of the basin and elevated recharge source along the palouse range bush et al 2018a b 2016 recharge in the basin is driven by snowmelt from the palouse range fig 1 and a primary recharge zone is located along the mountain front where the latah formation overlies the igneous and metamorphic basement rock fig 2 dijksma et al 2011 candel et al 2016 bush et al 2018a b previous studies indicate that groundwater recharge to the shallow aquifer occurs through surface percolation and mountain front recharge provant 1995 dijksma et al 2011 candel et al 2016 duckett et al 2019 the deeper aquifer primarily receives snowmelt recharge from the mountain front and may receive localized recharge from the shallow aquifer leek 2006 douglas et al 2007 carey 2011 moxley 2012 duckett et al 2019 the shallow aquifer contains the youngest water although 14c values did indicate relatively old water ranging from 3 300 to 14 600 bp median of 8900 bp crosby and chatters 1965 douglas et al 2007 brown et al 2010 the deep aquifer is connected with the shallow aquifer in select locations dijksma et al 2011 candel et al 2016 but the deep aquifer contains water estimated to range in age from 4 400 to 31 000 bp median of 19 000 bp douglas et al 2007 2 1 well sampling and prior source water analysis in 2017 groundwater was collected from private and municipal wells with dedicated pumps table 1 to identify source waters discriminate flowpaths and evaluate potential dead carbon sources as part of this combined study duckett et al 2019 identified source waters and their percent contribution to groundwater at each well location using water chemistry and isotope values which produced a discrimination of shallow and deep recharge sources with an associated mixing zone in the central portion of the study area figs 1 and 2 a hanna hi9829 multi parameter probe with in line flow cell was used to measure ph calibrated to ph of 4 and 7 oxidation reduction potential orp calibrated to a 200 mv vs ag agcl standard temperature and conductivity calibrated to a 1 000 μs cm at 25 c standard to ensure sufficient purging minimum 3 well volumes and stabilization of field measurements 3 consecutive stable readings prior to sample collection groundwater samples were collected as integrated samples representative of all well screen openings each groundwater sample is representative of the source waters table 1 subgroup identifier determined by duckett et al 2019 table 5 through inverse modeling of δ18o and δ2h values collected as part of this combined study all wells were sampled for noble gas analysis from spigot locations on the encased headworks that ensured no atmospheric influence collection of samples for noble gas analysis were completed using the standard copper tube method where sample water is pumped through copper tubes checked for gas bubbles and sealed with refrigeration style clamps 2 2 groundwater analyses alkalinity of filtered 0 45 µm samples were analyzed the same day of collection in the laboratory by inflection point titration using a hach digital titrator thermo scientific orion star ph meter stir plate and 0 16 n h2so4 digital titrator cartridge filtered 0 45 µm samples were analyzed for metal concentrations ba ca cd cr co cu fe k mg mn mo na ni v and zn and anion concentrations so4 br cl f po4 no2 and no3 at the university of idaho analytical sciences laboratory using inductively coupled plasma optical emission spectrometry perkinelmer optima 8300 and ion chromatography thermo scientific dionex aquion respectively water isotope δ18o and δ2h values of unfiltered samples were determined using a picarro l2130 i analyzer 0 1 for δ18o and 1 for δ2h at boise state university stable isotope laboratory values of δ13c were determined from dissolved 0 2 µm filtered inorganic carbon at the university of arizona environmental isotope laboratory using an automated kiel iii carbonate preparation device coupled to a finnigan mat 252 gas ratio mass spectrometer 0 15 the 0 2 µm filtering for 13c determination was chosen to reduce the need for introduction of an anti microbial agent for sample preservation révész and doctor 2014 noble gas concentrations ar kr ne xe 4he and he r ra were measured at the university of utah noble gas laboratory using a stanford research srs rga 300 quadrupole mass spectrometer and a mass analyzers products 215 50 magnetic sector mass spectrometer r ra values are a ratio of 3he 4he in a sample to the known 3he 4he atmospheric ratio mamyrin 1970 clarke et al 1976 associated 3he values were calculated from the concentration of 4he and r ra values for all samples quality control and accuracy of all sample types were checked with instrument blanks replicate samples and calibration standards over the course of sample collection and analysis no false positive results were reported and replicate results were within acceptable range 10 for all analytes 2 3 noble gas modeling of recharge temperature noble gas concentrations in groundwater remain constant without additional atmospheric influence or anthropogenic inputs except for ar and he because of their possible addition with decay of 40k to 40ar 3h to 3he u or th to 4he or inputs of terrigenic he solomon et al 1998 lu et al 2014 noble gas concentrations were used to reconstruct the temperature of soil air noble gas thermometer or ngt in the quasi saturated recharge zone at the time of infiltration aeschbach hertig et al 1999 aeschbach hertig et al 2000 stute and schlosser 2000 kipfer et al 2002 lu et al 2014 and evaluate potential contamination of 14c values from a co2 input given an associated accumulation of nonconservative noble gases ar and he ngt excess air component and terrigenic he were modeled using the inoble 2 2 dissolved gas probability calculator developed by the iaea water resources programme aeschbach hertig et al 1999 aeschbach hertig et al 2000 ngts were modeled using the continuous equilibration model and the partial reequilibration model to evaluate the potential range of recharge temperatures an altitude of 900 90 m navd88 was estimated for the elevation of the mountain front recharge zone where the sediments of the latah formation overlie the basement rock outside of the basalt flow extent fig 2 this estimated altitude for the mountain front recharge zone aligned with the deep water recharge identified by duckett et al 2019 and is based on interpretation of recently published geologic strata across the study area bush et al 2018a and b model inputs of salinity were based on conductivity and temperature measurements taken during sampling measured concentrations of all noble gases and calculated ngts were compared to the standard saturation values at atmospheric pressure weiss 1970 1971 weiss and kyser 1978 clever 1979 kipfer et al 2002 to identify noble gas concentrations above expected solubilities 3 results concentrations of ar kr ne and xe in groundwater collected from the basin were near the published saturation values weiss 1970 1971 weiss and kyser 1978 clever 1979 kipfer et al 2002 for the modeled ngts table 2 he concentrations were elevated in 17 of 18 groundwater samples examined for this study the sample that indicated no excess he was from a shallow 78 m depth well wc3 that contains a mix of snowmelt recharge and nearby surface water duckett et al 2019 noble gas concentrations in this groundwater are assumed to contain the background level of he and this sample is representative of groundwater outside of hypothesized influences on dissolved inorganic carbon in the aquifer system groundwater 4he concentrations in the remaining wells were one to two orders of magnitude greater than expected saturation values table 2 which also correlates with elevated r ra values 2 to 4 times greater than expected the largest 4he concentrations and r ra values were for groundwater from deep central and western wells fig 3 the influence on he in basin groundwater appears to be a deep source and the influence of the source lessens closer to the surface 3 1 recharge temperatures and δ18o values lower ngts were identified for deeper basin groundwater that correspond to a depleted δ18o signal fig 4 previously identified by duckett et al 2019 as indicative of snowmelt recharge the depleted δ18o and lower ngt values table 2 and fig 4 indicate cooler higher elevation recharge locations shallower eastern and central wells contained groundwater with less depleted δ18o and higher ngt values which indicate recharge from warmer lower elevation locations the correlation of δ18o and ngt values confirm a more direct snowmelt driven recharge to deeper parts of the aquifer system previously identified by duckett et al 2019 3 2 excess helium δ13c and alkalinity the excess 4he and larger r ra and smaller ngt values of the snowmelt driven deep groundwater in the basin table 2 correspond to larger alkalinity and enriched δ13c values figs 5 and 6 to understand the larger alkalinity concentrations in deeper groundwater additional solutes were examined as possible alkalinity contributors with travel to this part of the aquifer system only fe had sufficient concentration detection level to have any influence on deep groundwater alkalinity because other possible contributors such as organic matter and phosphates were of negligible concentration detection levels fe concentrations were evaluated as a potential alkalinity contributor by assuming a maximum of three mol of hydroxide oh for every mol of fe fe oh 3 or fe3 3oh given the measured fe concentration and assumption of all fe in solution is able to contribute to alkalinity results indicate that fe concentrations measured in all groundwater samples were not a substantial portion maximum of 10 of alkalinity in the aquifer system the largest contribution of fe to alkalinity 11 mg l as caco3 was in shallow groundwater within the wanapum formation which contains a relatively higher fe concentration compared to the grande ronde formation reidel and tolan 2013 in comparison minimal fe contributions to alkalinity 1 mg l as caco3 were estimated for groundwater from the shallow well without excess 4he wc3 and a deep well with the largest alkalinity value 207 mg l dgc2 alkalinity of the deeper groundwater is assumed to be primarily carbonate alkalinity corresponding to dissolved inorganic carbon 3 3 groundwater he yellowstone caldera and mantle gases during precipitation and infiltration through the soil zone groundwater recharge equilibrates to the atmosphere 3he 4he ratio r ra 1 3he is considered a primordial substance captured in the earth s mantle which results in a greater abundance of 3he and larger 3he 4he ratio and r ra in the mantle compared to the atmosphere anderson 1993 dunai and baur 1995 dunai and porcelli 2002 graham 2002 if 3he concentrations exceed atmospheric saturation in groundwater r ra 1 an additional source of 3he must be present in the system there is no known radiogenic source of 3he and no expected reactions such as 6li neutron capture that could produce a 3he source in the basin aquifer system other influences on he concentrations such as u decay would produce 4he that would decrease the 3he 4he ratio r ra 1 aeschbach hertig et al 2000 the continental hot spot that produced the yellowstone caldera wyoming usa is the source of the crbg camp 1995 the northeasterly track of the hotspot initiated multiple flood basalt events over a relatively short period of time in the mid miocene and produced the columbia river plateau through a series of feeder dike swarms and structural pathways christiansen and mckee 1978 reidel et al 1989 tolan et al 2007 barry et al 2013 the yellowstone caldera is known to emit relatively high 3he concentrations with the largest concentrations 9 5 to 16 r ra found in hydrothermal springs welhan 1981 kennedy et al 1985 hearn et al 1990 additionally crbg rocks contain elevated r ra values indicative of the mantle source associated with the yellowstone caldera craig and lupton 1976 craig et al 1978 kurz et al 1982 duncan and richards 1991 graham et al 1992a b dodson et al 1997 camp and ross 2004 the elevated he and r ra values for deep groundwater in the basin figs 3 and 5 likely are a result of upwelling mantle gases that have an analog in the current emissions of the yellowstone caldera accepting a mantle source of he input to the base of the aquifer system would produce a corresponding influx of co2 similar to the large co2 emissions associated with the yellowstone caldera bargar 1978 werner and brantley 2003 bergfeld et al 2012 mantle co2 typically has enriched δ13c values 3 to 0 compared to biogenic carbon sources ballentine 1991 bergfeld et al 2012 brooker and blank 1994 werner et al 2000 ballentine et al 2002 ballentine and burnard 2002 which likely is the source of larger δ13c values in deeper basin groundwater fig 6 3 4 mantle carbon dioxide and dissolved inorganic carbon contamination with a mantle co2 input to the basin aquifer system a weathering reaction must occur to increase dissolved inorganic carbon alkalinity values instead of no net change with the formation of carbonic acid h2co3 eq 1 given the closed nature of the aquifer system outside of the recharge zone and mafic rocks composing the aquifer matrices it is valid to assume production of bicarbonate hco3 with an input of co2 and silicate weathering olivine fe mg sio4 example in eq 2 to constrain the possible addition of dead carbon hco3 from mantle co2 an increase in groundwater alkalinity from the hco3 addition can be inversely calculated from baseline conditions well wc3 where there is an assumption of no mantle gas influence and no additions of alkalinity from additional weathering reactions e g lack of fe derived alkalinity discussed in section 3 3 1 c o 2 g h 2 o l h 2 c o 3 aq hco 3 aq h aq 2 fe mg 2 si o 4 4 c o 2 4 h 2 o 2 m g 2 4 hco 3 h 4 si o 4 to test whether an input of co2 to the deep groundwater would increase the solubility of co2 and produce hco3 at a sufficient concentration that could result in the measured deep groundwater alkalinity phreeqc version 3 llnl dat was used to model an input of excess pco2 with the baseline groundwater condition well wc3 and variable pressure 1 25 and 200 atm under equilibrium conditions this pressure range is representative of the range of overburden pressure from the recharge zone 1 atm to a maximum of 700 m perceived base of the aquifer system or 200 atm calculations for the greatest potential pressure p ρgz due to vertical force exerted by the overburden z or thickness of the rock matrix were completed using an average density ρ of 2 900 kg m3 for crbg basalt discounting relatively low density interbeds and flowtops and an acceleration of 9 8 m s2 for gravity g regardless of depth the resulting maximum alkalinity produced during equilibration modeling of co2 solubility was 237 mg l as caco3 similar to the highest alkalinity recorded for deep groundwater in the basin 207 mg l mineralization and loss of the dissolved co2 was not predicted carbonate mineral phases were not oversaturated for any of the pressure conditions 3 4 1 alkalinity and carbon 14 contamination the change in alkalinity from the baseline condition wc3 at 119 mg l to the largest alkalinity of 207 mg l in deep groundwater dgc2 is about 90 mg l this 90 mg l difference in carbonate alkalinity corresponds to an approximate 40 addition of inorganic carbon based on the calculated proportion of dead carbon added to the system by change in alkalinity 120 mg l no initial dead carbon 210 mg l 40 initial dead carbon it is possible to reinterpret the original 14c pmc and calculated ages table 3 from douglas et al 2007 with a modification of the 14c age dating equation eqs 3 and 4 the corrected ages 8 to 19 based on increased alkalinity table 3 discount dissolved co2 that may have escaped during alkalinity titration under standard atmospheric conditions therefore this interpretation of the change in alkalinity may represent an under correction of pmc and age given possible mantle co2 inputs 3 age 8033 ln pmc 100 4 age 8033 ln δ a l k al k 0 1 pmc 100 3 4 2 δ13c and carbon 14 contamination a mantle co2 addition to deep groundwater in the basin should provide a solely dead carbon source that can alter the isotopic composition of the dissolved inorganic carbon from which δ13c values and 14c ages are derived co2 associated with the yellowstone caldera has a δ13c range of 3 to 0 which is substantially enriched compared to the δ13c of shallow 15 9 to 12 9 and deep 12 8 to 10 groundwater in the basin if we assume the δ13c of the baseline conditions in groundwater from well wc3 15 9 represents the soil zone δ13c and no other carbon inputs to groundwater besides mantle co2 it is possible to inversely mass balance a dead carbon input to deeper groundwater eqs 5 and 6 the calculated fraction f of dead carbon indicated a potential age correction of 13 to 26 this estimated input of dead carbon age correction through δ13c analysis is slightly greater than the estimated dead carbon input age correction from the alkalinity difference calculation table 3 the δ13c analysis assumes no loss or gain of dissolved inorganic carbon in the aquifers except for upwelling mantle co2 with an enriched δ13c 3 signal additionally there is an assumption of no loss of carbonate alkalinity because of methanogenesis this assumption likely is valid given the oxidizing to minimally reducing conditions orp 194 mv to 115 mv for shallow groundwater and 299 mv to 78 mv for deep groundwater observed for groundwater in the aquifer system 5 f δ 13 c shallowgroundwater 1 f δ 13 c c o 2 δ 13 c measured 6 age 8033 ln 1 f pmc 100 3 4 3 helium 3 and carbon 14 contamination in addition to changes in alkalinity and δ13c 3he concentrations in basin groundwater can be correlated to possible co2 inputs and changes in dissolved inorganic carbon 3he concentrations in basin groundwater were used to derive co2 inputs from a maximum 3he co2 ratio given a documented range of 3he co2 10 10 to 10 9 for gas rich plume environments mid ocean ridge basalt systems island arc environments and hydrothermal vent systems marty and jambon 1987 burnard 2001 trull and kurz 1993 marty and tolstikhin 1998 van soest et al 1998 marty and zimmermann 1999 using concentrations of 3he and an inferred maximum co2 input from the 3he co2 ratio 10 10 potential molar co2 inputs were derived and equilibrated to dissolved inorganic carbon carbonate alkalinity values a maximum correction of 4 1 mg l as caco3 was calculated as a potential dead carbon input for groundwater from the shallow eastern and central wells which were only slightly elevated in 3he concentrations table 2 however the maximum input of dead carbon to groundwater for deep central and western wells from the 3he co2 ratio was predicted at 372 mg l as caco3 this potential dead carbon input to the basin groundwater produced an age correction of 2 to 64 which is substantially larger than the 13 to 26 age correction based on δ13c values table 3 the smallest age correction 2 based on the 3he co2 ratio is for the shallowest screen interval wc1 suggesting possible loss of co2 with less overburden pressure or limited input of mantle co2 to shallower depths 3 4 4 potential errors of age adjustment the potential for large dead carbon inputs to the aquifer system as indicated by the 3he co2 relation suggests an even greater addition of dead carbon to the system that may not have been captured with sample collection and analysis of alkalinity δ13c and 14c the potential loss of dead carbon mantle co2 as degassed co2 or uncaptured carbon species with sample collection and analysis would result in underestimated corrections to ages based solely on measured change in alkalinity additionally degassing during sampling could lead to fractionation of total carbon species remaining in solution and preferentially releasing 12c as a gas compared to 13c fractionation of carbon isotopes to produce more negative ratios would lead to an underestimate of age correction based on δ13c values although degassing from the collected samples was not observed no bubble formation and pressure release with opening of the samples for alkalinity titration yet accounting for dead carbon lost during sampling and analysis could explain the suggested larger additions of co2 alkalinity to the system indicated by the 3he co2 relation which would produce greater corrections to groundwater ages compared to alkalinity or δ13c table 3 therefore the 3he co2 relation appears to represent the most appropriate method for age adjustment given the available data 4 conclusions identification of mantle gas inputs to groundwater in the basin and corresponding changes to alkalinity δ13c and he values support a conclusion of a substantial dead carbon input that impacted the prior determination of 14c ages and implied travel times the effect of a mantle co2 input had a gradation effect with the largest influence in the deeper groundwater and least influence in the shallower groundwater analysis of differences in alkalinity between shallower and deeper groundwater and an assumption of increased dissolved inorganic carbon alkalinity in deeper groundwater from mantle co2 indicated the possible correction of 14c ages that were up to 19 smaller compared to uncorrected ages evaluation of dissolved inorganic carbon changes based on δ13c values produced corrected 14c ages up to 26 smaller than uncorrected ages correlating a possible maximum co2 addition and input of dissolved dead carbon based on the possible 3he co2 ratio produced corrected 14c ages up to 64 smaller than uncorrected ages the three analytical estimates of dead carbon input through evaluation of alkalinity δ13c and 3he co2 all suggest substantial inputs of dead carbon and a wide range of possible age corrections for groundwater in this fractured basalt and interbedded sediment aquifer system the potential decrease in groundwater ages through correction with this newly identified dead carbon input still implies substantial travel times although the corrected ages are more realistic of perceived travel time given the likely distance of travel correction of groundwater ages was less applicable to groundwater from shallow wells age corrections of 2 to 16 compared to groundwater from deeper wells age corrections of 13 to 64 the range of ages and influence of mantle co2 on groundwater in the aquifer system reflects the heterogeneity of the fractured basalt and interbedded sediment matrix and mixed samples from multiple screen depth intervals capture of co2 from the mantle source by the lower aquifer and less input to the upper aquifer is expected although it is possible that a change in pressure with migration upward through the system is leading to degassing of co2 and alteration of remaining dissolved inorganic carbon in solution declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement we acknowledge the support of the palouse basin aquifer committee pbac for funding the study in particular we wish to acknowledge the dedication and contribution of steve robischon technical advisor for pbac as the driving force in trying to understand recharge to this critical resource we also would like to thank korey woodley executive manager of pbac and the rest of the pbac leadership for their roles in supporting this research we acknowledge the contribution of kip solomon and alan rigby of the university of utah noble gas laboratory david dettman of the university of arizona environmental isotope laboratory and samantha evans of the boise state university stable isotope laboratory we wish to thank meg aunan tom jeute kiel kenning liam knudsen taylor moore ricardo ruiz holguin gabriela villegas mikahala waters and chengqian ye for their help in collecting and processing samples 
5905,groundwater noble gas concentrations are used to model the temperature of aquifer recharge but also may be used to understand geologic influences on water chemistry aquifers in the south fork palouse river basin are hosted within the fractured basalts of the columbia river basalt group and the interbedded sediments of the latah formation the travel time of groundwater and the associated recharge rate in this multiple aquifer system is of primary interest to water resource managers because of declining water levels prior investigations of the deeper groundwater indicated low values of percent modern carbon and elevated alkalinity and δ13c values compared to shallower groundwater the groundwater travel time suggested by the uncorrected carbon 14 ages up to 31 000 bp implies a recharge rate much slower than hypothesized from identified recharge pathways low storativity values and relatively large groundwater withdrawals no sources of dead carbon were previously identified but the disconnect between old groundwater and likely recharge pathways suggest input from a dead carbon source groundwater collected for this study contained elevated alkalinity δ13c he and 3he 4he values deeper in this aquifer system located in this young flood basalt province elevated alkalinity and δ13c values correlate with a mantle co2 source that is reflected in oversaturated he and elevated 3he 4he r ra ratios the flood basalts are miocene expressions of the modern yellowstone hotspot which exudes relatively large concentrations of he with elevated 3he 4he r ra ratios and co2 a deep and 14c free geologic source of co2 helps to explain the low percent modern carbon in the deeper groundwater correction of groundwater ages through incorporation of this dead carbon source produced ages up to 64 smaller than previous age estimates although greater age corrections may be necessary because of differences in sample and analysis methods for alkalinity δ13c and 14c that influence detection of the dead carbon input keywords carbon 14 dating aquifer travel time noble gases mantle co2 1 introduction estimating groundwater travel time in fractured rock aquifers can be difficult due to the complexity of potential travel paths in these highly heterogeneous and anisotropic aquifers the fractured basalt aquifers of the columbia plateau regional aquifer system cpras have been historically productive and supply irrigation and municipal water across the region yet these aquifers are being mined in many areas foxworthy and washburn 1963 beall et al 2011 robischon 2016 these aquifers are located within the columbia river basalt group crbg and are a series of aquifers consisting of permeable interflow zones composed of sediments estimated at 10 of the matrix separated by less permeable basalt interiors burns et al 2012 burns et al 2015 groundwater preferentially travels along pathways developed during lava deposition and post deposition weathering and sedimentation reidel et al 1989 and 2013 burns et al 2015 such flow paths were identified through use of geochemical tracers in this project s study area along the eastern margin of the cpras fig 1 by duckett et al 2019 as part of this combined study the tortuous groundwater pathways in the study area located in the south fork palouse river basin basin have made it difficult for water resource managers to estimate recharge and storativity for development of appropriate management practices to reduce declining water levels 0 3 m yr since 1992 robischon 2016 and ensure future availability of the resource lum et al 1990 beall et al 2011 dhungel and fiedler 2016 attempts to use carbon 14 14c to date groundwater bethke and johnson 2008 in the shallow and deep aquifers of the basin produced ages ranging from 3 300 to 31 000 years before present bp crosby and chatters 1965 douglas et al 2007 brown et al 2010 such long travel times old ages are unexpected given the location of the groundwater from 20 m to 700 m below land surface at well locations within 5 km to 20 km of the mountain front recharge zone duckett et al 2019 the long travel time s suggested by the 14c values would indicate hydraulic conductivity values of 1 m y 10 7 m s which are typical of glacial till or fractured rock freeze and cherry 1979 fetter 2000 but not productive aquifers given the low storativity of the aquifers estimated median of 10 4 piersol and sprenke 2015 median annual pumping volume of 95 mcm 1992 to 2017 robischon 2016 and 14c ages an assumption of complete depletion of the groundwater resource would not be unrealistic under current pumping conditions beall et al 2011 dhungel and fiedler 2016 the old age estimates of the deep groundwater were given credence because of depleted oxygen 18 δ18o values recorded by larson et al 2000 and carey 2011 who concluded late pleistocene and early holocene recharge although carey 2011 found tritium 3h present in certain wells which indicates mixed water sources similar to recent mixing scenarios described by duckett et al 2019 during the indicated age range of the deep groundwater the basin was not covered by the cordilleran ice sheet or impacted by the floodwaters of lake missoula or lake bonneville clarke and waldron 1984 o connor 1993 alho et al 2010 therefore the basin likely received recharge from local precipitation similar to modern times and not large piston flow from basin wide flooding that has been hypothesized to explain the depleted δ18o values goode 1996 varni and carrera 1998 such long travel times and recharge in the late pleistocene and early holocene are counterintuitive to an identified recharge zone along the nearby mountain front interface dijksma et al 2011 candel et al 2016 duckett et al 2019 and substantial groundwater withdrawals that sustain the population dhungel and fiedler 2016 robischon 2016 across this palouse geographic region busacca 1989 such old water suggests aquifers primarily cut off from modern recharge yet periods of stabilized pumping in the deep aquifer have diminished water level fluctuations dijksma et al 2011 moran 2011 robischon 2016 and a gravity analysis by piersol and sprenke 2015 suggested that 90 percent of the water pumped annually from the aquifers is replenished by recharge the 14c groundwater ages determined by douglas et al 2007 were calculated as uncorrected or minimally corrected ages a lack of dead carbon no 14c input was assumed due to a lack of carbonate deposits and findings by bacon 1997 that 14co2 in the local vadose zone contained 100 modern carbon pmc a dead carbon input was considered due to variable δ13c values range of 18 1 to 11 0 that suggested the potential for other carbon inputs in the subsurface but no other carbon source s could be identified it was assumed that the δ13c variation was due to changes in co2 from soil reactions prior to recharge douglas et al 2007 for this study noble gas concentrations in groundwater from the deep and shallow aquifers of the basin were analyzed along with changes in δ13c values and alkalinity to try and identify possible dead carbon inputs the authors hypothesized potential dead carbon sources such as non mineralized wood and peat captured during landslides rapid sedimentation since the miocene bush et al 2018a or co2 inputs from the mantle suggested by relatively higher crustal p wave velocities in the region newell et al 2005 the goal of this study was a reinterpretation of 14c ages if a dead carbon source could be identified and sufficiently resolved 2 study site and methodology the aquifers of the basin consist of miocene sediments of the latah formation interbedded permeable zones and lava flows of the wanapum shallow aquifer and grande ronde deep aquifer formations of the crbg groundwater in the aquifer system latah wanapum grande ronde flows to the west given the westerly tilt of the basin and elevated recharge source along the palouse range bush et al 2018a b 2016 recharge in the basin is driven by snowmelt from the palouse range fig 1 and a primary recharge zone is located along the mountain front where the latah formation overlies the igneous and metamorphic basement rock fig 2 dijksma et al 2011 candel et al 2016 bush et al 2018a b previous studies indicate that groundwater recharge to the shallow aquifer occurs through surface percolation and mountain front recharge provant 1995 dijksma et al 2011 candel et al 2016 duckett et al 2019 the deeper aquifer primarily receives snowmelt recharge from the mountain front and may receive localized recharge from the shallow aquifer leek 2006 douglas et al 2007 carey 2011 moxley 2012 duckett et al 2019 the shallow aquifer contains the youngest water although 14c values did indicate relatively old water ranging from 3 300 to 14 600 bp median of 8900 bp crosby and chatters 1965 douglas et al 2007 brown et al 2010 the deep aquifer is connected with the shallow aquifer in select locations dijksma et al 2011 candel et al 2016 but the deep aquifer contains water estimated to range in age from 4 400 to 31 000 bp median of 19 000 bp douglas et al 2007 2 1 well sampling and prior source water analysis in 2017 groundwater was collected from private and municipal wells with dedicated pumps table 1 to identify source waters discriminate flowpaths and evaluate potential dead carbon sources as part of this combined study duckett et al 2019 identified source waters and their percent contribution to groundwater at each well location using water chemistry and isotope values which produced a discrimination of shallow and deep recharge sources with an associated mixing zone in the central portion of the study area figs 1 and 2 a hanna hi9829 multi parameter probe with in line flow cell was used to measure ph calibrated to ph of 4 and 7 oxidation reduction potential orp calibrated to a 200 mv vs ag agcl standard temperature and conductivity calibrated to a 1 000 μs cm at 25 c standard to ensure sufficient purging minimum 3 well volumes and stabilization of field measurements 3 consecutive stable readings prior to sample collection groundwater samples were collected as integrated samples representative of all well screen openings each groundwater sample is representative of the source waters table 1 subgroup identifier determined by duckett et al 2019 table 5 through inverse modeling of δ18o and δ2h values collected as part of this combined study all wells were sampled for noble gas analysis from spigot locations on the encased headworks that ensured no atmospheric influence collection of samples for noble gas analysis were completed using the standard copper tube method where sample water is pumped through copper tubes checked for gas bubbles and sealed with refrigeration style clamps 2 2 groundwater analyses alkalinity of filtered 0 45 µm samples were analyzed the same day of collection in the laboratory by inflection point titration using a hach digital titrator thermo scientific orion star ph meter stir plate and 0 16 n h2so4 digital titrator cartridge filtered 0 45 µm samples were analyzed for metal concentrations ba ca cd cr co cu fe k mg mn mo na ni v and zn and anion concentrations so4 br cl f po4 no2 and no3 at the university of idaho analytical sciences laboratory using inductively coupled plasma optical emission spectrometry perkinelmer optima 8300 and ion chromatography thermo scientific dionex aquion respectively water isotope δ18o and δ2h values of unfiltered samples were determined using a picarro l2130 i analyzer 0 1 for δ18o and 1 for δ2h at boise state university stable isotope laboratory values of δ13c were determined from dissolved 0 2 µm filtered inorganic carbon at the university of arizona environmental isotope laboratory using an automated kiel iii carbonate preparation device coupled to a finnigan mat 252 gas ratio mass spectrometer 0 15 the 0 2 µm filtering for 13c determination was chosen to reduce the need for introduction of an anti microbial agent for sample preservation révész and doctor 2014 noble gas concentrations ar kr ne xe 4he and he r ra were measured at the university of utah noble gas laboratory using a stanford research srs rga 300 quadrupole mass spectrometer and a mass analyzers products 215 50 magnetic sector mass spectrometer r ra values are a ratio of 3he 4he in a sample to the known 3he 4he atmospheric ratio mamyrin 1970 clarke et al 1976 associated 3he values were calculated from the concentration of 4he and r ra values for all samples quality control and accuracy of all sample types were checked with instrument blanks replicate samples and calibration standards over the course of sample collection and analysis no false positive results were reported and replicate results were within acceptable range 10 for all analytes 2 3 noble gas modeling of recharge temperature noble gas concentrations in groundwater remain constant without additional atmospheric influence or anthropogenic inputs except for ar and he because of their possible addition with decay of 40k to 40ar 3h to 3he u or th to 4he or inputs of terrigenic he solomon et al 1998 lu et al 2014 noble gas concentrations were used to reconstruct the temperature of soil air noble gas thermometer or ngt in the quasi saturated recharge zone at the time of infiltration aeschbach hertig et al 1999 aeschbach hertig et al 2000 stute and schlosser 2000 kipfer et al 2002 lu et al 2014 and evaluate potential contamination of 14c values from a co2 input given an associated accumulation of nonconservative noble gases ar and he ngt excess air component and terrigenic he were modeled using the inoble 2 2 dissolved gas probability calculator developed by the iaea water resources programme aeschbach hertig et al 1999 aeschbach hertig et al 2000 ngts were modeled using the continuous equilibration model and the partial reequilibration model to evaluate the potential range of recharge temperatures an altitude of 900 90 m navd88 was estimated for the elevation of the mountain front recharge zone where the sediments of the latah formation overlie the basement rock outside of the basalt flow extent fig 2 this estimated altitude for the mountain front recharge zone aligned with the deep water recharge identified by duckett et al 2019 and is based on interpretation of recently published geologic strata across the study area bush et al 2018a and b model inputs of salinity were based on conductivity and temperature measurements taken during sampling measured concentrations of all noble gases and calculated ngts were compared to the standard saturation values at atmospheric pressure weiss 1970 1971 weiss and kyser 1978 clever 1979 kipfer et al 2002 to identify noble gas concentrations above expected solubilities 3 results concentrations of ar kr ne and xe in groundwater collected from the basin were near the published saturation values weiss 1970 1971 weiss and kyser 1978 clever 1979 kipfer et al 2002 for the modeled ngts table 2 he concentrations were elevated in 17 of 18 groundwater samples examined for this study the sample that indicated no excess he was from a shallow 78 m depth well wc3 that contains a mix of snowmelt recharge and nearby surface water duckett et al 2019 noble gas concentrations in this groundwater are assumed to contain the background level of he and this sample is representative of groundwater outside of hypothesized influences on dissolved inorganic carbon in the aquifer system groundwater 4he concentrations in the remaining wells were one to two orders of magnitude greater than expected saturation values table 2 which also correlates with elevated r ra values 2 to 4 times greater than expected the largest 4he concentrations and r ra values were for groundwater from deep central and western wells fig 3 the influence on he in basin groundwater appears to be a deep source and the influence of the source lessens closer to the surface 3 1 recharge temperatures and δ18o values lower ngts were identified for deeper basin groundwater that correspond to a depleted δ18o signal fig 4 previously identified by duckett et al 2019 as indicative of snowmelt recharge the depleted δ18o and lower ngt values table 2 and fig 4 indicate cooler higher elevation recharge locations shallower eastern and central wells contained groundwater with less depleted δ18o and higher ngt values which indicate recharge from warmer lower elevation locations the correlation of δ18o and ngt values confirm a more direct snowmelt driven recharge to deeper parts of the aquifer system previously identified by duckett et al 2019 3 2 excess helium δ13c and alkalinity the excess 4he and larger r ra and smaller ngt values of the snowmelt driven deep groundwater in the basin table 2 correspond to larger alkalinity and enriched δ13c values figs 5 and 6 to understand the larger alkalinity concentrations in deeper groundwater additional solutes were examined as possible alkalinity contributors with travel to this part of the aquifer system only fe had sufficient concentration detection level to have any influence on deep groundwater alkalinity because other possible contributors such as organic matter and phosphates were of negligible concentration detection levels fe concentrations were evaluated as a potential alkalinity contributor by assuming a maximum of three mol of hydroxide oh for every mol of fe fe oh 3 or fe3 3oh given the measured fe concentration and assumption of all fe in solution is able to contribute to alkalinity results indicate that fe concentrations measured in all groundwater samples were not a substantial portion maximum of 10 of alkalinity in the aquifer system the largest contribution of fe to alkalinity 11 mg l as caco3 was in shallow groundwater within the wanapum formation which contains a relatively higher fe concentration compared to the grande ronde formation reidel and tolan 2013 in comparison minimal fe contributions to alkalinity 1 mg l as caco3 were estimated for groundwater from the shallow well without excess 4he wc3 and a deep well with the largest alkalinity value 207 mg l dgc2 alkalinity of the deeper groundwater is assumed to be primarily carbonate alkalinity corresponding to dissolved inorganic carbon 3 3 groundwater he yellowstone caldera and mantle gases during precipitation and infiltration through the soil zone groundwater recharge equilibrates to the atmosphere 3he 4he ratio r ra 1 3he is considered a primordial substance captured in the earth s mantle which results in a greater abundance of 3he and larger 3he 4he ratio and r ra in the mantle compared to the atmosphere anderson 1993 dunai and baur 1995 dunai and porcelli 2002 graham 2002 if 3he concentrations exceed atmospheric saturation in groundwater r ra 1 an additional source of 3he must be present in the system there is no known radiogenic source of 3he and no expected reactions such as 6li neutron capture that could produce a 3he source in the basin aquifer system other influences on he concentrations such as u decay would produce 4he that would decrease the 3he 4he ratio r ra 1 aeschbach hertig et al 2000 the continental hot spot that produced the yellowstone caldera wyoming usa is the source of the crbg camp 1995 the northeasterly track of the hotspot initiated multiple flood basalt events over a relatively short period of time in the mid miocene and produced the columbia river plateau through a series of feeder dike swarms and structural pathways christiansen and mckee 1978 reidel et al 1989 tolan et al 2007 barry et al 2013 the yellowstone caldera is known to emit relatively high 3he concentrations with the largest concentrations 9 5 to 16 r ra found in hydrothermal springs welhan 1981 kennedy et al 1985 hearn et al 1990 additionally crbg rocks contain elevated r ra values indicative of the mantle source associated with the yellowstone caldera craig and lupton 1976 craig et al 1978 kurz et al 1982 duncan and richards 1991 graham et al 1992a b dodson et al 1997 camp and ross 2004 the elevated he and r ra values for deep groundwater in the basin figs 3 and 5 likely are a result of upwelling mantle gases that have an analog in the current emissions of the yellowstone caldera accepting a mantle source of he input to the base of the aquifer system would produce a corresponding influx of co2 similar to the large co2 emissions associated with the yellowstone caldera bargar 1978 werner and brantley 2003 bergfeld et al 2012 mantle co2 typically has enriched δ13c values 3 to 0 compared to biogenic carbon sources ballentine 1991 bergfeld et al 2012 brooker and blank 1994 werner et al 2000 ballentine et al 2002 ballentine and burnard 2002 which likely is the source of larger δ13c values in deeper basin groundwater fig 6 3 4 mantle carbon dioxide and dissolved inorganic carbon contamination with a mantle co2 input to the basin aquifer system a weathering reaction must occur to increase dissolved inorganic carbon alkalinity values instead of no net change with the formation of carbonic acid h2co3 eq 1 given the closed nature of the aquifer system outside of the recharge zone and mafic rocks composing the aquifer matrices it is valid to assume production of bicarbonate hco3 with an input of co2 and silicate weathering olivine fe mg sio4 example in eq 2 to constrain the possible addition of dead carbon hco3 from mantle co2 an increase in groundwater alkalinity from the hco3 addition can be inversely calculated from baseline conditions well wc3 where there is an assumption of no mantle gas influence and no additions of alkalinity from additional weathering reactions e g lack of fe derived alkalinity discussed in section 3 3 1 c o 2 g h 2 o l h 2 c o 3 aq hco 3 aq h aq 2 fe mg 2 si o 4 4 c o 2 4 h 2 o 2 m g 2 4 hco 3 h 4 si o 4 to test whether an input of co2 to the deep groundwater would increase the solubility of co2 and produce hco3 at a sufficient concentration that could result in the measured deep groundwater alkalinity phreeqc version 3 llnl dat was used to model an input of excess pco2 with the baseline groundwater condition well wc3 and variable pressure 1 25 and 200 atm under equilibrium conditions this pressure range is representative of the range of overburden pressure from the recharge zone 1 atm to a maximum of 700 m perceived base of the aquifer system or 200 atm calculations for the greatest potential pressure p ρgz due to vertical force exerted by the overburden z or thickness of the rock matrix were completed using an average density ρ of 2 900 kg m3 for crbg basalt discounting relatively low density interbeds and flowtops and an acceleration of 9 8 m s2 for gravity g regardless of depth the resulting maximum alkalinity produced during equilibration modeling of co2 solubility was 237 mg l as caco3 similar to the highest alkalinity recorded for deep groundwater in the basin 207 mg l mineralization and loss of the dissolved co2 was not predicted carbonate mineral phases were not oversaturated for any of the pressure conditions 3 4 1 alkalinity and carbon 14 contamination the change in alkalinity from the baseline condition wc3 at 119 mg l to the largest alkalinity of 207 mg l in deep groundwater dgc2 is about 90 mg l this 90 mg l difference in carbonate alkalinity corresponds to an approximate 40 addition of inorganic carbon based on the calculated proportion of dead carbon added to the system by change in alkalinity 120 mg l no initial dead carbon 210 mg l 40 initial dead carbon it is possible to reinterpret the original 14c pmc and calculated ages table 3 from douglas et al 2007 with a modification of the 14c age dating equation eqs 3 and 4 the corrected ages 8 to 19 based on increased alkalinity table 3 discount dissolved co2 that may have escaped during alkalinity titration under standard atmospheric conditions therefore this interpretation of the change in alkalinity may represent an under correction of pmc and age given possible mantle co2 inputs 3 age 8033 ln pmc 100 4 age 8033 ln δ a l k al k 0 1 pmc 100 3 4 2 δ13c and carbon 14 contamination a mantle co2 addition to deep groundwater in the basin should provide a solely dead carbon source that can alter the isotopic composition of the dissolved inorganic carbon from which δ13c values and 14c ages are derived co2 associated with the yellowstone caldera has a δ13c range of 3 to 0 which is substantially enriched compared to the δ13c of shallow 15 9 to 12 9 and deep 12 8 to 10 groundwater in the basin if we assume the δ13c of the baseline conditions in groundwater from well wc3 15 9 represents the soil zone δ13c and no other carbon inputs to groundwater besides mantle co2 it is possible to inversely mass balance a dead carbon input to deeper groundwater eqs 5 and 6 the calculated fraction f of dead carbon indicated a potential age correction of 13 to 26 this estimated input of dead carbon age correction through δ13c analysis is slightly greater than the estimated dead carbon input age correction from the alkalinity difference calculation table 3 the δ13c analysis assumes no loss or gain of dissolved inorganic carbon in the aquifers except for upwelling mantle co2 with an enriched δ13c 3 signal additionally there is an assumption of no loss of carbonate alkalinity because of methanogenesis this assumption likely is valid given the oxidizing to minimally reducing conditions orp 194 mv to 115 mv for shallow groundwater and 299 mv to 78 mv for deep groundwater observed for groundwater in the aquifer system 5 f δ 13 c shallowgroundwater 1 f δ 13 c c o 2 δ 13 c measured 6 age 8033 ln 1 f pmc 100 3 4 3 helium 3 and carbon 14 contamination in addition to changes in alkalinity and δ13c 3he concentrations in basin groundwater can be correlated to possible co2 inputs and changes in dissolved inorganic carbon 3he concentrations in basin groundwater were used to derive co2 inputs from a maximum 3he co2 ratio given a documented range of 3he co2 10 10 to 10 9 for gas rich plume environments mid ocean ridge basalt systems island arc environments and hydrothermal vent systems marty and jambon 1987 burnard 2001 trull and kurz 1993 marty and tolstikhin 1998 van soest et al 1998 marty and zimmermann 1999 using concentrations of 3he and an inferred maximum co2 input from the 3he co2 ratio 10 10 potential molar co2 inputs were derived and equilibrated to dissolved inorganic carbon carbonate alkalinity values a maximum correction of 4 1 mg l as caco3 was calculated as a potential dead carbon input for groundwater from the shallow eastern and central wells which were only slightly elevated in 3he concentrations table 2 however the maximum input of dead carbon to groundwater for deep central and western wells from the 3he co2 ratio was predicted at 372 mg l as caco3 this potential dead carbon input to the basin groundwater produced an age correction of 2 to 64 which is substantially larger than the 13 to 26 age correction based on δ13c values table 3 the smallest age correction 2 based on the 3he co2 ratio is for the shallowest screen interval wc1 suggesting possible loss of co2 with less overburden pressure or limited input of mantle co2 to shallower depths 3 4 4 potential errors of age adjustment the potential for large dead carbon inputs to the aquifer system as indicated by the 3he co2 relation suggests an even greater addition of dead carbon to the system that may not have been captured with sample collection and analysis of alkalinity δ13c and 14c the potential loss of dead carbon mantle co2 as degassed co2 or uncaptured carbon species with sample collection and analysis would result in underestimated corrections to ages based solely on measured change in alkalinity additionally degassing during sampling could lead to fractionation of total carbon species remaining in solution and preferentially releasing 12c as a gas compared to 13c fractionation of carbon isotopes to produce more negative ratios would lead to an underestimate of age correction based on δ13c values although degassing from the collected samples was not observed no bubble formation and pressure release with opening of the samples for alkalinity titration yet accounting for dead carbon lost during sampling and analysis could explain the suggested larger additions of co2 alkalinity to the system indicated by the 3he co2 relation which would produce greater corrections to groundwater ages compared to alkalinity or δ13c table 3 therefore the 3he co2 relation appears to represent the most appropriate method for age adjustment given the available data 4 conclusions identification of mantle gas inputs to groundwater in the basin and corresponding changes to alkalinity δ13c and he values support a conclusion of a substantial dead carbon input that impacted the prior determination of 14c ages and implied travel times the effect of a mantle co2 input had a gradation effect with the largest influence in the deeper groundwater and least influence in the shallower groundwater analysis of differences in alkalinity between shallower and deeper groundwater and an assumption of increased dissolved inorganic carbon alkalinity in deeper groundwater from mantle co2 indicated the possible correction of 14c ages that were up to 19 smaller compared to uncorrected ages evaluation of dissolved inorganic carbon changes based on δ13c values produced corrected 14c ages up to 26 smaller than uncorrected ages correlating a possible maximum co2 addition and input of dissolved dead carbon based on the possible 3he co2 ratio produced corrected 14c ages up to 64 smaller than uncorrected ages the three analytical estimates of dead carbon input through evaluation of alkalinity δ13c and 3he co2 all suggest substantial inputs of dead carbon and a wide range of possible age corrections for groundwater in this fractured basalt and interbedded sediment aquifer system the potential decrease in groundwater ages through correction with this newly identified dead carbon input still implies substantial travel times although the corrected ages are more realistic of perceived travel time given the likely distance of travel correction of groundwater ages was less applicable to groundwater from shallow wells age corrections of 2 to 16 compared to groundwater from deeper wells age corrections of 13 to 64 the range of ages and influence of mantle co2 on groundwater in the aquifer system reflects the heterogeneity of the fractured basalt and interbedded sediment matrix and mixed samples from multiple screen depth intervals capture of co2 from the mantle source by the lower aquifer and less input to the upper aquifer is expected although it is possible that a change in pressure with migration upward through the system is leading to degassing of co2 and alteration of remaining dissolved inorganic carbon in solution declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement we acknowledge the support of the palouse basin aquifer committee pbac for funding the study in particular we wish to acknowledge the dedication and contribution of steve robischon technical advisor for pbac as the driving force in trying to understand recharge to this critical resource we also would like to thank korey woodley executive manager of pbac and the rest of the pbac leadership for their roles in supporting this research we acknowledge the contribution of kip solomon and alan rigby of the university of utah noble gas laboratory david dettman of the university of arizona environmental isotope laboratory and samantha evans of the boise state university stable isotope laboratory we wish to thank meg aunan tom jeute kiel kenning liam knudsen taylor moore ricardo ruiz holguin gabriela villegas mikahala waters and chengqian ye for their help in collecting and processing samples 
5906,the rainfall intercepted by an isolated olive tree was measured in a traditional olive grove pasture system with a sparse canopy cover results from a two year period of observations are presented the data are then used to test models of the interception process in this type of agricultural system modelling was performed at the single tree level using the sparse forest version of the gash analytical model combined with two other methodologies the wet bulb approach to estimate the evaporation rate from the wet canopies of individual olive trees and a newly developed procedure to estimate the canopy structure parameters good model performance was achieved at the storm level with model simulations within 1 5 of the observed value clearly within the expected error of interception loss measurements keywords interception loss storage capacity gash s analytical model wet bulb approach tree based modelling approach stemflow 1 introduction rainfall interception loss from wet tree canopies can be an important component of the local and regional water balances and must be accounted for when drawing up any sustainable water management programme designed to foster water conservation in many dryland regions such as those with a mediterranean type climate those programmes are essential although land use in the mediterranean zone is very diverse olive production is a major agricultural activity globally the area cultivated with olive trees has been continuously expanding for the past two decades increasing by more than 25 10 3 km2 from 80 10 3 km2 in 1996 to 106 10 3 km2 in 2016 fao 2019 most olive tree stands are used to produce olive oil the european countries of the mediterranean zone are responsible for about two thirds of the world s olive oil production but new regions are becoming productive such as the usa and especially china and australia fao 2019 olive trees are also more resilient than other commercial tree species they are drought resistant and less susceptible to fire they can also regrow from the root stock after fires have occurred climate change with its accompanying droughts is thus likely to result in further expansion of olive tree plantations this large and expanding area of olive groves growing in water scarce regions makes understanding the hydrological behaviour of this land use an important priority olive groves can be managed in different ways from traditional olive grove pasture managed as a mixed use system for olive production and grazing to highly intensive systems in these two contrasting situations tree densities can range between 20 and 2000 trees ha 1 although in most of the olive cultivated area typical densities vary from 100 to 400 trees ha 1 faostat 2019 fernandez escobar et al 2013 in portugal the traditional low density olive tree plantations are still quite common yet few studies have researched their water use particularly their rainfall interception most early interception measurements were made in closed canopy forests the results were successfully modelled by process based models of the rutter type gash 1979 rutter et al 1971 rutter et al 1975 these models were later reformulated to allow their use with more open forests gash et al 1995 valente et al 1997 these revised versions which revert to the original models under closed canopy conditions proved to be successful at estimating both closed and moderately sparse forest interception loss the revised models calculate the stand level evaporation under the assumption that the evaporation from a sparse forest canopy is given by the closed canopy evaporation scaled down in proportion to the canopy cover with the hypothetical closed canopy evaporation being estimated by the penman monteith equation however this assumption becomes increasingly less valid as forest sparseness increases but pereira et al 2009b has shown that this questionable assumption can be avoided by estimating the evaporation rate using a new method the wet bulb approach according to the pereira method in stands with very sparse tree covers the wet crowns of isolated trees behave as large wet bulbs allowing the evaporation rate from their saturated surfaces to be estimated through a simple diffusion equation this method is not subject to the same constraints as the penman monteith equation the approach is also physically based and requires only a limited amount of data the pereira method was initially tested against data from an isolated holm oak tree here we investigate the further applicability of the method to estimating evaporation of rainfall intercepted by an olive tree growing within a typical olive grove the water storage capacity of a canopy is another factor that affects interception loss klaassen et al 1998 linhoss and siegert 2016 pereira et al 2016 smets et al 2019 valente et al 1997 however quantifying the water storage of a single tree crown or stand canopy has been a challenging task friesen et al 2015 levia et al 2011 usually the water storage capacities of the canopy s and trunks s t are assessed indirectly based on relationships between gross rainfall p g and the components of net rainfall namely throughfall t f and stemflow s f the so called leyton method leyton et al 1967 or any of its variants is the indirect method that has been most commonly used to estimate s david et al 2005 s is derived as the negative intercept of the envelope line or linear regression between t f and p g considering only storms capable of saturating the canopy and for which evaporation during rain is negligible the subjectivity inherent in the selection of such rainfall events is further complicated by the problems arising from the generally high spatial and temporal variability of net rainfall lloyd and marques filho 1988 zimmermann et al 2009 these factors contribute to significant errors in the estimates of storage capacity obtained by this method attempting to avoid these problems pereira et al 2009a proposed a new procedure to estimate s which is conceptually coherent with the formulation of the revised versions of both gash and rutter models gash et al 1995 valente et al 1997 the method uses information from a larger number of rainfall events and accounts for the evaporation during the wetting phase of the storms however it does not account for stemflow an important drawback whenever this component of the water balance cannot be neglected here we overcome this limitation by reformulating the procedure to estimate s making it more robust and independent of the magnitude of stemflow we also extend the approach to develop a new method of determining the trunk storage capacity this paper reports on a study on the rainfall interception process in a traditional low density olive grove pasture system in portugal as with mediterranean savanna type oak woodlands david et al 2006 pereira et al 2009a we believe that olive grove interception loss is best estimated as the sum of the contribution of all individual trees therefore and focusing on a single representative individual tree we hypothesize that a combination of the wet bulb approach robust procedures to estimate the canopy structural parameters and the revised version of the gash analytical model is the best way to model rainfall interception by the tree component of these agricultural systems 2 methods 2 1 experimental site data were collected from 25 august 2011 to 30 april 2013 in an olive grove pasture system located on the experimental farm of the school of agriculture of the polytechnic institute of castelo branco 39 49 15 n 7 27 33 w 365 m a s l in central portugal this is a traditional rain fed olive grove the trees are 80 90 years old and have an approximate spacing of 11 m 11 m giving 83 trees ha 1 canopy cover is 19 4 measured through image analysis of a digital orthophotomap using arcgis the site is flat and the local climate is mediterranean under continental influence with hot dry summers and mild wet winters long term 1981 2010 average annual rainfall is 783 mm falling mainly between october and may and mean annual temperature is 16 c ipma 2019 2 2 instrumentation the rainfall interception experiment was installed around a single olive tree olea europea l cultivar galega vulgar chosen as being representative of the grove table 1 distance to the nearest neighbouring tree was 9 6 m throughfall t f was measured by an array of 24 tipping bucket rain gauges installed around the tree the gauges 0 2 and 0 5 mm per tip w5724 and w5720 casella limited bedford uk 0 2 mm per tip arg100 environmental measurements gateshead uk were positioned in three concentric circles with radii of 1 2 25 and 5 m centred on the tree trunk fig 1 the sampling area expanded outside the crown limit to account for the rain shadow effect on the leeward side of the tree david et al 2006 stemflow s f was collected by a spiral rubber gutter attached to the tree trunk and connected to a covered 0 5 mm tipping bucket rain gauge w5720 casella limited bedford uk all tipping bucket measurements were stored as 10 min cumulative values by a cr10x data logger campbell scientific shepshed uk an automatic weather station was installed on a metal structure consisting of a 4 m high metal tower and an additional 2 m length mast the tower was erected next to a second tree approximately 15 m away which had reached a height of 5 7 m by the end of the experiment while the air wet and dry bulb temperatures were measured at mid crown level at a height of ca 3 m using an aspirated psychrometer institute of hydrology uk see wright et al 1992 net radiation nr lite kipp zonen delft the netherlands and wind speed and direction vector instruments rhyl uk were measured above the canopy on the top of the tower mast at a height of 6 m gross rainfall p g was collected by a funnel with a diameter of 25 4 cm mounted on the top of the tower at a height of 4 m and measured in a covered tipping bucket rain gauge w5724 casella limited bedford uk with 22 5 cm of diameter on the ground resulting in a resolution of 0 16 mm per tip data were sampled at 10 s intervals and recorded as 10 min totals rainfall or averages by another cr10x data logger occasionally during the data collection period some of the tipping bucket gauges were not operational e g clogging of the filter damaged cables for these short periods data gap filling was performed using linear regressions with the other fully operational gauges 2 3 interception loss following the whole tree approach of david et al 2006 and pereira et al 2009a interception loss from the monitored tree was first calculated as the difference in volume between the gross rainfall and the stemflow s f plus throughfall t f note that here the term throughfall includes all the water collected by the network of gauges on the ground drips from the canopy and rainfall collected both upwind of the tree and in the rain shadow on its leeward side the total volume of throughfall was calculated with each gauge in the sampling area weighted according to its area of influence circular quarter or sector as depicted in fig 1 interception loss i on a crown area basis was then expressed in millimetres by dividing its volume in litres by the tree crown projected area in m2 once interception loss is calculated in mm equivalent throughfall t f e mm on a crown area basis is calculated as the difference between p g and s f plus interception david et al 2006 pereira et al 2009a these values can then also be expressed on the basis of the whole olive grove ground area if multiplied by the average crown cover fraction 0 194 when the mass balance equation is used to evaluate the interception loss i is a small number obtained from the difference between two large ones gross and net rainfall accurate measurements are therefore needed to give a useful estimate of interception loss david et al 2005 however in forests and other tree covers the accurate measurement of p g is particularly difficult robinson et al 2004 a preliminary data analysis of the gross rainfall measured during this study showed a significant under catch by the tower gauge when results from this rain gauge were compared to those obtained by one of the throughfall gauges located in the outer circle outside of the influence of the tree crown gauge number 19 was chosen as a reference because it was operational during all the experimental period it was found that the tower rain gauge underestimated p g by 6 2 fig 2 a this result was confirmed by a similar analysis using daily data from the weather station at castelo branco belonging to the national meteorological service ipma located about 2 km from the experimental site fig 2b to ensure that the t f gauge used was outside the tree rain shadow this analysis was done with daily data for wet periods when the mean wind speed was lower than 3 m s 1 the location of the tower upwind of the nearest tree and the proximity between the funnel rim 4 m high and the tree top 5 7 m high at the end of the experiment may have caused this bias the presence of the tree may not only have enhanced the wind turbulence near the funnel but could also be responsible for a sheltering effect on the tower gauge resulting in its under catch robinson et al 2004 to avoid additional errors due to differences in the time and spatial distribution of rainfall p g data measured at the experimental site on the top of the tower were used but only after the correction for the measurement error of 6 2 apart from this systematic bias in the precipitation measurement measurements are also affected by random experimental errors to quantify these errors for interception loss measurements we assumed that p g t f and s f were variables measured independently with an error not worse than 2 5 muzylo et al 2009 the uncertainty in interception loss was calculated as the root sum squares of those errors in the input quantities of the water balance equation kirkup and frenkel 2006 computing this uncertainty for all the storms of the validation period allowed us to allocate error bounds to the cumulative measured interception loss 2 4 rainfall interception modelling the tree based approach for modelling interception loss proposed by pereira et al 2009a was used in this study the sparse forest version of the gash analytical model valente et al 1997 was applied at the tree level to simulate the three main components of the rainfall interception process throughfall stemflow and evaporation the model was run both on a rainfall event and on a rain day basis each rainfall event was defined as a continuous or intermittent rainfall period separated from other storms by at least six hours without rain david et al 2006 pereira et al 2009a valente et al 1997 when using rain days as the data source a single event per day was assumed 2 5 model parameterization all model parameters were estimated using data collected between august 2011 and august 2012 hereafter referred to as the 2011 12 period the remaining data from september 2012 to april 2013 2012 13 period was used as an independent dataset for model validation modelling performance was assessed by calculating the normalized mean bias and modelling efficiency janssen and heuberger 1995 mayer and butler 1993 like the coefficient of determination used in linear regression modelling efficiency is a measure of the overall goodness of fit which quantifies the percentage of the variance of the observed values which is explained by the model the wet bulb approach described by pereira et al 2009b was adopted to estimate the mean rate of evaporation from the saturated wet tree crowns e mm hr 1 this method considers that the instantaneous evaporation rate e kg m 2 s 1 from a fully wet isolated tree crown can be estimated using a simple dalton type diffusion equation for water vapour brutsaert 1991 monteith and unsworth 2008 as long as its surface temperature t s k is known 1 e ρ a c p λ γ g bv e s t s e a where ρ a kg m 3 is air density c p j kg 1 k 1 is air specific heat at constant pressure λ j kg 1 is the latent heat of vaporization γ pa k 1 represents the psychrometric constant g bv m s 1 is the tree bulk aerodynamic conductance for water vapour e s t s pa is the saturation vapour pressure at surface temperature t s and e a pa represents the actual vapour pressure of the surrounding air pereira et al 2009b also showed that t s depends on available energy and wind speed through its influence on tree bulk aerodynamic conductance g bv t s can be estimated as 2 t s 1 ρ a c p γ δ γ a g bv t w where δ pa k 1 is the slope of the saturation vapour pressure vs temperature curve a w m 2 is the available energy per unit tree crown projected area and t w k is the air wet bulb temperature however under rainy conditions the radiative energy input to the tree crowns reduces to nearly zero pereira et al 2009b stewart 1977 teklehaimanot and jarvis 1991 physically restricting the surface temperature of a wet saturated tree crown to be near the air wet bulb temperature t w therefore t s can either be calculated by eq 2 t sc or set to its t w limit value t sw given the high sensitivity of the gash analytical model to e pereira et al 2016 here we used eq 1 with both estimates of t s the use of eqs 1 and 2 requires an evaluation of the bulk tree crown aerodynamic conductance g bv for uniform tree covers this conductance is usually estimated by the aerodynamic conductance for momentum calculated as a function of tree height and wind speed measured at some reference level above the canopy however this is no longer valid when trees are well separated as in traditional olive groves and an individual tree approach should be used instead pereira et al 2009a following pereira et al 2009a 2016 g bv was estimated as the product of the average leaf boundary layer conductance for water vapour g lv m s 1 by the tree leaf area index expressed on a crown projected area basis lai dimensionless 3 g bv g lv lai with g lv calculated using the so called engineering formulas as a function of wind speed at crown level u m s 1 4 g lv 0 015 u 0 5 eq 4 was derived following monteith and unsworth 2008 assuming leaves can be represented as flat plates with an average characteristic dimension of 29 5 mm measured for the leaves of the olive tree studied here and using 1 3 as an enhancement factor the value 1 3 was obtained experimentally by pereira et al 2009a for the leaves of isolated holm oak trees we used 1 3 because it is within the usual range of values of the ratio between experimental measurements and estimates of leaf conductance by engineering formulas 1 25 1 50 schuepp 1993 total leaf area was estimated by partial destructive sampling of the monitored olive tree at the end of the observation period following häusler et al 2014 a relationship between branch diameter up to 30 mm and its projected leaf area was established for two of the ten main branches of the tree the software tool lamina leaf shape determination bylesjö et al 2008 was used to evaluate the area of leaves and their length and width total tree leaf area was estimated using this relationship and the diameters of all small branches with diameter 30 mm not sampled before following gash 1979 tree crowns were considered saturated for all hours with gross rainfall greater than 0 5 mm average evaporation and rainfall for all these hourly periods were considered representative of the average evaporation and rainfall rates under saturated canopy conditions required by the model e c and r respectively the evaporation rate from the trunks is usually small typically 1 to 5 of the evaporation rate from the canopy during a rainfall event gash 1979 the value of ε the parameter relating the evaporation rates from saturated trunks and saturated canopy was set to 0 02 a value obtained experimentally by valente et al 1997 following pereira et al 2009a complete cover was assumed at the individual crown level and accordingly crown cover fraction was set to one c 1 the olive tree structural parameters required by the rainfall interception model are the crown storage capacity s the drainage partitioning coefficient p d and the trunk storage capacity s t in this study all these parameters were estimated using two new procedures see the appendix for a detailed presentation which provide an easier yet more reliable way to predict their values to estimate s all rainfall events large enough to saturate the canopy p g 1 5 mm were selected and a linear regression established between t f and p g regression coefficients were used to derive s and p d p d first being estimated by eq 5 eq a15 in the appendix allowing later estimation of s by eq 6 eq a16 in the appendix 5 p d a 1 1 c 1 ε e c r c 1 ε e c r 1 6 s a 0 1 p d 1 ε r e c 1 ln 1 e c r where a 0 and a 1 represent the intercept and the slope of the regression line between throughfall and gross precipitation respectively if stemflow is negligible s can be estimated setting p d 0 to estimate the storage capacity of trunks a linear regression is established between s f and p g considering all rainfall events large enough to saturate the canopy and trunks i e events with p g 1 5 mm and s f 0 mm s t is derived from the intercept of the regression line b 0 by eq 7 eq a27 in the appendix 7 s t b 0 ε b 1 s ln 1 e c r 1 b b ln 1 1 b where b p d r 1 ε e c ε e c to apply the above methods gross precipitation throughfall and stemflow need to be expressed per unit of the same reference area in our case equivalent throughfall t f e and s f data were expressed in mm on a crown area basis i e litres per m2 of crown projected area 3 results 3 1 measurements cumulative measured gross rainfall p g for the entire experimental period august 2011 april 2013 was 1358 7 mm of which 1078 3 mm were collected as throughfall 79 4 of p g and 35 3 mm as stemflow 2 6 of p g on a crown area basis total interception loss during the experiment was 245 0 mm representing 18 0 of p g on a crown projected area basis or 47 5 mm 3 5 of p g when expressed on total ground area considering the canopy cover of the grove 19 4 the possible maximum experimental error for total interception loss was estimated as 43 2 mm on a crown area basis i e 17 7 of the observed value these totals comprise 113 rainfall events the histograms of observed rainfall amount duration and intensity of all these storms are presented in fig s1 as supplementary material although the average storm duration was approximately 18 h only 42 5 of them started and ended on the same day with the remaining 57 5 ending in the next or following 2 3 days table 2 3 2 parameters of the interception model the mean rainfall and evaporation rates estimated as described in section 2 5 methods model parameterization were 1 954 mm hr 1 and 0 224 mm hr 1 respectively this value of the evaporation rate e tsc was obtained considering the surface temperature of the saturated tree crowns as given by eq 2 the mean evaporation rate when assuming the surface temperature equal to the air wet bulb temperature e tsw was 0 220 mm hr 1 both these estimates of the evaporation rate required the prior estimation of leaf area index and a model for the tree bulk aerodynamic conductance the mean aerodynamic conductance was found to be 0 232 0 061 m s 1 a value which is purely indicative since specific hourly values were used when calculating the evaporation rate for each hour in line with the small difference between e tsc and e tsw the estimates of the other three structural parameters were also very similar irrespective of the value used for the mean evaporation rate table 3 considering e tsc the estimates of s and p d derived from the regression between t f e and p g fig 3a were 0 972 mm and 0 045 respectively while s t was estimated as 0 086 mm based on the regression between s f and p g fig 3b table 3 summarizes the values estimated for all the parameters of the gash interception model 3 3 modelled throughfall stemflow and interception loss simulated modelled and measured values are presented in table 4 with the indication of the corresponding normalized mean bias values fig 4 shows the cumulative course of measured interception loss and the associated error bounds for the 2012 13 validation period the simulations obtained both on a storm and rain day basis are also presented in fig 4 for storm based simulations during the validation period the modelling efficiency was 70 99 and 88 for interception loss throughfall and stemflow respectively all these modelling results were obtained considering the mean evaporation rate estimated by eq 1 and the saturated canopy surface temperature t sc estimated by eq 2 however the implications of considering the alternative of the evaporation rate being based on t sw was also assessed by simulating monthly interception loss using both e tsc and e tsw fig 5 shows the results of this comparison by plotting the simulations obtained with these two evaporation rates against the observed values of interception loss for each month of the entire experimental period the modelling performance for these simulations was also assessed through the modelling efficiency for interception loss which was 91 irrespective of considering e tsc or e tsw 4 discussion 4 1 interception measurement the small number of studies on rainfall interception by isolated individual trees limits the comparisons we can make between the results obtained here and those of other experiments for both the rainfall interception components and model parameters furthermore any comparisons should only be made for values expressed in the same area basis considering the olive grove canopy cover fraction 0 194 interception loss represented 3 5 of p g total ground area basis which is similar to the value of 4 reported by mateos and schnabel 2001 for four holm oak trees in spain but lower than the values from several other studies with different cover fractions e g david et al 2006 gómez et al 2001 jackson 2000 pereira et al 2009a when interception loss depth is referenced to the tree crown projected area our results are also near the lower end of the range of other studies 12 30 according to fathizadeh et al 2013 gómez et al 2001 hassan et al 2017 mateos and schnabel 2001 pereira et al 2009a xiao et al 2000 however even though apparently expressing interception loss on the same area basis some studies on individual trees may not have accounted for the effect of wind driven rainfall i e they have assumed that precipitation always falls vertically in fact several of the above mentioned studies e g fathizadeh et al 2013 gómez et al 2001 hassan et al 2017 mateos and schnabel 2001 only monitored net precipitation beneath the tree crown not taking into account the rainfall depletion area or rain shadow extending downwind beyond the vertical projection of the crown this can result in important errors in the measurement of throughfall and on the subsequent estimation of interception loss to give an example of the under over estimation of interception loss due to omitting measurements in the rain shadow interception loss was also calculated at our site using only data from the gauges installed underneath the crown i e the two innermost circles of the experimental layout fig 1 table 5 if the arithmetic mean of the water depth measured by the 12 gauges beneath the crown were to be used interception loss would be underestimated by 8 of observed loss if data from just the four inner most throughfall gauges are used interception loss would be overestimated by 67 examining the prevailing micrometeorological conditions during the study namely wind speed and rainfall intensity the rainfall inclination angle was less than 30 in 75 of all the hours with rainfall during which 69 of the total precipitation occurred considering that these conditions are similar to those of other studies in the mediterranean climate zone e g david et al 2006 hassan et al 2017 the above analysis highlights the importance of an adequate experimental setup in correctly evaluating throughfall and interception loss this is not only relevant in the case of isolated trees but also for hedgerows see herbst et al 2006 the present study used a circular monitoring area with a diameter about twice the crown diameter fig 1 besides avoiding the errors caused by non vertical precipitation this allowed us to determine the equivalent throughfall necessary for the correct estimation of the tree structural parameters s p d and s t given the extensive equipment resources required by such an experimental setup we opted for monitoring a single individual tree in general observing just one tree may introduce a sampling error when extrapolating the results to the stand level it should not though affect the primary objective of the study which was validation of the modelling procedure the sampling errors were minimized by carefully choosing a representative olive tree not only in terms of its quantitative allometric characteristics table 1 but also in terms of its location and crown shape moreover we also took into consideration the results from other rainfall interception studies where several isolated trees were sampled statistical analyses of the longitudinal data presented by gómez et al 2001 and of unpublished data from the study of pereira et al 2009a showed that no significant differences p 0 05 existed between interception loss of the three monitored trees of each experiment although pereira et al 2009a studied a different tree species holm oak in a very sparse oak pasture system gómez et al 2001 measured rainfall interception in three mature olive trees giving support to our decision to just monitor a single representative tree another possible source of error in the quantification of throughfall was the use of a stationary network of gauges to measure this rainfall interception component it is well established that for the same number of gauges a roving random sampling scheme provides more accurate and precise long term estimates of mean throughfall than a fixed approach e g holwerda et al 2006 lloyd and marques filho 1988 ritter and regalado 2014 ziegler et al 2009 however many of these studies used a relatively small number of gauges taking into account the experimental plot area in general less than 0 1 devices m 2 in the present study this number was higher approximately 0 3 gauges m 2 and well above the upper bound value recommended by ritter and regalado 2014 based on numerical experiments on a real data set of 100 rainfall storms these authors concluded that in one hectare of a tropical semideciduous rainforest 30 gauges relocated after every five events would be a good strategy in the best case scenario always moving to new fresh positions this would be similar to use 600 fixed gauges in 1 ha i e 0 06 gauges m 2 therefore our measurements using 24 fixed gauges positioned to take account for the throughfall non random spatial distribution by sampling outside the tree crown projected area and using 0 5 gauges m 2 underneath the tree should have provided a good assessment of this variable unlike throughfall the measurement of stemflow in individual trees is more straightforward and comparison with the results of other studies is easier as long as the units used are equivalent in our study measured stemflow s f represented 2 6 of p g a value that is within the range reported in the literature for various species 2 6 p g as observed by gómez et al 2001 rodrigo et al 2003 valente et al 1997 however stemflow in this study was much higher than that observed also in portugal by valente et al 1997 in a pinus pinaster forest 0 5 p g or in an isolated holm oak tree 0 26 p g by david et al 2006 4 2 modelling parameterization correctly quantifying the canopy storage capacity s of a tree crown or plant cover may be difficult because it can be influenced by many different factors such as rainfall amount and intensity wind speed and the characteristics of the canopy and its foliage and their changes over time calder et al 1996 fleischbein et al 2005 holder 2013 hörmann et al 1996 jackson 1975 klaassen et al 1998 leonard et al 1967 llorens and gallart 2000 the commonly used methods to estimate s in particular the leyton method are based on a selection of storms making this selection can be quite subjective and critical in the case of isolated trees where throughfall can have a large spatial variability david et al 2006 pereira et al 2009a furthermore by not accounting for the evaporation that takes place during rainfall these methods tend to overestimate both the crown and trunk storage capacities the new method used in this study avoids these problems and allows the estimation not only of s but of all the structural parameters it uses information from a large number of rain events including all of those large enough to saturate the tree crown or to generate stemflow the value estimated for s in our study was 0 97 mm smaller than those reported by gómez et al 2001 for five olive trees in spain that varied between 1 53 and 3 63 mm and by several other authors for various mediterranean species e g fathizadeh et al 2013 pereira et al 2009a xiao et al 2000 this small value of s may be a result of the waxy nature of the leaves of olive trees combined with their morphology flat leaves with their edges curled down these characteristics tend to facilitate the drainage of raindrops falling onto the leaves however the big difference between the results of the present study and those of gómez et al 2001 cannot be ascribed to these features nor to differences in the leaf area index of the trees 3 1 in this work versus values in the range 1 1 5 3 reported by gómez et al 2001 the most likely explanation lies in the different methods used to derive this parameter gómez et al acknowledged that their values of s could be overestimated because evaporation during rainfall was not considered in their procedure the estimated values of stemflow parameters in the present study table 3 emphasize the importance of this interception component in olive trees the drainage partitioning coefficient p d 0 045 and trunk storage capacity s t 0 086 mm are high when compared to other tree species e g valente et al 1997 the morphological characteristics of the bark and leaves and the structure and lay out of branches are probably responsible for the high volume of stemflow in olive trees the smooth bark of young branches filippou et al 2007 the low wetability and water retention of the leaves leon and bukovac 1978 and the frequent pruning of trees all contribute to channelling the crown intercepted rainfall to the trunks the characteristics of the trunks of old trees covered by smooth and rough bark with numerous large longitudinal cracks and lenticels filippou et al 2007 promote the drainage of that water resulting in relatively high amounts of stemflow the average hourly evaporation rate for saturated canopy conditions e c is relatively conservative over the different regions of the earth and between species miralles et al 2010 and therefore it is not surprising that the estimates obtained in this study for e c table 3 agree well with those estimated for forests across a wide range of environmental conditions in the interval 0 19 0 32 pereira et al 2009a gash et al 1980 herbst et al 2008 lloyd et al 1988 valente et al 1997 however the high sensitivity of the sparse forest version of the gash model to this parameter pereira et al 2016 means that small changes in e c can have a significant impact in modelled interception loss nevertheless in the present work the difference between e c estimated when using eq 2 and when it is estimated assuming the surface temperature equal to the air wet bulb temperature is small 0 004 mm hr 1 as a result the modelled interception loss was not much affected by the method used for the estimation of e c fig 5 in contrast the mean hourly rainfall rate for periods of full tree crown saturation r depends on climate and on the prevailing type of storms miralles et al 2010 r can be as low as 1 1 mm hr 1 in southwest france loustau et al 1992 or as high as 11 8 mm hr 1 in amazonia cuartas et al 2007 the average rate obtained in this work was 1 95 mm hr 1 table 3 a value within the range reported for other sites with similar mediterranean type climate e g llorens 1997 mużyło et al 2012 pereira et al 2009a sraj et al 2008 valente et al 1997 4 3 model performance all the rainfall interception components were modelled with a good accuracy however and in relative terms interception loss had a lower performance but still with a good modelling efficiency of approximately 70 despite this lower performance of interception loss its total bias was only 1 5 in the validation period a value much smaller than the maximum estimated experimental error in interception loss measurements fig 4 the modelling of the other two components throughfall and stemflow performed even better with modelling efficiencies of 99 and 88 respectively however although the small differences between modelled and observed stemflow ranging between 0 37 and 0 67 mm across storms of the validation period the total difference was 5 5 mm amounting to nearly 23 of the observed value table 4 a possible reason for this overestimation of stemflow is the low ratio between the evaporation rates from saturated trunks and canopy assumed in the present study ε 0 02 according to the results of van stan et al 2017 in a well ventilated urban pine tree row this ratio should be much bigger corresponding on average to 10 however our modelling results do not support this high value of ε when we used ε 0 1 in our simulation affecting not only the evaporation rates but also the structural parameter estimates modelling performance was worse for all the interception components but particularly for stemflow with a normalized mean bias of 54 and a modelling efficiency of 63 although van stan et al 2017 argue that their evaporation estimates used a more direct measuring technique in fact their rates were modelled through the wet bulb approach even though pereira et al 2009a 2016 showed that this method can be used to estimate the maximum evaporation rate of a fully ventilated saturated canopy and the present study confirms it its application to estimate wet stem evaporation rates requires additional validation that has not yet been done the way in which the interception model is run also affects the modelling results with the model performing differently when run on a storm to when it is run on a daily basis contrasting with the 1 5 underestimate when modelling was done on a storm basis interception loss was overestimated by nearly 12 when modelled using daily rainfall data in the validation period table 4 however this is not surprising running the gash model with daily data i e assuming one storm per rain day is a pragmatic simplification suggested by gash 1979 to increase the amount of data available to drive the model it should not be expected to deliver results as good as those of storm based modelling an analysis on the duration and temporal distribution of the rain events throughout the experimental period showed that the average storm duration was about 18 h but 58 of the storms extended for more than one day table 2 interception loss was overestimated when modelled on a daily basis since the number of storms 62 in 2012 13 and 113 in the whole experimental period is smaller than the number of days with rainfall 92 in 2012 13 and 158 in 2011 13 an identical result has already been described by pearce and rowe 1981 working in a forest in new zealand where the number of rain days greatly exceeded the number of storms despite being poorer than storm based estimates cumulative daily based interception loss simulations still are well within the error bounds of the observed value fig 4 importantly we found here that the modelled evaporation was nearly the same whether or not account was taken of the available energy during rainfall e c 0 224 mm hr 1 when net radiation is included but e c 0 220 mm hr 1 when the canopy is assumed to be at the wet bulb temperature normalized mean bias of total modelled interception loss for the validation period was 1 5 in the first case and 2 6 in the second modelling efficiency for interception loss was also quite similar in the two cases 70 and 69 respectively the same happened when modelling was carried out on a monthly basis throughout the entire experimental period with the model performing equally well irrespective of whether e tsc or e tsw were used modelling efficiency for interception loss was 91 in both cases fig 5 overall the good modelling performance evidenced here by the gash model is certainly an indication that in such sparse tree covers the interception process is best modelled at the tree level and that under these conditions the physically based wet bulb approach is a preferable alternative to the penman monteith model not only does it perform well but it also requires less data and is simpler because the tree bulk aerodynamic conductance may be easily estimated using the engineering formula while the surface temperature of the wet tree crowns can be assumed equal to the air wet bulb temperature 5 conclusion despite the possible but unlikely limitations associated with the experimental setup our results show that the evaporation of intercepted rainfall by a traditional olive grove pasture system is important and should not be neglected these observations also confirm the good performance of the gash model the approach of modelling the interception process in this sparse cover at the tree level rather than at the grove scale certainly contributed to these good modelling results under these conditions rather than using the penman monteith model to estimate the average evaporation rate the adoption of the wet bulb approach to estimating e c proved to be a correct choice as well the good performance of the gash model is also a consequence of its adequate parameterization provided by the new methods developed here to estimate the structural parameters s p d and s t being consistent with the framework of both the gash and rutter models these new methods should be equally effective when modelling the interception process in different situations and regardless the model adopted further studies are needed to confirm this conclusion for the widest possible range of conditions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was carried in centro de estudos florestais a research unit funded by fundação para a ciência e a tecnologia i p fct portugal uid agr 00239 2013 we also acknowledge the financial support provided by the r d project futurolive efeitos das alterações climáticas na cultura produção e economia do olival ptdc agr aam 104562 2008 thanks are also due to rita peres pereira for her help with the diagrams presented in the paper and to joaquim mendes for help with the field work appendix a a new procedure to estimate the drainage partitioning coefficient the canopy storage capacity and the storage capacity of the trunks as defined by the revised version of the gash analytical model following valente et al 1997 and using the parameterization of the revised versions of the rutter and the gash models for any storm that completely saturates the forest canopy and trunks throughfall t f and stemflow s f can be expressed on a whole ground area basis as a1 t f 1 c p d p g 1 p d s c 1 p d e c dt a2 s f c p d d c dt s t c e t c dt where c is the cover fraction p d the drainage partitioning coefficient p g the storm gross rainfall s the canopy storage capacity s t c the storage capacity of the trunks d c the drip drainage from the canopy after saturation and e c and e t c the evaporation rates of the water intercepted by the canopy and the trunks respectively the subscript c indicates that the corresponding parameter or variable refers to the area covered by the canopy assuming that a linear relationship exists between t f and p g eq a1 can be taken as the basis for a procedure to determine the drainage partitioning coefficient and the canopy storage capacity in an analogous way the trunk storage capacity can be determined by a new method that takes eq a2 as the starting point a 1 canopy structural parameters s and p d for storms large enough to saturate the canopy and following gash 1979 evaporation from the canopy during rainfall can be separated into two components evaporation during the period of unsaturated canopy from the beginning of rainfall t 0 until canopy saturation is reached t t and evaporation from the saturated canopy until the end of rainfall during the time interval t t e fig a1 accordingly the rightmost integral in eq a1 can be expanded to a3 e c dt 0 t e e c dt 0 t e c dt 1 ε t t e e c dt with ε the constant ratio between the evaporation rates from saturated trunks and the canopy and whereby the evaporation from the saturated canopy t t is set to 1 ε e c to meet the requirements of the energy balance valente et al 1997 following gash 1979 the mean evaporation rate e c and the mean rainfall rate r during saturated canopy conditions can be defined as a4 e c t t e e c dt t e t and a5 r t t e r dt t e t where r is the intensity of gross rainfall defining p g as the amount of rain necessary to saturate the canopy this last equation can be rewritten as a6 p g p g r t e t and eq a4 as a7 t t e e c dt e c r p g p g since p g can be expressed as gash et al 1995 a8 p g s c 0 t e c dt eq a7 can be written as a9 t t e e c dt e c r p g s c 0 t e c dt following the assumptions of rutter et al 1971 and gash 1979 pereira et al 2009a showed that the evaporation from the unsaturated canopy during the wetting phase can be calculated as a10 0 t e c dt s c r e c s c ln 1 e c r substituting eqs a9 and a10 into eqs a3 and a1 and rearranging a11 t f s 1 p d 1 ε r e c 1 ln 1 e c r 1 c p d c 1 p d 1 ε e c r p g showing that the relationship between throughfall and gross rainfall can be generically expressed in the form a12 t f a 0 a 1 p g if a linear regression between measured t f and p g is established the intercept a 0 and slope a 1 of the regression line can be expressed as a13 a 0 s 1 p d 1 ε r e c 1 ln 1 e c r a14 a 1 1 c p d c 1 p d 1 ε e c r from eq a14 the drainage partitioning coefficient can be calculated as a15 p d a 1 1 c 1 ε e c r c 1 ε e c r 1 allowing the canopy storage capacity to be calculated from eq a13 as a16 s a 0 1 p d 1 ε r e c 1 ln 1 e c r a 2 storage capacity of the trunks s t the stemflow modelling in the sparse forest versions of both the rutter and gash models assumes that the water input to the trunks comes only from the canopy drainage and that it only starts after saturation of the tree crowns is completed gash et al 1995 valente et al 1997 fig a1 therefore stemflow only occurs during storms that are large enough to saturate both the canopy and trunks considering the time needed to reach canopy saturation t and the mean evaporation and rainfall rates for saturated canopy conditions eqs a4 and a5 respectively total drainage from the canopy can be calculated as a17 d c dt t t e r 1 ε e c dt 1 1 ε e c r p g p g combining eqs a8 and a10 p g can be calculated as a18 p g r e c s c ln 1 e c r substituting for p g in eq a17 and rearranging a19 d c dt 1 1 ε e c r p g r e c s c ln 1 e c r as with the canopy total evaporation from the trunks can be separated into two components before and after saturation of the trunks a20 e t c dt t t e e t c dt t t e t c dt t t e e t c dt where t is the time taken for the saturation of the trunk to occur fig a1 following valente et al 1997 the evaporation from saturated trunks is equal to ε e c furthermore before complete trunk saturation is reached evaporation from the trunk is proportional to the ratio between the amount of water retained by the trunk c t c and the trunk storage capacity s t c that is a21 e t c ε e c c t c s t c c t c s t c ε e c c t c s t c therefore eq a20 can be written as a22 t t e e t c dt ε e c s t c t t c t c dt ε e c r p g p g where p g the amount of rainfall necessary to saturate the trunks can be calculated as valente et al 1997 a23 p g r r 1 ε e c s t c p d p g according to the sparse forest version of the rutter model valente et al 1997 and before trunk saturation occurs the rate of change of the water stored on the trunks is the difference between trunk input and output rates a24 dc t c dt p d r 1 ε e c ε e c c t c s t c this differential equation allows the explicit calculation of the integral present in eq a22 as a25 t t c t c dt s t c 2 ε e c 1 b ln 1 1 b with b p d r 1 ε e c ε e c substituting eqs a19 a22 and a25 into eq a2 and rearranging allows s f to be rewritten as a26 s f ε b 1 s ln 1 e c r b ln 1 1 b 1 b s t ε b 1 e c r p g this last equation shows that a linear relationship can also be assumed between s f and p g s f b 0 b 1 p g establishing a linear regression between measured s f and p g allows the trunk storage capacity to be calculated as a27 s t b 0 ε b 1 s ln 1 e c r 1 b b ln 1 1 b appendix b supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2019 124417 supplementary data the following are the supplementary data to this article supplementary data 1 
5906,the rainfall intercepted by an isolated olive tree was measured in a traditional olive grove pasture system with a sparse canopy cover results from a two year period of observations are presented the data are then used to test models of the interception process in this type of agricultural system modelling was performed at the single tree level using the sparse forest version of the gash analytical model combined with two other methodologies the wet bulb approach to estimate the evaporation rate from the wet canopies of individual olive trees and a newly developed procedure to estimate the canopy structure parameters good model performance was achieved at the storm level with model simulations within 1 5 of the observed value clearly within the expected error of interception loss measurements keywords interception loss storage capacity gash s analytical model wet bulb approach tree based modelling approach stemflow 1 introduction rainfall interception loss from wet tree canopies can be an important component of the local and regional water balances and must be accounted for when drawing up any sustainable water management programme designed to foster water conservation in many dryland regions such as those with a mediterranean type climate those programmes are essential although land use in the mediterranean zone is very diverse olive production is a major agricultural activity globally the area cultivated with olive trees has been continuously expanding for the past two decades increasing by more than 25 10 3 km2 from 80 10 3 km2 in 1996 to 106 10 3 km2 in 2016 fao 2019 most olive tree stands are used to produce olive oil the european countries of the mediterranean zone are responsible for about two thirds of the world s olive oil production but new regions are becoming productive such as the usa and especially china and australia fao 2019 olive trees are also more resilient than other commercial tree species they are drought resistant and less susceptible to fire they can also regrow from the root stock after fires have occurred climate change with its accompanying droughts is thus likely to result in further expansion of olive tree plantations this large and expanding area of olive groves growing in water scarce regions makes understanding the hydrological behaviour of this land use an important priority olive groves can be managed in different ways from traditional olive grove pasture managed as a mixed use system for olive production and grazing to highly intensive systems in these two contrasting situations tree densities can range between 20 and 2000 trees ha 1 although in most of the olive cultivated area typical densities vary from 100 to 400 trees ha 1 faostat 2019 fernandez escobar et al 2013 in portugal the traditional low density olive tree plantations are still quite common yet few studies have researched their water use particularly their rainfall interception most early interception measurements were made in closed canopy forests the results were successfully modelled by process based models of the rutter type gash 1979 rutter et al 1971 rutter et al 1975 these models were later reformulated to allow their use with more open forests gash et al 1995 valente et al 1997 these revised versions which revert to the original models under closed canopy conditions proved to be successful at estimating both closed and moderately sparse forest interception loss the revised models calculate the stand level evaporation under the assumption that the evaporation from a sparse forest canopy is given by the closed canopy evaporation scaled down in proportion to the canopy cover with the hypothetical closed canopy evaporation being estimated by the penman monteith equation however this assumption becomes increasingly less valid as forest sparseness increases but pereira et al 2009b has shown that this questionable assumption can be avoided by estimating the evaporation rate using a new method the wet bulb approach according to the pereira method in stands with very sparse tree covers the wet crowns of isolated trees behave as large wet bulbs allowing the evaporation rate from their saturated surfaces to be estimated through a simple diffusion equation this method is not subject to the same constraints as the penman monteith equation the approach is also physically based and requires only a limited amount of data the pereira method was initially tested against data from an isolated holm oak tree here we investigate the further applicability of the method to estimating evaporation of rainfall intercepted by an olive tree growing within a typical olive grove the water storage capacity of a canopy is another factor that affects interception loss klaassen et al 1998 linhoss and siegert 2016 pereira et al 2016 smets et al 2019 valente et al 1997 however quantifying the water storage of a single tree crown or stand canopy has been a challenging task friesen et al 2015 levia et al 2011 usually the water storage capacities of the canopy s and trunks s t are assessed indirectly based on relationships between gross rainfall p g and the components of net rainfall namely throughfall t f and stemflow s f the so called leyton method leyton et al 1967 or any of its variants is the indirect method that has been most commonly used to estimate s david et al 2005 s is derived as the negative intercept of the envelope line or linear regression between t f and p g considering only storms capable of saturating the canopy and for which evaporation during rain is negligible the subjectivity inherent in the selection of such rainfall events is further complicated by the problems arising from the generally high spatial and temporal variability of net rainfall lloyd and marques filho 1988 zimmermann et al 2009 these factors contribute to significant errors in the estimates of storage capacity obtained by this method attempting to avoid these problems pereira et al 2009a proposed a new procedure to estimate s which is conceptually coherent with the formulation of the revised versions of both gash and rutter models gash et al 1995 valente et al 1997 the method uses information from a larger number of rainfall events and accounts for the evaporation during the wetting phase of the storms however it does not account for stemflow an important drawback whenever this component of the water balance cannot be neglected here we overcome this limitation by reformulating the procedure to estimate s making it more robust and independent of the magnitude of stemflow we also extend the approach to develop a new method of determining the trunk storage capacity this paper reports on a study on the rainfall interception process in a traditional low density olive grove pasture system in portugal as with mediterranean savanna type oak woodlands david et al 2006 pereira et al 2009a we believe that olive grove interception loss is best estimated as the sum of the contribution of all individual trees therefore and focusing on a single representative individual tree we hypothesize that a combination of the wet bulb approach robust procedures to estimate the canopy structural parameters and the revised version of the gash analytical model is the best way to model rainfall interception by the tree component of these agricultural systems 2 methods 2 1 experimental site data were collected from 25 august 2011 to 30 april 2013 in an olive grove pasture system located on the experimental farm of the school of agriculture of the polytechnic institute of castelo branco 39 49 15 n 7 27 33 w 365 m a s l in central portugal this is a traditional rain fed olive grove the trees are 80 90 years old and have an approximate spacing of 11 m 11 m giving 83 trees ha 1 canopy cover is 19 4 measured through image analysis of a digital orthophotomap using arcgis the site is flat and the local climate is mediterranean under continental influence with hot dry summers and mild wet winters long term 1981 2010 average annual rainfall is 783 mm falling mainly between october and may and mean annual temperature is 16 c ipma 2019 2 2 instrumentation the rainfall interception experiment was installed around a single olive tree olea europea l cultivar galega vulgar chosen as being representative of the grove table 1 distance to the nearest neighbouring tree was 9 6 m throughfall t f was measured by an array of 24 tipping bucket rain gauges installed around the tree the gauges 0 2 and 0 5 mm per tip w5724 and w5720 casella limited bedford uk 0 2 mm per tip arg100 environmental measurements gateshead uk were positioned in three concentric circles with radii of 1 2 25 and 5 m centred on the tree trunk fig 1 the sampling area expanded outside the crown limit to account for the rain shadow effect on the leeward side of the tree david et al 2006 stemflow s f was collected by a spiral rubber gutter attached to the tree trunk and connected to a covered 0 5 mm tipping bucket rain gauge w5720 casella limited bedford uk all tipping bucket measurements were stored as 10 min cumulative values by a cr10x data logger campbell scientific shepshed uk an automatic weather station was installed on a metal structure consisting of a 4 m high metal tower and an additional 2 m length mast the tower was erected next to a second tree approximately 15 m away which had reached a height of 5 7 m by the end of the experiment while the air wet and dry bulb temperatures were measured at mid crown level at a height of ca 3 m using an aspirated psychrometer institute of hydrology uk see wright et al 1992 net radiation nr lite kipp zonen delft the netherlands and wind speed and direction vector instruments rhyl uk were measured above the canopy on the top of the tower mast at a height of 6 m gross rainfall p g was collected by a funnel with a diameter of 25 4 cm mounted on the top of the tower at a height of 4 m and measured in a covered tipping bucket rain gauge w5724 casella limited bedford uk with 22 5 cm of diameter on the ground resulting in a resolution of 0 16 mm per tip data were sampled at 10 s intervals and recorded as 10 min totals rainfall or averages by another cr10x data logger occasionally during the data collection period some of the tipping bucket gauges were not operational e g clogging of the filter damaged cables for these short periods data gap filling was performed using linear regressions with the other fully operational gauges 2 3 interception loss following the whole tree approach of david et al 2006 and pereira et al 2009a interception loss from the monitored tree was first calculated as the difference in volume between the gross rainfall and the stemflow s f plus throughfall t f note that here the term throughfall includes all the water collected by the network of gauges on the ground drips from the canopy and rainfall collected both upwind of the tree and in the rain shadow on its leeward side the total volume of throughfall was calculated with each gauge in the sampling area weighted according to its area of influence circular quarter or sector as depicted in fig 1 interception loss i on a crown area basis was then expressed in millimetres by dividing its volume in litres by the tree crown projected area in m2 once interception loss is calculated in mm equivalent throughfall t f e mm on a crown area basis is calculated as the difference between p g and s f plus interception david et al 2006 pereira et al 2009a these values can then also be expressed on the basis of the whole olive grove ground area if multiplied by the average crown cover fraction 0 194 when the mass balance equation is used to evaluate the interception loss i is a small number obtained from the difference between two large ones gross and net rainfall accurate measurements are therefore needed to give a useful estimate of interception loss david et al 2005 however in forests and other tree covers the accurate measurement of p g is particularly difficult robinson et al 2004 a preliminary data analysis of the gross rainfall measured during this study showed a significant under catch by the tower gauge when results from this rain gauge were compared to those obtained by one of the throughfall gauges located in the outer circle outside of the influence of the tree crown gauge number 19 was chosen as a reference because it was operational during all the experimental period it was found that the tower rain gauge underestimated p g by 6 2 fig 2 a this result was confirmed by a similar analysis using daily data from the weather station at castelo branco belonging to the national meteorological service ipma located about 2 km from the experimental site fig 2b to ensure that the t f gauge used was outside the tree rain shadow this analysis was done with daily data for wet periods when the mean wind speed was lower than 3 m s 1 the location of the tower upwind of the nearest tree and the proximity between the funnel rim 4 m high and the tree top 5 7 m high at the end of the experiment may have caused this bias the presence of the tree may not only have enhanced the wind turbulence near the funnel but could also be responsible for a sheltering effect on the tower gauge resulting in its under catch robinson et al 2004 to avoid additional errors due to differences in the time and spatial distribution of rainfall p g data measured at the experimental site on the top of the tower were used but only after the correction for the measurement error of 6 2 apart from this systematic bias in the precipitation measurement measurements are also affected by random experimental errors to quantify these errors for interception loss measurements we assumed that p g t f and s f were variables measured independently with an error not worse than 2 5 muzylo et al 2009 the uncertainty in interception loss was calculated as the root sum squares of those errors in the input quantities of the water balance equation kirkup and frenkel 2006 computing this uncertainty for all the storms of the validation period allowed us to allocate error bounds to the cumulative measured interception loss 2 4 rainfall interception modelling the tree based approach for modelling interception loss proposed by pereira et al 2009a was used in this study the sparse forest version of the gash analytical model valente et al 1997 was applied at the tree level to simulate the three main components of the rainfall interception process throughfall stemflow and evaporation the model was run both on a rainfall event and on a rain day basis each rainfall event was defined as a continuous or intermittent rainfall period separated from other storms by at least six hours without rain david et al 2006 pereira et al 2009a valente et al 1997 when using rain days as the data source a single event per day was assumed 2 5 model parameterization all model parameters were estimated using data collected between august 2011 and august 2012 hereafter referred to as the 2011 12 period the remaining data from september 2012 to april 2013 2012 13 period was used as an independent dataset for model validation modelling performance was assessed by calculating the normalized mean bias and modelling efficiency janssen and heuberger 1995 mayer and butler 1993 like the coefficient of determination used in linear regression modelling efficiency is a measure of the overall goodness of fit which quantifies the percentage of the variance of the observed values which is explained by the model the wet bulb approach described by pereira et al 2009b was adopted to estimate the mean rate of evaporation from the saturated wet tree crowns e mm hr 1 this method considers that the instantaneous evaporation rate e kg m 2 s 1 from a fully wet isolated tree crown can be estimated using a simple dalton type diffusion equation for water vapour brutsaert 1991 monteith and unsworth 2008 as long as its surface temperature t s k is known 1 e ρ a c p λ γ g bv e s t s e a where ρ a kg m 3 is air density c p j kg 1 k 1 is air specific heat at constant pressure λ j kg 1 is the latent heat of vaporization γ pa k 1 represents the psychrometric constant g bv m s 1 is the tree bulk aerodynamic conductance for water vapour e s t s pa is the saturation vapour pressure at surface temperature t s and e a pa represents the actual vapour pressure of the surrounding air pereira et al 2009b also showed that t s depends on available energy and wind speed through its influence on tree bulk aerodynamic conductance g bv t s can be estimated as 2 t s 1 ρ a c p γ δ γ a g bv t w where δ pa k 1 is the slope of the saturation vapour pressure vs temperature curve a w m 2 is the available energy per unit tree crown projected area and t w k is the air wet bulb temperature however under rainy conditions the radiative energy input to the tree crowns reduces to nearly zero pereira et al 2009b stewart 1977 teklehaimanot and jarvis 1991 physically restricting the surface temperature of a wet saturated tree crown to be near the air wet bulb temperature t w therefore t s can either be calculated by eq 2 t sc or set to its t w limit value t sw given the high sensitivity of the gash analytical model to e pereira et al 2016 here we used eq 1 with both estimates of t s the use of eqs 1 and 2 requires an evaluation of the bulk tree crown aerodynamic conductance g bv for uniform tree covers this conductance is usually estimated by the aerodynamic conductance for momentum calculated as a function of tree height and wind speed measured at some reference level above the canopy however this is no longer valid when trees are well separated as in traditional olive groves and an individual tree approach should be used instead pereira et al 2009a following pereira et al 2009a 2016 g bv was estimated as the product of the average leaf boundary layer conductance for water vapour g lv m s 1 by the tree leaf area index expressed on a crown projected area basis lai dimensionless 3 g bv g lv lai with g lv calculated using the so called engineering formulas as a function of wind speed at crown level u m s 1 4 g lv 0 015 u 0 5 eq 4 was derived following monteith and unsworth 2008 assuming leaves can be represented as flat plates with an average characteristic dimension of 29 5 mm measured for the leaves of the olive tree studied here and using 1 3 as an enhancement factor the value 1 3 was obtained experimentally by pereira et al 2009a for the leaves of isolated holm oak trees we used 1 3 because it is within the usual range of values of the ratio between experimental measurements and estimates of leaf conductance by engineering formulas 1 25 1 50 schuepp 1993 total leaf area was estimated by partial destructive sampling of the monitored olive tree at the end of the observation period following häusler et al 2014 a relationship between branch diameter up to 30 mm and its projected leaf area was established for two of the ten main branches of the tree the software tool lamina leaf shape determination bylesjö et al 2008 was used to evaluate the area of leaves and their length and width total tree leaf area was estimated using this relationship and the diameters of all small branches with diameter 30 mm not sampled before following gash 1979 tree crowns were considered saturated for all hours with gross rainfall greater than 0 5 mm average evaporation and rainfall for all these hourly periods were considered representative of the average evaporation and rainfall rates under saturated canopy conditions required by the model e c and r respectively the evaporation rate from the trunks is usually small typically 1 to 5 of the evaporation rate from the canopy during a rainfall event gash 1979 the value of ε the parameter relating the evaporation rates from saturated trunks and saturated canopy was set to 0 02 a value obtained experimentally by valente et al 1997 following pereira et al 2009a complete cover was assumed at the individual crown level and accordingly crown cover fraction was set to one c 1 the olive tree structural parameters required by the rainfall interception model are the crown storage capacity s the drainage partitioning coefficient p d and the trunk storage capacity s t in this study all these parameters were estimated using two new procedures see the appendix for a detailed presentation which provide an easier yet more reliable way to predict their values to estimate s all rainfall events large enough to saturate the canopy p g 1 5 mm were selected and a linear regression established between t f and p g regression coefficients were used to derive s and p d p d first being estimated by eq 5 eq a15 in the appendix allowing later estimation of s by eq 6 eq a16 in the appendix 5 p d a 1 1 c 1 ε e c r c 1 ε e c r 1 6 s a 0 1 p d 1 ε r e c 1 ln 1 e c r where a 0 and a 1 represent the intercept and the slope of the regression line between throughfall and gross precipitation respectively if stemflow is negligible s can be estimated setting p d 0 to estimate the storage capacity of trunks a linear regression is established between s f and p g considering all rainfall events large enough to saturate the canopy and trunks i e events with p g 1 5 mm and s f 0 mm s t is derived from the intercept of the regression line b 0 by eq 7 eq a27 in the appendix 7 s t b 0 ε b 1 s ln 1 e c r 1 b b ln 1 1 b where b p d r 1 ε e c ε e c to apply the above methods gross precipitation throughfall and stemflow need to be expressed per unit of the same reference area in our case equivalent throughfall t f e and s f data were expressed in mm on a crown area basis i e litres per m2 of crown projected area 3 results 3 1 measurements cumulative measured gross rainfall p g for the entire experimental period august 2011 april 2013 was 1358 7 mm of which 1078 3 mm were collected as throughfall 79 4 of p g and 35 3 mm as stemflow 2 6 of p g on a crown area basis total interception loss during the experiment was 245 0 mm representing 18 0 of p g on a crown projected area basis or 47 5 mm 3 5 of p g when expressed on total ground area considering the canopy cover of the grove 19 4 the possible maximum experimental error for total interception loss was estimated as 43 2 mm on a crown area basis i e 17 7 of the observed value these totals comprise 113 rainfall events the histograms of observed rainfall amount duration and intensity of all these storms are presented in fig s1 as supplementary material although the average storm duration was approximately 18 h only 42 5 of them started and ended on the same day with the remaining 57 5 ending in the next or following 2 3 days table 2 3 2 parameters of the interception model the mean rainfall and evaporation rates estimated as described in section 2 5 methods model parameterization were 1 954 mm hr 1 and 0 224 mm hr 1 respectively this value of the evaporation rate e tsc was obtained considering the surface temperature of the saturated tree crowns as given by eq 2 the mean evaporation rate when assuming the surface temperature equal to the air wet bulb temperature e tsw was 0 220 mm hr 1 both these estimates of the evaporation rate required the prior estimation of leaf area index and a model for the tree bulk aerodynamic conductance the mean aerodynamic conductance was found to be 0 232 0 061 m s 1 a value which is purely indicative since specific hourly values were used when calculating the evaporation rate for each hour in line with the small difference between e tsc and e tsw the estimates of the other three structural parameters were also very similar irrespective of the value used for the mean evaporation rate table 3 considering e tsc the estimates of s and p d derived from the regression between t f e and p g fig 3a were 0 972 mm and 0 045 respectively while s t was estimated as 0 086 mm based on the regression between s f and p g fig 3b table 3 summarizes the values estimated for all the parameters of the gash interception model 3 3 modelled throughfall stemflow and interception loss simulated modelled and measured values are presented in table 4 with the indication of the corresponding normalized mean bias values fig 4 shows the cumulative course of measured interception loss and the associated error bounds for the 2012 13 validation period the simulations obtained both on a storm and rain day basis are also presented in fig 4 for storm based simulations during the validation period the modelling efficiency was 70 99 and 88 for interception loss throughfall and stemflow respectively all these modelling results were obtained considering the mean evaporation rate estimated by eq 1 and the saturated canopy surface temperature t sc estimated by eq 2 however the implications of considering the alternative of the evaporation rate being based on t sw was also assessed by simulating monthly interception loss using both e tsc and e tsw fig 5 shows the results of this comparison by plotting the simulations obtained with these two evaporation rates against the observed values of interception loss for each month of the entire experimental period the modelling performance for these simulations was also assessed through the modelling efficiency for interception loss which was 91 irrespective of considering e tsc or e tsw 4 discussion 4 1 interception measurement the small number of studies on rainfall interception by isolated individual trees limits the comparisons we can make between the results obtained here and those of other experiments for both the rainfall interception components and model parameters furthermore any comparisons should only be made for values expressed in the same area basis considering the olive grove canopy cover fraction 0 194 interception loss represented 3 5 of p g total ground area basis which is similar to the value of 4 reported by mateos and schnabel 2001 for four holm oak trees in spain but lower than the values from several other studies with different cover fractions e g david et al 2006 gómez et al 2001 jackson 2000 pereira et al 2009a when interception loss depth is referenced to the tree crown projected area our results are also near the lower end of the range of other studies 12 30 according to fathizadeh et al 2013 gómez et al 2001 hassan et al 2017 mateos and schnabel 2001 pereira et al 2009a xiao et al 2000 however even though apparently expressing interception loss on the same area basis some studies on individual trees may not have accounted for the effect of wind driven rainfall i e they have assumed that precipitation always falls vertically in fact several of the above mentioned studies e g fathizadeh et al 2013 gómez et al 2001 hassan et al 2017 mateos and schnabel 2001 only monitored net precipitation beneath the tree crown not taking into account the rainfall depletion area or rain shadow extending downwind beyond the vertical projection of the crown this can result in important errors in the measurement of throughfall and on the subsequent estimation of interception loss to give an example of the under over estimation of interception loss due to omitting measurements in the rain shadow interception loss was also calculated at our site using only data from the gauges installed underneath the crown i e the two innermost circles of the experimental layout fig 1 table 5 if the arithmetic mean of the water depth measured by the 12 gauges beneath the crown were to be used interception loss would be underestimated by 8 of observed loss if data from just the four inner most throughfall gauges are used interception loss would be overestimated by 67 examining the prevailing micrometeorological conditions during the study namely wind speed and rainfall intensity the rainfall inclination angle was less than 30 in 75 of all the hours with rainfall during which 69 of the total precipitation occurred considering that these conditions are similar to those of other studies in the mediterranean climate zone e g david et al 2006 hassan et al 2017 the above analysis highlights the importance of an adequate experimental setup in correctly evaluating throughfall and interception loss this is not only relevant in the case of isolated trees but also for hedgerows see herbst et al 2006 the present study used a circular monitoring area with a diameter about twice the crown diameter fig 1 besides avoiding the errors caused by non vertical precipitation this allowed us to determine the equivalent throughfall necessary for the correct estimation of the tree structural parameters s p d and s t given the extensive equipment resources required by such an experimental setup we opted for monitoring a single individual tree in general observing just one tree may introduce a sampling error when extrapolating the results to the stand level it should not though affect the primary objective of the study which was validation of the modelling procedure the sampling errors were minimized by carefully choosing a representative olive tree not only in terms of its quantitative allometric characteristics table 1 but also in terms of its location and crown shape moreover we also took into consideration the results from other rainfall interception studies where several isolated trees were sampled statistical analyses of the longitudinal data presented by gómez et al 2001 and of unpublished data from the study of pereira et al 2009a showed that no significant differences p 0 05 existed between interception loss of the three monitored trees of each experiment although pereira et al 2009a studied a different tree species holm oak in a very sparse oak pasture system gómez et al 2001 measured rainfall interception in three mature olive trees giving support to our decision to just monitor a single representative tree another possible source of error in the quantification of throughfall was the use of a stationary network of gauges to measure this rainfall interception component it is well established that for the same number of gauges a roving random sampling scheme provides more accurate and precise long term estimates of mean throughfall than a fixed approach e g holwerda et al 2006 lloyd and marques filho 1988 ritter and regalado 2014 ziegler et al 2009 however many of these studies used a relatively small number of gauges taking into account the experimental plot area in general less than 0 1 devices m 2 in the present study this number was higher approximately 0 3 gauges m 2 and well above the upper bound value recommended by ritter and regalado 2014 based on numerical experiments on a real data set of 100 rainfall storms these authors concluded that in one hectare of a tropical semideciduous rainforest 30 gauges relocated after every five events would be a good strategy in the best case scenario always moving to new fresh positions this would be similar to use 600 fixed gauges in 1 ha i e 0 06 gauges m 2 therefore our measurements using 24 fixed gauges positioned to take account for the throughfall non random spatial distribution by sampling outside the tree crown projected area and using 0 5 gauges m 2 underneath the tree should have provided a good assessment of this variable unlike throughfall the measurement of stemflow in individual trees is more straightforward and comparison with the results of other studies is easier as long as the units used are equivalent in our study measured stemflow s f represented 2 6 of p g a value that is within the range reported in the literature for various species 2 6 p g as observed by gómez et al 2001 rodrigo et al 2003 valente et al 1997 however stemflow in this study was much higher than that observed also in portugal by valente et al 1997 in a pinus pinaster forest 0 5 p g or in an isolated holm oak tree 0 26 p g by david et al 2006 4 2 modelling parameterization correctly quantifying the canopy storage capacity s of a tree crown or plant cover may be difficult because it can be influenced by many different factors such as rainfall amount and intensity wind speed and the characteristics of the canopy and its foliage and their changes over time calder et al 1996 fleischbein et al 2005 holder 2013 hörmann et al 1996 jackson 1975 klaassen et al 1998 leonard et al 1967 llorens and gallart 2000 the commonly used methods to estimate s in particular the leyton method are based on a selection of storms making this selection can be quite subjective and critical in the case of isolated trees where throughfall can have a large spatial variability david et al 2006 pereira et al 2009a furthermore by not accounting for the evaporation that takes place during rainfall these methods tend to overestimate both the crown and trunk storage capacities the new method used in this study avoids these problems and allows the estimation not only of s but of all the structural parameters it uses information from a large number of rain events including all of those large enough to saturate the tree crown or to generate stemflow the value estimated for s in our study was 0 97 mm smaller than those reported by gómez et al 2001 for five olive trees in spain that varied between 1 53 and 3 63 mm and by several other authors for various mediterranean species e g fathizadeh et al 2013 pereira et al 2009a xiao et al 2000 this small value of s may be a result of the waxy nature of the leaves of olive trees combined with their morphology flat leaves with their edges curled down these characteristics tend to facilitate the drainage of raindrops falling onto the leaves however the big difference between the results of the present study and those of gómez et al 2001 cannot be ascribed to these features nor to differences in the leaf area index of the trees 3 1 in this work versus values in the range 1 1 5 3 reported by gómez et al 2001 the most likely explanation lies in the different methods used to derive this parameter gómez et al acknowledged that their values of s could be overestimated because evaporation during rainfall was not considered in their procedure the estimated values of stemflow parameters in the present study table 3 emphasize the importance of this interception component in olive trees the drainage partitioning coefficient p d 0 045 and trunk storage capacity s t 0 086 mm are high when compared to other tree species e g valente et al 1997 the morphological characteristics of the bark and leaves and the structure and lay out of branches are probably responsible for the high volume of stemflow in olive trees the smooth bark of young branches filippou et al 2007 the low wetability and water retention of the leaves leon and bukovac 1978 and the frequent pruning of trees all contribute to channelling the crown intercepted rainfall to the trunks the characteristics of the trunks of old trees covered by smooth and rough bark with numerous large longitudinal cracks and lenticels filippou et al 2007 promote the drainage of that water resulting in relatively high amounts of stemflow the average hourly evaporation rate for saturated canopy conditions e c is relatively conservative over the different regions of the earth and between species miralles et al 2010 and therefore it is not surprising that the estimates obtained in this study for e c table 3 agree well with those estimated for forests across a wide range of environmental conditions in the interval 0 19 0 32 pereira et al 2009a gash et al 1980 herbst et al 2008 lloyd et al 1988 valente et al 1997 however the high sensitivity of the sparse forest version of the gash model to this parameter pereira et al 2016 means that small changes in e c can have a significant impact in modelled interception loss nevertheless in the present work the difference between e c estimated when using eq 2 and when it is estimated assuming the surface temperature equal to the air wet bulb temperature is small 0 004 mm hr 1 as a result the modelled interception loss was not much affected by the method used for the estimation of e c fig 5 in contrast the mean hourly rainfall rate for periods of full tree crown saturation r depends on climate and on the prevailing type of storms miralles et al 2010 r can be as low as 1 1 mm hr 1 in southwest france loustau et al 1992 or as high as 11 8 mm hr 1 in amazonia cuartas et al 2007 the average rate obtained in this work was 1 95 mm hr 1 table 3 a value within the range reported for other sites with similar mediterranean type climate e g llorens 1997 mużyło et al 2012 pereira et al 2009a sraj et al 2008 valente et al 1997 4 3 model performance all the rainfall interception components were modelled with a good accuracy however and in relative terms interception loss had a lower performance but still with a good modelling efficiency of approximately 70 despite this lower performance of interception loss its total bias was only 1 5 in the validation period a value much smaller than the maximum estimated experimental error in interception loss measurements fig 4 the modelling of the other two components throughfall and stemflow performed even better with modelling efficiencies of 99 and 88 respectively however although the small differences between modelled and observed stemflow ranging between 0 37 and 0 67 mm across storms of the validation period the total difference was 5 5 mm amounting to nearly 23 of the observed value table 4 a possible reason for this overestimation of stemflow is the low ratio between the evaporation rates from saturated trunks and canopy assumed in the present study ε 0 02 according to the results of van stan et al 2017 in a well ventilated urban pine tree row this ratio should be much bigger corresponding on average to 10 however our modelling results do not support this high value of ε when we used ε 0 1 in our simulation affecting not only the evaporation rates but also the structural parameter estimates modelling performance was worse for all the interception components but particularly for stemflow with a normalized mean bias of 54 and a modelling efficiency of 63 although van stan et al 2017 argue that their evaporation estimates used a more direct measuring technique in fact their rates were modelled through the wet bulb approach even though pereira et al 2009a 2016 showed that this method can be used to estimate the maximum evaporation rate of a fully ventilated saturated canopy and the present study confirms it its application to estimate wet stem evaporation rates requires additional validation that has not yet been done the way in which the interception model is run also affects the modelling results with the model performing differently when run on a storm to when it is run on a daily basis contrasting with the 1 5 underestimate when modelling was done on a storm basis interception loss was overestimated by nearly 12 when modelled using daily rainfall data in the validation period table 4 however this is not surprising running the gash model with daily data i e assuming one storm per rain day is a pragmatic simplification suggested by gash 1979 to increase the amount of data available to drive the model it should not be expected to deliver results as good as those of storm based modelling an analysis on the duration and temporal distribution of the rain events throughout the experimental period showed that the average storm duration was about 18 h but 58 of the storms extended for more than one day table 2 interception loss was overestimated when modelled on a daily basis since the number of storms 62 in 2012 13 and 113 in the whole experimental period is smaller than the number of days with rainfall 92 in 2012 13 and 158 in 2011 13 an identical result has already been described by pearce and rowe 1981 working in a forest in new zealand where the number of rain days greatly exceeded the number of storms despite being poorer than storm based estimates cumulative daily based interception loss simulations still are well within the error bounds of the observed value fig 4 importantly we found here that the modelled evaporation was nearly the same whether or not account was taken of the available energy during rainfall e c 0 224 mm hr 1 when net radiation is included but e c 0 220 mm hr 1 when the canopy is assumed to be at the wet bulb temperature normalized mean bias of total modelled interception loss for the validation period was 1 5 in the first case and 2 6 in the second modelling efficiency for interception loss was also quite similar in the two cases 70 and 69 respectively the same happened when modelling was carried out on a monthly basis throughout the entire experimental period with the model performing equally well irrespective of whether e tsc or e tsw were used modelling efficiency for interception loss was 91 in both cases fig 5 overall the good modelling performance evidenced here by the gash model is certainly an indication that in such sparse tree covers the interception process is best modelled at the tree level and that under these conditions the physically based wet bulb approach is a preferable alternative to the penman monteith model not only does it perform well but it also requires less data and is simpler because the tree bulk aerodynamic conductance may be easily estimated using the engineering formula while the surface temperature of the wet tree crowns can be assumed equal to the air wet bulb temperature 5 conclusion despite the possible but unlikely limitations associated with the experimental setup our results show that the evaporation of intercepted rainfall by a traditional olive grove pasture system is important and should not be neglected these observations also confirm the good performance of the gash model the approach of modelling the interception process in this sparse cover at the tree level rather than at the grove scale certainly contributed to these good modelling results under these conditions rather than using the penman monteith model to estimate the average evaporation rate the adoption of the wet bulb approach to estimating e c proved to be a correct choice as well the good performance of the gash model is also a consequence of its adequate parameterization provided by the new methods developed here to estimate the structural parameters s p d and s t being consistent with the framework of both the gash and rutter models these new methods should be equally effective when modelling the interception process in different situations and regardless the model adopted further studies are needed to confirm this conclusion for the widest possible range of conditions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was carried in centro de estudos florestais a research unit funded by fundação para a ciência e a tecnologia i p fct portugal uid agr 00239 2013 we also acknowledge the financial support provided by the r d project futurolive efeitos das alterações climáticas na cultura produção e economia do olival ptdc agr aam 104562 2008 thanks are also due to rita peres pereira for her help with the diagrams presented in the paper and to joaquim mendes for help with the field work appendix a a new procedure to estimate the drainage partitioning coefficient the canopy storage capacity and the storage capacity of the trunks as defined by the revised version of the gash analytical model following valente et al 1997 and using the parameterization of the revised versions of the rutter and the gash models for any storm that completely saturates the forest canopy and trunks throughfall t f and stemflow s f can be expressed on a whole ground area basis as a1 t f 1 c p d p g 1 p d s c 1 p d e c dt a2 s f c p d d c dt s t c e t c dt where c is the cover fraction p d the drainage partitioning coefficient p g the storm gross rainfall s the canopy storage capacity s t c the storage capacity of the trunks d c the drip drainage from the canopy after saturation and e c and e t c the evaporation rates of the water intercepted by the canopy and the trunks respectively the subscript c indicates that the corresponding parameter or variable refers to the area covered by the canopy assuming that a linear relationship exists between t f and p g eq a1 can be taken as the basis for a procedure to determine the drainage partitioning coefficient and the canopy storage capacity in an analogous way the trunk storage capacity can be determined by a new method that takes eq a2 as the starting point a 1 canopy structural parameters s and p d for storms large enough to saturate the canopy and following gash 1979 evaporation from the canopy during rainfall can be separated into two components evaporation during the period of unsaturated canopy from the beginning of rainfall t 0 until canopy saturation is reached t t and evaporation from the saturated canopy until the end of rainfall during the time interval t t e fig a1 accordingly the rightmost integral in eq a1 can be expanded to a3 e c dt 0 t e e c dt 0 t e c dt 1 ε t t e e c dt with ε the constant ratio between the evaporation rates from saturated trunks and the canopy and whereby the evaporation from the saturated canopy t t is set to 1 ε e c to meet the requirements of the energy balance valente et al 1997 following gash 1979 the mean evaporation rate e c and the mean rainfall rate r during saturated canopy conditions can be defined as a4 e c t t e e c dt t e t and a5 r t t e r dt t e t where r is the intensity of gross rainfall defining p g as the amount of rain necessary to saturate the canopy this last equation can be rewritten as a6 p g p g r t e t and eq a4 as a7 t t e e c dt e c r p g p g since p g can be expressed as gash et al 1995 a8 p g s c 0 t e c dt eq a7 can be written as a9 t t e e c dt e c r p g s c 0 t e c dt following the assumptions of rutter et al 1971 and gash 1979 pereira et al 2009a showed that the evaporation from the unsaturated canopy during the wetting phase can be calculated as a10 0 t e c dt s c r e c s c ln 1 e c r substituting eqs a9 and a10 into eqs a3 and a1 and rearranging a11 t f s 1 p d 1 ε r e c 1 ln 1 e c r 1 c p d c 1 p d 1 ε e c r p g showing that the relationship between throughfall and gross rainfall can be generically expressed in the form a12 t f a 0 a 1 p g if a linear regression between measured t f and p g is established the intercept a 0 and slope a 1 of the regression line can be expressed as a13 a 0 s 1 p d 1 ε r e c 1 ln 1 e c r a14 a 1 1 c p d c 1 p d 1 ε e c r from eq a14 the drainage partitioning coefficient can be calculated as a15 p d a 1 1 c 1 ε e c r c 1 ε e c r 1 allowing the canopy storage capacity to be calculated from eq a13 as a16 s a 0 1 p d 1 ε r e c 1 ln 1 e c r a 2 storage capacity of the trunks s t the stemflow modelling in the sparse forest versions of both the rutter and gash models assumes that the water input to the trunks comes only from the canopy drainage and that it only starts after saturation of the tree crowns is completed gash et al 1995 valente et al 1997 fig a1 therefore stemflow only occurs during storms that are large enough to saturate both the canopy and trunks considering the time needed to reach canopy saturation t and the mean evaporation and rainfall rates for saturated canopy conditions eqs a4 and a5 respectively total drainage from the canopy can be calculated as a17 d c dt t t e r 1 ε e c dt 1 1 ε e c r p g p g combining eqs a8 and a10 p g can be calculated as a18 p g r e c s c ln 1 e c r substituting for p g in eq a17 and rearranging a19 d c dt 1 1 ε e c r p g r e c s c ln 1 e c r as with the canopy total evaporation from the trunks can be separated into two components before and after saturation of the trunks a20 e t c dt t t e e t c dt t t e t c dt t t e e t c dt where t is the time taken for the saturation of the trunk to occur fig a1 following valente et al 1997 the evaporation from saturated trunks is equal to ε e c furthermore before complete trunk saturation is reached evaporation from the trunk is proportional to the ratio between the amount of water retained by the trunk c t c and the trunk storage capacity s t c that is a21 e t c ε e c c t c s t c c t c s t c ε e c c t c s t c therefore eq a20 can be written as a22 t t e e t c dt ε e c s t c t t c t c dt ε e c r p g p g where p g the amount of rainfall necessary to saturate the trunks can be calculated as valente et al 1997 a23 p g r r 1 ε e c s t c p d p g according to the sparse forest version of the rutter model valente et al 1997 and before trunk saturation occurs the rate of change of the water stored on the trunks is the difference between trunk input and output rates a24 dc t c dt p d r 1 ε e c ε e c c t c s t c this differential equation allows the explicit calculation of the integral present in eq a22 as a25 t t c t c dt s t c 2 ε e c 1 b ln 1 1 b with b p d r 1 ε e c ε e c substituting eqs a19 a22 and a25 into eq a2 and rearranging allows s f to be rewritten as a26 s f ε b 1 s ln 1 e c r b ln 1 1 b 1 b s t ε b 1 e c r p g this last equation shows that a linear relationship can also be assumed between s f and p g s f b 0 b 1 p g establishing a linear regression between measured s f and p g allows the trunk storage capacity to be calculated as a27 s t b 0 ε b 1 s ln 1 e c r 1 b b ln 1 1 b appendix b supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2019 124417 supplementary data the following are the supplementary data to this article supplementary data 1 
5907,gravitational search algorithm gsa 2 2 lévy flight strategy to improve the local search ability of the global best known agent 2 3 mutation operation strategy to improve the diversity of the swarm 2 4 elitism selection strategy to promote the exploration capability of the swarm 2 5 execution steps of the mgsa method 3 numerical experiments to verify the performance of the mgsa method 3 1 benchmark functions 3 2 parameter setting 3 3 result comparison 4 mathematical model 4 1 mathematical model 4 1 1 objective function 4 1 2 physical constraints 4 2 details of mgsa for the ecological operation problem of cascade hydropower reservoirs 4 2 1 individual structure and swarm initialization 4 2 2 constraint handling method 4 2 3 flowchart of mgsa for cascade hydropower reservoir ecological operation problem 5 case studies 5 1 engineering background 5 2 case study 1 5 2 1 statistical results analysis 5 2 2 box plot analysis 5 2 3 scheduling process 5 3 case study 2 6 conclusions credit authorship contribution statement acknowledgments adnan 2017 r cao 2019 159 167 y catalao 2009 337 346 j catalao 2007 1297 1304 j catalao 2012 237 244 j catalao 2010 935 942 j chang 2011 70 80 j chang 2018 886 897 j chen 2015 258 268 x chen 2014 306 315 z fang 2018 3835 3852 g feng 2020 z feng 2017 718 730 z feng 2019 229 238 z feng 2017 165 178 z feng 2018 706 718 z feng 2018 432 442 z feng 2019 2179 z feng 2019 618 629 z feng 2020 z geem 2001 60 68 z ji 2014 589 598 b jia 2015 11 25 b jiang 2018 309 323 z jiang 2017 z li 2015 127 136 c li 2014 363 373 c li 2013 2073 2082 c li 2011 370 379 y li 2019 53 59 z li 2015 z liu 2014 102 113 p liu 2019 2189 s liu 2019 337 354 y liu 2019 19 40 y ma 2013 616 627 c madani 2010 225 238 k madani 2011 174 183 k ming 2017 1173 1190 b ming 2018 528 540 b mirjalili 2014 1569 1584 s mirjalili 2016 51 67 s mu 2015 159 174 j naderi 2017 1186 1206 e niu 2018 562 575 w niu 2018 04018002 w niu 2019 82 w niu 2020 w peng 2014 123 137 a rashedi 2009 2232 2248 e ren 2018 11 18 g shang 2016 808 817 y shareef 2015 315 333 h sheikholeslami 2016 544 563 r tian 2014 504 519 h varshney 2013 176 191 l wang 2019 294 310 s wang 2018 85 95 y xia 2019 105715 y xie 2018 10 16 x xu 2013 174 193 d yang 2017 302 316 t yang 2015 262 279 t yang 2010 x fireflyalgorithminengineeringoptimization yang 2018 441 456 y yao 2011 3 20 f windenergyresourcestheorydesignapplications yin 2013 114 120 x yuan 2014 535 546 x yuan 2014 249 260 x zeng 2018 1613 1628 x zhang 2019 c zhang 2019 722 734 j zhang 2015 22 34 y zhao 2014 365 374 t zhao 2014 1142 1157 t zheng 2011 f zheng 2013 380 399 f zheng 2016 04016017 f fengx2020x124425 fengx2020x124425xz 2021 12 26t00 00 00 000z 2021 12 26t00 00 00 000z http creativecommons org licenses by nc nd 4 0 2019 elsevier b v all rights reserved 2019 12 06t01 26 41 152z http vtw elsevier com data voc addontypes 50 7 eoas natural science foundation of hubei province http data elsevier com vocabulary scivalfunders 501100003819 http sws geonames org 1814991 nsfc national natural science foundation of china http data elsevier com vocabulary scivalfunders 501100001809 http sws geonames org 1814991 item s0022 1694 19 31160 6 s0022169419311606 1 s2 0 s0022169419311606 10 1016 j jhydrol 2019 124425 271842 2020 11 27t15 23 34 542759z 2020 02 01 2020 02 29 1 s2 0 s0022169419311606 main pdf https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 main application pdf 71858fbb6c238e829488f424e015c0fb main pdf main pdf pdf true 2471810 main 13 1 s2 0 s0022169419311606 main 1 png https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 preview image png 7c6445d9226dd24c57a7ca209157a3ba main 1 png main 1 png png 57922 849 656 image web pdf 1 1 s2 0 s0022169419311606 gr9 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr9 downsampled image jpeg 9cf0753208641930fde06e4d92c5cea1 gr9 jpg gr9 gr9 jpg jpg 86987 472 756 image downsampled 1 s2 0 s0022169419311606 gr10 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr10 downsampled image jpeg 247969b234a2238503a0288f074560e4 gr10 jpg gr10 gr10 jpg jpg 62520 347 778 image downsampled 1 s2 0 s0022169419311606 gr2 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr2 downsampled image jpeg 38490616f41d77e49fafd0012cf58ad5 gr2 jpg gr2 gr2 jpg jpg 99824 407 778 image downsampled 1 s2 0 s0022169419311606 gr1 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr1 downsampled image jpeg 1c106ee5b08a5a34f59715c426a8ea72 gr1 jpg gr1 gr1 jpg jpg 71018 337 645 image downsampled 1 s2 0 s0022169419311606 gr4 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr4 downsampled image jpeg 0289c48f6ad35eb0bf9396ccaacfea4d gr4 jpg gr4 gr4 jpg jpg 77022 595 369 image downsampled 1 s2 0 s0022169419311606 gr3 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr3 downsampled image jpeg 7aabc232549d4d13431692df3520fe3b gr3 jpg gr3 gr3 jpg jpg 93620 512 778 image downsampled 1 s2 0 s0022169419311606 gr6 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr6 downsampled image jpeg cb9b6d86196276e91d444a7ec5bf6e26 gr6 jpg gr6 gr6 jpg jpg 32190 186 712 image downsampled 1 s2 0 s0022169419311606 gr5 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr5 downsampled image jpeg 7128913f11a5321a3e788230314a32e6 gr5 jpg gr5 gr5 jpg jpg 51331 269 667 image downsampled 1 s2 0 s0022169419311606 gr8 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr8 downsampled image jpeg 669c84693e05837d2f4d38bd7449d9bf gr8 jpg gr8 gr8 jpg jpg 73756 278 774 image downsampled 1 s2 0 s0022169419311606 gr7 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr7 downsampled image jpeg c5d7756355f6c0f0c3b129778f8cb5a7 gr7 jpg gr7 gr7 jpg jpg 63981 479 778 image downsampled 1 s2 0 s0022169419311606 gr9 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr9 thumbnail image gif a4fa992853d2d2d2d499812126cbf33e gr9 sml gr9 gr9 sml sml 9889 137 219 image thumbnail 1 s2 0 s0022169419311606 gr10 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr10 thumbnail image gif bb932b71036af2dc0d00db15b7982690 gr10 sml gr10 gr10 sml sml 5057 98 219 image thumbnail 1 s2 0 s0022169419311606 gr2 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr2 thumbnail image gif f17884441cfe97a57028abb059893b3c gr2 sml gr2 gr2 sml sml 14221 115 219 image thumbnail 1 s2 0 s0022169419311606 gr1 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr1 thumbnail image gif a9b2f2cc5d1e07821dcadf08fc52d6c6 gr1 sml gr1 gr1 sml sml 9332 114 219 image thumbnail 1 s2 0 s0022169419311606 gr4 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr4 thumbnail image gif 918fa940ed87d27caad1e0980c19fe30 gr4 sml gr4 gr4 sml sml 6100 163 101 image thumbnail 1 s2 0 s0022169419311606 gr3 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr3 thumbnail image gif ca316251bf583bed1e146ec7b218e638 gr3 sml gr3 gr3 sml sml 8120 144 219 image thumbnail 1 s2 0 s0022169419311606 gr6 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr6 thumbnail image gif fd1e5183b68233b83e0a3e4e042a905c gr6 sml gr6 gr6 sml sml 4660 57 219 image thumbnail 1 s2 0 s0022169419311606 gr5 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr5 thumbnail image gif ef385803ef09eeb16085b75447b92343 gr5 sml gr5 gr5 sml sml 7429 88 219 image thumbnail 1 s2 0 s0022169419311606 gr8 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr8 thumbnail image gif 30688b611877cab5d79e94967cc5cc75 gr8 sml gr8 gr8 sml sml 7825 79 219 image thumbnail 1 s2 0 s0022169419311606 gr7 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr7 thumbnail image gif 9aeac64f340b303efc5d311760cb61c3 gr7 sml gr7 gr7 sml sml 6404 135 219 image thumbnail 1 s2 0 s0022169419311606 gr9 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr9 highres image jpeg fcfd7a49057e26fb2f3ffe9ec6de467c gr9 lrg jpg gr9 gr9 lrg jpg jpg 615762 2090 3346 image high res 1 s2 0 s0022169419311606 gr10 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr10 highres image jpeg d6ddc274c6580f9b7bd430a2093c89de gr10 lrg jpg gr10 gr10 lrg jpg jpg 459482 1537 3446 image high res 1 s2 0 s0022169419311606 gr2 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr2 highres image jpeg addaa1880ee61bc73890cda418774fbe gr2 lrg jpg gr2 gr2 lrg jpg jpg 797118 1804 3445 image high res 1 s2 0 s0022169419311606 gr1 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr1 highres image jpeg cdbace1f2671d449350aa93761ddd1ff gr1 lrg jpg gr1 gr1 lrg jpg jpg 522170 1490 2854 image high res 1 s2 0 s0022169419311606 gr4 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr4 highres image jpeg a2b7e558b0699afb59fbcadb6fefdb2a gr4 lrg jpg gr4 gr4 lrg jpg jpg 597193 2639 1636 image high res 1 s2 0 s0022169419311606 gr3 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr3 highres image jpeg 5568aa5b9b794d949c1d4dbcb5c1c0f3 gr3 lrg jpg gr3 gr3 lrg jpg jpg 658810 2267 3445 image high res 1 s2 0 s0022169419311606 gr6 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr6 highres image jpeg 45be09d23426cd0e84227852ffa54129 gr6 lrg jpg gr6 gr6 lrg jpg jpg 228449 823 3151 image high res 1 s2 0 s0022169419311606 gr5 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr5 highres image jpeg 575043b8e58865ed75c0b845b3f58718 gr5 lrg jpg gr5 gr5 lrg jpg jpg 344248 1192 2955 image high res 1 s2 0 s0022169419311606 gr8 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr8 highres image jpeg 19e3bdf048a39eebbe5dfc20a0b280ad gr8 lrg jpg gr8 gr8 lrg jpg jpg 567662 1229 3425 image high res 1 s2 0 s0022169419311606 gr7 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr7 highres image jpeg 25c9063fe05f3afe08603b24ff75664f gr7 lrg jpg gr7 gr7 lrg jpg jpg 446839 2123 3446 image high res 1 s2 0 s0022169419311606 am pdf am am pdf pdf 5455943 aam pdf https s3 eu west 1 amazonaws com prod ucs content store eu west content egi 10xl2nxh5qm main application pdf 1aeb7ce7e349c29eefd2911aa88fe600 am pdf hydrol 124425 124425 s0022 1694 19 31160 6 10 1016 j jhydrol 2019 124425 elsevier b v fig 1 sketch map of the framework of the mgsa method fig 2 2 d shape of some selected benchmark functions fig 3 box plot of three methods for 24 benchmark functions fig 4 the flowchart of mgsa for cascade hydropower reservoir ecological operation fig 5 location of the 5 reservoir hydropower system fig 6 minimum and suitable required ecological flows of five hydropower reservoirs fig 7 box plots of different methods in different cases fig 8 scheduling results of two methods with suitable ecological flow requirement in a dry year fig 9 water shortages of five reservoirs obtained by the mgsa method in different cases fig 10 box plot obtained by three algorithms in 8 scenarios table 1 details of the unimodal benchmark functions with changeable variables function dim range f min f 1 x i 1 n x i 2 30 100 100 0 f 2 x i 1 n x i i 1 n x i 30 10 10 0 f 3 x i 1 n j 1 i x j 2 30 100 100 0 f 4 x max x i 1 i n 30 100 100 0 f 5 x i 1 n 1 100 x i 1 x i 2 2 x i 1 2 30 30 30 0 f 6 x i 1 n x i 0 5 2 30 100 100 0 f 7 x i 1 n i x i 4 r a n d o m 0 1 30 1 28 1 28 0 f 8 x i 1 n x i i 1 30 1 1 0 table 2 details of the multimodal benchmark functions with changeable variables function dim range f min f 9 x i 1 n x i sin x i 30 500 500 418 9 dim f 10 x i 1 n x i 2 10 cos 2 π x i 10 30 5 12 5 12 0 f 11 x 20 exp 0 2 i 1 n x i 2 1 n exp 1 n i 1 n cos 2 π x i 20 e 30 32 32 0 f 12 x 1 4000 i 1 n x i 2 i 1 n cos x i i 1 30 600 600 0 f 13 x π n 10 sin 2 π y 1 i 1 n 1 y i 1 2 1 10 sin 2 π y i 1 y n 1 2 i 1 n u x i 10 100 4 y i 1 x i 1 4 u x i a k m k x i a m x i a 0 a x i a k x i a m x i a 30 50 50 0 f 14 x 0 1 sin 2 3 π x 1 i 1 n x i 1 2 1 sin 2 3 π x i 1 1 x n 1 2 1 sin 2 2 π x n i 1 n u x i 5 100 4 30 50 50 0 table 3 details of the multimodal benchmark functions with fixed variables function dim range f min f 15 x 1 500 j 1 25 1 j i 1 2 x i a ij 6 1 2 65 536 65 536 1 f 16 x i 1 11 a i x 1 b i 2 b i x 2 b i 2 b i x 3 x 4 2 4 5 5 0 0003075 f 17 x 4 x 1 2 2 1 x 1 4 1 3 x 1 6 x 1 x 2 4 x 2 2 4 x 2 4 2 5 5 1 0316285 f 18 x x 2 5 1 4 π 2 x 1 2 5 π x 1 6 2 10 1 1 8 π cos x 1 10 2 5 10 0 15 0 398 f 19 x 1 x 1 x 2 1 2 19 14 x 1 3 x 1 2 14 x 2 6 x 1 x 2 3 x 1 2 30 2 x 1 3 x 2 2 18 32 x 1 12 x 1 2 48 x 2 36 x 1 x 2 27 x 2 2 2 2 2 3 f 20 x i 1 4 c i exp j 1 3 a ij x j p ij 2 3 0 1 3 86 f 21 x i 1 4 c i exp j 1 6 a ij x j p ij 2 6 0 1 3 32 f 22 x i 1 5 x a i x a i t c i 1 4 0 10 10 1532 f 23 x i 1 7 x a i x a i t c i 1 4 0 10 10 4028 f 24 x i 1 10 x a i x a i t c i 1 4 0 10 10 5363 table 4 results comparison of different methods for unimodal benchmark functions with 30 variables function item woa lsa fa hsa igsa ggsa pso de gsa sca mgsa f 1 ave 1 41e 30 4 81e 08 0 01196 24 71118 2 29e 15 7 05e 15 7 17e 09 0 00213 2 13e 12 1 08e 35 0 std 4 91e 30 3 40e 07 0 00430 6 67110 4 60e 16 1 56e 15 7 07e 09 0 00101 6 82e 13 4 98e 35 0 f 2 ave 1 06e 21 0 03681 0 37332 1 45749 2e 07 2 97e 07 2 98e 05 0 02136 4 33e 06 9 24e 28 1 35e 300 std 2 39e 21 0 15623 0 10143 0 2681 1 65e 08 2 38e 08 2 42e 05 0 00676 9 68e 07 2e 27 0 f 3 ave 5 39e 07 43 2408 1808 80 6878 65 365 22118 549 66138 151 13784 953 39192 351 8897 40 17709 0 2581 std 2 93e 06 29 92194 659 65 1943 08 171 78621 189 55875 28 41543 498 5259 132 01197 129 36059 0 64767 f 4 ave 0 07258 1 49327 0 07669 9 38543 0 07266 4 08e 08 0 06336 1 67661 1 04e 06 2 0253 4 75e 241 std 0 39747 1 30282 0 01461 1 22651 0 29567 7 13e 09 0 01695 0 50488 2 83e 07 4 38521 0 f 5 ave 27 87 64 2816 128 289 830 0325 41 13 86 52 110 18 30 05 49 36 27 82 27 14 std 0 7636 43 7557 278 634 474 1998 45 8328 156 9572 53 7473 2 7592 55 1424 1 2945 0 8833 f 6 ave 3 11627 3 34 0 25 1 2 37e 15 6 97e 15 2 21e 08 5 82e 09 2 33e 12 0 0562 1 37e 16 std 0 53242 2 086 0 7 53292 4 33e 16 1 58e 15 3 89e 08 3 11e 09 7 52e 13 0 04532 1 92e 16 f 7 ave 0 00143 0 02407 0 03522 0 46324 0 44262 0 57291 0 58575 0 09377 0 01691 0 00726 8 46e 05 std 0 00114 0 00572 0 02398 0 11272 0 32658 0 30808 1 78168 0 01943 0 00592 0 00567 0 00011 f 8 ave n a n a n a n a 3 26e 12 6 14e 08 5 18e 15 4 04e 08 3 32e 08 8 03e 20 0 std n a n a n a n a 5 22e 12 8 45e 08 1 09e 14 1 17e 07 8 59e 08 3 31e 19 0 note ave average and std standard deviation the same below table 5 results comparison of different methods for multimodal benchmark functions with 30 variables function item woa lsa fa hsa igsa ggsa pso de gsa sca mgsa f 9 ave 5080 76 8001 39 5900 33 7395 27 6960 32 2694 05 3777 22 6603 9 2640 1 5580 56 8827 86 std 695 7968 669 1593 655 5192 350 4224 789 8971 383 9121 793 5304 661 3071 367 8920 426 7432 750 2256 f 10 ave 0 62 7619 26 2570 87 0362 30 1803 16 9474 42 8519 110 1980 15 2892 1 43e 07 0 std 0 14 9153 9 1492 10 7857 9 7986 4 4456 12 7207 10 1279 4 0771 7 86e 07 0 f 11 ave 7 4043 2 68619 0 05117 8 81991 3 49e 08 5 78e 08 8 49e 05 0 0017 9 65e 07 8 7159 4 44e 16 std 9 8975 0 9108 0 0137 0 61249 3 72e 09 5 53e 09 5 13e 05 0 0034 2 19e 07 10 1374 0 f 12 ave 0 0003 0 00724 0 00584 1 24411 0 0431 0 0025 5 6202 0 0006 0 6547 1 15e 14 0 std 0 0015 0 0067 0 00143 0 0641 0 0454 0 0074 2 0978 0 0011 0 6412 5 99e 14 0 f 13 ave 0 3396 0 35817 0 00024 0 17966 0 0207 0 1677 0 1313 0 0293 0 0907 0 0079 1 03e 18 std 0 2148 0 7439 0 0001 0 0974 0 0421 0 2249 0 1884 0 0232 0 1358 0 0038 1 85e 18 f 14 ave 1 889 0 02415 0 00224 1 83258 0 0007 0 0643 0 0007 0 0572 0 0011 0 4644 3 31e 17 std 0 266 0 0473 0 0011 0 54988 0 0027 0 2020 0 0027 0 0405 0 0033 0 2231 7 28e 17 table 6 results comparison of different methods for multimodal benchmark functions with fixed dimension function item woa lsa fa hsa igsa ggsa pso de gsa sca mgsa f 15 ave 2 11197 1 07745 1 87559 1 60593 0 998 1 64344 1 92157 1 42613 2 21605 1 48905 1 13028 std 2 49859 0 3379 0 6688 1 3716 5 83e 17 0 84191 1 48691 1 2607 0 90379 1 81018 0 50338 f 16 ave 0 00057 0 00053 0 00106 0 00096 0 00088 0 00420 0 00616 0 00089 0 00237 0 00067 0 00032 std 0 00032 0 00042 0 00036 0 00018 0 00036 0 00227 0 00872 0 00039 0 00164 0 00021 4 22e 05 f 17 ave 1 03163 1 03163 1 03163 0 99651 1 03163 0 91676 1 03162 1 03163 1 03162 1 03163 1 03163 std 4 2e 07 0 2 83e 09 0 06811 5 98e 16 0 458062 6 77e 16 1 06e 05 6 71e 15 2 45e 08 6 71e 16 f 18 ave 0 39791 0 39789 0 39789 0 40777 0 39789 0 39789 0 39789 0 39827 0 39789 0 39789 0 39789 std 0 00003 1 68e 16 3 13e 09 0 02163 9 34e 07 0 0 0 00207 3 17e 15 2 01e 06 0 f 19 ave 3 3 3 00001 3 00001 3 3 00001 3 3 21742 3 00001 3 00001 3 std 4 22e 15 3 35e 15 2 56e 08 5 38e 05 9 26e 15 0 02504 1 54e 15 0 84770 1 22e 12 6 96e 07 1 56e 15 f 20 ave 3 85616 3 86278 3 86278 3 86021 3 86278 3 38721 3 86226 3 86261 3 86249 3 86187 3 86278 std 0 0027 0 9 16e 10 0 00325 1 56e 15 0 28127 0 00199 0 00081 0 00044 0 00223 2 71e 15 f 21 ave 2 98105 3 27206 3 26767 3 12164 3 24273 1 72123 3 2137 3 10885 3 12626 3 20121 3 2467 std 0 37666 0 05927 0 06198 0 13347 0 05701 0 48689 0 08432 0 09844 0 06759 0 06877 0 05827 f 22 ave 7 04918 7 02732 8 42709 2 78267 8 89006 3 38492 5 22318 7 97536 6 5085 8 73321 9 79148 std 3 62955 3 15615 3 12029 1 81360 2 22290 2 08366 2 96835 3 20526 3 66461 2 25732 1 38006 f 23 ave 8 1818 7 1367 10 2785 3 0458 10 4029 4 5079 4 4771 7 786 9 5804 9 84 10 4029 std 3 8292 3 51497 0 88004 1 64549 1 09e 15 2 41441 1 41352 3 31857 1 95511 1 61153 9 89e 16 f 24 ave 9 3424 7 9104 10 5364 4 2043 10 5364 8 6673 9 7853 9 5248 10 2785 10 4989 10 5364 std 2 4147 3 596 1 11e 06 3 0085 5 53e 15 3 2414 1 8611 2 4859 0 9819 0 0554 1 89e 15 table 7 statistical results of several methods in different cases ecological flow runoff item 108m3 pso de gsa igsa ggsa mgsa minimum 75 best 0 00 0 00 0 00 0 00 0 00 0 00 average 0 44 1 59 0 00 0 00 0 00 0 00 std 1 33 1 64 0 00 0 00 0 00 0 00 90 best 21 07 36 01 13 77 10 43 11 23 5 53 average 32 72 61 05 17 63 20 00 14 74 8 71 std 17 25 36 45 2 62 5 37 2 26 1 48 95 best 48 51 57 09 40 16 33 96 37 54 31 15 average 60 67 428 91 46 75 48 22 42 12 34 30 std 9 47 404 62 4 96 8 09 2 41 1 63 suitable 75 best 248 97 253 32 256 20 249 02 249 81 248 50 average 256 44 269 67 261 23 256 44 254 74 249 35 std 8 00 10 75 3 24 4 53 2 72 0 93 90 best 380 22 387 86 380 64 379 46 379 14 379 12 average 387 36 426 32 385 63 383 62 381 50 379 73 std 6 47 52 84 2 22 3 76 1 62 0 67 95 best 426 39 436 66 424 15 423 72 424 00 423 49 average 438 71 680 08 428 57 430 52 425 49 424 30 std 24 90 347 77 1 85 6 38 1 25 0 92 table 8 statistical results obtained by three methods in 8 scenarios item method best average variation coefficient range scenario 1 pso 0 00 0 32 3 156 4 15 gsa 0 00 0 01 4 000 0 20 mgsa 0 00 0 00 0 000 0 00 scenario 2 pso 0 00 0 44 2 182 3 44 gsa 0 00 0 55 1 364 2 54 mgsa 0 00 0 00 0 000 0 00 scenario 3 pso 0 00 3 46 1 069 14 72 gsa 1 32 4 87 0 454 11 10 mgsa 0 00 0 24 1 625 1 48 scenario 4 pso 3 97 10 53 0 405 18 19 gsa 7 11 13 47 0 222 16 30 mgsa 2 15 5 32 0 312 7 46 scenario 5 pso 13 48 22 73 0 255 22 13 gsa 23 44 28 01 0 086 9 44 mgsa 13 45 17 84 0 130 8 95 scenario 6 pso 47 83 59 49 0 133 30 71 gsa 59 12 72 28 0 493 149 74 mgsa 46 07 49 24 0 043 9 99 scenario 7 pso 51 24 58 11 0 088 16 57 gsa 66 71 75 54 0 050 17 25 mgsa 50 92 55 51 0 039 8 75 scenario 8 pso 223 52 229 07 0 016 18 62 gsa 188 72 191 98 0 011 7 94 mgsa 178 89 181 26 0 006 4 27 research papers ecological operation of cascade hydropower reservoirs by elite guide gravitational search algorithm with lévy flight local search and mutation zhong kai feng data curation formal analysis funding acquisition methodology visualization writing original draft writing review editing a shuai liu data curation formal analysis visualization methodology validation a wen jing niu data curation formal analysis funding acquisition methodology visualization writing original draft writing review editing b shu shan li data curation formal analysis visualization methodology validation c hui jun wu data curation formal analysis visualization methodology validation c jia yang wang data curation formal analysis visualization methodology validation d a school of hydropower and information engineering huazhong university of science and technology wuhan 430074 china school of hydropower and information engineering huazhong university of science and technology wuhan 430074 china school of hydropower and information engineering huazhong university of science and technology wuhan 430074 china b bureau of hydrology changjiang water resources commission wuhan 430010 china bureau of hydrology changjiang water resources commission wuhan 430010 china bureau of hydrology changjiang water resources commission wuhan 430010 china c power dispatching control center china southern power grid guangzhou 510663 china power dispatching control center china southern power grid guangzhou 510663 china power dispatching control center china southern power grid guangzhou 510663 china d power research institute china southern power grid guangzhou 510080 china power research institute china southern power grid guangzhou 510080 china power research institute china southern power grid guangzhou 510080 china corresponding author this manuscript was handled by corrado corradini editor in chief with the assistance of weiping chen associate editor gravitational search algorithm gsa is an evolutionary algorithm developed to solve the global optimization problems but still suffers from the premature convergence problem due to the loss of swarm diversity in order to improve the gsa performance this paper develops a novel multi strategy gravitational search algorithm mgsa where the lévy flight strategy is adopted to increase the local search ability of the global best known agent and then the mutation strategy is used to improve the swarm diversity in the evolutionary process finally the elitism selection strategy is used to enhance the exploration ability and convergence speed of the swarm the mgsa method is compared with several methods in 24 famous benchmark functions and the results demonstrate the superiority of the mgsa method in both search ability and convergence rate next the mgsa method is used to solve the ecological operation problem of the wu hydropower system the results indicate that compared with several existing methods mgsa can obtain better scheduling schemes to make obvious reductions in the inappropriate ecological water volume in different scenarios thus this paper provides a new effective tool for the complex engineering optimization problems keywords cascade hydropower reservoirs ecological operation gravitational search algorithm lévy flight local search strategy mutation operation elitism selection strategy 1 introduction recently a series of large scale water conservancy projects and hydropower reservoirs are built throughout the world feng et al 2020a ma et al 2013 varshney et al 2013 yao et al 2011 zheng et al 2013 in practice unreasonable scheduling schemes of cascade hydropower reservoirs may harm the health and stability of the river ecological system chang et al 2018 li et al 2011 liu et al 2014 yin and yang 2013 for the sake of guaranteeing the sustainable development the ecological operation of cascade hydropower reservoirs is gaining more and more attention from operators and managers in recent years chang et al 2011 li et al 2015a yang et al 2018 zeng et al 2018 from a mathematical point the ecological operation of cascade hydropower reservoirs is classified as a complicated nonlinear multistage optimization problem catalão et al 2007 catalão et al 2012 madani 2010 madani 2011 while a variety of equality and inequality physical constraints should be well met fang et al 2018 feng et al 2018a during the past decades many famous optimization tools are successfully proposed to address this kind of problem mu et al 2015 peng et al 2014 zhang et al 2019a like linear programming feng et al 2019a feng et al 2019b quadratic programming catalao et al 2009 catalão et al 2010 dynamic programming feng et al 2018b jiang et al 2018 jiang et al 2017 zhao et al 2014 decomposition coordination method jia et al 2015 li et al 2014 shang et al 2016 and network based programming cao et al 2019 li et al 2019 ren et al 2018 wang et al 2019 xie et al 2018 even though a great deal of success has been achieved in different fields the widespread applications of the traditional methods in the large and complex reservoir operation problems are still limited by some defects feng et al 2020b zhang et al 2019 zhao and zhao 2014 like dimensionality problem feng et al 2017a yang et al 2015 zhang et al 2015 and huge computational burden wang et al 2018 with the rapid development of computer technique a large number of evolutionary algorithms based on the biologic evolution phenomenon are proposed to alleviate the defects in conventional methods niu et al 2018a yang et al 2017 zheng et al 2016 and the typical representatives are genetic algorithm ga yuan et al 2014a particle swarm optimization pso feng et al 2019c and differential evolution de chen et al 2015 in general evolutionary algorithms have the merits of easy implementation clear principle and strong applicability but still suffer from the serious premature convergence problem feng et al 2017b ming et al 2017 xu et al 2013 thus it is of great necessity to develop effective approaches to improve the overall operational benefit of cascade hydropower reservoirs inspired by the classical newton s law of gravity and motion a new heuristic optimizer called as gravitational search algorithm gsa is developed to handle the global optimization problems adnan et al 2017 rashedi et al 2009 yuan et al 2014b in gsa each solution is regarded as an object with a certain mass in the universe and any one agent will be attracted by other agents at the same time via the gravity force by the unique information interaction strategy the individual experience can be effectively shared with other agents in the population and the quality of the best known solution found by the swarm can be gradually improved the gsa method is successfully applied to many engineering fields like hydrological forecasting niu et al 2019 parameter identification li et al 2013 hydrothermal scheduling li et al 2015b and unit commitment ji et al 2014 however there are few literatures about using gsa to solve the ecological operation of cascade hydropower reservoirs when this paper tries to refill this research gap it is unfortunately found that the standard gsa method suffers from the premature convergence and exploitation failure to improve the gsa performance this paper tries to develop a multi strategy gravitational search algorithm mgsa based on lévy flight local search mutation operation and elitism selection strategies the experiment results in a real world hydropower system of china demonstrate the superior performance of the developed method to sum up the main research objectives of this paper are composed of two aspects ① gsa is used to deal with the ecological operation of cascade hydropower system which may be the first open report in the water resources field by far ② a novel mgsa method aiming at improving the gsa defects is applied to the wu hydropower system in china which can produce satisfying results in both numerical tests and engineering problem thus the proposed modified strategies can provide certain technical reference for addressing similar problems in other parts of the world 2 multi strategy gravitational search algorithm mgsa 2 1 gravitational search algorithm gsa the gravitational search algorithm gsa is a novel intelligence method inspired by the famous newton s gravity and motion law in gsa a potential solution for the target optimization problem is treated as an agent with a certain quality of mass and then a set of agents form the swarm to iteratively search for the optimal solutions in the decision space niu et al 2020 tian et al 2014 the agent s movement is affected by the total gravity forces produced by the other agents and then the agents with smaller masses can gradually move to the heavier agents representing better solutions for the sake of simplicity it is assumed that the number of individuals in the swarm is set as n and the goal is set to find out the minimal objective value of the d variable optimization problem then the position vector of the ith agent at the kth iteration can be expressed as below 1 x i k x i 1 k x i 2 k x i d k x i d k where x i d k is the dth position value of the ith agent at the kth iterations based on the position vectors the fitness values of all the agents in the swarm can be obtained based on the actual features of the problem and then the mass of the ith agent at the kth iteration m i k for short can be expressed as below 2 m i k m i k i 1 n m i k 3 m i k fi t i k max i 1 2 n fi t i k min i 1 2 n fi t i k max i 1 2 n fi t i k where fi t i k and m i k are the original and normalized fitness values of the ith agent at kth iteration then the force f ij d k for short between the ith and jth agents in the dth position at the kth iteration can be expressed as follows 4 f ij d k g k m i k m j k r ij k ε x i d k x j d k 5 g k g 0 exp α k k where ε is a small constant to prevent the computational problem where the denominator is equal to zero g k is the gravitational constant at the kth iteration which is used to control the agent s search range g 0 is the initial gravitational constant k is the maximal iterations a is the attenuation factor r ij k is the euclidean distance of the ith agent and the jth agent to improve the random characteristics of the gsa approach the random weighting strategy is often adopted to estimate the forces performed on the ith agent based on the newton s second law the acceleration a i d k for short of the ith agent in the dth dimension is expressed as follows 6 a i d k j k b e s t j i ran d j f ij d k m i k where ran d j is a random number uniformly distributed in the range of 0 1 kbest is the set of agents with better fitness values by this time the velocity value and position value of the ith individual in the current swarm can be updated as follows 7 v i d k 1 r a n d i v i d k a i d k 8 x i d k 1 x i d k v i d k 1 where ran d i is a random number uniformly distributed in the range of 0 1 v i d k is the dth velocity value of the ith agent at the kth iteration 2 2 lévy flight strategy to improve the local search ability of the global best known agent generally the best known agent of the swarm often has the largest probability to find the global optimal solution for the target problem obviously it stands a good chance to find better solutions by searching in the neighborhood of the global best known agent in nature to increase the swarm viability the lévy flight is often used in the foraging behavior of many creatures to balance the short distance search range and the long distance search probability ming et al 2018 sheikholeslami et al 2016 inspired by this case the lévy flight strategy is used to improve the local search capability of the gsa method for each agent a temporary agent using the velocity information and lévy flight is produced around the global best known agent and then the newly obtained solution will replace its parent solution when the performance is improved mathematically the lévy flight strategy can be expressed as below 9 te m i d k g b e s t d k v i d k l e v y β where gbes t d k is the dth position value of the global best known agent of the swarm at the kth iteration te m i d k is the dth position value of the ith temporary agent at the kth iteration levy β is random search step size obeying the lévy distribution which can be approximately obtained by the following equation 10 levy β δ u v 1 β 11 δ γ 1 β sin π β 2 β γ β 1 2 2 β 1 2 1 β where β is the positive constant u and v are two random numbers obeying the normal distribution γ is the gamma function 2 3 mutation operation strategy to improve the diversity of the swarm similar to other evolutionary algorithms the standard gsa approach usually suffers from the serious premature convergence problem since the population diversity gradually decreases as the number of iterations proceeds feng et al 2017b xia et al 2019 thus the mutation operation strategy is introduced to improve the convergence rate of the swarm specifically after obtaining the difference between the operated agent and the global best known agent the random resize idea is adopted to generate the mutated solutions and then the greedy selection preferring heavier agents is used to help jump out of local optima then the mutation operation can be expressed as below 12 u i d k x ind d k r 5 gbes t d k x i d k where u i d k is the dth position value of the ith mutant agent at the kth iteration x ind d k is the dth position value of the agent randomly chosen from the current swarm and there is ind i r 5 is the random number uniformly distributed in the range of 0 1 2 4 elitism selection strategy to promote the exploration capability of the swarm generally when the excellent agents found in the evolutionary process are well preserved the quality of the swarm can be gradually improved from generation to generation liu et al 2019a liu et al 2019b zheng et al 2011 thus the elitism selection strategy is employed to promote the exploration ability of the swarm where the one to one competition between parent agents and its offspring is executed to choose the elite solution for the next cycle then the elitism selection strategy can be expressed as below 13 x i k b i k if f x i k worse than f b i k x i k otherwise where b i k is the ith offspring agent at the kth iteration 2 5 execution steps of the mgsa method from the framework of the gsa method in fig 1 it can be clearly found that several improved strategies are embedded into gsa to effectively resolve the complicated numerical optimization problems including the lévy flight strategy mutation operator and elitism selection strategy specially the lévy flight strategy can provide multiple different evolutionary directions for each agent and enhance the local search ability of the swarm and then the mutation operator can effectively improve the diversity of the population while the elitism selection strategy is used to guarantee the survival of the fittest in this way the mgsa performance can sharply improve by the dynamic integration of the modified strategies besides in the iterative process some agents may violate the boundary limits of decision variables and by this time the infeasible agents will be initialized in the feasible space then the overall execution steps of mgsa for the optimization problems are given as below step 1 set all the necessary computational parameters and then randomly initialize the position and velocity values of all the agents in the search space step 2 calculate the fitness values of all the agents in the current swarm and then update the global best known position of the swarm step 3 update the gravitational constant at the current cycle and then update the velocity and position values of each agent after obtaining its mass and acceleration step 4 use the lévy flight strategy to improve the local search ability of the global best known agent in the current swarm step 5 use the mutation operation strategy to improve the diversity of the population step 6 use the elitism selection strategy to choose better solutions for the next cycle step 7 repeat step 2 to step 6 until the stop criteria is met and the global best agent found by the swarm will be treated as the best solution for the target optimization problem 3 numerical experiments to verify the performance of the mgsa method 3 1 benchmark functions in this section 24 classic benchmark functions are used to testify the performance of the mgsa method the test functions can be divided into three different kinds of groups unimodal functions f 1 f 8 or multimodal functions f 9 f 14 with changeable variables multimodal functions f 15 f 24 with fixed variables the unimodal functions are used to reflect the convergence performance of the method and the multimodal functions are employed to verify the ability of escaping from local optima tables 1 3 lists the detailed information of three kinds of test functions where dim range and f min denote the number of variables search range per variable and optimal objective value respectively fig 2 shows the 2 d shape of some benchmark functions it can be seen that the selected benchmark functions have different features like nonlinearity and modality which can fully test the performance of the developed method in different cases 3 2 parameter setting several famous methods are used to resolve 24 benchmark functions including the whale optimization algorithm woa mirjalili and lewis 2016 lightning search algorithm lsa shareef et al 2015 firefly algorithm fa yang 2010 harmony search algorithm hsa geem et al 2001 particle swarm optimization pso niu et al 2018b differential evolution de naderi et al 2017 sine cosine algorithm sca liu et al 2019c gravitational search algorithm gsa niu et al 2019 improved gsa igsa chen et al 2014 and gbest guided gsa ggsa mirjalili and lewis 2014 for the sake of fairness the number of maximal iterations and agents for all the developed methods are set as 50 and 1000 while the other parameters are set as follows pso the inertia weight w is linearly decreased from the initial value 0 9 to the final value 0 4 while the values of two learning factors c 1 and c 2 are set as 2 0 respectively de the crossover probability cr is set as 0 6 and the scaling factor f is set as 0 5 sca the computational constant a is set as 2 0 gsa the attenuation factor a 20 and the initial gravitational constant g 0 100 igsa a 20 g 0 100 and the learning factors c 1 c 2 0 6 ggsa a 20 g 0 100 and the learning factors c 1 2 1 k 3 k 3 c 2 2 k 3 k 3 mgsa a 20 g 0 100 and β 1 5 3 3 result comparison tables 4 6 show the results of 24 test functions obtained by 11 methods in 30 independent runs including the average ave and standard deviation std it can be found that for f 1 f 14 mgsa almost always achieves the best performances among all the methods for f 16 f 20 and f 22 f 24 mgsa and other methods can converge to the optimal solution or approximate optimal solution for other functions the results of mgsa are similar to other methods thus it can be concluded that mgsa is able to produce satisfying solutions for the numerical optimization problems then to clearly reflect the distribution features of the obtained solutions the box diagram of 24 test functions of three methods igsa ggsa and mgsa in 30 independent runs is shown in fig 3 for the box diagram the results are not easily affected by the outliers and thereby the typical data features can be fully showed including the maximum minimum median upper and lower quartile of the attribute data from fig 3 it can be seen that in most benchmark functions mgsa has fewer outliers and smaller solution distribution than ggsa and igsa demonstrating the robustness and practicability of the mgsa method 4 mathematical model 4 1 mathematical model 4 1 1 objective function as the concept of sustainable development deepens continuously in recent years the ecological protection is playing an increasingly important role in the modern water resource field hence the objective function is set to minimize the total inappropriate ecological water volume of cascade hydropower reservoirs which can be expressed as below 14 ew min i 1 num t 1 t y i t δ t 15 y i t o i t o i t eco if o i t o i t eco o i t eco o i t if o i t o i t eco 0 otherwise where ew is the total inappropriate ecological water volume of all the hydropower reservoirs in m3 num and t are the number of reservoirs and periods o i t eco and o i t eco are the maximum and minimum required ecological flow of the ith reservoir at the tth period in m3 s respectively o i t and y i t are the total water discharge and inappropriate ecological flow of the ith reservoir at the tth period in m3 s respectively 4 1 2 physical constraints 1 water balance equations 16 v i t 1 v i t i i t j 1 n u i o j t o i t δ t o i t s i t q i t where v i t i i t q i t and s i t are the storage volume in m3 local inflow in m3 s turbine discharge in m3 s and water spillage in m3 s of the ith reservoir at the tth period respectively n u i denotes the number of upstream reservoirs of the ith reservoir 2 water head equation limits 17 h i t 0 5 z i t z i t 1 d i t where z i t h i t and d i t are the forebay water level water head and downstream water level of the ith reservoir at the tth period in m respectively 3 initial and final forebay water level limits 18 z i 0 z i begin z i t z i end where z i begin and z i end are the initial and final forebay water levels of the ith reservoir in m 4 forebay water level limits 19 z i t down z i t z i t up where z i t down and z i t up are the minimum and maximum forebay water levels of the ith reservoir at the tth period in m respectively 5 turbine discharge limits 20 q i t up q i t q i t down where q i t down and q i t up are the minimum and maximum turbine discharges of the ith reservoir at the tth period in m3 s respectively 6 total discharge limits 21 o i t down o i t o i t up where o i t down and o i t up are the minimum and maximum total discharges of the ith reservoir at the tth period in m3 s respectively 7 power output limits 22 p i t down p i t p i t up where p i t down and p i t up are the minimum and maximum power outputs of the ith reservoir at the tth period in kw respectively 8 nonlinear characteristic curves limits 23 v i t f i 1 z i t d i t f i 2 o i t p i t f i 3 h i t q i t where f i 1 is the stage storage curve of the ith reservoir f i 2 is the stage discharge curve of the ith reservoir f i 3 is the nonlinear generation curve of the ith reservoir 4 2 details of mgsa for the ecological operation problem of cascade hydropower reservoirs 4 2 1 individual structure and swarm initialization to effectively address the equality and inequality constraints the water level per hydropower reservoir is treated as the decision variables then each agent in the mgsa approach is composed of t water levels of all the hydropower reservoirs which can be described as below 24 x z 1 1 z 1 2 z 1 t z 2 1 z 2 2 z 2 t z i t z num 1 z num 2 z num t during the initialization phase the elements of any one solution will be randomly generated in the feasible range between the maximum and minimum water levels which can be expressed as 25 z i t z i t down r a n d z i t up z i t down where rand is a random number uniformly distributed in the range of 0 1 4 2 2 constraint handling method in the search process of the mgsa approach some newly generated individual in the current generation may violate the physical constraints imposed on the hydropower system like water level total discharge and power output limits to effectively identify the agent s feasibility the infeasible agent will be firstly forced to the nearest boundary value and then the total violation value will be merged into the objective values to form the final fitness values as described in eq 26 obviously the violation values will be zero and positive constant for feasible and infeasible agents respectively in this way when two agents with the same objective values the infeasible agent is always dominated by the feasible one due to its larger fitness value which can effectively increase the possibility of finding feasible solutions 26 f x i k i 1 num t 1 t y i t δ t i 1 num t 1 t j 1 c i t ρ i t j z i t j z i t j max z z i t j z i t j up 0 z i t j down z z i t j where f x i k is the fitness value of the agent x i k c i t is the number of constraints for the ith reservoir at the tth period ρ i t j and z i t j are the penalty coefficient and violation value of the jth constraint of the ith reservoir at the tth period respectively z i t j up and z i t j down are the maximum and minimum of the jth constraint of the ith reservoir at the tth period respectively 4 2 3 flowchart of mgsa for cascade hydropower reservoir ecological operation problem the flowchart of mgsa for solving the ecological operation problem of cascade hydropower reservoirs is given in fig 4 5 case studies 5 1 engineering background in this section 5 hydropower reservoirs located on wu river are chosen to test the feasibility of the mgsa method in addressing reservoir ecological operation problem fig 5 show the location of the wu hydropower system respectively with a total length of about 1 037 km and a drainage area of about 89 700 km2 the wu river is the largest tributary in the southern bank of the upper reaches of yangtze river to avoid the negative effect of climate change and human activities operators are paying growing attention to the ecological protection of rivers in recent years hence it is of great importance to find appropriate tools for the ecological operation of wu hydropower system generally the ecosystem may be destroyed if the minimum ecological flow is not satisfied for a long time while it is almost impossible to realize the healthy development of the ecosystem if the total discharge is always smaller than the suitable ecological flow fig 6 shows the minimum and suitable required ecological flows of five reservoirs it can be found that the overall trends of two required ecological flows gradually increase at the early stage and then decrease at the latter stage in the following cases the scheduling horizon 1 year is spilt into 12 identical periods month and three kinds of typical local runoffs are chosen as the input of the studied hydropower system including a little dry year 75 dry year 90 and extremely dry year 95 5 2 case study 1 5 2 1 statistical results analysis to verify the sensitivity of the model the statistical results of six methods with different runoffs in the minimum and suitable ecological flows cases are given in table 7 it can be seen that the mgsa method is obviously better than the other methods in terms of almost all the indicators for the minimum ecological flow requirement the mgsa method makes about 35 79 45 44 22 44 8 27 and 17 02 reductions in the best objective value in comparison with pso de gsa igsa and ggsa in the 95 runoff case respectively for the suitable ecological flow requirement the average objective values of the mgsa method are reduced by about 7 09 20 32 11 88 7 09 and 5 39 108m3 compared with pso de gsa igsa and ggsa in the 75 runoff case respectively hence the developed model is able to produce satisfying performances in the ecological operation of hydropower system 5 2 2 box plot analysis fig 7 shows results distributions of three methods in different cases it can be seen that in the minimum ecological flow and 75 runoff case there is no obvious difference in the solutions of three methods since the best scheduling scheme without ecological shortage can always be found regardless of the initial random seeds in other cases the solutions of the mgsa method are more concentrated than igsa and ggsa thus the above analysis clearly demonstrates that the mgsa method has satisfying robustness in the complex reservoir operation problem 5 2 3 scheduling process to verify the consequence rationality fig 8 shows the best scheduling schemes obtained by mgsa with the suitable ecological flow requirement it can be seen that for each reservoir the inappropriate water discharge grows with the increase of the required ecological flow over the scheduling horizon for the hydropower system the probability of ecological deficiency gradually grows from upstream to downstream reservoirs meanwhile it is worth noting that the maximum ecological water deficits of 5 reservoirs often occur in the periods from june to august which means that managers should give full consideration to the water supply during this period hence this case demonstrates the rationality of the scheduling scheme obtained by the mgsa method in the ecological operation of cascade reservoirs problem fig 9 shows the water shortages of different reservoirs obtained by the mgsa method in both minimum and suitable ecological runoff cases it can be found that in the wu hydropower system the ecological shortages are mainly concentrated in two downstream reservoirs wjd and gpt in the scheduling horizon the ecological deficiency often occurs in the periods between june and december while the water shortage of the hydropower reservoir is positively correlated with the ecological requirement in the scheduling period therefore it is great importance for operators to manage the scheduling process of downstream reservoirs in the latter half of the year 5 3 case study 2 in this section 8 scenarios with different runoffs and ecological flow requirements are used to further testify the robustness of the mgsa method table 8 and fig 10 give the statistical results and the box plot obtained by three methods in different cases respectively it can be found that the range of the solutions obtained by the mgsa method is obviously smaller than pso and gsa while mgsa outperforms two other methods in almost all the evaluation indexes taking the gsa range as an example mgsa can make about 100 100 86 7 54 2 5 2 93 3 49 3 and 46 2 reductions in 8 cases respectively thus this case fully proves the strong robustness of the mgsa method in the complex hydropower operation problem 6 conclusions in this research a novel multi strategy gravitational search algorithm mgsa is proposed to alleviate the premature convergence shortcoming of the standard gsa algorithm in ecological operation of cascade hydropower reservoirss in mgsa the lévy flight with self adaptive adjustment strategy is used to improve the local exploration of the swarm the mutation strategy is executed on the global optima to expand the diversity of evolution population while the elitism selection strategy is introduced to decrease the probability of falling into local optimal solution the superior performance of the mgsa method is fully demonstrated by the simulations of 24 famous benchmark functions then mgsa is applied to the ecological operation of cascade hydropower reservoirs in china s wu river and the simulations indicate that mgsa outperforms several existing methods in maintaining the water demands of the ecological environment to sum up the paper can provide technical measures to improve the global search ability of the famous gsa method in global optimization problems in the future the feasibility of the mgsa method in other complicated real world engineering problems can be deepened credit authorship contribution statement zhong kai feng data curation formal analysis funding acquisition methodology visualization writing original draft writing review editing shuai liu data curation formal analysis visualization methodology validation wen jing niu data curation formal analysis funding acquisition methodology visualization writing original draft writing review editing shu shan li data curation formal analysis visualization methodology validation hui jun wu data curation formal analysis visualization methodology validation jia yang wang data curation formal analysis visualization methodology validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this paper is supported by the national natural science foundation of china 51709119 natural science foundation of hubei province 2018cfb573 and the fundamental research funds for the central universities hust 2017kfyxjj193 the writers would like to thank the reviewers and editors for their valuable comments and suggestions 
5907,gravitational search algorithm gsa 2 2 lévy flight strategy to improve the local search ability of the global best known agent 2 3 mutation operation strategy to improve the diversity of the swarm 2 4 elitism selection strategy to promote the exploration capability of the swarm 2 5 execution steps of the mgsa method 3 numerical experiments to verify the performance of the mgsa method 3 1 benchmark functions 3 2 parameter setting 3 3 result comparison 4 mathematical model 4 1 mathematical model 4 1 1 objective function 4 1 2 physical constraints 4 2 details of mgsa for the ecological operation problem of cascade hydropower reservoirs 4 2 1 individual structure and swarm initialization 4 2 2 constraint handling method 4 2 3 flowchart of mgsa for cascade hydropower reservoir ecological operation problem 5 case studies 5 1 engineering background 5 2 case study 1 5 2 1 statistical results analysis 5 2 2 box plot analysis 5 2 3 scheduling process 5 3 case study 2 6 conclusions credit authorship contribution statement acknowledgments adnan 2017 r cao 2019 159 167 y catalao 2009 337 346 j catalao 2007 1297 1304 j catalao 2012 237 244 j catalao 2010 935 942 j chang 2011 70 80 j chang 2018 886 897 j chen 2015 258 268 x chen 2014 306 315 z fang 2018 3835 3852 g feng 2020 z feng 2017 718 730 z feng 2019 229 238 z feng 2017 165 178 z feng 2018 706 718 z feng 2018 432 442 z feng 2019 2179 z feng 2019 618 629 z feng 2020 z geem 2001 60 68 z ji 2014 589 598 b jia 2015 11 25 b jiang 2018 309 323 z jiang 2017 z li 2015 127 136 c li 2014 363 373 c li 2013 2073 2082 c li 2011 370 379 y li 2019 53 59 z li 2015 z liu 2014 102 113 p liu 2019 2189 s liu 2019 337 354 y liu 2019 19 40 y ma 2013 616 627 c madani 2010 225 238 k madani 2011 174 183 k ming 2017 1173 1190 b ming 2018 528 540 b mirjalili 2014 1569 1584 s mirjalili 2016 51 67 s mu 2015 159 174 j naderi 2017 1186 1206 e niu 2018 562 575 w niu 2018 04018002 w niu 2019 82 w niu 2020 w peng 2014 123 137 a rashedi 2009 2232 2248 e ren 2018 11 18 g shang 2016 808 817 y shareef 2015 315 333 h sheikholeslami 2016 544 563 r tian 2014 504 519 h varshney 2013 176 191 l wang 2019 294 310 s wang 2018 85 95 y xia 2019 105715 y xie 2018 10 16 x xu 2013 174 193 d yang 2017 302 316 t yang 2015 262 279 t yang 2010 x fireflyalgorithminengineeringoptimization yang 2018 441 456 y yao 2011 3 20 f windenergyresourcestheorydesignapplications yin 2013 114 120 x yuan 2014 535 546 x yuan 2014 249 260 x zeng 2018 1613 1628 x zhang 2019 c zhang 2019 722 734 j zhang 2015 22 34 y zhao 2014 365 374 t zhao 2014 1142 1157 t zheng 2011 f zheng 2013 380 399 f zheng 2016 04016017 f fengx2020x124425 fengx2020x124425xz 2021 12 26t00 00 00 000z 2021 12 26t00 00 00 000z http creativecommons org licenses by nc nd 4 0 2019 elsevier b v all rights reserved 2019 12 06t01 26 41 152z http vtw elsevier com data voc addontypes 50 7 eoas natural science foundation of hubei province http data elsevier com vocabulary scivalfunders 501100003819 http sws geonames org 1814991 nsfc national natural science foundation of china http data elsevier com vocabulary scivalfunders 501100001809 http sws geonames org 1814991 item s0022 1694 19 31160 6 s0022169419311606 1 s2 0 s0022169419311606 10 1016 j jhydrol 2019 124425 271842 2020 11 27t15 23 34 542759z 2020 02 01 2020 02 29 1 s2 0 s0022169419311606 main pdf https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 main application pdf 71858fbb6c238e829488f424e015c0fb main pdf main pdf pdf true 2471810 main 13 1 s2 0 s0022169419311606 main 1 png https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 preview image png 7c6445d9226dd24c57a7ca209157a3ba main 1 png main 1 png png 57922 849 656 image web pdf 1 1 s2 0 s0022169419311606 gr9 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr9 downsampled image jpeg 9cf0753208641930fde06e4d92c5cea1 gr9 jpg gr9 gr9 jpg jpg 86987 472 756 image downsampled 1 s2 0 s0022169419311606 gr10 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr10 downsampled image jpeg 247969b234a2238503a0288f074560e4 gr10 jpg gr10 gr10 jpg jpg 62520 347 778 image downsampled 1 s2 0 s0022169419311606 gr2 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr2 downsampled image jpeg 38490616f41d77e49fafd0012cf58ad5 gr2 jpg gr2 gr2 jpg jpg 99824 407 778 image downsampled 1 s2 0 s0022169419311606 gr1 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr1 downsampled image jpeg 1c106ee5b08a5a34f59715c426a8ea72 gr1 jpg gr1 gr1 jpg jpg 71018 337 645 image downsampled 1 s2 0 s0022169419311606 gr4 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr4 downsampled image jpeg 0289c48f6ad35eb0bf9396ccaacfea4d gr4 jpg gr4 gr4 jpg jpg 77022 595 369 image downsampled 1 s2 0 s0022169419311606 gr3 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr3 downsampled image jpeg 7aabc232549d4d13431692df3520fe3b gr3 jpg gr3 gr3 jpg jpg 93620 512 778 image downsampled 1 s2 0 s0022169419311606 gr6 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr6 downsampled image jpeg cb9b6d86196276e91d444a7ec5bf6e26 gr6 jpg gr6 gr6 jpg jpg 32190 186 712 image downsampled 1 s2 0 s0022169419311606 gr5 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr5 downsampled image jpeg 7128913f11a5321a3e788230314a32e6 gr5 jpg gr5 gr5 jpg jpg 51331 269 667 image downsampled 1 s2 0 s0022169419311606 gr8 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr8 downsampled image jpeg 669c84693e05837d2f4d38bd7449d9bf gr8 jpg gr8 gr8 jpg jpg 73756 278 774 image downsampled 1 s2 0 s0022169419311606 gr7 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr7 downsampled image jpeg c5d7756355f6c0f0c3b129778f8cb5a7 gr7 jpg gr7 gr7 jpg jpg 63981 479 778 image downsampled 1 s2 0 s0022169419311606 gr9 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr9 thumbnail image gif a4fa992853d2d2d2d499812126cbf33e gr9 sml gr9 gr9 sml sml 9889 137 219 image thumbnail 1 s2 0 s0022169419311606 gr10 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr10 thumbnail image gif bb932b71036af2dc0d00db15b7982690 gr10 sml gr10 gr10 sml sml 5057 98 219 image thumbnail 1 s2 0 s0022169419311606 gr2 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr2 thumbnail image gif f17884441cfe97a57028abb059893b3c gr2 sml gr2 gr2 sml sml 14221 115 219 image thumbnail 1 s2 0 s0022169419311606 gr1 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr1 thumbnail image gif a9b2f2cc5d1e07821dcadf08fc52d6c6 gr1 sml gr1 gr1 sml sml 9332 114 219 image thumbnail 1 s2 0 s0022169419311606 gr4 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr4 thumbnail image gif 918fa940ed87d27caad1e0980c19fe30 gr4 sml gr4 gr4 sml sml 6100 163 101 image thumbnail 1 s2 0 s0022169419311606 gr3 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr3 thumbnail image gif ca316251bf583bed1e146ec7b218e638 gr3 sml gr3 gr3 sml sml 8120 144 219 image thumbnail 1 s2 0 s0022169419311606 gr6 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr6 thumbnail image gif fd1e5183b68233b83e0a3e4e042a905c gr6 sml gr6 gr6 sml sml 4660 57 219 image thumbnail 1 s2 0 s0022169419311606 gr5 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr5 thumbnail image gif ef385803ef09eeb16085b75447b92343 gr5 sml gr5 gr5 sml sml 7429 88 219 image thumbnail 1 s2 0 s0022169419311606 gr8 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr8 thumbnail image gif 30688b611877cab5d79e94967cc5cc75 gr8 sml gr8 gr8 sml sml 7825 79 219 image thumbnail 1 s2 0 s0022169419311606 gr7 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr7 thumbnail image gif 9aeac64f340b303efc5d311760cb61c3 gr7 sml gr7 gr7 sml sml 6404 135 219 image thumbnail 1 s2 0 s0022169419311606 gr9 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr9 highres image jpeg fcfd7a49057e26fb2f3ffe9ec6de467c gr9 lrg jpg gr9 gr9 lrg jpg jpg 615762 2090 3346 image high res 1 s2 0 s0022169419311606 gr10 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr10 highres image jpeg d6ddc274c6580f9b7bd430a2093c89de gr10 lrg jpg gr10 gr10 lrg jpg jpg 459482 1537 3446 image high res 1 s2 0 s0022169419311606 gr2 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr2 highres image jpeg addaa1880ee61bc73890cda418774fbe gr2 lrg jpg gr2 gr2 lrg jpg jpg 797118 1804 3445 image high res 1 s2 0 s0022169419311606 gr1 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr1 highres image jpeg cdbace1f2671d449350aa93761ddd1ff gr1 lrg jpg gr1 gr1 lrg jpg jpg 522170 1490 2854 image high res 1 s2 0 s0022169419311606 gr4 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr4 highres image jpeg a2b7e558b0699afb59fbcadb6fefdb2a gr4 lrg jpg gr4 gr4 lrg jpg jpg 597193 2639 1636 image high res 1 s2 0 s0022169419311606 gr3 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr3 highres image jpeg 5568aa5b9b794d949c1d4dbcb5c1c0f3 gr3 lrg jpg gr3 gr3 lrg jpg jpg 658810 2267 3445 image high res 1 s2 0 s0022169419311606 gr6 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr6 highres image jpeg 45be09d23426cd0e84227852ffa54129 gr6 lrg jpg gr6 gr6 lrg jpg jpg 228449 823 3151 image high res 1 s2 0 s0022169419311606 gr5 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr5 highres image jpeg 575043b8e58865ed75c0b845b3f58718 gr5 lrg jpg gr5 gr5 lrg jpg jpg 344248 1192 2955 image high res 1 s2 0 s0022169419311606 gr8 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr8 highres image jpeg 19e3bdf048a39eebbe5dfc20a0b280ad gr8 lrg jpg gr8 gr8 lrg jpg jpg 567662 1229 3425 image high res 1 s2 0 s0022169419311606 gr7 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s0022169419311606 gr7 highres image jpeg 25c9063fe05f3afe08603b24ff75664f gr7 lrg jpg gr7 gr7 lrg jpg jpg 446839 2123 3446 image high res 1 s2 0 s0022169419311606 am pdf am am pdf pdf 5455943 aam pdf https s3 eu west 1 amazonaws com prod ucs content store eu west content egi 10xl2nxh5qm main application pdf 1aeb7ce7e349c29eefd2911aa88fe600 am pdf hydrol 124425 124425 s0022 1694 19 31160 6 10 1016 j jhydrol 2019 124425 elsevier b v fig 1 sketch map of the framework of the mgsa method fig 2 2 d shape of some selected benchmark functions fig 3 box plot of three methods for 24 benchmark functions fig 4 the flowchart of mgsa for cascade hydropower reservoir ecological operation fig 5 location of the 5 reservoir hydropower system fig 6 minimum and suitable required ecological flows of five hydropower reservoirs fig 7 box plots of different methods in different cases fig 8 scheduling results of two methods with suitable ecological flow requirement in a dry year fig 9 water shortages of five reservoirs obtained by the mgsa method in different cases fig 10 box plot obtained by three algorithms in 8 scenarios table 1 details of the unimodal benchmark functions with changeable variables function dim range f min f 1 x i 1 n x i 2 30 100 100 0 f 2 x i 1 n x i i 1 n x i 30 10 10 0 f 3 x i 1 n j 1 i x j 2 30 100 100 0 f 4 x max x i 1 i n 30 100 100 0 f 5 x i 1 n 1 100 x i 1 x i 2 2 x i 1 2 30 30 30 0 f 6 x i 1 n x i 0 5 2 30 100 100 0 f 7 x i 1 n i x i 4 r a n d o m 0 1 30 1 28 1 28 0 f 8 x i 1 n x i i 1 30 1 1 0 table 2 details of the multimodal benchmark functions with changeable variables function dim range f min f 9 x i 1 n x i sin x i 30 500 500 418 9 dim f 10 x i 1 n x i 2 10 cos 2 π x i 10 30 5 12 5 12 0 f 11 x 20 exp 0 2 i 1 n x i 2 1 n exp 1 n i 1 n cos 2 π x i 20 e 30 32 32 0 f 12 x 1 4000 i 1 n x i 2 i 1 n cos x i i 1 30 600 600 0 f 13 x π n 10 sin 2 π y 1 i 1 n 1 y i 1 2 1 10 sin 2 π y i 1 y n 1 2 i 1 n u x i 10 100 4 y i 1 x i 1 4 u x i a k m k x i a m x i a 0 a x i a k x i a m x i a 30 50 50 0 f 14 x 0 1 sin 2 3 π x 1 i 1 n x i 1 2 1 sin 2 3 π x i 1 1 x n 1 2 1 sin 2 2 π x n i 1 n u x i 5 100 4 30 50 50 0 table 3 details of the multimodal benchmark functions with fixed variables function dim range f min f 15 x 1 500 j 1 25 1 j i 1 2 x i a ij 6 1 2 65 536 65 536 1 f 16 x i 1 11 a i x 1 b i 2 b i x 2 b i 2 b i x 3 x 4 2 4 5 5 0 0003075 f 17 x 4 x 1 2 2 1 x 1 4 1 3 x 1 6 x 1 x 2 4 x 2 2 4 x 2 4 2 5 5 1 0316285 f 18 x x 2 5 1 4 π 2 x 1 2 5 π x 1 6 2 10 1 1 8 π cos x 1 10 2 5 10 0 15 0 398 f 19 x 1 x 1 x 2 1 2 19 14 x 1 3 x 1 2 14 x 2 6 x 1 x 2 3 x 1 2 30 2 x 1 3 x 2 2 18 32 x 1 12 x 1 2 48 x 2 36 x 1 x 2 27 x 2 2 2 2 2 3 f 20 x i 1 4 c i exp j 1 3 a ij x j p ij 2 3 0 1 3 86 f 21 x i 1 4 c i exp j 1 6 a ij x j p ij 2 6 0 1 3 32 f 22 x i 1 5 x a i x a i t c i 1 4 0 10 10 1532 f 23 x i 1 7 x a i x a i t c i 1 4 0 10 10 4028 f 24 x i 1 10 x a i x a i t c i 1 4 0 10 10 5363 table 4 results comparison of different methods for unimodal benchmark functions with 30 variables function item woa lsa fa hsa igsa ggsa pso de gsa sca mgsa f 1 ave 1 41e 30 4 81e 08 0 01196 24 71118 2 29e 15 7 05e 15 7 17e 09 0 00213 2 13e 12 1 08e 35 0 std 4 91e 30 3 40e 07 0 00430 6 67110 4 60e 16 1 56e 15 7 07e 09 0 00101 6 82e 13 4 98e 35 0 f 2 ave 1 06e 21 0 03681 0 37332 1 45749 2e 07 2 97e 07 2 98e 05 0 02136 4 33e 06 9 24e 28 1 35e 300 std 2 39e 21 0 15623 0 10143 0 2681 1 65e 08 2 38e 08 2 42e 05 0 00676 9 68e 07 2e 27 0 f 3 ave 5 39e 07 43 2408 1808 80 6878 65 365 22118 549 66138 151 13784 953 39192 351 8897 40 17709 0 2581 std 2 93e 06 29 92194 659 65 1943 08 171 78621 189 55875 28 41543 498 5259 132 01197 129 36059 0 64767 f 4 ave 0 07258 1 49327 0 07669 9 38543 0 07266 4 08e 08 0 06336 1 67661 1 04e 06 2 0253 4 75e 241 std 0 39747 1 30282 0 01461 1 22651 0 29567 7 13e 09 0 01695 0 50488 2 83e 07 4 38521 0 f 5 ave 27 87 64 2816 128 289 830 0325 41 13 86 52 110 18 30 05 49 36 27 82 27 14 std 0 7636 43 7557 278 634 474 1998 45 8328 156 9572 53 7473 2 7592 55 1424 1 2945 0 8833 f 6 ave 3 11627 3 34 0 25 1 2 37e 15 6 97e 15 2 21e 08 5 82e 09 2 33e 12 0 0562 1 37e 16 std 0 53242 2 086 0 7 53292 4 33e 16 1 58e 15 3 89e 08 3 11e 09 7 52e 13 0 04532 1 92e 16 f 7 ave 0 00143 0 02407 0 03522 0 46324 0 44262 0 57291 0 58575 0 09377 0 01691 0 00726 8 46e 05 std 0 00114 0 00572 0 02398 0 11272 0 32658 0 30808 1 78168 0 01943 0 00592 0 00567 0 00011 f 8 ave n a n a n a n a 3 26e 12 6 14e 08 5 18e 15 4 04e 08 3 32e 08 8 03e 20 0 std n a n a n a n a 5 22e 12 8 45e 08 1 09e 14 1 17e 07 8 59e 08 3 31e 19 0 note ave average and std standard deviation the same below table 5 results comparison of different methods for multimodal benchmark functions with 30 variables function item woa lsa fa hsa igsa ggsa pso de gsa sca mgsa f 9 ave 5080 76 8001 39 5900 33 7395 27 6960 32 2694 05 3777 22 6603 9 2640 1 5580 56 8827 86 std 695 7968 669 1593 655 5192 350 4224 789 8971 383 9121 793 5304 661 3071 367 8920 426 7432 750 2256 f 10 ave 0 62 7619 26 2570 87 0362 30 1803 16 9474 42 8519 110 1980 15 2892 1 43e 07 0 std 0 14 9153 9 1492 10 7857 9 7986 4 4456 12 7207 10 1279 4 0771 7 86e 07 0 f 11 ave 7 4043 2 68619 0 05117 8 81991 3 49e 08 5 78e 08 8 49e 05 0 0017 9 65e 07 8 7159 4 44e 16 std 9 8975 0 9108 0 0137 0 61249 3 72e 09 5 53e 09 5 13e 05 0 0034 2 19e 07 10 1374 0 f 12 ave 0 0003 0 00724 0 00584 1 24411 0 0431 0 0025 5 6202 0 0006 0 6547 1 15e 14 0 std 0 0015 0 0067 0 00143 0 0641 0 0454 0 0074 2 0978 0 0011 0 6412 5 99e 14 0 f 13 ave 0 3396 0 35817 0 00024 0 17966 0 0207 0 1677 0 1313 0 0293 0 0907 0 0079 1 03e 18 std 0 2148 0 7439 0 0001 0 0974 0 0421 0 2249 0 1884 0 0232 0 1358 0 0038 1 85e 18 f 14 ave 1 889 0 02415 0 00224 1 83258 0 0007 0 0643 0 0007 0 0572 0 0011 0 4644 3 31e 17 std 0 266 0 0473 0 0011 0 54988 0 0027 0 2020 0 0027 0 0405 0 0033 0 2231 7 28e 17 table 6 results comparison of different methods for multimodal benchmark functions with fixed dimension function item woa lsa fa hsa igsa ggsa pso de gsa sca mgsa f 15 ave 2 11197 1 07745 1 87559 1 60593 0 998 1 64344 1 92157 1 42613 2 21605 1 48905 1 13028 std 2 49859 0 3379 0 6688 1 3716 5 83e 17 0 84191 1 48691 1 2607 0 90379 1 81018 0 50338 f 16 ave 0 00057 0 00053 0 00106 0 00096 0 00088 0 00420 0 00616 0 00089 0 00237 0 00067 0 00032 std 0 00032 0 00042 0 00036 0 00018 0 00036 0 00227 0 00872 0 00039 0 00164 0 00021 4 22e 05 f 17 ave 1 03163 1 03163 1 03163 0 99651 1 03163 0 91676 1 03162 1 03163 1 03162 1 03163 1 03163 std 4 2e 07 0 2 83e 09 0 06811 5 98e 16 0 458062 6 77e 16 1 06e 05 6 71e 15 2 45e 08 6 71e 16 f 18 ave 0 39791 0 39789 0 39789 0 40777 0 39789 0 39789 0 39789 0 39827 0 39789 0 39789 0 39789 std 0 00003 1 68e 16 3 13e 09 0 02163 9 34e 07 0 0 0 00207 3 17e 15 2 01e 06 0 f 19 ave 3 3 3 00001 3 00001 3 3 00001 3 3 21742 3 00001 3 00001 3 std 4 22e 15 3 35e 15 2 56e 08 5 38e 05 9 26e 15 0 02504 1 54e 15 0 84770 1 22e 12 6 96e 07 1 56e 15 f 20 ave 3 85616 3 86278 3 86278 3 86021 3 86278 3 38721 3 86226 3 86261 3 86249 3 86187 3 86278 std 0 0027 0 9 16e 10 0 00325 1 56e 15 0 28127 0 00199 0 00081 0 00044 0 00223 2 71e 15 f 21 ave 2 98105 3 27206 3 26767 3 12164 3 24273 1 72123 3 2137 3 10885 3 12626 3 20121 3 2467 std 0 37666 0 05927 0 06198 0 13347 0 05701 0 48689 0 08432 0 09844 0 06759 0 06877 0 05827 f 22 ave 7 04918 7 02732 8 42709 2 78267 8 89006 3 38492 5 22318 7 97536 6 5085 8 73321 9 79148 std 3 62955 3 15615 3 12029 1 81360 2 22290 2 08366 2 96835 3 20526 3 66461 2 25732 1 38006 f 23 ave 8 1818 7 1367 10 2785 3 0458 10 4029 4 5079 4 4771 7 786 9 5804 9 84 10 4029 std 3 8292 3 51497 0 88004 1 64549 1 09e 15 2 41441 1 41352 3 31857 1 95511 1 61153 9 89e 16 f 24 ave 9 3424 7 9104 10 5364 4 2043 10 5364 8 6673 9 7853 9 5248 10 2785 10 4989 10 5364 std 2 4147 3 596 1 11e 06 3 0085 5 53e 15 3 2414 1 8611 2 4859 0 9819 0 0554 1 89e 15 table 7 statistical results of several methods in different cases ecological flow runoff item 108m3 pso de gsa igsa ggsa mgsa minimum 75 best 0 00 0 00 0 00 0 00 0 00 0 00 average 0 44 1 59 0 00 0 00 0 00 0 00 std 1 33 1 64 0 00 0 00 0 00 0 00 90 best 21 07 36 01 13 77 10 43 11 23 5 53 average 32 72 61 05 17 63 20 00 14 74 8 71 std 17 25 36 45 2 62 5 37 2 26 1 48 95 best 48 51 57 09 40 16 33 96 37 54 31 15 average 60 67 428 91 46 75 48 22 42 12 34 30 std 9 47 404 62 4 96 8 09 2 41 1 63 suitable 75 best 248 97 253 32 256 20 249 02 249 81 248 50 average 256 44 269 67 261 23 256 44 254 74 249 35 std 8 00 10 75 3 24 4 53 2 72 0 93 90 best 380 22 387 86 380 64 379 46 379 14 379 12 average 387 36 426 32 385 63 383 62 381 50 379 73 std 6 47 52 84 2 22 3 76 1 62 0 67 95 best 426 39 436 66 424 15 423 72 424 00 423 49 average 438 71 680 08 428 57 430 52 425 49 424 30 std 24 90 347 77 1 85 6 38 1 25 0 92 table 8 statistical results obtained by three methods in 8 scenarios item method best average variation coefficient range scenario 1 pso 0 00 0 32 3 156 4 15 gsa 0 00 0 01 4 000 0 20 mgsa 0 00 0 00 0 000 0 00 scenario 2 pso 0 00 0 44 2 182 3 44 gsa 0 00 0 55 1 364 2 54 mgsa 0 00 0 00 0 000 0 00 scenario 3 pso 0 00 3 46 1 069 14 72 gsa 1 32 4 87 0 454 11 10 mgsa 0 00 0 24 1 625 1 48 scenario 4 pso 3 97 10 53 0 405 18 19 gsa 7 11 13 47 0 222 16 30 mgsa 2 15 5 32 0 312 7 46 scenario 5 pso 13 48 22 73 0 255 22 13 gsa 23 44 28 01 0 086 9 44 mgsa 13 45 17 84 0 130 8 95 scenario 6 pso 47 83 59 49 0 133 30 71 gsa 59 12 72 28 0 493 149 74 mgsa 46 07 49 24 0 043 9 99 scenario 7 pso 51 24 58 11 0 088 16 57 gsa 66 71 75 54 0 050 17 25 mgsa 50 92 55 51 0 039 8 75 scenario 8 pso 223 52 229 07 0 016 18 62 gsa 188 72 191 98 0 011 7 94 mgsa 178 89 181 26 0 006 4 27 research papers ecological operation of cascade hydropower reservoirs by elite guide gravitational search algorithm with lévy flight local search and mutation zhong kai feng data curation formal analysis funding acquisition methodology visualization writing original draft writing review editing a shuai liu data curation formal analysis visualization methodology validation a wen jing niu data curation formal analysis funding acquisition methodology visualization writing original draft writing review editing b shu shan li data curation formal analysis visualization methodology validation c hui jun wu data curation formal analysis visualization methodology validation c jia yang wang data curation formal analysis visualization methodology validation d a school of hydropower and information engineering huazhong university of science and technology wuhan 430074 china school of hydropower and information engineering huazhong university of science and technology wuhan 430074 china school of hydropower and information engineering huazhong university of science and technology wuhan 430074 china b bureau of hydrology changjiang water resources commission wuhan 430010 china bureau of hydrology changjiang water resources commission wuhan 430010 china bureau of hydrology changjiang water resources commission wuhan 430010 china c power dispatching control center china southern power grid guangzhou 510663 china power dispatching control center china southern power grid guangzhou 510663 china power dispatching control center china southern power grid guangzhou 510663 china d power research institute china southern power grid guangzhou 510080 china power research institute china southern power grid guangzhou 510080 china power research institute china southern power grid guangzhou 510080 china corresponding author this manuscript was handled by corrado corradini editor in chief with the assistance of weiping chen associate editor gravitational search algorithm gsa is an evolutionary algorithm developed to solve the global optimization problems but still suffers from the premature convergence problem due to the loss of swarm diversity in order to improve the gsa performance this paper develops a novel multi strategy gravitational search algorithm mgsa where the lévy flight strategy is adopted to increase the local search ability of the global best known agent and then the mutation strategy is used to improve the swarm diversity in the evolutionary process finally the elitism selection strategy is used to enhance the exploration ability and convergence speed of the swarm the mgsa method is compared with several methods in 24 famous benchmark functions and the results demonstrate the superiority of the mgsa method in both search ability and convergence rate next the mgsa method is used to solve the ecological operation problem of the wu hydropower system the results indicate that compared with several existing methods mgsa can obtain better scheduling schemes to make obvious reductions in the inappropriate ecological water volume in different scenarios thus this paper provides a new effective tool for the complex engineering optimization problems keywords cascade hydropower reservoirs ecological operation gravitational search algorithm lévy flight local search strategy mutation operation elitism selection strategy 1 introduction recently a series of large scale water conservancy projects and hydropower reservoirs are built throughout the world feng et al 2020a ma et al 2013 varshney et al 2013 yao et al 2011 zheng et al 2013 in practice unreasonable scheduling schemes of cascade hydropower reservoirs may harm the health and stability of the river ecological system chang et al 2018 li et al 2011 liu et al 2014 yin and yang 2013 for the sake of guaranteeing the sustainable development the ecological operation of cascade hydropower reservoirs is gaining more and more attention from operators and managers in recent years chang et al 2011 li et al 2015a yang et al 2018 zeng et al 2018 from a mathematical point the ecological operation of cascade hydropower reservoirs is classified as a complicated nonlinear multistage optimization problem catalão et al 2007 catalão et al 2012 madani 2010 madani 2011 while a variety of equality and inequality physical constraints should be well met fang et al 2018 feng et al 2018a during the past decades many famous optimization tools are successfully proposed to address this kind of problem mu et al 2015 peng et al 2014 zhang et al 2019a like linear programming feng et al 2019a feng et al 2019b quadratic programming catalao et al 2009 catalão et al 2010 dynamic programming feng et al 2018b jiang et al 2018 jiang et al 2017 zhao et al 2014 decomposition coordination method jia et al 2015 li et al 2014 shang et al 2016 and network based programming cao et al 2019 li et al 2019 ren et al 2018 wang et al 2019 xie et al 2018 even though a great deal of success has been achieved in different fields the widespread applications of the traditional methods in the large and complex reservoir operation problems are still limited by some defects feng et al 2020b zhang et al 2019 zhao and zhao 2014 like dimensionality problem feng et al 2017a yang et al 2015 zhang et al 2015 and huge computational burden wang et al 2018 with the rapid development of computer technique a large number of evolutionary algorithms based on the biologic evolution phenomenon are proposed to alleviate the defects in conventional methods niu et al 2018a yang et al 2017 zheng et al 2016 and the typical representatives are genetic algorithm ga yuan et al 2014a particle swarm optimization pso feng et al 2019c and differential evolution de chen et al 2015 in general evolutionary algorithms have the merits of easy implementation clear principle and strong applicability but still suffer from the serious premature convergence problem feng et al 2017b ming et al 2017 xu et al 2013 thus it is of great necessity to develop effective approaches to improve the overall operational benefit of cascade hydropower reservoirs inspired by the classical newton s law of gravity and motion a new heuristic optimizer called as gravitational search algorithm gsa is developed to handle the global optimization problems adnan et al 2017 rashedi et al 2009 yuan et al 2014b in gsa each solution is regarded as an object with a certain mass in the universe and any one agent will be attracted by other agents at the same time via the gravity force by the unique information interaction strategy the individual experience can be effectively shared with other agents in the population and the quality of the best known solution found by the swarm can be gradually improved the gsa method is successfully applied to many engineering fields like hydrological forecasting niu et al 2019 parameter identification li et al 2013 hydrothermal scheduling li et al 2015b and unit commitment ji et al 2014 however there are few literatures about using gsa to solve the ecological operation of cascade hydropower reservoirs when this paper tries to refill this research gap it is unfortunately found that the standard gsa method suffers from the premature convergence and exploitation failure to improve the gsa performance this paper tries to develop a multi strategy gravitational search algorithm mgsa based on lévy flight local search mutation operation and elitism selection strategies the experiment results in a real world hydropower system of china demonstrate the superior performance of the developed method to sum up the main research objectives of this paper are composed of two aspects ① gsa is used to deal with the ecological operation of cascade hydropower system which may be the first open report in the water resources field by far ② a novel mgsa method aiming at improving the gsa defects is applied to the wu hydropower system in china which can produce satisfying results in both numerical tests and engineering problem thus the proposed modified strategies can provide certain technical reference for addressing similar problems in other parts of the world 2 multi strategy gravitational search algorithm mgsa 2 1 gravitational search algorithm gsa the gravitational search algorithm gsa is a novel intelligence method inspired by the famous newton s gravity and motion law in gsa a potential solution for the target optimization problem is treated as an agent with a certain quality of mass and then a set of agents form the swarm to iteratively search for the optimal solutions in the decision space niu et al 2020 tian et al 2014 the agent s movement is affected by the total gravity forces produced by the other agents and then the agents with smaller masses can gradually move to the heavier agents representing better solutions for the sake of simplicity it is assumed that the number of individuals in the swarm is set as n and the goal is set to find out the minimal objective value of the d variable optimization problem then the position vector of the ith agent at the kth iteration can be expressed as below 1 x i k x i 1 k x i 2 k x i d k x i d k where x i d k is the dth position value of the ith agent at the kth iterations based on the position vectors the fitness values of all the agents in the swarm can be obtained based on the actual features of the problem and then the mass of the ith agent at the kth iteration m i k for short can be expressed as below 2 m i k m i k i 1 n m i k 3 m i k fi t i k max i 1 2 n fi t i k min i 1 2 n fi t i k max i 1 2 n fi t i k where fi t i k and m i k are the original and normalized fitness values of the ith agent at kth iteration then the force f ij d k for short between the ith and jth agents in the dth position at the kth iteration can be expressed as follows 4 f ij d k g k m i k m j k r ij k ε x i d k x j d k 5 g k g 0 exp α k k where ε is a small constant to prevent the computational problem where the denominator is equal to zero g k is the gravitational constant at the kth iteration which is used to control the agent s search range g 0 is the initial gravitational constant k is the maximal iterations a is the attenuation factor r ij k is the euclidean distance of the ith agent and the jth agent to improve the random characteristics of the gsa approach the random weighting strategy is often adopted to estimate the forces performed on the ith agent based on the newton s second law the acceleration a i d k for short of the ith agent in the dth dimension is expressed as follows 6 a i d k j k b e s t j i ran d j f ij d k m i k where ran d j is a random number uniformly distributed in the range of 0 1 kbest is the set of agents with better fitness values by this time the velocity value and position value of the ith individual in the current swarm can be updated as follows 7 v i d k 1 r a n d i v i d k a i d k 8 x i d k 1 x i d k v i d k 1 where ran d i is a random number uniformly distributed in the range of 0 1 v i d k is the dth velocity value of the ith agent at the kth iteration 2 2 lévy flight strategy to improve the local search ability of the global best known agent generally the best known agent of the swarm often has the largest probability to find the global optimal solution for the target problem obviously it stands a good chance to find better solutions by searching in the neighborhood of the global best known agent in nature to increase the swarm viability the lévy flight is often used in the foraging behavior of many creatures to balance the short distance search range and the long distance search probability ming et al 2018 sheikholeslami et al 2016 inspired by this case the lévy flight strategy is used to improve the local search capability of the gsa method for each agent a temporary agent using the velocity information and lévy flight is produced around the global best known agent and then the newly obtained solution will replace its parent solution when the performance is improved mathematically the lévy flight strategy can be expressed as below 9 te m i d k g b e s t d k v i d k l e v y β where gbes t d k is the dth position value of the global best known agent of the swarm at the kth iteration te m i d k is the dth position value of the ith temporary agent at the kth iteration levy β is random search step size obeying the lévy distribution which can be approximately obtained by the following equation 10 levy β δ u v 1 β 11 δ γ 1 β sin π β 2 β γ β 1 2 2 β 1 2 1 β where β is the positive constant u and v are two random numbers obeying the normal distribution γ is the gamma function 2 3 mutation operation strategy to improve the diversity of the swarm similar to other evolutionary algorithms the standard gsa approach usually suffers from the serious premature convergence problem since the population diversity gradually decreases as the number of iterations proceeds feng et al 2017b xia et al 2019 thus the mutation operation strategy is introduced to improve the convergence rate of the swarm specifically after obtaining the difference between the operated agent and the global best known agent the random resize idea is adopted to generate the mutated solutions and then the greedy selection preferring heavier agents is used to help jump out of local optima then the mutation operation can be expressed as below 12 u i d k x ind d k r 5 gbes t d k x i d k where u i d k is the dth position value of the ith mutant agent at the kth iteration x ind d k is the dth position value of the agent randomly chosen from the current swarm and there is ind i r 5 is the random number uniformly distributed in the range of 0 1 2 4 elitism selection strategy to promote the exploration capability of the swarm generally when the excellent agents found in the evolutionary process are well preserved the quality of the swarm can be gradually improved from generation to generation liu et al 2019a liu et al 2019b zheng et al 2011 thus the elitism selection strategy is employed to promote the exploration ability of the swarm where the one to one competition between parent agents and its offspring is executed to choose the elite solution for the next cycle then the elitism selection strategy can be expressed as below 13 x i k b i k if f x i k worse than f b i k x i k otherwise where b i k is the ith offspring agent at the kth iteration 2 5 execution steps of the mgsa method from the framework of the gsa method in fig 1 it can be clearly found that several improved strategies are embedded into gsa to effectively resolve the complicated numerical optimization problems including the lévy flight strategy mutation operator and elitism selection strategy specially the lévy flight strategy can provide multiple different evolutionary directions for each agent and enhance the local search ability of the swarm and then the mutation operator can effectively improve the diversity of the population while the elitism selection strategy is used to guarantee the survival of the fittest in this way the mgsa performance can sharply improve by the dynamic integration of the modified strategies besides in the iterative process some agents may violate the boundary limits of decision variables and by this time the infeasible agents will be initialized in the feasible space then the overall execution steps of mgsa for the optimization problems are given as below step 1 set all the necessary computational parameters and then randomly initialize the position and velocity values of all the agents in the search space step 2 calculate the fitness values of all the agents in the current swarm and then update the global best known position of the swarm step 3 update the gravitational constant at the current cycle and then update the velocity and position values of each agent after obtaining its mass and acceleration step 4 use the lévy flight strategy to improve the local search ability of the global best known agent in the current swarm step 5 use the mutation operation strategy to improve the diversity of the population step 6 use the elitism selection strategy to choose better solutions for the next cycle step 7 repeat step 2 to step 6 until the stop criteria is met and the global best agent found by the swarm will be treated as the best solution for the target optimization problem 3 numerical experiments to verify the performance of the mgsa method 3 1 benchmark functions in this section 24 classic benchmark functions are used to testify the performance of the mgsa method the test functions can be divided into three different kinds of groups unimodal functions f 1 f 8 or multimodal functions f 9 f 14 with changeable variables multimodal functions f 15 f 24 with fixed variables the unimodal functions are used to reflect the convergence performance of the method and the multimodal functions are employed to verify the ability of escaping from local optima tables 1 3 lists the detailed information of three kinds of test functions where dim range and f min denote the number of variables search range per variable and optimal objective value respectively fig 2 shows the 2 d shape of some benchmark functions it can be seen that the selected benchmark functions have different features like nonlinearity and modality which can fully test the performance of the developed method in different cases 3 2 parameter setting several famous methods are used to resolve 24 benchmark functions including the whale optimization algorithm woa mirjalili and lewis 2016 lightning search algorithm lsa shareef et al 2015 firefly algorithm fa yang 2010 harmony search algorithm hsa geem et al 2001 particle swarm optimization pso niu et al 2018b differential evolution de naderi et al 2017 sine cosine algorithm sca liu et al 2019c gravitational search algorithm gsa niu et al 2019 improved gsa igsa chen et al 2014 and gbest guided gsa ggsa mirjalili and lewis 2014 for the sake of fairness the number of maximal iterations and agents for all the developed methods are set as 50 and 1000 while the other parameters are set as follows pso the inertia weight w is linearly decreased from the initial value 0 9 to the final value 0 4 while the values of two learning factors c 1 and c 2 are set as 2 0 respectively de the crossover probability cr is set as 0 6 and the scaling factor f is set as 0 5 sca the computational constant a is set as 2 0 gsa the attenuation factor a 20 and the initial gravitational constant g 0 100 igsa a 20 g 0 100 and the learning factors c 1 c 2 0 6 ggsa a 20 g 0 100 and the learning factors c 1 2 1 k 3 k 3 c 2 2 k 3 k 3 mgsa a 20 g 0 100 and β 1 5 3 3 result comparison tables 4 6 show the results of 24 test functions obtained by 11 methods in 30 independent runs including the average ave and standard deviation std it can be found that for f 1 f 14 mgsa almost always achieves the best performances among all the methods for f 16 f 20 and f 22 f 24 mgsa and other methods can converge to the optimal solution or approximate optimal solution for other functions the results of mgsa are similar to other methods thus it can be concluded that mgsa is able to produce satisfying solutions for the numerical optimization problems then to clearly reflect the distribution features of the obtained solutions the box diagram of 24 test functions of three methods igsa ggsa and mgsa in 30 independent runs is shown in fig 3 for the box diagram the results are not easily affected by the outliers and thereby the typical data features can be fully showed including the maximum minimum median upper and lower quartile of the attribute data from fig 3 it can be seen that in most benchmark functions mgsa has fewer outliers and smaller solution distribution than ggsa and igsa demonstrating the robustness and practicability of the mgsa method 4 mathematical model 4 1 mathematical model 4 1 1 objective function as the concept of sustainable development deepens continuously in recent years the ecological protection is playing an increasingly important role in the modern water resource field hence the objective function is set to minimize the total inappropriate ecological water volume of cascade hydropower reservoirs which can be expressed as below 14 ew min i 1 num t 1 t y i t δ t 15 y i t o i t o i t eco if o i t o i t eco o i t eco o i t if o i t o i t eco 0 otherwise where ew is the total inappropriate ecological water volume of all the hydropower reservoirs in m3 num and t are the number of reservoirs and periods o i t eco and o i t eco are the maximum and minimum required ecological flow of the ith reservoir at the tth period in m3 s respectively o i t and y i t are the total water discharge and inappropriate ecological flow of the ith reservoir at the tth period in m3 s respectively 4 1 2 physical constraints 1 water balance equations 16 v i t 1 v i t i i t j 1 n u i o j t o i t δ t o i t s i t q i t where v i t i i t q i t and s i t are the storage volume in m3 local inflow in m3 s turbine discharge in m3 s and water spillage in m3 s of the ith reservoir at the tth period respectively n u i denotes the number of upstream reservoirs of the ith reservoir 2 water head equation limits 17 h i t 0 5 z i t z i t 1 d i t where z i t h i t and d i t are the forebay water level water head and downstream water level of the ith reservoir at the tth period in m respectively 3 initial and final forebay water level limits 18 z i 0 z i begin z i t z i end where z i begin and z i end are the initial and final forebay water levels of the ith reservoir in m 4 forebay water level limits 19 z i t down z i t z i t up where z i t down and z i t up are the minimum and maximum forebay water levels of the ith reservoir at the tth period in m respectively 5 turbine discharge limits 20 q i t up q i t q i t down where q i t down and q i t up are the minimum and maximum turbine discharges of the ith reservoir at the tth period in m3 s respectively 6 total discharge limits 21 o i t down o i t o i t up where o i t down and o i t up are the minimum and maximum total discharges of the ith reservoir at the tth period in m3 s respectively 7 power output limits 22 p i t down p i t p i t up where p i t down and p i t up are the minimum and maximum power outputs of the ith reservoir at the tth period in kw respectively 8 nonlinear characteristic curves limits 23 v i t f i 1 z i t d i t f i 2 o i t p i t f i 3 h i t q i t where f i 1 is the stage storage curve of the ith reservoir f i 2 is the stage discharge curve of the ith reservoir f i 3 is the nonlinear generation curve of the ith reservoir 4 2 details of mgsa for the ecological operation problem of cascade hydropower reservoirs 4 2 1 individual structure and swarm initialization to effectively address the equality and inequality constraints the water level per hydropower reservoir is treated as the decision variables then each agent in the mgsa approach is composed of t water levels of all the hydropower reservoirs which can be described as below 24 x z 1 1 z 1 2 z 1 t z 2 1 z 2 2 z 2 t z i t z num 1 z num 2 z num t during the initialization phase the elements of any one solution will be randomly generated in the feasible range between the maximum and minimum water levels which can be expressed as 25 z i t z i t down r a n d z i t up z i t down where rand is a random number uniformly distributed in the range of 0 1 4 2 2 constraint handling method in the search process of the mgsa approach some newly generated individual in the current generation may violate the physical constraints imposed on the hydropower system like water level total discharge and power output limits to effectively identify the agent s feasibility the infeasible agent will be firstly forced to the nearest boundary value and then the total violation value will be merged into the objective values to form the final fitness values as described in eq 26 obviously the violation values will be zero and positive constant for feasible and infeasible agents respectively in this way when two agents with the same objective values the infeasible agent is always dominated by the feasible one due to its larger fitness value which can effectively increase the possibility of finding feasible solutions 26 f x i k i 1 num t 1 t y i t δ t i 1 num t 1 t j 1 c i t ρ i t j z i t j z i t j max z z i t j z i t j up 0 z i t j down z z i t j where f x i k is the fitness value of the agent x i k c i t is the number of constraints for the ith reservoir at the tth period ρ i t j and z i t j are the penalty coefficient and violation value of the jth constraint of the ith reservoir at the tth period respectively z i t j up and z i t j down are the maximum and minimum of the jth constraint of the ith reservoir at the tth period respectively 4 2 3 flowchart of mgsa for cascade hydropower reservoir ecological operation problem the flowchart of mgsa for solving the ecological operation problem of cascade hydropower reservoirs is given in fig 4 5 case studies 5 1 engineering background in this section 5 hydropower reservoirs located on wu river are chosen to test the feasibility of the mgsa method in addressing reservoir ecological operation problem fig 5 show the location of the wu hydropower system respectively with a total length of about 1 037 km and a drainage area of about 89 700 km2 the wu river is the largest tributary in the southern bank of the upper reaches of yangtze river to avoid the negative effect of climate change and human activities operators are paying growing attention to the ecological protection of rivers in recent years hence it is of great importance to find appropriate tools for the ecological operation of wu hydropower system generally the ecosystem may be destroyed if the minimum ecological flow is not satisfied for a long time while it is almost impossible to realize the healthy development of the ecosystem if the total discharge is always smaller than the suitable ecological flow fig 6 shows the minimum and suitable required ecological flows of five reservoirs it can be found that the overall trends of two required ecological flows gradually increase at the early stage and then decrease at the latter stage in the following cases the scheduling horizon 1 year is spilt into 12 identical periods month and three kinds of typical local runoffs are chosen as the input of the studied hydropower system including a little dry year 75 dry year 90 and extremely dry year 95 5 2 case study 1 5 2 1 statistical results analysis to verify the sensitivity of the model the statistical results of six methods with different runoffs in the minimum and suitable ecological flows cases are given in table 7 it can be seen that the mgsa method is obviously better than the other methods in terms of almost all the indicators for the minimum ecological flow requirement the mgsa method makes about 35 79 45 44 22 44 8 27 and 17 02 reductions in the best objective value in comparison with pso de gsa igsa and ggsa in the 95 runoff case respectively for the suitable ecological flow requirement the average objective values of the mgsa method are reduced by about 7 09 20 32 11 88 7 09 and 5 39 108m3 compared with pso de gsa igsa and ggsa in the 75 runoff case respectively hence the developed model is able to produce satisfying performances in the ecological operation of hydropower system 5 2 2 box plot analysis fig 7 shows results distributions of three methods in different cases it can be seen that in the minimum ecological flow and 75 runoff case there is no obvious difference in the solutions of three methods since the best scheduling scheme without ecological shortage can always be found regardless of the initial random seeds in other cases the solutions of the mgsa method are more concentrated than igsa and ggsa thus the above analysis clearly demonstrates that the mgsa method has satisfying robustness in the complex reservoir operation problem 5 2 3 scheduling process to verify the consequence rationality fig 8 shows the best scheduling schemes obtained by mgsa with the suitable ecological flow requirement it can be seen that for each reservoir the inappropriate water discharge grows with the increase of the required ecological flow over the scheduling horizon for the hydropower system the probability of ecological deficiency gradually grows from upstream to downstream reservoirs meanwhile it is worth noting that the maximum ecological water deficits of 5 reservoirs often occur in the periods from june to august which means that managers should give full consideration to the water supply during this period hence this case demonstrates the rationality of the scheduling scheme obtained by the mgsa method in the ecological operation of cascade reservoirs problem fig 9 shows the water shortages of different reservoirs obtained by the mgsa method in both minimum and suitable ecological runoff cases it can be found that in the wu hydropower system the ecological shortages are mainly concentrated in two downstream reservoirs wjd and gpt in the scheduling horizon the ecological deficiency often occurs in the periods between june and december while the water shortage of the hydropower reservoir is positively correlated with the ecological requirement in the scheduling period therefore it is great importance for operators to manage the scheduling process of downstream reservoirs in the latter half of the year 5 3 case study 2 in this section 8 scenarios with different runoffs and ecological flow requirements are used to further testify the robustness of the mgsa method table 8 and fig 10 give the statistical results and the box plot obtained by three methods in different cases respectively it can be found that the range of the solutions obtained by the mgsa method is obviously smaller than pso and gsa while mgsa outperforms two other methods in almost all the evaluation indexes taking the gsa range as an example mgsa can make about 100 100 86 7 54 2 5 2 93 3 49 3 and 46 2 reductions in 8 cases respectively thus this case fully proves the strong robustness of the mgsa method in the complex hydropower operation problem 6 conclusions in this research a novel multi strategy gravitational search algorithm mgsa is proposed to alleviate the premature convergence shortcoming of the standard gsa algorithm in ecological operation of cascade hydropower reservoirss in mgsa the lévy flight with self adaptive adjustment strategy is used to improve the local exploration of the swarm the mutation strategy is executed on the global optima to expand the diversity of evolution population while the elitism selection strategy is introduced to decrease the probability of falling into local optimal solution the superior performance of the mgsa method is fully demonstrated by the simulations of 24 famous benchmark functions then mgsa is applied to the ecological operation of cascade hydropower reservoirs in china s wu river and the simulations indicate that mgsa outperforms several existing methods in maintaining the water demands of the ecological environment to sum up the paper can provide technical measures to improve the global search ability of the famous gsa method in global optimization problems in the future the feasibility of the mgsa method in other complicated real world engineering problems can be deepened credit authorship contribution statement zhong kai feng data curation formal analysis funding acquisition methodology visualization writing original draft writing review editing shuai liu data curation formal analysis visualization methodology validation wen jing niu data curation formal analysis funding acquisition methodology visualization writing original draft writing review editing shu shan li data curation formal analysis visualization methodology validation hui jun wu data curation formal analysis visualization methodology validation jia yang wang data curation formal analysis visualization methodology validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this paper is supported by the national natural science foundation of china 51709119 natural science foundation of hubei province 2018cfb573 and the fundamental research funds for the central universities hust 2017kfyxjj193 the writers would like to thank the reviewers and editors for their valuable comments and suggestions 
5908,traditional power generation operation of reservoir mainly considers the maximization of power generation and guarantees the stability of the power system however blindly considering power generation objectives may ignore its impact on the ecological environment and navigation a multi objective optimization operation model considering power generation ecological and navigation objectives is established in this paper in order to efficiently solve the model a new improved multi objective moth flame optimization algorithm based on r domination r imomfo has been proposed in order to enhance the ability of moth flame optimization algorithm mfo to overcome falling into the local optimum it is improved from three aspects update formula inspiration of moth linear flight path and flame population update strategy called improved mfo imfo algorithm in order to distinguish these individuals who are not dominated by each other in pareto domination the r domination is proposed in combination with reference points to verify the performance of imfo and r domination separately different evolutionary algorithms and multi objective mechanisms are combined to generate five new algorithms five new algorithms and five state of the art algorithms are tested on the benchmark functions and reservoir operation model the test results show that the proposed r imomfo algorithm has the ability to obtain a set of solution with good convergence and strong distribution in the optimization operation problem of cascade reservoirs finally the relationships between the objectives of the operation model are explored by the set of solution obtained by r imomfo and the reason for the relationships is analyzed the operation results show that the ecological demand and navigation demand have obvious contradictory relationships keywords cascade reservoir operation ecology navigation r domination multi objective optimization improved moth flame optimization algorithm 1 introduction reservoir operation is a complex decision making process that requires balancing benefits and various needs such as water supply ecology flood control navigation and so on chang and chang 2009 liu et al 2019a traditional reservoir operation models often only consider the power generation benefit of a single reservoir however blindly maximizing power generation may have a significant negative impact on the ecological environment within the basin tsai et al 2015 xue et al 2019 the operation solution obtained by traditional reservoir operation models may pose danger to the navigation of the vessels in the channel such as ship stranding and overturning tang et al 2014 many large river basins are developed in cascades and the optimal benefit of a single reservoir may not be optimal for the entire basin zhou et al 2014 therefore it is the purpose of this study to establish an optimization operation model considering power generation ecology and navigation for cascade reservoirs and to solve it efficiently power generation objective generally considers two aspects one is to maximize the total power generation yoo 2009 which reflects the economic benefits of the hydropower plant and the other is to maximize the minimum output of the period shang et al 2018 which can ensure safe and stable operation of the power system in order to coordinate the contradiction between the exploitation of water resources and the ecological protection of rivers the concept of ecological flow is proposed gippel and stewardson 1998 according to the principle of calculation it can be mainly divided into four categories hydrological hydraulic habitat and overall analysis methods shokoohi and amini 2014 in practical ecological operation hydrological methods are widely used due to their simple operation and low data requirements li et al 2007 in hydrological method some researchers believe that the optimal ecological flow should be in an appropriate interval duan et al 2016 therefore the objective of minimizing ecological deviation water quantity is established in the short term optimal operation model of the reservoir the navigation demand is usually controlled by the upper and lower limits of the navigation flow river flow velocity and water level variation limit chen et al 2007 however in the medium and long term optimal operation model river flow velocity and water level variation cannot be accurately considered because of the length of the period in this study a new navigation operation objective is proposed which is maximizing navigation capacity the navigation capacity is measured by the normalized quantity and tonnage of the vessel the navigation curve is a correspondence relationship between the discharge flow and the navigation capacity which is obtained by statistical historical navigation data the model established in this study considers multiple objectives multiple constraints and multiple reservoirs which is very complicated the algorithm with good convergence and strong distribution is very urgently needed when solving the optimization operation model of cascade reservoirs with high dimensional objectives early methods for solving reservoir operation are mostly based on dynamic programming linear programming non linear programming and stochastic dynamic programming labadie 2004 these methods face curse of dimensionality when the number of decision variables increases mceneaney 2007 early mechanisms for solving multi objective problems are mostly based on the weighting method and the constraint method chen et al 2017 these mechanisms can only obtain one solution in one calculation the multi objective evolutionary algorithms moeas based on pareto front pf are widely used because they solve the above two problems at the same time liu et al 2019b with the development of moeas a number of excellent algorithms have emerged such as non dominated sorting genetic algorithm ii nsgaⅱ deb et al 2002a strength pareto evolutionary algorithm 2 spea2 kim et al 2004 multi objective particle swarm optimization algorithm based on decomposition dmopso zapotecas martínez and coello coello 2011 multi objective evolutionary algorithm based on decomposition moea d zhang and li 2007 non dominated sorting genetic algorithm iii nsgaiii deb and jain 2014 and so on these algorithms can be split into two aspects to discuss one is the evolutionary algorithm such as genetic algorithm ga ahn and ramakrishna 2002 particle swarm optimization pso coello et al 2004 and differential evolution de algorithm qin et al 2009 and the other is the multi objective mechanism such as non dominated sorting method decomposition mechanism and reference point mechanism in evolutionary algorithms ga pso and de have many variants that can be used to solve various problems since they appear early there have been many new intelligent algorithms in the past decade such as black hole bh algorithm hatamlou 2013 harmony search hs optimization algorithm assad and deep 2018 chemical reaction optimization cro lam and li 2010 symbiotic organisms search sos cheng and prayogo 2014 mine blast algorithm mba sadollah et al 2013 and moth flame optimization mfo algorithm mirjalili 2015 it is noted that mfo converges quickly but is easy to fall into local optimum zhang et al 2016 to overcome this shortcoming it is improved from three aspects update formula inspiration of moth linear flight path and flame population update strategy called improved mfo imfo algorithm in multi objective mechanism pareto domination and non dominated sorting methods is very classic however when the objective dimension is increased more and more individuals are not dominated by each other which greatly increases the selection pressure of non dominated sorting methods deb and jain 2014 a new domination relationship called r domination is proposed by combining reference points and pareto domination to handle high dimension objective problems in this paper improved multi objective moth flame optimization algorithm based on r domination r imomfo is proposed to solve the optimization operation model of cascade reservoirs with high dimensional objectives the main contributions are outlined as follows 1 an improved evolutionary algorithm is proposed to enhance the ability of jumping out of the local optimum 2 a new domination relationship called r domination is proposed by combining reference points and pareto domination to handle high dimensional objectives optimization problem 3 imfo and r domination sorting method are combined into a novel well performing multi objective evolutionary algorithm called r imomfo which is applied to solve the benchmark functions and reservoir operation model nine state of the art algorithms are compared with r imomfo empirical results show that r imomfo is the most competitive among the ten algorithms 4 the relationships between the power generation ecological and navigation objective are explored and the reason for the relationships is analyzed the rest of the paper is organized as follows in section 2 the optimization operation model considering power generation ecology and navigation for cascade reservoirs is introduced in section 3 the proposed algorithm r imomfo is described in detail in section 4 the performance of r imomfo on the benchmark functions is tested in section 5 the r imomfo algorithm is applied to solve the practical model established in section 2 and in section 6 the work of this paper is summarized and the conclusions are given abbreviation descriptions of this paper are shown in appendix 1 2 operation model of cascade reservoirs 2 1 power generation objective the traditional power generation objectives shang et al 2018 are usually set to maximize the total power generation and maximize the minimum output for the period the formulas of power generation objective are described as follows 1 max f 1 max e max i 1 s t 1 t k i h i t q i t f δ t 2 max f 2 max n f max min t 1 2 t n t s n t s i 1 s n i t where e stands for the total power generated by cascade reservoirs h i t and q i t f are water head and power generation flow of the i th reservoir in the t th period respectively k i represents the integrated output coefficient of the i th reservoir s is the total number of cascade reservoirs while t is the total number of periods the duration of one period is denoted by δ t n f is the minimum output of the cascade reservoirs during the entire operation periods n t s is the total output of all cascade reservoirs in t th period which equals to the sum of n i t that is the output of each reservoir in t th period 2 2 ecological objective 2 2 1 minimizing ecological deviation water quantity some researchers believe that suitable ecological flow should have upper and lower limits and the runoff after reservoir operation should fall within this interval as much as possible duan et al 2016 the upper and lower limits of appropriate ecological flow can be calculated by the monthly frequency method li et al 2007 therefore minimizing ecological deviation water quantity is established and formulated as follows 3 min f 3 min v eco min v ecoover v ecolack 4 v ecoover i 1 m t 1 t max q i t x q i t ecou 0 δ t v ecolack i 1 m t 1 t max q i t ecol q i t x 0 δ t in above formulas v eco is the total ecological deviation water quantity of cascade reservoirs v ecoover and v ecolack stands for the total ecological overflow water quantity and the total ecological shortage water quantity of cascade reservoirs respectively q i t x q i t ecou and q i t ecol are discharge flow upper and lower limits of the suitable ecological flow of the i th ecological control section in the t th period m is the total number of ecological control sections 2 2 2 minimizing ecological change degree in order to better describe the ecological changes minimizing ecological change degree is proposed to quantify ecological objective from perspective of day based on indicators of hydrologic alteration iha richter et al 1996 poff et al 1997 and range of variability approach rva richter et al 1997 32 ihas are shown in table 1 a set of statistics a j 1 a j 2 a j t h can be obtained for each iha a j by evaluating the historical flow data of the ecological control section where a j represents the j th iha and th represents the number of historical years the mean a j and standard deviation σ a j of statistics for each iha can be further obtained the upper and lower limits of each iha are recommended in the rva richter et al 1997 as the one σ a j interval boundary 5 a j min a j σ a j a j max a j σ a j based on iha and rva minimizing ecological change degree is defined as follows 6 min f 3 min c eco min i 1 m j 1 32 c eco i j 7 c eco i j a i j a i j max a i j max a i j min a i j a i j max a i j min a i j a i j max a i j min a i j a i j min where c eco is the total ecological change degree c eco i j is the j th iha ecological change degree of i th ecological control section a i j a i j max and a i j min are j th iha value upper and lower limits of i th ecological control section m is the total number of ecological control sections 2 3 navigation objective in this study the navigation capacity is measured by normalizing the quantity and tonnage of the vessel the relationship between the discharge flow and the navigation capacity can be obtained by statistical historical navigation data in the historical data the navigation capacity under the discharge flow that can pass the largest quantity and tonnage of vessels is set to one the navigation capacity under the discharge flow that does not open the navigation channel is set to zero schematic diagram of the relationship between the discharge flow and the navigation capacity is shown in fig 1 when q x is less than q min x or greater than q max x the navigation channel is closed and the navigation capability nc is zero because of safety when q x is equal to q min x navigation is allowed and as q x increases nc also increases when q x increases in the interval q 1 x q 2 x nc reaches the maximum value and nc does not change with the change of q x when q x exceeds q 2 x nc decreases as q x increases 8 max f 4 max n c m a x 1 p 1 t i 1 p t 1 t n c i t where n c i t is the navigation capacity of the i th navigation control section in the t th period p is the total number of navigation control sections 2 4 constraints 2 4 1 constraint details 1 water level constraints 9 z i t min z i t z i t max where z i t is the water level of the i th reservoir in t th period which is also the decision variable of the optimization problem z i t min and z i t max are the lower and upper limits of water level of i th reservoir in t th period 2 flow constraints 10 q i t min q i t q i t max where q i t is the discharge flow of i th reservoir in t th period q i t min and q i t max are the lower and upper limits of discharge flow of i th reservoir in t th period 3 output constraints 11 n i t min n i t n i t max where n i t is the output of i th reservoir in t th period n i t min and n i t max are the lower and upper limits of output of i th reservoir in t th period 4 water balance equation 12 v i t 1 v i t i i t q i t e v i t δ t where v i t and v i t 1 are the initial and final storage capacity of the i th reservoir in t th period i i t is the incoming flow of i th reservoir in t th period calculated by the hydraulic connection between cascade reservoirs q i t is the outgoing flow of i th reservoir in t th period which is the sum of the power generation flow denoted by q i t f and the abandoned water flow denoted by q i t s e v i t is the system losses such as evaporation 5 hydraulic connection between cascade reservoirs 13 i i t q i 1 t τ i 1 q i t where i i t is the incoming flow of i th reservoir in t th period and q i 1 t τ i 1 is the outgoing flow of i 1 th reservoir τ i 1 is the time lag of water flow from i 1 th reservoir to i th reservoir q i t stands for the interval inflow of i th reservoir in t th period 2 4 2 constraint handling constraints can be divided into two types equality constraints and inequality constraints in this paper the equality constraints are processed in the propagation of reservoir operation calculation such as water balance equation and hydraulic connection between cascade reservoirs inequality constraints are processed in the domination relationship comparison such as water level constraints flow constraints and output constraints the degree of constraint violation is defined in the domination relationship comparison 14 dcv c c max c max c min c c max c min c c max c min c c min where dcv is the degree of constraint violation c represents the value of the any constraint c max and c min are the corresponding upper and lower limits in the search process of the evolutionary algorithm it is need to find an operation solution with a dcv value of zero 3 improved multi objective moth flame optimization algorithm based on r domination 3 1 review of mfo the mfo algorithm is an intelligent optimization algorithm inspired by the horizontal positioning mechanism of the moths in flight mirjalili 2015 moths are always positioned at an angle to the light when flying at night in ancient times because there are not so many point light sources and the moonlight can be approximated as parallel light on the earth the moths can achieve a linear flight by being at an angle to the moonlight as shown in fig 2 b however in modern times due to the increase of the number of point light sources the moth still flies at a certain angle with the light and its flight path will form a spiral line which will cause the moth to hit the point light source as shown in fig 2 a the original mfo algorithm has two populations one is the moth population denoted by m that represents the most common population in all evolutionary algorithms and the other is the flame population denoted by f that represents a better population of all moths moth individuals are updated using the spiral formula centered on flame individuals when the current moth individual is superior to the current flame individual the flame individual is replaced with the moth individual the spiral update function is shown as follows 15 m ij d ij e bt cos 2 π t f ij d ij f ij m ij where m ij and m ij are the j th decision variable of the i th moth population before and after the update respectively f ij is the flame population d ij is distance between flame population and moth population parameter t is a random number between 1 and 1 the value of parameter b is usually set to one more detailed implementation steps can be found in the paper mirjalili 2015 it has been shown in the literature zhang et al 2016 that the ability of mfo to avoid stalling in the local optima is not strong enough also as evidenced by the experiments in section 4 in the spiral update formula of the original mfo algorithm the center of the spiral is the flame population f however if the moth individual is not updated to a better position than the flame individual the spiral center will remain unchanged which makes it difficult to jump out of local optimum in addition the flame individual only records the historical optimal solution of its corresponding moth individual and the update of the moth individual is always based on its corresponding flame individual in other words there is no communication between the moth individuals which will make it easy to fall into local optimum 3 2 improved mfo algorithm imfo 1 improvement of the update formula the update formula of imfo is similar to the original mfo but there are three changes in the details first the center of the spiral is replaced with the mean of the moth individual and the flame individual since the moth individual changes at each iteration the center of the spiral will also change which helps to avoid stalling in the local optima then the distance influence parameter c between the moth individual and the flame individual are also improved there is no theoretical derivation and support for the calculation formula of c but it is obtained by many experiments and tried many times more than ten kinds of alternative formulas were listed preliminarily in the experiments and the parameters of each alternative formula were determined by the classic single objective benchmark functions liang et al 2005 finally the absolute sign of the distance between the flame individual and moth individual is removed since the value of c is a positive number if d ij is limited to a positive number this will lose half the probability the improved update formulas are as follows 16 m ij f ij m ij 2 0 5 d ij c d ij f ij m ij 17 c tanh 1 b t 1 t a n h 1 b t r a n d 0 1 1 tanh 3 b t a n h 3 b t t r a n d 1 2 where t is a random number between 0 and 2 b is a constant and usually set to 1 c is the distance influence parameter 2 inspiration of moth linear flight path the original mfo algorithm only considered the spiral flight path not the linear flight path in order to inspire a linear flight path a new population is created which is moon population denoted by m o in single objective imfo algorithm m o can be the optimal solution for all individuals in multi objective imfo algorithm m o can be an external archive set maintained by a certain strategy in the real world moths are affected more by the point light than the moonlight so the moon population assists in updating the moth individual with a small probability the updated formula is a linear formula as shown below 18 m ij m ij m o rj 2 where m ij represents the j th decision variable of the i th moth individual while m o rj represents the j th decision variable of the r th moon individual r means randomly selecting an individual from the moon population since moon population m o represents the optimal solution set in the entire search process the introduction of m o can speed up the convergence 3 improvement of flame population update strategy in the single objective algorithm the newly generated moth individual and its corresponding flame individual can directly determine the pros and cons by comparing the objective value thereby whether to replace the flame individual with the newly generated moth individual however in the multi objective algorithm relying solely on the objective values may not be able to determine the pros and cons because there may be the situation in which two individuals do not dominate each other if the flame individual is dominated by the newly generated moth individual the former is replaced by the latter if the newly generated moth individual is dominated by the flame individual the flame individual is not changed if the two do not dominate each other randomly select one from the moon population to replace the current flame individual this improvement not only preserves the newly created superior individuals but also enhances the communication between individuals which is beneficial for improving the convergence speed and to avoid falling into the local optima the pseudocode of imfo is shown in appendix 2 3 3 new domination relationship r domination the solution a is said to pareto dominate the solution b denoted by a b if one of the following conditions is true 1 a is a feasible solution and b is not 2 both a and b are infeasible solutions and a violates constraints less than b 3 both a and b are feasible solutions at the same time a is not worse than b in all objective dimensions and superior to b in at least one objective dimension obviously when the objective dimension is increased the above three conditions are difficult to achieve more and more individuals are not dominated by each other which greatly increases the selection pressure of non dominated sorting methods the r domination relationship is proposed to deal with this situation the individual a is said to r dominate the individual b denoted by a r b if one of the following two situations occurs 1 a pareto dominates b 2 a and b can not be pareto dominated by each other and the r value of a is smaller than b r value is a measure of the degree of association between individual and reference point whose calculation method is shown below the reference points are a set of points uniformly distributed in the hyperplane its generation method and properties are the same as those in the moea d zhang and li 2007 and nsgaiii deb and jain 2014 19 r p o r d e r p d p where r p is the r value of individual p dp is the vertical distance from the individual p to the reference line order p is the order number of individual p in its associative reference points in ascending order of dp the schematic diagram of r domination relationship is shown in fig 3 where r1 and r2 are reference points a b c d and e are individuals individual a b and c are associated with r1 while individual d and e are associated with r2 it is assumed that d4 d2 d1 d5 d3 in ordinary pareto domination relationship the individual a b c d and e cannot dominate other individuals and their priorities are the same but in r domination they need to further calculate r value r a 2 d 1 r b 1 d 2 r c 3 d 3 r d 1 d 4 r e 2 d 5 and r value in ascending order is r d r b r a r e r c so their r domination relationship is d r b r a r e r c since it is almost impossible to equalize the dp of two individuals all individuals in r domination can be distinguished furthermore r domination sorting method is proposed which still adopts the non dominated sorting framework deb et al 2002a the difference is that in the non dominated sorting method individuals in the same rank cannot distinguish priorities but in the r domination sorting method r value is used to distinguish priorities the r domination sorting method follows two principles one is that for individuals with different ranks individuals with lower rank are superior to individuals with higher rank another is that for individuals with the same rank individuals with smaller r value are superior to those with larger r value if the five individuals in fig 3 can only have two individuals entering the next generation individual d and b will be lift according to r domination sorting method visual inspection can verify that the solution set obtained by the r domination sorting method in this case is the best distributed 3 4 framework of r imomfo the complete steps of the r imomfo algorithm are shown in the pseudocodes algorithm 2 is the overall framework of the r imomfo algorithm there are several important functions in algorithm 2 including imfo normalize associate r value their pseudocodes are shown in appendix 2 the function normalize and associate are the same as that of nsgaiii deb and jain 2014 3 5 advantages of r imomfo 3 5 1 convergence the convergence performance of r imomfo mainly comes from the improvement of evolutionary algorithm it overcomes the local optimization and accelerates convergence from the following four aspects 1 the center of the spiral is adjusted to be dynamic which ensures vitality in the evolutionary process and helps avoid local optima 2 the absolute sign of the distance between the flame individual and moth individual is removed which doubles the possibility of finding a better solution 3 the introduction of moon population can speed up the convergence since it represents the optimal solution set in the entire search process 4 improvement of flame population update strategy not only preserves the newly created superior individuals but also enhances the communication between individuals which is beneficial for improving the convergence speed and to avoid falling into the local optima 3 5 2 distribution the distribution performance of r imomfo mainly comes from the improvement of domination relationship r domination further compares the quality of non inferior solutions by reference points on the basis of ordinary pareto domination since reference points are a set of evenly distributed points generated in the objective space individuals screened by r domination sorting method will have a good distribution specifically in the following two aspects 1 due to order p in the r value calculation method it can guaranteed that at least one individual of each associated reference point is retained in the next generation 2 due to dp in the r value calculation method it can guaranteed that the closer the individual is to the vertical line the more likely it is to enter the next generation 4 performance test 4 1 benchmark function in order to test performance of proposed algorithm two famous benchmark functions that are deb thiele laumanns zitzler dtlz deb et al 2002b and walking fish group wfg huband et al 2006 are involved in the experiments these benchmark functions cover linear multi modal concave biased scaled and non separable features which can be used to test the performance of the algorithm comprehensively huband et al 2006 in order to compare with the existing research results deb and jain 2014 yuan et al 2016 dtlz1 4 dtlz7 and wfg1 9 are considered in the experiments the objective dimension and decision variable dimension of all these functions can be any non negative number the number of objectives o of all functions is set as 3 5 8 10 for dtlz1 4 and dtlz7 the total number of decision variables is given by d o k 1 k is set to 5 for dtlz1 10 for dtlz2 4 and 20 for dtlz7 as recommended in deb and jain 2014 and deb et al 2002b as for all wfg problems the number of decision variables d is set to 24 and position related parameter is set to o 1 according to the papers hernandez gomez and coello coello 2013 huband et al 2006 4 2 evaluation metric 1 inverted generational distance igd the inverted generational distance igd is one of the most widely used metrics which can simultaneously evaluate the convergence and distribution of a solution set zitzler et al 2003 a set of uniformly distributed points among the known pareto front pf is required to calculate igd as follows 20 igd a v 1 v i 1 v min f a d v i f for each reference direction λ i the targeted point v i on the known pf can be located all n targeted points constitute the set v v 1 v 2 v n symbol a represents for the points of solution set obtained by specific algorithm in the objective space d v i f is the euclidean distance between the points v i and f the smaller the igd values the better the set a 2 hypervolume hv the hypervolume hv is another popular metrics which also can simultaneously measure the convergence and distribution of a solution set zitzler and thiele 1999 hv s strong theoretical characteristics make it a very fair metric zitzler et al 2003 hv is defined as follows 21 hv a r v o l u m e f a f 1 r 1 f m r m symbol a is the same as mentioned before symbol r r 1 r 2 r m t is a reference point in the objective space which is dominated by any point in the set a hv of a with regard to r is the volume of the region dominated by a and bounded by r the larger the hv values the better the set a 4 3 experimental design in order to compare the effects of imfo and r domination sorting method respectively different evolutionary algorithms ga mfo imfo and different multi objective mechanisms framework of nsgaiii r domination sorting method are combined to obtain the following algorithms r imomfo r momfo r moga nsimfoiii nsmfoiii and nsgaiii in addition moea d θ dea yuan et al 2016 dmopso zapotecas martínez and coello coello 2011 and an existing improved mfo algorithm taher et al 2018 with r domination r imfo participate in the comparison for ease of expression iii mechanism is shorthand for the framework of nsgaiii and r mechanism is shorthand for the r domination sorting method parameter settings of ten algorithms are shown in table 2 iteration numbers of all benchmark functions are shown in table 3 in order to ensure the fairness of the verification and to utilize the existing results the settings of all parameters without bold fonts are the same as those in the paper yuan et al 2016 the setting of the parameter b in mfo and imfo is to first preset some values 0 5 1 1 5 2 then test the performance of benchmark functions under these values respectively and finally determine by comprehensive comparison in addition each algorithm runs 20 times in each benchmark function to avoid randomness 4 4 experimental results best median and worst igd values obtained by ten algorithms on six benchmark functions are shown in table 4 the average hv values obtained by ten algorithms on dtlz and wfg benchmark functions are shown in tables 5 and 6 respectively the best and second best results for each row in these three tables are highlighted with dark and light gray background respectively 1 first of all in order to compare the performance of imfo proposed in this paper and mfo metrics of r imomfo r momfo and nsimfoiii nsmfoiii should be extracted for analysis regardless of whether it is on r mechanism or iii mechanism imfo has all the metrics better than mfo on all benchmark functions which shows that the improvements of imfo is very effective 2 furthermore in order to compare the performance of imfo proposed in this paper an existing imfo and ga metrics of r imomfo r imfo r moga and nsimfoiii nsgaiii should be extracted on r mechanism r imomfo s 45 igd values are better than r moga among total 72 igd values expressed by r imomfo 45 72 igd r moga r imomfo 72 72 igd r imfo r imomfo 44 56 hv r moga and r imomfo 56 56 hv r imfo on iii mechanism the comparison results are nsimfoiii 70 72 igd nsgaiii and nsimfoiii 42 56 hv nsgaiii these verification results show that imfo proposed in this paper is also very competitive compared with ga and an existing imfo 3 then in order to compare the performance of r mechanism and iii mechanism metrics of r imomfo nsimfoiii and r moga nsgaiii should be extracted for analysis in the mfo the comparison results are r 51 72 igd i i i and r 43 56 hv i i i in the ga the comparison results are r 68 72 igd i i i and r 37 56 hv i i i these verification results show that r mechanism is superior to the iii mechanism in most cases 4 next in order to compare the performance of r imomfo proposed in this paper and other multi objective mechanisms and swarm intelligent optimization algorithm metrics of r imomfo moea d θ dea dmopso are extracted for analysis the comparison results are r imomfo 64 72 igd moea d r imomfo 57 72 igd θ dea r imomfo 67 72 igd dmopso r imomfo 54 56 hv moea d r imomfo 47 56 hv θ dea r imomfo 56 56 hv dmopso these verification results show that r imomfo is very competitive compared with these existing multi objective evolutionary algorithm 5 finally the ten algorithms are put together for overall comparison by observing the dark background in these tables it can be known that r imomfo is generally optimal among the ten algorithms in the benchmark functions 5 case study 5 1 description of the case 1 the object selected for the case study is the lancang basin that is one of the largest basin in southwest china the topological structure of the cascade reservoirs in the case is shown in fig 4 the xiaowan manwan dachaoshan nuozhadu and jinghong hydropower stations in the lower reaches of the lancang river are selected in this case for joint operation the entire basin s main goal is to generate power taking into account ecological and navigation objectives the model established in this case have four objectives that are described in sections 2 1 2 2 1 and 2 3 the constraints of the model is introduced in section 2 4 the five sections are all ecological control sections and jinghong is a navigation control section the reservoir features of the cascade reservoirs in the lancang river are shown in table 7 in this case data from the lancang river in 2000 is used a period is one month the decision variables are the upstream water level of the five reservoirs at 13 moments parameter settings of ten algorithms in the case study are shown in table 8 each algorithm runs 20 times the iteration numbers of each algorithm is set to 5000 in this case there are six tasks to complete as shown below 1 compare ten algorithms on the complex actual reservoir operation problem by hv metric 2 visualization of the pareto front of the case 3 explore the relationships between the objectives in the case 4 compare the water level change process of different solutions 5 analyze the reason for the relationship between power generation and ecological objective and 6 analyze the reason for the relationship between power generation and navigation objective 5 2 results and discussion of the case 1 5 2 1 evaluation metrics in the case 1 the calculation of igd needs to know the true pf however true pf of actual problem is almost impossible to get therefore igd cannot be computed to evaluate the performance of the ten algorithms in this case the accurate hv requires extreme points of the true pf in each objective dimension for normalizing the solution set strictly speaking hv is also incalculable in actual cases however the exact value of hv in this study is not what we care about but the relative order of hv obtained by each algorithm is what we really care about regardless of which algorithm is used as the standard their relative order does not change therefore the extreme points of the solution set obtained by nsgaiii in each objective dimension are set as a standard to normalize the solution set obtained by the ten algorithms the order of hv calculated by this method can evaluate the relative performance of the ten algorithms in this practical case the average hv values obtained by ten algorithms in the case study are shown in table 9 from the relative order of hv in table 9 hv of r imomfo is the largest in this case which indicates that r imomfo is very powerful when solving the cascade reservoir operation multi objective optimization problem 5 2 2 visualization of the pareto front of the case 1 the visualization of pareto front of high dimensional objective optimization problem greater than 3 d is still a research hotspot in the field of many objective optimization deb and jain 2014 radar figures are used to visualize the pf in this study there are two criteria for evaluating the performance of pf via radar figures 1 the convergence of pf is measured by the range of the objective value on each coordinate axis the wider range and the better objective values on each coordinate axis has better convergence 2 the distribution of pf is measured by the uniformity of each point on the coordinate axis the more uniform the better the distribution the radar figures of pf obtained by r imomfo nsgaiii moea d and θ dea are shown in fig 5 for each radar figure the data uses the corresponding solution set with the highest hv value among the 20 results e n f v eco and nc are the total power generation minimum output of the period ecological deviation water quantity and navigation capacity respectively each line in the radar figure represents a solution 1 convergence the ranges of r imomfo on the four objectives are 822 10 863 62 593 48 816 40 305 47 740 75 and 0 79 0 97 the ranges of θ dea on the four objectives are 837 09 852 79 746 56 795 07 676 51 747 04 and 0 86 0 93 taking the objective dimension of total power generation e as an example one the one hand the best objective value 863 62 of r imomfo is better than the best objective value 852 79 of θ dea on the other hand the range 822 10 863 62 of r imomfo is wider than the range 837 09 852 79 of θ dea which shows that r imomfo converges better than θ dea in the objective dimension e the convergence comparison of other objective dimensions and other algorithms is similar 2 distribution the point distribution of r imomfo on the four axes is significantly more uniform than other algorithms which shows that the distribution of r imomfo is stronger than that of other algorithms 5 2 3 relationship between objectives in the case 1 the solution set with the highest hv value among 20 results obtained by r imomfo is used to explore the relationship between objectives in the case objective projections of the pf obtained by r imomfo are shown in fig 6 1 the relationship between e and n f is not obvious literature shang et al 2018 suggests that the economic benefits of the hydropower station and the stability of the power system are inversely related however the relationship has become less obvious under the influence of ecological objective and navigation objective 1 2 e and v eco are proportional relationship the greater the amount of power generated the greater the damage to the ecology 2 3 e and nc are proportional relationship the greater the amount of power generated the greater the navigation capacity 3 4 v eco and nc are proportional relationship since both v eco and nc are proportional to e and n f v eco and nc are also proportional 5 2 4 analysis of water level change process the solution set with the highest hv value among 20 results obtained by r imomfo is used to analyze the water level change process which explains how the decision variables influence the objectives the upstream water level of the five reservoirs at 13 moments are the decision variables first the 120 solutions are arranged in ascending order of the total power generation then the seven solutions are sampled at equal intervals finally the water level change process of these solutions on five reservoirs is plotted in fig 7 the results can be analyzed as follows 1 the water level of each solution on manwan dachaoshan and jinghong has not changed much in the flood season the water level of these solutions is maintained at the flood control level the water level differences of each solution are mainly reflected in the non flood period and the differences are very small which can be ignored when analyzing the influence of the water level on the objective values 2 the water level process of xiaowan and manwan is the main difference between the various solutions the water level difference of each solution in flood season is much larger than that in non flood period 3 during the flood season of xiaowan and manwan area ⅰ and area ⅱ the average water level from solution 1 to 120 is roughly high to low which means that more water is used for power generation this is why the total power generation from solution 1 to 120 increases in turn 5 2 5 analysis of relationship between power generation and ecological objective in order to analyze the reason for the relationship between the total power generation and ecological objective the discharge flow change process of the solutions obtained by r imomfo is plotted in fig 8 the ecological objective of the discharge flow process line falling into the gray suitable ecological flow interval is optimal the farther away from the gray interval the worse the ecological objective the results can be analyzed as follows 1 the difference in the each solution s discharge flow process of the two ecological control sections of nuozhadu and jinghong is larger than that of the three ecological control sections of xiaowan manwan and dachaoshan the difference of discharge flow process in xiaowan manwan and dachaoshan is very small which can be ignored when analyzing the influence of the discharge flow on the ecological objective 2 in the two ecological control sections of nuozhadu and jinghong the difference in the discharge flow process is mainly reflected in january to may and july to september 3 in january to may and july to september of nuozhadu and jinghong the discharge flow process lines of solution 1 to 120 gradually move away from the gray interval indicating that their ecological objectives are gradually deteriorating this is the reason why the greater the amount of power generated the greater the damage to the ecology 5 2 6 analysis of relationship between power generation and navigation objective in order to analyze the reason for the relationship between power generation and navigation objective the discharge flow process and navigation capacity process of jinghong navigation control section are plotted in fig 9 the discharge flow process of the seven solutions is shown in the lower part of fig 9 the black curve is the relationship curve between the discharge flow and the navigation capacity qx nc the discharge flow process of each solution is transformed into the navigation capacity process through the black curve as shown in the upper part of fig 9 the navigation capabilities of the seven solutions are shown in the histogram in fig 9 the results can be analyzed as follows 1 the difference of the discharge flow process curves of each solution is large and the corresponding navigation capability curve is also different 2 the discharge flow process of the solutions 80 100 and 120 is closer to the gray interval than that of solutions 1 20 40 and 60 which means that the corresponding navigation capacity of the former is larger than that of the latter as can be seen from the histogram the navigation capacity of solutions 1 to 120 is roughly increasing the closer the discharge flow is to the dark gray interval whose discharge flow is located in the interval 1900 2100 the stronger its corresponding navigation capability 5 3 description of the case 2 in order to further test the performance of the algorithm r imomfo and better consider the ecological changes case 2 of the lancang basin is performed in case 2 an operation period is one day and the total operation period is one year the xiaowan hydropower station is selected in this case the model established in this case have four objectives that are described in sections 2 1 2 2 2 and 2 3 the constraints of the model is introduced in section 2 4 xiaowan is an ecological control section and jinghong is a navigation control section in this case data from the lancang river in 2014 is used the decision variables are the upstream water level of xiaowan reservoir at 365 moments parameter settings are the same as case 1 in this case there are four tasks to complete as shown below 1 compare ten algorithms by hv metric in case 2 2 visualize the pareto front in case 2 3 analyze ecological objectives of typical solutions 5 4 results and discussion of case 2 5 4 1 evaluation metrics in case 2 in order to further verify the performance of r imomfo hv metric is also used to test 10 algorithms in case 2 the average hv values obtained by ten algorithms in case 2 are shown in table 10 the hv value of r imomfo is 0 797483 which is the largest among 10 algorithms it shows that the solution set obtained by r imomfo has the best convergence and distribution which again verifies the performance of r imomfo 5 4 2 pareto front of case 2 the pareto front of r imomfo in case 2 is shown in fig 10 the four objective e n f ceco nc ranges in the pareto front are 180 194 0 098 3 919 2 07 2 88 and 0 713 0 771 respectively intuitively the pareto front of r imomfo has a good distribution 5 4 3 analysis of ecological objectives of typical solutions in order to analyze the difference of different ecological objectives iha metrics of two typical solutions are shown in fig 11 in each figure the left five parts are histograms of five groups of iha metrics the upper right corner is the flow process of the ecological control section before and after operation the bottom right corner is a histogram of ecological change degree of iha metrics with descending sort by comparing two typical solutions the following two results can be analyzed 1 in general the difference between the two solutions lies in the difference in the flow process and mainly concentrated in the period 150 to the period 300 2 what the two solutions have in common is that the six iha metrics with the highest ecological change degree are all 1 3 12 29 30 21 however the 29 th and 30 th ecological change degrees of the solution solution 2 with worst ecological objective are significantly larger than the solution solution 1 with optimal ecological objective and the 29 th and 30 th iha metrics are means of all positive and negative differences between consecutive daily values respectively it is precisely because the solution 2 has more volatility between period 150 to 300 than solution 1 resulting in more damage to metrics 29 and 30 which can also be seen visually from the iha diagram on the left 6 conclusions first an optimization operation model considering power generation ecology and navigation for cascade reservoirs is established then the mfo s shortcoming that is easy to fall into the local optimum is pointed out and the reasons are analyzed to overcome this shortcoming imfo is proposed next the shortcoming of the ordinary pareto domination is explained when there are many objective dimensions many solutions cannot dominate each other and the priority between those solutions is lost which makes the non dominated sorting method face huge selection pressure r domination based on reference points is proposed to distinguish those solutions that cannot dominate each other in pareto domination further r domination sorting method is proposed in combination with non dominated sorting method and r domination in order to verify the performance of imfo and r domination sorting method separately different evolutionary algorithms and multi objective mechanisms are combined into five new algorithms r imomfo r momfo r moga nsimfoiii nsmfoiii five new algorithms and five existing algorithms are tested on the dtlz and wfg benchmark functions the test results of hv and igd show the solution set obtained by r imomfo is the best among the ten algorithms in most test functions indicating both imfo and r domination sorting method are very effective finally the ten algorithms are applied to solve the operation model comparing the solution set of the ten algorithms it is verified that the performance of the r imomfo is also the best in practical problems the relationships between the objectives of the operation model are explored by the solution set obtained by r imomfo the reasons for the relationship between power generation and ecological objective navigation objective are explained by analyzing the water level change process and the discharge flow change process of the solution set in the future research work the update formula with better convergence and the domination relationship with stronger distribution can be further explored at the same time it is worthwhile to discuss the performance of the framework proposed in this study in solving more complex reservoir operation problem such as the reservoir operation model of flood control power generation ecology navigation and water supply it is also a future work to use the method of this research to solve the complementary operation of wind solar hydro hybrid system zhang et al 2019a b declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work is supported by the national key r d program of china 2016yfc0402209 the national public research institutes for basic r d operating expenses special project cksf2017061 sz the national natural science foundation of china nos 91647114 51709119 51809098 51579107 91547208 huazhong university of science and technology 2019ygscxcy072 and special thanks are given to the anonymous reviewers and editors for their constructive comments appendix 1 acronym full name ga genetic algorithm pso particle swarm optimization de differential evolution algorithm mfo moth flame optimization algorithm imfo improved moth flame optimization algorithm nsgaⅱ non dominated sorting genetic algorithm ii spea2 strength pareto evolutionary algorithm 2 dmopso multi objective particle swarm optimization algorithm based on decomposition mechanism moea d multiobjective evolutionary algorithm based on decomposition θ dea θ domination evolutionary algorithm r imomfo improved multi objective moth flame optimization algorithm based on r domination r momfo multi objective moth flame optimization algorithm based on r domination r moga multi objective genetic algorithm based on r domination r imfo existing improved mfo algorithm with r domination nsimfoiii non dominated sorting improved multi objective moth flame optimization algorithm iii nsmfoiii non dominated sorting multi objective moth flame optimization algorithm iii nsgaiii non dominated sorting genetic algorithm iii pf pareto front igd inverted generational distance hv hypervolume iha indicators of hydrologic alteration rva range of variability approach appendix 2 the pseudocodes of the proposed method can be downloaded here the pseudocodes of imfo are shown in algorithm 1 algorithm 1 imfo mt ft mo input mt current moth population ft current flame population mo moon population d number of decision variables n size of population output qt offspring population 1 qt ø i 1 2 while qt n 3 current flame individual ft i 4 current moth individual mt i 5 for j 1 d 6 dis ft ij mt ij 7 t random 0 2 b 1 8 if t 1 9 c tanh 1 bt 1 tanh 1 b 10 else 11 c 1 tanh 3 b tanh 3 bt 12 end if 9 pij 0 5 mt ij ft ij 0 5c dis 10 if random 0 1 0 2 11 random choose an individual from mo mor 12 pij 0 5 pij morj 13 end if 14 end for 15 polynomial mutation pi 16 update fi if single objective compare the objective value of pi and fi to take a better solution as fi if multi objective if fi is dominated by pi fi is replaced by pi if pi is dominated by fi fi is not changed if fi and pi do not dominate each other randomly choose an individual mor from moon population to replace fi 17 qt qt pi 18 i i 1 19 end while 20 mo mo qt 21 update mo as mo if single objective mo is the best solution of mo if multi objective mo is maintained from mo by a specific strategy in this paper the specific strategy is r domination sorting method algorithm 2 is the overall framework of the r imomfo algorithm there are several important functions in algorithm 2 including imfo normalize associate r value their pseudocodes are shown in algorithm 1 3 4 5 respectively algorithm 2 generation t of r imomfo procedure input mt current moth population ft current flame population mo moon population zr reference points n size of population output mt 1 next generation of the moth population ft 1 next generation of the flame population mo moon population 1 st ø i 1 2 qt imfo mt ft mo 3 rt mt qt 4 p1 p2 non dominated sorting rt 5 do 6 st st pi 7 i i 1 8 while st n 9 save key rank pl pi 10 if st n then 11 mt 1 st 12 else 13 m t 1 j 1 l 1 p j 14 compute the number of individuals to be chosen from pl k n mt 1 15 normalize st 16 associate st zr 17 calculate r value st zr 18 pl ascending sort by r value 19 m t 1 m t 1 j 1 k p lj 20 end if 21 for j 1 n 22 if mt 1 j is not dominated by ft j then 23 ft 1 j mt 1 j 24 else 25 ft 1 j ft j 26 end if 27 end for algorithm 3 normalize st input st to be normalized population o number of objective functions 1 for i 1 o 2 compute ideal point f i min min f i s s st 3 translate objectives f i s f i s f i min s st 4 compute extreme points yi max of st 5 end for 6 for i 1 o 7 compute intercepts ai according to yi max 8 normalize objectives f i s f i s f i min a i s st 9 end for algorithm 4 associate st zr input st to be associated population zr reference points 1 for each s st 2 for each w zr 3 compute vertical distance d s w s wtsw w 2 4 end for 5 find the reference point zr m for the minimum d 6 associate s with zr m 7 end for algorithm 5 r value st zr input st population zr reference points 1 for i 1 length zr 2 get all individuals associated with z i r pi 3 sort pi by ascending order of vertical distance from individual to z i r 4 for j 1 length pi 5 set pij s r value j dj 6 end for 7 end for 
5908,traditional power generation operation of reservoir mainly considers the maximization of power generation and guarantees the stability of the power system however blindly considering power generation objectives may ignore its impact on the ecological environment and navigation a multi objective optimization operation model considering power generation ecological and navigation objectives is established in this paper in order to efficiently solve the model a new improved multi objective moth flame optimization algorithm based on r domination r imomfo has been proposed in order to enhance the ability of moth flame optimization algorithm mfo to overcome falling into the local optimum it is improved from three aspects update formula inspiration of moth linear flight path and flame population update strategy called improved mfo imfo algorithm in order to distinguish these individuals who are not dominated by each other in pareto domination the r domination is proposed in combination with reference points to verify the performance of imfo and r domination separately different evolutionary algorithms and multi objective mechanisms are combined to generate five new algorithms five new algorithms and five state of the art algorithms are tested on the benchmark functions and reservoir operation model the test results show that the proposed r imomfo algorithm has the ability to obtain a set of solution with good convergence and strong distribution in the optimization operation problem of cascade reservoirs finally the relationships between the objectives of the operation model are explored by the set of solution obtained by r imomfo and the reason for the relationships is analyzed the operation results show that the ecological demand and navigation demand have obvious contradictory relationships keywords cascade reservoir operation ecology navigation r domination multi objective optimization improved moth flame optimization algorithm 1 introduction reservoir operation is a complex decision making process that requires balancing benefits and various needs such as water supply ecology flood control navigation and so on chang and chang 2009 liu et al 2019a traditional reservoir operation models often only consider the power generation benefit of a single reservoir however blindly maximizing power generation may have a significant negative impact on the ecological environment within the basin tsai et al 2015 xue et al 2019 the operation solution obtained by traditional reservoir operation models may pose danger to the navigation of the vessels in the channel such as ship stranding and overturning tang et al 2014 many large river basins are developed in cascades and the optimal benefit of a single reservoir may not be optimal for the entire basin zhou et al 2014 therefore it is the purpose of this study to establish an optimization operation model considering power generation ecology and navigation for cascade reservoirs and to solve it efficiently power generation objective generally considers two aspects one is to maximize the total power generation yoo 2009 which reflects the economic benefits of the hydropower plant and the other is to maximize the minimum output of the period shang et al 2018 which can ensure safe and stable operation of the power system in order to coordinate the contradiction between the exploitation of water resources and the ecological protection of rivers the concept of ecological flow is proposed gippel and stewardson 1998 according to the principle of calculation it can be mainly divided into four categories hydrological hydraulic habitat and overall analysis methods shokoohi and amini 2014 in practical ecological operation hydrological methods are widely used due to their simple operation and low data requirements li et al 2007 in hydrological method some researchers believe that the optimal ecological flow should be in an appropriate interval duan et al 2016 therefore the objective of minimizing ecological deviation water quantity is established in the short term optimal operation model of the reservoir the navigation demand is usually controlled by the upper and lower limits of the navigation flow river flow velocity and water level variation limit chen et al 2007 however in the medium and long term optimal operation model river flow velocity and water level variation cannot be accurately considered because of the length of the period in this study a new navigation operation objective is proposed which is maximizing navigation capacity the navigation capacity is measured by the normalized quantity and tonnage of the vessel the navigation curve is a correspondence relationship between the discharge flow and the navigation capacity which is obtained by statistical historical navigation data the model established in this study considers multiple objectives multiple constraints and multiple reservoirs which is very complicated the algorithm with good convergence and strong distribution is very urgently needed when solving the optimization operation model of cascade reservoirs with high dimensional objectives early methods for solving reservoir operation are mostly based on dynamic programming linear programming non linear programming and stochastic dynamic programming labadie 2004 these methods face curse of dimensionality when the number of decision variables increases mceneaney 2007 early mechanisms for solving multi objective problems are mostly based on the weighting method and the constraint method chen et al 2017 these mechanisms can only obtain one solution in one calculation the multi objective evolutionary algorithms moeas based on pareto front pf are widely used because they solve the above two problems at the same time liu et al 2019b with the development of moeas a number of excellent algorithms have emerged such as non dominated sorting genetic algorithm ii nsgaⅱ deb et al 2002a strength pareto evolutionary algorithm 2 spea2 kim et al 2004 multi objective particle swarm optimization algorithm based on decomposition dmopso zapotecas martínez and coello coello 2011 multi objective evolutionary algorithm based on decomposition moea d zhang and li 2007 non dominated sorting genetic algorithm iii nsgaiii deb and jain 2014 and so on these algorithms can be split into two aspects to discuss one is the evolutionary algorithm such as genetic algorithm ga ahn and ramakrishna 2002 particle swarm optimization pso coello et al 2004 and differential evolution de algorithm qin et al 2009 and the other is the multi objective mechanism such as non dominated sorting method decomposition mechanism and reference point mechanism in evolutionary algorithms ga pso and de have many variants that can be used to solve various problems since they appear early there have been many new intelligent algorithms in the past decade such as black hole bh algorithm hatamlou 2013 harmony search hs optimization algorithm assad and deep 2018 chemical reaction optimization cro lam and li 2010 symbiotic organisms search sos cheng and prayogo 2014 mine blast algorithm mba sadollah et al 2013 and moth flame optimization mfo algorithm mirjalili 2015 it is noted that mfo converges quickly but is easy to fall into local optimum zhang et al 2016 to overcome this shortcoming it is improved from three aspects update formula inspiration of moth linear flight path and flame population update strategy called improved mfo imfo algorithm in multi objective mechanism pareto domination and non dominated sorting methods is very classic however when the objective dimension is increased more and more individuals are not dominated by each other which greatly increases the selection pressure of non dominated sorting methods deb and jain 2014 a new domination relationship called r domination is proposed by combining reference points and pareto domination to handle high dimension objective problems in this paper improved multi objective moth flame optimization algorithm based on r domination r imomfo is proposed to solve the optimization operation model of cascade reservoirs with high dimensional objectives the main contributions are outlined as follows 1 an improved evolutionary algorithm is proposed to enhance the ability of jumping out of the local optimum 2 a new domination relationship called r domination is proposed by combining reference points and pareto domination to handle high dimensional objectives optimization problem 3 imfo and r domination sorting method are combined into a novel well performing multi objective evolutionary algorithm called r imomfo which is applied to solve the benchmark functions and reservoir operation model nine state of the art algorithms are compared with r imomfo empirical results show that r imomfo is the most competitive among the ten algorithms 4 the relationships between the power generation ecological and navigation objective are explored and the reason for the relationships is analyzed the rest of the paper is organized as follows in section 2 the optimization operation model considering power generation ecology and navigation for cascade reservoirs is introduced in section 3 the proposed algorithm r imomfo is described in detail in section 4 the performance of r imomfo on the benchmark functions is tested in section 5 the r imomfo algorithm is applied to solve the practical model established in section 2 and in section 6 the work of this paper is summarized and the conclusions are given abbreviation descriptions of this paper are shown in appendix 1 2 operation model of cascade reservoirs 2 1 power generation objective the traditional power generation objectives shang et al 2018 are usually set to maximize the total power generation and maximize the minimum output for the period the formulas of power generation objective are described as follows 1 max f 1 max e max i 1 s t 1 t k i h i t q i t f δ t 2 max f 2 max n f max min t 1 2 t n t s n t s i 1 s n i t where e stands for the total power generated by cascade reservoirs h i t and q i t f are water head and power generation flow of the i th reservoir in the t th period respectively k i represents the integrated output coefficient of the i th reservoir s is the total number of cascade reservoirs while t is the total number of periods the duration of one period is denoted by δ t n f is the minimum output of the cascade reservoirs during the entire operation periods n t s is the total output of all cascade reservoirs in t th period which equals to the sum of n i t that is the output of each reservoir in t th period 2 2 ecological objective 2 2 1 minimizing ecological deviation water quantity some researchers believe that suitable ecological flow should have upper and lower limits and the runoff after reservoir operation should fall within this interval as much as possible duan et al 2016 the upper and lower limits of appropriate ecological flow can be calculated by the monthly frequency method li et al 2007 therefore minimizing ecological deviation water quantity is established and formulated as follows 3 min f 3 min v eco min v ecoover v ecolack 4 v ecoover i 1 m t 1 t max q i t x q i t ecou 0 δ t v ecolack i 1 m t 1 t max q i t ecol q i t x 0 δ t in above formulas v eco is the total ecological deviation water quantity of cascade reservoirs v ecoover and v ecolack stands for the total ecological overflow water quantity and the total ecological shortage water quantity of cascade reservoirs respectively q i t x q i t ecou and q i t ecol are discharge flow upper and lower limits of the suitable ecological flow of the i th ecological control section in the t th period m is the total number of ecological control sections 2 2 2 minimizing ecological change degree in order to better describe the ecological changes minimizing ecological change degree is proposed to quantify ecological objective from perspective of day based on indicators of hydrologic alteration iha richter et al 1996 poff et al 1997 and range of variability approach rva richter et al 1997 32 ihas are shown in table 1 a set of statistics a j 1 a j 2 a j t h can be obtained for each iha a j by evaluating the historical flow data of the ecological control section where a j represents the j th iha and th represents the number of historical years the mean a j and standard deviation σ a j of statistics for each iha can be further obtained the upper and lower limits of each iha are recommended in the rva richter et al 1997 as the one σ a j interval boundary 5 a j min a j σ a j a j max a j σ a j based on iha and rva minimizing ecological change degree is defined as follows 6 min f 3 min c eco min i 1 m j 1 32 c eco i j 7 c eco i j a i j a i j max a i j max a i j min a i j a i j max a i j min a i j a i j max a i j min a i j a i j min where c eco is the total ecological change degree c eco i j is the j th iha ecological change degree of i th ecological control section a i j a i j max and a i j min are j th iha value upper and lower limits of i th ecological control section m is the total number of ecological control sections 2 3 navigation objective in this study the navigation capacity is measured by normalizing the quantity and tonnage of the vessel the relationship between the discharge flow and the navigation capacity can be obtained by statistical historical navigation data in the historical data the navigation capacity under the discharge flow that can pass the largest quantity and tonnage of vessels is set to one the navigation capacity under the discharge flow that does not open the navigation channel is set to zero schematic diagram of the relationship between the discharge flow and the navigation capacity is shown in fig 1 when q x is less than q min x or greater than q max x the navigation channel is closed and the navigation capability nc is zero because of safety when q x is equal to q min x navigation is allowed and as q x increases nc also increases when q x increases in the interval q 1 x q 2 x nc reaches the maximum value and nc does not change with the change of q x when q x exceeds q 2 x nc decreases as q x increases 8 max f 4 max n c m a x 1 p 1 t i 1 p t 1 t n c i t where n c i t is the navigation capacity of the i th navigation control section in the t th period p is the total number of navigation control sections 2 4 constraints 2 4 1 constraint details 1 water level constraints 9 z i t min z i t z i t max where z i t is the water level of the i th reservoir in t th period which is also the decision variable of the optimization problem z i t min and z i t max are the lower and upper limits of water level of i th reservoir in t th period 2 flow constraints 10 q i t min q i t q i t max where q i t is the discharge flow of i th reservoir in t th period q i t min and q i t max are the lower and upper limits of discharge flow of i th reservoir in t th period 3 output constraints 11 n i t min n i t n i t max where n i t is the output of i th reservoir in t th period n i t min and n i t max are the lower and upper limits of output of i th reservoir in t th period 4 water balance equation 12 v i t 1 v i t i i t q i t e v i t δ t where v i t and v i t 1 are the initial and final storage capacity of the i th reservoir in t th period i i t is the incoming flow of i th reservoir in t th period calculated by the hydraulic connection between cascade reservoirs q i t is the outgoing flow of i th reservoir in t th period which is the sum of the power generation flow denoted by q i t f and the abandoned water flow denoted by q i t s e v i t is the system losses such as evaporation 5 hydraulic connection between cascade reservoirs 13 i i t q i 1 t τ i 1 q i t where i i t is the incoming flow of i th reservoir in t th period and q i 1 t τ i 1 is the outgoing flow of i 1 th reservoir τ i 1 is the time lag of water flow from i 1 th reservoir to i th reservoir q i t stands for the interval inflow of i th reservoir in t th period 2 4 2 constraint handling constraints can be divided into two types equality constraints and inequality constraints in this paper the equality constraints are processed in the propagation of reservoir operation calculation such as water balance equation and hydraulic connection between cascade reservoirs inequality constraints are processed in the domination relationship comparison such as water level constraints flow constraints and output constraints the degree of constraint violation is defined in the domination relationship comparison 14 dcv c c max c max c min c c max c min c c max c min c c min where dcv is the degree of constraint violation c represents the value of the any constraint c max and c min are the corresponding upper and lower limits in the search process of the evolutionary algorithm it is need to find an operation solution with a dcv value of zero 3 improved multi objective moth flame optimization algorithm based on r domination 3 1 review of mfo the mfo algorithm is an intelligent optimization algorithm inspired by the horizontal positioning mechanism of the moths in flight mirjalili 2015 moths are always positioned at an angle to the light when flying at night in ancient times because there are not so many point light sources and the moonlight can be approximated as parallel light on the earth the moths can achieve a linear flight by being at an angle to the moonlight as shown in fig 2 b however in modern times due to the increase of the number of point light sources the moth still flies at a certain angle with the light and its flight path will form a spiral line which will cause the moth to hit the point light source as shown in fig 2 a the original mfo algorithm has two populations one is the moth population denoted by m that represents the most common population in all evolutionary algorithms and the other is the flame population denoted by f that represents a better population of all moths moth individuals are updated using the spiral formula centered on flame individuals when the current moth individual is superior to the current flame individual the flame individual is replaced with the moth individual the spiral update function is shown as follows 15 m ij d ij e bt cos 2 π t f ij d ij f ij m ij where m ij and m ij are the j th decision variable of the i th moth population before and after the update respectively f ij is the flame population d ij is distance between flame population and moth population parameter t is a random number between 1 and 1 the value of parameter b is usually set to one more detailed implementation steps can be found in the paper mirjalili 2015 it has been shown in the literature zhang et al 2016 that the ability of mfo to avoid stalling in the local optima is not strong enough also as evidenced by the experiments in section 4 in the spiral update formula of the original mfo algorithm the center of the spiral is the flame population f however if the moth individual is not updated to a better position than the flame individual the spiral center will remain unchanged which makes it difficult to jump out of local optimum in addition the flame individual only records the historical optimal solution of its corresponding moth individual and the update of the moth individual is always based on its corresponding flame individual in other words there is no communication between the moth individuals which will make it easy to fall into local optimum 3 2 improved mfo algorithm imfo 1 improvement of the update formula the update formula of imfo is similar to the original mfo but there are three changes in the details first the center of the spiral is replaced with the mean of the moth individual and the flame individual since the moth individual changes at each iteration the center of the spiral will also change which helps to avoid stalling in the local optima then the distance influence parameter c between the moth individual and the flame individual are also improved there is no theoretical derivation and support for the calculation formula of c but it is obtained by many experiments and tried many times more than ten kinds of alternative formulas were listed preliminarily in the experiments and the parameters of each alternative formula were determined by the classic single objective benchmark functions liang et al 2005 finally the absolute sign of the distance between the flame individual and moth individual is removed since the value of c is a positive number if d ij is limited to a positive number this will lose half the probability the improved update formulas are as follows 16 m ij f ij m ij 2 0 5 d ij c d ij f ij m ij 17 c tanh 1 b t 1 t a n h 1 b t r a n d 0 1 1 tanh 3 b t a n h 3 b t t r a n d 1 2 where t is a random number between 0 and 2 b is a constant and usually set to 1 c is the distance influence parameter 2 inspiration of moth linear flight path the original mfo algorithm only considered the spiral flight path not the linear flight path in order to inspire a linear flight path a new population is created which is moon population denoted by m o in single objective imfo algorithm m o can be the optimal solution for all individuals in multi objective imfo algorithm m o can be an external archive set maintained by a certain strategy in the real world moths are affected more by the point light than the moonlight so the moon population assists in updating the moth individual with a small probability the updated formula is a linear formula as shown below 18 m ij m ij m o rj 2 where m ij represents the j th decision variable of the i th moth individual while m o rj represents the j th decision variable of the r th moon individual r means randomly selecting an individual from the moon population since moon population m o represents the optimal solution set in the entire search process the introduction of m o can speed up the convergence 3 improvement of flame population update strategy in the single objective algorithm the newly generated moth individual and its corresponding flame individual can directly determine the pros and cons by comparing the objective value thereby whether to replace the flame individual with the newly generated moth individual however in the multi objective algorithm relying solely on the objective values may not be able to determine the pros and cons because there may be the situation in which two individuals do not dominate each other if the flame individual is dominated by the newly generated moth individual the former is replaced by the latter if the newly generated moth individual is dominated by the flame individual the flame individual is not changed if the two do not dominate each other randomly select one from the moon population to replace the current flame individual this improvement not only preserves the newly created superior individuals but also enhances the communication between individuals which is beneficial for improving the convergence speed and to avoid falling into the local optima the pseudocode of imfo is shown in appendix 2 3 3 new domination relationship r domination the solution a is said to pareto dominate the solution b denoted by a b if one of the following conditions is true 1 a is a feasible solution and b is not 2 both a and b are infeasible solutions and a violates constraints less than b 3 both a and b are feasible solutions at the same time a is not worse than b in all objective dimensions and superior to b in at least one objective dimension obviously when the objective dimension is increased the above three conditions are difficult to achieve more and more individuals are not dominated by each other which greatly increases the selection pressure of non dominated sorting methods the r domination relationship is proposed to deal with this situation the individual a is said to r dominate the individual b denoted by a r b if one of the following two situations occurs 1 a pareto dominates b 2 a and b can not be pareto dominated by each other and the r value of a is smaller than b r value is a measure of the degree of association between individual and reference point whose calculation method is shown below the reference points are a set of points uniformly distributed in the hyperplane its generation method and properties are the same as those in the moea d zhang and li 2007 and nsgaiii deb and jain 2014 19 r p o r d e r p d p where r p is the r value of individual p dp is the vertical distance from the individual p to the reference line order p is the order number of individual p in its associative reference points in ascending order of dp the schematic diagram of r domination relationship is shown in fig 3 where r1 and r2 are reference points a b c d and e are individuals individual a b and c are associated with r1 while individual d and e are associated with r2 it is assumed that d4 d2 d1 d5 d3 in ordinary pareto domination relationship the individual a b c d and e cannot dominate other individuals and their priorities are the same but in r domination they need to further calculate r value r a 2 d 1 r b 1 d 2 r c 3 d 3 r d 1 d 4 r e 2 d 5 and r value in ascending order is r d r b r a r e r c so their r domination relationship is d r b r a r e r c since it is almost impossible to equalize the dp of two individuals all individuals in r domination can be distinguished furthermore r domination sorting method is proposed which still adopts the non dominated sorting framework deb et al 2002a the difference is that in the non dominated sorting method individuals in the same rank cannot distinguish priorities but in the r domination sorting method r value is used to distinguish priorities the r domination sorting method follows two principles one is that for individuals with different ranks individuals with lower rank are superior to individuals with higher rank another is that for individuals with the same rank individuals with smaller r value are superior to those with larger r value if the five individuals in fig 3 can only have two individuals entering the next generation individual d and b will be lift according to r domination sorting method visual inspection can verify that the solution set obtained by the r domination sorting method in this case is the best distributed 3 4 framework of r imomfo the complete steps of the r imomfo algorithm are shown in the pseudocodes algorithm 2 is the overall framework of the r imomfo algorithm there are several important functions in algorithm 2 including imfo normalize associate r value their pseudocodes are shown in appendix 2 the function normalize and associate are the same as that of nsgaiii deb and jain 2014 3 5 advantages of r imomfo 3 5 1 convergence the convergence performance of r imomfo mainly comes from the improvement of evolutionary algorithm it overcomes the local optimization and accelerates convergence from the following four aspects 1 the center of the spiral is adjusted to be dynamic which ensures vitality in the evolutionary process and helps avoid local optima 2 the absolute sign of the distance between the flame individual and moth individual is removed which doubles the possibility of finding a better solution 3 the introduction of moon population can speed up the convergence since it represents the optimal solution set in the entire search process 4 improvement of flame population update strategy not only preserves the newly created superior individuals but also enhances the communication between individuals which is beneficial for improving the convergence speed and to avoid falling into the local optima 3 5 2 distribution the distribution performance of r imomfo mainly comes from the improvement of domination relationship r domination further compares the quality of non inferior solutions by reference points on the basis of ordinary pareto domination since reference points are a set of evenly distributed points generated in the objective space individuals screened by r domination sorting method will have a good distribution specifically in the following two aspects 1 due to order p in the r value calculation method it can guaranteed that at least one individual of each associated reference point is retained in the next generation 2 due to dp in the r value calculation method it can guaranteed that the closer the individual is to the vertical line the more likely it is to enter the next generation 4 performance test 4 1 benchmark function in order to test performance of proposed algorithm two famous benchmark functions that are deb thiele laumanns zitzler dtlz deb et al 2002b and walking fish group wfg huband et al 2006 are involved in the experiments these benchmark functions cover linear multi modal concave biased scaled and non separable features which can be used to test the performance of the algorithm comprehensively huband et al 2006 in order to compare with the existing research results deb and jain 2014 yuan et al 2016 dtlz1 4 dtlz7 and wfg1 9 are considered in the experiments the objective dimension and decision variable dimension of all these functions can be any non negative number the number of objectives o of all functions is set as 3 5 8 10 for dtlz1 4 and dtlz7 the total number of decision variables is given by d o k 1 k is set to 5 for dtlz1 10 for dtlz2 4 and 20 for dtlz7 as recommended in deb and jain 2014 and deb et al 2002b as for all wfg problems the number of decision variables d is set to 24 and position related parameter is set to o 1 according to the papers hernandez gomez and coello coello 2013 huband et al 2006 4 2 evaluation metric 1 inverted generational distance igd the inverted generational distance igd is one of the most widely used metrics which can simultaneously evaluate the convergence and distribution of a solution set zitzler et al 2003 a set of uniformly distributed points among the known pareto front pf is required to calculate igd as follows 20 igd a v 1 v i 1 v min f a d v i f for each reference direction λ i the targeted point v i on the known pf can be located all n targeted points constitute the set v v 1 v 2 v n symbol a represents for the points of solution set obtained by specific algorithm in the objective space d v i f is the euclidean distance between the points v i and f the smaller the igd values the better the set a 2 hypervolume hv the hypervolume hv is another popular metrics which also can simultaneously measure the convergence and distribution of a solution set zitzler and thiele 1999 hv s strong theoretical characteristics make it a very fair metric zitzler et al 2003 hv is defined as follows 21 hv a r v o l u m e f a f 1 r 1 f m r m symbol a is the same as mentioned before symbol r r 1 r 2 r m t is a reference point in the objective space which is dominated by any point in the set a hv of a with regard to r is the volume of the region dominated by a and bounded by r the larger the hv values the better the set a 4 3 experimental design in order to compare the effects of imfo and r domination sorting method respectively different evolutionary algorithms ga mfo imfo and different multi objective mechanisms framework of nsgaiii r domination sorting method are combined to obtain the following algorithms r imomfo r momfo r moga nsimfoiii nsmfoiii and nsgaiii in addition moea d θ dea yuan et al 2016 dmopso zapotecas martínez and coello coello 2011 and an existing improved mfo algorithm taher et al 2018 with r domination r imfo participate in the comparison for ease of expression iii mechanism is shorthand for the framework of nsgaiii and r mechanism is shorthand for the r domination sorting method parameter settings of ten algorithms are shown in table 2 iteration numbers of all benchmark functions are shown in table 3 in order to ensure the fairness of the verification and to utilize the existing results the settings of all parameters without bold fonts are the same as those in the paper yuan et al 2016 the setting of the parameter b in mfo and imfo is to first preset some values 0 5 1 1 5 2 then test the performance of benchmark functions under these values respectively and finally determine by comprehensive comparison in addition each algorithm runs 20 times in each benchmark function to avoid randomness 4 4 experimental results best median and worst igd values obtained by ten algorithms on six benchmark functions are shown in table 4 the average hv values obtained by ten algorithms on dtlz and wfg benchmark functions are shown in tables 5 and 6 respectively the best and second best results for each row in these three tables are highlighted with dark and light gray background respectively 1 first of all in order to compare the performance of imfo proposed in this paper and mfo metrics of r imomfo r momfo and nsimfoiii nsmfoiii should be extracted for analysis regardless of whether it is on r mechanism or iii mechanism imfo has all the metrics better than mfo on all benchmark functions which shows that the improvements of imfo is very effective 2 furthermore in order to compare the performance of imfo proposed in this paper an existing imfo and ga metrics of r imomfo r imfo r moga and nsimfoiii nsgaiii should be extracted on r mechanism r imomfo s 45 igd values are better than r moga among total 72 igd values expressed by r imomfo 45 72 igd r moga r imomfo 72 72 igd r imfo r imomfo 44 56 hv r moga and r imomfo 56 56 hv r imfo on iii mechanism the comparison results are nsimfoiii 70 72 igd nsgaiii and nsimfoiii 42 56 hv nsgaiii these verification results show that imfo proposed in this paper is also very competitive compared with ga and an existing imfo 3 then in order to compare the performance of r mechanism and iii mechanism metrics of r imomfo nsimfoiii and r moga nsgaiii should be extracted for analysis in the mfo the comparison results are r 51 72 igd i i i and r 43 56 hv i i i in the ga the comparison results are r 68 72 igd i i i and r 37 56 hv i i i these verification results show that r mechanism is superior to the iii mechanism in most cases 4 next in order to compare the performance of r imomfo proposed in this paper and other multi objective mechanisms and swarm intelligent optimization algorithm metrics of r imomfo moea d θ dea dmopso are extracted for analysis the comparison results are r imomfo 64 72 igd moea d r imomfo 57 72 igd θ dea r imomfo 67 72 igd dmopso r imomfo 54 56 hv moea d r imomfo 47 56 hv θ dea r imomfo 56 56 hv dmopso these verification results show that r imomfo is very competitive compared with these existing multi objective evolutionary algorithm 5 finally the ten algorithms are put together for overall comparison by observing the dark background in these tables it can be known that r imomfo is generally optimal among the ten algorithms in the benchmark functions 5 case study 5 1 description of the case 1 the object selected for the case study is the lancang basin that is one of the largest basin in southwest china the topological structure of the cascade reservoirs in the case is shown in fig 4 the xiaowan manwan dachaoshan nuozhadu and jinghong hydropower stations in the lower reaches of the lancang river are selected in this case for joint operation the entire basin s main goal is to generate power taking into account ecological and navigation objectives the model established in this case have four objectives that are described in sections 2 1 2 2 1 and 2 3 the constraints of the model is introduced in section 2 4 the five sections are all ecological control sections and jinghong is a navigation control section the reservoir features of the cascade reservoirs in the lancang river are shown in table 7 in this case data from the lancang river in 2000 is used a period is one month the decision variables are the upstream water level of the five reservoirs at 13 moments parameter settings of ten algorithms in the case study are shown in table 8 each algorithm runs 20 times the iteration numbers of each algorithm is set to 5000 in this case there are six tasks to complete as shown below 1 compare ten algorithms on the complex actual reservoir operation problem by hv metric 2 visualization of the pareto front of the case 3 explore the relationships between the objectives in the case 4 compare the water level change process of different solutions 5 analyze the reason for the relationship between power generation and ecological objective and 6 analyze the reason for the relationship between power generation and navigation objective 5 2 results and discussion of the case 1 5 2 1 evaluation metrics in the case 1 the calculation of igd needs to know the true pf however true pf of actual problem is almost impossible to get therefore igd cannot be computed to evaluate the performance of the ten algorithms in this case the accurate hv requires extreme points of the true pf in each objective dimension for normalizing the solution set strictly speaking hv is also incalculable in actual cases however the exact value of hv in this study is not what we care about but the relative order of hv obtained by each algorithm is what we really care about regardless of which algorithm is used as the standard their relative order does not change therefore the extreme points of the solution set obtained by nsgaiii in each objective dimension are set as a standard to normalize the solution set obtained by the ten algorithms the order of hv calculated by this method can evaluate the relative performance of the ten algorithms in this practical case the average hv values obtained by ten algorithms in the case study are shown in table 9 from the relative order of hv in table 9 hv of r imomfo is the largest in this case which indicates that r imomfo is very powerful when solving the cascade reservoir operation multi objective optimization problem 5 2 2 visualization of the pareto front of the case 1 the visualization of pareto front of high dimensional objective optimization problem greater than 3 d is still a research hotspot in the field of many objective optimization deb and jain 2014 radar figures are used to visualize the pf in this study there are two criteria for evaluating the performance of pf via radar figures 1 the convergence of pf is measured by the range of the objective value on each coordinate axis the wider range and the better objective values on each coordinate axis has better convergence 2 the distribution of pf is measured by the uniformity of each point on the coordinate axis the more uniform the better the distribution the radar figures of pf obtained by r imomfo nsgaiii moea d and θ dea are shown in fig 5 for each radar figure the data uses the corresponding solution set with the highest hv value among the 20 results e n f v eco and nc are the total power generation minimum output of the period ecological deviation water quantity and navigation capacity respectively each line in the radar figure represents a solution 1 convergence the ranges of r imomfo on the four objectives are 822 10 863 62 593 48 816 40 305 47 740 75 and 0 79 0 97 the ranges of θ dea on the four objectives are 837 09 852 79 746 56 795 07 676 51 747 04 and 0 86 0 93 taking the objective dimension of total power generation e as an example one the one hand the best objective value 863 62 of r imomfo is better than the best objective value 852 79 of θ dea on the other hand the range 822 10 863 62 of r imomfo is wider than the range 837 09 852 79 of θ dea which shows that r imomfo converges better than θ dea in the objective dimension e the convergence comparison of other objective dimensions and other algorithms is similar 2 distribution the point distribution of r imomfo on the four axes is significantly more uniform than other algorithms which shows that the distribution of r imomfo is stronger than that of other algorithms 5 2 3 relationship between objectives in the case 1 the solution set with the highest hv value among 20 results obtained by r imomfo is used to explore the relationship between objectives in the case objective projections of the pf obtained by r imomfo are shown in fig 6 1 the relationship between e and n f is not obvious literature shang et al 2018 suggests that the economic benefits of the hydropower station and the stability of the power system are inversely related however the relationship has become less obvious under the influence of ecological objective and navigation objective 1 2 e and v eco are proportional relationship the greater the amount of power generated the greater the damage to the ecology 2 3 e and nc are proportional relationship the greater the amount of power generated the greater the navigation capacity 3 4 v eco and nc are proportional relationship since both v eco and nc are proportional to e and n f v eco and nc are also proportional 5 2 4 analysis of water level change process the solution set with the highest hv value among 20 results obtained by r imomfo is used to analyze the water level change process which explains how the decision variables influence the objectives the upstream water level of the five reservoirs at 13 moments are the decision variables first the 120 solutions are arranged in ascending order of the total power generation then the seven solutions are sampled at equal intervals finally the water level change process of these solutions on five reservoirs is plotted in fig 7 the results can be analyzed as follows 1 the water level of each solution on manwan dachaoshan and jinghong has not changed much in the flood season the water level of these solutions is maintained at the flood control level the water level differences of each solution are mainly reflected in the non flood period and the differences are very small which can be ignored when analyzing the influence of the water level on the objective values 2 the water level process of xiaowan and manwan is the main difference between the various solutions the water level difference of each solution in flood season is much larger than that in non flood period 3 during the flood season of xiaowan and manwan area ⅰ and area ⅱ the average water level from solution 1 to 120 is roughly high to low which means that more water is used for power generation this is why the total power generation from solution 1 to 120 increases in turn 5 2 5 analysis of relationship between power generation and ecological objective in order to analyze the reason for the relationship between the total power generation and ecological objective the discharge flow change process of the solutions obtained by r imomfo is plotted in fig 8 the ecological objective of the discharge flow process line falling into the gray suitable ecological flow interval is optimal the farther away from the gray interval the worse the ecological objective the results can be analyzed as follows 1 the difference in the each solution s discharge flow process of the two ecological control sections of nuozhadu and jinghong is larger than that of the three ecological control sections of xiaowan manwan and dachaoshan the difference of discharge flow process in xiaowan manwan and dachaoshan is very small which can be ignored when analyzing the influence of the discharge flow on the ecological objective 2 in the two ecological control sections of nuozhadu and jinghong the difference in the discharge flow process is mainly reflected in january to may and july to september 3 in january to may and july to september of nuozhadu and jinghong the discharge flow process lines of solution 1 to 120 gradually move away from the gray interval indicating that their ecological objectives are gradually deteriorating this is the reason why the greater the amount of power generated the greater the damage to the ecology 5 2 6 analysis of relationship between power generation and navigation objective in order to analyze the reason for the relationship between power generation and navigation objective the discharge flow process and navigation capacity process of jinghong navigation control section are plotted in fig 9 the discharge flow process of the seven solutions is shown in the lower part of fig 9 the black curve is the relationship curve between the discharge flow and the navigation capacity qx nc the discharge flow process of each solution is transformed into the navigation capacity process through the black curve as shown in the upper part of fig 9 the navigation capabilities of the seven solutions are shown in the histogram in fig 9 the results can be analyzed as follows 1 the difference of the discharge flow process curves of each solution is large and the corresponding navigation capability curve is also different 2 the discharge flow process of the solutions 80 100 and 120 is closer to the gray interval than that of solutions 1 20 40 and 60 which means that the corresponding navigation capacity of the former is larger than that of the latter as can be seen from the histogram the navigation capacity of solutions 1 to 120 is roughly increasing the closer the discharge flow is to the dark gray interval whose discharge flow is located in the interval 1900 2100 the stronger its corresponding navigation capability 5 3 description of the case 2 in order to further test the performance of the algorithm r imomfo and better consider the ecological changes case 2 of the lancang basin is performed in case 2 an operation period is one day and the total operation period is one year the xiaowan hydropower station is selected in this case the model established in this case have four objectives that are described in sections 2 1 2 2 2 and 2 3 the constraints of the model is introduced in section 2 4 xiaowan is an ecological control section and jinghong is a navigation control section in this case data from the lancang river in 2014 is used the decision variables are the upstream water level of xiaowan reservoir at 365 moments parameter settings are the same as case 1 in this case there are four tasks to complete as shown below 1 compare ten algorithms by hv metric in case 2 2 visualize the pareto front in case 2 3 analyze ecological objectives of typical solutions 5 4 results and discussion of case 2 5 4 1 evaluation metrics in case 2 in order to further verify the performance of r imomfo hv metric is also used to test 10 algorithms in case 2 the average hv values obtained by ten algorithms in case 2 are shown in table 10 the hv value of r imomfo is 0 797483 which is the largest among 10 algorithms it shows that the solution set obtained by r imomfo has the best convergence and distribution which again verifies the performance of r imomfo 5 4 2 pareto front of case 2 the pareto front of r imomfo in case 2 is shown in fig 10 the four objective e n f ceco nc ranges in the pareto front are 180 194 0 098 3 919 2 07 2 88 and 0 713 0 771 respectively intuitively the pareto front of r imomfo has a good distribution 5 4 3 analysis of ecological objectives of typical solutions in order to analyze the difference of different ecological objectives iha metrics of two typical solutions are shown in fig 11 in each figure the left five parts are histograms of five groups of iha metrics the upper right corner is the flow process of the ecological control section before and after operation the bottom right corner is a histogram of ecological change degree of iha metrics with descending sort by comparing two typical solutions the following two results can be analyzed 1 in general the difference between the two solutions lies in the difference in the flow process and mainly concentrated in the period 150 to the period 300 2 what the two solutions have in common is that the six iha metrics with the highest ecological change degree are all 1 3 12 29 30 21 however the 29 th and 30 th ecological change degrees of the solution solution 2 with worst ecological objective are significantly larger than the solution solution 1 with optimal ecological objective and the 29 th and 30 th iha metrics are means of all positive and negative differences between consecutive daily values respectively it is precisely because the solution 2 has more volatility between period 150 to 300 than solution 1 resulting in more damage to metrics 29 and 30 which can also be seen visually from the iha diagram on the left 6 conclusions first an optimization operation model considering power generation ecology and navigation for cascade reservoirs is established then the mfo s shortcoming that is easy to fall into the local optimum is pointed out and the reasons are analyzed to overcome this shortcoming imfo is proposed next the shortcoming of the ordinary pareto domination is explained when there are many objective dimensions many solutions cannot dominate each other and the priority between those solutions is lost which makes the non dominated sorting method face huge selection pressure r domination based on reference points is proposed to distinguish those solutions that cannot dominate each other in pareto domination further r domination sorting method is proposed in combination with non dominated sorting method and r domination in order to verify the performance of imfo and r domination sorting method separately different evolutionary algorithms and multi objective mechanisms are combined into five new algorithms r imomfo r momfo r moga nsimfoiii nsmfoiii five new algorithms and five existing algorithms are tested on the dtlz and wfg benchmark functions the test results of hv and igd show the solution set obtained by r imomfo is the best among the ten algorithms in most test functions indicating both imfo and r domination sorting method are very effective finally the ten algorithms are applied to solve the operation model comparing the solution set of the ten algorithms it is verified that the performance of the r imomfo is also the best in practical problems the relationships between the objectives of the operation model are explored by the solution set obtained by r imomfo the reasons for the relationship between power generation and ecological objective navigation objective are explained by analyzing the water level change process and the discharge flow change process of the solution set in the future research work the update formula with better convergence and the domination relationship with stronger distribution can be further explored at the same time it is worthwhile to discuss the performance of the framework proposed in this study in solving more complex reservoir operation problem such as the reservoir operation model of flood control power generation ecology navigation and water supply it is also a future work to use the method of this research to solve the complementary operation of wind solar hydro hybrid system zhang et al 2019a b declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work is supported by the national key r d program of china 2016yfc0402209 the national public research institutes for basic r d operating expenses special project cksf2017061 sz the national natural science foundation of china nos 91647114 51709119 51809098 51579107 91547208 huazhong university of science and technology 2019ygscxcy072 and special thanks are given to the anonymous reviewers and editors for their constructive comments appendix 1 acronym full name ga genetic algorithm pso particle swarm optimization de differential evolution algorithm mfo moth flame optimization algorithm imfo improved moth flame optimization algorithm nsgaⅱ non dominated sorting genetic algorithm ii spea2 strength pareto evolutionary algorithm 2 dmopso multi objective particle swarm optimization algorithm based on decomposition mechanism moea d multiobjective evolutionary algorithm based on decomposition θ dea θ domination evolutionary algorithm r imomfo improved multi objective moth flame optimization algorithm based on r domination r momfo multi objective moth flame optimization algorithm based on r domination r moga multi objective genetic algorithm based on r domination r imfo existing improved mfo algorithm with r domination nsimfoiii non dominated sorting improved multi objective moth flame optimization algorithm iii nsmfoiii non dominated sorting multi objective moth flame optimization algorithm iii nsgaiii non dominated sorting genetic algorithm iii pf pareto front igd inverted generational distance hv hypervolume iha indicators of hydrologic alteration rva range of variability approach appendix 2 the pseudocodes of the proposed method can be downloaded here the pseudocodes of imfo are shown in algorithm 1 algorithm 1 imfo mt ft mo input mt current moth population ft current flame population mo moon population d number of decision variables n size of population output qt offspring population 1 qt ø i 1 2 while qt n 3 current flame individual ft i 4 current moth individual mt i 5 for j 1 d 6 dis ft ij mt ij 7 t random 0 2 b 1 8 if t 1 9 c tanh 1 bt 1 tanh 1 b 10 else 11 c 1 tanh 3 b tanh 3 bt 12 end if 9 pij 0 5 mt ij ft ij 0 5c dis 10 if random 0 1 0 2 11 random choose an individual from mo mor 12 pij 0 5 pij morj 13 end if 14 end for 15 polynomial mutation pi 16 update fi if single objective compare the objective value of pi and fi to take a better solution as fi if multi objective if fi is dominated by pi fi is replaced by pi if pi is dominated by fi fi is not changed if fi and pi do not dominate each other randomly choose an individual mor from moon population to replace fi 17 qt qt pi 18 i i 1 19 end while 20 mo mo qt 21 update mo as mo if single objective mo is the best solution of mo if multi objective mo is maintained from mo by a specific strategy in this paper the specific strategy is r domination sorting method algorithm 2 is the overall framework of the r imomfo algorithm there are several important functions in algorithm 2 including imfo normalize associate r value their pseudocodes are shown in algorithm 1 3 4 5 respectively algorithm 2 generation t of r imomfo procedure input mt current moth population ft current flame population mo moon population zr reference points n size of population output mt 1 next generation of the moth population ft 1 next generation of the flame population mo moon population 1 st ø i 1 2 qt imfo mt ft mo 3 rt mt qt 4 p1 p2 non dominated sorting rt 5 do 6 st st pi 7 i i 1 8 while st n 9 save key rank pl pi 10 if st n then 11 mt 1 st 12 else 13 m t 1 j 1 l 1 p j 14 compute the number of individuals to be chosen from pl k n mt 1 15 normalize st 16 associate st zr 17 calculate r value st zr 18 pl ascending sort by r value 19 m t 1 m t 1 j 1 k p lj 20 end if 21 for j 1 n 22 if mt 1 j is not dominated by ft j then 23 ft 1 j mt 1 j 24 else 25 ft 1 j ft j 26 end if 27 end for algorithm 3 normalize st input st to be normalized population o number of objective functions 1 for i 1 o 2 compute ideal point f i min min f i s s st 3 translate objectives f i s f i s f i min s st 4 compute extreme points yi max of st 5 end for 6 for i 1 o 7 compute intercepts ai according to yi max 8 normalize objectives f i s f i s f i min a i s st 9 end for algorithm 4 associate st zr input st to be associated population zr reference points 1 for each s st 2 for each w zr 3 compute vertical distance d s w s wtsw w 2 4 end for 5 find the reference point zr m for the minimum d 6 associate s with zr m 7 end for algorithm 5 r value st zr input st population zr reference points 1 for i 1 length zr 2 get all individuals associated with z i r pi 3 sort pi by ascending order of vertical distance from individual to z i r 4 for j 1 length pi 5 set pij s r value j dj 6 end for 7 end for 
5909,the river health assessment rha usually concerns multiple criteria including streamflow ecology physical structure water quality and social service functions and evaluation standards formulated by managers as well as groups with different interests conventional multi criteria decision making mcdm models are used to comprehensively evaluate river condition through multiple criteria under deterministic environment in fact uncertainties are always existed in these criteria data since they are correlated with hydrology and water resources system in this work we proposed a stochastic cloud model based mcdm framework for solving rha considering multiple uncertainties in criteria performance values pvs and criteria weights cws the cloud model is allied to describe uncertainty of pvs using numerous drops following normal distribution generated by forward drop generator fdg the minimum deviation principle based aggregated cws are utilized to efficiently quantify uncertainty in cws and reduce conflict between multiple cws sources a novel stochastic multi criteria acceptability analysis smaa is developed coupling with grey correlation analysis gca and topsis the risk information for river evaluation caused by multiple uncertainties are described using quantified decision error risk qder and rank uncertainty degree rud the proposed methodology is verified practicability by applying it to river health evaluation in taihu basin the numerical simulations are conducted to demonstrate superiority and efficiency of novel smaa in comparison with conventional smaa and deterministic mcdm models based on gca and topsis the robustness analysis is implemented to disclose its computation stability and reliability as well as effects of cloud parameters on final mcdm results the results of novel smaa show that it provides river managers with comprehensive river health and risk analysis information assisting them to make highly reliable assessment and adopt effective measures harnessing rivers keywords river health assessment cloud model stochastic multi criteria acceptability analysis grey correlation analysis topsis risk analysis information 1 introduction river is an essential component of surface water which is important ecological and environmental guarantee for regional sustainable development and one of the basic objectives in water resource management pan et al 2015 among ecosystems on the earth however rivers are the most intensively influenced by human activities and the intensity of human activity on river health is becoming stronger moya et al 2011 the significance of a healthy river system lies not only in maintaining the structure and function of ecosystem but also in serving human and society meyer 1997 the comprehensive methods evaluating the river eco system were explored after 1980s norris and thoms 1999 rapport 1989 as a result river health has been widely studied and become valuable evaluation method in river research and management xia et al 2007 the river health assessment rha is usually conducted based on multiple criteria and standards concerning river ecology physical structure hydrologic characteristics and social functions etc these criteria are initially analysed and evaluated by biological methods such as index of biotic integrity ibi and river invertebrate pre diction and classification system rivpacs deng et al 2015 in recent decades mathematical tools are developed such as analytic hierarchy process ahp ramanathan 2001 multivariate statistical analysis mvsa chau and muttil 2007 data envelopment analysis dea zhao et al 2006 grey cloud model gcm yang et al 2019 fuzzy comprehensive assessment fca zhao and yang 2009 artificial neural network ann xie et al 2006 and matter element analysis mea liu and zou 2012 deng et al 2015 pan et al 2015 these methods effectively evaluate river health situation and have obtained numerous achievements however river managers usually face changing and uncertainty environment when they conduct rha work methods summarized above are always limited to deterministic environment where uncertainty factors are ignored or simplified in real world the regional development especially urbanization changes the original functions and structures of river profoundly leading to multiple environmental and ecological problems and associated uncertainties the uncertainties in rha are mainly divided into two aspects 1 the uncertainty of criteria performance values pvs and 2 uncertainty of criteria weights cws for rha in terms of the first aspect pvs are correlated with the hydrologic environmental economic social and ecological data which are inherently uncertain singh 2016 for example the managers evaluate water quality criterion according to monitor data in monitoring stations these data exist deviation derived from instrument errors and monitoring temporary scale since pollutant concentration is variable in real time moreover numerous groups river served may change over time implying that data concerning river health is dynamically changed the cws which are also identified a potential uncertainty source is influenced by subjectivity and fuzziness of expert s judgments resulting in imprecise or uncertain cws zhu et al 2019 furthermore as rivers serve multiple users with respective interest and play role in environmental biological economic and social benefits the emphasis of cws will also exhibit a changing trend for example the social function of river is stressed to assist industrial and urbanized development for a long time however managers or policy makers now attach importance to ecological and biological functions of river recently in order to realize the sustainable development therefore as policy preferences of river health protection change the cws are uncertain and dynamically changeable to some extent the final rha results may not exist obvious difference when taking uncertainties mentioned into account even so neglecting these uncertain factors can be treated as a behaviour of overlooking assessment risk or error as a multi criteria evaluation system associated with uncertainties in pvs and cws rha can be conducted by multi criteria decision making mcdm modelling process the mcdm is fruitful decision making support approach which not only aggregates both quantitative and qualitative data into general index but also identify desirable healthy river involving discrete multiple conflicting criteria shih and ingram 1981 khadam and kaluarachchi 2003 lu et al 2015 since the late 1980s mcdm techniques have attracted much attention and been applied not only to water resources system but also outside the scientific community wan et al 2014 kou et al 2014 wang et al 2016 lu et al 2017 zhu et al 2017 khosravi et al 2019 kanani sadata et al 2019 raei et al 2019 sparrevik et al 2012 proposed stochastic mcda based on outranking algorithms to implement integrative sustainability strategies for sediment management lin et al 2016 improved conventional range of variability approach rva considering order and symmetry to evaluate hydrologic alteration of river systems wang et al 2016 proposed a mcdm model combining grey relational analysis gra techniques for order preference by similarity to an ideal solution topsis and simple additive weighting saw verified applicability of model based on experimental design subagadis et al 2016 developed novel fuzzy stochastic multiple criteria decision making approach for groundwater agricultural system management for assessment of flood management alternatives a spatial probabilistic multi criteria decision making spmcdm framework is developed considering design rainfall uncertainty ahmadisharaf et al 2016 lu et al 2017 proposed a cloud model based mcmd technique with monte carlo simulation for selecting contaminated groundwater remediation strategies zhu et al 2017 developed mcdm model based on topsis and stochastic multi criteria acceptability analysis smaa to explore real time flood control decision making problem under uncertainties ren et al 2018 proposed an inexact interval valued triangular fuzzy based multi attribute preference model ivtf mapm for prioritization of groundwater resources system kanani sadata et al 2019 solved flood susceptibility assessment using geo information system gis based mcdm method these mcdm models have been verified efficiency and reliability on solving decision making problems nevertheless few mcdm models incorporate uncertainties of criteria pvs and cws simultaneously to conduct stochastic mcdm instead most mcdm are constrained under deterministic environment and inputs data the mcdm for rha under uncertain inputs and stochastic environment remains incompletely addressed and it is urgent to develop more effective way to make high reliability evaluation of river situation with quantified assessment error risk caused by uncertainties in this paper a unified framework for stochastic river health mcdm under uncertainties is proposed first we established the multi criteria system for rha to systematically elaborate river health situation from aspects of hydrology water quality biological diversity ecological and environmental suitability physical structure complexity and social services function the criteria are effectively selected to represent not only common attributes of rivers common criteria but also distinct characters distinct criteria between each river then the cloud model is used to describe and quantify uncertainties existed in criteria pvs which can describe the fuzziness and stochasticity of the pvs fully and precisely the minimum deviation principle mdp based cws calculation method is applied to reduce uncertainties and achieve balance and compromise between different cws sources the cws following probability distributions are used to further quantify the uncertainties existed in cws moreover a novel smaa incorporating the grey correlation analysis gca and topsis are developed to better reflect grey characteristic caused by uncertain factors the smaa topsis gca enables to consider uncertainties in pvs and cws simultaneously and output evaluation risk information for rha with two indicators 1 the quantified decision error risk qder and 2 the rank uncertainty degree rud finally total three case studies are conducted to demonstrate superiority of novel smaa model proposed the case study 1 validates model applicability throughout evaluating typical rivers in taihu basin and efficiency of novel smaa is verified by case study 2 in comparison with conventional smaa in case study 3 numerical simulations are conducted to demonstrate superiority of novel smaa compared with mcdm model under deterministic environment and explore effects of different cloud parameters on mcdm results 2 methodology to systematically demonstrate methodology proposed the flowchart of stochastic mcdm framework for rha shown in fig 1 is developed illustrating the multi levels criteria system novel smaa based on cloud model and decision error risk quantification the first sub module elaborates multi levels criteria system establishment process the common and distinct criteria are developed to disclose critical criteria for rha the next sub module demonstrates two sources of uncertainties in rha these uncertainties in pvs and cws are simulated and quantified based on cloud model the novel smaa model incorporating gca and topsis is proposed to provide more feasible and efficient decision and risk information the last sub module contains quantification indices of decision risk caused by multiple uncertainties 2 1 the multi criteria weights acquirement and uncertainty analysis usually the criteria weights cws are obtained combining different types of cws determination methods which are classified into subjective and objective methods these cws determination methods are integrated usually using linear combination coefficient influenced by subjective experiences therefore a novel combination measure is developed based on minimum deviation principle mdp to achieve the balance and compromise between various competing cws determination methods and decision makers by minimizing their deviation based on the mdp the efficient combination coefficient can be obtained to find the optimal combination of different cws types 2 1 1 cws obtained based on mdp let r denotes total cws methods selected and m represents the quantity of evaluation indicators or criteria the criteria weight vector β k can be described as follows 1 β k β k 1 β k 2 β k 3 β km t k 1 2 3 r i 1 m β ki 1 the comprehensive cws model based on mdp is established and shown as follows 2 min w j 1 n k 1 r i 1 m k β ki j β ij 2 s t k 1 r k 1 k 0 k 1 2 r where w denotes the minimum weight deviation between each cws method 1 2 3 r indicates combination coefficient of all cws methods the optimization model can be solved by lagrangian function method the derivative of k k 1 2 3 r components and λ are used to further simplify formula the lagrangian function l λ and simplification form are elaborated as follows 3 l λ j 1 n k 1 r i 1 m k β ki j β ij 2 λ t 1 r t 1 l k i 1 m k β ki 1 β 1 i k β ki 2 β 2 i k β ki r β ri β ki λ 2 0 l k r k i 1 m β ki 2 1 i 1 m β 1 i β ki 2 i 1 m β 2 i β ki r i 1 m β ri β ki λ 2 0 l λ k 1 r k 1 0 where n and λ are intermediate variables during the solving process the simplification forms are multidimensional linear equations containing r 1th unknown numbers the multidimensional linear equations have unique solution vector 1 2 3 r if determinant of coefficient a 0 2 1 2 the cws uncertainty analysis the deterministic cws dcws are obtained based on mdp to effectively reduce deviation of different cws determination measures and resolve conflicts among different cws methods and sources however the subjective and fuzzy judgements from different managers experts and policy makers the mechanism difference between cws methods conflicts between competing criteria and multiple stakeholders and the combination process of various cws types are still potential sources of cws uncertainties zhu et al 2019 to further quantify the uncertainties existed in cws the probability distributions including the normal uniform are considered the cws following normal distribution ncws will satisfy the 95 44 confidence interval principle considering value of cws as mean value and 1 10 of mean value as standard deviation in terms of cws following uniform distribution ucws the upper and lower intervals are defined as 20 in addition decision makers may be unwilling to express their preferences information due to numerous reasons or difficulties at the beginning of decision making process therefore the cws preferences within feasible weight space provided by decision makers are unavailable and this scenario can also be regarded as the extremely uncertain cws 2 2 the cloud model and multi criteria performance values pvs uncertainty 2 2 1 the cloud model review the cloud model is a quantitative and qualitative uncertainty conversion model first proposed in 1995 this model elaborates the fuzziness of a qualitative concept with normal membership function and the stochasticity with normal distribution based on the probability theory and fuzzy set theory qin et al 2011 wang et al 2014a b 2016 it can represent the fuzziness and randomness and their relations of uncertain concepts establishing the mapping quantitative and qualitative relationship yang et al 2019a the cloud model is verified with better applicability and distinct mathematical properties when it is applied to natural social sciences li et al 2004 the cloud model has attracted much attention from academia even more recently involving numerous fields such as risk assessment groundwater management slope stability evaluation and teacher evaluation in higher education zhang et al 2014 2015 wang et al 2015 2019 2020 chang and wang 2016 lu et al 2017 ma et al 2017 chang and wang 2016 proposed mcdm model combining cloud model and decision tree which is applied to teacher evaluation lu et al 2017 develop a cloud model based mcdm model for groundwater management wang et al 2019 conduct risk assessment of water inrush in karst tunnels using based on cloud model the definition and description of cloud model are shown as follows let the u be a domain represented by precise number which is one dimensional or multi dimensional c is defined as qualitative concept in u for an element x u a random number with stable tendency f c x is the certainty degree of x belonging to c each x can be regarded as a cloud drop and distribution of x in the domain u is defined as cloud model the cloud model can not only integrate fuzziness and stochasticity of concept but also describes numerical characteristic and uncertainty of qualitative concept by using numerical characters including the expectation e x entropy e n and hyper entropy h e fig 2 the e x is the most representative and typical cloud droplet the entropy e n denotes the uncertainty measurement of randomness and stochasticity and reveals the correlation between the fuzziness and randomness the scope of cloud droplet is decided by value of e n specifically the larger e n is and the wider scope is shown in fig 2 the hyper entropy h e h e k e n k c o n s tan t is used to measure uncertainty of entropy e n the thickness of cloud drops guo et al 2016 yang et al 2019 wu et al 2016 2 2 2 the pvs uncertainty description based on cloud drop generator cdg usually the criteria for rha and corresponding pvs are shown to river manager or decision makers based on monitoring data under deterministic or fuzzy environment ignoring uncertainties in fact river managers are working in a situation under multiple uncertainties where the pvs they obtained are changed over time and imprecise in terms of water quality criteria the quality levels quantified for each river will suffer an error derived from water quality monitoring instrument and subjective uncertainty caused by monitor the effects of human activities which are nonnegligible factors influencing multiple criteria pvs of rivers are difficult for river managers to respond to in real time moreover numerous hydrologic environment and ecological data which pvs depend on are inherently affected by uncertainties these uncertainties will lead to uncertainties of multiple criteria or attributes when conducting river health work as a result the river health results obtained by solving the multi criteria evaluation model without uncertainties are imprecise and inconvincible therefore it is critical to quantify uncertainties existed in pvs of multiple criteria and explore its effects on final decision results in this work the drops in cloud model which follow normal probability distribution are used to represent variability and uncertainty of pvs the cloud drops are usually generated by the cloud drop generator cdg the cdg can be basically divided into two types 1 the forward drop generator fdg which is used to transform qualitative concept with three numerical characters e x e n h e into multiple cloud drops 2 the backward drop generator bdg transforming a group of cloud drops into the three characters in this work we use the fdg to generate cloud drops of the given cloud numerical characters the basic steps are summarized as follows sun et al 2016 step 1 generate a normal random number e nn with expectation e n and standard deviation h e step 2 thereafter generate a normal random number x as a cloud droplet which is taken e x e nn as expectation and standard deviation respectively step 3 the calculation e nn and x are plugged into formula f e x e x 2 2 e nn 2 to figure up certainty pertain to the qualitative concept c step 4 repeat the step1 2 until the total cloud droplets are generated 2 3 the novel multi criteria decision making mcdm model 2 3 1 the stochastic multicriteria acceptability analysis smaa the stochastic multi criteria acceptability analysis smaa is a set of related models which helps to solve mcdm problem where decision information such as cws pvs are characterized with uncertainty imprecision durbach et al 2014 unlike the conventional framework of dmcdm models smaa explores feasible weight space in order to describe the cws that make each alternative the most preferred one or that would give a certain rank for a specific alternative under circumstance of inadequate decision maker preference information the inverse weight space analysis in smaa can assist decision makers to find the potential preferred solution the advantage of smaa lies in that it can flexibly handle the uncertain imprecise or missing information with suitable probability distributions zhu et al 2019 the smaa has attracted public interests for decade years and extension studies with respect to smaa 2 smaa p smaa ahp are also conducted yang and wang 2018 pelissari et al 2019 durbach et al 2014 from these smaa models the smaa 2 is the most typical and derivation of others to explore stochastic decision making problem let m represents total solutions for selection and n denotes evaluation criteria used by decision makers the criteria weight vector is defined as ω ω 1 ω 2 ω 3 ω n unlike the deterministic mcdm dmcdm the cws in conventional smaa 2 are uncertain and can be quantified using probability distribution in feasible weights space moreover the criteria data of rivers are mapped to additive utility values according to following real value additive utility function 4 fun u i u v i ω j 1 n v ij ω j 5 w s ω r n j 1 n ω j 1 ω 0 where v ij is the j th criteria pvs of the i th river fun u i is additive utility function which is related with criteria pvs and cws w s denotes the feasible space of cws the main outputs of the smaa 2 model include the rank acceptability index rai i a i r and holistic acceptability index hai i b i h the rai is calculated as multidimensional integral over distribution of cv and favorable rank weight this index aims to measure a group of different preferences that grant solution specific rank r in terms of hai it is used to examine overall acceptability of each solution through combining all rank acceptability indices the rai can be obtained by following equations 6 i a i r v f v sv w i r sv f w w d w d s v w i r sv w w r a n k s v i w r where the v denotes corresponding decision matrix v v ij m n w i r sv represents the favorable rank weights to which weight vector belong will promise the i th river with r th rank the hai is calculated as follows 7 i b i h r 1 m r i a i r where m denotes the quantity of solutions r are meta weights which indicate contribution of each rai to the hai in smaa 2 there are three types of meta weights among which the centroid weights are verified more reasonable and effective the hai is responsible to make final decision and select the efficient solution or alternative the bigger the hai is the superiority of corresponding solution is furthermore smaa 2 illustrates the best single vector of preferences of typical solution accepted by decision maker among all weights that can make the solution get the first rank using a central weight vector the central weight vector can be calculated by following equation 8 central w i v f v sv w i r sv w f w w d w d s v i a i r r 1 where central w i denotes central weight that support the i th river to obtain the best rank to demonstrate the probability of a solution getting the first rank based on its central weight vector the confidence factor con p i is used as a quantification measure the confidence factor discloses whether the criteria pvs are sufficiently accurate to discern preferred solution and provides decision maker with confidence level of a solution being the best given suitable cws preference information zhu et al 2016 the con p i is calculated as follows 9 con p i sv v r a n k s v c e n t r a l w i 1 f v sv d s v 2 3 2 the grey correlation analysis gca model the grey system theory is firstly proposed by deng 1989 which extends the views and methods of general system and information theory and cybernetics to abstract systems such as society economy and ecology deng 1989 wen 2003 combining with mathematical methods it can be used to solve the incomplete information system i e the grey system as opposed to black unknown or uncertain and white given information systems grey correlation refers to the uncertain correlation between things or system factors the grey correlation analysis gca is used to analyze and determine the influence degree between factors or contribution quantification of factors to the main behavior based on the microscopic and macroscopic geometric approximation of behavior factor sequence the gca determines the quality grade of samples according to the correlation between the comparison sequence and reference sequence the reference sequence has the best correlation with the largest degree of correlation and quality grade of the sample can be obtained accordingly the principle of gca is simple and it requires fewer original data with more convenient operation making it easier to mine data rules the essential steps of gca model include 1 data sequence determination including reference and comparison sequences 2 building decision matrix 3 calculate ideal and anti ideal schemes 4 calculate grey correlation coefficient gcc and grey correlation degree gcd which is defined as the sum of weighted gcc the grey correlation coefficient gcc is defined as 10 ς 0 i j μ ρ η δ i j ρ η η max i max j δ i i μ min i min j δ i i δ i j x 0 j x i j where ς 0 i j is the grey correlation coefficient δ i j is difference sequence x 0 j denotes the ideal solution in terms of the j th indicator x i j is the i th solution in terms of the j th indicator η and μ maximum and minimum difference in difference sequence respectively and ρ denotes identification coefficient which is distributed in the range of 0 1 the gcc matrix between solution and ideal anti ideal solutions is developed and corresponding gcd of each solution g r i and g r i is calculated as follows 11 ς ς ij m n ς ς ij m n ς ij min v j v ij ρ max v j v ij v j v ij ρ max v j v ij ς ij min v j v ij ρ max v j v ij v j v ij ρ max v j v ij 12 g r i i 1 m weigh t j t ς ij g r i i 1 m weigh t j t ς ij where g r i and g r i represent gcd relating i th solution with ideal and anti ideal solutions respectively ς ij and ς ij are correlation coefficient elements in matrix weigh t j t is the weight of the j th indicator ρ denotes identification coefficient which is distributed in the range of 0 1 the empirical value of ρ is 0 5 usually 2 3 3 the technique for order preference by similarity to ideal solution topsis topsis is well known multicriteria decision making mcdm method based on the concept of ideal and anti ideal points where the best alternative should be one that is closest to the ideal alternative and farthest from anti ideal alternative lai et al 1994 boran et al 2009 yang et al 2019 this method has no strict limitations and requirements in terms of the number of indicators also referred as criteria samples and data it can fully make use of original data with less information loss lei et al 2016 the topsis describes quality of solution river through the closeness degree coefficient cdc which represents the proximity degree between each river and the optimal one the main steps of topsis are elaborated as follows step 1 building a normalized decision matrix and calculating the corresponding weighted matrix according to following equations 13 no r ij x ij i 1 m x ij 14 wv v ij m n v ij ω j x ij i j m n where x ij is the initial value of the j th criterion or attribute in the i th evaluation rivers v ij is the weighted x ij no r ij is the value with normalization step 2 calculate ideal and anti ideal solutions according to the following principle 15 v i v 1 v 2 v n max v ij j ben min v ij j c o s t v i v 1 v 2 v n max v ij j ben min v ij j c o s t where v i and v i are ideal and anti ideal solutions respectively ben and cost are sets corresponding to benefit and cost types of river health attributes step 3 calculate the euclidean distance ed between the criteria pvs and the ideal and anti ideal solutions d i and d i the specific method is shown as follows 16 d i j 1 n v ij v j 2 d i j 1 n v ij v j 2 step 4 calculate close degree clos e i which represents the degree of proximity between each scheme and the optimal one the closeness is obtained by following equation 17 clos e i d i d i d i 2 3 4 the smaa topsis gca model the utility function in smaa 2 can be expanded to many forms making it possible to utilize smaa 2 in conjunction with other dmcdm models in this work the utility function fun u i in conventional smaa is replaced by combined utility function based on topsis and gca the new form of utility function is shown as follows 18 newfun u i f u n t o p s i s g c a v i ω where the topsis g c a v i ω denotes the comprehensive closeness degree function coupling ed topsis model with gcd gca model the new utility additive function is developed by steps as follows step 1 the ed and gcd are merged with dimensionless treatment 19 topgc a i a 1 d i a 2 g r i t o p g c a i a 1 d i a 2 g r i where topgc a i and topgc a i are components of merged equations a 1 and a 2 are usually constant which denote preference degree of topsis and gca step 2 the coupling comprehensive closeness degree ccd ccd v i ω is developed according to following equation the larger value ccd is the better solution or alternatives will be and vice versa 20 ccd v i ω topgc a i topgc a i t o p g c a i the smaa topsis gca model is regarded as an extension of conventional smaa using utility function incorporating gca and topsis it can also be regarded as the stochastic version of topsis gca in order to solve mcdm problems with multiple uncertainties in comparison with conventional smaa the new additive utilization function which aggregates topsis and gca can make full utilization of respective strengths the gca contributes to reflect grey characteristic caused by uncertain factors in river health evaluation meanwhile the topsis can reflect the overall closeness degree between solutions and the optimal one 2 3 5 the risk information for evaluation decision when the pvs and cws are precise river managers can obtain a fixed ranking result by deterministic topsis and gca models as the health situation of each river is available managers can take measures to harness the rivers with worst situation however when we take uncertainty information of the pvs and cws into consideration the rivers evaluated may have indeterministic ranks and possibility to get better or worse one instead of the fixed ranking therefore the risk is existed because that an arbitrary rank is likely to be assigned to each river which will lead to a reversal of the established ranking under extreme situation zhu et al 2019 to this end ranking uncertainty and risk should be evaluated and quantified in order to reduce possibility of erroneous results the quantified decision error risk qder in evaluation decision is defined as follows 21 qder r 2 m β r i a r rfirst β r r r 2 m r where β r represents risk weights to distinguish the contribution of each solution to qder showing risk that a relative inferior solution obtains the best ranking i a r rfirst denotes the acceptability of the first ranking of solution that obtains the r th rank according to hais results for instance one river gets the r th rank except the best rank according to hais however the first ranking acceptability of this river may not be zero m denotes the total number of rivers evaluated in addition the rank uncertainty degree rud zhu et al 2017 is utilized to assess overall ranking uncertainty based on the rais results the rud is calculated by summarizing probabilities that each river obtains the other ranks except for its final rank 22 rud i 1 m r 1 r r f i n a l m i a i r i 1 m r 1 m i a i r i 1 m i a i rfinal m i 1 m i a i rfinal where the rfinal is the final rank of each river according to the hais 2 4 the multi criteria system for river health assessment and decision making 2 4 1 the criteria selection the evaluation criteria for river health selected from authoritative and representative papers are analyzed statistically from multiple aspects including hydrology water resources ecology physical structure water quality and social services function these criteria are integrated and re classified according to aspects such as criteria item criteria definition membership relation calculation measure to effectively select most suitable criteria yang et al 2019a moreover the river health multi criteria system is quite distinct due to unique characters such as river location length runoff functions water environment etc to this end based on existing achievements from academia the key criteria are divided into common and distinct criteria from perspectives of river universality and individuality the common and distinct indicators are interrelated and complementary to each other which contribute to describe river health condition variability trend and multiple hydrologic environmental and social characters 2 4 2 multi levels river health criteria system shan et al and han et al indicate that river health criteria system should follow principles including scientificity pertinence systematisms and operability han 2015 shan et al 2012 in this work the constructed multi levels criteria system is composed of four levels 1 the river health comprehensive assessment index which is defined as the target level 2 the natural environment and social service subsystems which are regarded as the control level 3 the norm level including nine characteristics selected from control level 4 the criteria level containing common and distinct criteria the specific multi levels evaluation criteria system for rha is elaborated in fig 3 3 case study 3 1 deterministic and uncertain multi criteria cws acquirement in this section we select the analytic hierarchy process ahp and improved entropy weights iew yang et al 2019b as the cws determination methods ahp is a systematized and hierarchical technique for complex decision making and subjective weights determination where the qualitative problem is analyzed quantitatively by classifying multiple factors or criteria into an ordered hierarchy of interconnections zhong et al 2019 the entropy and information in iew objective weighting method are used to measure disorder and order degrees respectively the information entropy of criteria discloses information quantity it provides and significance it occupies in real world application we should take both subjectivity and objectivity of cws represented by ahp and iew into consideration to reasonably quantify criteria significance then we applied the mdp to obtain efficient deterministic cws which achieve the balance between two methods and integrate respective advantages the optimal combination of cws obtained based on mdp are shown in following table 1 next the two types of uncertain cws following normal and uniform probability distributions are calculated the specific cws with uncertainty are listed in table 2 3 2 case description and simulation settings the case for rha are selected from taihu basin shown in fig 4 where ten rivers and related lakes water quality monitoring sites are involved these rivers are interrelated and connected with ge lake dongjiu lake and tiahu lake as main carriers of surface water resources these rivers play critical role in maintaining ecosystem health and economic benefits such as cargo shipping and industrial water consumption for example river 6 r6 is crucial riverway and channel of shipping which links up river 1 r1 river 3 r3 river 7 r7 and river 9 r9 it plays a crucial role in regulating the water level of northern and southern rivers in this work we conduct simulations to verify the feasibility and practicability of proposed methodology in the first simulation case study 1 novel smaa topsis gca based on cloud model are demonstrated by assessing health situation of selected case in taihu basin then we conduct comparison analysis to demonstrate the efficiency of the novel model case study 2 the third simulation case study 3 we designed is used to verify the robustness of model proposed 3 3 case study 1 we run the novel smaa topsis gca based on cloud mode with inputs of stochastic decision matrix and cws information the stochastic decision matrix which represents pvs uncertainty is obtained using the fgd to generate drops of given cloud numerical characters the cloud numerical characters of e x e n are determined according to 95 44 confidence principle and h e 0 1 e n total 10 000 drops are generated following normal distribution the decision matrix is shown in table 3 and criteria pvs are normalized in commensurable units 3 3 1 results of smaa topsis gca without cws information at the initial stage of rha the cws information may be unavailable for river managers due to the inadequate information the opinion conflict between experts and unclear policy or standard from policy makers first we run the novel smaa model without providing river managers cws preference instead the model will randomly explore the whole feasible cws space the model is numerically solved based on the 10 000 monte carlo simulations the rank acceptability indices indicating probability or acceptance degree that each river obtains ranks from 1 to 10 are shown in fig 5 the fig 6 presents central weight vectors of rivers in the form of stacked bars according to fig 5 the river 5 r5 should be rejected as river with the best health situation since its rais show larger probabilities of worst ranks ranks 8 10 especially the rank 10 however the rai of rank 1 is zero implying that there is no chance for this river obtaining the best health situation at current stage the r4 r7 r9 and r10 whose rais are larger for excellent ranks before 3 and less for worst ranks are demonstrated more likely to obtain the lead ranks among all rivers assessed the r7 has the largest probability for achieving the first rank while the rais of worst ranks after rank 7 are low indicating that r7 is most likely selected as the preferred healthy river moreover although the r4 has relatively large rai of rank 1 it has nonnegligible probabilities of acquiring the worst ranks such as rank 6 rank7 and rank8 therefore in comparison with r7 r9 and r10 r4 is less likely to be the river with optimal health situation inspect of fig 6 stacked bars show the criteria preferences of rivers implying that river will get the ideal health situation if cws preferences from managers are coincide with its favors the selected multiple criteria are composed of cost type and benefit type for cost type criteria of a river criteria will small values should be assigned with larger weights in order to obtain the best rank on the contrary the benefit type criteria with larger values will be emphasized for example the r5 favors criteria such as c3 c6 c9 and c14 while dislikes the criteria of c2 c4 c8 and c11 the c6 is defined as a cost type criterion and r5 has smaller values of this criterion consequently the weight assigned with c6 is large so that r5 can obtain the best rank similarly as the performance value of c2 in r5 is the worst this criterion is assigned with minimum weight among all rivers although the cws preference information is unavailable the novel smaa model is capable to preliminarily make a discrimination between rivers in terms of their health situation the central weight vectors help managers to clearly aware the problems existed in the river and adopt pointed measures to improve performance of worst criteria 3 3 2 results of smaa topsis gca cws information available in this section the river managers show their cws preference as they obtain adequate information from experts and policy makers to quantify the uncertainty of cws information the cws following normal and uniform probability distributions ncws and ucws are developed based on the given deterministic cws we run the novel smaa topsis gca with inputs of stochastic decision matrix and cws the rank acceptability indices rais under three types of cws are demonstrated in fig 7 the hais and confidence factors are shown in fig 8 the quantified risk information qri and rud are shown in fig 9 according to fig 7 when the specific weighting information is integrated into the model the discrimination degree reflected by rais is higher than that of results based on random weighting information the r7 is the healthiest river with the largest rai for rank 1 while r5 has more than 70 probability of acquiring final rank 10 implying that the r10 faces numerous water body problems and should arise manager s attention unlike the deterministic mcdm models with fixed rank results each river assessed can obtain several ranks with different probabilities because of stochastic uncertainties existed in criteria pvs and cws moreover the rais differences between three types pf deterministic and uncertain cws are minor implying that the rais are insensible with different cws types moreover we can see from fig 9 that ucws have a slightly larger qri and rud than ncws the reason can be summarized that sampled cws in ncws have larger probability for distributing around the mean value than boundary values however ucws have equality of probability for all values in the interval as observed in fig 8 the r7 occupies the largest hai and dominates other rivers in terms of confidence factor if we investigate the inputs of decision matrix in table 3 it is obvious that the r7 outperforms on criteria including c1 c2 c4 c6 c10 and c13 indicating that the river 7 we evaluated is consistent with its situation in real world the water quality criterion c6 cost type criterion for r7 which directly reflect health situation of water body is the minimum among all rivers on the contrary the r5 is inefficient on numerous criteria leading it to obtain the worst rank and urgent to effectively restore to health by adopting practicable measures 3 4 case study 2 in this case we conduct comparison experiments to demonstrate the efficiency of novel smaa model with respect of mcdm problem 3 4 1 the novel smaa versus conventional smaa first the conventional smaa is compared with model proposed the rais hais and confidence factors under three types of deterministic and uncertain cws are shown in figs 10 and 11 respectively in addition the final decision risk information quantified by qder and rud is shown in fig 12 according to figs 10 and 11 the rais and hais of novel smaa indicate that it has larger probability for rivers acquiring respective ranks than that of conventional smaa the ranking information of each river assessed is clear and distinguished for managers to decide however ranking information of rivers based on rais and hais with respect to conventional smaa is unclear especially the r3 r7 and r9 their deviation is so insignificant that managers are difficult to decide the heathiest river leading to greater uncertainties and risk in decision process moreover the fig 12 demonstrates that the final risk information of novel smaa is drastically reduced in comparison with conventional model whether it is from qder or rud in addition the confidence factors cfs of each river obtained by novel model are clearer than that of conventional model for instance cfs of r7 are the highest among all rivers the cfs calculated by novel smaa are bigger implying that r7 has the larger probability of being the healthiest river compared with conventional smaa similarly r1 can be seen as the river which is unlikely to be the healthiest river with help of novel smaa however the cfs of r1 in conventional smaa is about 0 20 indicating that managers cannot exclude r1 to be the best so the above results imply that novel smaa outperforms on reducing assess risk and errors and showing more explicit ranking information to river managers 3 4 2 the novel smaa versus deterministic topsis and gca based model in this section we make a contrast between the novel smaa and deterministic mcdm model based on smaa and gca the probability density curve of ccd obtained by novel smaa and ccds by deterministic model are elaborated in fig 13 the dashed lines and bars denote deterministic ccd and probability density curve of ccd respectively as observed in fig 13 the assessment uncertainty derived from uncertainty of a series of comprehensive closeness degree ccd variables following normal distributions these stochastic variables are valued in a certain range instead of the constant value obtained by deterministic model the superiority of novel smaa model lies in capabilities of providing probability that each river obtains a certain rank based on rais and probabilistic ranking information reflected by possible range of ccd variables moreover the assessment risk information quantified by two indices qder and rud are available when taking uncertainties of cws and criteria pvs into consideration when we apply the deterministic model to assess river health situation risk information is usually unavailable since the function of model is based on deterministic inputs and environment the ccd is constant without showing its dynamic variation within specific range furthermore the difference between several rivers are insignificant such as the r6 and r8 leading to worse discrimination of rivers and unclear ranking information with the heap of novel smaa model river managers can aware the possibility of potential assessment error and risk when they make final decision 3 5 case study 3 in this section we continue to investigate the effect of sampling variability and different cloud parameter on mcdm results first we run the novel smaa model for 10 times with different input variables to examine its reliability and robustness the mcdm results summarized include the rai of the first rank with respect to river which obtains the first rank the corresponding hai and two risk information quantification indicators qedr and rud we conduct the robustness analysis without cws preference and three types of deterministic and uncertain cws the results are obtained by solving the model based on monte carlo simulations as we can see from fig 14 where plots of each analysis indicator are developed the mcdm results are variated within a narrow interval implying that the model proposed is reliable and robust in terms of a group of random inputs for the results in fig 14 a as the cws preference is not designated the model will explore the entire feasible cws space where criteria weights are randomly generated thus the potential decision risk under this scenario is bigger than that of others the decision uncertainty and risk are significantly reduced since cws information is definite and managers preferences are available to help model discriminate rivers more clearly then we design a numerical experiment to investigate effect of cloud parameters on the mcdm results total six group of cloud parameters with different h e h e k e n k c o n s tan t are shown in following table 4 the mcdm results under each parameter scheme are demonstrated in fig 15 according to fig 15 rai of the first rank and hai markedly decrease as the increase of h e which is used to measure uncertainty of entropy e n as shown in fig 2 the increase of h e denotes the increase thickness of cloud drops i e the uncertainty of criteria pvs increases thus the aggravation of pvs uncertainty leads to rai and probability reduction of the first rank for r7 moreover as we expected the quantified risk information qder and rud exhibit an increasing trend with the increase of criteria pvs uncertainties implying that the decision risk intensifies with increasing h e 4 discussion and conclusions the rha work is always influenced by changing environment where numerous uncertain factors or activities make data used to evaluate river situation imprecise or inconvincible conventional mcdm methods are efficient for water resources management including rha under deterministic situation however they are inefficient when uncertainties in criteria pvs and cws are integrated and incapable to reflect risk information existed in decision process to this end we proposed novel systematic mcdm framework for stochastic rha considering multiple uncertainty sources the cloud model which can describe the fuzziness of river health concept with normal membership function and the stochasticity with normal distribution is used to quantify the criteria pvs uncertainty the minimum deviation principle mdp based cws method is developed to effectively aggregate conflicting weight vectors obtained by different cws methods and represent uncertainties in cws then a novel smaa model based on gca and topsis is proposed to take cws and pvs uncertainties into consideration in multi criteria river health assessment modeling process due to the uncertainty effect on final evaluation results we use the quantified decision error risk qder and ranking uncertainty degree rud to show managers potential risk information propagated to decision process a multi criteria system for river health assessment is established based on efficient criteria selection and division into common and distinct criteria groups according to characters of each river the cdg in cloud model generates numerous drops following normal distribution which are defined as criteria pvs inputs of novel smaa model and dcws and two types of uncertainty cws following probability distributions are cws inputs the framework proposed is verified practicability by case study containing ten rivers in taihu basin moreover the other two case studies are conducted to demonstrate efficiency of novel smaa model in comparison with conventional one and its robustness with respect to numerous independent simulations as well as effects of different cloud parameters on evaluation results the conclusions can be reached as follows 1 the cloud model can represent fuzziness and randomness of river health with three numerical characters including e x e n and h e the forward drop generator fdg transforming qualitative concept with three numerical characters e x e n h e into multiple cloud drops which describe uncertainty of criteria pvs effectively furthermore it is easily to combine with existing decision making models due to less parameters to control 2 the conventional mcdm models which show managers with constant ranking information leading to illusion that rank results are credible without any deviation in contrast the novel smaa model we developed can not only provide river managers with probabilities that each river obtains all ranks but also quantified risk information caused by uncertainties in criteria pvs and cws the results remind managers to reexamine reliability of river rankings and make final convincible decision with informed risk in addition the novel smaa helps managers to form a consciousness that risk information should be attached to their decision in order to make comprehensive decision information presented to public 3 unlike single ranking information provided by conventional mcdm the rais of novel smaa display probability or acceptability of all ranks that each river acquires the confidence factors are referred to assist decision with quantified credibility the two risk indicators qder and rud make uncertainty effect propagated from stochastic rha data and cws quantification these results assist managers to make a comprehensive evaluation of current river situation with high reliability 4 when river managers are incapable to show their cws emphasis at initial stage the novel smaa model helps them with preliminary discrimination of river ranking information through exploring feasible criteria weight space although the results are just for reference managers can use central weight vectors of each river to judge their basic situation and locate respective limitations these vectors are meaningful for managers to adopt effective measures to harness rivers 5 as the cws preference information are available novel smaa better discriminate with larger rai and hai among rivers to acquire respective ranks in comparison with conventional smaa the less qder and rud indicate that novel smaa significantly reduce the decision error risk caused by uncertainty factors as a result the final river assessment results are more explicit and reliable than that of conventional one in comparison with deterministic mcdm model based on gca and topsis novel smaa demonstrates clearer ranking information for rivers and provides quantified risk information under uncertain environment moreover the novel smaa can be discern as a new stochastic mcdm model based on gca and topsis since it can handle with uncertainties existed in criteria pvs and cws 6 the robustness analysis in case study 3 shows the better stability of novel smaa with minor deviation in several independent computations the qder and rud drastically reduce under three types of deterministic and uncertain cws compared with no cws preference the results under different cloud parameters indicate that as uncertainty of cloud drops increases both rai and hai significantly decrease while the qder and rud present increasing trend thus we developed an efficient cloud model based smaa technique which provides managers with more intelligent and feasible decision and risk information the novel model is regarded as extension of conventional smaa using utility function incorporating gca and topsis also it can be seen as stochastic type of gca and topsis which is capable to handle mcdm problem involving multiple uncertainties the limitation of novel smaa model lies in solving decision problem where multiple quantitative and qualitative criteria are mixed in comparable manner in addition model is unable to deal with irreversible and catastrophic events for instance suddenly serious pollution event which brings uncontrollable uncertainty credit authorship contribution statement zhe yang conceptualization methodology writing original draft yufeng wang writing review editing resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the first author was supported by a fellowship from the china scholarship council china program id 201806710136 for his visit to the iihr hydroscience and engineering university of iowa c maxwell stanley hydraulics laboratory iowa city usa 
5909,the river health assessment rha usually concerns multiple criteria including streamflow ecology physical structure water quality and social service functions and evaluation standards formulated by managers as well as groups with different interests conventional multi criteria decision making mcdm models are used to comprehensively evaluate river condition through multiple criteria under deterministic environment in fact uncertainties are always existed in these criteria data since they are correlated with hydrology and water resources system in this work we proposed a stochastic cloud model based mcdm framework for solving rha considering multiple uncertainties in criteria performance values pvs and criteria weights cws the cloud model is allied to describe uncertainty of pvs using numerous drops following normal distribution generated by forward drop generator fdg the minimum deviation principle based aggregated cws are utilized to efficiently quantify uncertainty in cws and reduce conflict between multiple cws sources a novel stochastic multi criteria acceptability analysis smaa is developed coupling with grey correlation analysis gca and topsis the risk information for river evaluation caused by multiple uncertainties are described using quantified decision error risk qder and rank uncertainty degree rud the proposed methodology is verified practicability by applying it to river health evaluation in taihu basin the numerical simulations are conducted to demonstrate superiority and efficiency of novel smaa in comparison with conventional smaa and deterministic mcdm models based on gca and topsis the robustness analysis is implemented to disclose its computation stability and reliability as well as effects of cloud parameters on final mcdm results the results of novel smaa show that it provides river managers with comprehensive river health and risk analysis information assisting them to make highly reliable assessment and adopt effective measures harnessing rivers keywords river health assessment cloud model stochastic multi criteria acceptability analysis grey correlation analysis topsis risk analysis information 1 introduction river is an essential component of surface water which is important ecological and environmental guarantee for regional sustainable development and one of the basic objectives in water resource management pan et al 2015 among ecosystems on the earth however rivers are the most intensively influenced by human activities and the intensity of human activity on river health is becoming stronger moya et al 2011 the significance of a healthy river system lies not only in maintaining the structure and function of ecosystem but also in serving human and society meyer 1997 the comprehensive methods evaluating the river eco system were explored after 1980s norris and thoms 1999 rapport 1989 as a result river health has been widely studied and become valuable evaluation method in river research and management xia et al 2007 the river health assessment rha is usually conducted based on multiple criteria and standards concerning river ecology physical structure hydrologic characteristics and social functions etc these criteria are initially analysed and evaluated by biological methods such as index of biotic integrity ibi and river invertebrate pre diction and classification system rivpacs deng et al 2015 in recent decades mathematical tools are developed such as analytic hierarchy process ahp ramanathan 2001 multivariate statistical analysis mvsa chau and muttil 2007 data envelopment analysis dea zhao et al 2006 grey cloud model gcm yang et al 2019 fuzzy comprehensive assessment fca zhao and yang 2009 artificial neural network ann xie et al 2006 and matter element analysis mea liu and zou 2012 deng et al 2015 pan et al 2015 these methods effectively evaluate river health situation and have obtained numerous achievements however river managers usually face changing and uncertainty environment when they conduct rha work methods summarized above are always limited to deterministic environment where uncertainty factors are ignored or simplified in real world the regional development especially urbanization changes the original functions and structures of river profoundly leading to multiple environmental and ecological problems and associated uncertainties the uncertainties in rha are mainly divided into two aspects 1 the uncertainty of criteria performance values pvs and 2 uncertainty of criteria weights cws for rha in terms of the first aspect pvs are correlated with the hydrologic environmental economic social and ecological data which are inherently uncertain singh 2016 for example the managers evaluate water quality criterion according to monitor data in monitoring stations these data exist deviation derived from instrument errors and monitoring temporary scale since pollutant concentration is variable in real time moreover numerous groups river served may change over time implying that data concerning river health is dynamically changed the cws which are also identified a potential uncertainty source is influenced by subjectivity and fuzziness of expert s judgments resulting in imprecise or uncertain cws zhu et al 2019 furthermore as rivers serve multiple users with respective interest and play role in environmental biological economic and social benefits the emphasis of cws will also exhibit a changing trend for example the social function of river is stressed to assist industrial and urbanized development for a long time however managers or policy makers now attach importance to ecological and biological functions of river recently in order to realize the sustainable development therefore as policy preferences of river health protection change the cws are uncertain and dynamically changeable to some extent the final rha results may not exist obvious difference when taking uncertainties mentioned into account even so neglecting these uncertain factors can be treated as a behaviour of overlooking assessment risk or error as a multi criteria evaluation system associated with uncertainties in pvs and cws rha can be conducted by multi criteria decision making mcdm modelling process the mcdm is fruitful decision making support approach which not only aggregates both quantitative and qualitative data into general index but also identify desirable healthy river involving discrete multiple conflicting criteria shih and ingram 1981 khadam and kaluarachchi 2003 lu et al 2015 since the late 1980s mcdm techniques have attracted much attention and been applied not only to water resources system but also outside the scientific community wan et al 2014 kou et al 2014 wang et al 2016 lu et al 2017 zhu et al 2017 khosravi et al 2019 kanani sadata et al 2019 raei et al 2019 sparrevik et al 2012 proposed stochastic mcda based on outranking algorithms to implement integrative sustainability strategies for sediment management lin et al 2016 improved conventional range of variability approach rva considering order and symmetry to evaluate hydrologic alteration of river systems wang et al 2016 proposed a mcdm model combining grey relational analysis gra techniques for order preference by similarity to an ideal solution topsis and simple additive weighting saw verified applicability of model based on experimental design subagadis et al 2016 developed novel fuzzy stochastic multiple criteria decision making approach for groundwater agricultural system management for assessment of flood management alternatives a spatial probabilistic multi criteria decision making spmcdm framework is developed considering design rainfall uncertainty ahmadisharaf et al 2016 lu et al 2017 proposed a cloud model based mcmd technique with monte carlo simulation for selecting contaminated groundwater remediation strategies zhu et al 2017 developed mcdm model based on topsis and stochastic multi criteria acceptability analysis smaa to explore real time flood control decision making problem under uncertainties ren et al 2018 proposed an inexact interval valued triangular fuzzy based multi attribute preference model ivtf mapm for prioritization of groundwater resources system kanani sadata et al 2019 solved flood susceptibility assessment using geo information system gis based mcdm method these mcdm models have been verified efficiency and reliability on solving decision making problems nevertheless few mcdm models incorporate uncertainties of criteria pvs and cws simultaneously to conduct stochastic mcdm instead most mcdm are constrained under deterministic environment and inputs data the mcdm for rha under uncertain inputs and stochastic environment remains incompletely addressed and it is urgent to develop more effective way to make high reliability evaluation of river situation with quantified assessment error risk caused by uncertainties in this paper a unified framework for stochastic river health mcdm under uncertainties is proposed first we established the multi criteria system for rha to systematically elaborate river health situation from aspects of hydrology water quality biological diversity ecological and environmental suitability physical structure complexity and social services function the criteria are effectively selected to represent not only common attributes of rivers common criteria but also distinct characters distinct criteria between each river then the cloud model is used to describe and quantify uncertainties existed in criteria pvs which can describe the fuzziness and stochasticity of the pvs fully and precisely the minimum deviation principle mdp based cws calculation method is applied to reduce uncertainties and achieve balance and compromise between different cws sources the cws following probability distributions are used to further quantify the uncertainties existed in cws moreover a novel smaa incorporating the grey correlation analysis gca and topsis are developed to better reflect grey characteristic caused by uncertain factors the smaa topsis gca enables to consider uncertainties in pvs and cws simultaneously and output evaluation risk information for rha with two indicators 1 the quantified decision error risk qder and 2 the rank uncertainty degree rud finally total three case studies are conducted to demonstrate superiority of novel smaa model proposed the case study 1 validates model applicability throughout evaluating typical rivers in taihu basin and efficiency of novel smaa is verified by case study 2 in comparison with conventional smaa in case study 3 numerical simulations are conducted to demonstrate superiority of novel smaa compared with mcdm model under deterministic environment and explore effects of different cloud parameters on mcdm results 2 methodology to systematically demonstrate methodology proposed the flowchart of stochastic mcdm framework for rha shown in fig 1 is developed illustrating the multi levels criteria system novel smaa based on cloud model and decision error risk quantification the first sub module elaborates multi levels criteria system establishment process the common and distinct criteria are developed to disclose critical criteria for rha the next sub module demonstrates two sources of uncertainties in rha these uncertainties in pvs and cws are simulated and quantified based on cloud model the novel smaa model incorporating gca and topsis is proposed to provide more feasible and efficient decision and risk information the last sub module contains quantification indices of decision risk caused by multiple uncertainties 2 1 the multi criteria weights acquirement and uncertainty analysis usually the criteria weights cws are obtained combining different types of cws determination methods which are classified into subjective and objective methods these cws determination methods are integrated usually using linear combination coefficient influenced by subjective experiences therefore a novel combination measure is developed based on minimum deviation principle mdp to achieve the balance and compromise between various competing cws determination methods and decision makers by minimizing their deviation based on the mdp the efficient combination coefficient can be obtained to find the optimal combination of different cws types 2 1 1 cws obtained based on mdp let r denotes total cws methods selected and m represents the quantity of evaluation indicators or criteria the criteria weight vector β k can be described as follows 1 β k β k 1 β k 2 β k 3 β km t k 1 2 3 r i 1 m β ki 1 the comprehensive cws model based on mdp is established and shown as follows 2 min w j 1 n k 1 r i 1 m k β ki j β ij 2 s t k 1 r k 1 k 0 k 1 2 r where w denotes the minimum weight deviation between each cws method 1 2 3 r indicates combination coefficient of all cws methods the optimization model can be solved by lagrangian function method the derivative of k k 1 2 3 r components and λ are used to further simplify formula the lagrangian function l λ and simplification form are elaborated as follows 3 l λ j 1 n k 1 r i 1 m k β ki j β ij 2 λ t 1 r t 1 l k i 1 m k β ki 1 β 1 i k β ki 2 β 2 i k β ki r β ri β ki λ 2 0 l k r k i 1 m β ki 2 1 i 1 m β 1 i β ki 2 i 1 m β 2 i β ki r i 1 m β ri β ki λ 2 0 l λ k 1 r k 1 0 where n and λ are intermediate variables during the solving process the simplification forms are multidimensional linear equations containing r 1th unknown numbers the multidimensional linear equations have unique solution vector 1 2 3 r if determinant of coefficient a 0 2 1 2 the cws uncertainty analysis the deterministic cws dcws are obtained based on mdp to effectively reduce deviation of different cws determination measures and resolve conflicts among different cws methods and sources however the subjective and fuzzy judgements from different managers experts and policy makers the mechanism difference between cws methods conflicts between competing criteria and multiple stakeholders and the combination process of various cws types are still potential sources of cws uncertainties zhu et al 2019 to further quantify the uncertainties existed in cws the probability distributions including the normal uniform are considered the cws following normal distribution ncws will satisfy the 95 44 confidence interval principle considering value of cws as mean value and 1 10 of mean value as standard deviation in terms of cws following uniform distribution ucws the upper and lower intervals are defined as 20 in addition decision makers may be unwilling to express their preferences information due to numerous reasons or difficulties at the beginning of decision making process therefore the cws preferences within feasible weight space provided by decision makers are unavailable and this scenario can also be regarded as the extremely uncertain cws 2 2 the cloud model and multi criteria performance values pvs uncertainty 2 2 1 the cloud model review the cloud model is a quantitative and qualitative uncertainty conversion model first proposed in 1995 this model elaborates the fuzziness of a qualitative concept with normal membership function and the stochasticity with normal distribution based on the probability theory and fuzzy set theory qin et al 2011 wang et al 2014a b 2016 it can represent the fuzziness and randomness and their relations of uncertain concepts establishing the mapping quantitative and qualitative relationship yang et al 2019a the cloud model is verified with better applicability and distinct mathematical properties when it is applied to natural social sciences li et al 2004 the cloud model has attracted much attention from academia even more recently involving numerous fields such as risk assessment groundwater management slope stability evaluation and teacher evaluation in higher education zhang et al 2014 2015 wang et al 2015 2019 2020 chang and wang 2016 lu et al 2017 ma et al 2017 chang and wang 2016 proposed mcdm model combining cloud model and decision tree which is applied to teacher evaluation lu et al 2017 develop a cloud model based mcdm model for groundwater management wang et al 2019 conduct risk assessment of water inrush in karst tunnels using based on cloud model the definition and description of cloud model are shown as follows let the u be a domain represented by precise number which is one dimensional or multi dimensional c is defined as qualitative concept in u for an element x u a random number with stable tendency f c x is the certainty degree of x belonging to c each x can be regarded as a cloud drop and distribution of x in the domain u is defined as cloud model the cloud model can not only integrate fuzziness and stochasticity of concept but also describes numerical characteristic and uncertainty of qualitative concept by using numerical characters including the expectation e x entropy e n and hyper entropy h e fig 2 the e x is the most representative and typical cloud droplet the entropy e n denotes the uncertainty measurement of randomness and stochasticity and reveals the correlation between the fuzziness and randomness the scope of cloud droplet is decided by value of e n specifically the larger e n is and the wider scope is shown in fig 2 the hyper entropy h e h e k e n k c o n s tan t is used to measure uncertainty of entropy e n the thickness of cloud drops guo et al 2016 yang et al 2019 wu et al 2016 2 2 2 the pvs uncertainty description based on cloud drop generator cdg usually the criteria for rha and corresponding pvs are shown to river manager or decision makers based on monitoring data under deterministic or fuzzy environment ignoring uncertainties in fact river managers are working in a situation under multiple uncertainties where the pvs they obtained are changed over time and imprecise in terms of water quality criteria the quality levels quantified for each river will suffer an error derived from water quality monitoring instrument and subjective uncertainty caused by monitor the effects of human activities which are nonnegligible factors influencing multiple criteria pvs of rivers are difficult for river managers to respond to in real time moreover numerous hydrologic environment and ecological data which pvs depend on are inherently affected by uncertainties these uncertainties will lead to uncertainties of multiple criteria or attributes when conducting river health work as a result the river health results obtained by solving the multi criteria evaluation model without uncertainties are imprecise and inconvincible therefore it is critical to quantify uncertainties existed in pvs of multiple criteria and explore its effects on final decision results in this work the drops in cloud model which follow normal probability distribution are used to represent variability and uncertainty of pvs the cloud drops are usually generated by the cloud drop generator cdg the cdg can be basically divided into two types 1 the forward drop generator fdg which is used to transform qualitative concept with three numerical characters e x e n h e into multiple cloud drops 2 the backward drop generator bdg transforming a group of cloud drops into the three characters in this work we use the fdg to generate cloud drops of the given cloud numerical characters the basic steps are summarized as follows sun et al 2016 step 1 generate a normal random number e nn with expectation e n and standard deviation h e step 2 thereafter generate a normal random number x as a cloud droplet which is taken e x e nn as expectation and standard deviation respectively step 3 the calculation e nn and x are plugged into formula f e x e x 2 2 e nn 2 to figure up certainty pertain to the qualitative concept c step 4 repeat the step1 2 until the total cloud droplets are generated 2 3 the novel multi criteria decision making mcdm model 2 3 1 the stochastic multicriteria acceptability analysis smaa the stochastic multi criteria acceptability analysis smaa is a set of related models which helps to solve mcdm problem where decision information such as cws pvs are characterized with uncertainty imprecision durbach et al 2014 unlike the conventional framework of dmcdm models smaa explores feasible weight space in order to describe the cws that make each alternative the most preferred one or that would give a certain rank for a specific alternative under circumstance of inadequate decision maker preference information the inverse weight space analysis in smaa can assist decision makers to find the potential preferred solution the advantage of smaa lies in that it can flexibly handle the uncertain imprecise or missing information with suitable probability distributions zhu et al 2019 the smaa has attracted public interests for decade years and extension studies with respect to smaa 2 smaa p smaa ahp are also conducted yang and wang 2018 pelissari et al 2019 durbach et al 2014 from these smaa models the smaa 2 is the most typical and derivation of others to explore stochastic decision making problem let m represents total solutions for selection and n denotes evaluation criteria used by decision makers the criteria weight vector is defined as ω ω 1 ω 2 ω 3 ω n unlike the deterministic mcdm dmcdm the cws in conventional smaa 2 are uncertain and can be quantified using probability distribution in feasible weights space moreover the criteria data of rivers are mapped to additive utility values according to following real value additive utility function 4 fun u i u v i ω j 1 n v ij ω j 5 w s ω r n j 1 n ω j 1 ω 0 where v ij is the j th criteria pvs of the i th river fun u i is additive utility function which is related with criteria pvs and cws w s denotes the feasible space of cws the main outputs of the smaa 2 model include the rank acceptability index rai i a i r and holistic acceptability index hai i b i h the rai is calculated as multidimensional integral over distribution of cv and favorable rank weight this index aims to measure a group of different preferences that grant solution specific rank r in terms of hai it is used to examine overall acceptability of each solution through combining all rank acceptability indices the rai can be obtained by following equations 6 i a i r v f v sv w i r sv f w w d w d s v w i r sv w w r a n k s v i w r where the v denotes corresponding decision matrix v v ij m n w i r sv represents the favorable rank weights to which weight vector belong will promise the i th river with r th rank the hai is calculated as follows 7 i b i h r 1 m r i a i r where m denotes the quantity of solutions r are meta weights which indicate contribution of each rai to the hai in smaa 2 there are three types of meta weights among which the centroid weights are verified more reasonable and effective the hai is responsible to make final decision and select the efficient solution or alternative the bigger the hai is the superiority of corresponding solution is furthermore smaa 2 illustrates the best single vector of preferences of typical solution accepted by decision maker among all weights that can make the solution get the first rank using a central weight vector the central weight vector can be calculated by following equation 8 central w i v f v sv w i r sv w f w w d w d s v i a i r r 1 where central w i denotes central weight that support the i th river to obtain the best rank to demonstrate the probability of a solution getting the first rank based on its central weight vector the confidence factor con p i is used as a quantification measure the confidence factor discloses whether the criteria pvs are sufficiently accurate to discern preferred solution and provides decision maker with confidence level of a solution being the best given suitable cws preference information zhu et al 2016 the con p i is calculated as follows 9 con p i sv v r a n k s v c e n t r a l w i 1 f v sv d s v 2 3 2 the grey correlation analysis gca model the grey system theory is firstly proposed by deng 1989 which extends the views and methods of general system and information theory and cybernetics to abstract systems such as society economy and ecology deng 1989 wen 2003 combining with mathematical methods it can be used to solve the incomplete information system i e the grey system as opposed to black unknown or uncertain and white given information systems grey correlation refers to the uncertain correlation between things or system factors the grey correlation analysis gca is used to analyze and determine the influence degree between factors or contribution quantification of factors to the main behavior based on the microscopic and macroscopic geometric approximation of behavior factor sequence the gca determines the quality grade of samples according to the correlation between the comparison sequence and reference sequence the reference sequence has the best correlation with the largest degree of correlation and quality grade of the sample can be obtained accordingly the principle of gca is simple and it requires fewer original data with more convenient operation making it easier to mine data rules the essential steps of gca model include 1 data sequence determination including reference and comparison sequences 2 building decision matrix 3 calculate ideal and anti ideal schemes 4 calculate grey correlation coefficient gcc and grey correlation degree gcd which is defined as the sum of weighted gcc the grey correlation coefficient gcc is defined as 10 ς 0 i j μ ρ η δ i j ρ η η max i max j δ i i μ min i min j δ i i δ i j x 0 j x i j where ς 0 i j is the grey correlation coefficient δ i j is difference sequence x 0 j denotes the ideal solution in terms of the j th indicator x i j is the i th solution in terms of the j th indicator η and μ maximum and minimum difference in difference sequence respectively and ρ denotes identification coefficient which is distributed in the range of 0 1 the gcc matrix between solution and ideal anti ideal solutions is developed and corresponding gcd of each solution g r i and g r i is calculated as follows 11 ς ς ij m n ς ς ij m n ς ij min v j v ij ρ max v j v ij v j v ij ρ max v j v ij ς ij min v j v ij ρ max v j v ij v j v ij ρ max v j v ij 12 g r i i 1 m weigh t j t ς ij g r i i 1 m weigh t j t ς ij where g r i and g r i represent gcd relating i th solution with ideal and anti ideal solutions respectively ς ij and ς ij are correlation coefficient elements in matrix weigh t j t is the weight of the j th indicator ρ denotes identification coefficient which is distributed in the range of 0 1 the empirical value of ρ is 0 5 usually 2 3 3 the technique for order preference by similarity to ideal solution topsis topsis is well known multicriteria decision making mcdm method based on the concept of ideal and anti ideal points where the best alternative should be one that is closest to the ideal alternative and farthest from anti ideal alternative lai et al 1994 boran et al 2009 yang et al 2019 this method has no strict limitations and requirements in terms of the number of indicators also referred as criteria samples and data it can fully make use of original data with less information loss lei et al 2016 the topsis describes quality of solution river through the closeness degree coefficient cdc which represents the proximity degree between each river and the optimal one the main steps of topsis are elaborated as follows step 1 building a normalized decision matrix and calculating the corresponding weighted matrix according to following equations 13 no r ij x ij i 1 m x ij 14 wv v ij m n v ij ω j x ij i j m n where x ij is the initial value of the j th criterion or attribute in the i th evaluation rivers v ij is the weighted x ij no r ij is the value with normalization step 2 calculate ideal and anti ideal solutions according to the following principle 15 v i v 1 v 2 v n max v ij j ben min v ij j c o s t v i v 1 v 2 v n max v ij j ben min v ij j c o s t where v i and v i are ideal and anti ideal solutions respectively ben and cost are sets corresponding to benefit and cost types of river health attributes step 3 calculate the euclidean distance ed between the criteria pvs and the ideal and anti ideal solutions d i and d i the specific method is shown as follows 16 d i j 1 n v ij v j 2 d i j 1 n v ij v j 2 step 4 calculate close degree clos e i which represents the degree of proximity between each scheme and the optimal one the closeness is obtained by following equation 17 clos e i d i d i d i 2 3 4 the smaa topsis gca model the utility function in smaa 2 can be expanded to many forms making it possible to utilize smaa 2 in conjunction with other dmcdm models in this work the utility function fun u i in conventional smaa is replaced by combined utility function based on topsis and gca the new form of utility function is shown as follows 18 newfun u i f u n t o p s i s g c a v i ω where the topsis g c a v i ω denotes the comprehensive closeness degree function coupling ed topsis model with gcd gca model the new utility additive function is developed by steps as follows step 1 the ed and gcd are merged with dimensionless treatment 19 topgc a i a 1 d i a 2 g r i t o p g c a i a 1 d i a 2 g r i where topgc a i and topgc a i are components of merged equations a 1 and a 2 are usually constant which denote preference degree of topsis and gca step 2 the coupling comprehensive closeness degree ccd ccd v i ω is developed according to following equation the larger value ccd is the better solution or alternatives will be and vice versa 20 ccd v i ω topgc a i topgc a i t o p g c a i the smaa topsis gca model is regarded as an extension of conventional smaa using utility function incorporating gca and topsis it can also be regarded as the stochastic version of topsis gca in order to solve mcdm problems with multiple uncertainties in comparison with conventional smaa the new additive utilization function which aggregates topsis and gca can make full utilization of respective strengths the gca contributes to reflect grey characteristic caused by uncertain factors in river health evaluation meanwhile the topsis can reflect the overall closeness degree between solutions and the optimal one 2 3 5 the risk information for evaluation decision when the pvs and cws are precise river managers can obtain a fixed ranking result by deterministic topsis and gca models as the health situation of each river is available managers can take measures to harness the rivers with worst situation however when we take uncertainty information of the pvs and cws into consideration the rivers evaluated may have indeterministic ranks and possibility to get better or worse one instead of the fixed ranking therefore the risk is existed because that an arbitrary rank is likely to be assigned to each river which will lead to a reversal of the established ranking under extreme situation zhu et al 2019 to this end ranking uncertainty and risk should be evaluated and quantified in order to reduce possibility of erroneous results the quantified decision error risk qder in evaluation decision is defined as follows 21 qder r 2 m β r i a r rfirst β r r r 2 m r where β r represents risk weights to distinguish the contribution of each solution to qder showing risk that a relative inferior solution obtains the best ranking i a r rfirst denotes the acceptability of the first ranking of solution that obtains the r th rank according to hais results for instance one river gets the r th rank except the best rank according to hais however the first ranking acceptability of this river may not be zero m denotes the total number of rivers evaluated in addition the rank uncertainty degree rud zhu et al 2017 is utilized to assess overall ranking uncertainty based on the rais results the rud is calculated by summarizing probabilities that each river obtains the other ranks except for its final rank 22 rud i 1 m r 1 r r f i n a l m i a i r i 1 m r 1 m i a i r i 1 m i a i rfinal m i 1 m i a i rfinal where the rfinal is the final rank of each river according to the hais 2 4 the multi criteria system for river health assessment and decision making 2 4 1 the criteria selection the evaluation criteria for river health selected from authoritative and representative papers are analyzed statistically from multiple aspects including hydrology water resources ecology physical structure water quality and social services function these criteria are integrated and re classified according to aspects such as criteria item criteria definition membership relation calculation measure to effectively select most suitable criteria yang et al 2019a moreover the river health multi criteria system is quite distinct due to unique characters such as river location length runoff functions water environment etc to this end based on existing achievements from academia the key criteria are divided into common and distinct criteria from perspectives of river universality and individuality the common and distinct indicators are interrelated and complementary to each other which contribute to describe river health condition variability trend and multiple hydrologic environmental and social characters 2 4 2 multi levels river health criteria system shan et al and han et al indicate that river health criteria system should follow principles including scientificity pertinence systematisms and operability han 2015 shan et al 2012 in this work the constructed multi levels criteria system is composed of four levels 1 the river health comprehensive assessment index which is defined as the target level 2 the natural environment and social service subsystems which are regarded as the control level 3 the norm level including nine characteristics selected from control level 4 the criteria level containing common and distinct criteria the specific multi levels evaluation criteria system for rha is elaborated in fig 3 3 case study 3 1 deterministic and uncertain multi criteria cws acquirement in this section we select the analytic hierarchy process ahp and improved entropy weights iew yang et al 2019b as the cws determination methods ahp is a systematized and hierarchical technique for complex decision making and subjective weights determination where the qualitative problem is analyzed quantitatively by classifying multiple factors or criteria into an ordered hierarchy of interconnections zhong et al 2019 the entropy and information in iew objective weighting method are used to measure disorder and order degrees respectively the information entropy of criteria discloses information quantity it provides and significance it occupies in real world application we should take both subjectivity and objectivity of cws represented by ahp and iew into consideration to reasonably quantify criteria significance then we applied the mdp to obtain efficient deterministic cws which achieve the balance between two methods and integrate respective advantages the optimal combination of cws obtained based on mdp are shown in following table 1 next the two types of uncertain cws following normal and uniform probability distributions are calculated the specific cws with uncertainty are listed in table 2 3 2 case description and simulation settings the case for rha are selected from taihu basin shown in fig 4 where ten rivers and related lakes water quality monitoring sites are involved these rivers are interrelated and connected with ge lake dongjiu lake and tiahu lake as main carriers of surface water resources these rivers play critical role in maintaining ecosystem health and economic benefits such as cargo shipping and industrial water consumption for example river 6 r6 is crucial riverway and channel of shipping which links up river 1 r1 river 3 r3 river 7 r7 and river 9 r9 it plays a crucial role in regulating the water level of northern and southern rivers in this work we conduct simulations to verify the feasibility and practicability of proposed methodology in the first simulation case study 1 novel smaa topsis gca based on cloud model are demonstrated by assessing health situation of selected case in taihu basin then we conduct comparison analysis to demonstrate the efficiency of the novel model case study 2 the third simulation case study 3 we designed is used to verify the robustness of model proposed 3 3 case study 1 we run the novel smaa topsis gca based on cloud mode with inputs of stochastic decision matrix and cws information the stochastic decision matrix which represents pvs uncertainty is obtained using the fgd to generate drops of given cloud numerical characters the cloud numerical characters of e x e n are determined according to 95 44 confidence principle and h e 0 1 e n total 10 000 drops are generated following normal distribution the decision matrix is shown in table 3 and criteria pvs are normalized in commensurable units 3 3 1 results of smaa topsis gca without cws information at the initial stage of rha the cws information may be unavailable for river managers due to the inadequate information the opinion conflict between experts and unclear policy or standard from policy makers first we run the novel smaa model without providing river managers cws preference instead the model will randomly explore the whole feasible cws space the model is numerically solved based on the 10 000 monte carlo simulations the rank acceptability indices indicating probability or acceptance degree that each river obtains ranks from 1 to 10 are shown in fig 5 the fig 6 presents central weight vectors of rivers in the form of stacked bars according to fig 5 the river 5 r5 should be rejected as river with the best health situation since its rais show larger probabilities of worst ranks ranks 8 10 especially the rank 10 however the rai of rank 1 is zero implying that there is no chance for this river obtaining the best health situation at current stage the r4 r7 r9 and r10 whose rais are larger for excellent ranks before 3 and less for worst ranks are demonstrated more likely to obtain the lead ranks among all rivers assessed the r7 has the largest probability for achieving the first rank while the rais of worst ranks after rank 7 are low indicating that r7 is most likely selected as the preferred healthy river moreover although the r4 has relatively large rai of rank 1 it has nonnegligible probabilities of acquiring the worst ranks such as rank 6 rank7 and rank8 therefore in comparison with r7 r9 and r10 r4 is less likely to be the river with optimal health situation inspect of fig 6 stacked bars show the criteria preferences of rivers implying that river will get the ideal health situation if cws preferences from managers are coincide with its favors the selected multiple criteria are composed of cost type and benefit type for cost type criteria of a river criteria will small values should be assigned with larger weights in order to obtain the best rank on the contrary the benefit type criteria with larger values will be emphasized for example the r5 favors criteria such as c3 c6 c9 and c14 while dislikes the criteria of c2 c4 c8 and c11 the c6 is defined as a cost type criterion and r5 has smaller values of this criterion consequently the weight assigned with c6 is large so that r5 can obtain the best rank similarly as the performance value of c2 in r5 is the worst this criterion is assigned with minimum weight among all rivers although the cws preference information is unavailable the novel smaa model is capable to preliminarily make a discrimination between rivers in terms of their health situation the central weight vectors help managers to clearly aware the problems existed in the river and adopt pointed measures to improve performance of worst criteria 3 3 2 results of smaa topsis gca cws information available in this section the river managers show their cws preference as they obtain adequate information from experts and policy makers to quantify the uncertainty of cws information the cws following normal and uniform probability distributions ncws and ucws are developed based on the given deterministic cws we run the novel smaa topsis gca with inputs of stochastic decision matrix and cws the rank acceptability indices rais under three types of cws are demonstrated in fig 7 the hais and confidence factors are shown in fig 8 the quantified risk information qri and rud are shown in fig 9 according to fig 7 when the specific weighting information is integrated into the model the discrimination degree reflected by rais is higher than that of results based on random weighting information the r7 is the healthiest river with the largest rai for rank 1 while r5 has more than 70 probability of acquiring final rank 10 implying that the r10 faces numerous water body problems and should arise manager s attention unlike the deterministic mcdm models with fixed rank results each river assessed can obtain several ranks with different probabilities because of stochastic uncertainties existed in criteria pvs and cws moreover the rais differences between three types pf deterministic and uncertain cws are minor implying that the rais are insensible with different cws types moreover we can see from fig 9 that ucws have a slightly larger qri and rud than ncws the reason can be summarized that sampled cws in ncws have larger probability for distributing around the mean value than boundary values however ucws have equality of probability for all values in the interval as observed in fig 8 the r7 occupies the largest hai and dominates other rivers in terms of confidence factor if we investigate the inputs of decision matrix in table 3 it is obvious that the r7 outperforms on criteria including c1 c2 c4 c6 c10 and c13 indicating that the river 7 we evaluated is consistent with its situation in real world the water quality criterion c6 cost type criterion for r7 which directly reflect health situation of water body is the minimum among all rivers on the contrary the r5 is inefficient on numerous criteria leading it to obtain the worst rank and urgent to effectively restore to health by adopting practicable measures 3 4 case study 2 in this case we conduct comparison experiments to demonstrate the efficiency of novel smaa model with respect of mcdm problem 3 4 1 the novel smaa versus conventional smaa first the conventional smaa is compared with model proposed the rais hais and confidence factors under three types of deterministic and uncertain cws are shown in figs 10 and 11 respectively in addition the final decision risk information quantified by qder and rud is shown in fig 12 according to figs 10 and 11 the rais and hais of novel smaa indicate that it has larger probability for rivers acquiring respective ranks than that of conventional smaa the ranking information of each river assessed is clear and distinguished for managers to decide however ranking information of rivers based on rais and hais with respect to conventional smaa is unclear especially the r3 r7 and r9 their deviation is so insignificant that managers are difficult to decide the heathiest river leading to greater uncertainties and risk in decision process moreover the fig 12 demonstrates that the final risk information of novel smaa is drastically reduced in comparison with conventional model whether it is from qder or rud in addition the confidence factors cfs of each river obtained by novel model are clearer than that of conventional model for instance cfs of r7 are the highest among all rivers the cfs calculated by novel smaa are bigger implying that r7 has the larger probability of being the healthiest river compared with conventional smaa similarly r1 can be seen as the river which is unlikely to be the healthiest river with help of novel smaa however the cfs of r1 in conventional smaa is about 0 20 indicating that managers cannot exclude r1 to be the best so the above results imply that novel smaa outperforms on reducing assess risk and errors and showing more explicit ranking information to river managers 3 4 2 the novel smaa versus deterministic topsis and gca based model in this section we make a contrast between the novel smaa and deterministic mcdm model based on smaa and gca the probability density curve of ccd obtained by novel smaa and ccds by deterministic model are elaborated in fig 13 the dashed lines and bars denote deterministic ccd and probability density curve of ccd respectively as observed in fig 13 the assessment uncertainty derived from uncertainty of a series of comprehensive closeness degree ccd variables following normal distributions these stochastic variables are valued in a certain range instead of the constant value obtained by deterministic model the superiority of novel smaa model lies in capabilities of providing probability that each river obtains a certain rank based on rais and probabilistic ranking information reflected by possible range of ccd variables moreover the assessment risk information quantified by two indices qder and rud are available when taking uncertainties of cws and criteria pvs into consideration when we apply the deterministic model to assess river health situation risk information is usually unavailable since the function of model is based on deterministic inputs and environment the ccd is constant without showing its dynamic variation within specific range furthermore the difference between several rivers are insignificant such as the r6 and r8 leading to worse discrimination of rivers and unclear ranking information with the heap of novel smaa model river managers can aware the possibility of potential assessment error and risk when they make final decision 3 5 case study 3 in this section we continue to investigate the effect of sampling variability and different cloud parameter on mcdm results first we run the novel smaa model for 10 times with different input variables to examine its reliability and robustness the mcdm results summarized include the rai of the first rank with respect to river which obtains the first rank the corresponding hai and two risk information quantification indicators qedr and rud we conduct the robustness analysis without cws preference and three types of deterministic and uncertain cws the results are obtained by solving the model based on monte carlo simulations as we can see from fig 14 where plots of each analysis indicator are developed the mcdm results are variated within a narrow interval implying that the model proposed is reliable and robust in terms of a group of random inputs for the results in fig 14 a as the cws preference is not designated the model will explore the entire feasible cws space where criteria weights are randomly generated thus the potential decision risk under this scenario is bigger than that of others the decision uncertainty and risk are significantly reduced since cws information is definite and managers preferences are available to help model discriminate rivers more clearly then we design a numerical experiment to investigate effect of cloud parameters on the mcdm results total six group of cloud parameters with different h e h e k e n k c o n s tan t are shown in following table 4 the mcdm results under each parameter scheme are demonstrated in fig 15 according to fig 15 rai of the first rank and hai markedly decrease as the increase of h e which is used to measure uncertainty of entropy e n as shown in fig 2 the increase of h e denotes the increase thickness of cloud drops i e the uncertainty of criteria pvs increases thus the aggravation of pvs uncertainty leads to rai and probability reduction of the first rank for r7 moreover as we expected the quantified risk information qder and rud exhibit an increasing trend with the increase of criteria pvs uncertainties implying that the decision risk intensifies with increasing h e 4 discussion and conclusions the rha work is always influenced by changing environment where numerous uncertain factors or activities make data used to evaluate river situation imprecise or inconvincible conventional mcdm methods are efficient for water resources management including rha under deterministic situation however they are inefficient when uncertainties in criteria pvs and cws are integrated and incapable to reflect risk information existed in decision process to this end we proposed novel systematic mcdm framework for stochastic rha considering multiple uncertainty sources the cloud model which can describe the fuzziness of river health concept with normal membership function and the stochasticity with normal distribution is used to quantify the criteria pvs uncertainty the minimum deviation principle mdp based cws method is developed to effectively aggregate conflicting weight vectors obtained by different cws methods and represent uncertainties in cws then a novel smaa model based on gca and topsis is proposed to take cws and pvs uncertainties into consideration in multi criteria river health assessment modeling process due to the uncertainty effect on final evaluation results we use the quantified decision error risk qder and ranking uncertainty degree rud to show managers potential risk information propagated to decision process a multi criteria system for river health assessment is established based on efficient criteria selection and division into common and distinct criteria groups according to characters of each river the cdg in cloud model generates numerous drops following normal distribution which are defined as criteria pvs inputs of novel smaa model and dcws and two types of uncertainty cws following probability distributions are cws inputs the framework proposed is verified practicability by case study containing ten rivers in taihu basin moreover the other two case studies are conducted to demonstrate efficiency of novel smaa model in comparison with conventional one and its robustness with respect to numerous independent simulations as well as effects of different cloud parameters on evaluation results the conclusions can be reached as follows 1 the cloud model can represent fuzziness and randomness of river health with three numerical characters including e x e n and h e the forward drop generator fdg transforming qualitative concept with three numerical characters e x e n h e into multiple cloud drops which describe uncertainty of criteria pvs effectively furthermore it is easily to combine with existing decision making models due to less parameters to control 2 the conventional mcdm models which show managers with constant ranking information leading to illusion that rank results are credible without any deviation in contrast the novel smaa model we developed can not only provide river managers with probabilities that each river obtains all ranks but also quantified risk information caused by uncertainties in criteria pvs and cws the results remind managers to reexamine reliability of river rankings and make final convincible decision with informed risk in addition the novel smaa helps managers to form a consciousness that risk information should be attached to their decision in order to make comprehensive decision information presented to public 3 unlike single ranking information provided by conventional mcdm the rais of novel smaa display probability or acceptability of all ranks that each river acquires the confidence factors are referred to assist decision with quantified credibility the two risk indicators qder and rud make uncertainty effect propagated from stochastic rha data and cws quantification these results assist managers to make a comprehensive evaluation of current river situation with high reliability 4 when river managers are incapable to show their cws emphasis at initial stage the novel smaa model helps them with preliminary discrimination of river ranking information through exploring feasible criteria weight space although the results are just for reference managers can use central weight vectors of each river to judge their basic situation and locate respective limitations these vectors are meaningful for managers to adopt effective measures to harness rivers 5 as the cws preference information are available novel smaa better discriminate with larger rai and hai among rivers to acquire respective ranks in comparison with conventional smaa the less qder and rud indicate that novel smaa significantly reduce the decision error risk caused by uncertainty factors as a result the final river assessment results are more explicit and reliable than that of conventional one in comparison with deterministic mcdm model based on gca and topsis novel smaa demonstrates clearer ranking information for rivers and provides quantified risk information under uncertain environment moreover the novel smaa can be discern as a new stochastic mcdm model based on gca and topsis since it can handle with uncertainties existed in criteria pvs and cws 6 the robustness analysis in case study 3 shows the better stability of novel smaa with minor deviation in several independent computations the qder and rud drastically reduce under three types of deterministic and uncertain cws compared with no cws preference the results under different cloud parameters indicate that as uncertainty of cloud drops increases both rai and hai significantly decrease while the qder and rud present increasing trend thus we developed an efficient cloud model based smaa technique which provides managers with more intelligent and feasible decision and risk information the novel model is regarded as extension of conventional smaa using utility function incorporating gca and topsis also it can be seen as stochastic type of gca and topsis which is capable to handle mcdm problem involving multiple uncertainties the limitation of novel smaa model lies in solving decision problem where multiple quantitative and qualitative criteria are mixed in comparable manner in addition model is unable to deal with irreversible and catastrophic events for instance suddenly serious pollution event which brings uncontrollable uncertainty credit authorship contribution statement zhe yang conceptualization methodology writing original draft yufeng wang writing review editing resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the first author was supported by a fellowship from the china scholarship council china program id 201806710136 for his visit to the iihr hydroscience and engineering university of iowa c maxwell stanley hydraulics laboratory iowa city usa 
