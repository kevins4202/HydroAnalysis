index,text
4360,located in semi arid and arid regions in the world the middle east has always faced water shortage crisis therefore water resources in this area should be studied by accurate methods such as the stable isotope technique the results of the current isotopic study show the effects of the main local temperature and precipitation and regional parameters teleconnection indices on the δ18o values of precipitation and surface water resources across the middle east plotting the values of δ18o vs δ2h in some of the major rivers in the middle east on the local meteoric water lines shows that the surface water resources are dominantly recharged by local precipitation while the deviation observed in some samples is due to evaporation the contributions of various air masses the precipitation events originating from the main air masses in the recharge of the principal rivers have also been studied the results of the mixing models demonstrate that the contributions of various air masses in the recharge of rivers vary significantly across the middle east keywords teleconnection indices middle east precipitation stable isotopes surface water 1 introduction since 1961 when harmon craig published his finding that 18o 16o and 2h h ratios in freshwater are significantly related clark and fritz 1997 craig 1961 many studies have been conducted across the world on water resources and the hydrological cycle using 18o and 2h in cooperation with the world meteorological organization wmo the international atomic energy agency iaea has established numerous precipitation sampling stations called gnip global network of isotopes in precipitation across the world and has investigated the 18o and 2h signatures of precipitation iaea gnip 2018 the gnip stations collect precipitation samples in more than 125 countries across the world iaea gnip 2018 although the gnip stations have numerous advantages such as long period sampling in hundreds of stations and presenting stable isotopic data for many regions there are still some temporal and spatial gaps across the world for instance in the vast area of iran only one gnip station used to exist in tehran while there are no gnip stations in iraq tajikistan turkmenistan armenia azerbaijan georgia qatar etc the 18o and 2h signatures of precipitation are influenced by various small scale local parameters such as the altitudes latitudes temperatures and the amounts of precipitation in the sampling stations and large scale regional parameters such as teleconnection indices heydarizad 2018 the effects of the main local parameters including altitude giustini et al 2016 gonfiantini et al 2001 kumar et al 2010 sun et al 2019 latitude giustini et al 2016 tindall et al 2009 precipitation amount cai et al 2018 huang and wen 2014 kurita et al 2009 lone et al 2019 scholl et al 2009 yang et al 2019 and temperature kohn and welker 2005 sun et al 2019 on the δ18o values of precipitation have been studied earlier the stable isotope ratios are given in delta notation δ which is the relative deviation of the sample from the standard vienna standard mean ocean water vsmow according to eq 1 exemplarily for δ18o 1 δ o 18 s a m p l e o 18 o 16 s a m p l e o 18 o 16 r e f e r e n c e 1 1000 v s v s m o w furthermore the d excess d excess δ2h 8 δ18o dansgaard 1964 has been calculated and applied as a reliable fingerprint to study the characteristics of the moisture sources responsible for precipitation gat et al 1996 gat and carmi 1970 juhlke et al 2019 the precipitation events originating from water bodies with a high relative humidity and a low sea surface temperature sst normally have a moderate to low d excess while the precipitation events originating from water bodies with a low relative humidity and a high sst normally show high d excess values clark and fritz 1997 dansgaard 1964 gat et al 1996 gat and carmi 1970 the effects of large scale regional parameters teleconnection indices on the atmospheric conditions and the δ18o values in precipitation have not been studied adequately in the middle east the dominant climatic teleconnections in this region are the indian ocean dipole iod the el nino southern oscillation enso the north atlantic oscillation nao and the quasi biennial oscillation qbo heydarizad 2018 heydarizad et al 2018 the effects of some of these teleconnection indices on the 18o and 2h signatures of precipitation have been investigated in several studies such as cai et al 2017 deininger et al 2016 gao et al 2018 liu et al 2011 martin et al 2018 tindall et al 2009 yang et al 2016 across the world so far there has been no study considering the simultaneous effects of local and regional parameters on the δ18o values in precipitation the study of the simultaneous effects of local and regional parameters can present a comprehensive view of the parameters which influence the δ18o values in precipitation precipitation has a direct and significant effect on surface water resources the information about the recharge of surface water resources from precipitation and the role of evaporation on surface water resources can be obtained from stable isotope techniques furthermore the calculation of line conditioned excess lc excess index can also present valuable information regarding the intensity of evaporation in the surface water resources the contribution percentage of the main air masses the precipitation events originating from each air mass has also been studied using the simmr package this package was developed by parnell et al 2010 to solve the mixing equations in a bayesian framework the simmr package requires at least three obligatory input parameters to run including the endmember source means the endmember source standard deviation sd and the mixtures the surface water samples in which the contribution of each air mass is calculated furthermore the correction data which are also called trophic enrichment factors and concentration dependence values can also enter the model optionally parnell and inger 2021 as the middle east is an extensive area with large topographic variations as well as various climatic zones local and regional parameters may influence the δ18o and δ2h values of precipitation in this region furthermore the variations observed in the precipitation characteristics definitely influence the characteristics of water resources in this region the aim of the current research was first to study the effects of the local and regional parameters on the 18o and 2h signatures of precipitation in the middle east second the role of precipitation in the recharge of surface water resources was studied using stable isotopes in precipitation and surface water resources the role of evaporation on the surface water resources was studied by calculating the lc excess finally the contribution percentages of the precipitation events originating from each air mass in the recharge of several surface water resources were also studied using mixing models as well as the stable isotopes data of precipitation and surface water resources 2 description and climatology of the study area the middle east is a large geographical area located in southwest asia and northeast africa fig 1 this region is surrounded by the arabian sea and the red sea in the south the black sea and the mediterranean sea in the west the caspian sea in the north and afghanistan and pakistan in the east the middle east is mainly classified as an arid and semi arid region with a 45 year 1970 2015 average annual precipitation of 200 mm it has long and hot summers and mild and wet winters along the mediterranean coast mohebi 2012 precipitation and temperature vary greatly across this region the coastal area of the caspian sea receives more than 1800 mm of annual precipitation alijani 2000 while some desert areas in iran and the kingdom of saudi arabia ksa often receive no precipitation for many years mohebi 2012 summer temperatures are usually as high as 50 c maximum in the deserts of iran ksa and iraq while some regions in the zagros mountains experience very low temperatures about 30 c minimum in winter alijani 2000 mohebi 2012 five main air masses fig 1 affect the middle east during the year the mediterranean air mass medt influences the western and southwestern parts of this region and brings the moisture of the mediterranean sea via the western winds heydarizad et al 2019a the continental polar cp air mass the siberian high pressure system influences the northern and northeastern parts of this region and transfers the moisture of the caspian sea to it the maritime polar mp air mass has an effect on the northern and northwestern parts of this region heydarizad 2018 the continental tropical air mass ct the sudan air mass affects the southern and southwestern parts of this region and brings the moisture of the persian gulf the red sea the arabian sea and the oman sea to it heydarizad 2018 the medt cp mp and ct air masses influence the middle east during the cold and wet periods from november to april while in the dry and warm periods from may to october the southern and southeastern parts of this region are affected by the maritime tropical mt air mass which originates from the indian ocean and the arabian sea heydarizad et al 2019b mohebi 2012 large topographic variations various climatic zones and several air masses which influence the middle east have resulted in very complicated climatic conditions all of these confirm the importance of studying the effects of the local and regional parameters on the precipitation characteristics in this part of the world 3 materials and methods in the current study 26 precipitation sampling stations across the middle east which were mostly from the gnip network except for al raqqa kattan 2008 and amman morad 2015 were chosen the locations of these precipitation sampling stations as well as 12 main rivers in the middle east are shown in fig 1 the spatial distribution maps of δ18o δ2h and d excess over the middle east were developed using the inverse distance weighting idw kriging and spline techniques in the q gis software desktop version 3 14 15 q gis development team 2021 to validate the developed maps and to select the most accurate one the root mean square error rmse was used the rmse is a standard deviation of the residual which is also known as the prediction error in other words the rmse is a measure to demonstrate how concentrated the data around the best fit line are the rmse is calculated using equation 2 2 r m s e i 1 n p r e d i c t e d i a c t u a l i 2 n although developing the spatial distribution maps of δ18o and δ2h values in precipitation can have valuable advantages such as providing data for the regions where sampling is not available it may also have some disadvantages local parameters such as topographic variations have significant and direct effects on the accuracy of the developed maps to study the effects of the local and regional parameters on the stable isotope signatures of precipitation the value of δ18o is normally selected as an indicator yang et al 2019 this is due to this fact that the stable isotope fractionation during secondary evaporation in precipitation is unbalanced and dominantly controlled by kinetic fractionation whenever raindrops experience intense evaporation during precipitation δ18o is more obviously accumulated in the raindrops the liquid phase than the heavy isotope hydrogen δ2h due to molecular weight variations thus δ18o shows more obviously the influence of various local and regional parameters on the stable isotope signatures of precipitation yang et al 2019 the effects of the local parameters such as the precipitation amount latitude altitude and temperature on the values of δ18o in precipitation were studied using an ordinary linear regression model in the second step the effects of the regional parameters the teleconnection indices on the values of δ18o in precipitation were investigated the relationship between the values of δ18o in precipitation and the teleconnection indices including bivariate enso best the southern oscillation index soi nao iod and qbo which affect the middle east heydarizad 2018 was studied an ordinary linear regression method was employed to quantify the relationship between the values of δ18o and the teleconnection indices best soi nao iod and qbo the data of these teleconnection indices are freely available at http www cpc ncep noaa gov noaa 2018a and https www ncdc noaa gov noaa 2018b the statistical analyses in this study were performed using the r programming language r core team 2018 the analytic hierarchy process ahp technique was employed to study the importance and effects of various teleconnection indices on the values of δ18o in precipitation using super decision software version 2 10 0 the ahp is a multi criteria decision making method which has been developed by saaty 1987 this method shows the importance percentage of the parameters the teleconnection indices influencing the values of δ18o in precipitation in several stations across the middle east the ahp technique involves the comparison of parameter pairs within reciprocal matrices ahmad and verma 2018 to compare the parameter pairs a scale which ranges from 1 to 9 and shows the relative importance of the pairs is used table 1 whenever the value ofthe consistency ratio cr is smaller than or equal to 10 the importance of the pairs relative to each other is acceptable otherwise the subjective judgment needs to be significantly revised and a new value should be applied to the comparison matrix ahmad and verma 2018 the ahp technique has numerous applications in many fields of science does not need complete information datasets and a comprehensive procedure to run and solves very difficult problems by dividing them into several smaller parts however it has some shortcomings the most important disadvantage is that ahp is a partially subjective method introducing uncertainties to the evaluation furthermore the ahp technique can be applied only to direct models in which the outputs directly correspond to and depend on the initial input information karthikeyan et al 2016 to study more accurately the climatological parameters influencing the values of δ18o in precipitation the noaa interpolated outgoing longwave radiation olr liebmann and smith 1996 and the total precipitable water tpw kalnay et al 1996 datasets the parts related to the middle east with a spatial horizontal resolution of 2 5 2 5 were used these data were utilized to better understand the relationship between the convective activity and the amount of water potentially available in the atmosphere for precipitation and the variations of the δ18o values in precipitation in addition to olr and tpw atmospheric stability was also studied atmospheric stability is a measure of the atmosphere s tendency to prevent vertical motion in stable atmospheric conditions if a parcel of air is blown upward by an updraft or lifted over a mountain range it will sink down to the earth since it is cooler than the air particles around it this prevents precipitation from taking place to study atmospheric stability ω which is a partial differential equation for the vertical velocity is investigated equation 3 ω d p dt 3 where d dt represents a material derivative positive ω values demonstrate stable atmospheric conditions and descending motions while negative ω values represent instability and ascending motions holton 2004 in the final step the role of precipitation in the recharge of surface water resources was also studied the values of δ18o and δ2h in some of the main rivers in the middle east kashaf pakzad 2000 havasan khalaj amirhosseini 2011 zayandeh zendeh khademi et al 1997 and zohreh mirnejad et al 2011 rivers in iran belevi river in turkey somay altaş et al 2007 al khazir jassas and merker 2015 and euphrates ali and ajeena 2016 rivers in iraq istalef barik ab and logar rivers in afghanistan mack et al 2010 malir layari and indus rivers in pakistan mashiatullah et al 2006 were plotted on the local meteoric water lines lmwls furthermore the deviation of the surface water samples from the lmwl and the effect of evaporation were also studied using the lc excess index equation 4 presented by landwehr and coplen 2006 lc excess δ2h a δ18o b 4 where a and b represent the slope and intercept of the lmwl respectively in this study the authors used the lmwls of the regions near the studied rivers the contribution percentage of the precipitation events originating from each air mass in the recharge of the studied rivers was also investigated firstly using the hybrid single particle lagrangian integrated trajectory model hysplit the precipitation events were classified based on the air masses and the moisture sources that cause them stein et al 2015 the moisture origins of about 290 precipitation events in the middle east were determined by the backward trajectories of the hysplit model then the values of δ18o and δ2h in these precipitation events and their moisture sources obtained from the hysplit model were linked to demonstrate the stable isotope characteristics of the precipitation events originating from the main air masses which influence the middle east furthermore the average values of δ18o and δ2h in the precipitation events originating from each air mass were calculated using the approaches presented in previous studies heydarizad 2018 heydarizad et al 2019a 2019b in the last step the contribution percentage of the precipitation events originating from each air mass in the recharge of the studied rivers was calculated via the stable isotope signatures in precipitation and surface water using the simmr package in r language supplementary file 1 4 results and discussion the spatial distributions of δ18o δ2h and d excess maps were developed using various methods spline kriging and idw calculating the rmse for each map showed the lowest values for the maps developed by idw techniques and confirmed their high accuracy table 2 idw has several advantages such as the ability to predict extreme changes in different terrains such as cliffs and to increase or decrease the number of the sampling points to influence the cell values however it has some disadvantages such as the weakness to predict the values below minimum or above maximum and its low utility in mountainous regions the spatial distribution maps of δ18o δ2h and d excess developed by the idw technique show significant spatial variations in the middle east precipitation fig 2 due to the effects of the local and regional parameters highly enriched δ18o and δ2h values in precipitation were observed in the southern part of the middle east over the persian gulf the oman sea the arabian peninsula and the north of africa however very depleted isotope values were observed over the northern part of the middle east low d excess values were observed over the persian gulf and the southern part of the middle east which was due to the intense evaporation effect on precipitation in these regions clark and fritz 1997 nevertheless high d excess values were mainly observed in the eastern part of the mediterranean sea high d excess values in the precipitation over the eastern part of the mediterranean sea has also been confirmed by previous studies gat et al 1996 gat and carmi 1970 4 1 developing lmwls for the stations in the middle east lmwls were developed for all the studied stations across the middle east using an ordinary linear regression method and their slopes and intercepts are illustrated in supplementary file 2 in most of the stations the lmwls demonstrate lower slopes and intercepts compared to the global meteoric water line gmwl δ2h 8 13 δ18o 10 8 rozanski et al 1993 when the amount of precipitation is low raindrops are more influenced by secondary evaporation enriched isotopes are more accumulated in raindrops due to kinetic fractionation in this case the slope of the lmwl is less than 8 and its intercept demonstrates low values clark and fritz 1997 yang et al 2019 in the southern part of the middle east the stations including bahrain haray khatt wadi al qor jubial fanatir taif al hada qairoon salalah and saiq which receive their precipitation moisture from the persian gulf the arabian sea the oman sea and the red sea mostly demonstrate very low slopes and intercepts compared to the other stations due to the higher temperature lower relative humidity and more evaporation in the karachi station in the southeastern part of the middle east where the roles of the mt air mass and the indian ocean are dominant the lmwl has the high slope of 7 55 while the intercept has the low value of 3 41 vs vsmow the stations located in the western and southwestern parts of the mediterranean sea including adana antalya aaramta bet dagan beirut har kna an prodhromos nicosia soreq and tripoli show approximately the same slopes and intercepts as the lmwls in the lower latitudes in the southern parts of the middle east this is due to the fact that the temperature and the evaporation rate in the mediterranean region are also high however in the adana and antalya stations which are located in higher latitudes and have a lower temperature both the slopes and intercepts of the lmwls increase the prodhromos and beirut stations in the mediterranean region show very low slopes and intercepts the low r2 values calculated for the lmwls may be due to the involuntary machine or human errors in the sampling or analysis of the isotopic data in these stations finally in the stations deeply located in the continents including al raqqa kabul ankara tehran and amman the local climatic and geographical conditions have an important effect on the lmwls the amman station located in lower altitudes in an arid region with a high temperature shows a lower slope than the other stations due to intense evaporation 4 2 studying the effects of the local parameters on the δ18o values in the middle east precipitation the δ18o values in precipitation are under the dominant influence of small scale local parameters the effects of local parameters including altitude latitude temperature and precipitation amount on the δ18o signature of precipitation in the middle east were studied fig 3 the relationship between temperature and δ18o shows the gradient of 0 39 depletion in δ18o per 1 c decrease in temperature this gradient is lower than that of interior canada with the gradient of 0 49 depletion in δ18o per 1 c temperature decrease clark and fritz 1997 however it is higher than those of wallingford in england with the gradient of 0 25 depletion in δ18o per 1 c temperature decrease and greece with the gradient of 0 19 depletion in δ18o per 1 c temperature decrease argiriou and lykoudis 2006 the relationship between the precipitation amount and δ18o in the middle east shows the gradient of 3 6 depletion in δ18o per 100 mm increase in precipitation which is higher than those of the subtropical regions in china with the gradient of 1 depletion in δ18o per 18 2 mm and 6 2 mm increase in precipitation during the dry and wet periods respectively xia 2019 and lhasa in the tibetan plateau with the gradient of 1 depletion in δ18o per 25 mm increase in precipitation yao et al 2013 the relationship between altitude and δ18o demonstrates the gradient of 0 2 depletion in δ18o per 100 m increase in altitude in the middle east this gradient is lower than those of monachyle in scotland with the gradient of 0 34 depletion in δ18o per 100 m increase in altitude during winter darling and talbot 2003 the coast mountains in canada with the gradient of 0 25 depletion in δ18o per 100 m increase in altitude clark et al 1982 and the piedmont region in italy with the gradient of 0 31 depletion in δ18o per 100 m increase in altitude bortolami et al 1978 however this gradient is higher than that of the dohfar region in oman with the gradient of 0 1 depletion in δ18o per 100 m increase in altitude clark et al 1987 finally the relationship between latitude and δ18o in precipitation was studied the relationship between latitude and δ18o in the middle east shows the gradient of 0 4 depletion in δ18o per 1 increase in latitude this gradient is lower than that of the antarctic region with the gradient of 2 0 depletion in δ18o per 1 increase in latitude and that of europe and north america with the gradient of 0 6 depletion in δ18o per 1 increase in latitude clark and fritz 1997 among the various local parameters temperature and the amount of precipitation have significant effects on the stable isotope signatures in precipitation yang et al 2019 supplementary file 3 shows that the variations of temperature have a direct relationship with the values of δ18o and that the amount of precipitation and the values of δ18o are also directly related in the precipitations in the studied stations although the relationship between δ18o and temperature is not totally understood it is normally accepted that this relationship is steady with the decrease of the 18o 16o ratio in moisture since a heavier isotope 18o enters the condensate phase during the adiabatic cooling process dansgaard 1964 gat et al 1996 rozanski et al 1993 the relationship with a low r2 between δ18o and temperature in some of the studied stations indicates that factors other than temperature affect the values of δ18o in precipitation fricke and o neil 1999 the moisture originating from the evaporation of water bodies such as large lakes and the transpiration of moisture by vegetation coverage significantly influence the values of δ18o in precipitation by transferring the moisture back to upper air masses jacob and sonntag 1991 koster et al 1993 salati et al 1979 these phenomena resulted in a weak relationship between temperature and the values of δ18o in precipitation in some of the studied stations and made it difficult to interpret fricke and o neil 1999 in addition to temperature and the amount of precipitation the variations of the olr and tpw values over the middle east were also studied fig 4 the values of olr and tpw had a direct effect on the values of δ18o in precipitation the spatial variations of the olr and the stable isotope signatures of precipitation across the middle east are shown in fig 4 it can be observed that the low tpw and olr values which indicate more cloud coverage and a higher amount of precipitation in the higher latitudes of the middle east are accompanied by depleted isotope values due to the effect of the amount of precipitation the higher the precipitation amount the lower the values of δ18o due to the precipitation amount effect clark 2015 clark and fritz 1997 kurita et al 2009 yang et al 2019 in contrast to the higher latitudes enriched isotope values as well as higher olr and tpw values were observed in the lower latitudes in the southern part of the middle east very stable atmospheric conditions which prevent the movement of air parcels and precipitation are the main reasons for high tpw and olr values in this part of the middle east therefore to study the climatology of this region more accurately the spatial and temporal variations of atmospheric stability ω precipitation amount olr and tpw were also studied fig 5 during the cold and wet period from november to april very unstable atmospheric conditions ω 0 and low olr values indicating enhanced convection and more cloud coverage demonstrate appropriate conditions for precipitation occurrence low tpw values and high precipitation amounts in high latitudes create appropriate conditions for turning atmospheric moisture into precipitation however during the dry period from may to october very stable atmospheric conditions ω 0 and high olr values indicative of suppressed convection and hence less cloud coverage are mainly observed in the low latitudes in the middle east fig 5 in addition during the dry period very high amounts of tpw and low precipitation amounts are observed in the atmosphere confirming that the conditions for precipitation occurrence are not appropriate this large amount of tpw cannot turn into precipitation due to the intense atmospheric stability which prevents precipitation from taking place the intense atmospheric stability has also been confirmed by positive ω values in this period the atmospheric stability during the dry period in the middle east is due to the azores high pressure system which develops over most parts of this region 4 3 studying the effects of the regional parameters on the δ18o values in the middle east precipitation according to the importance intensity and influence domain of each climatic teleconnection in the middle east the four indices of best soi nao iod and qbo were selected the effects of these indices on the stable isotope signatures of precipitation were studied in the eight selected stations including bahrain antalya adana sidi barrani karachi kabul tehran and ankara across the middle east with a long period of stable isotope data supplementary file 4 the ahp technique was employed to show the importance percentage of each studied teleconnection index on the δ18o values in the precipitation in the studied stations table 3 the results showed that in the karachi station the iod had a more important effect than the other teleconnections on the values of δ18o in precipitation this was due to the significant effect of the indian ocean on the characteristics of precipitation in the southern and southeastern parts of asia mashiatullah et al 2006 the indian monsoons have a significant effect on the precipitation regimes in the south and southeast of asia the nao is the dominant teleconnection in the adana and sidi barrani stations this is due to the strong effect of the north atlantic ocean on the characteristics of precipitation in the stations located in the western and northwestern parts of the middle east mainly in the coastal areas of the mediterranean sea the best and soi in the bahrain station and the qbo in the ankara station are the dominant teleconnection indices influencing the values of δ18o in precipitation in the continental stations the situation is to some extent different in the kabul station the role of the iod teleconnection is dominant while the effects of the best and soi indices are significant on the values of δ18o in tehran precipitation the strong effect of the el nino southern oscillation enso on the precipitation events across iran has also been confirmed in previous studies nazemosadat 1999 pourasghar et al 2012 sabziparvar et al 2011 finally in the ankara station the effect of the qbo teleconnection on the values of δ18o in precipitation is stronger than those of the other indices 4 4 studying the effects of precipitation and air masses on the recharge of some of the major rivers in the middle east studying the effect of precipitation on the surface water resources has yielded valuable results plotting the surface water resources the main rivers in the middle east on the lmwls fig 6 shows that the belevi river in turkey is mainly plotted on the ankara lmwl however it shows a small deviation from the mwls of antalya and adana in iran the zayandeh and havasan rivers are mainly plotted on the tehran lmwl while the zohreh and kashaf rivers are plotted over the tehran lmwl this is perhaps due to the effects of the local parameters such as the considerable evaporation from the river water samples on the catchment areas of the zohreh and kashaf rivers afghanistan s main rivers including istalef barik ab and logar are mainly plotted on the kabul lmwl the rivers of afghanistan show the most depleted isotope values compared to the other rivers across the middle east since they are mainly recharged by the high elevation precipitations in the mountains the rivers of pakistan including indus layari and malir deviate from the karachi lmwl due to the evaporation effect among the studied rivers almost all the samples deviate from the lmwls of bahrain and sidi barrani except for the al khazir river in iraq and the zohreh river in iran these rivers belong to arid regions and are only plotted on the lmwls of the sidi barrani and bahrain stations respectively the deviation of the river water samples from the lmwls in the middle east can be studied using the lc excess the lc excess shows lower values in the regions influenced by more intense evaporation such as the zohreh river in iran with the lc excess value of 8 9 and the al khazir and euphrates rivers in iraq with the lc excess values of 11 5 and 9 0 respectively in contrast to the rivers located in regions with extensive evaporation the rivers located in regions with a lower evaporation rate such as istalef barik ab and logar in afghanistan show higher lc excess values 2 0 3 5 and 4 5 respectively the contributions of the precipitation events originating from each air mass in the recharge of the surface water resources across the middle east were also studied this was done with the help of the stable isotope mixing model simmr package parnell et al 2010 in r using the average values of δ18o δ2h and d excess in the precipitation events and the river water samples table 4 the results show that the istalef barik ab and logar rivers in afghanistan are mainly recharged by the precipitation events originating from the mp air mass in the high elevations of mountainous regions the role of the precipitation events originating from the cp air mass is stronger in the recharge of the belevi river in turkey and the havasan and kashaf rivers in iran which are all located in high latitudes however in the lower latitudes in the southern part of iran the roles of the ct and to a lower extent medt air masses are stronger in the recharge of the zohreh river this is due to the fact that the northern part of iran is mainly under the influence of the cp air mass and the moisture of high latitude water bodies such as the caspian sea the mediterranean sea the black sea and the atlantic ocean however the southern part of iran receives moisture mainly from the mediterranean sea the arabian sea the persian gulf and the red sea the zayandeh river in the central part of iran receives moisture from both high and low latitude water bodies in the euphrates and al khazir rivers in iraq the situation is to some extent different from those of iran and turkey the roles of the ct mp and medt air masses are to some extent similar in the recharge of the al khazir river however in the euphrates river the roles of the cp and ct air masses are more significant in the southeastern part of the middle east where the role of the mt air mass is significant the precipitation events originating from the mt air mass provide 56 68 and 82 of the total recharge in the indus layari and malir rivers respectively 5 conclusions the current study showed that both local temperature latitude altitude and precipitation amount and regional parameters teleconnection indices affect the values of δ18o in precipitation across the middle east most of the developed lmwls in this region had lower slopes and intercepts than the gmwl this was due to the extensive evaporation in the middle east similar to the small scale local parameters temperature latitude altitude and precipitation which control the values of δ18o in precipitation across the middle east the large scale regional parameters also directly influence the values of δ18o in precipitation the importance percentage of various teleconnection indices on the values of δ18o in precipitation was studied using the ahp technique studying the effect of precipitation on the surface water resources showed that the major rivers across the middle east are often plotted on the developed lmwls indicating that precipitation has a significant effect on the recharge of the surface water resources in this region however some rivers deviate from the lmwls due to the intense evaporation effect the contribution percentage of various air masses in the recharge of the studied rivers was also calculated using the isotope mixing model simmr package in r the obtained results showed large variations in the contribution rates of various air masses in the recharge of the rivers across the middle east in contrast to previous local investigations the present work was the first comprehensive stable isotope study of water resources precipitation and surface water which considered all parts of the middle east the stable isotope signatures in precipitation and surface water resources as well as the findings obtained from the simmr package in this study led to very valuable results regarding the role of precipitation and moisture sources in surface water recharge the results obtained in this research can also be used in future isotope hydrology investigations of other semi arid and arid parts of the world finally in recent years the high accuracy analysis of triple oxygen isotopes 16o 17o and 18o in precipitation has provided a very valuable tracer called 17o excess to study the relative humidity variations in the regions from which precipitation originates uechi and uemura 2019 unfortunately the 17o excess datasets have not been presented by gnip for the studied stations in the middle east it is suggested that the gnip iaea provide δ17o isotope datasets in precipitation besides δ18o and δ2h datasets in the gnip stations funding this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors credit authorship contribution statement mojtaba heydarizad conceptualization project administration software writing original draft masoud minaei conceptualization investigation methodology supervision kimpei ichiyanagi methodology project administration rogert sorí investigation software declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we would like to thank the iaea gnip for making their isotope dataset freely available which helped us do this research our special thanks are also extended to ferdowsi university of mashhad for helping us do this research the fourth author also acknowledges the post doctoral fellowship by the xunta de galicia the galician regional government under grant ed481b 2019 070 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126485 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 supplementary data 3 supplementary data 4 
4360,located in semi arid and arid regions in the world the middle east has always faced water shortage crisis therefore water resources in this area should be studied by accurate methods such as the stable isotope technique the results of the current isotopic study show the effects of the main local temperature and precipitation and regional parameters teleconnection indices on the δ18o values of precipitation and surface water resources across the middle east plotting the values of δ18o vs δ2h in some of the major rivers in the middle east on the local meteoric water lines shows that the surface water resources are dominantly recharged by local precipitation while the deviation observed in some samples is due to evaporation the contributions of various air masses the precipitation events originating from the main air masses in the recharge of the principal rivers have also been studied the results of the mixing models demonstrate that the contributions of various air masses in the recharge of rivers vary significantly across the middle east keywords teleconnection indices middle east precipitation stable isotopes surface water 1 introduction since 1961 when harmon craig published his finding that 18o 16o and 2h h ratios in freshwater are significantly related clark and fritz 1997 craig 1961 many studies have been conducted across the world on water resources and the hydrological cycle using 18o and 2h in cooperation with the world meteorological organization wmo the international atomic energy agency iaea has established numerous precipitation sampling stations called gnip global network of isotopes in precipitation across the world and has investigated the 18o and 2h signatures of precipitation iaea gnip 2018 the gnip stations collect precipitation samples in more than 125 countries across the world iaea gnip 2018 although the gnip stations have numerous advantages such as long period sampling in hundreds of stations and presenting stable isotopic data for many regions there are still some temporal and spatial gaps across the world for instance in the vast area of iran only one gnip station used to exist in tehran while there are no gnip stations in iraq tajikistan turkmenistan armenia azerbaijan georgia qatar etc the 18o and 2h signatures of precipitation are influenced by various small scale local parameters such as the altitudes latitudes temperatures and the amounts of precipitation in the sampling stations and large scale regional parameters such as teleconnection indices heydarizad 2018 the effects of the main local parameters including altitude giustini et al 2016 gonfiantini et al 2001 kumar et al 2010 sun et al 2019 latitude giustini et al 2016 tindall et al 2009 precipitation amount cai et al 2018 huang and wen 2014 kurita et al 2009 lone et al 2019 scholl et al 2009 yang et al 2019 and temperature kohn and welker 2005 sun et al 2019 on the δ18o values of precipitation have been studied earlier the stable isotope ratios are given in delta notation δ which is the relative deviation of the sample from the standard vienna standard mean ocean water vsmow according to eq 1 exemplarily for δ18o 1 δ o 18 s a m p l e o 18 o 16 s a m p l e o 18 o 16 r e f e r e n c e 1 1000 v s v s m o w furthermore the d excess d excess δ2h 8 δ18o dansgaard 1964 has been calculated and applied as a reliable fingerprint to study the characteristics of the moisture sources responsible for precipitation gat et al 1996 gat and carmi 1970 juhlke et al 2019 the precipitation events originating from water bodies with a high relative humidity and a low sea surface temperature sst normally have a moderate to low d excess while the precipitation events originating from water bodies with a low relative humidity and a high sst normally show high d excess values clark and fritz 1997 dansgaard 1964 gat et al 1996 gat and carmi 1970 the effects of large scale regional parameters teleconnection indices on the atmospheric conditions and the δ18o values in precipitation have not been studied adequately in the middle east the dominant climatic teleconnections in this region are the indian ocean dipole iod the el nino southern oscillation enso the north atlantic oscillation nao and the quasi biennial oscillation qbo heydarizad 2018 heydarizad et al 2018 the effects of some of these teleconnection indices on the 18o and 2h signatures of precipitation have been investigated in several studies such as cai et al 2017 deininger et al 2016 gao et al 2018 liu et al 2011 martin et al 2018 tindall et al 2009 yang et al 2016 across the world so far there has been no study considering the simultaneous effects of local and regional parameters on the δ18o values in precipitation the study of the simultaneous effects of local and regional parameters can present a comprehensive view of the parameters which influence the δ18o values in precipitation precipitation has a direct and significant effect on surface water resources the information about the recharge of surface water resources from precipitation and the role of evaporation on surface water resources can be obtained from stable isotope techniques furthermore the calculation of line conditioned excess lc excess index can also present valuable information regarding the intensity of evaporation in the surface water resources the contribution percentage of the main air masses the precipitation events originating from each air mass has also been studied using the simmr package this package was developed by parnell et al 2010 to solve the mixing equations in a bayesian framework the simmr package requires at least three obligatory input parameters to run including the endmember source means the endmember source standard deviation sd and the mixtures the surface water samples in which the contribution of each air mass is calculated furthermore the correction data which are also called trophic enrichment factors and concentration dependence values can also enter the model optionally parnell and inger 2021 as the middle east is an extensive area with large topographic variations as well as various climatic zones local and regional parameters may influence the δ18o and δ2h values of precipitation in this region furthermore the variations observed in the precipitation characteristics definitely influence the characteristics of water resources in this region the aim of the current research was first to study the effects of the local and regional parameters on the 18o and 2h signatures of precipitation in the middle east second the role of precipitation in the recharge of surface water resources was studied using stable isotopes in precipitation and surface water resources the role of evaporation on the surface water resources was studied by calculating the lc excess finally the contribution percentages of the precipitation events originating from each air mass in the recharge of several surface water resources were also studied using mixing models as well as the stable isotopes data of precipitation and surface water resources 2 description and climatology of the study area the middle east is a large geographical area located in southwest asia and northeast africa fig 1 this region is surrounded by the arabian sea and the red sea in the south the black sea and the mediterranean sea in the west the caspian sea in the north and afghanistan and pakistan in the east the middle east is mainly classified as an arid and semi arid region with a 45 year 1970 2015 average annual precipitation of 200 mm it has long and hot summers and mild and wet winters along the mediterranean coast mohebi 2012 precipitation and temperature vary greatly across this region the coastal area of the caspian sea receives more than 1800 mm of annual precipitation alijani 2000 while some desert areas in iran and the kingdom of saudi arabia ksa often receive no precipitation for many years mohebi 2012 summer temperatures are usually as high as 50 c maximum in the deserts of iran ksa and iraq while some regions in the zagros mountains experience very low temperatures about 30 c minimum in winter alijani 2000 mohebi 2012 five main air masses fig 1 affect the middle east during the year the mediterranean air mass medt influences the western and southwestern parts of this region and brings the moisture of the mediterranean sea via the western winds heydarizad et al 2019a the continental polar cp air mass the siberian high pressure system influences the northern and northeastern parts of this region and transfers the moisture of the caspian sea to it the maritime polar mp air mass has an effect on the northern and northwestern parts of this region heydarizad 2018 the continental tropical air mass ct the sudan air mass affects the southern and southwestern parts of this region and brings the moisture of the persian gulf the red sea the arabian sea and the oman sea to it heydarizad 2018 the medt cp mp and ct air masses influence the middle east during the cold and wet periods from november to april while in the dry and warm periods from may to october the southern and southeastern parts of this region are affected by the maritime tropical mt air mass which originates from the indian ocean and the arabian sea heydarizad et al 2019b mohebi 2012 large topographic variations various climatic zones and several air masses which influence the middle east have resulted in very complicated climatic conditions all of these confirm the importance of studying the effects of the local and regional parameters on the precipitation characteristics in this part of the world 3 materials and methods in the current study 26 precipitation sampling stations across the middle east which were mostly from the gnip network except for al raqqa kattan 2008 and amman morad 2015 were chosen the locations of these precipitation sampling stations as well as 12 main rivers in the middle east are shown in fig 1 the spatial distribution maps of δ18o δ2h and d excess over the middle east were developed using the inverse distance weighting idw kriging and spline techniques in the q gis software desktop version 3 14 15 q gis development team 2021 to validate the developed maps and to select the most accurate one the root mean square error rmse was used the rmse is a standard deviation of the residual which is also known as the prediction error in other words the rmse is a measure to demonstrate how concentrated the data around the best fit line are the rmse is calculated using equation 2 2 r m s e i 1 n p r e d i c t e d i a c t u a l i 2 n although developing the spatial distribution maps of δ18o and δ2h values in precipitation can have valuable advantages such as providing data for the regions where sampling is not available it may also have some disadvantages local parameters such as topographic variations have significant and direct effects on the accuracy of the developed maps to study the effects of the local and regional parameters on the stable isotope signatures of precipitation the value of δ18o is normally selected as an indicator yang et al 2019 this is due to this fact that the stable isotope fractionation during secondary evaporation in precipitation is unbalanced and dominantly controlled by kinetic fractionation whenever raindrops experience intense evaporation during precipitation δ18o is more obviously accumulated in the raindrops the liquid phase than the heavy isotope hydrogen δ2h due to molecular weight variations thus δ18o shows more obviously the influence of various local and regional parameters on the stable isotope signatures of precipitation yang et al 2019 the effects of the local parameters such as the precipitation amount latitude altitude and temperature on the values of δ18o in precipitation were studied using an ordinary linear regression model in the second step the effects of the regional parameters the teleconnection indices on the values of δ18o in precipitation were investigated the relationship between the values of δ18o in precipitation and the teleconnection indices including bivariate enso best the southern oscillation index soi nao iod and qbo which affect the middle east heydarizad 2018 was studied an ordinary linear regression method was employed to quantify the relationship between the values of δ18o and the teleconnection indices best soi nao iod and qbo the data of these teleconnection indices are freely available at http www cpc ncep noaa gov noaa 2018a and https www ncdc noaa gov noaa 2018b the statistical analyses in this study were performed using the r programming language r core team 2018 the analytic hierarchy process ahp technique was employed to study the importance and effects of various teleconnection indices on the values of δ18o in precipitation using super decision software version 2 10 0 the ahp is a multi criteria decision making method which has been developed by saaty 1987 this method shows the importance percentage of the parameters the teleconnection indices influencing the values of δ18o in precipitation in several stations across the middle east the ahp technique involves the comparison of parameter pairs within reciprocal matrices ahmad and verma 2018 to compare the parameter pairs a scale which ranges from 1 to 9 and shows the relative importance of the pairs is used table 1 whenever the value ofthe consistency ratio cr is smaller than or equal to 10 the importance of the pairs relative to each other is acceptable otherwise the subjective judgment needs to be significantly revised and a new value should be applied to the comparison matrix ahmad and verma 2018 the ahp technique has numerous applications in many fields of science does not need complete information datasets and a comprehensive procedure to run and solves very difficult problems by dividing them into several smaller parts however it has some shortcomings the most important disadvantage is that ahp is a partially subjective method introducing uncertainties to the evaluation furthermore the ahp technique can be applied only to direct models in which the outputs directly correspond to and depend on the initial input information karthikeyan et al 2016 to study more accurately the climatological parameters influencing the values of δ18o in precipitation the noaa interpolated outgoing longwave radiation olr liebmann and smith 1996 and the total precipitable water tpw kalnay et al 1996 datasets the parts related to the middle east with a spatial horizontal resolution of 2 5 2 5 were used these data were utilized to better understand the relationship between the convective activity and the amount of water potentially available in the atmosphere for precipitation and the variations of the δ18o values in precipitation in addition to olr and tpw atmospheric stability was also studied atmospheric stability is a measure of the atmosphere s tendency to prevent vertical motion in stable atmospheric conditions if a parcel of air is blown upward by an updraft or lifted over a mountain range it will sink down to the earth since it is cooler than the air particles around it this prevents precipitation from taking place to study atmospheric stability ω which is a partial differential equation for the vertical velocity is investigated equation 3 ω d p dt 3 where d dt represents a material derivative positive ω values demonstrate stable atmospheric conditions and descending motions while negative ω values represent instability and ascending motions holton 2004 in the final step the role of precipitation in the recharge of surface water resources was also studied the values of δ18o and δ2h in some of the main rivers in the middle east kashaf pakzad 2000 havasan khalaj amirhosseini 2011 zayandeh zendeh khademi et al 1997 and zohreh mirnejad et al 2011 rivers in iran belevi river in turkey somay altaş et al 2007 al khazir jassas and merker 2015 and euphrates ali and ajeena 2016 rivers in iraq istalef barik ab and logar rivers in afghanistan mack et al 2010 malir layari and indus rivers in pakistan mashiatullah et al 2006 were plotted on the local meteoric water lines lmwls furthermore the deviation of the surface water samples from the lmwl and the effect of evaporation were also studied using the lc excess index equation 4 presented by landwehr and coplen 2006 lc excess δ2h a δ18o b 4 where a and b represent the slope and intercept of the lmwl respectively in this study the authors used the lmwls of the regions near the studied rivers the contribution percentage of the precipitation events originating from each air mass in the recharge of the studied rivers was also investigated firstly using the hybrid single particle lagrangian integrated trajectory model hysplit the precipitation events were classified based on the air masses and the moisture sources that cause them stein et al 2015 the moisture origins of about 290 precipitation events in the middle east were determined by the backward trajectories of the hysplit model then the values of δ18o and δ2h in these precipitation events and their moisture sources obtained from the hysplit model were linked to demonstrate the stable isotope characteristics of the precipitation events originating from the main air masses which influence the middle east furthermore the average values of δ18o and δ2h in the precipitation events originating from each air mass were calculated using the approaches presented in previous studies heydarizad 2018 heydarizad et al 2019a 2019b in the last step the contribution percentage of the precipitation events originating from each air mass in the recharge of the studied rivers was calculated via the stable isotope signatures in precipitation and surface water using the simmr package in r language supplementary file 1 4 results and discussion the spatial distributions of δ18o δ2h and d excess maps were developed using various methods spline kriging and idw calculating the rmse for each map showed the lowest values for the maps developed by idw techniques and confirmed their high accuracy table 2 idw has several advantages such as the ability to predict extreme changes in different terrains such as cliffs and to increase or decrease the number of the sampling points to influence the cell values however it has some disadvantages such as the weakness to predict the values below minimum or above maximum and its low utility in mountainous regions the spatial distribution maps of δ18o δ2h and d excess developed by the idw technique show significant spatial variations in the middle east precipitation fig 2 due to the effects of the local and regional parameters highly enriched δ18o and δ2h values in precipitation were observed in the southern part of the middle east over the persian gulf the oman sea the arabian peninsula and the north of africa however very depleted isotope values were observed over the northern part of the middle east low d excess values were observed over the persian gulf and the southern part of the middle east which was due to the intense evaporation effect on precipitation in these regions clark and fritz 1997 nevertheless high d excess values were mainly observed in the eastern part of the mediterranean sea high d excess values in the precipitation over the eastern part of the mediterranean sea has also been confirmed by previous studies gat et al 1996 gat and carmi 1970 4 1 developing lmwls for the stations in the middle east lmwls were developed for all the studied stations across the middle east using an ordinary linear regression method and their slopes and intercepts are illustrated in supplementary file 2 in most of the stations the lmwls demonstrate lower slopes and intercepts compared to the global meteoric water line gmwl δ2h 8 13 δ18o 10 8 rozanski et al 1993 when the amount of precipitation is low raindrops are more influenced by secondary evaporation enriched isotopes are more accumulated in raindrops due to kinetic fractionation in this case the slope of the lmwl is less than 8 and its intercept demonstrates low values clark and fritz 1997 yang et al 2019 in the southern part of the middle east the stations including bahrain haray khatt wadi al qor jubial fanatir taif al hada qairoon salalah and saiq which receive their precipitation moisture from the persian gulf the arabian sea the oman sea and the red sea mostly demonstrate very low slopes and intercepts compared to the other stations due to the higher temperature lower relative humidity and more evaporation in the karachi station in the southeastern part of the middle east where the roles of the mt air mass and the indian ocean are dominant the lmwl has the high slope of 7 55 while the intercept has the low value of 3 41 vs vsmow the stations located in the western and southwestern parts of the mediterranean sea including adana antalya aaramta bet dagan beirut har kna an prodhromos nicosia soreq and tripoli show approximately the same slopes and intercepts as the lmwls in the lower latitudes in the southern parts of the middle east this is due to the fact that the temperature and the evaporation rate in the mediterranean region are also high however in the adana and antalya stations which are located in higher latitudes and have a lower temperature both the slopes and intercepts of the lmwls increase the prodhromos and beirut stations in the mediterranean region show very low slopes and intercepts the low r2 values calculated for the lmwls may be due to the involuntary machine or human errors in the sampling or analysis of the isotopic data in these stations finally in the stations deeply located in the continents including al raqqa kabul ankara tehran and amman the local climatic and geographical conditions have an important effect on the lmwls the amman station located in lower altitudes in an arid region with a high temperature shows a lower slope than the other stations due to intense evaporation 4 2 studying the effects of the local parameters on the δ18o values in the middle east precipitation the δ18o values in precipitation are under the dominant influence of small scale local parameters the effects of local parameters including altitude latitude temperature and precipitation amount on the δ18o signature of precipitation in the middle east were studied fig 3 the relationship between temperature and δ18o shows the gradient of 0 39 depletion in δ18o per 1 c decrease in temperature this gradient is lower than that of interior canada with the gradient of 0 49 depletion in δ18o per 1 c temperature decrease clark and fritz 1997 however it is higher than those of wallingford in england with the gradient of 0 25 depletion in δ18o per 1 c temperature decrease and greece with the gradient of 0 19 depletion in δ18o per 1 c temperature decrease argiriou and lykoudis 2006 the relationship between the precipitation amount and δ18o in the middle east shows the gradient of 3 6 depletion in δ18o per 100 mm increase in precipitation which is higher than those of the subtropical regions in china with the gradient of 1 depletion in δ18o per 18 2 mm and 6 2 mm increase in precipitation during the dry and wet periods respectively xia 2019 and lhasa in the tibetan plateau with the gradient of 1 depletion in δ18o per 25 mm increase in precipitation yao et al 2013 the relationship between altitude and δ18o demonstrates the gradient of 0 2 depletion in δ18o per 100 m increase in altitude in the middle east this gradient is lower than those of monachyle in scotland with the gradient of 0 34 depletion in δ18o per 100 m increase in altitude during winter darling and talbot 2003 the coast mountains in canada with the gradient of 0 25 depletion in δ18o per 100 m increase in altitude clark et al 1982 and the piedmont region in italy with the gradient of 0 31 depletion in δ18o per 100 m increase in altitude bortolami et al 1978 however this gradient is higher than that of the dohfar region in oman with the gradient of 0 1 depletion in δ18o per 100 m increase in altitude clark et al 1987 finally the relationship between latitude and δ18o in precipitation was studied the relationship between latitude and δ18o in the middle east shows the gradient of 0 4 depletion in δ18o per 1 increase in latitude this gradient is lower than that of the antarctic region with the gradient of 2 0 depletion in δ18o per 1 increase in latitude and that of europe and north america with the gradient of 0 6 depletion in δ18o per 1 increase in latitude clark and fritz 1997 among the various local parameters temperature and the amount of precipitation have significant effects on the stable isotope signatures in precipitation yang et al 2019 supplementary file 3 shows that the variations of temperature have a direct relationship with the values of δ18o and that the amount of precipitation and the values of δ18o are also directly related in the precipitations in the studied stations although the relationship between δ18o and temperature is not totally understood it is normally accepted that this relationship is steady with the decrease of the 18o 16o ratio in moisture since a heavier isotope 18o enters the condensate phase during the adiabatic cooling process dansgaard 1964 gat et al 1996 rozanski et al 1993 the relationship with a low r2 between δ18o and temperature in some of the studied stations indicates that factors other than temperature affect the values of δ18o in precipitation fricke and o neil 1999 the moisture originating from the evaporation of water bodies such as large lakes and the transpiration of moisture by vegetation coverage significantly influence the values of δ18o in precipitation by transferring the moisture back to upper air masses jacob and sonntag 1991 koster et al 1993 salati et al 1979 these phenomena resulted in a weak relationship between temperature and the values of δ18o in precipitation in some of the studied stations and made it difficult to interpret fricke and o neil 1999 in addition to temperature and the amount of precipitation the variations of the olr and tpw values over the middle east were also studied fig 4 the values of olr and tpw had a direct effect on the values of δ18o in precipitation the spatial variations of the olr and the stable isotope signatures of precipitation across the middle east are shown in fig 4 it can be observed that the low tpw and olr values which indicate more cloud coverage and a higher amount of precipitation in the higher latitudes of the middle east are accompanied by depleted isotope values due to the effect of the amount of precipitation the higher the precipitation amount the lower the values of δ18o due to the precipitation amount effect clark 2015 clark and fritz 1997 kurita et al 2009 yang et al 2019 in contrast to the higher latitudes enriched isotope values as well as higher olr and tpw values were observed in the lower latitudes in the southern part of the middle east very stable atmospheric conditions which prevent the movement of air parcels and precipitation are the main reasons for high tpw and olr values in this part of the middle east therefore to study the climatology of this region more accurately the spatial and temporal variations of atmospheric stability ω precipitation amount olr and tpw were also studied fig 5 during the cold and wet period from november to april very unstable atmospheric conditions ω 0 and low olr values indicating enhanced convection and more cloud coverage demonstrate appropriate conditions for precipitation occurrence low tpw values and high precipitation amounts in high latitudes create appropriate conditions for turning atmospheric moisture into precipitation however during the dry period from may to october very stable atmospheric conditions ω 0 and high olr values indicative of suppressed convection and hence less cloud coverage are mainly observed in the low latitudes in the middle east fig 5 in addition during the dry period very high amounts of tpw and low precipitation amounts are observed in the atmosphere confirming that the conditions for precipitation occurrence are not appropriate this large amount of tpw cannot turn into precipitation due to the intense atmospheric stability which prevents precipitation from taking place the intense atmospheric stability has also been confirmed by positive ω values in this period the atmospheric stability during the dry period in the middle east is due to the azores high pressure system which develops over most parts of this region 4 3 studying the effects of the regional parameters on the δ18o values in the middle east precipitation according to the importance intensity and influence domain of each climatic teleconnection in the middle east the four indices of best soi nao iod and qbo were selected the effects of these indices on the stable isotope signatures of precipitation were studied in the eight selected stations including bahrain antalya adana sidi barrani karachi kabul tehran and ankara across the middle east with a long period of stable isotope data supplementary file 4 the ahp technique was employed to show the importance percentage of each studied teleconnection index on the δ18o values in the precipitation in the studied stations table 3 the results showed that in the karachi station the iod had a more important effect than the other teleconnections on the values of δ18o in precipitation this was due to the significant effect of the indian ocean on the characteristics of precipitation in the southern and southeastern parts of asia mashiatullah et al 2006 the indian monsoons have a significant effect on the precipitation regimes in the south and southeast of asia the nao is the dominant teleconnection in the adana and sidi barrani stations this is due to the strong effect of the north atlantic ocean on the characteristics of precipitation in the stations located in the western and northwestern parts of the middle east mainly in the coastal areas of the mediterranean sea the best and soi in the bahrain station and the qbo in the ankara station are the dominant teleconnection indices influencing the values of δ18o in precipitation in the continental stations the situation is to some extent different in the kabul station the role of the iod teleconnection is dominant while the effects of the best and soi indices are significant on the values of δ18o in tehran precipitation the strong effect of the el nino southern oscillation enso on the precipitation events across iran has also been confirmed in previous studies nazemosadat 1999 pourasghar et al 2012 sabziparvar et al 2011 finally in the ankara station the effect of the qbo teleconnection on the values of δ18o in precipitation is stronger than those of the other indices 4 4 studying the effects of precipitation and air masses on the recharge of some of the major rivers in the middle east studying the effect of precipitation on the surface water resources has yielded valuable results plotting the surface water resources the main rivers in the middle east on the lmwls fig 6 shows that the belevi river in turkey is mainly plotted on the ankara lmwl however it shows a small deviation from the mwls of antalya and adana in iran the zayandeh and havasan rivers are mainly plotted on the tehran lmwl while the zohreh and kashaf rivers are plotted over the tehran lmwl this is perhaps due to the effects of the local parameters such as the considerable evaporation from the river water samples on the catchment areas of the zohreh and kashaf rivers afghanistan s main rivers including istalef barik ab and logar are mainly plotted on the kabul lmwl the rivers of afghanistan show the most depleted isotope values compared to the other rivers across the middle east since they are mainly recharged by the high elevation precipitations in the mountains the rivers of pakistan including indus layari and malir deviate from the karachi lmwl due to the evaporation effect among the studied rivers almost all the samples deviate from the lmwls of bahrain and sidi barrani except for the al khazir river in iraq and the zohreh river in iran these rivers belong to arid regions and are only plotted on the lmwls of the sidi barrani and bahrain stations respectively the deviation of the river water samples from the lmwls in the middle east can be studied using the lc excess the lc excess shows lower values in the regions influenced by more intense evaporation such as the zohreh river in iran with the lc excess value of 8 9 and the al khazir and euphrates rivers in iraq with the lc excess values of 11 5 and 9 0 respectively in contrast to the rivers located in regions with extensive evaporation the rivers located in regions with a lower evaporation rate such as istalef barik ab and logar in afghanistan show higher lc excess values 2 0 3 5 and 4 5 respectively the contributions of the precipitation events originating from each air mass in the recharge of the surface water resources across the middle east were also studied this was done with the help of the stable isotope mixing model simmr package parnell et al 2010 in r using the average values of δ18o δ2h and d excess in the precipitation events and the river water samples table 4 the results show that the istalef barik ab and logar rivers in afghanistan are mainly recharged by the precipitation events originating from the mp air mass in the high elevations of mountainous regions the role of the precipitation events originating from the cp air mass is stronger in the recharge of the belevi river in turkey and the havasan and kashaf rivers in iran which are all located in high latitudes however in the lower latitudes in the southern part of iran the roles of the ct and to a lower extent medt air masses are stronger in the recharge of the zohreh river this is due to the fact that the northern part of iran is mainly under the influence of the cp air mass and the moisture of high latitude water bodies such as the caspian sea the mediterranean sea the black sea and the atlantic ocean however the southern part of iran receives moisture mainly from the mediterranean sea the arabian sea the persian gulf and the red sea the zayandeh river in the central part of iran receives moisture from both high and low latitude water bodies in the euphrates and al khazir rivers in iraq the situation is to some extent different from those of iran and turkey the roles of the ct mp and medt air masses are to some extent similar in the recharge of the al khazir river however in the euphrates river the roles of the cp and ct air masses are more significant in the southeastern part of the middle east where the role of the mt air mass is significant the precipitation events originating from the mt air mass provide 56 68 and 82 of the total recharge in the indus layari and malir rivers respectively 5 conclusions the current study showed that both local temperature latitude altitude and precipitation amount and regional parameters teleconnection indices affect the values of δ18o in precipitation across the middle east most of the developed lmwls in this region had lower slopes and intercepts than the gmwl this was due to the extensive evaporation in the middle east similar to the small scale local parameters temperature latitude altitude and precipitation which control the values of δ18o in precipitation across the middle east the large scale regional parameters also directly influence the values of δ18o in precipitation the importance percentage of various teleconnection indices on the values of δ18o in precipitation was studied using the ahp technique studying the effect of precipitation on the surface water resources showed that the major rivers across the middle east are often plotted on the developed lmwls indicating that precipitation has a significant effect on the recharge of the surface water resources in this region however some rivers deviate from the lmwls due to the intense evaporation effect the contribution percentage of various air masses in the recharge of the studied rivers was also calculated using the isotope mixing model simmr package in r the obtained results showed large variations in the contribution rates of various air masses in the recharge of the rivers across the middle east in contrast to previous local investigations the present work was the first comprehensive stable isotope study of water resources precipitation and surface water which considered all parts of the middle east the stable isotope signatures in precipitation and surface water resources as well as the findings obtained from the simmr package in this study led to very valuable results regarding the role of precipitation and moisture sources in surface water recharge the results obtained in this research can also be used in future isotope hydrology investigations of other semi arid and arid parts of the world finally in recent years the high accuracy analysis of triple oxygen isotopes 16o 17o and 18o in precipitation has provided a very valuable tracer called 17o excess to study the relative humidity variations in the regions from which precipitation originates uechi and uemura 2019 unfortunately the 17o excess datasets have not been presented by gnip for the studied stations in the middle east it is suggested that the gnip iaea provide δ17o isotope datasets in precipitation besides δ18o and δ2h datasets in the gnip stations funding this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors credit authorship contribution statement mojtaba heydarizad conceptualization project administration software writing original draft masoud minaei conceptualization investigation methodology supervision kimpei ichiyanagi methodology project administration rogert sorí investigation software declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we would like to thank the iaea gnip for making their isotope dataset freely available which helped us do this research our special thanks are also extended to ferdowsi university of mashhad for helping us do this research the fourth author also acknowledges the post doctoral fellowship by the xunta de galicia the galician regional government under grant ed481b 2019 070 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126485 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 supplementary data 3 supplementary data 4 
4361,the nature of streamflow in the basins is stochastic and complex making it difficult to make an accurate prediction about the future river flows recently artificial neural based deep learning models with a nonlinear structure have become predominant in water engineering forecasting problems such as river flow predictions in this study we investigate the potential of singular spectral analysis ssa seasonal trend decomposition using loess stl and attribute selection pre processing approaches with the neural network methods in predicting monthly river streamflows in the nallihan stream turkey antecedent measured streamflow precipitation relative humidity and temperature data between the years 1996 and 2016 from the observing stations in the basin boundaries were used as model inputs under different scenarios using the correlations between the past measured variables to predict one step ahead flow data to compare the newer hybrid model performances evaluation metrics including coefficient of determination r2 nash sutcliffe efficiency ne willmott s index of agreement wi root mean square error mean absolute error together with judicious plots scatter plot time series and the taylor diagrams were utilized the developed hybrid ssa based models registered higher accuracy than other standalone neural networks models without pre processing approaches the r2 for ssa based models were higher ranging from 0 8300 to 0 9105 and the largest r2 0 9105 was registered by the proposed ssa ann model ssa ann models have also the highest ne and wi index values 0 9045 and 0 9764 respectively the outcomes revealed that based on ne the ssa decomposition increased the monthly streamflow prediction accuracy by 24 11 18 40 and 5 11 of respective ann cnn and lstm methods the ssa pre processing approach is able to unveil the embedded streamflow characteristics and could be further applied in basins with similar characteristics to attain more accurate predictions of river flows keywords data driven models deep learning attributes selections pre processing approaches ann cnn lstm gini index 1 introduction the management of sustainable water resources is crucial for any country around the world since many countries are having a very sensitive geopolitical climate surrounding this valuable resource successful and effective water resources planning and subsequent efficient management require timely data with accurate river flow predictions accurate river flow forecasts in arid and semi arid climates provide useful information to water managers for the allocation of available water for various purposes such as agriculture drinking and industrial usages in addition accurate forecasts of flows in wet climates play an important role in early flood warnings and preventing loss of life and property sattari et al 2012a kartal et al 2020 essentially river flow has a dynamic nature at temporal and spatial scales which interacts with the physical properties and meteorological variables of the basin hence river flow time series data have embedded nonlinear and stochastic structure that makes accurate prediction of river flows very difficult generally three main methods for modelling river flows are used including physical conceptual and data driven methods determining the complex physical properties of soil texture watershed and river networks within the basin together with radiative or other atmospheric forcing data that influences river flow is evidently difficult prasad et al 2017 sattari et al 2021 and leads to the adoption of necessary assumptions for this reason the forecasts of river flows via physical and conceptual models are difficult and assumptions induce a high level of unwarranted error mosavi et al 2018 on the other hand the data driven machine learning ml modelling approaches provide alternatives by achieving greater forecasting accuracy predictions without adopting the physics where the only requirement is high quality historical data prasad et al 2017 these data driven ml models offer a number of benefits as localized tools that operate locally using point based data and modelling frameworks not require initial forcings easy to develop in comparison to the physically based models and are free from underlying boundary conditions and physical assumptions a number of data driven machine learning techniques have been widely used in recent years for the simulation and forecasting of river flow data deo and sahin 2015 humphrey et al 2016 mehr et al 2014 onyari and ilunga 2013 prasad et al 2017 yaseen et al 2016 the models included neuronal based artificial neural networks ann el shafie et al 2007 karran et al 2014 li et al 2016 khazaee poul et al 2019 yang et al 2020 multilayer feed forward back propagation nn sattari et al 2012c recurrent neural networks rnn sattari et al 2012b to adaptive neuro fuzzy inference system anfis el shafie et al 2007 support vector machines sattari et al 2013 karran et al 2014 li et al 2016 and regression tree based m5 model tree sattari et al 2013 and random forest models wang et al 2015 shortridge et al 2016 li et al 2016 these all are standalone modelling approaches all these studies show that ai approaches have a better chance of increased predictability of streamflow however standalone models do not give appropriate results due to the complexity of the data structure with evolving science and technology new and versatile deep learning models have surfaced rnn is a type of deep nn model which creates a loop and provides useful historical information in this way the information of the previous time can be used and the new information can be obtained from the old information lecun et al 2015 apaydin et al 2020 developed rnn based deep learning approaches for predicting reservoir inflows in turkey in addition long short term memory lstm networks which have rnn architecture have been introduced to overcome the problem of training and memory preservation in long sequencing data ni et al 2020 the deep learning approach lstm has been used in forecasting applications the advantage of lstm is the ability to learn long term dependencies between the network s input and output provided hence kratzert et al 2018 developed the lstm model for rainfall runoff modelling in 241 basins the results showed that the lstm model was superior to the sacramento soil moisture accounting model coupled with the snow 17 model and other models lstm has also been recently applied in flood susceptibility prediction fang et al 2020 flood forecasting kao et al 2020 and streamflow forecasting cheng et al 2020 studies the results showed that deep learning approaches were successful in these prediction studies the streamflow time series consists of the trend seasonality periodic motion and error components with irregular random movements leading to inherently non linear complex and non stationary time series therefore different data pre processing approaches such as decomposition techniques are necessary to increase the forecasting accuracy of the respective models the data decomposition techniques that have been used include discrete wavelet transformations deo et al 2016a 2016b and maximum overlap dwt modwt prasad et al 2017 the dwt exhibits challenges of decimation effect induced in wavelet coefficients while both dwt and modwt require a suitable user defined mother wavelet which is time consuming to determine chen et al 2012 prasad et al 2019 an apt decomposition method separates the inherent components and presents the sub series to the model in an organized manner in this study two decomposition techniques seasonal trend decomposition using loess stl and singular spectrum analysis ssa are applied for data decomposition that are found to properly unveil and present the underlying features within the data wen et al 2018 in addition for high model performances the input features need to be properly selected for parsimonious models input selection methods used in literature for hydrological applications include but are not limited to cross correlation partial autocorrelations average mutual information bhattacharya and solomatine 2005 minimum redundancy maximum relevancy onyari and ilunga 2013 bootstrap ranked mutual information quilty et al 2016 boruta feature selections prasad et al 2019 and in many cases were from hydrological expertise campolo et al 2003 deo et al 2017a 2017b 2016b 2016a deo and sahin 2015 2016 2017 prasad et al 2019 in this study the gini index feature selection method is applied for developing input combination scenarios with the aim of prediction model accuracy improvement integration of data pre processing adoption of feature selections and optimization algorithms into artificial intelligence ai modelling approached leads to hybrid models the hybrid methods offer increased prediction accuracy in comparison to traditional standalone ai methods in river flows fahimi et al 2017 karran et al 2014 developed hybrid wavelet ann and wavelet svr for predicting daily streamflow in contrasting climate regimes while yaseen et al 2018 trialed the wavelet elm model following that dariane and azimi 2018 utilized ssa and genetic algorithm based input selection approaches in river flow forecasting and found that the accuracy increased the grey wolf optimization algorithm has also been applied in ai modelling to increase the accuracy of monthly streamflow predictions tikhamarine et al 2020 in another recent study integrated ensemble based and optimized models have been developed for predicting reservoir inflows ramaswamy and saleh 2020 overall hybrid models have been found to perform better in comparison to standalone models however literature shows very limited usage of hybrid deep learning approaches in hydrological applications only a recent study by bui et al 2020 hybridized the deep neural network dnn integrated with swarm intelligence algorithms for flood susceptibility mapping in vietnam chang et al 2020 proposed a machine learning approach to significantly improve existing flood warning systems and provide early warning to reservoir management zhu et al 2020 used feed forward neural network ffnn and dl technique to predict monthly lake water level the results indicate that the dl model did not show significant superiority over the traditional ffnn model indeed the ffnn model slightly outperformed the dl model for 33 of the 69 lakes more recently kao et al 2021 developed a hybrid machine learning model i e the stacked autoencoder with rnn to support emergency management in areas affected by flood hazards which achieved accuracies of r2 values high 0 95 the literature clearly shows that the data driven models which are defined as competitors of the conceptual models are indeed useful in river flow forecasts with hybrids via data pre processing and feature selection giving a competitive advantage to the hybrids another important feature is the emergence of deep learning methodologies however the performance of different deep learning methods has not been sufficiently investigated in predicting monthly river flows let alone the hybridized models thus the aim of this study is to investigate the potentials of ssa and stl data decomposition pre processing techniques combined with the gini index feature selection approach integrated with ann convolutional neural network cnn and lstm deep learning models for monthly flows predictions in nallihan river turkey the study led to the development of ssa cnn ssa lstm ssa ann stl cnn stl lstm stl ann models and similar gini hybrid models which are compared to non hybrid ann cnn and lstm models in addition the sensitivity of different input scenarios and the effect of different parameters and lag times on the flows are also determined in predicting monthly flows 2 material and methods the study was conducted in the nallihan region which is located within the continental climate bounds of turkey s sakarya basin fig 1 the surrounding districts harbor 18 of agriculture 51 of forest 3 of meadow and pasture and 28 of the non agricultural area ceylan et al 2009 the monthly streamflow rates between the years 1996 and 2016 for nallihan streamflow observation station were acquired from the general directorate of hydraulic works in the sakarya basin fig 2 shows the time series of historical observed flow data at nallihan station the highest streamflow rate recorded during this period was 15 67 m3 s in march 2009 while the average flow rate between 1996 and 2016 was 1 71 m3 s an interesting feature noted was that the streamflow between 2009 and 2016 was higher than previous years flows erogluer and apaydin 2020 the meteorological data recorded at nallihan beypazari mihaliccik goynuk mudurnu and eskisehir stations of the turkish state meteorological service were used in this study the location information of the stations and the data duration are given in table 1 nallihan has a semi arid climate with an average temperature of 12 1 c nallihan s climate is influenced by central anatolia and the western black sea climate although spring autumn and winter receive high rainfall the summer season does not experience much rainfall winter seasons are not too cold erogluer and apaydin 2020 the measured antecedent streamflow data up to three months were used in the model and also for calculating the average monthly values in addition precipitation temperature and relative humidity values are also used in the model development a summary of statistical parameters of monthly hydro meteorological variables is presented in table 2 the spatial interpolation method proposed by apaydin et al 2004 was applied to compute the spatial mean of hydro meteorological parameters of nallihan area as illustrated in table 2 there is a relatively low correlation between streamflow meteorological variables and the precipitation relative humidity and temperature values therefore antecedent monthly streamflow time series i e qt 1 qt 2 qt 3 were used as the inputs for the models monthly averages of hydro meteorological parameters used in the study are given in fig 3 it is seen that the streamflow increased in the first four months of the year and the highest value was recorded in april 2 1 model development for model development a ratio of 70 15 15 was used in training validation and testing stages respectively table 3 the model development was carried out in two parallel phases after the data was prepared in the first phase all meteorological data the antecedent three month and long term monthly mean streamflow data were taken into account as inputs to the cnn lstm and ann models in the second parallel phase streamflow data series were decomposed into their component series via ssa and stl methods subsequently the gini index method was utilized for parameter input selections and the salient inputs were channelled to the respective ai models the flow chart of the model development is presented in fig 4 this resulted in standalone ssa based hybrid models stl based hybrid models ssa gini based and stl gini based models the results obtained from these models were comprehensively evaluated using comparison metrics and diagnostic plots all the codes used are provided in github https github com hapaydin decompose 2 1 1 decomposition techniques used in the study two robust decomposition techniques were used in this study as outlined in this section 2 1 1 1 singular spectral analysis ssa the model free approach ssa is a very efficient methodology to analyze time series successfully which has been used in different fields of science ssa is executed in four steps embedding singular value decomposition grouping and diagonal averaging the ssa algorithm decomposes the original time series into noise trend and seasonality components liu et al 2018 the spectrum analysis via the singular value decomposition is the most important step in ssa decomposition ssa has been used in the medical field to resolve biomedical issues and to perform quantitative genetic analysis for further information readers are recommended to refer to golyandina and zhigljavsky 2013 golyandina et al 2018 golyandina 2019 and brunton and kutz 2019 2 1 1 2 seasonal trend decomposition using loess stl is another robust and versatile statistical method for decomposing time series into seasonality trend and residual components the trend illustrates a sequence of data points that varies across a continuous time axis while the seasonality is a continuous and regular pattern and it recurs at a fixed interval of time the residual represents the noise or randomness chen et al 2020 and describes random fluctuations or unpredictable changes the regression technique loess in stl estimates the nonlinear relationships within the different components using local regression data to match the curve the first step of stl decomposition is to approximate the trend line of the given time series which commonly is calculated from the polynomial model then de trending of series is conducted by subtracting time series data with the approximated trend line next the seasonal component is determined by populating the whole data by subtracting seasonal data from the time series data the seasonality component is removed or the time series is de seasonalised finally the residuals are determined which essentially are the leftovers after removing the seasonal and trend components hyndman and athanasopoulos 2018 wen et al 2018 python program using numpy https numpy stl readthedocs io en latest and pyssa https github com aj cloete pssa libraries was used to decompose streamflow into elements using ssa and stl decomposition method 2 1 2 feature selection via gini index feature selection is an important process of selecting the most relevant inputs whilst reducing the number of input parameters feature selection is one of the main steps of machine learning modelling as irrelevant or wrong features can negatively impact model results the objectives of selecting features are diverse the most important are a avoid overfitting and improve model performance b provide faster and less computationally expensive models and c gain deeper insights into the processes underlying the generated data saeys et al 2007 the gini index feature selection method adopted in this study is used for imbalanced data which is a common characteristic of real world hydrological applications liu et al 2019 pilnenskiy and smetannikov 2020 gini index feature selection algorithm is an embedded method with a tree based modelling approach and is also able to measure the purity of the feature aman et al 2019 in the gini index operation select k best function has been selected as univariatefilter pilnenskiy and smetannikov 2020 in addition the gini index feature selection method provides the best result when the number of selected features increases some of the real world applications include fraud detection classification of texts and illness diagnosis the gini index method in the python library named itmo fs developed by pilnenskiy and smetannikov 2020 was used to determine the highest effect among the variables consisting of past hydrological meteorological and time index values used in the study 2 1 3 deep learning modelling approaches the modelling approaches used in this study are all classified as neural networks nns nns are a set of learning algorithms that mimic the human brain to recognize relationships and patterns it consists of an input layer multiple hidden layers and an output layer and information or data flows through these layers each of the connections in these networks is associated with respective connection weights and has a threshold activation value governing the response of these neurons is special function or formula called the activation function during the training process a set of input data is provided together with corresponding outputs and the network adjusts the parameters tavanaei et al 2019 minimizing a cost function it checks the deviation of the result and re adjusts the parameters on each of the neurons using training algorithm the weights and threshold values are adjusted to reach the correct output during the learning or training process which is repeated a number of times until near correct output occurs with nonlinear activation functions nns are nonlinear modelling approaches and streamflow data has nonlinearity features as discussed earlier on for this study 200 neurons in input layer l1 and 100 neurons in hidden layer l2 gave the optimal results table 4 the cost function used was mse while using a sequential model these networks can be made deeper by increasing the number of hidden layers deep learning is a part of machine learning with larger networks that are capable enough to learn unstructured or unlabelled data these models can learn relevant features from large amounts of unstructured data that humans would normally take decades to understand and process goodfellow et al 2016 the deep learning model convolutional neural network cnn used in this study takes the training features as inputs and passes it through a series of convolution layers and pooling processes to fully connected layers using mathematical operations and kernels the machine observes features as an array of data albawi et al 2017 this network focuses on the movement of the cell and the state of the current cell s influence on the movement of the future cell in cnn 16 filters in l1 and 8 filters in l2 with rectified linear unit relu worked the best as presented in table 4 the filters represented by a vector of weights indicate the dimensionality of the output space in cnn in other words it shows the number of different results or channels which is required to convolve the inputs it is similar to a filter encountered in signal processing providing a measure of how close a patch of input resembles a feature whereby each filter is regarded as a single storage template pattern during the formation of the convolution of these filters across the corresponding inputs the similarity between the stored template and different locations in the inputs is determined in the training stages of cnn the minimizing of a cost function is achieved via systemic tuning of the abovementioned parameters including the filters the other deep learning model used in this study is long short term memory lstm is a recurrent neural network which is capable of learning order dependency in sequence prediction problems natural streamflow data is highly dependent on persistence which the lstm model can capitalize on during the training process however is a shortcoming of anns unlike traditional anns lstm takes windowed time steps as input and processes it step by step to learn the persistence in the series in addition lstm has advantages over classical modelling approaches as they can fit non linear streamflow data series without the need to specify the type of non linearity hence lstm modelling approach was adopted in this study lstm is a complex and intricate deep learning technique which has a chain structural process with four nns and different memory blocks called cells hua et al 2019 these cells retain all the information and the gates manipulate the memory there are three types of gates including forget gate input gate output gate the input gate is used to add useful data to the cell state while the forget gate removes the cells which are no longer useful the output gate is used to extract useful data from the current cell state which is represented as output during training the network parameters weights and biases are updated on the basis of the loss function in each iteration the mean squared error mse was used as the objective criterion essentially a subset called the batch or mini batch of the training data is used in respective iterations the number of samples per batch was 256 in this study in lstm modelling 200 neurons in l1 200 neurons in l2 and 100 neurons in l3 generated the best forecasts as summarized in table 4 to avoid overfitting weight regularisation is of utmost importance and was adopted the models were developed in python platform using matplotlib pandas math keras sci kit learn hydroerr libraries in google colab hunter 2007 the pandas development team 2010 chollet et al 2015 pedregosa et al 2011 roberts et al 2018 during the model development stage it is imperative to optimize and fine tune the models to get optimal outputs the alternative learning rate lr decay de and epochs of the respective models are determined using the grid search algorithm for respective ai modelling the learning rate ranged from 1e 1 to 1e 9 decay from 1e 1 to 1e 9 and 50 100 500 1000 1500 and 2000 epochs have been tried table 4 2 2 evaluation metrics four different well known metrics were calculated for evaluating the models eq 1 4 i pearson correlation coefficient cc is used to obtain the strength and direction of the linear relationship between the predicted value and observed value as 1 cc i 1 n p i p d i d σ i 1 n p i p 2 σ i 1 n d i d 2 ii nash sutcliffe coefficient ns describes the accuracy of model outputs 2 ns 1 i 1 n p i d i 2 i 1 n p i p 2 iii willmott index wi willmott 1982 is used to express the accuracy of model outputs 3 w i 1 i 1 n y i x i 2 i 1 n y i x x i x 2 iv root mean squared error rmse is the standard deviation of the residuals prediction errors 4 rmse 1 n σ i 1 n p i d i 2 v mean absolute error mae is commonly used in forecasting time series 5 mae 1 n i 1 n p i d i where n is the number of outputs pi is the i th predicted output and di is the i th desired observed output hyndman and athanasopoulos 2018 hyndman and koehler 2006 3 results 3 1 stationarity test outcomes it is imperative to perform some tests and data pre processing in hydrological modelling studies to increase the efficiency and accuracy of the models the first thing is to determine whether the data series is stationary the stationarity of the data was tested by adfuller and augmented dickey fuller adf test to determine the usability of decomposition techniques flandrin 1998 bógalo et al 2017 harmouche et al 2018 the results of the tests are shown in table 5 it can be realized that result of the test 2 944265 is higher than the value of 3 459620 at 1 but less than the value of 2 874415 at the 5 level this suggests that the null hypothesis can be rejected with a significance level of less than 5 i e a low probability that the result is a statistical fluke rejecting the null hypothesis implies that the process has no unit root and in turn that the time series is stationary or does not have time dependent structure 3 2 decomposition pre processing outcomes in this study two different data decomposition techniques were used to increase the predictive potential of the models fig 5 illustrates the outcomes of the eigenvalues and singular values data series decomposition by the ssa method of nallihan river flow data both graphics were examined in terms of slope and contribution and then the components with similar weights were determined when the signal components in fig 5 are evaluated it was determined that it is appropriate to reconstruct the 4 main elements comp0 0 comp1 1 2 comp2 3 8 and comp3 9 19 the signals were then combined to yield the streamflow series as in fig 6 since the decomposed signals after the 20th component did not have any significant effect these were not taken into consideration after this stage hassani 2007 gillard and knight 2014 de menezes et al 2015 decomposition results of nallihan streamflow data after the stl method are given in fig 7 it can be seen from figs 2 and 7a that between months 149 and 151 feb apr 2009 extreme values resulted and therefore the data deviated from zero to very large deviations in the residual graph fig 7d the extreme values are largely seen in the decomposed trend component and the residual the seasonality component was not affected by the extreme event which shows that the decomposition technique properly depicted the seasonality within the series 3 3 feature selection outcomes in modelling studies the outcomes are very much dependent on the input data hence it is desired that to reach the best results the least number of salient input parameters are to be selected in this study besides meteorological data precipitation relative humidity and temperature and hydrological data 1 3 months antecedent streamflow and long term monthly mean streamflow the decomposed streamflow components obtained by two different seasonal decomposition methods were pooled as the potential inputs in this case depending on the decomposition method 11 12 input series were used but increasing the number of input data creates measurement and model training difficulties hence a robust input selection is required for determining the most effective ones from the dataset in this study the gini index method is utilized for feature selection and the results are given in table 6 since ssa and stl methods produced different numbers and sizes of components the gini index was applied to two different data sets after ssa and feature selection the parameters humidity qt 1 and qt 2 and hydro meteorological data given table 6 were determined as the most effective ones humidity temperature t and qt 1 are the most influential parameters of stl decomposition methods among the input parameters those found to be statistically significant 5 according to the gini index were selected for modelling using the outcomes of feature selection in table 6 four main data sets were formed meteorological hydrological ssa outputs and stl outputs the modelling was performed in five scenarios using these data sets to allow for the development of novel modelling approaches together with the notion of studying the effects of input selections on the model performances the scenarios are displayed in table 7 in scenario i the dataset used is labelled ds i where all inputs have been channelled to the model while in scenario ii ds ii the data sets after ssa decomposition were utilized while in scenario ii ds iii the stl decomposed data were used as inputs in both scenarios iv and v the gini feature selection was applied to determine the best input series in scenario iv ds iv the ssa decomposed data went under gini feature selection and in scenario v ds v the stl decomposed series had features selected 3 4 ai prediction outcomes in this study streamflow values were forecasted with the ann and two deep learning techniques cnn and lstm using the different modelling scenarios three different ai models were developed including ann lstm and cnn improvement in models was facilitated by integrating two different data decomposition techniques ssa and stl this generated hybrid models i e ssa ann ssa cnn ssa lstm stl ann stl cnn and ssl lstm after employing the robust gini feature selection method where ssl and stl decomposed inputs had already been selected using the gini screening process resulted in ssa gini ann ssa gini cnn ssa gini lstm stl gini ann stl gini cnn and stl gini lstm hybrid models the modelling parameters and the results of different ai models ann cnn lstm and the respective hybrid models before and after decomposition are given in table 8 the results clearly show that both the decomposition techniques ssa and stl did improve the model performances out of these two interestingly the ssa separation method gave better results than the stl separation method with all the models showing that ssa hybrid models are better the ssa ann registered an ns value of 0 9045 while stl ann recorded 0 7981 with cnn the ssa cnn had an ns value of 0 8336 but the stl cnn merely reached 0 7570 similarly an ns value of 0 8714 was registered by the ssa lstm and a lower value of 0 8701 was stl lstm the other statistics cc wi rmse and mae supports these results and evidently show that the ssa decomposition method works better in the forecasting of streamflow data evaluating the model performances based on the cc alone it can be seen that the ssa ann model has the best performance out of all the comparative models developed yet this was not consistently lucid from other metrics the ns rmse and mae on the other hand consistently show that the ssa ann model has outperformed the other models the ssa ann recorded ns 0 9045 wi 0 9764 rmse 0 4455 and mae 0 3055 table 8 essentially no single metric is able to fully capture the model performances due to inherent merits and weaknesses as such a combination of metrics is required chai and draxler 2014 the cc provides information on the level of linear association between forecasted and observed streamflow together with the direction of this association even though cc is parametric and insensitive to additive and proportional differences between corresponding observed and forecasted streamflow values hora and campos 2015 cc is widely used in hydrological modeling studies serving as a benchmark for performance evaluation but is oversensitive to high extreme values legates and mccabe 1999 willmott 1981 krause et al 2005 moriasi et al 2015 as per eq 1 the differences between the measured and predicted values are averaged over the data series the points with extreme streamflows diverge from the y x line in scatter plots causing the cc value to be sensitive to extreme streamflows which decreases the cc substantially general extreme values in a long term streamflow time series are very few that are characterized by sudden jumps within the series as in fig 2 of the measured streamflow values there are only 17 extreme values during the training period on the other hand the ns is a skill score computed by comparing the ability of the current model with a baseline model gupta et al 2009 the baseline in this case is the mean of the observed streamflow values and the ns is a widely used metric in the field of hydrology in the case of error measures both rmse and mae compute the aggregation of residuals nourani et al 2011 prasad et al 2017 however the rmse aggregates square of residuals while the mae takes into account the absolute values rmse is commonly used in model performance evaluations and has proven to work well for continuous long term simulations rmse is computed and reported in the same units as the model output of concern and is hence easy for readers to interpret harmel et al 2010 due to this difference in methods of aggregation of errors the high flows are well captured by rmse whereas moderate flow values are well captured by mae galelli and castelletti 2013 the analysis of eqs 4 and 5 reveals the differences between rmse and mae as the errors between the measured and predicted values in these equations are the main contrasting feature the willmott s index wi or index of agreement is a goodness of fit measure has bounds between 0 0 no correlation and 1 0 perfect fit similar to cc however high values of wi greater than 0 65 have been registered at times for poor model fits and the interpretation and physical meaning is somewhat unclear to determine the effective inputs with optimal features the set of predictors were screened via the gini feature selection algorithm section 3 2 however decreasing the number of input parameters with gini index did not yield sufficient results except only cc and wi values of stl gini cnn decreasing the inputs did make the modes parsimonious yet in this case if the streamflow rate values are decomposed and given to ai the performances of the models increased the present results showed that the gini feature selection algorithm was not a suitable feature screening tool leading to no significant overall improvement of the model accuracy decreasing the inputs might have caused a reduction in important features and further investigations on the gini feature selection need to be conducted in streamflow applications to determine its applicability a further evaluation of the best model ssa ann was performed with respect to the comparative models using the time series plot of the observed and forecasted streamflow values fig 8 a d the outcomes were quite concealed when all plots were made in one figure fig 8a however separating the plots revealed interesting outcomes stl ann largely overpredicted during validation and testing periods when compared to the observed values while the best ann model ssa ann captured high flow events well but was not very successful in low flow events fig 8b in very erratic events the ssa ann just showed a lower plateau which was seen in 3 events during the 2013 to 2016 testing period fig 8b in the case of the best cnn model fig 8c the ssa cnn was able to very well emulate the high flow and extreme events which is very important to predict extreme flood and disaster events this model also tried very well to emulate the low flow events which are equally important for drought management in contrast the lstm and its hybrids did not work well in either the high flow or the low flow events fig 8d similar to ann the lstm also simply provided a plateau in very low flows of testing data and always under predicted the high flow events as it can be seen from table 8 that the best performing models are ssa ann ssa lstm and ssa cnn fig 8e illustrates the scatterplots of these best modelling methods it seems that there is very serious competition in the one month ahead forecast between ssa ann ssa cnn and ssa lstm hybrid methods however ssa cnn model does better in closely following the observed streamflow data patterns this shows that ssa cnn model is able to learn the patterns well in the streamflow data after ssa decomposition is performed on the data series so far the analysis has provided compelling evidence of the superiority of ssa data decomposition in terms of the accuracy of the studied streamflow models in fig 8 a b a visual evaluation of forecasted streamflow relative to the observed data has been performed with scatterplots prepared in the testing period when the ann results in fig 9 are examined it is seen that although the r2 values of standalone ann and stl ann estimates are close to each other there is no point on the 1 1 line in standalone ann modelling and there are a significant number of 0 estimates it estimated away from the measured values at both low and high values in the ssa ann graph which gives the most successful result among all models all points are on or quite close to the 1 1 line when cnn results are examined it is seen that the standalone cnn model usually overpredicted and the stl cnn model underpredicted the ssa cnn model has produced more successful results than the other two cnn models and points close to the 1 1 line are observed while ssa and stl decomposition made a significant contribution in other methods there was no significant difference between lstm models in terms of r2 predictions are generally close to the 1 1 line as can be seen from fig 9 using the ssa decomposition method shows that the predicted values of the observed values converge as can be seen in the time series graphs models predicted less frequent current events with lower accuracy however it appears to predict small amounts of currents that appear very often with higher accuracy as a matter of fact it was seen that similar results were obtained in previous studies in evaluating the best ssa based models i e ssa ann ssa cnn and ssa lstm the scatter plot also clearly shows that the ssa ann is the best performing model this is because the scatter points are in close proximity of the y x line while in all other cases the points are scattered further from the y x line the coefficients of determination r2 for ssa based models were higher than other models ranging from 0 83 to 0 9105 and the largest r2 0 9105 was registered by the proposed ssa ann model the scatterplot further concurs with the results of the ns rmse and mae metrics to further affirm the results the taylor diagram was also used to graphically assess the model performance fig 10 the taylor plot ingeniously plots the relationship between the correlations and the standard deviations with respect to the observed data in a radial form the taylor diagram in fig 10 shows that the decomposition methods generally cause an improvement in prediction models the hybrid ssa ann model and ssa cnn had very close performances and were better than the other comparative models owing to the results from the predictor metrics table 8 the time series plots fig 8a d and the scatter plots fig 9 there is sufficient evidence that shows that the ssa algorithm is a better decomposition technique in terms of streamflow time series decomposition for ai modelling in addition the ann model combined with the ssa decomposition leading to ssa ann has the best performance in streamflow forecasting since ann is a black box approach a whole lot of input parameters are required to increase the forecasting performance which could have been the reason for decreased performance when gini feature selection decreased the number of inputs however more studies on the application of deep learning in streamflow forecasting are required to understand its future in hydrological applications a key limitation of the study is the data availability the data used were from oct 1996 sep 2016 i e 240 monthly data points this limitation has also been identified in studies by cheng et al 2020 where 41 years of monthly data were only available longer time series are required to extract ample persistence and non linearity information together with robust decomposition methodology such as double decomposition prasad et al 2020 could further be tested in independent studies 4 conclusion in terms of water resources management accurate estimation of streamflow is always at the core of the study particularly with the increase of droughts in recent periods accurate estimation of existing water resources and streamflow has become important in managing dams preventing floods and taking measures and rehabilitating river beds in this paper the estimation of monthly nallihan river streamflow based on artificial intelligence models and the effect of pre processing techniques on the estimates are studied due to the random behaviour of streamflow data series two data decomposition techniques ssa and stl pre processing decomposition approaches were applied in the hybridization of the deep learning models both the ssa and stl pre processing decomposition approaches addressed the randomness property of the data for the study region with significantly improved streamflow predictions from the hybrid models despite the gini index feature selection approach negatively affecting the accuracy of the estimation of streamflow the best decomposition method was found to be the ssa algorithm and in combination with ann i e the hybrid ssa ann was the best performing model in this study the decomposition of streamflows with the ssa approach is a carefully detailed process that significantly increased the prediction accuracy and is recommended to be used in hybrid methods in areas similar to this study area declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
4361,the nature of streamflow in the basins is stochastic and complex making it difficult to make an accurate prediction about the future river flows recently artificial neural based deep learning models with a nonlinear structure have become predominant in water engineering forecasting problems such as river flow predictions in this study we investigate the potential of singular spectral analysis ssa seasonal trend decomposition using loess stl and attribute selection pre processing approaches with the neural network methods in predicting monthly river streamflows in the nallihan stream turkey antecedent measured streamflow precipitation relative humidity and temperature data between the years 1996 and 2016 from the observing stations in the basin boundaries were used as model inputs under different scenarios using the correlations between the past measured variables to predict one step ahead flow data to compare the newer hybrid model performances evaluation metrics including coefficient of determination r2 nash sutcliffe efficiency ne willmott s index of agreement wi root mean square error mean absolute error together with judicious plots scatter plot time series and the taylor diagrams were utilized the developed hybrid ssa based models registered higher accuracy than other standalone neural networks models without pre processing approaches the r2 for ssa based models were higher ranging from 0 8300 to 0 9105 and the largest r2 0 9105 was registered by the proposed ssa ann model ssa ann models have also the highest ne and wi index values 0 9045 and 0 9764 respectively the outcomes revealed that based on ne the ssa decomposition increased the monthly streamflow prediction accuracy by 24 11 18 40 and 5 11 of respective ann cnn and lstm methods the ssa pre processing approach is able to unveil the embedded streamflow characteristics and could be further applied in basins with similar characteristics to attain more accurate predictions of river flows keywords data driven models deep learning attributes selections pre processing approaches ann cnn lstm gini index 1 introduction the management of sustainable water resources is crucial for any country around the world since many countries are having a very sensitive geopolitical climate surrounding this valuable resource successful and effective water resources planning and subsequent efficient management require timely data with accurate river flow predictions accurate river flow forecasts in arid and semi arid climates provide useful information to water managers for the allocation of available water for various purposes such as agriculture drinking and industrial usages in addition accurate forecasts of flows in wet climates play an important role in early flood warnings and preventing loss of life and property sattari et al 2012a kartal et al 2020 essentially river flow has a dynamic nature at temporal and spatial scales which interacts with the physical properties and meteorological variables of the basin hence river flow time series data have embedded nonlinear and stochastic structure that makes accurate prediction of river flows very difficult generally three main methods for modelling river flows are used including physical conceptual and data driven methods determining the complex physical properties of soil texture watershed and river networks within the basin together with radiative or other atmospheric forcing data that influences river flow is evidently difficult prasad et al 2017 sattari et al 2021 and leads to the adoption of necessary assumptions for this reason the forecasts of river flows via physical and conceptual models are difficult and assumptions induce a high level of unwarranted error mosavi et al 2018 on the other hand the data driven machine learning ml modelling approaches provide alternatives by achieving greater forecasting accuracy predictions without adopting the physics where the only requirement is high quality historical data prasad et al 2017 these data driven ml models offer a number of benefits as localized tools that operate locally using point based data and modelling frameworks not require initial forcings easy to develop in comparison to the physically based models and are free from underlying boundary conditions and physical assumptions a number of data driven machine learning techniques have been widely used in recent years for the simulation and forecasting of river flow data deo and sahin 2015 humphrey et al 2016 mehr et al 2014 onyari and ilunga 2013 prasad et al 2017 yaseen et al 2016 the models included neuronal based artificial neural networks ann el shafie et al 2007 karran et al 2014 li et al 2016 khazaee poul et al 2019 yang et al 2020 multilayer feed forward back propagation nn sattari et al 2012c recurrent neural networks rnn sattari et al 2012b to adaptive neuro fuzzy inference system anfis el shafie et al 2007 support vector machines sattari et al 2013 karran et al 2014 li et al 2016 and regression tree based m5 model tree sattari et al 2013 and random forest models wang et al 2015 shortridge et al 2016 li et al 2016 these all are standalone modelling approaches all these studies show that ai approaches have a better chance of increased predictability of streamflow however standalone models do not give appropriate results due to the complexity of the data structure with evolving science and technology new and versatile deep learning models have surfaced rnn is a type of deep nn model which creates a loop and provides useful historical information in this way the information of the previous time can be used and the new information can be obtained from the old information lecun et al 2015 apaydin et al 2020 developed rnn based deep learning approaches for predicting reservoir inflows in turkey in addition long short term memory lstm networks which have rnn architecture have been introduced to overcome the problem of training and memory preservation in long sequencing data ni et al 2020 the deep learning approach lstm has been used in forecasting applications the advantage of lstm is the ability to learn long term dependencies between the network s input and output provided hence kratzert et al 2018 developed the lstm model for rainfall runoff modelling in 241 basins the results showed that the lstm model was superior to the sacramento soil moisture accounting model coupled with the snow 17 model and other models lstm has also been recently applied in flood susceptibility prediction fang et al 2020 flood forecasting kao et al 2020 and streamflow forecasting cheng et al 2020 studies the results showed that deep learning approaches were successful in these prediction studies the streamflow time series consists of the trend seasonality periodic motion and error components with irregular random movements leading to inherently non linear complex and non stationary time series therefore different data pre processing approaches such as decomposition techniques are necessary to increase the forecasting accuracy of the respective models the data decomposition techniques that have been used include discrete wavelet transformations deo et al 2016a 2016b and maximum overlap dwt modwt prasad et al 2017 the dwt exhibits challenges of decimation effect induced in wavelet coefficients while both dwt and modwt require a suitable user defined mother wavelet which is time consuming to determine chen et al 2012 prasad et al 2019 an apt decomposition method separates the inherent components and presents the sub series to the model in an organized manner in this study two decomposition techniques seasonal trend decomposition using loess stl and singular spectrum analysis ssa are applied for data decomposition that are found to properly unveil and present the underlying features within the data wen et al 2018 in addition for high model performances the input features need to be properly selected for parsimonious models input selection methods used in literature for hydrological applications include but are not limited to cross correlation partial autocorrelations average mutual information bhattacharya and solomatine 2005 minimum redundancy maximum relevancy onyari and ilunga 2013 bootstrap ranked mutual information quilty et al 2016 boruta feature selections prasad et al 2019 and in many cases were from hydrological expertise campolo et al 2003 deo et al 2017a 2017b 2016b 2016a deo and sahin 2015 2016 2017 prasad et al 2019 in this study the gini index feature selection method is applied for developing input combination scenarios with the aim of prediction model accuracy improvement integration of data pre processing adoption of feature selections and optimization algorithms into artificial intelligence ai modelling approached leads to hybrid models the hybrid methods offer increased prediction accuracy in comparison to traditional standalone ai methods in river flows fahimi et al 2017 karran et al 2014 developed hybrid wavelet ann and wavelet svr for predicting daily streamflow in contrasting climate regimes while yaseen et al 2018 trialed the wavelet elm model following that dariane and azimi 2018 utilized ssa and genetic algorithm based input selection approaches in river flow forecasting and found that the accuracy increased the grey wolf optimization algorithm has also been applied in ai modelling to increase the accuracy of monthly streamflow predictions tikhamarine et al 2020 in another recent study integrated ensemble based and optimized models have been developed for predicting reservoir inflows ramaswamy and saleh 2020 overall hybrid models have been found to perform better in comparison to standalone models however literature shows very limited usage of hybrid deep learning approaches in hydrological applications only a recent study by bui et al 2020 hybridized the deep neural network dnn integrated with swarm intelligence algorithms for flood susceptibility mapping in vietnam chang et al 2020 proposed a machine learning approach to significantly improve existing flood warning systems and provide early warning to reservoir management zhu et al 2020 used feed forward neural network ffnn and dl technique to predict monthly lake water level the results indicate that the dl model did not show significant superiority over the traditional ffnn model indeed the ffnn model slightly outperformed the dl model for 33 of the 69 lakes more recently kao et al 2021 developed a hybrid machine learning model i e the stacked autoencoder with rnn to support emergency management in areas affected by flood hazards which achieved accuracies of r2 values high 0 95 the literature clearly shows that the data driven models which are defined as competitors of the conceptual models are indeed useful in river flow forecasts with hybrids via data pre processing and feature selection giving a competitive advantage to the hybrids another important feature is the emergence of deep learning methodologies however the performance of different deep learning methods has not been sufficiently investigated in predicting monthly river flows let alone the hybridized models thus the aim of this study is to investigate the potentials of ssa and stl data decomposition pre processing techniques combined with the gini index feature selection approach integrated with ann convolutional neural network cnn and lstm deep learning models for monthly flows predictions in nallihan river turkey the study led to the development of ssa cnn ssa lstm ssa ann stl cnn stl lstm stl ann models and similar gini hybrid models which are compared to non hybrid ann cnn and lstm models in addition the sensitivity of different input scenarios and the effect of different parameters and lag times on the flows are also determined in predicting monthly flows 2 material and methods the study was conducted in the nallihan region which is located within the continental climate bounds of turkey s sakarya basin fig 1 the surrounding districts harbor 18 of agriculture 51 of forest 3 of meadow and pasture and 28 of the non agricultural area ceylan et al 2009 the monthly streamflow rates between the years 1996 and 2016 for nallihan streamflow observation station were acquired from the general directorate of hydraulic works in the sakarya basin fig 2 shows the time series of historical observed flow data at nallihan station the highest streamflow rate recorded during this period was 15 67 m3 s in march 2009 while the average flow rate between 1996 and 2016 was 1 71 m3 s an interesting feature noted was that the streamflow between 2009 and 2016 was higher than previous years flows erogluer and apaydin 2020 the meteorological data recorded at nallihan beypazari mihaliccik goynuk mudurnu and eskisehir stations of the turkish state meteorological service were used in this study the location information of the stations and the data duration are given in table 1 nallihan has a semi arid climate with an average temperature of 12 1 c nallihan s climate is influenced by central anatolia and the western black sea climate although spring autumn and winter receive high rainfall the summer season does not experience much rainfall winter seasons are not too cold erogluer and apaydin 2020 the measured antecedent streamflow data up to three months were used in the model and also for calculating the average monthly values in addition precipitation temperature and relative humidity values are also used in the model development a summary of statistical parameters of monthly hydro meteorological variables is presented in table 2 the spatial interpolation method proposed by apaydin et al 2004 was applied to compute the spatial mean of hydro meteorological parameters of nallihan area as illustrated in table 2 there is a relatively low correlation between streamflow meteorological variables and the precipitation relative humidity and temperature values therefore antecedent monthly streamflow time series i e qt 1 qt 2 qt 3 were used as the inputs for the models monthly averages of hydro meteorological parameters used in the study are given in fig 3 it is seen that the streamflow increased in the first four months of the year and the highest value was recorded in april 2 1 model development for model development a ratio of 70 15 15 was used in training validation and testing stages respectively table 3 the model development was carried out in two parallel phases after the data was prepared in the first phase all meteorological data the antecedent three month and long term monthly mean streamflow data were taken into account as inputs to the cnn lstm and ann models in the second parallel phase streamflow data series were decomposed into their component series via ssa and stl methods subsequently the gini index method was utilized for parameter input selections and the salient inputs were channelled to the respective ai models the flow chart of the model development is presented in fig 4 this resulted in standalone ssa based hybrid models stl based hybrid models ssa gini based and stl gini based models the results obtained from these models were comprehensively evaluated using comparison metrics and diagnostic plots all the codes used are provided in github https github com hapaydin decompose 2 1 1 decomposition techniques used in the study two robust decomposition techniques were used in this study as outlined in this section 2 1 1 1 singular spectral analysis ssa the model free approach ssa is a very efficient methodology to analyze time series successfully which has been used in different fields of science ssa is executed in four steps embedding singular value decomposition grouping and diagonal averaging the ssa algorithm decomposes the original time series into noise trend and seasonality components liu et al 2018 the spectrum analysis via the singular value decomposition is the most important step in ssa decomposition ssa has been used in the medical field to resolve biomedical issues and to perform quantitative genetic analysis for further information readers are recommended to refer to golyandina and zhigljavsky 2013 golyandina et al 2018 golyandina 2019 and brunton and kutz 2019 2 1 1 2 seasonal trend decomposition using loess stl is another robust and versatile statistical method for decomposing time series into seasonality trend and residual components the trend illustrates a sequence of data points that varies across a continuous time axis while the seasonality is a continuous and regular pattern and it recurs at a fixed interval of time the residual represents the noise or randomness chen et al 2020 and describes random fluctuations or unpredictable changes the regression technique loess in stl estimates the nonlinear relationships within the different components using local regression data to match the curve the first step of stl decomposition is to approximate the trend line of the given time series which commonly is calculated from the polynomial model then de trending of series is conducted by subtracting time series data with the approximated trend line next the seasonal component is determined by populating the whole data by subtracting seasonal data from the time series data the seasonality component is removed or the time series is de seasonalised finally the residuals are determined which essentially are the leftovers after removing the seasonal and trend components hyndman and athanasopoulos 2018 wen et al 2018 python program using numpy https numpy stl readthedocs io en latest and pyssa https github com aj cloete pssa libraries was used to decompose streamflow into elements using ssa and stl decomposition method 2 1 2 feature selection via gini index feature selection is an important process of selecting the most relevant inputs whilst reducing the number of input parameters feature selection is one of the main steps of machine learning modelling as irrelevant or wrong features can negatively impact model results the objectives of selecting features are diverse the most important are a avoid overfitting and improve model performance b provide faster and less computationally expensive models and c gain deeper insights into the processes underlying the generated data saeys et al 2007 the gini index feature selection method adopted in this study is used for imbalanced data which is a common characteristic of real world hydrological applications liu et al 2019 pilnenskiy and smetannikov 2020 gini index feature selection algorithm is an embedded method with a tree based modelling approach and is also able to measure the purity of the feature aman et al 2019 in the gini index operation select k best function has been selected as univariatefilter pilnenskiy and smetannikov 2020 in addition the gini index feature selection method provides the best result when the number of selected features increases some of the real world applications include fraud detection classification of texts and illness diagnosis the gini index method in the python library named itmo fs developed by pilnenskiy and smetannikov 2020 was used to determine the highest effect among the variables consisting of past hydrological meteorological and time index values used in the study 2 1 3 deep learning modelling approaches the modelling approaches used in this study are all classified as neural networks nns nns are a set of learning algorithms that mimic the human brain to recognize relationships and patterns it consists of an input layer multiple hidden layers and an output layer and information or data flows through these layers each of the connections in these networks is associated with respective connection weights and has a threshold activation value governing the response of these neurons is special function or formula called the activation function during the training process a set of input data is provided together with corresponding outputs and the network adjusts the parameters tavanaei et al 2019 minimizing a cost function it checks the deviation of the result and re adjusts the parameters on each of the neurons using training algorithm the weights and threshold values are adjusted to reach the correct output during the learning or training process which is repeated a number of times until near correct output occurs with nonlinear activation functions nns are nonlinear modelling approaches and streamflow data has nonlinearity features as discussed earlier on for this study 200 neurons in input layer l1 and 100 neurons in hidden layer l2 gave the optimal results table 4 the cost function used was mse while using a sequential model these networks can be made deeper by increasing the number of hidden layers deep learning is a part of machine learning with larger networks that are capable enough to learn unstructured or unlabelled data these models can learn relevant features from large amounts of unstructured data that humans would normally take decades to understand and process goodfellow et al 2016 the deep learning model convolutional neural network cnn used in this study takes the training features as inputs and passes it through a series of convolution layers and pooling processes to fully connected layers using mathematical operations and kernels the machine observes features as an array of data albawi et al 2017 this network focuses on the movement of the cell and the state of the current cell s influence on the movement of the future cell in cnn 16 filters in l1 and 8 filters in l2 with rectified linear unit relu worked the best as presented in table 4 the filters represented by a vector of weights indicate the dimensionality of the output space in cnn in other words it shows the number of different results or channels which is required to convolve the inputs it is similar to a filter encountered in signal processing providing a measure of how close a patch of input resembles a feature whereby each filter is regarded as a single storage template pattern during the formation of the convolution of these filters across the corresponding inputs the similarity between the stored template and different locations in the inputs is determined in the training stages of cnn the minimizing of a cost function is achieved via systemic tuning of the abovementioned parameters including the filters the other deep learning model used in this study is long short term memory lstm is a recurrent neural network which is capable of learning order dependency in sequence prediction problems natural streamflow data is highly dependent on persistence which the lstm model can capitalize on during the training process however is a shortcoming of anns unlike traditional anns lstm takes windowed time steps as input and processes it step by step to learn the persistence in the series in addition lstm has advantages over classical modelling approaches as they can fit non linear streamflow data series without the need to specify the type of non linearity hence lstm modelling approach was adopted in this study lstm is a complex and intricate deep learning technique which has a chain structural process with four nns and different memory blocks called cells hua et al 2019 these cells retain all the information and the gates manipulate the memory there are three types of gates including forget gate input gate output gate the input gate is used to add useful data to the cell state while the forget gate removes the cells which are no longer useful the output gate is used to extract useful data from the current cell state which is represented as output during training the network parameters weights and biases are updated on the basis of the loss function in each iteration the mean squared error mse was used as the objective criterion essentially a subset called the batch or mini batch of the training data is used in respective iterations the number of samples per batch was 256 in this study in lstm modelling 200 neurons in l1 200 neurons in l2 and 100 neurons in l3 generated the best forecasts as summarized in table 4 to avoid overfitting weight regularisation is of utmost importance and was adopted the models were developed in python platform using matplotlib pandas math keras sci kit learn hydroerr libraries in google colab hunter 2007 the pandas development team 2010 chollet et al 2015 pedregosa et al 2011 roberts et al 2018 during the model development stage it is imperative to optimize and fine tune the models to get optimal outputs the alternative learning rate lr decay de and epochs of the respective models are determined using the grid search algorithm for respective ai modelling the learning rate ranged from 1e 1 to 1e 9 decay from 1e 1 to 1e 9 and 50 100 500 1000 1500 and 2000 epochs have been tried table 4 2 2 evaluation metrics four different well known metrics were calculated for evaluating the models eq 1 4 i pearson correlation coefficient cc is used to obtain the strength and direction of the linear relationship between the predicted value and observed value as 1 cc i 1 n p i p d i d σ i 1 n p i p 2 σ i 1 n d i d 2 ii nash sutcliffe coefficient ns describes the accuracy of model outputs 2 ns 1 i 1 n p i d i 2 i 1 n p i p 2 iii willmott index wi willmott 1982 is used to express the accuracy of model outputs 3 w i 1 i 1 n y i x i 2 i 1 n y i x x i x 2 iv root mean squared error rmse is the standard deviation of the residuals prediction errors 4 rmse 1 n σ i 1 n p i d i 2 v mean absolute error mae is commonly used in forecasting time series 5 mae 1 n i 1 n p i d i where n is the number of outputs pi is the i th predicted output and di is the i th desired observed output hyndman and athanasopoulos 2018 hyndman and koehler 2006 3 results 3 1 stationarity test outcomes it is imperative to perform some tests and data pre processing in hydrological modelling studies to increase the efficiency and accuracy of the models the first thing is to determine whether the data series is stationary the stationarity of the data was tested by adfuller and augmented dickey fuller adf test to determine the usability of decomposition techniques flandrin 1998 bógalo et al 2017 harmouche et al 2018 the results of the tests are shown in table 5 it can be realized that result of the test 2 944265 is higher than the value of 3 459620 at 1 but less than the value of 2 874415 at the 5 level this suggests that the null hypothesis can be rejected with a significance level of less than 5 i e a low probability that the result is a statistical fluke rejecting the null hypothesis implies that the process has no unit root and in turn that the time series is stationary or does not have time dependent structure 3 2 decomposition pre processing outcomes in this study two different data decomposition techniques were used to increase the predictive potential of the models fig 5 illustrates the outcomes of the eigenvalues and singular values data series decomposition by the ssa method of nallihan river flow data both graphics were examined in terms of slope and contribution and then the components with similar weights were determined when the signal components in fig 5 are evaluated it was determined that it is appropriate to reconstruct the 4 main elements comp0 0 comp1 1 2 comp2 3 8 and comp3 9 19 the signals were then combined to yield the streamflow series as in fig 6 since the decomposed signals after the 20th component did not have any significant effect these were not taken into consideration after this stage hassani 2007 gillard and knight 2014 de menezes et al 2015 decomposition results of nallihan streamflow data after the stl method are given in fig 7 it can be seen from figs 2 and 7a that between months 149 and 151 feb apr 2009 extreme values resulted and therefore the data deviated from zero to very large deviations in the residual graph fig 7d the extreme values are largely seen in the decomposed trend component and the residual the seasonality component was not affected by the extreme event which shows that the decomposition technique properly depicted the seasonality within the series 3 3 feature selection outcomes in modelling studies the outcomes are very much dependent on the input data hence it is desired that to reach the best results the least number of salient input parameters are to be selected in this study besides meteorological data precipitation relative humidity and temperature and hydrological data 1 3 months antecedent streamflow and long term monthly mean streamflow the decomposed streamflow components obtained by two different seasonal decomposition methods were pooled as the potential inputs in this case depending on the decomposition method 11 12 input series were used but increasing the number of input data creates measurement and model training difficulties hence a robust input selection is required for determining the most effective ones from the dataset in this study the gini index method is utilized for feature selection and the results are given in table 6 since ssa and stl methods produced different numbers and sizes of components the gini index was applied to two different data sets after ssa and feature selection the parameters humidity qt 1 and qt 2 and hydro meteorological data given table 6 were determined as the most effective ones humidity temperature t and qt 1 are the most influential parameters of stl decomposition methods among the input parameters those found to be statistically significant 5 according to the gini index were selected for modelling using the outcomes of feature selection in table 6 four main data sets were formed meteorological hydrological ssa outputs and stl outputs the modelling was performed in five scenarios using these data sets to allow for the development of novel modelling approaches together with the notion of studying the effects of input selections on the model performances the scenarios are displayed in table 7 in scenario i the dataset used is labelled ds i where all inputs have been channelled to the model while in scenario ii ds ii the data sets after ssa decomposition were utilized while in scenario ii ds iii the stl decomposed data were used as inputs in both scenarios iv and v the gini feature selection was applied to determine the best input series in scenario iv ds iv the ssa decomposed data went under gini feature selection and in scenario v ds v the stl decomposed series had features selected 3 4 ai prediction outcomes in this study streamflow values were forecasted with the ann and two deep learning techniques cnn and lstm using the different modelling scenarios three different ai models were developed including ann lstm and cnn improvement in models was facilitated by integrating two different data decomposition techniques ssa and stl this generated hybrid models i e ssa ann ssa cnn ssa lstm stl ann stl cnn and ssl lstm after employing the robust gini feature selection method where ssl and stl decomposed inputs had already been selected using the gini screening process resulted in ssa gini ann ssa gini cnn ssa gini lstm stl gini ann stl gini cnn and stl gini lstm hybrid models the modelling parameters and the results of different ai models ann cnn lstm and the respective hybrid models before and after decomposition are given in table 8 the results clearly show that both the decomposition techniques ssa and stl did improve the model performances out of these two interestingly the ssa separation method gave better results than the stl separation method with all the models showing that ssa hybrid models are better the ssa ann registered an ns value of 0 9045 while stl ann recorded 0 7981 with cnn the ssa cnn had an ns value of 0 8336 but the stl cnn merely reached 0 7570 similarly an ns value of 0 8714 was registered by the ssa lstm and a lower value of 0 8701 was stl lstm the other statistics cc wi rmse and mae supports these results and evidently show that the ssa decomposition method works better in the forecasting of streamflow data evaluating the model performances based on the cc alone it can be seen that the ssa ann model has the best performance out of all the comparative models developed yet this was not consistently lucid from other metrics the ns rmse and mae on the other hand consistently show that the ssa ann model has outperformed the other models the ssa ann recorded ns 0 9045 wi 0 9764 rmse 0 4455 and mae 0 3055 table 8 essentially no single metric is able to fully capture the model performances due to inherent merits and weaknesses as such a combination of metrics is required chai and draxler 2014 the cc provides information on the level of linear association between forecasted and observed streamflow together with the direction of this association even though cc is parametric and insensitive to additive and proportional differences between corresponding observed and forecasted streamflow values hora and campos 2015 cc is widely used in hydrological modeling studies serving as a benchmark for performance evaluation but is oversensitive to high extreme values legates and mccabe 1999 willmott 1981 krause et al 2005 moriasi et al 2015 as per eq 1 the differences between the measured and predicted values are averaged over the data series the points with extreme streamflows diverge from the y x line in scatter plots causing the cc value to be sensitive to extreme streamflows which decreases the cc substantially general extreme values in a long term streamflow time series are very few that are characterized by sudden jumps within the series as in fig 2 of the measured streamflow values there are only 17 extreme values during the training period on the other hand the ns is a skill score computed by comparing the ability of the current model with a baseline model gupta et al 2009 the baseline in this case is the mean of the observed streamflow values and the ns is a widely used metric in the field of hydrology in the case of error measures both rmse and mae compute the aggregation of residuals nourani et al 2011 prasad et al 2017 however the rmse aggregates square of residuals while the mae takes into account the absolute values rmse is commonly used in model performance evaluations and has proven to work well for continuous long term simulations rmse is computed and reported in the same units as the model output of concern and is hence easy for readers to interpret harmel et al 2010 due to this difference in methods of aggregation of errors the high flows are well captured by rmse whereas moderate flow values are well captured by mae galelli and castelletti 2013 the analysis of eqs 4 and 5 reveals the differences between rmse and mae as the errors between the measured and predicted values in these equations are the main contrasting feature the willmott s index wi or index of agreement is a goodness of fit measure has bounds between 0 0 no correlation and 1 0 perfect fit similar to cc however high values of wi greater than 0 65 have been registered at times for poor model fits and the interpretation and physical meaning is somewhat unclear to determine the effective inputs with optimal features the set of predictors were screened via the gini feature selection algorithm section 3 2 however decreasing the number of input parameters with gini index did not yield sufficient results except only cc and wi values of stl gini cnn decreasing the inputs did make the modes parsimonious yet in this case if the streamflow rate values are decomposed and given to ai the performances of the models increased the present results showed that the gini feature selection algorithm was not a suitable feature screening tool leading to no significant overall improvement of the model accuracy decreasing the inputs might have caused a reduction in important features and further investigations on the gini feature selection need to be conducted in streamflow applications to determine its applicability a further evaluation of the best model ssa ann was performed with respect to the comparative models using the time series plot of the observed and forecasted streamflow values fig 8 a d the outcomes were quite concealed when all plots were made in one figure fig 8a however separating the plots revealed interesting outcomes stl ann largely overpredicted during validation and testing periods when compared to the observed values while the best ann model ssa ann captured high flow events well but was not very successful in low flow events fig 8b in very erratic events the ssa ann just showed a lower plateau which was seen in 3 events during the 2013 to 2016 testing period fig 8b in the case of the best cnn model fig 8c the ssa cnn was able to very well emulate the high flow and extreme events which is very important to predict extreme flood and disaster events this model also tried very well to emulate the low flow events which are equally important for drought management in contrast the lstm and its hybrids did not work well in either the high flow or the low flow events fig 8d similar to ann the lstm also simply provided a plateau in very low flows of testing data and always under predicted the high flow events as it can be seen from table 8 that the best performing models are ssa ann ssa lstm and ssa cnn fig 8e illustrates the scatterplots of these best modelling methods it seems that there is very serious competition in the one month ahead forecast between ssa ann ssa cnn and ssa lstm hybrid methods however ssa cnn model does better in closely following the observed streamflow data patterns this shows that ssa cnn model is able to learn the patterns well in the streamflow data after ssa decomposition is performed on the data series so far the analysis has provided compelling evidence of the superiority of ssa data decomposition in terms of the accuracy of the studied streamflow models in fig 8 a b a visual evaluation of forecasted streamflow relative to the observed data has been performed with scatterplots prepared in the testing period when the ann results in fig 9 are examined it is seen that although the r2 values of standalone ann and stl ann estimates are close to each other there is no point on the 1 1 line in standalone ann modelling and there are a significant number of 0 estimates it estimated away from the measured values at both low and high values in the ssa ann graph which gives the most successful result among all models all points are on or quite close to the 1 1 line when cnn results are examined it is seen that the standalone cnn model usually overpredicted and the stl cnn model underpredicted the ssa cnn model has produced more successful results than the other two cnn models and points close to the 1 1 line are observed while ssa and stl decomposition made a significant contribution in other methods there was no significant difference between lstm models in terms of r2 predictions are generally close to the 1 1 line as can be seen from fig 9 using the ssa decomposition method shows that the predicted values of the observed values converge as can be seen in the time series graphs models predicted less frequent current events with lower accuracy however it appears to predict small amounts of currents that appear very often with higher accuracy as a matter of fact it was seen that similar results were obtained in previous studies in evaluating the best ssa based models i e ssa ann ssa cnn and ssa lstm the scatter plot also clearly shows that the ssa ann is the best performing model this is because the scatter points are in close proximity of the y x line while in all other cases the points are scattered further from the y x line the coefficients of determination r2 for ssa based models were higher than other models ranging from 0 83 to 0 9105 and the largest r2 0 9105 was registered by the proposed ssa ann model the scatterplot further concurs with the results of the ns rmse and mae metrics to further affirm the results the taylor diagram was also used to graphically assess the model performance fig 10 the taylor plot ingeniously plots the relationship between the correlations and the standard deviations with respect to the observed data in a radial form the taylor diagram in fig 10 shows that the decomposition methods generally cause an improvement in prediction models the hybrid ssa ann model and ssa cnn had very close performances and were better than the other comparative models owing to the results from the predictor metrics table 8 the time series plots fig 8a d and the scatter plots fig 9 there is sufficient evidence that shows that the ssa algorithm is a better decomposition technique in terms of streamflow time series decomposition for ai modelling in addition the ann model combined with the ssa decomposition leading to ssa ann has the best performance in streamflow forecasting since ann is a black box approach a whole lot of input parameters are required to increase the forecasting performance which could have been the reason for decreased performance when gini feature selection decreased the number of inputs however more studies on the application of deep learning in streamflow forecasting are required to understand its future in hydrological applications a key limitation of the study is the data availability the data used were from oct 1996 sep 2016 i e 240 monthly data points this limitation has also been identified in studies by cheng et al 2020 where 41 years of monthly data were only available longer time series are required to extract ample persistence and non linearity information together with robust decomposition methodology such as double decomposition prasad et al 2020 could further be tested in independent studies 4 conclusion in terms of water resources management accurate estimation of streamflow is always at the core of the study particularly with the increase of droughts in recent periods accurate estimation of existing water resources and streamflow has become important in managing dams preventing floods and taking measures and rehabilitating river beds in this paper the estimation of monthly nallihan river streamflow based on artificial intelligence models and the effect of pre processing techniques on the estimates are studied due to the random behaviour of streamflow data series two data decomposition techniques ssa and stl pre processing decomposition approaches were applied in the hybridization of the deep learning models both the ssa and stl pre processing decomposition approaches addressed the randomness property of the data for the study region with significantly improved streamflow predictions from the hybrid models despite the gini index feature selection approach negatively affecting the accuracy of the estimation of streamflow the best decomposition method was found to be the ssa algorithm and in combination with ann i e the hybrid ssa ann was the best performing model in this study the decomposition of streamflows with the ssa approach is a carefully detailed process that significantly increased the prediction accuracy and is recommended to be used in hybrid methods in areas similar to this study area declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
4362,karst aquifers are difficult to model due to their complex conduit networks that are heterogeneous and anisotropic here we present a heuristic algorithm for modeling karst networks by calculating minimum effort paths based on our knowledge of karst evolution that is constrained by field observations the methodology consists of a using discrete fracture network models along with fracture parameter estimates e g frequency extent spacing and apertures to equivalent porous media properties e g size of the representative elementary volume hydraulic conductivity tensor b rendering the velocity field using the tensor field coupled with the 3d regional hydrogeology that includes likely recharge and discharge locations and c generating karst conduits using the anisotropic fast marching algorithm afma this approach a avoids the need to model discrete fractures by replacing them with a tensor that incorporates small scale dense and interconnected fractures b assumes that conduits follow the minimum effort path from sinkholes toward springs and c efficiently accounts for regional hydrogeology anisotropy and regional flow conditions within 3d conduit networks the application of the proposed approach in wulongdong basin in hubei province china is taken as the demonstrate example compared to other techniques this methodology substantially improves computational efficiency and reduces computer memory thus providing a useful tool for generating ensembles of possible karstic conduit networks to analyze flow and transport prediction uncertainty associated with a lack of knowledge about network geometry keywords anisotropic fast marching algorithm karst conduit networks hydraulic conductivity tensor discrete fracture networks equivalent porous medium 1 introduction karst aquifers currently provide drinking water for 15 of the world s population and are the only available water resource in some basins parise et al 2018 flow and transport through these aquifers are difficult to characterize due to their heterogeneity and anisotropy that result from their multi level porosity consisting of pores fractures and large conduits there are also different temporal scales and water quality characteristics with 90 95 of total storage within the rock matrix while 90 95 of runoff occurs through larger macro pores worthington 2003 worthington et al 2000 therefore both matrix and conduits must be considered when modeling karst aquifers for groundwater protection and management or to investigate contamination borghi et al 2012 király 1979 was the first to numerically model conduits in karst landscapes which has been followed by a wide number of techniques over the past forty years ghasemizadeh et al 2012 green and fratesi 2019 a notable feature of these numerical simulation techniques is that the geometry of the conduit networks is specified prior to flow and transport modeling yet the conduit geometry is often unknown because they are inaccessible seldom exposed by boreholes and difficult to detect by geophysical techniques especially when their aperture is small parise et al 2018 borghi et al 2012 a few techniques have been developed to model the geometry of karst conduit networks using speleogenesis models kaufmann and braun 2016 2000 dreybrodt et al 2005 these models use physico chemical processes to generate karst networks by coupling calcite dissolution with flow equations to generate a conduit based on a single fracture a network of fractures or a matrix with embedded fractures while this approach provides insight into conduit evolution in hypothetical idealized karst systems kaufmann and braun 2016 dreybrodt et al 2005 and was applied on a regional scale by using implicit switching algorithm and a coarser spatial discretization of the conduit cells de rooij and graham 2017 it s still difficult to generate realistic conduit networks due to its inability to reconstruct topography and paleo climatic conditions that prevailed during conduit formation de rooij and graham 2017 in addition these models are computationally challenging due to their need to solve highly nonlinear and coupled equations borghi et al 2012 approaches have also been developed to incorporate the geologic structure using geostatistical methods hendrick and renard 2016 jaquet et al 2004 viseur et al 2014 pardo igúzquiza et al 2012 generated individual conduit segments by resampling from a defined template and then generating the network topology using a diffusion limited aggregation method ronayne 2013 ronayne and gorelick 2006 used the non looping invasion percolation model proposed by stark 1991 to generate conduit networks while generating an accurate network by purely geo statistical methods remains an unresolved challenge de rooij and graham 2017 the method of pardo igúzquiza et al 2012 forces connections between the conduits and the resulting connectivity is not controlled by statistical input parameters ronayne s 2013 model defines a priori network a connectivity pattern more typical for stream networks than for conduit networks de rooij and graham 2017 the improved methods based on statistical characteristics are expected to eventually generate realistic patterns jouves et al 2017 collon et al 2017 pardo igúzquiza et al 2012 alternatively conduit networks may be generated uses a pseudo genetic algorithm henrion et al 2008 borghi et al 2012 which mimics the results of karst network structures produced by speleogenetical models without solving the complete kinetics of the system borghi 额头 2016 this approach based on the assume that water and thus karst conduits will follow the minimum effort path and generate the conduits in an iterative manner in which conduits are progressively widened using a heuris tic erosion potential collon et al 2012 simulated 3d branch work karst networks by a dijkstra s algorithm dijkstra 1959 the a algorithm hart et al 1968 extracts least cost paths between two given points using hydraulic conductivity information borghi et al 2016 2012 use the stochastic karst simulator sks pseudo genetic method in which the minimum effort paths between multi inlets and multi outlets are computed by a more accurate eikonal algorithm isorropic fast marching algorithm ifma based on the erosion potential hydraulic conductivity tensor pseudo genetic method is fast to account for the main factors controlling the 3d geometry of the network and has good potential to generate realistic conduit networks borghi et al 2012 to date pseudo genetic algorithm requires priority to generate a discrete fracture networks map both the erosion potential hydraulic conductivity and the best first search algorithm are isotropic so pseudo genetic algorithm is limited however to karst groundwater systems where conduits are primarily influenced by large scale features e g regional faults computational limitations i e speed memory preclude its use in systems with numerous small scale dense and interconnected fracture networks such as those found in south china for this situation we propose the use of an equivalent porous medium epm that treats our dense fracture network as homogeneous but anisotropic within each hydrostratigraphic unit and using an anisotropic best first search algorithm the equivalent continuum approach is common applied to simulate groundwater flow over large area with dense fracture networks because each local grid element is smaller than the hydrogeological unit at the regional scale borelli and pavlinz 1965 pankow et al 1986 the parameters that representative elementary volume rev size and hydraulic conductivity tensor k are used to define the equivalent porous medium epm bear 1972 long et al 1982 rong et al 2013 the existence and size of rev directly determine wheather a locally fracture network can be approximated by an equivalent porous medium at the scale of a rev and the symmetric hydraulic conductivity tensor is used to describe the anisotropic permeability snow 1969 oda 1985 chen et al 2008 lang et al 2014 the discrete fracture network dfn model is often used to determine rev sizes and hydraulic conductivity tensors by simulating water flow in individual fractures zheng et al 2020 li et al 2020 guo et al 2018 while fracture geometric parameters e g frequency extent spacing aperture are commonly required in these model as a priori but it is impossible to know the geometric parameters of all fractures thus stochastic approaches e g monte carlo simulation are used to develop the fracture networks using geologic survey data to generate random fracture networks that honor the statistical distribution of field mapped fractures with respect to their geometric parameters wang et al 2013 robertson 1970 was one of the first to conduct a field study of fracture networks using 9 000 fractures mapped in the debeer s mine in south africa fracture lengths at this site are equal in their strike and dip directions baecher et al 1977 subsequently proposed a fracture network model which has become widely adopted that assumes fractures discs that are distributed randomly and independent of each other many fracture flow models that are based on baecher and dfn models e g fracman mofrac and adfne have been developed as computational platforms have increased in speed and memory many of these models are closed source and expensive however the matlab toolbox adfne1 5 alghalandis 2018 is used by many studies chen et al 2019 feng et al 2020 liang 2019 because it is open source free comprehensive and convenient for secondary modifications yet the original adfne1 5 code is computationally intensive if used for tens of thousands of fracture nodes and is limited by computational speed and computer memory adfne1 5 also lacks the fability to calculate hydraulic conduicity tensors which are needed in anisotropic media in this paper we use the secondary development discrete fracture networks dfn seepage simulator matlab toolbox adfne1 5 alghalandis 2018 along with field measurements to determine equivalent continum parameters the rev size and k within a karstic multi aquifer groundwater system these tensors are then linked with regional topographic sinkholes and hydrogeologic recharge and discharge locations features to create an initial velocity field the most likely karst conduit network is then generated by finding the minimum effort paths between inflows and outflows using the anisotropic fast marching algorithm afma a case study in a 14 31 km2 karstic wulongdong basin in hubei province china is presented to evaluate the suitability of the method 2 methodology 2 1 determination of the epm fluid flow interacts with carbonate rock by dissolution along flowpaths defined by the discrete fracture network dfn that connects boundary inflows with outflows dreybrodt et al 2005 continued dissolution enlarges these fractures forming conduits that reinforce subsequent dissolution and enlargement while modeling flow and transport through these discrete fracture networks provides the ability to accurately account for physico chemical processes the computational burden of solving for flow and transport through fracture networks in karst systems that may contain 109 fractures is daunting instead it is common to represent these networks using an epm to specify our problem we start with darcy s law that relates flux q to the hydraulic gradient h in homogeneous anisotropic media using the hydraulic conductivity tensor k 1 q i k i j h j i 1 2 3 j 1 2 3 where the hydraulic conductivity tensor has the form 2 k k 11 k 12 k 13 k 21 k 22 k 23 k 31 k 32 k 33 the eigenvalues and eigenvectors of this tensor can be extracted to yield the principal axes and their orientation e g their principal direction of flows so that equation 2 can be written as 3 k k 1 0 0 0 k 2 0 0 0 k 3 where k 1 k 2 and k 3 are the principal values in the rotated coordinate system these values can then be used to fit the ellipsoid long et al 1982 4 x 2 k 1 2 y 2 k 2 2 z 2 k 3 2 1 where y and z represent the major intermediate and minor axes of the rotated tensor use of equation 1 in heterogeneous porous media assumes that a locally defined network can be approximated by an epm at the scale of a rev where anisotropy is described using the symmetric hydraulic conductivity tensor and homogeneity is defined at the scale of the rev long et al 1982 bear 1972 2 1 1 determining the rev the general process for developing a discrete fracture network dfn consists of a measuring fracture geometric paremeters e g frequency trace lengths orientations and apertures in a geologic exposure using a statistical window b performing a statistical analysis for each geometric element where similar fractures are grouped according to their occurrence with a probability distribution model selected and its associated parameters estimated for each group and c generating synthetic fractures using monte carlo methods that honors the observed statistical behavior in this study discrete fracture networks are generated using the matlab toolbox adfne1 5 alghalandis 2018 that randomly assigns a position for fracture centers within a specified domain and then a circular fracture disk is created with a geometric properties that are prescribed using statistical distributions the three dimensional fracture networks are simulated by the following functions in a similar fashion alghalandis 2017 5 fnm d f n dim n d i p d d i p d i r d d i r b b x where fnm is the discrete fracture networks dim is the dimension n is the number of fractures dip and ddip are the mean and the standard deviation of dip angle respectively dir and ddir are the mean and the standard deviation of orientation box is the study volume x min y min z min x max y max z max to which the simulated fracture network is clipped fig 1 presents a realization of this approach showing how a synthetic discrete fracture network be constructed the number of fractures n is determined by the study volume and fracture volume density d3 m3 which is estimated using the method of wolfsberg 1997 that assumes parallel fractures so that 6 d 3 4 d 1 π e d 2 where d 1 is the line density m e d 2 is the average of the squared track length m2 once a fracture network has been constructed the rev is determined within which the hydraulic properties behave as though they are an equivalent porous medium this means that the bulk hydrologic behavior no longer depends on the characteristics of individual fractures but rather on the bulk properties of the fracture network the process for determining the appropriate rev scale consists of the following steps step1 a trial subdomain is created using a specified volume within the global domain that contains the entire fracture network as shown in fig 1 step2 equivalent 1d pipes are used to represent the fluid flow in 2d fractures cacas et al 1990 parise et al 2018 wang et al 2002 which assumes that fracture flow through one or more channels tsang and tsang 1987 as shown in fig 2 the flow between any two intersected fractures is equivalent to two single flow pipes and the two nodes of which are the center of intersected fractures and the midpoints of their intersection lines respectively liang 2019 step3 isolated and dead end fractures are eliminated step4 for each trial subdomain a unit hydraulic gradient is specified across opposing boundaries and no flow conditions are specified on the remaining four boundaries as shown in fig 2 to calculated the hydraulic conductivity in the direction of the axes y and z nodal heads are calculated using priest 1993 7 hj i 1 n cij h i i 1 n cij where h j is the pressure head at node j cij is the conduit conductivity between nodes i and nodes j defined using the cubic law priest 1993 8 cij g a 3 b 12 v l in which g 9 8 m s 2 is the gravitational constant a m is the fracture aperture b m is the fracture width b 1 m for 2d v 10 6m2 s 1 for water is the kinematic viscosity and l m is the fracture length flow through each fracture is then determined using priest 1993 9 qi c i j δ h i j where q i is the flow of fracture i and δ h i j is the head difference of the nodes at both ends of the fracture i this procedure was implemented by alghalandis 2018 and is available within the matlab toolbox adfne 1 5 by the following functions 10 dfn s o l v e g r a p h b a c k b o n e p i p e be f n m c n t t o l a f u n d f u n b v k v the pipe function builds the pipe model based on 2d lines or 3d polygons be is the boundary elements cnt is the center methods many of the resulting parameters e g pipes intersection points intersection lengths initializes types etc are added to the results of pipe the backbone function extracts efficiently the backbone skeleton structure from the given pipe model the tol value is used to determine the tolerance for isolation test between pipes the graph function constructs the graph structure nodes and edges based on the given backbone with all necessary information such as the neighboring it also accepts two functions afun bfun as optional arguments the first to apply to aperture field and the second to apply to depth field of fractures the solve function solves the developed graph structure for fluid flow through the fractures it computes flow in each edges where dfn is the result of solve function bv is the boundary pressure heads kv is kinematic viscosityg step5 matlab function flow shown in appendix a 1 sums all n inflow edges that to generate the total flow through the trial subdomain so that the hydraulic conductivity kj m s between opposing faces is 11 q i 1 n q i k j a h j j 1 2 3 in which q m3 s is the total inflow to the trial submodel and a is the area of cross sectional in addition to this new function the original adfne1 5 toolbox was modified by using sparse matrices to eliminate large matrices and add parallel calculations or conversion loops into mex that required the elimination of loops see appendix a 2 which reduces the execution time from 21 to 9 min for 2 000 fracture disks and 66 336 pipes pc quad core 3 4 ghz 8 gb ram which is a relatively small network compared to those modeled here step6 the size of the trial subdomain is enlarged and the hydraulic conductivity components are recalculated the appropriate rev scale is found by noting when hydraulic conductivity values no longer vary as the size increases song 2004 rong et al 2013 the specific standard when the kj in the rev size is stable is noted as δ k j ε k j j x y z rong et al 2013 where δ k j are the differences of hydraulic conductivity in this calculation and those in the previous calculation kj j x y z are the values of hydraulic conductivity in this calculation ε is specific tolerances generally ε 5 2 1 2 determining the k tensor the hydraulic conductivity tensor is determined for each hydrogeologic unit once the rev size has been established positions in the original coordinate system x y z are first rotated by the angle θ in 30 increments around the z axis into the x y z coordinate system and then by the angle φ in 30 increments around the y axis into the x y z coordinate system fig 3 12 x y z cos θ sin θ 0 sin θ cos θ 0 0 0 1 x y z θ 0 30 60 180 13 x y z cos φ 0 sin φ 0 1 0 sin φ 0 cos φ x y z φ 0 30 60 36 0 the resulting hydraulic conductivities are then found after each rotation with directions distributed uniformly in the spherical coordinate system the six independent components of the hydraulic conductivity tensor are calculated using regression analysis of these directional hydraulic conductivity wang 2000 for steady flow the directional hydraulic conductivity is found using the flux vector along with the corresponding hydraulic gradient components bear 1972 14 kg q i n i h i i 1 2 3 where k g is the directional hydraulic conductivity aligned with the hydraulic gradient ni is the component of the unit vector of the gradient direction combining eqn 1 with eqn 14 yields 15 kg k i j n j n i i 1 2 3 j 1 2 3 for the l th direction hydraulic conductivity kg nl eqn 15 can be expanded to song 2004 16 kg n l n l 1 2 k 11 n l 2 2 k 22 n l 3 2 k 33 2 n l 1 n l 2 k 12 n l 2 n l 3 k 23 n l 1 n l 3 k 13 where n n l 1 n l 2 n l 3 t is the unit direction vector of the gradient at the l th calculation and kij are six independent components of the hydraulic conductivity tensor if the number of direction hydraulic conductivity is n where n 6 the n order linear equations for the six independent hydraulic conductivity components are obtained which are expressed in the form of a matrix wang et al 2002 17 ax b where 18 a n 11 2 n 12 2 n 13 2 2 n 11 n 12 2 n 12 n 13 2 n 11 n 13 n 21 2 n 22 2 n 23 2 2 n 21 n 22 2 n 22 n 23 2 n 21 n 23 n n 1 2 n n 2 2 n n 3 2 2 n n 1 n n 2 2 n n 2 n n 3 2 n n 1 n n 3 19 x k 11 k 22 k 33 k 12 k 23 k 13 t 20 b k g n 1 k g n 2 k g n n t the estimated values of the hydraulic conductivity tensor x are obtained using wang et al 2002 21 x a t a 1 a t b once the hydraulic conductivity tensor is known their eigenvalues and the eigenvectors p j p 1 j p 2 j p 3 j t are used to find their principal values k 1 k 2 k 3 orientation α and dips β the principal hydraulic conductivity vector is rotated using lei 2015 22 α a r c sin p 3 j p 1 j 2 p 2 j 2 p 3 j 2 23 β 270 arcsin p 2 j p 1 j 2 p 2 j 2 p 1 j 0 p 3 j 0 90 arcsin p 2 j p 1 j 2 p 2 j 2 p 1 j 0 p 3 j 0 and p j p j if p 3 j 0 this results in a hydraulic conductivity tensor with only the diagonal having non zero values which results in the standard ellipsoid representation shown in equation 3 where k 1 k 2 and k 3 are the three principal values major intermediate and minor respectively of the hydraulic conductivity tensor 2 2 karst conduit network modeling to accelerate the simulation same as stochastic karst simulator sks pseudo genetic method borghi et al 2012 a proxy is allowed to mimic the final result mature system without modeling the physical and chemical processes the proxy is based on the assumption that water and thus karst conduits will follow the minimum effort path i e the path that is the most convenient for flow between recharge and discharge locations borghi et al 2012 the karst conduit network modeling consists of four main steps fig 4 1 the 3d hydrogeologic structure is parameterized using the hydraulic conductivity tensor 2 the tensor is used to generate an initial flow field 3 the locations of hydrologic inputs e g sinkholes and outputs springs are defined based on field surveys and 4 conduit locations are determined using the afma to find the minimum effort paths between groundwater inputs and outputs 2 2 1 building 3d geological model the three dimensional geologic fabric is first specified using the geologic modeling system gms that defines a domain with n 3 nodes based on site hydrostratigraphic conditions along with recharge and discharge locations matlab is then used to define nodal positions x using the meshgrid function along with the spatial extent defined in gms yielding a domain that consists of nx n y n z nodes along the x y z axes respectively due to the irregular grid that results an indicator variable ig is used to define whether a node is included in calculations between specific nodes 24 i g x g 1 x g nan x g in which g is the position of geological structure nan is the non numeric symbol indicating that this position does not participate in the calculation 2 2 2 building the k tensor field the hydraulic conductivity tensor field developed earlier k is smoothed and interpolated using the matlab toolbox easykrigv3 0 developed by chu 2016 25 k 0 x i g x g k t x as a function of the connectivity of each node to surrounding nodes k 0 is initially velocity this new tensor field fig 5 b accounts for the evolution of the karst network over time by building a hydraulic structure that accounts for the connectivity along conduits 2 2 3 modeling karst conduits once the general conduit structure has been defined the afma is used to define the active pathways between recharge and discharge locations afma was developed by sethian 1999 and implemented by konukoglu et al 2007 the tool is widely used in determining blood vessel centerlines on computer tomographic images mirebeau 2014 seismic ray traces li 2012 and unmanned boat routes wang 2015 afma solves a partial differential equation pde that starts at the origin and then follows a characteristic direction defined by the pde to calculate the route and arrival time t using a front propagation algorithm konukoglu et al 2007 this algorithm is used to numerically solve 26 f x t x t k t x t x 1 where x is the position t x is the arrival time of the interface at point f x is the constant local propagation speed of the interface at point and k x is the local propagation velocity tensor note that this algorithm devolves to the ifma with scalar hydraulic conductivity k the general workflow of the afma sethian 1999 is as shown in the fig 4 step1 the initialization distance of sources t x 0 is zero and inf for other vertices t x i and the type of source point is trial and far for the other vertices step2 find the vertex x with the smallest distance value in the set of trial and update its type to known note that x n is the neighbor point of vertex xn and n x is the set of xn step3 xn is update to trial if xn is far step4 if there is an edge x y that can be directly reached for the vertex the distance value is recorded as t x y step5 t x x n is calculated by using equation 26 and then t x n is updated using t x n min t x n t x t x x n step6 return steps 2 5 until far 0 step7 terminate and provide output where the hydraulic conductivity is used to define the local flow tensor and f x 1is arbitrarily assumed because it does not affect the resulting solution the result is a 3d distance map fig 5c t s x between the starting locations s and each point pixels in 2d voxels in 3d within the domain 27 t s x t k 0 s the next step is to find travel routes from groundwater recharge locations e g sinkholes as starting points i to each of the mapped discharge points the gradient between inlets and outlets t s x is calculated and the shortest path from the sinkholes to the springs fig 5c is obtained this approach is implemented by peyré s 2014 matlab function compute geodesic fig 5d shows the solution of the fig 5a but using the ifma which using the equivalent hydraulic conductivity in fig 5b as the initial velocity field and leading to produce unacceptable results for anisotropic cases 2 2 4 incorporating the unsaturated zone unlike the saturated zone where flow is primarily horizontal flow through the unsaturated zone is primarily vertical so that surface depressions collect and concentrate epikarst flows into high angle conduits huntoon 1999 the water table position a function of regional spring locations is a critical factor that separates primarily vertical flow in the unsaturated zone with horizontal flow within the saturated zone borghi et al 2012 proposed that the simulation process be divided into two steps to simulate vertical flow within the unsaturated zone where the first step identifies high angle conduits within the unsaturated zone between the ground surface and the water table and the second step identifies sub horizontal flow in the saturated zone from unsaturated zone inputs to springs 3 3d demonstrative example the purpose of this paper is to develop a conceptual framework and numerical method but doesn t provide detailed and accurate regional models for testing for the lack of a karst system which both the real location of conduit networks and the geometric of fractures are known the simulation conduit networks results can t be compared with that of real and can only be verified by indirectly evidences e g tracer test and catchment area this is why we show the 3d example only to demon strate the applicability of the method our proposed methodology is applied to the 14 31 km2 wulongdong basin in xingshan county yichang city hubei province south china fig 6 which experiences a subtropical monsoon climate with an average annual precipitation of 952 mm and temperature of 12 9 c the basin is located in the east side of a wide syncline within the cambrian ordovician carbonate strata which dip gently 5 to 15 to the southeast at the site three carbonate limestone and dolostone aquifers underly the study area fig 6d the uppermost loushanguan formation lsg the intermediate qinjiamiao formation qjm and the lowermost tianheban formation thb while an overlying ordovician carbonate formation is distinct from the underlying loushanguan formation it is thin with few outcrops so that it is combined with the loushanguan formation in this study these carbonate rocks along with favorable climatic conditions promote the development of karst in the area sinkholes closed depressions are common so that most net precipitation infiltrates and recharges underlying karstic aquifers regional groundwater discharges at two springs springs 1 and 2 with elevations of 620 and 624 m and flow of 2 21 10 2 to 1 99 m3 s and 1 57 to 1 41 m3 s respectively that are found at the base of the thb where the gaolan river has incised into the underlying clastic shipai formation sp since wulongdong basin is a young underground river system with small scale the average diameter of maximum conduit is about 2 85 m which calculated by the results of tracer test the underground watershed is considered to be consistent with the surface watershed and each depression is isolated so the capture zones for each depression table 5 were calculated according to dem analysis two tracer tests were conducted to find out the connecting result between the sinkhole1 and 6 and two springs luo et al 2016 the details of each test are tabulated in table1 sodium fluorescein tracers injected in august 2014 and june 2015were detected at spring1 only 6 5hrs and 8hrs after they were injected into sinkhole 1 and 6 average inflows of 634 29 and 285 71 l s respectively and the maximum tracer concentrations were recorded only 0 97and 1 09hrs after the first arrival the results of two tracer test show that both sinkholes are linked to spring 1 and neither is linked to spring 2 both tracer break through curves show a single symmetrical peak that suggest that there is a conduit between the sinkholes and the spring 3 1 specifying the aquifer rev fracture geometries were measured at twelve outcrops using 2 2 m2 statistical windows fig 6c in order to obtain the measurement data of fractures as much as possible some outcrops near the study basin were measured because the process of forming the study region are monoclinic and under the same regional tectonic stress the fractures in a formation have the same directivity and regularity whether they are located in or near the basin fracture orientations were estimated and plotted using dips which identified four statistically significant groups in each formation table 2 fig 7 the first group corresponds to bedding plane fractures while the remaining three groups correspond to high angle structural fractures we used the method of song 2016 to characterize fracture aperture size and type where fracture apertures less than 200 μ m are considered closed and were not used in subsequent analyses single sample k s test analysis was performed on other geometric features using spss the length of bedding plane fractures are uniformly distributed the apertures are log normal distributed p 0 1 while the remainder are normally distributed p 0 1 statistical characteristics are summarized in tables 1 and 2 in which n is the fracture group α and β are fracture dip directions and angles respectively the minimum volume required to establish the representative equivalent volume rev was determined based on a global domain of 20 20 20 m cube a trial subdomain started at 1 1 1m cube and was then extended by one meter in each dimension until it reached ten meters the number of fractures in each trial subdomain increased from tens to thousands as the subdomain size increased calculation times also increased from tens of seconds to tens of hours with the longest execution time requires 56 hrs that was reduced by about 4 hrs compared with using the original code as shown in fig 8 the principal values of the hydraulic conductivity stabilized when grid sizes of 6 m 6 m and 7 m were reached for the thb qjm and lsg respectively 3 2 k tensor results hydraulic conductivity tensors were calculated within the specified rev by changing the orientation from 0 to 360 and dip angles from 0 to 180 in increments of 3 0 yielding 91 orientations an ellipsoid was then fit to the 91 values using ordinary least squares as shown in fig 9 this step required substantial computational effort the longest tianheban formation takes approximately 25 hrs for each model run which is about 7 hrs less than using the original code the resulting hydraulic conductivity tensors for each formation are provided in table 3 which are then reduced to their principal directions using their eigenfunctions shown in table 4 note that the principal magnitudes are within a factor of two of each other in each formation principal orientations are approximately 121 west northwest to east southeast 148 north northwest to south southeast and 189 north to south for the thb qjm and lsg respectively also note that major axes of thb and lsg and medium axes of qjm are steeply inclined 50 which supports increased vertical development and recharge the remainder axes are sub horizontal 30 which represents bedding plane flow 3 3 incorporating the hydrogeologic setting the regional hydrogeologic setting was established using 1 50 000 topographic maps and geologic surveys that were imported into gms these data were used to identify sinkhole and spring locations as well as aquifer thicknesses aquifer isopachs were used to establish the upper and lower elevations of each hydrostratigraphic unit the resulting aquifer extents were then discretized into 60 100 equal intervals horizontally and three layers vertically fig 10 a the uppermost formation the loushanguan was subdivided into five equal layers to better account for surface topographic features the resulting voxel size 1000 m3 was larger than the estimated rev voxels within each aquifer were then assigned corresponding hydraulic conductivity tensors 3 4 afma results the initial upstream computation started by defining the spring 2 elevation as the starting plane afma was then used to map the shortest distance in three dimensions from each point to this plane sinkholes were used as the end points for particle tracking to obtain the karst conduit networks within the unsaturated zone once the paths between the sinkholes and the plane were specified the travel paths between both springs 1 and 2 were used as the starting points with the end points being the location of the bottom of the unsaturated zone paths the resulting karst conduit networks are shown in fig 10b and table 5 which show that spring 1 collects water from sinkholes 1 to 7 while spring 2 collects water from sinkholes 8 to 14 which is consistent with tracer tests that show sinkholes 1 and 6 draining to spring 1 the corresponding catchment areas of springs 1 and 2 are estimated to be 7 20 and 4 84 km2 respectively and the ratio of their catchment areas 1 49 are approximately equal their baseflow discharge ratio 1 41 4 discussion 4 1 epm hct r vs discrete fractures hct en to explore the adaptability of our method in field application a 2d synthetic model is used to compare the results of the conduit network obtained by afma on discrete fracture networks dfn map and its equivalent porous medium epm map we define a simulation region that is 30 30 m2 with two sets of fractures shown in table 6 and an rev of 3 3 m2 we then compare the k tensor provided by adfne1 5 that is based on an rev hct r with the tensor generated at each geological position hct egp using graph theory method peyré 2014 fig 11 presents the conduit networks generated using both methods where blue dotted lines are the results of hct r and red dotted lines are the results of hct egp these results show a consistent paths except for two paths with a maximum deviation of 1 39 m this implies that the epm assumtion provides a feasible method for generating karst conduit networks to analyze flow and transport prediction with a lack of knowledge about network geometry 4 2 afma vs sks while our procedure resembles sks the methods used to generate the flow field are different a the initial sks step needs to stochastically generate fractures controlling the generation of karst conduits which means that sks is not suitable for the karst basin where the conduits are controlled by a large number of fractures our method uses equivalent hydraulic parameters to treat dense fractures avoiding the limitation caused by computer efficiency and memory b the sks flow field transforms geologic information using an isotropic hydraulic conductivity our method uses a tensor to represent hydraulic conductivity at the rev scale and c the final sks step is to find the 3d distance map using the isotropic fast marching algorithm ifma our method uses the anisotropic algorithm instead that allows for preferential flow based on the geologic framework on the case of discrete fracture networks map afma are more accurate than sks which can be demonstrated by comparing a 2d isotropic k borghi et al 2012 with a k tensor that has a principal hydraulic conductivity associated with bedding plain fractures kh that is twice that of vertical fractures kv the horizontal hydraulic conductivity at each point in sks is the equivalent hydraulic conductivity of the hydraulic conductivity tensor in afma 27 k k h k v 1 2 k h as shown in fig 12 using the sks method leads to erroneous results for general anisotropic cases the reason for this incorrect solution is that the gradient direction dosen t coincide with the characteristic direction due to the fact that sks is an single pass algorithm for the eikonal equation which omits the distance t x x n so that it does not correctly identify the minium error sethian and vladimirsky 2001 zhang et al 2013 based on this reasoning we believe that afma provides more realistic representations of flow conduits when compared with sks borghi et al 2012 4 3 afma vs streamline modeling the core of the approach relies on the use of the afma alternatively the similar re sults can be obtain by using groundwater flow simulations and compute streamlines borghi et al 2012 a synthetic model that two groups of mutually perpendicular fractures are simulated within a porous matrix the principal hydraulic conductivity of the first group of fractures is twice that of the second group and three orders of magnitude greater than the matrix flow was simulated using gms with a constant source term throughout the domain a drain at the spring position and no flow boundaries on the sides the shape of conduits generated by afma fig 13 a is strongly affected by the fracture location than those generated by gms fig 13b the conduit networks acquired by using gms are also strongly influenced by no flow boundary on the sides of the model furthermore gms simulations only account for fractures that are perpendicular to each other and finally gms simulations are more cpu demanding one steady flow simulation within a 600 600 m 2d domain takes about 2 3 min for gms but less than 2 s using for afma on a quad core pc running at 3 4 ghz with 8 gb of internal memory in 3d accounting for the vadose zone flow simulations would require solving the unsaturated flow equations on very large grids due to the nonlin earity of those equations the demonds of cpu can become extremely intensive borghi et al 2012 4 4 boundary effects generating the rev requires that a domain be constructed with specified heads on two opposing boundaries with no flow conditions specified on the four remaining boundaries unfortunately calculated flows are affected by the inability of flows to extend laterally beyond these no flow boundaries which reduces the calculated hydraulic conductivity extending the domain laterally to allow flow to leave and then re enter the domain would improve the estimated hydraulic conductivity alternatively establishing a unit gradient along the boundary may also improve the k tensor estimate 4 5 additional concerns it is important to note that conduit flows are critical for determining flowpaths in karst aquifers pardo igquiza et al 2012 saller et al 2013 yet the identification of these flow paths is challenging and estimates have high uncertainties our approach provides a means for both identifying the most likely path as well as a means for assessing its uncertainty in addition our method is based on measured attributes of the system including fracture geometries topographic information and hydrogeologic surveys while the true locations of identified conduits remain uncertain flow models using these conduits provide more realistic simulations of groundwater levels and flow paths than homogeneous or epm models vuilleumier et al 2013 one shortcoming of the 3d demonstrative example is the adoption of a single k tensor for each aquifer while it is expected that fracture network properties vary spatially it is difficult to account for these heterogeneities without field data to support them our view is that a single value is the most parsimonious for our system in that there are insufficient data to justify additional parameterization of course other field sites may have additional fracture network properties from well logs tunnels etc which would justify a spatially explicit k tensor another shortcoming is the failure to incorporate water rock interactions in the evolution of karst conduits while speleogenetic models that use physical and geochemical processes to estimate conduit formation by weathering and erosion provide additional insight into conduit formation they are difficult to apply due to uncertain paleo climatic and geological conditions during the evolutionary process borghi et al 2016 these models are also difficult to develop due to nonlinear coupled equations that require enormous computational effort borghi et al 2012 our method avoids these challenges by providing a computationally efficient alternative that incorporates these processes indirectly by accounting for important interactions between fractures and conduit formation 5 summary and conclusions understanding and predicting flow and transport in karst landscapes is difficult due to uncertainties associated with the locations of preferential flowpaths through conduits such as faults fractures and dissolution enlarged passageways here we present an improved method for determining conduit networks in karst aquifers that connects groundwater inputs e g sinkholes to outputs e g springs using fracture characteristics topographic features and hydrogeologic information field observations of fracture geometries e g length orientation and apertures obtained from rock outcrops are processed using the software tool dips to statistically characterize fracture properties and to group fractures into joint sets based on stereographic projections fracture characterization data are then used to generate multiple realizations of discrete fracture networks dfn using monte carlo methods within the matlab toolbox adfne1 5 the toolbox then uses dfn realizations to determine the minimum size of the representative elementary volume rev based on the scale at which the geologic medium behaves as an equivalent porous medium epm epm properties are then determined by generating the hydraulic conductivity tensor that describes the anisotropic hydraulic properties of each hydrogeologic unit topographic and hydrogeologic data are managed using the software tool gms to specify the flow domain by identifying groundwater recharge and discharge locations through multiple aquifers the domain is then transferred to matlab where it is further discretized into voxels that are larger than the rev volume conduits are then identified based on the minimum effort path between groundwater inputs and outputs using the matlab toolbox afma this is a two step process where the first step identifies near vertical flows through the unsaturated zone from the ground surface within local capture zones to the water table below it followed by determining near horizontal paths from unsaturated zone inputs through the saturated zone to springs the method is demonstrated using information from the 14 31 km2 karstic wulongdong basin in hubei province china where fourteen recharge locations contribute to two springs through three carbonate aquifers tracer experiments conducted between two recharge locations and springs are consistent with the predicted conduit network connection and the ratio of two springs predicted catchment areas are approximately equal to that of their baseflow discharge this approach is unique in that it uses the anisotropic fast marching algorithm afma to incorporate media anisotropy using the hydraulic conductivity tensor afma reduces the computational effort for our large fracture network where flow is controlled by local scale dense and interconnected fractures computation efforts were further reduced by updating adfne1 5 to include sparse matrix declarations and converting the code so that it performs parallel calculations using multiple processors we believe that afma provides a better prediction than the ifma because it accounts for the important effects of preferential flow directions also our method provides similar results to the more computationally intensive pten approach that assigns a different tensor to each node which can be difficult to determine in the absence of field data to parameterize and finally we emphasize that we do not account for stormflow that may alter flow pathways as water tables rise within our multilayer aquifer system we also do not account for increased aquifer hydraulic conductivities due to speleogenesis which is the interaction of water with carbonate rocks that promotes the dissolution and weathering of the host rock links for some toolboxes dips frac matlab mofrac credit authorship contribution statement lichuan luo methodology writing original draft xing liang supervision bin ma supervision hong zhou supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by national natural science foundation of china 41772268 we are grateful to todd c rasmussen of the university of georgia and menggui jin of the china university of geosciences wuhan for their revision of this article yf alghalandis for providing the matlab toolbox as well as manuscript reviewers for their helpful comments appendix matlab codes a 1 function flow function q flow dfn q inflow dfn struct fields pip etc type dfn pip type type of pipe b dfn bbn b the mask grh dfn grh graph i find type 1 inflow boundary j zeros length i 1 initialize the j for k 1 length i find the inflow edge if type i k 1 0 if b i k 1 1 j k numel find b 1 i k 1 1 end end end j find j 0 update j q sum cat 1 grh edge j flow results of inflow end a 2 toolbox adfne1 5 modifications modification 1 lines 86 113 in function pipe used to build pipe coordinates and types are moved to function pipe for modification 2 lines 69 83 in function bbox used to create an index of intersecting fractures are moved to function bbox for modification 3 inputs and outputs of functions pipe for and bbox for are out bbox for in bxs pip pla pdp typ pipe for xts center be ids la xls where in is the set of polygons cell bxs is the bounding box for every individual entity of the input out is set of two intersecting xts is set of intersection lines center is the center of fracture ids is the set of two intersecting be are boundary elements la is the clustering labels for all fractures in the network xls is set of intersection lengths pip is the set of intersection lengths pla is the set of pipe labels pdp is the percolating state typ is set of pipe types modification 4 function coder is used to generate mex files pipe for mex and bbox for mex for functions pipe for and bbox for respectively modification 5 line 44 of function isolated is altered by adding the code distcomp feature localusempiexec false change the for loop to a perfor loop to enable parallel calculation modification 6 lines 57 70 in function slove are changed to use functions sparse and full when calculating large matrices to reduce memory and computation time c cell inn 1 initializes cell c d cell inn 1 initializes cell d e cell inn 1 initializes cell e for i 1 inn loops over all inner nodes egs g edge g node inx i edges node s edges c conductance egs length egs aperture egs depth kv computes conductance nn setdiff egs nodes inx i stable node s neighboring nodes f g node nn type 0 inner mask u ind nn f inner neighboring node s indexes v c f inner node s conductance t size u 2 inner neighboring node s number f zeros t 3 initializes matrix f for nl 1 t loops over all inner node s neighboring nodes f nl 1 3 i u nl v nl fill in the matrix f end c i 1 f fill in the cell c d i 1 i i sum c fill in the cell d if all f continue end if all were inner nodes e i 1 i 1 sum c f g node nn f pressure updates e vector end a1 cell2mat c d a sparse a1 1 a1 2 a1 3 inn inn build sparse matrix a b1 cell2mat e b sparse b1 1 b1 2 b1 3 inn 1 build sparse matrix b x full a b finds the solution 
4362,karst aquifers are difficult to model due to their complex conduit networks that are heterogeneous and anisotropic here we present a heuristic algorithm for modeling karst networks by calculating minimum effort paths based on our knowledge of karst evolution that is constrained by field observations the methodology consists of a using discrete fracture network models along with fracture parameter estimates e g frequency extent spacing and apertures to equivalent porous media properties e g size of the representative elementary volume hydraulic conductivity tensor b rendering the velocity field using the tensor field coupled with the 3d regional hydrogeology that includes likely recharge and discharge locations and c generating karst conduits using the anisotropic fast marching algorithm afma this approach a avoids the need to model discrete fractures by replacing them with a tensor that incorporates small scale dense and interconnected fractures b assumes that conduits follow the minimum effort path from sinkholes toward springs and c efficiently accounts for regional hydrogeology anisotropy and regional flow conditions within 3d conduit networks the application of the proposed approach in wulongdong basin in hubei province china is taken as the demonstrate example compared to other techniques this methodology substantially improves computational efficiency and reduces computer memory thus providing a useful tool for generating ensembles of possible karstic conduit networks to analyze flow and transport prediction uncertainty associated with a lack of knowledge about network geometry keywords anisotropic fast marching algorithm karst conduit networks hydraulic conductivity tensor discrete fracture networks equivalent porous medium 1 introduction karst aquifers currently provide drinking water for 15 of the world s population and are the only available water resource in some basins parise et al 2018 flow and transport through these aquifers are difficult to characterize due to their heterogeneity and anisotropy that result from their multi level porosity consisting of pores fractures and large conduits there are also different temporal scales and water quality characteristics with 90 95 of total storage within the rock matrix while 90 95 of runoff occurs through larger macro pores worthington 2003 worthington et al 2000 therefore both matrix and conduits must be considered when modeling karst aquifers for groundwater protection and management or to investigate contamination borghi et al 2012 király 1979 was the first to numerically model conduits in karst landscapes which has been followed by a wide number of techniques over the past forty years ghasemizadeh et al 2012 green and fratesi 2019 a notable feature of these numerical simulation techniques is that the geometry of the conduit networks is specified prior to flow and transport modeling yet the conduit geometry is often unknown because they are inaccessible seldom exposed by boreholes and difficult to detect by geophysical techniques especially when their aperture is small parise et al 2018 borghi et al 2012 a few techniques have been developed to model the geometry of karst conduit networks using speleogenesis models kaufmann and braun 2016 2000 dreybrodt et al 2005 these models use physico chemical processes to generate karst networks by coupling calcite dissolution with flow equations to generate a conduit based on a single fracture a network of fractures or a matrix with embedded fractures while this approach provides insight into conduit evolution in hypothetical idealized karst systems kaufmann and braun 2016 dreybrodt et al 2005 and was applied on a regional scale by using implicit switching algorithm and a coarser spatial discretization of the conduit cells de rooij and graham 2017 it s still difficult to generate realistic conduit networks due to its inability to reconstruct topography and paleo climatic conditions that prevailed during conduit formation de rooij and graham 2017 in addition these models are computationally challenging due to their need to solve highly nonlinear and coupled equations borghi et al 2012 approaches have also been developed to incorporate the geologic structure using geostatistical methods hendrick and renard 2016 jaquet et al 2004 viseur et al 2014 pardo igúzquiza et al 2012 generated individual conduit segments by resampling from a defined template and then generating the network topology using a diffusion limited aggregation method ronayne 2013 ronayne and gorelick 2006 used the non looping invasion percolation model proposed by stark 1991 to generate conduit networks while generating an accurate network by purely geo statistical methods remains an unresolved challenge de rooij and graham 2017 the method of pardo igúzquiza et al 2012 forces connections between the conduits and the resulting connectivity is not controlled by statistical input parameters ronayne s 2013 model defines a priori network a connectivity pattern more typical for stream networks than for conduit networks de rooij and graham 2017 the improved methods based on statistical characteristics are expected to eventually generate realistic patterns jouves et al 2017 collon et al 2017 pardo igúzquiza et al 2012 alternatively conduit networks may be generated uses a pseudo genetic algorithm henrion et al 2008 borghi et al 2012 which mimics the results of karst network structures produced by speleogenetical models without solving the complete kinetics of the system borghi 额头 2016 this approach based on the assume that water and thus karst conduits will follow the minimum effort path and generate the conduits in an iterative manner in which conduits are progressively widened using a heuris tic erosion potential collon et al 2012 simulated 3d branch work karst networks by a dijkstra s algorithm dijkstra 1959 the a algorithm hart et al 1968 extracts least cost paths between two given points using hydraulic conductivity information borghi et al 2016 2012 use the stochastic karst simulator sks pseudo genetic method in which the minimum effort paths between multi inlets and multi outlets are computed by a more accurate eikonal algorithm isorropic fast marching algorithm ifma based on the erosion potential hydraulic conductivity tensor pseudo genetic method is fast to account for the main factors controlling the 3d geometry of the network and has good potential to generate realistic conduit networks borghi et al 2012 to date pseudo genetic algorithm requires priority to generate a discrete fracture networks map both the erosion potential hydraulic conductivity and the best first search algorithm are isotropic so pseudo genetic algorithm is limited however to karst groundwater systems where conduits are primarily influenced by large scale features e g regional faults computational limitations i e speed memory preclude its use in systems with numerous small scale dense and interconnected fracture networks such as those found in south china for this situation we propose the use of an equivalent porous medium epm that treats our dense fracture network as homogeneous but anisotropic within each hydrostratigraphic unit and using an anisotropic best first search algorithm the equivalent continuum approach is common applied to simulate groundwater flow over large area with dense fracture networks because each local grid element is smaller than the hydrogeological unit at the regional scale borelli and pavlinz 1965 pankow et al 1986 the parameters that representative elementary volume rev size and hydraulic conductivity tensor k are used to define the equivalent porous medium epm bear 1972 long et al 1982 rong et al 2013 the existence and size of rev directly determine wheather a locally fracture network can be approximated by an equivalent porous medium at the scale of a rev and the symmetric hydraulic conductivity tensor is used to describe the anisotropic permeability snow 1969 oda 1985 chen et al 2008 lang et al 2014 the discrete fracture network dfn model is often used to determine rev sizes and hydraulic conductivity tensors by simulating water flow in individual fractures zheng et al 2020 li et al 2020 guo et al 2018 while fracture geometric parameters e g frequency extent spacing aperture are commonly required in these model as a priori but it is impossible to know the geometric parameters of all fractures thus stochastic approaches e g monte carlo simulation are used to develop the fracture networks using geologic survey data to generate random fracture networks that honor the statistical distribution of field mapped fractures with respect to their geometric parameters wang et al 2013 robertson 1970 was one of the first to conduct a field study of fracture networks using 9 000 fractures mapped in the debeer s mine in south africa fracture lengths at this site are equal in their strike and dip directions baecher et al 1977 subsequently proposed a fracture network model which has become widely adopted that assumes fractures discs that are distributed randomly and independent of each other many fracture flow models that are based on baecher and dfn models e g fracman mofrac and adfne have been developed as computational platforms have increased in speed and memory many of these models are closed source and expensive however the matlab toolbox adfne1 5 alghalandis 2018 is used by many studies chen et al 2019 feng et al 2020 liang 2019 because it is open source free comprehensive and convenient for secondary modifications yet the original adfne1 5 code is computationally intensive if used for tens of thousands of fracture nodes and is limited by computational speed and computer memory adfne1 5 also lacks the fability to calculate hydraulic conduicity tensors which are needed in anisotropic media in this paper we use the secondary development discrete fracture networks dfn seepage simulator matlab toolbox adfne1 5 alghalandis 2018 along with field measurements to determine equivalent continum parameters the rev size and k within a karstic multi aquifer groundwater system these tensors are then linked with regional topographic sinkholes and hydrogeologic recharge and discharge locations features to create an initial velocity field the most likely karst conduit network is then generated by finding the minimum effort paths between inflows and outflows using the anisotropic fast marching algorithm afma a case study in a 14 31 km2 karstic wulongdong basin in hubei province china is presented to evaluate the suitability of the method 2 methodology 2 1 determination of the epm fluid flow interacts with carbonate rock by dissolution along flowpaths defined by the discrete fracture network dfn that connects boundary inflows with outflows dreybrodt et al 2005 continued dissolution enlarges these fractures forming conduits that reinforce subsequent dissolution and enlargement while modeling flow and transport through these discrete fracture networks provides the ability to accurately account for physico chemical processes the computational burden of solving for flow and transport through fracture networks in karst systems that may contain 109 fractures is daunting instead it is common to represent these networks using an epm to specify our problem we start with darcy s law that relates flux q to the hydraulic gradient h in homogeneous anisotropic media using the hydraulic conductivity tensor k 1 q i k i j h j i 1 2 3 j 1 2 3 where the hydraulic conductivity tensor has the form 2 k k 11 k 12 k 13 k 21 k 22 k 23 k 31 k 32 k 33 the eigenvalues and eigenvectors of this tensor can be extracted to yield the principal axes and their orientation e g their principal direction of flows so that equation 2 can be written as 3 k k 1 0 0 0 k 2 0 0 0 k 3 where k 1 k 2 and k 3 are the principal values in the rotated coordinate system these values can then be used to fit the ellipsoid long et al 1982 4 x 2 k 1 2 y 2 k 2 2 z 2 k 3 2 1 where y and z represent the major intermediate and minor axes of the rotated tensor use of equation 1 in heterogeneous porous media assumes that a locally defined network can be approximated by an epm at the scale of a rev where anisotropy is described using the symmetric hydraulic conductivity tensor and homogeneity is defined at the scale of the rev long et al 1982 bear 1972 2 1 1 determining the rev the general process for developing a discrete fracture network dfn consists of a measuring fracture geometric paremeters e g frequency trace lengths orientations and apertures in a geologic exposure using a statistical window b performing a statistical analysis for each geometric element where similar fractures are grouped according to their occurrence with a probability distribution model selected and its associated parameters estimated for each group and c generating synthetic fractures using monte carlo methods that honors the observed statistical behavior in this study discrete fracture networks are generated using the matlab toolbox adfne1 5 alghalandis 2018 that randomly assigns a position for fracture centers within a specified domain and then a circular fracture disk is created with a geometric properties that are prescribed using statistical distributions the three dimensional fracture networks are simulated by the following functions in a similar fashion alghalandis 2017 5 fnm d f n dim n d i p d d i p d i r d d i r b b x where fnm is the discrete fracture networks dim is the dimension n is the number of fractures dip and ddip are the mean and the standard deviation of dip angle respectively dir and ddir are the mean and the standard deviation of orientation box is the study volume x min y min z min x max y max z max to which the simulated fracture network is clipped fig 1 presents a realization of this approach showing how a synthetic discrete fracture network be constructed the number of fractures n is determined by the study volume and fracture volume density d3 m3 which is estimated using the method of wolfsberg 1997 that assumes parallel fractures so that 6 d 3 4 d 1 π e d 2 where d 1 is the line density m e d 2 is the average of the squared track length m2 once a fracture network has been constructed the rev is determined within which the hydraulic properties behave as though they are an equivalent porous medium this means that the bulk hydrologic behavior no longer depends on the characteristics of individual fractures but rather on the bulk properties of the fracture network the process for determining the appropriate rev scale consists of the following steps step1 a trial subdomain is created using a specified volume within the global domain that contains the entire fracture network as shown in fig 1 step2 equivalent 1d pipes are used to represent the fluid flow in 2d fractures cacas et al 1990 parise et al 2018 wang et al 2002 which assumes that fracture flow through one or more channels tsang and tsang 1987 as shown in fig 2 the flow between any two intersected fractures is equivalent to two single flow pipes and the two nodes of which are the center of intersected fractures and the midpoints of their intersection lines respectively liang 2019 step3 isolated and dead end fractures are eliminated step4 for each trial subdomain a unit hydraulic gradient is specified across opposing boundaries and no flow conditions are specified on the remaining four boundaries as shown in fig 2 to calculated the hydraulic conductivity in the direction of the axes y and z nodal heads are calculated using priest 1993 7 hj i 1 n cij h i i 1 n cij where h j is the pressure head at node j cij is the conduit conductivity between nodes i and nodes j defined using the cubic law priest 1993 8 cij g a 3 b 12 v l in which g 9 8 m s 2 is the gravitational constant a m is the fracture aperture b m is the fracture width b 1 m for 2d v 10 6m2 s 1 for water is the kinematic viscosity and l m is the fracture length flow through each fracture is then determined using priest 1993 9 qi c i j δ h i j where q i is the flow of fracture i and δ h i j is the head difference of the nodes at both ends of the fracture i this procedure was implemented by alghalandis 2018 and is available within the matlab toolbox adfne 1 5 by the following functions 10 dfn s o l v e g r a p h b a c k b o n e p i p e be f n m c n t t o l a f u n d f u n b v k v the pipe function builds the pipe model based on 2d lines or 3d polygons be is the boundary elements cnt is the center methods many of the resulting parameters e g pipes intersection points intersection lengths initializes types etc are added to the results of pipe the backbone function extracts efficiently the backbone skeleton structure from the given pipe model the tol value is used to determine the tolerance for isolation test between pipes the graph function constructs the graph structure nodes and edges based on the given backbone with all necessary information such as the neighboring it also accepts two functions afun bfun as optional arguments the first to apply to aperture field and the second to apply to depth field of fractures the solve function solves the developed graph structure for fluid flow through the fractures it computes flow in each edges where dfn is the result of solve function bv is the boundary pressure heads kv is kinematic viscosityg step5 matlab function flow shown in appendix a 1 sums all n inflow edges that to generate the total flow through the trial subdomain so that the hydraulic conductivity kj m s between opposing faces is 11 q i 1 n q i k j a h j j 1 2 3 in which q m3 s is the total inflow to the trial submodel and a is the area of cross sectional in addition to this new function the original adfne1 5 toolbox was modified by using sparse matrices to eliminate large matrices and add parallel calculations or conversion loops into mex that required the elimination of loops see appendix a 2 which reduces the execution time from 21 to 9 min for 2 000 fracture disks and 66 336 pipes pc quad core 3 4 ghz 8 gb ram which is a relatively small network compared to those modeled here step6 the size of the trial subdomain is enlarged and the hydraulic conductivity components are recalculated the appropriate rev scale is found by noting when hydraulic conductivity values no longer vary as the size increases song 2004 rong et al 2013 the specific standard when the kj in the rev size is stable is noted as δ k j ε k j j x y z rong et al 2013 where δ k j are the differences of hydraulic conductivity in this calculation and those in the previous calculation kj j x y z are the values of hydraulic conductivity in this calculation ε is specific tolerances generally ε 5 2 1 2 determining the k tensor the hydraulic conductivity tensor is determined for each hydrogeologic unit once the rev size has been established positions in the original coordinate system x y z are first rotated by the angle θ in 30 increments around the z axis into the x y z coordinate system and then by the angle φ in 30 increments around the y axis into the x y z coordinate system fig 3 12 x y z cos θ sin θ 0 sin θ cos θ 0 0 0 1 x y z θ 0 30 60 180 13 x y z cos φ 0 sin φ 0 1 0 sin φ 0 cos φ x y z φ 0 30 60 36 0 the resulting hydraulic conductivities are then found after each rotation with directions distributed uniformly in the spherical coordinate system the six independent components of the hydraulic conductivity tensor are calculated using regression analysis of these directional hydraulic conductivity wang 2000 for steady flow the directional hydraulic conductivity is found using the flux vector along with the corresponding hydraulic gradient components bear 1972 14 kg q i n i h i i 1 2 3 where k g is the directional hydraulic conductivity aligned with the hydraulic gradient ni is the component of the unit vector of the gradient direction combining eqn 1 with eqn 14 yields 15 kg k i j n j n i i 1 2 3 j 1 2 3 for the l th direction hydraulic conductivity kg nl eqn 15 can be expanded to song 2004 16 kg n l n l 1 2 k 11 n l 2 2 k 22 n l 3 2 k 33 2 n l 1 n l 2 k 12 n l 2 n l 3 k 23 n l 1 n l 3 k 13 where n n l 1 n l 2 n l 3 t is the unit direction vector of the gradient at the l th calculation and kij are six independent components of the hydraulic conductivity tensor if the number of direction hydraulic conductivity is n where n 6 the n order linear equations for the six independent hydraulic conductivity components are obtained which are expressed in the form of a matrix wang et al 2002 17 ax b where 18 a n 11 2 n 12 2 n 13 2 2 n 11 n 12 2 n 12 n 13 2 n 11 n 13 n 21 2 n 22 2 n 23 2 2 n 21 n 22 2 n 22 n 23 2 n 21 n 23 n n 1 2 n n 2 2 n n 3 2 2 n n 1 n n 2 2 n n 2 n n 3 2 n n 1 n n 3 19 x k 11 k 22 k 33 k 12 k 23 k 13 t 20 b k g n 1 k g n 2 k g n n t the estimated values of the hydraulic conductivity tensor x are obtained using wang et al 2002 21 x a t a 1 a t b once the hydraulic conductivity tensor is known their eigenvalues and the eigenvectors p j p 1 j p 2 j p 3 j t are used to find their principal values k 1 k 2 k 3 orientation α and dips β the principal hydraulic conductivity vector is rotated using lei 2015 22 α a r c sin p 3 j p 1 j 2 p 2 j 2 p 3 j 2 23 β 270 arcsin p 2 j p 1 j 2 p 2 j 2 p 1 j 0 p 3 j 0 90 arcsin p 2 j p 1 j 2 p 2 j 2 p 1 j 0 p 3 j 0 and p j p j if p 3 j 0 this results in a hydraulic conductivity tensor with only the diagonal having non zero values which results in the standard ellipsoid representation shown in equation 3 where k 1 k 2 and k 3 are the three principal values major intermediate and minor respectively of the hydraulic conductivity tensor 2 2 karst conduit network modeling to accelerate the simulation same as stochastic karst simulator sks pseudo genetic method borghi et al 2012 a proxy is allowed to mimic the final result mature system without modeling the physical and chemical processes the proxy is based on the assumption that water and thus karst conduits will follow the minimum effort path i e the path that is the most convenient for flow between recharge and discharge locations borghi et al 2012 the karst conduit network modeling consists of four main steps fig 4 1 the 3d hydrogeologic structure is parameterized using the hydraulic conductivity tensor 2 the tensor is used to generate an initial flow field 3 the locations of hydrologic inputs e g sinkholes and outputs springs are defined based on field surveys and 4 conduit locations are determined using the afma to find the minimum effort paths between groundwater inputs and outputs 2 2 1 building 3d geological model the three dimensional geologic fabric is first specified using the geologic modeling system gms that defines a domain with n 3 nodes based on site hydrostratigraphic conditions along with recharge and discharge locations matlab is then used to define nodal positions x using the meshgrid function along with the spatial extent defined in gms yielding a domain that consists of nx n y n z nodes along the x y z axes respectively due to the irregular grid that results an indicator variable ig is used to define whether a node is included in calculations between specific nodes 24 i g x g 1 x g nan x g in which g is the position of geological structure nan is the non numeric symbol indicating that this position does not participate in the calculation 2 2 2 building the k tensor field the hydraulic conductivity tensor field developed earlier k is smoothed and interpolated using the matlab toolbox easykrigv3 0 developed by chu 2016 25 k 0 x i g x g k t x as a function of the connectivity of each node to surrounding nodes k 0 is initially velocity this new tensor field fig 5 b accounts for the evolution of the karst network over time by building a hydraulic structure that accounts for the connectivity along conduits 2 2 3 modeling karst conduits once the general conduit structure has been defined the afma is used to define the active pathways between recharge and discharge locations afma was developed by sethian 1999 and implemented by konukoglu et al 2007 the tool is widely used in determining blood vessel centerlines on computer tomographic images mirebeau 2014 seismic ray traces li 2012 and unmanned boat routes wang 2015 afma solves a partial differential equation pde that starts at the origin and then follows a characteristic direction defined by the pde to calculate the route and arrival time t using a front propagation algorithm konukoglu et al 2007 this algorithm is used to numerically solve 26 f x t x t k t x t x 1 where x is the position t x is the arrival time of the interface at point f x is the constant local propagation speed of the interface at point and k x is the local propagation velocity tensor note that this algorithm devolves to the ifma with scalar hydraulic conductivity k the general workflow of the afma sethian 1999 is as shown in the fig 4 step1 the initialization distance of sources t x 0 is zero and inf for other vertices t x i and the type of source point is trial and far for the other vertices step2 find the vertex x with the smallest distance value in the set of trial and update its type to known note that x n is the neighbor point of vertex xn and n x is the set of xn step3 xn is update to trial if xn is far step4 if there is an edge x y that can be directly reached for the vertex the distance value is recorded as t x y step5 t x x n is calculated by using equation 26 and then t x n is updated using t x n min t x n t x t x x n step6 return steps 2 5 until far 0 step7 terminate and provide output where the hydraulic conductivity is used to define the local flow tensor and f x 1is arbitrarily assumed because it does not affect the resulting solution the result is a 3d distance map fig 5c t s x between the starting locations s and each point pixels in 2d voxels in 3d within the domain 27 t s x t k 0 s the next step is to find travel routes from groundwater recharge locations e g sinkholes as starting points i to each of the mapped discharge points the gradient between inlets and outlets t s x is calculated and the shortest path from the sinkholes to the springs fig 5c is obtained this approach is implemented by peyré s 2014 matlab function compute geodesic fig 5d shows the solution of the fig 5a but using the ifma which using the equivalent hydraulic conductivity in fig 5b as the initial velocity field and leading to produce unacceptable results for anisotropic cases 2 2 4 incorporating the unsaturated zone unlike the saturated zone where flow is primarily horizontal flow through the unsaturated zone is primarily vertical so that surface depressions collect and concentrate epikarst flows into high angle conduits huntoon 1999 the water table position a function of regional spring locations is a critical factor that separates primarily vertical flow in the unsaturated zone with horizontal flow within the saturated zone borghi et al 2012 proposed that the simulation process be divided into two steps to simulate vertical flow within the unsaturated zone where the first step identifies high angle conduits within the unsaturated zone between the ground surface and the water table and the second step identifies sub horizontal flow in the saturated zone from unsaturated zone inputs to springs 3 3d demonstrative example the purpose of this paper is to develop a conceptual framework and numerical method but doesn t provide detailed and accurate regional models for testing for the lack of a karst system which both the real location of conduit networks and the geometric of fractures are known the simulation conduit networks results can t be compared with that of real and can only be verified by indirectly evidences e g tracer test and catchment area this is why we show the 3d example only to demon strate the applicability of the method our proposed methodology is applied to the 14 31 km2 wulongdong basin in xingshan county yichang city hubei province south china fig 6 which experiences a subtropical monsoon climate with an average annual precipitation of 952 mm and temperature of 12 9 c the basin is located in the east side of a wide syncline within the cambrian ordovician carbonate strata which dip gently 5 to 15 to the southeast at the site three carbonate limestone and dolostone aquifers underly the study area fig 6d the uppermost loushanguan formation lsg the intermediate qinjiamiao formation qjm and the lowermost tianheban formation thb while an overlying ordovician carbonate formation is distinct from the underlying loushanguan formation it is thin with few outcrops so that it is combined with the loushanguan formation in this study these carbonate rocks along with favorable climatic conditions promote the development of karst in the area sinkholes closed depressions are common so that most net precipitation infiltrates and recharges underlying karstic aquifers regional groundwater discharges at two springs springs 1 and 2 with elevations of 620 and 624 m and flow of 2 21 10 2 to 1 99 m3 s and 1 57 to 1 41 m3 s respectively that are found at the base of the thb where the gaolan river has incised into the underlying clastic shipai formation sp since wulongdong basin is a young underground river system with small scale the average diameter of maximum conduit is about 2 85 m which calculated by the results of tracer test the underground watershed is considered to be consistent with the surface watershed and each depression is isolated so the capture zones for each depression table 5 were calculated according to dem analysis two tracer tests were conducted to find out the connecting result between the sinkhole1 and 6 and two springs luo et al 2016 the details of each test are tabulated in table1 sodium fluorescein tracers injected in august 2014 and june 2015were detected at spring1 only 6 5hrs and 8hrs after they were injected into sinkhole 1 and 6 average inflows of 634 29 and 285 71 l s respectively and the maximum tracer concentrations were recorded only 0 97and 1 09hrs after the first arrival the results of two tracer test show that both sinkholes are linked to spring 1 and neither is linked to spring 2 both tracer break through curves show a single symmetrical peak that suggest that there is a conduit between the sinkholes and the spring 3 1 specifying the aquifer rev fracture geometries were measured at twelve outcrops using 2 2 m2 statistical windows fig 6c in order to obtain the measurement data of fractures as much as possible some outcrops near the study basin were measured because the process of forming the study region are monoclinic and under the same regional tectonic stress the fractures in a formation have the same directivity and regularity whether they are located in or near the basin fracture orientations were estimated and plotted using dips which identified four statistically significant groups in each formation table 2 fig 7 the first group corresponds to bedding plane fractures while the remaining three groups correspond to high angle structural fractures we used the method of song 2016 to characterize fracture aperture size and type where fracture apertures less than 200 μ m are considered closed and were not used in subsequent analyses single sample k s test analysis was performed on other geometric features using spss the length of bedding plane fractures are uniformly distributed the apertures are log normal distributed p 0 1 while the remainder are normally distributed p 0 1 statistical characteristics are summarized in tables 1 and 2 in which n is the fracture group α and β are fracture dip directions and angles respectively the minimum volume required to establish the representative equivalent volume rev was determined based on a global domain of 20 20 20 m cube a trial subdomain started at 1 1 1m cube and was then extended by one meter in each dimension until it reached ten meters the number of fractures in each trial subdomain increased from tens to thousands as the subdomain size increased calculation times also increased from tens of seconds to tens of hours with the longest execution time requires 56 hrs that was reduced by about 4 hrs compared with using the original code as shown in fig 8 the principal values of the hydraulic conductivity stabilized when grid sizes of 6 m 6 m and 7 m were reached for the thb qjm and lsg respectively 3 2 k tensor results hydraulic conductivity tensors were calculated within the specified rev by changing the orientation from 0 to 360 and dip angles from 0 to 180 in increments of 3 0 yielding 91 orientations an ellipsoid was then fit to the 91 values using ordinary least squares as shown in fig 9 this step required substantial computational effort the longest tianheban formation takes approximately 25 hrs for each model run which is about 7 hrs less than using the original code the resulting hydraulic conductivity tensors for each formation are provided in table 3 which are then reduced to their principal directions using their eigenfunctions shown in table 4 note that the principal magnitudes are within a factor of two of each other in each formation principal orientations are approximately 121 west northwest to east southeast 148 north northwest to south southeast and 189 north to south for the thb qjm and lsg respectively also note that major axes of thb and lsg and medium axes of qjm are steeply inclined 50 which supports increased vertical development and recharge the remainder axes are sub horizontal 30 which represents bedding plane flow 3 3 incorporating the hydrogeologic setting the regional hydrogeologic setting was established using 1 50 000 topographic maps and geologic surveys that were imported into gms these data were used to identify sinkhole and spring locations as well as aquifer thicknesses aquifer isopachs were used to establish the upper and lower elevations of each hydrostratigraphic unit the resulting aquifer extents were then discretized into 60 100 equal intervals horizontally and three layers vertically fig 10 a the uppermost formation the loushanguan was subdivided into five equal layers to better account for surface topographic features the resulting voxel size 1000 m3 was larger than the estimated rev voxels within each aquifer were then assigned corresponding hydraulic conductivity tensors 3 4 afma results the initial upstream computation started by defining the spring 2 elevation as the starting plane afma was then used to map the shortest distance in three dimensions from each point to this plane sinkholes were used as the end points for particle tracking to obtain the karst conduit networks within the unsaturated zone once the paths between the sinkholes and the plane were specified the travel paths between both springs 1 and 2 were used as the starting points with the end points being the location of the bottom of the unsaturated zone paths the resulting karst conduit networks are shown in fig 10b and table 5 which show that spring 1 collects water from sinkholes 1 to 7 while spring 2 collects water from sinkholes 8 to 14 which is consistent with tracer tests that show sinkholes 1 and 6 draining to spring 1 the corresponding catchment areas of springs 1 and 2 are estimated to be 7 20 and 4 84 km2 respectively and the ratio of their catchment areas 1 49 are approximately equal their baseflow discharge ratio 1 41 4 discussion 4 1 epm hct r vs discrete fractures hct en to explore the adaptability of our method in field application a 2d synthetic model is used to compare the results of the conduit network obtained by afma on discrete fracture networks dfn map and its equivalent porous medium epm map we define a simulation region that is 30 30 m2 with two sets of fractures shown in table 6 and an rev of 3 3 m2 we then compare the k tensor provided by adfne1 5 that is based on an rev hct r with the tensor generated at each geological position hct egp using graph theory method peyré 2014 fig 11 presents the conduit networks generated using both methods where blue dotted lines are the results of hct r and red dotted lines are the results of hct egp these results show a consistent paths except for two paths with a maximum deviation of 1 39 m this implies that the epm assumtion provides a feasible method for generating karst conduit networks to analyze flow and transport prediction with a lack of knowledge about network geometry 4 2 afma vs sks while our procedure resembles sks the methods used to generate the flow field are different a the initial sks step needs to stochastically generate fractures controlling the generation of karst conduits which means that sks is not suitable for the karst basin where the conduits are controlled by a large number of fractures our method uses equivalent hydraulic parameters to treat dense fractures avoiding the limitation caused by computer efficiency and memory b the sks flow field transforms geologic information using an isotropic hydraulic conductivity our method uses a tensor to represent hydraulic conductivity at the rev scale and c the final sks step is to find the 3d distance map using the isotropic fast marching algorithm ifma our method uses the anisotropic algorithm instead that allows for preferential flow based on the geologic framework on the case of discrete fracture networks map afma are more accurate than sks which can be demonstrated by comparing a 2d isotropic k borghi et al 2012 with a k tensor that has a principal hydraulic conductivity associated with bedding plain fractures kh that is twice that of vertical fractures kv the horizontal hydraulic conductivity at each point in sks is the equivalent hydraulic conductivity of the hydraulic conductivity tensor in afma 27 k k h k v 1 2 k h as shown in fig 12 using the sks method leads to erroneous results for general anisotropic cases the reason for this incorrect solution is that the gradient direction dosen t coincide with the characteristic direction due to the fact that sks is an single pass algorithm for the eikonal equation which omits the distance t x x n so that it does not correctly identify the minium error sethian and vladimirsky 2001 zhang et al 2013 based on this reasoning we believe that afma provides more realistic representations of flow conduits when compared with sks borghi et al 2012 4 3 afma vs streamline modeling the core of the approach relies on the use of the afma alternatively the similar re sults can be obtain by using groundwater flow simulations and compute streamlines borghi et al 2012 a synthetic model that two groups of mutually perpendicular fractures are simulated within a porous matrix the principal hydraulic conductivity of the first group of fractures is twice that of the second group and three orders of magnitude greater than the matrix flow was simulated using gms with a constant source term throughout the domain a drain at the spring position and no flow boundaries on the sides the shape of conduits generated by afma fig 13 a is strongly affected by the fracture location than those generated by gms fig 13b the conduit networks acquired by using gms are also strongly influenced by no flow boundary on the sides of the model furthermore gms simulations only account for fractures that are perpendicular to each other and finally gms simulations are more cpu demanding one steady flow simulation within a 600 600 m 2d domain takes about 2 3 min for gms but less than 2 s using for afma on a quad core pc running at 3 4 ghz with 8 gb of internal memory in 3d accounting for the vadose zone flow simulations would require solving the unsaturated flow equations on very large grids due to the nonlin earity of those equations the demonds of cpu can become extremely intensive borghi et al 2012 4 4 boundary effects generating the rev requires that a domain be constructed with specified heads on two opposing boundaries with no flow conditions specified on the four remaining boundaries unfortunately calculated flows are affected by the inability of flows to extend laterally beyond these no flow boundaries which reduces the calculated hydraulic conductivity extending the domain laterally to allow flow to leave and then re enter the domain would improve the estimated hydraulic conductivity alternatively establishing a unit gradient along the boundary may also improve the k tensor estimate 4 5 additional concerns it is important to note that conduit flows are critical for determining flowpaths in karst aquifers pardo igquiza et al 2012 saller et al 2013 yet the identification of these flow paths is challenging and estimates have high uncertainties our approach provides a means for both identifying the most likely path as well as a means for assessing its uncertainty in addition our method is based on measured attributes of the system including fracture geometries topographic information and hydrogeologic surveys while the true locations of identified conduits remain uncertain flow models using these conduits provide more realistic simulations of groundwater levels and flow paths than homogeneous or epm models vuilleumier et al 2013 one shortcoming of the 3d demonstrative example is the adoption of a single k tensor for each aquifer while it is expected that fracture network properties vary spatially it is difficult to account for these heterogeneities without field data to support them our view is that a single value is the most parsimonious for our system in that there are insufficient data to justify additional parameterization of course other field sites may have additional fracture network properties from well logs tunnels etc which would justify a spatially explicit k tensor another shortcoming is the failure to incorporate water rock interactions in the evolution of karst conduits while speleogenetic models that use physical and geochemical processes to estimate conduit formation by weathering and erosion provide additional insight into conduit formation they are difficult to apply due to uncertain paleo climatic and geological conditions during the evolutionary process borghi et al 2016 these models are also difficult to develop due to nonlinear coupled equations that require enormous computational effort borghi et al 2012 our method avoids these challenges by providing a computationally efficient alternative that incorporates these processes indirectly by accounting for important interactions between fractures and conduit formation 5 summary and conclusions understanding and predicting flow and transport in karst landscapes is difficult due to uncertainties associated with the locations of preferential flowpaths through conduits such as faults fractures and dissolution enlarged passageways here we present an improved method for determining conduit networks in karst aquifers that connects groundwater inputs e g sinkholes to outputs e g springs using fracture characteristics topographic features and hydrogeologic information field observations of fracture geometries e g length orientation and apertures obtained from rock outcrops are processed using the software tool dips to statistically characterize fracture properties and to group fractures into joint sets based on stereographic projections fracture characterization data are then used to generate multiple realizations of discrete fracture networks dfn using monte carlo methods within the matlab toolbox adfne1 5 the toolbox then uses dfn realizations to determine the minimum size of the representative elementary volume rev based on the scale at which the geologic medium behaves as an equivalent porous medium epm epm properties are then determined by generating the hydraulic conductivity tensor that describes the anisotropic hydraulic properties of each hydrogeologic unit topographic and hydrogeologic data are managed using the software tool gms to specify the flow domain by identifying groundwater recharge and discharge locations through multiple aquifers the domain is then transferred to matlab where it is further discretized into voxels that are larger than the rev volume conduits are then identified based on the minimum effort path between groundwater inputs and outputs using the matlab toolbox afma this is a two step process where the first step identifies near vertical flows through the unsaturated zone from the ground surface within local capture zones to the water table below it followed by determining near horizontal paths from unsaturated zone inputs through the saturated zone to springs the method is demonstrated using information from the 14 31 km2 karstic wulongdong basin in hubei province china where fourteen recharge locations contribute to two springs through three carbonate aquifers tracer experiments conducted between two recharge locations and springs are consistent with the predicted conduit network connection and the ratio of two springs predicted catchment areas are approximately equal to that of their baseflow discharge this approach is unique in that it uses the anisotropic fast marching algorithm afma to incorporate media anisotropy using the hydraulic conductivity tensor afma reduces the computational effort for our large fracture network where flow is controlled by local scale dense and interconnected fractures computation efforts were further reduced by updating adfne1 5 to include sparse matrix declarations and converting the code so that it performs parallel calculations using multiple processors we believe that afma provides a better prediction than the ifma because it accounts for the important effects of preferential flow directions also our method provides similar results to the more computationally intensive pten approach that assigns a different tensor to each node which can be difficult to determine in the absence of field data to parameterize and finally we emphasize that we do not account for stormflow that may alter flow pathways as water tables rise within our multilayer aquifer system we also do not account for increased aquifer hydraulic conductivities due to speleogenesis which is the interaction of water with carbonate rocks that promotes the dissolution and weathering of the host rock links for some toolboxes dips frac matlab mofrac credit authorship contribution statement lichuan luo methodology writing original draft xing liang supervision bin ma supervision hong zhou supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by national natural science foundation of china 41772268 we are grateful to todd c rasmussen of the university of georgia and menggui jin of the china university of geosciences wuhan for their revision of this article yf alghalandis for providing the matlab toolbox as well as manuscript reviewers for their helpful comments appendix matlab codes a 1 function flow function q flow dfn q inflow dfn struct fields pip etc type dfn pip type type of pipe b dfn bbn b the mask grh dfn grh graph i find type 1 inflow boundary j zeros length i 1 initialize the j for k 1 length i find the inflow edge if type i k 1 0 if b i k 1 1 j k numel find b 1 i k 1 1 end end end j find j 0 update j q sum cat 1 grh edge j flow results of inflow end a 2 toolbox adfne1 5 modifications modification 1 lines 86 113 in function pipe used to build pipe coordinates and types are moved to function pipe for modification 2 lines 69 83 in function bbox used to create an index of intersecting fractures are moved to function bbox for modification 3 inputs and outputs of functions pipe for and bbox for are out bbox for in bxs pip pla pdp typ pipe for xts center be ids la xls where in is the set of polygons cell bxs is the bounding box for every individual entity of the input out is set of two intersecting xts is set of intersection lines center is the center of fracture ids is the set of two intersecting be are boundary elements la is the clustering labels for all fractures in the network xls is set of intersection lengths pip is the set of intersection lengths pla is the set of pipe labels pdp is the percolating state typ is set of pipe types modification 4 function coder is used to generate mex files pipe for mex and bbox for mex for functions pipe for and bbox for respectively modification 5 line 44 of function isolated is altered by adding the code distcomp feature localusempiexec false change the for loop to a perfor loop to enable parallel calculation modification 6 lines 57 70 in function slove are changed to use functions sparse and full when calculating large matrices to reduce memory and computation time c cell inn 1 initializes cell c d cell inn 1 initializes cell d e cell inn 1 initializes cell e for i 1 inn loops over all inner nodes egs g edge g node inx i edges node s edges c conductance egs length egs aperture egs depth kv computes conductance nn setdiff egs nodes inx i stable node s neighboring nodes f g node nn type 0 inner mask u ind nn f inner neighboring node s indexes v c f inner node s conductance t size u 2 inner neighboring node s number f zeros t 3 initializes matrix f for nl 1 t loops over all inner node s neighboring nodes f nl 1 3 i u nl v nl fill in the matrix f end c i 1 f fill in the cell c d i 1 i i sum c fill in the cell d if all f continue end if all were inner nodes e i 1 i 1 sum c f g node nn f pressure updates e vector end a1 cell2mat c d a sparse a1 1 a1 2 a1 3 inn inn build sparse matrix a b1 cell2mat e b sparse b1 1 b1 2 b1 3 inn 1 build sparse matrix b x full a b finds the solution 
4363,modeling spatial distribution of flow depth in fluvial systems using a hybrid two dimensional hydraulic multigene genetic programming approach xiaohui yan a abdolmajid mohammadian b ali khelifa c a school of water resources engineering dalian university of technology 2 ling gong road dalian 116024 china school of water resources engineering dalian university of technology 2 ling gong road dalian 116024 china school of water resources engineering dalian university of technology 2 ling gong road dalian 116024 china b professor department of civil engineering university of ottawa 161 louis pasteur ottawa k1n6n5 canada professor department of civil engineering university of ottawa 161 louis pasteur ottawa k1n6n5 canada professor department of civil engineering university of ottawa 161 louis pasteur ottawa k1n6n5 canada c emergencies science and technology division environmental technology centre environment canada 335 river road ottawa k1a0h3 canada emergencies science and technology division environmental technology centre environment canada 335 river road ottawa k1a0h3 canada emergencies science and technology division environmental technology centre environment canada 335 river road ottawa k1a0h3 canada corresponding author this manuscript was handled by huaming guo editor in chief modeling spatial distribution of flow depth in fluvial systems is crucial for flow mitigation river rehabilitation and design of water resources infrastructure flow depth in fluvial systems can be typically estimated using hydrological or physics based hydraulic models however hydrological models may not be able to provide satisfactory predictions for catchments with limited data because they normally ignored the strict conservation of momentum traditional fully physics based hydraulic models are often very computationally expensive limiting their wide usage in practical applications in this study a novel method based on a hybrid two dimensional 2d hydraulic multigene genetic programming mggp approach is proposed and employed to model the spatial distribution of flow depth in fluvial systems a 2d hydraulic model was constructed using the telemac 2d software and validated against field measurements the validated model was then assumed to reflect the real physical processes and utilized to carry out additional computations to obtain spatial distribution of flow depth under different discharge scenarios which provided a sufficient synthetic dataset for training machine learning models based on the mggp technique the study area a segment of the ottawa river near the island named île kettle was divided into 34 sub regions to further reduce the computational costs of the training processes and the complexity of the evolved models the numerical data were distributed to the corresponding sub regions and an mggp based model was trained for each sub region these models are compact explicit arithmetic equations that can be readily transferable and can immediately output the flow depth at any point in the corresponding sub region as functions of the flow rate longitudinal and transversal coordinates the best mggp model for each sub region amongst all the generated models was identified using the pareto optimization approach the results showed that the best mggp models satisfactorily reproduced the training data and predicted the testing data the root mean square errors were 0 303 m and 0 306 m respectively demonstrating the predictive capability of the approach a comparison between mggp and single gene genetic programming sggp approaches and confidence analysis were also reported which demonstrated the good performance of the proposed approach furthermore it took about 53 min for the hydraulic model to complete each simulation but it took only about 0 56 s using the final model the total size of the hydraulic output files for 12 different sizes was 432 948 kb but the total size of the script file for the final model was only about 46 kb therefore the present study found that the hybrid 2d hydraulic mggp approach was satisfactorily accurate fast to run and easy to use and thus it is a promising tool for modeling spatial distribution of flow depth in fluvial systems keywords spatial distribution flow depth 2d hydraulic multigene genetic programming ottawa river 1 introduction estimating flow depth of fluvial systems is very important for river engineering applications such as river rehabilitation and most importantly flood risk mitigation hosseiny et al 2020 flooding is one of the most common and widespread weather related natural disasters usually causing serious consequences such as human casualties and building collapses li et al 2020 ming et al 2020 due to global climate change more extreme climatic events and resultant flood events are expected or already experienced increasing the threats from floods for example what people thought were 100 year floods inundated some communities in ottawa twice within a three year period 2017 and 2019 respectively inundation forecasting can provide necessary information on flood hazards to the decision makers and stakeholders and is thus the crucial component of flood disaster control planning burn and whitfield 2016 inundation forecasting primarily focuses on two variables inundation region and inundation depth jamali et al 2018 these two variables can both be derived from the spatial distribution of flow depth for example a location can be regarded as inundated if the water depth exceeds a threshold such as 0 3 m ming et al 2020 therefore estimating flow depth is the core task of inundation analyses furthermore flow depth is one of the most important variables that characterize the hydrological and hydrodynamic properties of a river partially because water surface elevations can be easily calculated from river depth by adding up the river bed elevations and the averaged velocity at a cross section can be roughly estimated by dividing the discharge by the flow area which is a function of the river depth flow depth in fluvial systems has been a topic of significant research generally most of the existing models for flooding processes can be classified into two categories hydrological or hydraulic hydrological models are currently the most popular choice for inundation forecasting especially when a timely prediction is required and the study area is a large scale catchment bermúdez et al 2018 traditional hydrological models mainly calculate the time series of discharges in fluvial systems but recent distributed hydrological models based on digital elevation models dem can also delineate the inundation extends and depths zhang et al 2014 li et al 2020 ming et al 2020 making them widely used nowadays for flood forecasting however hydrological models typically ignore the strict conservation of momentum and can only provide a simplified representation of the hydrological responses thus the predictions obtained by hydrological models cannot meet the desired requirements of prediction accuracies in many cases ming et al 2020 for example a calibrated hydrological model often performs poorly for certain flow conditions such as extreme flows because most of hydrological models are largely dependent on calibrations instead of strict physical principles unduche et al 2018 the hydrological models based on the water level methods such as the flood connected domain algorithm cannot be employed in ungauged areas li et al 2020 those hydrological models based on the bulk method typically perform poorly in catchments with steep elevation differences li et al 2020 therefore physics based hydraulic models which can overcome most of the disadvantages of hydrological models are often required to provide predictions with higher accuracies ming et al 2020 due to the recent advances in computing techniques and resources modeling river channels and floodplains using fully physics based hydraulic models has become feasible teng et al 2017 ming et al 2020 for example the parallel computations and graphics processing units gpus can significantly improve the computing speeds smith liang 2013 ming et al 2020 1d models may not be capable of sufficiently predicting detailed spatial distribution of hydraulic variables because they solve highly simplified forms of the equations in recent years 2d and 3d models have been widely reported and validated e g yan et al 2019a b 2020a b c examples of some popular 2d or 3d hydraulic modeling system include mike dhi delft3d openfoam and telemac mascaret solving the 3d partial differential equations for mass continuity and momentum conservation for a large area is very computationally expensive and is thus still not very practical for some river engineering applications especially those needing real time forecasts the horizontal inundation length scale in fluvial systems typically are much greater than the water depth and thus the flow in fluvial systems can be reasonably resolved using 2d shallow water equations recently ming et al 2020 has executed the high performance integrated hydrodynamic modelling system hipims on a server fitted with 8 nvidia tesla k8 gpuss to simulate a catchment in the united kingdom with an area of 2500 km2 and grid resolution of 10 m the run time of the simulation was completed within 2 h indicating that the efficiency has been significantly enhanced compared to traditional hydraulic simulations ming et al 2020 compared to most hydrological models which can rapidly complete calculations on personal computers the computing machines and calculations for 2d hydraulic simulations are still more expensive and time consuming hindering its wider usage in practical applications previous studies e g bruwier et al 2018 mustafa et al 2020 have investigated the influence of urban characteristics on inundation extents and water depths by integrating hydraulic models and urban procedural models and the inundation properties can be efficiently predicted by using the developed relationships however the integrated model is specifically designed for modeling urban flooding events and is thus not very suitable for modeling flow depths in rivers therefore proposing a new approach for modeling spatial distribution of flow depth in fluvial systems that is highly efficient and accurate is still a significant challenge and requires further investigation supplementing physically based hydraulic models machine learning or artificial intelligence techniques has been successfully applied in water related problems e g mehr and nourani 2017 safari and mehr 2018 jamei and ahmadianfar 2020 jamei et al 2020a 2020b kabir et al 2020 mehr and safari 2020 yan and mohammadian 2019 yang et al 2020d yan and mohammadian 2020 these techniques can relate input and output variables without requiring a modeler to pre define the model structures and thus can eliminate the imperfections of model assumptions and can figure out some deeply hidden relationships the mathematical models obtained by these techniques are typically very efficient and are thus quite suitable for real time forecasts and comparative studies the models developed by machine learning techniques are typically easy to use and thus can reduce the requirements of expertise of the users although the models obtained by these techniques may only be valid within a certain data range depending on the training dataset similar to most data driven techniques these models can be continuously improved with data availability a common limitation of machine learning techniques is the extensive data requirements which often gives rise to the insufficient training problem yang et al 2020d typically flowrates or water depths are only sparsely recorded at a few gauges in a catchment and monitoring detailed spatial distribution of flow depth in fluvial systems is not a common practice therefore it is nearly impossible to employ a traditional machine learning technique to study the distributed flow depths due to the insufficiency of training data to overcome the insufficient training problems recent studies have proposed physical process and machine learning combined models for different problems ding et al 2019 guo et al 2021 hosseiny et al 2020 yang et al 2020d zahura et al 2020 in these studies a physically based model was first calibrated and validated and then the model was assumed to reflect the real physical process and used to provide sufficient data which was in turn adopted by a machine learning technique to train models for example ding et al 2019 combined a computational fluid dynamics model and a feed forward artificial neural network model to develop a multiscale data driven model for atomic layer deposition ald of sio2 the study showed that the model can efficiently describe the dynamic relationships for input and output variables for the sio2 thermal ald process and can significantly reduce the computational costs yang et al 2020d have combined a physically based distributed hydrological model the geomorphology based hydrological model with machine learning techniques to provide a model for daily streamflow simulations the combined model was then applied so as to predict daily streamflow in the upper chao phraya basin in thailand and the results demonstrated that the combined approach can significantly improve the predictions in data limited watersheds compared to the traditional machine learning techniques trained merely by the observational data zahura et al 2020 performed urban flooding simulations in the coastal city of norfolk usa and trained a surrogate model using the random forest rf machine learning technique the results demonstrated that using the rf approach to develop surrogate models is promising hosseiny et al 2020 integrated a physically based model the international river interface cooperative iric with the rf classification and the multilayer perceptron mlp machine learning methods for modeling the flow depth in a segment of the green river in the united states the results showed that the rf and mlp techniques can satisfactorily replicate the predictions obtained by the iric model the study of hosseiny et al 2020 has provided a starting point for estimating flow depth using an integrated numerical and machine learning model however the approach requires further improvements in two aspects first the machine learning techniques adopted by hosseiny et al 2020 were black box namely the techniques cannot provide a compact explicit arithmetic equation describing the relationships between the input and output variables and thus the model cannot be readily transferrable i e it is difficult to incorporate the model into another program and second the study trained a single machine learning based model for an entire large domain and thus the training process would be time consuming and the trained model would be extremely complicated the primary objective of this study is to propose and evaluate a new approach of estimating flow depth in fluvial systems using a hybrid 2d hydraulic multigene genetic programming mggp approach the study was motivated by the fact that there is a lack of flow depth modeling techniques that are satisfactorily accurate and fast to run the present study can provide a new promising tool for flow depth modeling and address the scientific question about whether a hybrid hydraulic mggp approach is capable of efficiently estimating flow depth in fluvial systems in this study the telemac 2d system was used for hydraulic modeling and the mggp technique was used for machine learning a key merit of the mggp approach is that it can provide compact explicit mathematical models and thus the evolved models can be easily transferable and used in different programs e g matlab excel or python etc therefore the mggp technique is adopted in this study instead of other machine learning techniques such as rf mlp and artificial neuron networks moreover instead of training a single mggp model using the numerical data for the entire study domain the present study divided the numerical dataset for the study domain into different sub datasets and each sub dataset was used to train an mggp model for the corresponding sub domain this can reduce the processing time for training the models because the work can be done in parallel and the complexity of the trained models is reduced to the best of the authors knowledge this is the first time that a hybrid 2d hydraulic mggp approach has been proposed to develop models for estimating spatial distribution of flow depth in fluvial systems 2 methodology 2 1 study area the area of interest fig 1 is a segment of the ottawa river in the vicinity of the ropec robert o pickard environmental centre wastewater treatment plant immediately downstream of the island named île kettle the length of the segment is approximately 3 2 km and the river width in the segment varies from approximately 1 06 km to 1 40 km the outaouais community near this area has been dealing with the ottawa river flooding problem for decades and an accurate and easy to use 2d model will be very beneficial for the community for the purpose of evaluating the proposed approach a small region shown in fig 1 was believed sufficient and the training and testing of similar models for the remaining parts of the catchment will be conducted in subsequent studies the bathymetry data in the study area were obtained from the city of ottawa and the data were composed of the canadian hydrographic services chart 1515 and hydrographic surveys the resolution of the bathymetry data varied but most of the data intervals were around 20 m the equipment used for the surveys included knudsen echosounder 320b and garmin gpsmap76 series water depth data used for the model calibrations and validations have been collected by the water resources research group of university of ottawa primarily using adcp acoustic doppler current profiler the data were collected on july 24 2012 and the upstream flowrate was estimated to be 554 5 m3 s the return period of this flowrate is unsure due to the lack of detailed hydrological data in this region but it is believed to be lower than 0 5 years a survey during flooding events is prohibited by the local safety regulations all the data involved in this study have been transformed to the universal transverse mercator utm world geodetic system 1984 wgs84 coordinate system and the zone number for the coordinates is 18 n the extent of the field survey was approximately 451600 m in the west 454800 m in the east 5034800 m in the north and 5 036 400 in the south the number of measured water depth values was 38 621 the shallowest water depth in the dataset was 0 382 m the deepest one was 11 65 m and the average value was 4 34 m the actual computational domain covered a larger area than the area of interest to avoid the imperfections related to boundary condition assumptions fig 1a as mentioned earlier in this paper the present study attempted to divide the area of interest into multiple sub domains this approach can reduce the computational costs and complexity of the evolved models in two ways first the training processes for different sub domains can be executed in parallel and second the output model for each sub region was only expected to describe the local features instead of the global physical processes a virtual rectangular mesh was mapped on the aerial map and numerical results showed that the flows in different scenarios simulated in this study only occurred in the 34 cells shown in fig 1b and thus the other sub regions are not considered in the machine learning study there is no standard guideline to determine the size of the virtual rectangular mesh in this study the mesh was primarily determined based on trial and error exercise the size is small enough to reduce the processing time and large enough to provide enough training data for each sub domain to keep the average amount of data in each sub domain at around 10 000 the statistical descriptions of the flow depth data for each sub region are presented in table 1 2 2 physically based model telemac mascaret is an integrated suite of solvers for hydraulic modeling the hydraulic model solves the shallow water equations also known as the saint venant s equations a form of which can be expressed as hervouet 2007 1 h t u h h d i v u s h 2 u t u v g z x s x 1 h d i v h ν t u 3 v t u v g z y s y 1 h d i v h ν t v where h is depth of water u and v are velocity components g is gravitational acceleration νt is momentum diffusion coefficient z is elevation of the free surface t is time x and y are horizontal space coordinates sh is source or sink of fluid sx and sy are momentum source terms including bottom friction surface wind shear and source sink of momentum in the domain the software mainly requires four input files geometry and mesh file slf boundary file bc2 liquid boundary condition file liq and the steering file cas the first two files were prepared using the software bluekenue and the last two files were simply prepared using wordpad the mesh resolution was determined based on a grid sensitivity study geravand et al 2020 for boundary conditions the upstream boundary was set as an open boundary with a prescribed flowrate and the downstream boundary was set as an open boundary with a prescribed water depth the normal flow assumption was adopted for the downstream computational boundary and the flow depth at the downstream boundary was estimated using the manning s equation using manning s equation to estimate normal depths is a common practice but it is under the assumption of uniform flow conditions while most flow conditions are actually non uniform therefore as mentioned above the actual downstream section of the computational domain has been placed far from the area of interest to minimize the influence of boundary condition imperfections the roughness coefficient was primarily determined based on model calibrations 2 3 multigene genetic programming mggp is a recent advancement of the genetic programming gp approach jamei et al 2020a 2020b khozani et al 2020 it can find relationships between input and output variables through an evolutionary process a key merit of the mggp approach is that it can provide explicit models that can be easily used in different programs e g matlab excel or python etc and its other advantages have been well documented elsewhere in the literature mehr and nourani 2018 pandey et al 2015 safari and mehr 2018 searson 2015 recently mggp has been successfully employed in many water related applications for example yan et al 2019 yang et al 2020d utilized multigene genetic programming approaches to study the mixing properties of inclined dense jets discharged from multiport diffusers and the trajectory of a rosette momentum jet group in flowing currents these studies have demonstrated the generalization capability of the mggp program mggp develops models in an evolving manner in the first generation the program develops an initial chromosome to relate the output and input variables the program then performs certain processes such as reproduction crossover and mutation to improve the model until certain termination criteria are achieved fig 2 presents an example of the evolutionary history of an mggp chromosome in the first generation the program randomly generated two genes which can be expressed as 4 gen e 1 x 1 x 2 cos x 2 and 5 gen e 2 x 2 x 2 x 1 x 2 where x1 and x2 are input values the model then compared the results obtained by the chromosome and those in the training dataset and then modified the model since the comparisons showed that the performance of the model was not satisfactory in the example shown in fig 2 the sub trees in the two initial genes were exchanged to form the second generation genes which is a process known as crossover after the process of crossover the two genes became 6 gen e 1 x 1 x 2 x 2 x 2 and 7 gen e 2 cos x 2 x 1 x 2 the chromosome was continuously evolved as shown in fig 2 a sub tree was randomly created and used to replace a sub tree in the second generation gene 1 to form the third generation gene 1 this process is known as mutation the third generation gene 1 can be expressed as 8 gen e 1 x 1 x 2 x 2 the process of evolution terminated either because the accuracy was regarded as satisfactory or because the program had run for a certain time duration the chromosome shown in fig 2 has two genes and it represents a mathematical model that can be expressed as 9 y α x 1 x 2 x 2 β cos x 2 x 1 x 2 γ where α and β are the weighting coefficients of gene 1 and gene 2 respectively γ is a bias term an ordinary least squares method was adopted to determine these coefficients as can be seen through the example the standard gp approach only allows for a single gene but an mggp chromosome can contain multiple genes the multiple genes can be nonlinear but they are linearly combined to form an mggp chromosome i e an mggp based model can be a linear combination of nonlinear terms therefore to achieve comparable levels of accuracy the required tree depths i e the maximum depth of an mggp tree in mggp chromosomes are typically less than those in gp chromosomes and thus the order of the nonlinear terms in a model developed by mggp is typically lower making the model simpler and easier to use to keep the model complexity i e measured by the nonlinear order comparable mggp chromosomes are expected to be more accurate because they allow for more terms 2 4 hydbrid 2d hydraulic mggp approach fig 3 shows the flow charts of the hybrid 2d hydraulic mggp approach firstly the hydraulic model reads the bathymetry data the boundary conditions and the initial roughness coefficient it then provides the numerical data set which includes the upstream discharge q the x coordinate x y coordinate y and river depth h the numerical results are then compared to the field data if the comparisons show that the model is not satisfactorily accurate the roughness coefficient should be adjusted after the model is calibrated the model is assumed to reflect the real physical processes and employed to the carry out additional computations in order to provide sufficient training samples for machine learning models the numerical data are split into training and testing data sets the training dataset is used to train models and the testing dataset is used as an unseen dataset to evaluate the performance of the model the mggp processes were conducted using the code gptips2 reported by searson 2015 which is open source and can be executed in the matlab environment the input features included q x and y and the output feature was h a pearson correlation assessment was conducted and the results showed that the h q h x and h y correlation coefficients were 0 676 p 0 000 0 007 p 0 015 and 0 191 p 0 000 respectively in each generation a total of 500 models were generated the tournament size and probability of the pareto tournament were set to be 10 and 0 3 respectively roughly 30 of the models were copied to the next generations the number of genes and tree depth were both set as 10 a higher value did not substantially improve the performance of the model for the training dataset but it gave rise to more sophisticated equations and may lead to an issue of overfitting the process was terminated either because the training time reached 3600 s or because the number of generations reached 300 these parameters could be determined by using a sophisticated cross validation approach e g the k fold approach but fixed values were used in this study first this study trained and tested models for a relatively large number of cases 34 sub regions and thus it is believed adequate to use the simple train test split approach for evaluating the performance of the machine learning algorithm and parameters second the results showed that the performance of the algorithm and parameters was satisfactory for all of the sub regions the final model was trained based on hydraulic data so its spatial resolution was the same as that of the hydraulic model after a machine learning model is developed and validated the input data including the discharge x and y coordinates can be used for the model to calculate the final output i e the flow depth corresponding to q x and y 2 5 performance indicies the mean bias error mbe mean absolute error mae root mean squared error rmse and correlation r are used as performance indices which can be expressed as 10 mbe 1 n i 1 n h predicted h actual 11 mae 1 n i 1 n h predicted h actual 12 rmse 1 n i 1 n h predicted h calculated 2 13 r n i 1 n h actual h predicted i 1 n h actual i 1 n h predicted i 1 n h actual 2 i 1 n h actual 2 i 1 n h predicted 2 i 1 n h predicted 2 where n indicates the number of data hpredicted and hactual represent the predicted and actual data respectively 3 results 3 1 model validation and additional computations a grid independence analysis was conducted to determine the optimal size of computational mesh a total of four different meshes mesh 1 mesh 4 were tested and their corresponding numerical results were compared the number of elements for mesh 1 to mesh 4 were 8 927 14 025 25 087 and 56 580 respectively it has been found that the difference between mesh 3 and mesh 4 was insignificant implying that the refinement effect on simulated results was negligible beyond the current level of the fineness to be conservative mesh 4 was adopted as the final mesh the average cpu time for the simulations reported in this study using a single core was approximately 53 min the velocity diffusivity was set as 1 10 6 the time step and number of time steps were set as 1 s and 50 000 s respectively the results obtained by running more time steps were almost identical to the current results a hydraulic model needs to be carefully calibrated and validated prior to being employed the common practice to calibrate a hydraulic river model is to adjust the roughness coefficient to improve the match between measurements and numerical results previous reports for flow mapping of the ottawa river has documented that the manning s roughness coefficient in the main channel was generally 0 03 estimated from aerial photos field inspections and calibration process for a 1d hydraulic model maclaren plansearch inc 1984 ahmed et al 2014 the manning s roughness coefficient typically ranges from 0 009 for plastic to 0 15 for floodplains with trees in this study simulations with different roughness coefficients ranging from 0 02 a value that is suitable for describing clean earth channels to 0 06 a value that is suitable for describing natural channels with very poor conditions have been conducted and the results confirmed that 0 03 was the most appropriate value for the study area in the base case for model validation the discharge was 554 5 m3 s the simulated results for the entire computational domain are shown in fig 4 a the field cruise was taken following a zig zag path and the measured river depths were shown in fig 4 b it should be acknowledged that numerical predictions close to boundaries were often less reliable because of the assumptions of boundary conditions and thus the simulated results for the area of interest shown in fig 1 a were extracted from the entire model for detailed further study fig 4c as can be seen from fig 4 b and c generally the numerical model captured the measured spatial distribution of flow depth very well to further compare the trends of the field and numerical data the numerical data at the locations with field measurements were extracted and used to create a new dataset that has pairs of field numerical data at all measurement points the datasets were sorted from largest to smallest based on the field data series and a moving average analysis with a period of 20 was performed to smooth out irregularities of the data series fig 5 the data in fig 5 corresponded to those in fig 4 b and c for measured and simulated data which were within the area of interest it can be clearly recognized from fig 5 that the hydraulic model tended to underestimate the river depth with high values e g greater than 6 m and overestimate the river depth with low values e g less than 2 m indicating that the numerical results were relatively smoother than the field data a possible reason was that the bathymetry data was not fine enough to capture some small peaks and valleys of the river bed therefore the numerical results at those locations should be used with caution however the performance indices including the mbs mae rmse and r2 for the data range without extreme values i e ranging from 2 to 5 m shown in fig 5 demonstrated that the overall performance of the model was satisfactory another possible reason for the relatively worse predictions was that a single roughness coefficient instead of spatially varied coefficients was employed in the model the match between field data and numerical results may be further improved by using a spatially varied roughness coefficient but this may cause a serious problem of over calibration given that there are not sufficient data for many different scenarios and thus the single value of roughness coefficient was adopted and the performance of the current model was regarded as satisfactory flowrate is a major variable that affects flow depths so this study performs numerical simulations to check how varying flowrate affects the flow depths in the area of interest the validated model has been employed to carry out additional computations for different discharges for the sake of keeping the simulated results more reliable it is better to select scenarios that are close to the one for model validation and thus the final flowrates ranged from 300 to 800 m3 s with an interval of 50 m3 s the flowrate of 550 m3 s is very close to the base case the first 5 cases have smaller flowrates and the last 5 have larger flowrates than the base case the mggp models were trained for all of these scenarios detailed historical flow data for this study area do not exist so it is difficult to estimate the corresponding return periods for these discharges but it is believed sufficient to use 12 different scenarios to evaluate the performance of the proposed method fig 6 presents the simulated distribution of river depths for different discharges in the study area as can be seen in the figure the river depth generally increased with increasing flowrates therefore the numerical outputs were extracted and summarized into a matrix including q x y and h which were then used for machine learning 3 2 evaluation of the hybrid approach developing a single mggp chromosome that can describe the entire study area requires large numbers of genes and trees and these numbers generally increase with increasing area of study domain making the developed model very sophisticated and difficult to use in other programs therefore this study proposes a new framework of training models for the study domain first a virtual mesh was generated fig 1b second the cells that contain water bodies were identified and used as sub domains third mggp models for each sub domain were trained and tested and finally the results for all sub domains were merged a major merit of this approach is that the developed model for each sub region can be quite simple and thus it can be easily integrated into another program another merit is that the training and testing processes can be performed simultaneously a total of 34 sub regions were defined the data points obtained by the hydraulic model were distributed into the corresponding sub region the input data points for each sub region were randomly distributed into two parts the training and testing regarded as unseen data points datasets the former dataset contained approximately 80 of the training data points and the latter dataset contained the remaining data points the mggp program developed 500 models in each generation within the evolutionary process the mean root mean square errors rmses and the standard deviations of these models for the sub region r1 are plotted against the number of generations in fig 7 a the mggp program first randomly generated some elements and thus the fitness at the early stage was low but it promptly reduced the mean rmses from about 0 9 m to about 0 2 m in about 20 generations after about 50 generations the change in fitness with generations became quite small and thus the model performance cannot be significantly improved by performing more evolutions the performance of the models quantified by the values of 1 r2 obtained in the final generation are plotted against the expressional complexity of the models in fig 7 b it can be seen from this trade off plot that the model performance generally increased with increasing complexity however the performance of some models can be further improved without increasing the efficiency and the efficiency of some models can be improved without sacrificing the accuracy these models are denoted using black dots and should not be adopted the other models correspond to the non dominated solutions in the pareto optimal multi objective optimization theory they are known as the pareto optimal models and are denoted using green dots these models located on the pareto front either have the best performance for the same complexity or have the least complexity for the same performance and thus any of these models can be regarded as the most suitable models depending on whether performance or simplicity is more important for the problem of interest a more complicated mggp model does not significantly increase the execution time so this study selected the most accurate mggp pareto optimal model as the best model circled in red in fig 7 the best mggp models for each sub region were identified and used to calculate the river depths as functions of discharge x and y coordinates the outputs were merged to provide the spatial distribution of river depth corresponding to different scenarios the merged results are presented in a way similar to those obtained by the hydraulic data fig 8 as can be seen the results reproduced by the mggp models were very close to those obtained by the numerical model demonstrating that the mggp models have a satisfactory ability of data generalization for spatial distribution of flow depth in a fluvial system to further quantify the performance of the mggp approach the mggp results and hydraulic results hereafter referred to as the actual results were compared in fig 9 the mbe mae rmse and r values are also indicated in the same plot the detailed performance indices for each sub region are listed in table 2 a one way anova analysis has also been performed in the analysis the null hypothesis was all means are equal the alternative hypothesis was at least one mean is different and the significance level was 0 05 the p values for the training and testing datasets were 0 233 and 0 546 respectively which were both greater than the significance level grouping information with the 95 confidence using the tukey method the fisher s least significant difference lsd method and the dunnett method showed that the datasets shared an identical letter therefore the mggp predictions for both the training and testing datasets were not found to be statistically different from the actual data the performance indices for the training and testing data sets were very close implying that the risk of data overfitting was well controlled using the current program settings some other aspects of model performance can also be observed from the data presented in fig 9 for example the maximum flow depths in the actual training and testing datasets were 10 14 m and 10 10 m and those in the predicted datasets were 10 15 m and 10 08 m respectively demonstrating that the technique can also perform well for the maximum flow depth 4 discussion a primary factor that limits the widespread usage of sophisticated hydraulic models in practical engineering projects is the heavy computational costs especially for large domain and real time purposes the outcomes obtained by the proposed approach were mggp based models which were very fast to run for example estimating the river depth at a location in the study area using the hydraulic model took about 53 min but estimating the same data using the mggp based model only took about 0 56 s therefore the proposed approach can significantly improve the efficiency of river depth estimations it should be acknowledged that the estimations produced by the proposed approach are not likely to be better than physics based hydraulic models especially when the machine learning based models are driven by the physically based results but it is still very beneficial because it can provide prompt results with comparable accuracies for example a total of six additional cases q1 425 m3 s q2 475 m3 s q3 525 m3 s q4 575 m3 s q5 625 m3 s q6 675 m3 s were considered with three of them having smaller flowrates than the base case q 554 5 m3 s while the other three cases had larger flowrates than the base case and the r values calculated by comparing the results from the hydraulic and mggp based model for r1 were 0 988 0 992 0 995 0 995 0 995 and 0 995 respectively these high r values imply that it is reasonable to employ the mggp based models as a substitution of hydraulic models to conduct predictions for new scenarios mggp based models trained using field data can be more accurate but detailed measurements of spatial distribution of flow depths in a large study area are difficult to obtain and thus the proposed method is more practical there are numerous different machine learning techniques that can be used for training models such as neural networks and rf approaches however the mggp technique is quite special among the machine learning techniques and advantageous in flow depth predictions because it can provide explicit mathematical expressions so the developed models can be easily used or integrated in other programs for example the best mggp based model for the sub region r1 is illustrated in fig 10 the weighting coefficients for genes 1 10 were 1 740 10 4 22 700 0 203 148 000 1 350 54 000 8 920 10 2 6 710 0 606 and 5 250 10 2 respectively and the bias was 127 000 the symbols x1 x2 and x3 represent the discharge x and y coordinates respectively the explicit formulation shown in fig 10 can be written as equation 14 although this expression includes some non linear terms the orders of these terms were low and they were linearly combined therefore the expressions can be easily copied to or re typed into another program and it is very easy to execute more details about the advantages and disadvantages of mggp over other machine learning techniques can be found elsewhere in the literature jamei et al 2020a 2020b mehr and nourani 2017 mehr and safari 2020 pandey et al 2015 safari and mehr 2018 14 y 22 7 cos log x 2 2 0 x 1 cos x 2 x 1 2 cos x 2 0 5 0 5 148 log cos x 2 x 2 0 0892 cos log x 1 x 1 cos x 2 2 cos cos x 2 0 0525 cos x 2 54 cos log x 1 cos 2 0 x 2 cos x 2 0 5 0 5 1 74 e 4 x 1 cos x 2 2 0 606 x 2 x 1 1 35 log x 1 cos x 1 x 2 cos x 2 3 log cos x 2 x 2 3 8 88 e 16 7 56 e 15 x 2 7 56 e 15 cos x 2 log cos x 2 x 2 3 7 56 e 15 log cos x 1 1 x 1 0 203 x 1 0 5 log sin 2 x 2 x 2 x 2 127 the proposed approach is also advantageous in terms of the requirements of computer storage for example the output file obtained by the hydraulic model for one scenario in this study was in a size of 36 079 kb for 12 different cases the total size was 432 948 kb therefore it can be deduced that storing hydraulic outputs for many different scenarios for a large study domain is not affordable in contrast the proposed approach is equivalent to converting the hydraulic outputs to equations with acceptable losses of accuracy because the efforts of obtaining results from the equations are negligible the total size of the equations stored in the matlab script file for the entire study domain was only about 46 kb and thus it significantly reduced the requirements of storage space as mentioned earlier mggp is a new advancement of the gp machine learning approach and an advantage of this approach is that it allows for multiple genes thus an mggp chromosome is generally more accurate than a traditional gp chromosome in this work the spatial distribution of flow depth in the study area has also been studied using the single gene genetic programing sggp approach which was identical to the mggp approach except that it only allows for a single gene for a chromosome fig 11 a shows the convergence history of the sggp evolutionary process for the sub region r1 the fitness for each generation shows that the mean rmse value dropped to a low level only in a few generations so it converged relatively fast however the rmse values were generally higher than those in the mggp evolutionary process indicating that the mggp models were more accurate than the sggp models fig 11 b presents the population in the last generation the 1 r 2 values were generally higher than those in the mggp population plot and the best model also had a higher value of 1 r 2 than that obtained by the mggp program table 3 listed the performance indices for the best mggp and sggp based models in each sub region which showed that the performance of mggp is superior to that of sggp therefore the results confirmed that the mggp technique developed better models than the sggp approach it is often useful to report the uncertainties of the models the uncertainties of the models can be quantified by using the prediction confidence analyses the analyses were conducted mainly using the nlpredci nonlinear regression prediction confidence intervals function available in matlab which is based on a symmetric confidence interval approach dolan et al 2007 lane and dumouchel 1994 seber and wild 1989 the function returns predictions and 95 confidence interval half widths for the nonlinear regression model at input values from the model coefficients residuals and jacobian matrix the results of nonlinear regression prediction confidence analysis for region r1 are shown in fig 12 as an example in this plot the data were re sorted from largest to smallest for display purposes the results for the other sub regions were close to these sample results in this study the computational downstream boundary condition was estimated based on the assumption that the flow at the downstream cross section was in the normal flow condition although this assumption is commonly used in practical engineering problems and the downstream cross section of the computational domain was located far from the actual downstream cross section of the area of interest this assumption may cause losses of accuracy of the hydraulic model in future work it is worthwhile to monitor the flow conditions at the downstream cross section and obtain a more accurate flow stage relationship from a hydraulic point of view it would be better to use the distances from boundaries or centerlines as mggp input variables because they have clearer physical meanings however the present study used the x and y coordinates instead first the current approach is consistent with most traditional hydrological practices such as estimating flow depths at certain hydrological stations with fixed x and y coordinates second the geographic features in the study area were believed to be stationary and thus the x y coordinates actually provide more or less the same spatial information as the distance values third using x and y coordinates as mggp input variables is more convenient and practical because they can be directly exported from numerical models whereas further calculations are required to obtain distance values the relation between coordinates and flood depth is highly nonlinear so it may be easier for mggp to extract information if distances from boundaries or centerlines were used as input features however the current configurations were believed satisfactory because the models were automatically developed by the program and the developed models can provide predictions in just a few seconds a model trained based on one river section should be used with caution for other sections especially when the differences between the river sections are significant it is not possible in the near future to obtain a generally valid data driven model due to the large amount of data required so it is practical to combine hydraulic and mggp modeling techniques to obtain locally valid models however it would be interesting for future studies to continuously improve the generalization of the model by considering more cases in the training processes it is a common practice to use single roughness values for a small segment and calibrate numerical models by adjusting the values but it should be noted that this is a limitation of the study the reliability and the accuracy of the hydraulic model can be further improved if possible by using spatially distributed roughness values obtained from field investigations declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was partially funded by the natural sciences and engineering research council of canada nserc discovery grants the first author xiaohui yan is supported by the fundamental research funds for the central universities china dut20rc 3 096 the field data were collected by dr ivana vouk we would like thank the editor in chief the anonymous associate editor and the four reviewers for their careful reading of our manuscript and their insightful comments and suggestions 
4363,modeling spatial distribution of flow depth in fluvial systems using a hybrid two dimensional hydraulic multigene genetic programming approach xiaohui yan a abdolmajid mohammadian b ali khelifa c a school of water resources engineering dalian university of technology 2 ling gong road dalian 116024 china school of water resources engineering dalian university of technology 2 ling gong road dalian 116024 china school of water resources engineering dalian university of technology 2 ling gong road dalian 116024 china b professor department of civil engineering university of ottawa 161 louis pasteur ottawa k1n6n5 canada professor department of civil engineering university of ottawa 161 louis pasteur ottawa k1n6n5 canada professor department of civil engineering university of ottawa 161 louis pasteur ottawa k1n6n5 canada c emergencies science and technology division environmental technology centre environment canada 335 river road ottawa k1a0h3 canada emergencies science and technology division environmental technology centre environment canada 335 river road ottawa k1a0h3 canada emergencies science and technology division environmental technology centre environment canada 335 river road ottawa k1a0h3 canada corresponding author this manuscript was handled by huaming guo editor in chief modeling spatial distribution of flow depth in fluvial systems is crucial for flow mitigation river rehabilitation and design of water resources infrastructure flow depth in fluvial systems can be typically estimated using hydrological or physics based hydraulic models however hydrological models may not be able to provide satisfactory predictions for catchments with limited data because they normally ignored the strict conservation of momentum traditional fully physics based hydraulic models are often very computationally expensive limiting their wide usage in practical applications in this study a novel method based on a hybrid two dimensional 2d hydraulic multigene genetic programming mggp approach is proposed and employed to model the spatial distribution of flow depth in fluvial systems a 2d hydraulic model was constructed using the telemac 2d software and validated against field measurements the validated model was then assumed to reflect the real physical processes and utilized to carry out additional computations to obtain spatial distribution of flow depth under different discharge scenarios which provided a sufficient synthetic dataset for training machine learning models based on the mggp technique the study area a segment of the ottawa river near the island named île kettle was divided into 34 sub regions to further reduce the computational costs of the training processes and the complexity of the evolved models the numerical data were distributed to the corresponding sub regions and an mggp based model was trained for each sub region these models are compact explicit arithmetic equations that can be readily transferable and can immediately output the flow depth at any point in the corresponding sub region as functions of the flow rate longitudinal and transversal coordinates the best mggp model for each sub region amongst all the generated models was identified using the pareto optimization approach the results showed that the best mggp models satisfactorily reproduced the training data and predicted the testing data the root mean square errors were 0 303 m and 0 306 m respectively demonstrating the predictive capability of the approach a comparison between mggp and single gene genetic programming sggp approaches and confidence analysis were also reported which demonstrated the good performance of the proposed approach furthermore it took about 53 min for the hydraulic model to complete each simulation but it took only about 0 56 s using the final model the total size of the hydraulic output files for 12 different sizes was 432 948 kb but the total size of the script file for the final model was only about 46 kb therefore the present study found that the hybrid 2d hydraulic mggp approach was satisfactorily accurate fast to run and easy to use and thus it is a promising tool for modeling spatial distribution of flow depth in fluvial systems keywords spatial distribution flow depth 2d hydraulic multigene genetic programming ottawa river 1 introduction estimating flow depth of fluvial systems is very important for river engineering applications such as river rehabilitation and most importantly flood risk mitigation hosseiny et al 2020 flooding is one of the most common and widespread weather related natural disasters usually causing serious consequences such as human casualties and building collapses li et al 2020 ming et al 2020 due to global climate change more extreme climatic events and resultant flood events are expected or already experienced increasing the threats from floods for example what people thought were 100 year floods inundated some communities in ottawa twice within a three year period 2017 and 2019 respectively inundation forecasting can provide necessary information on flood hazards to the decision makers and stakeholders and is thus the crucial component of flood disaster control planning burn and whitfield 2016 inundation forecasting primarily focuses on two variables inundation region and inundation depth jamali et al 2018 these two variables can both be derived from the spatial distribution of flow depth for example a location can be regarded as inundated if the water depth exceeds a threshold such as 0 3 m ming et al 2020 therefore estimating flow depth is the core task of inundation analyses furthermore flow depth is one of the most important variables that characterize the hydrological and hydrodynamic properties of a river partially because water surface elevations can be easily calculated from river depth by adding up the river bed elevations and the averaged velocity at a cross section can be roughly estimated by dividing the discharge by the flow area which is a function of the river depth flow depth in fluvial systems has been a topic of significant research generally most of the existing models for flooding processes can be classified into two categories hydrological or hydraulic hydrological models are currently the most popular choice for inundation forecasting especially when a timely prediction is required and the study area is a large scale catchment bermúdez et al 2018 traditional hydrological models mainly calculate the time series of discharges in fluvial systems but recent distributed hydrological models based on digital elevation models dem can also delineate the inundation extends and depths zhang et al 2014 li et al 2020 ming et al 2020 making them widely used nowadays for flood forecasting however hydrological models typically ignore the strict conservation of momentum and can only provide a simplified representation of the hydrological responses thus the predictions obtained by hydrological models cannot meet the desired requirements of prediction accuracies in many cases ming et al 2020 for example a calibrated hydrological model often performs poorly for certain flow conditions such as extreme flows because most of hydrological models are largely dependent on calibrations instead of strict physical principles unduche et al 2018 the hydrological models based on the water level methods such as the flood connected domain algorithm cannot be employed in ungauged areas li et al 2020 those hydrological models based on the bulk method typically perform poorly in catchments with steep elevation differences li et al 2020 therefore physics based hydraulic models which can overcome most of the disadvantages of hydrological models are often required to provide predictions with higher accuracies ming et al 2020 due to the recent advances in computing techniques and resources modeling river channels and floodplains using fully physics based hydraulic models has become feasible teng et al 2017 ming et al 2020 for example the parallel computations and graphics processing units gpus can significantly improve the computing speeds smith liang 2013 ming et al 2020 1d models may not be capable of sufficiently predicting detailed spatial distribution of hydraulic variables because they solve highly simplified forms of the equations in recent years 2d and 3d models have been widely reported and validated e g yan et al 2019a b 2020a b c examples of some popular 2d or 3d hydraulic modeling system include mike dhi delft3d openfoam and telemac mascaret solving the 3d partial differential equations for mass continuity and momentum conservation for a large area is very computationally expensive and is thus still not very practical for some river engineering applications especially those needing real time forecasts the horizontal inundation length scale in fluvial systems typically are much greater than the water depth and thus the flow in fluvial systems can be reasonably resolved using 2d shallow water equations recently ming et al 2020 has executed the high performance integrated hydrodynamic modelling system hipims on a server fitted with 8 nvidia tesla k8 gpuss to simulate a catchment in the united kingdom with an area of 2500 km2 and grid resolution of 10 m the run time of the simulation was completed within 2 h indicating that the efficiency has been significantly enhanced compared to traditional hydraulic simulations ming et al 2020 compared to most hydrological models which can rapidly complete calculations on personal computers the computing machines and calculations for 2d hydraulic simulations are still more expensive and time consuming hindering its wider usage in practical applications previous studies e g bruwier et al 2018 mustafa et al 2020 have investigated the influence of urban characteristics on inundation extents and water depths by integrating hydraulic models and urban procedural models and the inundation properties can be efficiently predicted by using the developed relationships however the integrated model is specifically designed for modeling urban flooding events and is thus not very suitable for modeling flow depths in rivers therefore proposing a new approach for modeling spatial distribution of flow depth in fluvial systems that is highly efficient and accurate is still a significant challenge and requires further investigation supplementing physically based hydraulic models machine learning or artificial intelligence techniques has been successfully applied in water related problems e g mehr and nourani 2017 safari and mehr 2018 jamei and ahmadianfar 2020 jamei et al 2020a 2020b kabir et al 2020 mehr and safari 2020 yan and mohammadian 2019 yang et al 2020d yan and mohammadian 2020 these techniques can relate input and output variables without requiring a modeler to pre define the model structures and thus can eliminate the imperfections of model assumptions and can figure out some deeply hidden relationships the mathematical models obtained by these techniques are typically very efficient and are thus quite suitable for real time forecasts and comparative studies the models developed by machine learning techniques are typically easy to use and thus can reduce the requirements of expertise of the users although the models obtained by these techniques may only be valid within a certain data range depending on the training dataset similar to most data driven techniques these models can be continuously improved with data availability a common limitation of machine learning techniques is the extensive data requirements which often gives rise to the insufficient training problem yang et al 2020d typically flowrates or water depths are only sparsely recorded at a few gauges in a catchment and monitoring detailed spatial distribution of flow depth in fluvial systems is not a common practice therefore it is nearly impossible to employ a traditional machine learning technique to study the distributed flow depths due to the insufficiency of training data to overcome the insufficient training problems recent studies have proposed physical process and machine learning combined models for different problems ding et al 2019 guo et al 2021 hosseiny et al 2020 yang et al 2020d zahura et al 2020 in these studies a physically based model was first calibrated and validated and then the model was assumed to reflect the real physical process and used to provide sufficient data which was in turn adopted by a machine learning technique to train models for example ding et al 2019 combined a computational fluid dynamics model and a feed forward artificial neural network model to develop a multiscale data driven model for atomic layer deposition ald of sio2 the study showed that the model can efficiently describe the dynamic relationships for input and output variables for the sio2 thermal ald process and can significantly reduce the computational costs yang et al 2020d have combined a physically based distributed hydrological model the geomorphology based hydrological model with machine learning techniques to provide a model for daily streamflow simulations the combined model was then applied so as to predict daily streamflow in the upper chao phraya basin in thailand and the results demonstrated that the combined approach can significantly improve the predictions in data limited watersheds compared to the traditional machine learning techniques trained merely by the observational data zahura et al 2020 performed urban flooding simulations in the coastal city of norfolk usa and trained a surrogate model using the random forest rf machine learning technique the results demonstrated that using the rf approach to develop surrogate models is promising hosseiny et al 2020 integrated a physically based model the international river interface cooperative iric with the rf classification and the multilayer perceptron mlp machine learning methods for modeling the flow depth in a segment of the green river in the united states the results showed that the rf and mlp techniques can satisfactorily replicate the predictions obtained by the iric model the study of hosseiny et al 2020 has provided a starting point for estimating flow depth using an integrated numerical and machine learning model however the approach requires further improvements in two aspects first the machine learning techniques adopted by hosseiny et al 2020 were black box namely the techniques cannot provide a compact explicit arithmetic equation describing the relationships between the input and output variables and thus the model cannot be readily transferrable i e it is difficult to incorporate the model into another program and second the study trained a single machine learning based model for an entire large domain and thus the training process would be time consuming and the trained model would be extremely complicated the primary objective of this study is to propose and evaluate a new approach of estimating flow depth in fluvial systems using a hybrid 2d hydraulic multigene genetic programming mggp approach the study was motivated by the fact that there is a lack of flow depth modeling techniques that are satisfactorily accurate and fast to run the present study can provide a new promising tool for flow depth modeling and address the scientific question about whether a hybrid hydraulic mggp approach is capable of efficiently estimating flow depth in fluvial systems in this study the telemac 2d system was used for hydraulic modeling and the mggp technique was used for machine learning a key merit of the mggp approach is that it can provide compact explicit mathematical models and thus the evolved models can be easily transferable and used in different programs e g matlab excel or python etc therefore the mggp technique is adopted in this study instead of other machine learning techniques such as rf mlp and artificial neuron networks moreover instead of training a single mggp model using the numerical data for the entire study domain the present study divided the numerical dataset for the study domain into different sub datasets and each sub dataset was used to train an mggp model for the corresponding sub domain this can reduce the processing time for training the models because the work can be done in parallel and the complexity of the trained models is reduced to the best of the authors knowledge this is the first time that a hybrid 2d hydraulic mggp approach has been proposed to develop models for estimating spatial distribution of flow depth in fluvial systems 2 methodology 2 1 study area the area of interest fig 1 is a segment of the ottawa river in the vicinity of the ropec robert o pickard environmental centre wastewater treatment plant immediately downstream of the island named île kettle the length of the segment is approximately 3 2 km and the river width in the segment varies from approximately 1 06 km to 1 40 km the outaouais community near this area has been dealing with the ottawa river flooding problem for decades and an accurate and easy to use 2d model will be very beneficial for the community for the purpose of evaluating the proposed approach a small region shown in fig 1 was believed sufficient and the training and testing of similar models for the remaining parts of the catchment will be conducted in subsequent studies the bathymetry data in the study area were obtained from the city of ottawa and the data were composed of the canadian hydrographic services chart 1515 and hydrographic surveys the resolution of the bathymetry data varied but most of the data intervals were around 20 m the equipment used for the surveys included knudsen echosounder 320b and garmin gpsmap76 series water depth data used for the model calibrations and validations have been collected by the water resources research group of university of ottawa primarily using adcp acoustic doppler current profiler the data were collected on july 24 2012 and the upstream flowrate was estimated to be 554 5 m3 s the return period of this flowrate is unsure due to the lack of detailed hydrological data in this region but it is believed to be lower than 0 5 years a survey during flooding events is prohibited by the local safety regulations all the data involved in this study have been transformed to the universal transverse mercator utm world geodetic system 1984 wgs84 coordinate system and the zone number for the coordinates is 18 n the extent of the field survey was approximately 451600 m in the west 454800 m in the east 5034800 m in the north and 5 036 400 in the south the number of measured water depth values was 38 621 the shallowest water depth in the dataset was 0 382 m the deepest one was 11 65 m and the average value was 4 34 m the actual computational domain covered a larger area than the area of interest to avoid the imperfections related to boundary condition assumptions fig 1a as mentioned earlier in this paper the present study attempted to divide the area of interest into multiple sub domains this approach can reduce the computational costs and complexity of the evolved models in two ways first the training processes for different sub domains can be executed in parallel and second the output model for each sub region was only expected to describe the local features instead of the global physical processes a virtual rectangular mesh was mapped on the aerial map and numerical results showed that the flows in different scenarios simulated in this study only occurred in the 34 cells shown in fig 1b and thus the other sub regions are not considered in the machine learning study there is no standard guideline to determine the size of the virtual rectangular mesh in this study the mesh was primarily determined based on trial and error exercise the size is small enough to reduce the processing time and large enough to provide enough training data for each sub domain to keep the average amount of data in each sub domain at around 10 000 the statistical descriptions of the flow depth data for each sub region are presented in table 1 2 2 physically based model telemac mascaret is an integrated suite of solvers for hydraulic modeling the hydraulic model solves the shallow water equations also known as the saint venant s equations a form of which can be expressed as hervouet 2007 1 h t u h h d i v u s h 2 u t u v g z x s x 1 h d i v h ν t u 3 v t u v g z y s y 1 h d i v h ν t v where h is depth of water u and v are velocity components g is gravitational acceleration νt is momentum diffusion coefficient z is elevation of the free surface t is time x and y are horizontal space coordinates sh is source or sink of fluid sx and sy are momentum source terms including bottom friction surface wind shear and source sink of momentum in the domain the software mainly requires four input files geometry and mesh file slf boundary file bc2 liquid boundary condition file liq and the steering file cas the first two files were prepared using the software bluekenue and the last two files were simply prepared using wordpad the mesh resolution was determined based on a grid sensitivity study geravand et al 2020 for boundary conditions the upstream boundary was set as an open boundary with a prescribed flowrate and the downstream boundary was set as an open boundary with a prescribed water depth the normal flow assumption was adopted for the downstream computational boundary and the flow depth at the downstream boundary was estimated using the manning s equation using manning s equation to estimate normal depths is a common practice but it is under the assumption of uniform flow conditions while most flow conditions are actually non uniform therefore as mentioned above the actual downstream section of the computational domain has been placed far from the area of interest to minimize the influence of boundary condition imperfections the roughness coefficient was primarily determined based on model calibrations 2 3 multigene genetic programming mggp is a recent advancement of the genetic programming gp approach jamei et al 2020a 2020b khozani et al 2020 it can find relationships between input and output variables through an evolutionary process a key merit of the mggp approach is that it can provide explicit models that can be easily used in different programs e g matlab excel or python etc and its other advantages have been well documented elsewhere in the literature mehr and nourani 2018 pandey et al 2015 safari and mehr 2018 searson 2015 recently mggp has been successfully employed in many water related applications for example yan et al 2019 yang et al 2020d utilized multigene genetic programming approaches to study the mixing properties of inclined dense jets discharged from multiport diffusers and the trajectory of a rosette momentum jet group in flowing currents these studies have demonstrated the generalization capability of the mggp program mggp develops models in an evolving manner in the first generation the program develops an initial chromosome to relate the output and input variables the program then performs certain processes such as reproduction crossover and mutation to improve the model until certain termination criteria are achieved fig 2 presents an example of the evolutionary history of an mggp chromosome in the first generation the program randomly generated two genes which can be expressed as 4 gen e 1 x 1 x 2 cos x 2 and 5 gen e 2 x 2 x 2 x 1 x 2 where x1 and x2 are input values the model then compared the results obtained by the chromosome and those in the training dataset and then modified the model since the comparisons showed that the performance of the model was not satisfactory in the example shown in fig 2 the sub trees in the two initial genes were exchanged to form the second generation genes which is a process known as crossover after the process of crossover the two genes became 6 gen e 1 x 1 x 2 x 2 x 2 and 7 gen e 2 cos x 2 x 1 x 2 the chromosome was continuously evolved as shown in fig 2 a sub tree was randomly created and used to replace a sub tree in the second generation gene 1 to form the third generation gene 1 this process is known as mutation the third generation gene 1 can be expressed as 8 gen e 1 x 1 x 2 x 2 the process of evolution terminated either because the accuracy was regarded as satisfactory or because the program had run for a certain time duration the chromosome shown in fig 2 has two genes and it represents a mathematical model that can be expressed as 9 y α x 1 x 2 x 2 β cos x 2 x 1 x 2 γ where α and β are the weighting coefficients of gene 1 and gene 2 respectively γ is a bias term an ordinary least squares method was adopted to determine these coefficients as can be seen through the example the standard gp approach only allows for a single gene but an mggp chromosome can contain multiple genes the multiple genes can be nonlinear but they are linearly combined to form an mggp chromosome i e an mggp based model can be a linear combination of nonlinear terms therefore to achieve comparable levels of accuracy the required tree depths i e the maximum depth of an mggp tree in mggp chromosomes are typically less than those in gp chromosomes and thus the order of the nonlinear terms in a model developed by mggp is typically lower making the model simpler and easier to use to keep the model complexity i e measured by the nonlinear order comparable mggp chromosomes are expected to be more accurate because they allow for more terms 2 4 hydbrid 2d hydraulic mggp approach fig 3 shows the flow charts of the hybrid 2d hydraulic mggp approach firstly the hydraulic model reads the bathymetry data the boundary conditions and the initial roughness coefficient it then provides the numerical data set which includes the upstream discharge q the x coordinate x y coordinate y and river depth h the numerical results are then compared to the field data if the comparisons show that the model is not satisfactorily accurate the roughness coefficient should be adjusted after the model is calibrated the model is assumed to reflect the real physical processes and employed to the carry out additional computations in order to provide sufficient training samples for machine learning models the numerical data are split into training and testing data sets the training dataset is used to train models and the testing dataset is used as an unseen dataset to evaluate the performance of the model the mggp processes were conducted using the code gptips2 reported by searson 2015 which is open source and can be executed in the matlab environment the input features included q x and y and the output feature was h a pearson correlation assessment was conducted and the results showed that the h q h x and h y correlation coefficients were 0 676 p 0 000 0 007 p 0 015 and 0 191 p 0 000 respectively in each generation a total of 500 models were generated the tournament size and probability of the pareto tournament were set to be 10 and 0 3 respectively roughly 30 of the models were copied to the next generations the number of genes and tree depth were both set as 10 a higher value did not substantially improve the performance of the model for the training dataset but it gave rise to more sophisticated equations and may lead to an issue of overfitting the process was terminated either because the training time reached 3600 s or because the number of generations reached 300 these parameters could be determined by using a sophisticated cross validation approach e g the k fold approach but fixed values were used in this study first this study trained and tested models for a relatively large number of cases 34 sub regions and thus it is believed adequate to use the simple train test split approach for evaluating the performance of the machine learning algorithm and parameters second the results showed that the performance of the algorithm and parameters was satisfactory for all of the sub regions the final model was trained based on hydraulic data so its spatial resolution was the same as that of the hydraulic model after a machine learning model is developed and validated the input data including the discharge x and y coordinates can be used for the model to calculate the final output i e the flow depth corresponding to q x and y 2 5 performance indicies the mean bias error mbe mean absolute error mae root mean squared error rmse and correlation r are used as performance indices which can be expressed as 10 mbe 1 n i 1 n h predicted h actual 11 mae 1 n i 1 n h predicted h actual 12 rmse 1 n i 1 n h predicted h calculated 2 13 r n i 1 n h actual h predicted i 1 n h actual i 1 n h predicted i 1 n h actual 2 i 1 n h actual 2 i 1 n h predicted 2 i 1 n h predicted 2 where n indicates the number of data hpredicted and hactual represent the predicted and actual data respectively 3 results 3 1 model validation and additional computations a grid independence analysis was conducted to determine the optimal size of computational mesh a total of four different meshes mesh 1 mesh 4 were tested and their corresponding numerical results were compared the number of elements for mesh 1 to mesh 4 were 8 927 14 025 25 087 and 56 580 respectively it has been found that the difference between mesh 3 and mesh 4 was insignificant implying that the refinement effect on simulated results was negligible beyond the current level of the fineness to be conservative mesh 4 was adopted as the final mesh the average cpu time for the simulations reported in this study using a single core was approximately 53 min the velocity diffusivity was set as 1 10 6 the time step and number of time steps were set as 1 s and 50 000 s respectively the results obtained by running more time steps were almost identical to the current results a hydraulic model needs to be carefully calibrated and validated prior to being employed the common practice to calibrate a hydraulic river model is to adjust the roughness coefficient to improve the match between measurements and numerical results previous reports for flow mapping of the ottawa river has documented that the manning s roughness coefficient in the main channel was generally 0 03 estimated from aerial photos field inspections and calibration process for a 1d hydraulic model maclaren plansearch inc 1984 ahmed et al 2014 the manning s roughness coefficient typically ranges from 0 009 for plastic to 0 15 for floodplains with trees in this study simulations with different roughness coefficients ranging from 0 02 a value that is suitable for describing clean earth channels to 0 06 a value that is suitable for describing natural channels with very poor conditions have been conducted and the results confirmed that 0 03 was the most appropriate value for the study area in the base case for model validation the discharge was 554 5 m3 s the simulated results for the entire computational domain are shown in fig 4 a the field cruise was taken following a zig zag path and the measured river depths were shown in fig 4 b it should be acknowledged that numerical predictions close to boundaries were often less reliable because of the assumptions of boundary conditions and thus the simulated results for the area of interest shown in fig 1 a were extracted from the entire model for detailed further study fig 4c as can be seen from fig 4 b and c generally the numerical model captured the measured spatial distribution of flow depth very well to further compare the trends of the field and numerical data the numerical data at the locations with field measurements were extracted and used to create a new dataset that has pairs of field numerical data at all measurement points the datasets were sorted from largest to smallest based on the field data series and a moving average analysis with a period of 20 was performed to smooth out irregularities of the data series fig 5 the data in fig 5 corresponded to those in fig 4 b and c for measured and simulated data which were within the area of interest it can be clearly recognized from fig 5 that the hydraulic model tended to underestimate the river depth with high values e g greater than 6 m and overestimate the river depth with low values e g less than 2 m indicating that the numerical results were relatively smoother than the field data a possible reason was that the bathymetry data was not fine enough to capture some small peaks and valleys of the river bed therefore the numerical results at those locations should be used with caution however the performance indices including the mbs mae rmse and r2 for the data range without extreme values i e ranging from 2 to 5 m shown in fig 5 demonstrated that the overall performance of the model was satisfactory another possible reason for the relatively worse predictions was that a single roughness coefficient instead of spatially varied coefficients was employed in the model the match between field data and numerical results may be further improved by using a spatially varied roughness coefficient but this may cause a serious problem of over calibration given that there are not sufficient data for many different scenarios and thus the single value of roughness coefficient was adopted and the performance of the current model was regarded as satisfactory flowrate is a major variable that affects flow depths so this study performs numerical simulations to check how varying flowrate affects the flow depths in the area of interest the validated model has been employed to carry out additional computations for different discharges for the sake of keeping the simulated results more reliable it is better to select scenarios that are close to the one for model validation and thus the final flowrates ranged from 300 to 800 m3 s with an interval of 50 m3 s the flowrate of 550 m3 s is very close to the base case the first 5 cases have smaller flowrates and the last 5 have larger flowrates than the base case the mggp models were trained for all of these scenarios detailed historical flow data for this study area do not exist so it is difficult to estimate the corresponding return periods for these discharges but it is believed sufficient to use 12 different scenarios to evaluate the performance of the proposed method fig 6 presents the simulated distribution of river depths for different discharges in the study area as can be seen in the figure the river depth generally increased with increasing flowrates therefore the numerical outputs were extracted and summarized into a matrix including q x y and h which were then used for machine learning 3 2 evaluation of the hybrid approach developing a single mggp chromosome that can describe the entire study area requires large numbers of genes and trees and these numbers generally increase with increasing area of study domain making the developed model very sophisticated and difficult to use in other programs therefore this study proposes a new framework of training models for the study domain first a virtual mesh was generated fig 1b second the cells that contain water bodies were identified and used as sub domains third mggp models for each sub domain were trained and tested and finally the results for all sub domains were merged a major merit of this approach is that the developed model for each sub region can be quite simple and thus it can be easily integrated into another program another merit is that the training and testing processes can be performed simultaneously a total of 34 sub regions were defined the data points obtained by the hydraulic model were distributed into the corresponding sub region the input data points for each sub region were randomly distributed into two parts the training and testing regarded as unseen data points datasets the former dataset contained approximately 80 of the training data points and the latter dataset contained the remaining data points the mggp program developed 500 models in each generation within the evolutionary process the mean root mean square errors rmses and the standard deviations of these models for the sub region r1 are plotted against the number of generations in fig 7 a the mggp program first randomly generated some elements and thus the fitness at the early stage was low but it promptly reduced the mean rmses from about 0 9 m to about 0 2 m in about 20 generations after about 50 generations the change in fitness with generations became quite small and thus the model performance cannot be significantly improved by performing more evolutions the performance of the models quantified by the values of 1 r2 obtained in the final generation are plotted against the expressional complexity of the models in fig 7 b it can be seen from this trade off plot that the model performance generally increased with increasing complexity however the performance of some models can be further improved without increasing the efficiency and the efficiency of some models can be improved without sacrificing the accuracy these models are denoted using black dots and should not be adopted the other models correspond to the non dominated solutions in the pareto optimal multi objective optimization theory they are known as the pareto optimal models and are denoted using green dots these models located on the pareto front either have the best performance for the same complexity or have the least complexity for the same performance and thus any of these models can be regarded as the most suitable models depending on whether performance or simplicity is more important for the problem of interest a more complicated mggp model does not significantly increase the execution time so this study selected the most accurate mggp pareto optimal model as the best model circled in red in fig 7 the best mggp models for each sub region were identified and used to calculate the river depths as functions of discharge x and y coordinates the outputs were merged to provide the spatial distribution of river depth corresponding to different scenarios the merged results are presented in a way similar to those obtained by the hydraulic data fig 8 as can be seen the results reproduced by the mggp models were very close to those obtained by the numerical model demonstrating that the mggp models have a satisfactory ability of data generalization for spatial distribution of flow depth in a fluvial system to further quantify the performance of the mggp approach the mggp results and hydraulic results hereafter referred to as the actual results were compared in fig 9 the mbe mae rmse and r values are also indicated in the same plot the detailed performance indices for each sub region are listed in table 2 a one way anova analysis has also been performed in the analysis the null hypothesis was all means are equal the alternative hypothesis was at least one mean is different and the significance level was 0 05 the p values for the training and testing datasets were 0 233 and 0 546 respectively which were both greater than the significance level grouping information with the 95 confidence using the tukey method the fisher s least significant difference lsd method and the dunnett method showed that the datasets shared an identical letter therefore the mggp predictions for both the training and testing datasets were not found to be statistically different from the actual data the performance indices for the training and testing data sets were very close implying that the risk of data overfitting was well controlled using the current program settings some other aspects of model performance can also be observed from the data presented in fig 9 for example the maximum flow depths in the actual training and testing datasets were 10 14 m and 10 10 m and those in the predicted datasets were 10 15 m and 10 08 m respectively demonstrating that the technique can also perform well for the maximum flow depth 4 discussion a primary factor that limits the widespread usage of sophisticated hydraulic models in practical engineering projects is the heavy computational costs especially for large domain and real time purposes the outcomes obtained by the proposed approach were mggp based models which were very fast to run for example estimating the river depth at a location in the study area using the hydraulic model took about 53 min but estimating the same data using the mggp based model only took about 0 56 s therefore the proposed approach can significantly improve the efficiency of river depth estimations it should be acknowledged that the estimations produced by the proposed approach are not likely to be better than physics based hydraulic models especially when the machine learning based models are driven by the physically based results but it is still very beneficial because it can provide prompt results with comparable accuracies for example a total of six additional cases q1 425 m3 s q2 475 m3 s q3 525 m3 s q4 575 m3 s q5 625 m3 s q6 675 m3 s were considered with three of them having smaller flowrates than the base case q 554 5 m3 s while the other three cases had larger flowrates than the base case and the r values calculated by comparing the results from the hydraulic and mggp based model for r1 were 0 988 0 992 0 995 0 995 0 995 and 0 995 respectively these high r values imply that it is reasonable to employ the mggp based models as a substitution of hydraulic models to conduct predictions for new scenarios mggp based models trained using field data can be more accurate but detailed measurements of spatial distribution of flow depths in a large study area are difficult to obtain and thus the proposed method is more practical there are numerous different machine learning techniques that can be used for training models such as neural networks and rf approaches however the mggp technique is quite special among the machine learning techniques and advantageous in flow depth predictions because it can provide explicit mathematical expressions so the developed models can be easily used or integrated in other programs for example the best mggp based model for the sub region r1 is illustrated in fig 10 the weighting coefficients for genes 1 10 were 1 740 10 4 22 700 0 203 148 000 1 350 54 000 8 920 10 2 6 710 0 606 and 5 250 10 2 respectively and the bias was 127 000 the symbols x1 x2 and x3 represent the discharge x and y coordinates respectively the explicit formulation shown in fig 10 can be written as equation 14 although this expression includes some non linear terms the orders of these terms were low and they were linearly combined therefore the expressions can be easily copied to or re typed into another program and it is very easy to execute more details about the advantages and disadvantages of mggp over other machine learning techniques can be found elsewhere in the literature jamei et al 2020a 2020b mehr and nourani 2017 mehr and safari 2020 pandey et al 2015 safari and mehr 2018 14 y 22 7 cos log x 2 2 0 x 1 cos x 2 x 1 2 cos x 2 0 5 0 5 148 log cos x 2 x 2 0 0892 cos log x 1 x 1 cos x 2 2 cos cos x 2 0 0525 cos x 2 54 cos log x 1 cos 2 0 x 2 cos x 2 0 5 0 5 1 74 e 4 x 1 cos x 2 2 0 606 x 2 x 1 1 35 log x 1 cos x 1 x 2 cos x 2 3 log cos x 2 x 2 3 8 88 e 16 7 56 e 15 x 2 7 56 e 15 cos x 2 log cos x 2 x 2 3 7 56 e 15 log cos x 1 1 x 1 0 203 x 1 0 5 log sin 2 x 2 x 2 x 2 127 the proposed approach is also advantageous in terms of the requirements of computer storage for example the output file obtained by the hydraulic model for one scenario in this study was in a size of 36 079 kb for 12 different cases the total size was 432 948 kb therefore it can be deduced that storing hydraulic outputs for many different scenarios for a large study domain is not affordable in contrast the proposed approach is equivalent to converting the hydraulic outputs to equations with acceptable losses of accuracy because the efforts of obtaining results from the equations are negligible the total size of the equations stored in the matlab script file for the entire study domain was only about 46 kb and thus it significantly reduced the requirements of storage space as mentioned earlier mggp is a new advancement of the gp machine learning approach and an advantage of this approach is that it allows for multiple genes thus an mggp chromosome is generally more accurate than a traditional gp chromosome in this work the spatial distribution of flow depth in the study area has also been studied using the single gene genetic programing sggp approach which was identical to the mggp approach except that it only allows for a single gene for a chromosome fig 11 a shows the convergence history of the sggp evolutionary process for the sub region r1 the fitness for each generation shows that the mean rmse value dropped to a low level only in a few generations so it converged relatively fast however the rmse values were generally higher than those in the mggp evolutionary process indicating that the mggp models were more accurate than the sggp models fig 11 b presents the population in the last generation the 1 r 2 values were generally higher than those in the mggp population plot and the best model also had a higher value of 1 r 2 than that obtained by the mggp program table 3 listed the performance indices for the best mggp and sggp based models in each sub region which showed that the performance of mggp is superior to that of sggp therefore the results confirmed that the mggp technique developed better models than the sggp approach it is often useful to report the uncertainties of the models the uncertainties of the models can be quantified by using the prediction confidence analyses the analyses were conducted mainly using the nlpredci nonlinear regression prediction confidence intervals function available in matlab which is based on a symmetric confidence interval approach dolan et al 2007 lane and dumouchel 1994 seber and wild 1989 the function returns predictions and 95 confidence interval half widths for the nonlinear regression model at input values from the model coefficients residuals and jacobian matrix the results of nonlinear regression prediction confidence analysis for region r1 are shown in fig 12 as an example in this plot the data were re sorted from largest to smallest for display purposes the results for the other sub regions were close to these sample results in this study the computational downstream boundary condition was estimated based on the assumption that the flow at the downstream cross section was in the normal flow condition although this assumption is commonly used in practical engineering problems and the downstream cross section of the computational domain was located far from the actual downstream cross section of the area of interest this assumption may cause losses of accuracy of the hydraulic model in future work it is worthwhile to monitor the flow conditions at the downstream cross section and obtain a more accurate flow stage relationship from a hydraulic point of view it would be better to use the distances from boundaries or centerlines as mggp input variables because they have clearer physical meanings however the present study used the x and y coordinates instead first the current approach is consistent with most traditional hydrological practices such as estimating flow depths at certain hydrological stations with fixed x and y coordinates second the geographic features in the study area were believed to be stationary and thus the x y coordinates actually provide more or less the same spatial information as the distance values third using x and y coordinates as mggp input variables is more convenient and practical because they can be directly exported from numerical models whereas further calculations are required to obtain distance values the relation between coordinates and flood depth is highly nonlinear so it may be easier for mggp to extract information if distances from boundaries or centerlines were used as input features however the current configurations were believed satisfactory because the models were automatically developed by the program and the developed models can provide predictions in just a few seconds a model trained based on one river section should be used with caution for other sections especially when the differences between the river sections are significant it is not possible in the near future to obtain a generally valid data driven model due to the large amount of data required so it is practical to combine hydraulic and mggp modeling techniques to obtain locally valid models however it would be interesting for future studies to continuously improve the generalization of the model by considering more cases in the training processes it is a common practice to use single roughness values for a small segment and calibrate numerical models by adjusting the values but it should be noted that this is a limitation of the study the reliability and the accuracy of the hydraulic model can be further improved if possible by using spatially distributed roughness values obtained from field investigations declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was partially funded by the natural sciences and engineering research council of canada nserc discovery grants the first author xiaohui yan is supported by the fundamental research funds for the central universities china dut20rc 3 096 the field data were collected by dr ivana vouk we would like thank the editor in chief the anonymous associate editor and the four reviewers for their careful reading of our manuscript and their insightful comments and suggestions 
4364,ecosystem water and carbon fluxes are inherently coupled through stomata a deep understanding of the water carbon relationship contributes to model development water and carbon management and decision making this study investigated the pattern of the water carbon relationship the difference in water carbon relationship at both the ecosystem and canopy scales in different growth stages in a vineyard in arid northwest china for three consecutive years 2017 2019 via an eddy covariance system combined with sap flow sensors and microlysimeters the results showed that the significant increase in soil evaporation e controlled by high surface soil water content swc 10 cm led to a transformation from a linear to nonlinear relationship between daily water and carbon fluxes from the canopy to ecosystem scale moreover the water carbon relationship varied with growth stages at both the ecosystem and canopy scales the water carbon coupling strength the determination coefficient of the water carbon correlation was higher in the early and late growing seasons than in the middle growing season additionally water use efficiency wue was more dependent on the carbon flux in the early and late growing seasons however wue was mainly determined by water flux in the middle growing season and the control of e surpassed that of transpiration t in ecosystem wue the results of the structural equation model sem indicated that canopy development in the early and late growing seasons together with the water and radiation conditions in the middle growing season played vital roles in controlling the water carbon relationship this study highlighted the critical role of swc in controlling the water carbon relationship and the differences in the coupling in various growth stages of an irrigated vineyard in the arid northwest china keywords gross primary productivity transpiration soil water content sem water use efficiency water and carbon fluxes 1 introduction the arid region of northwest china has abundant light and heat resources that are suitable for economic plants to grow however this area is confronted with severe water shortages and environmental degradation as a result of the limited water resources and certain anthropogenic activities this area suffers severe vegetation loss soil salinity and desertification which impede sustainable agricultural development in the region kang et al 2004 investigations related to the interaction and feedback among ecosystem processes are urgently needed which is of great importance in achieving a balance among food production water resource usage and ecosystem services kang et al 2017 during the past decade the area of vineyards has increased extensively in the northwest china which reached 218 4 thousand hectares and accounted for 31 of the total area of vineyards in china in 2017 the yield of vineyards in this region obtained 16 8 ton per hectare and the total yield of vineyard in northwest china took a proportion of 28 of the total yield of vineyard in china in 2017 china agriculture statistical report 2017 additionally the vineyard is a representation of the sparse ecosystem and its water consumption is characteristic of a relatively high ratio of soil evaporation to evapotranspiration compared with other ecosystems with dense canopies kool et al 2014a zhao et al 2018 water and carbon fluxes are two fundamental biogeophysical components law et al 2002 photosynthesis and transpiration as important components of water and carbon fluxes are both regulated and closely related through gas diffusion via plant stomata jarvis 1976 cowan and farquhar 1977 ball et al 1987 therefore water and carbon fluxes are inherently coupled at various scales from leaf to the ecosystem level law et al 2002 waring and running 2007 a deep understanding of the water carbon relationship and its evolution contributes to management and decision making efforts concerning food production and water resources sun et al 2019 previous studies have shown that gross ecosystem productivity and transpiration are linearly correlated at the canopy scale huang et al 2010 niu et al 2011 wang et al 2017 however at the ecosystem scale results are varied some studies indicated that gross primary productivity and evapotranspiration showed linear correlations baldocchi 1994 law et al 2002 beer et al 2009 niu et al 2011 singh et al 2014 ma et al 2019 nevertheless wang et al 2017 found that the correlation between gross ecosystem productivity and evapotranspiration were weak which was ascribed to the high ratio of soil evaporation to evapotranspiration in the early growing season of paddy rice some studies indicated that ecosystem water and carbon fluxes showed nonlinear relationships in which gross primary productivity demonstrated a saturating and decreasing trend when evapotranspiration increased to a certain level and it was presumed to be caused by the stomatal control yu et al 2008 shen et al 2013 zhang et al 2013 previous studies concerning water carbon coupling have mainly dealt with annual and the whole growing season scales yet few studies have focused on its dynamics during a year or the growing season to the best of our knowledge only one study in a subtropical pine ecosystem indicated that environmental factors and phenology affected the correlation coefficients between water and carbon fluxes during the whole year singh et al 2014 investigation of the dynamics of the water carbon coupling strength the determination coefficient of the water carbon correlation during the whole growing season or a year may reduce uncertainty of the process based ecosystem model simulation and improve water carbon management therefore it is necessary to investigate whether the strength of water carbon coupling changes during a whole growing season or a year and if so identify the underlying reasons water use efficiency wue as the ratio of carbon assimilation and water consumption is one of the critical values in plant production irrigation scheduling and ecosystem function evaluation and it quantifies the water carbon coupling as well some previous studies indicated that compared with water flux carbon flux played a more important function in wue zhang et al 2017 wang et al 2018a li et al 2019 nonetheless are there any differences in the roles played by water and carbon fluxes in wue in different growing seasons furthermore is there any relationship between the roles played by water and carbon fluxes in wue and the coupling strength between water and carbon fluxes based on these questions 1 investigate the pattern of the water carbon relationship linear or nonlinear 2 analyze the water carbon relationships with growing seasons 2 materials and methods 2 1 study site the experimental site is located in an arid region in the northwest china 37 51 n 102 53 e 1585 m a s l with a temperate continental climate the mean annual rainfall is 165 7 mm which is concentrated in summer and autumn approximately 86 of the total annual rainfall water resources report of gansu province 2019 the mean annual air temperature is 8 c with an annual total sunshine duration of 2904 h the region experiences an extreme shortage of water resources with a groundwater depth of 27 9 m below the ground surface in february in 2021 china monthly groundwater dynamics report 2021 02 and a mean annual pan evaporation of 1926 mm the experiment was conducted at shiyanghe experimental station of china agricultural university wuwei gansu province the area of the pinot noir vitis vinifera l cultivar pinot noir vineyard is approximately 400 ha and the vines were planted in 2014 with no cover crops root depth of the vines reached approximately 1 6 m the row direction is north south with row spacing and plant spacing of 3 3 m and 0 5 m respectively a single cordon and a vertical trellis system were applied with vine shoots positioned on three iron wires 0 4 0 7 and 1 0 m in height the soil texture is dominated by clay loam with an average bulk density of 1 67 g cm 3 and saturated soil water content of 0 38 cm3 cm 3 in 0 1 m drip irrigation was used with drip lines suspended 40 cm above the ground surface a discharge rate of 3 l h 1 from the emitters and an emitter spacing of 40 cm seasonal total irrigation of 2017 2019 were shown in table 1 2 2 experimental measurements the general principle of eddy covariance measurements is the covariance between the concentration of interest and vertical wind speed burba 2013 a set of water carbon and energy fluxes of the vineyard were measured via the eddy covariance ec system the instruments were mounted at 4 m above the ground and met the requirement that the ratio of the length of the fetch to the mounting height was higher than 100 1 the dominant wind direction was northwest and the instruments were mounted to the southeast of the vineyard the ec system consisted of a csat3 three dimensional ultrasonic anemometer campbell scientific inc usa a li 7500 open path gas analyzer li cor inc usa an nr lite net radiometer kipp zonen delft netherlands hfp01 soil heat flux plates hukseflux netherlands and a cr5000 datalogger campbell scientific inc usa latent sensible heat fluxes le h and co2 flux were obtained by measuring wind speed ultrasonic virtual temperature via the csat3 anemometer and densities of water and co2 via the li 7500 gas analyzer in 10 hz five soil heat flux plates were deployed at an 8 cm soil depth at 5 points across the interrow all of the above sensors were connected to the cr5000 datalogger and 30 min averages of the measured variables were recorded the daily soil evaporation e was measured by pvc tubes with an inner diameter of 10 cm and a height of 20 cm thirty microlysimeters were installed at 5 locations across the interrow with 6 replicates each along the drip line the daily evaporation of the microlysimeters was obtained by weighing them at 19 00 local time every day with an electronic scale the average evaporation of all microlysimeters was taken as the e of the vineyard trambouze et al 1998 yunusa et al 2004 kool et al 2014b zhao et al 2015 eight vines were randomly selected around the eddy covariance system to monitor the sap flow by a sap flow system flow 32 1 k system dynamax houston tx usa the sensors were connected with a cr1000 datalogger campbell scientific usa and an average flow rate of 15 min was output according to the average cover area of each vine the sap flow rate l d 1 of the vines was converted into the transpiration rate mm d 1 the average transpiration rate of the monitored vines was taken as the transpiration rate t of the vineyard heilman et al 1994 yunusa et al 2004 ech2o soil moisture sensors decagon devices inc usa were used to continuously monitor the surface water content swc fifteen sensors were deployed at 5 positions across the interrow with 3 replicates each along the drip line at 10 cm depth and connected to the em50 datalogger decagon devices inc usa which output the data every 10 min the average value of all sensors was taken as the surface swc the lai of the vineyard was measured by lai 2200c li cor bioscience inc lincoln usa every 5 7 days and the measurement suggestions for row crops were followed https www licor com env products leaf area lai 2200c applications html a 3 to obtain the variation in lai during the whole growth period data of the nonmeasured days between two adjacent measurements were linearly interpolated according to the method of allen et al 1998 the crop growth stages are divided into four stages i e the initial development mid and late stage and the mid season stage runs from effective full cover to the start of maturity based on the method of allen et al 1998 and the seasonal pattern of canopy development lai in this study the whole growing season was divided into the early growing season from the end of april to the end of june middle growing season from july to august with a relatively stable and high daily lai and late growing season september the middle growing season covered most of the reproductive growth stage including the berry expansion and ripening period for a more detailed description of the observations at the experimental site please refer to gao et al 2019 2 3 meteorological conditions meteorological variables such as air temperature ta relative humidity rh wind speed rainfall p solar radiation and photosynthetically active radiation par were continuously monitored by a standard automatic weather station hobo u30 onset computer corporation usa with an installation height of 2 m near the vineyard the daily average ta and par generally showed a unimodal curve throughout the growing season and peaked around mid july fig 1 a c j l the daily rh and vpd did not present any obvious seasonal dynamics yet when concentrated rainfall occurred rh increased and vpd decreased fig 1d i the seasonal averages of the above meteorological variables are listed in table 1 compared to the multiyear average rainfall of the region the seasonal total rainfall in 2017 was 20 2 lower that in 2018 was 14 4 higher and that in 2019 was similar table 1 2 4 data processing and calculation of wue the raw flux data were processed by eddypro 7 0 4 li cor inc lincoln ne usa in express mode and 30 min averages were output the data correction procedures included the planar fit coordination rotation correction paw et al 2000 finnigan et al 2003 30 min block averaging time lag compensation statistical tests vickers and mahrt 1997 wpl density correction webb et al 1980 correction for the ultrasonic virtual temperature van dijk et al 2004 spectral correction moncrieff et al 1997 2005 data quality control flags foken et al 2004 and footprint analysis kljun et al 2004 the processed eddypro data quality was marked as 0 maximum quality 1 and 2 minimum quality mauder and foken 2011 and the data marked as 0 and 1 were retained surface energy budget remains one of the most convincing ways to assess the quality of ec system measurements i e all of the key components add up to zero as required by conservation of energy burba 2013 thus energy balance closure ebr was calculated by establishing a linear relationship between turbulence flux h le and available energy rn g the difference between net radiation rn and soil heat flux g twine et al 2000 wilson et al 2002 after the linear regression using the filtered half hourly ec data processed by eddypro the slope of the regression equation in 2017 2019 was 0 75 0 77 and the determination coefficient r2 was 0 91 0 92 p 0 001 which fell within the common range of previous studies wilson et al 2002 ortega farias et al 2007 zhao et al 2015 according to the method of papale et al 2006 30 min net ecosystem exchange nee data processed by eddypro were successively corrected by storage correction spike detection and elimination of the data under weak turbulence low friction velocity u among them co2 storage flux was obtained from the data processed by eddypro the missing 30 min energy and carbon flux data le h nee caused by instrument problems power failure or data correction were interpolated through the reddyproc online interpolation program wutzler et al 2018 in which nee was divided into gross primary productivity gpp and ecosystem respiration reco according to reichstein et al 2005 where gpp reco nee was met in order to obtain the seasonal total and variation of e and t the missing daily e and t were interpolated as follows when merely either daily e or t was measured the missing daily t and e were calculated as t et e and e et t the regression equation of the sum of the measured e and t versus the ec measured et in the growth period of 2017 2019 was acceptable which could be regarded as cross validation of the measurement results of et e and t as shown in fig 2 when both daily e and t were unavailable e could be interpolated by the regression relationship among measured daily e and rn and swc raz yaseef et al 2010 and t et e zhao et al 2018 gao et al 2019 the average data coverage of daily e and t for the entire growing seasons of 2017 2019 was 99 6 and 92 5 respectively ecosystem wue is usually expressed at canopy and ecosystem levels the daily ecosystem wue wuee g c kg 1 h2o was defined as the ratio of gpp g c m 2 d 1 to evapotranspiration et kg h2o m 2 d 1 describing the amount of carbon assimilated per unit of water loss at the ecosystem scale hu et al 2008 tong et al 2009 2014 li et al 2015 xie et al 2016 wang et al 2017 2018b quan et al 2018 et was calculated by le le λet where λ was the latent heat of vaporization j kg 1 1 wuee gpp et the daily canopy wue wuec g c kg 1 h2o was defined as the ratio of gpp to t kg h2o m 2 d 1 indicating the amount of carbon gained per unit of plant transpiration hu et al 2008 wang et al 2017 quan et al 2018 the daily scale gpp et and t were calculated by the sums of the 30 min gpp et and 15 min t respectively 2 wuec gpp t 2 5 statistical analysis regression analysis was applied to examine the coupling between water and carbon fluxes and the significance level was tested a structural equation model sem a useful multivariate statistical model that integrated factor analysis path analysis and maximum likelihood estimation grace 2006 was performed to analyze the pathways affecting daily water carbon fluxes and wue through the biotic and abiotic factors the model in this study was constructed based on the methods of the previous studies wang et al 2018b 2019 fig 3 specifically ta par rh swc and lai can affect wue directly and the abiotic factors ta par rh and swc can also affect wue indirectly through their regulation on lai the standardized total effect of the biophysical variables could be acquired from sem and its significance test was obtained using a bootstrap method in the model bollen and stine 1990 which is a useful index to explain the water carbon relationship through the biophysical factors the ranking of the top three factors was determined by the occurrence frequency and order on daily water carbon fluxes and wue according to the standardized total effect 3 results 3 1 seasonal dynamics and relationships between daily water and carbon fluxes the daily average gpp net ecosystem productivity nep nee and reco showed similar unimodal patterns generally during the whole growing season and changed mildly during the middle growing season which was similar to that of the daily lai fig 4 a c compared with the seasonal dynamics of carbon fluxes daily et and t fluctuated more and daily e and swc varied nearly concurrently fig 1m o fig 4d f in the growing seasons of 2018 and 2019 daily wuee and wuec presented rough single peak changing patterns however in 2017 daily wuee and wuec showed relatively unobvious seasonal dynamics fig 4g i the seasonal average wuee and wuec during 2017 2019 were 1 21 0 02 g c kg 1 h2o and 2 30 0 25 g c kg 1 h2o respectively the seasonal total of water and carbon flux components during 2017 2019 are shown in table 1 from the perspective of the whole growing season during 2017 2019 daily gpp and t presented a strong positive linear correlation however daily gpp and et showed significant nonlinear relationship fig 5 i e when daily et was higher than approximately 4 mm d 1 daily gpp no longer increased and reached a plateau and then even started to decrease which weakened the coupling strength between gpp and et the underlying reason was examined by plotting colormaps using daily water and carbon components including e t nep and reco as the color scales which covaried with daily gpp and et fig 6 fig s1 in the colormap using e as the color scale when daily e was higher than approximately 2 1 mm d 1 daily gpp and et showed an obvious piecewise and transitional relationship fig 6 nonetheless the above relationship was not observed in the colormaps when using t nep or reco as the color scales however the daily t nep and reco varied nearly synchronously with the daily gpp and et presenting horizontal stratification fig s1 further analysis was performed by plotting the colormaps between daily gpp and et using the environmental and biotic factors as the color scales including daily swc ta par rh vpd and lai fig 7 fig s2 it is worth noting that in the colormap using swc as the color scale the relationship between daily gpp and et showed a piecewise and transitional phenomenon when daily swc was higher than approximately 0 16 cm3 cm 3 fig 7 which was very similar to that in fig 6 however a similar phenomenon could not be observed in the colormaps when using the other biotic or abiotic factors as the color scales fig s2 furthermore data points when daily et was higher than 4 mm d 1 were checked and the results showed that 30 4 occurred on the days of rainfall 60 9 occurred on 1 5 days after rainfall and 2 9 occurred on the day of irrigation and the day after irrigation this indicated that in the ecosystem with a sparse canopy on the day of and a few days after rainfall surface swc would derive a sharp increase in a short period of time and e increased rapidly under the effect of radiation e 34 28 swc 3 92 r2 0 59 p 0 001 which would lead to asynchronous variations in gpp and et under relatively high et 3 2 the water carbon relationships in different growth stages correlation between daily water and carbon fluxes in the early and late growing seasons was stronger than that in the middle growing season fig 8 moreover in the early and late growing seasons both daily wuee and wuec were more dependent on the carbon flux gpp fig 9 a b g h whereas in the middle growing season water flux et and t mainly determined daily wuee and wuec fig 9c d i j further analysis of the relationship between daily water carbon fluxes and daily wuee during the middle growing season showed that daily wuee was more dependent on e than t fig 9e f regarding the whole growing season both daily wuee and wuec were more dependent on the carbon flux gpp fig 10 3 3 the water carbon coupling explained by the biotic and abiotic factors to investigate the underlying reason for the difference in the water carbon coupling strength and roles played by water and carbon fluxes in wue in different growth stages sem was used to analyze the pathways affecting daily water carbon fluxes and wue during these stages fig 3 fig s3 the standardized total effect derived from the model showed that in the early and late growing seasons the top three factors controlling daily water carbon fluxes and wue were lai ta rh table 2 a and further lai was the top factor with the largest standardized total effect on daily gpp t wuee and wuec moreover sem results showed that during this growth stage rh and ta had a relatively strong significant and positive effect on lai p 0 001 fig s3a e thus it could be concluded that lai was the primary factor in water carbon coupling during the middle growing season the top three factors affecting daily water carbon fluxes and wue were par swc lai table 2b indicating that during this growth stage the control of lai on daily water carbon fluxes and wue decreased whereas that of par and swc increased notably only the increase in par caused a significant increase in lai p 0 001 fig s3f j additionally swc and par were the top two factors on daily gpp et and wuee in accordance with the standardized total effect in addition rainfall was concentrated during this season inducing a rapid increase in swc and e under favorable thermal conditions fig 1m o fig 4d f from the perspective of the whole growing season the top three factors affecting daily water carbon fluxes and wue were ta par lai rh table 2c among which ta par and rh exerted key influences on lai in different growth stages moreover humidity temperature and radiation conditions played key roles in canopy development and the dynamics of water carbon fluxes and wue during the whole growing season additionally our results presented an interesting phenomenon during the high water carbon coupling strength stage wue was mainly determined by carbon flux fig 8a c fig 9a b g h whereas during the low water carbon coupling strength stage the more significant role in wue shifted to the water flux fig 8b d fig 9c d i j the main reasons were that during the early and late growing seasons water and carbon fluxes were primarily determined by the biotic factor and varied towards a concurrent trend yet the amplitude of variation of the carbon flux was slightly larger than that of the water flux however in the middle growing season the control of the biotic factor on the water and carbon fluxes decreased and canopy development and the carbon flux varied mildly nevertheless e and t varied dramatically under irrigation and the constantly changing environment consequently the allometric variation in water and carbon fluxes weakened the water carbon coupling strength and led to the more critical role of water flux in wue 4 discussion 4 1 the nonlinear water carbon relationship induced by e at the ecosystem scale many previous studies have pointed out that ecosystem water and carbon fluxes are linearly correlated with different strengths baldocchi 1994 law et al 2002 beer et al 2009 huang et al 2010 niu et al 2011 singh et al 2014 ma et al 2019 yet a few studies have indicated that water and carbon fluxes show weak wang et al 2017 or nonlinear relationships at the ecosystem scale yu et al 2008 shen et al 2013 yu et al 2008 indicated that daily gpp and et presented a convex nonlinear relationship in subtropical forest ecosystems along a north south transect of eastern china and ascribed it to possible regulation of stomata as a result of seasonal drought which increased the leaf temperature accelerated photorespiration affected the electron transfer rate and thus reduced carbon assimilation and wue shen et al 2013 also found a similar phenomenon in which daily nee and et showed a convex parabolic relationship in a wheat ecosystem on the north china plain and attributed it to the increased t caused by the rising atmospheric demand which led to water stress in the plant leaves and a decrease in photosynthesis our study indicated that from the canopy scale to the ecosystem scale the relationship between water and carbon fluxes changed which transformed from a linear correlation to nonlinear relationship however unlike previous results the shift in this study was induced by the abiotic control of swc the increase of which increased e significantly and thus led to a faster increase in daily et than gpp under relatively high swc moreover the distinct sensitivity of water and carbon fluxes to relatively high swc caused the decrease in wuee this result demonstrated the critical role of swc in regulating the water carbon relationship in a sparse ecosystem it is possible to maintain a relatively high wuee under high swc if agronomic practices such as film mulch and cultivated cover crops in the interrow could be adopted meanwhile consideration of the key role of swc may decrease the uncertainty of ecosystem models 4 2 water carbon coupling strength varied with growth stages previous studies concerning ecosystem water carbon coupling were mainly performed in view of the whole growing season or the whole year singh et al 2014 indicated that the correlation coefficient between net photosynthesis assimilation and le varied in different growth stages in this regard the water carbon correlation coefficients of the season from spring to summer march to june and the late monsoon season october to november were higher than that of the monsoon season july to september which was similar to our results at the ecosystem scale the paper further indicated that the monsoon season was characterized by more cloudy conditions with relatively low vpd high soil water content and large stomatal conductance which might increase the inner leaf co2 concentration and consequently inhibited photosynthesis in addition the thin water film on the leaf enlarged the resistance to gas diffusion and might weaken the coupling between net photosynthesis assimilation and le during the monsoon season our study also found that the water carbon coupling strength differentiated in different growth stages and went a step further to confirm it at both the canopy and ecosystem scales in the early and late growing seasons the positive control of ta and rh on lai caused distinct variations in lai during this stage under the joint influence of biotic and abiotic factors the almost synchronous variation between gpp and et and between gpp and t as well as the primary control of canopy development and senescence induced a close water carbon coupling however in the middle growing season the lai varied mildly after reaching full development and led to a mildly changing carbon flux nonetheless water flux still fluctuated dramatically under favorable environmental conditions and irrigation and thus the synchronization of the dynamics of water and carbon fluxes was reduced according to beer et al 2009 at the leaf scale the difference between the variation of co2 assimilation al and transpiration tl is determined by that between ca ci the difference between ambient and inner leaf partial pressure of co2 and vpd under the assumption of equal temperatures of the leaves and the atmosphere and it was reported that ci ca was approximately constant when par was higher than a critical value tanner and sinclair 1983 therefore the relatively stable ca ci under the control of stomata and the dramatically fluctuating vpd during the middle growing season high vpd on dry warm days and low vpd on wet cold days probably induced the allometric dynamics of gpp and t and thus the weak coupling between them moreover concentrated rainfall occurred during this growing season and the strong positive control of swc on e also played a nonnegligible role in weakening the water carbon coupling strength at the ecosystem scale reason discussed in section 4 1 4 3 roles played by water and carbon fluxes in daily wue varied with growth stages previous studies concerning the roles played by water and carbon fluxes in daily wue mostly focused on the ecosystem and the whole growing season scale zhang et al 2017 wang et al 2018a li et al 2019 for instance wang et al 2018a concluded that compared with et gpp mainly determined the dynamics of wue gpp et through the analysis of 33 site year flux data in typical croplands soybean maize wheat and paddy rice in north america europe and asia li et al 2019 also indicated that nee rather than et played a much more important function in wue seasonal variability nee et in shrubland on the northeastern qinghai tibetan plateau the results of our study were similar to those of previous studies at the ecosystem level and further confirmed that this phenomenon existed at the canopy scale simultaneously from the perspective of the whole growing season notably our study found that the roles played by water and carbon fluxes in wue varied with growth stages in the early and late growing seasons gpp mainly determined the daily wuee and wuec implying a greater sensitivity of wue to carbon flux than to water flux however in the middle growing season daily wuee and wuec exhibited more sensitivity to water flux as a result daily wuee and wuec were much more dependent on water flux in particular the control of e exceeded that of t on daily wuee the above phenomenon also indicated the distinct response of the water and carbon fluxes to the biotic and abiotic factors in different growth stages our study was a strong indication that the water carbon coupling strength and roles played by water and carbon fluxes in wue varied with growth stages in an arid region especially the canopy development during the early and late growing seasons and the water and radiation conditions during the middle growing season played key roles in controlling the water carbon relationship 5 conclusions our study indicated that in ecosystems under sparse vegetation in the arid region the strong positive relationship between swc and e weakened the ecosystem water carbon coupling and induced a convex nonlinear relationship between daily gpp and et in addition the water carbon coupling strength and the roles played by water and carbon fluxes in daily wue varied with growth stages at both the canopy and ecosystem scales specifically the water carbon coupling strength was higher in the early and late growing seasons than in the middle growing season and carbon flux mainly determined wue in the early and late growing seasons whereas it changed to water flux in the middle growing season with e playing a more critical function than t in daily wuee the sem results showed that canopy development in the early and late growing seasons as well as the water and radiation conditions in the middle growing season played key roles in controlling the water carbon coupling this study highlighted the critical role of swc and e in controlling the water carbon relationship in ecosystems with sparse canopies in arid regions especially when precipitation or irrigation occurred moreover a deep understanding and full consideration of the distinct water carbon coupling strength and the roles played by water and carbon fluxes in wue in different growth stages could help improve the accuracy of process based ecosystem models our results also provide new references and evidence for a more profound understanding of the water carbon coupling further research could focus on the physiological explanation of the results at the leaf scale the applicability of the conclusion at other spatial scales and the improvement of the quantitative relationship between ecosystem wue and the factors credit authorship contribution statement lei gao data curation formal analysis investigation methodology writing original draft shaozhong kang conceptualization resources writing review editing funding acquisition supervision project administration xueer bai data curation writing review editing sien li writing review editing jun niu writing review editing risheng ding writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was financially and jointly supported by the national natural science foundation of china grant number 51790534 and the 111 program of introducing talents of discipline to universities grant number b14002 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126469 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4364,ecosystem water and carbon fluxes are inherently coupled through stomata a deep understanding of the water carbon relationship contributes to model development water and carbon management and decision making this study investigated the pattern of the water carbon relationship the difference in water carbon relationship at both the ecosystem and canopy scales in different growth stages in a vineyard in arid northwest china for three consecutive years 2017 2019 via an eddy covariance system combined with sap flow sensors and microlysimeters the results showed that the significant increase in soil evaporation e controlled by high surface soil water content swc 10 cm led to a transformation from a linear to nonlinear relationship between daily water and carbon fluxes from the canopy to ecosystem scale moreover the water carbon relationship varied with growth stages at both the ecosystem and canopy scales the water carbon coupling strength the determination coefficient of the water carbon correlation was higher in the early and late growing seasons than in the middle growing season additionally water use efficiency wue was more dependent on the carbon flux in the early and late growing seasons however wue was mainly determined by water flux in the middle growing season and the control of e surpassed that of transpiration t in ecosystem wue the results of the structural equation model sem indicated that canopy development in the early and late growing seasons together with the water and radiation conditions in the middle growing season played vital roles in controlling the water carbon relationship this study highlighted the critical role of swc in controlling the water carbon relationship and the differences in the coupling in various growth stages of an irrigated vineyard in the arid northwest china keywords gross primary productivity transpiration soil water content sem water use efficiency water and carbon fluxes 1 introduction the arid region of northwest china has abundant light and heat resources that are suitable for economic plants to grow however this area is confronted with severe water shortages and environmental degradation as a result of the limited water resources and certain anthropogenic activities this area suffers severe vegetation loss soil salinity and desertification which impede sustainable agricultural development in the region kang et al 2004 investigations related to the interaction and feedback among ecosystem processes are urgently needed which is of great importance in achieving a balance among food production water resource usage and ecosystem services kang et al 2017 during the past decade the area of vineyards has increased extensively in the northwest china which reached 218 4 thousand hectares and accounted for 31 of the total area of vineyards in china in 2017 the yield of vineyards in this region obtained 16 8 ton per hectare and the total yield of vineyard in northwest china took a proportion of 28 of the total yield of vineyard in china in 2017 china agriculture statistical report 2017 additionally the vineyard is a representation of the sparse ecosystem and its water consumption is characteristic of a relatively high ratio of soil evaporation to evapotranspiration compared with other ecosystems with dense canopies kool et al 2014a zhao et al 2018 water and carbon fluxes are two fundamental biogeophysical components law et al 2002 photosynthesis and transpiration as important components of water and carbon fluxes are both regulated and closely related through gas diffusion via plant stomata jarvis 1976 cowan and farquhar 1977 ball et al 1987 therefore water and carbon fluxes are inherently coupled at various scales from leaf to the ecosystem level law et al 2002 waring and running 2007 a deep understanding of the water carbon relationship and its evolution contributes to management and decision making efforts concerning food production and water resources sun et al 2019 previous studies have shown that gross ecosystem productivity and transpiration are linearly correlated at the canopy scale huang et al 2010 niu et al 2011 wang et al 2017 however at the ecosystem scale results are varied some studies indicated that gross primary productivity and evapotranspiration showed linear correlations baldocchi 1994 law et al 2002 beer et al 2009 niu et al 2011 singh et al 2014 ma et al 2019 nevertheless wang et al 2017 found that the correlation between gross ecosystem productivity and evapotranspiration were weak which was ascribed to the high ratio of soil evaporation to evapotranspiration in the early growing season of paddy rice some studies indicated that ecosystem water and carbon fluxes showed nonlinear relationships in which gross primary productivity demonstrated a saturating and decreasing trend when evapotranspiration increased to a certain level and it was presumed to be caused by the stomatal control yu et al 2008 shen et al 2013 zhang et al 2013 previous studies concerning water carbon coupling have mainly dealt with annual and the whole growing season scales yet few studies have focused on its dynamics during a year or the growing season to the best of our knowledge only one study in a subtropical pine ecosystem indicated that environmental factors and phenology affected the correlation coefficients between water and carbon fluxes during the whole year singh et al 2014 investigation of the dynamics of the water carbon coupling strength the determination coefficient of the water carbon correlation during the whole growing season or a year may reduce uncertainty of the process based ecosystem model simulation and improve water carbon management therefore it is necessary to investigate whether the strength of water carbon coupling changes during a whole growing season or a year and if so identify the underlying reasons water use efficiency wue as the ratio of carbon assimilation and water consumption is one of the critical values in plant production irrigation scheduling and ecosystem function evaluation and it quantifies the water carbon coupling as well some previous studies indicated that compared with water flux carbon flux played a more important function in wue zhang et al 2017 wang et al 2018a li et al 2019 nonetheless are there any differences in the roles played by water and carbon fluxes in wue in different growing seasons furthermore is there any relationship between the roles played by water and carbon fluxes in wue and the coupling strength between water and carbon fluxes based on these questions 1 investigate the pattern of the water carbon relationship linear or nonlinear 2 analyze the water carbon relationships with growing seasons 2 materials and methods 2 1 study site the experimental site is located in an arid region in the northwest china 37 51 n 102 53 e 1585 m a s l with a temperate continental climate the mean annual rainfall is 165 7 mm which is concentrated in summer and autumn approximately 86 of the total annual rainfall water resources report of gansu province 2019 the mean annual air temperature is 8 c with an annual total sunshine duration of 2904 h the region experiences an extreme shortage of water resources with a groundwater depth of 27 9 m below the ground surface in february in 2021 china monthly groundwater dynamics report 2021 02 and a mean annual pan evaporation of 1926 mm the experiment was conducted at shiyanghe experimental station of china agricultural university wuwei gansu province the area of the pinot noir vitis vinifera l cultivar pinot noir vineyard is approximately 400 ha and the vines were planted in 2014 with no cover crops root depth of the vines reached approximately 1 6 m the row direction is north south with row spacing and plant spacing of 3 3 m and 0 5 m respectively a single cordon and a vertical trellis system were applied with vine shoots positioned on three iron wires 0 4 0 7 and 1 0 m in height the soil texture is dominated by clay loam with an average bulk density of 1 67 g cm 3 and saturated soil water content of 0 38 cm3 cm 3 in 0 1 m drip irrigation was used with drip lines suspended 40 cm above the ground surface a discharge rate of 3 l h 1 from the emitters and an emitter spacing of 40 cm seasonal total irrigation of 2017 2019 were shown in table 1 2 2 experimental measurements the general principle of eddy covariance measurements is the covariance between the concentration of interest and vertical wind speed burba 2013 a set of water carbon and energy fluxes of the vineyard were measured via the eddy covariance ec system the instruments were mounted at 4 m above the ground and met the requirement that the ratio of the length of the fetch to the mounting height was higher than 100 1 the dominant wind direction was northwest and the instruments were mounted to the southeast of the vineyard the ec system consisted of a csat3 three dimensional ultrasonic anemometer campbell scientific inc usa a li 7500 open path gas analyzer li cor inc usa an nr lite net radiometer kipp zonen delft netherlands hfp01 soil heat flux plates hukseflux netherlands and a cr5000 datalogger campbell scientific inc usa latent sensible heat fluxes le h and co2 flux were obtained by measuring wind speed ultrasonic virtual temperature via the csat3 anemometer and densities of water and co2 via the li 7500 gas analyzer in 10 hz five soil heat flux plates were deployed at an 8 cm soil depth at 5 points across the interrow all of the above sensors were connected to the cr5000 datalogger and 30 min averages of the measured variables were recorded the daily soil evaporation e was measured by pvc tubes with an inner diameter of 10 cm and a height of 20 cm thirty microlysimeters were installed at 5 locations across the interrow with 6 replicates each along the drip line the daily evaporation of the microlysimeters was obtained by weighing them at 19 00 local time every day with an electronic scale the average evaporation of all microlysimeters was taken as the e of the vineyard trambouze et al 1998 yunusa et al 2004 kool et al 2014b zhao et al 2015 eight vines were randomly selected around the eddy covariance system to monitor the sap flow by a sap flow system flow 32 1 k system dynamax houston tx usa the sensors were connected with a cr1000 datalogger campbell scientific usa and an average flow rate of 15 min was output according to the average cover area of each vine the sap flow rate l d 1 of the vines was converted into the transpiration rate mm d 1 the average transpiration rate of the monitored vines was taken as the transpiration rate t of the vineyard heilman et al 1994 yunusa et al 2004 ech2o soil moisture sensors decagon devices inc usa were used to continuously monitor the surface water content swc fifteen sensors were deployed at 5 positions across the interrow with 3 replicates each along the drip line at 10 cm depth and connected to the em50 datalogger decagon devices inc usa which output the data every 10 min the average value of all sensors was taken as the surface swc the lai of the vineyard was measured by lai 2200c li cor bioscience inc lincoln usa every 5 7 days and the measurement suggestions for row crops were followed https www licor com env products leaf area lai 2200c applications html a 3 to obtain the variation in lai during the whole growth period data of the nonmeasured days between two adjacent measurements were linearly interpolated according to the method of allen et al 1998 the crop growth stages are divided into four stages i e the initial development mid and late stage and the mid season stage runs from effective full cover to the start of maturity based on the method of allen et al 1998 and the seasonal pattern of canopy development lai in this study the whole growing season was divided into the early growing season from the end of april to the end of june middle growing season from july to august with a relatively stable and high daily lai and late growing season september the middle growing season covered most of the reproductive growth stage including the berry expansion and ripening period for a more detailed description of the observations at the experimental site please refer to gao et al 2019 2 3 meteorological conditions meteorological variables such as air temperature ta relative humidity rh wind speed rainfall p solar radiation and photosynthetically active radiation par were continuously monitored by a standard automatic weather station hobo u30 onset computer corporation usa with an installation height of 2 m near the vineyard the daily average ta and par generally showed a unimodal curve throughout the growing season and peaked around mid july fig 1 a c j l the daily rh and vpd did not present any obvious seasonal dynamics yet when concentrated rainfall occurred rh increased and vpd decreased fig 1d i the seasonal averages of the above meteorological variables are listed in table 1 compared to the multiyear average rainfall of the region the seasonal total rainfall in 2017 was 20 2 lower that in 2018 was 14 4 higher and that in 2019 was similar table 1 2 4 data processing and calculation of wue the raw flux data were processed by eddypro 7 0 4 li cor inc lincoln ne usa in express mode and 30 min averages were output the data correction procedures included the planar fit coordination rotation correction paw et al 2000 finnigan et al 2003 30 min block averaging time lag compensation statistical tests vickers and mahrt 1997 wpl density correction webb et al 1980 correction for the ultrasonic virtual temperature van dijk et al 2004 spectral correction moncrieff et al 1997 2005 data quality control flags foken et al 2004 and footprint analysis kljun et al 2004 the processed eddypro data quality was marked as 0 maximum quality 1 and 2 minimum quality mauder and foken 2011 and the data marked as 0 and 1 were retained surface energy budget remains one of the most convincing ways to assess the quality of ec system measurements i e all of the key components add up to zero as required by conservation of energy burba 2013 thus energy balance closure ebr was calculated by establishing a linear relationship between turbulence flux h le and available energy rn g the difference between net radiation rn and soil heat flux g twine et al 2000 wilson et al 2002 after the linear regression using the filtered half hourly ec data processed by eddypro the slope of the regression equation in 2017 2019 was 0 75 0 77 and the determination coefficient r2 was 0 91 0 92 p 0 001 which fell within the common range of previous studies wilson et al 2002 ortega farias et al 2007 zhao et al 2015 according to the method of papale et al 2006 30 min net ecosystem exchange nee data processed by eddypro were successively corrected by storage correction spike detection and elimination of the data under weak turbulence low friction velocity u among them co2 storage flux was obtained from the data processed by eddypro the missing 30 min energy and carbon flux data le h nee caused by instrument problems power failure or data correction were interpolated through the reddyproc online interpolation program wutzler et al 2018 in which nee was divided into gross primary productivity gpp and ecosystem respiration reco according to reichstein et al 2005 where gpp reco nee was met in order to obtain the seasonal total and variation of e and t the missing daily e and t were interpolated as follows when merely either daily e or t was measured the missing daily t and e were calculated as t et e and e et t the regression equation of the sum of the measured e and t versus the ec measured et in the growth period of 2017 2019 was acceptable which could be regarded as cross validation of the measurement results of et e and t as shown in fig 2 when both daily e and t were unavailable e could be interpolated by the regression relationship among measured daily e and rn and swc raz yaseef et al 2010 and t et e zhao et al 2018 gao et al 2019 the average data coverage of daily e and t for the entire growing seasons of 2017 2019 was 99 6 and 92 5 respectively ecosystem wue is usually expressed at canopy and ecosystem levels the daily ecosystem wue wuee g c kg 1 h2o was defined as the ratio of gpp g c m 2 d 1 to evapotranspiration et kg h2o m 2 d 1 describing the amount of carbon assimilated per unit of water loss at the ecosystem scale hu et al 2008 tong et al 2009 2014 li et al 2015 xie et al 2016 wang et al 2017 2018b quan et al 2018 et was calculated by le le λet where λ was the latent heat of vaporization j kg 1 1 wuee gpp et the daily canopy wue wuec g c kg 1 h2o was defined as the ratio of gpp to t kg h2o m 2 d 1 indicating the amount of carbon gained per unit of plant transpiration hu et al 2008 wang et al 2017 quan et al 2018 the daily scale gpp et and t were calculated by the sums of the 30 min gpp et and 15 min t respectively 2 wuec gpp t 2 5 statistical analysis regression analysis was applied to examine the coupling between water and carbon fluxes and the significance level was tested a structural equation model sem a useful multivariate statistical model that integrated factor analysis path analysis and maximum likelihood estimation grace 2006 was performed to analyze the pathways affecting daily water carbon fluxes and wue through the biotic and abiotic factors the model in this study was constructed based on the methods of the previous studies wang et al 2018b 2019 fig 3 specifically ta par rh swc and lai can affect wue directly and the abiotic factors ta par rh and swc can also affect wue indirectly through their regulation on lai the standardized total effect of the biophysical variables could be acquired from sem and its significance test was obtained using a bootstrap method in the model bollen and stine 1990 which is a useful index to explain the water carbon relationship through the biophysical factors the ranking of the top three factors was determined by the occurrence frequency and order on daily water carbon fluxes and wue according to the standardized total effect 3 results 3 1 seasonal dynamics and relationships between daily water and carbon fluxes the daily average gpp net ecosystem productivity nep nee and reco showed similar unimodal patterns generally during the whole growing season and changed mildly during the middle growing season which was similar to that of the daily lai fig 4 a c compared with the seasonal dynamics of carbon fluxes daily et and t fluctuated more and daily e and swc varied nearly concurrently fig 1m o fig 4d f in the growing seasons of 2018 and 2019 daily wuee and wuec presented rough single peak changing patterns however in 2017 daily wuee and wuec showed relatively unobvious seasonal dynamics fig 4g i the seasonal average wuee and wuec during 2017 2019 were 1 21 0 02 g c kg 1 h2o and 2 30 0 25 g c kg 1 h2o respectively the seasonal total of water and carbon flux components during 2017 2019 are shown in table 1 from the perspective of the whole growing season during 2017 2019 daily gpp and t presented a strong positive linear correlation however daily gpp and et showed significant nonlinear relationship fig 5 i e when daily et was higher than approximately 4 mm d 1 daily gpp no longer increased and reached a plateau and then even started to decrease which weakened the coupling strength between gpp and et the underlying reason was examined by plotting colormaps using daily water and carbon components including e t nep and reco as the color scales which covaried with daily gpp and et fig 6 fig s1 in the colormap using e as the color scale when daily e was higher than approximately 2 1 mm d 1 daily gpp and et showed an obvious piecewise and transitional relationship fig 6 nonetheless the above relationship was not observed in the colormaps when using t nep or reco as the color scales however the daily t nep and reco varied nearly synchronously with the daily gpp and et presenting horizontal stratification fig s1 further analysis was performed by plotting the colormaps between daily gpp and et using the environmental and biotic factors as the color scales including daily swc ta par rh vpd and lai fig 7 fig s2 it is worth noting that in the colormap using swc as the color scale the relationship between daily gpp and et showed a piecewise and transitional phenomenon when daily swc was higher than approximately 0 16 cm3 cm 3 fig 7 which was very similar to that in fig 6 however a similar phenomenon could not be observed in the colormaps when using the other biotic or abiotic factors as the color scales fig s2 furthermore data points when daily et was higher than 4 mm d 1 were checked and the results showed that 30 4 occurred on the days of rainfall 60 9 occurred on 1 5 days after rainfall and 2 9 occurred on the day of irrigation and the day after irrigation this indicated that in the ecosystem with a sparse canopy on the day of and a few days after rainfall surface swc would derive a sharp increase in a short period of time and e increased rapidly under the effect of radiation e 34 28 swc 3 92 r2 0 59 p 0 001 which would lead to asynchronous variations in gpp and et under relatively high et 3 2 the water carbon relationships in different growth stages correlation between daily water and carbon fluxes in the early and late growing seasons was stronger than that in the middle growing season fig 8 moreover in the early and late growing seasons both daily wuee and wuec were more dependent on the carbon flux gpp fig 9 a b g h whereas in the middle growing season water flux et and t mainly determined daily wuee and wuec fig 9c d i j further analysis of the relationship between daily water carbon fluxes and daily wuee during the middle growing season showed that daily wuee was more dependent on e than t fig 9e f regarding the whole growing season both daily wuee and wuec were more dependent on the carbon flux gpp fig 10 3 3 the water carbon coupling explained by the biotic and abiotic factors to investigate the underlying reason for the difference in the water carbon coupling strength and roles played by water and carbon fluxes in wue in different growth stages sem was used to analyze the pathways affecting daily water carbon fluxes and wue during these stages fig 3 fig s3 the standardized total effect derived from the model showed that in the early and late growing seasons the top three factors controlling daily water carbon fluxes and wue were lai ta rh table 2 a and further lai was the top factor with the largest standardized total effect on daily gpp t wuee and wuec moreover sem results showed that during this growth stage rh and ta had a relatively strong significant and positive effect on lai p 0 001 fig s3a e thus it could be concluded that lai was the primary factor in water carbon coupling during the middle growing season the top three factors affecting daily water carbon fluxes and wue were par swc lai table 2b indicating that during this growth stage the control of lai on daily water carbon fluxes and wue decreased whereas that of par and swc increased notably only the increase in par caused a significant increase in lai p 0 001 fig s3f j additionally swc and par were the top two factors on daily gpp et and wuee in accordance with the standardized total effect in addition rainfall was concentrated during this season inducing a rapid increase in swc and e under favorable thermal conditions fig 1m o fig 4d f from the perspective of the whole growing season the top three factors affecting daily water carbon fluxes and wue were ta par lai rh table 2c among which ta par and rh exerted key influences on lai in different growth stages moreover humidity temperature and radiation conditions played key roles in canopy development and the dynamics of water carbon fluxes and wue during the whole growing season additionally our results presented an interesting phenomenon during the high water carbon coupling strength stage wue was mainly determined by carbon flux fig 8a c fig 9a b g h whereas during the low water carbon coupling strength stage the more significant role in wue shifted to the water flux fig 8b d fig 9c d i j the main reasons were that during the early and late growing seasons water and carbon fluxes were primarily determined by the biotic factor and varied towards a concurrent trend yet the amplitude of variation of the carbon flux was slightly larger than that of the water flux however in the middle growing season the control of the biotic factor on the water and carbon fluxes decreased and canopy development and the carbon flux varied mildly nevertheless e and t varied dramatically under irrigation and the constantly changing environment consequently the allometric variation in water and carbon fluxes weakened the water carbon coupling strength and led to the more critical role of water flux in wue 4 discussion 4 1 the nonlinear water carbon relationship induced by e at the ecosystem scale many previous studies have pointed out that ecosystem water and carbon fluxes are linearly correlated with different strengths baldocchi 1994 law et al 2002 beer et al 2009 huang et al 2010 niu et al 2011 singh et al 2014 ma et al 2019 yet a few studies have indicated that water and carbon fluxes show weak wang et al 2017 or nonlinear relationships at the ecosystem scale yu et al 2008 shen et al 2013 yu et al 2008 indicated that daily gpp and et presented a convex nonlinear relationship in subtropical forest ecosystems along a north south transect of eastern china and ascribed it to possible regulation of stomata as a result of seasonal drought which increased the leaf temperature accelerated photorespiration affected the electron transfer rate and thus reduced carbon assimilation and wue shen et al 2013 also found a similar phenomenon in which daily nee and et showed a convex parabolic relationship in a wheat ecosystem on the north china plain and attributed it to the increased t caused by the rising atmospheric demand which led to water stress in the plant leaves and a decrease in photosynthesis our study indicated that from the canopy scale to the ecosystem scale the relationship between water and carbon fluxes changed which transformed from a linear correlation to nonlinear relationship however unlike previous results the shift in this study was induced by the abiotic control of swc the increase of which increased e significantly and thus led to a faster increase in daily et than gpp under relatively high swc moreover the distinct sensitivity of water and carbon fluxes to relatively high swc caused the decrease in wuee this result demonstrated the critical role of swc in regulating the water carbon relationship in a sparse ecosystem it is possible to maintain a relatively high wuee under high swc if agronomic practices such as film mulch and cultivated cover crops in the interrow could be adopted meanwhile consideration of the key role of swc may decrease the uncertainty of ecosystem models 4 2 water carbon coupling strength varied with growth stages previous studies concerning ecosystem water carbon coupling were mainly performed in view of the whole growing season or the whole year singh et al 2014 indicated that the correlation coefficient between net photosynthesis assimilation and le varied in different growth stages in this regard the water carbon correlation coefficients of the season from spring to summer march to june and the late monsoon season october to november were higher than that of the monsoon season july to september which was similar to our results at the ecosystem scale the paper further indicated that the monsoon season was characterized by more cloudy conditions with relatively low vpd high soil water content and large stomatal conductance which might increase the inner leaf co2 concentration and consequently inhibited photosynthesis in addition the thin water film on the leaf enlarged the resistance to gas diffusion and might weaken the coupling between net photosynthesis assimilation and le during the monsoon season our study also found that the water carbon coupling strength differentiated in different growth stages and went a step further to confirm it at both the canopy and ecosystem scales in the early and late growing seasons the positive control of ta and rh on lai caused distinct variations in lai during this stage under the joint influence of biotic and abiotic factors the almost synchronous variation between gpp and et and between gpp and t as well as the primary control of canopy development and senescence induced a close water carbon coupling however in the middle growing season the lai varied mildly after reaching full development and led to a mildly changing carbon flux nonetheless water flux still fluctuated dramatically under favorable environmental conditions and irrigation and thus the synchronization of the dynamics of water and carbon fluxes was reduced according to beer et al 2009 at the leaf scale the difference between the variation of co2 assimilation al and transpiration tl is determined by that between ca ci the difference between ambient and inner leaf partial pressure of co2 and vpd under the assumption of equal temperatures of the leaves and the atmosphere and it was reported that ci ca was approximately constant when par was higher than a critical value tanner and sinclair 1983 therefore the relatively stable ca ci under the control of stomata and the dramatically fluctuating vpd during the middle growing season high vpd on dry warm days and low vpd on wet cold days probably induced the allometric dynamics of gpp and t and thus the weak coupling between them moreover concentrated rainfall occurred during this growing season and the strong positive control of swc on e also played a nonnegligible role in weakening the water carbon coupling strength at the ecosystem scale reason discussed in section 4 1 4 3 roles played by water and carbon fluxes in daily wue varied with growth stages previous studies concerning the roles played by water and carbon fluxes in daily wue mostly focused on the ecosystem and the whole growing season scale zhang et al 2017 wang et al 2018a li et al 2019 for instance wang et al 2018a concluded that compared with et gpp mainly determined the dynamics of wue gpp et through the analysis of 33 site year flux data in typical croplands soybean maize wheat and paddy rice in north america europe and asia li et al 2019 also indicated that nee rather than et played a much more important function in wue seasonal variability nee et in shrubland on the northeastern qinghai tibetan plateau the results of our study were similar to those of previous studies at the ecosystem level and further confirmed that this phenomenon existed at the canopy scale simultaneously from the perspective of the whole growing season notably our study found that the roles played by water and carbon fluxes in wue varied with growth stages in the early and late growing seasons gpp mainly determined the daily wuee and wuec implying a greater sensitivity of wue to carbon flux than to water flux however in the middle growing season daily wuee and wuec exhibited more sensitivity to water flux as a result daily wuee and wuec were much more dependent on water flux in particular the control of e exceeded that of t on daily wuee the above phenomenon also indicated the distinct response of the water and carbon fluxes to the biotic and abiotic factors in different growth stages our study was a strong indication that the water carbon coupling strength and roles played by water and carbon fluxes in wue varied with growth stages in an arid region especially the canopy development during the early and late growing seasons and the water and radiation conditions during the middle growing season played key roles in controlling the water carbon relationship 5 conclusions our study indicated that in ecosystems under sparse vegetation in the arid region the strong positive relationship between swc and e weakened the ecosystem water carbon coupling and induced a convex nonlinear relationship between daily gpp and et in addition the water carbon coupling strength and the roles played by water and carbon fluxes in daily wue varied with growth stages at both the canopy and ecosystem scales specifically the water carbon coupling strength was higher in the early and late growing seasons than in the middle growing season and carbon flux mainly determined wue in the early and late growing seasons whereas it changed to water flux in the middle growing season with e playing a more critical function than t in daily wuee the sem results showed that canopy development in the early and late growing seasons as well as the water and radiation conditions in the middle growing season played key roles in controlling the water carbon coupling this study highlighted the critical role of swc and e in controlling the water carbon relationship in ecosystems with sparse canopies in arid regions especially when precipitation or irrigation occurred moreover a deep understanding and full consideration of the distinct water carbon coupling strength and the roles played by water and carbon fluxes in wue in different growth stages could help improve the accuracy of process based ecosystem models our results also provide new references and evidence for a more profound understanding of the water carbon coupling further research could focus on the physiological explanation of the results at the leaf scale the applicability of the conclusion at other spatial scales and the improvement of the quantitative relationship between ecosystem wue and the factors credit authorship contribution statement lei gao data curation formal analysis investigation methodology writing original draft shaozhong kang conceptualization resources writing review editing funding acquisition supervision project administration xueer bai data curation writing review editing sien li writing review editing jun niu writing review editing risheng ding writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was financially and jointly supported by the national natural science foundation of china grant number 51790534 and the 111 program of introducing talents of discipline to universities grant number b14002 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126469 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
